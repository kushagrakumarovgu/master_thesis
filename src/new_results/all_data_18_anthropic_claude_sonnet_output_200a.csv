reviews,sentiment_scores,politeness_scores,reasonings
"[""Update: Based on the discussions and the revisions, I have improved my rating. However I still feel like the novelty is somewhat limited, hence the recommendation.\n\n======================\n\nThe paper introduces a system to estimate a floor-level via their mobile device's sensor data using an LSTM to determine when a smartphone enters or exits a building, then using the change in barometric pressure from the entrance of the building to indoor location. Overall the methodology is a fairly simple application of existing methods to a problem, and  there remain some methodological issues (see below).\n\nGeneral Comments\n- The claim that the bmp280 device is in most smartphones today doesn’t seem to be backed up by the “comScore” reference (a simple ranking of manufacturers).  Please provide the original source for this information.\n- Almost all exciting results based on RNNs are achieved with LSTMs, so calling an RNN with LSTM hidden units a new name IOLSTM seems rather strange - this is simply an LSTM.\n- There exist models for modelling multiple levels of abstraction, such as the contextual LSTM of [1]. This would be much more satisfying that the two level approach taken here, would likely perform better, would replace the need for the clustering method, and would solve issues such as the user being on the roof.  The only caveat is that it may require an encoding of the building (through a one-hot encoding) to ensure that the relationship between the floor height and barometric pressure is learnt. For unseen buildings a background class could be used, the estimators as used before, or aggregation of the other buildings by turning the whole vector on.\n- It’s not clear if a bias of 1 was added to the forget gate of the LSTM or not. This has been shown to improve results [2].\n- Overall the whole pipeline feels very ad-hoc, with many hand-tuned parameters.  Notwithstanding the network architecture, here I’m referring to the window for the barometric pressure, the Jaccard distance threshold, the binary mask lengths, and the time window for selecting p0.\n- Are there plans to release the data and/or the code for the experiments? Currently the results would be impossible to reproduce.\n- The typo of accuracy given by the authors is somewhat worrying, given that the result is repeated several times in the paper.\n\nTypographical Issues\n- Page 1:  ”floor-level accuracy” back ticks\n- Page  4:   Figure  4.1→Figure  1;  Nawarathne  et  al  Nawarathne  et  al.→Nawarathne et al.\n- Page 6:  ”carpet to carpet” back ticks\n- Table 2:  What does -4+ mean?\n- References.  The references should have capitalisation where appropriate.For example,  Iodetector→IODetector,  wi-fi→Wi-Fi,  apple→Apple, iphone→iPhone, i→I etc.\n\n[1]  Shalini Ghosh, Oriol Vinyals, Brian Strope, Scott Roy, Tom Dean, and LarryHeck. Contextual LSTM (CLSTM) models for large scale NLP tasks. arXivpreprint arXiv:1602.06291, 2016.\n[2]  Rafal Jozefowicz, Wojciech Zaremba, and Ilya Sutskever.  An empirical exploration of recurrent network architectures.  InProceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 2342–2350,2015"", 'The authors motivate the problem of floor level estimation and tackle it with a RNN. The results are good. The models the authors compare to are well chosen. As the paper foremost provides application (and combination) of existing methods it would be benefitial to know something about the limitations of their approach and about the observed prequesits. ', ""The paper proposes a two-step method to determine which floor a mobile phone is on inside a tall building. \nAn LSTM RNN classifier analyzes the changes/fading in GPS signals to determine whether a user has entered a building.  Using the entrance point's barometer reading as a reference, the method calculates the relative floor the user has moved to using a well known relationship between heights and barometric readings.\n\nThe paper builds on a simple but useful idea and is able to develop it into a basic method for the goal.  The method has minimal dependence on prior knowledge and is thus expected to have wide applicability, and is found to be sufficiently successful on data collected from a real world context.  The authors present some additional explorations on the cases when the method may run into complications.\n\nThe paper could use some reorganization.   The ideas are presented often out of order and are repeated in cycles, with some critical details that are needed to understand the method revealed only in the later cycles.   Most importantly, it should be stated upfront that the outdoor-indoor transition is determined using the loss of GPS signals.  Instead, the paper elaborates much on the neural net model but delays until the middle of p.4 to state this critical fact. However once this fact is stated, it is obvious that the neural net model is not the only solution.\n\nThe RNN model for Indoor/Outdoor determination is compared to several baseline classifiers.  However these are not the right methods to compare to -- at least, it is not clear how you set up the vector input to these non-auto-regressive classifiers. You need to compare your model to a time series method that includes auto-regressive terms, or other state space methods like Markov models or HMMs.\n\nOther questions:\n\np.2,  Which channel's RSSI is the one included in the data sample per second?\n\np.4,  k=3, what is k?\n\nDo you assume that the entrance is always at the lowest floor? What about basements or higher floor entrances?  Also, you may continue to see good GPS signals in elevators that are mounted outside a building, and by the time they fade out,  you can be on any floor reached by those elevators.\n\nHow does each choice of your training parameters affect the performance?  e.g. number of epoches, batch size, learning rate.   What are the other architectures considered?  What did you learn about which architecture works and which does not?  Why?\n\nAs soon as you start to use clustering to help in floor estimation, you are exploiting prior knowledge about previous visits to the building.  This goes somewhat against the starting assumption and claim.""]","[-20, 60, 20]","[50, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects, they express concerns about the novelty and methodological issues. The reviewer states that the methodology is 'a fairly simple application of existing methods' and mentions several areas for improvement. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, offering constructive criticism and specific suggestions for improvement. They use phrases like 'please provide' and 'it's not clear if' which are polite ways of requesting clarification. The reviewer also balances critique with positive acknowledgments, such as mentioning the 'exciting results' of RNNs with LSTMs. However, some phrases like 'somewhat worrying' and 'strange' slightly reduce the politeness score."", ""The sentiment score is 60 (positive) because the reviewer states that the results are good, the model comparisons are well-chosen, and the paper provides a valuable application of existing methods. However, it's not extremely positive as the reviewer suggests some improvements. The politeness score is 50 (somewhat polite) because the language is professional and constructive, without any harsh criticism. The reviewer acknowledges the paper's strengths and offers suggestions for improvement in a respectful manner. The tone is neutral to slightly positive, avoiding overly effusive praise or harsh criticism, which is appropriate for a scientific peer review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's useful idea, wide applicability, and successful real-world testing. However, they also point out several areas for improvement, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'could use some reorganization' and ask questions to prompt further thought, maintaining a professional and courteous tone. The reviewer balances positive feedback with areas for improvement, demonstrating a fair and considerate approach to the review process.""]"
"['The paper presents a method for finding related images (analogies) from different domains based on matching-by-synthesis. The general idea is interesting and the results show improvements over previous approaches, such as CycleGAN (with different initializations, pre-learned or not). The algorithm is tested on three datasets.\n\nWhile the approach has some strong positive points, such as good experiments and theoretical insights (the idea to match by synthesis and the proposed loss which is novel, and combines the proposed concepts), the paper lacks clarity and sufficient details.\n\nInstead of the longer intro and related work discussion, I would prefer to see a Figure with the architecture and more illustrative examples to show that the insights are reflected in the experiments. Also, the matching part, which is discussed at the theoretical level, could be better explained and presented at a more visual level. It is hard to understand sufficiently well what the formalism means without more insight.\n\nAlso, the experiments need more details. For example, it is not clear what the numbers in Table 2 mean.\n\n\n\n', 'This paper adds an interesting twist on top of recent unpaired image translation work. A domain-level translation function is jointly optimized with an instance-level matching objective. This yields the ability to extract corresponding image pairs out of two unpaired datasets, and also to potentially refine unpaired translation by subsequently training a paired translation function on the discovered matches. I think this is a promising direction, but the current paper has unconvincing results, and it’s not clear if the method is really solving an important problem yet.\n\nMy main criticism is with the experiments and results. The experiments focus almost entirely on the setting where there actually exist exact matches between the two image sets. Even the partial matching experiments in Section 4.1.2 only quantify performance on the images that have exact matches. This is a major limitation since the compelling use cases of the method are in scenarios where we do not have exact matches. It feels rather contrived to focus so much on the datasets with exact matches since, 1) these datasets actually come as paired data and, in actual practice, supervised translation can be run directly, 2) it’s hard to imagine datasets that have exact but unknown matches (I welcome the authors to put forward some such scenarios), 3) when exact matches exist, simpler methods may be sufficient, such as matching edges. There is no comparison to any such simple baselines.\n\nI think finding analogies that are not exact matches is much more compelling. Quantifying performance in this case may be hard, and the current paper only offers a few qualitative results. I’d like to see far more results, and some attempt at a metric. One option would be to run user studies where humans judge the quality of the matches. The results shown in Figure 2 don’t convince me, not just because they are qualitative and few, but also because I’m not sure I even agree that the proposed method is producing better results: for example, the DiscoGAN results have some artifacts but capture the texture better in row 3.\n\nI was also not convinced by the supervised second step in Section 4.3. Given that the first step achieves 97% alignment accuracy, it’s no surprised that running an off-the-shelf supervised method on top of this will match the performance of running on 100% correct data. In other words, this section does not really add much new information beyond what we could already infer given that the first stage alignment was so successful.\n\nWhat I think would be really interesting is if the method can improve performance on datasets that actually do not have ground truth exact matches. For example, the shoes and handbags dataset or even better, domain adaptation datasets like sim to real.\n\nI’d like to see more discussion of why the second stage supervised problem is beneficial. Would it not be sufficient to iterate alpha and T iterations enough times until alpha is one-hot and T is simply training against a supervised objective (Equation 7)?\n\nMinor comments:\n1. In the intro, it would be useful to have a clear definition of “analogy” for the present context.\n2. Page 2: a link should be provided for the Putin example, as it is not actually in Zhu et al. 2017.\n3. Page 3: “Weakly Supervised Mapping” — I wouldn’t call this weakly supervised. Rather, I’d say it’s just another constraint / prior, similar to cycle-consistency, which was referred to under the “Unsupervised” section.\n4. Page 4 and throughout: It’s hard to follow which variables are being optimized over when. For example, in Eqn. 7, it would be clearer to write out the min over optimization variables.\n5. Page 6: The Maps dataset was introduced in Isola et al. 2017, not Zhu et al. 2017.\n6. Page 7: The following sentence is confusing and should be clarified: “This shows that the distribution matching is able to map source images that are semantically similar in the target domain.”\n7. Page 7: “This shows that a good initialization is important for this task.” — Isn’t this more than initialization? Rather, removing the distributional and cycle constraints changes the overall objective being optimized.\n8. In Figure 2, are the outputs the matched training images, or are they outputs of the translation function?\n9. Throughout the paper, some citations are missing enclosing parentheses.', 'This paper presents an image-to-image cross domain translation framework based on generative adversarial networks. The contribution is the addition of an explicit exemplar constraint into the formulation which allows best matches from the other domain to be retrieved. The results show that the proposed method is superior for the task of exact correspondence identification and that AN-GAN rivals the performance of pix2pix with strong supervision.\n\n\nNegatives:\n1.) The task of exact correspondence identification seems contrived. It is not clear which real-world problems have this property of having both all inputs and all outputs in the dataset, with just the correspondence information between inputs and outputs missing.\n2.) The supervised vs unsupervised experiment on Facades->Labels (Table 3) is only one scenario where applying a supervised method on top of AN-GAN’s matches is better than an unsupervised method.  More transfer experiments of this kind would greatly benefit the paper and support the conclusion that “our self-supervised method performs similarly to the fully supervised method.” \n\nPositives:\n1.) The paper does a good job motivating the need for an explicit image matching term inside a GAN framework\n2.) The paper shows promising results on applying a supervised method on top of AN-GAN’s matches.\n\nMinor comments:\n1. The paper sometimes uses L1 and sometimes L_1, it should be L_1 in all cases.\n2. DiscoGAN should have the Kim et al citation, right after the first time it is used. I had to look up DiscoGAN to realize it is just Kim et al.']","[20, -30, 50]","[50, 50, 75]","[""The sentiment score is 20 (slightly positive) because the reviewer acknowledges the paper's interesting ideas, improvements over previous approaches, and strong positive points like good experiments and theoretical insights. However, they also point out significant shortcomings in clarity and detail, which tempers the positive sentiment. The politeness score is 50 (moderately polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They balance positive feedback with areas for improvement, using phrases like 'I would prefer to see' instead of more demanding language. The review maintains a professional tone while clearly communicating the paper's strengths and weaknesses."", ""The sentiment score is -30 because while the reviewer acknowledges the paper as 'interesting' and a 'promising direction', they express significant criticisms about the experiments, results, and overall convincingness of the work. The reviewer states that the 'current paper has unconvincing results' and it's 'not clear if the method is really solving an important problem yet'. These criticisms outweigh the initial positive remarks, resulting in a slightly negative overall sentiment.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think', 'I'd like to see', and 'I welcome the authors to', which are polite ways of expressing opinions and suggestions. The criticism is presented constructively, focusing on the work rather than the authors personally. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral to slightly positive tone in terms of politeness."", ""The sentiment score is 50 (slightly positive) because the review begins with a neutral summary of the paper's content, followed by a balanced presentation of both negatives and positives. The reviewer acknowledges the paper's contributions and promising results, while also pointing out areas for improvement. The politeness score is 75 (fairly polite) because the reviewer uses professional and respectful language throughout. They provide constructive criticism without harsh or dismissive comments, and they balance negative points with positive ones. The use of phrases like 'The paper does a good job' and the inclusion of 'Minor comments' rather than major criticisms further contribute to the polite tone.""]"
"[""This paper introduces bi-directional block self-attention model (Bi-BioSAN) as a general-purpose encoder for sequence modeling tasks in NLP. The experiments include tasks like natural language inference, reading comprehension (SquAD), semantic relatedness and sentence classifications. The new model shows decent performance when comparing with Bi-LSTM, CNN and other baselines while running at a reasonably fast speed.\n\nThe advantage of this model is that we can use little memory (as in RNNs) and enjoy the parallelizable computation as in (SANs), and achieve similar (or better) performance.\n\nWhile I do appreciate the solid experiment section, I don't think the model itself is sufficient contribution for a publication at ICLR. First, there is not much innovation in the model architecture. The idea of the Bi-BioSAN model simply to split the sentence into blocks and compute self-attention for each of them, and then using the same mechanisms as a pooling operation followed by a fusion level. I think this more counts as careful engineering of the SAN model rather than a main innovation. Second, the model introduces much more parameters. In the experiments, it can easily use 2 times parameters than the commonly used encoders. What if we use the same amount of parameters for Bi-LSTM encoders? Will the gap between the new model and the commonly used ones be smaller?\n\n====\n\nI appreciate the answers the authors added and I change the score to 6."", 'Pros: \nThe paper proposes a “bi-directional block self-attention network (Bi-BloSAN)” for sequence encoding, which inherits the advantages of multi-head (Vaswani et al., 2017) and DiSAN (Shen et al., 2017) network but is claimed to be more memory-efficient. The paper is written clearly and is easy to follow. The source code is released for duplicability. The main originality is using block (or hierarchical) structures; i.e., the proposed models split the an entire sequence into blocks, apply an intra-block SAN to each block for modeling local context, and then apply an inter-block SAN to the output for all blocks to capture long-range dependency. The proposed model was tested on nine benchmarks  and achieve good efficiency-memory trade-off. \n\nCons:\n- Methodology of the paper is very incremental compared with previous models.  \n- Many of the baselines listed in the paper are not competitive; e.g.,  for SNLI, state-of-the-art results are not included in the paper. \n- The paper argues advantages of the proposed models over CNN by assuming the latter only captures local dependency, which, however, is not supported by discussion on or comparison with hierarchical CNN.\n- The block splitting (as detailed in appendix) is rather arbitrary in terms of that it potentially divides coherent language segments apart. This is unnatural, e.g., compared  with alternatives such as using linguistic segments as blocks.\n- The main originality of paper is the block style. However, the paper doesn’t analyze how and why the block brings improvement. \n-If we remove intra-block self-attention (but only keep token-level self-attention), whether the performance will be significantly worse?\n', ""This high-quality paper tackles the quadratic dependency of memory on sequence length in attention-based models, and presents strong empirical results across multiple evaluation tasks. The approach is basically to apply self-attention at two levels, such that each level only has a small, fixed number of items, thereby limiting the memory requirement while having negligible impact on speed. It captures local information into so-called blocks using self-attention, and then applies a second level of self-attention over the blocks themselves.\n\nThe paper is well organized and clearly written, modulo minor language mistakes that should be easy to fix with further proof-reading. The contextualization of the method relative to CNNs/RNNs/Transformers is good, and the beneficial trade-offs between memory, runtime and accuracy are thoroughly investigated, and they're compelling.\n\nI am curious how the story would look if one tried to push beyond two levels...? For example, how effective might a further inter-sentence attention level be for obtaining representations for long documents? \n\nMinor points:\n- Text between Eq 4 & 5: W^{(1)} appears twice; one instance should probably be W^{(2)}.\n- Multiple locations, e.g. S4.1: for NLI, the word is *premise*, not *promise*.\n- Missing word in first sentence of S4.1: ... reason __ the ...""]","[-20, -20, 90]","[50, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('solid experiment section', 'decent performance'), they ultimately express skepticism about the paper's contribution and innovation. The reviewer states 'I don't think the model itself is sufficient contribution for a publication at ICLR' and raises concerns about the model's novelty and parameter count. However, the final sentence indicates a slight improvement in the reviewer's assessment after author responses. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positive aspects and framing criticisms constructively. Phrases like 'I do appreciate' and 'I appreciate the answers' demonstrate politeness, even while expressing concerns."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is written clearly', 'achieve good efficiency-memory trade-off'), there are more criticisms than praises. The cons section is longer and points out several limitations of the paper. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents both pros and cons in a professional manner without harsh criticism. The reviewer acknowledges the paper's strengths before listing its weaknesses, which is a polite approach. The language used is objective and constructive, avoiding personal attacks or overly negative phrasing."", ""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer describes the paper as 'high-quality' and praises its organization, clarity, and compelling results. They mention only minor language mistakes and express curiosity about potential extensions, which are constructive comments rather than criticisms. The politeness score is 80 because the reviewer uses respectful and professional language throughout. They offer praise generously and frame their suggestions and questions in a constructive manner. The minor points are presented as helpful observations rather than harsh criticisms. The overall tone is collegial and supportive, though not excessively formal or deferential, hence the score of 80 rather than 100.""]"
"['The authors propose a hybrid Bayesian inference approach for deep topic models that integrates stochastic gradient MCMC for global parameters and Weibull-based multilayer variational autoencoders (VAEs) for local parameters. The decoding arm of the VAE consists of deep latent Dirichlet allocation, and an upward-downward structure for the encoder. Gamma distributions are approximated as Weibull distributions since the Kullback-Leibler divergence is known and samples can be efficiently drawn from a transformation of samples from a uniform distribution. \n\nThe results in Table 1 are concerning for several reasons, i) the proposed approach underperfroms DLDA-Gibbs and DLDA-TLASGR. ii) The authors point to the scalability of the mini-batch-based algorithms, however, although more expensive, DLDA-Gibbs, is not prohibitive given results for Wikipedia are provided. iii) The proposed approach is certainly faster at test time, however, it is not clear to me in which settings such speed (compared to Gibbs) would be needed, provided the unsupervised nature of the task at hand. iv) It is not clear to me why there is no test-time difference between WAI and WHAI, considering that in the latter, global parameters are sampled via stochastic-gradient MCMC. One possible explanation being that during test time, the approach does not use samples from W but rather a summary of them, say posterior means, in which case, it defeats the purpose of sampling from global parameters, which may explain why WAI and WHAI perform about the same in the 3 datasets considered.\n\n- \\Phi is in a subset of R_+, in fact, columns of \\Phi are in the P_0-dimensional simplex.\n- \\Phi should have K_1 columns not K.\n- The first paragraph in Page 5 is very confusing because h is introduced before explicitly connecting it to k and \\lambda. Also, if k = \\lambda, why introduce different notations?', ""The authors develop a hybrid amortized variational inference MCMC inference \nframework for deep latent Dirichlet allocation. Their model consists of a stack of\n gamma factorization layers with a Poisson layer at the bottom. They amortize \ninference at the observation level using a Weibull approximation. The structure \nof the inference network mimics the MCMC sampler for this model. Finally they \nuse MCMC to infer the parameters shared across data. A couple of questions:\n\n1) How effective are the MCMC steps at mixing? It looks like this approach helps a \nbit with local optima?\n\n2) The gamma distribution can be reparameterized via its rejection sampler \n\n@InProceedings{pmlr-v54-naesseth17a,\n  title = \t {{Reparameterization Gradients through Acceptance-Rejection Sampling Algorithms}},\n  author = \t {Christian Naesseth and Francisco Ruiz and Scott Linderman and David Blei},\n  booktitle = \t {Proceedings of the 20th International Conference on Artificial Intelligence and Statistics},\n  pages = \t {489--498},\n  year = \t {2017}\n}\n\nI think some of the motivation for the Weibull is weakened by this work. Maybe a \ncomparison is in order?\n\n3) Analytic KL divergence can be good or bad. It depends on the correlation between \nthe gradients of the stochastic KL divergence and the stochastic log-likelihood\n\n4) One of the original motivations for DLDA was that the augmentation scheme \nremoved the need for most non-conjugate inference. However, this approach doesn't \nuse that directly. Thus, it seems more similar to inference procedure in deep exponential \nfamilies. Was the structure of the inference network proposed here crucial?\n\n5) How much like a Weibull do you expect the posterior to be? This seems unclear."", ""The paper presents a deep Poisson model where the last layer is the vector of word counts generated by a vector Poisson. This is parameterized by a matrix vector product, and the vector in this parameterizeation is itself generated by a vector Gamma with a matrix-vector parameterization. From there the vectors are all Gammas with matrix-vector parameterizations in a typical deep setup.\n\nWhile the model is reasonable, the purpose was not clear to me. If only the last layer generates a document, then what use is the deep structure? For example, learning hierarchical topics as in Figure 4 doesn't seem so useful here since only the last layer matters. Also, since no input is being mapped to an output, what does going deeper mean? It doesn't look like any linear mapping is being learned from the input to output spaces, so ultimately the document itself is coming from a simple linear Poisson model just like LDA and other non-deep methods.\n\nThe experiments are otherwise thorough and convincing that quantitative performance is improved over previous attempts at the problem.""]","[-50, 20, -20]","[20, 70, 50]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the proposed approach, particularly its underperformance compared to other methods and unclear advantages. The reviewer uses phrases like 'The results... are concerning for several reasons' and lists multiple issues, indicating a generally negative sentiment. However, it's not entirely negative as the reviewer acknowledges some potential benefits like faster test time. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'It is not clear to me' rather than making accusatory statements, and provide specific, constructive feedback. The language is formal and objective, avoiding personal attacks or overly harsh criticism."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the authors' work and asks thoughtful questions, indicating interest in the research. However, they also point out potential weaknesses and suggest comparisons, which prevents a higher positive score. The politeness score is relatively high (70) as the reviewer uses respectful language, frames their points as questions or suggestions rather than criticisms, and acknowledges the authors' work. The reviewer maintains a professional and constructive tone throughout, avoiding harsh or dismissive language. The use of phrases like 'I think' and 'Maybe a comparison is in order?' further contribute to the polite tone by presenting ideas as suggestions rather than demands."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the experiments are thorough and convincing, they express significant doubts about the purpose and usefulness of the deep structure in the model. The reviewer questions the utility of the deep layers and suggests that the model ultimately reduces to a simple linear Poisson model. These criticisms outweigh the positive comments about the experiments.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'the model is reasonable' and 'experiments are thorough and convincing,' which show respect for the authors' work. The criticisms are presented as questions or observations rather than harsh judgments. However, the score is not higher because the review lacks overtly polite language or praise, maintaining a mostly neutral, academic tone.""]"
"['This paper presents a method to cope with adversarial examples in classification tasks, leveraging a generative model of the inputs.  Given an accurate generative model of the input, this approach first projects the input onto the manifold learned by the generative model (the idea being that inputs on this manifold reflect the non-adversarial input distribution).  This projected input is then used to produce the classification probabilities.  The authors test their method on various adversarially constructed inputs (with varying degrees of noise). \n\nQuestions/Comments:\n\n- I am interested in unpacking the improvement of Defense-GAN over the MagNet auto-encoder based method.  Is the MagNet auto-encoder suffering lower accuracy because the projection of an adversarial image is based on an encoding function that is learned only on true data?  If the decoder from the MagNet approach were treated purely as a generative model, and the same optimization-based projection approach (proposed in this work) was followed, would the results be comparable?  \n\n- Is there anything special about the GAN approach, versus other generative approaches? \n\n- In the black-box vs. white-box scenarios, can the attacker know the GAN parameters?  Is that what is meant by the ""defense network"" (in experiments bullet 2)?\n\n- How computationally expensive is this approach take compared to MagNet or other adversarial approaches? \n\nQuality: The method appears to be technically correct.\n\nClarity: This paper clearly written; both method and experiments are presented well. \n\nOriginality: I am not familiar enough with adversarial learning to assess the novelty of this approach. \n\nSignificance: I believe the main contribution of this method is the optimization-based approach to project onto a generative model\'s manifold.  I think this kernel has the potential to be explored further (e.g. computational speed-up, projection metrics).', 'This paper presents Defense-GAN: a GAN that used at test time to map the input generate an image (G(z)) close (in MSE(G(z), x)) to the input image (x), by applying several steps of gradient descent of this MSE. The GAN is a WGAN trained on the train set (only to keep the generator). The goal of the whole approach is to be robust to adversarial examples, without having to change the (downstream task) classifier, only swapping in the G(z) for the x.\n\n+ The paper is easy to follow.\n+ It seems (but I am not an expert in adversarial examples) to cite the relevant litterature (that I know of) and compare to reasonably established attacks and defenses.\n+ Simple/directly applicable approach that seems to work experimentally, but\n- A missing baseline is to take the nearest neighbour of the (perturbed) x from the training set.\n- Only MNIST-sized images, and MNIST-like (60k train set, 10 labels) datasets: MNIST and F-MNIST.\n- Between 0.043sec and 0.825 sec to reconstruct an MNIST-sized image.\n? MagNet results were very often worse than no defense in Table 4, could you comment on that?\n- In white-box attacks, it seems to me like L steps of gradient descent on MSE(G(z), x) should be directly extended to L steps of (at least) FGSM-based attacks, at least as a control.', 'The authors describe a new defense mechanism against adversarial attacks on classifiers (e.g., FGSM). They propose utilizing Generative Adversarial Networks (GAN), which are usually used for training generative models for an unknown distribution, but have a natural adversarial interpretation. In particular, a GAN consists of a generator NN G which maps a random vector z to an example x, and a discriminator NN D which seeks to discriminate between an examples produced by G and examples drawn from the true distribution. The GAN is trained to minimize the max min loss of D on this discrimination task, thereby producing a G (in the limit) whose outputs are indistinguishable from the true distribution by the best discriminator. \n\nUtilizing a trained GAN, the authors propose the following defense at inference time. Given a sample x (which has been adversarially perturbed), first project x onto the range of G by solving the minimization problem z* = argmin_z ||G(z) - x||_2. This is done by SGD. Then apply any classifier trained on the true distribution on the resulting x* = G(z*). \n\nIn the case of existing black-box attacks, the authors argue (convincingly) that the method is both flexible and empirically effective. In particular, the defense can be applied in conjunction with any classifier (including already hardened classifiers), and does not assume any specific attack model. Nevertheless, it appears to be effective against FGSM attacks, and competitive with adversarial training specifically to defend against FGSM. \n\nThe authors provide less-convincing evidence that the defense is effective against white-box attacks. In particular, the method is shown to be robust against FGSM, RAND+FGSM, and CW white-box attacks. However, it is not clear to me that the method is invulnerable to novel white-box attacks. In particular, it seems that the attacker can design an x which projects onto some desired x* (using some other method entirely), which then fools the classifier downstream.\n\nNevertheless, the method is shown to be an effective tool for hardening any classifier against existing black-box attacks \n(which is arguably of great practical value). It is novel and should generate further research with respect to understanding its vulnerabilities more completely. \n\nMinor Comments:\nThe sentence starting “Unless otherwise specified…” at the top of page 7 is confusing given the actual contents of Tables 1 and 2, which are clarified only by looking at Table 5 in the appendix. This should be fixed.  \n']","[50, 20, 60]","[80, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's technical correctness, clear writing, and potential significance. They express interest in the method and ask thoughtful questions, indicating engagement with the work. However, they don't express strong enthusiasm or praise, keeping the sentiment moderately positive. The politeness score is 80 (quite polite) due to the reviewer's respectful tone throughout. They frame their comments as questions and suggestions rather than criticisms, use phrases like 'I am interested in' and 'I believe', and provide balanced feedback on different aspects of the paper. The language is professional and constructive, without any harsh or dismissive remarks."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges several positive aspects of the paper, such as it being easy to follow, citing relevant literature, and presenting a simple and applicable approach. However, there are also some criticisms and limitations pointed out, which prevent a higher positive score. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents both positive and negative points in a balanced manner without harsh criticism. The reviewer also uses phrases like 'it seems' and poses a question, which adds a polite tone to the critique. The combination of constructive feedback and respectful language contributes to the overall politeness of the review."", ""The sentiment score is 60 (positive) because the reviewer generally expresses approval of the authors' work, describing it as 'novel', 'effective', and of 'great practical value'. They mention that the method is 'convincingly' argued for black-box attacks and should 'generate further research'. However, it's not entirely positive as they express some doubts about its effectiveness against white-box attacks. The politeness score is 50 (somewhat polite) because the reviewer uses respectful language throughout, acknowledging the authors' contributions and providing constructive feedback. They use phrases like 'the authors argue (convincingly)' and offer balanced critiques. The tone is professional and courteous, though not excessively formal or deferential. The minor comments at the end are presented as suggestions rather than harsh criticisms.""]"
"['The paper investigates different representation learning methods to create a latent space for intrinsic goal generation in guided exploration algorithms.  The research is in principle very important and interesting.\n\nThe introduction discusses a great deal about intrinsic motivations and about goal generating algorithms. This is really great, just that the paper only focuses on a very small aspect of learning a state representation in an agent that has no intrinsic motivation other than trying to achieve random goals.\nI think the paper (not only the Intro) could be a bit condensed to more concentrate on the actual contribution. \n\nThe contribution is that the quality of the representation and the sampling of goals is important for the exploration performance and that classical methods like ISOMap are better than Autoencoder-type methods. \n\nAlso, it is written in the Conclusions (and in other places): ""[..] we propose a new intrinsically Motivated goal exploration strategy...."". This is not really true.  There is nothing new with the intrinsically motivated selection of goals here, just that they are in another space. Also, there is no intrinsic motivation. I also think the title is misleading.\n\nThe paper is in principle interesting. However, I doubt that the experimental evaluations are substantial enough for profound conclusion. \n\nSeveral points of critic: \n- the input space was very simple in all experiments, not suitable for distinguishing between the algorithms, for instance, ISOMap typically suffers from noise and higher dimensional manifolds, etc.\n- only the ball/arrow was in the input image, not the robotic arm. I understand this because in phase 1 the robot would not move, but this connects to the next point:\n- The representation learning is only a preprocessing step requiring a magic first phase.\n    -> Representation is not updated during exploration\n- The performance of any algorithm (except FI) in the Arm-Arrow task is really bad but without comment. \n- I am skeptical about the VAE  and RFVAE results. The difference between Gaussian sampling and the KDE is a bit alarming, as the KL in the VAE training is supposed to match the p(z) with N(0,1). Given the power of the encoder/decoder it should be possible to properly represent the simple embedded 2D/3D manifold and not just a very small part of it as suggested by Fig 10. \nI have a hard time believing these results. I urge you to check for any potential errors made. If there are not mistakes then this is indeed alarming.\n\nQuestions:\n- Is it true that the robot always starts from same initial condition?! Context=Emptyset. \n- For ISOMap etc, you also used a 10dim embedding?\n\nSuggestion:\n- The main problem seems to be that some algorithms are not representing the whole input space.\n- an additional measure that quantifies the difference between true input distribution and reproduced input distribution could tier the algorithms apart and would measure more what seems to be relevant here.  One could for instance measure the KL-divergence between the true input and the sampled (reconstructed) input (using samples and KDE or the like). \n- This could be evaluated on many different inputs (also those with a bit more complicated structure) without actually performing the goal finding.\n- BTW: I think Fig 10 is rather illustrative and should be somehow in the main part of the paper\n \nOn the positive side, the paper provides lots of details in the Appendix.\nAlso, it uses many different Representation Learning algorithms and uses measures from manifold learning to access their quality.\n\nIn the related literature, in particular concerning the intrinsic motivation, I think the following papers are relevant:\nJ. Schmidhuber, PowerPlay: training an increasingly general problem solver by continually searching for the simplest still unsolvable problem. Front. Psychol., 2013.\n\nand\n\nG. Martius, R. Der, and N. Ay. Information driven self-organization of complex robotic behaviors. PLoS ONE, 8(5):e63400, 2013.\n\n\nTypos and small details:\np3 par2: for PCA you cited Bishop. Not critical, but either cite one the original papers or maybe remove the cite altogether\np4 par-2: has multiple interests...: interests -> purposes?\np4 par-1: Outcome Space to the agent is is ...\nSec 2.2 par1: are rapidly mentioned... -> briefly\nSec 2.3 ...Outcome Space O, we can rewrite the architecture as:\n  and then comes the algorithm. This is a bit weird\nSec 3: par1: experimental campaign -> experiments?\np7: Context Space: the object was reset to a random position or always to the same position?\nFootnote 14: superior to -> larger than\np8 par2: Exploration Ratio Ratio_expl... probably also want to add (ER) as it is later used\nSec 4: slightly underneath -> slightly below\np9 par1: unfinished sentence: It is worth noting that the....\none sentence later: RP architecture? RPE?\nFig 3: the error of the methods (except FI) are really bad. An MSE of 1 means hardly any performance!\np11 par2: for e.g. with the SAGG..... grammar?\n\nPlots in general: use bigger font sizes.\n\n', '[Edit: After revisions, the authors have made a good-faith effort to improve the clarity and presentation of their paper: figures have been revised, key descriptions have been added, and (perhaps most critically) a couple of small sections outlining the contributions and significance of this work have been written. In light of these changes, I\'ve updated my score.]\n\nSummary:\n\nThe authors aim to overcome one of the central limitations of intrinsically motivated goal exploration algorithms by learning a representation without relying on a ""designer"" to manually specify the space of possible goals. This work is significant as it would allow one to learn a policy in complex environments even in the absence of a such a designer or even a clear notion of what would constitute a ""good"" distribution of goal states.\n\nHowever, even after multiple reads, much of the remainder of the paper remains unclear. Many important details, including the metrics by which the authors evaluate performance of their work, can only be found in the appendix; this makes the paper very difficult to follow.\n\nThere are too many metrics and too few conclusions for this paper. The authors introduce a handful of metrics for evaluating the performance of their approach; I am unfamiliar with a couple of these metrics and there is not much exposition justifying their significance and inclusion in the paper. Furthermore, there are myriad plots showing the performance of the different algorithms, but very little explanation of the importance of the results. For instance, in the middle of page 9, it is noted that some of the techniques ""yield almost as low performance as"" the randomized baseline, yet no attempt is made to explain why this might be the case or what implications it has for the authors\' approach. This problem pervades the paper: many metrics are introduced for how we might want to evaluate these techniques, yet there is no provided reason to prefer one over another (or even why we might want to prefer them over the classical techniques).\n\nOther comments:\n- There remain open questions about the quality of the MSE numbers; there are a number of instances in which the authors cite that the ""Meta-Policy MSE is not a simple to interpret"" (The remainder of this sentence is incomplete in the paper), yet little is done to further justify why it was used here, or why many of the deep representation techniques do not perform very well.\n- The authors do not list how many observations they are given before the deep representations are learned. Why is this? Additionally, is it possible that not enough data was provided?\n- The authors assert that 10 dimensions was chosen arbitrarily for the size of the latent space, but this seems like a hugely important choice of parameter. What would happen if a dimension of 2 were chosen? Would the performance of the deep representation models improve? Would their performance rival that of RGE-FI?\n- The authors should motivate the algorithm on page 6 in words before simply inserting it into the body of the text. It would improve the clarity of the paper.\n- The authors need to be clearer about their notation in a number of places. For instance, they use \\gamma to represent the distribution of goals, yet it does not appear on page 7, in the experimental setup.\n- It is never explicitly mentioned exactly how the deep representation learning methods will be used. It is pretty clear to those who are familiar with the techniques that the latent space is what will be used, but a few equations would be instructive (and would make the paper more self-contained).\n\nIn short, the paper has some interesting ideas, yet lacks a clear takeaway message. Instead, it contains a large number of metrics and computes them for a host of different possible variations of the proposed techniques, and does not include significant explanation for the results. Even given my lack of expertise in this subject, the paper has some clear flaws that need addressing.\n\nPros:\n- A clear, well-written abstract and introduction\n- While I am not experienced enough in the field to really comment on the originality, it does seem that the approach the authors have taken is original, and applies deep learning techniques to avoid having to custom-design a ""feature space"" for their particular family of problems.\n\nCons:\n- The figure captions are all very ""matter-of-fact"" and, while they explain what each figure shows, provide no explanation of the results. The figure captions should be as self-contained as possible (I should be able to understand the figures and the implications of the results from the captions alone).\n- There is not much significance in the current form of the paper, owing to the lack of clear message. While the overarching problem is potentially interesting, the authors seem to make very little effort to draw conclusions from their results. I.e. it is difficult for me to easily visualize all of the ""moving parts"" of this work: a figure showing the relationship bet\n- Too many individual ideas are presented in the paper, hurting clarity. As a result, the paper feels scattered. The authors do not have a clear message that neatly ties the results together.', 'This paper introduces a representation learning step in the Intrinsically Motivated Exploration Process (IMGEP)  framework.\n\nThough this work is far from my expertise fields I find it quite easy to read and a good introduction to IMGEP.\nNevertheless I have some major concerns that prevent me from giving an acceptance decision.\n\n1) The method uses mechanisms than can project back and forth a signal  to the ""outcome"" space. Nevertheless only the encoder/projection part seems to be used in the algorithm presented p6. For example the encoder part of an AE/VAE is used as a preprocesing stage of the phenomenon dynamic D. It should be obviously noticed that the decoder part could also be used for helping the inverse model I but apparently that is not the case in the proposed method.\n\n2) The representation stage R seems to be learned at the beginning of the algorithm and then fixed. When using DNN as R (when using AE/VAE) why don\'t you propagate a gradient through R when optimizing D and I ? In this way, learning R at the beginning is only an old good pre-training of DNN with AE.\n\n3) Eventually, Why not directly considering R as lower layers of D and using up to date techniques to train it ? (drop-out, weight clipping, batch normalization ...).\nWhy not using architecture adapted to images such as CNN ?\n\n']","[-20, 20, -30]","[50, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance and interest of the research, they express several significant criticisms and doubts about the experimental evaluations and conclusions. They point out misleading statements, question the novelty of the contribution, and express skepticism about some results. However, they also note positive aspects like the detailed appendix and use of various algorithms.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think,' 'I doubt,' and 'I am skeptical' to express concerns without being harsh. They also provide constructive suggestions and acknowledge positive aspects of the paper. The reviewer uses polite language even when pointing out potential errors, saying 'I urge you to check for any potential errors made' rather than accusing the authors of mistakes. The overall tone is critical but constructive and courteous."", ""The sentiment score is 20 (slightly positive) because the reviewer acknowledges the authors' efforts to improve the paper and recognizes some positive aspects, such as the clear abstract and introduction, and the originality of the approach. However, they still express significant concerns about clarity, lack of conclusions, and other issues. The politeness score is 50 (moderately polite) because the reviewer uses respectful language throughout, acknowledges improvements, and frames criticisms constructively. They use phrases like 'good-faith effort,' 'interesting ideas,' and provide both pros and cons. The reviewer maintains a professional tone while clearly expressing concerns, avoiding harsh or rude language."", ""The sentiment score is slightly negative (-30) because while the reviewer finds the paper easy to read and a good introduction, they express 'major concerns' that prevent them from accepting the paper. They use phrases like 'Nevertheless I have some major concerns' which indicates a negative sentiment towards aspects of the work. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, starting with positive comments and using phrases like 'Though this work is far from my expertise fields I find it quite easy to read'. They also frame their concerns as questions or suggestions rather than harsh criticisms. The reviewer maintains a professional and respectful tone while providing constructive feedback.""]"
"[""An unsupervised approach is proposed to build bilingual dictionaries without parallel corpora, by aligning the monolingual word embeddings spaces, i.a. via adversarial learning.\n\nThe paper is very well-written and makes for a rather pleasant read, save for some need for down-toning the claims to novelty as voiced in the comment re: Ravi & Knight (2011) or simply in general: it's a very nice paper, I enjoy reading it *in spite*, and not *because* of the text sales-pitching itself at times.\n\nThere are some gaps in the awareness of the related work in the sub-field of bilingual lexicon induction, e.g. the work by Vulic & Moens (2016).\n\nThe evaluation is for the most part intrinsic, and it would be nice to see the approach applied downstream beyond the simplistic task of English-Esperanto translation: plenty of outlets out there for applying multilingual word embeddings. Would be nice to see at least some instead of the plethora of intrinsic evaluations of limited general interest.\n\nIn my view, to conclude, this is still a very nice paper, so I vote clear accept, in hope to see these minor flaws filtered out in the revision."", 'This paper presents a new method for obtaining a bilingual dictionary, without requiring any parallel data between the source and target languages. The method consists of an adversarial approach for aligning two monolingual word embedding spaces, followed by a refinement step using frequent aligned words (according to the adversarial mapping). The approach is evaluated on single word translation, cross-lingual word similarity, and sentence translation retrieval tasks.\n\nThe paper presents an interesting approach which achieves good performance. The work is presented clearly, the approach is well-motivated and related to previous studies, and a thorough evaluation is performed.\n\nMy one concern is that the supervised approach that the paper compares to is limited: it is trained on a small fixed number of anchor points, while the unsupervised method uses significantly more words. I think the paper\'s comparisons are valid, but the abstract and introduction make very strong claims about outperforming ""state-of-the-art supervised approaches"". I think either a stronger supervised baseline should be included (trained on comparable data as the unsupervised approach), or the language/claims in the paper should be softened. The same holds for statements like ""... our method is a first step ..."", which is very hard to justify. I also do not think it is necessary to over-sell, given the solid work in the paper.\n\nFurther comments, questions and suggestions:\n- It might be useful to add more details of your actual approach in the Abstract, not just what it achieves.\n- Given you use trained word embeddings, it is not a given that the monolingual word embedding spaces would be alignable in a linear way. The actual word embedding method, therefore, has a big influence on performance (as you show). Could you comment on how crucial it would be to train monolingual embedding spaces on similar domains/data with similar co-occurrence statistics, in order for your method to be appropriate?\n- Would it be possible to add weights to the terms in eq. (6), or is this done implicitly?\n- How were the 5k source words for Procrustes supervised baseline selected?\n- Have you considered non-linear mappings, or jointly training the monolingual word embeddings while attempting the linear mapping between embedding spaces?\n- Do you think your approach would benefit from having a few parallel training points?\n\nSome minor grammatical mistakes/typos (nitpicking):\n- ""gives a good performance"" -> ""gives good performance""\n- ""Recent works"", ""several works"", ""most works"", etc. -> ""recent studies"", ""several studies"", etc.\n- ""i.e, the improvements"" -> ""i.e., the improvements""\n\nThe paper is well-written, relevant and interesting. I therefore recommend that the paper be accepted.\n\n', 'The paper proposes a method to learn bilingual dictionaries without parallel data using an adversarial technique. The task is interesting and relevant, especially for in low-resource language pair settings.\n\nThe paper, however, misses comparison against important work from the literature that is very relevant to their task — decipherment (Ravi, 2013; Nuhn et al., 2012; Ravi & Knight, 2011) and other approaches like CCA. \n\nThe former set of works, while focused on machine translation also learns a translation table in the process. Besides, the authors also claim that their approach is particularly suited for low-resource MT and list this as one of their contributions. Previous works have used non-parallel and comparable corpora to learn MT models and for bilingual lexicon induction. The authors seem aware of corpora used in previous works (Tiedemann, 2012) yet provide no comparison against any of these methods. While some of the bilingual lexicon extraction works are cited (Haghighi et al., 2008; Artetxe et al., 2017), they do not demonstrate how their approach performs against these baseline methods. Such a comparison, even on language pairs which share some similarities (e.g., orthography), is warranted to determine the effectiveness of the proposed approach.\n\nThe proposed methodology is not novel, it rehashes existing adversarial techniques instead of other probabilistic models used in earlier works. \n\nFor the translation task, it would be useful to see performance of a supervised MT baseline (many tools available in open-source) that was trained on similar amount of parallel training data (60k pairs) and see the gap in performance with the proposed approach.\n\nThe paper mentions that the approach is “unsupervised”. However, it relies on bootstrapping from word embeddings learned on Wikipedia corpus, which is a comparable corpus even though individual sentences are not aligned across languages. How does the quality degrade if word embeddings had to be learned from scratch or initialized from a different source?']","[80, 70, -50]","[70, 80, 20]","[""The sentiment score is 80 (positive) because the reviewer expresses clear approval of the paper, calling it 'very well-written' and 'a very nice paper'. They vote for a 'clear accept' despite noting some minor flaws. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering constructive criticism alongside praise. They suggest improvements without being harsh, using phrases like 'it would be nice to see' and acknowledging the paper's strengths. The score is not 100 as there are some direct criticisms, albeit expressed politely."", ""The sentiment score is 70 (positive) because the reviewer states that the paper presents an 'interesting approach which achieves good performance' and recommends acceptance. They praise the clear presentation, good motivation, and thorough evaluation. However, it's not 100 due to some concerns about the comparison to supervised approaches and overly strong claims. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as questions or possibilities. They also acknowledge the paper's strengths and use phrases like 'I think' to soften critiques. The minor grammatical corrections are presented as 'nitpicking', showing awareness of their trivial nature. The overall tone is professional and supportive."", ""The sentiment score is -50 because while the reviewer acknowledges the interesting and relevant task, they express several significant criticisms. These include missing comparisons to important related work, lack of novelty in methodology, and questions about the unsupervised nature of the approach. The overall tone suggests more negative than positive sentiment, but not extremely negative.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'it would be useful to see' and 'such a comparison... is warranted' rather than making demands. The criticism is presented as constructive feedback rather than harsh judgement. However, the score is only slightly positive as the language, while not impolite, is also not overtly courteous or warm.""]"
"['Authors of this paper provided full characterization of the analytical forms of the critical points for the square loss function of three types of neural networks: shallow linear networks, deep linear networks and shallow ReLU nonlinear networks. The analytical forms of the critical points have direct implications on the values of the corresponding loss functions, achievement of global minimum, and various landscape properties around these critical points.\n\nThe paper is well organized and well written. Authors exploited the analytical forms of the critical points to provide a new proof for characterizing the landscape around the critical points. This technique generalizes existing work under full relaxation of assumptions. In the linear network with one hidden layer, it generalizes the work Baldi & Hornik (1989) with arbitrary network parameter dimensions and any data matrices; In the deep linear networks, it generalizes the result in Kawaguchi (2016) under no assumptions on the network parameters and data matrices. Moreover, it also provides new characterization for shallow ReLU nonlinear networks, which is not discussed in previous work.\n\nThe results obtained from the analytical forms of the critical points are interesting, but one problem is that how to obtain the proper solution of equation (3)? In the Example 1, authors gave a concrete example to demonstrate both local minimum and local maximum do exist in the shallow ReLU nonlinear networks by properly choosing these matrices satisfying (12). It will be interesting to see how to choose these matrices for all the studied networks with some concrete examples.', 'This paper studies the critical points of shallow and deep linear networks. The authors give a (necessary and sufficient) characterization of the form of critical points and use this to derive necessary and sufficient conditions for which critical points are global optima. Essentially this paper revisits a classic paper by Baldi and Hornik (1989) and relaxes a few requires assumptions on the matrices. I have not checked the proofs in detail but the general strategy seems sound. While the exposition of the paper can be improved in my view this is a neat and concise result and merits publication in ICLR. The authors also study the analytic form of critical points of a single-hidden layer ReLU network. However, given the form of the necessary and sufficient conditions the usefulness of of these results is less clear.\n\n\nDetailed comments:\n\n- I think in the title/abstract/intro the use of Neural nets is somewhat misleading as neural nets are typically nonlinear. This paper is mostly about linear networks. While a result has been stated for single-hidden ReLU networks. In my view this particular result is an immediate corollary of the result for linear networks. As I explain further below given the combinatorial form of the result, the usefulness of this particular extension to ReLU network is not very clear. I would suggest rewording title/abstract/intro\n\n- Theorem 1 is neat, well done!\n\n- Page 4 p_i’s in proposition 1\nFrom my understanding the p_i have been introduced in Theorem 1 but given their prominent role in this proposition they merit a separate definition (and ideally in terms of the A_i directly). \n\n- Theorems 1, prop 1, prop 2, prop 3, Theorem 3, prop 4 and 5\n\tAre these characterizations computable i.e. given X and Y can one run an algorithm to find all the critical points or at least the parameters used in the characterization p_i, V_i etc?\n\n- Theorems 1, prop 1, prop 2, prop 3, Theorem 3, prop 4 and 5\n\tWould recommend a better exposition why these theorems are useful. What insights do you gain by knowing these theorems etc. Are less sufficient conditions that is more intuitive or useful. (an insightful sufficient condition in some cases is much more valuable than an unintuitive necessary and sufficient one).\n\n- Page 5 Theorem 2\n\tDoes this theorem have any computational implications? Does it imply that the global optima can be found efficiently, e.g. are saddles strict with a quantifiable bound?\n\n- Page 7 proposition 6 seems like an immediate consequence of Theorem 1 however given the combinatorial nature of the K_{I,J} it is not clear why this theorem is useful. e.g . back to my earlier comment w.r.t. Linear networks given Y and X can you find the parameters of this characterization with a computationally efficient algorithm? \n', ""This paper mainly focuses on the square loss function of linear networks. It provides the sufficient and necessary characterization for the forms of critical points of one-hidden-layer linear networks. Based on this characterization, the authors are able to discuss different types of non-global-optimal critical points and show that every local minimum is a global minimum for one-hidden-layer linear networks. As an extension, the manuscript also characterizes the analytical forms for the critical points of deep linear networks and deep ReLU networks, although only a subset of non-global-optimal critical points are discussed. In general, this manuscript is well written.   \n\nPros:\n1. This manuscript provides the sufficient and necessary characterization of critical points for deep networks. \n2. Compared to previous work, the current analysis for one-hidden-layer linear networks doesn’t require assumptions on parameter dimensions and data matrices. The novel analyses, especially the technique to characterize critical points and the proof of item 2 in Proposition 3, will probably be interesting to the community.\n3. It provides an example when a local minimum is not global for a one-hidden-layer neural network with ReLU activation.\n\nCons:\n1. I'm concerned that the contribution of this manuscript is a little incremental. The equivalence of global minima and local minima for linear networks is not surprising based on existing works e.g. Hardt & Ma (2017) and Kawaguchi (2016).  \n2. Unlike one-hidden-layer linear networks, the characterizations of critical points for deep linear networks and deep ReLU networks seem to be hard to be interpreted. This manuscript doesn't show that every local minimum of these two types of deep networks is a global minimum, which actually has been shown by existing works like Kawaguchi (2016) with some assumptions. The behaviors of linear networks and practical (deep and nonlinear) networks are very different. Under such circumstance, the results about one-hidden-layer linear networks are less interesting to the deep learning community.\n\nMinors:\nThere are some mixed-up notations: tilde{A_i} => A_i , and rank(A_2) => rank(A)_2 in Proposition 3.""]","[80, 50, 50]","[70, 70, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe it as 'well organized and well written' and highlight that the authors' work 'generalizes existing work' and 'provides new characterization'. The reviewer also notes that the results are 'interesting'. The only slight criticism is a suggestion for additional examples, which doesn't significantly detract from the overall positive sentiment. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They acknowledge the authors' contributions and express interest in their work. The suggestion for improvement is phrased as an interesting possibility rather than a demand. The tone is consistently courteous without being overly deferential."", ""The sentiment score is 50 (slightly positive) because the reviewer states that the paper 'merits publication in ICLR' and describes the result as 'neat and concise'. However, they also mention areas for improvement and express some reservations about the usefulness of certain results. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and acknowledges the authors' achievements (e.g., 'Theorem 1 is neat, well done!'). The reviewer maintains a professional tone, asking questions and making suggestions rather than being overly critical. The use of phrases like 'I think' and 'I would suggest' further contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the review begins with a neutral summary of the paper's content, followed by a balanced list of pros and cons. The reviewer acknowledges the paper is 'well written' and provides some positive feedback, but also expresses concerns about the incremental nature of the contribution and its relevance to deep learning. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as 'concerns' rather than direct attacks. The use of 'pros' and 'cons' sections also contributes to a polite, structured critique. The minor points about notation are presented neutrally without harsh criticism.""]"
"['The paper provides proof that gradient-based meta-learners (e.g. MAML) are ""universal leaning algorithm approximators"".\n\nPro:\n- Generally well-written with a clear (theoretical) goal\n- If the K-shot proof is correct*, the paper constitutes a significant contribution to the theoretical understanding of meta-learning.\n- Timely and relevant to a large portion of the ICLR community (assuming the proofs are correct)\n\nCon:\n- The theoretical and empirical parts seem quite disconnected. The theoretical results are not applied nor demonstrated in the empirical section and only functions as an underlying premise. I wonder if a purely theoretical contribution would be preferable (or with even fewer empirical results).\n\n* It has not yet been possible for me to check all the technical details and proofs.\n', 'The paper tries to address an interesting question: does deep representation combined with standard gradient descent have sufficient capacity to approximate any learning algorithm. The authors provide answers, both theoretically and empirically.\n\nThe presentation could be further improved. For example, \n\n-the notation $\\mathcal{L}$ is inconsistent. It has different inputs at each location.\n-the bottom of page 5, ""we then define""?\n-I couldn\'t understand the sentence ""can approximate any continuous function of (x,y,x^*) on compact subsets of R^{dim(y)}"" in Lemma 4.1"". \n-before Equation (1), ""where we will disregard the last term.."" should be further clarified.\n-the paragraph before Section 4. ""The first goal of this paper is to show that f_{MAML} is a universal function approximation of (D_{\\mathcal{T}},x^*)""? A function can only approximate the same type function.', 'This paper studies the capacity of the model-agnostic meta-learning (MAML) framework as a universal learning algorithm approximator. Since a (supervised) learning algorithm can be interpreted as a map from a dataset and an input to an output, the authors define a universal learning algorithm approximator to be a universal function approximator over the set of functions that map a set of data points and an  input to an output. The authors show constructively that there exists a neural network architecture for which the model learned through MAML can approximate any learning algorithm. \n\nThe paper is for the most part clear, and the main result seems original and technically interesting. At the same time, it is not clear to me that this result is also practically significant. This is because the universal approximation result relies on a particular architecture that is not necessarily the design one would always use in MAML. This implies that MAML as typically used (including in the original paper by Finn et al, 2017a) is not necessarily a universal learning algorithm approximator, and this paper does not actually justify its empirical efficacy theoretically. For instance, the authors do not even use the architecture proposed in their proof in their experiments. This is in contrast to the classical universal function approximator results for feedforward neural networks, as a single hidden layer feedforward network is often among the family of architectures considered in the course of hyperparameter tuning. This distinction should be explicitly discussed in the paper.  Moreover, the questions posed in the experimental results do not seem related to the theoretical result, which seems odd.\n\nSpecific comments and questions: \nPage 4: ""\\hat{f}(\\cdot; \\theta\') approximates f_{\\text{target}}(x, y, x^*) up to arbitrary position"". There seems to be an abuse of notation here as the first expression is a function and the second expression is a value.\nPage 4: ""to show universality, we will construct a setting of the weight matrices that enables independent control of the information flow..."". How does this differ from the classical UFA proofs? The relative technical merit of this paper would be more clear if this is properly discussed.\nPage 4: ""\\prod_{i=1}^N (W_i - \\alpha \\nabla_{W_i})"". There seems to be a typo here: \\nabla_{W_i} should be \\nabla_{W_i} L.\nPage 7: ""These error functions effectively lose information because simply looking at their gradient is insufficient to determine the label."" It would be interesting the compare the efficacy of MAML on these error functions as compared to cross entropy and mean-squared error.\nPage 7: ""(1) can a learner trained with MAML further improve from additional gradient steps when learning new tasks at test time...? (2) does the inductive bias of gradient descent enable better few-shot learning performance on tasks outside of the training distribution...?"". These questions seem unrelated to the universal learning algorithm approximator result that constitutes the main part of the paper. If you\'re going to study these question empirically, why didn\'t you also try to investigate them theoretically (e.g. sample complexity and convergence of MAML)? A systematic and comprehensive analysis of these questions from both a theoretical and empirical perspective would have constituted a compelling paper on its own.\nPages 7-8: Experiments. What are the architectures and hyperparameters used in the experiments, and how sensitive are the meta-learning algorithms to their choice?\nPage 8: ""our experiments show that learning strategies acquired with MAML are more successful when faced with out-of-domain tasks compared to recurrent learners....we show that the representations acquired with MAML are highly resilient to overfitting"". I\'m not sure that such general claims are justified based on the experimental results in this paper. Generalizing to out-of-domain tasks is heavily dependent on the specific level and type of drift between the old and new distributions. These properties aren\'t studied at all in this work.   \n\n\nPOST AUTHOR REBUTTAL: After reading the response from the authors and seeing the updated draft, I have decided to upgrade my rating of the manuscript to a 6. The universal learning algorithm approximator result is a nice result, although I do not agree with the other reviewer that it is a  ""significant contribution to the theoretical understanding of meta-learning,"" which the authors have reinforced (although it can probably be considered a significant contribution to the theoretical understanding of MAML in particular). Expressivity of the model or algorithm is far from the main or most significant consideration in a machine learning problem, even in the standard supervised learning scenario. Questions pertaining to issues such as optimization and model selection are just as, if not more, important. These sorts of ideas are explored in the empirical part of the paper, but I did not find the actual experiments in this section to be very compelling. Still, I think the universal learning algorithm approximator result is sufficient on its own for the paper to be accepted.\n']","[60, 20, -20]","[50, 50, 50]","[""The sentiment score is 60 (positive) because the review starts with a clear statement of the paper's contribution and lists several pros, including that it's well-written, potentially significant, and timely. There is only one con mentioned, which is relatively minor. The politeness score is 50 (somewhat polite) because the language is professional and constructive. The reviewer acknowledges the potential importance of the work and uses phrases like 'generally well-written' and 'significant contribution'. However, it's not overly effusive, maintaining a balanced tone. The reviewer also admits to not having checked all technical details, which shows honesty and humility."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper addresses an interesting question and provides both theoretical and empirical answers. However, the score is not higher due to the numerous suggestions for improvement. The politeness score is moderately positive (50) as the reviewer uses neutral language and frames their criticisms as suggestions for improvement rather than direct criticisms. The reviewer uses phrases like 'could be further improved' and provides specific examples, which is constructive and polite. The absence of harsh or dismissive language also contributes to the politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's clarity and technical interest, they express significant doubts about its practical significance and relevance of the experiments. The reviewer states that 'it is not clear to me that this result is also practically significant' and questions the relationship between the theoretical results and the experiments. However, the score is not deeply negative as the reviewer does recognize some positive aspects of the paper.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'It would be interesting to compare...' and 'I'm not sure that such general claims are justified...' instead of making blunt criticisms. The reviewer also provides specific, constructive feedback and suggestions for improvement, which is a polite way to offer criticism. However, the score is not extremely high as the review is still direct in its criticisms and doesn't use overly deferential language.""]"
"['The paper presents a new algorithm for inference-based reinforcement learning for deep RL. The algorithm decomposes the policy update in two steps, an E and an M-step. In the E-step, the algorithm estimates a variational distribution q which is subsequentially used for the M-step to obtain a new policy. Two versions of the algorithm are presented, using a parametric or a non-parametric (sample-based) distribution for q. The algorithm is used in combination with the retrace algorithm to estimate the q-function, which is also needed in the policy update.\n\nThis is a well written paper presenting an interesting algorithm. The algorithm is similar to other inference-based RL algorithm, but is the first application of inference based RL to deep reinforcement learning. The results look very promising and define a new state of the art or deep reinforcement learning in continuous control, which is a very active topic right now. Hence, I think the paper should be accepted. \n\n\nI do have a few comments / corrections / questions about the paper:\n\n- There are several approaches that already use the a combination of the KL-constraint with reverse KL on a non-parametric distribution and subsequently an M-projection to obtain again a parametric distribution, see HiREPS, non-parametric REPS [Hoof2017, JMLR] or AC-REPS [Wirth2016, AAAI]. These algorithms do not use the inference-based view but the trust region justification. As in the non-parametric case, the asymptotic performance guarantees from the EM framework are gone, why is it beneficial to formulate it with EM instead of directly with a trust region of the expected reward?\n\n- It is not clear to me whether the algorithm really optimizes the original maximum a posteriori objective defined in Equation 1. First, alpha changes every iteration of the algorithm while the objective assumes that alpha is constant. This means that we change the objective all the time which is theoretically a bit weird. Moreover, the presented algorithm also changes the prior all the time (in order to introduce the 2nd trust region) in the M-step. Again, this changes the objective, so it is unclear to me what exactly is maximised in the end. Would it not be cleaner to start with the average reward objective (no prior or alpha) and then introduce both trust regions just out of the motivation that we need trust regions in policy search? Then the objective is clearly defined.    \n\n- I did not get whether the additional ""one-step KL regularisation"" is obtained from the lower bound or just added as additional regularisation? Could you explain?\n\n- The algorithm has now 2 KL constraints, for E and M step. Is the epsilon for both the same or can we achieve better performance by using different epsilons?\n\n- I think the following experiments would be very informative:\n\n   - MPO without trust region in M-step\n   \n   - MPO without retrace algorithm for getting the Q-value\n\n   - test different epsilons for E and M step\n\n\n', ""This paper studies new off-policy policy optimization algorithm using relative entropy objective and use EM algorithm to solve it. The general idea is not new, aka, formulating the MDP problem as a probabilistic inference problem. \n\nThere are some technical questions:\n1. For parametric EM case, there is asymptotic convergence guarantee to local optima case; However, for nonparametric EM case, there is no guarantee for that. This is the biggest concern I have for the theoretical justification of the paper.\n\n2. In section 4, it is said that Retrace algorithm from Munos et al. (2016) is used for policy evaluation. This is not true. The Retrace algorithm, is per se, a value iteration algorithm. I think the author could say using the policy evaluation version of Retrace, or use the truncated importance weights technique as used in Retrace algorithm, which is more accurate.\n\nBesides, a minor point: Retrace algorithm is not off-policy stable with function approximation, as shown in several recent papers, such as \n“Convergent Tree-Backup and Retrace with Function Approximation”. But this is a minor point if the author doesn’t emphasize too much about off-policy stability.\n\n3. The shifting between the unconstrained multiplier formulation in Eq.9 to the constrained optimization formulation in Eq.10 should be clarified. Usually, an in-depth analysis between the choice of \\lambda in multiplier formulation and the \\epsilon in the constraint should be discussed, which is necessary for further theoretical analysis. \n\n4. The experimental conclusions are conducted without sound evidence. For example, the author claims the method to be 'highly data efficient' compared with existing approaches, however, there is no strong evidence supporting this claim. \n\n\nOverall, although the motivation of this paper is interesting, I think there is still a lot of details to improve. "", 'This is an interesting policy-as-inference approach, presented in a reasonably clear and well-motivated way. I have a couple questions which somewhat echo questions of other commenters here. Unfortunately, I am not sufficiently familiar with the relevant recent policy learning literature to judge novelty. However, as best I am aware the empirical results presented here seem quite impressive for off-policy learning.\n\n- When is it possible to normalize the non-parametric q(a|s) in equation (6)? It seems to me this will be challenging in most any situation where the action space is continuous. Is this guaranteed to be Gaussian? If so, I don’t understand why.\n\n– In equations (5) and (10), a KL divergence regularizer is replaced by a “hard” constraint. However, for optimization purposes, in C.3 the hard constraint is then replaced by a soft constraint (with Lagrange multipliers), which depend on values of epsilon. Are these values of epsilon easy to pick in practice? If so, why are they easier to pick than e.g. the lambda value in eq (10)?\n\n']","[80, -30, 60]","[90, 20, 70]","[""The sentiment score is 80 (positive) because the reviewer explicitly states that the paper is 'well written' and presents an 'interesting algorithm'. They also mention that the results are 'very promising' and 'define a new state of the art'. The reviewer recommends acceptance, which is a strong positive indicator. The score is not 100 because the reviewer does have some questions and suggestions for improvement. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their comments as questions or suggestions rather than criticisms. Phrases like 'I do have a few comments / corrections / questions' and 'Could you explain?' demonstrate a courteous approach to feedback. The reviewer also provides constructive suggestions for additional experiments, which is helpful and considerate."", ""The sentiment score is -30 because the review starts with a neutral tone, acknowledging the paper's topic, but then lists several technical concerns and criticisms. The reviewer states that 'there is still a lot of details to improve,' indicating an overall negative sentiment. However, it's not extremely negative as the reviewer does mention that the motivation is interesting. The politeness score is 20 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They use phrases like 'I think' and 'could' which soften the critique. The reviewer also acknowledges positive aspects, such as the interesting motivation, which contributes to a polite tone. However, the score is not higher as the review is primarily focused on pointing out issues rather than offering praise."", ""The sentiment score is 60 (positive) because the reviewer describes the work as 'interesting' and 'reasonably clear and well-motivated'. They also mention that the empirical results seem 'quite impressive'. However, it's not extremely positive as they express some uncertainty about novelty and have questions about the approach. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('I am not sufficiently familiar...'), and frames their criticisms as questions rather than direct criticisms. The use of phrases like 'interesting' and 'reasonably clear' also contribute to the polite tone. The reviewer maintains a professional and constructive approach, which is indicative of politeness in academic discourse.""]"
"['(a) Significance\nThe main contribution of this paper is to characterize the implicit bias introduced by gradient descent on separable data. The authors show the exact form of this bias (L_2 maximum margin separator), which is independent of the initialization and step size. The corresponding slow convergence rate explains the phenomenon that the predictor can continue to improve even when the training loss is already small. The result of this paper can inspire the study of the implicit bias introduced by gradient descent variants or other optimization methods, such as coordinate descent. In addition, the proposed analytic framework seems promising since it may be extended to analyze other models, like neural networks.\n\n(b) Originality\nThis is the first work to give the detailed characterizations of the implicit bias of gradient descent on separable data. The proposed assumptions are reasonable, but it seems to limit to the loss function with exponential tail. I’m curious whether the result in this paper can be applied to other loss functions, such as hinge loss.\n\n(c) Clarity & Quality \nThe presentation of this paper is OK. However, there are some places can be improved in this paper. For example, in Lemma 1, results (3) and (4) can be combined together. It is better for the authors to use another section to illustrate experimental settings instead of writing them in the caption of Figure 3.1. \n\nMinor comments: \n1. In Lemma 1 (4), w^T(t)->w(t)^T\n2. In the proof of Lemma 1, it’s better to use vector 0 for the gradient L(w)\n3. In Theorem 4, the authors should specify eta\n4. In appendix A, page 11, beta is double used\n5. In appendix D, equation (D.5) has an extra period\n', 'The paper offers a formal proof that gradient descent on the logistic\nloss converges very slowly to the hard SVM solution in the case where\nthe data are linearly separable. This result should be viewed in the\ncontext of recent attempts at trying to understand the generalization\nability of neural networks, which have turned to trying to understand\nthe implicit regularization bias that comes from the choice of\noptimizer. Since we do not even understand the regularization bias of\noptimizers for the simpler case of linear models, I consider the paper\'s\ntopic very interesting and timely.\n\nThe overall discussion of the paper is well written, but on a more\ndetailed level the paper gives an unpolished impression, and has many\ntechnical issues. Although I suspect that most (or even all) of these\nissues can be resolved, they interfere with checking the correctness of\nthe results. Unfortunately, in its current state I therefore do not\nconsider the paper ready for publication.\n\n\nTechnical Issues:\n\nThe statement of Lemma 5 has a trivial part and for the other part the\nproof is incorrect: Let x_u = ||nabla L(w(u))||^2.\n  - Then the statement sum_{u=0}^t x_u < infinity is trivial, because\n    it follows directly from ||nabla L(w(u))||^2 < infinity for all u. I\n    would expect the intended statement to be sum_{u=0}^infinity x_u <\n    infinity, which actually follows from the proof of the lemma.\n  - The proof of the claim that t*x_t -> 0 is incorrect: sum_{u=0}^t x_u\n    < infinity does not in itself imply that t*x_t -> 0, as claimed. For\n    instance, we might have x_t = 1/i^2 when t=2^i for i = 1,2,... and\n    x_t = 0 for all other t.\n\nDefinition of tilde{w} in Theorem 4:\n  - Why would tilde{w} be unique? In particular, if the support vectors\n    do not span the space, because all data lie in the same\n    lower-dimensional hyperplane, then this is not the case.\n  - The KKT conditions do not rule out the case that \\hat{w}^top x_n =\n    1, but alpha_n = 0 (i.e. a support vector that touches the margin,\n    but does not exert force against it). Such n are then included in\n    cal{S}, but lead to problems in (2.7), because they would require\n    tilde{w}^top x_n = infinity, which is not possible.\n\nIn the proof of Lemma 6, case 2. at the bottom of p.14:\n  - After the first inequality, C_0^2 t^{-1.5 epsilon_+} should be \n    C_0^2 t^{-epsilon_+}\n  - After the second inequality the part between brackets is missing an\n    additional term C_0^2 t^{-\\epsilon_+}.\n  - In addition, the label (1) should be on the previous inequality and\n    it should be mentioned that e^{-x} <= 1-x+x^2 is applied for x >= 0\n    (otherwise it might be false).\nIn the proof of Lemma 6, case 2 in the middle of p.15:\n  - In the line of inequality (1) there is a t^{-epsilon_-} missing. In\n    the next line there is a factor t^{-epsilon_-} too much.\n  - In addition, the inequality e^x >= 1 + x holds for all x, so no need\n    to mention that x > 0.\n\nIn Lemma 1:\n  - claim (3) should be lim_{t \\to \\infty} w(t)^\\top x_n = infinity\n  - In the proof: w(t)^top x_n > 0 only holds for large enough t.\n\nRemarks:\n\np.4 The claim that ""we can expect the population (or test)\nmisclassification error of w(t) to improve"" because ""the margin of w(t)\nkeeps improving"" is worded a little too strongly, because it presumes\nthat the maximum margin solution will always have the best\ngeneralization error.\n\nIn the proof sketch (p.3):\n  - Why does the fact that the limit is dominated by gradients that are\n    a linear combination of support vectors imply that w_infinity will\n    also be a non-negative linear combination of support vectors?\n  - ""converges to some limit"". Mention that you call this limit\n    w_infinity\n\n\nMinor Issues:\n\nIn (2.4): add ""for all n"".\n\np.10, footnote: Shouldn\'t ""P_1 = X_s X_s^+"" be something like ""P_1 =\n(X_s^top X_s)^+""?\n\nA.9: ell should be ell\'\n\nThe paper needs a round of copy editing. For instance:\n  - top of p.4: ""where tilde{w} A is the unique""\n  - p.10: ""the solution tilde{w} to TO eq. A.2""\n  - p.10: ""might BOT be unique""\n  - p.10: ""penrose-moorse pseudo inverse"" -> ""Moore-Penrose\n    pseudoinverse""\n  \nIn the bibliography, Kingma and Ba is cited twice, with different years.\n', 'Paper focuses on characterising behaviour of the log loss minimisation on the linearly separable data. As we know, optimisation like this does not converge in a strict mathematical sense, as the norm of the model will grow to infinity. However, one can still hope for a convergence of normalised solution (or equivalently - convergence in term of separator angle, rather than parametrisation). This paper shows that indeed, log-loss (and some other similar losses), minimised with gradient descent, leads to convergence (in the above sense) to the max-margin solution. On one hand it is an interesting property of model we train in practice, and on the other - provides nice link between two separate learning theories.\n\nPros:\n- easy to follow line of argument\n- very interesting result of mapping ""solution"" of unregularised logistic regression (under gradient descent optimisation) onto hard max margin one\n\nCons:\n- it is not clear in the abstract, and beginning of the paper what ""convergence"" means, as in the strict sense logistic regression optimisation never converges on separable data. It would be beneficial for the clarity if authors define what they mean by convergence (normalised weight vector, angle, whichever path seems most natural) as early in the paper as possible.']","[70, -50, 60]","[60, 50, 50]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its significance, originality, and potential impact. They mention it's 'the first work' in its area and that the results 'can inspire' further studies. The politeness score is 60 (polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'it's better for the authors to' and 'I'm curious whether', which are polite ways of offering feedback. The review maintains a professional tone, balancing praise with areas for improvement, without using harsh or dismissive language."", ""The sentiment score is -50 because while the reviewer finds the topic interesting and timely, they state that the paper is not ready for publication due to numerous technical issues and an unpolished impression. This indicates a negative overall sentiment, but not extremely negative as they suggest most issues can likely be resolved. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the paper's potential value while providing constructive criticism. They use phrases like 'I consider the paper's topic very interesting' and 'I suspect that most (or even all) of these issues can be resolved,' which maintain a polite tone while delivering critique. The reviewer also provides detailed feedback to help improve the paper, which is a courteous approach to peer review."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its interesting results and easy-to-follow arguments. They mention both pros and cons, but the pros outweigh the cons. The single con mentioned is more of a suggestion for improvement rather than a severe criticism. The politeness score is 50 (somewhat polite) because the reviewer uses neutral, professional language throughout. They offer constructive feedback without using harsh or negative words. The suggestion for improvement is framed politely as something that 'would be beneficial for clarity'. The reviewer also acknowledges the paper's strengths, which contributes to the polite tone.""]"
"['SUMMARY:\n\nThe authors reinvent a 20 years old technique for adapting a global or component-wise learning rate for gradient descent. The technique can be derived as a gradient step for the learning rate hyperparameter, or it can be understood as a simple and efficient adaptation technique.\n\n\nGENERAL IMPRESSION:\n\nOne central problem of the paper is missing novelty. The authors are well aware of this. They still manage to provide added value.\nDespite its limited novelty, this is a very interesting and potentially impactful paper. I like in particular the detailed discussion of related work, which includes some frequently overlooked precursors of modern methods.\n\n\nCRITICISM:\n\nThe experimental evaluation is rather solid, but not perfect. It considers three different problems: logistic regression (a convex problem), and dense as well as convolutional networks. That\'s a solid spectrum. However, it is not clear why the method is tested only on a single data set: MNIST. Since it is entirely general, I would rather expect a test on a dozen different data sets. That would also tell us more about a possible sensitivity w.r.t. the hyperparameters \\alpha_0 and \\beta.\n\nThe extensions in section 5 don\'t seem to be very useful. In particular, I cannot get rid of the impression that section 5.1 exists for the sole purpose of introducing a convergence theorem. Analyzing the actual adaptive algorithm would be very interesting. In contrast, the present result is trivial and of no interest at all, since it requires knowing a good parameter setting, which defeats a large part of the value of the method.\n\n\nMINOR POINTS:\n\npage 4, bottom: use \\citep for Duchi et al. (2011).\n\nNone of the figures is legible on a grayscale printout of the paper. Please do not use color as the only cue to identify a curve.\n\nIn figure 2, top row, please display the learning rate on a log scale.\n\npage 8, line 7 in section 4.3: ""the the"" (unintended repetition)\n\nEnd of section 4: an increase from 0.001 to 0.001002 is hardly worth reporting - or am I missing something?\n', '\nThis paper revisits an interesting and important trick to automatically adapt the stepsize. They consider the stepsize as a parameter to be optimized and apply stochastic gradient update for the stepsize. Such simple trick alleviates the effort in tuning stepsize, and can be incorporated with popular stochastic first-order optimization algorithms, including SGD, SGD with Nestrov momentum, and Adam. Surprisingly, it works well in practice.\n\nAlthough the theoretical analysis is weak that theorem 1 does not reveal the main reason for the benefits of such trick, considering their performance, I vote for acceptance. But before that, there are several issues need to be addressed. \n\n1, the derivation of the update of \\alpha relies on the expectation formulation. I would like to see the investigation of the effect of the size of minibatch to reveal the variance of the gradient in the algorithm combined with such trick. \n\n2, The derivation of the multiplicative rule of HD relies on a reference I cannot find. Please include this part for self-containing. \n\n3, As the authors claimed, the Maclaurin et.al. 2015 is the most related work, however, they are not compared in the experiments. Moreover, the empirical comparisons are only conducted on MNIST. To be more convincing, it will be good to include such competitor and comparing on practical applications on CIFAR10/100 and ImageNet. \n\nMinors: \n\nIn the experiments results figures, after adding the new trick, the SGD algorithms become more stable, i.e., the variance diminishes. Could you please explain why such phenomenon happens?', 'The authors consider a method (which they trace back to 1998, but may have a longer history) of learning the learning rate of a first-order algorithm at the same time as the underlying model is being optimized, using a stochastic multiplicative update. The basic observation (for SGD) is that if \\theta_{t+1} = \\theta_t - \\alpha \\nabla f(\\theta_t), then \\partial/\\partial\\alpha f(\\theta_{t+1}) = -<\\nabla f(\\theta_t), \\nabla f(\\theta_{t+1})>, i.e. that the negative inner product of two successive stochastic gradients is equal in expectation to the derivative of the tth update w.r.t. the learning rate \\alpha.\n\nI have seen this before for SGD (the authors do not claim that the basic idea is novel), but I believe that the application to other algorithms (the authors explicitly consider Nesterov momentum and ADAM) are novel, as is the use of the multiplicative and normalized update of equation 8 (particularly the normalization).\n\nThe experiments are well-presented, and appear to convincingly show a benefit. Figure 3, which explores the robustness of the algorithms to the choice of \\alpha_0 and \\beta, is particularly nicely-done, and addresses the most natural criticism of this approach (that it replaces one hyperparameter with two).\n\nThe authors highlight theoretical convergence guarantees as an important future work item, and the lack of them here (aside from Theorem 5.1, which just shows asymptotic convergence if the learning rates become sufficiently small) is a weakness, but not, I think, a critical one. This appears to be a promising approach, and bringing it back to the attention of the machine learning community is valuable.']","[50, 50, 80]","[70, 75, 70]","[""The sentiment score is 50 (slightly positive) because while the reviewer acknowledges the paper's lack of novelty, they still find it 'very interesting and potentially impactful'. They appreciate the detailed discussion of related work and consider the experimental evaluation 'rather solid'. However, they also point out some criticisms, which balances out the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'I like in particular...' and 'Please do not use...' which maintain a polite tone. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback. The criticism is presented in a professional manner without harsh language."", ""The sentiment score is 50 (moderately positive) because the reviewer expresses interest in the paper's topic, acknowledges its importance, and votes for acceptance. However, they also point out weaknesses in the theoretical analysis and request additional work before final acceptance. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions for improvement rather than harsh demands. The reviewer uses phrases like 'I would like to see' and 'it will be good to include' which maintain a courteous tone while providing feedback."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They acknowledge the novelty of applying the method to other algorithms, praise the well-presented experiments, and describe the approach as 'promising'. The reviewer also mentions that bringing this approach back to attention is 'valuable'. The score is not 100 because the reviewer does point out a weakness (lack of theoretical convergence guarantees), albeit not considering it critical. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They acknowledge the authors' contributions, use phrases like 'well-presented' and 'nicely-done', and frame the weakness as 'important future work' rather than a criticism. The tone is constructive and encouraging. However, it's not extremely effusive or overly formal, hence not scoring 100.""]"
"[""NOTE: \n\nWould the authors kindly respond to the comment below regarding Kekulisation of the Zinc dataset? Fair comparison of the data is a serious concern. I have listed this review as a good for publication due to the novelty of ideas presented, but the accusation of misrepresentation below is a serious one and I would like to know the author's response.\n\n*Overview*\n\nThis paper presents a method of generating both syntactically and semantically valid data from a variational autoencoder model using ideas inspired by compiler semantic checking. Instead of verifying the semantic correctness offline of a particular discrete structure, the authors propose “stochastic lazy attributes”, which amounts to loading semantic constraints into a CFG and using a tailored latent-space decoder algorithm that guarantees both syntactic semantic valid. Using Bayesian Optimization, search over this space can yield decodings with targeted properties.\n\nMany of the ideas presented are novel. The results presented are state-of-the art. As noted in the paper, the generation of syntactically and semantically valid data is still an open problem. This paper presents an interesting and valuable solution, and as such constitutes a large advance in this nascent area of machine learning.\n\n*Remarks on methodology*\n\nBy initializing a decoding by “guessing” a value, the decoder will focus on high-probability starting regions of the space of possible structures. It is not clear to me immediately how this will affect the output distribution. Since this process on average begins at high-probability region and makes further decoding decisions from that starting point, the output distribution may be biased since it is the output of cuts through high-probability regions of the possible outputs space. Does this sacrifice exploration for exploitation in some quantifiable way? Some exploration of this issue or commentary would be valuable. \n\n*Nitpicks*\n\nI found the notion of stochastic predetermination somewhat opaque, and section 3 in general introduces much terminology, like lazy linking, that was new to me coming from a machine learning background. In my opinion, this section could benefit from a little more expansion and conceptual definition.\n\nThe first 3 sections of the paper are very clearly written, but the remainder has many typos and grammatical errors (often word omission). The draft could use a few more passes before publication.\n"", 'Let me first note that I am not very familiar with the literature on program generation, \nmolecule design or compiler theory, which this paper draws heavily from, so my review is an educated guess. \n\nThis paper proposes to include additional constraints into a VAE which generates discrete sequences, \nnamely constraints enforcing both semantic and syntactic validity. \nThis is an extension to the Grammar VAE of Kusner et. al, which includes syntactic constraints but not semantic ones.\nThese semantic constraints are formalized in the form of an attribute grammar, which is provided in addition to the context-free grammar.\nThe authors evaluate their methods on two tasks, program generation and molecule generation. \n\nTheir method makes use of additional prior knowledge of semantics, which seems task-specific and limits the generality of their model. \nThey report that their method outperforms the Character VAE (CVAE) and Grammar VAE (GVAE) of Kusner et. al.  \nHowever, it isn\'t clear whether the comparison is appropriate: the authors report in the appendix that they use the kekulised version of the Zinc dataset of Kusner et. al, whereas Kusner et. al do not make any mention of this. \nThe baselines they compare against for CVAE and GVAE in Table 1 are taken directly from Kusner et. al though. \nCan the authors clarify whether the different methods they compare in Table 1 are all run on the same dataset format?\n\nTypos:\n- Page 5: ""while in sampling procedure"" -> ""while in the sampling procedure""\n- Page 6: ""a deep convolution neural networks"" -> ""a deep convolutional neural network""\n- Page 6: ""KL-divergence that proposed in"" -> ""KL-divergence that was proposed in"" \n- Page 6: ""since in training time"" -> ""since at training time""\n- Page 6: ""can effectively computed"" -> ""can effectively be computed""\n- Page 7: ""reset for training"" -> ""rest for training"" ', ""The paper presents an approach for improving variational autoencoders for structured data that provide an output that is both syntactically valid and semantically reasonable.  The idea presented seems to have merit , however, I found the presentation lacking. Many sentences are poorly written making the paper hard to read, especially when not familiar with the presented methods. The experimental section could be organized better. I didn't like that two types of experiment are now presented in parallel. Finally, the paper stops abruptly without any final discussion and/or conclusion. ""]","[60, -20, -20]","[80, 60, 20]","[""The sentiment score is 60 (positive) because the reviewer expresses overall approval of the paper, noting its novelty and valuable contribution to the field. They state it's 'good for publication' and a 'large advance' in the area. However, it's not 100 as there are some concerns and requests for clarification. The politeness score is 80 (very polite) due to the use of respectful language throughout. The reviewer uses phrases like 'Would the authors kindly respond' and 'In my opinion,' showing consideration. They balance praise with constructive criticism, maintaining a professional and courteous tone. The score isn't 100 as the review does point out flaws, albeit very politely."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, they express concerns about the comparison methodology and dataset usage. The reviewer also points out several typos, indicating some issues with the paper's quality. However, the tone isn't entirely negative, as the reviewer shows interest in the work and asks for clarification. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges their own potential limitations ('my review is an educated guess'), and phrases criticisms as questions or requests for clarification rather than direct accusations. The reviewer also helpfully points out typos in a neutral manner. The overall tone is professional and constructive, despite the concerns raised."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the idea has merit, they express several criticisms about the paper's presentation, readability, organization, and lack of conclusion. The overall tone suggests disappointment with the paper's execution despite its potential. The politeness score is slightly positive (20) as the reviewer uses relatively neutral language and begins with a positive note about the paper's merit. They avoid harsh or personal criticisms, instead focusing on specific areas for improvement. The reviewer's language is professional and constructive, even when pointing out flaws, which contributes to the slightly positive politeness score.""]"
"['Summary\n - This paper mainly focuses on a counting problem in visual question answering (VQA) using attention mechanism. The authors propose a differentiable counting component, which explicitly counts the number of objects. Given attention weights and corresponding proposals, the model deduplicates overlapping proposals by eliminating intra-object edges and inter-object edges using graph representation for proposals. In experiments, the effectiveness of proposed model is clearly shown in counting questions on both a synthetic toy dataset and the widely used VQA v2 dataset.\n\nStrengths\n - The proposed model begins with reasonable motivation and shows its effectiveness in experiments clearly. \n - The architecture of the proposed model looks natural and all components seem to have clear contribution to the model.\n - The proposed model can be easily applied to any VQA model using soft attention. \n - The paper is well written and the contribution is clear.\n\nWeaknesses\n - Although the proposed model is helpful to model counting information in VQA, it fails to show improvement with respect to a couple of important baselines: prediction from image representation only and from the combination of image representation and attention weights. \n - Qualitative examples of intermediate values in counting component--adjacency matrix (A), distance matrix (D) and count matrix (C)--need to be presented to show the contribution of each part, especially in the real examples that are not compatible with the strong assumptions in modeling counting component.\n\nComments\n - It is not clear if the value of count ""c"" is same with the final answer in counting questions. \n\n', '\nSummary: \n- This paper proposes a hand-designed network architecture on a graph of object proposals to perform soft non-maximum suppression to get object count.\n\nContribution:\n- This paper proposes a new object counting module which operates on a graph of object proposals.\n\nClarity:\n- The paper is well written and clarity is good. Figure 2 & 3 helps the readers understand the core algorithm.\n\nPros:\n- De-duplication modules of inter and intra object edges are interesting.\n- The proposed method improves the baseline by 5% on counting questions.\n\nCons:\n- The proposed model is pretty hand-crafted. I would recommend the authors to use something more general, like graph convolutional neural networks (Kipf & Welling, 2017) or graph gated neural networks (Li et al., 2016).\n- One major bottleneck of the model is that the proposals are not jointly finetuned. So if the proposals are missing a single object, this cannot really be counted. In short, if the proposals don’t have 100% recall, then the model is then trained with a biased loss function which asks it to count all the objects even if some are already missing from the proposals. The paper didn’t study what is the recall of the proposals and how sensitive the threshold is.\n- The paper doesn’t study a simple baseline that just does NMS on the proposal domain.\n- The paper doesn’t compare experiment numbers with (Chattopadhyay et al., 2017).\n- The proposed algorithm doesn’t handle symmetry breaking when two edges are equally confident (in 4.2.2 it basically scales down both edges). This is similar to a density map approach and the problem is that the model doesn’t develop a notion of instance.\n- Compared to (Zhou et al., 2017), the proposed model does not improve much on the counting questions.\n- Since the authors have mentioned in the related work, it would also be more convincing if they show experimental results on CL\n\nConclusion:\n- I feel that the motivation is good, but the proposed model is too hand-crafted. Also, key experiments are missing: 1) NMS baseline 2) Comparison with VQA counting work  (Chattopadhyay et al., 2017). Therefore I recommend reject.\n\nReferences:\n- Kipf, T.N., Welling, M., Semi-Supervised Classification with Graph Convolutional Networks. ICLR 2017.\n- Li, Y., Tarlow, D., Brockschmidt, M., Zemel, R. Gated Graph Sequence Neural Networks. ICLR 2016.\n\nUpdate:\nThank you for the rebuttal. The paper is revised and I saw NMS baseline is added. I understood the reason not to compare with certain related work. The rebuttal is convincing and I decided to increase my rating, because adding the proposed counting module achieve 5% increase in counting accuracy. However, I am a little worried that the proposed model may be hard to reproduce due to its complexity and therefore choose to give a 6.', 'This paper tackles the object counting problem in visual question answering. It is based on the two-stage method that object proposals are generated from the first stage with attention. It proposes many heuristics to use the object feature and attention weights to find the correct count.  In general, it treats all object proposals as nodes on the graph. With various agreement measures, it removes or merges edges and count the final nodes. The method is evaluated on one synthetic toy dataset and one VQA v2 benchmark dataset. The experimental results on counting are promising.  Although counting is important in VQA, the method is solving a very specific problem which cannot be generalized to other representation learning problems.  Additionally, this method is built on a series of heuristics without sound theoretically justification, and these heuristics cannot be easily adapted to other machine learning applications. I thus believe the overall contribution is not sufficient for ICLR.\n\nPros:\n1. Well written paper with clear presentation of the method. \n2. Useful for object counting problem.\n3. Experimental performance is convincing. \n\nCons:\n1. The application range of the method is very limited. \n2. The technique is built on a lot of heuristics without theoretical consideration. \n\nOther comments and questions:\n\n1. The determinantal point processes [1] should be able to help with the correct counting the objects with proper construction of the similarity kernel.  It may also lead to simpler solutions. For example, it can be used for deduplication using A (eq 1) as the similarity matrix. \n\n2. Can the author provide analysis on scalability the proposed method? When the number of objects is very large, the graph could be huge. What are the memory requirements and computational complexity of the proposed method?  \nIn the end of section 3, it mentioned that ""without normalization,"" the method will not scale to an arbitrary number of objects. I think that it will only be a problem for extremely large numbers. I wonder whether the proposed method scales. \n\n3. Could the authors provide more insights on why the structured attention (etc) did not significantly improve the result? Theoritically, it solves the soft attention problems. \n\n4. The definition of output confidence (section 4.3.1) needs more motivation and theoretical justification. \n\n[1] Kulesza, Alex, and Ben Taskar. ""Determinantal point processes for machine learning."" Foundations and Trends® in Machine Learning 5.2–3 (2012): 123-286.']","[60, -20, -30]","[70, 50, 60]","[""The sentiment score is 60 (moderately positive) because the review begins by highlighting several strengths of the paper, including its reasonable motivation, clear effectiveness in experiments, natural architecture, and clear contribution. The reviewer also praises the paper as being well-written. However, the score is not higher due to the mention of some weaknesses, particularly the model's failure to improve on certain important baselines. The politeness score is 70 (fairly polite) because the reviewer uses respectful and professional language throughout, acknowledging the paper's merits before discussing its limitations. The reviewer offers constructive criticism and suggestions for improvement rather than harsh criticism. The use of phrases like 'The paper is well written' and 'The proposed model begins with reasonable motivation' contribute to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('improves the baseline by 5%', 'well written'), they ultimately recommend rejection due to several criticisms and missing experiments. The overall tone suggests the paper has potential but falls short. The politeness score is moderately positive (50) as the reviewer uses professional language, offers specific constructive feedback, and acknowledges positive aspects alongside criticisms. They also show flexibility by increasing their rating after the rebuttal, demonstrating respect for the authors' response. The language remains objective and avoids harsh personal criticism."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('promising' results, 'well written paper'), they ultimately conclude that the 'overall contribution is not sufficient for ICLR'. They list more cons than pros and express concerns about the method's limited applicability and lack of theoretical justification. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and phrases criticisms constructively. They use polite phrases like 'Can the author provide...', 'Could the authors provide...', and offer suggestions for improvement rather than just criticism. The tone is professional and objective, avoiding harsh or personal comments.""]"
"['This paper introduces a smooth surrogate loss function for the top-k SVM, for the purpose of plugging the SVM to the deep neural networks. The idea is to replace the order statistics, which is not smooth and has a lot of zero partial derivatives, to the exponential of averages, which is smooth and is a good approximation of the order statistics by a good selection of the ""temperature parameter"". The paper is well organized and clearly written. The idea deserves a publication.\n\nOn the other hand, there might be better and more direct solutions to reduce the combinatorial complexity. When the temperature parameter is small enough, both of the original top-k SVM surrogate loss (6) and the smooth loss (9) can be computed precisely by sorting the vector s first, and take a good care of the boundary around s_{[k]}.', 'This paper made some efforts in smoothing the top-k losses proposed in Lapin et al. (2015).  A family of smooth surrogate loss es was proposed, with the help of which the top-k error may be minimized directly. The properties of the smooth surrogate losses were studied and the computational algorithms for SVM with these losses function were also proposed. \n\nPros:\n1, The paper is well presented and is easy to follow.\n2, The contribution made in this paper is sound, and the mathematical analysis seems to be correct. \n3, The experimental results look convincing. \n\nCons:\nSome statements in this paper are not clear to me. For example, the authors mentioned sparse or non-sparse loss functions. This statement, in my view, could be misleading without further explanation (the non-sparse loss was mentioned in the abstract).\n', ""The paper is clear and well written. The proposed approach seems to be of interest and to produce interesting results. As datasets in various domain get more and more precise, the problem of class confusing with very similar classes both present or absent of the training dataset is an important problem, and this paper is a promising contribution to handle those issues better.\n\nThe paper proposes to use a top-k loss such as what has been explored with SVMs in the past, but with deep models. As the loss is not smooth and has sparse gradients, the paper suggests to use a smoothed version where maximums are replaced by log-sum-exps.\n\nI have two main concerns with the presentation.\n\nA/ In addition to the main contribution, the paper devotes a significant amount of space to explaining how to compute the smoothed loss. This can be done by evaluating elementary symmetric polynomials at well-chosen values.\n\nThe paper argues that classical methods for such evaluations (e.g., using the usual recurrence relation or more advanced methods that compensate for numerical errors) are not enough when using single precision floating point arithmetic. The paper also advances that GPU parallelization must be used to be able to efficiently train the network.\n\nThose claims are not substantiated, however, and the method proposed by the paper seems to add substantial complexity without really proving that it is useful.\n\nThe paper proposes a divide-and-conquer approach, where a small amount of parallelization can be achieved within the computation of a single elementary symmetric polynomial value. I am not sure why this is of interest - can't the loss evaluation already be parallelized trivially over examples in a training/testing minibatch? I believe the paper could justify this approach better by providing a bit more insights as to why it is required. For instance:\n\n- What accuracies and train/test times do you get using standard methods for the evaluation of elementary symmetric polynomials?\n- How do those compare with CE and L_{5, 1} with the proposed method?\n- Are numerical instabilities making this completely unfeasible? This would be especially interesting to understand if this explodes in practice, or if evaluations are just a slightly inaccurate without much accuracy loss.\n\n\nB/ No mention is made of the object detection problem, although multiple of the motivating examples in Figure 1 consider cases that would fall naturally into the object detection framework. Although top-k classification considers in principle an easier problem (no localization), a discussion, as well as a comparison of top-k classification vs., e.g., discarding localization information out of object detection methods, could be interesting.\n\nAdditional comments:\n\n- Figure 2b: this visualization is confusing. This is presented in the same figure and paragraph as the CIFAR results, but instead uses a single synthetic data point in dimension 5, and k=1. This is not convincing. An actual experiment using full dataset or minibatch gradients on CIFAR and the same k value would be more interesting.\n\n""]","[70, 60, 20]","[80, 70, 60]","[""The sentiment score is 70 (positive) because the reviewer states that the paper is well-organized, clearly written, and the idea deserves publication. However, it's not 100 as there are some suggestions for improvement. The politeness score is 80 (very polite) due to the use of respectful language throughout, acknowledging the paper's strengths, and offering constructive feedback without harsh criticism. The reviewer uses phrases like 'well organized and clearly written' and 'deserves a publication', which are positive and encouraging. The suggestions for improvement are presented in a non-confrontational manner, using phrases like 'there might be better solutions' rather than direct criticism."", ""The sentiment score is 60 (positive) because the reviewer lists more pros than cons and uses positive language like 'well presented', 'easy to follow', 'sound', and 'convincing'. The overall tone is approving, with only minor criticisms. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and contributions. They phrase their criticism gently, using 'Some statements... are not clear to me' instead of more direct criticism. The reviewer maintains a professional and courteous tone throughout the review."", ""The sentiment score is 20 (slightly positive) because the reviewer starts with positive comments about the paper being clear, well-written, and producing interesting results. However, they also express two main concerns, which tempers the overall positivity. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the paper's contributions and framing criticisms as suggestions or questions rather than direct attacks. They use phrases like 'I have two main concerns' and 'The paper could justify this approach better' instead of more confrontational language. The reviewer also provides specific, constructive feedback, which is a polite way to offer criticism.""]"
"['Summary:\nThis paper proposes minimal-entropy correlation alignment, an unsupervised domain adaptation algorithm which links together two prior class of methods: entropy minimization and correlation alignment. Interesting new idea. Make a simple change in the distance function and now can perform adaptation which aligns with minimal entropy on target domain and thus can allow for removal of hyperparameter (or automatic validation of correct one).\n\nStrengths\n-  The paper is clearly written and effectively makes a simple claim that geodesic distance minimization is better aligned to final performance than euclidean distance minimization between source and target. \n- Figures 1 and 2 (right side) are particularly useful for fast understanding of the concept and main result.\n\n\nQuestions/Concerns:\n- Can entropy minimization on target be used with other methods for DA param tuning? Does it require that the model was trained to minimize the geodesic correlation distance between source and target?\n- It would be helpful to have a longer discussion on the connection with Geodesic flow kernel [1] and other unsupervised manifold based alignment methods [2]. Is this proposed approach an extension of this prior work to the case of non-fixed representations in the same way that Deep CORAL generalized CORAL?\n- Why does performance suffer compared to TRIPLE on the SYN->SVHN task? Is there some benefit to the TRIPLE method which may be combined with the MECA approach?\n\n\t\t\t\t\t\n[1] Boqing Gong, Yuan Shi, Fei Sha, and Kristen Grauman. Geodesic flow kernel for unsupervised domain adaptation. In CVPR, 2012.\n\t\t\t\t\t\n[2] Raghuraman Gopalan and Ruonan Li. Domain adaptation for object recognition: An unsupervised approach. In ICCV, 2011. \n', 'This paper improves the correlation alignment approach to domain adaptation from two aspects. One is to replace the Euclidean distance by the geodesic Log-Euclidean distance between two covariance matrices. The other is to automatically select the balancing cost by the entropy on the target domain. Experiments are conducted from SVHN to MNIST and from SYN MNIST to SVHN. Additional experiments on cross-modality recognition are reported from RGB to depth.\n\nStrengths:\n+ It is a sensible idea to improve the Euclidean distance by the geodesic Log-Euclidean distance to better explore the manifold structure of the PSD matrices. \n+ It is also interesting to choose the balancing cost using the entropy on the target. However, this point is worth further exploring (please see below for more detailed comments).\n+ The experiments show that the geodesic correlation alignment outperforms the original alignment method. \n\nWeaknesses: \n- It is certainly interesting to have a scheme to automatically choose the hyper-parameters in unsupervised domain adaptation, and the entropy over the target seems like a reasonable choice. This point is worth further exploring for the following reasons. \n1. The theoretical result is not convincing given it relies on many unrealistic assumptions, such as the null performance degradation under perfect correlation alignment, the Dirac’s delta function as the predictions over the target, etc.\n2. The theorem actually does not favor the correlation alignment over the geodesic alignment. It does not explain that, in Figure 2, the entropy is able to find the best balancing cost \\lamba for geodesic alignment but not for the Euclidean alignment.\n3. The entropy alignment seems an interesting criterion to explore in general. Could it be used to find fairly good hyper-parameters for the other methods? Could it be used to determine the other hyper-parameters (e..g, learning rate, early stopping) for the geodesic alignment? \n4. If one leaves a subset of the target domain out and use its labels for validation, how different would the selected balancing cost \\lambda differ from that by the entropy? \n\n- The cross-modality setup (from RGB to depth) is often not considered as domain adaptation. It would be better to replace it by another benchmark dataset. The Office-31 dataset is still a good benchmark to compare different methods and for the study in Section 5.1, though it is not necessary to reach state-of-the-art results on this dataset because, as the authors noted, it is almost saturated. \n\nQuestion:\n- I am not sure how the gradients were computed after the eigendecomposition in equation (8).\n\n\nI like the idea of automatically choosing free parameters using the entropy over the target domain. However, instead of justifying this point by the theorem that relies on many assumptions, it is better to further test it using experiments (e.g., on Office31 and for other adaptation methods). The geodesic correlation alignment is a reasonable improvement over the Euclidean alignment.\n', ""The authors propose a novel deep learning approach which leverages on our finding that entropy minimization\nis induced by the optimal alignment of second order statistics between source and target domains. Instead of relying on Euclidean distances when performing the alignment, the authors use geodesic distances which preserve the geometry of the manifolds. Among others, the authors also propose a handy way to cross-validate the model parameters on target data using the entropy criterion. The experimental validation is performed on benchmark datasets for image classification. Comparisons with the state-of-the-art approaches show that the proposed marginally improves the results. The paper is well written and easy to understand.\n\nAs a main difference from DeepCORAL method, this approach relies on the use of geodesic distances when doing the alignment of the distribution statistics, which turns out to be beneficial for improving the network performance on the target tasks. While I don't see this as substantial contribution to the field, I think that using the notion of geodesic distance in this context is novel.  The experiments show the benefit over the Euclidean distance when applied to the datasets used in the paper. \n\nA lot of emphasis in the paper is put on the methodology part. The experiments could have been done more extensively, by also providing some visual examples of the aligned distributions and image features. This would allow the readers to further understand why the proposed alignment approach performs better than e.g. Deep Coral.""]","[60, 50, 60]","[70, 75, 50]","[""The sentiment score is 60 (positive) because the review starts with acknowledging the paper as an 'interesting new idea' and highlights several strengths, including clear writing and effective presentation. The reviewer also provides constructive feedback and questions, which indicates engagement with the work. The politeness score is 70 (polite) due to the respectful tone throughout the review. The reviewer uses phrases like 'interesting new idea' and 'clearly written,' and frames criticisms as questions or concerns rather than direct negative statements. The reviewer also acknowledges the paper's strengths before moving on to questions and concerns, which is a polite approach to peer review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths and interesting ideas, while also pointing out several weaknesses and areas for improvement. The overall tone is constructive rather than overly critical or enthusiastic. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits and framing criticisms as suggestions for improvement or areas to explore further. Phrases like 'It is a sensible idea,' 'It is also interesting,' and 'I like the idea' contribute to the polite tone. The reviewer also uses phrases like 'please see below for more detailed comments' and 'it would be better to,' which are courteous ways of offering criticism."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the novelty of the approach, mentions that it marginally improves results, and states that the paper is well-written and easy to understand. However, it's not extremely positive as the reviewer doesn't see it as a substantial contribution and suggests more extensive experiments. The politeness score is 50 (somewhat polite) because the language is professional and constructive, without any harsh criticism. The reviewer offers balanced feedback, acknowledging strengths while also suggesting improvements. The tone is respectful but not overly formal or effusive in its politeness.""]"
"['This paper proposes a compositional nearest-neighbors approach to image synthesis, including results on several conditional image generation datasets. \n\nPros:\n- Simple approach based on nearest-neighbors, likely easier to train compared to GANs.\n- Scales to high-resolution images.\n\nCons:\n- Requires a potentially costly search procedure to generate images.\n- Seems to require relevant objects and textures to be present in the training set in order to succeed at any given conditional image generation task.', 'This paper presents a pixel-matching based approach to synthesizing RGB images from input edge or normal maps. The approach is compared to Isola et al’s conditional adversarial networks, and unlike the conditional GAN, is able to produce a diverse set of outputs.\n\nOverall, the paper describes a computer visions system based on synthesizing images, and not necessarily a new theoretical framework to compete with GANs. With the current focus of the paper being the proposed system, it is interesting to the computer vision community. However, if one views the paper in a different light, namely showing some “blind-spots” of current conditional GAN approaches like lack of diversity, then it can be of much more interest to the broader ICLR community.\n\nPros: \nOverall the paper is well-written\nMakes a strong case that random noise injection inside conditional GANs does not produce enough diversity\nShows a number of qualitative and quantitative results\n\nConcerns about the paper:\n1.) It is not clear how well the proposed approach works with CNN architectures other than PixelNet\n2.) Since the paper used “the pre-trained PixelNet to extract surface normal and edge maps” for ground-truth generation, it is not clear whether the approach will work as well when the input is a ground-truth semantic segmentation map.\n3.) Since the paper describes a computer-vision image synthesis system and not a new theoretical result, I believe reporting the actual run-time of the system will make the paper stronger. Can PixelNN run in real-time? How does the timing compare to Isola et al’s Conditional GAN?\n\nMinor comments:\n1.) The paper mentions making predictions from “incomplete” input several times, but in all experiments, the input is an edge map, normal map, or low-resolution image. When reading the manuscript the first time, I was expecting experiments on images that have regions that are visible and regions that are masked out. However, I am not sure if the confusion is solely mine, or shared with other readers.\n\n2.) Equation 1 contains the norm operator twice, and the first norm has no subscript, while the second one has an l_2 subscript. I would expect the notation style to be consistent within a single equation (i.e., use ||w||_2^2, ||w||^2, or ||w||_{l_2}^2)\n\n3.) Table 1 has two sub-tables: left and right. The sub-tables have the AP column in different places.\n\n4.) “Dense pixel-level correspondences” are discussed but not evaluated.\n', 'Overall I like the paper and the results look nice in a diverse set of datasets and tasks such as edge-to-image, super-resolution, etc. Unlike the generative distribution sampling of GANs, the method provides an interesting compositional scheme, where the low frequencies are regressed and the high frequencies are obtained by ""copying"" patches from the training set. In some cases the results are similar to pix-to-pix (also in the numerical evaluation) but the method allows for one-to-many image generation, which is a important contribution. Another positive aspect of the paper is that the synthesis results can be analyzed, providing insights for the generation process. \n\nWhile most of the paper is well written, some parts are difficult to parse. For example, the introduction has some parts that look more like related work (that is mostly a personal preference in writting). Also in Section 3, the paragraph for distance functions do not provide any insight about what is used, but it is included in the next paragraph (I would suggest either merging or not highlighting the paragraphs).\n\nQ: The spatial grouping that is happening in the compositional stage, is it solely due to the multi-scale hypercolumns?  Would the result be more inconsistent if the hypercolumns had smaller receptive field?\n\nQ: For the multiple outputs, the k neighbor is selected at random?\n']","[20, 20, 80]","[50, 80, 70]","['The sentiment score is slightly positive (20) because the review starts with a neutral description of the paper and then lists both pros and cons. The pros highlight positive aspects like simplicity and scalability, while the cons are presented as factual limitations rather than harsh criticisms. This balanced approach leans slightly positive overall. The politeness score is moderately positive (50) because the reviewer uses neutral, professional language throughout. They present their points objectively without using overly critical or praising language. The review maintains a respectful tone while providing constructive feedback, which is considered polite in academic contexts.', ""The sentiment score is slightly positive (20) because the reviewer acknowledges some strengths of the paper ('well-written', 'makes a strong case', 'shows a number of qualitative and quantitative results') while also raising several concerns and suggestions for improvement. The overall tone is constructive rather than overtly critical. The politeness score is high (80) as the reviewer uses respectful language throughout, frames concerns as suggestions ('I believe reporting...will make the paper stronger'), and acknowledges potential misunderstandings on their part ('I am not sure if the confusion is solely mine'). The reviewer also balances critique with praise, starting with 'pros' before moving to 'concerns', which contributes to the polite tone."", ""The sentiment score is 80 (positive) because the reviewer starts with 'Overall I like the paper' and mentions several positive aspects, including 'nice' results, 'interesting compositional scheme', and 'important contribution'. The few criticisms are minor and constructive. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms gently (e.g., 'some parts are difficult to parse'). The reviewer also asks questions at the end, showing engagement with the work. The language is professional and courteous without being overly formal or effusive.""]"
"['This paper presents a policy gradient method that employs entropy regularization and entropy constraint at the same time. The entropy regularization on action probability is to encourage the exploration of the policy, while the entropy constraint is to stabilize the gradient.\n\nThe major weakness of this paper is the unclear presentation. For example, the algorithm is never fully described, though a handful variants are discussed. How the off-policy version is implemented is missing.\n\nIn experiments, why the off-policy version of TRPO is not compared. Comparing the on-policy results, PCL does not show a significant advantage over TRPO. Moreover, the curves of TRPO is so unstable, which is a bit uncommon. \n\nWhat is the exploration strategy in the experiments? I guess it was softmax probability. However, in many cases, softmax does not perform a good exploration, even if the entropy regularization is added.\n\nAnother issue is the discussion of the entropy regularization in the objective function. This regularization, while helping exploration, do changes the original objective. When a policy is required to pass through a very narrow tunnel of states, the regularization that forces a wide action distribution could not have a good performance. Thus it would be more interesting to see experiments on more complex benchmark problems like humanoids.', 'Clarity \nThe paper is well-written and clear. \n\nOriginality\nThe paper proposes a path consistency learning method with a new combination of entropy regularization and relative entropy. The paper leverages a novel method in determining the coefficient of relative entropy. \n\nSignificance\n- Trust-PCL achieves overall competitive with state-of-the-art external implementations.\n- Trust-PCL (off-policy) significantly outperform TRPO in terms of data efficiency and final performance. \n- Even though the paper claims Trust-PCL (on-policy) is close to TRPO, the initial performance of TRPO looks better in HalfCheetah, Hopper, Walker2d and Ant. \n- Some ablation studies (e.g., on entropy regularization and relative entropy) and sensitivity analysis on parameters (e.g. \\alpha and update frequency on \\phi) would be helpful. \n\nPros:\n- The paper is well-written and clear. \n- Competitive with state-of-the-art external implementations\n- Significant empirical advantage over TRPO.\n-  Open source codes.\n\nCons:\n- No ablation studies. \n', 'The paper extends softmax consistency by adding in a relative entropy term to the entropy regularization and applying trust region policy optimization instead of gradient descent.  I am not an expert in this area. It is hard to judge the significance of this extension.\n\nThe paper largely follows the work of Nachum et al 2017. The differences (i.e., the claimed novelty) from that work are the relative entropy and trust region method for training. However, the relative entropy term added seems like a marginal modification. Authors claimed that it satisfies the multi-step path consistency but the derivation is missing.\n\nI am a bit confused about the way trust region method is used in the paper. Initially,  problem is written as a constrained optimization problem (12). It is then converted into a penalty form for softmax consistency. Finally, the Lagrange parameter is estimated from the trust region method. In addition, how do you get the Lagrange parameter from epsilon?\n\nThe pseudo code of the algorithm is missing. It would be much clearer if a detailed description of the algorithmic procedure is given.\n\nHow is the performance of Trust-PCL compared to PCL? ']","[-30, 60, -20]","[20, 50, 0]","[""The sentiment score is -30 because the review starts with a neutral description of the paper but then focuses on several weaknesses and issues, indicating a generally negative sentiment. However, it's not extremely negative as it does acknowledge the paper's contribution. The politeness score is 20 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They phrase concerns as questions or observations rather than direct attacks. The reviewer maintains a constructive tone, even when pointing out weaknesses, which contributes to the slightly positive politeness score."", ""The sentiment score is 60 (positive) because the review highlights several positive aspects of the paper, including that it is well-written, clear, and proposes a novel method. The reviewer notes that the paper's approach is competitive with state-of-the-art implementations and shows significant advantages over TRPO. However, it's not a perfect score due to some criticisms, such as the lack of ablation studies and the initial performance comparison with TRPO in certain scenarios. The politeness score is 50 (slightly positive) because the language used is professional and objective, without any harsh criticisms. The reviewer presents both pros and cons in a balanced manner, using neutral language throughout. While not overtly polite with praise or encouragement, the tone remains respectful and constructive."", ""The sentiment score is slightly negative (-20) because the reviewer expresses some skepticism and confusion about the paper's contributions. They state it's 'hard to judge the significance of this extension' and describe the modifications as 'marginal'. They also point out missing elements like derivations and pseudo-code. However, the review isn't entirely negative, as they don't outright reject the paper's approach.\n\nThe politeness score is neutral (0) because the reviewer maintains a professional tone throughout. They don't use overtly polite language, but they also avoid rudeness. The critique is presented in a straightforward, matter-of-fact manner without personal attacks or overly harsh language. The reviewer uses phrases like 'I am a bit confused' and 'It would be much clearer if...' which are neutral ways of expressing concerns.""]"
"['The authors propose to improve the robustness of trained neural networks against adversarial examples by randomly zeroing out weights/activations. Empirically the authors demonstrate, on two different task domains, that one can trade off some accuracy for a little robustness -- qualitatively speaking.\n\nOn one hand, the approach is simple to implement and has minimal impact computationally on pre-trained networks. On the other hand, I find it lacking in terms of theoretical support, other than the fact that the added stochasticity induces a certain amount of robustness. For example, how does this compare to random perturbation (say, zero-mean) of the weights? This adds stochasticity as well so why and why not this work? The authors do not give any insight in this regard.\n\nOverall, I still recommend acceptance (weakly) since the empirical results may be valuable to a general practitioner. The paper could be strengthened by addressing the issues above as well as including more empirical results (if nothing else).\n\n', 'This paper investigates a new approach to prevent a given classifier from adversarial examples. The most important contribution is that the proposed algorithm can be applied post-hoc to already trained networks. Hence, the proposed algorithm (Stochastic Activation Pruning) can be combined with algorithms which prevent from adversarial examples during the training.\n\nThe proposed algorithm is clearly described. However there are issues in the presentation.\n\nIn section 2-3, the problem setting is not suitably introduced.\nIn particular one sentence that can be misleading:\n“Given a classifier, one common way to generate an adversarial example is to perturb the input in direction of the gradient…”\nYou should explain that given a classifier with stochastic output, the optimal way to generate an adversarial example is to perturb the input proportionally to the gradient. The practical way in which the adversarial examples are generated is not known to the player. An adversary could choose any policy. The only thing the player knows is the best adversarial policy.\n\nIn section 4, I do not understand why the adversary uses only the sign and not also the value of the estimated gradient. Does it come from a high variance? If it is the case, you should explain that the optimal policy of the adversary is approximated by “fast gradient sign method”. \n\nIn comparison to dropout algorithm, SAP shows improvements of accuracy against adversarial examples. SAP does not perform as well as adversarial training, but SAP could be used with a trained network. \n\nOverall, this paper presents a practical method to prevent a classifier from adversarial examples, which can be applied in addition to adversarial training. The presentation could be improved.\n', 'This paper propose a simple method for guarding trained models against adversarial attacks. The method is to prune the network’s activations at each layer and renormalize the outputs. It’s a simple method that can be applied post-training and seems to be effective.\n\nThe paper is well written and easily to follow. Method description is clear. The analyses are interesting and done well. I am not familiar with the recent work in this area so can not judge if they compare against SOTA methods but they do compare against various other methods.\n\nCould you elaborate more on the findings from Fig 1.c Seems that  the DENSE model perform best against randomly perturbed images. Would be good to know if the authors have any intuition why is that the case.\n\nThere are some interesting analysis in the appendix against some other methods, it would be good to briefly refer to them in the main text.\n\nI would be interested to know more about the intuition behind the proposed method. It will make the paper stronger if there were more content arguing analyzing the intuition and insight that lead to the proposed method.\n\nAlso would like to see some notes about computation complexity of sampling multiple times from a larger multinomial.\n\nAgain I am not familiar about different kind of existing adversarial attacks, the paper seem to be mainly focus on those from Goodfellow et al 2014. Would be good to see the performance against other forms of adversarial attacks as well if they exist.']","[20, 50, 70]","[50, 75, 80]","[""The sentiment score is slightly positive (20) because the reviewer recommends acceptance, albeit weakly, and acknowledges that the empirical results may be valuable. However, they also express concerns about the lack of theoretical support and suggest improvements. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, balancing criticism with recognition of the paper's merits. They use phrases like 'On one hand... On the other hand' to present a balanced view, and offer constructive suggestions for improvement rather than harsh criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contribution and practical application, while also pointing out areas for improvement. The overall tone is constructive, recognizing the value of the work while suggesting enhancements. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offering suggestions rather than harsh criticisms. Phrases like 'could be improved' and 'I do not understand' are used instead of more confrontational language. The reviewer also balances critique with positive observations, maintaining a professional and courteous tone."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'well written and easily to follow' with 'interesting' analyses that are 'done well'. The reviewer also acknowledges the effectiveness of the proposed method. However, it's not a perfect score as the reviewer suggests some improvements and additional information. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than criticisms. Phrases like 'Could you elaborate more' and 'Would be good to know' indicate a polite and considerate tone. The reviewer also acknowledges their own potential lack of familiarity with some aspects, which shows humility and respect for the authors' expertise.""]"
"[""The paper proposed a copula-based modification to an existing deep variational information bottleneck model, such that the marginals of the variables of interest (x, y) are decoupled from the DVIB latent variable model, allowing the latent space to be more compact when compared to the non-modified version. The experiments verified the relative compactness of the latent space, and also qualitatively shows that the learned latent features are more 'disentangled'. However, I wonder how sensitive are the learned latent features to the hyper-parameters and optimizations?\n\nQuality: Ok. The claims appear to be sufficiently verified in the experiments. However, it would have been great to have an experiment that actually makes use of the learned features to make predictions. I struggle a little to see the relevance of the proposed method without a good motivating example.\n\nClarity: Below average. Section 3 is a little hard to understand. Is q(t|x) in Fig 1 a typo? How about t_j in equation (5)? There is a reference that appeared twice in the bibliography (1st and 2nd).\n\nOriginality and Significance: Average. The paper (if I understood it correctly) appears to be mainly about borrowing the key ideas from Rey et. al. 2014 and applying it to the existing DVIB model."", 'This paper presents a sparse latent representation learning algorithm based on an information theoretic objective formulated through meta-Gaussian information bottleneck and solved via variational auto-encoder stochastic optimization. The authors suggest Gaussianify the data using copula transformation and  further adopt a diagonal determinant approximation with justification of minimizing an upper bound of mutual information.  Experiments include both artificial data and real data. \n\nThe paper is unclear at some places and writing gets confusing. For example, it is unclear whether and when explicit or implicit transforms are used for x and y in the experiments, and the discussion at the end of Section 3.3 also sounds confusing. It would be more helpful if the author can make those points more clear and offer some guidance about the choices between explicit and implicit transform in practice. Moreover, what is the form of f_beta and how beta is optimized?  In the first equation on page 5, is tilde y involved? How to choose lambda?\n\nIf MI is invariant to monotone transformations and information curves are determined by MIs, why “transformations basically makes information curve arbitrary”? Can you elaborate?  \n\nAlthough the experimental results demonstrate that the proposed approach with copula transformation yields higher information curves, more compact representation and better reconstruction quality, it would be more significant if the author can show whether these would necessarily lead to any improvements on other goals such as classification accuracy or robustness under adversarial attacks. \n\nMinor comments: \n\n- What is the meaning of the dashed lines and the solid lines respectively in Figure 1? \n- Section 3.3 at the bottom of page 4: what is tilde t_j? and x in the second term? Is there a typo? \n- typo, find the “most orthogonal” representation if the inputs -> of the inputs \n\nOverall, the main idea of this paper is interesting and well motivated and but the technical contribution seems incremental. The paper suffers from lack of clarity at several places and the experimental results are convincing but not strong enough. \n\n***************\nUpdates: \n***************\nThe authors have clarified some questions that I had and further demonstrated the benefits of copula transform with new experiments in the revised paper. The new results are quite informative and addressed some of the concerns raised by me and other reviewers. I have updated my score to 6 accordingly. \n\n\n', 'This paper identifies and proposes a fix for a shortcoming of the Deep Information Bottleneck approach, namely that the induced representation is not invariant to monotonic transform of the marginal distributions (as opposed to the mutual information on which it is based). The authors address this shortcoming by applying the DIB to a transformation of the data, obtained by a copula transform. This explicit approach is shown on synthetic experiments to preserve more information about the target, yield better reconstruction and converge faster than the baseline. The authors further develop a sparse extension to this Deep Copula Information Bottleneck (DCIB), which yields improved representations (in terms of disentangling and sparsity) on a UCI dataset.\n\n(significance) This is a promising idea. This paper builds on the information theoretic perspective of representation learning, and makes progress towards characterizing what makes for a good representation. Invariance to transforms of the marginal distributions is clearly a useful property, and the proposed method seems effective in this regard.\nUnfortunately, I do not believe the paper is ready for publication as it stands, as it suffers from lack of clarity and the experimentation is limited in scope.\n\n(clarity) While Section 3.3 clearly defines the explicit form of the algorithm (where data and labels are essentially pre-processed via a copula transform), details regarding the “implicit form” are very scarce. From Section 3.4, it seems as though the authors are optimizing the form of the gaussian information bottleneck I(x,t), in the hopes of recovering an encoder $f_\\beta(x)$ which gaussianizes the input (thus emulating the explicit transform) ? Could the authors clarify whether this interpretation is correct, or alternatively provide additional clarifying details ? There are also many missing details in the experimental section: how were the number of “active” components selected ? Which versions of the algorithm (explicit/implicit) were used for which experiments ? I believe explicit was used for Section 4.1, and implicit for 4.2 but again this needs to be spelled out more clearly. I would also like to see a discussion (and perhaps experimental comparison) to standard preprocessing techniques, such as PCA-whitening.\n\n(quality) The experiments are interesting and seem well executed. Unfortunately, I do not think their scope (single synthetic, plus a single UCI dataset) is sufficient. While the gap in performance is significant on the synthetic task, this gap appears to shrink significantly when moving to the UCI dataset. How does this method perform for more realistic data, even e.g. MNIST ? I think it is crucial to highlight that the deficiencies of DIB matter in practice, and are not simply a theoretical consideration. Similarly, the representation analyzed in Figure 7 is promising, but again the authors could have targeted other common datasets for disentangling, e.g. the simple sprites dataset used in the beta-VAE paper. I would have also liked to see a more direct and systemic validation of the claims made in the paper. For example, the shortcomings of DIB identified in Section 3.1, 3.2 could have been verified more directly by plotting I(y,t) for various monotonic transformations of x. A direct comparison of the explicit and implicit forms of the algorithms would also also make for a stronger paper in my opinion.\n\nPros:\n* Theoretically well motivated\n* Promising results on synthetic task\n* Potential for impact\nCons:\n* Paper suffers from lack of clarity (method and experimental section)\n* Lack of ablative / introspective experiments\n* Weak empirical results (small or toy datasets only).', '[====================================REVISION ======================================================]\nOk so the paper underwent major remodel, which significantly improved the clarity. I do agree now on Figure 5, which tips the scale for me to a weak accept. \n[====================================END OF REVISION ================================================]\n\nThis paper explores the problems of existing Deep variational bottle neck approaches for compact representation learning. Namely, the authors adjust deep variational bottle neck to conform to invariance properties (by making latent variable space to depend on copula only) - they name this model a  copula extension to dvib. They then go on to explore the sparsity of the latent space\n\nMy main issues with this paper are experiments: The proposed approach is tested only on 2 datasets (one synthetic, one real but tiny - 2K instances) and some of the plots (like Figure 5) are not convincing to me. On top of that, it is not clear how two methods compare computationally and how introduction of the copula  affects the convergence (if it does)\n\nMinor comments\nPage 1: forcing an compact -> forcing a compact\n“and and” =>and\nSection 2: mention that I is mutual information, it is not obvious for everyone\n\nFigure 3: circles/triangles are too small, hard to see \nFigure 5: not really convincing. B does not appear much more structured than a, to me it looks like a simple transformation of a. \n']","[-20, 20, -20, 20]","[50, 60, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The claims appear to be sufficiently verified in the experiments'), they also express several concerns and criticisms. The reviewer notes issues with clarity, struggles to see the relevance of the method, and describes the originality as 'Average'. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, even when expressing criticisms. They use phrases like 'I wonder' and 'it would have been great' to soften their critiques, and they provide specific, constructive feedback without using harsh or dismissive language."", ""Sentiment score: The review starts with a neutral summary of the paper's content. While it points out some unclear aspects and areas for improvement, it also acknowledges the interesting main idea and well-motivated approach. The reviewer suggests additional experiments but recognizes the informative new results in the update. The overall tone is slightly positive, hence a score of 20.\n\nPoliteness score: The language used is generally polite and constructive. The reviewer uses phrases like 'it would be more helpful if' and 'it would be more significant if' when suggesting improvements. They also acknowledge the authors' efforts in addressing concerns in the update. The critique is presented in a professional manner without harsh language. However, it's not overly formal or deferential, so a score of 60 reflects this balanced politeness."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's promising idea and potential impact, they state that the paper is not ready for publication due to lack of clarity and limited experimentation. The reviewer lists more cons than pros and expresses significant concerns about the paper's current state. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'I believe,' 'Could the authors clarify,' and 'I would like to see,' which maintain a polite tone while providing feedback. The reviewer also balances criticism with positive remarks about the paper's potential and interesting experiments."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges significant improvements in clarity and indicates a 'weak accept' for the paper. However, they still express some concerns about the experiments and figures. The politeness score is moderately positive (50) as the reviewer uses professional language and offers constructive criticism without harsh or rude comments. They provide specific suggestions for improvement and balance positive aspects ('significantly improved clarity') with areas of concern. The tone is generally respectful and aimed at improving the paper rather than being overly critical.""]"
"['In this paper, the authors studied the problem of semi-supervised few-shot classification, by extending the prototypical networks into the setting of semi-supervised learning with examples from distractor classes.  The studied problem is interesting, and the paper is well-written. Extensive experiments are performed to demonstrate the effectiveness of the proposed methods.  While the proposed method is a natural extension of the existing works (i.e., soft k-means and meta-learning).On top of that, It seems the authors have over-claimed their model capability at the first place as the proposed model cannot properly classify the distractor examples but just only consider them as a single class of outliers. Overall, I would like to vote for a weakly acceptance regarding this paper.', ""This paper proposes to extend the Prototypical Network (NIPS17) to the semi-supervised setting with three possible \nstrategies. One consists in self-labeling the unlabeled data and then updating the prototypes on the basis of the \nassigned pseudo-labels. Another is able to deal with the case of distractors i.e.  unlabeled samples not beloning to\nany of the known categories. In practice this second solution is analogous to the first, but a general 'distractor' class\nis added. Finally the third technique learns to weight the samples according to their distance to the original prototypes.\n\nThese strategies are evaluated in a particular semi-supervised transfer learning setting:  the models are first trained \non some source categories with few labeled data and large unlabeled samples (this setting is derived by subselecting\nmultiple times a large dataset), then they are used on a final target task with again few labeled data and large \nunlabeled samples but beloning to a different set of categories.\n\n+ the paper is well written, well organized and overall easy to read\n+/-  this work builds largely on previous work. It introduces only some small technical novelty inspired by soft-k-means\nclustering that anyway seems to be effective.\n+ different aspect of the problem are analyzed by varying the number of disctractors and varying the level of\nsemantic relatedness between the source and the target sets\n\nFew notes and questions\n1) why for the omniglot experiment the table reports the error results? It would be better to present accuracy as for the other tables/experiments\n2) I would suggest to use source and target instead of train and test -- these two last terms are confusing because\nactually there is a training phase also at test time.\n3) although the paper indicate that there are different other few-shot methods that could be applicable here, \nno other approach is considered besides the prothotipical network and its variants. An further external reference \ncould be used to give an idea of what would be the experimental result at least in the supervised case.\n\n\n\n\n"", 'This paper is an extension of the “prototypical network” which will be published in NIPS 2017. The classical few-shot learning has been limited to using the unlabeled data, while this paper considers employing the unlabeled examples available to help train each episode. The paper solves a new semi-supervised situation, which is more close to the setting of the real world, with an extension of the prototype network.  Sufficient implementation detail and analysis on results.\n\nHowever, this is definitely not the first work on semi-supervised formed few-shot learning. There are plenty of works on this topic [R1, R2, R3]. The authors are advised to do a thorough survey of the relevant works in Multimedia and computer vision community. \n \nAnother concern is that the novelty. This work is highly incremental since it is an extension of existing prototypical networks by adding the way of leveraging the unlabeled data. \n\nThe experiments are also not enough. Not only some other works such as [R1, R2, R3]; but also the other naïve baselines should also be compared, such as directly nearest neighbor classifier, logistic regression, and neural network in traditional supervised learning. Additionally, in the 5-shot non-distractor setting on tiered ImageNet, only the soft kmeans method gets a little bit advantage against the semi-supervised baseline, does it mean that these methods are not always powerful under different dataset?\n\n[R1] “Videostory: A new multimedia embedding for few-example recognition and translation of events,” in ACM MM, 2014\n\n[R2] “Transductive Multi-View Zero-Shot Learning”, IEEE TPAMI 2015\n\n[R3] “Video2vec embeddings recognize events when examples are scarce,” IEEE TPAMI 2014\n']","[20, 60, -20]","[50, 70, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting problem, good writing, and extensive experiments. However, they also point out limitations and over-claims, leading to a 'weakly acceptance' rather than strong approval. The politeness score is moderately positive (50) as the reviewer uses respectful language, acknowledges the paper's strengths, and provides constructive criticism without harsh words. The tone is professional and balanced, offering both praise and areas for improvement."", ""The sentiment score is 60 (moderately positive) because the reviewer starts with a neutral summary of the paper's content, followed by several positive points (well-written, well-organized, effective technique, thorough analysis). There are some minor criticisms, but they are balanced by the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as suggestions or questions rather than direct attacks. The reviewer acknowledges the paper's strengths before offering areas for improvement, which is a polite approach. The use of '+' and '+/-' to structure feedback is also a considerate way to present information."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'Sufficient implementation detail and analysis on results'), they express several concerns about novelty, lack of comprehensive literature review, and insufficient experiments. The overall tone suggests the paper needs significant improvements.\n\nThe politeness score is moderately positive (50) as the reviewer uses respectful language throughout. They start with positive comments and use phrases like 'The authors are advised to' rather than making harsh demands. The criticism is presented constructively, suggesting improvements rather than outright dismissing the work.\n\nThe reviewer balances positive and negative feedback, maintaining a professional tone throughout, which contributes to both the sentiment and politeness scores.""]"
"['This paper proposes a method to learn contextualized word representations (ELMO) by pretraining a multilayer bidirectional LSTM language model and using representations from all levels of the LSTM in the input or output layer of a supervised task of interest. \nExperiments on various datasets (SNLI, SQuAD, SRL, Coref, NER, SST) show that the proposed method improve over baseline models.\nAblation analysis demonstrate that using all layers of ELMO is always better than just using only the final layer, and that representations learned by ELMO capture basic notions of word senses and part of speeches.\n\nThe paper is well written and I think learning contextualized word representations is an important topic.\nHowever, one thing that I am not sure about from experiments in the paper is whether the improvements come from an increase in model capacity and (unlabeled) data used to train the model, or whether there are more interesting things going on.\n- What makes the proposed approach different than just a deeper architecture for each of the considered tasks, where some parts of the network are trained using unlabeled data?\n- Is the pretraining with unlabeled data necessary, or can we just have this deep architecture and train everything with the available supervised data?\n- An ELMO enhanced model has more parameters than the baseline model for each task. What is the performance of the (non deep) baseline method with comparable number of parameters (bigger hidden size)?\n\nMore generally, it is not surprising that given sufficient training data, a deeper model (e.g., ELMO enhanced models) with multiple connections across layers will perform better than shallower models with fewer parameters.\nI would like to see more analysis and/or explanations on why the proposed method contributes more beyond this.', 'The authors learn token embeddings that use surrounding context by concatenating representations obtained by training a bidirectional language model, very similar to Peters et al. 2017. They learn a distribution of weights for each layer of embeddings of the pre-trained bi-lm language model. These embeddings improve accuracies over a large range of tasks. \n\nThe technical contribution of the paper seems minimal on top of Peters et al.: Learning weights for every layer of embeddings, adding dropout, and adding a regularization term to the training. They have evaluated the efficacy of these embeddings on more tasks than the original paper that introduced them. As it stands, there is not enough novelty in this paper. Answering the questions from their future work would be interesting and would add more technical depth to the paper. ', 'This paper proposed a model called ‘deep contextualized’ to extract word embeddings for downstream applications. This model is simply a bi-directional language model (biLM) and the word embedding is a weighted combination of the output of the hidden layers (forward and backward). Furthermore like previous work, the authors proposed to pre-train the biLM with a large amount of data and then use the embeddings in combination with the context-independent word embedding in neural network models (in this paper, RNN) for final applications. Their results showed consistent improvements over the baseline and the previous best systems on several tasks.\n\nSome detailed comments:\n-\tI would like to see an overview figure which illustrates the biLM and its integration in downstream applications. Furthermore, it is also interesting to see the performance difference between with and without fine-tuning of the biLM.\n-\tIntrinsic evaluations are missing in this paper. Although we know that word similarity tasks are not the best way to evaluate word embeddings, it is always informative to report results on these standard tasks.\n-\tThe baseline results in table 1 and table 2 are not consistent. Is there something wrong?\n-\tDid the baseline systems use pretrained embeddings or randomly initialized ones? In my opinion, the right baseline systems should use pretrained word2vec or glove embeddings.\n']","[-20, -50, 50]","[60, 0, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and the paper's good writing, they express significant doubts about the novelty and depth of the contribution. The reviewer raises several critical questions and suggests that the improvements might be due to increased model capacity rather than innovative techniques. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting their concerns. They phrase their criticisms as questions and suggestions rather than direct attacks, maintaining a professional and constructive tone."", ""The sentiment score is -50 because the reviewer expresses a generally negative view of the paper, stating that the 'technical contribution of the paper seems minimal' and that there is 'not enough novelty in this paper.' However, it's not entirely negative as the reviewer acknowledges some improvements and suggests potential future work. The politeness score is 0 (neutral) because the language used is professional and matter-of-fact, without being particularly polite or rude. The reviewer presents their critique directly but without using harsh or overly critical language. They objectively state their observations and concerns about the paper's novelty and contribution."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and consistent improvements over baselines, but also provides several suggestions for improvement. The tone is generally positive, but not overwhelmingly so. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases suggestions as 'I would like to see' rather than demands, and provides constructive feedback. The reviewer maintains a professional tone without being overly formal or informal.""]"
"['The submission presents a method or video prediction from single (or multiple) frames, which is capable of producing stochastic predictions by means of training a variational encoder-decoder model. Stochastic video prediction is a (still) somewhat under-researched direction, due to its inherent difficulty.\n\nThe method can take on several variants: time-invariant [latent variable] vs. time-variant, or action-conditioned vs unconditioned. The generative part of the method is mostly borrowed from Finn et al. (2016). Figure 1 clearly motivates the problem. The method itself is fairly clearly described in Section 3; in particular, it is clear why conditioning on all frames during training is helpful. As a small remark, however, it remains unclear what the action vector a_t is comprised of, also in the experiments.\n\nThe experimental results are good-looking, especially when looking at the provided web site images. \nThe main goal of the quantitative comparison results (Section 5.2) is to determine whether the true future is among the generated futures. While this is important, a question that remains un-discussed is whether all generated stochastic samples are from realistic futures. The employed metrics (best PSNR/SSIM among multiple samples) can only capture the former, and are also pixel-based, not perceptual.\n\nThe quantitative comparisons are mostly convincing, but Figure 6 needs some further clarification. It is mentioned in the text that ""time-varying latent sampling is more stable beyond the time horizon used during training"". While true for Figure 6b), this statement is contradicted by both Figure 6a) and 6c), and Figure 6d) seems to be missing the time-invariant version completely (or it overlaps exactly, which would also need explanation). As such, I\'m not completely clear on whether the time variant or invariant version is the stronger performer.\n\nThe qualitative comparisons (Section 5.3) are difficult to assess in the printed material, or even on-screen. The animated images on the web site provide a much better impression of the true capabilities, and I find them convincing.\n\nThe experiments only compare to Reed et al. (2017)/Kalchbrenner et al. (2017), with Finn at al. (2016) as a non-stochastic baseline, but no comparisons to, e.g., Vondrick et al. (2016) are given. Stochastic prediction with generative adversarial networks is a bit dismissed in Section 2 with a mention of the mode-collapse problem.\n\nOverall the submission makes a significant enough contribution by demonstrating a (mostly) working stochastic prediction method on real data.', 'Quality: above threshold\nClarity: above threshold, but experiment details are missing.\nOriginality: slightly above threshold.\nSignificance: above threshold\n\nPros:\n\nThis paper proposes a stochastic variational video prediction model. It can be used for prediction in optionally available external action cases. The inference network is a convolution net and the generative network is using a previously structure with minor modification. The result shows its ability to sample future frames and outperforms with methods in qualitative and quantitive metrics.\n\nCons:\n\n1. It is a nice idea and it seems to perform well in practice, but are there careful experiments justifying the 3-stage training scheme? For example, compared with other schemes like alternating between 3 stages, dynamically soft weighting terms. \n\n2. It is briefly mentioned in the context, but has there any attempt towards incorporating previous frames context for z, instead of sampling from prior? This piece seems much important in the scenarios which this paper covers.\n\n3. No details about training (training data size, batches, optimization) are provided in the relevant section, which greatly reduces the reproducibility and understanding of the proposed method. For example, it is not clear whether the model can generative samples that are not previously seen in the training set. It is strongly suggested training details be provided. \n\n4. Minor, If I understand correctly, in equation in the last paragraph above 3.1,  z instead of z_t \n', ""1) Summary\nThis paper proposed a new method for predicting multiple future frames in videos. A new formulation is proposed where the frames’ inherent noise is modeled separate from the uncertainty of the future. This separation allows for directly modeling the stochasticity in the sequence through a random variable z ~ p(z)  where the posterior  q(z | past and future frames) is approximated by a neural network, and as a result, sampling of a random future is possible through sampling from the prior p(z) during testing. The random variable z can be modeled in a time-variant and time-invariant way. Additionally, this paper proposes a training procedure to prevent their method from ignoring the stochastic phenomena modeled by z. In the experimental section, the authors highlight the advantages of their method in 1) a synthetic dataset of shapes meant to clearly show the stochasticity in the prediction, 2) two robotic arm datasets for video prediction given and not given actions, and 3) A challenging human action dataset in which they perform future prediction only given previous frames.\n\n\n\n2) Pros:\n+ Novel/Sound future frame prediction formulation and training for modeling the stochasticity of future prediction.\n+ Experiments on the synthetic shapes and robotic arm datasets highlight the proposed method’s power of multiple future frame prediction possible.\n+ Good analysis on the number of samples improving the chance of outputting the correct future, the modeling power of the posterior for reconstructing the future, and a wide variety of qualitative examples.\n+ Work is significant for the problem of modeling the stochastic nature of future frame prediction in videos.\n\n\n\n\n3) Cons:\nApproximate posterior in non-synthetic datasets:\nThe variable z seems to not be modeling the future very well. In the robot arm qualitative experiments, the robot motion is well modeled, however, the background is not. Given that for the approximate posterior computation the entire sequence is given (e.g. reconstruction is performed), I would expect the background motion to also be modeled well. This issue is more evident in the Human 3.6M experiments, as it seems to output blurriness regardless of the true future being observed. This problem may mean the method is failing to model a large variety of objects and clearly works for the robotic arm because a very similar large shape (e.g. robot arm) is seen in the training data. Do you have any comments on this?\n\n\n\nFinn et al 2016 PNSR performance on Human 3.6M:\nIs the same exact data, pre-processing, training, and architecture being utilized? In her paper, the PSNR for the first timestep on Human 3.6M is about 41 (maybe 42?)  while in this paper it is 38.\n\n\n\nAdditional evaluation on Human 3.6M:\nPSNR is not a good evaluation metric for frame prediction as it is biased towards blurriness, and also SSIM does not give us an objective evaluation in the sense of semantic quality of predicted frames. It would be good if the authors present additional quantitative evaluation to show that the predicted frames contain useful semantic information [1, 2, 3, 4]. For example, evaluating the predicted frames for the Human 3.6M dataset to see if the human is still detectable in the image or if the expected action is being predicted could be useful to verify that the predicted frames contain the expected meaningful information compared to the baselines.\n\n\n\nAdditional comments:\nAre all 15 actions being used for the Human 3.6M experiments? If so, the fact of the time-invariant model performs better than the time-variant one may not be the consistent action being performed (last sentence of 5.2). The motion performed by the actors in each action highly overlaps (talking on the phone action may go from sitting to walking a little to sitting again, and so on). Unless actions such as walking and discussion were only used, it is unlikely the time-invariant z is performing better because of consistent action. Do you have any comments on this?\n\n\n\n4) Conclusion\nThis paper proposes an interesting novel approach for predicting multiple futures in videos, however, the results are not fully convincing in all datasets. If the authors can provide additional quantitative evaluation besides PSNR and SSIM (e.g. evaluation on semantic quality), and also address the comments above, the current score will improve.\n\n\n\nReferences:\n[1] Emily Denton and Vighnesh Birodkar. Unsupervised Learning of Disentangled Representations from Video. In NIPS, 2017.\n[2] Ruben Villegas, Jimei Yang, Yuliang Zou, Sungryull Sohn, Xunyu Lin, and Honglak Lee. Learning to generate long-term future via hierarchical prediction. In ICML, 2017.\n[3] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive Growing of GANs for Improved Quality, Stability, and Variation. arXiv preprint arXiv:1710.10196, 2017.\n[4] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved Techniques for Training GANs. In NIPS, 2017.\n\n\nRevised review:\nGiven the authors' thorough answers to my concerns, I have decided to change my score. I would like to thank the authors for a very nice paper that will definitely help the community towards developing better video prediction algorithms that can now predict multiple futures.""]","[60, 50, 50]","[70, 70, 75]","[""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the significance of the contribution, praises aspects like clear problem motivation and good-looking results, while also raising some concerns and requesting clarifications. The overall tone is constructive and appreciative of the work's value. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, frames criticisms constructively (e.g., 'needs some further clarification'), and balances positive and negative feedback. The reviewer avoids harsh language and presents concerns as opportunities for improvement rather than outright flaws."", ""The sentiment score is 50 (slightly positive) because the review begins with a generally positive tone, noting that the paper is 'above threshold' in quality, clarity, and significance. The reviewer lists several pros before moving on to cons, indicating a balanced but overall positive view. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions or questions rather than direct attacks. For example, they use phrases like 'It is strongly suggested' and 'are there careful experiments justifying...' instead of more confrontational language. The reviewer also acknowledges the paper's strengths before presenting areas for improvement, which is a polite approach to criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and soundness of the proposed method, highlights its advantages, and notes its significance. However, they also raise several concerns and suggest additional evaluations, indicating a balanced view. The initial review was more critical, but the revised review shows a more positive sentiment after the authors addressed the concerns. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, phrases criticisms as questions or suggestions rather than direct criticisms (e.g. 'Do you have any comments on this?'), and thanks the authors in the revised review. The tone is professional and constructive throughout.""]"
"['[REVISION]\n\nThank you for your clarification. I appreciate the effort and think it has improved the paper. I have updated my score accordingly\n\n====== \n\nThis paper proposes a new objective for learning SkipThought-style sentence representations from corpora of ordered sentences. The algorithm is much faster than SkipThoughts as it swaps the word-level decoder for a contrastive classification loss. \n\nComments:\n\nSince one of the key advantages of this method is the speed, I was surprised there was not a more formal comparison of the speed of training different models. For instance, it would be more convincing if two otherwise identical encoders were trained on the same machine on the books corpus with the proposed objective and the skipthoughts decoding objective, and the representations compared after X hours of training. The reported 2 weeks required to train Skipthoughts comes from the paper, but things might be faster now with more up-to-date deep learning libraries etc. If this was what was in fact done, then it\'s probably just a case of presenting the comparison in a more formal way. I would also lose the sentence ""we are able to train many models in the time it takes to train most unsupervised"" (see next point for reasons why this is questionable).\n\nIt would have been interesting to apply this method with BOW encoders, which should be even faster than RNN-based encoders reported in this paper. The faster BOW models tend to give better performance on cosine-similarity evaluations ( quantifying the nearest-neighbour analysis that the authors use in this paper). Indeed, it would be interesting (although of course not definitive) to see comparison of the proposed algorithm (with BOW and RNN encoders) on cosine sentence similarity evaluations. \n\nThe proposed novelty is simple and intuitive, which I think is a strength of the method. However, a simple idea makes overlap with other proposed approaches more likely, and I\'d like the author to check through the public comments to ensure that all previous related ideas are noted in this paper. \n\nI think the authors could do more to emphasise what the point is of trying to learn sentence embeddings. An idea of the eventual applications of these embeddings would make it easier to determine, for instance, whether the supervised ensembling method applied here would be applicable in practice. Moreover, many papers have emphasised the limitations of the evaluations used in this paper (although they are still commonly used) so it would be good to acknowledge that it\'s hard to draw too many conclusions from such numbers. That said, the numbers are comparable Skipthoughts, so it\'s clear that this method learns representations of comparable quality. \n\nThe justification for the proposed algorithm is clear in terms of efficiency, but I don\'t think it\'s immediately clear from a semantic / linguistic point of view. The statement ""The meaning of a sentence is the property that creates bonds...."" seems to have been cooked up to justify the algorithm, not vice versa. I would cut all of that speculation out and focus on empirically verifiable advantages. \n\nThe section of image embeddings comes completely out of the blue and is very hard to interpret. I\'m still not sure I understand this evaluation (short of looking up the Kiros et al. paper), or how the proposed model is applied to a multi-modal task.\n\nThere is much scope to add more structured analysis of the type hinted by the nearest neighbours section. Cherry picked lists don\'t tell the reader much, but statistics or more general linguistic trends can be found in these neighbours and aggregated, that could be very interesting. \n\n', '==Update==\n\nI appreciate the response, and continue to recommend acceptance. The evaluation metric used in this paper (SentEval) represents an important open problem in NLP—learning reusable sentence representations—and one of the problems in NLP best suited to presentation at IC*LR*. Because of this, I\'m willing to excuse the fact that the paper is only moderately novel, in light of the impressive reported results.\n\nWhile I would appreciate a direct (same codebase, same data) comparison with some outside baselines, this paper meets or exceeds the standards for rigor that were established by previous published work in the area, and the existing results are sufficient to support some substantial conclusions.\n\n==========\n\nThis paper proposes an alternative formulation of Kiros\'s SkipThought objective for training general-purpose sentence encoder RNNs on unlabeled data. This formulation replaces the decoder in that model with a second encoder, and yields substantial improvements to both speed and model performance (as measured on downstream transfer tasks). The resulting model is, for the first time, reasonably competitive even with models that are trained end-to-end on labeled data for the downstream tasks (despite the requirement, imposed by the evaluation procedure, that only the top layer classifier be trained for the downstream tasks here), and is also competitive with models trained on large labeled datasets like SNLI. The idea is reasonable, the topic is important, and the results are quite strong. I recommend acceptance, with some caveats that I hope can be addressed.\n\nConcerns:\n\nA nearly identical idea to the core idea of this paper was proposed in an arXiv paper this spring, as a commenter below pointed out. That work has been out for long enough that I\'d urge you to cite it, but it was not published and it reports results that are far less impressive than yours, so that omission isn\'t a major problem.\n\nI\'d like to see more discussion of how you performed your evaluation on the downstream tasks. Did you use the SentEval tool from Conneau et al., as several related recent papers have? If not, does your evaluation procedure differ from theirs or Kiros\'s in any meaningful way?\n\nI\'m also a bit uncomfortable that the paper doesn\'t directly compare with any baselines that use the exact same codebase, word representations, hyperparameter tuning procedure, etc.. I would be more comfortable with the results if, for example, the authors compared a low-dimensional version of their model with a low-dimensional version of SkipThought, trained in the *exact* same way, or if they implemented the core of their model within the SkipThought codebase and showed strong results there.\n\nMinor points:\n\nThe headers in Table 1 don\'t make it all that clear which additions (vectors, UMBC) are cumulative with what other additions. This should be an easy fix. \n\nThe use of the check-mark as an output in Figure 1 doesn\'t make much sense, since the task is not binary classification.\n\n""Instead of training a model to reconstruct the surface form of the input sentence or its neighbors, our formulation attempts to focus on the semantic aspects of sentences. The meaning of a sentence is the property that creates bonds between a sequence of sentences and makes it logically flow."" – It\'s hard to pin down exactly what this means, but it sounds like you\'re making an empirical claim here: semantic information is more important than non-semantic sources of variation (syntactic/lexical/morphological factors) in predicting the flow of a text. Provide some evidence for this, or cut it.\n\nYou make a similar claim later in the same section: ""In figure 1(a) however, the reconstruction loss forces the model to predict local structural information about target sentences that may be irrelevant to its meaning (e.g., is governed by grammar rules)."" This is a testable prediction: Are purely grammatical (non-semantic) variations in sentence form helpful for your task? I\'d suspect that they are, at least in some cases, as they might give you clues as to style, dialect, or framing choices that the author made when writing that specific passage.\n\n""Our best BookCorpus model (MC-QT) trains in just under 11hrs, compared to skip-thought model’s training time of 2 weeks."" –  If you say this, you need to offer evidence that your model is faster. If you don\'t use the same hardware and low-level software (i.e., CuDNN), this comparison tells us nearly nothing. The small-scale replication of SkipThought described above should address this issue, if performed.\n', 'This paper proposes a framework for unsupervised learning of sentence representations by maximizing a model of the probability of true context sentences relative to random candidate sentences. Unique aspects of this skip-gram style model include separate target- and context-sentence encoders, as well as a dot-product similarity measure between representations. A battery of experiments indicate that the learned representations have comparable or better performance compared to other, more computationally-intensive models.\n\nWhile the main constituent ideas of this paper are not entirely novel, I think the specific combination of tools has not been explored previously. As such, the novelty of this paper rests in the specific modeling choices and the significance hinges on the good empirical results. For this reason, I believe it is important that additional details regarding the specific architecture and training details be included in the paper. For example, how many layers is the GRU? What type of parameter initialization is used? Releasing source code would help answer these and other questions, but including more details in the paper itself would also be welcome.\n\nRegarding the empirical results, the method does appear to achieve good performance, especially given the compute time. However, the balance between performance and computational complexity is not investigated, and I think such an analysis would add significant value to the paper. For example, I see at least three ways in which performance could be improved at the expense of additional computation: 1) increasing the candidate pool size 2) increasing the corpus size and 3) increasing the embedding size / increasing the encoder capacity. Does the good performance/efficiency reported in the paper depend on achieving a sweet spot among those three hyperparameters?\n\nOverall, the novelty of this paper is fairly low and there is still substantial room for improvement in some of the analysis. On the other hand, I think this paper proposes an intuitive model and demonstrates good performance. I am on the fence, but ultimately I vote to accept this paper for publication.']","[20, 60, 50]","[60, 70, 75]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges improvements in the paper and sees value in the proposed method, stating it is 'simple and intuitive' and learns representations 'comparable to Skipthoughts'. However, they also raise several concerns and suggest multiple improvements, indicating a mix of positive and critical feedback. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, starting with 'Thank you for your clarification' and using phrases like 'I appreciate the effort'. They frame criticisms constructively, often using 'would be interesting' or 'could do more' rather than direct negative statements. The tone remains professional and courteous while providing detailed feedback."", ""The sentiment score is 60 (positive) because the reviewer recommends acceptance and appreciates the paper's contribution, despite some concerns. They describe the results as 'impressive' and 'quite strong', and state that the paper 'meets or exceeds the standards for rigor'. The politeness score is 70 (polite) due to the reviewer's constructive and respectful tone throughout. They use phrases like 'I appreciate', 'I would appreciate', and 'I hope can be addressed', which indicate politeness. The reviewer also balances criticism with praise and provides specific, actionable feedback. However, they don't use overly formal or deferential language, keeping the score from being extremely high."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's good empirical results and intuitive model, while also noting areas for improvement. The reviewer ultimately votes to accept the paper, indicating a positive overall sentiment despite some reservations. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as opportunities for improvement rather than harsh criticisms. The reviewer also acknowledges the paper's strengths alongside its weaknesses, maintaining a balanced and professional tone.""]"
"['This is an ""analyze why"" style of paper:  the authors attempt to explain the relationship between some network property (in this case, ""reliance on single directions""), and a desired performance metric (in this case, generalization ability).   The authors quantify a variety of related ways to measure ""reliance on single directions"" and show that the more reliant on a single directions a given network is, the less well it generalizes.   \n\nClarity:  The paper is fairly clearly written.  Sometimes key details are in the footnotes (e.g. see footnote 3) -- not sure why -- but on the  whole, I think the followed the paper reasonably well.  \n\nQuality: The work makes a good-faith attempt to be fairly systematic -- e.g evaluating several different types of network structures, with reasonable numbers of random initializations, and also illustrates the main point in several different comparatively independent-seeming ways.  I feel fairly confident that the results are basically right within the somewhat limited domain that the authors explore. \n\nOriginality: This work is one in a series of papers about the topic of trying to understand what leads to good generalization in deep neural networks. I don\'t know that the concept of ""reliance on a single direction"" seems especially novel to me, but on the other hand, I can\'t think of another paper that precisely investigates this notion the way it is done here.   \n\nSignificance: The work touches on some important issues.  I think the demonstration that the existence of strongly class-selective neurons is not a good correlate for generalization is interesting.   This point illustrates something that has made me a bit uncomfortable with the trend toward ""interpretable machine learning"" that has been arising recently:  in many of those results, it is shown that some fraction of the units at various levels of a trained deepnet have optimal driving stimuli that seem somewhat interpretable, with the implication that the existence of such units is an important correlate of network performance.  There has even been some claims that better-performing networks have more ""single-direction"" interpretable units [1].  The fact that the current results seem directly in contradiction to that line of work is interesting, and the connections to batch normalization and dropout are for the same reason interesting.  However, I wish the authors had grappled more directly with the apparent contradiction with (e.g.) [1].   There is probably a kind of tradeoff here.   The closer the training dataset is to what is being tested for ""generalization"", the more likely that having single-direction units is useful; and vice-versa.   I guess the big question is: what types of generalization are actually demanded / desired in real deployed machine learning systems (or in the brain)?  How does those cases compare with the toy examples analyzed here?   The paper doesn\'t go far enough in really addressing these questions, but it is sort of beginning to make an effort. \n\nHowever, for me the main failing of the paper is that it\'s fairly descriptive without being that prescriptive. Does using their metric of reliance on a single direction, as a regularizer in and of itself, add anything above any beyond existing regularizers (e.g. batch normalization or dropout)?  It doesn\'t seem like they tried. This seems to me the key question to understanding the significance of their results.   Is ""reliance on single direction"" actually a good regularizer as such, especially for ""real"" problems like (e.g.) training a deep Convnet on (e.g.) ImageNet or some other challenging dataset?  Would penalizing for this quantity improve the generalization of a network trained on ImageNet to other visual datasets (e.g. MS-COCO)?  If so, this would be a very significant result and would make me really care about their idea of ""reliance on a singe direction"".  If such results do not hold, it seems to me like one more theoretical possibility that would bite the dust when tested at scale.  \n\n[1] http://netdissect.csail.mit.edu/final-network-dissection.pdf', '\nSummary:\n- nets that rely on single directions are probably overfitting\n- batch norm helps not having large single directions\n- high class selectivity of single units is a bad measure to find ""important"" neurons that help a NN generalize.\n\nThe experiments that this paper does are quite interesting, somewhat confirming intuitions that the community had, and bringing new insights into generalization. The presentation is good overall, but many minor improvements could help with readability.\n\n\nRemarks:\n- The first thing you should say in this paper is what you mean by ""single direction"", at least an intuition, to be refined later. The second sentence of section 2 could easily be plugged in your abstract.\n- You should already mention in section 2.1 that you are using ReLUs, otherwise clamping to 0 might take a different sense.\n- considering the lack of page limit at ICLR, making *all* your figures bigger would be beneficial to readability.\n- Figure 2\'s y values drop rapidly as a function of x, maybe make x have a log scale or something that zooms in near 0 would help readability.\n- Figure 3b\'s discrete regimes is very weird, did you actually look at how much these clusters converged to the same solution in parameter space?\n- Figure 4a is nice, but an additional figure zooming in on the first 2 epochs would be really great, because that AUC curve goes up really fast in the beginning.\n- Arpit et al. find that there is more cross-class information being shared for true labels than random labels. Considering you find that low class selectivity is an indicator of good generalization, would it make sense to look at ""cross-class selectivity""? If a neuron learns a feature shared by 2 or more classes, then it has this interesting property of offering a discrimination potential for multiple classes at the same time, rather than just 1, making it more ""useful"" potentially, maybe less adversary prone?\n- You say in the figure captions that you use random orderings of the features to perform ablation, but nowhere in the main text (which would be nice).\n\n', 'article summary: \nThe authors use ablation analyses to evaluate the reliance on single coordinate-aligned directions in activation space (i.e. the activation of single units or feature maps) as a function of memorization. They find that the performance of networks that memorize more are also more affected by ablations. This result holds even for identical networks trained on identical data. The dynamics of this reliance on single directions suggest that it could be used as a criterion for early stopping. The authors discuss this observation in relation to dropout and batch normalization. Although dropout is an effective regularizer to prevent memorization of random labels, it does not prevent over-reliance on single directions. Batch normalization does appear to reduce the reliance on single directions, providing an alternative explanation for the effectiveness of batch normalization. Networks trained without batch normalization also demonstrated a significantly higher amount of class selectivity in individual units compared to networks trained without batch normalization. Highly selective units were found to be no more important than units that were not selective to a particular class. These results suggest that highly selective units may actually be harmful to network performance. \n\n* Quality: The paper presents thorough and careful empirical analyses to support their claims.\n* Clarity: The paper is very clear and well-organized. Sufficient detail is provided to reproduce the results.\n* Originality: This work is one of many recent papers trying to understand generalization in deep networks. Their description of the activation space of networks that generalize compared to those that memorize is novel. The authors throughly relate their findings to related work on generalization, regularization, and pruning. However, the authors may wish to relate their findings to recent reports in neuroscience observing similar phenomena (see below).\n* Significance: The paper provides valuable insight that helps to relate existing theories about generalization in deep networks. The insights of this paper will have a large impact on regularization, early stopping, generalization, and methods used to explain neural networks. \n\nPros:\n* Observations are replicated for several network architectures and datasets. \n* Observations are very clearly contextualized with respect to several active areas of deep learning research.\nCons:\n* The class selectivity measure does not capture all class-related information that a unit may pass on. \n\nComments:\n* Regarding the class selectivity of single units, there is a growing body of literature in neurophysiology and neuroimaging describing similar observations where the interpretation has been that a primary role of any neural pathway is to “denoise” or cancel out the “distractor” rather than just amplifying the “signal” of interest. \n    * Untuned But Not Irrelevant: The Role of Untuned Neurons In Sensory Information Coding, https://www.biorxiv.org/content/early/2017/09/21/134379\n    * Correlated variability modifies working memory fidelity in primate prefrontal neuronal ensembles https://www.ncbi.nlm.nih.gov/pubmed/28275096\n    * On the interpretation of weight vectors of linear models in multivariate neuroimaging http://www.sciencedirect.com/science/article/pii/S1053811913010914\n        * see also LEARNING HOW TO EXPLAIN NEURAL NETWORKS https://openreview.net/forum?id=Hkn7CBaTW\n* Regarding the intuition in section 3.1, ""The minimal description length of the model should be larger for the memorizing network than for the structure- finding network. As a result, the memorizing network should use more of its capacity than the structure-finding network, and by extension, more single directions”. Does reliance on single directions not also imply a local encoding scheme? We know that for a fixed number of units, a distributed representation will be able to encode a larger number of unique items than a local one. Therefore if this behaviour was the result of needing to use up more of the capacity of the network, wouldn’t you expect to observe more distributed representations? \n\nMinor issues:\n* In the first sentence of section 2.3, you say you analyzed three models and then you only list two. It seems you forgot to include ResNet trained on ImageNet.']","[20, 60, 80]","[60, 70, 90]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's clarity, quality, and originality, while also pointing out some limitations. The reviewer finds the work interesting and touching on important issues, but also notes that it doesn't go far enough in addressing key questions. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and providing constructive criticism. The reviewer balances positive comments with areas for improvement without using harsh or dismissive language. The tone is professional and academic, offering suggestions for enhancement rather than outright criticism."", ""The sentiment score is 60 (moderately positive) because the reviewer describes the experiments as 'quite interesting' and notes that they confirm intuitions and bring new insights. They also state that the presentation is 'good overall'. However, it's not extremely positive as they suggest 'many minor improvements'. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticism. Phrases like 'would be beneficial' and 'would be really great' indicate a polite tone. The reviewer also balances positive comments with areas for improvement, maintaining a courteous and professional tone throughout the review."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, highlighting its quality, clarity, originality, and significance. They use phrases like 'thorough and careful empirical analyses', 'very clear and well-organized', and 'valuable insight'. The few cons mentioned are minor and constructive. The politeness score is 90 (very polite) due to the reviewer's consistently respectful and professional tone. They offer praise where due and frame criticisms as suggestions or questions rather than direct attacks. The use of phrases like 'The authors may wish to' and 'Does reliance on single directions not also imply...' demonstrates a courteous approach to providing feedback.""]"
"['SUMMARY \n\nThe model evaluates symbolic algebraic/trigonometric equalities for validity, with an output unit for validity level at the root of a tree of LSTM nodes feeding up to the root; the structure of the tree matches the parse tree of the input equation and the type of LSTM cell at each node matches the symbol at that node in the equation: there is a different cell type for each symbol. It is these cell types that are learned. The training data includes labeled true and false algebraic/trigonometric identities (stated over symbols for variables) as well as function-evaluation equalities such as ""tan(0.28) = 0.29"" and decimal-expansion equations like ""0.29 = 2*10^(-1) + 9*10^(-2)"".  I believe continuous values like ""0.29"" in the preceding expressions are encoded as the literal value of a single unit (feeding into an embedding unit of type W_{num}), whereas the symbols proper (including digit numerals) are encoded as 1-hot vectors (feeding into an embedding unit of type W_{symb}).\nPerformance is at least 97% when testing on unseen expressions of the same depth (up to 4) as the training data. Performance when trained on 3 levels (among 1 - 4) and testing on generalization to the held-out level is at least 96% when level 2 is held out, at least 92% when level 4 is withheld. Performance degrades (even on symbolic identities) when the function-evaluation equalities are omitted, and degrades when LSTM cells are replaced by plain RNN cells. The largest degradation is when the tree structure is replaced (presumably) by a sequence structure.\nPerformance was also tested on a fill-in-the-blank test, where a symbol from a correct equation was removed and all possible replacements for that symbol with expressions of depth up to 2 were tested, then ranked by the resulting validity score from the model. From the graph it looks like an accuracy of about 95% was achieved for the 1-best substituted expression (accuracy was about 32% for a sequential LSTM).\n\nWEAKNESSES\n\n* The title is misleading; ""blackbox function evaluation"" does not suggest what is intended, which is training on function-evaluation equations. The actual work is more interesting than what the title suggests.\n* The biggest performance boost (roughly 15%) arises from use of the tree structure, which is given by an oracle (implemented in a symbolic expression parser, presumably): the network does not design its own example-dependent structure.\n* What does the sympy baseline mean in Table 2? We are only told that sympy is a ""symbolic solver"". Yet the sympy performance scores are in the 70-80% range. If the solver’s performance is that weak, why is it used during generation of training data to determine the validity of possible equations?\n* Given that this is a conference on ""learning representations"" it would have been nice to see at least a *little* examination of the learned representations. It would be easy to do some interesting tests. How well does the vector embedding for ""2*10^(-1) + 9*10^(-2)"" match the vector for the real value 0.29? W_{num} embeds a continuum of real values in R^d: what is this 1-dimensional embedding manifold like? How do the embeddings of different integers provided by W_{sym} relate to one another? My rating would have been higher had there been some analysis of the learned representations.\n* We are told only that the ""hidden dimension … varies""; it would be nice if the text or results tables gave at least some idea of what magnitude of embedding dimension we’re talking about.\n\nSTRENGTHS\n\nThe weaknesses above notwithstanding, this is a very interesting piece of work with impressive results. \n* The number of functions learned, 28, is a quantum jump from previous studies using 8 or fewer functions.\n* It is good to see the power of training the same system to learn the semantics of functions from the equations they satisfy AND from the values they produce. \n* The inclusion of decimal-expansion equations for relating numeral embeddings to number embeddings is clever. \n* The general method used for randomly generating a non-negligible proportion of true equations is useful.\n* The evaluation of the model is thorough and clear.\n* In fact the exposition in the paper as a whole is very clear.', 'This paper proposes a model that predicts the validity of a mathematical expression (containing trigonometric or elementary algebraic expressions) using a recursive neural network (TreeLSTM).  The idea is to take the parse tree of the expression, which is converted to the recursive neural network architecture, where weights are tied to the function or symbol used at that node.  Evaluation is performed on a dataset generated specifically for this paper.\n\nThe overall approach described in this paper is technically sound and there are probably some applications (for example in online education).  However the novelty factor of this paper is fairly low — recursive neural nets have been applied to code/equations before in similar models.  See, for example, “Learning program embeddings to propagate feedback on student code” by Piech et al, which propose a somewhat more complex model applied to abstract syntax trees of student written code.\n\nI’m also not completely sure what to make of the experimental results.  One weird thing is that the performance does not seem to drop off for the models as depth grows.  Another strange thing is that the accuracies reported do not seem to divide the reported test set sizes (see, e.g., the depth 1 row in Table 2).  It would also be good to discuss the Sympy baseline a bit — being symbolic, my original impression was that it would be perfect all the time (if slow), but that doesn’t seem to be the case, so some explanation about what exactly was done here would help.  For the extrapolation evaluation — evaluating on deeper expressions than were in the training set — I would have liked the authors to be more ambitious and see how deep they could go (given, say, up to depth 3 training equations).  \n\n', 'Summary\n\nThis paper presents a dataset of mathematical equations and applies TreeLSTMs to two tasks: verifying and completing mathematical equations. For these tasks, TreeLSTMs outperform TreeNNs and RNNs. In my opinion, the main contribution of this paper is this potentially useful dataset, as well as an interesting way of representing fixed-precision floats. However, the application of TreeNNs and TreeLSTMs is rather straight-forward, so in my (subjective) view there are only a few insights salvageable for the ICLR community and compared to Allamanis et al. (2017) this paper is a rather incremental extension.\n\nStrengths\n\nThe authors present a new datasets for mathematical identities. The method for generating additional correct identities could be useful for future research in this area.\nI find the representation of fixed-precision floats presented in this paper intriguing. I believe this contribution should be emphasized more as it allows the model to generalize to unseen numbers and I am wondering whether the authors see some wider application of this representation for neural programming models.\nI liked the categorization of the related work.\n\nWeaknesses\n\np2: It is mentioned that the framework is the first to combine symbolic expressions with black-box function evaluations, but I would argue that Neural Programmer-Interpreters (NPI; Reed & De Freitas) are already doing that (see Fig 1 in that paper where the execution trace is a symbolic expression and some expressions ""Act(LEFT)"" are black-box function applications directly changing the image).\nThe differences to Allamanis et al. (2017) are not worked out well. For instance, the authors use the TreeNN model from that paper as a baseline but the EqNet model is not mentioned at all. The obvious question is whether EqNets can be applied to the two tasks (verifying and completing mathematical equations) and if so why this has not been done.\nThe contribution regarding black box function application is unclear to me. On page 6, it is unclear to me what ""handles […] function evaluation expressions"". As far as I understand, the TreeLSTM learns to the return value of function evaluation expressions in order to predict equality of equations, but this should be clarified.\nI find the connection of the proposed model and task to ""neural programming"" weak. For instance, as far as I understand there is no support for stateful programs. Furthermore, it would be interesting to hear how this work can be applied to existing programming languages such as Haskell. What are the limitations of the architecture? Could it learn to identify equality of two lists in Haskell?\np6: The paragraph on baseline models is rather uninformative. TreeLSTMs have been shown to outperform Tree NN\'s in various prior work. The statement that ""LSTM cell […] helps the model to have a better understanding of the underlying functions in the domain"" is vague. LSTM cells compared to fully-connected layers in Tree NNs ameliorate vanishing and exploding gradients along paths in the tree. Furthermore, I would like to see a qualitative analysis of the reasoning capabilities that are mentioned here. Did you observe any systematic differences in the ~4% of equations where the TreeLSTM fails to generalize (Table 3; first column).\n\nMinor Comments\n\nAbstract: ""Our framework generalizes significantly better"" I think it would be good to already mention in comparison to what this statement is.\np1: ""aim to solve tasks such as learn mathematical"" -> ""aim to solve tasks such as learning mathematical""\np2: You could add a citation for Theano, Tensorflow and Mxnet.\np2: Could you elaborate how equation completion is used in Mathematical Q&A?\np3: Could you expand on ""mathematical equation verification and completion […] has broader applicability"" by maybe giving some concrete examples.\np3 Eq. 5: What precision do you consider? Two digits?\np3: ""division because that they can"" -> ""division because they can""\np4 Fig. 1: Is there a reason 1 is represented as 10^0 here? Do you need the distinction between 1 (the integer) and 1.0 (the float)?\np5: ""we include set of changes"" -> ""we include the set of changes""\np5: In my view there is enough space to move appendix A to section 2. In addition, it would be great to see more examples of generated identities at this stage (including negative ones).\np5: ""We generate all possible equations (with high probability)"" – what is probabilistic about this?\np5: I don\'t understand why function evaluation results in identities of depth 2 and 3. Is it both or one of them?\np6: The modules ""symbol"" and ""number"" are not shown in the figure. I assume they refer to projections using Wsymb and Wnum?\np6: ""tree structures neural networks"" -> ""tree structured neural networks""\np6: A reference for the ADAM optimizer should be added.\np6: Which method was used for optimizing these hyperparameters? If a grid search was used, what intervals were used?\np7: ""the superiority of Tree LSTM to Tree NN shows that is important to incorporate cells that have memory"" is not a novel insight.\np8: When you mention ""you give this set of equations to the models look at the top k predictions"" I assume you ranked the substituted equations by the probability that the respective model assigns to it?\np8: Do you have an intuition why prediction function evaluations for ""cos"" seem to plateau certain points? Furthermore, it would be interesting to see what effect the choice of non-linearity on the output of the TreeLSTM has on how accurately it can learn to evaluate functions. For instance, one could replace the tanh with cos and might expect that the model has now an easy time to learn to evaluate cos(x).\np8 Fig 4b; p9: Relating to the question regarding plateaus in the function evaluation: ""in Figure 4b […] the top prediction (0.28) is the correct value for tan with precision 2, but even other predictions are quite close"" – they are all the same and this bad, right?\np9: ""of the state-of-the-art neural reasoning systems"" is very broad and in my opinion misleading too. First, there are other reasoning tasks (machine reading/Q&A, Visual Q&A, knowledge base inference etc.) too and it is not obvious how ideas from this paper translate to these domains. Second, for other tasks TreeLSTMs are likely not state-of-the-art (see for example models on the SQuAD leaderboard: https://rajpurkar.github.io/SQuAD-explorer/) .\np9: ""exploring recent neural models that explicitly use memory cells"" – I think what you mean is models with addressable differentiable memory.\n\n# Update after the rebuttal\nThank you for the in-depth response and clarifications. I am increasing my score by one point. I have looked at the revised paper and I strongly suggest that you add the clarifications and in particular comments regarding comparison to related work (NPI, EqNet etc) to the paper. Regarding Fig. 4b, I am still not sure why all scores are the same (0.9977) -- I assume this is not the desired behavior?']","[60, -20, -20]","[70, 50, 60]","[""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the work as 'very interesting' with 'impressive results', and praises several aspects like the quantum jump in functions learned, clever techniques used, and clear exposition. However, they also list several weaknesses, which tempers the overall positivity. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging strengths alongside weaknesses, and phrases criticisms constructively (e.g. 'it would have been nice to see...'). They avoid harsh or dismissive language, instead offering specific suggestions for improvement. The tone remains professional and courteous throughout."", 'The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the approach is technically sound and has potential applications, they also point out several limitations. The reviewer mentions low novelty, questions about experimental results, and suggests more ambitious testing. These critiques outweigh the positive aspects, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They offer constructive criticism without harsh or rude phrasing, maintaining a respectful tone while providing detailed feedback. The reviewer balances positive observations with areas for improvement, which contributes to the polite tone of the review.', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they express several significant criticisms and weaknesses. The reviewer states the paper is 'rather incremental' and has 'only a few insights salvageable for the ICLR community'. However, they do note some positive aspects like the 'potentially useful dataset' and 'interesting way of representing fixed-precision floats'. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout, even when expressing criticisms. They use phrases like 'in my opinion', 'I would argue', and 'I find', which soften the critiques. The reviewer also provides detailed, constructive feedback and suggestions for improvement, which is a polite and helpful approach in academic peer review.""]"
"['The paper presents an extensive framework for complex-valued neural networks. Related literature suggests a variety of motivations for complex valued neural networks: biological evidence, richer representation capacity, easier optimization, faster learning, noise-robust memory retrieval mechanisms and more. \n\nThe contribution of the current work does not lie in presenting significantly superior results, compared to the traditional real-valued neural networks, but rather in developing an extensive framework for applying and conducting research with complex-valued neural networks. Indeed, the most standard work nowadays with real-valued neural networks depends on a variety of already well-established techniques for weight initialization, regularization, activation function, convolutions, etc. In this work, the complex equivalent of many of these basics tools are developed, such as a number of complex activation functions, complex batch normalization, complex convolution, discussion of complex differentiability, strategies for complex weight initialization, complex equivalent of a residual neural network. \n\nEmpirical results show that the new complex-flavored neural networks achieve generally comparable performance to their real-valued counterparts, on a variety of different tasks. Then again, the major contribution of this work is not advancing the state-of-the-art on many benchmark tasks, but constructing a solid framework that will enable stable and solid application and research of these well-motivated models. \n', 'Authors present complex valued analogues of real-valued convolution, ReLU and batch normalization functions. Their ""related work section"" brings up uses of complex valued computation such as discrete Fourier transforms and Holographic Reduced Representations. However their application don\'t seem to connect to any of those uses and simply reimplement existing real-valued networks as complex valued.\n\nTheir contributions are:\n\n1. Formulate complex valued convolution\n2. Formulate two complex-valued alternatives to ReLU and compare them\n3. Formulate complex batch normalization as a ""whitening"" operation on complex domain\n4. Formulate complex analogue of Glorot weight normalization scheme\n\nSince any complex valued computation can be done with a real-valued arithmetic, switching to complex arithmetic needs a compelling use-case. For instance, some existing algorithm may be formulated in terms of complex values, and reformulating it in terms of real-valued computation may be awkward. However, cases the authors address, which are training batch-norm ReLU networks on standard datasets, are already formulated in terms of real valued arithmetic. Switching these networks to complex values doesn\'t seem to bring any benefit, either in simplicity, or in classification performance.', 'This paper defines building blocks for complex-valued convolutional neural networks: complex convolutions, complex batch normalisation, several variants of the ReLU nonlinearity for complex inputs, and an initialisation strategy. The writing is clear, concise and easy to follow.\n\nAn important argument in favour of using complex-valued networks is said to be the propagation of phase information. However, I feel that the observation that CReLU works best out of the 3 proposed alternatives contradicts this somewhat. CReLU simply applies ReLU component-wise to the real and imaginary parts, which has an effect on the phase information that is hard to conceptualise. It definitely does not preserve phase, like modReLU would.\n\nThis makes me wonder whether the ""complex numbers"" paradigm is applied meaningfully here, or whether this is just an arbitrary way of doing some parameter sharing in convnets that happens to work reasonably well (note that even completely random parameter tying can work well, as shown in ""Compressing neural networks with the hashing trick"" by Chen et al.). Some more insight into how phase information is used, what it represents and how it is propagated through the network would help to make sense of this.\n\nThe image recognition results are mostly inconclusive, which makes it hard to assess the benefit of this approach. The improved performance on the audio tasks seems significant, but how the complex nature of the networks helps achieve this is not really demonstrated. It is unclear how the phase information in the input waveform is transformed into the phase of the complex activations in the network (because I think it is implied that this is what happens). This connection is a bit vague. Once again, a more in-depth analysis of this phase behavior would be very welcome.\n\nI\'m on the fence about this work: I like the ideas and they are explained well, but I\'m missing some insight into why and how all of this is actually helping to improve performance (especially w.r.t. how phase information is used).\n\n\nComments:\n\n- The related work section is comprehensive but a bit unstructured, with each new paragraph seemingly describing a completely different type of work. Maybe some subsection titles would help make it feel a bit more cohesive.\n\n- page 3: ""(cite a couple of them)"" should be replaced by some actual references :)\n\n- Although care is taken to ensure that the complex and real-valued networks that are compared in the experiments have roughly the same number of parameters, doesn\'t the complex version always require more computation on account of there being more filters in each layer? It would be nice to discuss computational cost as well.\n\n\nREVISION: I have decided to raise my rating from 5 to 7 as I feel that the authors have adequately addressed many of my comments. In particular, I really appreciated the additional appendix sections to clarify what actually happens as the phase information is propagated through the network.\n\nRegarding the CIFAR results, I may have read over it, but I think it would be good to state even more clearly that these experiments constitute a sanity check, as both reviewer 1 and myself were seemingly unaware of this. With this in mind, it is of course completely fine that the results are not better than for real-valued networks.\n']","[60, -50, 50]","[80, 0, 80]","[""The sentiment score is 60 (positive) because the reviewer acknowledges the extensive framework developed by the authors and its potential value for future research, despite not showing significantly superior results. The reviewer appreciates the work's contribution in developing complex equivalents of standard neural network techniques. The politeness score is 80 (quite polite) as the reviewer uses respectful and professional language throughout, acknowledging the paper's merits without harsh criticism. The reviewer objectively describes the work's contributions and limitations, maintaining a constructive tone."", ""The sentiment score is -50 because the reviewer appears to be somewhat critical of the paper. While they acknowledge the authors' contributions, they question the necessity and benefits of switching to complex-valued arithmetic for the given applications. The reviewer suggests that the authors' approach doesn't bring any significant advantages in terms of simplicity or performance. This critique indicates a negative sentiment, but not extremely so, hence the moderate negative score.\n\nThe politeness score is 0 (neutral) because the reviewer maintains a professional and objective tone throughout. They neither use overly polite language nor any rude or disrespectful expressions. The review focuses on the content and merits of the paper without personal comments or unnecessarily harsh criticism. The language is direct and matter-of-fact, which is typical for academic peer reviews."", ""The sentiment score is 50 (slightly positive) because while the reviewer expresses appreciation for the ideas and clear writing, they also raise several concerns and are 'on the fence' about the work. The revision note indicates an improved opinion, raising their rating. The politeness score is 80 (quite polite) due to the constructive tone, use of phrases like 'I feel that,' 'I like the ideas,' and offering specific suggestions for improvement. The reviewer maintains a respectful and professional tone throughout, even when expressing criticisms.""]"
"['The authors proposed to compress word embeddings by approximate matrix factorization, and to solve the problem with the Gumbel-soft trick. The proposed method achieved compression rate 98% in a sentiment analysis task, and compression rate over 94% in machine translation tasks, without a performance loss. \n\nThis paper is well-written and easy to follow.  The motivation is clear and the idea is simple and effective.\n\nIt would be better to provide deeper analysis in Subsection 6.1. The current analysis is too simple. It may be interesting to explain the meanings of individual components. Does each component is related to a certain topic? Is it meaningful to perform ADD or SUBSTRACT on the leaned code? \n\nIt may also be interesting to provide suitable theoretical analysis, e.g., relationships with the SVD of the embedding matrix.\n', 'This paper proposed a new method to compress the space complexity of word embedding vectors by introducing summation composition over a limited number of basis vectors, and representing each embedding as a list of the basis indices. The proposed method can reduce more than 90% memory consumption while keeping original model accuracy in both the sentiment analysis task and the machine translation tasks.\n\nOverall, the paper is well-written. The motivation is clear, the idea and approaches look suitable and the results clearly follow the motivation.\n\nI think it is better to clarify in the paper that the proposed method can reduce only the complexity of the input embedding layer. For example, the model does not guarantee to be able to convert resulting ""indices"" to actual words (i.e., there are multiple words that have completely same indices, such as rows 4 and 6 in Table 5), and also there is no trivial method to restore the original indices from the composite vector. As a result, the model couldn\'t be used also as the proxy of the word prediction (softmax) layer, which is another but usually more critical bottleneck of the machine translation task.\nFor reader\'s comprehension, it would like to add results about whole memory consumption of each model as well.\nAlso, although this paper is focused on only the input embeddings, authors should refer some recent papers that tackle to reduce the complexity of the softmax layer. There are also many studies, and citing similar approaches may help readers to comprehend overall region of these studies.\n\nFurthermore, I would like to see two additional analysis. First, if we trained the proposed model with starting from ""zero"" (e.g., randomly settling each index value), what results are obtained? Second, What kind of information is distributed in each trained basis vector? Are there any common/different things between bases trained by different tasks?', 'This paper presents an interesting idea to word embeddings that it combines a few base vectors to generate new word embeddings. It also adopts an interesting multicodebook approach for encoding than binary embeddings. \n\nThe paper presents the proposed approach to a few NLP problems and have shown that this is able to significant reduce the size, increase compression ratio, and still achieved good accuracy.\n\nThe experiments are convincing and solid. Overall I am weakly inclined to accept this paper.']","[80, 70, 60]","[70, 80, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, calling it 'well-written and easy to follow' with 'clear' motivation and a 'simple and effective' idea. The reviewer also notes the paper's achievements in compression rates without performance loss. The score is not 100 as the reviewer does suggest some improvements. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive suggestions rather than harsh criticisms. Phrases like 'It would be better' and 'It may be interesting' are used to introduce suggestions, which is a polite way of providing feedback. The reviewer also starts with positive comments before moving to suggestions, which is a courteous approach."", ""The sentiment score is 70 (positive) because the reviewer starts with a positive overview, stating that the paper is 'well-written' with clear motivation, suitable approaches, and results that follow the motivation. The reviewer also acknowledges the paper's contribution to reducing memory consumption while maintaining accuracy. However, it's not a perfect 100 as the reviewer suggests some improvements and additional analyses. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions. Phrases like 'I think it is better to clarify' and 'I would like to see' are polite ways of suggesting improvements. The reviewer also acknowledges the paper's strengths before offering critiques, which is a polite approach to reviewing."", ""The sentiment score is 60 (moderately positive) because the reviewer describes the paper as 'interesting' multiple times, states that the experiments are 'convincing and solid', and is 'weakly inclined to accept this paper'. However, it's not overwhelmingly positive, hence not a higher score. The politeness score is 50 (somewhat polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths without harsh criticism. The tone is professional and constructive, but doesn't go out of its way to be exceptionally polite or encouraging, thus a moderate positive score.""]"
"[""It seems like the authors have carefully thought about this problem, and have come up with some elegant solutions, but I am not sold on whether it's an appropriate match for this conference, mainly because it's not clear how many machine learning people will be interested in this approach.\n\nThere was a time about 2 or 3 years ago when sparse-matrix approaches seemed to have a lot of promise, but I get the impression that a lot of people have moved on.  The issue is that it's hard to construct a scenario where it makes sense from a speed or memory standpoint to do this.  The authors seem to have found a way to substantially compress the indexes, but it's not clear to me that this really ends up solving any practical problem.  Towards the end of the paper I see mention of a 38.1% reduction in matrix size.  That is way too little to make sense in any practical application, especially when you consider the overhead of decompression.   It seems to me that you could easily get a factor of 4 to 8 of compression just by finding a suitable way to encode the floating-point numbers in many fewer bits (since the weight parameters are quite Gaussian-distributed and don't need to be that accurate).\n"", 'The paper proposes VCM, a novel way to store sparse matrices that is based on the Viterbi Decompressor. Only a subset of sparse matrices can be represented in the VCM format, however, unlike CSR format, it allows for faster parallel decoding and requires much less index space. The authors also propose a novel method of pruning of neural network that constructs an (sub)optimal (w.r.t. a weight magnitude based loss) Viterbi-compressed matrix given the weights of a pretrained DNN.\nVCM is an interesting analog to the conventional CSR format that may be more computationally efficient given particular software and/or hardware implementations of the Viterbi Decompressor. However, the empirical study of possible acceleration remains as an open question.\nHowever, I have a major concern regarding the efficiency of the pruning procedure. Authors report practically the same level of sparsity, as the pruning procedure from the Deep Compression paper. Both the proposed Viterbi-based pruning, and Deep Compression pruning belong to the previous era of pruning methods. They separate the pruning procedure and the training procedure, so that the model is not trained end-to-end. However, during the last two years a lot of new adaptive pruning methods have been developed, e.g. Dynamic Network Surgery, Soft Weight Sharing, and Sparse Variational DropOut. All of them in some sense incorporate the pruning procedure into the training procedure and achieve a much higher level of sparsity (e.g. DC achieves ~13x compression of LeNet5, and SVDO achieves ~280x compression of the same network). Therefore the reported 35-50% compression of the index storage is not very significant.\nIt is not clear whether it is possible to take a very sparse matrix and transform it into the VCM format without a high accuracy degradation. It is also not clear whether the VCM format would be efficient for storage of extremely sparse matrices, as they would likely be more sensitive to the mismatch of the original sparsity mask, and the best possible VCM sparsity mask. Therefore I’m concerned whether it would be possible to achieve a close-to-SotA level of compression using this method, and it is not yet clear whether this method can be used for practical acceleration or not.\nThe paper presents an interesting idea that potentially has useful applications, however the experiments are not convincing enough.', 'quality: this paper is of good quality\nclarity: this paper is very clear but contains a few minor typos/grammatical mistakes (missing -s for plurals, etc.)\noriginality: this paper is original\nsignificance: this paper is significant\n\nPROS\n- Using ECC theory for reducing the memory footprint of a neural network seems both intuitive and innovative, while being grounded in well-understood theory.\n- The authors address a consequence of current approaches to neural network pruning, i.e., the high cost of sparse matrix index storage.\n- The results are extensive and convincing.\n\nCONS\n- The authors mention in the introduction that this encoding can speed up inference by allowing efficient parallel sparse-to-dense matrix conversion, and hence batch inference, but do not provide any experimental confirmation.\n\nMain questions\n- It is not immediately clear to me why the objective function (2) correlates to a good accuracy of the pruned network. Did you try out other functions before settling on this one, or is there a larger reason for which (2) is a logical choice? \n- On a related note, I would find a plot of the final objective value assigned to a pruning scheme compared to the true network accuracy very helpful in understanding how these two correlate.\n- Could this approach be generalized to RNNs?\n- How long does the Viterbi pruning algorithm take, as it explores all 2^p possible prunings?\n- How difficult is it to tune the pruning algorithm hyper-parameters?']","[-20, -20, 80]","[50, 50, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the authors' careful thought and elegant solutions, they express significant doubts about the work's relevance and practical applicability. The reviewer is 'not sold' on the conference fit and questions the practical value of the approach. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and providing constructive criticism without harsh or dismissive phrasing. They present their concerns in a professional manner, using phrases like 'it's not clear to me' rather than making absolute statements, which maintains a polite tone while still conveying their reservations."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper presents 'an interesting idea' and 'novel way to store sparse matrices', they express 'major concern' about the efficiency of the pruning procedure and state that 'the experiments are not convincing enough'. The reviewer also questions the practical applicability and significance of the proposed method compared to state-of-the-art techniques. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the potential of the idea and framing criticisms as concerns or questions rather than direct attacks. They use phrases like 'It is not clear' and 'I'm concerned' rather than more aggressive language, maintaining a professional tone while expressing their reservations about the work."", ""The sentiment score is 80 (positive) because the review starts with highlighting the good quality, clarity, originality, and significance of the paper. The reviewer lists several pros and only one con, indicating a generally positive view. The main questions are constructive and show interest in the work. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as questions or suggestions rather than direct criticisms. The reviewer maintains a professional and courteous tone, avoiding harsh language or dismissive comments.""]"
"[""This paper proposed a new approach for counting in VQA called Interpretable Counting in Visual Question Answering.  The authors create a new dataset (HowMany-QA) by processing the VQA 2.0 and Visual Genome dataset. In the paper, the authors use object detection framework (R-FCN) to extract bounding boxes information as well as visual features and propose three different strategies for counting. 1: SoftCount; 2: UpDown; 3: IRLC.  The authors show results on HowMany-QA dataset for the proposed methods, and the proposed IRLC method achieves the best performance among all the baselines.   \n\n[Strenghts]\n\nThis paper first introduced a cleaned visual counting dataset by processing existing VQA 2.0 and Visual Genome dataset, which can filter out partial non-counting questions. The proposed split is a good testbed for counting in VQA. \n\nThe authors proposed 3 different methods for counting, which both use object detection feature trained on visual genome dataset.  The object detector is trained with multiple objectives including object detection, relation detection, attribute classification and caption grounding to produce rich object representation. The author first proposed 2 baselines: SoftCount uses a Huber loss, UpDown uses a cross entropy loss. And further proposed interpretable RL counter which enumerates the object as a sequential decision process. The proposed IRLC more intuitive and outperform the previous VQA method  (UpDown) on both accuracy and RMSE. \n\n[Weaknesses]\n\nThis paper proposed an interesting and intuitive counting model for VQA. However, there are several weaknesses existed:\n\n1: The object detector is pre-trained with multiple objectives. However, there is no ablation study to show the differences. Since the model only uses the object and relationship feature as input, the authors could show results on counting with different  objects detector. For example, object detector trained using object + relation v.s. object + relation + attribute v.s. object + relation + attribute + caption. \n\n2: Figure 9 shows an impressive result of the proposed method. Given the detection result, there are a lot of repetitive candidates detection bounding boxes. Without any strong supervision, IRLC could select the correct bounding boxes associated with the different objects. This is interesting, however, the authors didn't show any quantitative results on this. One experiment could verify the performance on IRLC is to compute the IOU between the GT COCO bounding box annotation on a small validation set. The validation set could be obtained by comparing the number of the bounding box and VQA answer with respect to similar COCO categories and VQA entities. \n\n3: The proposed IRLC is not significantly outperform baseline method (SoftCount) with respect to RMSE (0.1). However, it would be interesting to see how the counting performance can change the result of object detection. As Chattopadhyay's CVPR2017 paper Sec 5.3 on the same subset as in point 2. \n\n[Summary]\n\nThis paper proposed an interesting and interpretable model for counting in VQA. It formulated the counting as a sequential decision process that enumerated the subset of target objects. The authors introduce several new techniques in the IRLC counter. However, there is a lack of ablation study on the proposed model. Taking all these into account, I suggest accepting this paper if the authors could provide more ablation study on the proposed methods. \n"", 'Summary:\nThe paper presents a novel method for answering “How many …?” questions in the VQA datasets. Unlike previously proposed approaches, the proposed method uses an iterative sequential decision process for counting the relevant entity. The proposed model makes discrete choices about what to count at each time step. Another qualitative difference compared to existing approaches is that the proposed method returns bounding boxes for the counted object. The training and evaluation of the proposed model and baselines is done on a subset of the existing VQA dataset that consists of “How many …?” questions. The experimental results show that the proposed model outperforms the baselines discussed in the paper.\n\nStrengths:\n1.\tThe idea of sequential counting is novel and interesting.\n2.\tThe analysis of model performance by grouping the questions as per frequency with which the counting object appeared in the training data is insightful. \n \nWeaknesses:\n1.\tThe proposed dataset consists of 17,714 QA pairs in the dev set, whereas only 5,000 QA pairs in the test set. Such a 3.5:1 split of dev and test seems unconventional. Also, the size of the test set seems pretty small given the diversity of the questions in the VQA dataset.\n2.\tThe paper lacks quantitative comparison with existing models for counting such as with Chattopadhyay et al. This would require the authors to report the accuracies of existing models by training and evaluating on the same subset as that used for the proposed model. Absence of such a comparison makes it difficult to judge how well the proposed model is performing compared to existing models.\n3.\tThe paper lacks analysis on how much of performance improvement is due to visual genome data augmentation and pre-training? When comparing with existing models (as suggested in above), this analysis should be done, so as to identify the improvements coming from the proposed model alone.\n4.\tThe paper does not report the variation in model performance when changing the weights of the various terms involved in the loss function (equations 15 and 16).\n5.\tRegarding Chattopadhyay et al. the paper says that “However, their analysis was limited to the specific subset of examples where their approach was applicable.” It would be good it authors could elaborate on this a bit more.\n6.\tThe relation prediction part of the vision module in the proposed model seems quite similar to the Relation Networks, but the paper does not mention Relation Networks. It would be good to cite the Relation Networks paper and state clearly if the motivation is drawn from Relation Networks.\n7.\tIt is not clear what are the 6 common relationships that are being considered in equation 1. Could authors please specify these?\n8.\tIn equation 1, if only 6 relationships are being considered, then why does f^R map to R^7 instead of R^6?\n9.\tIn equations 4 and 5, it is not clarified what each symbol represents, making it difficult to understand.\n10.\tWhat is R in equation 15? Is it reward?\n\nOverall:\nThe paper proposes a novel and interesting idea for solving counting questions in the Visual Question Answering tasks. However, the writing of the paper needs to be improved to make is easier to follow. The experimental set-up – the size of the test dataset seems too small. And lastly, the paper needs to add comparisons with existing models on the same datasets as used for the proposed model. So, the paper seems to be not ready for the publication yet.', '\n------------------\nSummary:\n------------------\nThis work introduces a discrete and interpretable model for answering visually grounded counting questions. The proposed model executes a sequential decision process in which it 1) selects an image region to ""add to the count"" and then 2) updates the likelihood of selecting other regions based on their relationships (defined broadly) to the selected region. After substantial module pre-trianing, the model is trained end-to-end with the REINFORCE policy gradient method (with the recently proposed self-critical sequence training baseline). Compared to existing approaches for counting (or VQA in general), this approach not only produces lower error but also provides a more human-intuitive discrete, instance-pointing representation of counting. \n\n-----------------------\nPreliminary Evaluation:\n-----------------------\nThe paper presents an interesting approach that seems to outperform existing methods. More importantly in my view, the model treats counting as a discrete human-intuitive process. The presentation and experiments are okay overall but I have a few questions and requests below that I feel would strengthen the submission.\n\n------------------\nStrengths:\n------------------\n- I generally agree with the authors that approaching counting as a region-set selection problem provides an interpretable and human-intuitive methodology that seems more appropriate than attentional or monolithic approaches. \n\n- To the best of my knowledge, the writing does a good job of placing the work in the context of existing literature.\n\n- The dataset construction is given appropriate attention to restrict its instances to counting questions and will be made available to the public.\n\n- The model outperforms existing approaches given the same visual and linguistic inputs / encodings. While I find improvements in RMSE a bit underwhelming, I\'m still generally positive about the results given the improved accuracy and human-intuitiveness of the grounded outputs.\n\n- I appreciated the analysis of the effect of ""commonness"" and think it provides interesting insight into the generalization of the proposed model.\n\n- Qualitative examples are interesting.\n\n------------------\nWeaknesses:\n------------------\n- There is a lot going on in this paper as far as model construction and training procedures go. In its current state, many of the details are pushed to the supplement such that the main paper would be insufficient for replication. The authors also do not promise code release. \n\n- Maybe it is just my unfamiliarity with it, but the caption grounding auxiliary-task feels insufficiently introduced in the main paper.  I also find it a bit discouraging that the details of joint training is regulated to the supplementary material, especially given that the UpDown is not using it! I would like to see an ablation of the proposed model without joint training.\n\n- Both the IRLC and SoftCount models are trained with objectives that are aware of the ordinal nature of the output space (such that predicting 2 when the answer is 20 is worse than predicting 19). Unfortunately, the UpDown model is trained with cross-entropy and lacks access to this notion. I believe that this difference results in the large gap in RMSE between IRLC/SoftCount and UpDown. Ideally an updated version of UpDown trained under an order-aware loss would be presented during the rebuttal period. Barring that due to time constraints, I would otherwise like to see some analysis to explore this difference, maybe checking to see if UpDown is putting mass in smooth blobs around the predicted answer (though there may be better ways to see if UpDown has captured similar notions of output order as the other models).\n\n- I would like to see a couple of simple baselines evaluated on HowMany-QA. Specifically, I think the paper would be stronger if results were put in context with a question only model and a model which just outputs the mean training count. Inter-human agreement would also be interesting to discuss (especially for high counts).\n\n- The IRLC model has a significantly large (4x) capacity scoring function than the baseline methods. If this is restricted, do we see significant changes to the results?\n\n- This is a relatively mild complaint. This model is more human-intuitive than existing approaches, but when it does make an error by selecting incorrect objects or terminating early, it is no more transparent about the cause of these errors than any other approach. As such, claims about interpretability should be made cautiously.  \n\n------------------\nCuriosities:\n------------------\n- In my experience, Visual Genome annotations are often noisy, with many different labels being applied to the same object in different images. For per-image counts, I don\'t imagine this will be too troubling but was curious if you ran into any challenges.\n\n- It looks like both IRLC and UpDown consistently either get the correct count (for small counts) or underestimate. This is not the Gaussian sort of regression error that we might expect from a counting problem. \n\n- Could you speak to the sensitivity of the proposed model with respect to different loss weightings? I saw the values used in Section B of the supplement and they seem somewhat specific. \n\n------------------\nMinor errors:\n------------------\n[5.1 end of paragraph 2] \'that accuracy and RSME and not\' -> \'that accuracy and RSME are not\'\n[Fig 9 caption] \'The initial scores are lack\' -> \'The initial scores lack\'']","[50, -50, 50]","[80, 50, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as introducing a new dataset and proposing innovative methods, while also pointing out weaknesses and suggesting improvements. The overall tone is constructive rather than overtly critical or enthusiastic. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout, acknowledging the paper's contributions, and framing criticisms as suggestions for improvement rather than harsh judgments. The reviewer uses phrases like 'interesting and intuitive' and 'impressive result' to commend aspects of the work, while softening critiques with phrases like 'it would be interesting to see' and 'I suggest accepting this paper if...', maintaining a professional and courteous tone throughout the review."", ""The sentiment score is -50 because while the reviewer acknowledges some strengths of the paper, they ultimately conclude that it is 'not ready for publication yet' and list several significant weaknesses. This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses professional and respectful language throughout, acknowledging strengths before discussing weaknesses, and phrasing criticisms as suggestions for improvement rather than harsh judgments. The reviewer maintains a constructive tone, which is polite, but doesn't go out of their way to be overly courteous, hence a moderately positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges strengths of the paper such as the interesting approach, outperforming existing methods, and providing interpretable results. However, they also point out several weaknesses and areas for improvement, balancing the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's contributions, and frames criticisms as suggestions or requests rather than demands. They use phrases like 'I would like to see' and 'I think the paper would be stronger if' which maintain a constructive and courteous tone. The reviewer also balances critiques with positive feedback, further contributing to the polite tone.""]"
"['Summary:\n\nThis paper investigated the problem of controlled image generation. Assuming images can be disentangled by identity-related factors and style factors, this paper proposed an algorithm that produces a pair of images with the same identity. Compared to standard GAN framework, this algorithm first generated two latent variables for the pair images. The two latent variables are partially shared reflecting the shared identity information. The generator then transformed the latent variables into high-resolution images with a deconvolution decoder networks. The discriminator was used to distinguish paired images from database or paired images sampled by the algorithm. Experiments were conducted using DCGAN and BEGAN on portrait images and shoe product images. Qualitative results demonstrated that the learned style representations capture viewpoint, illumination and background color while the identity was well preserved by the identity-related representations.\n\n\n== Novelty & Significance ==\nPaired image generation is an interesting topic but this has been explored to some extent. Compared to existing coupled generation pipeline such as CoGAN, I can see the proposed formulation is more application-driven.\n\n== Technical Quality ==\nIn Figure 3, the portrait images in the second row and fourth row look quite similar. I wonder if the trained model works with only limited variability (in terms of identity).\nIn Figure 4, the viewpoint is quite limited (only 4 viewpoints are provided).\n\nI am not very convinced whether SD-GAN is a generic algorithm for controlled image generation. Based on the current results, I suspect it only works in fairly constrained settings. \nIt would be good to know if it actually works in more challenging datasets such as SUN bedroom, CUB and Oxford Flowers. \n\n“the AC-DCGAN model cannot imagine new identities”\nI feel the author of this paper made an unfair argument when comparing AC-DCGAN with the proposed method. First, during training, the proposed SD-GAN needs to access the identity information and there is only limited identity in the dataset. Based on the presentation, it is not very clear how does the model generate novel identities (in contrast to simply interpolating existing identities). For example, is it possible to generate novel viewpoints in Figure 4?\n\nMissing references on conditional image generation and coupled image generation:\n-- Generative Adversarial Text-to-Image Synthesis. Reed et al., In ICML 2016.\n-- Attribute2Image: Conditional Image Generation from Visual Attributes. Yan et al., In ECCV 2016.\n-- Domain Separation Networks. Bousmalis et al., In NIPS 2016.\n-- Unsupervised Image-to-Image Translation Networks. Liu et al., In NIPS 2017.\n\nOverall, I rate this paper slightly above borderline. It showed some good visualization results on controlled image generation. But the comparison to AC-GAN is not very fair, since the identity pairs are fully supervised for the proposed method. As far as I can see, there are no clear-cut improvements quantitatively. Also, there is no comparison with CoGAN, which I believe is the most relevant work for coupled image generation. \n', '[Overview]\n\nIn this paper, the authors proposed a model called SD-GAN, to decompose semantical component of the input in GAN. Specifically, the authors proposed a novel architecture to decompose the identity latent code and non-identity latent code. In this new architecture, the generator is unchanged while the discriminator takes pair data as the input, and output the decision of whether two images are from the same identity or not. By training the whole model with a conventional GAN-training regime, SD-GAN learns to take a part of the input Z as the identity information, and the other part of input Z as the non-identity (or attribute) information. In the experiments, the authors demonstrate that the proposed SD-GAN could generate images preserving the same identity with diverse attributes, such as pose, age, expression, etc. Compared with AC-GAN, the proposed SD-GAN achieved better performance in both automatically evaluation metric (FaceNet) and Human Study. In the appendix, the authors further presented ablated qualitative results in various settings.\n\n[Strengths]\n\n1. This paper proposed a simple but effective generative adversarial network, called SD-GAN, to decompose the input latent code of GAN into separate semantical parts. Specifically, it is mainly instantiated on face images, to decompose the identity part and non-identity part in the latent code. Unlike the previous works such as AC-GAN, SD-GAN exploited a Siamese network to replace the conventional discriminator used in GAN. By this way, SD-GAN could generate images of novel identities, rather than being constrained to those identities used during training. I think this is a very good property. Due to this, SD-GAN consumes much less memory than AC-GAN, when training on a large number of identities.\n\n2. In the experiment section, the authors quantitatively evaluate the generated images based on two methods, one is using a pre-trained FaceNet model to measure the verification accuracy and one is human study. When evaluated based on FaceNet, the proposed SD-GAN achieved higher accuracy and obtained more diverse face images, compared with AC-GAN. In human study, SD-GAN achieved comparable verification accuracy, while higher diversity than AC-GAN. The authors further presented ablated experiments in the Appendix.\n\n[Comments]\n\nThis paper presents a novel model to decompose the latent code in a semantic manner. However, I have several questions about the model:\n\n1. Why would SD-GAN not generate images merely have a smaller number of identities or just a few identities? In Algorithm 1, the authors trained the model by sampling one identity vector, which is then concatenated to two observation vectors. In this case, the generator always takes the same identity vectors, and the discriminator is used to distinguish these fake same-identity pair and the real same-identity pair from training data. As such, even if the generator generates the same identity, say mean identity, given different identity vectors, the generated images can still obtain a lower discrimination loss. Without any explicite constraint to enforce the generator to generate different identity with different identity vectors, I am wondering what makes SD-GAN be able to generate diverse identities? \n\n2. Still about the identity diversity. Though the authors showed the identity-matched diversity in the experiments, the diversity across identity on the generated images is not evaluated. The authors should also evaluate this kind of identity. Generally, AC-GAN could generate as many identities as the number of identities in training data. I am curious about whether SD-GAN could generate comparable diverse identity to AC-GAN. One simple way is to evaluate the whole generated image set using Inception Score based on a Pre-trained face identification network; Another way is to directly use the generated images to train a verification model or identification model and evaluate it on real images. Though compared with AC-GAN, SD-GAN achieved better identity verification performance and sample diversity, I suspect the identity diversity is discounted, though SD-GAN has the property of generating novel identities. Furthermore,  the authors should also compare the general quality of generated samples with DC-GAN and BEGAN as well (at least qualitatively), apart from the comparison to AC-GAN on the identity-matched generation.\n\n3. When making the comparison with related work, the authors mentioned that Info-GAN was not able to determine which factors are assigned to each dimension. I think this is not precise. The lack of this property is because there are no data annotations. Given the data annotations, Info-GAN can be easily augmented with such property by sending the real images into the discriminator for classification. Also, there is a typo in the caption of Fig. 10. It looks like each column shares the same identity vector instead of each row.\n\n[Summary]\n\nThis paper proposed a new model called SD-GAN to decompose the input latent code of GAN into two separete semantical parts, one for identity and one for observations. Unlike AC-GAN, SD-GAN exploited a Siamese architecture in discriminator. By this way, SD-GAN could not only generate more identity-matched face image pairs but also more diverse samples with the same identity,  compared with AC-GAN. I think this is a good idea for decomposing the semantical parts in the latent code, in the sense that it can imagine new face identities and consumes less memory during training. Overall, I think this is a good paper. However, as I mentioned above, I am still not clear why SD-GAN could generate diverse identities without any constraints to make the model do that. Also, the authors should further evaluate the diversity of identity and compare it with AC-GAN.', 'Quality\nThe paper is well written and the model is simple and clearly explained. The idea for disentangling identity from other factors of variation using identity-matched image pairs is quite simple, but the experimental results on faces and shoes are impressive.\n\nClarity\nThe model and its training objective are simple and clearly explained.\n\nOriginality\nThere are now many, many papers on generative models with disentangled feature representations, including with GANs. However, to my knowledge this is the first paper showing very compelling results using this particular setup of identity-aligned images.\n\nSignificance\nDisentangled generative models are an important line of work in my opinion. This paper presents a very simple but apparently effective way of disentangling identity from other factors, and implements in two of the more recent GAN architectures.\n\nSuggestion for an experiment - can you do few shot image generation? A simple way to do it would be to train an encoder from image → identity encoding. Then, given one or a few images of a new person’s face or a new shoe, you could estimate the identity latent variable, and then generate many additional samples.\n\nPros\n- Very simple and effective disentangling technique for GANs.\n- Great execution, compelling samples on both faces and shoes.\n\nCons\n- Only two factors of variations are disentangled in this model. Could it be generalized to specify more than just two, e.g. lighting, pose, viewpoint, etc?\n- Not much technically new or surprising compared to past work on disentangling generative models.']","[-20, 60, 80]","[50, 80, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('showed some good visualization results'), they express several criticisms and doubts about the paper's methods and comparisons. The overall tone suggests the paper is only 'slightly above borderline'. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'I wonder if', 'It would be good to know', and 'I feel' to soften their critiques. The reviewer also acknowledges positive aspects before presenting concerns, which is a polite approach to feedback."", ""The sentiment score is 60 (positive) because the reviewer begins by highlighting the strengths of the paper, praising it as 'simple but effective' and noting its good properties. They use positive language like 'very good property' and 'achieved higher accuracy'. However, the score is not higher because the reviewer also raises several questions and concerns in the 'Comments' section, suggesting areas for improvement. The politeness score is 80 (quite polite) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think this is a good idea' and 'Overall, I think this is a good paper', even when raising concerns. The reviewer also frames their criticisms as questions or suggestions rather than direct criticisms, which is a polite approach. The language is consistently formal and courteous, without any rude or dismissive remarks."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, praising its clarity, originality, and significance. They use phrases like 'well written', 'clearly explained', and 'impressive results'. The few criticisms are minor and constructive. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and balances praise with suggestions for improvement. They use phrases like 'suggestion for an experiment' rather than demanding changes, and present both pros and cons in a balanced manner.""]"
"[""The authors present an interesting idea to reduce the size of neural networks via adaptive compression, allowing the network to use high precision where it is crucial and low precision in other parts. The problem and the proposed solution is well motivated. However, there are some elements of the manuscript that are hard to follow and need further clarification/information. These need to definitely be addressed before this paper can be accepted.\n\nSpecific comments/questions:\n- Page 1: Towards the bottom, in the 3rd to last line, reference is missing.\n- Page 1: It is a little hard to follow the motivation against existing methods.\n- Page 2: DenseNets and DeepCompression need citations\n- Lemma 2.1 seems interesting - is this original work? This needs to be clarified.\n- Lemma 2.2: Reference to Equation 17 (which has not been presented in the manuscript at this point) seems a little confusing and I am unable to following the reasoning and the subsequent proof which again refers to Equation 17.\n- Alg 2: Should it be $\\Delta$ or $\\Delta_{k+1}$? Because in one if branch, we use $\\Delta$, in the other, we use the subscripted one.\n- Derivation in section 2.3 has some typographical errors.\n- What is $d$ in Equation 20 (with cases)? Without this information, it is unclear how the singular points are handled.\n- Page 6, first paragraph of Section 3: The evaluation is a little confusing - when is the compression being applied during the training process, and how is the training continued post-compression? What does each compression 'pass' constitute of?\n- Figure 1b: what is the 'iteration' on the horizontal axis, is it the number of iterations of Alg3 or Alg2? Hoping it is Alg3 but needs to be clarified in the text.\n- Section 3: What about compression results for CIFAR and SVNH? "", 'I have read the responses to the concerns raised by all reviewers. I find the clarifications and modifications satisfying, therefore I keep my rating of the paper to above acceptance threshold.\n\n-----------------\nORIGINAL REVIEW:\n\nThe paper proposes a method for quantizing neural networks that allows weights to be quantized with different precision depending on their importance, taking into account the loss. If the weights are very relevant, it assigns more bits to them, and in the other extreme it does pruning of the weights.\n\nThis paper addresses a very relevant topic, because in limited resources there is a constrain in memory and computational power, which can be tackled by quantizing the weights of the network. The idea presented is an interesting extension to weight pruning with a close form approximate solution for computing the adaptive quantization of the weights.\n\nThe results presented in the experimental section are promising. The quantization is quite cheap to compute and the results are similar to other state-of-the-art quantization methods. \nFrom the tables and figures, it is difficult to grasp the decrease in accuracy when using the quantized model, compared to the full precision model, and also the relative memory compression. It would be nice to have this reference in the plots of figure 3.  Also, it is difficult to see the benefits in terms of memory/accuracy compromise since not all competing quantization techniques are compared for all the datasets.\nAnother observation is that it seems from figure 2 that a lot of the weights are quantized with around 10 bits, and it is not clear how the compromise accuracy/memory can be turned to less memory, if possible. It would be interesting to know an analogy, for instance, saying that this adaptive compression in memory would be equivalent to quantizing all weights with n bits.\n\nOTHER COMMENTS:\n\n-missing references in several points of the paper. For instance, in the second paragraph of the introduction, 1st paragraph of section 2.\n\n- few typos:\n*psi -> \\psi in section 2.3\n*simply -> simplify in proof of lemma 2.2\n*Delta -> \\Delta in last paragraph of section 2.2\n*l2 -> L_2 or l_2 in section 3.1 last paragraph.', 'Revised Review:\n\nThe authors have addressed most of my concerns with the revised manuscript. I now think the paper does just enough to warrant acceptance, although I remain a bit concerned that since the benefits are only achievable with customized hardware, the relevance/applicability of the work is somewhat limited.\n\nOriginal Review:\n\nThe paper proposes a technique for quantizing the weights of a neural network, with bit-depth/precision varying on a per-parameter basis. The main idea is to minimize the number of bits used in the quantization while constraining the loss to remain below a specified upper bound. This is achieved by formulating an upper bound on the number of bits used via a set of ""tolerances""; this upper bound is then minimized while estimating any increase in loss using a first order Taylor approximation.\n\nI have a number of questions and concerns about the proposed approach. First, at a high level, there are many details that aren\'t clear from the text. Quantization has some bookkeeping associated with it: In a per-parameter quantization setup it will be necessary to store not just the quantized parameter, but also the number of bits used in the quantization (takes e.g. 4-5 extra bits), and there will be some metadata necessary to encode how the quantized value should be converted back to floating point (e.g., for 8-bit quantization of a layer of weights, usually the min and max are stored). From Algorithm 1 it appears the quantization assumes parameters in the range [0, 1]. Don\'t negative values require another bit? What happens to values larger than 1? How are even bit depths and associated asymmetries w.r.t. 0 handled (e.g., three bits can represent -1, 0, and 1, but 4 must choose to either not represent 0 or drop e.g. -1)? None of these details are clearly discussed in the paper, and it\'s not at all clear that the estimates of compression are correct if these bookkeeping matters aren\'t taken into account properly.\n\nAdditionally the paper implies that this style of quantization has benefits for compute in addition to memory savings. This is highly dubious, since the method will require converting all parameters to a standard bit-depth on the fly (probably back to floating point, since some parameters may have been quantized with bit depth up to 32). Alternatively custom GEMM/conv routines would be required which are impossible to make efficient for weights with varying bit depths. So there are likely not runtime compute or memory savings from such an approach.\n\nI have a few other specific questions: Are the gradients used to compute \\mu computed on the whole dataset or minibatches? How would this scale to larger datasets? I am confused by the equality in Equation 8: What happens for values shared by many different quantization bit depths (e.g., representing 0 presumably requires 1 bit, but may be associated with a much finer tolerance)? Should ""minimization in equation 4"" refer to equation 3?\n\nIn the end, while do like the general idea of utilizing the gradient to identify how sensitive the model might be to quantization of various parameters, there are significant clarity issues in the paper, I am a bit uneasy about some of the compression results claimed without clearer description of the bookkeeping, and I don\'t believe an approach of this kind has any significant practical relevance for saving runtime memory or compute resources. ']","[-20, 70, 20]","[60, 80, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting idea and good motivation, they also point out several issues that need to be addressed before the paper can be accepted. The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the positive aspects of the work and framing criticisms as questions or suggestions for improvement rather than harsh criticisms. The reviewer uses phrases like 'interesting idea', 'well motivated', and 'needs to be clarified' which maintain a professional and courteous tone while still conveying the need for revisions."", ""The sentiment score is 70 (positive) because the reviewer states they find the clarifications and modifications satisfying and keep their rating above the acceptance threshold. They also describe the paper's topic as 'very relevant' and the idea as 'interesting', with 'promising' results. The politeness score is 80 (polite) due to the constructive and respectful tone throughout. The reviewer offers suggestions and observations without harsh criticism, using phrases like 'it would be nice' and 'it would be interesting'. They also acknowledge the paper's strengths before offering suggestions for improvement. The minor corrections are presented neutrally as 'OTHER COMMENTS', further contributing to the polite tone."", ""For the sentiment score, I assigned 20 out of 100 because the reviewer states that the paper 'does just enough to warrant acceptance', which is mildly positive. However, they still express concerns about the limited applicability of the work, tempering the positivity. For the politeness score, I assigned 50 out of 100. The language is generally neutral and professional, without any overtly rude comments. The reviewer raises concerns and questions in a respectful manner, using phrases like 'I have a number of questions and concerns' rather than harsh criticisms. The tone is constructive, aiming to improve the paper rather than dismiss it outright, which contributes to its politeness.""]"
"['This paper is well written and it was easy to follow. The authors propose prunning model technique by enforcing sparsity on the scaling parameter of batch normalization layers. This is achieved by forcing the output of some channels being constant during training. This is achieved an adaptation of ISTA algorithm to update the batch-norm parameter. \n\nThe authors evaluate the performance of the proposed approach on different classification and segmentation tasks. The method seems to be relatively straightforward to train and achieve good performance (in terms of performance/parameter reduction) compared to other methods on Imagenet.\n\nSome of the hyperparameters used (alpha and specially rho) seem to be used very ad-hoc. Could the authors explain their choices? How sensible is the algorithm to these hyperparameters?\nIt would be nice to see empirically how much of computation the proposed approach takes during training. How much longer does it takes to train the model with the ISTA based constraint?\n\nOverall this is a good paper and I believe it should be accepted, given the authors are more clear on the details pointed above.\n', 'In this paper, the authors propose a data-dependent channel pruning approach to simplify CNNs with batch-normalizations. The authors view CNNs as a network flow of information and applies sparsity regularization on the batch-normalization scaling parameter \\gamma which is seen as a “gate” to the information flow. Specifically, the approach uses iterative soft-thresholding algorithm step to induce sparsity in \\gamma during the overall training phase of the CNN (with additional rescaling to improve efficiency. In the experiments section, the authors apply their pruning approach on a few representative problems and networks. \n\nThe concept of applying sparsity on \\gamma to prune channels is an interesting one, compared to the usual approaches of sparsity on weights. However, the ISTA, which is equivalent to L1 penalty on \\gamma is in spirit same as “smaller-norm-less-informative” assumption. Hence, the title seems a bit misleading. \n\nThe quality and clarity of the paper can be improved in some sections. Some specific comments by section:\n\n3. Rethinking Assumptions:\n-\tWhile both issues outlined here are true in general, the specific examples are either artificial or can be resolved fairly easily. For example: L-1 norm penalties only applied on alternate layers is artificial and applying the penalties on all Ws would fix the issue in this case. Also, the scaling issue of W can be resolved by setting the norm of W to 1, as shown in He et. al., 2017. Can the authors provide better examples here?\n-\tCan the authors add specific citations of the existing works which claim to use Lasso, group Lasso, thresholding to enforce parameter sparsity?\n\n4. Channel Pruning\n-\tThe notation can be improved by defining or replacing “sum_reduced”\n-\tISTA – is only an algorithm, the basic assumption is still L1 -> sparsity or smaller-norm-less-informative. Can the authors address the earlier comment about “a theoretical gap questioning existing sparsity inducing formulation and actual computational algorithms”?\n-\tCan the authors address the earlier comment on “how to set thresholds for weights across different layers”, by providing motivation for choice of penalty for each layer? \n-\tCan the authors address the earlier comment on how their approach provides “guarantees for preserving neural net functionality approximately”?\n\n5. Experiments\n-\tCIFAR-10: Since there is loss of accuracy with channel pruning, it would be useful to compare accuracy of a pruned model with other simpler models with similar param.size? (like pruned-resnet-101 vs. resnet-50 in ISLVRC subsection)\n-\tISLVRC: The comparisons between similar param-size models is exteremely useful in highlighting the contribution of this. However, resnet-34/50/101 top-1 error rates from Table 3/4 in (He et.al. 2016) seem to be lower than reported in table 3 here. Can the authors clarify?\n-\tFore/Background: Can the authors add citations for datasets, metrics for this problem?\n\n\nOverall, the channel pruning with sparse \\gammas is an interesting concept and the numerical results seem promising. The authors have started with right motivation and the initial section asks the right questions, however, some of those questions are left unanswered in the subsequent work as detailed above.', 'This paper proposes an interesting  approach to prune a deep model from a computational point of view. The idea is quite simple as pruning using the connection in the batch norm layer. It is interesting to add the memory cost per channel into the optimization process. \n\nThe paper suggests normal pruning does not necessarily preserve the network function. I wonder if this is also applicable to the proposed method and how can this be evidenced. \n\nAs strong points, the paper is easy to follow and does a good review of existing methods. Then, the proposal is simple and easy to reproduce and leads to interesting results. It is clearly written (there are some typos / grammar errors). \n\nAs weak points:\n1) The paper claims the selection of \\alpha is critical but then, this is fixed empirically without proper sensitivity analysis. I would like to see proper discussion here. Why is \\alpha set to 1.0 in the first experiment while set to a different number elsewhere. \n\n2) how is the pruning (as post processing) performed for the base model (the so called model A).\n\nIn section 4, in the algorithmic steps. How does the 4th step compare to the statement in the initial part of the related work suggesting zeroed-out parameters can affect the functionality of the network?\n\n3) Results for CIFAR are nice although not really impressive as the main benefit comes from the fully connected layer as expected.']","[80, -20, 50]","[70, 50, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe it as 'well written' and 'easy to follow', and state that it 'should be accepted'. The reviewer also praises the method's performance and straightforwardness. The score is not 100 because the reviewer does raise some questions and requests for clarification.\n\nThe politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They begin with positive comments, phrase their questions and suggestions politely (e.g., 'Could the authors explain...', 'It would be nice to see...'), and conclude with a positive overall assessment. The score is not 100 because the language, while polite, is not excessively formal or deferential."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting concept and promising results, they also point out several areas for improvement and unanswered questions. The review begins with a neutral summary but then highlights misleading aspects, areas needing clarity, and specific issues with examples and comparisons. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, often phrasing criticisms as questions or suggestions for improvement. They acknowledge the interesting aspects of the work and frame their comments constructively, using phrases like 'Can the authors...' and 'It would be useful to...', which maintains a polite tone while still conveying critical feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting approach, strong points like being easy to follow and having interesting results, while also pointing out weak points and areas for improvement. The overall tone is balanced but leans positive. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the paper's merits and framing criticisms as suggestions or questions rather than harsh judgments. Phrases like 'interesting approach,' 'clearly written,' and 'I would like to see' contribute to the polite tone. The reviewer maintains a professional and constructive attitude, even when pointing out weaknesses.""]"
"[""This paper proposes an interesting model of self-play where one agent learns to propose tasks that are easy for her but difficult for an opponent. This creates a moving target of self-play objectives and learning curriculum.\n\nThe idea is certainly elegant and clearly described. \nI don't really feel qualified to comment on the novelty, since this paper is somewhat out of my area of expertise, but I did notice that the authors' own description of Baranes and Oudeyer (2013) seems very close to the proposal in this paper. Given the existence of similar forms of self-play the key issue with paper I see is that there is no strong self-play baseline in the experimental evaluation. It is hard to tell whether this neat idea is really an improvement.\n\nIs progress guaranteed? Is it not possible for Alice to imemdiately find an easy task for her where Bob times out, gets no reward signal, and therefore is unable to learn anything? Then repeating that task will loop forever without progress. This suggests that the adversarial setting is quite brittle.\n\nI also find that the paper is a little light on the technical side."", 'The paper presents a method for learning a curriculum for reinforcement learning tasks.The approach revolves around splitting the personality of the agent into two parts. The first personality learns to generate goals for other personality for which the second agent is just barely capable--much in the same way a teacher always pushes just past the frontier of a student’s ability. The second personality attempts to achieve the objectives set by the first as well as achieve the original RL task.  \n\nThe novelty of the proposed method is introduction of a teacher that learns to generate a curriculum for the agent.The formulation is simple and elegant as the teacher is incentivised to widen the gap between bob but pays a price for the time it takes which balances the adversarial behavior. \n\nPrior and concurrent work on learning curriculum and intrinsic motivation in RL rely on GANs (e.g., automatic goal generation by Held et al.), adversarial agents (e.g., RARL by Pinto et al.), or algorithmic/heuristic methods (e.g., reverse curriculum by Florensa et al. and HER Andrychowicz et al.).  In the context of this work, the contribution is the insight that an agent can be learned to explore the immediate reachable space but that is just within the capabilities of the agent. HER and goal generation share the core insight on training to reach goals. However, HER does generate goals beyond the reachable it instead relies on training on existing reached states or explicitly consider the capabilities of the agent on reaching a goal. Goal generation while learning to sample from the achievable frontier does not ensure the goal is reachable and may not be as stable to train. \n\nAs noted by the authors the above mentioned prior work is closely related to the proposed approach. However, the paper only briefly mentions this corpus of work. A more thorough comparison with these techniques should be provided even if somewhat concurrent with the proposed method. The authors should consider additional experiments on the same domains of this prior work to contrast performance.\n\nQuestions:\nDo the plots track the combined iterations that both Alice and Bob are in control of the environment or just for Bob? \n', 'In this paper, the authors describe a new formulation for exploring the environment in an unsupervised way to aid a specific task later. Using two “minds”, Alice and Bob, where the former proposes increasingly difficult tasks and the latter tries to accomplish them as fast as possible, the learning agent Bob can later perform a given task faster having effectively learned the environment dynamics from playing the game with Alice. \n\nThe idea of unsupervised exploration has been visited before. However, the paper presents a novel way to frame the problem, and shows promising results on several tasks. The ideas are well-presented and further expounded in a systematic way. Furthermore, the crux of the proposal and simple and elegant yet leading to some very interesting results. My only complaint is that some of the finer implementation details seems to have been omitted. For example, the parameter update equation is section 4 is somewhat opaque and requires more discussion than the motivation presented in the preceding paragraph.\n\nTypos and grammatical errors: let assume (section 2.2), it is possible show (section 5).\n\nOverall, I think the paper presents a novel and unique idea that would be interesting to the wider research community. ']","[20, 60, 80]","[60, 80, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting and elegant idea, and the clear description. However, they express concerns about novelty, lack of strong baselines, and potential issues with the proposed method, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging their own limitations ('I don't really feel qualified to comment on the novelty'), and framing criticisms as questions or observations rather than direct attacks. The reviewer maintains a professional tone while providing constructive feedback."", ""The sentiment score is 60 (positive) because the reviewer expresses appreciation for the paper's novelty, describing the approach as 'simple and elegant'. They acknowledge the contribution and insight of the work. However, they also suggest improvements and additional comparisons, which prevents the score from being higher. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledging the authors' work positively. They offer constructive criticism and suggestions in a professional manner, without using harsh or dismissive language. The reviewer also asks a clarifying question at the end, which is a polite way to seek additional information."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They describe the idea as 'novel and unique', 'well-presented', 'simple and elegant', and leading to 'very interesting results'. The reviewer also states that the paper would be 'interesting to the wider research community'. The only negative point is a minor complaint about omitted implementation details, which doesn't significantly detract from the overall positive sentiment.\n\nThe politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the authors' work positively and frame their criticism gently ('My only complaint is...'). The reviewer also offers specific, helpful feedback, including pointing out typos. The tone is professional and courteous, without being overly formal or effusive.""]"
"['This paper provides a very original & promising method to scale distributed training beyond the current limits of mini-batch stochastic gradient descent. As authors point out, scaling distributed stochastic gradient descent to more workers typically requires larger batch sizes in order to fully utilize computational resource, and increasing the batch size has a diminishing return. This is clearly a very important problem, as it is a major blocker for current machine learning models to scale beyond the size of models and datasets we currently use. Authors propose to use distillation as a mechanism of communication between workers, which is attractive because prediction scores are more compact than model parameters, model-agnostic, and can be considered to be more robust to out-of-sync differences. This is a simple and sensible idea, and empirical experiments convincingly demonstrate the advantage of the method in large scale distributed training.\n\nI would encourage authors to experiment in broader settings, in order to demonstrate that the general applicability of the proposed method, and also to help readers better understand its limitations. Authors only provide a single positive data point; that co-distillation was useful in scaling up from 128 GPUs to 258 GPUs, for the particular language modeling problem (commoncrawl) which others have not previously studied. In order for other researchers who work on different problems and different system infrastructure to judge whether this method will be useful for them, however, they need to understand better when codistillation succeeds and when it fails. It will be more useful to provide experiments with smaller and (if possible) larger number of GPUs (16, 32, 64, and 512?, 1024?), so that we can more clearly understand how useful this method is under the regime mini-batch stochastic gradient continues to scale. Also, more diversity of models would also help understanding robustness of this method to the model. Why not consider ImageNet? Goyal et al reports that it took an hour for them to train ResNet on ImageNet with 256 GPUs, and authors may demonstrate it can be trained faster.\n\nFurthermore, authors briefly mention that staleness of parameters up to tens of thousands of updates did not have any adverse effect, but it would good to know how the learning curve behaves as a function of this delay. Knowing how much delay we can tolerate will motivate us to design different methods of communication between teacher and student models.', ""The paper proposes an online distillation method, called co-distillation, where the two different models are trained to match the predictions of other model in addition to minimizing its own loss. The proposed method is applied to two large-scale datasets and showed to perform better than other baselines such as label smoothing, and the standard ensemble. \n\nThe paper is clearly written and was easy to understand. My major concern is the significance and originality of the proposed method. As written by the authors, the main contribution of the paper is to apply the codistillation method, which is pretty similar to Zhang et. al (2017), at scale. But, because from Zhang's method, I don't see any significant difficulty in applying to large-scale problems, I'm not sure that this can be a significant contribution. Rather, I think, it would have been better for the authors to apply the proposed methods to a smaller scale problems as well in order to explore more various aspects of the proposed methods including the effects of number of different models. In this sense, it is also a limitation that the authors showing experiments where only two models are codistillated. Usually, ensemble becomes stronger as the number of model increases.\n"", 'Although I am not an expert on this area, but this paper clearly explains their contribution and provides enough evidences to prove their results.\nOnline distillation technique is introduced to accelerate traditional algorithms for large-scale distributed NN training.\nCould the authors add more results on the CNN ?']","[80, -20, 70]","[70, 60, 60]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as providing a 'very original & promising method' and states that the 'empirical experiments convincingly demonstrate the advantage of the method'. The reviewer also calls it a 'simple and sensible idea'. The score is not 100 as the reviewer does suggest additional experiments and improvements. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, such as 'I would encourage authors' and 'it would be good to know'. The reviewer provides constructive criticism in a positive manner, suggesting improvements rather than pointing out flaws. The score is not 100 as the language, while polite, is not excessively formal or deferential."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is clearly written and easy to understand, they express major concerns about the significance and originality of the proposed method. The reviewer questions whether the contribution is substantial enough, suggesting that applying the method to smaller scale problems might have been more beneficial. This critique outweighs the initial positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects of the paper before presenting their concerns. They offer constructive suggestions for improvement rather than harsh criticism. The phrases 'clearly written', 'easy to understand', and the use of 'I think' to soften their critique contribute to the polite tone."", ""The sentiment score is 70 (positive) because the reviewer expresses a clear positive view of the paper, stating that it 'clearly explains their contribution and provides enough evidences to prove their results.' The reviewer also acknowledges the paper's introduction of a new technique. The score is not higher because the reviewer admits to not being an expert in the area and suggests an additional result. The politeness score is 60 (polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('I am not an expert'), and phrases their suggestion as a question ('Could the authors add...') rather than a demand. The language is consistently professional and constructive, without any harsh criticism or rudeness.""]"
"['In this paper a modular architecture is proposed with the aim of separating environment specific (dynamics) knowledge and task-specific knowledge into different modules. Several complex but discrete control tasks, with relatively small action spaces, are cast as continuous control problems, and the task specific module is trained to produce non-linear representations of goals in the domain of transformed high-dimensional inputs.\n\nPros\n- “Monolithic” policy representations can make it difficult to reuse or jointly represent policies for related tasks in the same environment; a modular architecture is hence desirable.\n- An extensive study of methods for dimensionality reduction is performed for a task with sparse rewards.\n- Despite all the suggestions and questions below, the method is clearly on par with standard A3C across a wide range of tasks, which makes it an attractive architecture to explore further.\n\nCons\n- In general, learning a Path function could very well turn out to be no simpler than learning a good policy for the task at hand. I have 2 main concerns:\nThe data required for learning a good Path function may include similar states to those visited by some optimal policy. However, there is no such guarantee for random walks; indeed, for most Atari games which have several levels, random policies don’t reach beyond the first level, so I don’t see how a Path function would be informative beyond the ‘portions’ of the state space which were visited by policies used to collect data.\nHence, several policies which are better than random are likely to be required for sampling this data, in general. In my mind this creates a chicken-and-egg issue: how to get the data, to learn the right Path function which does not make it impossible to still reach optimal performance on the task at hand? How can we ensure that some optimal policy can still be represented using appropriate Goal function outputs? I don’t see this as a given in the current formulation.\n- Although the method is atypical compared to standard HRL approaches, the same pitfalls may apply, especially that of ‘option collapse’: given a fixed Path function, the Goal function need only figure out which goal state outputs almost always lead to the same output action in the original action space, irrespective of the current state input phi(s), and hence bypass the Path function altogether; then, the role of phi(s) could be taken by tau(s), and we would end up with the original RL problem but in an arguably noisier (and continuous) action space. I recommend comparing the Jacobian w.r.t the phi(s) and tau(s) inputs to the Path function using saliency maps [1, 2]; alternatively, evaluating final policies with out of date input states s to phi, and the correct tau(s) inputs to Path function should degrade performance severely if it playing the role assumed. Same goes for using a running average of phi(s) and the correct tau(s) in final policies.\n- The ability to use state restoration for Path function learning is actually introducing a strong extra assumption compared to standard A3C, which does not technically require it. For cheap emulators and fully deterministic games (Atari) this assumption holds, but in general restoring expensive, stochastic environments to some state is hard (e.g. robot arms playing ping-pong, ball at given x, y, z above the table, with given velocity vector).\n- If reported results are single runs, please replace with averages over several runs, e.g. a few random seeds. Given the variance in deep RL training curves, it is hard to make definitive claims from single runs. If curves are already averages over several experiment repeats, some form of error bars or variance plot would also be informative.\n- How much data was actually used to learn the Path function in each case? If the amount is significant compared to task-specific training, then UA/A3C-L curves should start later than standard A3C curves, by that amount of data.\n\n\nReferences\n[1] Simonyan, K., Vedaldi, A., and Zisserman, A. Deep inside\nconvolutional networks: Visualising image classification\nmodels and saliency maps. arXiv preprint arXiv:1312.6034, 2013.\n[2] Z Wang, T Schaul, M Hessel, H Van Hasselt, M Lanctot, N De Freitas, Dueling network architectures for deep reinforcement learning arXiv preprint arXiv:1511.06581\n', ""The authors propose to decompose reinforcement learning into a PATH function that can learn how to solve reusable sub-goals an agent might have in a specific environment and a GOAL function that chooses subgoals in order to solve a specific task in the environment using path segments. So I guess it can be thought of as a kind of hierarchical RL.\nThe exposition of the model architecture could use some additional detail to clarify some steps and possibly fix some minor errors (see below). I would prefer less material but better explained. I had to read a lot of sections more than once and use details across sections to fill in gaps. The paper could be more focused around a single scientific question: does the PATH function as formulated help?\n\nThe authors do provide a novel formulation and demonstrate the gains on a variety of concrete problems taken form the literature. I also like that they try to design experiments to understand the role of specific parts of the proposed architecture.\n\nThe graphs are WAY TOO SMALL to read. Figure #s are missing off several figures.\n\n\nMODEL & ARCHITECTURE\n\nThe PATH function given a current state s and a goal state s', returns a distribution over the best first action to take to get to the goal P(A).  ( If the goal state s’ was just the next state, then this would just be a dynamics model and this would be model-based learning? So I assume there are multiple steps between s and s’?). \n\nAt the beginning of section 2.1, I think the authors suggest the PATH function could be pre-trained independently by sampling a random state in the state space to be the initial state and a second random state to be the goal state and then using an RL algorithm to find a path. \n\nPresumably, once one had found a path ( (s, a0), (s1, a1), (s2, a2), …, (sn-1,an-1),  s’ ) one could then train the PATH policy on the triple (s, s’, a0) ? This seems like a pretty intense process: solving some representative subset of all possible RL problems for a particular environment … Maybe one choses s and s’ so they are not too far away from each other (the experimental section later confirms this distance is >= 7. Maybe bring this detail forward)?\n\nThe expression Trans’( (s,s’), a) = (Trans(s,a), s’) was confusing.  I think the idea here is that the expression \nTrans’(  (s,s’) , a ) represents the n-step transition function and ‘a' represents the first action?\n\nThe second step is to train the goal function for a specific task. So I gather our policy takes the form of a composed function and the chain rule gives close to their expression in 2.2\n\n    PATH(  s,  Tau( s, th^g ),  a ; th^p )\n\n    d / { d th^g }  PATH(  s,  Tau( s, th^g ),  a ; th^p ) \n\n         =  {d / d {s’ }  PATH } ( s,  Tau( s, th^g ),  a )    d / {d th^g}  Tau( s, th^g) \n\nWhat is confusing is that they define\n\n    A( s, a, th^p, th^g, th^v ) = sum_i   gamma^i  r_{t+1}  +  gamma^k  V(  s_{t+k}  ;  th^v  )   -   V( s_t ;  th^v )\n\nThe left side contains th^p and th^g, but the right side does not. Should these parameters be take out of the n-step advantage function A?\n\nThe second alternative for training the goal function tau seems confusing. I get that tau is going to be constrained by whatever representation PATH function was trained on and that this representation might affect the overall performance - performance.  I didn’t get the contrast with method one.  How do we treat the output of Tau as an action? Are you thinking of the gradient coming back through PATH as a reward signal? More detail here would be helpful.\n\n\nEXPERIMENTS:\n\nLavaworld: authors show that pretraining the PATH function on longer 7-11 step policies leads to better performance\nwhen given a specific Lava world problem to solve.  So the PATH function helps and longer paths are better. This seems reasonable. What is the upper bound on the size of PATH lengths you can train? \n\nReachability: authors show that different ways of abstracting the state s into a vector encoding affect the performance of the system.  From a scientific point of view, this seems orthogonal to the point of the paper, though is relevant if you were trying to build a system. \n\nTaxi: the authors train the PATH problem on reachability and then show that it works for TAXI. This isn’t too surprising. Both picking up the passenger (reachability) and dropping them off somewhere are essentially the same task: moving to a point. It is interesting that the Task function is able to encode the higher level structure of the TAXI problem’s two phases.\n\nAnother task you could try is to learn to perform the same task in two different environments. Perhaps the TAXI problem, but you have two different taxis that require different actions in order to execute the same path in state space. This would require a phi(s) function that is trained in a way that doesn’t depend on the action a.\n\nATARI 2600 games: I am not sure what state restoration is.  Is this where you artificially return an agent to a state that would normally be hard to reach? The authors show that UA results in gains on several of the games.\n\nThe authors also demonstrate that using multiple agents with different policies can be used to collect training examples for the PATH function that improve its utility over training examples collected by a single agent policy.\n\nRELATED WORK:\n\nGood contrast to hierarchical learning: we don’t have switching regimes here between high-level options\n\nI don’t understand why the authors say the PATH function can be viewed as an inverse? Oh - now I get it.\nBecause it takes an extended n-step transition and generates an action.  \n\n\n\n\n\n"", 'Thank you for the submission. It was an interesting read. Here are a few comments: \n\nI think when talking about modelling the dynamics of the world, it is natural to discuss world models and model based RL, which also tries to explicitly take advantage of the separation between the dynamics of the world and the reward scheme. Granted, most world model also try to predict the reward. I’m not sure there is something specific I’m proposing here, I do understand the value of the formulation given in the work, I just find it strange that model based RL is not mention at all in the paper. \n\nI think reading the paper, it should be much clearer how the embedding is computed for Atari, and how this choice was made. Going through the paper I’m not sure I know how this latent space is constructed. This however should be quite important. The goal function tries to predict states in this latent space. So the simpler the structure of this latent space, the easier it should be to train a goal function, and hence quickly adapt to the current reward scheme.  \n\nIn complex environments learning the PATH network is far from easy. I.e. random walks will not expose the model to most states of the environment (and dynamics). Curiosity-driven RL can be quite inefficient at exploring the space. If the focus is transfer, one could argue that another way of training the PATH net could be by training jointly the PATH net and goal net, with the intend of then transferring to another reward scheme.\n\nA3C is known to be quite high variance. I think there are a lot of little details that don’t seem that explicit to me. How many seeds are run for each curve (are the results an average over multiple seeds). What hyper-parameters are used. What is the variance between the seeds. I feel that while the proposed solution is very intuitive, and probably works as described, the paper does not do a great job at properly comparing with baseline and make sure the results are solid. In particular looking at Riverraid-new is the advantage you have there significant? How does the game do on the original task? \n\nThe plots could also use a bit of help. Lines should be thicker. Even when zooming, distinguishing between colors is not easy. Because there are more than two lines in some plots, it can also hurt people that can’t distinguish colors easily. \n\n']","[20, 50, -20]","[60, 70, 40]","[""The sentiment score is slightly positive (20) because the review acknowledges some pros of the paper, such as the desirability of a modular architecture and the method being on par with standard A3C across various tasks. However, it also lists several significant cons and concerns, which temper the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses professional and respectful language throughout, offering constructive criticism and suggestions without harsh or dismissive comments. The reviewer acknowledges the paper's strengths before delving into concerns, and phrases criticisms as questions or recommendations rather than outright dismissals. The use of phrases like 'I recommend' and 'please' also contribute to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty of the approach and its demonstrated gains on various problems. They appreciate the authors' efforts to understand specific parts of the architecture. However, they also point out areas for improvement, such as the need for better exposition and larger graphs. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They use phrases like 'I would prefer,' 'I like that,' and 'could use some additional detail' instead of harsh or demanding language. The reviewer also balances critique with positive observations, maintaining a professional and courteous tone."", ""The sentiment score is slightly negative (-20) because while the reviewer starts with a polite acknowledgment, the majority of the review focuses on areas for improvement and missing elements in the paper. The reviewer points out several issues such as the lack of discussion on model-based RL, unclear explanations of the embedding computation, and concerns about the experimental setup and results presentation. However, the tone is not overly critical, which is why the score is only mildly negative. The politeness score is moderately positive (40) as the reviewer begins with a polite thank you and uses generally respectful language throughout. They phrase criticisms as suggestions or observations rather than direct attacks. The use of phrases like 'I think' and 'I'm not sure' softens the critique. However, the politeness is not overly effusive, maintaining a professional tone, which is why the score is not higher.""]"
"['The primary intellectual point the authors make is that previous networks for machine comprehension are not fully attentive. That is, they do not provide attention on all possible layers on abstraction such as the word-level and the phrase-level. The network proposed here, FusionHet, fixes problem. Importantly, the model achieves state-of-the-art performance of the SQuAD dataset.\n\nThe paper is very well-written and easy to follow. I found the architecture very intuitively laid out, even though this is not my area of expertise. Moreover, I found the figures very helpful -- the authors clearly took a lot of time into clearly depicting their work! What most impressed me, however, was the literature review. Perhaps this is facilitated by the SQuAD leaderboard, which makes it simple to list related work. Nevertheless, I am not used to seeing comparison to as many recent systems as are presented in Table 2. \n\nAll in all, it is difficult not to highly recommend an architecture that achieves state-of-the-art results on such a popular dataset.', 'The paper first analyzes recent works in machine reading comprehension (largely centered around SQuAD), and mentions their common trait that the attention is not ""fully-aware"" of all levels of abstraction, e.g. word-level, phrase-level, etc. In turn, the paper proposes a model that performs attention at all levels of abstraction, which achieves the state of the art in SQuAD. They also propose an attention mechanism that works better than others (Symmetric + ReLU).\n\nStrengths:\n- The paper is well-written and clear.\n- I really liked Table 1 and Figure 2; it nicely summarizes recent work in the field.\n- The multi-level attention is novel and indeed seems to work, with convincing ablations.\n- Nice engineering achievement, reaching the top of the leaderboard (in early October).\n\n\nWeaknesses:\n- The paper is long (10 pages) but relatively lacks substances. Ideally, I would want to see the visualization of the attention at each level (i.e. how they differ across the levels) and also possibly this model tested on another dataset (e.g. TriviaQA).\n- The authors claim that the symmetric + ReLU is novel, but  I think this is basically equivalent to bilinear attention [1] after fully connected layer with activation, which seems quite standard. Still useful to know that this works better, so would recommend to tone down a bit regarding the paper\'s contribution.\n\n\nMinor:\n- Probably figure 4 can be drawn better. Not easy to understand nor concrete.\n- Section 3.2 GRU citation should be Cho et al. [2].\n\n\nQuestions:\n- Contextualized embedding seems to give a lot of improvement in other works too. Could you perform ablation without contextualized embedding (CoVe)?\n\n\nReference:\n[1] Luong et al. Effective Approaches to Attention-based Neural Machine Translation. EMNLP 2015.\n[2] Cho et al. Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. EMNLP 2014.', '(Score before author revision: 4)\n(Score after author revision: 7)\n\nI think the authors have taken both the feedback of reviewers as well as anonymous commenters thoroughly into account, running several ablations as well as reporting nice results on an entirely new dataset (MultiNLI) where they show how their multi level fusion mechanism improves a baseline significantly. I think this is nice since it shows how their mechanism helps on two different tasks (question answering and natural language inference).\n\nTherefore I would now support accepting this paper.\n\n------------(Original review below) -----------------------\n\nThe authors present an enhancement to the attention mechanism called ""multi-level fusion"" that they then incorporate into a reading comprehension system. It basically takes into account a richer context of the word at different levels in the neural net to compute various attention scores.\n\ni.e. the authors form a vector ""HoW"" (called history of the word), that is defined as a concatenation of several vectors:\n\nHoW_i = [g_i, c_i, h_i^l, h_i^h]\n\nwhere g_i = glove embeddings, c_i = COVE embeddings (McCann et al. 2017), and h_i^l and h_i^h are different LSTM states for that word.\n\nThe attention score is then a function of these concatenated vectors i.e. \\alpha_{ij} = \\exp(S(HoW_i^C, HoW_j^Q))\n\nResults on SQuAD show a small gain in accuracy (75.7->76.0 Exact Match). The gains on the adversarial set are larger but that is because some of the higher performing, more recent baselines don\'t seem to have adversarial numbers.\n\nThe authors also compare various attention functions (Table 5) showing a particularone (Symmetric + ReLU) works the best. \n\nComments:\n\n-I feel overall the contribution is not very novel.  The general neural architecture that the authors propose in Section 3 is generally quite similar to the large number of neural architectures developed for this dataset (e.g. some combination of attention between question/context and LSTMs over question/context). The only novelty is these ""HoW"" inputs to the extra attention mechanism that takes a richer word representation into account.\n\n-I feel the model is seems overly complicated for the small gain (i.e. 75.7->76.0 Exact Match), especially on a relatively exhausted dataset (SQuAD) that is known to have lots of pecularities (see anonymous comment below). It is possible the gains just come from having more parameters.\n\n-The authors (on page 6) claim that that by running attention multiple times with different parameters but different inputs (i.e. \\alpha_{ij}^l, \\alpha_{ij}^h, \\alpha_{ij}^u) it will learn to attend to ""different regions for different level"". However, there is nothing enforcing this and the gains just probably come from having more parameters/complexity.']","[90, 60, 20]","[80, 70, 0]","[""The sentiment score is 90 because the reviewer expresses highly positive views about the paper, praising its writing, clarity, figures, and literature review. They also emphasize the achievement of state-of-the-art results and conclude by saying it's 'difficult not to highly recommend' the work. The politeness score is 80 as the reviewer uses respectful and appreciative language throughout, highlighting the authors' efforts and achievements without any criticism. They use phrases like 'very well-written', 'clearly depicting', and 'most impressed', which contribute to a polite and encouraging tone. The review maintains a professional and constructive approach without being overly formal or effusive, hence not reaching the maximum score of 100."", ""The sentiment score is 60 (moderately positive) because the reviewer begins by highlighting several strengths of the paper, including its clarity, novel approach, and achievement of state-of-the-art results. However, they also point out some weaknesses, which prevents the score from being higher. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits while offering constructive criticism. They use phrases like 'I really liked' and 'Nice engineering achievement' to offer praise, and soften criticisms with phrases like 'Ideally, I would want to see' and 'would recommend to tone down a bit'. The review maintains a professional and courteous tone throughout, offering specific suggestions for improvement without being harsh or dismissive."", 'The sentiment score is slightly positive (20) because the reviewer acknowledges some improvements made by the authors in response to feedback, including new results on an additional dataset. However, the overall tone remains somewhat critical, pointing out limitations in novelty and questioning the significance of the gains. The politeness score is neutral (0) as the language is professional and matter-of-fact, neither particularly polite nor rude. The reviewer provides direct criticism but also acknowledges positive aspects, maintaining a balanced and objective tone throughout.']"
"['Summary:\nThe paper gives theoretical results regarding the existence of local minima in the objective function of deep neural networks. In particular:\n- in the case of deep linear networks, they characterize whether a critical point is a global optimum or a saddle point by a simple criterion. This improves over recent work by Kawaguchi who showed that each critical point is either a global minimum or a saddle point (i.e., none is a local minimum), by relaxing some hypotheses and adding a simple criterion to know in which case we are.\n- in the case of nonlinear network, they provide a sufficient condition for a solution to be a global optimum, using a function space approach.\n\nQuality:\nThe quality is very good. The paper is technically correct and nontrivial. All proofs are provided and easy to follow.\n\nClarity:\nThe paper is very clear. Related work is clearly cited, and the novelty of the paper well explained. The technical proofs of the paper are in appendices, making the main text very smooth.\n\nOriginality:\nThe originality is weak. It extends a series of recent papers correctly cited. There is some originality in the proof which differs from recent related papers.\n\nSignificance:\nThe result is not completely surprising, but it is significant given the lack of theory and understanding of deep learning. Although the model is not really relevant for deep networks used in practice, the main result closes a question about characterization of critical points in simplified models if neural network, which is certainly interesting for many people.', ""The paper gives sufficient and necessary conditions for the global optimality of the loss function of deep linear neural networks. The paper is an extension of Kawaguchi'16. It also provides some sufficient conditions for the non-linear cases. \n\nI think the main technical concerns with the paper is that the technique only applies to a linear model, and it doesn't sound the techniques are much beyond Kawaguchi'16. I am happy to see more papers on linear models, but I would expect there are more conceptual or technical ingredients in it. As far as I can see, the same technique here will fail for non-linear models for the same reason as Kawaguchi's technique. Also, I think a more interesting question might be turning the landscape results into an algorithmic result --- have an algorithm that can guarantee to converge a global minimum. This won't be trivial because the deep linear networks do have a lot of very flat saddle points and therefore it's unclear whether one can avoid those saddle points. "", '\n-I think title is misleading, as the more concise results in this paper is about linear networks I recommend adding linear in the title i.e. changing the title to … deep LINEAR networks\n\n- Theorems 2.1, 2.2 and the observation (2) are nice!\n \n- Theorem 2.2 there is no discussion about the nature of the saddle point is it strict? Does this theorem imply that the global optima can be reached from a random initialization? Regardless of if this theorem can deal with these issues, a discussion of the computational implications of this theorem is necessary.\n\n- I’m a bit puzzled by Theorems 4.1 and 4.2 and why they are useful. Since these results do not seem to have any computational implications about training the neural nets what insights do we gain about the problem by knowing this result? Further discussion would be helpful.\n']","[80, -30, 50]","[90, 20, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable opinion of the paper, describing it as 'very good', 'technically correct', 'nontrivial', and 'very clear'. They also note its significance in the field. The only slight negative is the mention of weak originality, but this is balanced by acknowledging some originality in the proof. The politeness score is 90 (very polite) due to the consistently respectful and professional tone. The reviewer uses phrases like 'very good', 'easy to follow', and 'certainly interesting', which convey positive feedback in a courteous manner. There are no harsh criticisms or impolite language, and the reviewer takes care to acknowledge the paper's strengths even when pointing out limitations."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the paper's contributions, they express significant concerns about its limitations and lack of novelty. The reviewer states that the techniques don't go much beyond previous work and fail for non-linear models. They also suggest that more interesting questions could be explored. However, the score is not deeply negative as the reviewer does show some appreciation for work on linear models. The politeness score is slightly positive (20) as the reviewer uses respectful language throughout, acknowledging the paper's contributions before presenting criticisms. They use phrases like 'I think' and 'I would expect' to soften their critiques, and offer constructive suggestions for improvement rather than harsh dismissals."", ""The sentiment score is 50 (slightly positive) because the reviewer offers both positive and constructive feedback. They praise certain aspects of the paper ('Theorems 2.1, 2.2 and the observation (2) are nice!') while also providing suggestions for improvement. The overall tone is balanced and not overly critical. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing their suggestions as recommendations ('I recommend...') and questions ('Does this theorem imply...?') rather than demands. They also use phrases like 'I'm a bit puzzled' and 'Further discussion would be helpful' which maintain a courteous tone while expressing concerns. The reviewer avoids harsh or accusatory language, focusing instead on constructive feedback and areas for clarification or expansion.""]"
"['The paper presents a clever trick for updating the actor in an actor-critic setting: computing a guide actor that diverges from the actor to improve critic value, then updating the actor parameters towards the guide actor. This can be done since, when the parametrized actor is Gaussian and the critic value can be well-approximated as quadratic in the action, the guide actor can be optimized in closed form.\n\nThe paper is mostly clear and well-presented, except for two issues: 1) there is virtually nothing novel presented in the first half of the paper (before Section 3.3); and 2) the actual learning step is only presented on page 6, making it hard to understand the motivation behind the guide actor until very late through the paper.\n\nThe presented method itself seems to be an important contribution, even if the results are not overwhelmingly positive. It\'d be interesting to see a more elaborate analysis of why it works well in some domains but not in others. More trials are also needed to alleviate any suspicion of lucky trials.\n\nThere are some other issues with the presentation of the method, but these don\'t affect the merit of the method:\n\n1. Returns are defined from an initial distribution that is stationary for the policy. While this makes sense in well-mixing domains, the experiment domains are not well-mixing for most policies during training, for example a fallen humanoid will not get up on its own, and must be reset.\n\n2. The definition of beta(a|s) as a mixture of past actors is inconsistent with the sampling method, which seems to be a mixture of past trajectories.\n\n3. In the first paragraph of Section 3.3: ""[...] the quality of a guide actor mostly depends on the accuracy of Taylor\'s approximation."" What else does it depend on? Then: ""[...] the action a_0 should be in a local vicinity of a.""; and ""[...] the action a_0 should be similar to actions sampled from pi_theta(a|s)."" What do you mean ""should""? In order for the Taylor approximation to be good?\n\n4. The line before (19) is confusing, since (19) is exact and not an approximation. For the approximation (20), it isn\'t clear if this is a good approximation. Why/when is the 2nd term in (19) small?\n\n5. The parametrization nu of \\hat{Q} is never specified in Section 3.6. This is important in order to evaluate the complexities involved in computing its Hessian.\n', ""\n\nThe authors devise and explore use of the hessian of the\n(approximate/learned) value function (the critic) to update the policy\n(actor) in the actor-critic  approach to RL.  They connect their\ntechnique, 'guide actor-critic' or GAC, to existing actor-critic\nmethods (authors claim only two published work use 1st order\ninformation on the critic). They show that the 2nd order information\ncan be useful (in several of the 9 tasks, their GAC techniques were\nbest or competitive, and in only one, performed poorly compared to best).\n\nThe paper has a technical focus.\n\npros:\n\n- Strict generalization of an existing (up to 1st order) actor-critic approaches.\n\n- Compared to many existing techniques, on 9 tasks\n\ncons:\n\n- no mention of time costs, except that for more samples, S > 1, for\n taylor approximation, it can be very expensive.\n\n- one would expect more information to strictly improve performance,\n  but the results are a bit mixed (perhaps due to convergence to local\n  optima and both actor and critic being learned at same time, \n  or the Gaussian assumptions, etc.).\n\n- relevance: the work presents a new approach to actor-critique strategy for\n  reinforcement learning, remotely related to 'representation\n  learning' (unless value and policies are deemed a form of\n  representation).\n\n\nOther comments/questions:\n\n- Why does the performance start high on Ant (1000), then goes to 0\n(all approaches)?\n\n- How were the tasks selected? Are they all the continuous control\n  tasks available in open ai?\n\n\n \n\n\n\n\n"", 'The paper introduces a modified actor-critic algorithm where a “guide actor” uses approximate second order methods to aid computation. The experimental results are similar to previously proposed methods. \n\nThe paper is fairly well-written, provides proofs of detailed properties of the algorithm, and has decent experimental results. However, the method is not properly motivated. As far as I can tell, the paper never answers the questions: Why do we need a guide actor? What problem does the guide actor solve? \n\nThe paper argues that the guide actor allows to introduce second order methods, but (1) there are other ways of doing so and (2) it’s not clear why we should want to use second-order methods in reinforcement learning in the first place. Using second order methods is not an end in itself. The experimental results show the authors have found a way to use second order methods without making performance *worse*. Given the high variability of deep RL, they have not convincingly shown it performs better.\n\nThe paper does not discuss the computational cost of the method. How does it compare to other methods? My worry is that the method is more complicated and slower than existing methods, without significantly improved performance.\n\nI recommend the authors take the time to make a much stronger conceptual and empirical case for their algorithm. \n']","[20, 50, -30]","[60, 20, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's 'clever trick' and 'important contribution,' while also providing constructive criticism. The overall tone is balanced, pointing out both strengths and areas for improvement. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing criticisms as suggestions or observations rather than harsh judgments. Phrases like 'The paper is mostly clear and well-presented' and 'It'd be interesting to see' contribute to the polite tone. The reviewer also provides specific, detailed feedback, which is a courteous way to help the authors improve their work."", ""For the sentiment score, I assigned 50 (slightly positive) because the review acknowledges the novelty and potential of the proposed method (GAC), noting its competitiveness in several tasks and its generalization of existing approaches. However, it also points out some limitations, creating a balanced view. The reviewer lists both pros and cons, indicating a fair assessment.\n\nFor the politeness score, I assigned 20 (slightly polite) because the language is generally neutral and professional, without any overtly rude comments. The reviewer uses phrases like 'the authors devise and explore' and 'the paper has a technical focus,' which are respectful. However, the review doesn't go out of its way to be exceptionally polite either, maintaining a matter-of-fact tone throughout. The questions at the end are direct but not impolite.\n\nThe reasoning behind these scores is based on the overall tone, the balance of positive and negative comments, and the absence of strongly emotional or judgmental language. The review maintains a professional, academic tone while providing both praise and constructive criticism."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('fairly well-written', 'provides proofs', 'decent experimental results'), they express significant concerns about the paper's motivation, effectiveness, and comparative advantages. The overall tone suggests the paper needs substantial improvements. The politeness score is 50 because the reviewer uses respectful language throughout, avoiding harsh criticism, and offers constructive feedback. They use phrases like 'I recommend' and 'fairly well-written', which maintain a professional and courteous tone. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a balanced, objective stance.""]"
"['This paper extends the Kronecker-factor Approximate Curvature (K-FAC) optimization method to the setting of recurrent neural networks. The K-FAC method is an approximate 2nd-order optimization method that builds a block diagonal approximation of the Fisher information matrix, where the block diagonal elements are Kronecker products of smaller matrices. \n\nIn order to approximate the Fisher information matrix for RNNs, the authors assume that the derivative of the loss function with respect to each weight matrix at each time step is independent of the length of the sequence, that these derivatives are temporally homogeneous, that the input and derivatives of the output are independent across every point in time, and that either the one-step cross-covariance of these derivatives is symmetric or that the training sequences are effectively infinite in length. Based on these assumptions, the authors show that the Fisher information can be reduced into a form in which the derivatives of the weight matrices can be approximated by a linear Gaussian graphical model and in which the approximate 2nd order method can be efficiently carried out. The authors compare their method to SGD on two language modeling tasks and against Adam for learning differentiable neural computers.\n\nThe paper is relatively clear, and the authors do a reasonable job of introducing related work of the original K-FAC algorithm as well as its extension to CNNs before systematically deriving their method for RNNs. The problem of extending the K-FAC algorithm is natural, and the steps taken in this paper seem natural yet also original and non-trivial.  \n\nThe main issue that I have with this paper is the lack of theoretical justification or even intuition for the many approximations carried out in the course of approximating the Fisher information matrix. In many instances, it seemed like these approximations were made purely for convenience and tractability without much regard for (even approximate) correctness. This quality of this paper would be greatly  strengthened if it had some bounds on approximation error or even empirical results testing the validity of the assumptions in the paper. Moreover, the experiments do not demonstrate levels of statistical significance in the results, so it is difficult to assert the practical significance of this work.  \n\nSpecific comments and questions\nPage 2, ""r is is"". Typo.\nPage 2, ""DV"". I found the introduction of V without any explanation to be confusing.\nPage 2, ""P_{y|x}(\\theta)"". The relation between P_{y|x}(\\theta) and f(x,\\theta) is never explained.\nPage 3, ""common practice of computing the natural gradient as (F + \\lambda I) \\nabla h instead of F^{-1} \\nabla h"". I don\'t see how the former can serve as a replacement for the latter.\nPage 3, ""approximate g and a as statistically independent"". Even though K-FAC already exists, it would be good to explain why this assumption is reasonable, since similar assumptions are made for the work presented in this paper.\nPage 4, ""This new approximation, called ""KFC"", is derived by assuming...."". Same as previous comment. It would be good to briefly discuss why these assumptions are reasonable.\nPage 5, Independence of T and w_t\'s, temporal homogeneity of w_t\'s,, and independence between a_t\'s and g_t\'s. I can see why these are convenient assumptions, but why are they reasonable? Moreover, why is it further natural to assume that A and G are temporally homogeneous as well?\nPage 7, ""But insofar as the w_t\'s ... encode the relevant information contained in these external variables, they should be approximately Markovian"". I am not sure what this means.\nPage 7, ""The linear-Gaussian assumption meanwhile is a more severe one to make, but it seems necessary for there to be any hope that the required expectations remain tractable"". I am not sure that this is a good enough justification for such an idea, unless there are compelling approximation error bounds. \nPage 8, Option 1. In what situations is it reasonable to assume that V_1 is symmetric? \nPages 8-9, Option 2. What is a good finite sample size in which the assumption that the training sequences are infinitely long is reasonable in practice? Can the error |\\kappa(x) - \\zeta_T(x)| be translated into a statement on the approximation error?\nPage 9, ""V_1 = V_{1,0} = ..."". Typos (that appear to have been caught by the authors already).\nPage 9, ""The 2nd-order statistics ... are accumulated through an exponential moving average during training"". How sensitive is the performance of this method to the decay rate of the exponential moving average? \nPage 10, ""The additional computations required to get the approximate Fisher inverse from these statistics ... are performed asynchronously on the CPU\'s"". I find it a bit unfair to compare SGD to K-FAC in terms of wall clock time without also using the extra CPU\'s for SGD as well (e.g. via Hogwild or synchronous parallel SGD).\nPage 10, ""The hyperparameters of our approach..."". What is the sensitivity of the experimental results to these hyperparameters? Moreover, how sensitive are the results to initialization?\nPage 10, ""we found that each parameter update of our method required about 80% more wall-clock time than an SGD update"". How much of this is attributed to the fact that the statistics are computed asynchronously?\nPages 10-12, Experiments. There are no error bars in any of the plots, so it is impossible to ascertain the statistical significance of any of these results. \nPage 11: Figure 2. Where is the Adam batchsize 50 line in the left plot? Why did the Adam batchsize 200 line disappear halfway through the right plot?\n  \n\n\n  ', 'In this paper, the authors present a second-order method that is specifically designed for RNNs. The paper overall is well-written and I enjoyed reading the paper. \n\nThe main idea of the paper is to extend the existing kronecker-factored algorithms to RNNs. In order to obtain a tractable formulation, the authors impose certain assumptions and provide detailed derivations. Even though the gain in the convergence speed is not very impressive and the algorithm is quite complicated and possibly not very accessible by deep learning practitioners, I still believe this is a novel and valuable contribution and will be of interest to the community. \n\nI only have some minor corrections:\n\n1) Sec 2.1: typo ""is is""\n2) Sec 2.2: typo ""esstentiallybe""\n3) Sec 2.2: (F+lambda I) --> should be inverse\n4) The authors should include a proper conclusion', '\nSummary of the paper\n-------------------------------\n\nThe authors extend the K-FAC method to RNNs. Due to the nature of BPTT, the approximation that the activations \'a\' are independent from the gradients \'Ds\' doesn\'t hold anymore and thus other approximations have to be made. They present 3 ways of approximating F, and show optimization results on 3 datasets, outperforming ADAM in both number of updates and computation time.\n\nClarity, Significance and Correctness\n--------------------------------------------------\n\nClarity: Above average. The mathematical notations is overly verbose, so it makes the paper harder to understand. Note that it is not the author\'s fault only, since they followed the notation of the other K-FAC papers.\nFor instance, the notations goes from \'E[xy^T]\' to \'cov(x, y)\' to \'V_{x,y}\'. I don\'t think introducing the \'cov\' notation helps with the understanding of the paper (unless they explicitly wanted to stress out that the covariance of the gradients of the outputs of the model are centered). Also the \'V\' in equation (4) could be confused with the \'V\' in the first equation. Moreover, for the gradients with respect to the activations, we go from \'dL/ds\' to \'Ds\' to \'g\', and for the weights we go from \'dL/dW\' to \'DW\' to \'w\'. Why not keeping the \'Ds\' and \'Dw\' notation throughout the paper, and defining Dx as vec(dL/dx)?\n\nSignificance: This paper aims at helping with the optimization of RNNs and is thus and important contribution for our community.\n\nCorrectness: The paper is technically correct.\n\nQuestions\n--------------\n\n1. In figure 1, how does it compare to Adam instead of SGD? I think it would be a more fair comparison since SGD is rarely used to train RNNs (as RMSprop and ADAM might help with the vanishing/exploding gradients problem). Also, does the SGD baseline has momentum (since your method does)?\n2. In all experiments, how do the validation / testing curves look like?\n3. How does it compare to different reparametrization techniques, such as Layer Normalization or Batch Normalization?\n\nPros\n------\n\n1. This paper completes the K-FAC family.\n2. It addresses the optimization of RNNs, which is an important research direction in our field.\n3. It shows different levels of approximations of the Fisher, with the corresponding performances.\n\nCons\n-------\n\n1. No validation / test curves for any experiments, which makes it hard to asses if one should use this method in practice or not.\n2. The notation is a bit verbose and can become confusing.\n3. Small experimental setting (only PTB and DNC).\n\nTypos\n--------\n\n1. Sec 1, par 5: ""a new family curvature"" -> ""a new family of curvature""']","[-20, 70, 50]","[60, 80, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's clarity and originality, they express significant concerns about the lack of theoretical justification for the approximations and the absence of statistical significance in the experimental results. The reviewer states that the 'main issue' is the lack of theoretical backing, which indicates a notable criticism. However, the score is not deeply negative as the reviewer also recognizes the paper's contributions and clarity.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'The paper is relatively clear,' and 'The authors do a reasonable job,' which show appreciation for the authors' work. Even when expressing criticisms, the reviewer uses constructive language, suggesting ways to improve the paper rather than dismissing it outright. The use of phrases like 'The quality of this paper would be greatly strengthened if...' indicates a desire to help improve the work rather than simply criticize it. The reviewer also asks questions and provides specific, detailed feedback, which is a polite and helpful approach in academic review."", ""The sentiment score is 70 (positive) because the reviewer expresses enjoyment in reading the paper, describes it as well-written, and believes it to be a 'novel and valuable contribution' that will interest the community. However, it's not 100 as the reviewer notes that the gain in convergence speed is not very impressive and the algorithm is complicated. The politeness score is 80 (polite) due to the reviewer's positive and constructive tone throughout. They use phrases like 'I enjoyed reading the paper' and 'I still believe this is a novel and valuable contribution'. Even when pointing out limitations, the language remains respectful. The reviewer also frames their corrections as 'minor', which is a polite way to present criticism. The use of 'please' in requesting a conclusion further adds to the politeness."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's significance and correctness while also pointing out some areas for improvement. They mention pros like completing the K-FAC family and addressing important research directions, but also note cons such as lack of validation/test curves and verbose notation. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's contributions, and frames criticisms constructively. They use phrases like 'Above average' and 'important contribution' while offering suggestions for improvement rather than harsh criticisms. The reviewer also provides specific, helpful feedback and questions, which is a polite way to engage with the authors' work.""]"
"[""In their paper, the authors propose to learn a metric between neural responses by either optimizing a quadratic form or a deep neural network. The pseudometric is optimized by positing that the distance between two neural responses to two repeats of the same stimulus should be smaller than the distance between responses to different stimuli. They do so with the application of improving neural prosthesis in mind. \n\nFirst of all, I am doubtful about this application: I don't think the task of neural prosthesis can ever be to produce idential output pattern to the same stimuli. Nevertheless, a good metric for neural responses that goes beyond e.g. hamming distance or squared error between spike density function would be clearly useful for understanding neural representations.\n\nSecond, I find the framework proposed by the authors interesting, but not clearly motivated from a neurobiological perspective, as the similarity between stimuli does not appear to play a role in the optimized loss function. For two similar stimuli, natural responses of neural population can be more similar than the responses to two repetitions of the same stimulus.\n\nThird, the results presented by the authors are not convincing throughout. For example, 4B suggests that indeed the Hamming distance achieves lower error than the learned representation.\n\nNevertheless, it is an interesting approach that is worthwhile pursuing further. "", ""The authors develop new spike train distance metrics that cluster together responses to the same stimulus, and push responses to different stimuli away from each other. Two such metrics are discussed: neural networks, and quadratic metrics. They then show that these metrics can be used to classify neural responses as coming from the same vs different stimuli, and that they outperform the naive Hamming distance metric at this task. Moreover, they show that this metric implicitly captures some structure in the neural code: more similar responses correspond to more similar visual stimuli. Finally, they discuss the implications of their metric for retinal prosthesis, and show some (fairly preliminary) data for how it could be used.\n\nOverall, I love the concepts in this paper. I have some reasonably substantive concerns over the execution, outlined below. But I encourage the authors to consider following through on these suggestions to improve their paper: the paper's key idea is really good, and I think it's worth the effort to flesh that idea out more thoroughly.\n\nMy specific suggestions / criticisms are:\n\n1) The quadratic metric seems only marginally better than the Hamming one (especially in Figs. 3 and 4), whereas the neural nets do much better as a metric (Fig. 3). However, most of the analyses (Figs. 4,5) use the quadratic metric. Why not use the better neural network metric for the subsequent studies of image similarity, and retinal stimulation? \n\n2) For Figs. 4, 5, where you use linear decoders to test the stimuli corresponding to the neural responses, how good are those decoders (i.e., MSE between decoded stim and true stim.)? If the decoders are poor, then the comparisons based on those decoders might not be so meaningful. I encourage you to report the decoding error, and if it's large, to make a better decoder and use it for these studies.\n\n3) Similarly, for Fig. 4, why not measure the MSE between the actual image frames corresponding to these neural responses? Presumably, you have the image frames corresponding to the target response, and for each of the other responses shown (i.e., the responses at different distances from the target). This would avoid any complications from sub-optimal decoders, and be a much more direct test.\n\n(I understand that, for Fig. 5, you can't do this direct comparison, as the electrically stimulated patterns don't have corresponding image frames, so you need to decode them.)"", '* Summary of paper: The paper addresses the problem of optimizing metrics in the context of retinal prosthetics: Their goal is to learn a metric which assumes spike-patterns generated by the same stimulus to be more similar to each other than spike-patterns generated by different stimuli. They compare a conventional, quadratic metric to a neural-network based representation and a simple Hamming metric, and show that the neural-network based on achieves higher performance, but that the quadratic metric does not substantially beat the simple Hamming baseline. They subsequently evaluate the metric (unfortunately, only the quadratic metric) in two interesting applications involving electrical stimulation, with the goal of selecting stimulations which elicit spike-patterns which are maximally similar to spike-patterns evoked by particular stimuli.\n\n* Quality: Overall, the paper is of high quality. What puzzled me, however is the fact that, in the applications using electrical stimulation in the paper (i.e. the applications targeted to retinal prosthetics, Secs 3.3 and 3.4), the authors do not actually used the well-performing neural-network based metric, but rather the quadratic metric, which is no better than the baseline Hamming metric?  It would be valuable for them to comment on what additional challenges would arise by using the neural network instead, and whether they think they could be surmonted.\n\n* Clarity: The paper is overall clear, but specific aspects could be improved: First, it took me a while to understand (and is not entirely clear to me) what the goal of the paper is, in particular outside the setting studied by the authors (in which there is a small number of stimuli to be distinguished). Second, while the paper does not claim to provide a new metric-learning approach, it would benefit from more clearly explaining if and how their approach relates to previous approaches to metric learning.  Third, the paper, in my view, overstating some of the implications. As an example, Figure 5 is titled \'Learned quadratic response metric gives better perception than using a Hamming metric.\': there is no psychophysical evaluation of perception in the paper, and even the (probably hand-picked?) examples in the figure do not look amazing.\n\n* Originality: To the best of my knowledge, this is the first paper addressing the question of learning similarity metrics in the context of retinal prosthetics. Therefore, this specific paper and approach is certainly novel and original. From a machine-learning perspective, however, this seems like pretty standard metric learning with neural networks, and no attempt is made to either distinguish or relate their approach to prior work in this field (e.g. Chopra et al 2005, Schroff et al 2015 or Oh Song et al 2016.)\n\nIn addition, there is a host of metrics and kernels which have been proposed for measuring similarity between spike trains (Victor-Purpura) -- while they might not have been developed in the context of prosthetics, they might still be relevant to this tasks, and it would have been useful to see a comparison of how well they do relative to a Hamming metric. The paper states this as a goal (""This measure should expand upon...), but then never does that- why not?\n\n* Significance: The general question the authors are approaching (how to improve retinal prosthetics) is,  an extremely important one both from a scientific and societal perspective. How important is the specific advance presented in this paper? The authors learn a metric for quantifying similarity between neural responses, and show that it performs better than a Hamming metric. It would be useful for the paper to comment on how they think that metric to be useful for retinal prosthetics. In a real prosthetic device, one will not be able learn a metric, as the metric learning her requires access to multiple trials of visual stimulation data, neuron-by-neuron. Clearly, any progress on the way to retinal prosthetics is important and this approach might contribute that. However, the current presentation of the manuscripts gives a somewhat misleading presentation of what has been achieved, and a more nuanced presentation would be important and appropriate. \n\n\nOverall, this is a nice paper which could be of interest to  ICLR. Its strengths are that i) they identified a novel, interesting and potentially impactful problem that has not been worked on in machine learning before, ii) they provide a solution to it based on metric learning, and show that it performs better than a non-learned metrics. Its limitations are that i) no novel machine-learning methodology is used (and relationship to prior work in machine learning is not clearly described) ii) comparisons with previously proposed similarity measures of spike trains are lacking, iii) the authors do not actually use their learned, network based metric, but the metric which performs no better than the baseline in their main results, and  iv) it is not well explained how this improved metric could actually be used in the context of retinal prosthetics.\n\nMinor comments:\n\n  - p.2 The authors write that the element-wise product is denoted by $A \\bullet B = \\Tr(A^{\\intercal}) B$\n    This seems to be  incorrect, as the r.h.s. corresponds to a scalar.\n  - p.3 What exactly is meant by “mining”?\n  - p.4 It would be useful to give an example of what is meant by “similarity learning”.\n  - p.4 “Please the Appendix” -> “Please see the Appendix”\n  - p.5 (Fig. 3) The abbreviation “AUC” is not defined.\n  - p.5 (Fig. 3B) The figure giving \'recall\' should have a line indicating perfect performance, for comparison.\n  - Sec 3.3: How was the decoder obtained ?\n  - p.6 (Fig. 4) Would be useful to state that column below 0 is the target. Or just replace “0” by “target”.\n  - p.6 (3rd paragraph) The sentence “Figure 4A bottom left shows the spatial profile of the linear decoding 20ms prior to the target response.” is unclear. It took me a very long time to realize that ""bottom left"" meant ""column 0, \'decoded stimulus\'"" row. It\'s also unclear why the authors chose to look at 20ms prior to the target response.\n  - p.6 The text says RMS distance, but the Fig. 4B caption says MSE— is this correct?']","[-20, 60, 20]","[50, 80, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer finds the approach 'interesting' and 'worthwhile pursuing further', they express several doubts and criticisms. They are 'doubtful about this application', find the framework 'not clearly motivated', and state that 'the results presented by the authors are not convincing throughout'. The overall tone suggests more concerns than praise, but it's not entirely negative. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, acknowledges potential value in the work, and frames criticisms as personal opinions ('I am doubtful', 'I find'). They also end on a positive note, encouraging further pursuit of the approach. The language is professional and constructive, avoiding harsh or dismissive statements."", ""The sentiment score is 60 (positive) because the reviewer expresses enthusiasm for the paper's key idea, stating 'I love the concepts in this paper' and encouraging the authors to improve it further. However, they also mention 'reasonably substantive concerns', which tempers the overall positivity. The politeness score is 80 (quite polite) due to the reviewer's constructive and encouraging tone throughout. They use phrases like 'I encourage the authors' and offer specific suggestions for improvement rather than harsh criticism. The reviewer also balances critique with praise, acknowledging the paper's strengths while pointing out areas for improvement. The language is professional and respectful throughout, without any rude or dismissive comments."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's high quality, originality, and potential significance, they also point out several limitations and areas for improvement. The overall tone is constructive but with significant critiques. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing its weaknesses. They offer suggestions for improvement rather than harsh criticisms, and use phrases like 'it would be useful' and 'it would benefit from' to soften their critiques. The reviewer also acknowledges the importance of the research topic, which adds to the polite tone.""]"
"['The authors propose a new defense against security attacks on neural networks. The attack model involves a standard l_inf norm constraint. Remarkably, the approach outputs a security certificate (security guarantee) on the algorithm, which makes it appealing for security use in practice. Furthermore, the authors include an approximation of the certificate into their objective function, thus training networks that are more robust against attacks. The approach is evaluated for several attacks on MNIST data.\n\nFirst of all, the paper is very well written and structured. As standard in the security community, the attack model is precisely formalized (I find this missing in several other ML papers on the topic). The certificate is derived with rigorous and sound math. An innovative approximation based on insight into a relation to the MAXCUT algorithm is shown. An innovative training criterion based on that certificate is proposed. Both the performance of the new training objective and the tightness of the cerificate are analyzed empirically showing that good agreement with the theory and good results in terms of robustness against several attacks.\n\nIn summary, this is an innovative paper that treats the subject with rigorous mathematical formalism and is successful in the empirical evaluation. For me, it is a clear accept. The only drawback I see is the missing theoretical and empirical comparison to the recent NIPS 2017 paper by Hein et al.\n', 'This paper derived an upper bound on adversarial perturbation for neural networks with one hidden layer. The upper bound is derived via (1) theorem of middle value; (2) replace the middle value by the maximum (eq 4); (3) replace the maximum of the gradient value (locally) by the global maximal value (eq 5); (4) this leads to a non-convex quadratic program, and then the authors did a convex relaxation similar to maxcut to upper bound the function by a SDP, which then can be solved in polynomial time.\n\nThe main idea of  using upper bound (as opposed to lower bound) is reasonable. However, I find there are some limitations/weakness of the proposed method:\n1. The method is likely not extendable to more complicated and more practical networks, beyond the ones discussed in the paper (ie with one hidden layer)\n2. SDP while tractable, would still require very expensive computation to solve exactly.\n3. The relaxation seems a bit loose - in particular, in above step 2 and 3, the authors replace the gradient value by a global upper bound on that, which to me seems can be pretty loose.', 'This paper develops a new differentiable upper bound on the performance of classifier when the adversarial input in l_infinity is assumed to be applied.\nWhile the attack model is quite general, the current bound is only valid for linear and NN with one hidden layer model, so the result is quite restrictive.\n\nHowever the new bound is an ""upper"" bound of the worst-case performance which is very different from the conventional sampling based ""lower"" bounds. Therefore minimizing this upper bound together with a classification loss makes perfect sense and provides a theoretically sound approach to train a robust classifier.\nThis paper provides a gradient of this new upper bound with respect to model parameters so we can apply the usual first order optimization scheme to this joint optimization (loss + upper bound).\nIn conclusion, I recommend this paper to be accepted, since it presents a new and feasible direction of a principled approach to train a robust classifier, and the paper is clearly written and easy to follow.\n \nThere are possible future directions to be developed.\n\n1. Apply the sum-of-squares (SOS) method.\nThe paper\'s SDP relaxation is the straightforward relaxation of Quadratic Program (QP), and in terms of SOS relaxation hierarchy, it is the first hierarchy. One can increase the complexity going beyond the first hierarchy, and this should provides a computationally more challenging but tighter upper bound.\nThe paper already mentions about this direction and it would be interesting to see the experimental results.\n\n2. Develop a similar relaxation for deep neural networks.\nThe author already mentioned that they are pursuing this direction. While developing the result to the general deep neural networks might be hard, residual networks maybe fine thanks to its structure.']","[90, -30, 80]","[80, 50, 70]","[""The sentiment score is 90 because the reviewer expresses strong positive sentiment throughout the review. They describe the paper as 'very well written and structured', 'innovative', and 'successful in the empirical evaluation'. The reviewer explicitly states 'For me, it is a clear accept', indicating high approval. The only minor criticism is the 'missing theoretical and empirical comparison' to another paper, which slightly reduces the score from 100. The politeness score is 80 because the reviewer uses respectful and professional language throughout. They offer praise generously and frame their sole criticism constructively. The tone is consistently positive and encouraging, without being overly effusive or informal, maintaining a polite but professional distance."", ""The sentiment score is -30 because while the reviewer acknowledges the main idea as 'reasonable', they spend more time highlighting limitations and weaknesses of the proposed method. The tone is more critical than positive, but not entirely negative. The politeness score is 50 because the reviewer uses neutral, professional language without harsh criticism. They present their concerns as 'limitations/weakness' rather than outright flaws, and use phrases like 'I find' to soften their critique. The review maintains a respectful tone throughout, even when pointing out potential issues with the paper."", ""The sentiment score is 80 (positive) because the reviewer recommends acceptance, praises the paper for presenting a 'new and feasible direction' and a 'principled approach', and describes it as 'clearly written and easy to follow'. The reviewer also suggests future directions, indicating interest in the work. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledges the paper's contributions, and offers constructive suggestions for future work without harsh criticism. The tone is professional and encouraging, with phrases like 'it would be interesting to see' and 'the author already mentioned', showing respect for the authors' work and intentions.""]"
"['+ Pros:\n- The paper properly compares and discusses the connection between AM-GAN and class conditional GANs in the literature (AC-GAN, LabelGAN)\n- The experiments are thorough\n- Relation to activation maximization in neural visualization is also properly mentioned\n- The authors publish code and honestly share that they could not reproduce AC-GAN\'s results and thus using to its best variant AC-GAN* that they come up with. I find this an important practice worth encouraging!\n- The analysis of Inception score is sound.\n+ Cons:\n- A few presentation/clarity issues as below\n- This paper leaves me wonder why AM-GAN rather than simply characterizing D as a 2K-way classifier (1K real vs 1K fake).\n\n+ Clarity: \nThe paper is generally well-written. However, there are a few places that can be improved:\n- In 2.2, the authors mentioned ""In fact, the above formulation is a modified version of the original AC-GAN.."", which puts readers confusion whether they were previously just discussed AC-GAN or AC-GAN* (because the previous paragraph says ""AC-GAN are defined as.."".\n- Fig. 2: it\'s not clear what the authors trying to say if looking at only figures and caption. I\'d suggest describe more in the caption and follow the concept figure in Odena et al. 2016.\n- A few typos here and there e.g. ""[a]n diversity measurement""\n\n+ Originality: AM-GAN is an incremental work by applying AM to GAN. However, I have no problems with this.\n+ Significance: \n- Authors show that in quantitative measures, AM-GAN is better than existing GANs on CIFAR-10 / TinyImageNet. Although I don\'t find much a real difference by visually comparing of samples of AM-GAN to AC-GAN*.\n\nOverall, this is a good paper with thorough experiments supporting their findings regarding AM-GAN and Inception score!', 'This paper is a thorough investigation of various “class aware” GAN architectures. It purposes a variety of modifications on existing approaches and additionally provides extensive analysis of the commonly used Inception Score evaluation metric.\n\nThe paper starts by introducing and analyzing two previous class aware GANs - a variant of the Improved GAN architecture used for semi-supervised results (named Label GAN in this work) and AC-GAN, which augments the standard discriminator with an auxiliary classifier to classify both real and generated samples as specific classes. \n\nThe paper then discusses the differences between these two approaches and analyzes the loss functions and their corresponding gradients. Label GAN’s loss encourages the generator to assign all probability mass cumulatively across the k-different label classes while the discriminator tries to assign all probability mass to the k+1th output corresponding to a “generated” class. The paper views the generators loss as a form of implicit class target loss.\n\nThis analysis motivates the paper’s proposed extension, called Activation Maximization. It corresponds to a variant of Label GAN where the generator is encouraged to maximize the probability of a specific class for every sample instead of just the cumulative probability assigned to label classes. The proposed approach performs strongly according to inception score on CIFAR-10 and includes additional experiments on Tiny Imagenet to further increase confidence in the results.\n\nA discussion throughout the paper involves dealing with the issue of mode collapse - a problem plaguing standard GAN variants. In particular the paper discusses how variants of class conditioning effect this problem. The paper presents a useful experimental finding - dynamic labeling, where targets are assigned based on whatever the discriminator thinks is the most likely label, helps prevent mode collapse compared to the predefined assignment approach used in AC-GAN / standard class conditioning.\n\nI am unclear how exactly predefined vs dynamic labeling is applied in the case of the Label GAN results in Table 1. The definition of dynamic labeling is specific to the generator as I interpreted it. But Label GAN includes no class specific loss for the generator. I assume it refers to the form of generator - whether it is class conditional or not - even though it would have no explicit loss for the class conditional version. It would be nice if the authors could clarify the details of this setup.\n\nThe paper additionally performs a thorough investigation of the inception score and proposes a new metric the AM score. Through analysis of the behavior of the inception score has been lacking so this is an important contribution as well.\n\nAs a reader, I found this paper to be thorough, honest, and thoughtful. It is a strong contribution to the “class aware” GAN literature.\n', ""\nI thank the authors for the thoughtful responses and updated manuscript. Although the manuscript is improved, I still feel it is unfocused and may be substantially improved, thus my review score remains unchanged.\n\n===============\n\nThe authors describe a new version of a generative adversarial network (GAN) for generating images that is heavily related to class-conditional GAN's. The authors highlight several additional results on evaluation metrics and demonstrate some favorable analyses using their new proposed GAN.\n\nMajor comments:\n1) Unfocused presentation. The paper presents a superfluous and extended background section that needs to be cut down substantially. The authors should aim for a concise presentation of their work in 8 pages. Additionally, the authors present several results (e.g. Section 5.1 on dynamic labeling, Section 6.1 on Inception score) that do not appear to improve the results of the paper, but merely provide commentary. The authors should either defend why these sections are useful or central to the arguments in the paper; otherwise, remove them.\n\n2) Quantitative evaluation highlight small gains. The gains in Table 1 seem to be quite small and additionally there are no error bars so it is hard to assess what is statistically meaningful. Table 2 highlights some error bars but again the gains some quite small. Given that the AM-GAN seems like a small change from an AC-GAN model, I am not convinced there is much gained using this model.\n\n3) MS-SSIM. The authors' discussion of MS-SSIM is fairly confusing. MS-SSIM is a measure of image similarity between a pair of images. However, the authors quote an MS-SSIM for various GAN models in Table 3. What does this number mean?  I suspect the authors are calculating some cumululative statistics across many images, but I was not able to find a description, nor understand what these statistics mean.\n\n4) 'Inception score as a diversity measurement.' This argument is not clear to me. Inception scores can be quite high for an individual image indicating that the image 'looks' like a given class in a discriminative model.  If a generative model always generates a single, good image of a 'dog', then the classification score would be quite high but the generative model would be very poor because the images are not diverse. Hence, I do not see how the inception score captures this property.\n\nIf the authors can address all of these points in a substantive manner, I would consider raising my rating.\n\n""]","[70, 80, -50]","[80, 70, 50]","[""The sentiment score is 70 (positive) because the review begins by listing several pros, uses positive language like 'thorough experiments' and 'sound analysis', and concludes that it is 'a good paper'. There are some cons mentioned, but they are relatively minor. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the authors' honesty and good practices, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. The reviewer also balances critique with praise and ends on a positive note."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'thorough', 'honest', and 'thoughtful', and states it is a 'strong contribution'. They highlight several positive aspects of the paper, including its extensive analysis, useful experimental findings, and important contributions. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their one point of confusion as a request for clarification rather than a criticism. The reviewer's tone is professional and constructive, avoiding harsh or negative language."", ""The sentiment score is -50 because the reviewer expresses that the manuscript is still 'unfocused' and 'may be substantially improved,' with their review score remaining unchanged. This indicates a negative sentiment, though not extremely harsh. The politeness score is 50 because the reviewer begins by thanking the authors for their responses and uses professional language throughout. They provide detailed feedback and suggestions for improvement, which is courteous. However, the tone is not overly warm or exceptionally polite, maintaining a professional distance. The reviewer uses phrases like 'I thank the authors,' 'I still feel,' and 'I would consider raising my rating,' which are polite ways of expressing criticism and expectations.""]"
"['Traditional open-domain QA systems typically have two steps: passage retrieval and aggregating answers extracted from the retrieved passages.  This paper essentially follows the same paradigm, but leverages the state-of-the-art reading comprehension models for answer extraction, and develops the neural network models for the aggregating component.  Although the idea seems incremental, the experimental results do seem solid.  The paper is generally easy to follow, but in several places the presentation can be further improved.\n\nDetailed comments/questions:\n  1. In Sec. 2.2, the justification for adding H^{aq} and \\bar{H}^{aq} is to downweigh the impact of stop word matching.  I feel this is a somewhat indirect and less effective design, if avoiding stop words is really the reason.  A standard preprocessing step may be better.\n  2. In Sec. 2.3, it seems that the final score is just the sum of three individual normalized scores. It\'s not truly a ""weighted"" combination, where the weights are typically assumed to be tuned.\n  3. Figure 3: Connecting the dots in the two subfigures on the right does not make sense.  Bar charts should be used instead.\n  4. The end of Sec. 4.2: I feel it\'s a bad example, as the passage does not really support the answer. The fact that ""Sesame Street"" got picked is probably just because it\'s more famous.\n  5. It\'d be interesting to see how traditional IR answer aggregation methods perform, such as simple classifiers or heuristics by word matching (or weighted by TFIDF) and counting.  This will demonstrates the true advantages of leveraging modern NN models.\n\nPros:\n  1. Updating a traditional open-domain QA approach with neural models\n  2. Experiments demonstrate solid positive results\n\nCons:\n  1. The idea seems incremental\n  2. Presentation could be improved\n', 'The paper is clear, although there are many English mistakes (that should be corrected).\nThe proposed method aggregates answers from multiple passages in the context of QA. The new method is motivated well and departs from prior work. Experiments on three datasets show the proposed method to be notably better than several baselines (although two of the baselines, GA and BiDAF, appear tremendously weak). The analysis of the results is interesting and largely convincing, although a more dedicated error analysis or discussion of the limitation of the proposed approach would be welcome.\n\nMinor point: in the description of Quasar-T, the IR model is described as lucene index. An index is not an IR model. Lucene is an IR system that implements various IR models. The terminology should be corrected here. \n', 'The authors propose an approach where they aggregate, for each candidate answer, text from supporting passages. They make use of two ranking components. A strength-based re-ranker captures how often a candidate answer would be selected while a coverage-based re-ranker aims to estimate the coverage of the question by the supporting passages. Potential answers are extracted using a machine comprehension model. A bi-LSTM model is used to estimate the coverage of the question. A weighted combination of the outputs of both components generates the final ranking (using softmax). \nThis article is really well written and clearly describes the proposed scheme. Their experiments clearly indicate that the combination of the two re-ranking components outperforms raw machine comprehension approaches. The paper also provides an interesting analysis of various design issues. Finally they situate the contribution with respect to some related work pertaining to open domain QA. This paper seems to me like an interesting and significant contribution.\n']","[20, 50, 90]","[60, 75, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the solid experimental results and the paper's readability, despite noting that the idea seems incremental. They mention both pros and cons, but the overall tone leans positive. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They use phrases like 'can be further improved' and 'it'd be interesting to see' which maintain a polite and professional tone. The reviewer also balances critique with positive observations, which contributes to the politeness of the review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's clarity, good motivation, and notable experimental results. However, they also point out several areas for improvement, including English mistakes and the need for more error analysis. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'should be corrected' and 'would be welcome' instead of more demanding language. The reviewer also balances critique with praise, noting the method's strengths alongside areas for improvement."", ""The sentiment score is 90 because the reviewer expresses a very positive view of the paper, calling it 'really well written,' praising its clear description and experiments, and concluding that it's 'an interesting and significant contribution.' The politeness score is 80 because the language used is consistently respectful and professional, with no negative or critical comments. The reviewer uses phrases like 'clearly describes,' 'clearly indicate,' and 'interesting analysis,' which convey a polite and constructive tone throughout the review.""]"
"['This paper studies the problem of one-shot and few-shot learning using the Graph Neural Network (GNN) architecture that has been proposed and simplified by several authors. The data points form the nodes of the graph with the edge weights being learned, using ideas similar to message passing algorithms similar to Kearnes et al and Gilmer et al. This method generalizes several existing approaches for few-shot learning including Siamese networks, Prototypical networks and Matching networks. The authors also conduct experiments on the Omniglot and mini-Imagenet data sets, improving on the state of the art.\n\nThere are a few typos and the presentation of the paper could be improved and polished more. I would also encourage the authors to compare their work to other unrelated approaches such as Attentive Recurrent Comparators of Shyam et al, and the Learning to Remember Rare Events approach of Kaiser et al, both of which achieve comparable performance on Omniglot. I would also be interested in seeing whether the approach of the authors can be used to improve real world translation tasks such as GNMT. ', ""This paper introduces a graph neural net approach to few-shot learning. Input examples form the nodes of the graph and edge weights are computed as a nonlinear function of the absolute difference between node features. In addition to standard supervised few-shot classification, both semi-supervised and active learning task variants are introduced. The proposed approach captures several popular few-shot learning approaches as special cases. Experiments are conducted on both Omniglot and miniImagenet datasets.\n\nStrengths\n- Use of graph neural nets for few-shot learning is novel.\n- Introduces novel semi-supervised and active learning variants of few-shot classification.\n\nWeaknesses\n- Improvement in accuracy is small relative to previous work.\n- Writing seems to be rushed.\n\nThe originality of applying graph neural networks to the problem of few-shot learning and proposing semi-supervised and active learning variants of the task are the primary strengths of this paper. Graph neural nets seem to be a more natural way of representing sets of items, as opposed to previous approaches that rely on a random ordering of the labeled set, such as the FCE variant of Matching Networks or TCML. Others will likely leverage graph neural net ideas to further tackle few-shot learning problems in the future, and this paper represents a first step in that direction.\n\nRegarding the graph, I am wondering if the authors can comment on what scenarios is the graph structure expected to help? In the case of 1-shot, the graph can only propagate information about other classes, which seems to not be very useful.\n\nThough novel, the motivation behind the semi-supervised and active learning setup could use some elaboration. By including unlabeled examples in an episode, it is already known that they belong to one of the K classes. How realistic is this set-up and in what application is it expected that this will show up?\n\nFor active learning, the proposed method seems to be specific to the case of obtaining a single label. How can the proposed method be scaled to handle multiple requested labels?\n\nOverall the paper is well-structured and related work covers the relevant papers, but the details of the paper seem hastily written.\n\nIn the problem set-up section, it is not immediately clear what the distinction between s, r, and t is. Stating more explicitly that s is for the labeled data, etc. would make this section easier to follow. In addition, I would suggest stating the reason why t=1 is a necessary assumption for the proposed model in the few-shot and semi-supervised cases.\n\nRegarding the Omniglot dataset, Vinyals et al. (2016) augmented the classes so that 4,800 classes were used for training and 1,692 for test. Was the same procedure done for the experiments in the paper? If yes, please update 6.1.1 to make this distinction more clear. If not, please update the experiments to be consistent with the baselines.\n\nIn the experiments, does the \\varphi MLP explicitly enforce symmetry and identity or is it learned?\n\nRegarding the Omniglot baselines, it appears that Koch et al. (2015), Edwards & Storkey (2016), and Finn et al. (2017) use non-standard class splits relative to the other methods. This should probably be noted.\n\nThe results for Prototypical Networks appear to be incorrect in the Omniglot and Mini-Imagenet tables. According to Snell et al. (2017) they should be 49.4% and 68.2% for miniImagenet. Moreover, Snell et al. (2017) only used 64 classes for training instead of 80 as utilized in the proposed approach. Given this, I am wondering if the authors can comment on the performance difference in the 5-shot case, even though Prototypical Networks is a special case of GNNs?\n\nFor semi-supervised and active-learning results, please include error bars for the miniImagenet results. Also, it would be interesting to see 20-way results for Omniglot as the gap between the proposed method and the baseline would potentially be wider.\n\nOther Comments:\n\n- In Section 4.2, Gc(.) is defined in Equation 2 but not mentioned in the text.\n- In Section 4.3, adding an equation to clarify the relationship with Matching Networks would be helpful.\n- I believe there is a typo in section 4.3 in that softmax(\\varphi) should be softmax(-\\varphi), so that more similar pairs will be more heavily weighted.\n- The equation in 5.1 appears to be missing a minus sign.\n\nOverall, the paper is novel and interesting, though the clarity and experimental results could be better explained.\n\nEDIT: I have read the author's response. The writing is improved and my concerns have largely been addressed. I am therefore revising my rating of the paper to a 7."", ""This paper proposes to use graph neural networks for the purpose of few-shot learning, as well as semi-supervised learning and active learning. The paper first relies on convolutional neural networks to extract image features. Then, these image features are organized in a fully connected graph. Then, this graph is processed with an graph neural network framework that relies on modelling the differences between features maps, \\propto \\phi(abs(x_i-x_j)).  For few-shot classification then the cross-entropy classification loss is used on the node.\n\nThe paper has some interesting contributions and ideas, mainly from the point of view of applications, since the basic components (convnets, graph neural networks) are roughly similar to what is already proposed. However, the novelty is hurt by the lack of clarity with respect to the model design.\n\nFirst, as explained in 5.1 a fully connected graph is used (although in Fig. 2 the graph nodes do not have connections to all other nodes). If all nodes are connected to all nodes, what is the different of this model from a fully connected, multi-stream networks composed of S^2 branches? To rephrase, what is the benefit of having a graph structure when all nodes are connected with all nodes. Besides, what is the effect when having more and more support images? Is the generalization hurt?\n\nSecond, it is not clear whether the label used as input in eq. (4) is a model choice or a model requirement. The reason is that the label already appears in the loss of the nodes  in 5.1. Isn't using the label also as input redundant?\n\nThird, the paper is rather vague or imprecise at points.  In eq. (1) many of the notations remain rather unclear until later in the text (and even then they are not entirely clear). For instance, what is s, r, t. \n\nThe experimental section is also ok, although not perfect.  The proposed method appears to have a modest improvement for few-shot learning. However, in the case of  active learning and semi-supervised learning the method is not compared to any baselines (other than the random one), which makes conclusions hard to reach.\n\nIn general, I tend to be in favor of accepting the paper if the authors have persuasive answers and provide the clarifications required.""]","[70, 50, 20]","[60, 75, 60]","[""The sentiment score is 70 (positive) because the reviewer praises the paper's contribution to the field, noting that it 'improves on the state of the art' and 'generalizes several existing approaches'. The overall tone is supportive and encouraging. However, it's not a perfect score as the reviewer does point out some areas for improvement. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticism. Phrases like 'I would encourage the authors' and 'I would be interested in seeing' demonstrate a collegial tone. The reviewer also balances positive comments with areas for improvement in a tactful manner. The score isn't higher because the review is primarily focused on the content rather than being overtly polite."", 'The sentiment score is 50 (slightly positive) because the reviewer acknowledges strengths of the paper such as novelty and interesting approach, while also pointing out weaknesses and areas for improvement. The overall tone is constructive rather than overly critical or enthusiastic. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions rather than direct attacks, and ends on a positive note. The reviewer also acknowledges improvements made in response to their feedback, showing a collaborative attitude.', ""The sentiment score is slightly positive (20) because the reviewer acknowledges 'interesting contributions and ideas' and is 'in favor of accepting the paper' with some clarifications. However, they also point out several issues and areas needing improvement, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their concerns as questions or requests for clarification rather than direct criticisms. They also end on a positive note, indicating willingness to accept the paper with appropriate revisions.""]"
"['The paper proposes action-dependent baselines for reducing variance in policy gradient, through the derivation based on Stein’s identity and control functionals. The method relates closely to prior work on action-dependent baselines, but explores in particular on-policy fitting and a few other design choices that empirically improve the performance. \n\nA criticism of the paper is that it does not require Stein’s identity/control functionals literature to derive Eq. 8, since it can be derived similarly to linear control variate and it has also previously been discussed in IPG [Gu et. al., 2017] as reparameterizable control variate. The derivation through Stein’s identity does not seem to provide additional insights/algorithm designs beyond direct derivation through reparameterization trick.\n\nThe empirical results appear promising, and in particular in comparison with Q-Prop, which fits Q-function using off-policy TD learning. However, the discussion on the causes of the difference should be elaborated much more, as it appears there are substantial differences besides on-policy/off-policy fitting of the Q, such as:\n\n-FitLinear fits linear Q (through parameterization based on linearization of Q) using on-policy learning, rather than fitting nonlinear Q and then at application time linearize around the mean action. A closer comparison would be to use same locally linear Q function for off-policy learning in Q-Prop.\n\n-The use of on-policy fitted value baseline within Q-function parameterization during on-policy fitting is nice. Similar comparison should be done with off-policy fitting in Q-Prop.\n\nI wonder if on-policy fitting of Q can be elaborated more. Specifically, on-policy fitting of V seems to require a few design details to have best performance [GAE, Schulman et. al., 2016]: fitting on previous batch instead of current batch to avoid overfitting  (this is expected for your method as well, since by fitting to current batch the control variate then depends nontrivially on samples that are being applied), and possible use of trust-region regularization to prevent V from changing too much across iterations. \n\nThe paper presents promising results with direct on-policy fitting of action-dependent baseline, which is promising since it does not require long training iterations as in off-policy fitting in Q-Prop. As discussed above, it is encouraged to elaborate other potential causes that led to performance differences. The experimental results are presented well for a range of Mujoco tasks. \n\nPros:\n\n-Simple, effective method that appears readily available to be incorporated to any on-policy PG methods without significantly increase in computational time\n\n-Good empirical evaluation\n\nCons:\n\n-The name Stein control variate seems misleading since the algorithm/method does not rely on derivation through Stein’s identity etc. and does not inherit novel insights due to this derivation.\n', 'In this work, the authors suggest the use of control variate schemes for estimating gradient values, within a reinforcement learning  framework. The authors also introduce a specific control variate technique based on the so-called Stein’s identity. The paper is interesting and well-written.\n\nI have some question and some consideration that can be useful for improving the appealing of the paper.\n\n- I believe that different Monte Carlo (or Quasi-Monte Carlo) strategies can be applied in order to estimate the integral (expected value) in Eq. (1), as also suggested in this work. Are there other alternatives in the literature? Please, please discuss and cite some papers if required.  \n\n- I suggest to divide Section 3.1 in two subsections. The first one introducing Stein’s identity and the related comments that you need, and a second one, starting after Theorem 3.1, with title “Stein Control Variate”.\n\n-  Please also discuss the relationships, connections, and possible applications of your technique to other algorithms used in Bayesian optimization, active learning and/or sequential learning, for instance as\n\nM. U. Gutmann and J. Corander, “Bayesian optimization for likelihood-free inference of simulator-based statistical mod- els,” Journal of Machine Learning Research, vol. 16, pp. 4256– 4302, 2015. \n\nG. da Silva Ferreira and D. Gamerman, “Optimal design in geostatistics under preferential sampling,” Bayesian Analysis, vol. 10, no. 3, pp. 711–735, 2015. \n\nL. Martino, J. Vicent, G. Camps-Valls, ""Automatic Emulator and Optimized Look-up Table Generation for Radiative Transfer Models"", IEEE International Geoscience and Remote Sensing Symposium (IGARSS), 2017.\n\n-  Please also discuss the dependence of your algorithm with respect to the starting baseline function \\phi_0.', ""This paper proposed a class of control variate methods based on Stein's identity. Stein's identity has been widely used in classical statistics and recently in statistical machine learning literature. Nevertheless, applying Stein's identity to estimating policy gradient is a novel approach in reinforcement learning community. To me, this approach is the right way of constructing control variates for estimating policy gradient. The authors also did a good job in connecting with existing works and gave concrete examples for Gaussian policies. The experimental results also look promising.\n\nIt would be nice to include some theoretical analyses like under what conditions, the proposed method can achieve smaller sample complexity than existing works.    \n\nOverall this is a strong paper and I recommend to accept.\n \n\n\n""]","[50, 60, 90]","[70, 80, 80]","[""The sentiment score is 50 (slightly positive) because while the reviewer acknowledges the paper's promising results and good empirical evaluation, they also raise several criticisms and areas for improvement. The review begins with a positive tone, highlighting the paper's contributions, but then moves on to discuss limitations and suggestions for enhancement. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'I wonder if...' and 'it is encouraged to...' which maintain a collegial tone. The reviewer also balances critique with praise, noting both 'Pros' and 'Cons' at the end, which contributes to the overall polite and professional tone of the review."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as 'interesting and well-written', which indicates a generally positive view. However, it's not extremely high as the reviewer also has several questions and suggestions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, such as 'I believe', 'I suggest', and 'Please discuss'. The reviewer also frames their comments as suggestions rather than demands, and acknowledges the paper's strengths before offering critiques. The use of 'please' twice in one sentence further emphasizes the polite tone. The review maintains a constructive and collegial tone throughout, without any harsh or dismissive language."", ""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer describes the paper as 'strong' and recommends acceptance. They praise the novelty of the approach, the authors' connection to existing work, and the promising experimental results. The only slight criticism is a suggestion for additional theoretical analyses, which doesn't significantly detract from the overall positive sentiment. The politeness score is 80 because the language used is consistently respectful and constructive. The reviewer uses phrases like 'good job' and 'it would be nice to include,' which are polite ways of offering praise and suggestions. The tone is professional and courteous throughout, without any harsh or rude language.""]"
"['The paper presents a new approach to generate adversarial attacks to a neural network, and subsequently present a method to defend a neural network from those attacks. I am not familiar with other adversarial attack strategies aside from the ones mentioned in this paper, and therefore I cannot properly assess how innovative the method is.\n\nMy comments are the following:\n\n1- I would like to know if benign examples are just regular examples or some short of simple way of computing adversarial attacks.\n\n2- I think the authors should provide a more detailed and formal description of the OPTMARGIN method. In section 3.2 they explain that ""Our attack uses existing optimization attack techniques to..."", but one should be able to understand the method without reading further references. Specially a formal representation of the method should be included.\n\n3- Authors mention that OPTSTRONG attack does not succeed in finding adversarial examples (""it succeeds on 28% of the samples on MNIST;73% on CIFAR-10""). What is the meaning of success rate in here? Is it the % of times that the classifier is confused?\n\n4- OPTSTRONG produces images that are notably more distorted than OPTBRITTLE (by RMS and also visually in the case of MNIST). So I actually cannot tell which method is better, at least in the MNIST experiment. One could do a method that completely distort the image and therefore will be classified with as a class. But adversarial images should be visually undistinguishable from original images. Generated CIFAR images seem similar than the originals, although CIFAR images are very low resolution, so judging this is hard.\n\n4- As a side note, it would be interesting to have an explanation about why region classification is providing a worse accuracy than point classification for CIFAR-10 benign samples.\n\nAs a summary, the authors presented a method that successfully attacks other existing defense methods, and present a method that can successfully defend this attack. I would like to see more formal definitions of the methods presented. Also, just by looking at RMS it is expected that this method works better than OPTBRITTLE, since the images are more distorted. It would be needed to have a way of visually evaluate the similarity between original images and generated images.', 'Summary of paper:\n\nThe authors present a novel attack for generating adversarial examples, deemed OptMargin, in which the authors attack an ensemble of classifiers created by classifying at random L2 small perturbations. They compare this optimization method with two baselines in MNIST and CIFAR, and provide an analysis of the decision boundaries by their adversarial examples, the baselines and non-altered examples. \n\nReview summary:\n\nI think this paper is interesting. The novelty of the attack is a bit dim, since it seems it\'s just the straightforward attack against the region cls defense. The authors fail to include the most standard baseline attack, namely FSGM. The authors also miss the most standard defense, training with adversarial examples. As well, the considered attacks are in L2 norm, and the distortion is measured in L2, while the defenses measure distortion in L_\\infty (see detailed comments for the significance of this if considering white-box defenses). The provided analysis is insightful, though the authors mostly fail to explain how this analysis could provide further work with means to create new defenses or attacks.\n\nIf the authors add FSGM to the batch of experiments (especially section 4.1) and address some of the objections I will consider updating my score.\n\nA more detailed review follows.\n\n\nDetailed comments:\n\n- I think the novelty of the attack is not very strong. The authors essentially develop an attack targeted to the region cls defense. Designing an attack for a specific defense is very well established in the literature, and the fact that the attack fools this specific defense is not surprising.\n\n- I think the authors should make a claim on whether their proposed attack works only for defenses that are agnostic to the attack (such as PGD or region based), or for defenses that know this is a likely attack (see the following comment as well). If the authors want to make the second claim, training the network with adversarial examples coming from OptMargin is missing.\n\n- The attacks are all based in L2, in the sense that the look for they measure perturbation in an L2 sense (as the paper evaluation does), while the defenses are all L_\\infty based (since the region classifier method samples from a hypercube, and PGD uses an L_\\infty perturbation limit). This is very problematic if the authors want to make claims about their attack being effective under defenses that know OptMargin is a possible attack.\n\n- The simplest most standard baseline of all (FSGM) is missing. This is important to compare properly with previous work.\n\n- The fact that the attack OptMargin is based in L2 perturbations makes it very susceptible to a defense that backprops through the attack. This and / or the defense of training to adversarial examples is an important experiment to assessing the limitations of the attack. \n\n- I think the authors rush to conclude that ""a small ball around a given input distance can be misleading"". Wether balls are in L2 or L_\\infty, or another norm makes a big difference in defense and attacks, given that they are only equivalent to a multiplicative factor of sqrt(d) where d is the dimension of the space, and we are dealing with very high dimensional problems. I find the analysis made by the authors to be very simplistic.\n\n- The analysis of section 4.1 is interesting, it was insightful and to the best of my knowledge novel. Again I would ask the authors to make these plots for FSGM. Since FSGM is known to be robust to small random perturbations, I would be surprised that for a majority of random directions, the adversarial examples are brought back to the original class.\n\n- I think a bit more analysis is needed in section 4.2. Do the authors think that this distinguishability can lead to a defense that uses these statistics? If so, how?\n\n- I think the analysis of section 5 is fairly trivial. Distinguishability in high dimensions is an easy problem (as any GAN experiment confirms, see for example Arjovsky & Bottou, ICLR 2017), so it\'s not surprising or particularly insightful that one can train a classifier to easily recognize the boundaries.\n\n- Will the authors release code to reproduce all their experiments and methods?\n\nMinor comments:\n- The justification of why OptStrong is missing from Table2 (last three sentences of 3.3) should be summarized in the caption of table 2 (even just pointing to the text), otherwise a first reader will mistake this for the omission of a baseline.\n\n- I think it\'s important to state in table 1 what is the amount of distortion noticeable by a human.\n\n=========================================\n\nAfter the rebuttal I\'ve updated my score, due to the addition of FSGM added as a baseline and a few clarifications. I now understand more the claims of the paper, and their experiments towards them. I still think the novelty, significance of the claims and protocol are still perhaps borderline for publication (though I\'m leaning towards acceptance), but I don\'t have a really high amount of experience in the field of adversarial examples in order to make my review with high confidence.', 'Compared to previous studies, this paper mainly claims that the information from larger neighborhoods (more directions or larger distances) will better characterize the relationship between adversarial examples and the DNN model.\n\nThe idea of employing ensemble of classifiers is smart and effective. I am curious about the efficiency of the method.\n\nThe experimental study is extensive. Results are well discussed with reasonable observations. In addition to examining the effectiveness, authors also performed experiments to explain why OPTMARGIN is superior. Authors are suggested to involve more datasets to validate the effectiveness of the proposed method.\n\nTable 5 is not very clear. Authors are suggested to discuss in more detail.\n']","[20, -20, 60]","[60, 50, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's successful approach in attacking existing defense methods and presenting a new defense method. However, they also express several concerns and requests for clarification, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions, and provides a balanced summary. They use phrases like 'I would like to know' and 'I think the authors should' which are polite ways of requesting more information or suggesting improvements. The reviewer also acknowledges their own limitations ('I am not familiar with...') which adds to the polite tone. The review is constructive and focused on improving the paper rather than being overly critical."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper 'interesting' and some analysis 'insightful', they express several criticisms and concerns about the novelty, methodology, and missing baselines. The reviewer suggests major additions and changes before considering updating their score. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'I think' and 'I would ask the authors to' which maintain a respectful tone. The reviewer also acknowledges when their expertise may be limited, showing humility."", ""The sentiment score is 60 (positive) because the reviewer expresses appreciation for the paper's ideas, calling them 'smart and effective', and notes the 'extensive' experimental study with 'well discussed' results. However, it's not extremely positive as there are suggestions for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than criticisms. Phrases like 'Authors are suggested to' indicate a polite tone. The review maintains a professional and courteous demeanor while providing both positive feedback and areas for improvement.""]"
"['Overall, the idea of this paper is simple but interesting. Via weighted mean NLL over retrieved neighbors, one can update parameters of output network for a given query input. The MAP interpretation provides a flexible Bayesian explanation about this MbPA.\n\nThe paper is written well, and the proposed method is evaluated on a number of relevant applications (e.g., continuing learning, incremental learning, unbalanced data, and domain shifts.)\n\nHere are some comments:\n1 MbPA is built upon memory. How large should it be? Is it efficient to retrieve neighbors for a given query?\n2 For each test, how many steps of MbPA do we need in general? Furthermore, it is a bit unfair for me to retrain deep model, based on test inputs. It seems that, you are implicitly using test data to fit model.\n', 'This paper proposes a non-parametric episodic memory that can be used for the rapid acquisition of new knowledge while preserving the old ones. More specially, it locally adapts the parameters of a network using the episodic memory structure. \n\nStrength:\n+   The paper works on a relevant and interesting problem.\n+   The experiment sections are very thorough and I like the fact that the authors selected different tasks to compare their models with. \n+ The paper is well-written except for sections 2 and 3. \nWeakness and Questions:\n-    Even though the paper addresses the interesting and challenging problem of slow adaption when distribution shifts, their episodic memory is quite similar (if not same as) to the Pritzel et al., 2017. \n- In addition, as the author mentioned in the text, their model is also similar to the Kirkpatrick et al., 2017,  Finn et al., 2017, Krause et al., 2017. That would be great if the author can list ""explicitly"" the contribution of the paper with comparing with those. Right now, the text mentioned some of the similarity but it spreads across different sections and parts. \n- The proposed model does adaption during the test time, but other papers such as Li & Hoiem, 2016 handles the shift across domain in the train time. Can authors say sth about the motivation behind adaptation during test time vs. training time? \n- There are some inconsistencies in the text about the parameters and formulations:\n      -- what is second subscript in {v_i}_i? (page 2, 3rd paragraph)\n      -- in Equation 4, what is the difference between x_c and x?\n      -- What happened to $x$ in Eq 5?\n      -- The ""−"" in Eq. 7 doesn\'t make sense. \n- Section 2.2, after equation 7, the text is not that clear.\n- Paper is well beyond the 8-page limit and should be fitted to be 8 pages.\n- In order to make the experiments reproducible, the paper needs to contain full details (in the appendix) about the setup and hyperparameters of the experiments.   \n\nOthers:\nDo the authors plan to release the codes?\n\n\n------------------------------------\n------------------------------------\nUpdate after rebuttal:\nThanks for the revised version and answering my concerns.  \nIn the revised version, the writing has been improved and the contribution of the paper is more obvious. \nGiven the authors\' responses and the changes, I have increased my review score.\n\nA couple of comments and questions:\n1. Can you explain how/why $x_c$ is replaced by $h_k$ in eq_7? \n2. In the same equation (7), how $\\log p(v_k| h_k,\\theta_x, x)$ will be calculated? I have some intuition but not sure.  Can you please explain?\n3. in equation(8), what happened to $x$ in log p(..)?\n4. How figure 2 is plotted? based on a real experiment? if yes, what was the setting? if not, how?\n5. It\'d be very useful to the community if the authors decide to release their codes. \n\n', 'This article introduces a new method to improve neural network performances on tasks ranging from continual learning (non-stationary target distribution, appearance of new classes, adaptation to new tasks, etc) to better handling of class imbalance, via a hybrid architecture between nearest neighbours and neural net.\nAfter an introduction summarizing their goal, the authors introduce their Model-based parameter adaptation: this hybrid architecture enriches classical deep architectures with a non-parametric “episodic” memory, which is filled at training time with (possibly learned) encodings of training examples and then polled at inference time to refine the neural network parameters with a few steps of gradient in a direction determined by the closest neighbours in memory to the input being processed.  The authors justify this inference-time SGD update with three different interpretations: one linked in Maximum A Posteriori optimization, another to Elastic Weight Regularisation (the current state of the art in continual learning), and one generalising attention mechanisms (although to be honest that later was more elusive to this reviewer). The mandatory literature review on the abundant recent uses of memory in neural networks is then followed by experiments on continual learning tasks involving permuted MNIST tasks, ImageNET incremental inclusion of classes, ImageNet unbalanced, and two language modeling tasks. \n\nThis is an overall very interesting idea, which has the merit of being rather simple in its execution and can be combined with many other methods: it is fully compatible with any optimiser (e.g. ADAM) and can be tacked on top of EWC (which the authors do). The justification is clear, the examples reasonably thorough. It is a very solid paper, which this reviewer believes to be of real interest to the ICLR community.\n\n\nThe following important clarifications from the authors could make it even better:\n*  Algorithm 1 in its current form seems to imply an infinite memory, which the experiments make clear is not the case. Therefore: how does the algorithm decide what entries to discard when the memory fills up?\n* In most non-trivial settings, the parameter $gamma$ of the encoding is learned, and therefore older entries in the memory lose any ability to be compared to more recent encodings. How do the authors handle this obsolescence of the memory, other than the trivial scheme of relying on KNN to only match recent entries?\n* Because gamma needs to be “recent”, this means “theta” is also recent: could the authors give a good intuition on how the two sets of parameters can evolve at different enough timescales to really make the episodic memory relevant? Is it anything else than relying on the fact that the lower levels of a neural net converge before the upper levels?\n* Table 1:  could the authors explain why the pre-trained Parametric (and then Mixture) models have the best  AUC in the low-data regime, whereas MbPA was designed very much to be superior in such regimes?\n* Paragraph below equation (5), page 3: why not including the regularisation term, whereas the authors just went to great pain to explain it? Rationale? Not including it is also akin to using an improper non-information prior on theta^x independent of theta, which is quite a strong choice to be made “by default”.\n* The extra complexity of choosing the learning rate alpha_M and the number of  MpAB steps is worrying this reviewer somewhat. In practice, in Section 4.1the authors explain using grid search to tune the parameters. Is this reviewer correct in understanding that this search is done across all tasks, as opposed to only the first task? And if so, doesn’t this grid search introduce an information leak by bringing information from the whole pre-determined set of task, therefore undermining the very “continuous learning” aim? How do the algorithm performs if the grid search is done only on the first task?\n* Figure 3:  the text could clarify that the accuracy is measured across all tasks seen so far. It would be interesting to add a figure (in the Appendix) showing the evolution of the accuracy *per task*, not just the aggregated accuracy. \n* In the related works linking neural networks to encoded episodic memory, the authors might want to include the stream of research on HMAX of Anselmi et al 2014 (https://arxiv.org/pdf/1311.4158.pdf) , Leibo et al 2015 (https://arxiv.org/abs/1512.08457), and Blundell et al 2016 (https://arxiv.org/pdf/1606.04460.pdf ).\n\nMinor typos:\n* Figure 4: the title of the key says “New/Old” but then the lines read, in order, “Old” then “New” -- it would be nicer to have them in the same order.\n* Section 5: missing period between ""ephemeral gradient modifications"" and ""Further"".\n* Section 4.2, parenthesis should be ""perform well across all 1000 classes"", not ""all 100 classes"".\n \nWith the above clarifications, this article could become a very remarked contribution.\n']","[60, 20, 80]","[80, 60, 90]","[""The sentiment score is 60 (positive) because the reviewer starts by stating the paper's idea is 'simple but interesting' and mentions that it is 'written well' and evaluated on relevant applications. This indicates a generally positive view, though not overwhelmingly enthusiastic. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive comments. The phrase 'Here are some comments:' introduces critiques in a non-confrontational way. The reviewer also uses phrases like 'a bit unfair for me' when expressing concerns, which shows consideration for the authors' perspective."", 'The sentiment score is slightly positive (20) because the reviewer acknowledges strengths of the paper, such as addressing a relevant problem and having thorough experiments. However, they also point out several weaknesses and areas for improvement, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases their concerns as questions or suggestions rather than harsh criticisms. They also thank the authors for their revisions and increased their review score after the rebuttal, showing a willingness to reconsider their initial assessment. The reviewer maintains a professional and courteous tone while providing detailed feedback.', ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'very interesting', 'solid', and 'of real interest to the ICLR community'. They also state that with clarifications, it 'could become a very remarked contribution'. The overall tone is highly supportive and encouraging. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames their suggestions as ways to make an already good paper even better. They use phrases like 'could make it even better' and 'The following important clarifications' which are polite ways of offering criticism. The reviewer also acknowledges the authors' efforts and the merit of their work. The only reason it's not 100 is that there's room for even more explicit praise or courtesy, but the tone is consistently professional and respectful.""]"
"['Quality: The paper presents a novel solution to an incremental classification problem based on a dual memory system. The proposed solution is inspired by the memory storage mechanism in brain.\n\nClarity: The problem has been clearly described and the proposed solution is described in detail. The results of numerical experiments and the real data analysis are satisfactory and clearly shows the superior performance of the method compared to the existing ones.\n\nOriginality: The solution proposed is a novel one based on a dual memory system inspired by the memory storage mechanism in brain. The memory consolidation is inspired by the mechanisms that occur during sleep. The numerical experiments showing the FearNet performance with sleep frequency also validate the comparison with the brain memory system.\n\nSignificance: The work discusses a significant problem of incremental classification. Many of the shelf deep neural net methods require storage of previous training samples too and that slows up the application to larger dataset. Further the traditional deep neural net also suffers from the catastrophic forgetting. Hence, the proposed work provides a novel and scalable solution to the existing problem.\n\npros: (a) a scalable solution to the incremental classification problem using a brain inspired dual memory system\n          (b) mitigates the catastrophic forgetting problem using a memory consolidation by pseudorehearsal.\n          (c) introduction of a subsystem that allows which memory system to use for the classification\n\ncons: (a)  How FearNet would perform if imbalanced classes are seen in more than one study sessions?\n          (b) Storage of class statistics during pseudo rehearsal could be computationally expensive. How to cope with that?\n          (c) How FearNet would handle if there are multiple data sources?', '\nThis paper addresses the problem of incremental class learning with brain inspired memory system. This relies on 1/ hippocampus like system relying on a temporary memory storage and probabilistic neural network classifier, 2/ a prefrontal cortex-like ladder network architecture, performing joint autoencoding and classification, 3/ an amygdala-like classifier that combines the decision of both structures. The experiments suggests that the approach performs better than state-of-the-art incremental learning approaches, and approaches offline learning.\nThe paper is well written. The main issue I have with the approach is the role of the number of examples stored in hippocampus and its implication for the comparison to state-of-the art approaches.\nComments:\nIt seems surprising to me that the network manages to outperform other approaches using such a simplistic network for hippocampus (essentially a Euclidian distance based classifier). I assume that the great performance is due to the fact that a lot of examples per classes are stored in hippocampus. I could not find an investigation of the effect of this number on the performance. I assume this number corresponds to the mini-batch size (450). I would like that the authors elaborate on how fair is the comparison to methods such as iCaRL, which store very little examples per classes according to Fig. 2. I assume the comparison must take into account the fact that FearNet stores permanently relatively large covariance matrices for each classes.\nOverall, the hippocampus structure is the weakness of the approach, as it is so simple that I would assume it cannot adapt well to increasingly complex tasks. Also, making an analogy with hippocampus for such architecture seems a bit exaggerated.\n', 'I quite liked the revival of the dual memory system ideas and the cognitive (neuro) science inspiration. The paper is overall well written and tackles serious modern datasets, which was impressive, even though it relies on a pre-trained, fixed ResNet (see point below).\n\nMy only complaint is that I felt I couldn’t understand why the model worked so well. A better motivation for some of the modelling decisions would be helpful. For instance, how much the existence (and training) of a BLA network really help — which is a central new part of the paper, and wasn’t in my view well motivated. It would be nice to compare with a simpler baseline, such as a HC classifier network with reject option. I also don’t really understand why the proposed pseudorehearsal works so well. Some formal reasoning, even if approximate, would be appreciated.\n\nSome additional comments below:\n\n- Although the paper is in general well written, it falls on the lengthy side and I found it difficult at first to understand the flow of the algorithm. I think it would be helpful to have a high-level pseudocode presentation of the main steps.\n\n- It was somewhat buried in the details that the model actually starts with a fixed, advanced feature pre-processing stage (the ResNet, trained on a distinct dataset, as it should). I’m fine with that, but this should be discussed. Note that there is evidence that the neuronal responses in areas as early as V1 change as monkeys learn to solve discrimination tasks. It should be stressed that the model does not yet model end-to-end learning in the incremental setting.\n\n- p. 4, Eq. 4, is it really necessary to add a loss for the intermediate layers, and not only for the input layer? I think it would be clearer to define the \\mathcal{L} explictily somewhere. Also, shouldn’t the sum start at j=0?']","[80, 20, 50]","[50, 60, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, highlighting its novelty, clarity, and significance. They use positive phrases like 'novel solution', 'clearly described', 'superior performance', and 'provides a novel and scalable solution'. The cons mentioned are phrased as questions for improvement rather than criticisms. The politeness score is 50 (somewhat polite) because while the reviewer maintains a professional and respectful tone throughout, they don't use overtly polite language. The review is straightforward and focused on the paper's content without personal comments or excessive courtesy, but also without any rudeness or harsh criticism."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's good writing and its performance improvements over state-of-the-art approaches. However, they express concerns about the role of the hippocampus-like system and the fairness of comparisons, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'I assume' and 'I would like' when making suggestions, which maintains a polite tone. The reviewer also provides constructive feedback and specific areas for improvement without using harsh or dismissive language."", ""The sentiment score is 50 (slightly positive) because the reviewer starts with positive comments about liking the revival of ideas and the paper being well-written and impressive. However, they also express some complaints and areas for improvement, balancing out the overall sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'It would be nice to...', 'I think it would be helpful...'), and acknowledges the paper's strengths before offering suggestions. The reviewer maintains a professional and courteous tone, even when pointing out areas for improvement.""]"
"['This paper presents a fully differentiable neural architecture for mapping and path planning for navigation in previously unseen environments, assuming near perfect* relative localization provided by velocity. The model is more general than the cognitive maps (Gupta et al, 2017) and builds on the NTM/DNC or related architectures (Graves et al, 2014, 2016, Rae et al, 2017) thanks to the 2D spatial structure of the associative memory. Basically, it consists of a 2D-indexed grid of features (the map) M_t that can be summarized at each time point into read vector r_t, and used for extracting a context c_t for the current agent state s_t, compute (thanks to an LSTM/GRU) an updated write vector w_{t+1}^{x,y} at the current position and update the map using that write vector. The position {x,y} is a binned representation of discrete or continuous coordinates. The absolute coordinate map can be replaced by a relative ego-centric map that is shifted (just like in Gupta et al, 2017) as the agent moves.\n\nThe experiments are exhaustive and include remembering the goal location with or without cues (similarly to Mirowski et al, 2017, not cited) in simple mazes of size 4x4 up to 8x8 in the 3D Doom environment. The most important aspect is the capability to build a feature map of previously unseen environments.\n\nThis paper, showing excellent and important work, has already been published on arXiv 9 months ago and widely cited. It has been improved since, through different sets of experiments and apparently a clearer presentation, but the ideas are the same. I wonder how it is possible that the paper has not been accepted at ICML or NIPS (assuming that it was actually submitted there). What are the motivations of the reviewers who rejected the paper - are they trying to slow down competing research, or are they ignorant, and is the peer review system broken? I quite like the formulation of the NIPS ratings: ""if this paper does not get accepted, I am considering boycotting the conference"".\n\n* The noise model experiment in Appendix D is commendable, but the noise model is somewhat unrealistic (very small variance, zero mean Gaussian) and assumes only drift in x and y, not along the orientation. While this makes sense in grid world environments or rectilinear mazes, it does not correspond to realistic robotic navigation scenarios with wheel skid, missing measurements, etc... Perhaps showing examples of trajectories with drift added would help convince the reader (there is no space restriction in the appendix).', ""The paper introduces a new memory mechanism specifically tailored for agent navigation in 2D environments. The memory consists of a 2D array and includes trainable read/write mechanisms. The RL agent's policy is a function of the context read, read, and next step write vectors (which are functions of the observation). The effectiveness of the proposed architecture is evaluated via reinforcement learning (% of mazes solved). The evaluation included 1000 test mazes--which sets a good precedent for evaluation in this subfield. \n\nMy main concern is the lack of experiments to test whether the agent really learned to localize and plan routes using it's memory architecture. The downsampling experiment in Section 5.1 seems to indicate the contrary: downsampling the memory should lead to position aliasing which seems to indicate that the agent is not using its memory to store the map and its own location. I'm concerned whether the proposed agent is actually employing a navigation strategy, as seems to be suggested, or is simply a good agent architecture for this task (e.g. for optimization reasons). The short experiment in Appendix E seems to try and answer this question, but it's results are anecdotal at best. \n\nIf good RL performance on navigation tasks is the ultimate goal then one can imagine an agent that directly copies the raw map observation (world centric) into memory and use something like a value iteration network or shortest path planning to plan routes. My point is that there are classical algorithms to solve navigation even in partially observable 2D grid worlds, why bother with deep RL here? "", '# Summary\nThis paper presents a new external-memory-based neural network (Neural Map) for handling partial observability in reinforcement learning. The proposed memory architecture is spatially-structured so that the agent can read/write from/to specific positions in the memory. The results on several memory-related tasks in 2D and 3D environments show that the proposed method outperforms existing baselines such as LSTM and MQN/FRMQN. \n\n[Pros]\n- The overall direction toward more flexible/scalable memory is an important research direction in RL.\n- The proposed memory architecture is new. \n- The paper is well-written.\n\n[Cons]\n- The proposed memory architecture is new but a bit limited to 2D/3D navigation tasks.\n- Lack of analysis of the learned memory behavior.\n\n# Novelty and Significance\nThe proposed idea is novel in general. Though [Gupta et al.] proposed an ego-centric neural memory in the RL context, the proposed memory architecture is still new in that read/write operations are flexible enough for the agent to write any information to the memory, whereas [Gupta et al.] designed the memory specifically for predicting free space. On the other hand, the proposed method is also specific to navigation tasks in 2D or 3D environment, which is hard to apply to more general memory-related tasks in non-spatial environments. But, it is still interesting to see that the ego-centric neural memory works well on challenging tasks in a 3D environment.\n\n# Quality\nThe experiment does not show any analysis of the learned memory read/write behavior especially for ego-centric neural map and the 3D environment. It is hard to understand how the agent utilizes the external memory without such an analysis. \n\n# Clarity\nThe paper is overall clear and easy-to-follow except for the following. In the introduction section, the paper claims that ""the expert must set M to a value that is larger than the time horizon of the currently considered task"" when mentioning the limitation of the previous work. In some sense, however, Neural Map also requires an expert to specify the proper size of the memory based on prior knowledge about the task. ']","[80, -20, 50]","[60, 50, 80]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'excellent and important work' and expresses strong support for its acceptance, even suggesting boycotting the conference if it's not accepted. The politeness score is 60 (moderately polite) because the reviewer uses respectful language overall and offers constructive feedback. However, the score is not higher due to some critical comments about the peer review process and other reviewers, which could be seen as slightly impolite. The reviewer provides detailed analysis of the paper's content, acknowledges its strengths, and offers specific suggestions for improvement, all of which contribute to a generally positive and polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (new memory mechanism, good evaluation precedent), they express significant concerns about the lack of experiments to test the agent's learning and the overall approach. The reviewer questions whether the agent is actually employing a navigation strategy as suggested. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, presenting their concerns as constructive criticism rather than harsh judgments. They use phrases like 'My main concern is...' and 'I'm concerned whether...' which maintain a polite tone while expressing doubts. The reviewer also offers alternative perspectives and suggestions, which contributes to the politeness of the review."", ""The sentiment score is 50 (slightly positive) because the review begins with a balanced summary, listing both pros and cons. The reviewer acknowledges the novelty and importance of the research direction, while also pointing out limitations. The overall tone is constructive rather than overly critical or enthusiastic. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths ('well-written', 'novel', 'interesting') while framing criticisms as suggestions for improvement rather than harsh judgments. The reviewer also uses phrases like 'it is hard to understand' instead of more accusatory language, maintaining a professional and courteous tone.""]"
"['# Paper overview:\nThis paper presents an analysis of a basket of approaches which together enable one to sample conditionally from a class of \ngenerative models which have been trained to match a joint distribution. Latent space constraints (framed as critics) are learned which confine the generating distribution to lie in a conditional subspace, which when combined with what is termed a \'realism\' constraint enables the generation of realistic conditional images from a more-or-less standard VAE trained to match the joint data-distribution.\n\n\'Identity preserving\' transformations are then introduced within the latent space, which allow the retrospective minimal modification of sample points such that they lie in the conditional set of interest (or not).  Finally, a brief foray into unsupervised techniques for learning these conditional constraints is made, a straightforward extension which I think clouds rather than enlightens the overall exposition.\n\n# Paper discussion:\nI think this is a nicely written paper, which gives a good explanation of the problem and their proposed innovations, however I am curious to see that the more recent ""Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space"" by Nguyen et al. was not cited.  This is an empirically very successful approach for conditional generation at \'test-time\'. \n\nOther minor criticisms include:\n* I find the \'realism\' constraint a bit weak, but perhaps it is simply a naming issue.  Did you experiment with alternative approaches for encouraging marginal probability mass?\n\n* The regularisation term L_dist, why this and not log(1 + exp(z\' - z)) (or many arbitrary others)? \n\n* The claim of identity preservation is (to me) a strong one: it would truly be hard to minimise the trajectory distance wrt. the actual \'identity\' of the subject.\n\n* For Figure 6 I would prefer a different colourscheme: the red does not show up well on screen.\n\n* ""Furthermore, CGANs and CVAEs suffer from the same problems of mode-collapse and blurriness as their unconditional cousins"" -> this is debateable, there are many papers which employ various methods to (attempt to) alleviate this issue.\n\n\n# Conclusion:\nI think this is a nice piece of work, if the authors can confirm why ""Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space"" is not placed relative to this work in the paper, I would be happy to see it published.  If stuck for space, I would personally recommend moving the one-shot generation section to the appendix as I do not think it adds a huge amount to the overall exposition.', 'UPDATE: I think the authors\' rebuttal and updated draft address my points sufficiently well for me to update my score and align myself with the other reviewers.\n\n-----\n\nORIGINAL REVIEW: The paper proposes a method for learning post-hoc to condition a decoder-based generative model which was trained unconditionally. Starting from a VAE trained with an emphasis on good reconstructions (and at the expense of sample quality, via a small hard-coded standard deviation on the conditional p(x | z)), the authors propose to train two ""critic"" networks on the latent representation:\n\n1. The ""realism"" critic receives either a sample z ~ q(z) (which is implicitly defined as the marginal of q(z | x) over all empirical samples) or a sample z ~ p(z) and must tell them apart.\n2. The ""attribute"" critic receives either a (latent code, attribute) pair from the dataset or a synthetic (latent code, attribute) pair (obtained by passing both the attribute and a prior sample z ~ p(z) through a generator) and must tell them apart.\n\nThe goal is to find a latent code which satisfies both the realism and the attribute-exhibiting criteria, subject to a regularization penalty that encourages it to stay close to its starting point.\n\nIt seems to me that the proposed realism constraint hinges exclusively on the ability to implictly capture the marginal distribution q(z) via a trained discriminator. Because of that, any autoencoder could be used in conjunction with the realism constraint to obtain good-looking samples, including the identity encoder-decoder pair (in which case the problem reduces to generative adversarial training). I fail to see why this observation is VAE-specific. The authors do mention that the VAE semantics allow to provide some weak form of regularization on q(z) during training, but the way in which the choice of decoder standard deviation alters the shape of q(z) is not explained, and there is no justification for choosing one standard deviation value in particular.\n\nWith that in mind, the fact that the generator mapping prior samples to ""realistic"" latent codes works is expected: if the VAE is trained in a way that encourages it to focus almost exclusively on reconstruction, then its prior p(z) and its marginal q(z) have almost nothing to do with each other, and it is more convenient to view the proposed method as a two-step procedure in which an autoencoder is first trained, and an appropriate prior on latent codes is then learned. In other words, the generator represents the true prior by definition.\n\nThe paper is also rather sparse in terms of comparison with existing work. Table 1 does compare with Perarnau et al., but as the caption mentions, the two methods are not directly comparable due to differences in attribute labels.\n\nSome additional comments:\n\n- BiGAN [1] should be cited as concurrent work when citing (Dumoulin et al., 2016).\n- [2] and [3] should be cited as concurrent work when citing (Ulyanov et al., 2016).\n\nOverall, the relative lack of novelty and comparison with previous work make me hesitant to recommend the acceptance of this paper.\n\nReferences:\n\n[1] Donahue, J., Krähenbühl, P., and Darrell, T. (2017). Adversarial feature learning. In Proceedings of the International Conference on Learning Representations.\n[2] Li, C., and Wand, M. (2016). Precomputed real-time texture synthesis with markovian generative adversarial networks. In European Conference on Computer Vision.\n[3] Johnson, J., Alahi, A., and Fei-Fei, L. (2016). Perceptual losses for real-time style transfer and super-resolution. In European Conference on Computer Vision.', 'This paper considers the problem of generating conditional samples from unconditional models, such that one can query the learned model with a particular set of attributes to receive conditional samples.  Key to achieving this is the introduction of a realism constraint that encourages samples to be more realistic without degrading their reconstruction and a critic which identifies regions of the latent space with targeted attributes.   Generating conditional samples then involves finding points in the latent space which satisfy both the realism constraint and the critic.  This is carried out either used gradient-based optimization or using an actor function which tries to amortize this process.\n\nThis paper is clearly on a timely topic and addresses an important problem.  The low-level writing is good and the paper uses figures effectively to explain its points.  The qualitative results presented are compelling and the approaches taken seem reasonable.  On the downside, the quantitative evaluation of method does not seem very thorough and the approach seems quite heuristical at times. Overall though, the paper seems like a solid step in a good direction with some clearly novel ideas.\n\nMy two main criticisms are as follows\n1. The evaluation of the method is generally subjective without clear use of baselines or demonstration of what would do in the absence of this work - it seems like it works, but I feel like I have a very poor grasp of relative gains.  There is little in the way of quantitative results and no indication of timing is given at any point.  Given that the much of the aim of the work is to avoid retraining, I think it is clear to show that the approach can be run sufficiently quickly to justify its approach over naive alternatives.\n\n2. I found the paper rather hard to follow at times, even though the low-level writing is good.  I think a large part of this is my own unfamiliarity with the literature, but I also think that space has been prioritized to showing off the qualitative results at the expense of more careful description of the approach and the evaluation methods.  This is a hard trade-off to juggle but I feel that the balance is not quite right at the moment.  I think this is a paper where it would be reasonable to go over the soft page limit by a page or so to provide more precise descriptions.  Relatedly, I think the authors could do a better job of linking the different components of the paper together as they come across a little disjointed at the moment.']","[60, -60, 50]","[80, 20, 70]","[""The sentiment score is 60 (positive) because the reviewer describes the paper as 'nicely written' and 'a nice piece of work', and expresses willingness to see it published with minor revisions. However, it's not extremely positive due to some criticisms and suggestions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as 'minor', and asks questions rather than making blunt statements. The reviewer also acknowledges the paper's strengths before offering critiques, which is a polite approach. The language is professional and constructive, avoiding any harsh or rude expressions."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's novelty and comparisons with existing work, ultimately recommending against acceptance. However, it's not entirely negative as they acknowledge some merits of the approach. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'It seems to me' and 'I fail to see' rather than making blunt criticisms. They also provide constructive feedback and additional references. However, the overall critique is still quite direct, preventing a higher politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's timeliness, importance, and novel ideas, calling it a 'solid step in a good direction'. However, they also point out significant criticisms, particularly regarding evaluation methods and clarity of explanation. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging both strengths and weaknesses without harsh criticism. They use phrases like 'clearly on a timely topic', 'low-level writing is good', and offer constructive feedback for improvement. The reviewer also admits their own potential lack of familiarity with the literature, showing humility. The tone remains professional and courteous while providing honest feedback.""]"
"['The paper describes another instantiation of ""capsules"" which attempt to learn part-whole relationships and the geometric pose transformations between them.  Results are presented on the smallNORB test set obtaining impressive performance.\n\nAlthough I like very much this overall approach, this particular paper is so opaquely written that it is difficult to understand exactly what was done and how the network works.  It sounds like the main innovation here is using a 4x4 matrix for the pose parameters, and an iterative EM algorithm to find the correspondence between capsules (routing by agreement).  But what exactly the pose matrix represents, and how they get transformed from one layer to the next, is left almost entirely to the reader\'s imagination.  In addition, how EM factors in, what the probabilities P_ih represent, etc. is not clear.  I think the authors could do a much better job explaining this model, the rationale behind it, and how it works.\n\nPerhaps the most interesting and compelling result is Figure 2, which shows how ambiguity in object class assignment is resolved with each iteration.  This is very intriguing, but it would be great to understand what is going on and how this is happening.\n\nAlthough the results are impressive, if one can\'t understand how this was achieved it is hard to know what to make of it.\n\n', 'The paper proposes a novel architecture for capsule networks. Each capsule has a logistic unit representing the presence of an entity plus a 4x4 pose matrix representing the entity/viewer relationship. This new representation comes with a novel iterative routing scheme, based on the EM algorithm.\nEvaluated on the SmallNORB dataset, the approach proves to be more accurate than previous work (beating also the recently proposed ""routing-by-agreement"" approach for capsule networks by Sabour et al.). It also generalizes well to new, unseen viewpoints and proves to be more robust to adversarial examples than traditional CNNs.\n\nCapsule networks have recently gained attention from the community. The paper addresses important shortcomings exhibited by previous work (Sabour et al.), introducing a series of valuable technical novelties.\nThere are, however, some weaknesses. The proposed routing scheme is quite complex (involving an EM-based step at each layer); it\'s not fully clear how efficiently it can be performed / how scalable it is. Evaluation is performed on a small dataset for shape recognition; as noted in Sec. 6, the approach will need to be tested on larger, more challenging datasets. Clarity could be improved in some parts of the paper (e.g.: Sec. 1.1 may not be fully clear if the reader is not already familiar with (Sabour et al., 2017); the authors could give a better intuition about what is kept and what is discarded, and why, from that approach. Sec. 2: the sentence ""this is incorrect because the transformation matrix..."" could be elaborated more. V_{ih} in eq. 1 is defined only a few lines below; perhaps, defining the variables before the equations could improve clarity. Sec. 2.1 could be accompanied by mathematical formulation).\nAll in all, the paper brings an original contribution and will encourage further research / discussion on an important research question (how to effectively leverage knowledge about the part-whole relationships).\n\nOther notes:\n- There are a few typos (e.g. Sec. 1.2 ""(Jaderberg et al. (2015)"",  Sec. 2 ""the the transformation"", Sec. 4 ""cetral crop"" etc.).\n- The authors could discuss in more detail why the approach does not show significant improvement on NORB with respect to the state of the art.\n- The authors could provide more insights about why capsule gradients are smaller than CNN ones.\n- It would be interesting to discuss how the network could potentially be adapted, in the future, to: 1. be more efficient 2. take into account other changes produced by viewpoint changes (pixel intensities, as noted in Sec. 1).\n- In Sec, 4, the authors could provide more details about the network training.\n- In Procedure 1, for indexing tensors and matrices it might be better to use a comma to separate dimensions (e.g. V_{:,c,:} instead of V_{:c:}).', 'This paper proposes a new kind of capsules for CNN. The capsule contains a 4x4 pose matrix motivated by 3D geometric transformations describing the relationship between the viewer and the object (parts). An EM-type of algorithm is used to compute the routing.\n\nThe authors use the smallNORB dataset as an example. Since the scenes are simulated from different viewer angles, the pose matrix quite fits the motivation. It would be more beneficial to know if this kind of capsules is limited to the motivation or is general. For example, the authors may consider reporting the results of the affNIST dataset where the digits undergo 2D affine transformations (in which case perhaps 3x3 pose matrices are enough?).\n\nMinor: The arguments in line 5 of the procedure RM Routing(a,V) do not match those in line 1 of the procedure E-Step.\n\nSection 2.1 (objective of EM) is unclear. The authors may want to explicitly write down the free energy function.\n\nThe section about robustness against adversarial attacks is interesting.\n\nOverall the idea appears to be useful but needs more empirical validation (affNIST, ImageNet, etc).\n']","[-20, 60, 20]","[50, 70, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges liking the overall approach and finding some results impressive, they express significant concerns about the paper's clarity and understandability. The reviewer states that the paper is 'opaquely written' and 'difficult to understand,' which are clear criticisms. However, the presence of some positive comments prevents the score from being more negative. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, even when criticizing. They use phrases like 'I like very much this overall approach' and 'Perhaps the most interesting and compelling result,' which maintain a polite tone. The reviewer also frames criticisms as suggestions for improvement rather than harsh judgments, such as 'I think the authors could do a much better job explaining this model.' This constructive approach contributes to the politeness of the review."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's novel contributions and its improvements over previous work. They state that it 'addresses important shortcomings' and brings 'an original contribution.' However, they also point out some weaknesses, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They balance positive feedback with areas for enhancement, using phrases like 'could be improved' and 'could provide more details' rather than harsh criticism. The reviewer also acknowledges the paper's potential to encourage further research, which adds to the polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting aspects and potential usefulness, but also points out areas needing improvement and more validation. The review starts with a neutral description and ends with a cautiously positive overall assessment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions without harsh criticism. The reviewer uses phrases like 'It would be more beneficial' and 'The authors may consider' which are polite ways of suggesting improvements. The tone is professional and objective, focusing on the content rather than making personal comments.""]"
"['This paper proposes a device placement algorithm to place operations of tensorflow on devices. \n\nPros:\n\n1. It is a novel approach which trains the placement end to end.\n2. The experiments are solid to demonstrate this method works very well.\n3. The writing is easy to follow.\n4. This would be a very useful tool for the community if open sourced.\n\nCons:\n\n1. It is not very clear in the paper whether the training happens for each model yielding separate agents, or a shared agent is trained and used for all kinds of models. The latter would be more exciting. The adjacency matrix varies size for different graphs, so I guess a separate agent is trained for each graph? However, if the agent is not shared, why not just use integer to represent each operation in the graph, since overfitting would be more desirable in this case.\n2. Averaging the embedding is hard to understand especially for the output sizes and number of outputs.\n3. It is not clear how the adjacency information is used.\n', 'In a previous work [1], an auto-placement (better model partition on multi GPUs) method was proposed to accelerate a TensorFlow model’s runtime. However, this method requires the rule-based co-locating step, in order to resolve this problem, the authors of this paper purposed a fully connect network (FCN) to replace the co-location step. In particular, hand-crafted features are fed to the FCN and the output is the prediction of group id of this operation. Then all the embeddings in each group are averaged to serve as the input of a seq2seq encoder. \n\nOverall speaking, this work is quite interesting. However, it also has several limitations, as explained below.\n\nFirst, the computational cost of the proposed method seems very high. It may take more than one day on 320-640 GPUs for training (I did not find enough details in this paper, but the training complexity will be no less than the in [1]). This makes it very hard to reproduce the experimental results (in order to verify it), and its practical value becomes quite restrictive (very few organizations can afford such a cost).\n\nSecond, as the author mentioned, it’s hard to compare the experimental results in this paper wit those in [1] because different hardware devices and software versions were used. However, this is not a very sound excuse. I would encourage the authors to implement colocRL [1] on their own hardware and software systems, and make direct comparison. Otherwise, it is very hard to tell whether there is improvement, and how significant the improvement is. In addition, it would be better to have some analysis on the end-to-end runtime efficiency and the effectiveness of the placements.\n\n [1] Mirhoseini A, Pham H, Le Q V, et al. Device Placement Optimization with Reinforcement Learning[J]. arXiv preprint arXiv:1706.04972, 2017. https://arxiv.org/pdf/1706.04972.pdf \n', 'The paper seems clear enough and original enough. The idea of jointly forming groups of operations to colocate and figure out placement on devices seems to hold merit. Where the paper falls short is motivating the problem setting. Traditionally, for determining optimal execution plans, one may resort to cost-based optimization (e.g., database management systems). This paper\'s introduction provides precisely 1 statement to suggest that may not work for deep learning. Here\'s the relevant phrase: ""the cost function is typically non-stationary due to the interactions between multiple devices"". Unfortunately, this statement raises more questions than it answers. Why are the cost functions non-stationary? What exactly makes them dynamic? Are we talking about a multi-tenancy setting where multiple processes execute on the same device? Unlikely, because GPUs are involved. Without a proper motivation, its difficult to appreciate the methods devised.\n\nPros:\n- Jointly optimizing forming of groups and placing these seems to have merit\n- Experiments show improvements over placement by human ""experts""\n- Targets an important problem\n\nCons:\n- Related work seems inadequately referenced. There exist other linear/tensor algebra engines/systems that perform such optimization including placing operations on devices in a distributed setting. This paper should at least cite those papers and qualitatively compare against those approaches. Here\'s one reference (others should be easy to find): ""SystemML\'s Optimizer: Plan Generation for Large-Scale Machine Learning Programs"" by Boehm et al, IEEE Data Engineering Bulletin, 2014.\n- The methods are not well motivated. There are many approaches to devising optimal execution plans, e.g., rule-based, cost-based, learning-based. In particular, what makes cost-based optimization inapplicable? Also, please provide some reasoning behind your hypothesis which seems to be that while costs may be dynamic, optimally forming groups and placing them is learn-able.\n- The template seems off. I don\'t see the usual two lines under the title (""Anonymous authors"", ""Paper under double-blind review"").\n- The title seems misleading. "".... Device Placement"" seems to suggest that one is placing devices when in fact, the operators are being placed.']","[60, -20, -20]","[70, 60, 50]","[""The sentiment score is 60 (positive) because the review starts with a clear list of pros, highlighting several positive aspects of the paper such as its novelty, solid experiments, clear writing, and potential usefulness. The cons are presented as constructive criticism rather than severe flaws. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering suggestions for improvement. The critique is presented in a professional manner without harsh or dismissive language. The reviewer also uses phrases like 'It is not very clear' instead of more accusatory language, maintaining a courteous tone."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the work 'quite interesting', they also point out several significant limitations. The reviewer expresses concerns about the high computational cost, difficulty in reproducing results, and the lack of direct comparison with previous work. These criticisms outweigh the initial positive comment, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the interesting aspects of the work and offering constructive criticism. They use phrases like 'I would encourage the authors' and 'it would be better', which are polite ways of suggesting improvements. The reviewer also provides specific recommendations for enhancing the work, which is a courteous approach in academic peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some merits of the paper ('seems clear enough and original enough', 'holds merit', 'shows improvements'), they also point out significant shortcomings, particularly in motivation and related work. The cons outweigh the pros in the review. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'seems to hold merit' and 'targets an important problem' to soften critiques, and frame issues as areas for improvement rather than outright failures.""]"
"['The paper aims at improving the accuracy of a low precision network based on knowledge distillation from a full-precision network. Instead of distillation from a pre-trained network, the paper proposes to train both teacher and student network jointly. The paper shows an interesting result that the distilled low precision network actually performs better than high precision network.\n\nI found the paper interesting but the contribution seems quite limited.\n\nPros:\n1. The paper is well written and easy to read.\n2. The paper reported some interesting result such as that the distilled low precision network actually performs better than high precision network, and that training jointly outperforms the traditional distillation method (fixing the teacher network) marginally.\n\nCons:\n1. The name Apprentice seems a bit confusing with apprenticeship learning.\n2. The experiments might be further improved by providing a systematic study about the effect of precisions in this work (e.g., producing more samples of precisions on activations and weights).\n3. It is unclear how the proposed method outperforms other methods based on fine-tuning. It is also quite possible that after fine-tuning the compressed model usually performs quite similarly to the original model.', ""The authors investigate knowledge distillation as a way to learn low precision networks. They propose three training schemes to train a low precision student network from a teacher network. They conduct experiments on ImageNet-1k with variants of ResNets and multiple low precision regimes and compare performance with previous works\n\nPros:\n(+) The paper is well written, the schemes are well explained\n(+) Ablations are thorough and comparisons are fair\nCons:\n(-) The gap with full precision models is still large \n(-) Transferability of the learned low precision models to other tasks is not discussed\n\nThe authors tackle a very important problem, the one of learning low precision models without comprosiming performance. For scheme-A, the authors show the performance of the student network under many low precision regimes and different depths of teacher networks. One observation not discussed by the authors is that the performance of the student network under each low precision regime doesn't improve with deeper teacher networks (see Table 1, 2 & 3). As a matter of fact, under some scenarios performance even decreases. \n\nThe authors do not discuss the gains of their best low-precision regime in terms of computation and memory.\n\nFinally, the true applications for models with a low memory footprint are not necessarily related to image classification models (e.g. ImageNet-1k). How good are the low-precision models trained by the authors at transferring to other tasks? Is it possible to transfer student-teacher training practices to other tasks?"", 'Summary:\nThe paper presents three different methods of training a low precision student network from a teacher network using knowledge distillation.\nScheme A consists of training a high precision teacher jointly with a low precision student. Scheme B is the traditional knowledge distillation method and Scheme C uses knowledge distillation for fine-tuning a low precision student which was pretrained in high precision mode.\n\nReview:\nThe paper is well written. The experiments are clear and the three different schemes provide good analytical insights.\nUsing scheme B  and C student model with low precision could achieve accuracy close to teacher while compressing the model.\n\nComments:\nTensorflow citation is missing.\nConclusion is short and a few directions for future research would have been useful.']","[20, 50, 80]","[50, 75, 60]","[""The sentiment score is slightly positive (20) because the reviewer finds the paper interesting and well-written, noting some pros such as interesting results. However, they also mention that the contribution seems quite limited and list some cons, which prevents a higher positive score. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'I found the paper interesting' and 'The paper is well written,' which contribute to a polite tone. The cons are presented as suggestions for improvement rather than harsh criticisms, maintaining a courteous approach."", 'The sentiment score is 50 (slightly positive) because the reviewer acknowledges both pros and cons of the paper. They praise the writing quality, thorough explanations, and fair comparisons, but also point out limitations such as the performance gap and lack of discussion on transferability. The overall tone is constructive and balanced. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledges the importance of the problem, and frames criticisms as observations or suggestions rather than harsh judgments. The reviewer maintains a professional and courteous tone while providing both positive feedback and areas for improvement.', ""The sentiment score is 80 (positive) because the reviewer states that the paper is 'well written' and the experiments are 'clear' with 'good analytical insights'. They also mention that the student model could achieve accuracy close to the teacher while compressing the model, which is a positive outcome. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths without harsh criticism. The minor suggestions for improvement (missing citation and short conclusion) are presented as neutral observations rather than criticisms. The overall tone is professional and constructive, indicating a polite approach to the review process.""]"
"['\nThis paper shows that residual networks can be viewed as doing a sort of iterative inference, where each layer is trained to use its “nonlinear part” to push its values in the negative direction of the loss gradient.  The authors demonstrate this using a Taylor expansion of a standard residual block first, then follow up with several experiments that corroborate this interpretation of iterative inference.  Overall the strength of this paper is that the main insight is quite interesting — though many people have informally thought of residual networks as having this interpretation — this paper is the first one to my knowledge to explain the intuition in a more precise way.  \n\nSome weaknesses of the paper on the other hand — some of the parts of the paper (e.g. on weight sharing) are only somewhat related to the main topic of the paper. In fact, the authors moved the connection to SGD to the appendix, which I thought would be *more* related.   Additionally, parts of the paper are not as clearly written as they could be and lack rigor.  This includes the mathematical derivation of the main insight — some of the steps should be spelled out more explicitly.  The explanation following is also handwavey despite claims to being formal.   \n\nSome other lower level thoughts:\n* Regarding weight sharing for residual layers, I don’t understand why we can draw the conclusion that the initial gradient explosion is responsible for the lower generalization capability of the model with shared weights.  Are there other papers in literature that have shown this connection?\n* The name “cosine loss” suggests that this function is actually being minimized by a training procedure, but it is just a value that is being plotted… perhaps just call it the cosine?\n* I recommend that the authors also check out Figurnov et al CVPR 2017 (""Spatially Adaptive Computation Time for Residual Networks"") which proposes an “adaptive” version of ResNet based on the intuition of adaptive inference.\n* The plots in the later parts of the paper are quite small and hard to read.  They are also spaced together too tightly (horizontally), making it difficult to immediately see what each plot is supposed to represent via the y-axis label.\n* Finally, the citations need to be fixed (use \\citep{} instead of \\cite{})\n\n', ""This paper investigates residual networks (ResNets) in an empirical way. The authors argue that shallow layers are responsible for learning important feature representations, while deeper layers focus on refining the features. They validate this point by performing a series of lesion study on ResNet.\n\nOverall, the experiments and discussions in the first part of Section 4.2 and 4.3 appears to be interesting, while other observations are not quite surprising. I have two questions:\n1)\tWhat is the different between the layer-dropping experiment in sec 4.2 and that in [Veit, et al, Residual networks are exponential ensembles of relatively shallow networks] ? What is the main point here? \n2)\tI don't quite understand the first paragraph of sec 4.5. Could you elaborate more on this?\n"", 'The author unveils some properties of the resnets, for example, the cosine loss and l2 ratio of the layers. \nI think the author should place more focus to study ""real"" iterative inference with shared parameters rather than analyzing original resnets.\n\nIn resnet without sharing parameters, it is quite ambiguous to say whether it is doing representation learning or iterative refinement.\n\n1. The cosine loss is not meaningful in the sense that the classification layer is trained on the output of the last residual block and fixed. Moving the classification layer to early layers will definitely result in accuracy loss. Even in non-residual network, we can always say that the vector h_{i+1} - h_i is refining h_i towards the negative gradient direction. The motivation of iterative inference would be to generate a feature that is easier to classify rather than to match the current fixed classifier. Thus the final classification layer should be retrained for every addition or removal of residual blocks.\n\n2. The l2 ratio. The l2 ratio is small for higher residual layers, I\'m not sure how much this phenomenon can prove that resnet is actually doing iterative inference.\n\n3. In section 4.4 it is shown that unrolling the layers can improve the performance of the network. However, the same can be achieved by adding more unshared layers. I think the study should focus more on whether shared or unshared is better.\n\n4. Section 4.5 is a bit weak in experiments, my conclusion is that currently it is still limited by batch normalization and optimization, the evidence is still not strong enough to show that iterative inference is advantageous / disadvantageous.\n\nThe the above said, I think the more important thing is how we can benefit from iterative inference interpretation, which is relatively weak in this paper.']","[50, 20, -30]","[60, 50, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer begins by highlighting the paper's strengths and interesting insights, calling it the 'first one to my knowledge to explain the intuition in a more precise way.' However, this is balanced by criticisms about weaknesses in clarity, rigor, and relevance of some sections. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'I recommend' and 'Some weaknesses' rather than harsh or dismissive language. The reviewer also provides specific, actionable feedback, which is a polite way to help the authors improve their work."", 'The sentiment score is slightly positive (20) because the reviewer finds parts of the paper interesting, particularly sections 4.2 and 4.3. However, they also mention that some observations are not surprising, indicating a mixed but overall positive sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral language and poses questions in a respectful manner without harsh criticism. They acknowledge the interesting aspects of the paper and frame their concerns as questions rather than direct criticisms, which contributes to a polite tone.', ""The sentiment score is -30 because the reviewer expresses several criticisms and suggests that the paper's focus should be shifted. While they acknowledge some positive aspects ('unveils some properties'), the overall tone is critical, pointing out weaknesses in the methodology and conclusions. The politeness score is 20 because the reviewer uses relatively neutral language and phrases criticisms as suggestions ('I think the author should...') rather than direct attacks. They also use phrases like 'I'm not sure' to soften disagreements. However, the review doesn't go out of its way to be overtly polite or complimentary, maintaining a professional but somewhat critical tone throughout.""]"
"[""\n1) Summary\nThis paper proposes a recurrent neural network (RNN) training formulation for encouraging RNN the hidden representations to contain information useful for predicting future timesteps reliably. The authors propose to train a forward and backward RNN in parallel. The forward RNN predicts forward in time and the backward RNN predicts backwards in time. While the forward RNN is trained to predict the next timestep, its hidden representation is forced to be similar to the representation of the backward RNN in the same optimization step. In experiments, it is shown that the proposed method improves training speed in terms of number of training iterations, achieves 0.8 CIDEr points improvement over baselines using the proposed training, and also achieves improved performance for the task of speech recognition.\n\n\n2) Pros:\n+ Novel idea that makes sense for learning a more robust representation for predicting the future and prevent only local temporal correlations learned.\n+ Informative analysis for clearly identifying the strengths of the proposed method and where it is failing to perform as expected.\n+ Improved performance in speech recognition task.\n+ The idea is clearly explained and well motivated.\n\n\n3) Cons:\nImage captioning experiment:\nIn the experimental section, there is an image captioning result in which the proposed method is used on top of two baselines. This experiment shows improvement over such baselines, however, the performance is still worse compared against baselines such as Lu et al, 2017 and Yao et al, 2016. It would be optimal if the authors can use their training method on such baselines and show improved performance, or explain why this cannot be done.\n\n\nUnconditioned generation experiments:\nIn these experiments, sequential pixel-by-pixel MNIST generation is performed in which the proposed method did not help. Because of this, two conditioned set ups are performed: 1) 25% of pixels are given before generation, and 2) 75% of pixels are given before generation. The proposed method performs similar to the baseline in the 25% case, and better than the baseline in the 75% case. For completeness, and to come to a stronger conclusion on how much uncertainty really affects the proposed method, this experiment needs a case in which 50% of the pixels are given. Observing 25% of the pixels gives almost no information about the identity of the digit and it makes sense that it’s hard to encode the future, however, 50% of the pixels give a good idea of what the digit identity is. If the authors believe that the 50% case is not necessary, please feel free to explain why.\n\n\nAdditional comments:\nThe method is shown to converge faster compared to the baselines, however, it is possible that the baseline may finish training faster (the authors do acknowledge the additional computation needed in the backward RNN).\nIt would be informative for the research community to see the relationship of training time (how long it takes in hours) versus how fast it learns (iterations taken to learn).\n\nExperiments on RL planning tasks would be interesting to see (Maybe on a simple/predictable environment).\n\n\n4) Conclusion\nThe paper proposes a method for training RNN architectures to better model the future in its internal state supervised by another RNN modeling the future in reverse. Correctly modeling the future is very important for tasks that require making decisions of what to do in the future based on what we predict from the past. The proposed method presents a possible way of better modeling the future, however, some the results do not clearly back up the claim yet. The given score will improve if the authors are able to address the stated issues.\n\n\nPOST REBUTTAL RESPONSE:\nThe authors have addressed the comments on the MNIST experiments and show better results, however, as far as I can see, they did not address my concern about the comparisons on the image captioning experiment. In the image captioning experiment the authors choose two networks (Show & Tell and Soft attention) that they improve using the proposed method that end up performing similar to the second best baseline (Yao et al. 2016) based on Table 3 and their response. I requested for the authors to use their method on the best performing baselines (i.e. Yao et al. 2016 or Liu et al. 2017) or explain why this cannot be done (maybe my request was not clearly stated). Applying the proposed method on the strong baselines would highlight the author's claims more strongly than just applying on the average performing chosen baselines. This request was not addressed and instead the authors just improved the average performing baselines in Table 3 to meet the best baselines. Given, that the authors were able to improve the results in the sequential MNIST and improve the average baselines, my rating improves one point. However, I still have concerns about this method not being shown to improve the best methods presented in Table 3 which would give a more solid result. My rating changes to marginally above threshold for acceptance."", 'Twin Networks: Using the Future as a Regularizer\n\n** PAPER SUMMARY **\n\nThe authors propose to regularize RNN for sequence prediction by forcing states of the main forward RNN to match the state of a secondary backward RNN. Both RNNs are trained jointly and only the forward model is used at test time. Experiments on conditional generation (speech recognition, image captioning), and unconditional generation (MNIST pixel RNN, language models) show the effectiveness of the regularizer.\n\n** REVIEW SUMMARY **\n\nThe paper reads well, has sufficient reference. The idea is simple and well explained. Positive empirial results support the proposed regularizer.\n\n** DETAILED REVIEW **\n\nOverall, this is a good paper. I have a few suggestions along the text but nothing major.\n\nIn related work, I would cite co-training approaches. In effect, you have two view of a point in time, its past and its future and you force these two views to agree, see  (Blum and Mitchell, 1998) or Xu, Chang, Dacheng Tao, and Chao Xu. ""A survey on multi-view learning."" arXiv preprint arXiv:1304.5634 (2013). I would also relate your work to distillation/model compression which tries to get one network to behave like another. On that point, is it important to train the forward and backward network jointly or could the backward network be pre-trained? \n\nIn section 2, it is not obvious to me that the regularizer (4) would not be ignored in absence of regularization on the output matrix. I mean, the regularizer could push h^b to small norm, compensating with higher norm for the output word embeddings. Could you comment why this would not happen?\n\nIn Section 4.2, you need to refer to Table 2 in the text. You also need to define the evaluation metrics used. In this section, why are you not reporting the results from the original Show&Tell paper? How does your implementation compare to the original work?\n\nOn unconditional generation, your hypothesis on uncertainty is interesting and could be tested. You could inject uncertainty in the captioning task for instance, e.g. consider that multiple version of each word e.g. dogA, dogB, docC which are alternatively used instead of dog with predefined substitution rates. Would your regularizer still be helpful there? At which point would it break?', '** post-rebuttal revision **\n\nI thank the authors for running the baseline experiments, especially for running the TwinNet to learn an agreement between two RNNs going forward in time. This raises my confidence that what is reported is better than mere distillation of an ensemble of rnns. I am raising the score.\n\n** original review **\n\n\nThe paper presents a way to regularize a sequence generator by making the hidden states also predict the hidden states of an RNN working backward.\n\nApplied to sequence-to-sequence networks, the approach requires training one encoder, and two separate decoders, that generate the target sequence in forward and reversed orders. A penalty term is added that forces an agreement between the hidden states of the two decoders. During model evaluation only the forward decoder is used, with the backward operating decoder discarded. The method can be interpreted to generalize other recurrent network regularizers, such as putting an L2 loss on the hidden states.\n\nExperiments indicate that the  approach is most successful when the regularized RNNs are conditional generators, which emit sequences of low entropy, such as decoders of a seq2seq speech recognition network. Negative results were reported when the proposed regularization technique was applied to language models, whose output distribution has more entropy.\n\nThe proposed regularization is evaluated with positive results on a speech recognition task and on an  image captioning task, and with negative results (no improvement, but also no deterioration) on a language modeling and sequential MNIST digit generation tasks.\n\nI have one question about baselines: is the proposed approach better than training to forward generators and force an agreement between them (in the spirit of the concurrent ICLR submission https://openreview.net/forum?id=rkr1UDeC-)? \n\nAlso, would using the backward RNN, e.g. for rescoring, bring another advantage? In other words, what is (and is there) a gap between an ensemble of a forward and backward rnn and the forward-rnn only, but trained with the state-matching penalty?\n\nQuality:\nThe proposed approach is well motivated and the experiments show the limits of applicability range of the technique.\n\nClarity:\nThe paper is clearly written.\n\nOriginality:\nThe presented idea seems novel.\n\nSignificance:\nThe method may prove to be useful to regularize recurrent networks, however I would like to see a comparison with ensemble methods. Also, as the authors note the method seems to be limited to conditional sequence generators.\n\nPros and cons:\nPros: the method is simple to implement, the paper lists for what kind of datasets it can be used.\nCons: the method needs to be compared with typical ensembles of models going only forward in time, it may turn that it using the backward RNN is not necessary\n']","[20, 70, 50]","[80, 80, 80]","[""The sentiment score is 20 (slightly positive) because while the reviewer acknowledges the paper's novel ideas and improvements in some areas, they also point out significant shortcomings and request additional experiments. The overall tone is constructive but with reservations. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions for improvement rather than harsh judgments. They use phrases like 'It would be optimal if...' and 'please feel free to explain why' which maintain a courteous tone even when pointing out weaknesses."", ""The sentiment score is 70 (positive) because the reviewer states 'Overall, this is a good paper' and describes the paper as reading well, having sufficient references, and being well explained with positive empirical results. The tone is generally approving, with only minor suggestions offered. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering suggestions rather than demands (e.g. 'I would cite', 'Could you comment'), and acknowledging the paper's strengths. The reviewer maintains a professional and constructive tone, balancing praise with thoughtful questions and recommendations for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the authors' efforts in running additional experiments, which increased their confidence in the reported results. They also mention raising the score. However, the review still includes some critical questions and points out limitations of the method. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout, thanking the authors for their work, and framing criticisms as questions or suggestions rather than direct criticisms. The reviewer maintains a professional and courteous tone, even when pointing out potential shortcomings or requesting additional comparisons.""]"
"['Neural-net based image compression is a field which is about to get hot, and this paper asks the obvious question: can we design a neural-net based image compression algorithm such that the features it produces are useful for classification & segmentation?\n\nThe fact that it\'s an obvious question does not mean that it\'s a question that\'s worthless. In fact, I am glad someone asked this question and tried to answer it. \n\nPros:\n- Clear presentation, easy to follow.\n- Very interesting, but obvious, question is explored. \n- The paper is very clear, and uses building blocks which have been analyzed before, which leaves the authors free to explore their interactions rather than each individual building block\'s property.\n- Results are shown on two tasks (classification / segmentation) rather than just one (the obvious one would have been to only discuss results on classification), and relatively intuitive results are shown (i.e., more bits = better performance). What is perhaps not obvious is how much impact does doubling the bandwidth have (i.e., initially it means more, then later on it plateaus, but much earlier than expected).\n- Joint training of compression + other tasks. As far as I know this is the first paper to talk about this particular scenario.\n- I like the fact that classical codecs were not completely discarded (there\'s a comparison with JPEG 2K).\n- The discussion section is of particular interest, discussing openly the pros/cons of the method (I wish more papers would be as straightforward as this one).\n\nCons:\n- I would have liked to have a discussion on the effect of the encoder network. Only one architecture/variant was used.\n- For PSNR, SSIM and MS-SSIM I would like a bit more clarity whether these were done channel-wise, or on the grayscale channel.\n- While runtime is given as pro, it would be nice for those not familiar with the methods to provide some runtime numbers (i.e., breakdown how much time does it take to encode and how much time does it take to classify or segment, but in seconds, not flops). For example, Figure 6 could be augmented with actual runtime in seconds.\n- I wish the authors did a ctrl+F for ""??"" and fixed all the occurrences.\n- One of the things that would be cool to add later on but I wished to have beeyn covered is whether it\'s possible to learn not only to compress, but also downscale. In particular, the input to ResNet et al for classification is fixed sized, so the question is -- would it be possible to produced a compact representation to be used for classification given arbitrary image resolutions, and if yes, would it have any benefit?\n\nGeneral comments:\n- The classification bits are all open source, which is very good. However, there are very few neural net compression methods which are open sourced. Would you be inclined to open source the code for your implementation? It would be a great service to the community if yes (and I realize that it could already be open sourced -- feel free to not answer if it may lead to break anonymity, but please take this into consideration).\n', 'This is a well-written and quite clear work about how a previous work on image compression using deep neural networks can be extended to train representations which are also valid for semantic understanding. IN particular, the authors tackle the classic and well-known problems of image classification and segmentation.\n\nThe work evolves around defining a loss function which initially considers only a trade-off between reconstruction error and total bit-rate. The representations trained with the loss function, at three different operational points, are used as inputs for variations of ResNet (image classification) and DeepLab (segmentation). The results obtained are similar to a ResNet trained directly over the RGB images, and actually with a slight increase of performance in segmentation. The most interesting part is a joint training for both compression and image classification.\n\nPROS\nP.1 Joint training for both compression and classification. First time to the authors knowledge.\nP.2 Performance on classification and segmentation tasks are very similar when compared to the non-compressed case with state-of-the-art ResNet architectures.\nP.3 Text is very clear.\nP.4 Experimentation is exhaustive and well-reported.\n\nCONS\nC1. The authors fail into providing a better background regarding the metrics MS-SSIM and SSIM (and PSNR, as well) and their relation to the MSE used for training the network. Also, I missed an explanation about whether high or low values for them are beneficial, as actually results compared to JPEG and JPEG-2000 differ depending on the experiment.\nC2. The main problem is of the work is that, while the whole argument is that in an indexing system it would not be necessary to decompress the representation coded with a DNN, in terms of computation JPEG2000 (and probably JPEG) are much lighter that coding with DNN, even if considering both the compression and decompression. The authors already point at another work where they explore the efficient compression with GPUs, but this point is the weakest one for the adoption of the proposed scheme.\nC3. The paper exceeds the recommendation of 8 pages and expands up to 13 pages, plus references. An effort of compression would be advisable, moving some of the non-core results to the appendixes.\n\nQUESTIONS\nQ1. Do you have any explanation for the big jumps on the plots of Figure 5 ?\nQ2. Did you try a joint training for the segmentation task as well ?\nQ3. Why are the dots connected in Figure 10, but not in Figure 11.\nQ4. Actually results in Figure 10 do not seem good... or maybe I am not understanding them properly. This is related to C1.\nQ5. There is a broken reference in Section 5.3. Please fix.', 'Thanks for addressing most of the issues. I changed my given score from 3 to 6.\n\nSummary:\nThis work explores the use of learned compressed image representation for solving 2 computer vision tasks without employing a decoding step. \n\nThe paper claims to be more computationally and memory efficient compared to the use of original or the decompressed images. Results are presented on 2 datasets ""Imagenet"" and ""PASCAL VOC 2012"". They also jointly train the compression and classification together and empirically shows it can improve both classification and compression together.\n\nPros:\n+ The idea of learning from a compressed representation is a very interesting and beneficial idea for large-scale image understanding tasks. \n\nCons:\n- The paper is too long (13 pages + 2 pages of references). The suggested standard number of pages is 8 pages + 1 page of references. There are many parts that are unnecessary in the paper and can be summarized. Summarizing and rewording them makes the paper more consistent and easier to read:\n  ( 1. A very long introduction about the benefits of inferring from the compressed images and examples.\n    2. A large part of the intro and Related work can get merged.  \n    3. Experimental setup part is long but not well-explained and is not self-contained particularly for the evaluation metrics. \n    “Please briefly explain what MS-SSIM, SSIM, and PSNR stand for”. There is a reference to the Agustsson et al 2017 paper \n     “scalar quantization”, which is not well explained in the paper. It is better to remove this part if it is not an important part or just briefly but clearly explain it.\n     4. Fig. 4 is not necessary. 4.3 contains extra information and could be summarized in a more consistent way.\n     5. Hyperparameters that are applied can be summarized in a small table or just explain the difference between the \n      architectures that are used.)\n\n- There are parts of the papers which are confusing or not well-written. It is better to keep the sentences short and consistent:\nE.g: subsection 3.2, page 5: “To adapt the ResNet … where k is the number of … layers of the network” can be changed to 3 shorter sentences, which is easier to follow.\nThere are some typos: e.g: part 3.1, fever ---> fewer, \n\n- As it is mentioned in the paper, solving a Vision problem directly from a compressed image, is not a novel method (e.g: DCT coefficients were used for both vision and audio data to solve a task without any decompression). However, applying a deep representation for the compression and then directly solving a vision task (classification and segmentation) can be considered as a novel idea.\n\n- In the last part of the paper, both compression and classification parts are jointly trained, and it is empirically presented that both results improved by jointly training them. However, to me, it is not clear if the trained compression model on this specific dataset and for the task of classification can work well for other datasets or other tasks.  \nThe experimental setup and the figures are not well explained and well written. \n\n']","[80, 60, 20]","[90, 70, 60]","[""The sentiment score is 80 (positive) because the reviewer expresses clear enthusiasm for the paper, highlighting numerous pros and stating they are 'glad someone asked this question.' The reviewer also provides constructive criticism, which prevents the score from being higher. The politeness score is 90 (very polite) due to the reviewer's respectful tone throughout, using phrases like 'I would have liked' and 'I wish' when suggesting improvements, and acknowledging the value of the work even when pointing out limitations. The reviewer also compliments the clarity and straightforwardness of the paper. The high scores in both categories reflect the overall positive and constructive nature of the review, balanced with polite and thoughtful suggestions for improvement."", ""The sentiment score is 60 (positive) because the review starts with praising the work as 'well-written and quite clear', and lists several pros including 'joint training for both compression and classification' and 'exhaustive and well-reported' experimentation. However, it also includes some cons and questions, which prevent it from being extremely positive. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms constructively. The cons and questions are presented in a professional manner without harsh language. The use of 'PROS' and 'CONS' sections, along with specific questions, shows a structured and considerate approach to feedback."", ""The sentiment score is 20 (slightly positive) because the reviewer acknowledges the interesting and beneficial aspects of the paper, and has increased their score from 3 to 6. However, they also provide several criticisms and areas for improvement, which tempers the overall positivity. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They begin with a thank you and use phrases like 'It is better to' when making recommendations. The reviewer maintains a professional tone while providing detailed feedback, balancing positive aspects with areas needing improvement.""]"
"['The paper provides methods for training deep networks using half-precision floating point numbers without losing model accuracy or changing the model hyper-parameters. The main ideas are to use a master copy of weights when updating the weights, scaling the loss before back-prop and using full precision variables to store products. Experiments are performed on a large number of state-of-art deep networks, tasks and datasets which show that the proposed mixed precision training does provide the same accuracy at half the memory.\n\nPositives\n- The experimental evaluation is fairly exhaustive on a large number of deep networks, tasks and datasets and the proposed training preserves the accuracy of all the tested networks at half the memory cost.\n\nNegatives\n- The overall technical contribution is fairly small and are ideas that are regularly implemented when optimizing systems.\n- The overall advantage is only a 2x reduction in memory which can be gained by using smaller batches at the cost of extra compute. ', 'The paper presents three techniques to train and test neural networks using half precision format (FP16) while not losing accuracy. This allows to train and compute networks faster, and potentially create larger models that use less computation and energy.\n\nThe proposed techniques are rigorously evaluated in several tasks, including CNNs for classification and object detection, RNNs for machine translation, language generation and speech recognition, and generative adversarial networks. The paper consistently shows that the accuracy of training and validation matches the baseline using single precision (FP32), which is the common practice.\n\nThe paper is missing results comparing training and testing speeds in all these models, to illustrate the benefits of using the proposed techniques. It would be very valuable to add the baseline wall-time to the tables, together with the obtained wall-time for training and testing using the proposed techniques. ', 'The paper considers the problem of training neural networks in mixed precision (MP), using both 16-bit floating point (FP16) and 32-bit floating point (FP32). The paper proposes three techniques for training networks in mixed precision: first, keep a master copy of network parameters in FP32; second, use loss scaling to ensure that gradients are representable using the limited range of FP16; third, compute dot products and reductions with FP32 accumulation. \n\nUsing these techniques allows the authors to match the results of traditional FP32 training on a wide variety of tasks without modifying any training hyperparameters. The authors show results on ImageNet classification (with AlexNet, VGG, GoogLeNet, Inception-v1, Inception-v3, and ResNet-50), VOC object detection (with Faster R-CNN and Multibox SSD), speech recognition in English and Mandarin (with CNN+GRU), English to French machine translation (with multilayer LSTMs), language modeling on the 1 Billion Words dataset (with a bigLSTM), and generative adversarial networks on CelebFaces (with DCGAN).\n\nPros:\n- Three simple techniques to use for mixed-precision training\n- Matches performance of traditional FP32 training without modifying any hyperparameters\n- Very extensive experiments on a wide variety of tasks\n\nCons:\n- Experiments do not validate the necessity of FP32 accumulation\n- No comparison of training time speedup from mixed precision\n\nWith new hardware (such as NVIDIA’s Volta architecture) providing large computational speedups for MP computation, I expect that MP training will become standard practice in deep learning in the near future. Naively porting FP32 training recipes can fail due to the reduced numeric range of FP16 arithmetic; however by adopting the techniques of this paper, practitioners will be able to migrate their existing FP32 training pipelines to MP without modifying any hyperparameters. I expect these techniques to be hugely impactful as more people begin migrating to new MP hardware.\n\nThe experiments in this paper are very exhaustive, covering nearly every major application of deep learning. Matching state-of-the-art results on so many tasks increases my confidence that I will be able to apply these techniques to my own tasks and architectures to achieve stable MP training.\n\nMy first concern with the paper is that there are no experiments to demonstrate the necessity of FP32 accumulation. With an FP32 master copy of the weights and loss scaling, can all arithmetic be performed solely in FP16, or are there some tasks where training will still diverge?\n\nMy second concern is that there is no comparison of training-time speedup using MP. The main reason that MP is interesting is because new hardware promises to accelerate it. If people are willing to endure the extra engineering overhead of implementing the techniques from this paper, what kind of practical speedups can they expect to see from their workloads? NVIDIA’s marketing material claims that the Tensor Cores in the V100 offer an 8x speedup over its general-purpose CUDA cores (https://www.nvidia.com/en-us/data-center/tesla-v100/). Since in this paper some operations are performed in FP32 (weight updates, batch normalization) and other operations are bound by memory and not compute bandwidth, what kinds of speedups do you see in practice when moving from FP32 to MP on V100?\n\nMy other concerns are minor. Mandarin speech recognition results are reported on “our internal test set”. Is there any previously published work on this dataset, or any publicly available test set for this task?\n\nThe notation around the Inception architectures should be clarified. According to [3] and [4], “Inception-v1” and “GoogLeNet” both refer to the architecture used in [1]. The architecture used in [2] is referred to as “BN-Inception” by [3] and “Inception-v2” by [4]. “Inception-v3” is the architecture from [3], which is not currently cited. To improve clarity in Table 1, I suggest renaming “GoogLeNet” to “Inception-v1”, changing “Inception-v1” to “Inception-v2”, and adding explicit citations to all rows of the table.\n\nIn Section 4.3 the authors note that “half-precision storage format may act as a regularizer during training”. Though the effect is most obvious from the speech recognition experiments in Section 4.3, MP also achieves slightly higher performance than baseline for all ImageNet models but Inception-v1 and for both object detection models; these results add support to the idea of FP16 as a regularizer.\n\nMinor typos:\nSection 3.3, Paragraph 3: “either FP16 or FP16 math” -> “either FP16 or FP32 math”\nSection 4.1, Paragraph 4: “ pre-ativation” -> “pre-activation”\n\nOverall this is a strong paper, and I believe that it will be impactful as MP hardware becomes more widely used.\n\n\nReferences\n\n[1] Szegedy et al, “Going Deeper with Convolutions”, CVPR 2015\n[2] Ioffe and Szegedy, “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift”, ICML 2015\n[3] Szegedy et al, “Rethinking the Inception Architecture for Computer Vision”, CVPR 2016\n[4] Szegedy et al, “Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning”, ICLR 2016 Workshop']","[20, 50, 80]","[50, 75, 70]","[""The sentiment score is slightly positive (20) because the review acknowledges the paper's contributions and extensive experimental evaluation, but also points out some negatives. The reviewer notes that the paper provides methods for training deep networks using half-precision floating point numbers without losing accuracy, and praises the exhaustive experimental evaluation. However, they also mention that the technical contribution is small and the advantage is limited to a 2x reduction in memory. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents both positives and negatives in a professional manner without using harsh or overly critical language. The review is structured and objective, listing both positive and negative aspects without personal attacks or overly emotional language."", ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the paper's contributions and rigorous evaluations, but also points out a significant missing element (comparison of training and testing speeds). The politeness score is 75 (quite polite) as the reviewer uses respectful language, acknowledges the paper's strengths, and frames the criticism constructively as a suggestion for improvement rather than a harsh critique. The reviewer uses phrases like 'The paper consistently shows' and 'It would be very valuable to add' which contribute to the polite tone."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, highlighting its extensive experiments, potential impact, and the expectation that the techniques will become standard practice. The reviewer uses phrases like 'hugely impactful' and 'strong paper'. The few concerns raised are presented as constructive feedback rather than major criticisms. The politeness score is 70 (polite) due to the reviewer's respectful tone throughout. They balance praise with constructive criticism, use phrases like 'I suggest' for recommendations, and maintain a professional, objective tone. The reviewer also acknowledges the potential impact of the work and provides detailed, helpful feedback, which contributes to the polite tone.""]"
"['Summary\n---\nThis work applies a representaion learning technique that segments entities to learn simple 2d intuitive physics without per-entity supervision. It adds a relational mechanism to Neural Expectation Maximization and shows that this mechanism provides a better simulation of bouncing balls in a synthetic environment.\n\nNeural Expectation Maximization (NEM) decomposes an image into K latent variables (vectors of reals) theta_k. A decoder network reconstructs K images from each of these latent variables and these K images are combined into a single reconstruction using pixel-wise mixture components that place more weight on pixels that match the ground truth. An encoder network f_enc() then updates the latent variables to better explain the reconstructions they produced.\nThe neural nets are learned so that the latent variables reconstruct the image well when used by the mixture model and match a prior otherwise. Previously NEM has been shown to learn variables which represent individual objects (simple shapes) in a compositional manner, using one variable per object.\n\nOther recent neural models can learn to simulate simple 2d physics environments (balls bouncing around in a 2d plane). That work supervises the representation for each entity (ball) explicitly using states (e.g. position and velocity of balls) which are known from the physics simulator used to generate the training data. The key feature of these models is the use of a pairwise embedding of an object and its neighbors (message passing) to predict the object\'s next state in the simulation.\n\nThis paper paper combines the two methods to create Relational Neural Expectation Maximization (R-NEM), allowing direct interaction at inference time between the latent variables that encode a scene. The encoder network from NEM can be seen as a recurrent network which takes one latent variable theta_k at time t and some input x to produce the next latent variable theta_k at time t+1. R-NEM adds a relational module which computes an embedding used as a third input to the recurrent encoder. Like previous relational models, this one uses a pairwise embedding of the object being updated (object k) and its neighbors. Unlike previous neural physics models, R-NEM uses a soft attention mechanism to determine which objects are neighbors and which are not. Also unlike previous neural models, this method does not require per-object supervision.\n\nExperiments show that R-NEM learns compositional representations that support intuitive physics more effectively than ablative baselines. These experiments\nshow:\n1) R-NEM reconstructs images more accurately than baselines (RNN/LSTM) and NEM (without object interaction).\n2) R-NEM is trained with 4 objects per image. It does a bit worse at reconstructing images with 6-8 objects per image, but still performs better than baselines.\n3) A version of R-NEM without neighborhood attention in the relation module matches the performance of R-NEM using 4 objects and performs worse than R-NEM at 6-8 objects.\n4) R-NEM learns representations which factorize into one latent variable per object as measured by the Adjusted Rand Index, which compares NEM\'s pixel clustering to a ground truth clustering with one cluster per object.\n5) Qualitative and quantitative results show that R-NEM can simulate 2d ball physics for many time steps more effectively than an RNN and while only suffering gradual divergence from the ground truth simulation.\n\nQualitative results show that the attentional mechanism attends to objects which are close to the context object together, acting like the heuristic neighborhood mechanism from previous work.\n\nFollow up experiments extend the basic setup significantly. One experiment shows that R-NEM demonstrates object permanence by correctly tracking a collision when one of the objects is completely occluded. Another experiment applies the method to the Space Invaders Atari game, showing that it treats columns of aliens as entities. This representation aligns with the game\'s goal.\n\n\nStrengths\n---\n\nThe paper presents a clear, convincing, and well illustrated story.\n\nWeaknesses\n---\n\n* RNN-EM BCE results are missing from the simulation plot (right of figure 4).\n\nMinor comments/concerns:\n\n* 2nd paragraph in section 4: Are parameters shared between these 3 MLPs (enc,emb,eff)? I guess not, but this is ambiguous.\n\n* When R-NEM is tested against 6-8 balls is K set to the number of balls plus 1? How does performance vary with the number of objects?\n\n* Previous methods report performance across simulations of a variety of physical phenomena (e.g., see ""Visual Interaction Networks""). It seems that supervision isn\'t needed for bouncing ball physics, but I wonder if this is the case for other kinds of phenomena (e.g., springs in the VIN paper). Can this method eliminate the need for per-entity supervision in this domain?\n\n* A follow up to the previous comment: Could a supervised baseline that uses per-entity state supervision and neural message passsing (like the NPE from Chang et. al.) be included?\n\n* It\'s a bit hard to qualitatively judge the quality of the simulations without videos to look at. Could videos of simulations be uploaded (e.g., via anonymous google drive folder as in ""Visual Interaction Networks"")?\n\n* This uses a neural message passing mechanism like those of Chang et. al. and Battaglia et. al. It would be nice to see a citation to neural message passing outside of the physics simulation domain (e.g. to ""Neural Message Passing for Quantum Chemistry"" by Gilmer et. al. in ICML17).\n\n* Some work uses neighborhood attention coefficients for neural message passing. It would be nice to see a citation included.\n    * See ""Neighborhood Attention"" in ""One-Shot Imitation Learning"" by Duan et. al. in NIPS17\n    * Also see ""Programmable Agents"" by Denil et. al.\n\n\nFinal Evaluation\n---\n\nThis paper clearly advances the body of work on neural intuitive physics by incorporating NEM entity representation to allow for less supervision. Alternatively, it adds a message passing mechanism to the NEM entity representation technique. These are moderately novel contributions and there are only minor weaknesses, so this is a clear accept.', 'Summary:\nThe manuscript extends the Neural Expectation Maximization framework by integrating an interaction function that allows asymmetric pairwise effects between objects. The network is demonstrated to learn compositional object representations which group together pixels, optimizing a predictive coding objective. The effectiveness of the approach is demonstrated on bouncing balls sequences and gameplay videos from Space Invaders. The proposed R-NEM model generalizes\n\nReview:\nVery interesting work and the proposed approach is well explained. The experimental section could be improved.\nI have a few questions/comments:\n1) Some limitations could have been discussed, e.g. how would the model perform on sequences involving more complicated deformations of objects than in the Space Invaders experiment? As you always take the first frame of the 4-frame stacks in the data set, do the objects deform at all?\n2) It would have been interesting to vary K, e.g. study the behaviour for K in {1,5,10,25,50}. In Space Invaders the model would probably really group together separate objects. What happens if you train with K=8 on sequences of 4 balls and then run on 8-ball sequences instead of providing (approximately) the right number of components both at training and test time (in the extrapolation experiment).\n3) One work that should be mentioned in the related work section is Michalski et al. (2014), which also uses noise and predictive coding to model sequences of bouncing balls and NORBvideos. Their model uses a factorization that also discovers relations between components of the frames, but in contrast to R-NEM the components overlap.\n4) A quantitative evaluation of the bouncing balls with curtain and Space Invaders experiments would be useful for comparison.\n5) I think the hyperparameters of the RNN and LSTM are missing from the manuscript. Did you perform any hyperparameter optimization on these models?\n6) Stronger baselines would improve the experimental section, maybe Seo et al (2016). Alternatively, you could train the model on Moving MNIST (Srivastava et al., 2015) and compare with other published results.\n\nI would consider increasing the score, if at least some of the above points are sufficiently addressed.\n\nReferences:\nMichalski, Vincent, Roland Memisevic, and Kishore Konda. ""Modeling deep temporal dependencies with recurrent grammar cells""""."" In Advances in neural information processing systems, pp. 1925-1933. 2014.\nSeo, Youngjoo, Michaël Defferrard, Pierre Vandergheynst, and Xavier Bresson. ""Structured sequence modeling with graph convolutional recurrent networks."" arXiv preprint arXiv:1612.07659 (2016).\nSrivastava, Nitish, Elman Mansimov, and Ruslan Salakhudinov. ""Unsupervised learning of video representations using lstms."" In International Conference on Machine Learning, pp. 843-852. 2015.', 'This was a pretty interesting read. Thanks. A few comments: \n\nOne sentence that got me confused is this: “Unlike other work (Battaglia et al., 2016) this function is not commutative and we opt for a clear separation between the focus object k and the context object i as in previous work (Chang et al., 2016)”. What exactly is not commutative? The formulation seems completely align with the work of Battaglia et al, with the difference that one additionally has an attention on which edges should be considered (attention on effects). What is the difference to Battaglia et al. that this should highlight? \n\nI don’t think is very explicit what k is in the experiments with bouncing balls. Is it 5 in all of them ? When running with 6-8 balls, how are balls grouped together to form just 5 objects? \n\nIs there any chance of releasing the code/ data used in this experiments? ']","[80, 50, 50]","[60, 75, 70]","[""The sentiment score is 80 (positive) because the reviewer states 'This paper clearly advances the body of work' and concludes with 'this is a clear accept'. They also mention several strengths and only minor weaknesses. The politeness score is 60 (somewhat polite) because the reviewer uses respectful language throughout, acknowledges the paper's contributions, and phrases criticisms constructively as suggestions or questions. However, they don't use overtly polite language or praise excessively, maintaining a professional tone. The review is structured clearly with separate sections for strengths, weaknesses, and minor comments, which is considerate to the authors."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by calling the work 'Very interesting' and states the approach is 'well explained', indicating a positive view. However, they also note areas for improvement and provide a list of questions/comments, suggesting a balanced perspective rather than overwhelmingly positive. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as suggestions or questions, and ends with a constructive note about potentially increasing the score if points are addressed. The tone is professional and courteous, avoiding harsh or dismissive language."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by saying it was 'a pretty interesting read' and thanking the authors, indicating a generally positive view. However, they then raise some questions and points of confusion, balancing out the initial positivity. The politeness score is 70 (fairly polite) because the reviewer uses polite language throughout, starting with thanks and framing their comments as questions or suggestions rather than criticisms. They use phrases like 'Is there any chance...' which is a very polite way to make a request. The tone is consistently respectful and constructive.""]"
"['The paper spends lots of (repeated)  texts on motivating and explaining ISS. But the algorithm is simple, using group lasso to find components that are can retained to preserve the performance.  Thus the novelty is limited.\n\nThe experiments results are good.\n\nSec 3.1 should be made more concise. ', 'The authors propose a technique to compress LSTMs in RNNs by using a group Lasso regularizer which results in structured sparsity, by eliminating individual hidden layer inputs at a particular layer. The authors present experiments on unidirectional and bidirectional LSTM models which demonstrate the effectiveness of this method. The proposed techniques are evaluated on two models: a fairly large LSTM with ~66.0M parameters, as well as a more compact LSTM with ~2.7M parameters, which can be sped up significantly through compression.\nOverall this is a clearly written paper that is easy to follow, with experiments that are well motivated. To the best of my knowledge most previous papers in the area of RNN compression focus on pruning or compression of the node outputs/connections, but do not focus as much on reducing the computation/parameters within an RNN cell. I only have a few minor comments/suggestions which are listed below:\n\n1. It is interesting that the model structure where the number of parameters is reduced to the number of ISSs chosen from the proposed procedure does not attain the same performance as when training with a larger number of nodes, with the group lasso regularizer. It would be interesting to conduct experiments for a range of \\lambda values: i.e., to allow for different degrees of compression, and then examine whether the model trained from scratch with the “optimal” structure achieves performance closer to the ISS-based strategy, for example, for smaller amounts of compression, this might be the case?\n\n2. In the experiment, the authors use a weaker dropout when training with ISS. Could the authors also report performance for the baseline model if trained with the same dropout (but without the group LASSO regularizer)?\n\n3. The colors in the figures: especially the blue vs. green contrast is really hard to see. It might be nicer to use lighter colors, which are more distinct.\n\n4. The authors mention that the thresholding operation to zero-out weights based on the hyperparameter \\tau is applied “after each iteration”. What is an iteration in this context? An epoch, a few mini-batch updates, per mini-batch? Could the authors please clarify.\n\n5. Clarification about the hyperparameter \\tau used for sparsification: Is \\tau determined purely based on the converged weight values in the model when trained without the group LASSO constraint? It would be interesting to plot a histogram of weight values in the baseline model, and perhaps also after the group LASSO regularized training.\n\n6. Is the same value of \\lambda used for all groups in the model? It would be interesting to consider the effect of using stronger sparsification in the earlier layers, for example.\n\n7. Section 4.2: Please explain what the exact match (EM) and F1 metrics used to measure performance of the BIDAF model are, in the text. \n\nMinor Typographical/Grammatical errors:\n- Sec 1: “... in LSTMs meanwhile maintains the dimension consistency.” → “... in LSTMs while maintaining the dimension consistency.”\n- Sec 1: “... is public available” → “is publically available”\n- Sec 2: Please rephrase: “After learning those structures, compact LSTM units remain original structural schematic but have the sizes reduced.”\n- Sec 4.1: “The exactly same training scheme of the baseline ...” → “The same training scheme as the baseline ...”', 'Quality: \nThe motivation and experimentation is sound.\n\nOriginality:\nThis work is a natural follow up on previous work that used group lasso for CNNs, namely learning sparse RNNs with group-lasso. Not very original, but nevertheless important.\n\nClarity:\nThe fact that the method is using a group-lasso regularization is hidden in the intro section and only fully mentioned in section 3.2 I would mention that clearly in the abstract.\n\nSignificance:\nLeaning small models is important and previous sparse RNN work (Narang, 2017) did not do it in a structured way, which may lead to slower inference step time. So this is an investigation of interest for the community.\n\nMinor comments:\n- One main claim in the paper is that group lasso is better than removing individual weights, yet not experimental evidence is provided for that.\n- The authors found that their method beats ""direct design"". This is somewhat unintuitive, yet no explanation is provided. ']","[-20, 80, 50]","[0, 90, 75]","['The sentiment score is slightly negative (-20) because the reviewer points out limited novelty and suggests making a section more concise, indicating some criticism. However, they also mention that the experimental results are good, which balances the negative aspects somewhat. The politeness score is neutral (0) as the language used is direct and matter-of-fact, without being particularly polite or rude. The reviewer states their observations plainly without using overly harsh language or excessive praise.', ""The sentiment score is 80 (positive) because the reviewer starts by praising the paper as 'clearly written' and 'easy to follow', with 'well motivated' experiments. They also note the novelty of the approach. The overall tone is very positive, with only 'minor comments/suggestions' offered. The politeness score is 90 (very polite) due to the consistently respectful and constructive language used throughout. The reviewer offers suggestions phrased as questions or polite requests (e.g., 'Could the authors...', 'It would be interesting...'). They also acknowledge the authors' work positively before offering suggestions. The minor grammatical corrections are presented neutrally at the end, without criticism. The high scores reflect the reviewer's overall positive and courteous approach to providing feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the sound motivation and experimentation, the importance of the work, and its significance for the community. However, they also point out some limitations in originality and clarity. The politeness score is 75 (fairly polite) as the reviewer uses respectful language throughout, offers constructive criticism, and balances positive and negative feedback. They use phrases like 'sound,' 'important,' and 'investigation of interest' which contribute to a polite tone. The reviewer also provides specific suggestions for improvement without using harsh or dismissive language.""]"
"[""Overall, this work seems like a reasonable attempt to answer the question of how the empirical loss landscape relates to the true population loss landscape.  The analysis answers:\n\n1) When empirical gradients are close to true gradients\n2) When empirical isolated saddle points are close to true isolated saddle points\n3) When the empirical risk is close to the true risk.\n\nThe answers are all of the form that if the number of training examples exceeds a quantity that grows with the number of layers, width and the exponential of the norm of the weights with respect to depth, then empirical quantities will be close to true quantities.  I have not verified the proofs in this paper (given short notice to review) but the scaling laws in the upper bounds found seem reasonably correct. \n\nAnother reviewer's worry about why depth plays a role in the convergence of empirical to true values in deep linear networks is a reasonable worry, but I suspect that depth will necessarily play a role even in deep linear nets because the backpropagation of gradients in linear nets can still lead to exponential propagation of errors between empirical and true quantities due to finite training data.  Moreover the loss surface of deep linear networks depends on depth even though the expressive capacity does not.   An analysis of dynamics on this loss surface was presented in Saxe et. al. ICLR 2014 which could be cited to address that reviewer's concern.  However, the reviewer's suggestion that the results be compared to what is known more exactly for simple linear regression is a nice one. \n\nOverall, I believe this paper is a nice contribution to the deep learning theory literature. However,  it would even better to help the reader with more intuitive statements about the implications of their results for practice, and the gap between their upper bounds and practice, especially given the intense interest in the generalization error problem.   Because their upper bounds look similar to those based on Rademacher complexity or VC dimension (although they claim theirs are a little tighter) - they should put numbers in to their upper bounds taken from trained neural networks, and see what the numerical evaluation of their upper bounds turn out to be in situations of practical interest where deep networks show good generalization performance despite having significantly less training data than number of parameters.  I suspect their upper bounds will be loose, but still  - it would be an excellent contribution to the literature to quantitatively compare theory and practice with bounds that are claimed to be slightly tigher than previous bounds.  Even if they are loose - identifying the degree of looseness could inspire interesting future work. \n"", ""This paper provides the analysis of empirical risk landscape for GENERAL deep neural networks (DNNs). Assumptions are comparable to existing results for OVERSIMPLIFED shallow neural networks. The main results analyzed: 1) Correspondence of non-degenerate stationary points between empirical risk and the population counterparts. 2) Uniform convergence of the empirical risk to population risk. 3) Generalization bound based on stability. The theory is first developed for linear DNNs and then generalized to nonlinear DNNs with sigmoid activations.\n\nHere are two detailed comments:\n\n1) For deep linear networks with squared loss, Kawaguchi 2016 has shown that the global optima are the only non-degerenate stationary points. Thus, the obtained non-degerenate stationary deep linear network should be equivalent to the linear regression model Y=XW. Should the risk bound only depends on the dimensions of the matrix W?\n\n2) The comparison with Bartlett & Maass’s (BM) work is a bit unfair, because their result holds for polynomial activations while this paper handles linear activations. Thus, the authors need to refine BM's result for comparison."", 'This paper studies empirical risk in deep neural networks. Results are provided in Section 4 for linear networks and in Section 5 for nonlinear networks.\nResults for deep linear neural networks are puzzling. Whatever the number of layers, a deep linear NN is simply a matrix multiplication and minimizing the MSE is simply a linear regression. So results in Section 4 are just results for linear regression and I do not understand why the number of layers come into play? \nAlso this is never explicitly mentioned in the paper, I guess the authors make an assumption that the samples (x_i,y_i) are drawn i.i.d. from a given distribution D. In such a case, I am sure results on the population risk minimization can be found for linear regression and should be compare to results in Section 4.\n\n']","[60, 20, -50]","[80, 50, 0]","[""The sentiment score is 60 (positive) because the reviewer generally expresses approval of the paper, calling it a 'nice contribution' and a 'reasonable attempt'. They provide constructive feedback and suggestions for improvement, indicating overall positive sentiment. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms as suggestions for improvement rather than harsh critiques. They use phrases like 'I believe', 'it would be even better', and 'nice suggestion', which contribute to a polite tone. The reviewer also shows consideration by mentioning the short notice given for the review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions in analyzing empirical risk landscape for general deep neural networks and provides a summary of the main results. However, the reviewer also raises two specific concerns, which tempers the overall positive sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout and frames their comments as suggestions rather than criticisms. The reviewer begins with a summary of the paper's strengths before moving on to their concerns, which is a polite approach. The specific comments are presented as questions or observations rather than direct criticisms, maintaining a respectful tone."", ""The sentiment score is -50 because the reviewer expresses confusion and skepticism about the paper's results, particularly in the section on deep linear neural networks. The reviewer points out that the results seem to be simply those of linear regression and questions why the number of layers is relevant. They also note that important assumptions are not explicitly mentioned in the paper. These criticisms indicate a negative sentiment, though not extremely harsh.\n\nThe politeness score is 0 (neutral) because the reviewer's language is neither particularly polite nor rude. They express their concerns directly without using overly harsh language, but also without any notably courteous phrasing. The tone is professional and matter-of-fact, focusing on the content of the paper rather than personal comments or excessive formalities.""]"
"[""The paper was a good contribution to domain adaptation. It provided a new way of looking at the problem by using the cluster assumption. The experimental evaluation was very thorough and shows that VADA and DIRT-T performs really well. \n\nI found the math to be a bit problematic. For example, L_d in (4) involves a max operator. Although I understand what the authors mean, I don't think this is the correct way to write this. (5) should discuss the min-max objective. This will probably involve an explanation of the gradient reversal etc. Speaking of GRL, it's mentioned on p.6 that they replaced GRL with the traditional GAN objective. This is actually pretty important to discuss in detail: did that change the symmetric nature of domain-adversarial training to the asymmetric nature of traditional GAN training? Why was that important to the authors?\n\nThe literature review could also include Shrivastava et al. and Bousmalis et al. from CVPR 2017. The latter also had MNIST/MNIST-M experiments."", ""This paper presents two complementary models for unsupervised domain adaptation (classification task): 1) the Virtual Adversarial Domain Adaptation (VADA) and 2) the Decision-boundary Iterative Refinement Training with a Teacher (DIRT-T). The authors make use of the so-called cluster assumption, i.e., decision boundaries should not cross high-density data regions. VADA extends the standard Domain-Adversarial training by introducing an additional objective L_t that measures the target-side cluster assumption violation, namely, the conditional entropy w.r.t. the target distribution. Since the empirical estimate of the conditional entropy breaks down for non-locally-Lipschitz classifiers, the authors also propose to incorporate virtual adversarial training in order to make the classifier well-behaved. The paper also argues that the performance on the target domain can be further improved by a post-hoc minimization of L_t using natural gradient descent (DIRT-T) which ensures that the decision boundary changes incrementally and slowly.    \n\nPros:\n+ The paper is written clearly and easy to read\n+ The idea to keep the decision boundary in the low-density region of the target domain makes sense\n+ The both proposed methods seem to be quite easy to implement and incorporate into existing DATNN-based frameworks\n+ The combination of VADA and DIRT-T performs better than existing DA algorithms on a range of visual DA benchmarks\n\nCons:\n- Table 1 can be a bit misleading as the performance improvements may be partially attributed to the fact that different methods employ different base NN architectures and different optimizers\n- The paper deals exclusively with visual domains; applying the proposed methods to other modalities would make this submission stronger\n\nOverall, I think it is a good paper and deserves to be accepted to the conference. I’m especially appealed by the fact that the ideas presented in this work, despite being simple, demonstrate excellent performance.\n\nPost-rebuttal revision:\nAfter reading the authors' response to my review, I decided to leave the score as is."", 'As there are many kinds of domain adaptation problems, the need to mix several learning strategies to improve the existing approaches is obvious. However, this task is not necessarily easy to succeed. The authors proposed a sound approach to learn a proper representation (in an adversarial way) and comply the cluster assumption.\n\nThe experiments show that this Virtual Adversarial Domain Adaptation network (VADA) achieves great results when compared to existing learning algorithms. Moreover, we also see the learned model is consistently improved using the proposed ""Decision-boundary Iterative Refinement Training with a Teacher"" (DIRT-T) approach.\n\nThe proposed methodology relies on multiple choices that could sometimes be better studied and/or explained. Namely, I would like to empirically see which role of the locally-Lipschitz regularization term (Equation 7). Also, I wonder why this term is tuned by an hyperparameter (lamda_s) for the source, while a single hyperparamer (lambda_t) is used for the sum of the two target quantity.\n \nOn the theoretical side, the discussion could be improved. Namely, Section 3 about ""limitation of domain adversarial training"" correctly explained that ""domain adversarial training may not be sufficient for domain adaptation if the feature extraction function has high-capacity"". It would be interesting to explain whether this observation is consistent with Theorem 1 of the paper (due to Ben-David et al., 2010), on which several domain adversarial approaches are based. The need to consider supplementary assumptions (such as ) to achieve good adaptation can also be studied through the lens of more recent Ben-David\'s work, e.g. Ben-David and Urner (2014). In the latter, the notion of ""Probabilistic Lipschitzness"", which is a relaxation of the ""cluster assumption"" seems very related to the actual work.\n\nReference:\nBen-David and Urner. Domain adaptation-can quantity compensate for quality?, Ann. Math. Artif. Intell., 2014\n\nPros:\n- Propose a sound approach to mix two complementary strategies for domain adaptation.\n- Great empirical results.\n\nCons:\n- Some choices leading to the optimization problem are not sufficiently explained.\n- The theoretical discussion could be improved.\n\nTypos:\n- Equation 14: In the first term (target loss), theta should have an index t (I think).\n- Bottom of page 6: ""... and that as our validation set"" (missing word).\n']","[60, 80, 60]","[50, 70, 70]","[""The sentiment score is 60 (positive) because the reviewer starts by praising the paper as 'a good contribution' and mentions that the experimental evaluation was 'very thorough' and shows that the proposed methods perform 'really well'. However, it's not extremely positive due to some criticisms about the math and literature review. The politeness score is 50 (somewhat polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. The reviewer phrases concerns as suggestions or questions rather than harsh criticisms. For example, 'I found the math to be a bit problematic' is a gentle way to introduce concerns. The reviewer also uses phrases like 'I understand what the authors mean' to soften critiques."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, stating it's 'a good paper and deserves to be accepted' and praising its clarity, sensible ideas, and excellent performance. The reviewer lists more pros than cons and is 'especially appealed' by the paper's ideas. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and offering constructive criticism. The reviewer balances positive feedback with gentle suggestions for improvement, maintaining a professional and courteous tone. The use of phrases like 'I think' and 'I'm especially appealed' adds a personal, considerate touch to the review."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the sound approach and great empirical results of the paper, while also providing constructive criticism. The overall tone is supportive, but the reviewer does point out areas for improvement. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the authors' achievements and framing criticisms as suggestions or questions. The reviewer uses phrases like 'I would like to empirically see' and 'I wonder why' instead of making demands. The review also includes a balanced 'Pros and Cons' section, further demonstrating a fair and polite approach to feedback.""]"
"['This paper explores the idea of adding parameter space noise in service of exploration. The paper is very well written and quite clear. It does a good job of contrasting parameter space noise to action space noise and evolutionary strategies.\n\nHowever, the results are weak. Parameter noise does better in some Atari + Mujoco domains, but shows little difference in most domains. The domains where parameter noise (as well as evolutionary strategies) does really well are Enduro and the Chain environment, in which a policy that repeatedly chooses a particular action will do very well. E-greedy approaches will always struggle to choose the same random action repeatedly. Chain is great as a pathological example to show the shortcomings of e-greedy, but few interesting domains exhibit such patterns. Similarly for the continuous control with sparse rewards environments – if you can construct an environment with sparse enough reward that action-space noise results in zero rewards, then clearly parameter space noise will have a better shot at learning. However, for complex domains with sparse reward (e.g. Montezuma’s Revenge) parameter space noise is just not going to get you very far.\n\nOverall, I think parameter space noise is a worthy technique to have analyzed and this paper does a good job doing just that. However, I don’t expect this technique to make a large splash in the Deep RL community, mainly because simply adding noise to the parameter space doesn’t really gain you much more than policies that are biased towards particular actions. Parameter noise is not a very smart form of exploration, but it should be acknowledged as a valid alternative to action-space noise.\n\nA non-trivial amount of work has been done to find a sensible way of adding noise to parameter space of a deep network and defining the specific distance metrics and thresholds for (dual-headed) DQN, DDPG, and TRPO.\n', 'This paper proposes a method for parameter space noise in exploration.\nRather than the ""baseline"" epsilon-greedy (that sometimes takes a single action at random)... this paper presents an method for perturbations to the policy.\nIn some domains this can be a much better approach and this is supported by experimentation.\n\nThere are several things to like about the paper:\n- Efficient exploration is a big problem for deep reinforcement learning (epsilon-greedy or Boltzmann is the de-facto baseline) and there are clearly some examples where this approach does much better.\n- The noise-scaling approach is (to my knowledge) novel, good and in my view the most valuable part of the paper.\n- This is clearly a very practical and extensible idea... the authors present good results on a whole suite of tasks.\n- The paper is clear and well written, it has a narrative and the plots/experiments tend to back this up.\n- I like the algorithm, it\'s pretty simple/clean and there\'s something obviously *right* about it (in SOME circumstances).\n\nHowever, there are also a few things to be cautious of... and some of them serious:\n- At many points in the paper the claims are quite overstated. Parameter noise on the policy won\'t necessarily get you efficient exploration... and in some cases it can even be *worse* than epsilon-greedy... if you just read this paper you might think that this was a truly general ""statistically efficient"" method for exploration (in the style of UCRL or even E^3/Rmax etc).\n- For instance, the example in 4.2 only works because the optimal solution is to go ""right"" in every timestep... if you had the network parameterized in a different way (or the actions left/right were relabelled) then this parameter noise approach would *not* work... By contrast, methods such as UCRL/PSRL and RLSVI https://arxiv.org/abs/1402.0635 *are* able to learn polynomially in this type of environment. I think the claim/motivation for this example in the bootstrapped DQN paper is more along the lines of ""deep exploration"" and you should be clear that your parameter noise does *not* address this issue.\n- That said I think that the example in 4.2 is *great* to include... you just need to be more upfront about how/why it works and  what you are banking on with the parameter-space exploration. Essentially you perform a local exploration rule in parameter space... and sometimes this is great - but you should be careful to distinguish this type of method from other approaches. This must be mentioned in section 4.2 ""does parameter space noise explore efficiently"" because the answer you seem to imply is ""yes"" ... when the answer is clearly NOT IN GENERAL... but it can still be good sometimes ;D\n- The demarcation of ""RL"" and ""evolutionary strategies"" suggests a pretty poor understanding of the literature and associated concepts. I can\'t really support the conclusion ""RL with parameter noise exploration learns more efficiently than both RL and evolutionary strategies individually"". This sort of sentence is clearly wrong and for many separate reasons:\n    - Parameter noise exploration is not a separate/new thing from RL... it\'s even been around for ages! It feels like you are talking about DQN/A3C/(whatever algorithm got good scores in Atari last year) as ""RL"" and that\'s just really not a good way to think about it.\n    - Parameter noise exploration can be *extremely* bad relative to efficient exploration methods (see section 2.4.3 https://searchworks.stanford.edu/view/11891201)\n\n\nOverall, I like the paper, I like the algorithm and I think it is a valuable contribution.\nI think the value in this paper comes from a practical/simple way to do policy randomization in deep RL.\nIn some (maybe even many of the ones you actually care about) settings this can be a really great approach, especially when compared to epsilon-greedy.\n\nHowever, I hope that you address some of the concerns I have raised in this review.\nYou shouldn\'t claim such a universal revolution to exploration / RL / evolution because I don\'t think that it\'s correct.\nFurther, I don\'t think that clarifying that this method is *not* universal/general really hurts the paper... you could just add a section in 4.2 pointing out that the ""chain"" example wouldn\'t work if you needed to do different actions at each timestep (this algorithm does *not* perform ""deep exploration"").\n\nI vote accept.', ""In recent years there have been many notable successes in deep reinforcement learning. However, in many tasks, particularly sparse reward tasks, exploration remains a difficult problem. For off-policy algorithms it is common to explore by adding noise to the policy action in action space, while on-policy algorithms are often regularized in the action space to encourage exploration. This work introduces a simple, computationally straightforward approach to exploring by perturbing the parameters (similar to exploration in some evolutionary algorithms) of policies parametrized with deep neural nets. This work argues this results in more consistent exploration and compares this approach empirically on a range of continuous and discrete tasks. By using layer norm and adaptive noise, they are able to generate robust parameter noise (it is often difficult to estimate the appropriate variance of parameter noise, as its less clear how this relates to the magnitude of variance in the action space).\n\nThis work is well-written and cites previous work appropriately. Exploration is an important topic, as it often appears to be the limiting factor of Deep RL algorithms. The authors provide a significant set of experiments using their method on several different RL algorithms in both continuous and discrete cases, and find it generally improves performance, particularly for sparse rewards.\n\nOne empirical baseline that would helpful to have would be a stochastic off-policy algorithm (both off-policy algorithms compared are deterministic), as this may better capture uncertainty about the value of actions (e.g. SVG(0) [3]).\n\nAs with any empirical results with RL, it is a challenging problem to construct comparable benchmarks due to minor variations in implementation, environment or hyper-parameters all acting as confounding variables [1]. It would be helpful if the authors are able to make their paper reproducible by releasing the code on publication. As one example, figure 4 of [1] seems to show DDPG performing much better than the DDPG baseline in this work on half-cheetah.\n\nMinor points:\n- The definition of a stochastic policy (section 2) is unusual (it is defined as an unnormalized distribution). Usually it would be defined as $\\mathcal{S} \\rightarrow \\mathcal{P}(\\mathcal{A})$\n\n- This work extends DQN to learn an explicitly parametrized policy (instead of the greedy policy) in order to useful perturb the parameters of this policy. Instead of using a single greedy target, you could consider use the relationship between the advantage function and an entropy-regularized policy [2] to construct a target.\n\n[1] Henderson, P., Islam, R., Bachman, P., Pineau, J., Precup, D., & Meger, D. (2017). Deep reinforcement learning that matters. arXiv preprint arXiv:1709.06560.\n\n[2] O'Donoghue, B., Munos, R., Kavukcuoglu, K., & Mnih, V. (2016). Combining policy gradient and Q-learning.\n\n[3] Heess, N., Wayne, G., Silver, D., Lillicrap, T., Erez, T., & Tassa, Y. (2015). Learning continuous control policies by stochastic value gradients. In Advances in Neural Information Processing Systems (pp. 2944-2952).""]","[20, 60, 80]","[80, 80, 90]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's strengths (well-written, clear, good analysis), they also point out significant limitations in the results and impact. The overall tone suggests the work is valuable but not groundbreaking. The politeness score is high (80) as the reviewer uses respectful language throughout, acknowledging the paper's merits and framing criticisms constructively. They use phrases like 'very well written,' 'good job,' and 'worthy technique,' which contribute to a polite tone even when discussing limitations."", ""The sentiment score is 60 (positive) because the reviewer expresses several positive aspects of the paper, including its novelty, practicality, and clear writing. They vote to accept the paper. However, they also raise significant concerns, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'I like the paper' and 'I hope that you address some of the concerns,' which maintain a collegial tone. The reviewer balances praise with critique in a professional manner, avoiding harsh language even when pointing out flaws."", ""The sentiment score is 80 (positive) because the reviewer describes the work as 'well-written' and states that it 'provides a significant set of experiments' and 'generally improves performance'. The reviewer also acknowledges the importance of the topic. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, offers constructive suggestions for improvement, and frames criticisms as helpful additions rather than flaws. The reviewer also acknowledges the challenges in the field and offers specific, actionable feedback. The language is professional and courteous throughout, with phrases like 'it would be helpful' and 'you could consider' when making suggestions.""]"
"['Summary: \nThe paper presents a new model called Compositional Attention Networks (CAN) for visual reasoning. The complete model consists of an input unit, a sequence of the proposed Memory, Attention and Composition (MAC) cell, and an output unit. Experiments on CLEVR dataset shows that the proposed model outperforms previous models.\n\nStrengths: \n— The idea of building a compositional model for visual reasoning and visual question answering makes a lot of sense, and, I think, is the correct direction to go forward in these fields.\n— The proposed model outperforms existing models pushing the state-of-the-art.\n— The proposed model is computationally cheaper and generalizes well with less training data as compared to existing models.\n— The proposed model has been described in detail in the paper.\n\nWeaknesses: \n— Given that the performance of state-on-art on CLEVR dataset is already very high ( <5% error) and the performance numbers of the proposed model are not very far from the previous models, it is very important to report the variance in accuracies along with the mean accuracies to determine if the performance of the proposed model is statistically significantly better than the previous models.\n— It is not clear which part of the proposed model leads to how much improvement in performance. Ablations studies are needed to justify the motivations for each of the components of the proposed model.\n— Analysis of qualitative results (including attention maps, gate values, etc.) is needed to justify if the model is actually doing what the authors think it should do. For example, the authors mention an example on page 6 at the end of Section 3.2.2, but do not justify if this is actually what the model is doing.\n— Why is it necessary to use both question and memory information to answer the question even when the question was already used to compute the memory information? I would think that including the question information helps in learning the language priors in the dataset. Have the authors looked at some qualitative examples where the model which only uses memory information gives an incorrect answer but adding the question information results in a correct answer?\n— Details such as using Glove word embeddings are important and can affect the performance of models significantly. Therefore, they should be clearly mentioned in the main paper while comparing with other models which do not use them.\n— The comparisons of number of epochs required for training and the training time need fixed batch sizes and CPU/GPU configurations. Is that true? These should be reported in this section.\n— The authors claim that their model is robust to linguistic variations and diverse vocabulary, by which I am guessing they are referring to experiments on CLEVR-Humans dataset. What is there in the architecture of the proposed model which provides this ability? If it is the Glove vectors, it should be clearly mentioned since any other model using Glove vectors should have this ability.\n— On page 6, second paragraph, the authors mention that there are cases which necessitate the model to ignore current memories. Can the authors show some qualitative examples for such cases?\n— In the intro, the authors claim that their proposed cell encourages transparency. But, the design of their cell doesn’t seem to do so, nor it is justified in the paper.\n\nOverall: The performance reported in the paper is impressive and outperforms previous state-of-the-art, but without proper statistical significance analysis of performance, ablation studies, analysis of various attention maps, memory gates, etc. and qualitative results, I am not sure if this work would be directly useful for the research community.', 'This paper proposes a recurrent neural network for visual question answering. The recurrent neural network is equipped with a carefully designed recurrent unit called MAC (Memory, Attention and Control) cell, which encourages sequential reasoning by restraining interaction between inputs and its hidden states. The proposed model shows the state-of-the-art performance on CLEVR and CLEVR-Humans dataset, which are standard benchmarks for visual reasoning problem. Additional experiments with limited training data shows the data efficiency of the model, which supports its strong generalization ability.\n\nThe proposed model in this paper is designed with reasonable motivations and shows strong experimental results in terms of overall accuracy and the data efficiency. However, an issue in the writing, usage of external component and lack of experimental justification of the design choices hinder the clear understanding of the proposed model.\n\nAn issue in the writing\nOverall, the paper is well written and easy to understand, but Section 3.2.3 (The Write Unit) has contradictory statements about their implementation. Specifically, they proposed three different ways to update the memory (simple update, self attention and memory gate), but it is not clear which method is used in the end.\n\nUsage of external component\nThe proposed model uses pretrained word vectors called GloVE, which has boosted the performance on visual question answering. This experimental setting makes fair comparison with the previous works difficult as the pre-trained word vectors are not used for the previous works. To isolate the strength of the proposed reasoning module, I ask to provide experiments without pretrained word vectors.\n\nLack of experimental justification of the design choices\nThe proposed recurrent unit contains various design choices such as separation of three different units (control unit, read unit and memory unit), attention based input processing and different memory updates stem from different motivations. However, these design choices are not justified well because there is neither ablation study nor visualization of internal states. Any analysis or empirical study on these design choices is necessary to understand the characteristics of the model. Here, I suggest to provide few visualizations of attention weights and ablation study that could support indispensability of the design choices.\n', 'This paper describes a new model architecture for machine reasoning. In contrast\nto previous approaches that explicitly predict a question-specific module\nnetwork layout, the current paper introduces a monolithic feedforward network\nwith iterated rounds of attention and memory. On a few variants of the CLEVR\ndataset, it outperforms both discrete modular approaches, existing iterated\nattention models, and the conditional-normalization-based FiLM model. \n\nSo many models are close to perfect accuracy on the standard CLEVR dataset that\nI\'m not sure how interesting these results are. In this respect I think the\ncurrent paper\'s results on CLEVR-Humans and smaller fractions of synthetic CLEVR\nare much more exciting.\n\nOn the whole I think this is a strong paper. I have two main concerns. The\nlargest is that this paper offers very little in the way of analysis. The model\nis structurally quite similar to a stacked attention network or a particular\nfixed arrangement of attentive N2NMN modules, and it\'s not at all clear based on\nthe limited set of experimental results where the improvements are actually\ncoming from. It\'s also possible that many of the proposed changes are\ncomplementary to NMN- or CBN-type models, and it would be nice to know if this\nis the case.\n\nSecondarily, the paper asserts that ""our architecture can handle\ndatasets more diverse than CLEVR"", but runs no experiments to validate this. It\nseems like once all the pieces are in place it should be very easy to get\nnumbers on VQA or even a more interesting synthetic dataset like NLVR.\n\nBased on a sibling comment, it seems that there may also be some problems with\nthe comparison to FiLM, and I would like to see this addressed.\n\nOn the whole, the results are probably strong enough on their own to justify\nadmitting this paper. But I will become much more enthusiastic about if if the\nauthors can provide results on other datasets (even if they\'re not\nstate-of-the-art!) as well as evidence for the following:\n\n1. Does the control mechanism attend to reasonable parts of the sentence?\n\nHere it\'s probably enough to generate a bunch of examples showing sentence\nattentions evolving over time.\n\n2. Do these induce reasonable attentions over regions of the image?\n\nAgain, examples are fine.\n\n3. Do the self-attention and gating mechanisms recover the right structure?\n\nIn addition to examples, here I think there are some useful qualitative\nmeasures. It should be possible to extract reasonable discretized ""reasoning\nmaps"" by running MST or just thesholding on the ""edge weights"" induced by\nattention and gating. Having extracted these from a bunch of examples, you can\ncompare them to the structural properties of the ground-truth CLEVR network\nlayouts by plotting a comparison of sizes, branching factors, etc.\n\n4. More on the left side of the dataset size / accuracy curve. What happens if\n   you only give the model 7000 examples? 700? 70?\n\nFussy typographical notes:\n\n- This paper makes use of a lot of multi-letter names in mathmode. These are\n  currently written like $KB$, which looks bad, and should instead be\n  $\\mathit{KB}$.\n\n- Variables with both superscripts and subscripts have the superscripts pushed\n  off to the right; I think you\'re writing these like $b_5 ^d$ but they should\n  just be $b_5^d$ (no space).\n\n- Number equations and then don\'t bother carrying subscripts like $W_3$, $W_4$\n  around across different parts of the model---this isn\'t helpful.\n\n- The superscripts indicating the dimensions of parameter matrices and vectors\n  are quite helpful, but don\'t seem to be explained anywhere in the text. I\n  think the notation $W^{(d \\times d)}$ is more standard than $W^{d, d}$.\n\n- Put the cell diagrams right next to the body text that describes them (maybe even\n  inline, rather than in figures). It\'s annoying to flip back and forth.']","[-20, 50, 50]","[50, 75, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they express several significant concerns and weaknesses. The overall tone suggests that the work is not yet ready for publication without major revisions. The politeness score is moderately positive (50) as the reviewer uses professional language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions for improvement rather than harsh judgments. The reviewer maintains a respectful tone while providing detailed feedback, balancing positive and negative comments."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as 'reasonable motivations' and 'strong experimental results,' while also pointing out areas for improvement. The overall tone is constructive rather than overly critical. The politeness score is 75 (quite polite) due to the reviewer's use of respectful language throughout. They offer suggestions using phrases like 'I ask to provide' and 'I suggest to provide,' which are polite ways of requesting additional information. The reviewer also balances criticism with praise, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is 50 (slightly positive) because the reviewer states 'On the whole I think this is a strong paper' and mentions that the results are 'probably strong enough on their own to justify admitting this paper'. However, they also express concerns and request additional analysis, which tempers the positivity. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and provides specific suggestions for improvement. They use phrases like 'I think' and 'I would like to see' rather than making demands. The reviewer also offers helpful typographical notes in a non-confrontational manner. The overall tone is professional and courteous, while still providing honest feedback.""]"
"[""The method is posed in the Bayesian setting, the main idea being to achieve the data augmentation through domain-guided perturbations of input instances. Different from traditional adaptation methods, where the adaptation step is applied explicitly, in this paper the authors exploit labeled instances from several domains to collectively train a system that can handle new domains without the adaptation step. While this is another way of looking at domain adaptation, it may be misleading to say 'without' adaptation step. By the gradient perturbations on multi-domain training data, the learning of the adaptation step is effectively done. This should be clarified in the paper. The notion of using 'scarce' training domains to cover possible choices for the target domain is interesting and novel. The experimental validation should also include a deeper analysis of this factor: how the proposed adaptation performance is affected by the scarcity of the training multi-domain data. While this is partially shown in Table 8, it seems that by adding more domains the performance is compromised (compared to the baseline) (?).  It would be useful to see how the model ranks the multiple domains in terms of their relatedness to the target domain. Figs 6-7 are unclear and difficult to read. The captions should provide more information about the main point of these figures. "", 'The authors proposed to perturbed the estimated domain features for data augmentation, which is done by using the gradients of label and domain classification losses. The idea is interesting and new. And the paper is well written.\n\nMy major conerns are as follows:\n1. Section 3 seems a bit too lengthy or redundant to derive the data augmentation by introducing the latent domain features g. In fact, without g, it also makes sense to perturb x as done in lines 6 and 7 in Alg. 1.\n2. The assumption in (A1) can only be guaranteed under certain theoretical conditions. The authors should provide more explanations to better convey the assumption to readers.\n\nMinors:\n1. LabelGrad was not defined when firstly being used in Section 4.\n2. Fig. 1 looks redundant.', 'Quality, clarity : Very well written, well motivated, convincing experiments and analysis\nOriginality: I think they framed the problem of domain-robustness very well: how to obtain a ""domain level embedding"" which generalizes to unseen domains. To do this the  authors introduce the CrossGrad method, which trains both a label classification task and a domain classification task (from which the domain-embedding is obtained)\nSignificance: Robustness in new domains is a very important practical and theoretical issue.\n\nPros:\n- It\'s novel, interesting, well written, and appears to work very well in the experiments provided.\n\nCons:\n- Formally, for the embedding to generalize one needs to make the ""domain continuity assumption"", which is not guaranteed to hold in any realistic settings (e.g. when there are no underlying continuous  factors) \n- The training set needs to be in the form (x,y,d) where \'d\' is a domain, this information might not exist or be only partially present.\n- A single step required 2 forward and 2 backward passes - thus is twice as expensive. \n\nConstructive comments:\n- Algorithm 1 uses both X_l and X_d, yet the text only discusses X_d, there is some symmetry, but more discussion will help.\n- LabelGrad is mentioned in section 4 but defined in section 4.1, it should be briefly defined in the first mention.', 'This paper proposed a domain generalization approach by domain-dependent data augmentation. The augmentation is guided by a network that is trained to classify a data point to different domains. Experiments on four datasets verify the effectiveness of the proposed approach. \n\nStrengths:\n+ The proposed classification model is domain-dependent, as opposed to being domain-invariant. This is new and differs from most existing works on domain adaptation/generalization, to the best of my knowledge. \n+ The experiments show that the proposed method outperforms two baselines. However, more related approaches could be included to strengthen the experiments (see below for details).\n\n\nWeaknesses:\n- The paper studies domain generalization and yet fails to position it in the right literature. By a simple search of ""domain generalization"" using Google Scholar, I found several existing works on this problem and have listed some below. The authors may consider to include them in both the related works and the experiments. \n\nQuestions: \n1. It is intuitive to directly define the data augmentation by x_i+Grad_x J_d. Why is it necessary to instead define it as the inverse transformation G^{-1}(g\') and then go through the approximations to derive the final augmentation? \n2. Is the CrossGrad training necessary? What if one trains the network in two steps? Step 1: learn G using J_d and a regularization to avoid misclassification over the labels using the original data. Step 2: Learn the classification network (possibly different from G) by the domain-dependent augmentation.\n\n\nSaeid Motiian, Marco Piccirilli, Donald A. Adjeroh, and Gianfranco Doretto. Unified deep supervised\ndomain adaptation and generalization. In IEEE International Conference on Computer\nVision (ICCV), 2017.\n\nMuandet, K., Balduzzi, D. and Schölkopf, B., 2013. Domain generalization via invariant feature representation. In Proceedings of the 30th International Conference on Machine Learning (ICML-13) (pp. 10-18).\n\nXu, Z., Li, W., Niu, L. and Xu, D., 2014, September. Exploiting low-rank structure from latent domains for domain generalization. In European Conference on Computer Vision (pp. 628-643). Springer, Cham.\n\nGhifary, M., Bastiaan Kleijn, W., Zhang, M. and Balduzzi, D., 2015. Domain generalization for object recognition with multi-task autoencoders. In Proceedings of the IEEE international conference on computer vision (pp. 2551-2559).\n\nGan, C., Yang, T. and Gong, B., 2016. Learning attributes equals multi-source domain generalization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 87-97).']","[20, 50, 80, 20]","[60, 70, 70, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and interesting aspects of the paper, such as the 'notion of using 'scarce' training domains' and the 'interesting and novel' approach. However, they also point out areas for improvement and clarification, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'it would be useful' and 'should be clarified' which maintain a polite tone while providing feedback. The reviewer also acknowledges the paper's strengths before suggesting improvements, which is a polite approach to peer review."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by acknowledging the interesting and novel idea, and mentions that the paper is well-written. However, they also express 'major concerns,' which balances out the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, such as 'The authors proposed' and 'My major concerns are as follows,' rather than using harsh or critical language. They also provide specific, constructive feedback. The reviewer maintains a professional tone while clearly communicating their concerns and suggestions for improvement."", ""The sentiment score is 80 (positive) because the reviewer expresses a very positive view of the paper, describing it as 'very well written, well motivated' with 'convincing experiments and analysis'. They also highlight its novelty, interesting nature, and effectiveness. The few cons mentioned are presented as minor concerns rather than major flaws. The politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They begin with praise, present criticisms as 'cons' rather than attacks, and offer 'constructive comments' to improve the paper. The tone is professional and supportive, avoiding any harsh or dismissive language."", 'The sentiment score is slightly positive (20) because the reviewer acknowledges some strengths of the paper, such as the novelty of the domain-dependent approach and the effectiveness shown in experiments. However, they also point out weaknesses and suggest improvements, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases their concerns as questions rather than direct criticisms. They also provide helpful suggestions for additional references and experiments, which is a polite way of pointing out areas for improvement.']"
"[""This paper proposes a formulation for discovering subtasks in Linearly-solvable MDPs. The idea is to decompose the optimal value function into a fixed set of sub value functions (each corresponding to a subtask) in a way that they best approximate (e.g. in a KL-divergence sense) the original value.\n\nAutomatically discovering hierarchies in planning/RL problems is an important problem that may provide important benefits especially in multi-task environments. In that sense, this paper makes a reasonable contribution to that goal for multitask LMDPs. The simulations also show that the discovered hierarchy can be interpreted. Although the contribution is a methodological one, from an empirical standpoint, it may be interesting to provide further evidence of the benefits of the proposed approach. Overall, it would also be useful to provide a short paragraph about similarities to the literature on discovering hierarchies in MDPs.  \n\nA few other comments and questions: \n\n- This may be a fairly naive question but given your text I'm under the impression that the goal in LMDPs is to find z(s) for all states (and Z in the multitask formulation). Then, your formulation for discovery subtasks seems to assume that Z is given. Does that mean that the LMDPs must first be solved and only then can subtasks be discovered? (The first sentence in the introduction seems to imply that there's hope of faster learning by doing hierarchical decomposition).\n\n- You motivate your approach (Section 3) using a max-variance criterion (as in PCA), yet your formulation actually uses the KL-divergence. Are these equivalent objectives in this case?\n\n\nOther (minor) comments: \n\n- In Section it would be good to define V(s) as well as 'i' in q_i (it's easy to mistake it for an index). "", 'The present paper extends a previous work by Saxe et al (2017) that considered multitask learning in RL and proposed a hierarchical learner based on concurrent execution of many actions in parallel. That framework made heavy use of the framework of linearly solvable Markov decision process (LMDP) proposed by Todorov, which allows for closed form solutions of the control due to the linearity of the Bellman optimality equations. The simple form of the solutions allow them to be composed naturally, and to form deep hierarchies through iteration. The framework is restricted to domains where the transitions are fixed but the rewards may change between tasks.  A key role is played in the formalism by the so-called ‘free dynamics’ that serves to regularize the action selected. \n\nThe present paper goes beyond Saxe et al. in several ways. First, it renders the process of deep hierarchy formation automatic, by letting the algorithm determine the new passive dynamics at each stage, as well as the subtasks themselves. The process of subtask discovery is done via non-negative matrix factorization, whereby the matrix of desirability functions, determined by the solution of the LMDPs with exponentiated reward. Since the matrix is non-negative, the authors propose a non-negative factorization into a product of non-negative low rank matrices that capture its structure at a more abstract level of detail. A family of optimization criteria for this process are suggested, based on a subclass if Bregman divergences. Interestingly, the subtasks discovered correspond to distributions over states, rather than single states as in many previous approaches. The authors present several demonstrations of the intuitive decomposition achieved. A nice feature of the present framework is that a fully autonomous scheme (given some assumed parameter values) is demonstrated for constructing the full hierarchical decomposition.  \n\nI found this to be an interesting approach to hierarchical multitask learning, augmenting a previous approach with several steps leading to increased autonomy, an essential agent for any learning agent. Both the intuition behind the construction and the application to test problem reveal novel insight. The utilization on the analytic framework of LMDP facilitates understanding and efficient algorithms. \n\nI would appreciate the authors’ clarification of several issues. First, the LMDP does not seem to be completely general, so I would appreciate a description of the limitations of this framework. The description of the elbow-joint behavior around eq. (4) was not clear to me, please expand. The authors do not state any direct or indirect extensions – please do so. Please specify how many free parameters the algorithm requires, and what is a reasonable way to select them. Finally, it would be instructive to understand where the algorithm may fail.   \n\n', 'The paper builds upon the work of Saxe et al on multitask LMDP and studies how to automatically discover useful subtasks. The key idea is to perform nonnegative matrix factorization on the desirability matrix Z to uncover the task basis.\n\nThe paper does a good job in illustrating step by step how the proposed algorithms work in simple problems. In my opinion, however, the paper falls short on two particular aspects that needs further development:\n\n(1) As far as I can tell, in all the experiments the matrix Z is computed from the MDP specification. If we adopt the proposed algorithm in an actual RL setting, however, we will need to estimate Z from data since the MDP specification is not available. I would like to see a detailed discussion on how this matrix can be estimated and also see some RL experiment results. \n\n(2) If I understand correctly, the row dimension of Z is equal to the size of the state space, so the algorithm can only be applied to tabular problem as-is. I think it is important to come up with variants of the algorithm that can scale to large state spaces.\n\nIn addition, I would encourage the authors to discuss connection to Machado et al. Despite the very different theoretical foundations, both papers deal with subtask discovery in HRL and appeal to matrix factorization techniques. I would also like to point out that this other paper is in a more complete form as it clears the issues (1) and (2) I raised above. I believe the current paper should also make further development in these two aspects  before it is published.\n\nMinor problems:\n- Pg 2, ""... can simply be taken as the resulting Markov chain under a uniformly random policy"". This statement seems problematic. The LMDP framework requires that the agent can choose any next-state distribution that has finite KL divergence from the passive dynamics, while in a standard MDP, the possible next-state distribution is always a convex combination of the transition distribution of different actions.\n\nReferences\nMachado et al. ICML 2017. A Laplacian Framework for Option Discovery in Reinforcement Learning.']","[50, 80, -30]","[80, 70, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contribution as 'reasonable' and notes that the simulations show interpretable results. However, they also suggest areas for improvement, such as providing more empirical evidence and discussing similarities to existing literature. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as suggestions (e.g., 'it may be interesting to provide...'), and frames questions as seeking clarification rather than pointing out flaws. The reviewer also acknowledges their own potential naivety in asking a question, which shows humility and respect for the authors."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'interesting' and praises its 'novel insight' and 'increased autonomy'. They also mention that the approach 'facilitates understanding and efficient algorithms'. The overall tone is appreciative of the work's contributions. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, such as 'I would appreciate the authors' clarification' and 'please expand'. They offer constructive feedback and ask for clarifications in a courteous manner. The review maintains a professional and supportive tone without any harsh criticism."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('does a good job in illustrating'), they primarily focus on shortcomings and areas needing improvement. The reviewer states the paper 'falls short on two particular aspects' and suggests significant additional work before publication. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions politely ('I would like to see', 'I would encourage'). The reviewer maintains a professional tone, avoiding harsh language while clearly communicating areas for improvement.""]"
"[""The paper is a step forward for image deep compression, at least when departing from the (Balle et al., 2017) scheme.\nThe proposed hyperpriors are especially useful for medium to high bpp and optimized for L2/ PSNR evaluation.\n\nI find the description of the maths too laconic and hard to follow. For example, what’s the U(.|.) operator in (5)?\n\nWhat’s the motivation of using GDN as non linearity instead of e.g. ReLU?\n\nI am not getting the need of MSSSIM (dB).  How exactly was it defined/computed?\n\nImportance of training data? The proposed models are trained on 1million images while others like (Theis et al, 2017) and [Ref1,Ref2] use smaller datasets for training.\n\nI am missing a discussion about Runtime / complexity vs. other approaches?\n\nWhy MSSSIM is a relevant measure? The Fig. 6 seem to show better visual results for L2 loss (PSNR) than when optimized for MSSSIM, at least in my opinion.\n\nWhat's the reason to use 4:4:4 for BPG and 4:2:0 for JPEG?\n\nWhat is the relation between hyperprior and importance maps / content-weights [Ref1] ?\n\nWhat about reproducibility of the results? Will be the codes/models made publicly available?\n\nRelevant literature:\n[Ref1] Learning Convolutional Networks for Content-weighted Image Compression (https://arxiv.org/abs/1703.10553)\n[Ref2] Soft-to-Hard Vector Quantization for End-to-End Learned Compression of Images and Neural Networks  (https://arxiv.org/abs/1704.00648)\n"", 'Summary:\n\nThis paper extends the work of Balle et al. (2016, 2017) on using certain types of variational autoencoders for image compression. After encoding pixels with a convolutional net with GDN nonlinearities, the quantized coefficients are entropy encoded. Where before the coefficients were independently encoded, the coefficients are now jointly modeled using a latent variable model. In particular, the model exploits dependencies in the scale of neighboring coefficients. The additional latent variables are used to efficiently represent these scales. Both the coefficients and the representation of the scales are quantized and encoded in the binary image representation.\n\nReview:\n\nLossy image compression using neural networks is a rapidly advancing field and of considerable interest to the ICLR community. I like the approach of using a hierarchical entropy model, which may inspire further work in this direction. It is nice to see that the variational approach may be able to outperform the more complicated state-of-the-art approach of Rippel and Bourdev (2017). That said, the evaluation is in terms of MS-SSIM and only the network directly optimized for MS-SSIM outperformed the adversarial approach of R&B. Since the reconstructions generated by a network optimized for MSE tend to look better than those of the MS-SSIM network (Figure 6), I am wondering if the proposed approach is indeed outperforming R&B or just exploiting a weakness of MS-SSIM. It would have been great if the authors included a comparison based on human judgments or at least a side-by-side comparison of reconstructions generated by the two approaches.\n\nIt might be interesting to relate the entropy model used here to other work involving scale mixtures, e.g. the field of Gaussian scale mixtures (Lyu & Simoncelli, 2007).\n\nAnother interesting comparison might be to other compression approaches where scale mixtures were used and pixels were encoded together with scales (e.g., van den Oord & Schrauwen, 2017).\n\nThe authors combine their approach using MS-SSIM as distortion. Is this technically still a VAE? Might be worth discussing.\n\nI did not quite follow the motivation for convolving the prior distributions with a uniform distribution.\n\nThe paper is mostly well written and clear. Minor suggestions:\n\n–\xa0On page 3 the paper talks about “the true posterior” of a model which hasn’t been defined yet. Although most readers will not stumble here as they will be familiar with VAEs, perhaps mention first that the generative model is defined over both $x$ and $\\tilde y$.\n\n–\xa0Below Equation 2 it sounds like the authors claim that the entropy of the uniform distribution is zero independent of its width.\n\n–\xa0Equation 7 is missing some $\\tilde z$.\n\n–\xa0The operational diagram in Figure 3 is missing a “|”.', '\nAuthors propose a transform coding solution by extending the work in Balle 2016. They define an hyperprior for the entropy coder to model the spatial relation between the transformed coefficients.    \n\nThe paper is well written, although I had trouble following some parts. The results of the proposal are state-of-the-art, and there is an extremely exhaustive comparison with many methods.\n\nIn my opinion the work has a good quality to be presented at the ICLR. However, I think it could be excellent if some parts are improved. Below I detail some parts that I think could be improved.\n\n\n*** MAIN ISSUES\n\nI have two main concerns about motivation that are related. The first refers to hyperprior motivation. It is not clear why, if GDN was proposed to eliminate statistical dependencies between pixels in the image, the main motivation is that GDN coefficients are not independent. Perhaps this confusion could be resolved by broadening the explanation in Figure 2. My second concern is that it is not clear why it is better to modify the probability distribution for the entropy encoder than to improve the GDN model. I think this is a very interesting issue, although it may be outside the scope of this work. As far as I know, there is no theoretical solution to find the right balance between the complexity of transformation and the entropy encoder. However, it would be interesting to discuss this as it is the main novelty of the work compared to other methods of image compression based on deep learning. \n\n*** OTHER ISSUES \n\nINTRODUCTION\n\n-""...because our models are optimized end-to-end, they minimize the total expected code length by learning to balance the amount of side information with the expected improvement of the entropy model."" \nI think this point is very interesting, it would be good to see some numbers of how this happens for the results presented, and also during the training procedure. For example, a simple comparison of the number of bits in the signal and side information depending on the compression rate or the number of iterations during model training.  \n\n\nCOMPRESSION WITH VARIATIONAL MODELS\n\n- There is something missing in the sentence: ""...such as arithmetic coding () and transmitted...""\n\n- Fig1. To me it is not clear how to read the left hand schemes. Could it be possible to include the distributions specifically? Also it is strange that there is a \\tiled{y} in both schemes but with different conditional dependencies. Another thing is that the symbol ψ appears in this figure and is not used in section 2. \n\n- It would be easier to follow if change the symbols of the functions parameters by something like \\theta_a and \\theta_s.\n\n- ""Distortion is the expected difference between..."" Why is the ""expected"" word used here? \n\n- ""...and substituting additive uniform noise..."" is this phrase correct? Are authors is Balle 2016 substituting additive uniform noise?   \n\n- In equation (1), is the first term zero or constant? when talking about equation (7) authors say ""Again, the first term is constant,..."".\n\n- The sentence ""Most previous work assumes..."" sounds strange.\n\n- The example in Fig. 2 is extremely important to understand the motivation behind the hyperprior but I think it needs a little more explanation. This example is so important that it may need to be explained at the beginning of the work. Is this a real example, of a model trained without and with normalization? If so specify it please. Why is GDN not able to eliminate these spatial dependencies? Would these dependencies be eliminated if normalization were applied between spatial coefficients? Could you remove dependencies with more layers or different parameters in the GDN?\n\nINTRODUCTION OF A SCALE HYPERPRIOR\n\n- TYPO ""...from the center pane of...""\n\n- ""...and propose the following extension of the model (figure 3):"" there is nothing after the colon. Maybe there is something missing, or maybe it should be a dot instead of a colon. However to me there is a lack of explanation about the model. \n\n \nRESULTS\n\n- ""...,the probability mass functions P_ŷi need to be constructed “on the fly”...""\nHow computationally costly is this? \n\n- ""...batch normalization or learning rate decay were found to have no beneficial effect (this may be due to the local normalization properties of GDN, which contain global normalization as a special case).""\n\nThis is extremely interesting. I see the connection for batch normalization, but not for decay of the learning rate. Please, clarify it. Does this mean that when using GDN instead of regular nonlinearity we no longer need to use batch normalization? Or in other words, do you think that batch normalization is useful only because it is special case of GSN? It would be useful for the community to assess what are the benefits of local normalization versus global normalization.\n\n- ""...each of these combinations with 8 different values of λ in order to cover a range of rate–distortion tradeoffs."" \n\nWould it be possible with your methods including \\lambda as an input and the model parameters as side information?\n\n- I guess you included the side information when computing the total entropy (or number of bits), was there a different way of compressing the image and the side information?\n\n- Using the same metrics to train and to evaluate is a little bit misleading. Evaluation plots using a different perceptual metric would be helpful. \n\n-""Since MS-SSIM yields values between 0 (worst) and 1 (best), and most of the compared methods achieve values well above 0.9, we converted the quantity to decibels in order to improve legibility."" \nAre differences of MS-SSIM with this conversion significant? Is this transformation necessary, I lose the intuition. Besides, probably is my fault but I have not being able to ""unconvert"" the dB to MS-SSIM units, for instance 20*log10(1)= 20 but most curves surpass this value.  \n\n- ""..., results differ substantially depending on which distortion metric is used in the loss function during training.""   \nIt would be informative to understand how the parameters change depending on the metric employed, or at least get an intuition about which set of parameters adapt more g_a, g_s, h_a and h_s.\n\n- Figs 5, 8 and 9. How are the curves aggregated for different images? Is it the mean for each rate value? Note that depending on how this is done it could be totally misleading.\n \t\n- It would be nice to include results from other methods (like the BPG and Rippel 2017) to compare with visually.\n\nRELATED WORK\n\nBalle et al. already published a work including a perceptual metric in the end-to-end training procedure, which I think is one of the main contributions of this work. Please include it in related work:\n\n""End-to-end optimization of nonlinear transform codes for perceptual quality."" J. Ballé, V. Laparra, and E.P. Simoncelli. PCS: Picture Coding Symposium, (2016) \n\nDISCUSSION\n\nFirst paragraphs of discussion section look more like a second section of ""related work"". \nI think it is more interesting if the authors discuss the relevance of putting effort into modelling hyperprior or the distribution of images (or transformation). Are these things equivalent? Or is there some reason why we can\'t include hyperprior modeling in the g_a transformation? For me it is not clear why we should model the distribution of outputs as, in principle, the g_a transformation has to enforce (using the training procedure) that the transformed data follow the imposed distribution. Is it because the GDN is not powerful enough to make the outputs independent? or is it because it is beneficial in compression to divide the problem into two parts?   \n\nREFERENCES\n\n- Balle 2016 and Theis 2017 seem to be published in the same conference the same year. Using different years for the references is confusing.\n\n- There is something strange with these references\n\nBallé, J, V Laparra, and E P Simoncelli (2016). “Density Modeling of Images using a Generalized\nNormalization Transformation”. In: Int’l. Conf. on Learning Representations (ICLR2016). URL :\nhttps://arxiv.org/abs/1511.06281.\nBallé, Valero Laparra, and Eero P. Simoncelli (2015). “Density Modeling of Images Using a Gen-\neralized Normalization Transformation”. In: arXiv e-prints. Published as a conference paper at\nthe 4th International Conference for Learning Representations, San Juan, 2016. arXiv: 1511.\n06281.\n– (2016). “End-to-end Optimized Image Compression”. In: arXiv e-prints. 5th Int. Conf. for Learn-\ning Representations.\n\n']","[50, 50, 50]","[75, 80, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by acknowledging the paper as 'a step forward for image deep compression' and notes that the proposed hyperpriors are 'especially useful'. However, this positive sentiment is balanced by several critiques and questions throughout the review. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, framing critiques as questions or suggestions rather than direct criticisms. For example, they use phrases like 'I find', 'I am not getting', and 'I am missing' to introduce their points, which maintains a polite tone. The reviewer also provides constructive feedback and suggestions for improvement, which is a polite approach to peer review."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses appreciation for the approach and its potential impact, but also raises some concerns and suggests additional comparisons. The reviewer states 'I like the approach' and 'It is nice to see', indicating positive sentiment. However, they also express doubts about whether the approach truly outperforms others and suggest additional evaluations.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions positively. Phrases like 'It would have been great if' and 'Might be worth discussing' demonstrate a polite tone. The reviewer also acknowledges the paper's strengths before offering critiques.\n\nThe review maintains a professional and courteous tone throughout, balancing praise with constructive feedback, which is characteristic of a well-written, polite peer review."", ""The sentiment score is 50 (moderately positive) because the reviewer states the paper is 'well written' and has 'good quality to be presented at the ICLR'. They also mention the results are 'state-of-the-art'. However, they express some concerns and suggest improvements, which prevents a higher score. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as opportunities for improvement rather than flaws. They use phrases like 'I think it could be excellent if some parts are improved' and 'it would be interesting to discuss', which maintain a collegial tone. The reviewer also acknowledges when issues might be their own misunderstanding, such as 'probably is my fault but I have not being able to...'. This balanced and considerate approach contributes to the high politeness score.""]"
"['This paper studies the application of different existing active learning strategies for the deep models for NER.\n\nPros:\n* Active learning may be used for improving the performance of deep models for NER in practice\n* All the proposed approaches are sound and the experimental results showed that active learning is beneficial for the deep models for NER\n\nCons:\n* The novelty of this paper is marginal. The proposed approaches turn out to be a combination of existing active learning strategies for selecting data to query with the existing deep model for NER. \n* No conclusion can be drawn by comparing with the 4 different strategies.\n\n======= After rebuttal  ================\n\nThank you for the clarification and revision on this paper. It looks better now.\n\nI understand that the purpose of this paper is to give actionable insights to the practice of deep learning. However, since AL itself is a meta learning framework and neural net as the base learner has been shown to be effective for AL, the novelty and contribution of a general discussion of applying AL for deep neural nets is marginal.  What I really expected is a tightly-coupled active learning strategy that is specially designed for the particular deep neural network structure used for NER. Apparently, however, none of the strategies used in this work is designed for this purpose (e.g., the query strategy or model update strategy should at least reflex some properties of deep learning or NER). Thus, it is still below my expectation. \n\nAnyway, since the authors had attempted to improved this paper, and the results may provide some information to practice, I would like to slightly raise my rating to give this attempt a chance.\n\n', 'Summary:\nThis paper applies active learning to a deep neural model (CNN-CNN-LSTM) for  named-entity recognition, which allows the model to match state-of-the-art performance with about 25% of the full training data.\n\nStrength:\nThe paper is relatively easy to follow. Experiments show significant reduction of training samples needed.\n\nWeaknesses:\nAbout half of the content is used to explain the CNN-CNN-LSTM architecture, which seems orthogonal to the active learning angle, except for the efficiency gain from replacing the CRF with an LSTM.\n\nThe difference in performance among the sampling strategies (as shown in Figure 4) seems very tiny. Therefore, it is difficult to tell what we can really learn from these empirical results.\n\nOther questions and comments:\nIn Table 4: Why is the performance of LSTM-LSTM-LSTM not reported for OntoNotes 5.0, or was the model simply too inefficient? \n\nHow is the variance of the model performance? At the early stage of active learning, the model uses as few as 1% of the training samples, which might cause large variance in terms of dev/test accuracy. \n\nThe SUBMOD method is not properly explained in Section 4. As one of the active learning techniques being compared in experiments, it might be better to formally describe the approach instead of putting it in the appendix.\n', ""This paper introduces a lightweight neural network that achieves state-of-the-art performance on NER. The network allows efficient active incremental training, which significantly reduces the amount of training data needed to match state-of-the-art performance.\n\nThe paper is well-written. The ideas are simple, but they seem to work well in the experiments. Interestingly, LSTM decoder seems to have slight advantage over CRF decoder although LSTM does not output the best tag sequence. It'd be good to comment on this.\n\n* After rebuttal\nThank you for your response and revision of the paper. I think the empirical study could be useful to the community.""]","[-20, -20, 80]","[50, 50, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('active learning may be used for improving performance', 'experimental results showed that active learning is beneficial'), they express significant concerns about the novelty and contribution of the paper. The reviewer states that 'the novelty of this paper is marginal' and that it's 'still below my expectation', indicating overall disappointment despite some improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, thanks the authors for their clarification and revision, and shows willingness to 'slightly raise my rating to give this attempt a chance'. The tone is professional and constructive, even when expressing criticisms."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths ('relatively easy to follow', 'significant reduction of training samples needed'), they also point out several weaknesses and concerns. The reviewer questions the relevance of half the content, notes that performance differences seem tiny, and raises several other issues or questions. This suggests a somewhat critical overall view, though not overwhelmingly negative.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns ('seems orthogonal', 'difficult to tell', 'might be better') rather than harsh criticism. The reviewer also balances negative points with positive ones and phrases their feedback as questions or suggestions rather than direct criticisms. This approach is generally considered polite in academic peer reviews."", ""The sentiment score is 80 (positive) because the reviewer expresses that the paper is well-written, the ideas work well in experiments, and the study could be useful to the community. They also thank the authors for their response and revision. The politeness score is 70 (polite) due to the use of respectful language throughout, such as 'Thank you for your response' and the constructive nature of the feedback. The reviewer offers suggestions without being demanding and acknowledges the paper's strengths. The scores are not 100 as there is some critique and suggestion for improvement, but overall the tone is very positive and polite.""]"
"[""The main insight in this paper is that LSTMs can be viewed as producing a sort of sketch of tensor representations of n-grams.  This allows the authors to design a matrix that maps bag-of-n-gram embeddings into the LSTM embeddings. They then show that the result matrix satisfies a restricted isometry condition.  Combining these results allows them to argue that the classification performance based on LSTM embeddings is comparable to that based on bag-of-n-gram embeddings.\n\nI didn't check all the proof details, but based on my knowledge of compressed sensing theory, the results seem plausible. I think the paper is a nice contribution to the theoretical analysis of LSTM word embeddings."", 'My review reflects more from the compressive sensing perspective, instead that of deep learners.\n\nIn general, I find many of the observations in this paper interesting. However, this paper is not strong enough as a theory paper; rather, the value lies perhaps in its fresh perspective.\n\nThe paper studies text embeddings through the lens of compressive sensing theory. The authors proved that, for the proposed embedding scheme, certain LSTMs with random initialization are at least as good as the linear classifiers; the theorem is almost a direction application of the RIP of random Rademacher matrices. Several simplifying assumptions are introduced, which rendered the implication of the main theorem vague, but it can serve as a good start for the hardcore statistical learning-theoretical analysis to follow.\n\nThe second contribution of the paper is the (empirical) observation that, in terms of sparse recovery of embedded words, the pretrained embeddings are better than random matrices, the latter being the main focus of compressive sensing theory. Partial explanations are provided, again using results in compressive sensing theory. In my personal opinion, the explanations are opaque and unsatisfactory. An alternative route is suggested in my detailed review.\nFinally, extensive experiments are conducted and they are in accordance with the theory.\n\nMy most criticism regarding this paper is the narrow scope on compressive sensing, and this really undermines the potential contribution in Section 5.\n\nSpecifically, the authors considered only Basis Pursuit estimators for sparse recovery, and they used the RIP of design matrices as the main tool to argue what is explainable by compressive sensing and what is not. This seems to be somewhat of a tunnel-visioning for me: There are a variety of estimators in sparse recovery problems, and there are much less restrictive conditions than RIP of the design matrices that guarantee perfect recovery.\n\nIn particular, in Section 5, instead of invoking [Donoho&Tanner 2005], I believe that a more plausible approach is through [Chandrasekaran et al. 2012]. There, a simple deterministic condition (the null space property) for successful recovery is proved. It would be of direct interest to check whether such condition holds for a pretrained embedding (say GloVe) given some BoWs. Furthermore, it is proved in the same paper that Restricted Strong Convexity (RSC) alone is enough to guarantee successful recovery; RIP is not required at all. While, as the authors argued in Section 5.2, it is easy to see that pretrained embeddings can never possess RIP, they do not rule out the possibility of RSC.\n\nExactly the same comments above apply to many other common estimators (lasso, Dantzig selector, etc.) in compressive sensing which might be more tolerant to noise.\n\nSeveral minor comments:\n\n1. Please avoid the use of “information theory”, especially “classical information theory”, in the current context. These words should be reserved to studies of Channel Capacity/Source Coding `a la Shannon. I understand that in recent years people are expanding the realm of information theory, but as compressive sensing is a fascinating field that deserves its own name, there’s no need to mention information theory here.\n\n2. In Theorem 4.1, please be specific about how the l2-regularization is chosen.\n\n3. In Section 4.1, please briefly describe why you need to extend previous analysis to the Lipschitz case. I understood the necessity only through reading proofs.\n\n4. Can the authors briefly comment on the two assumptions in Section 4, especially the second one (on n- cooccurrence)? Is this practical?\n\n5. Page 1, there is a typo in the sentence preceding [Radfors et al., 2017].\n\n6. Page 2, first paragraph of related work, the sentence “Our method also closely related to ...” is incomplete.\n\n7. Page 2, second paragraph of related work, “Pagliardini also introduceD a linear ...”\n\n8. Page 9, conclusion, the beginning sentence of the second paragraph is erroneous.\n\n[1] Venkat Chandrasekaran, Benjamin Recht, Pablo A. Parrilo, Alan S. Willsky, “The Convex Geometry of Linear Inverse Problems”, Foundations of Computational Mathematics, 2012.', 'The interesting paper provides theoretical support for the low-dimensional vector embeddings computed using LSTMs or simple techniques, using tools from compressed sensing. The paper also provides numerical results to support their theoretical findings. The paper is well presented and organized.\n\n-In theorem 4.1, the embedding dimension $d$ is depending on $T^2$, and it may scale poorly with respect to $T$.']","[80, 20, 80]","[50, 60, 60]","[""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, calling it a 'nice contribution' and stating that the results seem 'plausible'. They also mention not checking all proof details, which slightly tempers the positivity. The politeness score is 50 (somewhat polite) as the language is professional and respectful, but not overtly warm or effusive. The reviewer uses neutral academic language throughout, avoiding any harsh criticism while also not being excessively complimentary."", ""The sentiment score is slightly positive (20) because while the reviewer finds many observations interesting and sees value in the paper's fresh perspective, they also express significant criticisms. The reviewer acknowledges the paper's contributions but points out several weaknesses, particularly in the theoretical aspects and scope of analysis. The politeness score is moderately high (60) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I find many of the observations interesting' and 'In my personal opinion,' which soften criticisms. The reviewer also provides constructive feedback and suggestions for improvement, demonstrating respect for the authors' work. However, some direct criticisms slightly lower the politeness score from being extremely high."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'interesting' and states that it is 'well presented and organized'. They also mention that the paper provides theoretical support and numerical results, which are positive aspects. The only slightly negative point is a minor concern about scaling in Theorem 4.1, but this doesn't significantly detract from the overall positive sentiment. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths without harsh criticism. The phrasing of the concern about Theorem 4.1 is neutral and constructive rather than critical. While polite, the review doesn't go out of its way to be overly deferential, hence the score of 60 rather than higher.""]"
"['Quality: The authors study non-saturating GANs and the effect of two penalized gradient approaches. The authors consider a number of thought experiments to demonstrate their observations and validate these on real data experiments. \n\nClarity: The paper is well-written and clear. The authors could be more concise when reporting results. I would suggest keeping the main results in the main body and move extended results to an appendix.\n\nOriginality: The authors demonstrate experimentally that there is a benefit of using non-saturating GANs. More specifically, the provide empirical evidence that they can fit problems where Jensen-Shannon divergence fails. They also show experimentally that penalized gradients stabilize the learning process.\n\nSignificance: The problems the authors consider is worth exploring further. The authors describe their finding in the appropriate level of details and demonstrate their findings experimentally. However, publishing this  work is in my opinion premature for the following reasons:\n\n- The authors do not provide further evidence of why non-saturating GANs perform better or under which mathematical conditions (non-saturating) GANs will be able to handle cases where distribution manifolds do not overlap;\n- The authors show empirically the positive effect of penalized gradients, but do not provide an explanation grounded in theory;\n- The authors do not provide practical recommendations how to set-up GANs and not that these findings did not lead to a bullet-proof recipe to train them.\n\n', 'This paper answers recent critiques about ``standard GAN\'\' that were recently formulated to motivate variants based on other losses, in particular using ideas from optimal transport.  It makes main points\n1) ``standard GAN\'\' is an ill-defined term that may refer to two different learning criteria, with different properties\n2) though the non-saturating variant (see Eq. 3) of ``standard GAN\'\' may converge towards a minimum of the Jensen-Shannon divergence, it does not mean that the minimization process follows gradients of the Jensen-Shannon divergence (and conversely, following gradient paths of the Jensen-Shannon divergence may not converge towards a minimum, but this was rather the point of the previous critiques about ``standard GAN\'\'). \n3) the penalization strategies introduced for ``non-standard GAN\'\' with specific motivations, may also apply successfully to the ``standard GAN\'\', improving robustness, thereby helping to set hyperparameters.\nNote that item 2) is relevant in many other setups in the deep learning framework and is often overlooked.\n\nOverall, I believe that the paper provides enough material to substantiate these claims, even if the message could be better delivered. In particular, the writing is sometimes ambiguous (e.g. in Section 2.3, the reader who did not follow the recent developments on the subject on arXiv will have difficulties to rebuild the cross-references between authors, acronyms and formulae). The answers to the critiques referenced in the \n paper are convincing, though I must admit that I don\'t know how crucial it is to answer these critics, since it is difficult to assess wether they reached or will reach a large audience.\n\nDetails:\n- p. 4 please do not qualify KL as a distance metric \n- Section 4.3: ""Every GAN variant was trained for 200000 iterations, and 5 discriminator updates were done for each generator update"" is ambiguous: what is exactly meant by ""iteration"" (and sometimes step elsewhere)? \n- Section 4.3: the performance measure is not relevant regarding distributions. The l2 distance is somewhat OK for means, but it makes little sense for covariance matrices. ', 'The submission describes an empirical study regarding the training performance\nof GANs; more specifically, it aims to present empirical evidence that the\ntheory of divergence minimization is more a tool to understand the outcome of\ntraining (i.e. Nash equillibrium) than a necessary condition to be enforce\nduring training itself.\n\nThe work focuses on studying ""non-saturating"" GANs, using the modified generator\nobjective function proposed by Goodfellow et al. in their seminal GAN paper, and\naims to show increased capabilities of this variant, compared to the ""standard""\nminimax formulation. Since most theory around divergence minimization is based\non the unmodified loss function for generator G, the experiments carried out in\nthe submission might yield somewhat surprising results compared the theory.\n\nIf I may summarize the key takeaways from Sections 5.4 and 6, they are:\n- GAN training remains difficult and good results are not guaranteed (2nd bullet\n  point);\n- Gradient penalties work in all settings, but why is not completely clear;\n- NS-GANs + GPs seems to be best sample-generating combination, and faster than\n  WGAN-GP.\n- Some of the used metrics can detect mode collapse.\n\nThe submission\'s (counter-)claims are served by example (cf. Figure 2, or Figure\n3 description, last sentence), and mostly relate to statements made in the WGAN\npaper (Arjovsky et al., 2017).\n\nAs a purely empirical study, it poses more new and open questions on GAN\noptimization than it is able to answer; providing theoretical answers is\ndeferred to future studies. This is not necessarily a bad thing, since the\nextensive experiments (both ""toy"" and ""real"") are well-designed, convincing and\ncomprehensible. Novel combinations of GAN formulations (non-saturating with\ngradient penalties) are evaluated to disentangle the effects of formulation\nchanges.\n\nOverall, this work is providing useful experimental insights, clearly motivating\nfurther study.\n']","[-20, 50, 60]","[60, 70, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (well-written, clear, worth exploring), they ultimately conclude that publishing the work is premature due to several significant shortcomings. The reviewer lists multiple areas where the authors need to provide more evidence or explanations, indicating that the paper is not yet ready for publication in its current state. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'I would suggest' and 'in my opinion' which soften the critique. The reviewer also provides specific, constructive feedback on how to improve the paper, which is a polite way to offer criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer believes the paper 'provides enough material to substantiate these claims' and offers 'convincing' answers to critiques. However, they also mention that the message 'could be better delivered' and question the importance of answering these critiques. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'I believe' and 'I must admit' which soften their critiques. The reviewer also provides specific suggestions for improvement without harsh language."", ""The sentiment score is 60 (positive) because the reviewer generally expresses a favorable view of the submission. They describe the work as providing 'useful experimental insights' and 'clearly motivating further study'. The experiments are called 'well-designed, convincing and comprehensible'. However, it's not extremely positive as the reviewer notes that the study raises more questions than it answers and defers theoretical answers to future studies. The politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout. They acknowledge the value of the work even while pointing out limitations, using phrases like 'This is not necessarily a bad thing' and 'If I may summarize'. The tone is constructive and supportive, without any harsh criticism or dismissive remarks.""]"
"['This paper proposes a lightweight neural network architecture for reading comprehension, which 1) only consists of feed-forward nets; 2) aggregates information from different occurrences of candidate answers, and demonstrates good performance on TriviaQA (where documents are generally pretty long).\n\nOverall, I think it is a nice demonstration that non-recurrent models can work so well, but I also don’t find the results strikingly surprising. It is also a bit hard to get the main takeaway messages. It seems that multi-loss is important (highlight that!), summing up multiple mentions of the same candidate answers seems to be important (This paper should be cited: Text Understanding with the Attention Sum Reader Network https://arxiv.org/abs/1603.01547). But all the other components seem to have been demonstrated previously in other papers. \n\nAn important feature of this model is it is easier to parallelize and speed up the training/testing processes. However, I don’t see any demonstration of this in the experiments section.\n\nAlso, I am a bit disappointed by how “cascades” are actually implemented. I was expecting some sophisticated ways of combining information in a cascaded way (finding the most relevant piece of information, and then based on what it is obtained so far trying to find the next piece of relevant information and so on). The proposed model just simply sums up all the occurrences of candidate answers throughout the full document. 3-layer cascade is really just more like stacking several layers where each layer captures information of different granularity. \n\nI am wondering if the authors can also add results on other RC datasets (e.g., SQuAD) and see if the model can generalize or not. \n', 'This paper proposes a method that scales reading comprehension QA to large quantities of text with much less document truncation than competing approaches. The model also does not consider the first mention of the answer span as gold, instead formulating its loss function to incorporate multiple mentions of the answer within the evidence. The reported results were state-of-the-art(*) on the TriviaQA dataset at the time of the submission deadline. It\'s interesting that such a simple model, relying mainly on (weighted) word embedding averages, can outperform more complex architectures; however, these improvements are likely due to decreased truncation as opposed to bag-of-words architectures being superior to RNNs. \n\nOverall, I found the paper interesting to read, and scaling QA up to larger documents is definitely an important research direction. On the other hand, I\'m not quite convinced by its experimental results (more below) and the paper is lacking an analysis of what the different sub-models are learning. As such, I am borderline on its acceptance.\n\n* The TriviaQA leaderboard shows a submission from 9/24/17 (by ""chrisc"") that has significantly higher EM/F1 scores than the proposed model. Why is this result not compared to in Table 1? \n\nDetailed comments:\n- Did you consider pruning spans as in the end-to-end coreference paper of Lee et al., EMNLP 2017? This may allow you to avoid truncation altogether. Perhaps this pruning could occur at level 1, making subsequent levels would be much more efficient.\n- How long do you estimate training would take if instead of bag-of-words, level 1 used a biLSTM encoder for spans / questions?\n- What is the average number of sentences per document? It\'s hard to get an idea of how reasonable the chosen truncation thresholds are without this.\n- In Figure 3, it looks like the exact match score is still increasing as the maximum tokens in document is increased. Did the authors try truncating after more words (e.g., 10k)?\n- I would have liked to see some examples of questions that are answered correctly by level 3 but not by level 2 or 1, for example, to give some intuition as to how each level works.\n- ""Krasner"" misspelled multiple times as ""Kramer""', 'The authors present a scalable model for questioning answering that is able to train on long documents. On the TriviaQA dataset, the proposed model achieves state of the art results on both domains (wikipedia and web). The formulation of the model is straight-forward, however I am skeptical about whether the results prove the premise of the paper (e.g. multi-mention reasoning is necessary). Furthermore, I am slightly unconvinced about the authors\' claim of efficiency. Nevertheless, I think this work is important given its performance on the task.\n\n1. Why is this model successful? Multi-mention reasoning or more document context?\nI am not convinced of the necessity of multi-mention reasoning, which the authors use as motivation, as shown in the examples in the paper. For example, in Figure 1, the answer is solely obtained using the second last passage. The other mentions provide signal, but does not provide conclusive evidence. Perhaps I am mistaken, but it seems to me that the proposed model cannot seem to handle negation, can the authors confirm/deny this? I am also skeptical about the computation efficiency of a model that scores all spans in a document (which is O(N^2), where N is the document length). Can you show some analysis of your model results that confirm/deny this hypothesis?\n\n2. Why is the computational complexity not a function of the number of spans?\nIt seems like the derivations presents several equations that score a given span. Perhaps I am mistaken, but there seems to be n^2 spans in the document that one has to score. Shouldn\'t the computational complexity then be at least O(n^2), which makes it actually much slower than, say, SQuAD models that do greedy decoding O(2n + nm)?\n\nSome minor notes\n- 3.3.1 seems like an attention computation in which the attention context over the question and span is computed using the question. Explicitly mentioning this may help the reading grasp the formulation.\n- Same for 3.4, which seems like the biattention (Seo 2017) or coattention (Xiong 2017) from previous squad work.\n- The sentence ""We define ... to be the embeddings of the l words of the sentence that contains s."" is not very clear. Do you mean that the sentence contains l words? It could be interpreted that the span has l words.\n- There is a typo in your 3.7 ""level 1 complexity"": there is an extra O inside the big O notation.']","[-20, 20, 20]","[50, 60, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice demonstration', 'good performance'), they express several criticisms and disappointments. They mention that the results are not 'strikingly surprising', that it's 'hard to get the main takeaway messages', and that they are 'a bit disappointed' by some aspects of the implementation. The overall tone suggests more reservations than enthusiasm about the paper.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think' and 'I am wondering' to soften their criticisms, and they offer constructive suggestions for improvement. The language is not overly formal or deferential, but it avoids any rudeness or harsh criticism, striking a balance between honesty and courtesy."", ""The sentiment score is slightly positive (20) because the reviewer finds the paper interesting and acknowledges its importance, but expresses some reservations about the experimental results and analysis. The reviewer is 'borderline on its acceptance', indicating a mixed but slightly favorable view. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames concerns as suggestions for improvement rather than harsh criticisms. The reviewer acknowledges the paper's strengths before discussing areas for improvement, which is a polite approach. The specific recommendations are phrased as questions or suggestions rather than demands, further contributing to the polite tone."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the importance of the work and its state-of-the-art results, they express skepticism about some of the authors' claims and the necessity of multi-mention reasoning. The overall tone is cautiously positive but with significant reservations. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the possibility of their own misunderstanding. They use phrases like 'Perhaps I am mistaken' and offer the authors opportunities to clarify or confirm points, which contributes to a polite tone while still conveying critical feedback.""]"
"[""UPDATE: Following the author's response I've increased my score from 5 to 6. The revised paper includes many of the additional references that I suggested, and the author response clarified my confusion over the Charades experiments; their results are indeed close to state-of-the-art on Charades activity localization (slightly outperformed by [6]), which I had mistakenly confused with activity classification (from [5]).\n\nThe paper proposes the Skip RNN model which allows a recurrent network to selectively skip updating its hidden state for some inputs, leading to reduced computation at test-time. At each timestep the model emits an update probability; if this probability is over a threshold then the next input and state update will be skipped. The use of a straight-through estimator allows the model to be trained with standard backpropagation. The number of state updates that the model learns to use can be controlled with an auxiliary loss function. Experiments are performed on a variety of tasks, demonstrating that the Skip-RNN compares as well or better than baselines even when skipping nearly half its state updates.\n\nPros:\n- Task of reducing computation by skipping inputs is interesting\n- Model is novel and interesting\n- Experiments on multiple tasks and datasets confirm the efficacy of the method\n- Skipping behavior can be controlled via an auxiliary loss term\n- Paper is clearly written\n\nCons:\n- Missing comparison to prior work on sequential MNIST\n- Low performance on Charades dataset, no comparison to prior work\n- No comparison to prior work on IMDB Sentiment Analysis or UCF-101 activity classification\n\nThe task of reducing computation by skipping RNN inputs is interesting, and the proposed method is novel, interesting, and clearly explained. Experimental results across a variety of tasks are convincing; in all tasks the Skip-RNNs achieve their goal of performing as well or better than equivalent non-skipping variants. The use of an auxiliary loss to control the number of state updates is interesting; since it sometimes improves performance it appears to have some regularizing effect on the model in addition to controlling the trade-off between speed and accuracy.\n\nHowever, where possible experiments should compare directly with prior published results on these tasks; none of the experiments from the main paper or supplementary material report any numbers from any other published work.\n\nOn permuted MNIST, Table 2 could include results from [1-4]. Of particular interest is [3], which reports 98.9% accuracy with a 100-unit LSTM initialized with orthogonal and identity weight matrices; this is significantly higher than all reported results for the sequential MNIST task.\n\nFor Charades, all reported results appear significantly lower than the baseline methods reported in [5] and [6] with no explanation. All methods work on “fc7 features from the RGB stream of a two-stream CNN provided by the organizers of the [Charades] challenge”, and the best-performing method (Skip GRU) achieves 9.02 mAP. This is significantly lower than the two-stream results from [5] (11.9 mAP and 14.3 mAP) and also lower than pretrained AlexNet features averaged over 30 frames and classified with a linear SVM, which [5] reports as achieving 11.3 mAP. I don’t expect to see state-of-the-art performance on Charades; the point of the experiment is to demonstrate that Skip-RNNs perform as well or better than their non-skipping counterparts, which it does. However I am surprised at the low absolute performance of all reported results, and would appreciate if the authors could help to clarify whether this is due to differences in experimental setup or something else.\n\nIn a similar vein, from the supplementary material, sentiment analysis on IMDB and action classification on UCF-101 are well-studied problems, but the authors do not compare with any previously published results on these tasks.\n\nThough experiments may not show show state-of-the-art performance, I think that they still serve to demonstrate the utility of the Skip-RNN architecture when compared side-by-side with a similarly tuned non-skipping baseline. However I feel that the authors should include some discussion of other published results.\n\nOn the whole I believe that the task and method are interesting, and experiments convincingly demonstrate the utility of Skip-RNNs compared to the author’s own baselines. I will happily upgrade my rating of the paper if the authors can address my concerns over prior work in the experiments.\n\n\nReferences\n\n[1] Le et al, “A Simple Way to Initialize Recurrent Networks of Rectified Linear Units”, arXiv 2015\n[2] Arjovsky et al, “Unitary Evolution Recurrent Neural Networks”, ICML 2016\n[3] Cooijmans et al, “Recurrent Batch Normalization”, ICLR 2017\n[4] Zhang et al, “Architectural Complexity Measures of Recurrent Neural Networks”, NIPS 2016\n[5] Sigurdsson et al, “Hollywood in homes: Crowdsourcing data collection for activity understanding”, ECCV 2016\n[6] Sigurdsson et al, “Asynchronous temporal fields for action recognition”, CVPR 2017"", ""This paper proposes an idea to do faster RNN inference via skip RNN state updates. \nI like the idea of the paper, in particular the design which enables calculating the number of steps to skip in advance. But the experiments are not convincing enough. First the tasks it was tested on are very simple -- 2 synthetic tasks plus 1 small-scaled task. I'd like to see the idea works on larger scale problems -- as that is where the computation/speed matters. Also besides the number of updates reported in table, I think the wall-clock time for inference should also be reported, to demonstrate what the paper is trying to claim.\n\nMinor -- \nCite Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation by Yoshua Bengio, Nicholas Leonard and Aaron Courville for straight-through estimator."", 'The authors proposed a novel RNN model where both the input and the state update of the recurrent cells are skipped adaptively for some time steps. The proposed models are learned by imposing a soft constraint on the computational budget to encourage skipping redundant input time steps. The experiments in the paper demonstrated skip RNNs outperformed regular LSTMs and GRUs o thee addition, pixel MNIST and video action recognition tasks.\n\n\n\nStrength:\n- The experimental results on the simple skip RNNs have shown a good improvement over the previous results.\n\nWeakness:\n- Although the paper shows that skip RNN worked well, I found the appropriate baseline is lacking here. Comparable baselines, I believe, are regular LSTM/GRU whose inputs are randomly dropped out during training.\n\n- Most of the experiments in the main paper are on toy tasks with small LSTMs. I thought the main selling point of the method is the computational gain. Would it make more sense to show that on large RNNs with thousands of hidden units? After going over the additional experiments in the appendix, and I find the three results shown in the main paper seem cherry-picked, and it will be good to include more NLP tasks.']","[60, 20, 20]","[80, 60, 50]","[""The sentiment score is 60 (positive) because the reviewer expresses overall approval of the paper, noting its interesting and novel approach, clear writing, and convincing experiments. They increased their initial score after the authors' response, indicating improved satisfaction. However, they also point out some cons and areas for improvement, which prevents a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'I would appreciate if the authors could help to clarify' and 'I will happily upgrade my rating' which demonstrate courtesy. The reviewer also provides detailed feedback and suggestions for improvement, showing engagement and respect for the authors' work."", ""The sentiment score is slightly positive (20) because the reviewer expresses liking the idea of the paper, particularly the design aspect. However, they also express concerns about the experiments not being convincing enough and suggest improvements, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the positive aspects before offering constructive criticism. They use phrases like 'I like the idea' and 'I'd like to see', which are polite ways of expressing opinions and suggestions. The reviewer also offers a specific recommendation for improvement in a neutral, professional tone, without using harsh or dismissive language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the strengths of the paper, particularly the experimental results showing improvement over previous results. However, the reviewer also points out significant weaknesses, which tempers the overall positive sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents criticisms constructively without harsh or rude phrasing. The reviewer acknowledges the paper's strengths before discussing its weaknesses, which is a polite approach. The use of phrases like 'I believe' and 'I thought' softens the criticisms, making them appear as suggestions rather than demands.""]"
"[""Summary of paper: The paper proposes an RNN-based neural network architecture for embedding programs, focusing on the semantics of the program rather than the syntax. The application is to predict errors made by students on programming tasks. This is achieved by creating training data based on program traces obtained by instrumenting the program by adding print statements. The neural network is trained using this program traces with an objective for classifying the student error pattern (e.g. list indexing, branching conditions, looping bounds).\n\n---\n\nQuality: The experiments compare the three proposed neural network architectures with two syntax-based architectures. It would be good to see a comparison with some techniques from Reed & De Freitas (2015) as this work also focuses on semantics-based embeddings.\nClarity: The paper is clearly written.\nOriginality: This work doesn't seem that original from an algorithmic point of view since Reed & De Freitas (2015) and Cai et. al (2017) among others have considered using execution traces. However the application to program repair is novel (as far as I know).\nSignificance: This work can be very useful for an educational platform though a limitation is the need for adding instrumentation print statements by hand.\n\n---\n\nSome questions/comments:\n- Do we need to add the print statements for any new programs that the students submit? What if the structure of the submitted program doesn't match the structure of the intended solution and hence adding print statements cannot be automated?\n\n---\n\nReferences \n\nCai, J., Shin, R., & Song, D. (2017). Making Neural Programming Architectures Generalize via Recursion. In International Conference on Learning Representations (ICLR)."", ""This paper considers the task of learning program embeddings with neural networks with the ultimate goal of bug detection program repair in the context of students learning to program. Three NN architectures are explored, which leverage program semantics rather than pure syntax.  The approach is validated using programming assignments from an online course, and compared against syntax based approaches as a baseline.\n\nThe problem considered by the paper is interesting, though it's not clear from the paper that the approach is a substantial improvement over previous work. This is in part due to the fact that the paper is relatively short, and would benefit from more detail.  I noticed the following issues:\n\n1) The learning task is based on error patterns, but it's not clear to me what exactly that means from a software development standpoint.\n2) Terms used in the paper are not defined/explained. For example, I assume GRU is gated recurrent unit, but this isn't stated.\n3) Treatment of related work is lacking.  For example, the Cai et al. paper from ICLR 2017 is not considered\n4) If I understand dependency reinforcement embedding correctly, a RNN is trained for every trace. If so, is this scalable?\n\nI believe the work is very promising, but this manuscript should be improved prior to publication."", 'The authors present 3 architectures for learning representations of programs from execution traces. In the variable trace embedding, the input to the model is given by a sequence of variable values. The state trace embedding combines embeddings for variable traces using a second recurrent encoder. The dependency enforcement embedding performs element-wise multiplication of embeddings for parent variables to compute the input of the GRU to compute the new hidden state of a variable. The authors evaluate their architectures on the task of predicting error patterns for programming assignments from Microsoft DEV204.1X (an introduction to C# offered on edx) and problems on the Microsoft CodeHunt platform. They additionally use their embeddings to decrease the search time for the Sarfgen program repair system.\n\nThis is a fairly strong paper. The proposed models make sense and the writing is for the most part clear, though there are a few places where ambiguity arises:\n\n- The variable ""Evidence"" in equation (4) is never defined. \n\n- The authors refer to ""predicting the error patterns"", but again don\'t define what an error pattern is. The appendix seems to suggest that the authors are simply performing multilabel classification based on a predefined set of classes of errors, is this correct? \n\n- It is not immediately clear from Figures 3 and 4 that the architectures employed are in fact recurrent.\n\n- Figure 5 seems to suggest that dependencies are only enforced at points in a program where assignment is performed for a variable, is this correct?\n\nAssuming that the authors can address these clarity issues, I would in principle be happy for the paper to appear. ']","[20, -20, 60]","[50, 60, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's clarity, novelty in application, and potential usefulness, while also offering constructive criticism and suggestions for improvement. The tone is not overwhelmingly positive, but it leans more towards approval than disapproval. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms as suggestions or questions rather than harsh judgments. The reviewer maintains a professional and courteous tone, even when pointing out limitations or areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'interesting' and 'very promising', they also point out several issues and state that the manuscript 'should be improved prior to publication'. This indicates a generally constructive but somewhat critical stance. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the potential of the work while offering constructive criticism. They use phrases like 'I believe the work is very promising' and 'would benefit from more detail', which maintain a polite and professional tone even while pointing out areas for improvement."", ""The sentiment score is 60 (moderately positive) because the reviewer describes the paper as 'fairly strong' and states they would be 'happy for the paper to appear' if certain clarity issues are addressed. This indicates a generally positive view, but with some reservations. The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames their criticisms as questions or suggestions rather than direct criticisms. The reviewer also balances their critique with positive comments. The language is professional and courteous, avoiding any harsh or rude phrasing.""]"
"['Summary:\nThis paper shows that incorporating invariance to time transformations in recurrent networks naturally results in a gating mechanism used by LSTMs and their variants. This is then used to develop a simple bias initialization scheme for the gates when the range of temporal dependencies relevant for a problem can be estimated or are known. Experiments demonstrate that the proposed initialization speeds up learning on synthetic tasks, although benefits for next-step prediction tasks are limited.\n\nQuality and significance:\nThe core insight of the paper is the link between recurrent network design and its effect on how the network reacts to time transformations. This insight is simple, elegant and valuable in my opinion. \n\nIt is becoming increasingly apparent recently that the benefits of the gating and cell mechanisms introduced by the LSTM, now also used in feedforward networks, go beyond avoiding vanishing gradients. The particular structural elements also induce certain inductive biases which make learning or generalization easier in many cases. Understanding the link between model architecture and behavior is very useful for the field in general, and this paper contributes to this knowledge. In light of this, I think it is reasonable to ignore the fact that the proposed initialization does not provide benefits on Penn Treebank and text8. The real value of the paper is in providing an alternative way of thinking about LSTMs that is theoretically sound and intuitive. \n\nClarity:\nThe paper is well-written in general and easy to understand. A minor complaint is that there are an unnecessarily large number of paragraph breaks, especially on pages 3 and 4, which make reading slightly jarring.', 'tl;dr: \n - The paper has a really cool theoretical contribution. \n - The experiments do not directly test whether the theoretical insight holds in practice, but instead a derivate method is tested on various benchmarks. \n\nI must say that this paper has cleared up quite a few things for me. I have always been a skeptic wrt LSTM, since I myself did not fully understand when to prefer them over vanilla RNNs for reasons other than “they empirically work much better in many domains.” and “they are less prone to vanishing gradients”. \n\nSection 1 is a bliss: it provides a very useful candidate explanation under which conditions vanilla RNNs fail (or at least, do not efficiently generalise) in contrast to gated cells. I am sincerely happy about the write up and will point many people to it.\n\nThe major problem with the paper, in my eyes, is the lack of experiments specific to test the hypothesis. Obviously, quite a bit of effort has gone into the experimental section. The focus however is comparison to the state of the art in terms of raw performance.  \n\nThat leaves me asking: are gated RNNs superior to vanilla RNNs if the data is warped?\nWell, I don’t know now. I only can say that there is reason to believe so. \n\nI *really* do encourage the authors to go back to the experiments and see if they can come up with an experiment to test the main hypothesis of the paper. E.g. one could make synthetic warpings, apply it to any data set and test if things work out as expected. Such a result would in my opinion be of much more use than the tiny increment in performance that is the main output of the paper as of now, and which will be stomped by some other trick in the months to come. It would be a shame if such a nice theoretical insight got under the carpet because of that. E.g. today we hold [Pascanu 2013] dear not because of the proposed method, but because of the theoretical analysis.\n\nSome minor points.\n- The authors could make use of less footnotes, and try to incorporate them into the text or appendix.\n- A table of results would be nice.\n- Some choices of the experimental section seem arbitrary, e.g. the use of optimiser and to not use clipping of gradients. In general, the evaluation of the hyper parameters is not rigorous.\n- “abruplty” -> “abruptly” on page 5, 2nd paragraph\n\n### References\n[Pascanu 2013] Pascanu, Razvan, Tomas Mikolov, and Yoshua Bengio. ""On the difficulty of training recurrent neural networks."" International Conference on Machine Learning. 2013.', 'The paper provides an interesting theoretical explanation on why gated RNN architectures such as LSTM and GRU work well in practice. The paper shows how ""gate values appear as time contraction or time dilation coefficients"". The authors also point out the connection between the gate biases and the range of time dependencies captured in the network. From that, they develop a simple yet effective initialization method which performs well on different datasets.\n\nPros:\n- The idea is interesting, it well explain the success of gated RNNs.\n- Writing: The paper is well written and easy to read. \n\nCons:\nExperiments: only small datasets were used in the experiments, it would be more convincing if the author could use larger datasets. One suggestion to make the experiment more complete is to gradually increase the initial value of the biases to see how it affect the performance. To use \'chrono initialization\', one need to estimate the range of time dependency which could be difficult in practice. \n']","[80, 50, 60]","[70, 80, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper's core insight, calling it 'simple, elegant and valuable'. They also state that the paper's real value is in providing a new way of thinking about LSTMs that is 'theoretically sound and intuitive'. The reviewer even defends the paper's limitations on certain datasets. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's contributions and significance. They offer a minor criticism about paragraph breaks in a gentle way, calling it a 'minor complaint'. The overall tone is constructive and appreciative of the authors' work."", ""The sentiment score is 50 (moderately positive) because the reviewer expresses appreciation for the theoretical contribution and clarity of explanation, calling it 'really cool' and 'a bliss'. However, they also point out a major issue with the lack of experiments to directly test the hypothesis. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and encourages the authors to improve their work. They use phrases like 'I must say', 'I am sincerely happy', and 'I really do encourage' which convey a polite and supportive tone. Even when pointing out issues, the language remains courteous."", ""The sentiment score is 60 (positive) because the reviewer starts by describing the paper as 'interesting' and providing 'an interesting theoretical explanation'. They list several positive aspects ('Pros') and acknowledge the paper is 'well written and easy to read'. However, it's not extremely positive due to the 'Cons' section suggesting improvements. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. Phrases like 'it would be more convincing if' and 'One suggestion to make the experiment more complete' indicate a polite approach to providing feedback. The overall tone is professional and courteous, without being overly formal or excessively complimentary.""]"
"['This paper studies learning to play two-player general-sum games with state (Markov games) with imperfect information. The idea is to learn to cooperate (think prisoner\'s dilemma) but in more complex domains. Generally, in repeated prisoner\'s dilemma, one can punish one\'s opponent for noncooperation. In this paper, they design an apporach to learn to cooperate in a more complex game, like a hybrid pong meets prisoner\'s dilemma game. This is fun but I did not find it particularly surprising from a game-theoretic or from a deep learning point of view. \n\nFrom a game-theoretic point of view, the paper begins with a game-theoretic analysis of a cooperative strategy for these markov games with imperfect information. It is basically a straightforward generalization of the idea of punishing, which is common in ""folk theorems"" from game theory, to give a particular equilibrium for cooperating in Markov games. Many Markov games do not have a cooperative equilibrium, so this paper restricts attention to those that do. Even in games where there is a cooperative solution that maximizes the total welfare, it is not clear why players would choose to do so. When the game is symmetric, this might be ""the natural"" solution but in general it is far from clear why all players would want to maximize the total payoff. \n\nThe paper follows with some fun experiments implementing these new game theory notions. Unfortunately, since the game theory was not particularly well-motivated, I did not find the overall story compelling. It is perhaps interesting that one can make deep learning learn to cooperate with imperfect information, but one could have illustrated the game theory equally well with other techniques.\n\nIn contrast, the paper ""Coco-Q: Learning in Stochastic Games with Side Payments"" by Sodomka et. al. is an example where they took a well-motivated game theoretic cooperative solution concept and explored how to implement that with reinforcement learning. I would think that generalizing such solution concepts to stochastic games and/or deep learning might be more interesting.\n\nIt should also be noted that I was asked to review another ICLR submission entitled ""MAINTAINING COOPERATION IN COMPLEX SOCIAL DILEMMAS USING DEEP REINFORCEMENT LEARNING"" which amazingly introduced the same ""Pong Player’s Dilemma"" game as in this paper. \n\nNotice the following suspiciously similar paragraphs from the two papers:\n\nFrom ""MAINTAINING COOPERATION IN COMPLEX SOCIAL DILEMMAS USING DEEP REINFORCEMENT LEARNING"":\nWe also look at an environment where strategies must be learned from raw pixels. We use the method\nof Tampuu et al. (2017) to alter the reward structure of Atari Pong so that whenever an agent scores a\npoint they receive a reward of 1 and the other player receives −2. We refer to this game as the Pong\nPlayer’s Dilemma (PPD). In the PPD the only (jointly) winning move is not to play. However, a fully\ncooperative agent can be exploited by a defector.\n\nFrom ""CONSEQUENTIALIST CONDITIONAL COOPERATION IN SOCIAL DILEMMAS WITH IMPERFECT INFORMATION"":\nTo demonstrate this we follow the method of Tampuu et al. (2017) to construct a version of Atari Pong \nwhich makes the game into a social dilemma. In what we call the Pong Player’s Dilemma (PPD) when an agent \nscores they gain a reward of 1 but the partner receives a reward of −2. Thus, in the PPD the only (jointly) winning\nmove is not to play, but selfish agents are again tempted to defect and try to score points even though\nthis decreases total social reward. We see that CCC is a successful, robust, and simple strategy in this\ngame.', ""The main result specifies a (trigger) strategy (CCC) and corresponding algorithm that leads to an efficient outcome in social dilemmas, the theoretical basis of which is provided by theorem 1. This underscores an algorithm that uses a prosocial adjustment of the agents rewards to encourage efficient behaviour. The paper makes a useful contribution in demonstrating that convergence to efficient outcomes in social dilemmas without the need for agents to observe each other's actions. The paper is also clearly written and the theoretical result is accompanied by some supporting experiments. The numerical experiments show that using CCC strategy leads to an increase in the proportion of efficient equilibrium outcomes. However, in order to solidify the experimental validation, the authors could consider a broader range of experimental evaluations. There are also a number of items that could be added that I believe would strengthen the contribution and novelty, in particular:\n\nSome highly relevant references on (prosocial) reward shaping in social dilemmas are missing, such as Babes, Munoz de cote and Littman, 2008 and for the (iterated) prisoner's dilemma; Vassiliades and Christodoulou, 2010 which all provide important background material on the subject. In addition, it would be useful to see how the method put forward in the paper compares with other (reward-shaping) techniques within MARL (especially in the perfect information case in the pong players' dilemma (PPD) experiment) such as those already mentioned. The authors could, therefore, provide more detail in relating the contribution to these papers and other relevant past work and existing algorithms. \n\nThe paper also omits any formal discussion on the equilibrium concepts being used in the Markov game setting (e.g. Markov Perfect Equilibrium or Markov-Nash equilibrium) which leaves a notable gap in the theoretical analysis.  \n\nThere are also some questions that to me, remain unaddressed namely:\n\ni. the model of the experiments, particularly a description of the structure of the pong players' dilemma in terms of the elements of the partially observed Markov game described in definition 1. In particular, what are the state space and transitions?\n\nii. the equilibrium concepts being considered i.e. does the paper consider Markov perfect equilibria. Some analysis on the conditions that under which the continuation equilibria e.g. cooperation in the social dilemma is expected to arise would also be beneficial.\n\niii. Although the formal discussion is concerned with Markov games (i.e. repeated games with stochastic transitions with multiple states) the experiments (particularly the PPD) appear to apply to repeated games (this could very much be cleared up with a formal description of the games in the experimental sections and the equilibrium concept being used). \n\niv. In part 1 of the proof of the main theorem, it seems unclear why the sign of the main inequality has changed after application of Cauchy convergence in probability (equation at the top of the page). As this is an important component of the proof of the main result, the paper would benefit from an explanation of this step?\n"", ""This paper proposes a novel adaptive learning mechanism to improve results in ergodic cooperation games. The algorithm, tagged 'Consequentialist Conditional Cooperation', uses outcome-based accumulative rewards of different strategies established during prior training. Its core benefit is its adaptiveness towards diverse opposing player strategies (e.g. selfish, prosocial, CCC) while maintaining maximum reward.\n\nWhile the contribution is explored in all its technical complexity, fundamentally this algorithm exploits policies for selfish and prosocial strategies to determine expected rewards in a training phase. During operation it then switches its strategy depending on a dynamically-calculated threshold reward value (considering variation in agent-specific policies, initial game states and stochasticity of rewards) relative to the total reward of the played game instance. The work is contrasted to tit-for-tat approaches that require complete observability and operate based on expected future rewards. In addition to the observability, approximate Markov TFT (amTFT) methods are more processing-intense, since they fall back on a game's Q-function, as opposed to learned policies, making CCC a lightweight alternative. \n\nComments:\n\nThe findings suggest the effectiveness of that approach. In all experiments CCC-based agents fare better than agents operating based on a specific strategy. While performing worse than the amTFT approach and only working well for larger number of iterations, the outcome-based evaluation shows benefits. Specifically in the PPD game, the use of CCC produces interesting results; when paired with cooperate agents in the PPD game, CCC-based players produce higher overall reward than pairing cooperative players (see Figure 2, (d) & (e)). This should be explained. To improve the understanding of the CCC-based operation, it would further be worthwhile to provide an additional graph that shows the action choices of CCC agents over time to clarify behavioural characteristics and convergence performance.\n\nHowever, when paired with non-cooperative players in the risky PPD game, CCC players lead to an improvement of pay-offs by around 50 percent (see Figure 2, (e)), compared to payoff received between non-cooperative players (-28.4 vs. -18, relative to -5 for defection). This leads to the question: How much CCC perform compared to random policy selection? Given its reduction of processing-intensive and need for larger number of iterations, how much worse is the random choice (no processing, independent of iterations)? This is would be worthwhile to appreciate the benefit of the proposed approach.\n\nAnother point relates to the fishing game. The game is parameterized with the rewards of +1 and +3. What is the bases for these parameter choices? What would happen if the higher reward was +2, or more interestingly, if the game was extended to allow agents to fish medium-sized fish (+2), in addition to small and large fish. Here it would be interesting to see how CCC fares (in all combinations with cooperators and defectors).\n\nOverall, the paper is well-written and explores the technical details of the presented approach. The authors position the approach well within contemporary literature, both conceptually and using experimental evaluation, and are explicit about its strengths and limitations.\n\nPresentation aspects:\n- Minor typo: Page 2, last paragraph of Introduction: `... will act act identically.'\n- Figure 2 should be shifted to the next page, since it is not self-explanatory and requires more context.\n""]","[-50, 50, 70]","[20, 80, 80]","[""The sentiment score is -50 because the reviewer expresses a generally negative view of the paper, stating they didn't find it 'particularly surprising' or 'compelling'. They also point out potential issues with the game-theoretic motivation and suggest alternative approaches might be more interesting. However, it's not entirely negative as they do acknowledge some aspects as 'fun'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'It is perhaps interesting' and 'It should also be noted', which soften the criticism. However, the reviewer does directly state their negative opinions without much sugar-coating, which prevents a higher politeness score. The reviewer also raises a concern about similarity with another submission in a straightforward manner, which is necessary but could be perceived as slightly impolite."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's useful contribution and clear writing, but also points out several areas for improvement and missing elements. The overall tone is constructive rather than overly critical. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering suggestions rather than demands (e.g., 'could consider', 'would be useful'), and acknowledges the paper's strengths before discussing its weaknesses. The reviewer also frames criticisms as questions or areas for clarification rather than outright faults."", ""The sentiment score is 70 (positive) because the reviewer generally expresses approval of the paper, highlighting its effectiveness, good positioning within literature, and explicit discussion of strengths and limitations. The reviewer also provides constructive feedback for improvement, which indicates a positive engagement with the work. The politeness score is 80 (polite) due to the reviewer's use of respectful language throughout, acknowledging the paper's strengths, and framing suggestions as questions or areas for potential improvement rather than criticisms. The reviewer uses phrases like 'it would be worthwhile' and 'would be interesting to see,' which maintain a courteous tone. The overall structure and language of the review demonstrate professionalism and respect for the authors' work.""]"
"['\nSummary:\n A method for creation of semantical adversary examples in suggested. The ‘semantic’ property is measured by building a latent space with mapping from this space to the observable (generator) and back (inverter). The generator is trained with a WGAN optimization. Semantic adversarials examples are them searched for by inverting an example to its sematic encoding and running local search around it in that space. The method is tested for generation of images on MNist and part of LSUM data and for creation of text examples which are adversarial in some sense to inference and translation sentences. It is shown that the distance between adversarial example and the original example in the latent space is proportional to the accuracy of the classifier inspected.\nPage 3: It seems that the search algorithm has a additional parameter: r_0, the size of the area in which search is initiated. This should be explicitly said and the parameter value should be stated.\nPage 4: \n-\tthe implementation details of the generator, critic and invertor networks are not given in enough details, and instead the reader is referred to other papers. This makes this paper non-clear as a stand alone document, and is a problem for a paper which is mostly based on experiments and their results: the main networks used are not described.\n-\tthe visual examples are interesting, but it seems that they are able to find good natural adversary examples only for a weak classifier. In the MNist case, the examples for thr random forest are nautral and surprising, but those for the LE-Net are often not: they often look as if they indeed belong to the other class (the one pointed by the classifier). In the churce-vs. tower case, a  relatively weak MLP classifier was used. It would be more instructive to see the results for a better, convolutional classifier.\nPage 5:\n-\tthe description of the various networks used for text generation is insufficient for understanding:\no\tThe AREA is described in two sentences. It is not clear how this module is built, was loss was it used to optimize in the first place, and what elements of it are re0used for the current task\no\t ‘inverter’ here is used in a sense which is different than in previous sections of the paper: earlier it denoted the mapping from output (images) to the underlying latent space. Here it denote  a mapping between two latent spaces.\no\t It is not clear what the ‘four-layers strided CNN’ is: its structure, its role in the system. How is it optimized?\no\tIn general: a block diagram showing the relation between all the system’s components may be useful, plus the details about the structure and optimization of the various modules. It seems that the system here contains 5 modules instead of the three used before (critic, generator and inverter), but this is not clear enough. Also which modules are pre-trained, which are optimized together,a nd which are optimized separately is not clear.\no\tSNLI data should be described: content, size, the task it is used for\n\n\nPro:\n-\tA novel idea of producing natural adversary examples with a GAN\n-\tThe generated examples are in some cases useful for interpretation and network understanding \n-\tThe method enables creation of adversarial examples for block box classifiers\nCons\n-\tThe idea implementation is basic. Specifically search algorithm presented is quite simplistic, and no variations other than plain local search were developed and tested\n-\tThe generated adversarial examples created for successful complex classifiers are often not impressive and useful (they are either not semantical, or semantical but correctly classified by the classifier). Hence It is not clear if the latent space used by the method enables finding of interesting adversarial examples for accurate classifiers. \n\n', 'Quality: Although the research problem is an interesting direction the quality of the work is not of a high standard. My main conservation is that the idea of perturbation in semantic latent space has not been described in an explicit way. How different it will be compared to a perturbation in an input space? \n\nClarity: The use of the term ""adversarial"" is not quite clear in the context as in many of those example classification problems the perturbation completely changes the class label (e.g. from ""church"" to ""tower"" or vice-versa)\n\nOriginality: The generation of adversarial examples in black-box classifiers has been looked in GAN literature as well and gradient based perturbations are studied too. What is the main benefit of the proposed mechanism compared to the existing ones?\n\nSignificance: The research problem is indeed a significant one as it is very important to understand the robustness of the modern machine learning methods by exposing them to adversarial scenarios where they might fail.\n\npros:\n(a) An interesting problem to evaluate the robustness of black-box classifier systems\n(b) generating adversarial examples for image classification as well as text analysis.\n(c) exploiting the recent developments in GAN literature to build the framework forge generating adversarial examples.\n\ncons:\n(a) The proposed search algorithm in the semantic latent space could be computationally intensive. any remedy for this problem?\n(b) Searching in the latent space z could be strongly dependent on the matching inverter $I_\\gamma(.)$. any comment on this?\n(c) The application of the search algorithm in case of imbalanced classes could be something that require further investigation.', 'The authors of the paper propose a framework to generate natural adversarial examples by searching adversaries in a latent space of dense and continuous data representation (instead of in the original input data space). The details of their proposed method are covered in Algorithm 1 on Page 12, where an additional GAN (generative adversarial network) I_{\\gamma}, which can be regarded as the inverse function of the original GAN G_{\\theta}, is trained to learn a map from the original input data space to the latent z-space. The authors empirically evaluate their method in both image and text domains and claim that the corresponding generated adversaries are natural (legible, grammatical, and semantically similar to the input).\n\nGenerally, I think that the paper is written well (except some issues listed at the end). The intuition of the proposed approach is clearly explained and it seems very reasonable to me.  \nMy main concern, however, is in the current sampling-based search algorithm in the latent z-space, which the authors have already admitted in the paper. The efficiency of such a search method decreases very fast when the dimensions of the z-space increases. Furthermore, such an approximation solution based on the sampling may be not close to the original optimal solution z* in Equation (3). This makes me feel that there is large room to further advance the paper. Another concern is that the authors have not provided sufficient number of examples to show the advantages of their proposed method over the other method (such as FGSM) in generating the adversaries. The example in Table 1 is very good; but more examples (especially involving the quantitative comparison) are needed to demonstrate the claimed advantages. For example, could the authors add such a comparison in Human Evaluation in Section 4 to support the claim that the adversaries generated by their method are more natural? \n\nOther issues are listed as follows:\n(1). Could you explicitly specify the dimension of the latent z-space in each example in image and text domain in Section 3?\n(2). In Tables 7 and 8, the human beings agree with the LeNet in >= 58% of cases. Could you still say that your generated “adversaries” leading to the wrong decision from LeNet? Are these really “adversaries”?\n(3). How do you choose the parameter \\lambda in Equation (2)?\n']","[-20, -20, 20]","[50, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('novel idea', 'useful for interpretation'), they also point out several significant limitations and areas for improvement. The cons section highlights basic implementation, simplistic search algorithm, and unimpressive results for complex classifiers, which outweigh the pros. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using neutral language to describe both strengths and weaknesses. They provide specific, constructive feedback without using harsh or dismissive language. The review is structured with clear 'Pro' and 'Con' sections, which is helpful and respectful to the authors."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting and significant research problem, they express several concerns about the quality, clarity, and originality of the work. The reviewer points out multiple 'cons' and areas needing improvement, which outweigh the 'pros' mentioned. However, the score is not deeply negative as the reviewer still finds value in the research direction.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express concerns (e.g., 'My main conservation is...', 'The use of the term... is not quite clear') rather than harsh criticism. The reviewer also balances negative points with positive ones, listing both 'pros' and 'cons'. The phrasing of questions and suggestions (e.g., 'any remedy for this problem?', 'any comment on this?') is polite and constructive rather than demanding or accusatory."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges that the paper is generally well-written and the proposed approach is reasonable. However, they express significant concerns about the sampling-based search algorithm and the lack of sufficient examples, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'My main concern, however, is...'), and offers specific suggestions for improvement. The reviewer also acknowledges the authors' own admission of limitations, which shows a considerate approach. The use of phrases like 'Could you...' when asking for clarifications further contributes to the polite tone.""]"
"['The paper proves the weak convergence of the regularised OT problem to Kantorovich / Monge optimal transport problems.\n\nI like the weak convergence results, but this is just weak convergence. It appears to be an overstatement to claim that the approach ""nearly-optimally"" transports one distribution to the other (Cf e.g. Conclusion). There is a penalty to pay for choosing a small epsilon -- it seems to be visible from Figure 2. Also, near-optimality would refer to some parameters being chosen in the best possible way. I do not see that from the paper. However, the weak convergence results are good.\n\nA better result, hinting on how ""optimal"" this can be, would have been to guarantee that the solution to regularised OT is within f(epsilon) from the optimal one, or from within f(epsilon) from the one with a smaller epsilon (more possibilities exist). This is one of the things experimenters would really care about -- the price to pay for regularisation compared to the unknown unregularized optimum. \n\nI also like the choice of the two regularisers and wonder whether the authors have tried to make this more general, considering other regularisations ? After all, the L2 one is just an approximation of the entropic one.\n\nTypoes:\n\n1- Kanthorovich -> Kantorovich (Intro)\n2- Cal C <-> C (eq. 4)', 'This paper explores a new approach to optimal transport. Contributions include a new dual-based algorithm for the fundamental task of computing an optimal transport coupling, the ability to deal with continuous distributions tractably by using a neural net to parameterize the functions which occur in the dual formulation, learning a Monge map parameterized by a neural net allowing extremely tractable mapping of samples from one distribution to another, and a plethora of supporting theoretical results. The paper presents significant, novel work in a straightforward, clear and engaging way. It represents an elegant combination of ideas, and a well-rounded combination of theory and experiments.\n\nI should mention that I\'m not sufficiently familiar with the optimal transport literature to verify the detailed claims about where the proposed dual-based algorithm stands in relation to existing algorithms.\n\nMajor comments:\n\nNo major flaws. The introduction is particular well written, as an extremely clear and succinct introduction to optimal transport.\n\nMinor comments:\n\nIn the introduction, for VAEs, it\'s not the case that f(X) matches the target distribution. There are two levels of sampling: of the latent X and of the observed value given the latent. The second step of sampling is ignored in the description of VAEs in the first paragraph.\n\nIn the comparison to previous work, please explicitly mention the EMD algorithm, since it\'s used in the experiments.\n\nIt would\'ve been nice to see an experimental comparison to the algorithm proposed by Arjovsky et al. (2017), since this is mentioned favorably in the introduction.\n\nIn (3), R is not defined. Suggest adding a forward reference to (5).\n\nIn section 3.1, it would be helpful to cite a reference to support the form of dual problem.\n\nPerhaps the authors have just done a good job of laying the groundwork, but the dual-based approach proposed in section 3.1 seems quite natural. Is there any reason this sort of approach wasn\'t used previously, even though this vein of thinking was being explored for example in the semi-dual algorithm? If so, it would interesting to highlight the key obstacles that a naive dual-based approach would encounter and how these are overcome.\n\nIn algorithm 1, it is confusing to use u to mean both the parameters of the neural net and the function represented by the neural net.\n\nThere are many terms in R_e in (5) which appear to have no effect on optimization, such as a(x) and b(y) in the denominator and ""- 1"". It seems like R_e boils down to just the entropy.\n\nThe definition of F_\\epsilon is made unnecessarily confusing by the omission of x and y as arguments.\n\nIt would be great to mention very briefly any helpful intuition as to why F_\\epsilon and H_\\epsilon have the forms they do.\n\nIn the discussion of Table 1, it would be helpful to spell out the differences between the different Bary proj algorithms, since I would\'ve expected EMD, Sinkhorn and Alg. 1 with R_e to all perform similarly.\n\nIn Figure 4 some of the samples are quite non-physical. Is their any helpful intuition about what goes wrong?\n\nWhat cost is used for generative modeling on MNIST?\n\nFor generative modeling on MNIST, ""784d vector"" is less clear than ""784-dimensional vector"". The fact that the variable d is equal to 768 is not explicitly stated.\n\nIt seems a bit strange to say ""The property we gain compared to other generative models is that our generator is a nearly optimal map w.r.t. this cost"" as if this was an advantage of the proposed method, since arguably there isn\'t a really natural cost in the generative modeling case (unlike in the domain adaptation case); the latent variable seems kind of conceptually distinct from observation space.\n\nAppendix A isn\'t referred to from the main text as far as I could tell. Just merge it into the main text?\n\n\n\n', 'Quality\nThe theoretical results presented in the paper appear to be correct. However, the experimental evaluation is globally limited,  hyperparameter tuning on test which is not fair.\n\nClarity\nThe paper is mostly clear, even though some parts deserve more discussion/clarification (algorithm, experimental evaluation).\n\nOriginality\nThe theoretical results are original, and the SGD approach is a priori original as well.\n\nSignificance\nThe relaxed dual formulation and OT/Monge maps convergence results are interesting and can of of interest for researchers in the area, the other aspects of the paper are limited.\n\nPros:\n-Theoretical results on the convergence of OT/Monge maps\n-Regularized formulation compatible with SGD\nCons\n-Experimental evaluation limited\n-The large scale aspect lacks of thorough analysis\n-The paper presents 2 contributions but at then end of the day, the development of each of them appears limited\n\nComments:\n\n-The weak convergence results are interesting. However, the fact that no convergence rate is given makes the result weak. \nIn particular, it is possible that the number of examples needed for achieving a given approximation is at least exponential.\nThis can be coherent with the problem of Domain Adaptation that can be NP-hard even under the co-variate shift assumption (Ben-David&Urner, ALT2012).\nThen, I think that the claim of page 6 saying that Domain Adaptation can be performed ""nearly optimally"" has then to be rephrased.\nI think that results show that the approach is theoretically justified but optimality is not here yet.\n\nTheorem 1 is only valid for entropy-based regularizations, what is the difficulty for having a similar result with L2 regularization?\n\n-The experimental evaluation on the running time is limited to one particular problem. If this subject is important, it would have been interesting to compare the approaches on other large scale problems and possibly with other implementations.\nIt is also surprising that the efficiency the L2-regularized version is not evaluated.\nFor a paper interesting in large scale aspects, the experimental evaluation is rather weak.\n \nThe 2 methods compared in Fig 2 reach the same objective values at convergence, but is there any particular difference in the solutions found?\n\n-Algorithm 1 is presented without any discussion about complexity, rate of convergence. Could the authors discuss this aspect?\nThe presentation of this algo is a bit short and could deserve more space (in the supplementary)\n\n-For the DA application, the considered datasets are classic but not really ""large scale"", anyway this is a minor remark.\nThe setup is not completely clear, since the approach is interesting for out of sample data, so I would expect the map to be computed on a small sample of source data, and then all source instances to be projected on target with the learned map. This point is not very clear and we do not know how many source instances are used to compute the mapping - the mapping is incomplete on this point while this is an interesting aspect of the paper: this justifies even more the large scale aspect is the algo need less examples during learning to perform similar or even better classification.\nHyperparameter tuning is another aspect that is not sufficiently precise in the experimental setup: it seems that the parameters are tuned on test (for all methods), which is not fair since target label information will not be available from a practical standpoint.\n\nThe authors claim that they did not want to compete with state of the art DA, but the approach of Perrot et al., 2016 seems to a have a similar objective and could be used as a baseline.\n\nExperiments on generative optimal transport are interesting and probably generate more discussion/perspectives.\n\n--\nAfter rebuttal\n--\nAuthors have answered to many of my comments, I think this is an interesting paper, I increase my score.\n', 'This paper proposes a new method for estimating optimal transport plans and maps among continuous distributions, or discrete distributions with large support size. First, the paper proposes a dual algorithm to estimate Kantorovich plans, i.e. a coupling between two input distributions minimizing a given cost function, using dual functions parameterized as neural networks. Then an algorithm is given to convert a generic plan into a Monge map, a deterministic function from one domain to the other, following the barycenter of the plan. The algorithms are shown to be consistent, and demonstrated to be more efficient than an existing semi-dual algorithm. Initial applications to domain adaptation and generative modeling are also shown.\n\nThese algorithms seem to be an improvement over the current state of the art for this problem setting, although more of a discussion of the relationship to the technique of Genevay et al. would be useful: how does your approach compare to the full-dual, continuous case of that paper if you simply replace their ball of RKHS functions with your class of deep networks?\n\nThe consistency properties are nice, though they don\'t provide much insight into the rate at which epsilon should be decreased with n or similar properties. The proofs are clear, and seem correct on a superficial readthrough; I have not carefully verified them.\n\nThe proofs are mainly limited in that they don\'t refer in any way to the class of approximating networks or the optimization algorithm, but rather only to the optimal solution. Although of course proving things about the actual outcomes of optimizing a deep network is extremely difficult, it would be helpful to have some kind of understanding of how the class of networks in use affects the solutions. In this way, your guarantees don\'t say much more than those of Arjovsky et al., who must assume that their ""critic function"" reaches the global optimum: essentially you add a regularization term, and show that as the regularization decreases it still works, but under seemingly the same kind of assumptions as Arjovsky et al.\'s approach which does not add an explicit regularization term at all. Though it makes sense that your regularization might lead to a better estimator, you don\'t seem to have shown so either in theory or empirically.\n\nThe performance comparison to the algorithm of Genevay et al. is somewhat limited: it is only on one particular problem, with three different hyperparameter settings. Also, since Genevay et al. propose using SAG for their algorithm, it seems strange to use plain SGD; how would the results compare if you used SAG (or SAGA/etc) for both algorithms?\n\nIn discussing the domain adaptation results, you mention that the L2 regularization ""works very well in practice,"" but don\'t highlight that although it slightly outperforms entropy regularization in two of the problems, it does substantially worse in the other. Do you have any guesses as to why this might be?\n\nFor generative modeling: you do have guarantees that, *if* your optimization and function parameterization can reach the global optimum, you will obtain the best map relative to the cost function. But it seems that the extent of these guarantees are comparable to those of several other generative models, including WGANs, the Sinkhorn-based models of Genevay et al. (2017, https://arxiv.org/abs/1706.00292/), or e.g. with a different loss function the MMD-based models of Li, Swersky, and Zemel (ICML 2015) / Dziugaite, Roy, and Ghahramani (UAI 2015). The different setting than the fundamental GAN-like setup of those models is intriguing, but specifying a cost function between the source and the target domains feels exceedingly unnatural compared to specifying a cost function just within one domain as in these other models.\n\nMinor:\n\nIn (5), what is the purpose of the -1 term in R_e? It seems to just subtract a constant 1 from the regularization term.']","[20, 80, -20, 20]","[60, 70, 50, 60]","[""The sentiment score is slightly positive (20) because the reviewer expresses appreciation for the weak convergence results and the choice of regularizers. However, they also point out limitations and suggest improvements, indicating a mixed but generally positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions without harsh or rude phrasing. They use phrases like 'I like' and 'I wonder' which contribute to a polite tone. The reviewer also provides helpful feedback on typos, which is a courteous gesture. The overall tone is professional and constructive, maintaining politeness while still providing critical feedback."", ""The sentiment score is 80 (quite positive) because the reviewer describes the paper as presenting 'significant, novel work in a straightforward, clear and engaging way' and an 'elegant combination of ideas'. They state there are 'No major flaws' and praise the introduction as 'extremely clear and succinct'. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as suggestions (e.g. 'It would've been nice to see...'). They also acknowledge their own limitations ('I'm not sufficiently familiar...'). The review maintains a professional tone while offering specific, actionable feedback. The slightly lower politeness score compared to sentiment reflects the directness of some critiques, though these are still phrased politely."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('theoretical results appear to be correct', 'original', 'interesting'), there are several criticisms and limitations pointed out ('experimental evaluation is globally limited', 'hyperparameter tuning on test which is not fair', 'large scale aspect lacks thorough analysis'). The overall tone suggests more areas for improvement than praise. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, balancing critiques with acknowledgments of the paper's strengths. They provide constructive feedback and suggestions rather than harsh criticism. The use of phrases like 'Could the authors discuss this aspect?' and 'I think that' when offering opinions contributes to the polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions as an improvement over the state of the art and praises the consistency properties and clear proofs. However, they also raise several limitations and questions, balancing out the positive aspects. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, poses questions and suggestions constructively, and acknowledges the paper's strengths alongside areas for improvement. They avoid harsh criticism and frame their points as opportunities for clarification or expansion rather than outright flaws.""]"
"[""NOTE:\nI'm very willing to change my recommendation if I turn out to be wrong \nabout the issues I'm addressing and if certain parts of the experiments are fixed.\n\nHaving said that, I do (think I) have some serious issues: \nboth with the experimental evaluation and with the theoretical results.\nI'm pretty sure about the experimental evaluation and less sure about the theoretical results.\n\n\nTHEORETICAL CLAIMS:\n\nThese are the complaints I'm not as sure about:\n\nTheorem 1 assumes that L is convex/concave.\nThis is not generally true for GANs.\nThat's fine and it doesn't necessarily make the statement useless, but:\n\nIf we are willing to assume that L is convex/concave, \nthen there already exist other algorithms that will provably converge\nto a saddle point (I think). [1] contains an explanation of this.\nGiven that there are other algorithms with the same theoretical guarantees,\nand that those algorithms don't magically make GANs work better, \nI am much less convinced about the value of your theorem.\n\nIn [0] they show that GANs trained with simultaneous gradient descent are locally asymptotically stable, \neven when L is not convex/concave. \nThis seems like it makes your result a lot less interesting, though perhaps I'm wrong to think this?\n\nFinally, I'm not totally sure you can show that simultaneous gradient descent won't converge \nas well under the assumptions you made.\nIf you actually can't show that, then the therom *is* useless, \nbut it's also the thing I've said that I'm the least sure about.\n\n\nEXPERIMENTAL EVALUATION:\n\nRegarding the claims of being able to train with a higher learning rate:\nI would consider this a useful contribution if it were shown that (by some measure of GAN 'goodness')\na high goodness was achieved faster because a higher learning rate was used.\nYour experiments don't support this claim presently, because you evaluate all the models at the same step.\nIn fact, it seems like both evaluated Stacked GAN models get worse performance with the higher learning rate.\nThis calls into question the usefulness of training with a higher learning rate.\nThe performance is not a huge amount worse though (based on my understanding of Inception Scores),\nso if it turns out that you could get that performance\nin 1/10th the time then that wouldn't be so bad.\n\nRegarding the experiment with Stacked GANs, the scores you report are lower than what they report [2].\nTheir reported mean score for joint training is 8.59.\nAre the baseline scores you report from an independent reproduction?\nAlso, the model they have trained uses label information. \nDoes your model use label information?\nGiven that your reported improvements are small, it would be nice to know what the proposed mechanism is by \nwhich the score is improved. \nWith a score of 7.9 and a standard deviation of 0.08, presumably none of the baseline model runs\nhad 'stability issues', so it doesn't seem like 'more stable training' can be the answer.\n\nFinally, papers making claims about fixing GAN stability should support those claims by solving problems\nwith GANs that people previously had a hard time solving (due to instability).\nI don't believe this is true of CIFAR10 (especially if you're using the class information).\nSee [3] for an example of a paper that does this by generating 128x128 Imagenet samples with a single generator.\n\nI didn't pay as much attention to the non-GAN experiments because\na) I don't have as much context for evaluating them, because they are a bit non-standard.\nb) I had a lot of issues with the GAN experiments already and I don't think the paper should be accepted unless those are addressed.\n\n\n[0] https://arxiv.org/abs/1706.04156 (Gradient Descent GAN Optimization is Locally Stable)\n\n[1] https://arxiv.org/pdf/1705.07215.pdf (On Convergence and Stability of GANs)\n\n[2] https://arxiv.org/abs/1612.04357 (Stacked GAN)\n\n[3] https://openreview.net/forum?id=B1QRgziT (Spectral Regularization for GANs)\n\nEDIT: \nAs discussed below, I have slightly raised my score. \nI would raise it more if more of my suggestions were implemented (although I'm aware that the authors don't have much (any?) time for this - and that I am partially to blame for that, since I didn't respond that quickly).\nI have also slightly raised my confidence.\nThis is because now I've had more time to think about the paper, and because the authors didn't really address a lot of my criticisms (which to me seems like evidence that some of my criticisms were correct)."", 'This paper proposes a simple modification to the standard alternating stochastic gradient method for GAN training, which stabilizes training, by adding a prediction step. \n\nThis is a clever and useful idea, and the paper is very well written. The proposed method is very clearly motivated, both intuitively and mathematically, and the authors also provide theoretical guarantees on its convergence behavior. I particularly liked the analogy with the damped harmonic oscillator.  \n\nThe experiments are well designed and provide clear evidence in favor of the usefulness of the proposed technique. I believe that the method proposed in this paper will have a significant impact in the area of GAN training.\n\nI have only one minor question: in the prediction step, why not use a step size, say \n$\\bar{u}_k+1 = u_{k+1} + \\gamma_k (u_{k+1} − u_k)$, such that the ""amount of predition"" may be adjusted?\n', 'This work proposes a framework for stabilizing adversarial nets using a prediction step. The prediction step is motivated by primal-dual algorithms in convex optimization where the term having both variables is bi-linear.  \n\nThe authors prove a convergence result when the function is convex in one variable and concave in the other. This problem is more general than the previous one in convex optimization.  Then this prediction step is applied in many recent applications in training adversarial nets and compared with state-of-the-art solvers. The better performance of this simple step is shown in most of the numerical experiments. \n\nThough this work applies one step from the convex optimization to solve a more complicated problem and obtain improved performance,  there is more work to be done. Whether there is a better generalization of this prediction step? There are also other variants of primal-dual algorithms in convex optimization; can other modification including the accelerated variants be applied?']","[-60, 90, 70]","[20, 80, 50]","[""The sentiment score is -60 because the reviewer expresses 'serious issues' with both the experimental evaluation and theoretical results. They use phrases like 'I do (think I) have some serious issues' and point out multiple problems with the paper's claims and experiments. However, they do leave room for the authors to address these concerns, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they use polite language throughout. They start by saying they're 'willing to change my recommendation' and use phrases like 'I'm not totally sure' and 'perhaps I'm wrong to think this?' which show respect and openness to dialogue. They also provide detailed explanations and references to support their critiques, which is a courteous way to provide feedback. The overall tone is professional and constructive, despite the negative sentiment."", ""The sentiment score is 90 (highly positive) because the reviewer expresses strong approval of the paper, calling it a 'clever and useful idea' and 'very well written'. They predict it will have 'significant impact' and provide 'clear evidence' of its usefulness. The only slight detraction is a minor question at the end. The politeness score is 80 (quite polite) due to the use of positive and respectful language throughout. The reviewer compliments the authors' work multiple times and frames their single question as a minor inquiry rather than a criticism. The tone is consistently professional and courteous."", ""The sentiment score is 70 (positive) because the reviewer acknowledges the work's contributions and improved performance in most numerical experiments. They use phrases like 'better performance' and 'improved performance', indicating a generally positive view. However, it's not 100 as they also mention 'there is more work to be done' and raise questions for further research. The politeness score is 50 (slightly polite) because the language is professional and respectful throughout. The reviewer acknowledges the work's merits and offers constructive suggestions for improvement without using harsh or critical language. However, it doesn't contain overtly polite phrases or compliments, keeping it from scoring higher on the politeness scale.""]"
"['This paper extends the concept of global rather than local optimization from the learning to search (L2S) literature to RNNs, specifically in the formation and implementation of SEARNN. Their work takes steps to consider and resolve issues that arise from restricting optimization to only local ground truth choices, which traditionally results in label / transition bias from the teacher forced model.\n\nThe underlying issue (MLE training of RNNs) is well founded and referenced, their introduction and extension to the L2S techniques that may help resolve the issue are promising, and their experiments, both small and large, show the efficacy of their technique.\n\nI am also glad to see the exploration of scaling SEARNN to the IWSLT\'14 de-en machine translation dataset. As noted by the authors, it is a dataset that has been tackled by related papers and importantly a well scaled dataset. For SEARNN and related techniques to see widespread adoption, the scaling analysis this paper provides is a fundamental component.\n\nThis reviewer, whilst not having read all of the appendix in detail, also appreciates the additional insights provided by it, such as including losses that were attempted but did not result in appreciable gains.\n\nOverall I believe this is a paper that tackles an important topic area and provides a novel and persuasive potential solution to many of the issues it highlights.\n\n(extremely minor typo: ""One popular possibility from L2S is go the full reduction route down to binary classification"")', 'This paper proposes an adaptation of the SEARN algorithm to RNNs for generating text. In order to do so, they discuss various issues on how to scale the approach to large output vocabularies by sampling which actions the algorithm to explore.\n\nPros:\n- Good literature review. But the future work on bandits is already happening:\nPaper accepted at ACL 2017: Bandit Structured Prediction for Neural Sequence-to-Sequence Learning. Julia Kreutzer, Artem Sokolov, Stefan Riezler.\n\n\nCons:\n- The key argument of the paper is that SEARNN is a better IL-inspired algorithm than the previously proposed ones. However there is no direct comparison either theoretical or empirical against them. In the examples on spelling using the dataset of Bahdanau et al. 2017, no comparison is made against their actor-critic method. Furthermore, given its simplicity, I would expect a comparison against scheduled sampling.\n\n- A lot of important experimental details are in the appendices and they differ among experiments. For example, while mixed rollins are used in most experiments, reference rollins are used in MT, which is odd since it is a bad option theoretically. Also,  no details are given on how the mixing in the rollouts was tuned. Finally, in the NMT comparison while it is stated that similar architecture is used in order to compare fairly against previous work, this is not the case eventually, as it is acknowledged at least in the case of MIXER. I would have expected the same encoder-decoder architecture to have been used for all the methods considered.\n \n- the two losses introduced are not really new. The log-loss is just MLE, only assuming that instead of a fixed expert that always returns the same target, we have a dynamic one. Note that the notion of dynamic expert is present in the SEARN paper too. Goldberg and Nivre just adapted it to transition-based dependency parsing. Similarly, since the KL loss is the same as XENT, why give it a new name?\n\n- the top-k sampling method is essentially the same as the targeted exploration of Goodman et al. (2016) which the authors cite. Thus it is not a novel contribution.\n  \n- Not sure I see the difference between the stochastic nature of SEARNN and the online one of LOLS mentioned in section 7. They both could be mini-batched similarly. Also, not sure I see why SEARNN can be used on any task, in comparison to other methods. They all seem to be equally capable.\n\nMinor comments:\n- Figure 1: what is the difference between ""cost-sensitive loss"" and just ""loss""?\n- local vs sequence-level losses: the point in Ranzato et al and Wiseman & Rush is that the loss they optimizise (BLEU/ROUGE) do not decompose over the the predictions of the RNNs.\n- Can\'t see why SEARNN can help with the vanishing gradient problem. Seem to be rather orthogonal.\n', 'The paper proposes new RNN training method based on the SEARN learning to search (L2S) algorithm and named as SeaRnn. It proposes a way of overcoming the limitation of local optimization trough the exploitation of the structured losses by L2S. It can consider different classifiers and loss functions, and a sampling strategy for making the optimization problem scalable is proposed. SeaRnn improves the results obtained by MLE training in three different problems, including a large-vocabulary machine translation. In summary, a very nice paper.\n\nQuality: SeaRnn is a well rooted and successful application of the L2S strategy to the RNN training that combines at the same time global optimization and scalable complexity. \n\nClarity: The paper is well structured and written, with a nice and well-founded literature review.\n\nOriginality: the paper presents a new algorithm for training RNN based on the L2S methodology, and it has been proven to be competitive in both toy and real-world problems.\n\nSignificance: although the application of L2S to RNN training is not new, the contribution to the overcoming the limitations due to error propagation and MLE training of RNN is substantial.\n']","[90, -50, 90]","[80, 20, 80]","[""The sentiment score is 90 because the reviewer expresses a very positive view of the paper throughout. They describe the work as 'promising', 'efficacious', and 'novel and persuasive'. They appreciate various aspects of the paper, including its foundation, experiments, and additional insights. The only slight negative is a minor typo mentioned at the end, which barely impacts the overall positive sentiment. The politeness score is 80 because the reviewer uses respectful and appreciative language throughout. They express gladness for certain aspects of the work and appreciation for the additional insights. The tone is professional and constructive, without any harsh criticism. The reviewer even frames the typo note as 'extremely minor', showing consideration for the authors' feelings. While very polite, it doesn't reach 100 as it maintains a professional rather than overly deferential tone."", ""The sentiment score is -50 because while the reviewer acknowledges some pros like a good literature review, they list several significant cons and criticisms of the paper. These include lack of direct comparisons, important details missing or in appendices, claims of novelty that aren't justified, and questioning of the paper's key arguments. The overall tone is more negative than positive. The politeness score is 20 because the reviewer uses professional and neutral language throughout, avoiding harsh or rude phrasing even when critical. They use phrases like 'I would expect' or 'Not sure I see' rather than more confrontational language. However, the review is also quite direct in its criticisms rather than being overly polite or deferential."", ""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer describes the paper as 'a very nice paper' and praises its quality, clarity, originality, and significance. They use phrases like 'well rooted and successful,' 'well structured and written,' and 'competitive' to describe various aspects of the paper. The only reason it's not 100 is because there's no explicit mention of the paper being perfect or flawless. The politeness score is 80 because the language used is consistently respectful and professional. The reviewer offers praise without using overly effusive language, maintaining a polite and academic tone throughout. They don't use any negative or critical language, which contributes to the high politeness score. However, it's not 100 as the review doesn't go out of its way to be exceptionally polite; it maintains a standard level of academic courtesy.""]"
"['General comment:\n\nThis paper proposes a GAN-based method which learns bidirectional mappings between the real-data and the simulated data. The proposed methods builds upon the CycleGAN and the Simulated+Unsupervised (S+U) learning frameworks. The authors show that the proposed method is able to fully leverage the flexibility of simulators by presenting an improved performance on the gaze estimation task.\n\nDetailed comments:\n\n1. The proposed method seems to be a direct combination of the CycleGAN and the S+U learning. Firstly, the CycleGAN propose a to learn a bidirectional GAN model between for image translation. Here the author apply it by ""translating"" the the simulated data to real-data. Moreover, the mapping from simulated data to the real-data is learned, the S+U learning framework propose to train a model on the simulated data.\n\nHence, this paper seems to directly apply S+U learning to CycleGAN. The properties of the proposed method comes immediately from CycleGAN and S+U learning. Without deeper insights of the proposed method, the novelty of this paper is not sufficient.\n\n2. When discussing CycleGAN, the authors claim that CycleGAN is not good at preserving the labels. However, it is not clear what the meaning of preserving labels is. It would be nice if the authors clearly define this notion and rigorously discuss why CycleGAN is insufficient to reach such a goal and why combining with S+U learning would help.\n\n3. This work seems closely related to S+U learning. It would be nice if the authors also summarize S+U learning in Section 2, in the similar way they summarize CycleGAN in Section 2.2.\n\n4. In Section 2.2, the authors claim that the Cycle-consistency loss in CycleGAN is not sufficient for label preservation. To improve, they propose to use the feature consistency loss. However, the final loss function also contains this cycle-consistency loss. Moreover, in the experiments, the authors indeed use the cycle-consistency loss by setting \\lambda_{cyc} = 10. But the feature consistency loss may not be used by setting \\lambda_{feature} = 0 or 0.5. From table Two, it appears that whether using the feature-consistency loss does not have significant effect on the performance.\n\nIt would be nice to conduct more experiments to show the effect of adding the feature-consistent loss. Say, setting \\lambda_{cyc} = 0 and try different values of \\lambda_{feature}. Otherwise it is unclear whether the feature-consistent loss is necessary.\n', 'Review, ICLR 2018, Simulated+Unsupervised Learning With Adaptive Data Generation and Bidirectional Mappings\n\nSummary:\n\nThe paper presents several extensions to the method presented in SimGAN (Shirvastava et al. 2017). \nFirst, it adds a procedure to make the distribution of parameters of the simulation closer to the one in real world images. A predictor is trained on simulated images created with a manually initialized distribution. This predictor is used to estimate pseudo labels for the unlabeled real-world data. The distribution of the estimated pseudo labels is used produce a new set of simulated images. This process is iterated. \nSecond, it adds the idea of cycle consistency (e.g., from CycleGAN) in order to counter mode collapse and label shift. \nThird, since cycle consistency does not fully solve the label shift problem, a feature consistency loss is added.\nFinally, in contrast to ll related methods, the final system used for inference is not a predictor trained on a mix of real and “fake” images from the real-world target domain. Instead the predictor is trained purely on synthetic data and it is fed real world examples by using the back/real-to-sim-generator (trained in the conjunction with the forward mapping cycle) to map the real inputs to “fake” synthetic ones.\n\nThe paper is well written. The novelty is incremental in most parts, but the overall system can be seen as novel. \n\nIn particular, I am not aware of any published work that uses of the (backwards) real-to-sim generator plus sim-only trained predictor for inference (although I personally know several people who had the same idea and have been working on it). I like this part because it perfectly makes sense not to let the generator hallucinate real-world effects on rather clean simulated data, but the other way around, remove all kinds of variations to produce a clean image from which the prediction should be easier.\n\nThe paper should include Bousmalis et al., “Unsupervised Pixel-Level Domain Adaptation With Generative Adversarial Networks”, CVPR 2017 in its discussion, since it is very closely related to Shirvastava et al. 2017.\n\nWith respect to the feature consistency loss the paper should also discuss related work defining losses over feature activations for very similar reasons, such as in image stylization (e.g. L. A. Gatys et al. “Image Style Transfer Using Convolutional Neural Networks” CVPR 2016, L. A. Gatys et al. “Controlling Perceptual Factors in Neural Style Transfer” CVPR 2017), or the recently presented “Photographic Image Synthesis with Cascaded Refinement Networks”, ICCV 2017.\nBousmalis et al., “Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping”, arXiv:1709.07857, even uses the same technique in the context of training GANs.\n\nAdaptive Data Generation:\nI do not fully see the point in matching the distribution of parameters of the real world samples with the simulated data. For the few, easily interpretable parameters in the given task it should be relatively easy to specify reasonable ranges. If the simulation in some edge cases produces samples that are beyond the range of what occurs in the real world, that is maybe not very efficient, but I would be surprised if it ultimately hurt the performance of the predictor. \nI do see the advantage when training the GAN though, since a good discriminator would learn to pick out those samples as generated. Again, though, I am not very sure whether that would hurt the performance of the overall system in practice.\n\nLimiting the parameters to those values of the real world data also seems rather restricting. If the real world data does not cover certain ranges, not because those values are infeasible or infrequent, but just because it so happens that this range was not covered in the data acquisition, the simulation could be used to fill in those ranges. \nAdditionally, the whole procedure of training on sim data and then pseudo-labeling the real data with it is based on the assumption that a predictor trained on simulated data only already works quite well on real data. It might be possible in the case of the task at hand, but for more challenging domain adaptation problem it might not be feasible. \nThere is also no guarantee for the convergence of the cycle, which is also evident from the experiments (Table 1. After three iterations the angle error increases again. (The use of the Hellinger distance is unclear to me since it, as explained in the text, does not correspond with what is being optimized). In the experiments the cycle was stopped after two iterations. However, how would you know when to stop if you didn’t have ground truth labels for the real world data?\n\nComparisons:\nThe experiments should include a comparison to using the forward generator trained in this framework to train a predictor on “fake” real data and test it on real data (ie. a line “ours | RS | R | ?” in Table 2, and a more direct comparison to Shrivastava). This would be necessary to prove the benefit of using the back-generator + sim trained predictor.\n\n\nDetailed comments:\n* Figure 1 seems not to be referenced in the text.\n* I don’t understand the choice for reduction of the sim parameters. Why was, e.g., the yaw and pitch parameters of the eyeball set equal to those of the camera? Also, I guess there is a typo in the last equality (pitch and yaw of the camera?).\n* The Bibliography needs to be checked. Names of journals and conferences are inconsistent, long and short forms mixed, year several times, “Proceedings” multiple times, ...\n', '* sec.2.2 is about label-preserving translation and many notations are introduced. However, it is not clear what label here refers to, and it does not shown in the notation so far at all. Only until the end of sec.2.2, the function F(.) is introduced and its revelation - Google Search as label function is discussed only at Fig.4 and sec.2.3.\n* pp.5 first paragraph: when assuming D_X and D_Y being perfect, why L_GAN_forward = L_GAN_backward = 0? To trace back, in fact it is helpful to have at least a simple intro/def. to the functions D(.) and G(.) of Eq.(1). \n* Somehow there is a feeling that the notations in sec.2.1 and sec.2.2 are not well aligned. It is helpful to start providing the math notations as early as sec.2.1, so labels, pseudo labels, the algorithm illustrated in Fig.2 etc. can be consistently integrated with the rest notations. \n* F() is firstly shown in Fig.2 the beginning of pp.3, and is mentioned in the main text as late as of pp.5.\n* Table 2: The CNN baseline gives an error rate of 7.80 while the proposed variants are 7.73 and 7.60 respectively. The difference of 0.07/0.20 are not so significant. Any explanation for that?\nMinor issues:\n* The uppercase X in the sentence before Eq.(2) should be calligraphic X']","[-30, 50, -20]","[50, 70, 50]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'improved performance on the gaze estimation task'), they express significant concerns about the novelty and methodology. Phrases like 'novelty of this paper is not sufficient' and 'it is unclear whether the feature-consistent loss is necessary' indicate a generally negative sentiment. However, it's not extremely negative as the reviewer offers constructive feedback and suggestions for improvement. The politeness score is 50 because the reviewer uses respectful language throughout, employing phrases like 'It would be nice if' and 'The authors claim that' rather than using harsh or dismissive language. They also offer specific suggestions for improvement, which is a polite way to provide criticism. The tone is professional and constructive, though not overly formal or deferential."", ""The sentiment score is 50 (slightly positive) because the reviewer begins with a neutral summary of the paper's content, then expresses appreciation for certain aspects ('I like this part...'), while also offering constructive criticism and suggestions for improvement. The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths ('The paper is well written', 'I like this part...'), and frames criticisms as suggestions or questions rather than harsh judgments. The reviewer also uses phrases like 'I do not fully see the point' instead of more confrontational language. The detailed comments are presented objectively without personal attacks."", ""The sentiment score is slightly negative (-20) because the review primarily focuses on areas for improvement and clarification, with multiple points of critique. However, it's not strongly negative as the tone is constructive rather than dismissive. The politeness score is moderately positive (50) as the reviewer uses neutral language and phrases suggestions as helpful recommendations ('it is helpful to...') rather than direct criticisms. The review maintains a professional tone throughout, avoiding harsh or rude language. The reviewer also acknowledges positive aspects, such as noting the proposed variants' improved error rates, even while asking for further explanation. This balanced approach contributes to the overall polite tone.""]"
"['Summary: This paper proposes a different approach to deep multi-task learning using “soft ordering.”  Multi-task learning encourages the sharing of learned representations across tasks, thus using less parameters and tasks help transfer useful knowledge across. Thus enabling the reuse of universally learned representations and reuse them by assembling them in novel ways for new unseen tasks. The idea of “soft ordering” enforces the idea that there shall not be a rigid structure for all the tasks, but a soft structure would make the models more generalizable and modular. \n\nThe methods reviewed prior work which the authors refer to as “parallel order”, which assumed that subsequences of the feature hierarchy align across tasks and sharing between tasks occurs only at aligned depths whereas in this work the authors argue that this shouldn’t be the case. They authors then extend the approach to “permuted order” and finally present their proposed “soft ordering” approach. The authors argue that their proposed soft ordering approach increase the expressivity of the model while preserving the performance. \n\nThe “soft ordering” approach simply enable task specific selection of layers, scaled with a learned scaling factor, to be combined in which order to result for the best performance for each task. The authors evaluate their approach on MNIST, UCI, Omniglot and CelebA datasets and compare their approach to “parallel ordering” and “permuted ordering” and show the performance gain.\n\nPositives: \n- The paper is clearly written and easy to follow\n- The idea is novel and impactful if its evaluated properly and consistently \n- The authors did a great job summarizing prior work and motivating their approach\n\nNegatives: \n- Multi-class classification problem is one incarnation of Multi-Task Learning, there are other problems where the tasks are different (classification and localization) or auxiliary (depth detection for navigation). CelebA dataset could have been a good platform for testing different tasks, attribute classification and landmark detection. \u2028\n(TODO) I would recommend that the authors test their approach on such setting.\n- Figure 6 is a bit confusing, the authors do not explain why the “Permuted Order” performs worse than “Parallel Order”. Their assumptions and results as of this section should be consistent that soft order>permuted order>parallel order>single task. \n\u2028(TODO) I would suggest that the authors follow up on this result, which would be beneficial for the reader.\n- Figure 4(a) and 5(b), the results shown on validation loss, how about testing error similar to Figure 6(a)? How about results for CelebA dataset, it could be useful to visualize them as was done for MNIST, Omniglot and UCL.\u2028\n(TODO) I would suggest that the authors make the results consistent across all datasets and use the same metric such that its easy to compare.\n\nNotation and Typos:\n- Figure 2 is a bit confusing, how come the accuracy decreases with increasing number of training samples? Please clarify.\n1- If I assume that the Y-Axis is incorrectly labeled and it is Training Error instead, then the permuted order is doing worse than the parallel order.\n\u20282- If I assume that the X-Axis is incorrectly labeled and the numbering is reversed (start from max and ending at 0), then I think it would make sense.\n- Figure 4 is very small and not easy to read the text. Does single task mean average performance over the tasks? \n- In eq.(3) Choosing \\sigma_i for a task-specific permutation of the network is a bit confusing, since it could be thought of as a sigmoid function, I suggest using a different symbol.\n\u2028Conclusion: I would suggest that the authors address the concerns mentioned above. Their approach and idea is very interesting and relevant, and addressing these suggestions will make the paper strong for publication.', ""- The paper proposes to learn a soft ordering over a set of layers for multitask learning (MTL) i.e.\n  at every step of the forward propagation, each task is free to choose its unique soft (`convex')\n  combination of the outputs from all available layers. This idea is novel and interesting.\n- The learning of such soft combination is done jointly while learning the tasks and is not set\n  manually cf. setting permutations of a fixed number of layer per task\n- The empirical evaluation is done on intuitively related, superficially unrelated, and a real world\n  task. The first three results are on small datasets/tasks, O(10) feature dimensions, and number of\n  tasks and O(1000) images; (i) distinguish two MNIST digits, (ii) 10 UCI tasks with feature sizes\n  4--30 and number of classes 2--10, (iii) 50 different character recognition on Omniglot dataset.\n  The last task is real world -- 40 attribute classification on the CelebA face dataset of 200K\n  images. While the first three tasks are smaller proof of concept, the last task could have been\n  more convincing if near state-of-the-art methods were used. The authors use a Resnet-50 which is a\n  smaller and lesser performing model, they do mention that benefits are expected to be \n  complimentary to say larger model, but in general it becomes harder to improve strong models.\n  While this does not significantly dilute the message, it would have made it much more convincing\n  if results were given with stronger networks.                      \n- The results are otherwise convincing and clear improvements are shown with the proposed method.\n- The number of layers over which soft ordering was tested was fixed however. It would be\n  interesting to see what would the method learn if the number of layers was explicitly set to be\n  large and an identity layer was put as one of the option. In that case the soft ordering could\n  actually learn the optimal depth as well, repeating identity layer beyond the option number of\n  layers.                                                            \n                                                                     \nOverall, the paper presents a novel idea, which is well motivated and clearly presented. The \nempirical validation, while being limited in some aspects, is largely convincing."", 'This paper proposes a new approach for multi-task learning. While previous approaches assumes the order of shared layers are the same between tasks, this paper assume the order can vary across tasks, and the (soft) order is learned during training.  They show improved performance on a number of multi-task learning problems. \n\nMy primary concern about this paper is the lack of interpretation on permuting the layers. For example, in standard vision systems, low level filters ""V1"" learn edge detectors (gabor filters) and higher level filters learn angle detectors [1]. It is confusing why permuting these filters make sense. They accept different inputs (raw pixels vs edges). Moreover, if the network contains pooling layers, different locations of the pooling layer result in different shapes of the feature map, and the soft ordering strategy Eq. (7) does not work. \n\nIt makes sense that the more flexible model proposed by this paper performs better than previous models. The good aspect of this paper is that it has some performance improvements. But I still wonder the effect of permuting the layers. The paper also needs more clarifications in the writing. For example, in Section 3.3, how each s_(i, j, k) is sampled from S? The ""parallel ordering"" terminology also seems to be arbitrary...\n\n[1] Lee, Honglak, Chaitanya Ekanadham, and Andrew Y. Ng. ""Sparse deep belief net model for visual area V2."" Advances in neural information processing systems. 2008.']","[50, 70, -20]","[80, 60, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges both positives and negatives of the paper. They praise the clear writing, novel idea, and good summary of prior work, but also point out several areas for improvement. The overall tone suggests the paper has potential but needs revisions. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as recommendations rather than demands. Phrases like 'I would suggest' and 'I would recommend' contribute to the polite tone. The reviewer also balances criticism with praise, which is a polite approach to feedback."", ""The sentiment score is 70 (positive) because the reviewer describes the paper's idea as 'novel and interesting', mentions that the results are 'convincing', and states that the paper is 'well motivated and clearly presented'. The overall tone is positive, with some constructive criticism. The politeness score is 60 (polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and offers suggestions for improvement in a constructive manner. The reviewer balances praise with areas for potential enhancement, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('good aspect', 'performance improvements'), they express significant concerns about the paper's approach and lack of interpretation. The reviewer uses phrases like 'primary concern', 'It is confusing', and 'I still wonder', indicating skepticism about the method's validity and effectiveness. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using neutral language and avoiding harsh criticism. They offer constructive feedback and suggestions for improvement, which is a polite approach in academic peer review. The reviewer also acknowledges the paper's strengths alongside its weaknesses, demonstrating a balanced and respectful critique.""]"
"[""This paper discusses several gradient based attribution methods, which have been popular for the fast computation of saliency maps for interpreting deep neural networks. The paper provides several advances:\n- \\epsilon-LRP and DeepLIFT are formulated in a way that can be calculated using the same back-propagation as training.\n- This gives a more unified way of understanding, and implementing the methods.\n- The paper points out situations when the methods are equivalent\n- The paper analyses the methods' sensitivity to identifying single and joint regions of sensitivity\n- The paper proposes a new objective function to measure joint sensitivity\n\nOverall, I believe this paper to be a useful contribution to the literature. It both solidifies understanding of existing methods and provides new insight into quantitate ways of analysing methods. Especially the latter will be appreciated."", 'The paper shows that several recently proposed interpretation techniques for neural network are performing similar processing and yield similar results. The authors show that these techniques can all be seen as a product of input activations and a modified gradient, where the local derivative of the activation function at each neuron is replaced by some fixed function.\n\nA second part of the paper looks at whether explanations are global or local. The authors propose a metric called sensitivity-n for that purpose, and make some observations about the optimality of some interpretation techniques with respect to this metric in the linear case. The behavior of each explanation w.r.t. these properties is then tested on multiple DNN models tested on real-world datasets. Results further outline the resemblance between the compared methods.\n\nIn the appendix, the last step of the proof below Eq. 7 is unclear. As far as I can see, the variable g_i^LRP wasn’t defined, and the use of Eq. 5 to achieve this last could be better explained. There also seems to be some issues with the ordering i,j, where these indices alternatively describe the lower/higher layers, or the higher/lower layers.', 'The paper summarizes and compares some of the current explanation techniques for deep neural networks that rely on the redistribution of relevance / contribution values from the output to the input space.\n\nThe main contributions are the introduction of a unified framework that expresses 4 common attribution techniques (Gradient * Input, Integrated Gradient, eps-LRP and DeepLIFT) in a similar way as modified gradient functions and the definition of a new evaluation measure (\'sensitivity n\') that generalizes the earlier defined properties of \'completeness\' and \'summation to delta\'.\n\nThe unified framework is very helpful since it points out equivalences between the methods and makes the implementation of eps-LRP and DeepLIFT substantially more easy on modern frameworks. However, as correctly stated by the authors some of the unification (e.g. relation between LRP and Gradient*Input) has been already mentioned in prior work.\n\nSensitivity-n as a measure tries to tackle the difficulty of estimating the importance of features that can be seen either separately or in combination. While the measure shows interesting trends towards a linear behaviour for simpler methods, it does not persuade me as a measure of how well the relevance attribution method mimics the decision making process and does not really point out substantial differences between the different methods. Furthermore, The authors could comment on the relation between sensitivity-n and region perturbation techniques (Samek et al., IEEE TNNLS, 2017). Sensitivtiy-n seems to be an extension of the region perturbation idea to me.\n\nIt would be interesting to see the relation between the ""unified"" gradient-based explanation methods and approaches (e.g. Saliency maps, alpha-beta LRP, Deep Taylor, Deconvolution Networks, Grad-CAM, Guided Backprop ...) which do not fit into the unification framework. It\'s good that the author mention these works, still it would be great to see more discussion on the advantages/disadvantages, because these methods may have some nice theoretically properties (see e.g. the discussion on gradient vs. decompositiion techniques in Montavon et al., Digital Signal Processing, 2017) which can not be incorporated into the unified framework.']","[80, 50, 50]","[60, 20, 75]","[""The sentiment score is 80 (positive) because the reviewer expresses a clear positive view, stating that the paper is 'a useful contribution to the literature' and highlighting several advances and positive aspects. The reviewer also mentions that the paper's contributions 'will be appreciated'. The politeness score is 60 (moderately polite) as the reviewer uses respectful and professional language throughout, avoiding any harsh criticism. The tone is constructive and appreciative, using phrases like 'I believe' to soften opinions. However, it doesn't go to extremes of politeness, maintaining a professional, matter-of-fact tone overall."", ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the paper's contributions in showing similarities between interpretation techniques and proposing a new metric. The tone is generally positive, highlighting the paper's findings and observations. However, it's not overwhelmingly positive, as the reviewer points out some unclear aspects in the appendix. The politeness score is 20 (slightly polite) because the language is professional and respectful, without being overly formal or deferential. The reviewer provides constructive feedback, particularly about the appendix, in a neutral tone without harsh criticism. The use of phrases like 'The paper shows' and 'The authors show' indicates a respectful acknowledgment of the authors' work."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions, particularly the unified framework, which is described as 'very helpful'. However, they also express some reservations about the novelty of certain aspects and the effectiveness of the new evaluation measure. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' correct statements, and phrases criticisms constructively (e.g., 'it would be interesting to see...' and 'it would be great to see more discussion...'). The reviewer also balances positive comments with areas for improvement, maintaining a professional and courteous tone.""]"
"['This paper introduces an architecture for training a MT model without any parallel material, and tests it on benchmark datasets (WMT and captions) for two language pairs. Although the resulting performance is only about half that of a more traditional model, the fact that this is possible at all is remarkable.\n\nThe method relies on fairly standard components which will be familiar to most readers: a denoising auto-encoder and an adversarial discriminator. Not much detail is given on the actual models used, for which the authors mainly refer to prior work. This is disappointing: the article would be more self-contained by providing even a high-level description of the models, such as provided (much too late) for the discriminator architecture.\n\nMisc comments:\n\n""domain"" seems to be used interchangeably with ""language"". This is unfortunate as ""domain"" has another, specific meaning in NLP in general and SMT in partiular. Is this intentional (if so what is the intention?) or is this just a carry-over from other work in cross-domain learning?\n\nSection 2.3: How do you sample permutations for the noise model, with the constraint on reordering range, in the general case of sentences of arbitrary lengths?\n\nSection 2.5: ""the previously introduced loss [...] mitigates this concern"" -- How? Is there a reference backing this?\n\nFigure 3: In the caption, what is meant by ""(t) = 1""? Are these epochs only for the first iteration (from M(1) to M(2))?\n\nSection 4.1: Care is taken to avoid sampling corresponding src and tgt sentences. However, was the parallel corpus checked for duplicates or near duplicates? If not, ""aligned"" segments may still be present. (Although it is clear that this information is not used in the algorithm)\n\nThis yields a natural question: Although the two monolingual sets extracted from the parallel data are not aligned, they are still very close. It would be interesting to check how the method behaves on really comparable corpora where its advantage would be much clearer.\n\nSection 4.2 and Table 1: Is the supervised learning approach trained on the full parallel corpus? On a parallel corpus of similar size?\n\nSection 4.3: What are the quoted accuracies (84.48% and 77.29%) measured on?\n\nSection 4.5: Experimental results show a regular inprovement from iteration 1 to 2, and 2 to 3. Why not keep improving performance? Is the issue training time?\n\nReferences: (He, 2016a/b) are duplicates\n\nResponse read -- thanks.', 'The authors present an approach for unsupervised MT which uses a weighted loss function containing 3 components: (i) self reconstruction (ii) cross reconstruction and (iii) adversarial loss. The results are interesting (but perhaps less interesting than what is hinted in the abstract). \n\n1) In the abstract the authors mention that they achieve a BLEU score of 32.8 but omit the fact that this is only on Multi30K dataset and not on the more standard WMT datasets. At first glance, most people from the field would assume that this is on the WMT dataset. I request the authors to explicitly mention this in the abstract itself (there is clearly space and I don\'t see why this should be omitted)\n\n2) In section 2.3, the authors talk about the Noise Model which is inspired by the standard Denoising Autoencoder setup.  While I understand the robustness argument in the case of AEs I am not convinced that the same applies to languages. Such random permutations can often completely alter the meaning of the sentence. The ablation test seems to suggest that this process helps. I read another paper which suggests that this noise does not help (which intuitively makes sense). I would like the authors to comment on this (of course, I am not asking you to compare with  the other paper but I am just saying that I have read contradicting observations - one which seems intuitive and the other does not).\n\n3) How were the 3 lambdas in Equation 3 selected ? What ranges did you consider. The three loss terms seem to have very different ranges. How did you account for that?\n\n4) Clarification: In section 2.5 what exactly do you mean by ""as long as the two monolingual corpora exhibit strong structure in feature space."" How do you quantify this ?\n\n5) In section 4.1, can you please mention the exact number of sentences that you sampled from WMT\'14. You mention that selected sentences from 15M random pairs but how many did you select ? The caption of one of the figure mentions that there were 10M sentences. Just want to confirm this.\n\n6) The improvements are much better on the Multi30k dataset. I guess this is because this dataset has smaller sentences with smaller vocabulary. Can you provide a table comparing the average number of sentences and vocabulary size of the two datasets (Multi30k and WMT).\n\n7) The ablation results are provided only for the Multi30k dataset. Can you provide similar results for the WMT dataset. Perhaps this would help in answering my query in point (2) above.\n\n8) Can you also check the performance of a PBSMT system trained on 100K parallel sentences? Although NMT outperforms PBSMT when the data size is large, PBSMT might still be better suited for low resource settings.\n\n9) There are some missing citations (already pointed by others in the forum) . Please add those.\n\n\n+++++++++++++++++++++++\nI have noted the clarifications posted by the authors. I still have concerns about a couple of things.  For example, I am still not convinced about the justification given for word order. I understand that empirically it works better but I don\'t get the intuition. Similarly, I don\'t get the argument about ""strong structure in feature space"". This is just a conjecture and it is very hard to measure it. I would request the authors to not emphasize on it or give a different more grounded intuition. \n\nI do acknowledge the efforts put in by the authors to address some of my comments and for that I would like to change my rating a bit.\n', 'This paper describes an approach to train a neural machine translation system without parallel data. Starting from a word-to-word translation lexicon, which was also learned with unsupervised methods, this approach combines a denoising auto-encoder objective with a back-translation objective, both in two translation directions, with an adversarial objective that attempts to fool a discriminator that detects the source language of an encoded sentence. These five objectives together are sufficient to achieve impressive English <-> German and Engish <-> French results in Multi30k, a bilingual image caption scenario with short simple sentences, and to achieve a strong start for a standard WMT scenario.\n\nThis is very nice work, and I have very little to criticize. The approach is both technically interesting, and thorough in that it explores and combines a host of ideas that could work in this space (initial bilingual embeddings, back translation, auto-encoding, and adversarial techniques). And it is genuinely impressive to see all these pieces come together into something that translates substantially better than a word-to-word baseline. But the aspect I like most about this paper is the experimental analysis. Considering that this is a big, complicated system, it is crucial that the authors included both an ablation experiment to see which pieces were most important, and an experiment that indicates the amount of labeled data that would be required to achieve the same results with a supervised system.\n\nIn terms of specific criticisms:\n\nIn Equations (2), consider replacing C(y) with C(M(x)), or use compose notation, in order to make x-hat\'s relationship to x clear and self-contained within the equation.\n\nI am glad you take the time to give your model selection criterion it\'s own section in 3.2, as it does seem to be an important part of this puzzle. However, it would be nice to provide actual correlation statistics rather than an anecdotal illustration of correlation.\n\nIn the first paragraph of Section 4.5, I disagree with the sentence, ""Similar observations can be made for the other language pairs we considered."" In fact, I would go so far as to say that the English to French scenario described in that paragraph is a notable outlier, in that it is the other language pair where you beat the oracle re-ordering baseline in both Multi30k and WMT.\n\nWhen citing Shen et al., 2017, consider also mentioning the following:\n\nControllable Invariance through Adversarial Feature Learning; Qizhe Xie, Zihang Dai, Yulun Du, Eduard Hovy, Graham Neubig; NIPS 2017; https://arxiv.org/abs/1705.11122\n\nResponse read -- thanks.']","[50, -20, 80]","[70, 60, 70]","[""The sentiment score is 50 (slightly positive) because while the reviewer acknowledges the work as 'remarkable', they also express disappointment about the lack of detail and raise several questions and concerns. The overall tone is balanced between praise and critique. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the significance of the work, and frames criticisms as suggestions or questions rather than direct attacks. They also thank the authors for their response at the end, which adds to the politeness. The reviewer maintains a professional and constructive tone, even when pointing out areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting results, they express several concerns and requests for clarification. The reviewer points out omissions in the abstract, questions the noise model, and asks for additional experiments and comparisons. However, in the follow-up, the reviewer acknowledges the authors' efforts to address some comments, slightly improving their rating. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, making requests politely (e.g., 'I request', 'Can you please', 'I would like') and acknowledging the authors' efforts. The tone is professional and constructive, offering specific suggestions for improvement without being harsh or dismissive."", ""The sentiment score is 80 (positive) because the reviewer describes the work as 'very nice' and 'genuinely impressive', highlighting its technical interest and thoroughness. They also praise the experimental analysis. The few criticisms are minor and constructive. The politeness score is 70 (polite) due to the respectful tone throughout, use of phrases like 'I am glad you take the time', and the constructive nature of the feedback. The reviewer balances praise with specific, helpful suggestions for improvement, maintaining a professional and courteous tone throughout.""]"
"['This paper proposes NerveNet to represent and learn structured policy for continuous control tasks. Instead of using the widely adopted fully connected MLP, this paper uses Graph Neural Networks to learn a structured controller for various MuJoco environments. It shows that this structured controller can be easily transferred to different tasks or dramatically speed up the fine-tuning of transfer.\n\nThe idea to build structured policy is novel for continuous control tasks. It is an exciting direction since there are inherent structures that should be exploited in many control tasks, especially for locomotion. This paper explores this less-studied area and demonstrates promising results.\n\nThe presentation is mostly clear. Here are some questions and a list of minor suggestions:\n1) In the Output Model section, I am not sure how the controller is shared. It first says that ""Nodes with the same node type should share the instance of MLP"", which means all the ""joint"" nodes should share the same controller. But later it says ""Two LeftHip should have a shared controller."" What about RightHip? or Ankle? They all belongs to the same node type ""joint"". Am I missing something here? It seems that in this paper, weights sharing is an essential part of the structured policy, it would be great if it can be described in more details.\n\n2) In States Update of Propagation Model Section, it is not clear how the aggregated message is used in eq. (4).\n\n3) Typo in Caption of Table 1: CentipedeFour not CentipedeSix.\n\n4) If we just use MLP but share weights among joints (e.g. the weights from observation to action of all the LeftHips are constrained to be same), how would it compare to the method proposed in this paper?\n\nIn summary, I think that it is worthwhile to develop structured representation of policies for control tasks. It is analogue to use CNN that share weights between kernels for computer vision tasks. I believe that this paper could inspire many follow-up work. For this reason, I would recommend accepting this paper.', 'The submission proposes incorporation of additional structure into reinforcement learning problems. In particular, the structure of the agent\'s morphology. The policy is represented as a graph neural network over the agent\'s morphology graph and message passing is used to update individual actions per joint.\n\nThe exposition is fairly clear and the method is well-motivated. I see no issues with the mathematical correctness of the claims made in the paper. However, the paper could benefit from being shorter by moving some details to the appendix (such as much of section 2.1 and PPO description).\n\nRelated work section could consider the following papers:\n\n""Discrete Sequential Prediction of Continuous Actions for Deep RL""\nAnother approach that outputs actions per joint, although in a general manner that does not require morphology structure\n\n""Generalized Biped Walking Control""\nConsiders the task of interactively changing limb lengths (your size transfer task) in a zero-shot manner, albeit with a non-neural network controller\n\nThe experimental results investigate the effects of various algorithm parameters, which is appreciated. However, a wider range of experiments would have been helpful to judge the usefulness of the proposed policy representation. In addition to robustness to limb length and disability perturbations, it would have been very nice to see multi-task learning that takes advantage of body structure (such as learning to reach for target with arms while walking with legs and being able to learn those independently, for example).\n\nHowever, I do think using agent morphology is an under-explored idea and one that is general, since we tend to have access to this structure in continuous control tasks for the time being. As a result, I believe this submission would be of interest to ICLR community.', 'The authors present an interesting application of Graph Neural Networks to learning policies for controlling ""centipede"" robots of different lengths. They leverage the non-parametric nature of graph neural networks to show that their approach is capable of transferring policies to different robots more quickly than other approaches. The significance of this work is in its application of GNNs to a potentially practical problem in the robotics domain. The paper suffers from some clarity/presentation issues that will need to be improved. Ultimately, the contribution of this paper is rather specific, yet the authors show the clear advantage of their technique for improved performance and transfer learning on some agent types within this domain.\n\nSome comments:\n- Significant: A brief statement of the paper\'s ""contributions"" is also needed; it is unclear at first glance what portions of the work are the authors\' own contributions versus prior work, particularly in the section describing the GNN theory.\n- Abstract: I take issue with the phrase ""are significantly better than policies learned by other models"", since this is not universally true. While there is a clear benefit to their technique for the centipede and snake models, the performance on the other agents is mostly comparable, rather than ""significantly better""; this should be reflected in the abstract.\n- Figure 1 is instructive, but another figure is needed to better illustrate the algorithm (including how the state of the world is mapped to the graph state h, how these ""message"" are passed between nodes, and how the final graph states are used to develop a policy). This would greatly help clarity, particularly for those who have not seen GNNs before, and would make the paper more self-contained and easier to follow. The figure could also include some annotated examples of the input spaces of the different joints, etc. Relatedly, Sec. 2.2.2 is rather difficult to follow because of the lack of a figure or concrete example (an example might help the reader understand the procedure without having to develop an intuition for GNNs).\n- There is almost certainly a typo in Eq. (4), since it does not contain the aggregated message \\bar{m}_u^t.\n\nSmaller issues / typos:\n- Abstract: please spell out spell out multi-layer perceptrons (MLP).\n- Sec 2.2: ""servers"" should be ""serves""\n- ""performance By"" on page 4 is missing a "".""\n\nPros:\n- The paper presents an interesting application of GNNs to the space of reinforcement learning and clearly show the benefits of their approach for the specific task of transfer learning.\n- To the best of my knowledge, the paper presents an original result and presents a good-faith effort to compare to existing, alternative systems (showing that they outperform on the tasks of interest).\n\nCons:\n- The contributions of the paper should be more clearly stated (see comment above).\n- The section describing their approach is not ""self contained"" and is difficult for an unlearned reader to follow.\n- The problem the authors have chosen to tackle is perhaps a bit ""specific"", since the performance of their approach is only really shown to exceed the performance on agents, like centipedes or snakes, which have this ""modular"" quality.\n\nI certainly hope the authors improve the quality of the theory section; the poor presentation here brings down the rest of the paper, which is otherwise an easy read.']","[80, 60, 50]","[70, 70, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses enthusiasm for the paper's novel approach, calling it an 'exciting direction' and stating that it 'demonstrates promising results.' The reviewer also recommends accepting the paper, indicating a strong positive sentiment. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions. They phrase their questions and recommendations politely, using phrases like 'I am not sure' and 'It would be great if.' The reviewer also acknowledges the potential impact of the paper, which is a polite way to recognize the authors' work. While the review is generally positive and polite, it's not at the maximum of either scale as it does include some critiques and areas for improvement."", ""The sentiment score is 60 (positive) because the reviewer expresses overall positive sentiment towards the paper. They note that the exposition is clear, the method is well-motivated, and they believe the submission would be of interest to the ICLR community. However, they also suggest some improvements, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and offers constructive criticism. They use phrases like 'I see no issues with...', 'The experimental results... is appreciated', and 'I do think... is an under-explored idea', which contribute to a polite tone. The reviewer also provides specific suggestions for improvement without being harsh or dismissive."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'interesting' and notes clear advantages of the technique, but also points out several issues and areas for improvement. The review is balanced, highlighting both pros and cons. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and expresses hope for improvement. The reviewer's tone is professional and helpful, providing specific suggestions without being harsh or dismissive.""]"
"['This paper proposes the idea of having an agent learning a policy that resets the agent\'s state to one of the states drawn from the distribution of starting states. The agent learns such policy while also learning how to solve the actual task. This approach generates more autonomous agents that require fewer human interventions in the learning process. This is a very elegant and general idea, where the value function learned in the reset task also encodes some measure of safety in the environment.\n\nAll that being said, I gave this paper a score of 6 because two aspects that seem fundamental to me are not clear in the paper. If clarified, I\'d happily increase my score.\n\n1) *Defining state visitation/equality in the function approximation setting:* The main idea behind the proposed algorithm is to ensure that ""when the reset policy is executed from any state, the distribution over final states matches the initial state distribution p_0"". This is formally described, for example, in line 13 of Algorithm 1.\nThe authors ""define a set of safe states S_{reset} \\subseteq S, and say that we are in an irreversible state if the set of states visited by the reset policy over the past N episodes is disjoint from S_{reset}."" However, it is not clear to me how one can uniquely identify a state in the function approximation case. Obviously, it is straightforward to apply such definition in the tabular case, where counting state visitation is easy. However, how do we count state visitation in continuous domains? Did the authors manually define the range of each joint/torque/angle that characterizes the start state? In a control task from pixels, for example, would the exact configuration of pixels seen at the beginning be the start state? Defining state visitation in the function approximation setting is not trivial and it seems to me the authors just glossed over it, despite being essential to your work.\n\n2) *Experimental design for Figure 5*: This setup is not clear to me at all and in fact, my first reaction is to say it is wrong. An episodic task is generally defined as: the agent starts in a state drawn from the distribution of starting states and at the moment it reaches the goal state, the task is reset and the agent starts again. It doesn\'t seem to be what the authors did, is that right? The sentence: ""our method learns to solve this task by automatically resetting the environment after each episode, so the forward policy can practice catching the ball when initialized below the cup"" is confusion. When is the task reset to the ""status quo"" approach? Also, let\'s say an agent takes 50 time steps to reach the goal and then it decides to do a soft-reset. Are the time steps it is spending on its soft-reset being taken into account when generating the reported results?\n\n\nSome other minor points are:\n\n- The authors should standardize their use of citations in the paper. Sometimes there are way too many parentheses in a reference. For example: ""manual resets are necessary when the robot or environment breaks (e.g. Gandhi et al. (2017))"", or ""Our methods can also be used directly with any other Q-learning methods ((Watkins & Dayan, 1992; Mnih et al., 2013; Gu et al., 2017; Amos et al., 2016; Metz et al., 2017))""\n\n- There is a whole line of work in safe RL that is not acknowledged in the related work section. Representative papers are:\n    [1] Philip S. Thomas, Georgios Theocharous, Mohammad Ghavamzadeh: High-Confidence Off-Policy Evaluation. AAAI 2015: 3000-3006\n    [2] Philip S. Thomas, Georgios Theocharous, Mohammad Ghavamzadeh: High Confidence Policy Improvement. ICML 2015: 2380-2388\n\n- In the Preliminaries Section the next state is said to be drawn from s_{t+1} ~ P(s\'| s, a). However, this hides the fact the next state is dependent on the environment dynamics and on the policy being followed. I think it would be clearer if written: s_{t+1} ~ P(s\'| s, \\pi(a|s)).\n\n- It seems to me that, in Algorithm 1, the name \'Act\' is misleading. Shouldn\'t it be \'ChooseAction\' or \'EpsilonGreedy\'? If I understand correctly, the function \'Act\' just returns the action to be executed, while the function \'Step\' is the one that actually executes the action.\n\n- It is absolutely essential to depict the confidence intervals in the plots in Figure 3. Ideally we should have confidence intervals in all the plots in the paper.', 'If one is committed to doing value-function or policy-based RL for an episodic task on a real physical system, then one has to come up with a way of resetting the domain for new trials.  This paper proposes a good way of doing this:  learn a policy for resetting at the same time as learning a policy for solving the problem.  As a side effect, the Q values associated with the reset policy can be used to predict when the system is about to enter an unrecoverable state and ""forbid"" the action.\n\nIt is, of course, necessary that the domain be, in fact, reversible  (or, at least, that it be possible to reach a starting state from at least one goal state--and it\'s better if that goal state is not significantly harder to reach than other goal states.\n\nThere were a couple of places in the paper that seemed to be to be not strictly technically correct.\n\nIt says that the reset policy is designed to achieve a distribution of final states that is equivalent to a starting distribution on the problem.  This is technically fairly difficult, as a problem, and I don\'t think it can be achieved through standard RL methods.   Later, it is clearer that there is a set of possible start states and they are all treated as goal states from the perspective of the reset policy.   That is a start set, not a distribution.  And, there\'s no particular reason to think that the reset policy will not, for example, always end up returning to a particular state.\n\nAnother point is that training a set of Q functions from different starting states generates some kind of an ensemble, but I don\'t think you can guarantee much about what sort of a distribution on values it will really represent.   Q learning + function approximation can go wrong in a variety of ways, and so some of these values might be really gross over or under estimates of what can be achieved even by the policies associated with those values. \n\nA final, higher-level, methodological concern is that, it seems to me, as the domains become more complex, rather than trying to learn two (or more) policies, it might be more effective to take a model-based approach, learn one model, and do reasoning to decide how to return home (and even to select from a distribution of start states) and/or to decide if a step is likely to remove the robot from the ""resettable"" space.\n\nAll this aside, this seems like a fairly small but well considered and executed piece of work.  I\'m rating it as marginally above threshold, but I indeed find it very close to the threshold.', '(This delayed review is based on the deadline version of the paper.)\n\nThis paper proposes to learn by RL a reset policy at the same time that we learn the forward policy, and use the learned reset Q-function to predict and avoid actions that would prevent reset — an indication that they are ""unsafe"" in some sense.\n\nThis idea (both parts) is interesting and potentially very useful, particularly in physical domains where reset is expensive and exploration is risky. While I\'m sure the community can benefit from ideas of this kind, it really needs clearer presentations of such ideas. I can appreciate the very intuitive and colloquial style of the paper, however the discussion of the core idea would benefit from some rigor and formal definitions.\n\nExamples of intuitive language that could be hiding the necessary complexities of a more formal treatment:\n\n1. In the penultimate paragraph of Section 1, actions are described as ""reversible"", while a stochastic environment may be lacking such a notion altogether (i.e. there\'s no clear inverse if state transitions are not deterministic functions).\n\n2. It\'s not clear whether the authors suggest that the ability to reset is a good notion of safety, or just a proxy to such a notion. This should be made more explicit, making it clearer what this proxy misses: states where the learned reset policy fails (whether due to limited controllability or errors in the policy), that are nonetheless safe.\n\n3. In the last paragraph of Section 3, a reset policy is defined as reaching p_0 from *any* state. This is a very strong requirement, which isn\'t even satisfiable in most domains, and indeed the reset policies learned in the rest of the paper don\'t satisfy it.\n\n4. What are p_0 and r_r in the experiments? What is the relation between S_{reset} and p_0? Is there a discount factor?\n\n5. In the first paragraph of Section 4.1, states are described as ""irreversible"" or ""irrecoverable"". Again, in a stochastic environment a more nuanced notion is needed, as there may be policies that take a long time to reset from some states, but do so eventually.\n\n6. A definition of a ""hard"" reset would make the paper clearer.\n\n7. After (1), states are described as ""allowed"". Again, preventing actions that are likely to hinder reset cannot completely prevent any given state in a stochastic environment. It also seems that (2) describes states where some allowed action can be taken, rather than states reachable by some allowed action. For both reasons, Algorithm 1 does not prevent reaching states outside S*, so what is the point of that definition?\n\n8. The paper is not explicit about the learning dynamics of the reset policy. It should include a figure showing the learning curve of this policy (or some other visualization), and explain how the reset policy can ever gain experience and learn to reset from states that it initially avoids as unsafe.\n\n9. Algorithm 1 is unclear on how a failed reset is identified, and what happens in such case — do we run another forward episode? Another reset episode?', 'The paper solves the problem of how to do autonomous resets, which is an important problem in real world RL. The method is novel, the explanation is clear, and has good experimental results.\n \nPros:\n1. The approach is simple, solves a task of practical importance, and performs well in the experiments. \n2. The experimental section performs good ablation studies wrt fewer reset thresholds, reset attempts, use of ensembles.\n\nCons:\n1. The method is evaluated only for 3 tasks, which are all in simulation, and on no real world tasks. Additional tasks could be useful, especially for qualitative analysis of the learned reset policies.\n2. It seems that while the method does reduce hard resets, it would be more convincing if it can solve tasks which a model without a reset policy couldnt. Right now, the methods without the reset policy perform about equally well on final reward.\n3. The method wont be applicable to RL environments where we will need to take multiple non-invertible actions to achieve the goal (an analogy would be multiple levels in a game). In such situations, one might want to use the reset policy to go back to intermediate “start” states from where we can continue again, rather than the original start state always.\n\nConclusion/Significance: The approach is a step in the right direction, and further refinements can make it a significant contribution to robotics work.\n\nRevision: Thanks to the authors for addressing the issues I raised, I revise my review to 7']","[-20, 20, -20, 70]","[60, 60, 60, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's 'very elegant and general idea', they express significant concerns about two fundamental aspects of the work. The reviewer states they gave the paper a score of 6 (out of 10, presumably) and would 'happily increase' it if these issues were clarified, indicating a generally positive view tempered by important criticisms. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms, and frames their concerns as requests for clarification rather than outright dismissals. They use phrases like 'If clarified, I'd happily increase my score' and 'it is not clear to me', which maintain a constructive tone. The reviewer also provides detailed feedback and suggestions for improvement, which is a polite and helpful approach in academic review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's good proposal and considers it a 'well considered and executed piece of work.' However, they also raise several technical concerns and rate it as only 'marginally above threshold,' which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's merits while constructively pointing out areas for improvement. They avoid harsh criticism and use phrases like 'seemed to be not strictly technically correct' instead of more direct accusations of error. The reviewer also balances critique with praise, ending on a positive note despite their reservations."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea as 'interesting and potentially very useful', they express significant concerns about the clarity and rigor of the presentation. The reviewer lists numerous points that need improvement or clarification, indicating that the paper requires substantial revision. However, the score is not deeply negative because the reviewer sees potential value in the work.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful language throughout. They begin by acknowledging the potential value of the work and use phrases like 'I can appreciate' and 'would benefit from' rather than harsh criticisms. The reviewer provides constructive feedback and specific examples of areas that need improvement, which is helpful and considerate. The tone is professional and focused on improving the paper rather than attacking the authors."", ""The sentiment score is 70 (positive) because the reviewer starts with a positive overall assessment, highlighting the paper's novelty, clarity, and good experimental results. They list more pros than cons and conclude that the approach is 'a step in the right direction'. The final revision also increases their rating, further indicating a positive sentiment. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement rather than harsh critiques. The use of phrases like 'Thanks to the authors' in the revision also contributes to the polite tone.""]"
"['** UPDATE ** upgraded my score to 7 based on the new version of the paper.\n\nThe main contribution of this paper is to introduce a new recurrent neural network for language modeling, which incorporates a tree structure More precisely, the model learns constituency trees (without any supervision), to capture syntactic information. This information is then used to define skip connections in the language model, to capture longer dependencies between words. The update of the hidden state does not depend only on the previous hidden state, but also on the hidden states corresponding to the following words: all the previous words belonging to the smallest subtree containing the current word, such that the current word is not the left-most one. The authors propose to parametrize trees using ""syntactic distances"" between adjacent words (a scalar value for each pair of adjacent words w_t, w_{t+1}). Given these distances, it is possible to obtain the constituents and the corresponding gating activations for the skip connections. These different operations can be relaxed to differentiable operations, so that stochastic gradient descent can be used to learn the parameters. The model is evaluated on three language modeling benchmarks: character level PTB, word level PTB and word level text8. The induced constituency trees are also evaluated, for sentence of length 10 or less (which is the standard setting for unsupervised parsing).\n\nOverall, I really like the main idea of the paper. The use of ""syntactic distances"" to parametrize the trees is clever, as they can easily be computed using only partial information up to time t. From these distances, it is also relatively straightforward to obtain which constituents (or subtrees) a word belongs to (and thus, the corresponding gating activations). Moreover, the operations can easily be relaxed to obtain a differentiable model, which can easily be trained using stochastic gradient descent.\n\nThe results reported on the language modeling experiments are strong. One minor comment here is that it would be nice to have an ablation analysis, as it is possible to obtain similarly strong results with simpler models (such as plain LSTM).\n\nMy main concern regarding the paper is that it is a bit hard to understand. In particular in section 4, the authors alternates between discrete and relaxed values: end of section 4.1, it is implied that alpha are in [0, 1], but in equation 6, alpha are in {0, 1}, then relaxed in equation 9 to [0, 1] again. I am also wondering whether it would make more sense to start by introducing the syntactic distances, then the alphas and finally the gates? I also found the section 5 to be quite confusing. While I get the\tgeneral idea, I am not sure what is the relation between hidden states h and m (section 5.1). Is there a mixup between h defined in equation 10 and h from section 5.1? I am aware that it is not straightforward to describe the proposed method, but believe it would be a much stronger paper if written more clearly.\n\nTo conclude, I really like the method proposed in this paper, and believe that the experimental results are quite strong.\nMy main concern\tregarding the paper is its clarity: I will gladly increase my score if the authors can improve the writing.', 'Summary: the paper proposes a novel method to leverage tree structures in an unsupervised learning manner. The key idea is to make use of “syntactic distance” to identify phrases, thus building up a tree for input sentence. The proposed model achieves SOTA on a char-level language modeling task and is demonstrated to yield reasonable tree structures.\n\nComment: I like the paper a lot. The idea is very creative and interesting. The paper is well written.\n\nBesides the official comment that the authors already replied, I have some more:\n- I was still wondering how to compute the left hand side of eq 3 by marginalizing over all possible unfinished structures so far. (Of course, what the authors do is showed to be a fast and good approximation.)\n- Using CNN to compute d has a disadvantage that the range of look-back must be predefined. Looking at fig 3, in order to make sure that d6 is smaller than d2, the look-back should have a wide coverage so that the computation for d6 has some knowledge about d2 (in some cases the local information can help to avoid it, but not always). I therefore think that using an RNN is more suitable than using a CNN.\n- Is it possible to extend this framework to dependency structure?\n- It would be great if the authors show whether the model can leverage given tree structures (like SPINN) (for instance we can do a multitask learning where a task is parsing given a treebank to train)\n', ""The paper proposes Parsing-Reading-Predict Networks (PRPN), a new model jointly learns syntax and lexicon. The main idea of this model is to add skip-connections to integrate syntax relationships into the context of predicting the next word (i.e. language modeling task).\n\nTo model this, the authors introduce hidden variable l_t, which break down to the decisions of a soft version of gate variable values in the previous possible positions. These variables are then parameterized using syntactic distance to ensure that the final structure inferred by the model has no overlapping ranges so that it will be a valid syntax tree.\n\nI think the paper is in general clearly written. The model is interesting and the experiment section is quite solid. The model reaches state-of-the-art level performance in language modeling and the performance on unsupervised parsing task (which is a by-product of the model) is also quite promising.\n\nMy main question is that the motivation/intuition of introducing the syntactic distance variable. I understand that they basically make sure the tree is valid, but the paper did not explain too much about what's the intuition behind this or is there a good way to interpret this. What motivates these d variables?""]","[60, 90, 70]","[80, 80, 80]","[""The sentiment score is 60 (positive) because the reviewer expresses strong approval of the paper's main idea, calling it 'clever' and stating they 'really like' it. They also mention 'strong' experimental results. However, they have concerns about the paper's clarity, which prevents a higher score. The politeness score is 80 (quite polite) due to the reviewer's consistently respectful tone. They use phrases like 'I really like' and 'I believe', and offer constructive criticism in a gentle manner, such as 'it would be nice to have' and 'I will gladly increase my score if the authors can improve'. The reviewer balances praise with concerns, maintaining a professional and courteous tone throughout."", ""The sentiment score is 90 because the reviewer expresses very positive sentiments about the paper, stating 'I like the paper a lot' and describing the idea as 'very creative and interesting'. The paper is also praised for being 'well written'. The politeness score is 80 because the reviewer uses respectful and constructive language throughout. They offer additional comments and suggestions in a polite manner, using phrases like 'I was still wondering' and 'It would be great if'. The reviewer also acknowledges the authors' previous responses to official comments. The tone is professional and courteous, without any harsh criticism or demanding language."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper. They state that the paper is 'clearly written', the model is 'interesting', and the experiment section is 'quite solid'. The reviewer also notes that the model achieves state-of-the-art performance and shows promising results. The only slight criticism is a question about the motivation behind certain aspects of the model, which prevents a higher score. The politeness score is 80 (polite) because the reviewer uses respectful and professional language throughout. They offer praise where due and frame their question as a request for clarification rather than a criticism. Phrases like 'I think' and 'My main question is' contribute to a polite tone. The reviewer maintains a constructive approach, even when raising a point for improvement.""]"
"['This paper studies the adjustment of dropout rates which is a useful tool to prevent the overfitting of deep neural networks. The authors derive a generalization error bound in terms of dropout rates. Based on this, the authors propose a regularization framework to adaptively select dropout rates. Experimental results are also given to verify the theory.\n\nMajor comments:\n(1) The Empirical Rademacher complexity is not defined. For completeness, it would be better to define it at least in the appendix.\n(2) I can not follow the inequality (5). Especially, according to the main text, f^L is a vector-valued function . Therefore, it is not clear to me the meaning of \\sum\\sigma_if^L(x_i,w) in (5).\n(3) I can also not see clearly the third equality in (9). Note that f^l is a vector-valued function. It is not clear to me how it is related to a summation over j there.\n(4) There is a linear dependency on the number of classes in Theorem 3.1. Is it possible to further improve this dependency?\n\nMinor comments:\n(1) Section 4: 1e-3,1e-4,1e-5 is not consistent with 1e^{-3}, 1e^{-4},1e^{-5}\n(2) Abstract: there should be a space before ""Experiments"".\n(3) It would be better to give more details (e.g., page, section) in citing a book in the proof of Theorem 3.1\n\nSummary:\nThe mathematical analysis in the present version is not rigorous. The authors should improve the mathematical analysis.\n\n----------------------------\nAfter Rebuttal:\nThank you for revising the paper. I think there are still some possible problems. \nLet us consider eq (12) in the appendix on the contraction property of Rademacher complexity (RC).\n(1) Since you consider a variant of RC with absolute value inside the supermum, to my best knowledge, the contraction property (12) should involve an additional factor of 2, see, e.g., Theorem 12 of ""Rademacher and Gaussian Complexities: Risk Bounds and Structural Results"" by Bartlett and Mendelson. Since you need to apply this contraction property L times, there should be a factor of 2^L in the error bound. This make the bound not appealing for neural networks with a moderate L.\n(2) Second, the function g involves an expectation w.r.t. r before the activation function. I am not sure whether this existence of expectation w.r.t. r would make the contraction property applicable in this case.', 'An important contribution. The paper is well written. Some questions that needs to be better answered are listed here.\n1. The theorem is difficult to decipher. Some remarks needs to be included explaining the terms on the right and what they mean with respect to learnability or complexity. \n2. How does the regularization term in eq (2) relate to the existing (currently used) norm based regularizers in deep network learning? It may be straight forward but some small simulation/plots explaining this is important. \n3. Apart from the accuracy results, the change in computational time for working with eq (2), rather than using existing state-of-the-art deep network optimization needs to be reported? How does this change vary with respect to dataset and network size (beyond the description of scaled regularization in section 4)?\n4. Confidence intervals needs to be computed for the retain-rates (reported as a function of epoch). This is critical both to evaluate the stability of regularizers as well as whether the bound from theorem is strong. \n5. Did the evaluations show some patterns on the retain rates across different layers? It seems from Figure 3,4 that retain rates in lower layers are more closer to 1 and they decrease to 0.5 as depth increases. Is this a general pattern? \n6. It has been long known that dropout relates to non-negative weighted averaging of partially learned neural networks and dropout rate of 0.5 provides best dymanics. The evaluations say that clearly 0.5 for all units/layers us not correct. What does this mean in terms of network architecture? Is it that some layers are easy to average (nothing is learned there, so dropped networks have small variance), while some other layers are sensitive? \n7. What are some simple guidelines for choosing the values of p and q? Again it appears p=q=2 is the best, but need confidence intervals here to say anything substantial. ', '==Main comments\n\nThe authors connect dropout parameters to a bound of the Rademacher complexity (Rad) of the network. While it is great to see deep learning techniques inspired by learning theory, I think the paper makes too many leaps and the Rad story is ultimately unconvincing.  Perhaps it is better to start with the resulting regularizer, and the interesting direct optimization of dropout parameters. In its current form, the following leaps problematic and were not addressed in the paper:\n\n1) Why is is adding Rad as a regularizer reasonable? Rad is usually hard to compute, and most useful for bounding the generalization error. It would be interesting if it also turns out to be a good regularizer, but the authors do not say why nor cite anything. Like the VC dimension, Rad itself depends on the model class, and cannot be directly optimized. Even if you can somehow optimize over the model class, these quantities give very loose bounds, and do not equal to generalization error. For example, I feel even just adding the actual generalization error bound is more natural. Would it make sense to just add Rad to the objective in this way for a linear model?\n\n2) Why is it reasonable to go from a regularizer based on RC to a loose bound of Rad? The actual resulting regularizer turns out to be a weight penalty but this seems to be a rather loose bound that might not have too much to do with Rad anymore. There should be some analysis on how loose this bound is, and if this looseness matter at all. \n\nThe empirical results themselves seem reasonable, but the results are not actually better than simpler methods in the corresponding tasks, the interpretation is less confident. Afterall, it seems that the proposed method had several parameters that were turned, where the analogous parameters are not present in the competing methods. And the per unit dropout rates are themselves additional parameters, but are they actually good use of parameters?\n\n==Minor comments\n\nThe optimization is perhaps also not quite right, since this requires taking the gradient of the dropout parameter in the original objective. While the authors point out that one can use the mean, but that is more problematic for the gradient than for normal forward predictions. The gradient used for regular learning is not based on the mean prediction, but rather the samples.\n\ntiny columns surrounding figures are ugly and hard to read\n']","[-50, 60, -60]","[20, 70, 20]","[""The sentiment score is -50 because while the reviewer acknowledges the paper's contribution ('useful tool', 'propose a regularization framework'), they express significant concerns about the mathematical rigor ('mathematical analysis is not rigorous', 'I can not follow', 'not clear to me'). Even after revisions, the reviewer still points out 'possible problems'. The politeness score is 20 because the reviewer uses polite language ('Thank you for revising', 'It would be better to'), asks questions instead of making accusations, and provides specific suggestions for improvement. However, the criticism is direct and the tone is not overly warm, keeping the score from being higher."", ""The sentiment score is 60 (positive) because the review starts with 'An important contribution. The paper is well written.' This indicates a generally positive view of the paper. However, it's not extremely high as the reviewer follows up with several questions and suggestions for improvement, indicating there's room for enhancement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing their comments as questions or suggestions rather than criticisms. Phrases like 'needs to be better answered' and 'it may be straightforward but...' show consideration for the authors. The reviewer also uses neutral, professional language without any harsh or rude expressions. The score isn't higher because while polite, it doesn't go out of its way to be exceptionally courteous."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's approach and methodology. They use phrases like 'makes too many leaps', 'unconvincing', and 'problematic', indicating a largely negative view of the work. However, they do acknowledge some positive aspects ('great to see deep learning techniques inspired by learning theory' and 'empirical results themselves seem reasonable'), which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They use phrases like 'I think' and 'Perhaps it is better to' which soften their criticisms. They also provide specific, detailed feedback which is helpful to the authors. The language is not overtly polite, but it avoids rudeness and maintains a respectful tone, hence a slightly positive score.""]"
"['This paper tackles two problems common in genome-wide association studies: confounding (i.e. structured noise) due to population structure and the potential presence of non-linear interactions between different parts of the genome. To solve the first problem this paper effectively suggests learning the latent confounders jointly with the rest of the model. For the second problem, this paper proposes “implicit causal models’, that is, models that  leverage neural architectures with an implicit density. \n\nThe main contribution of this paper is to create a bridge between the statistical genetics community and the ML community. The method is technically sound and does indeed generalize techniques currently used in statistical genetics. The main concerns with this paper is that 1) the claim that it can detect epistatic interactions is not really supported. Yes, in principle the neural model used to model y could detect them, but no experiments are shown to really tease this case apart 2) validating GWAS results is really hard, because no causal information is usually available. The authors did a great job on the simulation framework, but table 1 falls short in terms of evaluation metric: to properly assess the performance of the method on simulated data, it would be good to have evidence that the type 1 error is calibrated (e.g. by means of qq plots vs null distribution) for all methods. At the very least, a ROC curve could be used to show the quality of the ranking of the causal SNPs for each method, irrespective of p-value cutoff.\n\nQuality: see above. The technical parts of this paper are definitely high-quality, the experimental side could be improved.\nClarity: if the target audience of this paper is the probabilistic ML community, it’s very clear. If the statistical genetics community is expected to read this, section 3.1 could result too difficult to parse. As an aside: ICLR might be the right venue for this paper given the high ML content, but perhaps a bioinformatics journal would be a better fit, depending on intended audience.\n', 'The paper presents a non-linear generative model for GWAS that models population structure.\nNon-linearities are modeled using neural networks as non-linear function approximators and inference is performed using likelihood-free variational inference.\nThe paper is overall well-written and makes new and non-trivial contributions to model inference and the application.\nStated contributions are that the model captures causal relationships, models highly non-linear interactions between causes and accounts for confounders. However, not all claims are well-supported by the data provided in the paper. \nEspecially, the aspect of causality does not seem to be considered in the application beyond a simple dependence test between SNPs and phenotypes.\n\nThe paper also suffers from unconvincing experimental validation:\n- The evaluation metric for simulations based on precision is not meaningful without reporting the recall at the same time.\n\n- The details on how significance in each experiment has been determined are not sufficient.\nFrom the description in D.3 the p-value a p-value threshold of 0.0025 has been applied. Has this threshold been used for all methods?\nThe description in D.3 seems to describe a posterior probability of the weight being zero, instead of a Frequentist p-value, which would be the probability of estimating a parameter at least as large on a data set that had been generated with a 0-weight.\n\n- Genomic control is applied in the real world experiment but not on the simulations. Genomic control changes the acceptance threshold of each method in a different way. Both precision and recall depend on this acceptance threshold. Genomic control is a heuristic that adjusts for being too anti-conservative, but also for being too conservative, making it hard to judge the performance of each method on its own. Consequently, the paper should provide additional detail on the results and should contrast the performance of the method without the use of genomic control.\n\nminor:\n\nThe authors claim to model nonlinear, learnable gene-gene and gene-population interactions.\nWhile neural networks may approximate highly non-linear functions, it still  seems as if the confounders are modeled largely as linear. This is indicated by the fact that the authors report performance gains from adding the confounders as input to the final layer.\n\nThe two step approach to confounder correction is compared to PCA and LMMs, which are stated to first estimate confounders and then use them for testing.\nFor LMMs this is not really true, as LMMs treat the confounder as a latent variable throughout and only estimate the induced covariance.\n', 'In this paper, the authors propose to use the so-called implicit model to tackle Genome-Wide Association problem. The model can be viewed as a variant of Structural Equation Model. Overal the paper is interesting and relatively well-written but some important details are missing and way more experiments need to be done to show the effectiveness of the approach.\n\n*  How do the authors call a variant to be associated with the phenotype (y)? More specifically, what is the distribution of the null hypothesis? Section D.3 in the appendix does not explain the hypothesis testing part well. This method models $x$ (genetic), $y$ (phenotype), and $z$ (confounder) but does not have a latent variable for the association. For example, there is no latent indicator variable (e.g., Spike-Slab models [1]) for each variant.  Did they do hypothesis testing separately after they fit the model? If so, this has double dipping problem because the data is used once to fit the model and again to perform statistical inference. \n\n* In GWAS, a method resulting in high power with control of FP is favored. In traditional univariate GWAS, the false positive rate is controlled by genome-wide significant level (7e-8), Bonferroni correction or other FP control approaches.  Why Table 1 does not report FP? I need Table 1 to report the following: What is the power of this method if FPR is controlled(False Positive Rate < 0.05)? Also, the ROC curve for FPR<0.05 should be reported for all methods. \n\n* I believe that authors did a good job in term of a survey of the available models for GWA from marginal regression to mixed effect model, etc. The authors account for typical confounders such as cryptic relatedness which I liked. However, I recommend the authors to be cautious calling the association detected by their method "" a Causal Association."" There are tons of research done to understand the causal effect of the genetic variants and this paper (and this venue) is not addressing those.  There are several ways for an associated variant to be non-causal and this paper does not even scratch the surface of that. For example, in many studies, discovering the causal SNPs means finding a genetic variant among the SNPs in LD of each other (so-called fine mapping). The LD-pruning procedure proposed in this paper does not help for that purpose. \n\n* This approach jointly models the genetic variants and the phenotype (y). Let us assume that one can directly maximize the ML (ELBO maximizes a lower bound of ML). The objective function is disproportionally influenced by the genetic variants (x) than y because M is very large (  $\\prod_{m=1}^M p(w) p(x|z,w,\\phi)   >>   p(z) p(y|x,z,\\theta) $  ). Effectively, the model focuses on the genetic variants, not by the disease. This is why multi-variate GWAS focuses on the conditional p(y|x,z) and not p(y,x,z). Nothing was shown in the paper that this focusing on p(y,x,z) is advantageous to p(y|x,z). \n\n* In this paper, the authors use deep neural networks to model the general functional causal models. Since estimation of the causal effects is generally unidentifiable (Sprites 1993), I think using a general functional causal model with confounder modeling would have a larger chance to weaken the causal effects because the confounder part can also explain part of the causal influences. Is there a theoretical guarantee for the proposed method? Practically, how did the authors control the model complexity to avoid trivial solutions?\n\nMinor\n-------\n* The idea of representing (conditional) densities by neural networks was proposed in the generative adversarial networks (GAN). In this paper, the authors represent the functional causal models by neural networks, which is very related to the representation used in GANs. The only difference is that GAN does not specify a causal interpretation. I suggest the authors add a short discussion of the relations to GAN.\n\n* Previous methods on causal discovery rely on restricted functional causal models for identifiability results. They also use Gaussian process or multi-layer perceptron to model the functions implicitly, which can be consider as neural networks with one hidden layer. The sentence “These models typically focus on the task of causal discovery, and they assume fixed nonlinearities or smoothness which we relax using neural networks.” in the related work section is not appropriate. \n\n[1] Scalable Variational Inference for Bayesian Variable Selection in Regression, and Its Accuracy in Genetic Association Studies']","[50, -20, -20]","[80, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's technical soundness and its contribution in bridging two communities, while also pointing out areas for improvement. The review begins with positive aspects before addressing concerns, indicating a balanced but generally favorable view. The politeness score is 80 (quite polite) due to the reviewer's constructive tone, use of phrases like 'great job' and 'high-quality', and the way concerns are presented as suggestions rather than criticisms. The reviewer maintains a professional and respectful tone throughout, offering specific recommendations for improvement without being harsh or dismissive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions and good writing, they express several significant concerns about the experimental validation and unsupported claims. The review starts positively but then shifts to a more critical tone, highlighting multiple issues with the methodology and results presentation. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms, avoiding harsh or personal comments. The reviewer acknowledges the paper's strengths before presenting their concerns, which is a polite approach. The use of phrases like 'The paper also suffers from...' and 'The authors claim...' are direct but not impolite. Overall, the review balances constructive criticism with recognition of the paper's merits in a professionally courteous manner."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper 'interesting and relatively well-written', they also point out several significant issues and state that 'way more experiments need to be done'. The overall tone suggests the paper needs substantial revisions. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges positive aspects, and phrases criticisms as suggestions or questions rather than direct attacks. They use phrases like 'I recommend', 'I believe authors did a good job', and ask clarifying questions, which maintains a constructive tone despite the criticisms.""]"
"['This paper proposes the use of optimistic mirror descent to train Wasserstein Generative Adversarial Networks (WGANS). The authors remark that the current training of GANs, which amounts to solving a zero-sum game between a generator and discriminator, is often unstable, and they argue that one source of instability is due to limit cycles, which can occur for FTRL-based algorithms even in convex-concave zero-sum games. Motivated by recent results that use Optimistic Mirror Descent  (OMD) to achieve faster convergence rates (than standard gradient descent) in convex-concave zero-sum games and normal form games, they suggest using these techniques for WGAN training as well. The authors prove that, using OMD, the last iterate converges to an equilibrium and use this as motivation that OMD methods should be more stable for WGAN training. They then compare OMD against GD on both toy simulations and a DNA sequence task before finally introducing an adaptive generalization of OMD, Optimistic Adam, that they test on CIFAR10. \n\nThis paper is relatively well-written and clear, and the authors do a good job of introducing the problem of GAN training instability as well as the OMD algorithm, in particular highlighting its differences with standard gradient descent as well as discussing existing work that has applied it to zero-sum games. Given the recent work on OMD for zero-sum and normal form games, it is natural to study its effectiveness in training GANs.The issue of last iterate versus average iterate for non convex-concave problems is also presented well.  \n\nThe theoretical result on last-iterate convergence of OMD for bilinear games is interesting, but somewhat wanting as it does not provide an explicit convergence rate as in Rakhlin and Sridharan, 2013. Moreover, the result is only at best a motivation for using OMD in WGAN training since the WGAN optimization problem is not a bilinear game. \n\nThe experimental results seem to indicate that OMD is at least roughly competitive with GD-based methods, although they seem less compelling than the prior discussion in the paper would suggest. In particular, they are matched by SGD with momentum when evaluated by last epoch performance (albeit while being less sensitive to learning rates). OMD does seem to outperform SGD-based methods when using the lowest discriminator loss, but there doesn\'t seem to be even an attempt at explaining this in the paper. \n\nI found it a bit odd that Adam was not used as a point of comparison in Section 5, that optimistic Adam was only introduced and tested for CIFAR but not for the DNA sequence problem, and that the discriminator was trained for 5 iterations in Section 5 but only once in Section 6, despite the fact that the reasoning provided in Section 6 seems like it would have also applied for Section 5. This gives the impression that the experimental results might have been at least slightly ""gamed"". \n\nFor the reasons above, I give the paper high marks on clarity, and slightly above average marks on originality, significance, and quality.\n\nSpecific comments:\nPage 1, ""no-regret dynamics in zero-sum games can very often lead to limit cycles"": I don\'t think limit cycles are actually ever formally defined in the entire paper.  \nPage 3, ""standard results in game theory and no-regret learning"": These results should be either proven or cited.\nPage 3: Don\'t the parameter spaces need to be bounded for these convergence results to hold? \nPage 4, ""it is well known that GD is equivalent to the Follow-the-Regularized-Leader algorithm"": For completeness, this should probably either be (quickly) proven or a reference should be provided.\nPage 5, ""the unique equilibrium of the above game is...for the discriminator to choose w=0"": Why is w=0 necessary here?\nPage 6, ""We remark that the set of equilibrium solutions of this minimax problem are pairs (x,y) such that x is in the null space of A^T and y is in the null space of A"": Why is this true? This should either be proven or cited.\nPage 6, Initialization and Theorem 1: It would be good to discuss the necessity of this particular choice of initialization for the theoretical result. In the Initialization section, it appears simply to be out of convenience.\nPage 6, Theorem 1: It should be explicitly stated that this result doesn\'t provide a convergence rate, in contrast to the existing OMD results cited in the paper.   \nPage 7, ""we considered momentum, Nesterov momentum and AdaGrad"": Why isn\'t Adam used in this section if it is used in  later experiments?\nPage 7-8, ""When evaluated by....the lowest discriminator loss on the validation set, WGAN trained with Stochastic OMD (SOMD) achieved significantly lower KL divergence than the competing SGD variants."": Can you explain why SOMD outperforms the other methods when using the lowest discriminator loss on the validation set? None of the theoretical arguments presented earlier in the paper seem to even hint at this. The only result that one might expect from the earlier discussion and results is that SOMD would outperform the other methods when evaluating by the last epoch. However, this doesn\'t even really hold, since there exist learning rates in which SGD with momentum matches the performance of SOMD.\nPage 8, ""Evaluated by the last epoch, SOMD is much less sensitive to the choice of learning rate than the SGD variants"": Learning rate sensitivity doesn\'t seem to be touched upon in the earlier discussion. Can these results be explained by theory?\nPage 8, ""we see that optimistic Adam achieves high numbers of inception scores after very few epochs of training"": These results don\'t mean much without error bars.\nPage 8, ""we only trained the discriminator once after one iteration of generator training. The latter is inline with the intuition behind the use of optimism...."": Why didn\'t this logic apply to the previous section on DNA sequences, where the discriminator was trained multiple times?\n\n\nAfter reading the response of the authors (in particular their clarification of some technical results and the extra experiments they carried out during the rebuttal period), I have decided to upgrade my rating of the paper from a 6 to a 7. Just as a note, Figure 3b is now very difficult to read. \n\n', 'This paper proposes a simple modification of standard gradient descent -- called “Optimistic Mirror Descent” -- which is claimed to improve the convergence of GANs and other minimax optimization problems.  It includes experiments in toy settings which build intuition for the proposed algorithm, as well as in a practical GAN setting demonstrating the potential real-world benefits of the method.\n\n\nPros\n\nSection 3 directly compares the learning dynamics of GD vs. OMD for a WGAN in a simple toy setting, showing that the default GD algorithm oscillates around the optimum in the limit while OMD’s converges to the optimum.\n\nSection 4 demonstrates the convergence of OMD for a linear minimax optimization problem. (I did not thoroughly verify the proof’s correctness.)\n\nSection 6 proposes an OMD-like modification of Adam which achieves better results than standard Adam in a practical GAN setting (WGANs trained on CIFAR10) .\n\n\nCons/Suggestions\n\nThe paper could use a good deal of proofreading/revision for clarity and correctness. A couple examples from section 2:\n- “If the discriminator is very powerful and learns to accurately classify all samples, then the problem of the generator amounts to solving the Jensen-Shannon divergence between the true distribution and the generators distribution.” -> It would be clearer to say “minimizing” (rather than “solving”) the JS divergence. (“Solving” sounds more like what the discriminator does.)\n- “Wasserstein GANs (WGANs) Arjovsky et al. (2017), where the discriminator rather than being treated as a classifier is instead trying to simulate the Wasserstein−1 or earth-mover metric” -> Instead of “simulate”, “estimate” or “approximate” would be better word choices.  And although the standard GAN discriminator is a binary classifier, when optimized to convergence, it’s also estimating a divergence -- the JS divergence (or a shifted and scaled version of it).  Even though the previous paragraph mentions this, it feels a bit misleading to characterize WGANs as doing something fundamentally different.\n\nSec 2.1: There are several non-trivial but uncited mathematical claims hidden behind “well-known” or similar descriptors. These results could indeed be well-known in certain circles, but I’m not familiar with them, and I suspect most readers won’t be either. Please add citations. A few examples:\n- “If the loss function L(θ, w) ..., then standard results in game theory and no-regret learning imply that…”\n- “In particular, it is well known that GD is equivalent to the Follow-the-Regularized-Leader algorithm with an L2 regularizer...”\n- “It is known that if the learner knew in advance the gradient at the next iteration...” \n\nSection 4: vectors “b” and “c” are included in the objective written in (14), but are later dropped without explanation.  (The constant “d” is also dropped but clearly has no effect on the optimization.)\n\n\nOverall, the paper could use revision but the proposed approach is simple and seems to be theoretically well-motivated with solid analysis and benefits demonstrated in real-world settings.', 'The paper proposes to use optimistic gradient descent (OGD) for GAN training. Optimistic mirror descent is know to yield fast convergence for finding the optimum of zero-sum convex-concave games (when the players collaborate for fast computation), but earlier results concern the performance of the average iterate. This paper extends this result by showing that the last iterate of OGD also provides a good estimate of the value of bilinear games. Based on this new theoretical result (which is not unexpected but is certainly nice), the authors propose to use stochastic OGD in GAN training. Their experiments show that this new approach avoids the cycling behavior observed with SGD and its variants, and provides promising results in GAN training. (Extensive experiments show the cycling behavior of SGD variants in very simple problems, and some theoretical result is also provided when SGD diverges in solving a simple min-max game).\n\nThe paper is clearly written and easy to follow; in fact I quite enjoyed reading it. I have not checked all the details of the proofs, but they seem plausible.\nAll in all, this is a very nice paper.\n\nSome questions/comments:\n- Proposition 1: Could you show a similar example when you can prove the oscillating behavior?\n- Theorem 1: It would be interesting to write out the convergence rate of Delta_t, which could be used to optimize eta. Also, my understanding is that you actually avoid computing gamma, hence tuning eta is not straightforward. Alternatively, you could also use an adaptive OGD to automatically tune eta (see, e.g., Joulani et al, ""A modular analysis of adaptive (non-)convex optimization: optimism, composite objectives, and variational Bounds,"" ALT 2017). The non-adaptive selection of eta might be the reason that your method does not outperform adagrad SGD in 5 (b), although it is true that the behavior of your method seems quite stable for different learning rates).\n- LHS of the second line of (6) should be theta.\n- Below (6): \\mathcal{R}(A) is only defined in the appendix.']","[60, 50, 90]","[70, 60, 80]","[""The sentiment score is 60 (moderately positive) because the reviewer praises the paper's clarity and finds the theoretical result interesting, while also noting some limitations and areas for improvement. The overall tone is constructive and the reviewer sees value in the work, upgrading their rating from 6 to 7 after the authors' response. The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions or questions rather than harsh judgments. Phrases like 'This paper is relatively well-written and clear' and 'I give the paper high marks on clarity' demonstrate a polite and professional tone. Even when pointing out weaknesses, the reviewer maintains a courteous approach, using phrases like 'I found it a bit odd' rather than more confrontational language."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, including its novel approach, theoretical motivation, and practical benefits demonstrated in experiments. However, they also point out several areas needing improvement, particularly in clarity and correctness of writing. The overall tone suggests the paper has merit but requires revision. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They acknowledge the paper's contributions while tactfully pointing out areas for enhancement, maintaining a professional and courteous tone."", ""The sentiment score is 90 (very positive) because the reviewer expresses strong approval of the paper, calling it 'very nice' and stating they 'quite enjoyed reading it'. They praise the clarity of writing and the theoretical contributions. The politeness score is 80 (quite polite) due to the consistently respectful and constructive tone. The reviewer offers praise and frames their questions/comments as suggestions rather than criticisms. They use phrases like 'Could you' and 'It would be interesting', which are polite ways of making requests. The only slight reduction in politeness score is due to the direct nature of pointing out a minor error in the equation labeling, but even this is done matter-of-factly without any rudeness.""]"
"['The paper makes an important observation: the generating function of a generative model (deep or not) induces a (stochastic) Riemannian metric tensor on the latent space. This metric might be the correct way to measure distances in the latent space, as opposed to the Euclidean distance.\n\nWhile this seems obvious, I had actually always thought of the latent space as ""unfolding"" the data manifold as it exists in the output space. The authors propose a different view which is intriguing; however, they do not, to the best of my understand, give a definitive theoretical reason why the induced Riemannian metric is the correct choice over the Euclidean metric.\n\nThe paper correctly identifies an important problem with the way most deep generative models evaluate variance. However the solution proposed seems ad-hoc and not particularly related to the other parts of the paper. While the proposed variance estimation (using RBF networks) might work in some cases, I would love to see (perhaps in future work) a much more rigorous treatment of the subject.\n\nPros:\n1. Interesting observation and mathematical development of a Riemannian metric on the latent space.\n\n2. Good observation about the different roles of the mean and the variance in determining the geodesics: they tend to avoid areas of high variance.\n\n3. Intriguing experiments and a good effort at visualizing and explaining them. I especially appreciate the interpolation and random walk experiments. These are hard to evaluate objectively, but the results to hint at the phenomena the authors describe when comparing Euclidean to Riemannian metrics in the latent space.\n\nCons:\n1. The part of the paper proposing new variance estimators is ad-hoc and is not experimented with rigorously, comparing it to other methods in terms of calibration for example. \n\nSpecific comments:\n1. To the best of my understanding eq. (2) does not imply that the natural distance in Z is locally adaptive. I think of eq (2) as *defining* a type of distance on Z, that may or may not be natural. One could equally argue that the Euclidean distance on z is natural, and that this distance is then pushed forward by f to some induced distance over X. \n\n2. In the definition of paths \\gamma, shouldn\'t they be parametrized by arc-length (also known as unit-speed)? How should we think of the curve \\gamma(t^2) for example?\n\n3. In Theorem 2, is the term ""input dimension"" appropriate? Perhaps ""data dimension"" is better?\n\n4. I did not fully understand the role of the LAND model. Is this a model fit AFTER fitting the generative model, and is used to cluster Z like a GMM ? I would appreciate a clarification about the context of this model.', 'The paper investigates the geometry of deep generative models. In particular, it describes the geometry of the latent space when giving it the (stochastic) Riemannian geometry inherited from the embedding in the input space described by the generator function. The authors describe the geometric setting, how distances in the latent space can be interpreted with the non-Euclidean geometry, and how interpolation, probability distributions and random walks can be constructed.\n\nWhile the paper makes a decent presentation of the geometry of the generative setting, it is not novel. It is well known that (under certain conditions) the mapping described by the generator function is a submanifold of the input space. The latent space geometry is nothing but the submanifold geometry the image f(Z) inherits from the Euclidean geometry of X. Here f is the generator mapping f:Z->X. The latent space distances and geodesics corresponds to distances and geodesics on the submanifold f(Z) of X. Except for f being stochastic, the geometry is completely standard. It is not surprising that distances inherited from X are natural since they correspond to the Euclidean length of minimal curves in the input space (and thus the data representation) when restricting to f(Z).\n\nI cannot identify a clear contribution or novelty in the paper which is the basis for my recommendation of rejection of the paper.', 'In the paper the authors analyse the latent space generated by the variational autoencoder (VAE). They show that this latent space is imbued by a Riemannian metric and that this metric can be easily computed in terms of mean and variance functions of the corresponding VAE. They also argue that the current variance estimates are poor in regions without data and propose a meaningful variance function instead. In the experiments section the authors evaluate the quality and meaningfulness of the induced Riemannian metric.\n\nThere are minor grammatical errors and the paper would benefit from proofreading.\n\nIn the introduction the authors argue that points from different classes being close to each other is a misinterpretation of the latent space. An argument against would be that such a visualisation is simply bad. A better visualisation would explain the data structure without the need for an additional visualisation of the metric of the latent space.\n\nIn section 2, the multiplication symbol (circle with dot inside) is not defined.\n\nIt is not clear from the paper what the purpose of eq. 7 is, as well as most of the section 3. Only in appendix C, it is mentioned that eq. 7 is solved numerically to compute Riemannian distances, though it is still not clear how exactly this is achieved. I think this point should be emphasized and clarified in section 3.\n\nIn section 4, it says proof for theorem 1 is in appendix B. Appendix B says it proves theorem 2. Unfortunately, it is not clear how good the approximation in eq. 9 is.\n\nIs theorem 1 an original result by the authors? Please emphasize.\n\nIn Fig. 6, why was 7-NN used, instead of k-means, to colour the background?\n\nI think that the result from the theorem 1 is very important, since the estimation of the Riemannian metric is usually very slow. In this regard, it would be very interesting to know what the total computational complexity of the proposed approach is.\n']","[50, -70, 50]","[80, 20, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance and interesting aspects of the paper, noting several pros. However, they also point out some cons and areas for improvement, maintaining a balanced view. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms constructively. They use phrases like 'I would love to see' and 'I would appreciate a clarification' which are polite ways of suggesting improvements or requesting more information. The reviewer also balances critique with praise, showing respect for the authors' work."", ""The sentiment score is -70 because the reviewer expresses a clear negative opinion about the paper, stating that it lacks novelty and recommending rejection. The reviewer acknowledges some positive aspects ('decent presentation') but overall finds no clear contribution, which strongly indicates a negative sentiment. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone and provide explanations for their views without using harsh language. They acknowledge some positive aspects and use phrases like 'it is not surprising' rather than more confrontational language. The reviewer's tone is more matter-of-fact than overtly polite, but it avoids rudeness, hence a slightly positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the authors' work and findings, and provides constructive feedback. The review starts with a summary of the paper's content without criticism, which indicates a generally positive reception. However, it's not overwhelmingly positive as the reviewer points out several areas for improvement and clarification. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions rather than direct attacks, and acknowledges the importance of the authors' work. The reviewer uses phrases like 'would benefit from,' 'please emphasize,' and 'it would be very interesting to know,' which maintain a polite and constructive tone. The review also lacks any harsh or rude language, contributing to its overall politeness.""]"
"['The authors explore how sequence models that look at proprioceptive signals from a simulated or real-world robotic hand can be used to decode properties of objects (which are not directly observed), or produce entropy maximizing or minimizing motions.\n\nThe overall idea presented in the paper is quite nice: proprioception-based models that inject actions and encoder/pressure observations can be used to measure physical properties of objects that are not directly observed, and can also be used to create information gathering (or avoiding) behaviors. There is some related work that the authors do not cite that is highly relevant here. A few in particular come to mind:\n\nYu, Tan, Liu, Turk. Preparing for the Unknown: uses a sequence model to estimate physical properties of a robot (rather than unobserved objects)\n\nFu, Levine, Abbeel. One-Shot Learning of Manipulation Skills: trains a similar proprioception-only model and uses it for object manipulation, similar idea that object properties can be induced from proprioception\n\nBut in general the citations to relevant robotic manipulation work are pretty sparse.\n\nThe biggest issue with the paper though is with the results. There are no comparisons or reasonable baselines of any kind, and the reported results are a bit hard to judge. As far as I can understand, there are no quantitative results in simulation at all, and the real-world results are not good, indicating something like 15 degrees of error in predicting the pose of a single object. That doesn\'t seem especially good, though it\'s also very hard to tell without a baseline.\n\nOverall, this seems like a good workshop paper, but probably substantial additional experimental work is needed in order to evaluate the practical usefulness of this method. I would however strongly encourage the authors to pursue this research further: it seems very promising, and I think that, with more rigorous evaluation and comparisons, it could be quite a nice paper!\n\nOne point about style: I found the somewhat lofty claims in the introduction a bit off-putting. It\'s great to discuss the greater ""vision"" behind the work, but this paper suffers from a bit too much high-level vision and not enough effort put into explaining what the method actually does.', 'The paper proposes an architecture for internal model learning of a robotic system and applies it to a simulated and a real robotic hand.  The model allows making relatively long-term predictions with uncertainties. The models are used to perform model predictive control to achieve informative actions. It is shown that the hidden state of the learned models contains relevant information about the objects the hand was interacting with. \n\nThe paper reads well. The method is sufficiently well explained and the results are presented in an illustrative and informative way. \nupdate: See critique in my comment below.\nI have a few minor points:\n\n- Sec 2: you may consider to cite the work on maximising predictive information as intrinsic motivation:\nG. Martius, R. Der, and N. Ay. Information driven self-organization of complex robotic behaviors. PLoS ONE, 8(5):e63400, 2013.\n- Fig 2: bottom: add labels to axis, and maybe mention that same color code as above\n- Sec 4 par 3: .... intentionally not autoregressive: w.r.t. to what? to the observations? \n- Sec 7.1: how is the optimization for the MPC performed? Which algorithm did you use and long does the optimization take? \n in first Eq: should f not be sampled from GMMpdf, so replace = with \\sim\n\nTypos:\n- Sec1 par2: This pattern has has ...\n- Sec 2 par2: statistics ofthe\n- Sec 4 line2: prefix of an episode , where  (space before ,)\n \n', 'Summary:\nThe paper describes a system which creates an internal representation of the scene given observations, being this internal representation advantageous over raw sensory input for object classification and control. The internal representation comes from a recurrent network (more specifically, a sequence2sequence net) trained to maximize the likelihood of the observations from training\n\nPositive aspects:\nThe authors suggest an interesting hypothesis: an internal representation of the world which is useful for control could be obtained just by forcing the agent to be able to predict the outcome of its actions in the world. This hypothesis would enable robots to train it in a self-supervised manner, which would be extremely valuable.\n\nNegative aspects:\nAlthough the premise of the paper is interesting, its execution is not ideal. The formulation of the problem is unclear and difficult to follow, with a number of important terms left undefined. Moreover, the experiment task is too simplistic; from the results, it\'s not clear whether the representation is anything more than trivial accumulation of sensory input\n\n- Lack of clarity:\n-- what exactly is the ""generic cost"" C in section 7.1?\n-- why are both f and z parameters of C? f is directly a function of z. Given that the form of C is not explained, seems like f could be directly computing as part of C.\n-- what is the relation between actions a in section 7.1 and u in section 4?\n-- How is the minimization problem of u_{1:T} solved?\n-- Are the authors sure that they perform gathering information through ""maximizing uncertainty"" (section 7.1)? This sounds profoundly counterintuitive. Maximizing the uncertainty in the world state should result in minimum information about the worlds state. I would assume this is a serious typo, but cannot confirm given that the relation between the minimize cost C and the Renyi entropy H is not explicitely stated. \n-- When the authors state that ""The learner trains the model by maximum likelihood"" in section 7.1, do they refer to the prediction model or the control model? It would seem that it is the control model, but the objective being ""the same as in section 6"" points in the opposite direction\n-- What is the method for classifying and/or regressing given the features and internal representation? This is important because, if the method was a recurrent net with memory, the differences between the two representations would probably be minimal.\n\n- Simplistic experimental task:\nMy main intake from the experiments is that having a recurrent network processing the sensory input provides some ""memory"" to the system which reduces uncertainty when sensory data is ambiguous. This is visible from the fact that the performance from both systems is comparable at the beginning, but degrades for sensory input when the hand is open. This could be achievable in many simple ways, like modeling the classification/regression problem directly with an LSTM for example. Simpler modalities of providing a memory to the system should be used as a baseline.\n\n\nConclusion:\nAlthough the idea of learning an internal representation of the world by being able to predict its state from observations is interesting, the presented paper is a) too simplistic in its experimental evaluation and b) too unclear about its implementation. Consequently, I believe the authors should improve these aspects before the article is valuable to the community\n\n']","[20, 70, -50]","[60, 80, 20]","[""The sentiment score is slightly positive (20) because the reviewer sees promise in the research idea, calling it 'quite nice' and 'very promising', while encouraging the authors to pursue it further. However, they also point out significant issues with the paper, particularly around lack of comparisons, baselines, and rigorous evaluation. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and ends on an encouraging note. They balance critique with praise and use phrases like 'I would strongly encourage the authors' which maintains a supportive tone. The reviewer does criticize some aspects directly, but frames it politely, such as 'The biggest issue with the paper though is...' rather than using harsher language."", ""The sentiment score is 70 (positive) because the reviewer starts with a neutral summary of the paper's content, followed by positive comments such as 'The paper reads well' and 'The method is sufficiently well explained and the results are presented in an illustrative and informative way.' The reviewer then provides constructive feedback and minor suggestions, indicating overall approval with some room for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offers suggestions rather than demands (e.g., 'you may consider'), and frames critiques as 'minor points.' The reviewer also takes care to point out typos, which is helpful to the authors. The tone is professional and courteous throughout, without any harsh or rude comments."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('interesting hypothesis'), the overall tone is critical. The reviewer points out numerous negative aspects, including lack of clarity and simplistic experimental tasks. The conclusion suggests significant improvements are needed before the paper is valuable. The politeness score is 20 because the reviewer uses professional language and offers constructive criticism. They acknowledge positive aspects before detailing negatives, and use phrases like 'I believe' to soften critiques. However, the review is not overly polite, maintaining a direct and critical tone throughout.""]"
"[""The paper proposes an extension to a previous monotonic attention model (Raffel et al 2017) to attend to a fixed-sized window up to the alignment position. Both the soft attention approximation used for training the monotonic attention model, and the online decoding algorithm is extended to the chunkwise model. In terms of the model this is a relatively small extention of Raffel et al 2017.\n\nResults show that for online speech recognition the model matches the performance of an offline soft attention baseline, doing significantly better than the monotonic attention model. Is the offline attention baseline unidirectional or bidirectional? In case it is unidirectional it cannot really be claimed that the proposed model's performance is competitive with an offline model.\n\nMy concern with the statement that all hyper-parameters are kept the same as the monotonic model is that the improvement might partly be due to the increase in total number of parameters in the model. Especially given that w=2 works best for speech recognition, it not clear that the model extension is actually helping. My other concern is that in speech recognition the time-scale of the encoding is somewhat arbitrary, so possibly a similar effect could be obtained by doubling the time frame through the convolutional layer. While the empirical result is strong it is not clear that the proposed model is the best way to obtain the improvement.\n\nFor document summarization the paper presents a strong result for an online model, but the fact that it is still less accurate than the soft attention baseline makes it hard to see the real significance of this. If the contribution is in terms of speed (as shown with the synthetic benchmark in appendix B) more emphesis should be placed on this in the paper. \nSentence summarization tasks do exhibit mostly monotonic alignment, and most previous models with monotonic structure were evaluated on that, so why not test that here?\n\nI like the fact that the model is truely online, but that contribution was made by Raffel et al 2017, and this paper at best proposes a slightly better way to train and apply that model.\n\n---\n The additional experiments in the new version gives stronger support in favour of the proposed model architecture (vs the effect of hyperparameter choices). While I'm still on the fence on whether this paper is strong enough to be accepted for ICLR, this version is certainly improves the quality of the paper. \n"", 'This paper extends a previously proposed monotonic alignment based attention mechanism by considering local soft alignment across features in a chunk (certain window).  \n\nPros.\n- the paper is clearly written.\n- the proposed method is applied to several sequence-to-sequence benchmarks, and the paper show the effectiveness of the proposed method (comparable to full attention and better than previous hard monotonic assignments).\nCons.\n- in terms of the originality, the methodology of this method is rather incremental from the prior study (Raffel et al), but it shows significant gains from it.\n- in terms of considering a monotonic alignment, Hori et al, ""Advances in Joint CTC-Attention based End-to-End Speech Recognition with a Deep CNN Encoder and RNN-LM,"" in Interspeech\'17, also tries to solve this issue by combining CTC and attention-based methods. The paper should also discuss this method in Section 4.\n\nComments:\n- Eq. (16): $j$ in the denominator should be $t_j$.\n', ""This paper proposes a small modification to the monotonic attention in [1] by adding a soft attention to the segment predicted by the monotonic attention. The paper is very well written and easy to follow. The experiments are also convincing. Here are a few suggestions and questions to make the paper stronger.\n\nThe first set of questions is about the monotonic attention. Training the monotonic attention with expected context vectors is intuitive, but can this be justified further? For example, how far does using the expected context vector deviate from marginalizing the monotonic attention? The greedy step, described in the first paragraph of page 4, also has an effect on the produced attention. How does the greedy step affect training and decoding? It is also unclear how tricks in the paragraph above section 2.4 affect training and decoding. These questions should really be answered in [1]. Since the authors are extending their work and since these issues might cause training difficulties, it might be useful to look into these design choices.\n\nThe second question is about the window size $w$. Instead of imposing a fixed window size, which might not make sense for tasks with varying length segments such as the two in the paper, why not attend to the entire segment, i.e., from the current boundary to the previous boundary?\n\nIt is pretty clear that the model is discovering the boundaries in the utterance shown in Figure 2. (The spectrogram can be made more visible by removing the delta and delta-delta in the last subplot.) How does the MoCha attention look like for words whose orthography is very nonphonemic, for example, AAA and WWW?\n\nFor the experiments, it is intriguing to see that $w=2$ works best for speech recognition. If that's the case, would it be easier to double the hidden layer size and use the vanilla monotonic attention? The latter should be a special case of the former, and in general you can always increase the size of the hidden layer to incorporate the windowed information. Would the special cases lead to worse performance and if so why is there a difference?\n\n[1] C Raffel, M Luong, P Liu, R Weiss, D Eck, Online and linear-time attention by enforcing monotonic alignments, 2017""]","[-20, 50, 70]","[50, 75, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they express several concerns and reservations about the significance and novelty of the work. The reviewer mentions that it's a 'relatively small extension' of previous work, questions whether the improvement is due to the proposed model or just an increase in parameters, and states they're 'still on the fence' about acceptance. However, they do note some positive aspects, like strong empirical results and improvements in the new version.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I like the fact that...' and 'My concern is...', which are polite ways to express opinions. The reviewer also acknowledges improvements in the new version, showing fairness. There's no harsh language or personal attacks, just constructive criticism and suggestions for improvement, which is appropriate for a peer review."", ""The sentiment score is 50 (slightly positive) because the review begins with a neutral description of the paper, followed by a balanced list of pros and cons. The pros mention clear writing and effectiveness of the method, while the cons note incremental originality and a missing discussion point. This balance suggests a moderately positive view. The politeness score is 75 (quite polite) because the reviewer uses professional and respectful language throughout. They acknowledge the paper's strengths and frame criticisms constructively (e.g., 'should also discuss'). The use of 'pros' and 'cons' sections helps organize feedback clearly and objectively. The reviewer also offers a specific correction (Eq. 16) in a straightforward manner without harsh language."", ""The sentiment score is 70 (positive) because the reviewer starts by praising the paper as 'very well written and easy to follow' and states that 'the experiments are also convincing'. This indicates a generally positive view. However, it's not 100 as the reviewer does raise several questions and suggestions for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, framing their points as 'suggestions and questions' rather than criticisms. They use phrases like 'it might be useful' and ask questions rather than making demands. The tone is consistently professional and constructive, showing respect for the authors' work while still providing valuable feedback.""]"
"['The paper proposes a new multi-modal, multi-step reference game, where the sender has access to visual data and the receiver has access to textual messages, and also the conversation can be terminated by the receiver when proper. \n\nLater, the paper describes their idea and extension in details and reports comprehensive experiment results of a number of hypotheses. The research questions seems straightforward, but it is good to see those experiments review some interesting points.  One thing I am bit concerned is that the results are based on a single dataset. Do we have other datasets that can be used?\n\nThe authors also lay out further several research directions. Overall, I think this paper is easy to read and good. \n\n', 'The setup in the paper for learning representations is different to many other approaches in the area, using to agents that communicate over descriptions of objects using different modalities. The experimental setup is interesting in that it allows comparing approaches in learning an effective representation. The paper does mention the agents will be available, but leaves open wether the dataset will be also available. For reproducibility and comparisons, this availability would be essential. \n\nI like that the paper gives a bit of context, but presentation of results could be clearer, and I am missing some more explicit information on training and results (eg how long / how many training examples, how many testing, classification rates, etc).\nThe paper says is the training procedure is described in Appendix A, but as far as I see that contains the table of notations. \n\n\n', '--------------\nSummary and Evaluation:\n--------------\n\nThe paper presents a nice set of experiments on language emergence in a mutli-modal, multi-step setting. The multi-modal reference game provides an interesting setting for communication, with agents learning to map descriptions to images. The receiving agent\'s direct control over dialog length is also novel and allows for the interesting analysis presented in later sections. \n\nOverall I think this is an interesting and well-designed work; however, some details are missing that I think would make for a stronger submission (see weaknesses).\n\n\n--------------\nStrengths:\n--------------\n- Generally well-written with the Results and Analysis section appearing especially thought-out and nicely presented.\n\n- The proposed reference game provides a number of novel contributions -- giving the agents control over dialog length, providing both agents with the same vocabulary without constraints on how each uses it (implicit through pretraining or explicit in the structure/loss), and introducing an asymmetric multi-modal context for the dialog.\n\n- The analysis is extensive and well-grounded in the three key hypothesis presented at the beginning of Section 6.\n\n--------------\nWeaknesses:\n--------------\n\n- There is room to improve the clarity of Sections 3 and 4 and I encourage the authors to revisit these sections. Some specific suggestions that might help:\n\t\t- numbering all display style equations\n\t\t- when describing the recurrent receiver, explain the case where it terminates (s^t=1) first such that P(o_r=1) is defined prior to being used in the message generation equation. \n\n- I did not see an argument in support of the accuracy@K metric. Why is putting the ground truth in the top 10% the appropriate metric in this setting? Is it to enable comparison between the in-domain, out-domain, and transfer settings?\n\n- Unless I missed something, the transfer test set results only comes up once in the context of attention methods and are not mentioned elsewhere. Why is this? It seems appropriate to include in Figure 5 if no where else in the analysis.\n\n- Do the authors have a sense for how sensitive these results are to different runs of the training process?\n\n- I did not understand this line from Section 5.1: ""and discarding any image with a category beyond the 398-th most frequent one, as classified by a pretrained ImageNet classifier\'""\n\n- It is not specified (or I missed it) whether the F1 scores from the separate classifier are from training or test set evaluations.\n\n- I would have liked to see analysis on the training process such as a plot of reward (or baseline adjusted reward) over training iterations. \n\n- I encourage authors to see the EMNLP 2017 paper ""Natural Language Does Not Emerge ‘Naturally’ in Multi-Agent Dialog"" which also perform multi-round dialogs between two agents. Like this work, the authors also proposed removing memory from one of the agents as a means to avoid learning degenerate \'non-dialog\' protocols.\n\n- Very minor point: the use of fixed-length, non-sequence style utterances is somewhat disappointing given the other steps made in the paper to make the reference game more \'human like\' such as early termination, shared vocabularies, and unconstrained utterance types. I understand however that this is left as future work.\n\n\n--------------\nCuriosities:\n--------------\n- I think the analysis is Figure 3 b,c is interesting and wonder if something similar can be computed over all examples. One option would be to plot accuracy@k for different utterance indexes -- essentially forcing the model to make a prediction after each round of dialog (or simply repeating its prediction if the model has chosen to stop). \n\n']","[70, 20, 60]","[80, 60, 70]","[""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, describing it as 'easy to read and good.' They commend the comprehensive experiments and interesting findings. The only slight concern mentioned is about the use of a single dataset, which prevents a perfect score. The politeness score is 80 (polite) due to the reviewer's constructive and respectful tone throughout. They use phrases like 'it is good to see' and frame their concern as a question rather than a criticism. The review maintains a professional and courteous tone while providing balanced feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting aspects of the paper, such as the unique setup and experimental approach. However, they also point out some limitations and areas for improvement, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, starting with positive aspects before mentioning concerns. They use phrases like 'I like that' and frame criticisms as suggestions rather than harsh judgments. The reviewer maintains a professional and constructive tone, avoiding any rude or overly negative language."", ""The sentiment score is 60 (moderately positive) because the reviewer describes the paper as 'interesting and well-designed' with 'novel contributions' and 'extensive analysis'. However, they also point out several weaknesses and areas for improvement, tempering the overall positivity. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering constructive criticism with phrases like 'I encourage the authors' and 'I would have liked to see'. They balance positive feedback with areas for improvement, maintaining a professional and courteous tone. The reviewer also shows engagement by offering suggestions and expressing curiosity about potential further analysis.""]"
"['1) Summary\nThis paper proposes a study on the robustness of one low-precision neural networks class - binarized neural networks (BNN) - against adversarial attacks. Specifically, the authors show that these low precision networks are not just efficient in terms of memory consumption and forward computation, but also more immune to adversarial attacks than their high-precision counterparts. In experiments, they show the advantage of BNNs by conducting experiments based on black-box and white-box adversarial attacks without the need to artificially mask gradients.\n\n\n2) Pros:\n+ Introduced, studied, and supported the novel idea that BNNs are robust to adversarial attacks.\n+ Showed that BNNs are robust to the Fast Gradient Sign Method (FGSM) and Carlini-Wagner attacks in white-box adversarial attacks by presenting evidence that BNNs either outperform or perform similar to the high-precision baseline against the attacks.\n+ Insightful analysis and discussion of the advantages of using BNNs against adversarial attacks.\n\n3) Cons:\nMissing full-precision model trained with PGD in section 3.2:\nThe authors mention that the full-precision model would also likely improve with PGD training, but do not have the numbers. It would be useful to have such numbers to make a better evaluation of the BNN performance in the black-box attack setting.\n\n\nAdditional comments:\nCan the authors provide additional analysis on why BNNs perform worse than full-precision networks against black-box adversarial attacks? This could be insightful information that this paper could provide if possible.\n\n\n4) Conclusion:\nOverall, this paper proposes great insightful information about BNNs that shows the additional benefit of using them besides less memory consumption and efficient computation. This paper shows that the used architecture for BBNs makes them less susceptible to known white-box adversarial attack techniques.\n', 'his work presents an empirical study demonstrating that binarized networks are more robust to adversarial examples. The authors follow the stochastic binarization procedure proposed by Courbariaux et al. The robustness is tested with various attacks such as the fast gradient sign method and the projected gradient method on MNIST and CIFAR.\n\nThe experimental results validate the main claims of the paper on some datasets. While reducing the precision can intuitively improve the robustness, It remains unclear if this method would work on higher dimensional inputs such as Imagenet. Indeed: \n\n(1) state of the art architectures on Imagenet such as Residual networks are known to be very fragile to precision reduction. Therefore, reducing the precision can also reduce the robustness as it is positively correlated with accuracy. \n\n(2) Compressing reduces the size of the hypothesis space explored. Therefore, larger models may be needed to make this method work for higher dimensional inputs. \n\nThe paper is well written overall and the main idea is simple and elegant. I am less convinced by the experiments.  ', '\nThis paper starts by gently going over the concept of adversarial attacks on neural networks (black box vs white box, reactive vs proactive, transfer of attacks, linearity hypothesis), as well as low-precision nets and their deployement advantages. \nAdversarial examples are introduced as a norm-measurable deviation from natural inputs to a system. We are reminded of adversarial training, and of the fact that binarized nets are highly non linear due to the nature of their weights and activations.\n\nThis paper then proposes to examine the robustness of binarized neural networks to adversarial attacks on MNIST and CIFAR-10.\n\nThe quantization scheme used here is v32 Conv2D -> ReLU -> BNorm -> sign -> bit Conv2D -> ReLU -> Scalar -> BNorm -> sign, but sign is really done with the stochastic quantization method of Courbariaux et al, even at test time (in order to make it more robust).\n\nWhat the experimental results show:\n- High capacity BNNs are usually more robust to white-box attacks than normal networks, probably because the gradient information that an adversary would use becomes very poor as training progresses.\n- BNNs are harder to properly train with adversarial examples because of the polarized weight distribution that they induce\n- Against black-box attacks, it seems there is little difference between NNs and BNNs.\n\nSome comments and questions:\n- In figure 1 I\'m not sure what ""Scalar"" refers to, and it is not explained in the paper (nor could I find it explained in Papernot et al 2017a).\n- Do you adopt the ""Shift based Batch Normalizing Transform"" of Courbariaux et al? If not, why?\n- It might be worth at least _quickly_ explaining what the \'Carlini-Wagner L2 from CleverHans\' is rather than simply offering a citation with no explanation. Idem for \'smooth substitute model black-box misclassificiation attack\'. We often assume our readers know most of what we know, but I find this is often not the case and can discourage the many newcomers of our field.\n- ""Running these attacks to 1000 iterations [...], therefore we believe this targeted attack represents a fairly substantial level of effort on behalf of the adversary."" while true for us researchers, computational difficulty will not be a criterion to stop for state actor or multinational tech companies, unless it can be proven that e.g. the number of iterations needs to grow exponentially (or in some other unreasonable way) in order to get reliable attacks.\n- ""MLP with binary units 3 better"", \'as in Fig.\' is missing before \'3\', or something of the sort.\n- You say ""We postpone a formal explanation of this outlier for the discussion."" but really you\'re explaining it in the next paragraph (unless there\'s also another explanation I\'m missing). Training BNNs with adversarial examples is hard.\n- You compare stochastic BNNs with deterministic NNs, but not with stochastic NNs. What do you think would happen? Some of arguments that you make in favour of BNNs could also maybe be applied to stochastic NNs.\n\nMy opinions on this paper:\n- Novelty: it certainly seems to be the first time someone has tackled BNNs and adversarial examples\n- Relevance: BNNs can be a huge deal when deploying applications, it makes sense to study their vulnerabilities\n- Ease of understanding: To me the paper was mostly easy to understand, yet, considering there is no page limit in this conference, I would have buffed up the appendix, e.g. to include more details about the attacks used and how various hyperparameters affect things.\n- Clarity: I feel like some details are lacking that would hinder reproducing and extending the work presented here. Mostly, it isn\'t always clear why the chosen prodecures and hyperparameters were chosen (wrt the model being a BNN)\n- Method: I\'m concerned by the use of MNIST to study such a problem. MNIST is almost linearly separable, has few examples, and given the current computational landscape, much better alternatives are available (SVHN for example if you wish to stay in the digits domain). Concerning black-box attacks, it seems that BNNs less beneficial in a way; trying more types of attacks and/or delving a bit deeping into that would have been nice. The CIFAR-10 results are barely discussed.\n\nOverall I think this paper is interesting and relevant to ICLR. It could have stronger results both in terms of the datasets used and the variety of attacks tested, as well as some more details concerning how to perform adversarial training with BNNs (or why that\'s not a good idea).']","[80, 20, 50]","[70, 60, 80]","[""The sentiment score is 80 (positive) because the review begins with a neutral summary and then lists several pros, including praising the paper for introducing a 'novel idea' and providing 'insightful analysis'. The cons are minimal, mainly suggesting additional information. The conclusion is very positive, calling the paper 'great' and 'insightful'. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, such as 'Can the authors provide...' instead of demanding changes. The reviewer also balances critique with praise and uses positive adjectives like 'useful' and 'insightful'. The tone is professional and constructive throughout, without any harsh or rude language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's main claims are validated and describes the idea as 'simple and elegant'. However, they express skepticism about the experiments and applicability to higher-dimensional inputs, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while diplomatically expressing concerns. They use phrases like 'well written overall' and frame criticisms as questions or areas for further exploration rather than direct attacks."", ""The sentiment score is 50 (slightly positive) because while the reviewer finds the paper interesting and relevant, they also point out several areas for improvement. The review begins with a neutral summary, then highlights positive aspects ('novelty', 'relevance'), but also notes concerns and suggestions for enhancement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'It could have stronger results'), and balances negative points with positive ones. The reviewer also uses phrases like 'My opinions' and 'I think', which soften the critique. The tone is professional and helpful rather than harsh or dismissive.""]"
"[""The paper presents the Kanerva Machine, extending an interesting older conceptual memory model to modern usage. The review of Kanerva’s sparse distributed memory in the appendix was appreciated. While the analyses and bounds of the original work were only proven when restricted to uniform and binary data, the extensions proposed bring it to modern domain of non-uniform and floating point data.\n\nThe iterative reading mechanism which provides denoising and reconstruction when within tolerable error bounds, whilst no longer analytically provable, is well shown experimentally.\nThe experiments and results on Omniglot and CIFAR provide an interesting insight to the model's behaviour with the comparisons to VAE and DNC also seem well constructed.\n\nThe discussions regarding efficiency and potential optimizations of writing inference model were also interesting and indeed the low rank approximation of U seems an interesting future direction.\n\nOverall I found the paper well written and reintroduced + reframed a relatively underutilized but well theoretically founded model for modern use."", 'This paper generalizes the sparse distributed memory model of Kanerva to the Kanerva Machine by formulating a variational generative model of episodes with memory as the prior. \n\nPlease discuss the difference from other papers that implement memory as a generative model, i.e. (Bornschein, Mnih, Zoran, Rezende 2017)\n\nA probabilistic interpretation of Kanerva’s model was given before (Anderson, 1989 http://ieeexplore.ieee.org/document/118597/ ) and (Abbott, Hamrick, Griffiths, 2013). Please discuss.\n\nI found the relation to Kanerva’s original model interesting and well explained. The original model was motivated by human long term memory and neuroscience. It would be nice if the authors can provide what neuroscience implications their work has, and comment on its biological plausibility.', ""The generative model comprises a real-valued matrix M (with a multivariate normal prior) that serves\nas the memory for an episode (an unordered set of datapoints). For each datapoint a marginally independent\nlatent variable y_t is used to index into M and realize a conditional density\nof another latent variable z. z_t is used to generate the data.\n\nThe proposal of learning with a probabilistic memory is interesting and the framework proposed is elegant and cleanly explained. The model is evaluated on the following tasks:\n* Qualitative results on denoising and one-shot generation using the Omniglot dataset.\n* Qualitative results on sampling from the model using the CIFAR dataset.\n* Likelihood estimation on the Omniglot dataset\n\nQuestions and concerns: \n\nThe model appears novel and is interesting, the experiments, however, are lacking in that they\ndo not compare against other any recently proposed memory augmented deep generative models [Bornschein et al] and [Li et. al] (https://arxiv.org/pdf/1602.07416.pdf). At the very minimum, the paper should include a discussion and a comparison with the latter. Doing so will help better understand what is gained from using retaining a probabilistic form of memory versus a determinstic memory indexed with attention as in [Li et. al].\n\nHow does the model perform as a function of varying T (size of episodes) during training? It would be interesting to see how well the model performs in the limiting case of T=1.\n\nWhat is the task being solved in Section 4.4 by the DNC and the Kanerva machine? Please state this in the main paper.\n\nTraining and Evaluation: There is a mismatch in the training and evaluation procedure the implications of which I don't\nfully understand yet. The text states that the model was trained where each observation in an episode comprised randomly sampled datapoints. This corresponds to a generative process where (1) a memory is randomly drawn, (2) each observation in the episode is an independent draws from the memory conditioned decoder. During training,\npoints in an episode are randomly selected. At test time, (if I understand correctly, please correct me if I haven't), the model is evaluated by having multiple copies of the same test point within an episode. Is that correct? If so, doesn't that correspond to evaluating the model under a different generative assumption? Why is this OK?\n\nLikelihood evaluation: Could you expand on how the ELBO of 68.3 is computed under the model for a single test image in the Omniglot dataset? The text says that the likelihood of each data-point was divided by T (the length of the episode considered). This seems at odds with models, such as DRAW, evaluate the likelihood -- once at the end of the generative drawing process. What is the per-pixel likelihood obtained on the CIFAR dataset and what is the likelihood on a model where T=1 (for omniglot/cifar)?\n\nUsing Labels: Following up on the previous point, what happens if labelled information from Omniglot or CIFAR is used to define points within an episode during the training procedure? Does this help or hurt performance?\n\nFor the denoising comparison, how do the results compare to those obtained if you simulate a Markov Chain (sample latent state conditioned on noisy image, sample latent state, sample denoised observation, repeat using denoised observation) using a VAE?""]","[80, 50, 20]","[70, 80, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses appreciation for the paper's content, methodology, and contributions. They use phrases like 'interesting', 'well shown experimentally', and 'well written', indicating a favorable view of the work. The reviewer also highlights the paper's strengths and potential future directions, suggesting a positive overall assessment. The politeness score is 70 (polite) as the reviewer maintains a professional and respectful tone throughout. They offer constructive feedback and acknowledge the paper's merits without using overly effusive language. The reviewer's comments are framed positively, focusing on the paper's strengths and contributions rather than criticisms, which contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting aspects and good explanations, particularly regarding the relation to Kanerva's original model. However, they also request additional discussions and comparisons, indicating room for improvement. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, employing phrases like 'Please discuss' and 'It would be nice if' when making suggestions. The tone is constructive and encouraging rather than critical, maintaining a professional and courteous approach to feedback."", ""The sentiment score is slightly positive (20) because the reviewer starts by acknowledging the proposal as 'interesting' and the framework as 'elegant and cleanly explained'. However, they also express concerns and questions, which tempers the positivity. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the merits of the work before raising concerns. They use phrases like 'please correct me if I haven't' and 'Could you expand on', which are polite ways of seeking clarification. The review maintains a professional and constructive tone throughout, even when pointing out potential issues or requesting additional information.""]"
"['I found this paper an interesting read for two reasons: First, interpretability is an increasingly important problem as machine learning models grow more and more complicated. Second, the paper aims at generalization of previous work on confounded linear model interpretation in neuroimaging (the so-called filter versus patterns problem). The problem is relevant for discriminative problems: If the objective is really to visualize the generative process,  the ""filters"" learned by the discriminative process need to be transformed to correct for spatial correlated noise. \n\nGiven the focus on extracting visualization of the generative process, it would have been meaningful to place the discussion in a greater frame of generative model deep learning (VAEs, GANs etc etc). At present the ""state of the art"" discussion appears quite narrow, being confined to recent methods for visualization of discriminative deep models.\n\nThe authors convincingly demonstrate for the linear case, that their ""PatternNet"" mechanism can produce the generative process (i.e. discard spatially correlated ""distractors""). The PatternNet is generalized to multi-layer ReLu networks by construction of node-specific pattern vectors and back-propagating these through the network. The ""proof"" (eqs. 4-6) is sketchy and involves uncontrolled approximations. The back-propagation mechanism is very briefly introduced and depicted in figure 1.\n\nYet, the results are rather convincing. Both the anecdotal/qualitative examples and the more quantitative patch elimination experiment figure 4a (?number missing) \n\nI do not understand the remark: ""However, our method has the advantage that it is not only applicable to image models but is a generalization of the theory commonly used in neuroimaging Haufe et al. (2014).""  what ??\n\nOverall, I appreciate the general idea. However, the contribution could have been much stronger based on a detailed derivation with testable assumptions/approximations, and if based on a clear declaration of the aim.\n\n', 'summary of article: \nThis paper organizes existing methods for understanding and explaining deep neural networks into three categories based on what they reveal about a network: functions, signals, or attribution. “The function extracts the signal from the data by removing the distractor. The attribution of output values to input dimensions shows how much an individual component of the signal contributes to the output…” (p. 5). The authors propose a novel quality criterion for signal estimators, inspired by the analysis of linear models. They also propose two new explanatory methods, PatternNet (for signal estimation) and PatternAttribution (for relevance attribution), based on optimizing their new quality criterion. They present quantitative and qualitative analyses comparing PatternNet and PatternAttribution to several existing explanation methods on VGG-19.\n\n* Quality: The claims of the paper are well supported by quantitative results and qualitative visualizations. \n* Clarity: Overall the paper is clear and well organized. There are a few points that could benefit from clarification.\n* Originality: The paper puts forth an original framing of the problem of explaining deep neural networks. Related work is appropriately cited and compared. The authors\'s quality criterion for signal estimators allows them to do a quantitative analysis for a problem that is often hard to quantify.\n* Significance: This paper justifies PatternNet and PatternAttribution as good methods to explain predictions made by neural networks. These methods may now serve as an important tool for future work which may lead to new insights about how neural networks work. \n\nPros:\n* Helps to organize existing methods for understanding neural networks in terms of the types of descriptions they provide: functions, signals or attribution.\n* Creative quantitative analyses that evaluate their signal estimator at the level of single units and entire networks.\n\nCons:\n* Experiments consider only the pre-trained VGG-19 model trained on ImageNet. Results may not generalize to other architectures/datasets.\n* Limited visualizations are provided. \n\nComments:\n* Most of the paper is dedicated to explaining these signal estimators and quality criterion in case of a linear model. Only one paragraph is given to explain how they are used to estimate the signal at each layer in VGG-19. On first reading, there are some ambiguities about how the estimators scale up to deep networks. It would help to clarify if you included the expression for the two-component estimator and maybe your quality criterion for an arbitrary hidden unit. \n* The concept of signal is somewhat unclear. Is the signal \n    * (a) the part of the input image that led to a particular classification, as described in the introduction and suggested by the visualizations, in which case there is one signal per image for a given trained network?\n    *  (b) the part of the input that led to activation of a particular unit, as your unit wise signal estimators are applied, in which case there is one signal for every unit of a trained network? You might benefit from two terms to separate the unit-level signal (what caused the activation of a particular unit?) from the total signal (what caused all activations in this network?).\n* Assuming definition (b) I think the visualizations would be more convincing if you showed the signal for several output units. One would like to see that the signal estimation is doing more than separating foreground from background but is actually semantically specific. For instance, for the mailbox image, what does the signal look like if you propagate back from only the output unit for umbrella compared to the output unit for mailbox? \n* Do you have any intuition about why your two-component estimator doesn’t seem to be working as well in the convolutional layers? Do you think it is related to the fact that you are averaging within feature maps? Is it strictly necessary to do this averaging? Can you imagine a signal estimator more specifically designed for convolutional layers?\n\nMinor issues: \n* The label ""Figure 4"" is missing. Only subcaptions (a) and (b) are present.\n* Color scheme of figures: Why two oranges? It’s hard to see the difference.', 'The authors analyze show theoretical shortcomings in previous methods of explaining neural networks and propose an elegant way to remove these shortcomings in their methods PatternNet and PatternAttribution.\n\nThe quest of visualizing neural network decision is now a very active field with many contributions. The contribution made by the authors stands out due to its elegant combination of theoretical insights and improved performance in application. The work is very detailed and reads very well.\n\nI am missing at least one figure with comparison with more state-of-the-art methods (e.g. I would love to see results from the method by Zintgraf et al. 2017 which unlike all included prior methods seems to produce much crisper visualizations and also is very related because it learns from the data, too).\n\nMinor questions and comments:\n* Fig 3: Why is the random method so good at removing correlation from fc6? And the S_w even better? Something seems special about fc6.\n* Fig 4: Why is the identical estimator better than the weights estimator and that one better than S_a?\n* It would be nice to compare the image degradation experiment with using the ranking provided by the work from Zintgraf which should by definition function as a kind of gold standard\n* Figure 5, 4th row (mailbox): It looks like the umbrella significantly contributes to the network decision to classify the image as ""mailbox"" which doesn\'t make too much sense. Is is a problem of the visualization  (maybe there is next to no weight on the umbrella), of PatternAttribution or a strange but interesting a artifact of the analyzed network?\n* page 8 ""... closed form solutions (Eq (4) and Eq. (7))"" The first reference seems to be wrong. I guess Eq 4. should instead reference the unnumbered equation after Eq. 3.\n\nUpdate 2018-01-12: Upgraded Rating from 7 to 8 (see comment below)']","[50, 70, 80]","[60, 80, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer finds the paper interesting and acknowledges its relevance, but also points out areas for improvement. The reviewer uses phrases like 'interesting read', 'convincingly demonstrate', and 'appreciate the general idea', indicating a generally positive view. However, they also mention limitations and suggest areas where the paper could be stronger. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They acknowledge the paper's strengths before suggesting improvements, which is a polite approach. The use of phrases like 'it would have been meaningful' and 'the contribution could have been much stronger' are polite ways of suggesting improvements without being overly critical."", ""The sentiment score is 70 (positive) because the reviewer begins by highlighting the paper's strengths, including its well-supported claims, clarity, originality, and significance. They provide a list of pros before mentioning any cons, indicating an overall positive view. The politeness score is 80 (polite) due to the reviewer's constructive tone throughout. They use phrases like 'could benefit from clarification' and 'It would help to clarify' when suggesting improvements, rather than using harsh criticism. The reviewer also balances critique with praise and offers specific, actionable feedback. The use of questions to prompt further thought from the authors is a polite way of addressing potential issues. The review maintains a professional and respectful tone throughout, even when pointing out minor issues."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the authors' work, describing it as 'elegant', 'detailed', and reading 'very well'. They also highlight how the contribution 'stands out'. The only negative aspect is a missing comparison with a specific method, but this doesn't significantly detract from the overall positive sentiment. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames their suggestions as 'minor questions and comments'. The tone is professional and courteous, avoiding any harsh criticism. The reviewer even upgraded their rating at the end, further indicating a positive and polite approach.""]"
"['This paper presents an simple and interesting idea to improve the performance for neural nets. The idea is we can reduce the precision for activations and increase the number of filters, and is able to achieve better memory usage (reduced). The paper is aiming to solve a practical problem, and has done some solid research work to validate that.  In particular, this paper has also presented a indepth study on AlexNet with very comprehensive results and has validated the usefulness of this approach.   \n\nIn addition, in their experiments, they have demonstrated pretty solid experimental results, on AlexNet and even deeper nets such as the state of the art Resnet. The results are convincing to me. \n\nOn the other side, the idea of this paper does not seem extremely interesting to me, especially many decisions are quite natural to me, and it looks more like a very empirical practical study. So the novelty is limited.\n\nSo overall given limited novelty but the paper presents useful results, I would recommend borderline leaning towards reject.', 'The paper studies the effect of reduced precision weights and activations on the performance, memory and computation cost of deep networks and proposes a quantization scheme and wide filters to offset the accuracy lost due to the reduced precision. The study is performed on AlexNet, ResNet and Inception on the Imagenet datasets and results show that accuracy matching the full precision baselines can be obtained by widening the filters on the networks. \n\nPositives\n- Using lower precision activations to save memory and compute seems new and widening the filter sizes seems to recover the accuracy lost due to the lower precision.\n\nNegatives\n- While the exhaustive analysis is extremely useful the overall technical contribution of the paper that of widening the networks is fairly small. \n- The paper motivates the need for reduced precision weights from the perspective of saving memory footprint when using large batches. However, the results are more focused on compute cost. Also large batches are used mainly during training where memory is generally not a huge issue. Memory critical situations such as inference on mobile phones can be largely mitigated by using smaller batch sizes. It might help to emphasize the speed-up in compute more in the contributions.  ', 'This is a well-written paper with good comparisons to a number of earlier approaches. It focuses on an approach to get similar accuracy at lower precision, in addition to cutting down the compute costs. Results with 2-bit activations and 4-bit weights seem to match baseline accuracy across the models listed in the paper.\n\nOriginality\nThis seems to be first paper that consistently matches baseline results below int-8 accuracy, and shows a promising future direction.\n\nSignificance\nGoing down to below 8-bits and potentially all the way down to binary (1-bit weights and activations) is a promising direction for future hardware design. It has the potential to give good results at lower compute and more significantly in providing a lower power option, which is the biggest constraint for higher compute today. \n\nPros:\n- Positive results with low precision (4-bit, 2-bit and even 1-bit)\n- Moving the state of the art in low precision forward\n- Strong potential impact, especially on constrained power environments (but not limited to them)\n- Uses same hyperparameters as original training, making the process of using this much simpler.\n\nCons/Questions\n- They mention not quantizing the first and last layer of every network. How much does that impact the overall compute? \n- Is there a certain width where 1-bit activation and weights would match the accuracy of the baseline model? This could be interesting for low power case, even if the ""effective compute"" is larger than the baseline.\n']","[-20, 20, 80]","[50, 50, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's solid research work and convincing results, they ultimately recommend 'borderline leaning towards reject' due to limited novelty. The positive aspects (interesting idea, solid research, comprehensive results) are balanced against the criticism of limited novelty, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'interesting idea', 'solid research work', and 'convincing results', which maintain a polite tone even when expressing concerns about novelty."", ""The sentiment score is slightly positive (20) because the review begins with a neutral summary of the paper's content, followed by a 'Positives' section that highlights a novel aspect of the research. However, the 'Negatives' section points out some limitations, which prevents the score from being higher. The overall tone suggests the reviewer sees value in the work but has some reservations. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They present both positive and negative points in a balanced manner without using harsh or dismissive language. The critique is constructive and focuses on the content rather than making personal comments. The reviewer also acknowledges the 'extremely useful' nature of the analysis, which adds to the polite tone."", ""The sentiment score is 80 (positive) because the review starts with praising the paper as 'well-written' and highlights several positive aspects, including originality, significance, and potential impact. The reviewer lists more pros than cons and describes the work as 'moving the state of the art forward'. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as questions rather than direct negative statements. The tone is professional and constructive, offering suggestions for improvement without being harsh or dismissive.""]"
"['== Paper Summary ==\nThe paper addresses the problem of balancing capacities of generator and discriminator classes in generative adversarial nets (GANs) from purely theoretical (function analytical and statistical learning) perspective. In my point of view, the main *novel* contributions are: \n(a) Conditions on function classes guaranteeing that the induced IPMs are metrics and not pseudo-metrics (Theorem 2.2). Especially I liked an argument explaining why ReLu activations could work better in discriminator that tanh.\n(b) Proving that convergence in the neural distance implies a weak convergence (Theorem 2.5)\n(c) Listing particular cases when the neural distance upper bounds the so-called bounded Lipschitz distance (also know as the Fortet-Mourier distance) and the symmetrized KL-divergence (Corollary 2.8 and Proposition 2.9).\n\nThe paper is well written (although with *many* typos), the topic is clearly motivated and certainly interesting. The related literature is mainly covered well, apart from several important points listed below.\n\n== Major comments ==\nIn my opinion, the authors are slightly overselling the results. Next I shortly explain why:\n\n(1) First, point (a) above is indeed novel, but not groundbreaking. A very similar result previously appeared in [1, Theorem 5]. The authors may argue that the referenced result deals only with MMDs, that is IPMs specified to the function classes belonging to the Reproducing Kernel Hilbert Spaces. However, the technique used to prove the ""sufficient"" part of the statement is literally *identical*. \n\n(2) As discussed in the paragraph right after Theorem 2.5, Theorem 10 of [2] presents the same result which is on one hand stronger than Theorem 2.5 of the current paper because it allows for more general divergences than the neural distance and on the other hand weaker because in [2] the authors assumes a compact input space. Overall, Theorem 2.5 of course makes a novel contribution, because the compactness assumption is not required, however conceptually it is not that novel.\n\n(3) In Section 3 the authors discuss the generalization properties of the neural network distance. One of the main messages (emphasized several times throughout the paper) is that surprisingly the capacity of the generator class does not enter the generalization error bound. However, this is not surprising at all as it is a consequence of the way in which the authors define the generalization. In short, the capacity of discriminators (D) naturally enters the picture, because the generalization error accounts for the mismatch between the true data distribution mu (used for testing) and its empirical version hat{mu} (used for training). However, the authors assume the model distribution (nu) is the same both during testing and training. In practice this is not true and during testing GANs use the empirical version of nu. If the authors were to account for this mismatch, capacity of G would certainly pop up as well.\n\n(4) The error bounds of Section 3 are based on a very standard machinery (empirical processes, Rademacher complexity) and to the best of my knowledge do not lead to any new interesting conclusions in terms of GANs.\n\n(5) Finally, I would suggest the authors to remove Section 4. I suggest this mainly because the authors admit in Remark 4.1 that the main result of this section (Theorem 4.1) is a corollary of a stronger result appearing in [2]. Also, the main part of the paper has 13 pages, while a recommended amount is 8. \n\n== Minor comments ==\n\n(1) There are *MANY* typos in the paper. Only few of them are listed below.\n(2) First paragraph of page 18, proof of Theorem 2.2. This part is of course well known and the authors may just cite Lemma 9.3.2. of Dudley\'s ""Real analysis and probability"" for instance.\n(3) Theorem 2.5: ""Let ...""\n(4) Page 7, ""...we may BE interested...""\n(5) Corollary 3.2. I doubt that in practice anyone uses discriminator with one hidden unit. The authors may want to consider using the bound on the Rademacher complexity of DNNs recently derived in [3]. \n(6) Page 8, ""..is neural networK""\n(7) Page 9: ""...interested IN evaluating...""\n(8) Page 10. All most ---> almost.\n\n[1] Gretton et al., A Kernel Two-Sample Test, JMLR 2012.\n[2] Liu et al, Approximation and Convergence Properties of Generative Adversarial Learning, 2017\n[3] Bartlett et al, Spectrally-normalized margin bounds for neural networks, 2017', 'In more detail, the analysis of the paper is as follows.  Firstly, it primarily focuses on GAN objective functions which are ""integral probability metrics (IPMs)""; one way to define these is by way of similarity to the W-GAN, namely IPMs replace the 1-Lipschitz functions in W-GAN with a generic set of functions F.  The paper overall avoids computational issues and treats the suprema as though exactly solved by sgd or related heuristic (the results of the paper simply state supremum, but some of the prose seems to touch on this issue).\n\nThe key arguments of the paper are as follows.\n\n1. It argues that the discriminator set should be not simply large, it should be dense in all bounded continuous functions; as a consequence of this, the IPM is 0 iff the distributions are equal (in the weak sense).  Due to this assertion, it says that it suffices to use two layer neural networks as the discriminator set (as a consequence of the ""universal approximation"" results well-known in the neural network literature).\n\n2. It argues the discriminator set should be small in order to mitigate small-sample effects.  (Together, points 1 and 2 mimic a standard bias-variance tradeoff in statistics.)  For this step, the paper relies upon standard Rademacher results plus a little bit of algebraic glue.  Curiously, the paper chooses to argue (and forms as a key tenet, indeed in the abstract) that the size of the generator set is irrelevant for this, only the size of the discriminator matters.\n\nUnfortunately, I find significant problems with the paper, in order from most severe to least severe.\n\nA.  The calculation ruling out the impact of the generator in generalization calculations in 2 above is flawed.  Before pointing out the concrete bug, I note that this assertion runs completely counter to intuition, and thus should be made with more explanation (as opposed to the fortunate magic it is presented as).  Moreover, I\'ll say that if the authors choose to ""fix"" this bug by adding a generator generalization term, the bound is still a remedial application of Rademacher complexity, so I\'m not exactly blown away.  Anyway, the bug is as follows.  The equation which drops the role of the generator in the generalization calculation is the equation (10).  The proof of this inequality is at the start of appendix E.  Looking at the derivation in that appendix, everything is correct up to the second-to-last display, the one with a supremum over nu in G.  First of all, this right hand side should set off alarm bells; e.g., if we make the generator class big, we can make this right hand side essentially as big as the IPM allows even when mu = mu_m.  Now the bug itself appears when going to the next display: if the definition of d_F is expanded, one obtains two suprema, each own over _their own_ optimization variable (in this case the variables are discriminator functions).  When going to the next equation, the authors accidentally made the two suprema have the same variable and invoke a fortuitous but incorrect cancellation.  As stated a few sentences back, one can construct trivial counterexamples to these inequalities, for instance by making mu and mu_m arbitrarily close (even exactly equal if you wish) and then making nu arbitrarily far away and the discriminator set large enough to identify this.\n\nB. The assertions in 1, regarding sizes of discriminator sets needed to achieve the goal of the IPM being 0 iff the distributions are equal (in the weak sense), are nothing more than immediate corollaries of approximation results well-known for decades in the neural network literature.  It is thus hard to consider this a serious contribution.\n\nC. I will add on a non-technical note that the paper\'s assertion on what a good IPM ""should be"" is arguably misled.  There is not only a meaning to specific function classes (as with Lip_1 in Wasserstein_1) beyond simply ""many functions"", but moreover there is an interplay between the size of the generator set and the size of the discriminator set.  If the generator set is simple, then the discriminator set can also get away with being simple (this is dicussed in the Arora et al 2017 ICML paper, amongst other places).  Perhaps I am the one that is misled, but even so the paper does not appear to give a good justification of its standpoint.\n\nI will conclude with typos and minor remarks.  I found the paper to contain a vast number of small errors, to the point that I doubted a single proofread.\n\nAbstract, first line: ""a minimizing""?  general grammar issue in this sentence; this sort of issue throughout the paper.\n\nAbstract, ""this is a mild condition"".  Optimizing over a function class which is dense in all bounded measurable functions is not a mild assumption.  In the particular case under discussion, the size of the network can not be bounded (even though it has just two layers, or as the authors say is the span of single neurons).\n\nAbstract, ""...regardless of the size of the generator or hypothesis set"".  This really needs explanation in the abstract, it is such a bold claim.  For instance, I wrote ""no"" in the margin while reading the abstract the first time.\n\nIntro, first line: its -> their.\n\nIntro, #3 ""energy-based GANs"": \'m\' clashes with sample size.\n\nIntro, bottom of page 1, the sentence with ""irrelenvant"": I can\'t make any sense of this sentence.\n\nIntro, bottom of page 1, ""is a much smaller discriminator set"": no, the Lip_1 functions are in general incomparable to arbitrary sets of neural nets.\n\nFrom here on I\'ll comment less on typos.\n\nMiddle of page 2, point (i): this is the only place it is argued/asserted that the discriminator set should contain essentially everything?  I think this needs a much more serious justification.\n\nSection 1.1: Lebegure -> Lebesgue.\n\nPage 4, vicinity of equation 5: there should really be a mention that none of these universal approximation results give a meaningful bound on the size of the network (the bound given by Barron\'s work, while nice, is still massive).\n\nStart of section 3.  To be clear, while one can argue that the Lipschitz-1 constraint has a regularization effect, the reason it was originally imposed is to match the Kantorovich duality for Wasserstein_1.  Moreover I\'ll say this is another instance of the paper treating the discriminator set as irrelevant other than how close it is to being dense in all bounded measurable functions.', 'The authors provide an insight into the discriminative and generalizable aspect of the discriminator in GANs. They show that the richer discriminator set to enhance the discrimination power of the set while reducing the generalization bound. These facts are intuitive, but they made a careful analysis of it.\n\nThe authors provide more realistic analysis of discriminators by relaxing the constraint on discriminator set to have a richer closure of linear span instead of being rich by itself which is suitable for neural networks.\n\nThey analyze the weak convergence of probability measure under neural distance and generalize it to the other distances by bounding the neural distance.\n\nFor the generalization, they follow the standard generalization procedure and techniques while carefully adapt it to their setting.\n\nGenerally, I like the way the authors advertise their results, but it might be a bit oversold, especially for readers with theory background.\n\nThe authors made a good job in clarifying what is new and what is borrowed from previous work which makes this paper more interesting and easy to read.\n\nSince the current work is a theoretical work, being over 8 pages is acceptable, but since the section 4 is mostly based on the previous contributions, the authors might consider to have it in the appendix.']","[-20, -70, 70]","[50, 20, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('well written', 'clearly motivated', 'certainly interesting'), they also express several major criticisms. The reviewer suggests the authors are 'overselling the results' and points out multiple areas where the paper's contributions are less novel or significant than claimed. They even suggest removing an entire section. However, the tone isn't entirely negative, as they do recognize some novel contributions. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, even when critiquing. They use phrases like 'In my opinion' and 'I would suggest', which soften the criticisms. They also provide detailed explanations for their critiques and offer constructive suggestions. The presence of both positive and negative comments, delivered in a professional manner, indicates a balanced and courteous review."", ""The sentiment score is -70 because the reviewer expresses significant problems with the paper, including a major flaw in calculations (point A), lack of novel contribution (point B), and questionable assertions (point C). The reviewer also mentions numerous small errors and typos, suggesting a lack of proofreading. However, the score is not at the extreme negative end as the reviewer does provide some neutral analysis of the paper's content. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'Unfortunately, I find significant problems' and 'I will conclude with typos and minor remarks' which soften the criticism. The reviewer also provides detailed explanations for their critiques, which is a courteous approach. However, some phrases like 'I'm not exactly blown away' and 'nothing more than immediate corollaries' have a slightly dismissive tone, preventing a higher politeness score."", ""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, using phrases like 'I like the way the authors advertise their results' and 'The authors made a good job'. They also praise specific aspects of the work, such as the 'careful analysis' and the clarity in distinguishing new contributions. The score is not higher because there is a slight criticism about potentially overselling results.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout. They offer praise where due and frame their single criticism gently ('it might be a bit oversold'). The reviewer also provides constructive suggestions, such as considering moving a section to the appendix, which is presented as a polite recommendation rather than a demand. The tone is consistently courteous and academic, without any harsh or rude language.""]"
"['This paper proposes a novel reinforcement learning algorithm (« The Reactor ») based on the combination of several improvements to DQN: a distributional version of Retrace, a policy gradient update rule called beta-LOO aiming at variance reduction, a variant of prioritized experience replay for sequences, and a parallel training architecture. Experiments on Atari games show a significant improvement over prioritized dueling networks in particular, and competitive performance compared to Rainbow, at a fraction of the training time.\n\nThere are definitely several interesting and meaningful contributions in this submission, and I like the motivations behind them. They are not groundbreaking (essentially extending existing techniques) but are still very relevant to current RL research.\n\nUnfortunately I also see it as a step back in terms of comparison to other algorithms. The recent Rainbow paper finally established a long overdue clear benchmark on Atari. We have seen with the « Deep Reinforcement Learning that Matters » paper how important (and difficult) it is to properly compare algorithms on deep RL problems. I assume that this submission was mostly written before Rainbow came out, and that comparisons to Rainbow were hastily added just before the ICLR deadline: this would explain why they are quite limited, but in my opinion it remains a major issue, which is the main reason why I am advocating for rejection.\n\nMore precisely, focusing on the comparison to Rainbow which is the main competitor here, my concerns are the following:\n- There is almost no discussion on the differences between Reactor and Rainbow (actually the paper lacks a « related work » section). In particular Rainbow also uses a version of distributional multi-step, which as far as I can tell may not be as well motivated (from a mathematical point of view) as the one in this submission (since it does not correct for the « off-policyness » of the replay data), but still seems to work well on Atari.\n- Rainbow is not distributed. This was a deliberate choice by its authors to focus on algorithmic comparisons. However, it seems to me that it could benefit from a parallel training scheme like Reactor’s. I believe a comparison between Reactor and Rainbow needs to either have them both parallelized or none of them (especially for a comparison on time efficiency like in Fig. 2)\n- Rainbow uses the traditional feedforward DQN architecture while Reactor uses a recurrent network. It is not clear to which extent this has an impact on the results.\n- Rainbow was stopped at 200M steps, at which point it seems to be overall superior to Reactor at 200M steps. The results as presented here emphasize the superiority of Reactor at 500M steps, but a proper comparison would require Rainbow results at 500M steps as well.\n\nIn addition, although I found most of the paper to be clear enough, some parts were confusing to me, in particular:\n- « multi-step distributional Bellman operator » in 3.2: not clear exactly what the target distribution is. If I understand correctly this is the same as the Rainbow extension, but this link is not mentioned.\n- 3.4.1 (network architecture): a simple diagram in the appendix would make it much easier to understand (Table 3 is still hard to read because it is not clear which layers are connected together)\n- 3.3 (prioritized sequence replay): again a visual illustration of the partitioning scheme would in my opinion help clarify the approach\n\nA few minor points to conclude:\n- In eq. 6, 7 and the rest of this section, A does not depend (directly) on theta so it should probably be removed to avoid confusion. Note also that using the letter A may not be best since A is used to denote an action in 3.1.\n- In 3.1: « Let us assume that for the chosen action A we have access to an estimate R(A) of Qπ(A) » => « unbiased estimate »\n- In last equation of p.5 it is not clear what q_i^n is\n- There is a lambda missing on p.6 in the equation showing that alphas are non-negative on average, just before the min\n- In the equation above eq. 12 there is a sum over « i=1 »\n- That same equation ends with some h_z_i that are not defined\n- In Fig. 2 (left) for Reactor we see one worker using large batches and another one using many threads. This is confusing.\n- 3.3 mentions sequences of length 32 but 3.4 says length 33.\n- 3.3 says tree operations are in O(n ln(n)) but it should be O(ln(n))\n- At very end of 3.3 it is not clear what « total variation » is.\n- In 3.4 please specify the frequency at which the learner thread downloads shared parameters and uploads updates\n- Caption of Fig. 3 talks about « changing the number of workers » for the left plot while it is in the right plot\n- The explanation on what the variants of Reactor (ND and 500M) mean comes after results are shown in Fig. 2.\n- Section 4 starts with Fig. 3 without explaining what the task is, how performance is measured, etc. It also claims that Distributional Retrace helps while this is not the case in Fig. 3 (I realize it is explained afterwards, but it is confusing when reading the sentence « We can also see... »). Finally it says priorization is the most important component while the beta-LOO ablation seems to perform just the same.\n- Footnote 3 should say it is 200M observations except for Reactor 500M\n- End of 4.1: « The algorithms that we compare Reactor against are » => missing ACER, A3C and Rainbow\n- There are two references for « Sample efficient actor-critic with experience replay »\n- I do not see the added benefit of the Elo computation. It seems to convey essentially the same information as average rank.\n\nAnd a few typos:\n- Just above 2.1.3: « increasing » => increasingly\n- In 3.1: « where V is a baseline that depend » => depends\n- p.7: « hight » => high, and « to all other sequences » => of all other sequences\n- Double parentheses in Bellemare citation at beginning of section 4\n- Several typos in appendix (too many to list)\n\nNote: I did not have time to carefully read Appendix 6.3 (contextual priority tree)\n\nEdit after revision: bumped score from 5 to 7 because (1) authors did many improvements to the paper, and (2) their explanations shed light on some of my concerns', 'This paper proposes a novel reinforcement learning algorithm containing several contributions made by the authors: 1) a policy gradient algorithm that uses value function estimates to improve the policy gradient, 2) a distributed multi-step off-policy algorithm to estimate the value function, 3) an experience replay buffer mechanism that can handle sequences and (4) a distributed architecture, where threads are dedicated to either learning or interracting with the environment. Most contributions consist in improvements to handle multi-step trajectories instead of single step transitions. The resulting algorithm is evaluated on the ATARI domain and shown to outperform other similar algorithms, both in terms of score and training time. Ablation studies are also performed to study the interest of the 4 contributions. \n\nI find the paper interesting. It is also well written and reasonably clear. The experiments are large, although I was disappointed that PPO was not included in the evaluation, as this algorithm also trains much faster than other algorithms.\n\nquality\n+ several contributions\n+ impressive experiments\n\nclarity\n- I found the replay buffer not as clear as the other parts of the paper.\n. run time comparison: source of the code for the baseline methods?\n+ ablation study showing the merits of the different contributions\n- Methods not clearly labeled. For example, what is the difference between Reactor and Reactor 500M?\n\noriginality\n+ 4 contributions\n\nsignificance\n+ important problem, very active area of research\n+ comparison to very recent algorithms\n- but no PPO in the evaluation', 'This paper presents a new reinforcement learning architecture called Reactor by combining various improvements in\ndeep reinforcement learning algorithms and architectures into a single model. The main contributions of the paper\nare to achieve a better bias-variance trade-off in policy gradient updates, multi-step off-policy updates with\ndistributional RL, and prioritized experience replay for transition sequences. The different modules are integrated\nwell and the empirical results are very promising. The experiments (though limited to Atari) are well carried out and\nthe evaluation is performed on both sample efficiency and training time.\n\nPros:\n1. Nice integration of several recent improvements in deep RL, along with a few novel tricks to improve training.\n2. The empirical results on 57 Atari games are impressive, in terms of final scores as well as real-time training speed.\n\nCons:\n1. Reactor is still less sample-efficient than Rainbow, with significantly lower scores after 200M frames. While the\nreactor trains much faster, it does use more parallel compute, so the comparison with Rainbow on wall clock time is\n not entirely fair. Would a distributed version of Rainbow perform better in this respect?\n2. Empirical comparisons are restricted to the Atari domain. The conclusions of the paper will be much stronger if\nresults are also shown on other environments like Mujoco/Vizdoom/Deepmind Lab.\n3. Since the paper introduces a few new ideas like prioritized sequence replay, it would help if a more detailed analysis\n was performed on the impact of these individual schemes, even if in a model simpler than the Reactor. For instance, one could investigate the impact of prioritized sequence replay in models like multi-step DQN or recurrent DQN. This will help us understand  the impact of each of these ideas in a more comprehensive fashion.\n\n\n']","[20, 60, 60]","[60, 70, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges 'several interesting and meaningful contributions' and likes the motivations behind them. However, they also express significant concerns, particularly about comparisons to other algorithms, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. They use phrases like 'Unfortunately I also see' and 'In my opinion' to soften critiques. The reviewer provides detailed, specific feedback and suggestions for improvement, which is helpful and courteous. The tone remains professional and objective throughout, avoiding harsh or personal criticism."", ""The sentiment score is 60 (positive) because the reviewer finds the paper 'interesting' and 'well written', and acknowledges several positive aspects like 'impressive experiments' and 'several contributions'. However, it's not extremely positive due to some criticisms, such as the lack of PPO in the evaluation and clarity issues with the replay buffer. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism alongside praise. They use phrases like 'I find' and 'I was disappointed' to express personal opinions without being harsh. The reviewer also balances positive and negative points, showing a fair and considerate approach."", ""The sentiment score is 60 (positive) because the reviewer begins by highlighting the paper's contributions and describes the results as 'very promising' and 'impressive'. They provide a balanced view with both pros and cons, but the overall tone is more positive than negative. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'nice integration' and 'would help if' which maintain a courteous tone. The reviewer also provides specific suggestions for improvement without being harsh or dismissive, indicating a polite and professional approach to the review.""]"
"['This paper proposes a method for learning parsers for context-free languages. They demonstrate that this achieves perfect accuracy on training and held-out examples of input/output pairs for two synthetic grammars. In comparison, existing approaches appear to achieve little to no generalization, especially when tested on longer examples than seen during training.\n\nThe approach is presented very thoroughly. Details about the grammars, the architecture, the learning algorithm, and the hyperparameters are clearly discussed, which is much appreciated. Despite the thoroughness of the task and model descriptions, the proposed method is not well motivated. The description of the relatively complex two-phase reinforcement learning algorithm is largely procedural, and it is not obvious how necessary the individual pieces of the algorithm are. This is particularly problematic because the only empirical result reported is that it achieves 100% accuracy. Quite a few natural questions left unanswered, limiting what readers can learn from this paper, e.g.\n- How quickly does the model learn? Is there a smooth progression that leads to perfect generalization?\n- Presumably the policy learned in Phase 1 is a decent model by itself, since it can reliably find candidate traces. How accurate is it? What are the drawbacks of using that instead of the model from the second phase? Are there systematic problems, such as overfitting, that necessitate a second phase?\n- How robust is the method to hyperparameters and multiple initializations? Why choose F = 10 and K = 3? Presumably, there exists some hyperparameters where the model does not achieve 100% test accuracy, in which case, what are the failure modes?\n\nOther misc. points:\n- The paper mentions that ""the training curriculum is very important to regularize the reinforcement learning process."" Unless I am misunderstanding the experimental setup, this is not supported by the result, correct? The proposed method achieves perfect accuracy in every condition.\n- The reimplementations of the methods from Grefenstette et al. 2015 have surprisingly low training accuracy (in some cases 0% for Stack LSTM and 2.23% for DeQueue LSTM). Have you evaluated these reimplementations on their reported tasks to tease apart differences due to varying tasks and differences due to varying implementations?', 'This paper presents a reinforcement learning based approach to learn context-free\nparsers from pairs of input programs and their corresponding parse trees. The main\nidea of the approach is to learn a neural controller that operates over a discrete\nspace of programmatic actions such that the controller is able to produce the\ndesired parse trees for the input programs. The neural controller is trained using \na two-phase reinforcement learning approach where the first phase is used to find\na set of candidate traces for each input-output example and the second phase is \nused to find a satisfiable specification comprising of 1 unique trace per example\nsuch that there exists a program that is consistent with all the traces. The \napproach is evaluated on two datasets comprising of learning parsers for an \nimperative WHILE language and a functional LAMBDA language. The results show that\nthe proposed approach is able to achieve 100% generalization on test sets with \nprograms upto 100x longer than the training programs, while baseline approaches \nsuch as seq2seq and stack LSTM do not generalize at all.\n\nThe idea to decompose the synthesis task into two sub-tasks of first learning\na set of individual traces for each example, and then learning a program consistent\nwith a satisfiable subset of traces is quite interesting and novel. The use of \nreinforcement learning in the two phases of finding candidate trace sets with \ndifferent reward functions for different operators and searching for a satisfiable \nsubset of traces is also interesting. Finally, the results leading to perfect \ngeneralization on parsing 100x longer input programs is also quite impressive.\n\nWhile the presented results are impressive, a lot of design decisions such as \ndesigning specific operators (Call, Reduce,..) and their specific semantics seem\nto be quite domain-specific for the parsing task. The comparison with general \napproaches such as seq2seq and stack LSTM might not be that fair as they are \nnot restricted to only those operators and this possibly also explains the low \ngeneralization accuracies. Can the authors comment on the generality of the \npresented approach to some other program synthesis tasks?\n\nFor comparison with the baseline networks such as seq2seq and stack-LSTM, what \nhappens if the number of training examples is 1M (say programs upto size 100)? \n10k might be too small a number of training examples and these networks can \neasily overfit such a small dataset.\n\nThe paper mentions that developing a parser can take upto 2x/3x more time than \ndeveloping the training set. How large were the 150 examples that were used for\ntraining the models and were they hand-designed or automatically generated by a\nparsing algorithm? Hand generating parse trees for complex expressions seems to\nbe more tedious and error-prone that writing a modular parser.\n\nThe reason there are only 3 to 5 candidate traces per example is because the training\nexamples are small? For longer programs, I can imagine there can be thousands of bad\ntraces as it only needs one small mistake to propagate to full traces. Related to this\nquestion, what happens to the proposed approach if it is trained with 1000 length programs?\n\nWhat is the intuition behind keeping M1, M2 and M3 constants? Shouldn’t they be adaptive\nvalues with respect to the number of candidate traces found so far? \n\nFor phase-1 of learning candidate traces, what happens if the algorithm was only using the \noutside loop (M2) and performing REINFORCE without the inside loop?\n\nThe current paper presentation is a bit too dense to clearly understand the LL machine \nmodel and the two-phase algorithm. A lot of important details are currently in the\nappendix section with several forward references. I would suggest moving Figure 3 \nfrom appendix to the main paper, and also add a concrete example in section 4 to \nbetter explain the two-phase strategy.\n\n', 'Summary:\nI thank the authors for their update and clarifications.  They have addressed my concerns, and I will keep my score as it is.\n\n-----------------------------------------------------------------------\nThe authors present a system that parses DSL expressions into syntax trees when trained using input-output examples. Their approach is based around LSTMs predicting a sequence of program-like instructions/arguments, and they argue that their work is an illustration of how we should approach synthesis of complex algorithms using neural techniques.\n\nOverall I liked this paper: \nThe authors provide a frank view on the current state of neural program synthesis, which I am inclined to agree with: (1) existing neural program synthesis has only ever worked on ‘trivial’ problems, and (2) training program synthesizers is hard, but providing execution traces in the training data is not a practical solution. I am somewhat convinced that the task considered in this paper is not trivial (so the authors do not obviously fall into trap (1) ), and I am convinced that the authors’ two-phase reinforcement learning solution to (2) is an interesting approach.\nMy score reflects the fact that this paper seems like a solid piece of work: The task is difficult, the solution interesting and the results are favourable.\n\nHowever, I would like the authors to clarify the following points:\n1.\tIn the inner loop of Algorithm 1, it looks like Net_in is updated M1 times, and a candidate trace is only stored if arguments that generate an exact match with the ground truth tree are found. Since M1 = 20, I am surprised that an exact match can be generated with so few samples/updates. Similarly, I am surprised that the appendix mentions that only 1000 samples in the outer loop are required to find an exact match with the instruction trace. Could you clarify that I am reading this correctly and perhaps suggest intuition for why this method is so efficient. What is the size of the search space of programs that your LL machine can run? Should I conclude that the parsing task is actually not as difficult as it seems, or am I missing something?\n2.\tThe example traces in the appendix (fig 3, 6) only require 9 instructions. I’m guessing that these short programs are just for illustration – could you provide an example execution trace for one of the programs in the larger test sets? I assume that these require many more instructions & justify your claims of difficulty.\n3.\tAs a technique for solving the parsing problem, this method seems impressive. However, the authors present the technique as a general approach to synthesizing complex programs. I feel that the authors need to either justify this bold assertion with least one additional example task or tone down their claims. In particular, I would like to see performance on a standard benchmarking task e.g. the RobustFill tasks. I want to know whether (1) the method works across different tasks and (2) the baselines reproduce the expected performance on these benchmark tasks. \n4.\tRelated to the point above, the method seems to perform almost too well on the task it was designed for – we miss out on a chance to discuss where the model fails to work.\n\nThe paper is reasonably clear. It took a couple of considered passes to get to my current understanding of Algorithm 1, and I found it essential to refer to the appendix to understand LL machines and the proposed method. In places, the paper is somewhat verbose, but since many ideas are presented, I did not feel too annoyed by the fact that it (significantly) overshoots the recommended 8 page limit.\n\n']","[-20, 60, 70]","[60, 70, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The approach is presented very thoroughly'), they raise several significant concerns and unanswered questions that limit the paper's impact. The reviewer points out lack of motivation, unclear necessity of algorithm components, and missing empirical analyses. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positives ('much appreciated'), and frames criticisms as questions or suggestions rather than direct attacks. They maintain a professional tone while still clearly communicating areas for improvement."", ""The sentiment score is 60 (positive) because the reviewer expresses appreciation for the novelty and effectiveness of the approach, describing the results as 'impressive' and the idea as 'interesting'. However, they also raise several questions and suggest improvements, which prevents the score from being higher. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the strengths of the work. They use phrases like 'Can the authors comment on...' and 'I would suggest...', which are polite ways of offering feedback. The review maintains a professional and constructive tone throughout, without any rude or dismissive language."", ""Sentiment score (70): The reviewer expresses a generally positive sentiment towards the paper. They state 'Overall I liked this paper' and mention that it's 'a solid piece of work' with a 'difficult' task, 'interesting' solution, and 'favourable' results. However, they also raise several points for clarification, which prevents the score from being higher. Politeness score (80): The language used is consistently polite and professional. The reviewer thanks the authors for their update, uses phrases like 'I would like the authors to clarify' instead of making demands, and acknowledges the paper's strengths before presenting criticisms. The tone is constructive and respectful throughout, though not excessively formal or deferential, hence the high but not perfect score.""]"
"['This paper proposes a clever new test based on the birthday paradox for measuring diversity in generated samples. The main goal is to quantify mode collapse in state-of-the-art generative models. The authors also provide a specific theoretical construction that shows bidirectional GANs cannot escape specific cases of mode collapse.\nUsing the birthday paradox test, the experiments show that GANs can learn and consistently reproduce the same examples, which are not necessarily exactly the same as training data (eg. the triplets in Figure 1).\nThe results are interpreted to mean that mode collapse is strong in a number of state-of-the-art generative models.\nBidirectional models (ALI, BiGANs) however demonstrate significantly higher diversity that DCGANs and MIX+DCGANs.\nFinally, the authors verify empirically the hypothesis that diversity grows linearly with the size of the discriminator.\n\nThis is a very interesting area and exciting work. The main idea behind the proposed test is very insightful. The main theoretical contribution stimulates and motivates much needed further research in the area. In my opinion both contributions suffer from some significant limitations. However, given how little we know about the behavior of modern generative models, it is a good step in the right direction.\n\n\n1. The biggest issue with the proposed test is that it conflates mode collapse with non-uniformity. The authors do mention this issue, but do not put much effort into evaluating its implications in practice, or parsing Theorems 1 and 2. My current understanding is that, in practice, when the birthday paradox test gives a collision I have no way of knowing whether it happened because my data distribution is modal, or because my generative model has bad diversity. Anecdotally, real-life distributions are far from uniform, so this should be a common issue. I would still use the test as a part of a suite of measurements, but I would not solely rely on it. I feel that the authors should give a more prominent disclaimer to potential users of the test.\n\n2. Also, given how mode collapse is the main concern, it seems to me that a discussion on coverage is missing. The proposed test is a measure of diversity, not coverage, so it does not discriminate between a generator that produces all of its samples near some mode and another that draws samples from all modes of the true data distribution. As long as they yield collisions at the same rate, these two generative models are ‘equally diverse’. Isn’t coverage of equal importance?\n\n3. The other main contribution of the paper is Theorem 3, which shows—via a very particular construction on the generator and encoder—that bidirectional GANs can also suffer from serious mode collapse. I welcome and are grateful for any theory in the area. This theorem might very well capture the underlying behavior of bidirectional GANs, however, being constructive, it guarantees nothing in practice. In light of this, the statement in the introduction that “encoder-decoder training objectives cannot avoid mode collapse” might need to be qualified. In particular, the current statement seems to obfuscate the understanding that training such an objective would typically not result into the construction of Theorem 3.', 'The article ""Do GANs Learn the Distribution? Some Theory and Empirics"" considers the important problem of quantifying whether the distributions obtained from generative adversarial networks come close to the actual distribution of images. The authors argue that GANs in fact generate the distributions with fairly low support.\n\nThe proposed approach relies on so-called birthday paradox which allows to estimate the number of objects in the support by counting number of matching (or very similar) pairs in the generated sample. This test is expected to experimentally support the previous theoretical analysis by Arora et al. (2017). The further theoretical analysis is also performed showing that for encoder-decoder GAN architectures the distributions with low support can be very close to the optimum of the specific (BiGAN) objective.\n\nThe experimental part of the paper considers the CelebA and CIFAR-10 datasets. We definitely see many very similar images in fairly small sample generated. So, the general claim is supported. However, if you look closely at some pictures, you can see that they are very different though reported as similar. For example, some deer or truck pictures. That\'s why I would recommend to reevaluate the results visually, which may lead to some change in the number of near duplicates and consequently the final support estimates.\n\nTo sum up, I think that the general idea looks very natural and the results are supportive. On theoretical side, the results seem fair (though I didn\'t check the proofs) and, being partly based on the previous results of Arora et al. (2017), clearly make a step further.', 'The paper adds to the discussion on the question whether Generative Adversarial Nets (GANs) learn the target distribution. Recent theoretical analysis of GANs by Arora et al. show that of the discriminator capacity of is bounded, then there is a solution the closely meets the objective but the output distribution has a small support. The paper attempts to estimate the size of the support for solutions produced by typical GANs experimentally. The main idea used to estimate the support is the Birthday theorem that says that with probability at least 1/2, a uniform sample (with replacement) of size S from a set of  N elements will have a duplicate given S > \\sqrt{N}. The suggested plan is to manually check for duplicates in a sample of size s and if duplicate exists, then estimate the size of the support to be s^2. One should note that the birthday theorem assumes uniform sampling.  In the revised versions, it has been clarified that the tested distribution is not assumed to be uniform but the distribution has ""effectively"" small support size using an indistinguishability notion. Given this method to estimate the size of the support, the paper also tries to study the behaviour of estimated support size with the discriminator capacity. Arora et al. showed that the output support size has nearly linear dependence on the discriminator capacity. Experiments are conducted in this paper to study this behaviour by varying the discriminator capacity and then estimating the support size using the idea described above. A result similar to that of Arora et al. is also given for the special case of Encoder-Decoder GAN.\n\nEvaluation: \nSignificance: The question whether GANs learn the target distribution is important and any  significant contribution to this discussion is of value. \n\nClarity: The paper is written well and the issues raised are well motivated and proper background is given. \n\nOriginality: The main idea of trying to estimate the size of the support using a few samples by using birthday theorem seems new. \n\nQuality: The main idea of this work is to give a estimation technique for the support size for the output distribution of GANs. \n']","[50, 60, 60]","[80, 50, 80]","[""The sentiment score is 50 (moderately positive) because the reviewer describes the work as 'very interesting' and 'exciting', and acknowledges it as 'a good step in the right direction'. However, they also mention 'significant limitations', which tempers the positivity. The politeness score is 80 (quite polite) due to the use of respectful language throughout, such as 'very interesting area', 'exciting work', and 'I welcome and are grateful for any theory'. The reviewer also frames criticisms constructively, using phrases like 'I feel that the authors should' rather than making blunt demands. The tone remains professional and courteous even when pointing out limitations."", ""The sentiment score is 60 (positive) because the reviewer expresses overall approval of the paper's approach and results, using phrases like 'important problem', 'general idea looks very natural', and 'results are supportive'. They also note that the work 'clearly make[s] a step further' in the field. However, it's not extremely positive due to some critiques, particularly about the visual evaluation of image similarity. The politeness score is 50 (somewhat polite) because the reviewer uses respectful language throughout and frames their critique constructively ('I would recommend to reevaluate'). They also acknowledge the value of the work while offering suggestions for improvement. The tone is professional and objective, without being overly formal or deferential."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's significance, clarity, and originality. They state that the question addressed is important, the paper is well-written, and the main idea seems new. However, they don't express extreme enthusiasm, which prevents a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths without harsh criticism. They provide constructive feedback and use phrases like 'well motivated' and 'proper background is given,' which contribute to a polite tone. The absence of negative or critical comments also supports the high politeness score.""]"
"['This paper studies the problem of learning one-hidden layer neural networks and is a theory paper. A well-known problem is that without good initialization, it is not easy to learn the hidden parameters via gradient descent. This paper establishes an interesting connection between least squares population loss and Hermite polynomials. Following from this connection authors propose a new loss function. Interestingly, they are able to show that the loss function globally converges to the hidden weight matrix. Simulations confirm the findings.\n\nOverall, pretty interesting result and solid contribution. The paper also raises good questions for future works. For instance, is designing alternative loss function useful in practice? In summary, I recommend acceptance. The paper seems rushed to me so authors should polish up the paper and fix typos.\n\nTwo questions:\n1) Authors do not require a^* to recover B^*. Is that because B^* is assumed to have unit length rows? If so they should clarify this otherwise it confuses the reader a bit.\n2) What can be said about rate of convergence in terms of network parameters? Currently a generic bound is employed which is not very insightful in my opinion.\n\n', 'This paper proposes a tensor factorization-type method for learning one hidden-layer neural network. The most interesting part is the Hermite polynomial expansion of the activation function. Such a decomposition allows them to convert the population risk function as a fourth-order orthogonal tensor factorization problem. They further redesign a new formulation for the tensor decomposition problem, and show that the new formulation enjoys the nice strict saddle properties as shown in Ge et al. 2015. At last, they also establish the sample complexity for recovery.\n\nThe organization and presentation of the paper need some improvement. For example, the authors defer many technical details. To make the paper accessible to the readers, they could provide more intuitions in the first 9 pages.\n\nThere are also some typos: For example, the dimension of a is inconsistent. In the abstract, a is an m-dimensional vector, and on Page 2, a is a d-dimensional vector. On Page 8, P(B) should be a degree-4 polynomial of B.\n\nThe paper does not contains any experimental results on real data.', ""[ =========================== REVISION ===============================================================]\nI am satisfied with the answers to my questions. The paper still needs some work on clarity, and authors defer the changes to the next version (but as I understood, they did no changes for this paper as of now), which is a bit frustrating. However I am fine accepting it.\n[ ============================== END OF REVISION =====================================================]\n\nThis paper concerns with addressing the issue of SGD not converging to the optimal parameters on one hidden layer network for a particular type of data and label (gaussian features, label generated using a particular function that should be learnable with neural net). Authors demonstrate empirically that this particular learning problem is hard for SGD with l2 loss (due to apparently bad local optima) and suggest two ways of addressing it, on top of the known way of dealing with this problem (which is overparameterization). First is to use a new activation function, the second is by designing a new objective function that has only global optima and which can be efficiently learnt with SGD\n\nOverall the paper is well written. The authors first introduce their suggested loss function and then go into details about what inspired its creation. I do find interesting the formulation of population risk in terms of tensor decomposition, this is insightful\n\nMy issues with the paper are as follows:\n- The loss function designed seems overly complicated. On top of that authors notice that to learn with this loss efficiently, much larger batches had to be used. I wonder how applicable this in practice - I frankly didn't see insights here that I can apply to other problems that don't fit into this particular narrowly defined framework\n- I do find it somewhat strange that no insight to the actual problem is provided (e.g. it is known empirically but there is no explanation of what actually happens and there is a idea that it is due to local optima), but authors are concerned with developing new loss function that has provable properties about global optima. Since it is all empirical, the first fix (activation function) seems sufficient to me and new loss is very far-fetched. \n- It seems that changing activation function from relu to their proposed one fixes the problem without their new loss, so i wonder whether it is a problem with relu itself and may be other activations funcs, like sigmoids will not suffer from the same problem\n- No comparison with overparameterization in experiments results is given, which makes me wonder why their method is better.\n\nMinor: fix margins in formula 2.7. \n\n\n""]","[70, 50, 20]","[60, 60, 50]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, recommending acceptance and describing it as an 'interesting result and solid contribution.' They mention that the paper raises good questions for future work, which is also positive. The score is not higher because the reviewer does point out some areas for improvement, such as polishing the paper and fixing typos. The politeness score is 60 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticism. They phrase their concerns as questions rather than direct criticisms, which is a polite approach. The reviewer also balances their critique with positive comments. However, the score is not higher as the review maintains a professional tone rather than being overtly courteous."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the interesting aspects of the paper, such as the Hermite polynomial expansion and the tensor factorization approach. They also mention the paper's contributions to sample complexity for recovery. However, the reviewer points out areas for improvement, including organization and presentation, which balances out the positive aspects.\n\nThe politeness score is 60 (moderately polite) because the reviewer uses neutral language and offers constructive criticism. They acknowledge the paper's strengths before pointing out areas for improvement. The reviewer's tone is professional and respectful, using phrases like 'need some improvement' and 'could provide more intuitions' rather than harsh criticism. The mention of typos and lack of experimental results is presented factually without negative language."", ""The sentiment score is slightly positive (20) because the reviewer begins by stating they are 'satisfied with the answers' and are 'fine accepting' the paper, despite some frustrations. They also mention the paper is 'well written' and find some aspects 'interesting' and 'insightful'. However, they raise several issues and criticisms, which temper the overall positive sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I wonder', 'I find it somewhat strange', and 'it seems that' to express concerns politely rather than making harsh criticisms. They also acknowledge positive aspects of the paper before presenting their issues. The review doesn't contain any rude or overly negative language, but it also doesn't go out of its way to be exceptionally polite, hence the moderate positive score.""]"
"['This paper proposes a method for learning from noisy labels, particularly focusing on the case when data isn\'t redundantly labeled (i.e. the same sample isn\'t labeled by multiple non-expert annotators). The authors provide both theoretical and experimental validation of their idea. \n\nPros:\n+ The paper is generally very clearly written. The motivation, notation, and method are clear.\n+ Plentiful experiments against relevant baselines are included, validating both the no-redundancy and plentiful redundancy cases. \n+ The approach is a novel twist on an existing method for learning from noisy data. \n\nCons: \n- All experiments use simulated workers; this is probably common but still not very convincing.\n- The authors missed an important related work which studies the same problem and comes up with a similar conclusion: Lin, Mausam, and Weld. ""To re (label), or not to re (label)."" HCOMP 2014.\n- The authors should have compared their approach to the ""base"" approach of Natarajan et al. \n- It seems too simplistic too assume all workers are either hammers or spammers; the interesting cases are when annotators are neither of these.\n- The ResNet used for each experiment is different, and there is no explanation of the choice of architecture.\n\nQuestions: \n- How would the model need to change to account for example difficulty? \n- Why are Joulin 2016, Krause 2016 not relevant?\n- Best to clarify what the weights in the weighted sum of Natarajan are. \n- ""large training error on wrongly labeled examples"" -- how do we know they are wrongly labeled, i.e. do we have a ground truth available apart from the crowdsourced labels? Where does this ground truth come from?\n- Not clear what ""Ensure"" means in the algorithm description.\n- In Sec. 4.4, why is it important that the samples are fresh?\n', 'The authors proposed a supervised learning algorithm for modeling label and worker quality. Further utilize it to study one of the important problems in crowdsourcing - How much redundancy is required in crowdsourcing and whether low redundancy with abundant noise examples lead to better labels.\n\nOverall the paper was well written. The motivation of the work is clearly explained and supported with relevant related work. The main contribution of the paper is in the bootstrapping algorithm which models the worker quality and labels in an iterative fashion. Though limited to binary classification, the paper proposed a theoretical framework extending the existing work on VC dimension to compute the upper bound on the risk. The authors also showed theoretically and empirically on synthetic data sets that the low redundancy and larger set of labels in crowdsourcing gives better results. \n\nMore detailed comments\n1. Instead of considering multi-class classification as one-vs-all binary classification, can you extend the theoretical guarantee on the risk to multi-class set up like Softmax which is widely used in research nowadays.\n2. Can you introduce the Risk -R in the paper before using it in Theorem 4.1\n3. Is there any limit on how many examples each worker has to label? Can you comment more on how to pick that value in real-world settings? Just saying sufficiently many (Section 4.2) is not sufficient.\n4. Under the experiments, different variations of Majority Vote, EM and Oracle correction were used as baselines. Can you cite the references and also add some existing state-of-the-art techniques mentioned in the related work section.\n5. For the experiments on synthetic datasets, workers are randomly sampled with replacements. Were the scores reported based on average of multiple runs. If yes, can you please report the error bars.\n6. For the MS-COCO, examples can you provide more detailed results as shown for synthetic datasets? Majority vote is a very weak baseline. \n\nFor the novel approach and the theoretical backing, I consider the paper to be a good one. The paper has scope for improvement.\n\n   ', 'This paper focuses on the learning-from-crowds problem when there is only one (or very few) noisy label per item. The main framework is based on the Dawid-Skene model. By jointly update the classifier weights and the confusion matrices of workers, the predictions of the classifier can help on the estimation problem with rare crowdsourced labels. The paper discusses the influence of the label redundancy both theoretically and empirically. Results show that with a fixed budget, it’s better to label many examples once rather than fewer examples multiple times.\n\nThe model and algorithm in this paper are simple and straightforward. However, I like the motivation of this paper and the discussion about the relationship between training efficiency and label redundancy. The problem of label aggregation with low redundancy is common in practice but hardly be formally analyzed and discussed. The conclusion that labeling more examples once is better can inspire other researchers to find more efficient ways to improve crowdsourcing.\n\nAbout the technique details, this paper is clearly written, but some experimental comparisons and claims are not very convincing. Here I list some of my questions:\n+About the MBEM algorithm, it’s better to make clear the difference between MBEM and a standard EM. Will it always converge? What’s its objective?\n+The setting of Theorem 4.1 seems too simple. Can the results be extended to more general settings, such as when workers are not identical?\n+When n = O(m log m), the result that \\epslon_1 is constant is counterintuitive, people usually think large redundancy r can bring benefits on estimation, can you explain more on this?\n+During CIFAR-10 experiments when r=1, each example only have one label. For the baselines weighted-MV and weighted-EM, they can only be directly trained using the same noisy labels. So can you explain why their performance is slightly different in most settings? Is it due to the randomly chosen procedure of the noisy labels?\n+For ImageNet and MS-COCO experiments with a fixed budget, you reduced the training set when increasing the redundancy, which is unfair. The reduction of performance could mainly cause by seeing fewer raw images, but not the labels. It’s better to train some semi-supervised model to make the settings more comparable.\n']","[20, 70, 50]","[60, 80, 80]","[""The sentiment score is slightly positive (20) because the review begins with a neutral description of the paper and lists both pros and cons. The pros are substantial (clear writing, plentiful experiments, novel approach), but there are also several cons and questions raised. This balanced approach suggests a mildly positive sentiment overall. The politeness score is moderately high (60) because the reviewer uses professional and respectful language throughout. They acknowledge the paper's strengths and frame criticisms as constructive feedback or questions rather than harsh judgments. The use of bullet points for pros and cons, and the inclusion of specific questions, demonstrates a thoughtful and considerate approach to the review process."", ""The sentiment score is 70 (positive) because the reviewer starts by praising the paper as 'well written' and notes that the motivation is 'clearly explained'. They describe the paper's contribution as 'main' and highlight both theoretical and empirical strengths. While they suggest some improvements, they conclude by calling it a 'good' paper. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames suggestions as questions or polite requests (e.g., 'Can you...?'). They also acknowledge the paper's strengths before offering critiques. The tone is professional and courteous throughout, without any harsh or rude comments."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses appreciation for the paper's motivation and discussion, stating 'I like the motivation of this paper' and noting that the conclusion 'can inspire other researchers'. However, they also point out some limitations and areas for improvement, balancing the positive aspects. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, framing criticisms as questions or suggestions rather than direct criticisms. Phrases like 'It's better to' and 'Can you explain' demonstrate a constructive and polite approach to feedback. The reviewer also acknowledges positive aspects before presenting concerns, which is a polite review strategy.""]"
"['This paper studies the issue of truncated backpropagation for meta-optimization. Backpropagation through an optimization process requires unrolling the optimization, which due to computational and memory constraints, is typically restricted or truncated to a smaller number of unrolled steps than we would like.\n\nThis paper highlights this problem as a fundamental issue limiting meta-optimization approaches. The authors perform a number of experiments on a toy problem (stochastic quadratics) which is amenable to some theoretical analysis as well as a small fully connected network trained on MNIST.  \n\n(side note: I was assigned this paper quite late in the review process, and have not carefully gone through the derivations--specifically Theorems 1 and 2).\n\nThe paper is generally clear and well written.\n\nMajor comments\n-------------------------\nI was a bit confused why 1000 SGD+mom steps pre-training steps were needed. As far as I can tell, pre-training is not typically done in the other meta-optimization literature? The authors suggest this is needed because ""the dynamics of training are different at the very start compared to later stages"", which is a bit vague. Perhaps the authors can expand upon  this point?\n\nThe conclusion suggests that the difference in greedy vs. fully optimized schedule is due to the curvature (poor scaling) of the objective--but Fig 2. and earlier discussion talked about the noise in the objective as introducing the bias (e.g. from earlier in the paper, ""The noise in the problem adds uncertainty to the objective, resulting in failures of greedy schedule""). Which is the real issue, noise or curvature? Would running the problem on quadratics with different condition numbers be insightful?\n\nMinor comments\n-------------------------\nThe stochastic gradient equation in Sec 2.2.2 is missing a subscript: ""h_i"" instead of ""h""\n\nIt would be nice to include the loss curve for a fixed learning rate and momentum for the noisy quadratic in Figure 2, just to get a sense of how that compares with the greedy and optimized curves.\n\nIt looks like there was an upper bound constraint placed on the optimized learning rate in Figure 2--is that correct? I couldn\'t find a mention of the constraint in the paper. (the optimized learning rate remains at 0.2 for the first ~60 steps)?\n\nFigure 2 (and elsewhere): I would change \'optimal\' to \'optimized\' to distinguish it from an optimal curve that might result from an analytic derivation. \'Optimized\' makes it more clear that the curve was obtained using an optimization process.\n\nFigure 2: can you change the line style or thickness so that we can see both the red and blue curves for the deterministic case? I assume the red curve is hiding beneath the blue one--but it would be good to see this explicitly.\n\nFigure 4 is fantastic--it succinctly and clearly demonstrates the problem of truncated unrolls. I would add a note in the caption to make it clear that the SMD trajectories are the red curves, e.g.: ""SMD trajectories (red) during meta-optimization of initial effective ..."". I would also change the caption to use ""meta-training losses"" instead of ""training losses"" (I believe those numbers are for the meta-loss, correct?). Finally, I would add a colorbar to indicate numerical values for the different grayscale values.\n\nSome recent references that warrant a mention in the text:\n- both of these learn optimizers using longer numbers of unrolled steps:\nLearning gradient descent: better generalization and longer horizons, Lv et al, ICML 2017\nLearned optimizers that scale and generalize, Wichrowska et al, ICML 2017\n- another application of unrolled optimization:\nUnrolled generative adversarial networks, Metz et al, ICLR 2017\n\nIn the text discussing Figure 4 (middle of pg. 8) , ""which is obtained by using..."" should be ""which are obtained by using...""\n\nIn the conclusion, ""optimal for deterministic objective"" should be ""deterministic objectives""', 'The paper discusses the problems of meta optimization with small look-ahead: do small runs bias the results of tuning? The result is yes and the authors show how differently the tuning can be compared to tuning the full run. The Greedy schedules are far inferior to hand-tuned schedules as they focus on optimizing the large eigenvalues while the small eigenvalues can not be ""seen"" with a small lookahead. The authors show that this effect is caused by the noise in the obective function.\n\npro:\n- Thorough discussion of the issue with theoretical understanding on small benchmark functions as well as theoretical work\n- Easy to read and follow\n\ncons:\n-Small issues in presentation: \n* Figure 2 ""optimal learning rate"" -> ""optimal greedy learning rate"", also reference to Theorem 2 for increased clarity.\n* The optimized learning rate in 2.3 is not described. This reduces reproducibility.\n* Figure 4 misses the red trajectories, also it would be easier to have colors on the same (log?)-scale. \n  The text unfortunately does not explain why the loss function looks so vastly different\n  with different look-ahead. I would assume from the description that the colors are based\n  on the final loss values obtaine dby choosing a fixed pair of decay exponent and effective LR. \n\nTypos and notation:\npage 7 last paragraph: ""We train the all"" -> We train all\nnotation page 5: i find \\nabla_{\\theta_i} confusing when \\theta_i is a scalar, i would propose \\frac{\\partial}{\\partial \\theta_i}\npage 2: ""But this would come at the expense of long-term optimization process"": at this point of the paper it is not clear how or why this should happen. Maybe add a sentence regarding the large/Small eigenvalues?', 'This paper proposes a simple problem to demonstrate the short-horizon bias of the learning rate meta-optimization.\n\n- The idealized case of quadratic function the analytical solution offers a good way to understand how T-step look ahead can benefit the meta-algorithm.\n- The second part of the paper seems to be a bit disconnected to the quadratic function analysis. It would be helpful to understand if there is gap between gradient based meta-optimization and the best effort(given by the analytical solution)\n- Unfortunately, no guideline or solution is offered in the paper.\n\nIn summary, the idealized model gives a good demonstration of the problem itself. I think it might be of interest to some audiences in ICLR.']","[50, 50, 20]","[80, 70, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'generally clear and well written' and provides constructive feedback. They also praise Figure 4 as 'fantastic'. However, they do raise some concerns and questions, which prevents a higher positive score. The politeness score is 80 (quite polite) due to the reviewer's respectful tone throughout. They use phrases like 'I was a bit confused' and 'It would be nice to include' rather than making demands. They also offer suggestions and ask questions politely. The reviewer maintains a professional and courteous tone while providing both positive feedback and constructive criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer begins with a neutral summary of the paper's content, followed by a balanced list of pros and cons. The positive aspects ('thorough discussion', 'easy to read') are offset by several minor criticisms, resulting in a moderately positive overall sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They acknowledge the paper's strengths before pointing out areas for improvement, and frame their suggestions as recommendations rather than demands. The use of phrases like 'Small issues in presentation' and the detailed, helpful nature of the feedback further contribute to the polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's strengths, particularly in demonstrating the problem through an idealized model, and suggests it might be of interest to some ICLR audiences. However, the reviewer also points out some limitations, such as the disconnection between parts of the paper and the lack of guidelines or solutions offered. The politeness score is moderately positive (50) as the reviewer uses neutral language and offers constructive feedback without harsh criticism. The reviewer acknowledges the paper's merits while also suggesting areas for improvement in a respectful manner.""]"
"['This paper proposes a Laplace approximation to approximate the posterior distribution over the parameters of deep networks. \n\nThe idea is interesting and the realization of the paper is good. The idea builds upon previous work in scalable Gauss-Newton methods for optimization in deep networks, notably Botev et al., ICML 2017. In this respect, I think that the novelty in the current submission is limited, as the approximation is essentially what proposed in Botev et al., ICML 2017.  The Laplace approximation requires the Hessian of the posterior, so techniques developed for Gauss-Newton optimization can straightforwardly be applied to construct Laplace approximations.\n\nHaving said that, the experimental evaluation is quite interesting and in-depth. I think it would have been interesting to report comparisons with factorized variational inference (Graves, 2011) as it is a fairly standard and widely adopted in Bayesian deep learning. This would have been an interesting way to support the claims on the poor approximation offered by standard variational inference. \n\nI believe that the independence assumption across layers is a limiting factor of the proposed approximation strategy. Intuitively, changes in the weights in a given layer should affect the weights in other layers, so I would expect the posterior distribution over all the weights to reflect this through correlations across layers. I wonder how these results can be generalized to relax the independence assumption. \n\n', ""This paper proposes a novel scalable method for incorporating uncertainty estimate in neural networks, in addition to existing methods using, for example, variational inference and expectation propagation. The novelty is in extending the Laplace approximation introduced in MacKay (1992) using a Kronecker-factor approximation of the Hessian. The paper is well written and easy to follow. It provides extensive references to related works, and supports its claims with convincing experiments from different domains.\n\nPros:\n-A novel method in an important and interesting direction.\n-It is a prediction method, so can be applied on existing trained neural networks (however, see the first con).\n-Well-written with high clarity.\n-Extensive and convincing experiments.\n\nCons:\n-Although it is a predictive method, it's still worth discussing how this method relates to training. For example, I suspect it works better when the model is trained with second-order method, as the resulting Taylor approximation (eq. 2) of the log-likelihood function might have higher quality when both terms are explicitly used in optimisation.\n-The difference between using KFAC and KFRA is unclear, or should be better explained if they are identical in this context. Botev et al. 2017 reports they are slightly different in approximating the Gaussian Newton matrix.\n-Acronyms, even well-known, are better defined before using (e.g., EP, PSD).\n-Need more details of the optimisation method used in experiments, especially the last one."", 'This paper uses recent progress in the understanding and approximation of curvature matrices in neural networks to revisit a venerable area- that of Laplace approximations to neural network posteriors. The Laplace method requires two stages - 1) obtaining a point estimate of the parameters followed by 2) estimation of the curvature. Since 1) is close to common practice it raises the appealing possibility of adding 2) after the fact, although the prior may be difficult to interpret in this case. A pitfall is that the method needs the point estimate to fall in a locally quadratic bowl or to add regularisation to make this true. The necessary amount of regularisation can be large as reported in section 5.4.\n\nThe paper is generally well written. In particular the mathematical exposition attains good clarity. Much of the mathematical treatment of the curvature was already discussed by Martens and Grosse and Botev et al in previous works. The paper is generally well referenced. \n\nGiven the complexity of the method, I think it would have helped to submit the code in anonymized form at this point.There are also some experiments not there that would improve the contribution. Figure 1 should include a comparison to Hamiltonian Monte Carlo and the full Laplace approximation (It is not sufficient to point to experiments in Hernandez-Lobato and Adams 2015 with a different model/prior). The size of model and data would not be prohibitive for either of these methods in this instance. All that figure 1 shows at the moment is that the proposed approximation has smaller predictive variance than the fully diagonal variant of the method. \n\nIt would be interesting (but perhaps not essential) to compare the Laplace approximation to other scalable methods from the literature such as that of Louizos and Welling 2016 which uses also used matrix normal distributions. It is good that the paper includes a modern architecture with a more challenging dataset. It is a shame the method does not work better in this instance but the authors should not be penalized for reporting this. I think a paper on a probabilistic method should at some point evaluate log likelihood in a case where the test distribution is the same as the training distribution. This complements experiments where there is dataset shift and we wish to show robustness. I would be very interested to know how useful the implied marginal likelihoods of the approximation where, as suggested for further work in the conclusion.\n']","[-20, 80, 20]","[50, 70, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting idea and good realization, they also point out limitations in novelty and the approximation strategy. The reviewer states that 'the novelty in the current submission is limited' and questions the independence assumption across layers. However, they do praise the experimental evaluation as 'quite interesting and in-depth'. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positive aspects ('The idea is interesting', 'the experimental evaluation is quite interesting and in-depth') while offering constructive criticism. They use phrases like 'I think' and 'I believe' to soften their critiques, maintaining a professional and courteous tone."", ""The sentiment score is 80 (positive) because the review starts with a positive overview of the paper, highlighting its novelty, clarity, and convincing experiments. The reviewer lists more pros than cons and describes the paper as 'well written and easy to follow'. The cons are presented as constructive suggestions rather than severe criticisms. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering suggestions for improvement. The tone is professional and constructive, avoiding harsh criticism. The reviewer uses phrases like 'it's worth discussing' and 'need more details', which are polite ways of suggesting improvements."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's strengths (well-written, good mathematical clarity, well-referenced), they also point out several limitations and suggest additional experiments. The overall tone is constructive but with significant critiques. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms as suggestions for improvement rather than harsh judgments. They use phrases like 'I think it would have helped,' 'It would be interesting,' and 'It is good that' which contribute to a polite tone. Even when pointing out shortcomings, the reviewer does so in a considerate manner, such as 'It is a shame the method does not work better in this instance but the authors should not be penalized for reporting this.'""]"
"['The authors prove a generalization guarantee for deep\nneural networks with ReLU activations, in terms of margins of the\nclassifications and norms of the weight matrices.  They compare this\nbound with a similar recent bound proved by Bartlett, et al.  While,\nstrictly speaking, the bounds are incomparable in strength, the\nauthors of the submission make a convincing case that their new bound\nmakes stronger guarantees under some interesting conditions.\n\nThe analysis is elegant.  It uses some existing tools, but brings them\nto bear in an important new context, with substantive new ideas needed.\nThe mathematical writing is excellent.\n\nVery nice paper.\n\nI guess that networks including convolutional layers are covered by\ntheir analysis.  It feels to me that these tend to be sparse, but that\ntheir analysis still my provides some additional leverage for such\nlayers.  Some explicit discussion of convolutional layers may be\nhelpful.  ', 'This paper combines a simple PAC-Bayes argument with a simple perturbation analysis (Lemma 2) to get a margin based generalization error bound for ReLU neural networks (Theorem 1) which depends on the product of the spectral norms of the layer parameters as well as their Frobenius norm. The main contribution of the paper is the simple proof technique to derive Theorem 1, much simpler than the one use in the very interesting work [Bartlett et al. 2017] (appearing at NIPS 2017) which got an analogous bound but with a dependence on the l1-norm of the layers instead of the Frobenius norm. The authors make a useful comparison between these bounds in Section 3 showing that none is dominating the others, but still analyzing their properties in terms of structural properties of the weight matrices.\n\nI enjoyed reading this paper. One could think that it makes a somewhat incremental contribution with respect to the more complete work (both theory and practice) from [Bartlett et al. 2017]. Nevertheless, the simplicity and elegance of the proof as well as the result might be useful for the community to get progress on the theoretical analysis of NNs.\n\nThe paper is well written, though I make some suggestions for the camera ready version below to improve clarity.\n\nI verified most of the math.\n\n== Detailed suggestions ==\n\n1) The authors should specify in the abstract and in the introduction that they are analyzing feedforward neural networks *with ReLU activation functions* so that the current context of the result is more transparent. It is quite unclear how one could generalize the Theorem 1 to arbitrary activation functions phi given the crucial use of the homogeneity of the ReLU at the beginning of p.4. Though the proof of Lemma 2 only appears to be using the 1-Lipschitzness property of phi as well as phi(0) =0. (Unless they can generalize further; I also suggest that they explicitly state in the (interesting) Lemma 2 that it is for the ReLU activations (like they did in Theorem 1)).\n\n2) A footnote (or citation) could be useful to give a hint on how the inequality 1/e beta^(d-1) <= tilde{beta}^(d-1) <= e beta^(d-1) is proven from the property |beta-tilde{beta}|<= 1/d beta (middle of p.4).\n\n3) Equation (3) -- put the missing 2 subscript for the l2 norm of |f_(w+u)(x) - f_w(x)|_2 on the LHS (for clarity).\n\n4) One extra line of derivation would be helpful for the reader to rederive the bound|w|^2/2sigma^2  <= O(...) just above equation (4). I.e. first doing the expansion keeping the beta terms and Frobenius norm sum, and then going directly to the current O(...) term.\n\n5) bottom of p.4: use hat{L}_gamma = 1 instead of L_gamma =1 for more clarity.\n\n6) Top of p.5: the sentence ""Since we need tilde{beta} to satisfy (...)"" is currently awkwardly stated. I suggest instead to say that ""|tilde{beta}- beta| <= 1/d (gamma/2B)^(1/d) is a sufficient condition to have the needed condition |tilde{beta}-beta| <= 1/d beta over this range, thus we can use a cover of size dm^(1/2d).""\n\n7) Typo below (6): citetbarlett2017...\n\n8) Last paragraph p.5: ""Recalling that W_i is *at most* a hxh matrix"" (as your result do not require constant size layers and covers the rectangular case). \n', 'This paper provides a new generalization bound for feed forward networks based on a PAC-Bayesian analysis. The generalization bound depends on the spectral norm of the layers and the Frobenius norm of the weights. The resulting generalization bound is similar (though not comparable) to a recent result of Bartlett et al (2017), however the technique is different since this submission uses PAC-Bayesian analysis. The resulting proof is more simple and streamlined compared to that of Bartlett et al (2017).\n\nThe paper is well presented, the result is explained and compared to other results, and the proofs seem correct. The result is not particularly different from previous ones, but the different proof technique might be a good enough reason to accept this paper. \n\n\n\n\nTypos: Several citations are unparenthesized when they should be. Also, after equation (6) there is a reference command that is not compiled properly.\n\n']","[90, 70, 60]","[80, 80, 80]","[""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer describes the paper as 'elegant', with 'excellent' mathematical writing, and calls it a 'Very nice paper'. They also mention that the authors make a 'convincing case' for their new bound. The only slight criticism is a suggestion for additional discussion on convolutional layers, which doesn't significantly detract from the overall positive sentiment. The politeness score is 80 because the language used is consistently respectful and professional. The reviewer uses phrases like 'The authors prove...', 'The analysis is elegant', and offers a constructive suggestion rather than a criticism. The tone is formal and appreciative throughout, without any harsh or impolite language."", ""The sentiment score is 70 (positive) because the reviewer expresses enjoyment reading the paper, praises its simplicity and elegance, and states it could be useful for the community. They acknowledge it may be somewhat incremental but still view it positively overall. The politeness score is 80 (quite polite) due to the reviewer's respectful tone, use of phrases like 'I enjoyed reading this paper', and constructive suggestions for improvement. They verify the math and provide detailed, helpful feedback without harsh criticism. The language is consistently professional and courteous throughout."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting that it is 'well presented', the proofs 'seem correct', and that the different proof technique 'might be a good enough reason to accept this paper'. However, it's not extremely positive as the reviewer mentions that the result is 'not particularly different from previous ones'. The politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout, acknowledging the paper's strengths and offering constructive feedback. The reviewer also politely points out minor typos without being critical. The tone is consistently courteous and academic, avoiding any harsh or dismissive language.""]"
"[""The paper discusses the problem of optimizing neural networks with hard threshold and proposes a novel solution to it. The problem is of significance because in many applications one requires deep networks which uses reduced computation and limited energy. The authors frame the problem of optimizing such networks to fit the training data as a convex combinatorial problems. However since the complexity of such a problem is exponential, the authors propose a collection of heuristics/approximations to solve the problem. These include, a heuristic for setting the targets at each layer, using a soft hinge loss, mini-batch training and such. Using these modifications the authors propose an algorithm (Algorithm 2 in appendix) to train such models efficiently. They compare the performance of a bunch of models trained by their algorithm against the ones trained using straight-through-estimator (SSTE) on a couple of datasets, namely, CIFAR-10 and ImageNet. They show superiority of their algorithm over SSTE. \n\nI thought the paper is very well written and provides a really nice exposition of the problem of training deep networks with hard thresholds. The authors formulation of the problem as one of combinatorial optimization and proposing Algorithm 1 is also quite interesting. The results are moderately convincing in favor of the proposed approach. Though a disclaimer here is that I'm not 100% sure that SSTE is the state of the art for this problem. Overall i like the originality of the paper and feel that it has a potential of reasonable impact within the research community. \n\nThere are a few flaws/weaknesses in the paper though, making it somewhat lose. \n- The authors start of by posing the problem as a clean combinatorial optimization problem and propose Algorithm 1. Realizing the limitations of the proposed algorithm, given the assumptions under which it was conceived in, the authors relax those assumptions in the couple of paragraphs before section 3.1 and pretty much throw away all the nice guarantees, such as checks for feasibility, discussed earlier. \n- The result of this is another algorithm (I guess the main result of the paper), which is strangely presented in the appendix as opposed to the main text, which has no such guarantees.  \n- There is no theoretical proof that the heuristic for setting the target is a good one, other than a rough intuition\n- The authors do not discuss at all the impact on generalization ability of the model trained using the proposed approach. The entire discussion revolves around fitting the training set and somehow magically everything seem to generalize and not overfit. \n"", 'This paper examines the problem of optimizing deep networks of hard-threshold units. This is a significant topic with implications for quantization for computational efficiency, as well as for exploring the space of learning algorithms for deep networks. While none of the contributions are especially novel, the analysis is clear and well-organized, and the authors do a nice job in connecting their analysis to other work. ', 'The paper studies learning in deep neural networks with hard activation functions, e.g. step functions like sign(x). Of course, backpropagation is difficult to adapt to such networks, so prior work has considered different approaches. Arguably the most popular is straight-through estimation (Hinton 2012, Bengio et al. 2013), in which the activation functions are simply treated as identity functions during backpropagation. More recently, a new type of straight-through estimation, saturated STE (Hubara et al., 2016) uses 1[|z|<1] as the derivative of sign(z).\n\nThe paper generalizes saturated STE by recognizing that other discrete targets of each activation layer can be chosen. Deciding on these targets is formulated as a combinatorial optimization problem. Once the targets are chosen, updating the weights of each layer to minimize the loss on those targets is a convex optimization. The targets are heuristically updated through the layers, starting out the output using the proposed feasibility target propagation. At each layer, the targets can be chosen using a variety of search algorithms such as beam search.\n\nExperiments show that FTP often outperforms saturated STE on CIFAR and ImageNet with sign and quantized activation functions, reaching levels of performance closer to the full-precision activation networks.\n\nThis paper\'s ideas are very interesting, exploring an alternative training method to backpropagation that supports hard-threshold activation functions. The experimental results are encouraging, though I have a few questions below that prevent me for now from rating the paper higher.\n\nComments and questions:\n\n1) How computationally expensive is FTP? The experiments using ResNet indicate it is not prohibitively expensive, but I am eager for more details.\n\n2) Does (Hubara et al., 2016) actually compare their proposed saturated STE with the orignal STE on any tasks? I do not see a comparison. If that is so, should this paper also compare with STE? How do we know if generalizing saturated STE is more worthwhile than generalizing STE?\n\n3) It took me a while to understand the authors\' subtle comparison with target propagation, where they say ""Our framework can be viewed as an instance of target propagation that uses combinatorial optimization to set discrete targets, whereas previous approaches employed continuous optimization."" It seems that the difference is greater than explicitly stated, that prior target propagation used continuous optimization to set *continuous targets*. (One could imagine using continuous optimization to set discrete targets such as a convex relaxation of a constraint satisfaction problem.) Focusing on discrete targets gains the benefits of quantized networks. If I am understanding the novelty correctly, it would strengthen the paper to make this difference clear.\n\n4) On a related note, if feasible target propagation generalizes saturated straight through estimation, is there a connection between (continuous) target propagation and the original type of straight through estimation?\n\n5) In Table 1, the significance of the last two columns is unclear. It seems that ReLU and Saturated ReLU are included to show the performance of networks with full-precision activation functions (which is good). I am unclear though on why they are compared against each other (bolding one or the other) and if there is some correspondence between those two columns and the other pairs, i.e., is ReLU some kind of analog of SSTE and Saturated ReLU corresponds to FTP-SH somehow?']","[50, 50, 60]","[80, 75, 80]","[""The sentiment score is 50 (moderately positive) because the reviewer expresses overall approval of the paper, calling it 'very well written' and praising its originality and potential impact. However, they also point out several flaws and weaknesses, which prevents the score from being higher. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing its weaknesses. They use phrases like 'I thought' and 'I like' to express personal opinions, and frame criticisms constructively. The reviewer also admits their own potential lack of knowledge ('I'm not 100% sure') rather than making absolute statements, which adds to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the significance of the topic and praises the clear analysis and organization. However, they also note that 'none of the contributions are especially novel,' which tempers the positivity. The politeness score is 75 (quite polite) due to the use of respectful language and constructive feedback. The reviewer uses phrases like 'nice job' and 'well-organized,' which contribute to a polite tone. They also balance criticism with praise, presenting negative aspects in a gentle manner ('While none of the contributions are especially novel...')."", ""The sentiment score is 60 (positive) because the reviewer describes the paper's ideas as 'very interesting' and the experimental results as 'encouraging'. However, they also mention having questions that prevent them from rating the paper higher, indicating a positive but not overwhelmingly enthusiastic sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their criticisms as questions or suggestions rather than direct criticisms. They use phrases like 'I am eager for more details' and 'It would strengthen the paper to make this difference clear', which are constructive and polite ways of suggesting improvements.""]"
"['This is a nice paper. It makes novel contributions to neural program synthesis by (a) using RL to tune neural program synthesizers such that they can generate a wider variety of correct programs and (b) using a syntax checker (or a learned approximation thereof) to prevent the synthesizer from outputting any syntactically-invalid programs, thus pruning the search space. In experiments, the proposed method synthesizes correct Karel programs (non-trivial programs involving loops and conditionals) more frequently than synthesizers trained using only maximum likelihood supervised training.\n\nI have a few minor questions and requests for clarification, but overall the paper presents strong results and, I believe, should be accepted.\n\n\nSpecific comments/questions follow:\n\n\nFigure 2 is too small. It would be much more helpful (and easier to read) if it were enlarged to take the full page width.\n\nPage 7: ""In the supervised setting..."" This suggests that the syntaxLSTM can be trained without supervision in the form of known valid programs, a possibility which might not have occurred to me without this little aside. If that is indeed the case, that\'s a surprising and interesting result that deserves having more attention called to it (I appreciated the analysis in the results section to this effect, but you could call attention to this sooner, here on page 7).\n\nIs the ""Karel DSL"" in your experiments the full Karel language, or a subset designed for the paper?\n\nFor the versions of the model that use beam search, what beam width was used? Do the results reported in e.g. Table 1 change as a function of beam width, and if so, how? \n', 'The authors consider the task of program synthesis in the Karel DSL. Their innovations are to use reinforcement learning to guide sequential generation of tokes towards a high reward output, incorporate syntax checking into the synthesis procedure to prune syntactically invalid programs. Finally they learn a model that predicts correctness of syntax in absence of a syntax checker. \n\nWhile the results in this paper look good, I found many aspects of the exposition difficult to follow. In section 4, the authors define objectives, but do not clearly describe how these objectives are optimized, instead relying on the read to infer from context how REINFORCE and beam search are applied. I was not able to understand whether syntactic corrected is enforce by way of the reward introduced in section 4, or by way of the conditioning introduced in section 5.1. Discussion of the experimental results coould similarly be clearer. The best method very clearly depends on the taks and the amount of available data, but I found it difficult to extract an intuition for which method works best in which setting and why. \n\nOn the whole this seems like a promising paper. That said, I think the authors would need to convincingly address issues of clarity in order for this to appear. \n\nSpecific comments \n\n- Figure 2 is too small \n\n- Equation 8 is confusing in that it defines a Monte Carlo estimate of the expected reward, rather than an estimator of the gradient of the expected reward (which is what REINFORCE is). \n\n- It is not clear the how beam search is carried out. In equation (10) there appear to be two problems. The first is that the index i appears twice (once in i=1..N and once in i \\in 1..C), the second is that λ_r refers to an index that does not appear. More generally, beam search is normally an algorithm where at each search depth, the set of candidate paths is pruned according to some heuristic. What is the heuristic here? Is syntax checking used at each step of token generation, or something along these lines? \n \n- What is the value of the learned syntax in section 5.2? Presumaly we need a large corpus of syntax-checked training examples to learn this model, which means that, in practice, we still need to have a syntax-checker available, do we not?', 'The paper presents a reinforcement learning-based approach for program synthesis. The proposed approach claims two advantages over a baseline maximum likelihood estimation-based approach. MLE-based methods penalize syntactically different but semantically equivalent programs. Further, typical program synthesis approaches don\'t explicitly learn to produce correct syntax. The proposed approach uses a syntax-checker to limit the next-token distribution to syntactically-valid tokens.\n\nThe approach, and its constituent contributions, i.e. of using RL for program synthesis, and limiting to syntactically valid programs, are novel. Although both the contributions are fairly obvious, there is of course merit in empirically validating these ideas.\n\nThe paper presents comparisons with baseline methods. The improvements over the baseline methods is small but substantial, and enough experimental details are provided to reproduce the results.  However, there is no comparison with other approaches in the literature. The authors claim to improve the state-of-the-art, but fail to mention and compare with the state-of-the-art, such as [1]. I do find it hard to trust papers which do not compare with results from other papers.\n\nPros:\n1. Well-written paper, with clear contributions.\n2. Good empirical evaluation with ablations.\n\nCons:\n1. No SOTA comparison.\n2. Only one task / No real-world task, such as Excel Flashfill.\n\n[1]: ""Neural Program Meta-Induction"", Jacob Devlin, Rudy Bunel, Rishabh Singh, Matthew Hausknecht, Pushmeet Kohli']","[80, -20, 50]","[70, 50, 75]","[""The sentiment score is 80 (positive) because the reviewer starts by calling it a 'nice paper' and states that it makes 'novel contributions'. They also mention 'strong results' and recommend acceptance. The few questions are framed as 'minor'. The politeness score is 70 (polite) due to the overall positive tone, the use of phrases like 'I believe' to soften statements, and the constructive nature of the feedback. The reviewer asks questions respectfully and offers suggestions for improvement without being demanding. The language is professional and courteous throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'promising' with 'good' results, they express significant concerns about clarity and exposition. The reviewer states they found 'many aspects of the exposition difficult to follow' and that issues of clarity would need to be 'convincingly addressed' for publication. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positive aspects alongside criticisms. They offer specific, constructive feedback and frame concerns as areas for improvement rather than outright flaws. The tone remains professional and courteous, even when pointing out issues."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and merit of the approach, praises the clear writing and good empirical evaluation, but also points out significant cons like lack of state-of-the-art comparison and limited task scope. The overall tone is balanced, recognizing both strengths and weaknesses. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's contributions, and frames criticisms constructively. The reviewer uses phrases like 'I do find it hard to trust' instead of more accusatory language, maintaining a professional and courteous tone even when pointing out shortcomings.""]"
"['The authors introduce a novel approach to online learning of the parameters of recurrent neural networks from long sequences that overcomes the limitation of truncated backpropagation through time (BPTT) of providing biased gradient estimates.\n\nThe idea is to use a forward computation of the gradient as in Williams and Zipser (1989) with an unbiased approximation of Delta s_t/Delta theta to reduce the memory and computational cost.\n\nThe proposed approach, called UORO, is tested on a few artificial datasets.\n\nThe approach is interesting and could potentially be very useful. However, the paper lacks in providing a substantial experimental evaluation and comparison with other methods.\nRather than with truncated BPTT with smaller truncation than required, which is easy to outperform, I would have expected a comparison with some of the other methods mentioned in the Related Work Section, such as NBT, ESNs, Decoupled Neural Interfaces, etc. Also the evaluation should be extended to other challenging tasks. \n\nI have increased the score to 6 based on the comments and revisions from the authors.', 'This paper presents a generic unbiased low-rank stochastic approximation to full rank matrices that makes it possible to do online RNN training without the O(n^3) overhead of real-time recurrent learning (RTRL). This is an important and long-sought-after goal of connectionist learning and this paper presents a clear and concise description of why their method is a natural way of achieving that goal, along with experiments on classic toy RNN tasks with medium-range time dependencies for which other low-memory-overhead RNN training heuristics fail. My only major complaint with the paper is that it does not extend the method to large-scale problems on real data, for instance work from the last decade on sequence generation, speech recognition or any of the other RNN success stories that have led to their wide adoption (eg Graves 2013, Sutskever, Martens and Hinton 2011 or Graves, Mohamed and Hinton 2013). However, if the paper does achieve what it claims to achieve, I am sure that many people will soon try out UORO to see if the results are in any way comparable.', 'Post-rebuttal update:\nI am happy with the rebuttal and therefore I will keep the score of 7.\n\nThis is a very interesting paper. Training RNN\'s in an online fashion (with no backpropagation through time) is one of those problems which are not well explored in the research community. And I think, this paper approaches this problem in a very principled manner. The authors proposes to use forward approach for the calculation of the gradients. The author proposes to modify RTRL by maintaining a rank one approximation of jacobian matrix (derivative of state w.r.t parameters)  which was done in NoBackTrack Paper. The way I think this paper is different from NoBackTrack Paper is that this version can be implemented in a black box fashion and hence easy to implement using current DL libraries like Pytorch. \n\nPros.\n\n- Its an interesting paper, very easy to follow, and with proper literature survey.\n\nCons:\n\n- The results are quite preliminary. I\'ll note that this is a very difficult problem.\n- ""The proof of UORO’s convergence to a local optimum is soon to be published Masse & Ollivier (To appear).""  I think, paper violates the anonymity.  So, I\'d encourage the authors to remove this. \n\nSome Points: \n\n- I find the argument of stochastic gradient descent wrong (I could be wrong though). RNN\'s follow the markov property (wrt hidden states from previous time step and the current input) so from time step t to t+1, if you change the parameters, the hidden state at time t (and all the time steps before) would carry stale information unless until you\'re using something like eligibility traces from RL literature. I also don\'t know how to overcome this issue. \n\n- I\'d be worried about the variance in the estimate of rank one approximation. All the experiments carried out by the authors are small scale (hidden size = 64). I\'m curious if authors tried experimenting with larger networks, I\'d guess it wont perform well due to the high variance in the approximation. I\'d like to see an experiment with hidden size  = 128/256/512/1024. My intuition is that because of high variance it would be difficult to train this network, but I could be wrong. I\'m curious what the authors had to say about this. \n\n- If the variance of the approximation is indeed high, can we use something to control the dynamics of the network which can result in less variance. Have authors thought about this ? \n\n- I\'d also like to see experiments on copying task/adding task (as these are standard experiments which are done for analysis of long term dependencies) \n\n- I\'d also like to see what effect the length of sequence has on the approximation. As small errors in approximation on each step can compound giving rise to chaotic dynamics. (small change in input => large change in output)\n\n- I\'d also like to know how using UORO changes the optimization as compared to Back-propagation through time in the sense, does the two approaches would reach same local minimum ? or is there a possibility that the former can reach ""less"" number of potential local minimas as compared to BPTT. \n\n\nI\'m tempted to give high score for this paper( Score - 7) , as it is unexplored direction in our research community, and I think this paper makes a very useful contribution to tackle this problem in a very principled way.  But I\'d like some more experiments to be done (which I have mentioned above), failing to do those experiments, I\'d be forced to reduce the score (to score - 5) ']","[50, 80, 70]","[75, 70, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the approach as 'interesting and potentially very useful', but also points out significant limitations in the experimental evaluation. The increased score to 6 based on authors' revisions indicates a positive shift. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. Phrases like 'The approach is interesting' and 'I would have expected' maintain a professional and courteous tone while providing feedback."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper's contribution, calling it 'important and long-sought-after' and praising its 'clear and concise description'. The only major criticism is the lack of large-scale problem testing, but the reviewer still expresses optimism about future applications. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's merits and framing the criticism constructively. The use of phrases like 'My only major complaint' softens the critique, maintaining a courteous tone."", ""The sentiment score is 70 (positive) because the reviewer expresses strong interest in the paper, calling it 'very interesting' and praising its approach as 'principled'. They highlight several pros and are 'tempted to give high score'. The initial score of 7 out of 10 also indicates a positive view. However, it's not 100 as they do mention some cons and request additional experiments. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging their own potential for error ('I could be wrong though') and framing criticisms as suggestions or curiosities ('I'd like to see', 'I'm curious'). They also balance critiques with praise. The tone is professional and constructive, avoiding harsh or dismissive language.""]"
"['The paper proposes to use a deep neural network to embed probability distributions in a vector space, where the Euclidean distance in that space matches the Wasserstein distance in the original space of probability distributions. A dataset of pairs of probability distributions and their Wasserstein distance is collected, and serves as a target to be predicted by the deep network.\n\nThe method is straightforward, and clearly explained. Two analyses based on Wasserstein distances (computing barycenters, and performing geodesic analysis) are then performed directly in the embedded space.\n\nThe authors claim that the proposed method produces sharper barycenters than those learned using the standard (smooth) Wasserstein distance. It is unclear from the paper whether the advantage comes from the ability of the method to scale better and use more examples, or to be able to use the non-smooth Wasserstein distance, or finally, whether the learning of a deep embedding yields improved extrapolation properties. A short discussion could be added. It would also be interesting to provide some guidance on what is a good structure for the encoder (e.g. should it include spatial pooling layers?)\n\nThe term “Wasserstein deep learning” is probably too broad, “deep Wasserstein embedding” could be more appropriate.\n\nThe last line of future work in the conclusion seems to describe the experiment of Table 1.', 'The paper presents a simple idea to reduce the computational cost of computing Wasserstein distance between a pair of histograms. Specifically, the paper proposes learning an embedding on the original histograms into a new space where Euclidean distance in the latter relates to the Wasserstein distance in the original space. Despite simplicity of the idea, I think it can potentially be useful practical tool, as it allows for very fast approximation of Wasserstein distance. The empirical results show that embeddings learned by the proposed model indeed provide a good approximation to the actual Wasserstein distances.\n\nThe paper is well-written and is easy to follow and understand. There are some grammar/spelling issues that can be fixed by a careful proofreading. Overall, I find the paper simple and interesting.\n\nMy biggest concern however is the applicability of this approach to high-dimensional data. The experiments in the paper are performed on 2D histograms (images). However, the number of cells in the histogram grows exponentially in dimension. This may turn this approach impractical even in a moderate-sized dimensionality, because the input to the learning scheme  requires explicit representation of the histogram, and the proposed method may quickly run into memory problems. In contrast, if one uses the non-learning based approach (standard LP formulation of Wasserstein distance), at least in case of W_1, one can avoid memory issues caused by the dimensionality by switching to the dual form of the LP. I believe that is an important property that has made computation of Wasserstein distance practical in high dimensional settings, but seems inapplicable to the learning scheme. If there is a workaround, please specify.\n', 'This paper proposes approximating the Wasserstein distance between normalized greyscale images based on a learnable approximately isometric embedding of images into Euclidean space. The paper is well written with clear and generally thorough prose. It presents a novel, straightforward and practical solution to efficiently computing Wasserstein distances and performing related image manipulations.\n\nMajor comments:\n\nIt sounds like the same image may be present in the training set and eval set. This is methodologically suspect, since the embedding may well work better for images seen during training. This affects all experimental results.\n\nI was pleased to see a comparison between using exact and approximate Wasserstein distances for image manipulation in Figure 5, since that\'s a crucial aspect of whether the method is useful in practice. However the exact computation (OT LP) appears to be quite poor. Please explain why the approximation is better than the exact Wasserstein difference for interpolation. Relatedly, please summarize the argument in Cuturi and Peyre that is cited (""as already explained in"").\n\nMinor comments:\n\nIn section 3.1 and 4.1, ""histogram"" is used to mean normalized-to-sum-to-1 images, which is not the conventional meaning.\n\nIt would help to pick one of ""Wasserstein Deep Learning"" and ""Deep Wasserstein Embedding"" and use it and the acronym consistently throughout.\n\n""Disposing of a decoder network"" in section 3.1 should be ""using a decoder network""?\n\nIn section 4.1, the architectural details could be clarified. What size are the input images? What type of padding for the convolutions? Was there any reason behind the chosen architecture? In particular the use of a dense layers followed by convolutional layers seems peculiar.\n\nIt would be helpful to say explicitly what ""quadratic ground metric"" means (i.e. W_2, I presume) in section 4.2 and elsewhere.\n\nIt would be helpful to give a sense of scale for the numbers in Table 1, e.g. give the 95th percentile Wasserstein distance. Perhaps use the L2 distance passed through a 1D-to-1D learned warping as a baseline.\n\nMention that OT stands for optimal transport in section 4.3.\n\nSuggest mentioning ""there is no reason for a Wasserstein barycenter to be a realistic sample"" in the main text when first discussing barycenters.']","[50, 50, 60]","[75, 80, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's clear explanation and straightforward method, while also providing constructive feedback and suggestions for improvement. The review is not overwhelmingly positive, but it does recognize the value of the work. The politeness score is 75 (quite polite) due to the reviewer's use of respectful language throughout. They offer suggestions and critiques in a constructive manner, using phrases like 'It would be interesting' and 'A short discussion could be added' rather than making demands. The reviewer also acknowledges the authors' claims and provides thoughtful feedback without being dismissive or harsh."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's potential usefulness and interesting aspects, while also expressing a significant concern about its applicability to high-dimensional data. The positive comments include 'potentially be useful practical tool,' 'empirical results show... good approximation,' and 'well-written and easy to follow.' However, the 'biggest concern' about high-dimensional data applicability balances these positive aspects.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths before presenting criticisms, use phrases like 'I think' and 'I find' to soften opinions, and frame the main concern as a question for the authors to address rather than a direct criticism. The tone is professional and courteous throughout, without any harsh or dismissive language."", ""The sentiment score is 60 (positive) because the reviewer starts with praise, calling the paper 'well written' and the solution 'novel, straightforward and practical'. However, there are also significant criticisms, particularly about methodology, which prevents a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and balances negative feedback with positive comments. Phrases like 'I was pleased to see' and the use of 'please' when requesting changes indicate a polite tone. The reviewer also offers helpful suggestions rather than just pointing out flaws.""]"
"['Through evaluation of current popular GAN variants. \n  * useful AIS figure\n  * useful example of failure mode of inception scores\n   * interesting to see that using a metric based on a model’s distance does not make the model better at that distance\nthe main criticism that can be given to the paper is that the proposed metrics are based on trained models which do not have an independent clear evaluation metrics (as classifiers do for inception scores). However, the authors do show that the results are consistent when changing the critic architecture. Would be nice to see if this also holds for changes in learning rates. \n * nice to see an evaluation on how models scale with the increase in training data.\n\nUsing an Independent critic for evaluation has been proposed and used in practice before, see “Comparison of Maximum Likelihood and GAN-based training of Real NVPs”, Danihelka et all, as well as Variational Approaches for Auto-Encoding Generative Adversarial Networks, Rosca at all.\n\nImprovements to be added to the paper:\n   * How about overfitting? Would be nice to mention whether the proposed metrics are useful at detecting overfitting. From algorithm 1 one can see that the critic is trained on training data, but at evaluation time test data is used. However, if the generator completely memorizes the training set, the critic will not be able to learn anything useful. In that case, the test measure will not provide any information either. A way to go around this is to use validation data to train the critic, not training data. In that case, the critic can learn the difference between training and validation data and at test time the test set can be used. \n  * Using the WGAN with weight clipping is not a good baseline. The improved WGAN method is more robust to hyper parameters and is the one currently  used by the community. The WGAN with weight clipping is quite sensitive to the clipping hyperparameter, but the authors do not report having changed it from the original paper, both for the critic or for the discriminator used during training. \n  *  Is there a guidance for  which metric should be used? \n\nFigure 3 needs to be made a bit larger, it is quite hard to read in the current set up. ', 'the paper proposes an evaluation method for training GANs using four standard distribution distances in literature namely:\n- JSD\n- Pearson-chi-square\n- MMD\n- Wasserstein-1\n\nFor each distance, a critic is initialized with parameters p. The critic is a neural network with the same architecture as the discriminator.\nThe critic then takes samples from the trained generator model, and samples from the groundtruth dataset. It trains itself to maximize the distance measure between these two distributions (trained via gradient descent).\n\nThese critics after convergence will then give a measure of the quality of the generator (lower the better).\n\nThe paper is easy to read, experiments are well thought out.\nFigure 3 is missing (e) and (f) sub-figures.\n\nWhen proposing a distance measure for GANs (which is a high standard, because everyone is looking forward to a robust measure), one has to have enough convincing to do. The paper only does experiments on two small datasets MNIST and CIFAR. If the paper has to convince me that this metric is good and should be used, I need to see experiments on one large-scale datset, such as Imagenet or LSUN. If one can clearly identify the good generators from bad generators using a weighted-sum of these 4 distances on Imagenet or LSUN, this is a metric that is going to stand well.\nIf such experiments are constructed in the rebuttal period, I shall raise my rating.', 'This paper proposes using divergence and distance functions typically used for generative model training to evaluate the performance of various types of GANs. Through numerical evaluation, the authors observed that the behavior is consistent across various proposed metrics and the test-time metrics do not favor networks that use the same training-time criterion. \n\nMore specifically, the evaluation metric used in the paper are: 1) Jensen-Shannon divergence, 2) Constrained Pearson chi-squared, 3) Maximum Mean Discrepancy, 4) Wasserstein Distance, and 5) Inception Score. They applied those metrics to compare three different GANs: the standard DCGAN, Wasserstein DCGAN, and LS-DCGAN on MNIST and CIFAR-10 datasets. \n\nSummary:\n——\nIn summary, it is an interesting topic, but I think that the paper does not have sufficient novelty. Some empirical results are still preliminary. It is hard to judge the effectiveness of the proposed metrics for model selection and is not clear that those metrics are better qualitative descriptors to replace visual assessment. In addition, the writing should be improved. See comments below for details and other points.\n\nComments:\n——\n1.\tIn Section 3, the evaluation metrics are existing metrics and some of them have already been used in comparing GAN models.  Maximum mean discrepancy has been used before in work by Yujia Li et al. (2016, 2017)\n\n2.\tIn the experiments, the proposed metrics were only tested on small scale datasets; the authors should evaluate on larger datasets such as CIFAR-100, Toronto Faces, LSUN bedrooms or CelebA.\n\n3.\tIn the experiments, the authors noted that “Gaussian observable model might not be the ideal assumption for GANs. Moreover, we observe a high log-likelihood at the beginning of training, followed by a drop in likelihood, which then returns to the high value, and we are unable to explain why this happens.” Could the authors give explanation to this phenomenon? The authors should look into this more carefully.\n\n4.\tIn algorithm 1, it seems that the distance is computed via gradient decent. Is it possible to show that the optimization always converges? Is it meaningful to compare the metrics if some of them cannot be properly computed?\n\n5.     With many different metrics for assessing GANs, how should people choose? How do we trust the scores? Recently, Fréchet Inception Distance (FID) was proposed to evaluate the samples generated from GANs (Heusel et al. 2017), how are the above scores compared with FID?\n\nMinor Comments:\n——\n1.\tWriting should be fixed: “It seems that the common failure case of MMD is when the mean pixel intensities are a better match than texture matches (see Figure 5), and the common failure cases of IS happens to be when the samples are recognizable textures, but the intensity of the samples are either brighter or darker (see Figure 2).”\n']","[60, 20, -20]","[70, 60, 50]","[""The sentiment score is 60 (positive) because the reviewer highlights several positive aspects of the paper, such as the 'useful AIS figure', 'interesting' findings, and 'nice' evaluations. The reviewer also provides constructive criticism and suggestions for improvement, indicating an overall positive but not overwhelmingly enthusiastic sentiment. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms as suggestions for improvement. Phrases like 'Would be nice to see' and 'Improvements to be added' maintain a courteous tone. The reviewer also provides specific, actionable feedback without using harsh or dismissive language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's readability and well-thought-out experiments. However, they also point out missing figures and express a need for more extensive experiments on larger datasets to be fully convinced. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and even suggests a way for the authors to improve their rating in the rebuttal period. The reviewer maintains a professional tone without using overly harsh or negative language, even when pointing out limitations."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the topic as interesting, they express concerns about the paper's novelty, preliminary results, and effectiveness of the proposed metrics. The reviewer also points out several areas for improvement. However, the criticism is not overly harsh, hence the score is only mildly negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as suggestions for improvement rather than outright dismissals. The reviewer also acknowledges positive aspects of the paper before diving into critiques, which is a polite approach. The language used is professional and courteous, without any rude or confrontational phrases.""]"
"['This paper proposes a new method of detecting in vs. out of distribution samples. Most existing approaches for this deal with detecting out of distributions at *test time* by augmenting input data and or temperature scaling the softmax and applying a simple classification rule based on the output. This paper proposes a different approach (with could be combined with these methods) based on a new training procedure. \n\nThe authors propose to train a generator network in combination with the classifier and an adversarial discriminator. The generator is trained to produce images that (1) fools a standard GAN discriminator and (2) has high entropy (as enforced with the pull-away term from the EBGAN). Classifier is trained to not only maximize classification accuracy on the real training data but also to output a uniform distribution for the generated samples. \n\nThe model is evaluated on CIFAR-10 and SVNH, where several out of distribution datasets are used in each case. Performance gains are clear with respect to the baseline methods.\n\nThis paper is clearly written, proposes a simple model and seems to outperform current methods. One thing missing is a discussion of how this approach is related to semi-supervised learning approaches using GANS where a generative model produces extra data points for the classifier/discriminator. \n\n I have some clarifying questions below:\n- Figure 4 is unclear: does ""Confidence loss with original GAN"" refer to the method where the classifier is pretrained and then ""Joint confidence loss"" is with joint training? What does ""Confidence loss (KL on SVHN/CIFAR-10)"" refer to?\n\n- Why does the join training improve the ability of the model to generalize to out-of-distribution datasets not seen during training?\n\n- Why is the pull away term necessary and how does the model perform without it? Most GAN models are able to stably train without such explicit terms such as the pull away or batch discrimination. Is the proposed model unstable without the pull-away term? \n\n- How does this compare with a method whereby instead of pushing the fake sample\'s softmax distribution to be uniform, the model is simply a trained to classify them as an additional ""out of distribution"" class? This exact approach has been used to do semi supervised learning with GANS [1][2]. More generally, could the authors comment on how this approach is related to these semi-supervised approaches? \n\n- Did you try combining the classifier and discriminator into one model as in [1][2]?\n\n[1] Semi-Supervised Learning with Generative Adversarial Networks (https://arxiv.org/abs/1606.01583)\n[2] Good Semi-supervised Learning that Requires a Bad GAN (https://arxiv.org/abs/1705.09783)', ""I have read authors' reply.  In response to authors' comprehensive reply and feedback. I upgrade my score to 6.\n\n-----------------------------\n\nThis paper presents a novel approach to calibrate classifiers for out of distribution samples. In additional to the original cross entropy loss, the “confidence loss”  was proposed to guarantee the out of distribution points have low confidence in the classifier. As out of distribution samples are hard to obtain, authors also propose to use GAN generating “boundary” samples as out of distribution samples. \n\nThe problem setting is new and objective (1) is interesting and reasonable. However, I am not very convinced that objective (3) will generate boundary samples. Suppose that theta is set appropriately so that p_theta (y|x) gives a uniform distribution over labels for out of distribution samples. Because of the construction of U(y), which uniformly assign labels to generated out of distribution samples, the conditional probability p_g (y|x) should always be uniform so p_g (y|x) divided by p_theta (y|x) is almost always 1. The KL divergence in (a) of (3) should always be approximately 0 no matter what samples are generated. \n\nI also have a few other concerns: \n1. There seems to be a related work: \n[1] Perello-Nieto et al., Background Check: A general technique to build more reliable and versatile classifiers, ICDM 2016, \nWhere authors constructed a classifier, which output K+1 labels and the K+1-th label is the “background noise” label for this classification problem. Is the method in [1] applicable to this paper’s setting?  Moreover, [1] did not seem to generate any out of distribution samples. \n\n2. I am not so sure that how the actual out of distribution detection was done (did I miss something here?). Authors repeatedly mentioned “maximum prediction values”, but it was not defined throughout the paper. \nAlgorithm 1. is called “minimization for detection and generating out of distribution (samples)”, but this is only gradient descent, right? I do not see a detection procedure. Given the title also contains “detecting”, I feel authors should write explicitly how the detection is done in the main body. \n"", 'The manuscript proposes a generative approach to detect which samples are within vs. out of the sample space of the training distribution. This distribution is used to adjust the classifier so it makes confident predictions within sample, and less confident predictions out of sample, where presumably it is prone to mistakes. Evaluation on several datasets suggests that accounting for the within-sample distribution in this way can often actually improve evaluation performance, and can help the model detect outliers.\n\nThe manuscript is reasonably well written overall, though some of the writing could be improved e.g. a clearer description of the cost function in section 2. However, equation 4 and algorithm 1 were very helpful in clarifying the cost function. The manuscript also does a good job giving pointers to related prior work. The problem of interest is timely and important, and the provided solution seems reasonable and is well evaluated.\n\nLooking at the cost function and the intuition, the difference in figure 1 seems to be primarily due to the relative number of samples used during optimization -- and not to anything inherent about the distribution as is claimed. In particular, if a proportional number of samples is generated for the 50x50 case, I would expect the plots to be similar. I suggest the authors modify the claim of figure 1 accordingly.\n\nAlong those lines, it would be interesting if instead of the uniform distribution, a model that explicitly models within vs. out of sample might perform better? Though this is partially canceled out by the other terms in the optimization.\n\nFinally, the authors claim that the PT is approximately equal to entropy. The cited reference (Zhao et. al. 2017) does not justify the claim. I suggest the authors remove this claim or correctly justify it.\n\nQuestions:\n - Could the authors comment on cases where such a strong within-sample assumption may adversely affect performance?\n - Could the authors comment on how the modifications affect prediction score calibration?\n - Could the authors comment on whether they think the proposed approach may be more resilient to adversarial attacks?\n\nMinor issues:\n - Figure 1 is unclear using dots. Perhaps the authors can try plotting a smoothed decision boundary to clarify the idea?']","[70, 20, 60]","[80, 60, 70]","[""The sentiment score is 70 (positive) because the reviewer states that the paper is 'clearly written, proposes a simple model and seems to outperform current methods.' They also mention 'Performance gains are clear with respect to the baseline methods.' These are strong positive statements, though not overwhelmingly enthusiastic. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, poses questions in a constructive manner ('I have some clarifying questions below'), and acknowledges the paper's strengths. The reviewer also provides specific suggestions and references, which is helpful and courteous. The tone is professional and supportive, without any harsh criticism or rude language."", ""The sentiment score is 20 (slightly positive) because the reviewer acknowledges the novelty of the approach and the interesting problem setting, but expresses several concerns and doubts about certain aspects of the paper. The initial upgrade of the score to 6 also indicates a somewhat positive view. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, acknowledges the authors' comprehensive reply, and frames criticisms as personal opinions or questions rather than harsh statements. Phrases like 'I am not very convinced' and 'I feel authors should' maintain a polite tone while expressing concerns."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses overall approval of the manuscript, calling it 'reasonably well written' and stating that it addresses a 'timely and important' problem with a 'reasonable' solution that is 'well evaluated'. However, they also point out some areas for improvement, which prevents the score from being higher. The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as questions or polite requests (e.g. 'Could the authors comment on...'). The reviewer also acknowledges the strengths of the paper before discussing its weaknesses. The tone is professional and courteous, without any harsh or rude language.""]"
"['[Summary of paper] The paper presents a method for simulating spike trains from populations of neurons which match empirically measured multi-neuron recordings. They set up a Wasserstein-GAN and train it on both synthetic and real multi-neuron recordings, using data from the salamander retina. They find that their method (Spike-GAN) can produce spike trains that visually look like the original data, and which have low-order statistics (firing rates, correlations, time-lagged-correlations, total sum of population activity) which matches those of the original data. They emphasize that their network architecture is \'semi-convolutional\', i.e. convolutional in time but not across neurons. Finally, they suggest a way to analyse the fitted networks in order to gain insights into what the \'relevant\' neural features are, and illustrate it on synthetic data into which they embedded these features.\n\n[Originality] This paper falls into the category of papers that do a next obvious thing (""GANs have not been applied to population spike trains yet""), and which do it pretty well: If one wants to create simulated neural activity data which matches experimentally observed one, then this method indeed seems to do that. As far as I know, this would be the first peer-reviewed application of GANs to multi-neuron recordings of neural data (but see https://arxiv.org/abs/1707.04582 for an arxiv paper, not cited here-- should be discussed at least).  On a technical level, there is very little to no innovation here -- while the authors emphasise their \'semi-convolutional\' network architecture, this is obviously the right architecture to use for multivariate time-series data, and in itself not a big technical novel. Therefore, the paper should really be evaluate as an `application\' paper, and be assessed in terms of i) how important the application is, ii) how clearly it is presented, and iii) how convincing the results are relative to state of the art. \n\ni) [Importance of problem, potential significance] Finding statistical models for modelling and simulating population spike trains is a topic which is extensively studied in computational neuroscience, predominantly using  model-based approaches using MaxEnt models, GLMs or latent variable models. These models are typically simple and restricted, and certainly fall short of capturing the full complexity of neural data. Thus, better, and more flexible solutions for this problem would certainly be very welcome, and have an immediate impact in this community.  However, I think that the approach based on GANs actually has two shortcomings which are not stated by the authors, and which possibly limit the impact of the method: First, statistical models of neural spike trains are often used to compute probabilities e.g. for decoding analyses— this is difficult or impossible for GANs. Second, one most often does not want to simulate data which match a specific recording, but rather which have specified statistics (e.g. firing rates and correlations)— the method here is based on fitting a particular data-set, and it is actually unclear to me when that will be useful.\n\nii) [Clarity] The methods are presented and explained clearly and cleanly. In my view, too much emphasis is given to highlighting the ‘semi-convolutional’ network, and, conversely, practical issues (exact architectures, cost of training) should be explained more clearly, possibly in an appendix. Similarly, the method would benefit from the authors releasing their code.\n\niii) [Quality, advance over previous methods] The authors discuss several methods for simulating spike trains in the introduction. In their empirical comparisons, however, they completely focus on a particular model-class (maximum entropy models, ME) which they label being the ‘state-of-the-art’. This label is misleading— ME models are but one of several approaches to modelling neural spike trains, with different models having different advantages and limitations (there is no benchmark which can be used to rank them...). In particular, the only ‘gain’ of the GAN over ME  models in the results comes from their ability of the GAN to match temporal statistics. Given that the ME models used by the authors are blind to temporal correlations, this is, of course (and as pointed out by the authors) hardly surprising. How does the GAN approach fair against alternative models which do take temporal statistics into account, e.g. GLMs, or simple moment-based method e.g. Krumin et al 2009, Lyamzin 2010, Gutnisky et al 2010— setting these up would be simple, and it would provide a non-trivial baseline for the ability of spike-GAN to outperform at least these models? While it true that GANs are much more expressive than the model-based approaches used in neuroscience, a clear demonstration would have been useful.\n\nMinor comments: \n  - p.3: The abbreviation “1D-DCGAN” is never spelled out.\n  - p.3: The architecture of Spike-GAN is never explicitely given.\n  - p.3: (Sec. 2.2) Statistic 2) “average time course across activity patterns” is unclear to me -- how does one select the activity patterns over which to average? Moreover, later figures do not seem to use this statistic.\n  - p.4: “introduced correlations between randomly selected pairs” -- How many such pairs were formed?\n  - p.7 (just above Discussion) At the beginning of this section, and for Figs. 4A,B, the texts suggests that packets fire spontaneously with a given probability. For Figs. 4C-E, a particular packet responds to a particular input. Is then the neuron population used in these figures different from the one in Figs. 4A,B? How did the authors ensure that a particular set of neurons respond to their stimulus as a packet? What stimulus did they use?\n  - p.8 (Fig. 4E) Are the eight neurons with higher importance those corresponding to the packet? This is insinuated but not stated.\n  - p.12 (Appendix A) \n    + The authors do not mention how they produced their “ground truth” data. (What was its firing rate? Did it include correlations? A refractory period?)\n    + Generating samples from the trained Spike-GAN is ostensibly cheap. Hence it is unclear why the authors did not  produce a large enough number of samples in order to obtain a \'numerical probability\', just as they did for the ground truth data? \n    + Fig. S1B: The figure shows that every sample has the same empirical frequency. This indicates more a lack of statistical power rather than any correspondence between the theoretical and empirical probabilities. This undermines the argument in the second paragraph of p.12. In the other hand, if the authors did approximate numerical probabilities for the Spike-GAN, this argument would no longer be required.\n  - p.13 Fig. S1A,B: the abscissas mention “frequency”, while the ordinates mention “probability”\n  - p.25 Fig. S4: This figure suggests that the first layer of the Spike-GAN critic sometimes recognizes the packet patterns in the data. However, to know whether this is true, we would need to compare this to a representation of the neurons reordered in the same way and identified by packet. I.e. one expects something something like figure like Fig. 4A, with the packets lining up with the recovered filters when neurons are ordered the same way.\n', 'Summary:\n\nThe paper proposes to use GANs for synthesizing realistic neural activity patterns. Learning generative models of neural population activity is an important problem in computational neuroscience. The authors apply an established method (WGAN) to a new context (neuroscience). The work does not present a technical advance in itself, but it could be a valuable contribution if it created novel insights in neuroscience. Unfortunately, I do not see any such insights and am therefore not sure about the value of the paper.\n\n\n\nPros:\n\n- Using GANs to synthesize neural activity patterns is novel (to my knowledge).\n\n- Using GANs allows learning the crucial statistical patterns from data, which is more flexible than MaxEnt modeling, where one needs to define the statistics to be matched in advance.\n\n- Using the critic to learn something about what are the crucial population activity patterns is an interesting idea and could be a valuable contribution.\n\n\n\nCons:\n\n- Important architecture details missing: filter sizes, strides.\n\n- The only demonstrated advantage of the proposed approach over MaxEnt models is that it models temporal correlations. However, this difference has nothing to do with MaxEnt vs. GAN. A 64d MaxEnt model does not care whether you’re modeling 64 neurons in a single time bin or 8 neurons in 8 subsequent time bins. Thus, the comparison in Fig. 3E,F is not apples to apples. An apples-to-apples comparison would be to use a MaxEnt model that includes multiple time lags (if that’s infeasible with 16 neurons x 32 bins, use a smaller model). Given that the MaxEnt model does a better job at modeling neuron-to-neuron correlations, I would expect it to also outperform the GAN at modeling temporal correlations. There may well be a scalability issue of the MaxEnt model to large populations and long time windows, but that doesn’t seem to be the current line of argument.\n\n- GANs have well-known problems like mode collapse and low entropy of samples. Given the small amount of training examples (<10k) and large number of model parameters (3.5M), this issue is particularly worrisome. The authors do not address this issue, neither qualitatively nor quantitatively, although both would be possible:\n\n  a) A quantitative approach would be to look at the entropy of the data, the MaxEnt model and the GAN samples. Given the binary and relatively low-dimensional nature of the observations, this may be feasible (in contrast to image data). One would potentially have to look at shorter segments and smaller subpopulations of neurons, where entropy estimation is feasible given the available amount of data, but it’s definitely doable\n\n  b) Qualitative approaches include the typical one of showing the closest training example for each sample. \n\n- The novel idea of using the critic to learn something about the crucial population activity patterns is not fleshed out at all. I think this aspect of the paper could be a valuable contribution if the authors focused on it, studied it in detail and provided convincing evidence that it can be useful in practice (or, even better, actually produced some novel insight).\n\n  a) Visualizing the filters learned by the critic isn’t really useful in practice, since the authors used their ground truth knowledge to sort the neurons. In practice, the (unsorted) filters will look just as uninterpretable as the (unsorted) population activity they show.\n\n  b) Detection of the ‘packets’ via importance maps is an interesting idea to find potential temporal codes without explicitly prescribing their hypothesized structure. Unfortunately, the idea is not really fleshed out or studied in any detail. In particular, it’s not clear whether it would still work in a less extreme scenario (all eight neurons fire in exact sequence).\n\n- Poor comparison to state of the art. MaxEnt model is the only alternative approach tested. However, it is not clear that MaxEnt models are the state of the art. Latent variable models (e.g. Make et al. 2011) or more recent approaches based on autoencoders (Pandarinath et al. 2017; https://doi.org/10.1101/152884) are just among a few notable alternatives that the authors ignore.\n\n\n\nQuestions:\n\n- Can sequences of arbitrary length be generated or is it fixed to 32 samples? If the latter, then how do envision the algorithm’s use in real-world scenarios that you propose such as microstimulation?\n\n\n\nMinor:\n\n- There is nothing “semicomvolutional” here. Just like images are multi-channel (color channels) 2D (x, y) observation, here the observations are multi-channel (neurons) 1D (time) observations. \n\n- Fig. 3E is not time (ms), but time (x20 ms bins). Potentially the firing rates are also off by a factor of 20?\n\n- Why partition the training data into non-overlapping segments? Seems like a waste of training data not to use all possible temporal crops.', 'The paper applies the GAN framework to learn a generative model of spike trains.  The generated spike trains are compared to traditional model fitting methods, showing comparable or superior ability to capture statistical properties of real population  activity.\n\nThis seems like an interesting exercise, but it’s unclear what it contributes to our understanding of neural circuits in the brain.  The advantage of structured models is that they potentially correspond to underlying mechanisms and can provide insight.  The authors point to the superior ability to capture temporal structure, but this does not seem like a fundamental limitation of traditional approaches.\n\nThe potential applicability of this approach is alluded to in this statement toward the end of the paper:\n\n“...be used to describe and interpret experimental results and discover the key units of neural information used for functions such as sensation and behavior.”\n\nIt is left for the reader to connect the dots here and figure out how this might be done.  It would be helpful if the authors could at least sketch out a path by which this could be done with this approach.\n\nPerhaps the most compelling application is to perturbing neural activity, or intervening to inject specific activity patterns into the brain.\n']","[-20, -50, -20]","[60, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'do it pretty well', 'methods are presented and explained clearly'), they also point out several limitations and shortcomings. The reviewer suggests that the paper lacks significant technical innovation and has potential limitations in its applicability. They also criticize the comparison methods used, calling the 'state-of-the-art' label 'misleading'.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'In my view' and 'I think' to soften criticisms, and provide constructive feedback with specific suggestions for improvement. The reviewer also acknowledges the potential importance of the work. However, the score is not higher because some criticisms, while politely phrased, are quite direct (e.g., 'On a technical level, there is very little to no innovation here')."", ""The sentiment score is -50 because the review is overall negative, pointing out several major issues with the paper and expressing doubt about its value. However, it's not entirely negative as it acknowledges some positive aspects ('pros') and potential for improvement. The politeness score is 20 because the reviewer uses professional and respectful language throughout, avoiding personal attacks or harsh criticism. They offer constructive feedback and suggestions for improvement. The slightly positive score reflects the reviewer's effort to balance criticism with recognition of the paper's strengths and potential."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as an 'interesting exercise', they express skepticism about its contribution to understanding neural circuits and its practical applicability. The reviewer points out that the paper's advantages over traditional approaches are not clear and that the potential applications are not well-explained. However, the score is not deeply negative as the reviewer does see some potential in the approach, particularly for perturbing neural activity. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, avoiding harsh criticism. They use phrases like 'seems like an interesting exercise' and 'it would be helpful if', which maintain a constructive tone. The reviewer also offers suggestions for improvement rather than outright dismissal, indicating a polite and professional approach to the review.""]"
"[""Thank you for the feedback, and I think many of my concerns have been addressed.\n\nI think the paper should be accepted.\n\n==== original review ====\n\nThank you for an interesting read. \n\nApproximate inference with implicit distribution has been a recent focus of the research since late 2016. I have seen several papers simultaneously proposing the density ratio estimation idea using GAN approach. This paper, although still doing density ratio estimation, uses kernel estimators instead and thus avoids the usage of discriminators. \n\nFurthermore, the paper proposed a new type of implicit posterior approximation which uses intuitions from matrix factorisation. I do think that another big challenge that we need to address is the construction of good implicit approximations, which is not well studied in previous literature (although this is a very new topic). This paper provides a good start in this direction.\n\nHowever several points need to be clarified and improved:\n1. There are other ways to do implicit posterior inference such as amortising deterministic/stochastic dynamics, and approximating the gradient updates of VI. Please check the literature.\n2. For kernel based density ratio estimation methods, you probably need to cite a bunch of Sugiyama papers besides (Kanamori et al. 2009). \n3. Why do you need to introduce both regression under p and q (the reverse ratio trick)? I didn't see if you have comparisons between the two. From my perspective the reverse ratio trick version is naturally more suitable to VI.\n4. Do you have any speed and numerical issues on differentiating through alpha (which requires differentiating K^{-1})?\n5. For kernel methods, kernel parameters and lambda are key to performances. How did you tune them?\n6. For the celebA part, can you compute some quantitative metric, e.g inception score?\n"", ""Update: I read the other reviews and the authors' rebuttal. Thanks to the authors for clarifying some details. I'm still against the paper being accepted. But I don't have a strong opinion and will not argue against so if other reviewers are willing. \n\n------\n\nThe authors propose Kernel Implicit VI, an algorithm allowing implicit distributions as the posterior approximation by employing kernel ridge regression to estimate a density ratio. Unlike current approaches with adversarial training, the authors argue this avoids the problems of noisy ratio estimation, as well as potentially high-dimensional inputs to the discriminator.  The work has interesting ideas. Unfortunately, I'm not convinced that the method overcomes these difficulties as they argue in Sec 3.2.\n\nAn obvious difficulty with kernel ridge regression in practice is that its complete inaccuracy to estimate high-dimensional density ratios.  This is especially the case given a limited number of samples from both p and q (which is the same problem as previous methods) as well as the RBF kernel. While the RBF kernel still takes the same high-dimensional inputs and does not involve learning massive sets of parameters, it also does not scale well at all for accurate estimation. This is the same problem as related approaches with Stein variational gradient descent; namely, it avoids minimax problems as in adversarial training by implicitly integrating over the discriminator function space using the kernel trick.\n\nThis flaw has rather deep implications. For example, my understanding of the implicit VI on the Bayesian neural network in Sec 4 is that it ends up as cross-entropy minimization subject to a poorly estimated KL regularizer. I'd like to see just how much entropy the implicit approximation has instead of concnetrating toward a point; or more directly, what the implicit posterior approximation looks like compared to a true posterior inferred by, say, HMC as the ground truth. This approach also faces difficulties that the naive Gaussian approximation applied to Bayesian neural nets does not: implicit approximations cannot exploit the local reparameterization trick and are therefore limited to specific architectures that does not involve sampling very large weight matrices.\n\nThe authors report variational lower bounds, which I'm not sure is really a lower bound. Namely, the bias incurred by the ratio estimation makes it difficult to compare numbers. An obvious but very illustrative experiment I'd like to see would be the accuracy of the KL estimator on problems where we can compute it tractably, or where we can Monte Carlo estimate it very well under complicated but tractable densities. I also suggest the authors perform the experiment suggested above with HMC as ground truth on a non-toy problem such as a fairly large Bayesian neural net."", 'This paper presents Kernel Implicit Variational Inference (KIVI), a novel class of implicit variational distributions. KIVI relies on a kernel approximation to directly estimate the density ratio. Importantly, the optimal kernel approximation in KIVI has closed-form solution, which allows for faster training since it avoids gradient ascent steps that may soon get ""outdated"" as the optimization over the variational distribution runs. The paper presents experiments on a variety of scenarios to show the performance of KIVI.\n\nUp to my knowledge, the idea of estimating the density ratio using kernels is novel. I found it interesting, specially since there is a closed-form solution for this estimate. The closed form solution involves a matrix inversion, but this shouldn\'t be an issue, as the matrix size is controlled by the number of samples, which is a parameter that the practitioner can choose. I also found interesting the implicit MMNN architecture proposed in Section 4.\n\nThe experiments seem convincing too, although I believe the paper could probably be improved by comparing with other implicit VI methods, such as [Liu & Feng], [Tran et al.], or others.\n\nMy major criticism with the paper is the quality of the writing. I found quite a few errors in every page, which significantly affects readability. I strongly encourage the authors to carefully review the entire paper and search for typos, grammatical errors, unclear sentences, etc.\n\nPlease find below some further comments broken down by section.\n\nSection 1: In the introduction, it is unclear to me what ""protect these models"" means. Also, in the second paragraph, the authors talk about ""often leads to biased inference"". The concept to ""biased inference"" is unclear. Finally, the sentence ""the variational posterior we get in this way does not admit a tractable likelihood"" makes no sense to me; how can a posterior admit (or not admit) a likelihood?\n\nSection 3: The first paragraph of the KIVI section is also unclear to me. In Section 3.1, it looks like the cost function L(\\hat(r)) is different from the loss in Eq. 1, so it should have a different notation. In Eq. 4, I found it confusing whether L(r)=J(r). Also, it would be nice to include a brief description of why the expectation in Eq. 4 is taken w.r.t. p(z) instead of q(z), for those readers who are less familiar with [Kanamori et al.]. Finally, the motivation behind the ""reverse ratio trick"" was unclear to me (the trick is clear, but I didn\'t fully understand why it\'s needed).\n\nSection 4: The first paragraph of the example can be improved with a brief discussion of why the methods of [Mescheder et al.] and [Song et al.] ""are nor applicable"". Also, the paragraph above Eq. 11 (""When modeling a matrix..."") was unclear to me.\n\nSection 6: In Figure 1(a), I think there must be something wrong, because it is well-known that VI tends to cover one of the modes of the posterior only due to the form of the KL divergence (in contrast to EP, which should look like the curve in the figure). Additionally, Figure 3(a) (and the explanation in the text) was unclear to me. Finally, I disagree with the discussion regarding overfitting in Figure 3(b): that plot doesn\'t show overfitting because it is a plot of the training loss (and overfitting occurs on test); instead it looks like an optimization issue that makes the bound decrease.\n\n\n**** EDITS AFTER AUTHORS\' REBUTTAL ****\n\nI increased the rating to 7 after reading the revised version.\n']","[70, -60, 50]","[80, 20, 70]","[""The sentiment score is 70 (positive) because the reviewer starts by thanking the authors for an interesting read and states that many of their concerns have been addressed. They also recommend acceptance of the paper, which is a strong positive signal. The score is not higher because there are still some points that need clarification and improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, starting with 'Thank you' and phrasing their recommendations as suggestions rather than demands. They acknowledge the paper's contributions and provide constructive feedback. The tone is professional and courteous, without being overly formal or effusive."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper and is 'still against the paper being accepted'. They point out several flaws and limitations in the proposed method, indicating a generally negative view. However, it's not entirely negative as they acknowledge some 'interesting ideas'. The politeness score is 20 because the reviewer uses polite language throughout, thanking the authors for clarifications and using phrases like 'I'm not convinced' rather than more harsh criticisms. They also offer constructive suggestions for improvement. However, the overall tone is professional rather than overtly polite, hence the moderate positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses interest in the novel ideas presented and finds the experiments convincing, but also has significant criticisms about the writing quality and clarity of certain sections. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. Phrases like 'I found it interesting,' 'The experiments seem convincing,' and 'I strongly encourage the authors' indicate a polite tone. The reviewer also provides detailed, specific feedback to help improve the paper, which is a courteous approach in academic review.""]"
"['The authors propose a new episodic reinforcement learning algorithm based on contextual bandit oracles.\nThe key specificity of this algorithm is its ability to deal with the credit assignment problem by learning automatically a progressive ""reward shaping"" (the residual losses) from a feedback that is only provided at the end of the epochs.\n\nThe paper is dense but well written. \n\nThe theoretical grounding is a bit thin or hard to follow.\nThe authors provide a few regret theoretical results (that I did not check deeply) obtained by reduction to ""value-aware"" contextual bandits.\n\nThe experimental section is solid. The method is evaluated on several RL environments against state of the art RL algorithms. It is also evaluated on bandit structured prediction tasks.\nAn interesting synthetic experiment (Figure 4) is also proposed to study the ability of the algorithm to work on both decomposable and non-decomposable structured prediction tasks.\n\n\nQuestion 1: The credit assignment approach you propose seems way more sophisticated than eligibility traces in TD learning. But sometimes old and simple methods are not that bad. Could you develop a bit on the relation between RESLOPE and eligibility traces ?\n\nQuestion 2: RESLOPE is built upon contextual bandits which require a stationary environment. Does RESLOPE inherit from this assumption?\n\n\nTypos:\npage 1 \n""scalar loss that output."" -> ""scalar loss.""\n"", effectively a representation"" -> "". By effective we mean effective in term of credit assignment.""\npage 5\n""and MTR"" -> ""and DR""\npage 6\n""in simultaneously."" -> ???\n"".In greedy"" -> "". In greedy""\n', 'The authors present a new RL algorithm for sparse reward tasks. The work is fairly novel in its approach, combining a learned reward estimator with a contextual bandit algorithm for exploration/exploitation. The paper was mostly clear in its exposition, however some additional information of the motivation for why the said reduction is better than simpler alternatives would help.  \n\nPros\n1. The results on bandit structured prediction problems are pretty good\n2. The idea of a learnt credit assignment function, and using that to separate credit assignment from the exploration/exploitation tradeoff is good. \n\nCons: \n1. The method seems fairly more complicated than PPO / A2C, yet those methods seem to perform equally well on the RL problems (Figure 2.). It also seems to be designed only for discrete action spaces.\n2. Reslope Boltzmann performs much worse than Reslope Bootstrap, thus having a bag of policies helps. However, in the comparison in Figures 2 and 3, the policy gradient methods dont have the advantage of using a bag of policies. A fairer comparison would be to compare with methods that use ensembles of Q-functions. (like this https://arxiv.org/abs/1706.01502 by Chen et al.). The Q learning methods in general would also have better sample efficiency than the policy gradient methods.\n3. The method claims to learn an internal representation of a denser reward function for the sparse reward problem, however the experimental analysis of this is pretty limited (Section 5.3). It would be useful to do a more thorough investigation of whether it learnt a good credit assignment function in the games. One way to do this would be to check the qualitative aspects of the function in a well understood game, like Blackjack.\n\nSuggestions:\n1. What is the advantage of the method over a simple RL method that predicts a reward at every step (such that the dense rewards add up to match the sparse reward for the episode), and uses this predicted dense reward to perform RL? This, and also a bigger discussion on prior bandit learning methods like LOLS will help under the context for why we’re performing the reduction stated in the paper.  \n\nSignificance: While the method is novel and interesting, the experimental analysis and the explanations in the paper leave it unclear as to whether its significant compared to prior work.\n\nRevision: I thank the authors for addressing some of my concerns. The comparison with relative gain of bootstrap wrt ensemble of policies still needs more thorough experimentation, but the approach is novel and as the authors point out, does improve continually with better Contextual Bandit algorithms. I update my review to 6. ', 'After reading the other reviews and the authors\' responses, I am satisfied that this paper is above the accept threshold.  I think there are many areas of further discussion that the authors can flesh out (as mentioned below and in other reviews), but overall the contribution seems solid.   I also appreciate the reviewers\' efforts to run more experiments and flesh out the discussion in the revised version of the submission.\n\nFinal concluding thoughts:\n-- Perhaps pi^ref was somehow better for the structured prediction problems than RL problems?\n-- Can one show regret bound for multi-deviation if one doesn\'t have to learn x (i.e., we were given a good x a priori)?\n\n\n\n---------------------------------------------\nORIGINAL REVIEW\n\nFirst off, I think this paper is potentially above the accept threshold.  The ideas presented are interesting and the results are potentially interesting as well.   However, I have some reservations, a significant portion of which stem from not understanding aspects of the proposed approach and theoretical results, as outlined below.\n\n\n\nThe algorithm design and theoretical results in the appendix could be made substantially more rigorous. Specifically:\n\n--  basic notations such as regret (in Theorem 1), the total reward (J), Q-value (Q), and value function (V) are not defined.  While these concepts are fairly standard, it would be highly beneficial to define them formally. \n\n-- I\'m not convinced that the ""terms in the parentheses"" (Eq. 7) are ""exactly the contextual bandit cost"".  I would like to see a more rigorous derivation of the connection.  For instance, one could imagine that the policy disadvantage should be the difference between the residual costs of the bandit algorithm and the reference policy, rather than just the residual cost of the bandit algorithm. \n\n-- I\'m a little unclear in the proof of Theorem 1 where Q(s,pi_n) from Eq 7 fits into Eq 8.\n\n-- The residual cost used for CB.update depends on estimated costs at other time steps h!=h_dev.  Presumably, these estimated costs will change as learning progresses.  How does one reconcile that?  I imagine that it could somehow work out using a bandit algorithm with adversarial guarantees, but I can also imagine it not working out.  I would like to see a rigorous treatment of this issue.\n\n-- It would be nice to see an end-to-end result that instantiates Theorem 1 (and/or Theorem 2) with a contextual bandit algorithm to see a fully instantiated guarantee.  \n\n\n\nWith regards to the algorithm design itself, I have some confusions:\n\n-- How does one create x in practice? I believe this is described in Appendix H, but it\'s not obvious.  \n\n-- What happens if we don\'t have a good way to generate x and it must be learned as well?  I\'d imagine one would need larger RNNs in that case. \n\n-- If x is actually learned on-the-fly, how does that impact the theoretical results?\n\n-- I find it curious that there\'s no notion of future reward learning in the learning algorithm.  For instance, in Q learning, one directly models the the long-term (discounted) rewards during learning.  In fact, the theoretical analysis talks about advantage functions as well.  It would be nice to comment on this aspect at an intuitive level.\n\n\n\nWith regards to the experiments:\n\n-- I find it very curious that the results are so negative for using only 1-dev compared to multi-dev (Figure 9 in Appendix).  Given that much of the paper is devoted to 1-dev, it\'s a bit disappointing that this issue is not analyzed in more detail, and furthermore the results are mostly hidden in the appendix.\n\n-- It\'s not clear if a reference policy was used in the experiments and what value of beta was used.\n\n-- Can the authors speculate about the difference in performance between the RL and bandit structured prediction settings?  My personal conjecture is that the bandit structured prediction settings are more easily decomposable additively, which leads to a greater advantage of the proposed approach, but I would like to hear the authors\' thoughts.\n\n\n\nFinally, the overall presentation of this paper could be substantially improved.  In addition to the above uncertainties, some more points are described below.  I don\'t view these points as ""deal breakers"" for determining accept/reject.\n\n-- This paper uses too many examples, from part-of-speech tagging to credit assignment in determining paths.  I recommend sticking to one running example, which substantially reduces context switching for the reader.  In every such example, there are extraneous details are not relevant to making the point, and the reader needs to spend considerable effort figuring that out for each example used.  \n\n-- Inconsistent language. For instance, x is sometimes referred to as the ""input example"", ""context"" and ""features"".\n\n-- At the end of page 4, ""Internally, ReslopePolicy takes a standard learning to search step.""  Two issues: 1) ReslopePolicy is not defined or referred to anywhere else.  2) is the remainder of that paragraph a description of a ""standard learning to search step""?\n\n-- As mentioned before, Regret is not defined in Theorem 1 & 2.\n\n-- The discussion of the high-level algorithmic concepts is a bit diffuse or lacking.  For instance, one key idea in the algorithmic development is that it\'s sufficient to make a uniformly random deviation.  Is this idea from the learning to search literature?  If so, it would be nice to highlight this in Section 2.2.\n\n']","[60, 20, 50]","[80, 60, 75]","[""The sentiment score is 60 (positive) because the reviewer generally expresses a favorable view of the paper. They describe it as 'dense but well written' and note that the experimental section is 'solid'. The reviewer also praises the interesting synthetic experiment. However, they mention that the theoretical grounding is 'a bit thin or hard to follow', which slightly tempers the overall positive sentiment.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They offer balanced feedback, highlighting both strengths and areas for improvement. The questions posed are framed in a curious and non-confrontational manner, inviting further discussion rather than criticizing. The reviewer also helpfully points out typos, which is a courteous gesture. The tone remains professional and collegial throughout, without any harsh or rude comments."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and potential of the work, noting 'fairly novel' approach and 'pretty good' results. However, they also express several concerns and suggest the significance is unclear, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and even thanks the authors for addressing concerns in the revision. The tone is professional and objective, avoiding harsh or rude phrasing while providing both positive and negative feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer states the paper is 'above the accept threshold' and has 'interesting' ideas and results, but also expresses several reservations and areas for improvement. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms constructively as suggestions or areas for clarification rather than harsh judgments. The reviewer balances positive feedback with detailed recommendations for improvement, maintaining a professional and courteous tone throughout.""]"
"['The paper investigates a number of additions to DDPG algorithm and their effect on performance. The additions investigated are distributional Bellman updates, N-step returns, and prioritized experience replay.\n\nThe paper does a good job of analyzing these effects on a wide range of continuous control tasks, from the standard benchmark suite, to hand manipulation, to complex terrain locomotion and I believe these results are valuable to the community.\n\nHowever, I have a concern about the soundness of using N-step returns in DDPG setting. When a sequence of length N is sampled from the replay buffer and used to calculate N-step return, this sequence is generated according a particular policy. As a result, experience is non-stationary - for the same state-action pair, early iterations of the algorithm will produce structurally different (not just due to stochasticity) N-step returns because the policy to generate those N steps has changed between algorithm iterations. So it seems to me the authors are using off-policy updates where strictly on-policy updates should be used. I would like some clarification from the authors on this point, and if it is indeed the case to bring attention to this point in the final manuscript.\n\nIt would also be useful to evaluate the effect of N for values other than 1 and 5, especially given the significance this addition has on performance. I can believe N-step returns are useful, possibly due to effectively enlarging simulation timestep, but it would be good to know at which point it becomes detrimental.\n\nI also believe ""Distributional Policy Gradients"" is an overly broad title for this submission as this work still relies on off-policy updates and does not tackle the problem of marrying distributional updates with on-policy methods. ""Distributional DDPG"" or ""Distributional Actor-Critic"" or variant perhaps could be more fair title choices?\n\nAside from these concerns, lack of originality of contributions makes it difficult to highly recommend the paper. Nonetheless, I do believe the experimental evaluation if well-conducted and would be of interest to the ICLR community. ', 'A DeepRL algorithm is presented that represents distributions over Q values, as applied to DDPG,\nand in conjunction with distributed evaluation across multiple actors, prioritized experience replay, and \nN-step look-aheads. The algorithm is called Distributed Distributional Deep Deterministic Policy Gradient algorithm, D4PG.\nSOTA results are generated for a number of challenging continuous domain learning problems,\nas compared to benchmarks that include DDPG and PPO, in terms of wall-clock time, and also (most often) in terms\nof sample efficiency.\n\npros/cons\n+ the paper provides a thorough investigation of the distributional approach, as applied to difficult continuous\n  action problems, and in conjunction with a set of other improvements (with ablation tests)\n- the story is a bit mixed in terms of the benefits, as compared to the non-distributional approach, D3PG\n- it is not clear which of the baselines are covered in detail in the cited paper:\n  ""Anonymous. Distributed prioritized experience replay. In submission, 2017."", \n   i.e., should readers assume that D3PG already exists and is attributable to this other submission?\n\nOverall, I believe that the community will find this to be interesting work.\n\nIs a video of the results available?\n\nIt seems that the distributional model often does not make much of a difference, \nas compared to D3PG non-prioritized.  However, sometimes it does make a big difference, i.e., 3D parkour; acrobot.\nDo the examples where it yields the largest payoff share a particular characteristic?\n\nThe benefit of the distributional models is quite different between the 1-step and 5-step versions. Any ideas why?\n\nOccasionally, D4PG with N=1 fails very badly, e.g., fish, manipulator (bring ball), swimmer.\nWhy would that be? Shouldn\'t it do at least as well as D3PG in general?\n\nHow many atoms are used for the categorical representation?\nAs many as [Bellemare et al.], i.e., 51 ?\nHow much ""resolution"" is necessary here in order to gain most of the benefits of the distributional representation?\n\nAs far as I understand, V_min and V_max are not the global values, but are specific to the current distribution.\nHence the need for the projection. Is that correct?\n\nWould increasing the exploration noise result in a larger benefit for the distributional approach?\n\nFigure 2: DDPG performs suprisingly poorly in most examples. Any comments on this,\nor is DDPG best avoided in normal circumstances for continuous problems? :-)\n\nIs the humanoid stand so easy because of large (or unlimited) torque limits?\n\nThe wall-clock times are for a cluster with K=32 cores for Figure 1?\n\n""we utilize a network architecture as specified in Figure 1 which processes the terrain info in order to reduce its dimensionality""\nFigure 1 provides no information about the reduced dimensionality of the terrain representation, unless I am somehow failing to see this.\n\n""the full critic architecture is completed by attaching a critic head as defined in Section A""\nI could find no further documenation in the paper with regard to the ""head"" or a separate critic for the ""head"".\nIt is not clear to me why multiple critics are needed.\n\nDo you have an intuition as to why prioritized replay might be reducing performance in many cases?\n', '\nComment: The paper proposes a simple extension to DDPG that uses a distributional Bellman operator for critic updates, and introduces two simple modifications which are the use of N-step returns and parallelizing evaluations. The method is evaluated on a wide variety of many control and robotic talks. \n\nIn general, the paper is well written and organised. However I have some following major concerns regarding the quality of the paper:\n\n- The proposal, D4PG, is quite straightforward which is simply use the idea of distributional value function by Bellemare et al. (previously used in DQN). Two modifications are also simple and well-known techniques. It would be nicer if the description in Section 3 is less straightforward by giving more justifications and analysis why and how distributional updates are necessary in the context of policy search methods like DDPG. \n\n- A positive side of the paper is a large set of evaluations on many different control and robotic tasks. For many tasks, D4PG performs better than the variant that does not use distributional updates (D3PG), however by not much. There are some tasks showing no-difference. On the other hand, the choice of N=5 in comparisons is hard to understand and lacks further experimental justifications. Different setting and new performance metrics (e.g. data efficiency, number of episodes in total) might also reveal more properties of the proposed methods.\n\n\n\n* Other minor comments:\n\n- Algorithm 1 consists of two parts but there are connection between them. It might be confused for ones who are not familiar with the actor-critic framework.\n\n- It would be nicer if all expectation operators in Section 3 comes with corresponding distributions. \n\n- page 2, second paragraph: typos in ""hence my require less samples to learn""\n\n- it might be better if the reference on arXiv should be changed to relevant publication conferences with archival proceeding: work by Marc G. Bellemare at ICML 2017']","[20, 60, -20]","[60, 80, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's good job in analyzing effects on various tasks and believes the results are valuable to the community. However, they express concerns about the soundness of using N-step returns and the lack of originality, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement without being harsh or dismissive. They use phrases like 'I believe', 'It would be useful', and 'I would like some clarification', which maintain a polite and professional tone while expressing their concerns and recommendations."", ""The sentiment score is 60 (positive) because the reviewer expresses overall positive sentiment towards the paper, stating 'I believe that the community will find this to be interesting work.' They also highlight several pros of the paper. However, it's not extremely positive as they do point out some cons and areas for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, asks questions in a constructive manner, and provides balanced feedback. They offer suggestions and inquiries without being confrontational or harsh. The use of phrases like 'Any ideas why?' and 'Do you have an intuition...' demonstrate a collegial tone. The reviewer also acknowledges the potential value of the work to the community, which is a polite gesture."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written and organised', 'positive side... large set of evaluations'), they express 'major concerns' and point out several areas for improvement. The overall tone suggests the paper needs significant work. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'It would be nicer if...' and 'might be better if...', which are polite ways to suggest improvements. The reviewer also balances criticism with positive comments, which contributes to the polite tone.""]"
"['This paper provides an interesting analysis of the importance sampled estimate of the LL bound and proposes to use Jackknife to correct for the bias. The experiments show that the proposed method works for model evaluation and that computing the correction is archivable at a reasonable computational cost. It also contains an insightful analysis.\n\n', '[After author feedback]\nI think this is an interesting paper and recommend acceptance. My remaining main comments are described in the response to author feedback below.\n\n[Original review]\nThe authors introduce jackknife variational inference (JVI), a method for debiasing Monte Carlo objectives such as the importance weighted auto-encoder. Starting by studying the bias of the IWAE bound for approximating log-marginal likelihood, the authors propose to make use of debiasing techniques to improve the approximation. For the binarized MNIST the authors show improved approximations given the same number of samples from the auxiliary distribution q(z|x).\n\nJVI seems to be an interesting extension of, and perspective on, the IWAE bound (and other Monte Carlo objectives). Some questions and comments:\n\n* The Cremer et al. (2017) paper contains some errors when interpreting the IWAE bound as a standard ELBO with a more flexible variational approximation distribution. For example eq. (1) in their paper does not correspond to an actual distribution, it is not properly normalized. This makes the connection in their section 2.1 unclear. I would suggest citing the following paper instead for this connection and the relation to importance sampling (IS):\nNaesseth, Linderman, Ranganath, Blei, ""Variational Sequential Monte Carlo"", 2017.\n\n* Regarding the analysis of the IWAE bound the paper by Rainforth et al. (2017) mentioned in the comments seems very relevant. Also, because of the strong connection between IWAE and IS detailed in the Naesseth et al. (2017) paper it is possible to make use of a standard Taylor approximation/delta methods to derive Prop. 1 and Prop. 2, see e.g. Robert & Casella, ""Monte Carlo Statistical Methods"" or Liu\'s ""Monte Carlo Strategies for Scientific Computing"".\n\n* It could be worth mentioning that the JVI objective function is now no longer (I think?) a lower bound to the log-evidence.\n\n* Could the surprising issue (IWAE-learned, JV1-evaluated being better than JV1-learned, JV1-evaluated) in Table 1 be because of different local optima?\n\n* Also, we can easily get unbiased estimates of the evidence p(x) using IS and optimize this objective wrt to model parameters. The proposal parameters can be optimized to minimize variance, how do you think this compares to the proposed method?\n\nMinor comments:\n* p(x) -> p_\\theta(x)\n* In the last paragraph of section 1 it seems like you claim that the expressiveness of p_\\theta(x|z) is a limitation of VAE. It was a bit unclear to me what was actually a general limitation of maximum likelihood versus the approximation based on VAEs.\n* Last paragraph of section 1, ""strong bound"" -> ""tight bound""\n* Last paragraph of section 2, citation missing for DVI', ""The authors analyze the bias and variance of the IWAE bound from Burda et al. (2015), and with explicit formulas up to vanishing polynomial terms and intractable moments. This leads them to derive a jacknife approach to estimate the moments as a way to debias the IWAE for finite importance weighted samples. They apply it for training and also as an evaluation method to assess the marginal likelihood at test time.\n\nThe paper is well-written and offers an interesting combination of ideas motivated from statistical analysis. Following classical results from the debiasing literature, they show a jacknife approach has reduced bias (unknown for variance). In practice, this involves an enumerated subset of calculations leading to a linear cost with respect to the number of samples which I'm inclined to agree is not too expensive.\n\nThe experiments are unfortunately limited to binarized MNIST.  Also, all benchmarks measure lower bound estimates with respect to importance samples, when it's more accurate to measure with respect to runtime. This would be far more convincing as a way to explain how that constant to the linear-time affects computation in practice.  The same would be useful to compare the estimate of the marginal likelihood over training runtime.  Also, I wasn't sure if the JVI estimator still produced a lower bound to make the comparisons. It would be useful if the authors could clarify these details.""]","[80, 60, 50]","[50, 70, 70]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'interesting' and 'insightful', and states that the proposed method 'works' and is 'achievable at a reasonable computational cost'. These are all positive assessments of the paper's content and contributions. The politeness score is 50 (somewhat polite) because the language is professional and respectful, without being overly formal or effusive. The reviewer provides a balanced and objective assessment without using any negative or critical language, which contributes to the polite tone. However, it doesn't go out of its way to be exceptionally polite either, maintaining a neutral professional tone."", ""The sentiment score is 60 (positive) because the reviewer recommends acceptance and describes the paper as 'interesting' multiple times. They provide constructive feedback and suggestions for improvement, indicating a generally positive view of the work. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the value of the authors' work. They use phrases like 'I think' and 'It could be worth mentioning' which soften their critiques. The reviewer also provides specific, helpful feedback and references to support their comments, showing engagement with the paper and respect for the authors' work."", ""The sentiment score is 50 (moderately positive) because the reviewer describes the paper as 'well-written' and offering 'an interesting combination of ideas'. They also agree with some of the authors' claims. However, they express concerns about limited experiments and suggest improvements, which prevents a higher score. The politeness score is 70 (quite polite) due to the use of respectful language throughout. The reviewer acknowledges the paper's strengths before offering constructive criticism. They use phrases like 'I'm inclined to agree' and 'It would be useful if the authors could clarify', which maintain a polite and collaborative tone. The reviewer also frames their suggestions as opportunities for improvement rather than outright criticisms.""]"
"[""The basic idea is to train a neural network to predict various hyperparameters of a classifier from input-output pairs for that classifier (kennen-o approach). It is surprising that some of these hyperparameters can even be predicted with more than chance accuracy. As a simple example, it's possible that there are values of batch size for which the classifiers may become indistinguishable, yet Table 2 shows that batch size can be predicted with much higher accuracy than chance. It would be good to provide insights into under what conditions and why hyperparameters can be predicted accurately. That would make the results much more interesting, and may even turn out to be useful for other problems, such as hyperparameter optimization.\n\nThe selection of the queries for kennen-o is not explained. What is the procedure for selecting the queries? How sensitive is the performance of kennen-o to the choice of the queries? One would expect that there is significant sensitivity, in which case it may even make sense to consider learning to select a sequence of queries to maximize accuracy.\n\nIn table 3, it would be useful to show the results for kennen-o as well, because Split-E seems to be the more realistic problem setting and kennen-o seems to be a more realistic attack than kennen-i or kennen-io.\n\nIn the ImageNet classifier family prediction, how different are the various families from each other? Without going through all the references, it is difficult to get a sense of the difficulty of the prediction task for a non-computer-vision reader.\n\nOverall the results seem interesting, but without more insights it's difficult to judge how generally useful they are."", ""The paper attempts to study model meta parameter inference e.g. model architecture, optimization, etc using a supervised learning approach. They take three approaches one whereby the target models are evaluated on a fixed set of inputs, one where the access to the gradients is assumed and using that an input is crafted that can be used to infer the target quantities and one where both approaches are combined. The authors also show that these inferred quantities can be used to generate more effective attacks against the targets.\n\nThe paper is generally well written and most details for reproducibility are seem enough. I also find the question interesting and the fact that it works on this relatively broad set of meta parameters and under a rigorous train/test split intriguing. It is of course not entirely surprising that the system can be trained but that there is some form of generalization happening. \n\nAside that I think most system in practical use will be much more different than any a priori enumeration/brute force search for model parameters. I suspect in most cases practical systems will be adapted with many subsequent levels of preprocessing, ensembling, non-standard data and a number of optimization and architectural tricks that are developer dependent. It is really hard to say what a supervised learning meta-model approach such as the one presented in this work have to say about that case. \n\nI have found it hard to understand what table 3 in section 4.2 actually means. It seems to say for instance that a model is trained on 2 and 3 layers then queried with 4 and the accuracy only slightly drops. Accuracy of what ? Is it the other attributes ? Is it somehow that attribute ? if so how can that possibly ? \n\nMy main main concern is extrapolation out of the training set which is particularly important here. I don't find enough evidence in 4.2 for that point. One experiment that i would find compelling is to train for instance a meta model on S,V,B,R but not D on imagenet, predict all the attributes except architecture and see how that changes when D is added. If these are better than random and the perturbations are more successful it would be a much more compelling story. "", '\n-----UPDATE------\n\nHaving read the responses from the authors, and the other reviews, I am happy with my rating and maintain that this paper should be accepted.\n\n----------------------\n\n\n\nIn this paper, the authors trains a large number of MNIST classifier networks with differing attributes (batch-size, activation function, no. layers etc.) and then utilises the inputs and outputs of these networks to predict said attributes successfully. They then show that they are able to use the methods developed to predict the family of Imagenet-trained networks and use this information to improve adversarial attack.\n\nI enjoyed reading this paper. It is a very interesting set up, and a novel idea.\n\nA few comments:\n\nThe paper is easy to read, and largely written well. The article is missing from the nouns quite often though so this is something that should be amended. There are a few spelling slip ups (""to a certain extend"" --> ""to a certain extent"", ""as will see"" --> ""as we will see"")\n\nIt appears that the output for kennen-o is a discrete probability vector for each attribute, where each entry corresponds to a possibility (for example, for ""batch-size"" it is a length 3 vector where the first entry corresponds to 64, the second 128, and the third 256). What happens if you instead treat it as a regression task, would it then be able to hint at intermediates (a batch size of 96) or extremes (say, 512).\n\nA flaw of this paper is that kennen-i and io appear to require gradients from the network being probed (you do mention this in passing), which realistically you would never have access to. (Please do correct me if I have misunderstood this)\n\nIt would be helpful if Section 4 had a paragraph as to your thoughts regarding why certain attributes are easier/harder to predict. Also, the caption for Table 2 could contain more information regarding the network outputs.\n\nYou have jumped from predicting 12 attributes on MNIST to 1 attribute on Imagenet. It could be beneficial to do an intermediate experiment (a handful of attributes on a middling task).\n\nI think this paper should be accepted as it is interesting and novel.\n\nPros\n------\n- Interesting idea\n- Reads well\n- Fairly good experimental results\n\nCons\n------\n- kennen-i seems like it couldn\'t be realistically deployed\n- lack of an intermediate difficulty task\n']","[20, 20, 70]","[60, 60, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges that the results are 'interesting' and 'surprising,' but also expresses some reservations and requests for more insights and explanations. The overall tone is constructive rather than overtly critical. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering suggestions with phrases like 'It would be good to' and 'it may even make sense to,' rather than making demands. The reviewer also acknowledges the potential usefulness of the work. The language is professional and objective, without any harsh criticism or rude remarks."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is 'generally well written' and finds the question 'interesting' and 'intriguing'. However, they also express concerns and suggest improvements, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'I think' and 'I have found it hard to understand' which maintain a polite tone while expressing concerns. The reviewer also offers suggestions for improvement in a courteous manner, demonstrating respect for the authors' work while providing valuable feedback."", ""The sentiment score is 70 (positive) because the reviewer expresses enjoyment of the paper, calling it 'interesting' and 'novel', and recommends acceptance. They provide both pros and cons, but the overall tone is positive. The politeness score is 80 (polite) due to the reviewer's constructive and respectful language. They offer suggestions for improvement without harsh criticism, using phrases like 'It would be helpful' and 'could be beneficial'. The reviewer also acknowledges the possibility of misunderstanding, showing respect for the authors. The language is professional and courteous throughout, maintaining a positive and encouraging tone even when pointing out potential flaws.""]"
"[""The paper proposes an approach for query answering/link prediction in KBs that uses RL to navigate the KB graph between a query entity and a potential answer entity. The main originality is that, unlike random walk models, the proposed approach learns to navigate the graph while being conditioned on the query relation type.\n\nI find the method sound and efficient and the proposed experiments are solid and convincing; for what they test for.\n\nIndeed, for each relation type that one wants to be testing on, this type of approach needs many training examples of pairs of entities (say e_1, e_2) connected both by this relation type (e_1 R e_2) and by alternative paths (e_1 R' R'' R''' e_2). Because the model needs to discover and learn that R <=> R ' R'' R''' .\n\nThe proposed model seems to be able to do that well when the number of relation types remains low (< 50). But things get interesting in KBs when the number of relation types gets pretty large (hundreds / thousands). Learning the kind of patterns described above gets much trickier then. The results on FB15k are a bit worrying in that respect. Maybe this is a matter of the dataset FB15k itself but then having experiments on another dataset with hundreds of relation types could be important. \n\nNELL has indeed 200 relations but if I'm not mistaken, the NELL dataset is used for fact prediction and not query answering. And as noted in the paper, fact prediction is much easier.\n\n"", 'The paper proposes a new approach (Minerva) to perform query answering on knowledge bases via reinforcement learning. The method is intended to answer queries of the form (e,r,?) on knowledge graphs consisting of dyadic relations. Minerva is evaluated on a number of different datasets such as WN18, NELL-995, and WikiMovies.\n\nThe paper proposes interesting ideas to attack a challenging problem, i.e., how to perform query answering on incomplete knowledge bases. While RL methods for KG completion have been proposed recently (e.g., DeepPath), Minerva improves over these approaches by not requiring the target entity. This property can be indeed be important to perform query answering efficiently. The proposed model seems technically reasonable and the paper is generally written well and good to understand. However, important parts of the paper seem currently unfinished and would benefit from a more detailed discussion and analysis.\n\nMost importantly, I\'m currently missing a better motivation and especially a more thorough evaluation on how Minerva improves over non-RL methods. For instance, the authors mention multi-hop methods such as (Neelakantan, 2015; Guu, 2015) in the introduction. Since these methods are closely related, it would be important to compare to them experimentally (unfortunately, DeepPath doesn\'t do this comparison either). For instance, eliminating the need to pre-compute paths might be irrelevant when it doesn\'t improve actual performance. Similarly, the paper mentions improved inference time, which indeed is a nice feature. However, I\'m wondering, what is the training time and how does it compare to standard methods like ComplEx. Also, how robust is training using REINFORCE?\n\nWith regard to the experimental results: The  improvements over DeepPath on NELL and on WikiMovies are indeed promising. I found the later results the most convincing, as the setting is closest to the actual task of query answering. However, what is worrying is that Minerva doesn\'t do well on WN18 and FB15k-237 (for which the results are, unfortunately, only reported in the appendix). On FB15k-237 (which is harder than WN18 and arguably more relevant for real-world scenarios since it is a subset of a real-world knowledge graph), it is actually outperformed by the relatively simple DistMult method. From these results, I find it hard to justify that ""MINERVA obtains state-of-the-art results on seven KB datasets, significantly outperforming prior methods"", as stated in the abstract.\n\nFurther comments:\n- How are non-existing relations handled, i.e., queries (e,r,x) where there is no valid x? Does Minerva assume there is always a valid answer?\n- Comparison to DeepPath: Did you evaluate Minerva with fixed embeddings? Since the experiments in DeepPath used fixed embeddings, it would be important to know how much of the improvements can be attributed to this difference. \n- The experimental section covers quite a lot of different tasks and datasets (Countries, UMLS, Nations, NELL, WN18RR, Gridworld, WikiMovies) all with different combinations of methods. For instance, countries is evaluated against ComplEx,NeuralLP and NTP; NELL against DeepPath; WN18RR against ConvE, ComplEx, and DistMult; WikiMovies against MemoryNetworks, QA and NeuralLP. A more focused evaluation with a consistent set of methods could make the experiments more insightful.', ""The paper present a RL based approach to walk on a knowledge graph to answer queries. The idea is novel, the paper is clear in its exposition, and the authors provide a number of experimental comparisons with prior work on a variety of datasets . \n\nPros:\n1. The approach is simple (no pre-training, no reward shaping, just RL from scratch with terminal reward, uses LSTM for keeping track of past state), computationally efficient (no computation over the full graph), and performs well in most of the experiments reported in the paper. \n2. It scales well to longer path lengths, and also outperforms other methods for partially structured queries.\n\nCons:\n1. You should elaborate more on the negative results on FB15K and why this performance would not transfer to other KB datasets that exist. This seems especially important since it's a large scale dataset, while the datasets a)-c) reported in the paper are small scale. \n2. It would also be good to see if your method also performed well on the Nations dataset where the baselines performed well. That said, if its a small scale dataset, it would be preferable to focus on strengthening the experimental analysis on larger datasets.\n3. In Section 4.2, why have you only compared to NeuralLP and not compared with the other methods? \n\nSuggestions/Questions:\n1. In the datatset statistics, can you also add the average degree of the knowledge graphs, to get a rough sense of the difficulty of each task.\n2. The explanation of the knowledge graph and notation could be made cleaner. It would be easier to introduce the vertices as the entities, and edges as normal edges with a labelled relation on top. A quick example to explain the action space would also help.\n3. Did you try a model where instead of using A_t directly as the weight vector for the softmax, you use it as an extra input? Using it as the weight matrix directly might be over regularizing/constraining your model.  \n\nRevision: I appreciate the effort by the authors to update the paper. All my concerns were adequately addressed, plus improvements were made to better understand the comparison with other work. I update my review to 7: Good paper, accept.""]","[50, 20, 80]","[75, 60, 70]","[""The sentiment score is 50 (moderately positive) because the reviewer finds the method 'sound and efficient' and the experiments 'solid and convincing'. However, they also express concerns about the model's performance with a large number of relation types, which tempers the overall positivity. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively pointing out potential limitations. They use phrases like 'I find' and 'Maybe this is' which maintain a courteous tone while offering critique. The review is objective and professional, avoiding harsh criticism or overly effusive praise."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting ideas and potential improvements over existing methods. However, they also express concerns about missing comparisons and underwhelming performance on some datasets. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while providing constructive criticism. They use phrases like 'The paper proposes interesting ideas' and 'The proposed model seems technically reasonable,' which maintain a polite tone even when pointing out areas for improvement. The reviewer also offers specific suggestions for enhancing the paper, which is a courteous way to provide feedback."", ""The sentiment score is 80 (positive) because the reviewer starts by highlighting the novelty of the approach, clarity of the paper, and comprehensive experimental comparisons. They list several pros and only a few cons, which are presented as suggestions for improvement rather than major flaws. The final statement indicates the reviewer's satisfaction with the authors' revisions and recommends acceptance. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms constructively. Phrases like 'I appreciate the effort' and the use of 'suggestions' rather than demands contribute to the polite tone. The reviewer maintains a professional and courteous demeanor while providing both positive feedback and areas for improvement.""]"
"[""This paper studies a new architecture DualAC. The author give strong and convincing justifications based on the Lagrangian dual of the Bellman equation (although not new, introducing this as the justification for the architecture design is plausible).\n\nThere are several drawbacks of the current format of the paper:\n1. The algorithm is vague. Alg 1 line 5: 'closed form': there is no closed form in Eq(14). It is just an MC approximation.\nline 6: Decay O(1/t^\\beta). This is indeed vague albeit easy to understand. The algorithm requires that every step is crystal clear.\n\n2. Also, there are several format error which may be due to compiling, e.g., line 2 of Abstract,'Dual-AC ' (an extra space). There are many format errors like this throughout the paper. The author is suggested to do a careful format check.\n\n3. The author is suggested to explain more about the necessity of introducing path regularization and SDA. The current justification is reasonable but too brief.\n\n4. The experimental part is ok to me, but not very impressive.\n\nOverall, this seems to be a nice paper to me."", 'The paper is well written, and the authors do an admirable job of motivating their primary contributions throughout the early portions of the paper. Each extension to the Dual Actor-Critic is well motivated and clear in context. Perhaps the presentation of these extensions could be improved by providing a less formal explanation of what each does in practice; multi-step updates, regularized against MC returns, stochastic mirror descent. \n\nThe practical implementation section losses some of this clear organization, and could certainly be clarified each part tied into Algorithm 1, and this was itself made less high-level. But these are minor gripes overall.\n\nTurning to the experimental section, I think the authors did a good job of evaluating their approach with the ablation study and comparisons with PPO and TRPO. There were a few things that jumped out to me that I was surprised by. The difference in performance for Dual-AC between Figure 1 and Figure 2b is significant, but the only difference seems to be a reduce batch size, is this right? This suggests a fairly significant sensitivity to this hyperparameter if so.\n\nReproducibility in continuous control is particularly problematic. Nonetheless, in recent work PPO and TRPO performance on the same set of tasks seem to be substantively different than what the authors get in their experiments. I\'m thinking in particular of:\n\nProximal Policy Optimization Algorithms (Schulman et. al., 2017)\nMulti-Batch Experience Replay for Fast Convergence of Continuous Action Control (Han and Sung, 2017)\n\nIn both these cases the results for PPO and TRPO vary pretty significantly from what we see here, and an important one to look at is the InvertedDoublePendulum-v1 task, which I would think PPO would get closer to 8000, and TRPO not get off the ground. Part of this could be the notion of an ""iteration"", which was not clear to me how this corresponded to actual time steps. Most likely, to my mind, is that the parameterization used (discussed in the appendix) is improving TRPO and hurting PPO.\n\nWith these in mind I view the comparison results with a bit of uncertainty about the exact amount of gain being achieved, which may beg the question if the algorithmic contributions are buying much for their added complexity?\n\nPros:\nWell written, thorough treatment of the approaches\nImprovements on top of Dual-AC with ablation study show improvement\n\nCons:\nEmpirical gains might not be very large\n', 'This paper proposes a method, Dual-AC, for optimizing the actor(policy) and critic(value function) simultaneously which takes the form of a zero-sum game resulting in a principled method for using the critic to optimize the actor. In order to achieve that, they take the linear programming approach of solving the bellman optimality equations, outline the deficiencies of this approach, and propose solutions to mitigate those problems. The discussion on the deficiencies of the naive LP approach is mostly well done. Their main contribution is extending the single step LP formulation to a multi-step dual form that reduces the bias and makes the connection between policy and value function optimization much clearer without loosing convexity by applying a regularization. They perform an empirical study in the Inverted Double Pendulum domain to conclude that their extended algorithm outperforms the naive linear programming approach without the improvements. Lastly, there are empirical experiments done to conclude the superior performance of Dual-AC in contrast to other actor-critic algorithms. \n\nOverall, this paper could be a significant algorithmic contribution, with the caveat for some clarifications on the theory and experiments. Given these clarifications in an author response, I would be willing to increase the score. \n\nFor the theory, there are a few steps that need clarification and further clarification on novelty. For novelty, it is unclear if Theorem 2 and Theorem 3 are both being stated as novel results. It looks like Theorem 2 has already been shown in ""Randomized Linear Programming Solves the Discounted Markov Decision Problem in Nearly-Linear Running Time”. There is a statement that “Chen & Wang (2016); Wang (2017) apply stochastic first-order algorithms (Nemirovski et al., 2009) for the one-step Lagrangian of the LP problem in reinforcement learning setting. However, as we discussed in Section 3, their algorithm is restricted to tabular parametrization”. Is you Theorem 2 somehow an extension? Is Theorem 3 completely new?\n\nThis is particularly called into question due to the lack of assumptions about the function class for value functions. It seems like the value function is required to be able to represent the true value function, which can be almost as restrictive as requiring tabular parameterizations (which can represent the true value function). This assumption seems to be used right at the bottom of Page 17, where U^{pi*} = V^*. Further, eta_v must be chosen to ensure that it does not affect (constrain) the optimal solution, which implies it might need to be very small. More about conditions on eta_v would be illuminating. \n\nThere is also one step in the theorem that I cannot verify. On Page 18, how is the squared removed for difference between U and Upi? The transition from the second line of the proof to the third line is not clear. It would also be good to more clearly state on page 14 how you get the first inequality, for || V^* ||_{2,mu}^2. \n\n\nFor the experiments, the following should be addressed.\n\n1. It would have been better to also show the performance graphs with and without the improvements for multiple domains.\n\n2. The central contribution is extending the single step LP to a multi-step formulation. It would be beneficial to empirically demonstrate how increasing k (the multi-step parameter) affects the performance gains.\n\n3. Increasing k also comes at a computational cost. I would like to see some discussions on this and how long dual-AC takes to converge in comparison to the other algorithms tested (PPO and TRPO).\n\n4. The authors concluded the presence of local convexity based on hessian inspection due to the use of path regularization. It was also mentioned that increasing the regularization parameter size increases the convergence rate. Empirically, how does changing the regularization parameter affect the performance in terms of reward maximization? In the experimental section of the appendix, it is mentioned that multiple regularization settings were tried but their performance is not mentioned. Also, for the regularization parameters that were tried, based on hessian inspection, did they all result in local convexity? A bit more discussion on these choices would be helpful. \n\nMinor comments:\n1. Page 2: In equation 5, there should not be a \'ds\' in the dual variable constraint']","[50, 20, 20]","[60, 60, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by acknowledging the paper's strengths and justifications, and concludes that it 'seems to be a nice paper'. However, they also list several drawbacks, which prevents the score from being higher. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, such as 'the author is suggested to' instead of more direct commands. They also balance criticism with positive feedback. The reviewer's tone is professional and constructive, offering specific recommendations for improvement without being harsh or dismissive."", ""The sentiment score is slightly positive (20) because the reviewer starts with praise for the paper's writing and motivation, and acknowledges the authors' 'admirable job'. However, they also express some concerns and uncertainties about the results, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while framing criticisms as suggestions or personal observations (e.g., 'Perhaps the presentation...could be improved', 'I think the authors did a good job'). The reviewer also balances positive and negative points, listing both 'Pros' and 'Cons' at the end, which contributes to a polite and balanced tone."", ""Sentiment Score (20): The review starts with a positive tone, acknowledging the paper's potential as a 'significant algorithmic contribution'. However, it also expresses several concerns and requests for clarification, which tempers the overall positivity. The reviewer states they would be willing to increase the score given clarifications, indicating a cautiously positive stance.\n\nPoliteness Score (60): The language used is generally polite and professional. The reviewer uses phrases like 'could be a significant contribution' and 'I would be willing to increase the score', which are constructive and encouraging. They also frame their criticisms as requests for clarification rather than outright rejections. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional, slightly formal tone throughout.""]"
"[""The paper provides an interesting data collection scheme that improves upon standard collection of static databases that have multiple shortcomings -- End of Section 3 clearly summarizes the advantages of the proposed algorithm. The paper is easy to follow and the evaluation is meaningful.\n\nIn MTD, both data collection and training the model are intertwined and so, the quality of the data can be limited by the learning capacity of the model. It is possible that after some iterations, the data distribution is similar to previous rounds in which case, the dataset becomes similar to static data collection (albeit at a much higher cost and effort). Is this observed ? Further, is it possible to construct MTD variants that lead to constantly improving datasets by being agnostic to the actual model choice ? For example, utilizing only the priors of the D_{train_all}, mixing model and other humans' predictions, etc.\n\n\n\n"", 'TL;DR of paper: Improved human-in-the-loop data collection using crowdsourcing. The basic gist is that on every round, N mechanical turkers will create their own dataset. Each turker gets a copy of a base model which is trained on their own dataset, and each trained model is evaluated on all the other turker datasets. The top-performing models get a cash bonus, incentivizing turkers to provide high quality training data. A new base model is trained on the pooled-together data of all the turkers, and a new round begins. The results indicate an improvement over static data collection.\n\nThis idea of HITL dataset creation is interesting, because the competitive aspect incentivizes turkers to produce high quality data. Judging by the feedback given by turkers in the appendix, the workers seem to enjoy the competitive aspect, which would hopefully lead to better data. The results seem to suggest that MTD provides an improvement over non-HITL methods.\n\nThe authors repeatedly emphasize the ""collaborative"" aspect of MTD, saying that the turkers have to collaborate to produce similar dataset distributions, but this is misleading because the turkers don\'t get to see other datasets. MTD is mostly competitive, and the authors should reduce the emphasis on a stretched definition of collaboration.\n\nOne questionable aspect of MTD is that the turkers somehow have to anticipate what are the best examples for the model to train with. That is, the turkers have to essentially perform the example selection process in active learning with relatively little interaction with the training model. While the turkers are provided immediate feedback when the model already correctly classifies the proposed training example, it seems difficult for turkers to anticipate when an example is too hard, because they have no idea about the learning process.\n\nMy biggest criticism is that MTD seems more like an NLP paper rather than an ICLR paper. I gave a 7 because I like the idea, but I wouldn\'t be upset if the AC recommends submitting to an NLP conference instead.', 'The authors propose a framework for interactive language learning, called Mechanical Turker Descent (MTD). Over multiple iterations, Turkers provide training examples for a language grounding task, and they are incentivized to provide new training examples that quickly improve generalization. The framework is straightforward and makes few assumptions about the task, making it applicable to potentially more than grounded language. Unlike recent works on ""grounded language"" using synthetic templates, this work operates over real language while maintaining interactivity.\n \nResult show that the interactive learning outperforms the static learning baseline, but there are potential problems with the way the test set is collected. In MTD, the same users inherently provide both training and test examples. In the collaborative-only baseline, it is possible to ensure that the train and test sets are never annotated by the same user (which is ideal for testing generalization). If train and test sets are split this way, it would give an unfair advantage to MTD. Additionally, there is potentially a different distribution of language for gamified and non-gamified settings. By aggregating the test set over 3 MTD scenarios and 1 static scenario, the test set could be skewed towards gamified language, again making it unfair to the baseline. I would like to see the results over the different test subsets, allowing us to verify whether MTD outperforms the baseline for the baseline\'s test data.']","[80, 50, 50]","[70, 60, 75]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'interesting' and notes that it 'improves upon standard collection' methods. They also mention that the paper is 'easy to follow' and the evaluation is 'meaningful', all of which are positive comments. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and asking questions in a constructive manner. They use phrases like 'Is this observed?' and 'Is it possible...?' which show a polite and inquisitive approach rather than harsh criticism. The reviewer also offers suggestions for improvement in a courteous way, indicating a respectful tone overall."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses interest in the idea and acknowledges its potential benefits, stating 'This idea of HITL dataset creation is interesting' and 'The results seem to suggest that MTD provides an improvement over non-HITL methods.' However, they also raise some criticisms and suggest it might be better suited for an NLP conference, which tempers the overall positivity. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They acknowledge the paper's strengths before pointing out areas for improvement, and use phrases like 'My biggest criticism is...' which softens the critique. The reviewer also explains their reasoning for the score given, which is a polite gesture."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the strengths of the proposed framework, such as its straightforward nature and applicability to real language. However, they also raise concerns about potential problems with the test set collection, indicating a balanced view. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the authors' work positively before presenting their concerns. They use phrases like 'I would like to see' rather than making demands, maintaining a courteous tone while providing constructive feedback.""]"
"['The authors present an algorithm for training ensembles of policy networks that regularly mixes different policies in the ensemble together by distilling a mixture of two policies into a single policy network, adding it to the ensemble and selecting the strongest networks to remain (under certain definitions of a ""strong"" network). The experiments compare favorably against PPO and A2C baselines on a variety of MuJoCo tasks, although I would appreciate a wall-time comparison as well, as training the ""crossover"" network is presumably time-consuming.\n\nIt seems that for much of the paper, the authors could dispense with the genetic terminology altogether - and I mean that as a compliment. There are few if any valuable ideas in the field of evolutionary computing and I am glad to see the authors use sensible gradient-based learning for GPO, even if it makes it depart from what many in the field would consider ""evolutionary"" computing. Another point on terminology that is important to emphasize - the method for training the crossover network by direct supervised learning from expert trajectories is technically not imitation learning but behavioral cloning. I would perhaps even call this a distillation network rather than a crossover network. In many robotics tasks behavioral cloning is known for overfitting to expert trajectories, but that may not be a problem in this setting as ""expert"" trajectories can be generated in unlimited quantities.', 'This is a highly interesting paper that proposes a set of methods that combine ideas from imitation learning, evolutionary computation and reinforcement learning in a novel way. It combines the following ingredients:\na) a population-based setup for RL\nb) a pair-selection and crossover operator\nc) a policy-gradient based “mutation” operator\nd) filtering data by high-reward trajectories\ne) two-stage policy distillation\n\nIn its current shape it has a couple of major flaws (but those can be fixed during the revision/rebuttal period):\n\n(1) Related work. It is presented in a somewhat ahistoric fashion. In fact, ideas for evolutionary methods applied to RL tasks have been widely studied, and there is an entire research field called “neuroevolution” that specifically looks into which mutation and crossover operators work well for neural networks. I’m listing a small selection of relevant papers below, but I’d encourage the authors to read a bit more broadly, and relate their work to the myriad of related older methods. Ideally, a more reasonable form of parameter-crossover (see references) could be compared to -- the naive one is too much of a straw man in my opinion. To clarify: I think the proposed method is genuinely novel, but a bit of context would help the reader understand which aspects are and which aspects aren’t.\n\n(2) Ablations. The proposed method has multiple ingredients, and some of these could be beneficial in isolation: for example a population of size 1 with an interleaved distillation phase where only the high-reward trajectories are preserved could be a good algorithm on its own. Or conversely, GPO without high-reward filtering during crossover. Or a simpler genetic algorithm that just preserves the kills off the worst members of the population, and replaces them by (mutated) clones of better ones, etc. \n\n(3) Reproducibility. There are a lot of details missing; the setup is quite complex, but only partially described. Examples of missing details are: how are the high-reward trajectories filtered? What is the total computation time of the different variants and baselines? The x-axis on plots, does it include the data required for crossover/Dagger? What are do the shaded regions on plots indicate? The loss on \\pi_S should be made explicit. An open-source release would be ideal.\n\nMinor points:\n- naively, the selection algorithm might not scale well with the population size (exhaustively comparing all pairs), maybe discuss that?\n- the filtering of high-reward trajectories is what estimation of distribution algorithms [2] do as well, and they have a known failure mode of premature convergence because diversity/variance shrinks too fast. Did you investigate this?\n- for Figure 2a it would be clearer to normalize such that 1 is the best and 0 is the random policy, instead of 0 being score 0.\n- the language at the end of section 3 is very vague and noncommittal -- maybe just state what you did, and separately give future work suggestions?\n- there are multiple distinct metrics that could be used on the x-axis of plots, namely: wallclock time, sample complexity, number of updates. I suspect that the results will look different when plotted in different ways, and would enjoy some extra plots in the appendix. For example the ordering in Figure 6 would be inverted if plotting as a function of sample complexity?\n- the A2C results are much worse, presumably because batchsizes are different? So I’m not sure how to interpret them: should they have been run for longer? Maybe they could be relegated to the appendix?\n\nReferences:\n[1] Gomez, F. J., & Miikkulainen, R. (1999). Solving non-Markovian control tasks with neuroevolution.\n[2] Larranaga, P. (2002). A review on estimation of distribution algorithms.\n[3] Stanley, K. O., & Miikkulainen, R. (2002). Evolving neural networks through augmenting topologies. \n[4] Igel, C. (2003). Neuroevolution for reinforcement learning using evolution strategies.\n[5] Hausknecht, M., Lehman, J., Miikkulainen, R., & Stone, P. (2014). A neuroevolution approach to general atari game playing.\n[6] Gomez, F., Schmidhuber, J., & Miikkulainen, R. (2006). Efficient nonlinear control through neuroevolution.\n\n\nPros:\n- results\n- novelty of idea\n- crossover visualization, analysis\n- scalability\n\nCons:\n- missing background\n- missing ablations\n- missing details\n\n[after rebuttal: revised the score from 7 to 8]', 'This paper proposes a genetic algorithm inspired policy optimization method, which mimics the mutation and the crossover operators over policy networks.\n\nThe title and the motivation about the genetic algorithm are missing leading and improper. The genetic algorithm is a black-box optimization method, however, the proposed method has nothing to do with black-box optimization. \n\nThe mutation is a method to sample individual independence of the objective function, which is very different with the gradient step. Mimicking the mutation by a gradient step is very unreasonable. \n\nThe crossover operator is the policy mixing method employed in game context (e.g., Deep Reinforcement Learning from Self-Play in Imperfect-Information Games, https://arxiv.org/abs/1603.01121 ). It is straightforward if two policies are to be mixed. Although the mixing method is more reasonable than the genetic crossover operator, it is strange to compare with that operator in a method far away from the genetic algorithm.\n\nIt is highly suggested that the method is called as population-based method as a set of networks is maintained, instead of as ""genetic"" method.\n\nAnother drawback, perhaps resulted from the ""genetic algorithm"" motivation is that the proposed method has not been well explained. The only explanation is that this method mimics the genetic algorithm. However, this explanation reveals nothing about why the method could work well -- a random exploration could also waste a lot of samples with a very high probability.\n\nThe baseline methods result in rewards much lower than those in previous experimental papers. It is problemistic that if the baselines have bad parameters.\n1. Benchmarking Deep Reinforcement Learning for Continuous Control\n2. Deep Reinforcement Learning that Matters']","[50, 50, -70]","[70, 75, -20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the favorable comparison of the algorithm against baselines and compliments the authors on using gradient-based learning. However, they also request additional information (wall-time comparison) and suggest terminology changes, indicating a balanced view. The politeness score is 70 (fairly polite) due to the reviewer's constructive tone, use of phrases like 'I would appreciate' and 'I mean that as a compliment', and the overall respectful manner of providing feedback and suggestions. The reviewer maintains a professional and courteous tone throughout, even when suggesting changes or pointing out potential issues."", ""The sentiment score is 50 (moderately positive) because the reviewer starts by calling the paper 'highly interesting' and praising its novel approach. However, they also mention 'major flaws', balancing out the initial positivity. The overall tone suggests the paper has significant potential but needs improvements. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and provides helpful suggestions and references. They use phrases like 'I'd encourage the authors' and 'I think the proposed method is genuinely novel', which are encouraging and polite. The reviewer also frames criticisms as opportunities for improvement rather than outright flaws, maintaining a collegial tone."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer criticizes the paper's title, motivation, and methodology, stating they are 'misleading and improper'. They point out several flaws in the approach and suggest significant changes. The politeness score is -20 because while the language isn't overtly rude, it's quite direct and critical without much attempt to soften the feedback. Phrases like 'highly suggested' and 'problemistic' indicate a somewhat forceful tone. The reviewer doesn't use any polite phrases or acknowledge positive aspects, which contributes to the slightly negative politeness score.""]"
"['This paper presents a new covariance function for Gaussian processes (GPs) that is equivalent to a Bayesian deep neural network with a Gaussian prior on the weights and an infinite width. As a result, exact Bayesian inference with a deep neural network can be solved with the standard GP machinery.\n\n\nPros:\n\nThe result highlights an interesting relationship between deep nets and Gaussian processes. (Although I am unsure about how much of the kernel design had already appeared outside of the GP literature.)\n\nThe paper is clear and very well written.\n\nThe analysis of the phases in the hyperparameter space is interesting and insightful. On the other hand, one of the great assets of GPs is the powerful way to tune their hyperparameters via maximisation of the marginal likelihood but the authors have left this for future work!\n\n\nCons:\n\nAlthough the computational complexity of computing the covariance matrix is given, no actual computational times are reported in the article.\n\nI suggest using the same axis limits for all subplots in Figure 3.', 'This paper leverages how deep Bayesian NNs, in the limit of infinite width, are Gaussian processes (GPs). After characterizing the kernel function, this allows us to use the GP framework for prediction, model selection, uncertainty estimation, etc.\n\n\n- Pros of this work\n\nThe paper provides a specific method to efficiently compute the covariance matrix of the equivalent GP and shows experimentally on CIFAR and MNIST the benefits of using the this GP as opposed to a finite-width non-Bayesian NN.\n\nThe provided phase analysis and its relation to the depth of the network is also very interesting.\n\nBoth are useful contributions as long as deep wide Bayesian NNs are concerned. A different question is whether that regime is actually useful.\n\n\n- Cons of this work\n\nAlthough this work introduces a new GP covariance function inspired by deep wide NNs, I am unconvinced of the usefulness of this regime for the cases in which deep learning is useful. \n\nFor instance, looking at the experiments, we can see that on MNIST-50k (the one with most data, and therefore, the one that best informs about the ""true"" underlying NN structure) the inferred depth is 1 for the GP and 2 for the NN, i.e., not deep. Similarly for CIFAR, where only up to depth 3 is used. None of these results beat state-of-the-art deep NNs.\n\nAlso, the results about the phase structure show how increased depth makes the parameter regime in which these networks work more and more constrained. \n\nIn [1], it is argued that kernel machines with fixed kernels do not learn a hierarchical representation. And such representation is generally regarded as essential for the success of deep learning. \n\nMy impression is that the present line of work will not be relevant for deep learning and will not beat state-of-the-art results because of the lack of a structured prior. In that sense, to me this work is more of a negative result informing that to be successful, deep Bayesian NNs should not be wide and should have more structure to avoid reaching the GP regime.\n\n\n- Other comments:\n\nIn Fig. 5, use a consistent naming for the axes (bias and variances).\n\nIn Fig. 1, I didn\'t find the meaning of the acronym NN with no specified width.\n\nDoes the unit norm normalization used to construct the covariance disallow ARD input selection?\n\n\n[1] Yoshua Bengio, Olivier Delalleau, and Nicolas Le Roux. The Curse of Dimensionality for Local Kernel Machines. 2005.', 'Neal (1994) showed that a one hidden layer Bayesian neural network, under certain conditions, converges to a Gaussian process as the number of hidden units approaches infinity. Neal (1994) and Williams (1997) derive the resulting kernel functions for such Gaussian processes when the neural networks have certain transfer functions.\n\nSimilarly, the authors show an analogous result for deep neural networks with multiple hidden layers and an infinite number of hidden units per layer, and show the form of the resulting kernel functions. For certain transfer functions, the authors perform a numerical integration to compute the resulting kernels. They perform experiments on MNIST and CIFAR-10, doing classification by scaled regression. \n\nOverall, the work is an interesting read, and a nice follow-up to Neal’s earlier observations about 1 hidden layer neural networks. It combines several insights into a nice narrative about infinite Bayesian deep networks. However, the practical utility, significance, and novelty of this work -- in its current form -- are questionable, and the related work sections, analysis, and experiments should be significantly extended. \n\n\nIn detail:\n\n(1) This paper misses some obvious connections and references, such as \n* Krauth et. al (2017): “Exploring the capabilities and limitations of Gaussian process models” for recursive kernels with GPs.\n* Hazzan & Jakkola (2015): “Steps Toward Deep Kernel Methods from Infinite Neural Networks” for GPs corresponding to NNs with more than one hidden layer.\n* The growing body of work on deep kernel learning, which “combines the inductive biases and representation learning abilities of deep neural networks with the non-parametric flexibility of Gaussian processes”. E.g.: (i) “Deep Kernel Learning” (AISTATS 2016); (ii) “Stochastic Variational Deep Kernel Learning” (NIPS 2016); (iii) “Learning Scalable Deep Kernels with Recurrent Structure” (JMLR 2017). \n\nThese works should be discussed in the text.\n\n(2) Moreover, as the authors rightly point out, covariance functions of the form used in (4) have already been proposed. It seems the novelty here is mainly the empirical exploration (will return to this later), and numerical integration for various activation functions. That is perfectly fine -- and this work is still valuable. However, the statement “recently, kernel functions for multi-layer random neural networks have been developed, but only outside of a Bayesian framework” is incorrect. For example, Hazzan & Jakkola (2015) in “Steps Toward Deep Kernel Methods from Infinite Neural Networks” consider GP constructions with more than one hidden layer. Thus the novelty of this aspect of the paper is overstated. \n\nSee also comment [*] later on the presentation. In any case, the derivation for computing the covariance function (4) of a multi-layer network is a very simple reapplication of the procedure in Neal (1994). What is less trivial is estimating (4) for various activations, and that seems to the major methodological contribution. \n\nAlso note that multidimensional CLT here is glossed over. It’s actually really unclear whether the final limit will converge to a multidimensional Gaussian with that kernel without stronger conditions.  This derivation should be treated more thoroughly and carefully.\n\n(3) Most importantly, in this derivation, we see that the kernels lose the interesting representations that come from depth in deep neural networks. Indeed, Neal himself says that in the multi-output settings, all the outputs become uncorrelated. Multi-layer representations are mostly interesting because each layer shares hidden basis functions. Here, the sharing is essentially meaningless, because the variance of the weights in this derivation shrinks to zero. \nIn Neal’s case, the method was explored for single output regression, where the fact that we lose this sharing of basis functions may not be so restrictive. However, these assumptions are very constraining for multi-output classification and also interesting multi-output regressions.\n\n[*]: Generally, in reading the abstract and introduction, we get the impression that this work somehow allows us to use really deep and infinitely wide neural networks as Gaussian processes, and even without the pain of training these networks. “Deep neural networks without training deep networks”. This is not an accurate portrayal. The very title “Deep neural networks as Gaussian processes” is misleading, since it’s not really the deep neural networks that we know and love. In fact, you lose valuable structure when you take these limits, and what you get is very different than a standard deep neural network. In this sense, the presentation should be re-worked.\n\n(4) Moreover, neural networks are mostly interesting because they learn the representation. To do something similar with GPs, we would need to learn the kernel. But here, essentially no kernel learning is happening. The kernel is fixed. \n\n(5) Given the above considerations, there is great importance in understanding the practical utility of the proposed approach through a detailed empirical evaluation. In other words, how structured is this prior and does it really give us some of the interesting properties of deep neural networks, or is it mostly a cute mathematical trick?  \n\nUnfortunately, the empirical evaluation is very preliminary, and provides no reassurance that this approach will have any practical relevance:\n(i) Directly performing regression on classification problems is very heuristic and unnecessary.\n(ii) Given the loss of dependence between neurons in this approach, it makes sense to first explore this method on single output regression, where we will likely get the best idea of its useful properties and advantages. \n(iii) The results on CIFAR10 are very poor. We don’t need to see SOTA performance to get some useful insights in comparing for example parametric vs non-parametric, but 40% more error than SOTA makes it very hard to say whether any of the observed patterns hold weight for more competitive architectural choices. \n\nA few more minor comments:\n(i) How are you training a GP exactly on 50k training points? Even storing a 50k x 50k matrix requires about 20GB of RAM. Even with the best hardware, computing the marginal likelihood dozens of times to learn hyperparameters would be near impossible. What are the runtimes?\n(ii) ""One benefit in using the GP is due to its Bayesian nature, so that predictions have uncertainty estimates (Equation (9)).”  The main benefit of the GP is not the uncertainty in the predictions, but the marginal likelihood which is useful for kernel learning.']","[60, -20, -50]","[80, 60, 20]","[""The sentiment score is 60 (positive) because the reviewer starts with a neutral summary and then lists several pros, including that the paper is 'clear and very well written' and presents 'interesting and insightful' analysis. The cons mentioned are relatively minor. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions (e.g., 'I suggest using...'). The reviewer also uses phrases like 'interesting relationship' and 'insightful' which contribute to a positive and polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the work, they express significant doubts about its usefulness and relevance to deep learning. The reviewer states they are 'unconvinced of the usefulness of this regime' and suggests the work might be more of a 'negative result'. However, the review is not entirely negative, as it does highlight some positive aspects, which prevents the score from being lower. The politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'My impression is...' and 'I am unconvinced...' rather than making blunt or harsh statements. The reviewer also balances criticism with praise, acknowledging both pros and cons of the work. The language is formal and constructive, offering specific suggestions for improvement, which contributes to the polite tone."", ""The sentiment score is -50 because while the reviewer acknowledges the work as 'interesting' and 'a nice follow-up', they express significant concerns about its practical utility, significance, and novelty. They point out several shortcomings and areas for improvement, indicating a generally negative sentiment. However, it's not entirely negative as they do recognize some value in the work. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'interesting read' and 'nice narrative'. They provide constructive criticism and detailed explanations for their concerns, which is respectful. However, they don't go out of their way to be overly polite or complimentary, keeping the tone mostly neutral with a slight lean towards politeness.""]"
"['Please see my detailed comments in the ""official comment""\n\nThe extensive revisions addressed most of my concerns\n\nQuality\n======\nThe idea is interesting, the theory is hand-wavy at best (ADDRESSED but still a bit vague), the experiments show that it works but don\'t evaluate many interesting/relevant aspects (ADDRESSED). It is also unclear how much tuning is involved (ADDRESSED).\n\nClarity\n=====\nThe paper reads OK. The general idea is clear but the algorithm is only provided in vague text form (and actually changing from sequential to asynchronous without any justification why this should work) (ADDRESSED) leaving many details up the the reader\'s best guess (ADDRESSED).\n\nOriginality\n=========\nThe idea looks original.\n\nSignificance\n==========\nIf it works as advertised this approach would mean a drastic speedup on previously unseen task from the same distribution.\n\nPros and Cons\n============\n+ interesting idea\n- we do everything asynchronously and in parallel and it magically works (ADDRESSED)\n- many open questions / missing details (ADDRESSED)', 'This paper proposes a novel hierarchical reinforcement learning method for a fairly particular setting.  The setting is one where the agent must solve some task for many episodes in a sequence, after which the task will change and the process repeats.  The proposed solution method splits the agent into two components, a master policy which is reset to random initial weights for each new task, and several sub-policies (motor primitives) that are selected between by the master policy every N steps and whose weights are not reset on task switches.  The core idea is that the master policy is given a relatively easy learning task of selecting between useful motor primitives and this can be efficiently learned from scratch on each new task, whereas learning the motor primitives occurs slowly over many different tasks.  To push this motivation into the learning process, the master policy is updated always but the sub-policies are only updated after an extended warmup period (called the joint-update or training period).  This experiments include both small domains (moving to 2D goals and four-rooms) and more complex physics simulations (4-legged ants and humanoids).  In both the simple and complex domains, the proposed method (MLSH) is able to robustly achieve good performance.\n\nThis approach to obtaining complex structured behavior appears impressive despite the amount of temporal structure that must be provided to the method (the choice of N, the warmup period, and the joint-update period).  Relying on the temporal structure for the hierarchy, and forcing the master policy to be relearned from scratch for each new task may be problematic in general, but this work shows that in some complex settings, a simple temporal decomposition may be sufficient to encourage the development of reusable motor primitives and to also enable quick learning of meta-policies over these motor-primitives.  Moreover, the results show that these temporal hierarchies are helpful in these domains, as the corresponding non-hierarchical methods failed on the more challenging tasks.\n\nThe paper could be improved in some places (e.g. unclear aliases of joint-update or training periods, describing how the parameters were chosen, and describing what kinds of sub-policies are learned in these domains when different parameter choices are made).\n', 'This paper considers the reinforcement learning problem setup in which an agent must solve not one, but a set of tasks in some domain, in which the state space and action space are fixed. The authors consider the problem of learning a useful set of ‘sub policies’ that can be shared between tasks so as to jump start learning on new tasks drawn from the task distribution.\n\nI found the paper to be generally well written and the key ideas easy to understand on first pass. The authors should be commended for this. Aside from a few minor grammatical issues (e.g. missing articles here and there), the writing cannot be too strongly faulted.\n\nThe problem setup is of general interest to the community. Metalearning in the multitask setup seems to be gaining attention and is certainly a necessary  step towards building rapidly adaptable agents.\n\nWhile the concepts were clearly introduced, I think the authors need to make, much more strongly, the case that the method is actually valuable. In that vein, I would have liked to see more work done on elucidating how this method works ‘under the hood’. For example, it is not at all clear how the number of sub policies affects performance (one would imagine that there is a clear trade off), nor how this number should be chosen. It seems obvious that this choice would also affect the subtle dynamics between holding the master policy constant while updating the sub policies and vice versa. While the authors briefly touch on some of these issues in the rationale section, I found these arguments largely unsubstantiated. Moreover, this leads to a number of unjustified hyper-parameters in the method which I suspect would affect the training catastrophically without significant fine-tuning.\n\nThere are also obvious avenues to be followed to check/bolster the intuitions behind the method. By way of example, my sense is that the procedure described in the paper uncovers a set of sub policies that form a `good’ cover for the task space - if so simply plotting out what they policies look like (or better yet how they adapt in time) would be very insightful (the rooms domain is perhaps a good candidate for this).\n\nWhile the key ideas are clearly articulated  the practical value of the procedure is insufficiently motivated. The paper would benefit hugely from additional analysis.']","[50, 70, -20]","[70, 50, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges that 'extensive revisions addressed most of my concerns' and notes several positive aspects like 'interesting idea' and 'original'. However, there are still some lingering concerns, preventing a higher score. The politeness score is 70 (fairly polite) as the reviewer uses professional language, acknowledges improvements, and frames criticisms constructively. The reviewer uses phrases like 'please see my detailed comments' and 'if it works as advertised', which maintain a respectful tone. The balanced presentation of pros and cons also contributes to the polite impression."", ""The sentiment score is 70 (positive) because the reviewer describes the paper's approach as 'impressive' and notes that it achieves 'good performance' in complex domains. The reviewer acknowledges the method's effectiveness while also mentioning some potential limitations. The politeness score is 50 (slightly polite) because the reviewer uses neutral, professional language throughout and offers constructive criticism. They balance positive comments with suggestions for improvement without using harsh or negative language. The reviewer's tone is respectful and objective, focusing on the paper's content rather than making personal comments."", ""The sentiment score is slightly negative (-20) because while the reviewer commends the authors for clear writing and acknowledges the general interest of the problem setup, they express significant concerns about the lack of substantiation for the method's value and insufficient analysis. The reviewer suggests several areas where the paper needs improvement, indicating an overall critical stance.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful language throughout. They begin with positive comments about the paper's writing quality and the relevance of the topic. Even when expressing criticisms, the reviewer maintains a professional tone, using phrases like 'I would have liked to see' and 'The paper would benefit from' rather than harsh or dismissive language. The reviewer also acknowledges the authors' efforts, stating they 'should be commended' for the clear writing.""]"
"['The authors propose to use a generative model of images to detect and defend against adverarial examples. White-box attacks against standard models for image recognition (Resnet and VGG) are considered, and a generative model (a PixelCNN) is trained on the same data as the classifiers. The authors first show that adversarial examples created by the white-box attacks correspond to low likelihood region (according to the pixelCNN), which first gives a classification rule for detecting adversarial examples.\n\nThen, to turn the genrative model into a defensive algorithm, the authors propose to preprocess test images by approximately maximizing the likelihood under similar constraints as the attacker of images, to ""project"" adversarial examples back to high-density regions (as estimated by the generative model). As a heuristic method, the authors propose to greedily maximize the likelihood of the incoming images pixel-by-pixel, which is possible because of the specific form of the PixelCNN likelihood in the context of l-infty attacks. An ""adaptive"" version of the algorithm, in which the preprocessing is used only when the likelihood of an example is below a certain threshold, is also proposed.\n\nExperiments are carried out on Fashion MNIST and CIFAR-10. At a high level, the message is that projecting the image into a high density region is sufficient to correct for a significant portions of the mistakes made on adversarial examples. The main result is that this approach based on generative models seems to work even on against the strongest attacks.\n\nOverall, the idea proposed in the paper, using a generative model to detect and filter out spurious patterns that can appear in adversarial examples, is rather intuitive. The experimental result that adversarial examples can somehow be corrected by a generative model is also interesting. The design choice of PixelCNN, which allows for a greedy optimization seems reasonable in that setting.\n\nWhereas the paper is an interesting step forward, the paper still doesn\'t provide definitive arguments in favor of using such approaches in practice. There is a significant loss in accuracy on clean examples (2% on CIFAR-10 for a resnet), and more generally against weaker opponents such as the fast gradient sign. Thus, in reality, the experiments show that the pipeline generative model + classifier is robust against the strongest white box methods for this classifier, but on the other hand these methods do not transfer well to new models. This somewhat weakens the result, since robustness against these methods that do not transfer well is achieved by changing the model. \n', 'The paper describes the creative application of a density estimation model to clean up adversarial examples before applying and image model (for classification, in this setup). The basic idea is that the image is first moved back to the probable region of images before applying the classifier. For images, the successful PiexlCNN model is used as a density estimator and is applied to clean up the image before the classification is attempted.\n\nThe proposed method is very intuitive, but might be expensive if a naive implementation of PixelCNN is used for the cleaning. The approach is novel. It is useful that the density estimator model does not have to rely on the labels. Also, it might even be trained on a different dataset potentially.\n\nThe con is that the proposed methodology still does not solve the problem of adversarial examples completely.\n\nMinor nitpick: In section 2.1, it is suggested that DeepFool was the first optimization based attack to minimize the perturbation wrt the original image. In fact the much earler (2013) ""Intriguing Propoerties ... "" paper relied on the same formulation (minimizing perturbation under several constraints: changed detection and pixel intensities are being in the given range).', ""\nI read the rebuttal and thank the authors for the thoughtful responses and revisions. The updated Figure 2 and Section 4.4. addresses my primary concerns. Upwardly revising my review.\n\n====================\n\nThe authors describe a method for detecting adversarial examples by measuring the likelihood in terms of a generative model of an image. Furthermore, the authors prescribe a method for cleaning or 'santizing' an adversarial image through employing a generative model. The authors demonstrate some success in restoring images that have been adversarially perturbed with this technique.\n\nThe idea of using a generative model (PixelCNN) to assess whether a given image has been adversarially perturbed is a very interesting and understandable finding that may contribute quite nicely to the adversarial literature. One limitation of this method, however, is our ability to build successful generative models for high resolution images. However, I would be curious to know if the authors tried their method on high resolution images, regardless?\n\nMajor comments:\n1) Cross validation. Figure 2a is quite interesting and compelling. It is not clear from the figure if the 'clean' (nor the other data for that matter) is from the *training* or  *testing* data for the PixelCNN model. I would *hope* that this is from the *testing* data indicating that these are the likelihood on unseen images?\n\nThat said, it would be interesting to see the *training* data on this plot as well to see if there are any systematic shifts that might make the distribution of adversarial examples less discernible.\n\n2) Adversary to PixelCNN. It is not clear why a PixelCNN may not be adversarially attacked, nor if such a model would be able to guard against an adversarial attack. I am not sure how well viable of strategy this may be but it is worth understanding or addressing to determine how viable this method for guarding actually is.\n\n3) Restorative effects of PixelDefend. I would like to see individual examples of (a) adversarial perturbation for a given image and (b) PixelDefend perturbation for that adversarial image. In particular, I would like to see how close (a) is the negative of (b). This would give me more confidence that this techniques is successfully guarding against the original attack.\n\nI am willing to adjust my rating upward if the authors are able to address some of the points above in a substantive manner. \n\n""]","[50, 60, 50]","[75, 70, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting ideas and experimental results, calling it 'an interesting step forward.' However, they also point out limitations, creating a balanced view. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively presenting concerns. They use phrases like 'interesting' and 'reasonable' to describe aspects of the work, and frame criticisms as observations rather than direct attacks, maintaining a professional tone."", ""The sentiment score is 60 (positive) because the reviewer expresses appreciation for the paper's creative application, intuitive approach, and novelty. They highlight several positive aspects, such as the usefulness of the density estimator not relying on labels. However, they also mention a potential drawback (expense of implementation) and note that it doesn't completely solve the problem of adversarial examples, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while gently pointing out limitations. The use of phrases like 'very intuitive' and 'novel' contribute to the polite tone. Even when mentioning drawbacks, the reviewer frames them as 'cons' rather than harsh criticisms. The 'minor nitpick' at the end is presented in a non-confrontational manner, further demonstrating politeness."", ""The sentiment score is 50 (moderately positive) because the reviewer begins by thanking the authors for their thoughtful responses and revisions, and mentions upwardly revising their review. They also describe the authors' method as 'very interesting' and potentially contributing 'quite nicely' to the literature. However, they also raise several concerns and request additional information, which prevents the score from being higher. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout, such as thanking the authors, using phrases like 'I would be curious to know' and 'I would like to see', and offering to adjust their rating upward if concerns are addressed. The reviewer maintains a professional and constructive tone, even when raising criticisms or suggestions for improvement.""]"
"['This paper describes computationally efficient methods for training adversarially robust deep neural networks for image classification. (These methods may extend to other machine learning models and domains as well, but that\'s beyond the scope of this paper.) \n\nThe former standard method for generating adversarially images quickly and using them in training was to do a single gradient step to increase the loss of the true label or decrease the loss of an alternate label. This paper shows that such training methods only lead to robustness against these ""weak"" adversarial examples, leaving the adversarially-trained models vulnerable to multi-step white-box attacks and black-box attacks (adversarial examples generated to attack alternate models).\n\nThere are two proposed solutions. The first is to generate additional adversarial examples from other models and use them in training. This seems to yield robustness against black-box attacks from held-out models as well.  Of course, it requires that you have a somewhat diverse group of models to choose from. If that\'s the case, why not directly build an ensemble of all the models? An ensemble of neural networks can still be represented as a neural network, although a more computationally costly one. Thus, while this heuristic appears to be useful with current models against current attacks, I don\'t know how well it will hold up in the future.\n\nThe second solution is to add random noise before taking the gradient step.  This yields more effective adversarial examples, both for attacking models and for training, because it relies less on the local gradient. This is another simple idea that appears to be effective. However, I would be interested to see a comparison to a 2-step gradient-based attack.  R+Step-LL can be viewed as a 2-step attack: a random step followed by a gradient step. What if both steps were gradient steps instead? This interpolates between Step-LL and I-Step-LL, with an intermediate computational cost. It would be very interesting to know if R+Step-LL is more or less effective than 2+Step-LL, and how large the difference is.\n\nI like that this paper demonstrates the weakness of previous methods, including extensive experiments and a very nice visualization of the loss landscape in two adversarial dimensions. The proposed heuristics seem effective in practice, but they\'re somewhat ad hoc and there is no analysis of how these heuristics might or might not be vulnerable to future attacks.', 'This paper proposes ensemble adversarial training, in which adversarial examples crafted on other static pre-trained models are used in the training phase. Their method makes deep networks robust to black-box attacks, which was empirically demonstrated.\n\nThis is an empirical paper. The ideas are simple and not surprising but seem reasonable and practically useful.\nEmpirical results look natural.\n\n[Strong points]\n* Proposed randomized white-box attacks are empirically shown to be stronger than original ones.\n* Proposed ensemble adversarial training empirically achieves smaller error rate for black-box attacks.\n\n[Weak points]\n* no theoretical guarantee for proposed methods.\n* Robustness of their ensemble adversarial training depends on what pre-trained models and attacks are used in the training phase.\n', 'The paper proposes a modification to adversarial training. Instead of alternating between clean and examples generated on-the-fly by the fast gradient sign during training, the model training is performed by alternating clean examples and adversarial examples generated from pre-trained models. The motivation behind this change is that one-step method to generate adversarial examples fail at generating good adversarial examples when applied to models trained in the adversarial setting. In contrast, one-step methods applied to models trained only on natural data generate adversarial examples that transfer reasonably well, even on models trained with usual adversarial training. The authors also propose a slight modification to the fast gradient sign method, in which an adversarial example is created using a random perturbation and the current model\'s gradient, which seems to work better than the fast gradient sign method. Experiments with inception models on ImageNet show increased robustness both against ""black-box"" attacks using held-out models not used in ensemble adversarial training.\n\nOne advantage of the method is that it is extremely simple. It uses pre-trained models that are readily available, and gains robustness against several well-known adversaries widely considered in the state of the art. The experiments are carried out on ImageNet and are seriously conducted.\n\nOn the negative side, there is a significant loss in accuracy, and the models are more vulnerable to white-box attacks than using standard adversarial training. As the authors discuss in the conclusion, this leaves open the question as to whether the models are indeed more robust, or whether it is an artifact of the static black-box attack schemes that are considered in the paper, which measures how much a single model is robust to adversarial examples for other models that were trained independently. For instance, there are no experiments against what is called adaptive black-box adversaries; one could also imagine finding adversarial examples that are trained to fool all models in a predefined collection of models. In the end, while the work presented in the paper found its use in the recent NIPS competition on defending against adversarial examples, it is still unclear whether this kind of defence would make a difference in critical applications.\n\n']","[50, 60, 50]","[75, 50, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and effectiveness of the proposed methods, while also providing constructive criticism and suggestions for improvement. The reviewer uses phrases like 'I like that this paper demonstrates' and 'The proposed heuristics seem effective in practice,' indicating a generally positive view. However, they also point out limitations and areas for further investigation, balancing the positive aspects.\n\nThe politeness score is 75 (quite polite) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I would be interested to see' and 'It would be very interesting to know,' which express curiosity and engagement rather than criticism. The reviewer also acknowledges the paper's strengths before suggesting improvements, which is a polite approach to feedback. There are no rude or dismissive comments, and the overall tone is constructive and collegial."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the paper's contributions and empirical results as 'reasonable and practically useful'. They highlight strong points and mention that the results 'look natural'. However, it's not extremely positive due to the mentioned weak points. The politeness score is 50 (slightly polite) as the reviewer uses neutral language without harsh criticism. They objectively state both strong and weak points, and use phrases like 'seem reasonable' which softens potential criticism. The review maintains a professional tone throughout, neither overly formal nor casual."", ""The sentiment score is 50 (slightly positive) because the review begins by objectively describing the paper's approach and noting its advantages, such as simplicity and increased robustness against certain attacks. However, it also points out significant drawbacks, creating a balanced view. The politeness score is 75 (quite polite) because the reviewer uses neutral, professional language throughout, acknowledging both strengths and weaknesses without harsh criticism. The reviewer presents concerns as open questions rather than direct criticisms, which is a polite approach. The overall tone is respectful and constructive, typical of a well-mannered academic review.""]"
"['This paper proposed an improved version of dynamic coattention networks, which is used for question answering tasks. Specifically, there are 2 aspects to improve DCN: one is to use a mixed objective that combines cross entropy with self-critical policy learning, the other one is to imporve DCN with deep residual coattention encoder. The proposed model achieved STOA performance on Stanford Question Asnwering Dataset and several ablation experiments show the effectiveness of these two improvements. Although DCN+ is an improvement of DCN, I think the improvement is not incremental. \n\nOne question is that since the model is compicated, will the authors release the source code to repeat all the experimental results?', 'The authors of this paper propose some extensions to the Dynamic Coattention Networks models presented last year at ICLR. First they modify the architecture of the answer selection model by adding an extra coattention layer to improve the capture of dependencies between question and answer descriptions. The other main modification is to train their DCN+ model using both cross entropy loss and F1 score (using RL supervision) in order to  reward the system for making partial matching predictions. Empirical evaluations conducted on the SQuAD dataset indicates that this architecture achieves an improvement of at least 3%, both on F1 and exact match accuracy, over other comparable systems. An ablation study clearly shows the contribution of the deep coattention mechanism and mixed objective training on the model performance. \n\nThe paper is well written, ideas are presented clearly and the experiments section provide interesting insights such as the impact of RL on system training or the capability of the model to handle long questions and/or answers. It seems to me that this paper is a significant contribution to the field of question answering systems. \n', 'Summary:\nThis paper proposed an extension of the dynamic coattention network (DCN) with deeper residual layers and self-attention. It also introduced a mixed objective with self-critical policy learning to encourage predictions with high word overlap with the gold answer span. The resulting DCN+ model achieved significant improvement over DCN.\n\nStrengths:\nThe model and the mixed objective is well-motivated and clearly explained.\nNear state-of-the-art performance on SQuAD dataset (according to the SQuAD leaderboard).\n\nOther questions and comments:\nThe ablation shows 0.7 improvement on EM with mixed objective. It is interesting that the mixed objective (which targets F1) also brings improvement on EM. \n']","[50, 90, 70]","[60, 80, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's achievements, such as achieving state-of-the-art performance and demonstrating effectiveness through experiments. However, they also express that the improvement is 'not incremental,' which tempers the overall positivity. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, acknowledges the paper's contributions, and frames their critique as a personal opinion ('I think'). The reviewer also asks a question about code release in a non-demanding way. The language is professional and constructive without being overly formal or effusive."", ""The sentiment score is 90 because the reviewer expresses a very positive view of the paper, calling it a 'significant contribution' and praising its clarity, interesting insights, and empirical improvements. The politeness score is 80 because the language used is professional and respectful, with phrases like 'well written' and 'interesting insights'. The reviewer provides constructive feedback without any harsh criticism, maintaining a polite and encouraging tone throughout."", ""The sentiment score is 70 (positive) because the review highlights significant strengths of the paper, including a well-motivated model, clear explanations, and near state-of-the-art performance. The reviewer uses phrases like 'significant improvement' and notes the paper's strengths explicitly. The politeness score is 50 (somewhat polite) because the language is professional and respectful, without being overly formal or deferential. The reviewer provides constructive feedback and asks a thoughtful question about the results, maintaining a collegial tone throughout. There are no rude or harsh comments, but also no explicitly polite phrases, resulting in a moderately positive politeness score.""]"
"[""This paper proposes a simple post-processing technique for word representations designed to improve representational quality and performance on downstream tasks. The procedure involves mean subtraction followed by projecting out the first D principle directions and is motivated by improving isotropy of the partition function. Extensive empirical analysis supports the efficacy of the approach.\n\nThe idea of post-processing word embeddings to improve their performance is not new, but I believe the specific procedure and its connection to the concept of isotropy has not been investigated previously. Relative to other post-processing techniques, this method has a fair amount of theoretical justification, particularly as described in Appendix A. I think the experiments are reasonably comprehensive. All told, I think this is a good paper, but I do have some comments and questions that I think should be addressed before publication.\n\n1) I think it is useful to analyze the distribution of singular values of the matrix of word vectors. However, I did not find the heuristic analysis based on the visual appearance of these distributions to be convincing. For example, in Fig. 1, it is not clear to me that there exists a separation between regimes of exponential decay and rough constancy. It would be ideal if a more quantitative metric is established that captures the main qualitative behavior alluded to here.\n\nFurthermore, the vocabulary size is likely to have a strong effect on the shape of the distributions. Are the plots in Fig. 4 for the same vocabulary size? Related to this, the dimensionality of the representation will have a strong effect on the shape, and this should be controlled for in Fig. 8. One way to do this would be to instead plot the density of singular values. Finally, for the Gaussian matrix simulations, in the asymptotic limit, the density of singular values depends only on the ratio of dimensions, i.e. the vector dimension to the vocabulary size. Fig. 4/8 might be more revealing if this ratio were controlled for.\n\n2) It would be useful to describe why isotropy of the partition function is the goal, as opposed to isotropy of the vectors themselves. This may be argued in Arora et al. (2016), but summarizing that argument in this paper would be helpful. In fact, an additional experiment that would be very valuable would be to investigate empirically which form of isotropy is more effective in governing performance. One way to do this would be to enforce approximate isotropy of the partition function without also enforcing isotropy of the vectors themselves. Practically speaking, one might imagine doing this by requiring I = 1 to second order without also requiring that the mean vanish. I think this would allow for \\sigma_max > \\sigma_min while still satisfying I = 1 to second order. (But this is just off the top of my head -- there may be better ways to conduct this experiment).\n\nIt is not clear to me why the experiment leading to Table 2 is a good proxy for the exact computation of I. It would be great if there were some mathematical justification for this approximation.\n\nWhy does Fig. 3 use D=10, 20 when much smaller D are considered elsewhere? Also I think a log scale on the x-axis might be more informative.\n\n3) It would be good to mention other forms of post-processing, especially in the context of word similarity. For example, in the original paper, GloVe advocates averaging the target and context vector representations, and normalizing across the feature dimension before computing cosine similarity.\n\n4) I think it's likely that there is a strong connection between the optimal value of D and the frequency distribution of words in the evaluation dataset. While the paper does mention that D may depend on specifics of the dataset, etc., I would expect frequency-dependence to be the main factor, and it might be worth exploring this effect explicitly.\n"", ""This paper proposes that sets of word embeddings can be improved by subtracting the common mean vector and reducing the effect of dominant components of variation. \n\nComments:\n\nReference to 'energy' and 'isotropic' in the first paragraph come without any explanation. Can plain terms be used instead to express the same ideas? This would make understanding easier (I have a degree in maths, but never studied physics, and I had to look them up). Otherwise, I like the simple explanation of the method given in the intro. \n\nThe experiments conducted in the paper are comprehensive. It is very positive that the improvements appear to be quite consistent across well-known tasks. As well as proposing a simple trick to produce these improvements, the authors aim to provide theoretical insight and (implicitly, at least) pursue a better understanding of semantic word spaces. This has the potential to be a major contribution, as such spaces, and semantic representation in neural nets in general, is poorly understood. However (perhaps because I'm not familiar with Arora et al.) I found the mathematical analysis e.g. S2.2 dense, without any clearly-stated intuitive motivation or conclusions (as per the introduction section) about what is going on semantically. E.g. it is not clear to me why isotropy is something desirable in a word embedding space. I understand that the discarded components tend to encode frequency, and this is very interesting and somewhat indicative f why the method might work. However, Figure 2 is particularly hard to interpret? The correlations, and the distribution of high-frequency words) seems to be quite different for each of the three models?! \n\nIn general, I don't think the authors should rely on readers having read Arora et al. - anything that builds on that work needs to reintroduce their findings in pain terms in the current paper. \n\nAnother concern is the novelty in relation to related work. I have not read Arora et al. but the authors say that they 'null away the first principal component', and Sahlgren et al centre the mean. Taken together, this seems very similar to what the authors propose here (please clarify). More generally, these sorts of tricks have often been applied by deep learning researchers and passed around anecdotally (e.g. initialise transition matrix in RNNs with orthonormal noise) as ways to improve training. It is important to share and verify these things, but such a contribution feels more appropriate for a workshop than the main conference. This makes the work that the authors do in interpreting and understanding why these tricks work particularly important. As is, however, I thing that the conclusions from this analysis are unclear and opaque. Can they be better communicated, or is it the case that the results of the analysis are in fact inconclusive?\n\nThe vast amount of work included in the appendix is impressive. What particularly caught my eye was appendix B, where the authors try to understand if their method can simply be 'learned' by any network that uses pre-trained word embeddings. This is a really nice experiment, and I think it could easily be part of the main paper (perhaps swapping with the stuff in section 2.2). \n\nThe conclusion would be a good place for summarising the main findings in plain terms, but that doesn't really happen (unless the finding about frequency is the only finding). Instead, there is a vague connection to population genetics and language evolution. This may be an interesting future direction, but the connection is tenuous, so that this reader, at least, was left a little baffled. \n\n[REVISED following response]\n\nThanks for your thorough response which did a good job of addressing most of my concerns. I have changed the score accordingly.\n   \n\n"", 'This paper provides theoretical and empirical motivations for removing the top few principle components of commonly-used word embeddings.\n\nThe paper is well-written and I enjoyed reading it. However, it does not explain how significant this result is beyond that of (Bullinaria and Levy, 2012), who also removed the top N dimensions when benchmarking SVD-factorized word embeddings. From what I can see, this paper provides a more detailed explanation of the phenomenon (""why"" it works), which is supported with both theoretical results and a series of empirical analyses, as well as ""updating"" the benchmarks and methods from the pre-neural era. Although this contribution is relatively incremental, I find the depth of this work very interesting, and I think future work could perhaps rely on these insights to create better embedding algorithms that directly enforce isotropy.\n\nI have two concerns regarding the empirical section, which may be resolvable fairly quickly:\n1) Are the embedding vectors L2 normalized before using them in each task? This is known to significantly affect performance. I am curious whether removing the top PCs is redundant or not given L2 normalization.\n2) Most of the benchmarks used in this paper are ""toy"" tasks. As Schnabel et al (2015) and Tsvetkov et al (2015) showed, there is often little correlation between success on these benchmarks and improvement of downstream NLP tasks. I would like to measure the change in performance on a major NLP task that heavily relies on pre-trained word embeddings such as SQuAD.\n\nMinor Comments:\n* The last sentence in the first paragraph (""The success comes from the geometry of the representations..."") is not true; the success stems from the ability to capture lexical similarity. Levy and Goldberg (2014) showed that searching for the closest word vector to (king - man + woman) is equivalent to optimizing a linear combination of 3 similarity terms [+(x,king), -(x,man), +(x, woman)]. This explanation was further demonstrated by Linzen (2016) who showed that even when removing the negative term (x, man), many analogies can still be solved, i.e. by looking for a word that is similar both to ""king"" and to ""woman"". Add to that the fact that the analogy trick works best when the vectors are L2 normalized; if they are all on the unit sphere, what is the geometric interpretation of (king - man + woman), which is not on the unit sphere? I suggest removing this sentence and other references to linguistic regularities from this paper, since they are controversial at best, and distract from the main findings.\n* This is also related to Bullinaria and Levy\'s (2012) finding that downweighting the eigenvalue matrix in SVD-based methods improves their performance. Levy et al (2015) showed that keeping the original eigenvalues can actually degenerate SVD-based embeddings. Perhaps there is a connection to the findings in this paper?\n']","[60, 20, 60]","[80, 60, 80]","[""The sentiment score is 60 (positive) because the reviewer states 'I think this is a good paper' and acknowledges the novelty and theoretical justification of the approach. However, it's not extremely positive as the reviewer also has several comments and questions to be addressed. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'It would be useful to...', 'I think it's likely that...'), and acknowledges the paper's strengths. The reviewer maintains a professional and courteous tone while providing detailed feedback."", ""The sentiment score is slightly positive (20) because while the reviewer expresses some concerns and criticisms, they also highlight several positive aspects of the paper. They note the comprehensive experiments, consistent improvements across tasks, and potential for major contribution. The reviewer also praises the 'impressive' appendix work. However, they raise issues with clarity, novelty, and the conclusion, which tempers the overall positivity.\n\nThe politeness score is moderately high (60) as the reviewer uses respectful and constructive language throughout. They offer suggestions for improvement rather than harsh criticisms, and use phrases like 'I like', 'It is very positive', and 'This is a really nice experiment'. The reviewer also thanks the authors for their thorough response in the revised section. However, the score is not higher as the review maintains a professional tone rather than being overtly polite or complimentary."", ""The sentiment score is 60 (positive) because the reviewer expresses enjoyment in reading the paper and finds the work interesting, despite noting some concerns and areas for improvement. The overall tone is constructive and appreciative of the work's depth. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout, starting with positive comments before addressing concerns, and phrasing criticisms as suggestions or questions rather than direct criticisms. The reviewer also acknowledges the paper's contributions while providing detailed, constructive feedback for improvement.""]"
"['This paper presents an iterative approach to sparsify a network already during training. During the training process, the amount of connections in the network is guaranteed to stay under a specific threshold. This is a big advantage when training is performed on hardware with computational limitations, in comparison to ""post-hoc"" sparsification methods, that compress the network after training.\nThe method is derived by considering the ""rewiring"" of an (artificial) neural network as a stochastic process. This perspective is based on a recent model in computational biology but also can be interpreted as a (sequential) monte carlo sampling based stochastic gradient descent approach. References to previous work in this area are missing, e.g.\n\n[1] de Freitas et al., Sequential Monte Carlo Methods to Train Neural Network\nModels, Neural Computation 2000\n[2] Welling et al., Bayesian Learning via Stochastic Gradient Langevin Dynamics, ICML 2011\n\nEspecially the stochastic gradient method in [2] is strongly related to the existing approach.\n\nPositive aspects\n\n- The presented approach is well grounded in the theory of stochastic processes. The authors provide proofs of convergence by showing that the iterative updates converge to a fixpoint of the stochastic process\n\n- By keeping the temperature parameter of the stochastic process high, it can be directly applied to online transfer learning.\n\n- The method is specifically designed for online learning with limited hardware ressources.\n\nNegative aspects\n\n- The presented approach is outperformed for moderate compression levels (by Han\'s pruning method for >5% connectivity on MNIST, Fig. 3 A, and by l1-shrinkage for >40% connectivity on CIFAR-10 and TIMIT, Fig. 3 B&C). Especially the results on MNIST suggest that this method is most advantageous for very high compression levels. However in these cases the overall classification accuracy has already dropped significantly which could limit the practical applicability.\n\n- A detailled discussion of the relation to previously existing very similar work is missing (see above)\n\n\nTechnical Remarks\n\nFig. 1, 2 and 3 are referenced on the pages following the page containing the figure. Readibility could be slightly increased by putting the figures on the respective pages.\n', 'In this paper, the authors present an approach to implement deep learning directly on sparsely connected graphs. Previous approaches have focused on transferring trained deep networks to a sparse graph for fast or efficient utilization; using this approach, sparse networks can be trained efficiently online, allowing for fast and flexible learning. Further investigation is necessary to understand the full implications of the two main conceptual changes introduced here (signed connections that can disappear and random walk in parameter space), but the initial results are quite promising.\n\nIt would also be interesting to understand more fully how performance scales to larger networks. If the target connectivity could be pushed to a very sparse limit, where only a fixed number of connections were added with each additional neuron, then this could significantly shape how these networks are trained at very large scales. Perhaps the heuristics for initializing the connectivity matrices will be insufficient, but could these be improved in further work?\n\nAs a last minor comment, the authors should specify explicitly what the shaded areas are in Fig. 4b,c.', 'The authors provide a novel, interesting, and simple algorithm capable of training with limited memory.  The algorithm is well-motivated and clearly explained, and empirical evidence suggests that the algorithm works well.  However, the paper needs additional examination in how the algorithm can deal with larger data inputs and outputs.  Second, the relationship to existing work needs to be explained better.\n\nPro:\nThe algorithm is clearly explained, well-motivated, and empirically supported.\n\nCon:\nThe relationship to stochastic gradient markov chain monte carlo needs to be explained better.  In particular, the update form was first introduced in [1], the annealing scheme was analyzed in [2], and the reflection step was introduced in [3].  These relationships need to be explained clearly.\nThe evidence is presented on very small input data.  With something like natural images, the parameterization is much larger and with more data, the number of total parameters is much larger.  Is there any evidence that the proposed algorithm could continue performing comparatively as the total number of parameters in state-of-the-art networks increases? This would require a smaller ratio of included parameters.\n\n[1] Welling, M. and Teh, Y.W., 2011. Bayesian learning via stochastic gradient Langevin dynamics. In Proceedings of the 28th International Conference on Machine Learning (ICML-11)(pp. 681-688).\n\n[2] Chen, C., Carlson, D., Gan, Z., Li, C. and Carin, L., 2016, May. Bridging the gap between stochastic gradient MCMC and stochastic optimization. In Artificial Intelligence and Statistics(pp. 1051-1060).\n\n[3] Patterson, S. and Teh, Y.W., 2013. Stochastic gradient Riemannian Langevin dynamics on the probability simplex. In Advances in Neural Information Processing Systems (pp. 3102-3110).\n \n']","[50, 70, 50]","[75, 80, 75]","[""The sentiment score is 50 (slightly positive) because the review presents a balanced view with both positive and negative aspects. The reviewer acknowledges the method's theoretical grounding and advantages for online learning and limited hardware resources. However, they also point out performance limitations and missing references. The politeness score is 75 (quite polite) because the reviewer uses professional and respectful language throughout. They present criticisms constructively, using phrases like 'could be slightly increased' and 'discussion... is missing' rather than harsh or dismissive language. The reviewer also takes care to highlight positive aspects before discussing negatives, which is a polite approach in academic reviews."", ""The sentiment score is 70 (positive) because the reviewer describes the paper's approach as 'promising' and expresses interest in further investigations. They use phrases like 'quite promising' and 'interesting to understand more fully,' indicating a positive view of the work. The politeness score is 80 (polite) due to the constructive and respectful tone throughout. The reviewer offers suggestions and questions without harsh criticism, using phrases like 'It would be interesting' and 'Perhaps...could these be improved,' which maintain a polite and collaborative tone. The final comment is phrased as a 'minor' suggestion, further demonstrating courtesy. The language is consistently professional and encouraging, without any rude or dismissive remarks."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by praising the paper's novel and interesting algorithm, clear explanation, and empirical evidence. However, they also point out areas for improvement, balancing the positive with constructive criticism. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering suggestions for improvement. They use phrases like 'The authors provide' and 'needs to be explained better' rather than more direct or harsh criticism. The review maintains a professional and constructive tone, offering specific references to support their recommendations.""]"
"['Error-correcting codes constitute a well-researched area of study within communication engineering. In communication, messages that are to be transmitted are encoded into binary vector called codewords that contained some redundancy. The codewords are then transmitted over a channel that has some random noise. At the receiving end the noisy codewords are then decoded to recover the messages. Many well known families of codes exist, notably convolutional codes and Turbo codes, two code families that are central to this paper, that achieve the near optimal possible performance with efficient algorithms. For Turbo and convolutional codes the efficient MAP decodings are known as Viterbi decoder and the BCJR decoder. For drawing baselines, it is assumed that the random noise in channel is additive Gaussian (AWGN).\n\nThis paper makes two contributions. First, recurrent neural networks (RNN) are proposed to replace the Viterbi and BCJR algorithms for decoding of convolutional and Turbo decoders. These decoders are robust to changes in noise model and blocklength - and shows near optimal performance.\n\nIt is unclear to me what is the advantage of using RNNs instead of Viterbi or BCJR, both of which are optimal, iterative and runs in linear time. Moreover the authors point out that RNNs are shown to emulate BCJR and Viterbi decodings in prior works - in light of that, why their good performance surprising?\n\nThe second contribution of the paper constitutes the design and decoding of codes based on RNNs for a Gaussian channel with noisy feedback. For this channel the optimal codes are unknown. The authors propose an architecture to design codes for this channel. This is a nice step. However, in the performance plot (figure 8), the RNN based code-decoder does not seem to be outperforming the existing codes except for two points. For both in high and low SNR the performance is suboptimal to  Turbo codes and a code by Schalkwijk & Kailath. The section is also super-concise to follow. I think it was necessary to introduce an LSTM encoder - it was hard to understand the overall encoder. This is an issue with the paper - the authors previously mentioned (8,16) polar code without mentioning what the numbers mean. \n\nHowever, I overall liked the idea of using neural nets to design codes for some non-standard channels. While at the decoding end it does not bring in anything new (modern coding theory already relies on iterative decoders, that are super fast), at the designing-end the Gaussian feedback channel part can be a new direction. This paper lacks theoretical aspect, as to no indication is given why RNN based design/decoders can be good. I am mostly satisfied with the experiments, barring Fig 8, which does not show the results that the authors claim.\n', 'In this paper the authors propose to use RNNs and LSTMs for channel coding. But I have the impression the authors completely miss the state of the art in channel coding and the results are completely useless for any current communication system. I believe that machine learning, in general, and deep learning, in particular, might be of useful for physical layer communications. I just do not see why it would be useful for channel coding over the AWGN channel. Let me explain.\n\nIf the decoder knows that the encoder is using a convolutional code, why does it need to learn the decoder instead of using the Viterbi or BCJR algorithms that are known to be optimal for sequences and symbols, respectively. I cannot imagine an scenario in which the decoder does not know the convolutional code that it is being used and the encoder sends 120,000 bits of training sequence (useless bits from information standpoint) for the decoder to learn it. More important question, do the authors envision that this learning is done every time there is a new connection or it is learnt once and for all. If it is learnt every time that would be ideal if we were discovering new channel codes everyday, clearly not the case. If we learnt it one and for all and then we incorporated in the standard that would only make sense if the GRU structure was computationally better than the BCJR or Viterbi. I would be surprise if it is. If instead of using 2 or 3 memories, we used 6-8 does 120,000 bits be good enough or we need to exponentially increase the training sequence? So the first result in the paper shows that a tailored structure for convolutional encoding can learn to decode it. Basically, the authors are solving a problem that does not need solving. \n\nFor the Turbocodes the same principle as before applies. In this case the comments of the authors really show that they do not know anything about coding. In Page 6, we can read: “Unlike the convolutional codes, the state of the art (message-passing) decoders for turbo codes are not the corresponding MAP decoders, so there is no contradiction in that our neural decoder would beat the message-passing ones”. This is so true, so I expected the DNN structure to be significantly better than turbodecoding. But actually, they do not. These results are in Figure 15 page 6 and the solution for the turbo decoders and the DNN architecture are equivalent. I am sure that the differences in the plots can be explained by the variability in the received sequence and not because the DNN is superior to the turbodecoder. Also in this case the training sequence is measured in the megabits for extremely simple components. If the convolutional encoders were larger 6-8 bits, we would be talking about significantly longer training sequences and more complicated NNs.\n\nIn the third set the NNs seems to be superior to the standard methods when burst-y noise is used, but the authors seems to indicate that that NN is trained with more information about these bursts that the other methods do not have. My impression is that the authors would be better of focusing on this example and explain it in a way that it is reproducible. This experiment is clearly not well explained and it is hard to know if there is any merit for the proposed NN structure. \n\nFinally, the last result would be the more interesting one, because it would show that we can learn a better channel coding and decoding mechanism that the ones humans have been able to come up with. In this sense, if NNs can solve this problem that would be impressive and would turn around how channel coding is done nowadays. If this result were good enough, the authors should only focus in it and forget about the other 3 cases. The issue with this result is that it actually does not make sense. The main problem with the procedure is that the feedback proposal is unrealistic, this is easy to see in Figure 16 in which the neural encoder is proposed. It basically assumes that the received real-valued y_k can be sent (almost) noiselessly to the encoder with minimal delay and almost instantaneously. So the encoder knows the received error and is able to cancel it out. Even if this procedure could be implemented, which it cannot be. The code only uses 50 bits and it needed 10^7 iterations (500Mbs) to converge. The authors do not show how far they are from the Shannon limit, but I can imagine that with 50 bit code, it should be pretty far.  \n\nWe know that with long enough LDPC codes we can (almost) reach the Shannon limit, so new structure are not needed. If we are focusing on shorter codes (e.g. latency?) then it will be good to understand why do we need to learn the channel codes. A comparison to the state of the art would be needed. Because clearly the used codes are not close to state of the art. For me the authors either do not know about coding or are assuming that we do not, which explains part of the tone of this review. \n', 'This paper shows how RNNs can be used to decode convolutional error correcting codes. While previous recent work has shown neural decoders for block codes results had limited success and for small block lengths. \nThis paper shows that RNNs are very suitable for convolutional codes and achieves state of the art performance for the first time. \nThe second contribution is on adaptivity outside the AWGN noise model. The authors show that their decoder performs well for different noise statistics outside what it was trained on. This is very interesting and encouraging. It was not very clear to me if the baseline decoders (Turbo/BCJR) are fairly compared here since better decoders may be used for the different statistics, or some adaptivity could be used in standard decoders in various natural ways. \n\nThe last part goes further in designing new error correcting schemes using RNN encoders and decoders for noisy feedback communication. \nFor this case capacity is known to be impossible to improve, but the bit error error can be improved for finite lenghts. \nIt seems quite remarkable that they beat Schalkwijk and Kailath and shows great promise for other communication problems.\n\nThe paper is very well written with good historical context and great empirical results. I think it opens a new area for information theory and communications with new tools. \n\nMy only concern is that perhaps the neural decoders can be attacked with adversarial noise (which would not be possible for good-old Viterbi ). It would be interesting to discuss this briefly. \nA second (related) concern is the lack of theoretical understanding of these new decoders. It would be nice if we could prove something about them, but of course this will probably be challenging. \n\n']","[-20, -80, 90]","[50, -50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('I overall liked the idea', 'This is a nice step'), they express several criticisms and doubts about the paper's contributions and clarity. The reviewer questions the advantage of using RNNs over existing methods, points out performance issues, and mentions that the paper 'lacks theoretical aspect'. However, it's not entirely negative as they see potential in some aspects of the work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'It is unclear to me' and 'I think it was necessary' rather than making blunt criticisms. The reviewer also balances negative points with positive ones, showing a fair approach. However, the score is not higher because the review is primarily focused on critiquing the paper rather than offering excessive praise or using particularly polite language."", ""The sentiment score is -80 because the reviewer expresses strong criticism throughout the review, stating that the authors 'completely miss the state of the art' and that the results are 'completely useless'. The reviewer consistently points out flaws and shortcomings in the paper, questioning the authors' knowledge and the validity of their approach. The politeness score is -50 due to the harsh and direct language used. While the reviewer provides detailed explanations for their criticisms, the tone is often dismissive and bordering on condescending, particularly in phrases like 'the authors either do not know about coding or are assuming that we do not, which explains part of the tone of this review.' The reviewer does not attempt to soften their criticisms or provide encouragement, leading to a relatively impolite review."", ""The sentiment score is 90 because the reviewer expresses strong positive sentiment throughout the review. They describe the paper as showing 'state of the art performance', being 'very interesting and encouraging', and 'quite remarkable'. The reviewer also states that the paper is 'very well written' and 'opens a new area for information theory and communications'. The only slight concerns mentioned are framed constructively and do not significantly detract from the overall positive tone. The politeness score is 80 because the language used is consistently respectful and professional. The reviewer uses phrases like 'It would be interesting' and 'It would be nice if' when making suggestions, which is a polite way of offering feedback. They also acknowledge the potential difficulty of addressing one of their concerns ('this will probably be challenging'), showing consideration for the authors' perspective.""]"
"['The quality and clarity of this work are very good. The introduction of the kernel inception metric is well-motivated and novel, to my knowledge. With the mention of a bit more related work (although this is already quite good), I believe that this could be a significant resource for understanding MMD GANs and how they fit into the larger model zoo.\n\nPros\n - best description of MMD GANs that I have encountered\n - good contextualization of related work and descriptions of relationships, at least among the works surveyed\n - reasonable proposed metric (KID) and comparison with other scores\n - proof of unbiased gradient estimates is a solid contribution\n\nCons\n - although the review of related work is very good, it does focus on ~3 recent papers. As a review, it would be nice to see mention (even just in a list with citations) of how other models in the zoo fit in\n - connection between IPMs and MMD gets a bit lost; a figure (e.g.  flow chart) would help\n - wavers a bit between proposing/proving novel things vs. reviewing and lacks some overall structure/storyline\n - Figure 1 is a bit confusing; why is KID tested without replacement, and FID with? Why 100 vs 10 samples? The comparison is good to have, but it\'s hard to draw any insight with these differences in the subfigures. The figure caption should also explain what we are supposed to get out of looking at this figure.\n\nSpecific comments:\n - I suggest bolding terms where they are defined; this makes it easy for people to scan/find (e.g. Jensen-Shannon divergence, Integral Probability Metrics, witness functions, Wasserstein distance, etc.) \n - Although they are common knowledge in the field, because this is a review it could be helpful to provide references or brief explanations of e.g. JSD, KL, Wasserstein distance, RKHS, etc.\n - a flow chart (of GANs, IPMs, MMD, etc., mentioning a few more models than are discussed in depth here, would be *very* helpful.\n - page 2, middle paragraph, you mention ""...constraints to ensure the kernel distribution embeddings remained injective""; it would be helpful to add a sentence here to explain why that\'s a good thing.\n', 'The main contribution of the paper is that authors extend some work of Bellemare: they show that MMD GANs [which includes the Cramer GAN as a subset] do possess unbiased gradients. They provide a lot of context for the utility of this claim, and in the experiments section they provide a few different metrics for comparing GANs [as this is a known tricky problem]. The authors finally show that an MMD GAN can achieve comparable performance with a much smaller network used in the discriminator.\n\nAs previously mentioned, the big contribution of the paper is the proof that MMD GANs permit unbiased gradients. This is a useful result; however, given the lack of other outstanding theoretical or empirical results, it almost seems like this paper would be better shaped as a theory paper for a journal. I could be swayed to accept this paper however if others feel positive about it.\n\n', 'This paper claims to demystify MMD-GAN, a generative adversarial network with the maximum mean discrepancy (MMD) as a critic, by showing that the usual estimator for MMD yields unbiased gradient estimates (Theorem 1). It was noted by the authors that biased gradient estimate can cause problem when performing stochastic gradient descent, as also noted previously by Bellemare et al. The authors also proposed a kernel inception distance (KID) as a quantitative evaluation metric for GAN. The KID is defined to be the squared MMD between inception representation of the distributions. In experiments, the authors compared the quality of samples generated by MMD-GAN with various kernels with the ones generated from WGAN-GP (Gulrajani et al., 2017) and Cramer GAN (Bellemare et al., 2017). The empirical results show the benefits of using the MMD on top of deep convolutional features. \n\nThe major flaw of this paper is that its contribution is not really clear. Showing that the expectation and gradient can be interchanged (Theorem 1) does not seem to provide sufficient significance. Unbiasedness of the gradient alone does not guarantee that training will be successful and that the resulting models will better reflect the underlying data distribution, as evident by other successful variants of GANs, e.g., WGAN, which employ biased estimate. Indeed, since the training process relies on a small mini-batch, a small bias could help counteract the potentially high variance of the gradient estimate. The key is rather a good balance of both bias and variance during the training process and a guarantee that the estimate is asymptotically unbiased wrt the training iterations. Lastly, I do not see how the empirical results would demystify MMD-GANs, as claimed by the paper.\n\nThe paper is clearly written. \n\nSome minor comments:\n\n- The proof of the main result, Theorem 1, should be placed in the main paper.\n- Page 7, 2nd paragraph: later --> layer']","[70, 20, -50]","[80, 50, 50]","[""The sentiment score is 70 (positive) because the reviewer starts by stating that the quality and clarity of the work are 'very good' and mentions that it could be a 'significant resource'. They list several pros and describe the work as 'novel' and a 'solid contribution'. While there are some cons mentioned, they are presented as suggestions for improvement rather than major criticisms. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions. They balance positive comments with areas for improvement, and use phrases like 'I suggest' and 'it would be helpful' when making recommendations, which maintains a courteous tone. The reviewer also acknowledges the good aspects of the work before suggesting improvements, which is a polite approach to feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the main contribution of the paper as useful and provides context for its importance. However, they express some reservations about whether it's sufficient for acceptance, suggesting it might be better suited as a theory paper for a journal. This mixed sentiment leans slightly positive but with clear hesitation. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the authors' work and contributions without harsh criticism. They express their reservations politely, using phrases like 'I could be swayed' which shows openness to other opinions. The tone is professional and constructive, avoiding any rude or dismissive language."", ""The sentiment score is -50 because the review is generally critical of the paper's contribution, stating that 'its contribution is not really clear' and that the main theorem 'does not seem to provide sufficient significance'. However, it's not entirely negative as it acknowledges that the paper is 'clearly written' and provides some positive comments about the empirical results. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism and providing constructive feedback. The reviewer also acknowledges positive aspects of the paper, which contributes to the polite tone. The use of phrases like 'The major flaw' and 'I do not see how' are direct but not rude, maintaining a professional critique.""]"
"['This paper develop theory to study the impact of stochastic gradient noise for SGD, especially for deep neural network models. It is shown that when the gradient noise is isotropic normal, SGD converges to a distribution tilted by the original objective function. However, when the gradient noise is non isotropic normal, which is shown common in many models especially in deep neural network models, the behavior of SGD is intriguing, which will not converge to the tilted distribution by the original objective function, sometimes more interestingly, will converge to limit cycles around some critical points of the original objective function. The paper also provides some hints on why using SGD can get good generalization ability than gradient descend.\n\nI think the finding of this paper is interesting, and the technical details are correct. I still have the following comments.\n\nFirst, Assumption 4 seems a bit too abstract. It is not easy to see what the assumption means. It would be better if an example is given, which is verified to satisfy the assumption.\n\nAnother comment is related to the overall content of this paper. Thought the paper point out that SGD will have the out-of-equilibrium behavior when the gradient noise is non isotropic normal, it remains to show how far away this stationary distribution is from the original distribution defined by the objective function.', ""The paper takes a closer look at the analysis of SGD as variational inference, first proposed by Duvenaud et al. 2016\nand Mandt et al. 2016. In particular, the authors point out that in general, SGD behaves quite differently from Langevin diffusion due to the multivariate nature of the Gaussian noise. As the authors show based on the Fokker-Planck equation of the underlying stochastic process, there exists a conservative current (a gradient of an underlying potential) and a non-conservative current (which might induce stationary persistent currents at long times). The non-conservative part leads to the fact that the dynamics of SGD\tmay show oscillations, and these oscillations may even prevent the algorithm from converging to the 'right' local optima. The theoretical analysis is carried-out very nicely, and the theory is supported by experiments on two-dimensional toy examples, and Fourier-spectra of the iterates of SGD.\n\nThis is a nice paper which I would like to see accepted. In particular I appreciate that the authors stress the importance\nof 'non-equilibrium physics' for understanding the SGD process. Also, the presentation is quite clear and the paper well written.\n\nThere are a few minor points which I would like to ask the authors to address:\n\n1. Why cite Kingma and Welling as a source for variational inference in\tsection 3.1? VI is a much older\tfield, and Kingma and Welling proposed a very special form of VI, namely amortized VI with inference networks. A better citation would be Jordan et\tal 1999.\n\n2. I'm not sure how much to trust the Fourier-spectra. In particular, perhaps the deviations from Brownian motion could also be due to the discrete\tnature of SGD (i.e. that the continuous-time formalism is only an approximation of a discrete process). Could you elaborate on this?\n\n3. Could you give the reader more details on how the uncertainty estimates on the Fourier transformations were obtained?\n\nThanks."", 'The authors discuss the regularized objective function minimized by standard SGD in the context of neural nets, and provide a variational inference perspective using the Fokker-Planck equation. They note that the objective can be very different from the desired loss function if the SGD noise matrix is low rank, as evidenced in their experiments.\n\nOverall the paper is written quite well, and the authors do a good job of explaining their thesis. However I was unable to identify any real novelty in the theory: the Fokker-Planck equation has been widely used in analysis of stochastic noise in MCMC samplers in recent years, and this paper mostly rephrases those results. Also the fact that SGD theory only works for isotropic noise is well known, and that there is divergence from the true loss function in case of low rank noise is obvious. Thus I found most of section 3 to be a reformulation of known results, including Theorem 5 and its proof.\n\nSame goes for section 5; the symmetric- anti symmetric split is a common technique used in the stochastic MCMC literature over the last few years, and I did not find any new insight into those manipulations of the Fokker-Planck equation from this paper.\n\nThus I think that although this paper is written well, the theory is mostly recycled and the empirical results in Section 4 are known; thus it is below acceptance threshold due to lack of novelty.']","[50, 80, -60]","[70, 90, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer states that the paper's findings are 'interesting' and the technical details are 'correct'. However, they also provide some critical comments, which balances out the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, such as 'I think' and 'It would be better if', and frames their criticisms as suggestions rather than demands. The reviewer also acknowledges the paper's strengths before offering constructive feedback, which is a polite approach to peer review."", ""The sentiment score is 80 (positive) because the reviewer expresses a clear positive sentiment, stating 'This is a nice paper which I would like to see accepted' and praising the theoretical analysis and presentation. The reviewer also appreciates the authors' emphasis on 'non-equilibrium physics'. The score is not 100 as there are some minor points for improvement. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'I appreciate', 'I would like to ask', and 'Could you elaborate', which are polite ways to give feedback. The reviewer also thanks the authors at the end. The score is not 100 as it maintains a professional rather than overly deferential tone."", ""The sentiment score is -60 because the reviewer expresses a generally negative view of the paper, stating it lacks novelty and is 'below acceptance threshold'. However, they do acknowledge some positives like good writing and explanation, which prevents the score from being lower. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the paper's strengths before critiquing it. They avoid harsh or personal criticism, instead focusing on the content. The reviewer's tone is professional and constructive, even while delivering a negative overall assessment.""]"
"['This paper discusses the application of word prediction for software keyboards. The goal is to customize the predictions for each user to account for member specific information while adhering to the strict compute constraints and privacy requirements. \n\nThe authors propose a simple method of mixing the global model with user specific data. Collecting the user specific models and averaging them to form the next global model. \n\nThe proposal is practical. However, I am not convinced that this is novel enough for publication at ICLR. \n\nOne major question. The authors assume that the global model will depict general english. However, it is not necessary that the population of users will adhere to general English and hence the averaged model at the next time step t+1 might be significantly different from general English. It is not clear to me as how this mechanism guarantees that it will not over-fit or that there will be no catastrophic forgetting.', 'This paper deals with improving language models on mobile equipments\nbased on small portion of text that the user has ever input. For this\npurpose, authors employed a linearly interpolated objectives between user\nspecific text and general English, and investigated which method (learning\nwithout forgetting and random reheasal) and which interepolation works better.\nMoreover, authors also look into privacy analysis to guarantee some level of\ndifferential privacy is preserved.\n\nBasically the motivation and method is good, the drawback of this paper is\nits narrow scope and lack of necessary explanations. Reading the paper,\nmany questions arise in mind:\n\n- The paper implicitly assumes that the statistics from all the users must\n  be collected to improve ""general English"". Why is this necessary? Why not\n  just using better enough basic English and the text of the target user?\n\n- To achieve the goal above, huge data (not the ""portion of the general English"") should be communicated over the network. Is this really worth doing? If only\n  ""the portion of"" general English must be communicated, why is it validated?\n\n- For measuring performance, authors employ keystroke saving rate. For the\n  purpose of mobile input, this is ok: but the use of language models will\n  cover much different situation where keystrokes are not necessarily \n  available, such as speech recognition or machine translation. Since this \n  paper is concerned with a general methodology of language modeling, \n  perplexity improvement (or other criteria generally applicable) is also\n  important.\n\n- There are huge number of previous work on context dependent language models,\n  let alone a mixture of general English and specific models. Are there any\n  comparison with these previous efforts?\n\nFinally, this research only relates to ICLR in that the language model employed\nis LSTM: in other aspects, it easily and better fit to ordinary NLP conferences, such as EMNLP, NAACL or so. I would like to advise the authors to submit\nthis work to such conferences where it will be reviewed by more NLP experts.\n\nMinor:\n- t of $G_t$ in page 2 is not defined so far.\n- What is ""gr"" in Section 2.2?\n', 'my main concern is the relevance of this paper to ICLR.\nThis paper is much related not to representation learning but to user-interface.\nThe paper is NOT well organized and so the technical novelty of the method is unclear.\nFor example, the existing method and proposed method seems to be mixed in Section 2.\nYou should clearly divide the existing study and your work. \nThe experimental setting is also unclear.\nKSS seems to need the user study.\nBut I do not catch the details of the user study, e.g., the number of users.\n']","[-50, -20, -70]","[50, 50, -20]","[""The sentiment score is -50 because while the reviewer acknowledges that the proposal is practical, they express doubt about its novelty and suitability for publication at ICLR. They also raise a significant concern about the method's ability to prevent overfitting or catastrophic forgetting. This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses respectful and professional language throughout, avoiding harsh criticism while clearly expressing their concerns. They use phrases like 'I am not convinced' and 'It is not clear to me' which maintain a polite tone while conveying their reservations."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the motivation and method are good, they point out several drawbacks and limitations of the paper. The reviewer mentions the narrow scope, lack of necessary explanations, and raises multiple questions about the approach. They also suggest that the paper might be better suited for a different conference.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'Basically the motivation and method is good' and 'I would like to advise the authors' which show respect. The criticism is presented as questions and suggestions rather than harsh statements. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a balanced and objective tone."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses significant concerns about the paper's relevance, organization, clarity, and experimental setup. Phrases like 'main concern', 'NOT well organized', 'technical novelty... is unclear', and 'experimental setting is also unclear' indicate a strong negative sentiment. The politeness score is -20 because while the language isn't overtly rude, it's quite direct and lacks any positive reinforcement or polite phrasing. The use of capitalized 'NOT' comes across as somewhat aggressive. The reviewer doesn't use any softening language or offer encouragement, which contributes to the slightly impolite tone. However, the reviewer does use professional language and provides specific feedback, which prevents the score from being extremely negative.""]"
"['A new exploration method for deep RL is presented, based on the idea of injecting noise into the deep networks’ weights. The noise may take various forms (either uncorrelated or factored) and its magnitude is trained by gradient descent along other parameters. It is shown how to implement this idea both in DQN (and its dueling variant) and A3C, with experiments on Atari games showing a significant improvement on average compared to these baseline algorithms.\n\nThis definitely looks like a worthy direction of research, and experiments are convincing enough to show that the proposed algorithms indeed improve on their baseline version. The specific proposed algorithm is close in spirit to the one from “Parameter space noise for exploration”, but there are significant differences. It is also interesting to see (Section 4.1) that the noise evolves in non-obvious ways across different games.\n\nI have two main concerns about this submission. The first one is the absence of a comparison to the method from “Parameter space noise for exploration”, which shares similar key ideas (and was published in early June, so there was enough time to add this comparison by the ICLR deadline). A comparison to the paper(s) by Osband et al (2016, 2017) would have also been worth adding. My second concern is that I find the title and overall discussion in the paper potentially misleading, by focusing only on the “exploration” part of the proposed algorithm(s). Although the noise injected in the parameters is indeed responsible for the exploration behavior of the agent, it may also have an important effect on the optimization process: in both DQN and A3C it modifies the cost function being optimized, both through the “target” values (respectively Q_hat and advantage) and the parameters of the policy (respectively Q and pi). Since there is no attempt to disentangle these exploration and optimization effects, it is unclear if one is more important than the other to explain the success of the approach. It also sheds doubt on the interpretation that the agent somehow learns some kind of optimal exploration behavior through gradient descent (something I believe is far from obvious).\n\nEstimating the impact of a paper on future research is an important factor in evaluating it. Here, I find myself in the akward (and unusual to me) situation where I know the proposed approach has been shown to bring a meaningful improvement, more precisely in Rainbow (“Rainbow: Combining Improvements in Deep Reinforcement Learning”). I am unsure whether I should take it into account in this review, but in doubt I am choosing to, which is why I am advocating for acceptance in spite of the above-mentioned concerns.\n\nA few small remarks / questions / typos:\n- In eq. 3 A(...) is missing the action a as input\n- Just below: “the the”\n- Last sentence of p. 3 can be misleading because the gradient is not back-propagated through all paths in the defined cost\n- “In our experiments we used f(x) = sgn(x) p |x|”: this makes sense to me for eq. 9 but why not use f(x) = x in eq. 10?\n- Why use factored noise in DQN and independent noise in A3C? This is presented like an arbitrary choice here.\n- What is the justification for using epsilon’ instead of epsilon in eq. 15? My interpretation of double DQN is that we want to evaluate (with the target network) the action chosen by the Q network, which here is perturbed with epsilon (NB: eq. 15 should have b in the argmax, not b*)\n- Section 4 should say explicitly that results are over 200M frames\n- Assuming the noise is sampled similarly doing evaluation (= as in training), please mention it clearly.\n- In paragraph below eq. 18: “superior performance compare to their corresponding baselines”: compared\n- There is a Section 4.1 but no 4.2\n- Appendix has a lot of redundant material with the main text, for instance it seems to me that A.1 is useless.\n- In appendix B: “σi,j is simply set to 0.017 for all parameters” => where does this magic value come from?\n- List x seems useless in C.1 and C.2\n- C.1 and C.2 should be combined in a single algorithm with a simple “if dueling” on l. 24\n- In C.3: (1) missing pi subscript for zeta in the “Output:” line, (2) it is not clear what the zeta’ parameters are for, in particular should they be used in l. 12 and 22?\n- The paper “Dropout as a Bayesian approximation” seems worth at least  adding to the list of related work in the introduction.', 'In this paper, a new heuristic is introduced with the purpose of controlling the exploration in deep reinforcement learning. \n\nThe proposed approach, NoisyNet, seems very simple and smart: a noise of zero mean and unknown variance is added to each weight of the deep network. The matrices of unknown variances are considered as parameters and are learned with a standard gradient descent. The strengths of the proposed approach are the following:\n1 NoisyNet is generic: it is applied to A3C, DQN and Dueling agents. \n2 NoisyNet reduces the number of hyperparameters. NoisyNet does not need hyperparameters (only the kind of the noise distribution has to be defined), and replacing the usual exploration heuristics by NoisyNet, a hyperparameter is suppressed (for instance \\epsilon in the case of epsilon-greedy exploration).\n3 NoisyNet exhibits impressive experimental results in comparison to the usual exploration heuristics for to A3C, DQN and Dueling agents.\n\nThe weakness of the proposed approach is the lack of explanation and investigation (experimental or theoretical) of why does Noisy work so well. At the end of the paper a single experiment investigates the behavior of weights of noise during the learning.  Unfortunately this experiment seems to be done in a hurry. Indeed, the confidence intervals are not plotted, and probably no conclusion can be reached because the curves are averaged only across three seeds! It’s disappointing.  As expected for an exploration heuristic, it seems that the noise weights of the last layer (slowly) tend to zero. However for some games, the weights of the penultimate layer seem to increase. Is it due to NoisyNet or to the lack of seeds? \n\nIn the same vein, in section 3, two kinds of noise are proposed: independent or factorized Gaussian noise. The factorized Gaussian noise, which reduces the number of parameters, is associated with DQN and Dueling agents, while the independent noise is associated with A3C agent. Why? \n\nOverall the proposed approach is interesting and has strengths, but the paper has weaknesses. I am somewhat divided for acceptance. \n', 'This paper introdues NoisyNets, that are neural networks whose parameters are perturbed by a parametric noise function, and they apply them to 3 state-of-the-art deep reinforcement learning algorithms: DQN, Dueling networks and A3C. They obtain a substantial performance improvement over the baseline algorithms, without explaining clearly why.\n\nThe general concept is nice, the paper is well written and the experiments are convincing, so to me this paper should be accepted, despite a weak analysis.\n\nBelow are my comments for the authors.\n\n---------------------------------\nGeneral, conceptual comments:\n\nThe second paragraph of the intro is rather nice, but it might be updated with recent work about exploration in RL.\nNote that more than 30 papers are submitted to ICLR 2018 mentionning this topic, and many things have happened since this paper was\nposted on arxiv (see the ""official comments"" too).\n\np2: ""our NoisyNet approach requires only one extra parameter per weight"" Parameters in a NN are mostly weights and biases, so from this sentence\none may understand that you close-to-double the number of parameters, which is not so few! If this is not what you mean, you should reformulate...\n\np2: ""Though these methods often rely on a non-trainable noise of vanishing size as opposed to NoisyNet which tunes the parameter of noise by gradient descent.""\nTwo ideas seem to be collapsed here: the idea of diminishing noise over an experiment, exploring first and exploiting later, and the idea of\nadapting the amount of noise to a specific problem. It should be made clearer whether NoisyNet can address both issues and whether other\nalgorithms do so too...\n\nIn particular, an algorithm may adapt noise along an experiment or from an experiment to the next.\nFrom Fig.3, one can see that having the same initial noise in all environments is not a good idea, so the second mechanism may help much.\n\nBTW, the short section in Appendix B about initialization of noisy networks should be moved into the main text.\n\np4: the presentation of NoisyNets is not so easy to follow and could be clarified in several respects:\n- a picture could be given to better explain the structure of parameters, particularly in the case of factorised (factorized, factored?) Gaussian noise.\n- I would start with the paragraph ""Considering a linear layer [...] below)"" and only after this I would introduce \\theta and \\xi as a more synthetic notation.\nLater in the paper, you then have to state ""...are now noted \\xi"" several times, which I found rather clumsy.\n\np5: Why do you use option (b) for DQN and Dueling and option (a) for A3C? The reason why (if any) should be made clear from the clearer presentation required above.\n\nBy the way, a wild question: if you wanted to use NoisyNets in an actor-critic architecture like DDPG, would you put noise both in the actor and the critic?\n\nThe paragraph above Fig3 raises important questions which do not get a satisfactory answer.\nWhy is it that, in deterministic environments, the network does not converge to a deterministic policy, which should be able to perform better?\nWhy is it that the adequate level of noise changes depending on the environment? By the way, are we sure that the curves of Fig3 correspond to some progress\nin noise tuning (that is, is the level of noise really ""better"" through time with these curves, or they they show something poorly correlated with the true reasons of success?)?\n\nFinally, I would be glad to see the effect of your technique on algorithms like TRPO and PPO which require a stochastic policy for exploration, and where I believe that the role of the KL divergence bound is mostly to prevent the level of stochasticity from collasping too quickly.\n\n-----------------------------------\nLocal comments:\n\nThe first sentence may make the reader think you only know about 4-5 old works about exploration.\n\nPp. 1-2 : ""the approach differs ... from variational inference. [...] It also differs variational inference...""\nIf you mean it differs from variational inference in two ways, the paragraph should be reorganized.\n\np2: ""At a high level our algorithm induces a randomised network for exploration, with care exploration\nvia randomised value functions can be provably-efficient with suitable linear basis (Osband et al., 2014)""\n=> I don\'t understand this sentence at all.\n\nAt the top of p3, you may update your list with PPO and ACKTR, which are now ""classical"" baselines too.\n\nAppendices A1 and A2 are a lot redundant with the main text (some sentences and equations are just copy-pasted), this should be improved.\nThe best would be to need to reject nothing to the Appendix.\n\n---------------------------------------\nTypos, language issues:\n\np2\nthe idea ... the optimization process have been => has\n\np2\nThough these methods often rely on a non-trainable noise of vanishing size as opposed to NoisyNet which tunes the parameter of noise by gradient descent.\n=> you should make a sentence...\n\np3\nthe the double-DQN\n\nseveral times, an equation is cut over two lines, a line finishing with ""="", which is inelegant\n\nYou should deal better with appendices: Every ""Sec. Ax/By/Cz"" should be replaced by ""Appendix Ax/By/Cz"".\nBesides, the big table and the list of performances figures should themselves be put in two additional appendices\nand you should refer to them as Appendix D or E rather than ""the Appendix"".\n\n\n\n\n']","[50, 50, 50]","[80, 70, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as a 'worthy direction of research' with 'convincing' experiments, and advocates for acceptance despite some concerns. They see value in the work and its impact on future research. However, they also express two main concerns, which prevents the sentiment from being more strongly positive. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames their concerns as suggestions rather than harsh criticisms. They use phrases like 'I have two main concerns' and 'A few small remarks / questions / typos' which maintain a professional and courteous tone. The reviewer also acknowledges their own potential bias in a transparent manner. The high level of detail in the feedback also demonstrates respect for the authors' work."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges several strengths of the proposed approach (NoisyNet), such as its genericity, reduction of hyperparameters, and impressive experimental results. However, they also point out weaknesses, particularly the lack of explanation and investigation into why NoisyNet works so well. The reviewer expresses being 'somewhat divided for acceptance,' indicating a mixed but slightly positive overall sentiment.\n\nThe politeness score is 70 (fairly polite) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'seems very simple and smart' and 'impressive experimental results' when discussing strengths. When addressing weaknesses, they use more gentle language like 'It's disappointing' rather than harsh criticism. The reviewer also acknowledges both strengths and weaknesses, showing a balanced and fair approach. However, they don't use overly formal or excessively polite language, maintaining a neutral professional tone."", ""The sentiment score is 50 (slightly positive) because the reviewer states that 'the paper should be accepted' and describes the concept as 'nice', the paper as 'well written', and the experiments as 'convincing'. However, they also mention a 'weak analysis' which prevents a higher positive score. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames their comments as suggestions ('you should', 'could be clarified'). They also acknowledge positive aspects before offering critiques. The reviewer maintains a professional tone, avoiding harsh language or personal attacks, which contributes to the polite score. However, some direct criticisms prevent it from being extremely polite.""]"
"['This is a strong paper. It focuses on an important problem (speeding up program synthesis), it’s generally very well-written, and it features thorough evaluation. The results are impressive: the proposed system synthesizes programs from a single example that generalize better than prior state-of-the-art, and it does so ~50% faster on average.\n\nIn Appendix C, for over half of the tasks, NGDS is slower than PROSE (by up to a factor of 20, in the worst case). What types of tasks are these? In the results, you highlight a couple of specific cases where NGDS is significantly *faster* than PROSE—I would like to see some analysis of the cases were it is slower, as well. I do recognize that in all of these cases, PROSE is already quite fast (less than 1 second, often much less) so these large relative slowdowns likely don’t lead to a noticeable absolute difference in speed. Still, it would be nice to know what is going on here.\n\nOverall, this is a strong paper, and I would advocate for accepting it.\n\n\nA few more specific comments:\n\n\nPage 2, “Neural-Guided Deductive Search” paragraph: use of the word “imbibes” - while technically accurate, this use doesn’t reflect the most common usage of the word (“to drink”). I found it very jarring.\n\nThe paper is very well-written overall, but I found the introduction to be unsatisfyingly vague—it was hard for me to evaluate your “key observations” when I couldn’t quite yet tell what the system you’re proposing actually does. The paragraph about “key observation III” finally reveals some of these details—I would suggest moving this much earlier in the introduction.\n\nPage 4, “Appendix A shows the resulting search DAG” - As this is a figure accompanying a specific illustrative example, it belongs in this section, rather than forcing the reader to hunt for it in the Appendix.\n\n', 'This paper extends and speeds up PROSE, a programming by example system, by posing the selection of the next production rule in the grammar as a supervised learning problem.\n\nThis paper requires a large amount of background knowledge as it depends on understanding program synthesis as it is done in the programming languages community. Moreover the work mentions a neurally-guided search, but little time is spent on that portion of their contribution. I am not even clear how their system is trained.\n\nThe experimental results do show the programs can be faster but only if the user is willing to suffer a loss in accuracy. It is difficult to conclude overall if the technique helps in synthesis.', 'The paper presents a branch-and-bound approach to learn good programs\n(consistent with data, expected to generalise well), where an LSTM is\nused to predict which branches in the search tree should lead to good\nprograms (at the leaves of the search tree). The LSTM learns from\ninputs of program spec + candidate branch (given by a grammar\nproduction rule) and ouputs of quality scores for programms. The issue\nof how greedy to be in this search is addressed.\n\nIn the authors\' set up we simply assume we are given a \'ranking\nfunction\' h as an input (which we treat as black-box). In practice\nthis will simply be a guess (perhaps a good educated one) on which\nprograms will perform correctly on future data. As the authors\nindicate, a more ambitious paper would consider learning h, rather\nthan assuming it as a given.\n\nThe paper has a number of positive features. It is clearly written\n(without typo or grammatical problems). The empirical evaluation\nagainst PROSE is properly done and shows the presented method working\nas hoped. This was a competent approach to an interesting (real)\nproblem. However, the \'deep learning\' aspect of the paper is not\nprominent: an LSTM is used as a plug-in and that is about it. Also,\nalthough the search method chosen was reasonable, the only real\ninnovation here is to use the LSTM to learn a search heuristic.\n\n\nThe authors do not explain what ""without attention"" means.\n\n\nI think the authors should mention the existence of (logic) program\nsynthesis using inductive logic programming. There are also (closely\nrelated) methods developed by the LOPSTR (logic-based program\nsynthesis and transformation) community. Many of the ideas here are\nreminiscent of methods existing in those communities (e.g. top-down search\nwith heuristics). The use of a grammar to define the space of programs\nis similar to the ""DLAB"" formalism developed by researchers at KU\nLeuven.\n\nADDED AFTER REVISIONS/DISCUSSIONS\n\nThe revised paper has a number of improvements which had led me to give it slightly higher rating.\n\n']","[80, -30, 40]","[70, 0, 60]","[""The sentiment score is 80 because the review starts with 'This is a strong paper' and concludes with 'Overall, this is a strong paper, and I would advocate for accepting it.' The reviewer highlights the paper's importance, good writing, thorough evaluation, and impressive results. The politeness score is 70 because the reviewer uses respectful language throughout, offers constructive criticism, and balances positive feedback with suggestions for improvement. The reviewer's tone is professional and courteous, using phrases like 'I would like to see' and 'it would be nice to know' when requesting additional information. The slight deduction in politeness is due to the direct criticism of word choice ('very jarring') and structure of the introduction, though these are still presented in a constructive manner."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the paper's contribution in extending and speeding up PROSE, they express several concerns. They mention the need for extensive background knowledge, lack of clarity on the neural guidance aspect, and uncertainty about the overall effectiveness of the technique. The reviewer also points out that improved speed comes at the cost of accuracy. The politeness score is neutral (0) as the reviewer maintains a professional tone without being particularly polite or rude. They present their observations and criticisms in a straightforward manner without using overly harsh language or excessive praise."", ""The sentiment score is 40 (slightly positive) because the reviewer acknowledges several positive aspects of the paper, such as it being clearly written, having a proper empirical evaluation, and addressing an interesting real problem. However, the reviewer also points out limitations, like the limited 'deep learning' aspect and lack of major innovation. The final paragraph indicates a slight improvement after revisions, further supporting a mildly positive sentiment. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. The reviewer avoids harsh language when pointing out weaknesses and suggests improvements in a professional manner. The tone is academic and objective, maintaining courtesy while providing a thorough review.""]"
"[""- algorithm 1 has a lot of problem specific hyperparametes that may be difficult to get right. Not clear how important they are\n- they analyze the simpler (analytically and likely computationally) Boolean hyperparameter case (each hyperparameter is binary). Not a realistic setting. In their experiments they use these binary parameter spaces so I'm not sure how much I buy that it is straightforward to use continuous valued polynomials. \n- interesting idea but I think it's more theoretical than practical. Feels like a hammer in need of a nail. "", 'The paper is about hyperparameter optimization, which is an important problem in deep learning due to the large number of hyperparameters in contemporary model architectures and optimization algorithms.\n\nAt a high-level, hyperparameter optimization (for the challenging case of discrete variables) can be seen as a black-box optimization problem where we have only access to a function evaluation oracle (but no gradients etc.). In the entirely unstructured case, there are strong lower bounds with an exponential dependence on the number of hyperparameters. In order to sidestep these impossibility results, the current paper assumes structure in the unknown function mapping hyperparameters to classification accuracy. In particular, the authors assume that the function admits a representation as a sparse and low-degree polynomial. While the authors do not empirically validate whether this is a good model of the unknown function, it appears to be a reasonable assumption (the authors *do* empirically validate their overall approach).\n\nBased on the sparse and low-degree assumption, the paper introduces a new algorithm (called Harmonica) for hyperparameter optimization. The main idea is to leverage results from compressed sensing in order to recover the sparse and low-degree function from a small number of measurements (i.e., function evaluations). The authors derive relevant sample complexity results for their approach. Moreover, the method also yields new algorithms for learning decision trees.\n\nIn addition to the theoretical results , the authors conduct a detailed study of their algorithm on CIFAR10. They compare to relevant recent work in hyperparameter optimization (Bayesian optimization, random search, bandit algorithms) and find that their method significantly improves over prior work. The best parameters found by Harmonica improve over the hand-tuned results for their ""base architecture"" (ResNets).\n\nOverall, I find the main idea of the paper very interesting and well executed, both on the theoretical and empirical side. Hence I strongly recommend accepting this paper.\n\n\nSmall comments and questions:\n\n1. It would be interesting to see how close the hyperparameter function is to a low-degree and sparse polynomial (e.g., MSE of the best fit).\n\n2. A comparison without dummy parameters would be interesting to investigate the performance differences between the algorithms in a lower-dimensional problem.\n\n3. The current paper does not mention the related work on hyperparameter optimization using reinforcement learning techniques (e.g., Zoph & Le, ICLR 2017). While it might be hard to compare to this approach directly in experiments, it would still be good to mention this work and discuss how it relates to the current paper.\n\n4. Did the authors tune the hyperparameters directly using the CIFAR10 test accuracy? Would it make sense to use a slightly smaller training set and to hold out say 5k images for hyperparameter evaluation before making the final accuracy evaluation on the test set? The current approach could be prone to overfitting.\n\n5. While random search does not explicitly exploit any structure in the unknown function, it can still implicitly utilize smoothness or other benign properties of the hyperparameter space. It might be worth adding this in the discussion of the related work.\n\n6. Algorithm 1: Why is the argmin for g_i  (what does the index i refer to)?\n\n7. Why does PSR truncate the indices in alpha? At least in ""standard"" compressed sensing, the Lasso also has recovery guarantees without truncation (and empirically works sometimes better without).\n\n9. Definition 3: Should C be a class of functions mapping {-1, 1}^n to R?  (Note the superscript.)\n\n10. On Page 3 we assume that K = 1, but Theorem 6 still maintains a dependence on K. It might be cleaner to either treat the general K case throughout, or state the theorem for K = 1.\n\n11. On CIFAR10, the best hyperparameters do not improve over the state of the art with other models (e.g., a wide ResNet). It could be interesting to run Harmonica in the regime where it might improve over the best known models for CIFAR10.\n\n12. Similarly, it would be interesting to see whether the hyperparameters identified by Harmonica carry over to give better performance on ImageNet. The authors claim in C.3 that the hyperparameters identified by Harmonica generalize from small networks to large networks. Testing whether the hyperparameters also generalize from a smaller to a larger dataset would be relevant as well.', 'This paper looks at the problem of optimizing hyperparameters under the assumption that the unknown function can be approximated by a sparse and low degree polynomial in the Fourier basis. The main result is that the approximate minimization can be performed over the boolean hypercube where the number of evaluations is linear in the sparsity parameter. \n\nIn the presented experiments, the new spectral method outperforms the tool based on the Bayesian optimization, technique based on MAB and random search. Their result also has an application in learning decision trees where it significantly improves the sample complexity bound.\n\nThe main theoretical result, i.e., the improvement in the sample complexity when learning decision trees, looks very strong. However, I find this result to be out of the context with the main theme of the paper. \n\nI find it highly unlikely that a person interested in using Harmonica to find the right hyperparamters for her deep network would also be interested in provable learning of decision trees in quasi-polynomial time along with a polynomial sample complexity. Also the theoretical results are developed for Harmonica-1 while Harmonica-q is the main method used in the experiments.\n\nWhen it comes to the experiments only one real-world experiment is present. It is hard to conclude which method is better based on a single real-world experiment. Moreover, the plots are not very intuitive, i.e., one would expect that Random Search takes the smallest amount of time. I guess the authors are plotting the running time that also includes the time needed to evaluate different configurations. If this is the case, some configurations could easily require more time to evaluate than the others. It would be useful to plot the total number of function evaluations for each of the methods next to the presented plots.\n\nIt is not clear what is the stopping criterion for each of the methods used in the experiments. One weakness of Harmonica is that it has 6 hyperparameters itself to be tuned. It would be great to see how Harmonica compares with some of the High-dimensional Bayesian optimization methods. \n\nFew more questions:\n\nWhich problem does Harmonica-q solves that is present in Harmonica-1, and what is the intuition behind the fact that it achieves better empirical results?\n\nHow do you find best t minimizers of g_i in line 4 of Algorithm 3?\n']","[-50, 90, 20]","[0, 80, 60]","[""The sentiment score is -50 because the review is generally critical and points out several issues with the work, such as problem-specific hyperparameters, unrealistic settings, and questioning its practicality. However, it's not entirely negative as it acknowledges the idea as 'interesting'. The politeness score is 0 (neutral) because the language is direct and matter-of-fact without being overtly polite or rude. The reviewer states their concerns plainly without using harsh language or personal attacks, but also without softening their critique with polite phrases or compliments."", ""The sentiment score is 90 because the reviewer strongly recommends accepting the paper, describing the main idea as 'very interesting and well executed'. They provide positive feedback on both theoretical and empirical aspects. The politeness score is 80 as the reviewer uses respectful language throughout, offers constructive feedback, and frames their comments as suggestions or questions rather than demands. They acknowledge the authors' work positively and provide detailed, thoughtful comments without any harsh criticism. The slightly lower politeness score (compared to sentiment) is due to the review being primarily focused on the content rather than explicitly using highly polite language."", ""Sentiment Score (20): The review starts with a positive tone, acknowledging the paper's main results and its outperformance in experiments. However, it then raises several concerns and questions, which balance out the initial positivity. The overall sentiment is slightly positive but with significant reservations.\n\nPoliteness Score (60): The reviewer maintains a professional and respectful tone throughout. They use phrases like 'I find' and 'It would be useful' to express opinions and suggestions, which is polite. The critique is presented constructively, asking questions and suggesting improvements rather than making harsh judgments. However, the language is not overly formal or deferential, keeping the score from being higher.""]"
"['Learning better policies from logged bandit feedback is a very important problem, with wide applications in internet, e-commerce and anywhere it is possible to incorporate controlled exploration. The authors study the problem of learning the best policy from logged bandit data. While this is not a brand new problem, the important and relevant contribution that the authors make is to do this using policies that can be learnt via neural networks. The authors are motivated by two main applications: (i) multi-class classification problems with bandit feedback (ii) ad placements problem in the contextual bandit setting. \n\nThe main contributions of the authors is to design an output layer that allows training on logged bandit feedback data. Traditionally in the full feedback setting (setting where one gets to see the actual label and not just if our prediction is correct or incorrect) one uses cross-entropy loss function to optimize the parameters of a deep neural network. This does not work in a bandit setting, and previous work has developed various methods such as inverse-propensity scoring, self-normalized inverse propensity scoring, doubly robust estimators to handle the bandit setting. The authors in this paper work with self-normalized inverse propensity scoring as the technique to deal with bandit feedback data. the self normalized inverse propensity estimator (SNIPS) that the authors use is not a new estimator and has been previously studied in the work of Adith Swaminathan and co-authors. However, this estimator being a ratio is not an easy optimization problem to work with. The authors use a fairly standard reduction of converting ratio problems to a series of constrained optimization problems. This conversion of ratio problems to a series of constrained optimization problems is a standard textbook problem, and therefore not new. But, i like the authors handling of the constrained optimization problems via the use of Lagrangian constraints. It would have been great if the authors connected this to the REINFORCE algorithm of Williams. Unfortunately, the authors do not do a great job in establishing this connection, and I hope they do this in the full version of the paper.  The experimental results are fairly convincing and i really do not have any major comments. Here are my ""minor"" comments.\n\n1. It would be great if the authors can establish connections to the REINFORCE algorithm in a more elaborate manner. It would be really instructive to the reader.\n\n2.  On page 6,  the authors talk about lowering the learning rate and the learning rate schedule. I am guessing this is because of the intrinsic high variance of the problem. It would be great if the authors can explain in more detail why they did so.', 'This paper proposes a new output layer in neural networks, which allows them to use logged contextual bandit feedback for training. The paper is well written and well structured. \n\n\nGeneral feedback:\n\nI would say the problem addressed concerns stochastic learning in general, not just SGD for training neural nets. And it\'s not a ""new output layer"", but just a softmax output layer (Eq. 1) with an IPS+baseline training objective (Eq. 16).\n\n\nOthers:\n\n- The baseline in REINFORCE (Williams\'92), which is equivalent to introduced Lagrange multiplier, is well known and well defined as control variate in Monte Carlo simulation, certainly not an ""ad-hoc heuristic"" as claimed in the paper [see Greensmith et al. (2004). Variance Reduction for Gradient Estimates in Reinforcement Learning, JMLR 5.]\n\n- Bandit to supervised conversion: please add a supervised baseline system trained just on instances with top feedbacks -- this should be a much more interesting and relevant strong baseline. There are multiple indications that this bandit-to-supervised baseline is hard to outperform in a number of important applications.\n\n- The final objective IPS^lambda is identical to IPS with a translated loss and thus re-introduces problems of IPS in exactly the same form that the article claims to address, namely:\n    * the estimate is not bounded by the range of delta\n    * the importance sampling ratios can be large; samples with high such ratios lead to larger gradients thus dominating the updates. The control variate of the SNIPS objective can be seen as defining a probability distribution over the log, thus ensuring that for each sample that sample’s delta is multiplied by a value in [0,1] and not by a large importance sampling ratio.\n    * IPS^lambda introduces a grid search which takes more time and the best value for lambda might not even be tested. How do you deal with it?\n\n- As author note, IPS^lambda is very similar to an RL-baseline, so results of using IPS with it should be reported as well:\n    In more detail, Note:\n    1. IPS for losses<0 and risk minimization: raise the probability of every sample in the log irrespective of the loss itself\n    2. IPS for losses>0 and risk minimization: lower the same probability\n    3. IPS^lambda: by the translation of the loss, it divides the log into 2 groups: a group whose probabilities will be lowered and a group whose probabilities will be raised (and a third group for delta=lambda but the objective will be agnostic to these)\n    4. IPS with a baseline would do something similar but changes over time, which means the above groups are not fixed and might work better. Furthermore, there is no hyperparameter/grid search required for the simple RL-baseline\n    -> results of using IPS with the RL-baseline should be reported for the BanditNet rows in Table 1 and in CIFAR-10 experiments.\n\n- What is the feedback in the CIFAR-10 experiments? Assuming it\'s from [0..1], and given the tested range of lambdas, you should run into the same problems with IPS and its degenerate solutions for lambdas >=1.0. In general, how are your methods behaving for lambda* (corresponding to S*) such that makes all difference (delta_i - lambda*) positive or negative?\n\n- The claim of Theorem 2 in appendix B does not follow from its proof: what is proven is that the value of S(w) lies in an interval [1-e..1+e] with a certain probability for all w. It says nothing about a solution of an optimization problem of the form f(w)/S(w) or its constrained version. Actually, the proof never makes any connection to optimization.\n\n- What the appendix C basically claims is that it\'s not possible to get an unbiased estimate of a gradient for a certain class of non-convex ratios with a finite-sum structure. This would contradict some previously established convergence results for this type of problems: Reddi et al. (2016) Stochastic Variance Reduction for Nonconvex Optimization, ICML and Wang et al. 2013. Variance Reduction for Stochastic Gradient Optimization, NIPS. On the other hand, there seem to be no need to prove such a claim in the first claim, since the difficulty of performing self-normalized IPS on GPU should be evident, if one remembers that the normalization should run over the whole logged dataset (while only the current mini-batch is accessible to the GPU).', 'In this paper, the authors propose a new output layer for deep networks allowing training on logged contextual bandit feedback. They propose a counterfactual risk minimization objective which makes the training procedure different from the one that uses conventional cross-entropy in supervised learning. The authors claim that this is the first attempt where Batch Learning from Bandit Feedback (BLBF) is performed using deep learning. \n\nThe authors demonstrate the derivation steps of their theoretical model and present 2 empirical results. The first result is on visual object classification using CIFAR-10.  To simulate logged bandit feedback for CIFAR-10, the authors perform the standard supervised to bandit conversion using a hand-coded logging policy that achieves 49 % error rate on training data. Using the logged bandit feedback data for the proposed bandit model, the authors are able to achieve substantial improvement (13% error rate) and given more bandit feedback, the model is able to compete with the same architecture trained on the full-information using cross entropy (achieving 8.2% error rate).\n\nThe second result is a real-world verification of the proposed approach (as the logged feedback are real and not synthesized using a conversion approach) which is an advertisement placing task from Criteo’s display advertising system (Lefortier et al., 2016). The task consists of choosing the product to display in the ad in order to maximize the number of clicks. The proposed deep learning approach improve substantially on state-of-the-art. The authors show empirically that the proposed approach is able to have substantial gain compared to other methods. The analysis is done by performing ablation studies on context features which are not effective on linear models.\n\nThe paper is well written. The authors make sure to give the general idea of their approach and its motivation, detail the related work and position their proposed approach with respect to it. The authors also propose a new interpretation of the baseline in “REINFORCE-like” methods where it makes the counterfactual objective equivariant (besides the variance reduction role). The authors explain their choice of using importance sampling to estimate the counterfactual risk. They also detail the arguments for using the SNIPS estimator, the mathematical derivation for the training algorithm and finally present the empirical results.\n\nBesides the fact that empirical results are impressive, the presented approach allows to train use deep nets when manually labelling full-information feedback is not viable.\n\nIn section 4.2, the neural network that has been used is a 2 layer network with tanh activation. It is clear that the intention of the authors is to show that even with a simple neural architecture, the gain is substantial compared to the baseline method, which is indeed the right approach to go with. Still, it would have been of a great benefit if they had used a deeper architecture using ReLU-based activations.\n\n']","[70, -20, 80]","[80, 50, 70]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'important' and 'relevant', with 'fairly convincing' experimental results. They appreciate the authors' contributions and methodology. However, it's not 100 as they do point out some areas for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions. They use phrases like 'I like', 'It would be great if', and 'I hope', which are polite ways to offer critique. The reviewer also acknowledges the value of the work while suggesting improvements, maintaining a courteous tone throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and structured, they provide numerous critiques and point out several issues with the proposed method. The reviewer challenges some of the paper's claims, suggests additional baselines, and identifies potential problems with the approach. However, the score is not deeply negative as the reviewer does offer some positive comments and engages seriously with the content.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I would say' and 'please add' which soften their critiques. The reviewer also provides detailed explanations for their concerns, showing engagement with the work. However, the score is not extremely high as the review is quite direct in its criticisms and doesn't include many explicitly polite phrases or compliments beyond the initial positive comment."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They describe the work as 'well written', note that the empirical results are 'impressive', and highlight the substantial improvements and benefits of the proposed approach. The only minor criticism is a suggestion for using a deeper architecture, which doesn't significantly detract from the overall positive sentiment. The politeness score is 70 (polite) as the reviewer uses respectful and professional language throughout. They acknowledge the authors' efforts, use phrases like 'The authors make sure to...', and frame their suggestion constructively. The tone is consistently courteous without being overly deferential.""]"
"['This paper considers the problem of one/few-shot density estimation, using metalearning techniques that have been applied to one/few-shot supervised learning. The application is an obvious target for research and some relevant citations are missing, e.g. ""Towards a Neural Statistician"" (Edwards et al., ICLR 2017). Nonetheless, I think the current paper seems interesting enough to merit publication.\n\nThe paper is well-produced, i.e. the overall writing, visuals, and narrative flow are good. It was easy to read the paper straight through while understanding both the technical details and more intuitive motivations.\n\nI have some concerns about the architectures and experiments presented in the paper. For architectures: the attention-based model seems powerful but difficult to scale to problems with more inputs for conditioning, and the meta PixelCNN model is a standard PixelCNN trained with the MAML approach by Finn et al. For experiments: the ImageNet flipping task is clearly tailored to the strengths of the attention-based model, and the presentation of the general Omniglot results could be improved. The image flipping experiment is neat, but the attention-based model\'s strong performance is unsurprising. I think the results in Tables 1/2 should be merged into a single table. It would make it clear that the MAML-based and attention-based models achieve similar performance on this task.\n\nOverall, I think the paper makes a nice contribution. The paper could be improved significantly, e.g., by showing how to scale the attention-based architecture to problems with more data or by designing an architecture specifically for use with MAML-based inference.', 'This paper focuses on the density estimation when the amount of data available for training is low. The main idea is that a meta-learning model must be learnt, which learns to generate novel density distributions by learn to adapt a basic model on few new samples. The paper presents two independent method.\n\nThe first method is effectively a PixelCNN combined with an attention module. Specifically, the support set is convolved to generate two sets of feature maps, the so called ""key"" and the ""value"" feature maps. The key feature map is used from the model to compute the attention in particular regions in the support images to generate the pixels for the new ""target"" image. The value feature maps are used to copmpute the local encoding, which is used to generate the respective pixels for the new target image, taking into account also the attention values. The second method is simpler, and very similar to fine-tuning the basis network on the few new samples provided during training. Despite some interesting elements, the paper has problems.\n\nFirst, the novelty is rather limited. The first method seems to be slightly more novel, although it is unclear whether the contribution by combining different models is significant. The second method is too similar to fine-tuning: although the authors claim that \\mathcal{L}_inner can be any function that minimizes the total loss \\mathcal{L}, in the end it is clear that the log-likelihood is used. How is this approach (much) different from standard fine-tuning, since the quantity P(x; \\theta\') is anyways unknown and cannot be ""trained"" to be maximized.\n\nBesides the limited novelty, the submission leaves several parts unclear. First, why are the convolutional features of the support set in the first methods divided into ""key"" and ""value"" feature maps as in p_key=p[:, 0:P], p_value=p[:, P:2*P]? Is this division arbitrary, or is there a more basic reason? Also, is there any different between key and value? Why not use the same feature map for computing the attention and computing eq (7)?\n\nAlso, in the first model it is suggested that an additional feature can be having a 1-of-K channel for the supporting image label: the reason is that you might have multiple views of objects, and knowing which view contributes to the attention can help learning the density. However, this assumes that the views are ordered, namely that the recording stage has a very particular format. Isn\'t this a bit unrealistic, given the proposed setup anyways?\n\nRegarding the second method, it is not clear why leaving this room for flexibility (by allowing L_inner to be any function) to the model is a good idea. Isn\'t this effectively opening the doors to massive overfitting? Besides, isn\'t the statement that the function \\mathcal{L}_inner void? At the end of the day one can also claim the same for gradient descent: you don\'t need to have the true gradients of the true loss, as long as the objective function obtains gradually lower and lower values?\n\nLast, it is unclear what is the connection between the first and the second model. Are these two independent models that solve the same problem? Or are they connected?\n\nRegarding the evaluation of the models, the nature of the task makes the evaluation hard: for real data like images one cannot know the true distribution of particular support examples. Surrogate tasks are explored, first image flipping, then likelihood estimation of Omniglot characters, then image generation. Image flipping does not sound a very relevant task  to density estimation, given that the task is deterministic. Perhaps, what would make more sense would be to generate a new image given that the support set has images of a particular orientation, meaning that the model must learn how to learn densities from arbitrary rotations. Regarding Omniglot character generation, the surrogate task of computing likelihood of known samples gives a bit better, however, this is to be expected when combining a model without attention, with an attention module.\n\nAll in all, the paper has some interesting ideas. I encourage the authors to work more on their submission and think of a better evaluation and resubmit.\n\n', 'This paper focuses on few shot learning with autoregressive density estimation. Specifically, the paper improves PixelCNN with  1) neural attention, 2) meta learning techniques, and shows that the model achieve STOA few showt density estimation on the Omniglot dataset and demonstrate the few showt image generation on the Stanford Online Products dataset. \n\nThe model is interesting, however, several details are not clear, which  makes it harder to repeat the model and the experimental results. For example, what is the reason to use the (key, value) pair to encode these support images, what does the ""key"" means and what is the difference between ""keys"" and ""values""? In the experiments, the author did not explain the meaning of ""nats/dim"" and how to compute it. Another question is about the repetition of the experimental results. We know that PixelCNN is already a quite complicated model, it would be even harder to implement the proposed model. I wonder whether the author will release the official code to public to help the community?']","[50, -30, 20]","[75, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer states that the paper 'seems interesting enough to merit publication' and 'makes a nice contribution', despite having some concerns. They also praise the paper's production quality and readability. However, they do point out some limitations and areas for improvement, balancing the positive aspects.\n\nThe politeness score is 75 (quite polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths before presenting criticisms, and frame their concerns as suggestions for improvement rather than harsh critiques. Phrases like 'I think' and 'could be improved' maintain a collegial tone. The reviewer also provides specific, actionable feedback, which is considered polite in academic contexts."", ""The sentiment score is -30 because while the reviewer acknowledges some 'interesting ideas' and encourages the authors to work more on their submission, the overall tone is critical. The reviewer points out several problems with the paper, including limited novelty, unclear parts, and issues with evaluation. However, it's not entirely negative as they see potential for improvement. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They offer constructive feedback and suggestions for improvement, such as 'I encourage the authors to work more on their submission and think of a better evaluation and resubmit.' The tone is academic and objective, maintaining politeness while still conveying critical points."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting model and its achievement of state-of-the-art results. However, they express concerns about clarity and reproducibility, which tempers the positive sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, framing their criticisms as questions or suggestions rather than direct criticisms. They also acknowledge the paper's strengths before discussing areas for improvement. The reviewer's tone is professional and constructive, avoiding harsh or dismissive language.""]"
"['The authors propose a new network architecture for RL that contains some relevant inductive biases about planning. This fits into the recent line of work on implicit planning where forms of models are learned to be useful for a prediction/planning task. The proposed architecture performs something analogous to a full-width tree search using an abstract model (learned end-to-end). This is done by expanding all possible transitions to a fixed depth before performing a max backup on all expanded nodes. The final backup value is the Q-value prediction for a given state, or can represent a policy through a softmax.\n\nI thought the paper was clear and well-motivated. The architecture (and various associated tricks like state vector normalization) are well-described for reproducibility. \n\nExperimental results seem promising but I wasn’t fully convinced of its conclusions. In both domains, TreeQN and AtreeC are compared to a DQN architecture, but it wasn’t clear to me that this is the right baseline. Indeed TreeQN and AtreeC share the same conv stack in the encoder (I think?), but also have the extra capacity of the tree on top. Can the performance gain we see in the Push task as a function of tree depth be explained by the added network capacity? Same comment in Atari, but there it’s not really obvious that the proposed architecture is helping. Baselines could include unsharing the weights in the tree, removing the max backup, having a regular MLP with similar capacity, etc.\n\nPage 5, the auxiliary loss on reward prediction seems appropriate, but it’s not clear from the text and experiments whether it actually was necessary. Is it that makes interpretability of the model easier (like we see in Fig 5c)? Or does it actually lead to better performance?  \n\nDespite some shortcomings in the result section, I believe this is good work and worth communicating as is.', '\n This was an interesting read.  \n\nI feel that there is a mismatch between intuition of what a model could do (based on the structure of the architecture) versus what a model does. Just because the transition function is shared and the model could learn to construct a tree, when trained end-to-end the system is not sufficiently constrained to learn this specific behaviour. More to a point. I think the search tree perspective is interesting, but isn’t this just a deeper model with shared weights? And a max operation? It seems no loss is used to force the embeddings produced by the transition model to match the embeddings that you would get if you take a particular action in a particular state, right? Is there any specific attempt to visualize or understand the embeddings inside the tree? The same regarding the rewards. If there is no auxiliary loss attempting to force the intermediary prediction to be valid rewards, why would the model use those free latent variables to encode rewards? I think this is a pitfall that many deep network papers fall, where by laying out a particular structure it is directly inferred that the model discovers or follows a particular solution (where the latent have prescribed semantics). I would argue that is rarely the case. When the system is learned end-to-end, the structure does not impose the behaviour of the model, and is up to the authors of the paper to prove that the trained model does anything similar to expanding a tree. And this is not by showing final performance on a game. If indeed the model does anything similar to search, than all intermediary representations should correspond to what semantically they should. \nIgnoring my verbose comment, another view is that the baseline are disadvantaged to the treeQN, because they have less parameters (and are less deep which has a huge impact on the learnability and expressivity of the deep network). \n', '# Update after the rebuttal\nThank you for the rebuttal.\nThe authors claim that the source of objective mismatch comes from n-step Q-learning, and their method is well-justified in 1-step Q-learning. However, there is still a mismatch even with 1-step Q-learning because the bootstrapped target is also computed from the TreeQN. More specifically, there can be a mismatch between the optimal action sequences computed from TreeQN at time t and t+1 if the depth of TreeQN is equal or greater than 2. Thus, the author\'s response is still not convincing to me.\nI like the overall idea of using a tree-structured neural network which internally performs planning as an abstraction of Q-function, which makes implementation simpler compared to VPN. However, the particular method (TreeQN) proposed in this paper introduces a mismatch in the model learning as mentioned above. One could argue that TreeQN is learning an ""abstract"" planning rather than ""grounded"" planning. However, the fact that reward prediction loss is used to train TreeQN significantly weakens this claim, and there is no such an evidence in the paper. \nIn conclusion, I think the research direction is worth pursuing, but the proposed modification from VPN is not well-justified.\n\n# Summary\nThis paper proposes TreeQN and ATreeC which perform look-ahead planning using neural networks. TreeQN simulates the future by predicting rewards/values of the future states and performs tree backup to construct Q-values. ATreeC is an actor-critic architecture that uses a softmax over TreeQN. The architecture is trained through n-step Q-learning with reward prediction loss. The proposed methods outperform DQN baseline on 2D Box Pushing domain and outperforms VPN on Atari games.\n\n[Pros]\n- The paper is easy to follow.\n- The application to actor-critic setting (ATreeC) is novel, though the underlying idea was proposed by [O\'Donoghue et al., Schulman et al.].\n\n[Cons]\n- The proposed method has a technical issue.\n- The proposed idea (TreeQN) and underlying motivation are almost same as those of VPN [Oh et al.], but there is no in-depth discussion that shows why TreeQN is potentially better than VPN. \n- Comparison to VPN on Atari is not much convincing. \n\n# Novelty and Significance\n- The underlying motivation (planning without predicting observations), the architecture (transition/reward/value functions applied to the latent state space), and the algorithm (n-step Q-learning with reward prediction loss) are same as those of VPN. But, the paper does not provide in-depth discussion on this. The following is the differences that I found from this paper, so it would be important to discuss why such differences are important.\n\n1) The paper emphasizes the ""fully-differentiable tree planning"" aspect in contrast to VPN that back-propagates only through ""non-branching"" trajectories during training. However, differentiating TreeQN also amounts to back-propagating through a ""single"" trajectory in the tree that gives the maximum Q-value. Thus, the only difference between TreeQN and VPN is that TreeQN follows the best (estimated) action sequence, while VPN follows the chosen action sequence in retrospect during back-propagation. Can you justify why following the best estimated action sequence is better than following the chosen action sequence during back-propagation (see Technical Soundness section for discussion)?\n\n2) TreeQN only sets targets for the final Q-value after tree backup, whereas VPN sets targets for all intermediate value predictions in the tree. Why is TreeQN\'s approach better than VPN\'s approach? \n\n- The application to actor-critic setting (ATreeC) is novel, though the underlying idea of combining Q-learning with policy gradient was proposed by [O\'Donoghue et al.] and [Schulman et al.].\n\n# Technical Soundness\n- The proposed idea of setting targets for the final Q-value after tree backup can potentially make the temporal credit assignment difficult, because the best estimated actions during tree planning does not necessarily match with the chosen actions. Suppose that TreeQN estimated ""up-right-right"" as the best future action sequence the during 3-step tree planning, while the agent actually ended up with choosing ""up-left-left"" (this is possible because the agent re-plans at every step and follows epsilon-greedy policy). Following n-step Q-learning procedure, we end up with setting target Q-value based on on-policy action sequence ""up-left-left"", while back-propagating through ""up-right-right"" action sequence in the TreeQN\'s plan. This causes a wrong temporal credit assignment, because TreeQN can potentially increase/decrease value estimates in the wrong direction due to the mismatch between the planned actions and chosen actions. So, it is unclear why the proposed algorithm is technically correct or better than VPN\'s approach (i.e., back-propagating through the chosen actions in the search tree).\n \n# Quality\n- Comparison to VPN on Atari is not convincing because TreeQN-1 is actually (almost) equivalent to VPN-1, but the results show that TreeQN-1 performs much better than VPN on many games. Since the authors took the numbers from [Oh et al.] rather than replicating VPN, it is possible that the gap comes from implementation details (e.g., hyperparameter). \n\n# Clarity\n- The paper is overall easy to follow and the description of the proposed method is clear.']","[60, -50, -50]","[80, 20, 20]","[""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'clear and well-motivated' and stating that 'this is good work and worth communicating as is.' However, they also raise some concerns about the experimental results and baselines, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively pointing out areas for improvement. They use phrases like 'I thought' and 'I believe' to soften their criticisms, and their overall tone is professional and courteous."", ""The sentiment score is -50 because while the reviewer starts by saying it was an 'interesting read', the bulk of the review expresses skepticism and criticism about the paper's claims and methodology. The reviewer questions the model's ability to actually perform as described and suggests that the baseline comparisons may be unfair. This indicates a generally negative sentiment, though not extremely harsh.\n\nThe politeness score is 20 because the reviewer maintains a professional and academic tone throughout. They use phrases like 'I feel that' and 'I think' to soften their criticisms, and they acknowledge that their comment is 'verbose'. The reviewer also starts with a positive note about the paper being 'interesting'. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the technical soundness and novelty of the paper, stating that the proposed method has 'a technical issue' and that the core ideas are 'almost same as those of VPN'. However, they do acknowledge some positive aspects like the paper being 'easy to follow' and the application to actor-critic setting being 'novel', preventing the score from being more negative. The politeness score is 20 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'Thank you for the rebuttal' and 'I like the overall idea'. They also provide constructive feedback and detailed explanations for their concerns. However, the criticism is direct and unambiguous, which keeps the politeness score from being higher.""]"
"['SUMMARY\nThe paper proposes to apply GrOWL regularization to the tensors of parameters between each pair of layers. The groups are composed of all coefficients associated to inputs coming from the same neuron in the previous layer. The proposed algorithm is a simple proximal gradient algorithm using the proximal operator of the GrOWL norm. Given that the GrOWL norm tend to empirically reinforce a natural clustering of the vectors of coefficients which occurs in some layers, the paper proposes to cluster the corresponding parameter vectors, to replace them with their centroid and to retrain with the constrain that some vectors are now equal. Experiments show that some sparsity is obtained by the model and that together with the clustering and high compression of the model is obtained which maintaining or improving over a good level of generalization accuracy. In comparison, plain group Lasso yields compressed versions that are too sparse, and tend to degrade performance. The method is also competitive with weight decay with much better compression.\n\nREVIEW\nGiven the well known issue that the Lasso tends to select arbitrarily and in a non stable way variables\nthat are correlated *but* given that the well known elastic-net (and conceptually simpler than GrOWL) was proposed to address that issue already more than 10 years ago, it would seem relevant to compare the proposed method with the group elastic-net.\n\nThe proposed algorithm is a simple proximal gradient algorithm, but since the objective is non-convex it would be relevant to provide references for convergence guarantees of the algorithm.\n\nHow should the step size eta be chosen? I don\'t see that this is discussed in the paper.\n\nIn the clustering algorithm how is the threshold value chosen?\n\nIs it chosen by cross validation?\n\nIs the performance better with clustering or without?\n\nIs the same threshold chosen for GrOWL and the Lasso?\n\nIt would be useful to know which values of p, Lambda_1 and Lambda_2 are selected in the experiments?\n\nFor Figures 5,7,8,9 given that the matrices do not have particular structures that need to be visualized but that the important thing to compare is the distribution of correlation between pairs, these figures that are hard to read and compare would be advantageously replaced by histograms of the values of the correlations between pairs (of different variables). Indeed, right now one must rely on comparison of shades of colors in the thin lines that display correlation and it is really difficult to appreciate how much of correlation of what level are present in each Figure. Histograms would extract exactly the relevant information...\n\nA brief description of affinity propagation, if only in the appendix, would be relevant.\nWhy this method as opposed to more classical agglomerative clustering?\n\nA brief reminder of what the principle of weight decay is would also be relevant for the paper to more self contained.\n\nThe proposed experiments are compelling, except for the fact that it would be nice to have a comparison with the group elastic-net. \n\nI liked figure 6.d and would vote for inclusion in the main paper.\n\n\nTYPOS etc \n\n3rd last line of sec. 3.2 can fail at selecting -> fail to select\n\nIn eq. (5) theta^t should be theta^{(t)}\n\nIn section 4.1 you that the network has a single fully connected layer of hidden units -> what you mean is that the network has a single hidden layer, which is furthermore fully connected.\n\nYou cite several times Sergey (2015) in section 4.2. It seems you have exchanged first name and last name plus the corresponding reference is quite strange.\n\nAppendix B line 5 "", while."" -> incomplete sentence.\n\n', 'This paper proposes to apply a group ordered weighted l1 (GrOWL) regularization term to promote sparsity and parameter sharing in training deep neural networks and hence compress the model to a light version.\n\nThe GrOWL regularizer (Oswal et al., 2016) penalizes the sorted l2 norms of the rows in a parameter matrix with corresponding ordered regularization strength and the effect is similar to the OSCAR (Bondell & Reich, 2008) method that encouraging similar (rows of) features to be grouped together.\n\nA two-step method is used that the regularizer is applied to a deep neural network at the initial training phase, and after obtaining the parameters, a clustering method is then adopted to force similar parameters to share the same values and then the compacted neural network is retrained. The major concern is that a much more complicated neural network (with regularizations) has already been trained and stored to obtain the uncompressed parameters. What’s the benefit of the compression and retraining the trained neural network?\n\nIn the experiments, the performance of the uncompressed neural network should be evaluated to see how much accuracy loss the regularized methods have. Moreover, since the compressed network loses accuracy, will a smaller neural network can actually achieve similar performance compared to the compressed network from a larger network? If so, one can directly train a smaller network (with similar number of parameters as the compressed network) instead of using a complex two-step method, because the two-step method has to train the original larger network at the first step.\n', 'The authors propose to use the group ordered weighted l1 regulariser (GrOWL) combined with clustering of correlated features to select and tie parameters, leading to a sparser representation with a reduced parameter space. They apply the proposed method two well-known benchmark datasets under a fully connected and a convolutional neural network, and demonstrate that in the former case a slight improvement in accuracy can be achieved, while in the latter, the method performs similar to the group-lasso, but at a reduced computational cost for classifying new images due to increased compression of the network.\n\nThe paper is well written and motivated, and the idea seems fairly original, although the regularisation approach itself is not new. Like many new approaches in this field, it is hard to judge from this paper and its two applications alone whether the approach will lead to significant benefits in general, but it certainly seems promising.\n\nPositive points:\n- Demonstrated improved compression with similar performance to the standard weighted decay method.\n- Introduced a regularization technique that had not been previously used in this field, and that improves on the group lasso in terms of compression, without apparent loss of accuracy.\n- Applied an efficient proximal gradient algorithm to train the model.\n\nNegative points:\n- The method is sold as inducing a clustering, but actually, the clustering is a separate step, and the choice of clustering algorithm might well have an influence on the results. It would have been good to see more discussion or exploration of this. I would not claim that, for example, the fused lasso is a clustering algorithm for regression coefficients, even though it demonstrably sets some coefficients to the same value, so it seems wrong to imply the same for GrOWL.\n- In the example applications, it is not clear how the accuracy was obtained (held-out test set? cross-validation?), and it would have been good to get an estimate for the variance of this quantity, to see if the differences between methods are actually meaningful (I suspect not). Also, why is the first example reporting accuracy, but the second example reports error?\n- There is a slight contradiction in the abstract, in that the method is introduced as guarding against overfitting, but then the last line states that there is ""slight or even no loss on generalization performance"". Surely, if we reduce overfitting, then by definition there would have to be an improvement in generalization performance, so should we draw the conclusion that the method has not actually been demonstrated to reduce overfitting?\n\nMinor point:\n- p.5, in the definition of prox_Q(epsilon), the subscript for the argmin should be nu, not theta.\n\n']","[50, -20, 50]","[70, 50, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's compelling experiments and interesting findings, while also providing constructive criticism and suggestions for improvement. The review is not overwhelmingly positive, but it does recognize the value of the work. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions, and includes positive comments. The reviewer also uses phrases like 'it would be relevant' or 'it would be useful' rather than making demands. The polite tone is maintained even when pointing out typos and errors. However, it's not extremely formal or overly deferential, hence not scoring higher."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the proposed method, they express major concerns about its practicality and effectiveness. The reviewer questions the benefit of the compression and retraining process, and suggests that simpler alternatives might achieve similar results. This indicates a skeptical view of the paper's contribution.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns and suggestions, avoiding harsh criticism. The reviewer offers constructive feedback by suggesting additional experiments and comparisons that could strengthen the paper. The use of phrases like 'The major concern is...' and 'Moreover...' indicate a polite way of introducing critiques and suggestions."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as well-written, motivated, and original, with promising results. However, they also point out several negative aspects and areas for improvement, balancing the positive remarks. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing its weaknesses. They phrase criticisms constructively, using phrases like 'it would have been good to see' rather than direct accusations. The reviewer also provides specific positive and negative points, maintaining a professional and courteous tone throughout the review.""]"
"['The authors present a model for text classification. The parameters of the model are an embedding for each word and a local context unit. The local context unit can be seen as a filter for a convolutional layer, but which filter is used at location i depends on the word at location i (i.e. there is one filter per vocabulary word). After the filter is applied to the embeddings and after max pooling, the word-context region embeddings are summed and fed into a neural network for the classification task. The embeddings, the context units and the neural net parameters are trained jointly on a supervised text classification task. The authors also offer an alternative model, which changes the role of the embedding an the context unit, and results in context-word region embeddings. Here the embedding of word i is combined with the elements of the context units of words in the context. To get the region embeddings both model (word-context and context-word) combine attributes of the words (embeddings) with how their attributes should be emphasized or deemphasized based on nearby words (local context units and max pooling) while taking into account the relative position of the words in the context (columns of the context units). \n\nThe method beats existing methods for text classification including d-LSTMs , BoWs, and ngram TFIDFs on held out classification accuracy. the choice of baselines is convincing. What is the performance of the proposed method if the embeddings are initialized to pretrained word embeddings and a) trained for the classification task together with randomly initialized context units b) frozen to pretrained embeddings and only the context units are trained for the classification task?\n\nThe introduction was fine. Until page 3 the authors refer to the context units a couple of times without giving some simple explanation of what it could be. A simple explanation in the introduction would improve the writing.\nThe related work section only makes sense *after* there is at least a minimal explanation of what the local context units do. A simple explanation of the method, for example in the introduction, would then make the connections to CNNs more clear. Also, in the related work, the authors could include more citations (e.g. the d-LSTM and the CNN based methods from Table 2) and explain the qualitative differences between their method and existing ones.\n\nThe authors should consider adding equation numbers. The equation on the bottom of page 3 is fine, but the expressions in 3.2 and 3.3 are weird. A more concise explanation of the context-word region embeddings and the word-context region embeddings would be to instead give the equation for r_{i,c}.  \n\nThe included baselines are extensive and the proposed method outperforms existing methods on most datasets. In section 4.5 the authors analyze region and embedding size, which are good analyses to include in the paper. Figure 2 and 3 could be next to each other to save space. \nI found the idea of multi region sizes interesting, but no description is given on how exactly they are combined. Since it works so well, maybe it could be promoted into the method section? Also, for each data set, which region size worked best?\n\nQualitative analysis: It would have been nice to see some analysis of whether the learned embeddings capture semantic similarities, both at the embedding level and at the region level. It would also be interesting to investigate the columns of the context units, with different columns somehow capturing the importance of relative position. Are there some words for which all columns are similar meaning that their position is less relevant in how they affect nearby words? And then for other words with variation along the columns of the context units, do their context units modulate the embedding more when they are closer or further away? \n\nPros:\n + simple model\n + strong quantitative results\n\nCons:\n - notation (i.e. precise definition of r_{i,c})\n - qualitative analysis could be extended\n - writing could be improved  ', '() Summary\nIn this paper, the authors introduced a new simple model for text classification, which obtains state of the art results on several benchmark. The main contribution of the paper is to propose a new technique to learn vector representation of fixed-size text regions of up to a few words. In addition to learning a vector for each word of the vocabulary, the authors propose to also learn a ""context unit"" of size d x K, where d is the embedding size and K the region size. Thus, the model also have a vector representation for pair of word and position in the region. Then, given a region of K words, its vector representation is obtained by taking the elementwise product of the ""context unit"" of the middle word and the matrix obtained by concatenating the K vectors of words appearing in the region (the authors also propose a second model where the role of word vectors and ""context"" vectors are exchanged). The max-pooling operation is then used to obtain a vector representation of size d. Then a linear classifier is applied on top of the sum of the region embeddings. The authors then compare their approach to previous work on the 8 datasets introduced by Zhang et al. (2015). They obtain state of the art results on most of the datasets. They also perform some analysis of their models, such as the influence of the region size, embedding size, or replacing the ""context units"" vector by a scalar. The authors also provide some visualisation of the parameters of their model.\n\n() Discussion\nOverall, I think that the proposed method is sound and well justified. The empirical evaluations, analysis and comparisons to existing methods are well executed. I liked the fact that the proposed model is very simple, yet very competitive compared to the state-of-the-art. I suspect that the model is also computationally efficient: can the authors report training time for different datasets? I think that it would make the paper stronger. One of the main limitations of the model, as stated by the authors, is its number of parameters. Could the authors also report these?\n\nWhile the paper is fairly easy to read (because the method is simple and Figure 1 helps understanding the model), I think that copy editing is needed. Indeed, the papers contains many typos (I have listed a few), as well as ungrammatical sentences. I also think that a discussion of the ""attention is all you need"" paper by Vaswani et al. is needed, as both articles seem strongly related.\n\nAs a minor comment, I advise the authors to use a different letter for ""word embeddings"" and the ""projected word embeddings"" (equation at the bottom of page 3). It would also make the paper more clear.\n\n() Pros / Cons:\n+ simple yet powerful method for text classification\n+ strong experimental results\n+ ablation study / analysis of influence of parameters\n- writing of the paper\n- missing discussion to the ""attention is all you need paper"", which seems highly relevant\n\n() Typos:\nPage 1\n""a support vectors machineS"" -> ""a support vector machine""\n""performs good"" -> ""performs well""\n""the n-grams was widely"" -> ""n-grams were widely""\n""to apply large region size"" -> ""to apply to large region size""\n""are trained separately"" -> ""do not share parameters""\n\nPage 2\n""convolutional neural networks(CNN)"" -> ""convolutional neural networks (CNN)""\n""related works"" -> ""related work""\n""effective in Wang and Manning"" -> ""effective by Wang and Manning""\n""applied on text classification"" -> ""applied to text classification""\n""shard(word independent)"" -> ""shard (word independent)""\n\nPage 3\n""can be treat"" -> ""can be treated""\n""fixed length continues subsequence"" -> ""fixed length contiguous subsequence""\n""w_i stands for the"" -> ""w_i standing for the""\n""which both the unit"" -> ""where both the unit""\n""in vocabulary"" -> ""in the vocabulary""\n\netc...', 'The authors propose a mechanism for learning task-specific region embeddings for use in text classification. Specifically, this comprises a standard word embedding an accompanying local context embedding. \n\nThe key idea here is the introduction of a (h x c x v) tensor K, where h is the embedding dim (same as the word embedding size), c is a fixed window size around a target word, and v is the vocabulary size. Each word in v is then associated with an (h x c) matrix that is meant to encode how it affects nearby words, in particular this may be viewed as parameterizing a projection to be applied to surrounding word embeddings. The authors propose two specific variants of this approach, which combine the K matrix and constituent word embeddings (in a given region) in different ways. Region embeddings are then composed (summed) and fed through a standard model. \n\nStrong points\n---\n+ The proposed approach is simple and largely intuitive: essentially the context matrix allows word-specific contextualization. Further, the work is clearly presented.\n\n+ At the very least the model does seem comparable in performance to various recent methods (as per Table 2), however as noted below the gains are marginal and I have some questions on the setup.\n\n+ The authors perform ablation experiments, which are always nice to see. \n\nWeak points\n---\n- I have a critical question for clarification in the experiments. The authors write \'Optimal hyperparameters are tuned with 10% of the training set on Yelp Review Full dataset, and identical hyperparameters are applied to all datasets\' -- is this true for *all* models, or only the proposed approach? \n\n- The gains here appear to be consistent, but they seem marginal. The biggest gain achieved over all datasets is apparently .7, and most of the time the model very narrowly performs better (.2-.4 range). Moreoever, it is not clear if these results are averaged over multiple runs of SGD or not (variation due to initialization and stochastic estimation can account for up to 1 point in variance -- see ""A sensitivity analysis of (and practitioners guide to) CNNs..."" Zhang and Wallace, 2015.)\n\n- The related work section seems light. For instance, there is no discussion at all of LSTMs and their application to text classificatio (e.g., Tang et al., EMNLP 2015) -- although it is noted that the authors do compare against D-LSTM,  or char-level CNNs for the same (see Zhang et al., NIPs 2015). Other relevant work not discussed includes Iyyer et al. (ACL 2015). In their respective ways, these papers address some of the same issues the authors consider here. \n\n- The two approaches to inducing the final region embedding (word-context and then context-word in sections 3.2 and 3.3, respectively) feel a bit ad-hoc. I would have appreciated more intuition behind these approaches. \n\nSmall comments\n---\nThere is a typo in Figure 4 -- ""Howerver"" should be ""However""\n\n*** Update after author response ***\n\nThanks to the authors for their responses. My score is unchanged.']","[50, 60, -20]","[60, 70, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the strong quantitative results and the simplicity of the model as pros, while also providing constructive criticism and suggestions for improvement. The review is not overwhelmingly positive, but it does recognize the value of the work. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offers suggestions rather than demands, and balances criticism with praise. The reviewer points out areas for improvement in a constructive manner, using phrases like 'The authors should consider' and 'It would have been nice to see', which maintain a polite tone. The review also acknowledges the strengths of the paper, further contributing to its politeness."", ""The sentiment score is 60 (moderately positive) because the reviewer states the method is 'sound and well justified' and praises the simplicity and competitiveness of the model. They also note strong experimental results and a good ablation study. However, they point out some limitations and areas for improvement, preventing a higher score. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions politely (e.g., 'I think that it would make the paper stronger'). They balance positive feedback with areas for improvement. The reviewer does point out numerous typos, which slightly reduces the politeness score, but does so in a matter-of-fact way without being harsh."", ""The sentiment score is slightly negative (-20) because while the reviewer notes some strong points, there are more weak points highlighted, including critical questions about the experimental setup, marginal gains in performance, and a light related work section. The tone is not overwhelmingly negative, but the criticisms outweigh the positives. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges strengths, and frames criticisms constructively as 'weak points' rather than harsh criticisms. The reviewer also thanks the authors for their response at the end, showing courtesy. However, it's not extremely polite, maintaining a professional rather than overly deferential tone.""]"
"['This paper provides an overview of the Deep Voice 3 text-to-speech system. It describes the system in a fair amount of detail and discusses some trade-offs w.r.t. audio quality and computational constraints. Some experimental validation of certain architectural choices is also provided.\n\nMy main concern with this work is that it reads more like a tech report: it describes the workings and design choices behind one particular system in great detail, but often these choices are simply stated as fact and not really motivated, or compared to alternatives. This makes it difficult to tell which of these aspects are crucial to get good performance, and which are just arbitrary choices that happen to work okay.\n\nAs this system was clearly developed with actual deployment in mind (and not purely as an academic pursuit), all of these choices must have been well-deliberated. It is unfortunate that the paper doesn\'t demonstrate this. I think this makes the work less interesting overall to an ICLR audience. That said, it is perhaps useful to get some insight into what types of models are actually used in practice.\n\nAn exception to this is the comparison of ""converters"", model components that convert the model\'s internal representation of speech into waveforms. This comparison is particularly interesting because some of the results are remarkable, i.e. Griffin-Lim spectrogram inversion and the WORLD vocoder achieving very similar MOS scores in some cases (Table 2). I wish there would be more of that kind of thing in the paper. The comparison of attention mechanisms is also useful.\n\nI\'m on the fence as I think it is nice to get some insight into a practical pipeline which benefits from many current trends in deep learning research (autoregressive models, monotonic attention, ...), but I also feel that the paper is a bit meager when it comes to motivating all the architectural aspects. I think the paper is well written so I\'ve tentatively recommended acceptance.\n\n\nOther comments:\n\n- The separation of the ""decoder"" and ""converter"" stage is not entirely clear to me. It seems that the decoder is trained to predict spectrograms autoregressively, but its final layer is then discarded and its hidden representation is then used as input to the converter stage instead? The motivation for doing this is unclear to me, surely it would be better to train everything end-to-end, including the converter? This seems like an unnecessary detour, what\'s the reasoning behind this?\n\n- At the bottom of page 2 it is said that ""the whole model is trained end-to-end, excluding the vocoder"", which I think is an unfortunate turn of phrase. It\'s either end-to-end, or it isn\'t.\n\n- In Section 3.3, the point of mixing of h_k and h_e is unclear to me. Why is this done?\n\n- The gated linear unit in Figure 2a shows that speaker embedding information is only injected in the linear part. Has this been experimentally validated to work better than simpler mechanisms such as adding conditioning-dependent biases/gains?\n\n- When the decoder is trained to do autoregressive prediction of spectrograms, is it autoregressive only in time, or also in frequency? I\'m guessing it\'s the former, but this means there is an implicit independence assumption (the intensities in different frequency bins are conditionally independent, given all past timesteps). Has this been taken into consideration? Maybe it doesn\'t matter because the decoder is never used directly anyway, and this is only a ""feature learning"" stage of sorts?\n\n- Why use the L1 loss on spectrograms?\n\n- The recent work on Parallel WaveNet may allow for speeding up WaveNet when used as a vocoder, this could be worth looking into seeing as inference speed is used as an argument to choose different vocoder strategies (with poorer audio quality as a result).\n\n- The title heavily emphasizes that this model can do multi-speaker TTS with many (2000) speakers, but that seems to be only a minor aspect that is only discussed briefly in the paper. And it is also something that preceding systems were already capable of (although maybe it hasn\'t been tested with a dataset of this size before). It might make sense to rethink the title to emphasize some of the more relevant and novel aspects of this work.\n\n\n----\n\nRevision: the authors have adequately addressed quite a few instances where I feel motivations / explanations were lacking, so I\'m happy to increase my rating from 6 to 7. I think the proposed title change would also be a good idea.', 'The paper presents a speech synthesis system based on convolution neural networks. The proposed approach is an end-to-end characters to spectrogram system, trained on a very large dataset. The paper also introduces a attention model and can be used with various waveform synthesis methods. The proposed model is shown to match the state -of-the-art approaches performance in speech naturalness. \n\nThe paper is clearly written and easy to follow. The relation to previous works is detailed and clear.\n\nThe contributions of the paper are significants and an important step towards practical and efficient neural TTS system. The ability to train on a large corpus of speaker 10 times faster than current models is impressive and important for deployment, as is the cost-effective inference and the monotonic attention model. \nThe experiments on naturalness (Table 2) are convincing and show the viability of the approach. However, the experiments on multi-speaker synthesis (Table 3) are not very strong. The proposed model seems to need to use Wavenet as a vocoder to possibly outperform Deep Voice 2, which will slow down the inference time, one of the strong aspect of the proposed model.\n\nOther comments:\n\n* In Section 2, it is mentioned that RNN-based approaches can leads to attention errors, can the authors elaborate more on that aspect ? It seems important as the proposed approach alleviates these issues, but it is not clear from the paper what these errors are and why they happen.\n\n* In Table 3 there seems to be missing models compared to Table 2, like Tacotron with Wavenet, the authors should explain why in the text.  \n\n* The footnote 2 on page 3 looks important enough to be part of the main text.\n', 'This paper discusses a text-to-speech system which is based on a convolutional attentive seq2seq architecture.  It covers experiments on a few datasets, testing the model\'s ability to handle increasing numbers of speakers.\n\nBy and large, this is a ""system"" paper - it mostly describes the successful application of many different existing ideas to an important problem (with some exceptions, e.g. the novel method of enforcing monotonic alignments during inference).  In this type of paper, I typically am most interested in hearing about *why* a particular design choice was made, what alternatives were tried, and how different ideas worked.  This paper is lacking in this regard - I frequently was left looking for more insight into the particular system that was designed.  Beyond that, I think more detailed description of the system would be necessary in order to reimplement it suitably (another important potential takeaway for a ""system"" paper).  Separately, I the thousands-of-speakers results are just not that impressive - a MOS of 2 is not really useable in the real-world.  For that reason, I think it\'s a bit disingenuous to sell this system as ""2000-Speaker Neural Text-to-Speech"".\n\nFor the above reasons, I\'m giving the paper a ""marginally above"" rating.  If the authors provide improved insight, discussion of system specifics, and experiments, I\'d be open to raising my review.  Below, I give some specific questions and suggestions that could be addressed in future drafts.\n\n- It might be worth giving a sentence or two defining the TTS problem - the paper is written assuming background knowledge about the problem setting, including different possible input sources, what a vocoder is, etc.  The ICLR community at large may not have this domain-specific knowledge.\n- Why ""softsign"" and not tanh?  Seems like an unusual choice.\n- What do the ""c"" and ""2c"" in Figure 2a denote?\n- Why scale (h_k + h_e) by \\sqrt{0.5} when computing the attention value vectors?\n- ""An L1 loss is computed using the output spectrograms"" I assume you mean the predicted and target spectrograms are compared via an L1 loss.  Why L1?\n- In Vaswani et al., it was shown that a learned positional encoding worked about as well as the sinusoidal position encodings despite being potentially more flexible/less ""hand-designed"" for machine translation.  Did you also try this for TTS?  Any insight?\n- Some questions about monotonic attention: Did you use the training-time ""soft"" monotonic attention algorithm from Raffel et al. during training and inference, or did you use the ""hard"" monotonic attention at inference time?  IIUC the ""soft"" algorithm doesn\'t actually force strict monotonicity.  You wrote ""monotonic attention results in the model frequently mumbling words"", can you provide evidence/examples of this?  Why do you think this happens?  The monotonic attention approach seems more principled than post-hoc limiting softmax attention to be monotonic, why do you think it didn\'t work as well?\n- I can\'t find an actual reference to what you mean by a ""wavenet vocoder"".  The original wavenet paper describes an autoregressive model for waveform generation.  In order to use it as a vocoder, you\'d have to do conditioning in some way.  How?  What was the structure of the wavenet you used?   Why?  These details appear to be missing.  All you write is the sentence (which seems to end without a period) ""In the WaveNet vocoder, we use mel-scale spectrograms from the decoder to condition a Wavenet, which was trained separated"".\n- Can you provide examples of the mispronunciations etc. which were measured for Table 1?  Was the evaluation of each attention mechanism done blindly?\n- The 2.07 MOS figure produced for tacotron seems extremely low, and seems to indicate that something went wrong or that insufficient care was taken to report this baseline.  How did you adapt tacotron (which as I understand is a single-speaker model) to the multi-speaker setting?\n- Table 3 begs the question of whether Deep Voice 3 can outperform Deep Voice 2 when using a wavenet vocoder on VCTK (or improve upon the poor 2.09 MOS score reported).  Why wasn\'t this experiment run?\n- The paragraph and appendix about deploying at scale is interesting and impressive, but seems a bit out of place - it probably makes more sense to include this information in a separate ""systems"" paper.']","[20, 80, -20]","[60, 70, 50]","[""The sentiment score is slightly positive (20) because while the reviewer has some concerns, they ultimately recommend acceptance and see value in the paper. They note it provides useful insights into a practical system and is well-written, though they feel it lacks sufficient motivation for architectural choices. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. They use phrases like 'I think', 'I wish', and 'It might make sense to' when offering feedback, maintaining a collegial tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe the contributions as 'significant' and 'important', and praise the paper's clarity and performance. The few criticisms are constructive and relatively minor. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering praise where due and framing criticisms as suggestions or questions rather than direct criticisms. The tone is professional and constructive, with phrases like 'The paper is clearly written' and 'The experiments... are convincing'. The reviewer also provides specific, helpful feedback for improvement, which is a polite way to offer criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer sees some merit in the paper ('marginally above' rating), they express significant criticisms and disappointment. They mention lacking insights, insufficient system details, and unimpressive results for large-scale experiments. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, uses phrases like 'I think' to soften criticisms, and expresses openness to improving their rating if concerns are addressed. They also provide detailed, constructive feedback for improvement, which is a polite way to critique. The language is not overly formal or deferential, hence not scoring higher on politeness.""]"
"['The paper presents an approach to efficiently implement planar and group convolutions over hexagonal lattices to leverage better accuracy of these operations due to reduced anisotropy. They show that convolutional neural networks thus built lead to better performance - reduced inductive bias - for the same parameter budget.\n\nG-CNNs were introduced by Cohen and Welling in ICML, 2016. They proposed DNN layers that implemented equivariance to symmetry groups. They showed that group equivariant networks can lead to more effective weight sharing and hence more efficient networks as evinced by better performance on CIFAR10 & CIFAR10+ for the same parameter budget. This paper shows G-equivariance implemented on hexagonal lattices can lead to even more efficient networks. \n\nThe benefits of using hexagonal lattices over rectangular lattices is well known in the signal processing as well as in computer vision. For example, see   \n\nGolay M. Hexagonal parallel pattern transformation. IEEE Transactions on Computers 1969. 18(8): p. 733-740.\n\nStaunton R. The design of hexagonal sampling structures for image digitization and their use with local operators. Image and Vision Computing 1989. 7(3): p. 162-166. \n\nL. Middleton and J. Sivaswamy, Hexagonal Image Processing, Springer Verlag, London, 2005\n\nThe originality of the paper lies in the practical and efficient implementation of G-Conv layers. Group-equivariant DNNs could lead to more robust, efficient and (arguably) better performing neural networks.\n\nPros\n\n- A good paper that systematically pushes the state of the art towards the design of invariant, efficient and better performing  DNNs with G-equivariant representations.\n\n- It leverages upon the existing theory in a variety of areas - signal & image processing and machine learning, to design better DNNs.\n\n - Experimental evaluation suffices for a proof of concept validation of the presented ideas.   \n\n \nCons\n\n- The authors should relate the paper better to existing works in the signal processing and vision literature.\n\n- The results are on simple benchmarks like CIFAR-10. It is likely but not immediately apparent if the benefits scale to more complex problems.\n\n- Clarity could be improved in a few places\n\n: Since * is used for a standard convolution operator, it might be useful to use *_g as a G-convolution operator.\n\n: Strictly speaking, for translation equivariance, the shift should be cyclic etc.\n\n: Spelling mistakes - authors should run a spellchecker.\n', 'The paper proposes G-HexaConv, a framework extending planar and group convolutions for hexagonal lattices. Original Group-CNNs (G-CNNs) implemented on squared lattices were shown to be invariant to translations and rotations by multiples of 90 degrees. With the hexagonal lattices defined in this paper, this invariance can be extended to rotations by multiples of 60 degrees. This shows small improvements in the CIFAR-10 performances, but larger margins in an Aerial Image Dataset. \n\nDefining hexagonal pixel configurations in convolutional networks requires both resampling input images (under squared lattices) and reformulate image indexing. All these steps are very well explained in the paper, combining mathematical rigor and clarifications. \n\nAll this makes me believe the paper is worth being accepted at ICLR conference. \n\nSome issues that would require further discussion/clarification: \n- G-HexaConv critical points are memory and computation complexity. Authors claim to have an efficient implementation but the paper lacks a proper quantitative evaluation.  Memory complexity and computational time comparison between classic CNNs and G-HexaConv should be provided.\n- I encourage the authors to open the source  code for reproducibility and comparison with future transformational equivariant representations \n-Also, in Fig.1, I would recommend to clarify that image ‘f’ corresponds to a 2D view of a hexagonal image pixelation.  My first impression was a rectangular pixelation seen from a perspective view.\n', '\nThe authors took my comments nicely into account in their revision, and their answers are convincing. I increase my rating from 5 to 7. The authors could also integrate their discussion about their results on CIFAR in the paper, I think it would help readers understand better the advantage of the contribution.\n\n----\n\nThis paper is based on the theory of group equivariant CNNs (G-CNNs), proposed by Cohen and Welling ICML\'16.\n\nRegular convolutions are translation-equivariant, meaning that if an image is translated, its convolution by any filter is also translated. They are however not rotation-invariant for example.  G-CNN introduces G-convolutions, which are equivariant to a given transformation group G.\n\nThis paper proposes an efficient implementation of G-convolutions for 6-fold rotations (rotations of multiple of 60 degrees), using a hexagonal lattice. The approach is evaluated on CIFAR-10 and AID, a dataset of aerial scene classification. The approach outperforms G-convolutions implemented on a squared lattice, which allows only 4-fold rotations on AID by a short margin. On CIFAR-10, the difference does not seem significative (according to Tables 1 and 2).\nI guess this can be explained by the fact that rotation equivariance makes sense for aerial images, where the scene is mostly fronto-parallel, but less for CIFAR (especially in the upper layers), which exhibits 3D objects.\n\nI like the general approach of explicitly putting desired equivariance in the convolutional networks. Using a hexagonal lattice is elegant, even if it is not new in computer vision (as written in the paper). However, as the transformation group is limited to rotations, this is interesting in practice mostly for fronto-parallel scenes, as the experiences seem to show. It is not clear how the method can be extended to other groups than 2D rotations.\n\nMoreover, I feel like the paper sometimes tries to mask the fact that the proposed method is limited to rotations. It is admittedly clearly stated in the abstract and introduction, but much less in the rest of the paper.\n\nThe second paragraph of Section 5.1 is difficult to keep in a paper. It says that ""From a qualitative inspection of these hexagonal interpolations we conclude that no information is lost during the sampling procedure.""  ""No information is lost"" is a strong statement from a qualitative inspection, especially of a hexagonal image.  This statement should probably be removed. One way to evaluate the information lost could be to iterate interpolation between hexagonal and squared lattices to see if the image starts degrading at some point.\n\n\n\n']","[70, 80, 50]","[80, 70, 60]","[""The sentiment score is 70 (positive) because the reviewer describes the paper as 'good' and highlights several pros, including that it 'systematically pushes the state of the art' and 'leverages upon existing theory'. The cons mentioned are relatively minor and constructive. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offers balanced feedback with both pros and cons, and phrases criticisms as suggestions (e.g., 'The authors should relate the paper better...'). The reviewer also acknowledges the paper's contributions and potential impact, which adds to the polite tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a strong positive opinion, stating that the paper is 'worth being accepted at ICLR conference' and praising its clarity and mathematical rigor. The few issues mentioned are presented as suggestions for improvement rather than major criticisms. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering constructive feedback and encouragement. They use phrases like 'I encourage the authors' and 'I would recommend,' which are polite ways of suggesting improvements. The reviewer also acknowledges the paper's strengths before offering critiques, which is a courteous approach to peer review."", ""The sentiment score is 50 (moderately positive) because the reviewer starts by acknowledging that the authors addressed their previous comments well and increased their rating. They also offer constructive suggestions for improvement. However, they do point out some limitations of the method, which prevents the score from being higher. The politeness score is 60 (fairly polite) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms constructively. They use phrases like 'I like the general approach' and offer suggestions rather than demands. The tone is professional and objective, avoiding harsh or dismissive language.""]"
"['The paper takes an interesting approach to solve the existing problems of GAN training, using Coulomb potential for addressing the learning problem. It is also well written with a clear presentation of the motivation of the problems it is trying to address, the background and proves the optimality of the suggested solution. My understanding and validity of the proof is still an educated guess. I have been through section A.2 , but I\'m unfamiliar with the earlier literature on the similar topics so I would not be able to comment on it. \n\nOverall, I think this is a good paper that provides a novel way of looking at and solving problems in GANs. I just had a couple of points in the paper that I would like some clarification on : \n\n* In section 2.2.1 : The notion of the generated a_i not disappearing is something I did not follow. What does it mean for a generated sample to ""not disappear"" ? and this directly extends to the continuity equation in (2). \n\n* In section 1 : in the explanation of the 3rd problem that GANs exhibit i.e.  the generator not being able to generalize the distribution of the input samples, I was hoping if you could give a bit more motivation as to why this happens. I don\'t think this needs to be included in the paper, but would like to have it for a personal clarification. ', 'The authors draw from electrical field dynamics and propose to formulate the GAN learning problem in a way such that generated samples are attracted to training set samples, but repel each other. Optimizing this formulation using gradient descent can be proven to yield only one optimal global Nash equilibrium, which the authors claim allows Coulomb GANs to overcome the ""mode collapse"" issue. Experimental results are reported on image and language modeling tasks, and show that the model can produce very diverse samples, although some samples can consist of somewhat nonsensical interpolations.\n\nThis is a good, well-written paper. It is technically rigorous and empirically convincing. Overall, it presents an interesting approach to overcome the mode collapse problem with GANs. \n\nThe image samples presented -- although of high variability -- are not of very high quality, though, and I somewhat disagree with the claim that ""Coulomb GAN was able to efficiently learn the whole distribution"" (Sec 3.1). At best, it seems to me that the new objective does in fact force the generator to concentrate efforts on learning over the full support of the data distribution, but the lower quality samples and sometimes somewhat bad interpolations seem to suggest to me that it is *not* yet doing so very ""efficiently"". \n\nNonetheless, I think this is an important step forward in improving GANs, and should be accepted for publication.\n\nNote: I did not check all the proofs in the appendix.', '\nIn this paper, the authors interpret the training of GAN by potential field and inspired from which to provide new training procedure for GAN. They claim that under the condition that global optima are achieved for discriminator and generator in each iteration, the Coulomb GAN converges to the global solution. \n\nI think there are several points need to be addressed. \n\n1, I agree that the ""model collapsing"" is due to converging to a local Nash Equilibrium. However, there are more reasons besides the drawback of the loss function, which is emphasized in the paper. Leave the stochastic gradient descent optimization algorithm apart (since most of the neural networks are trained in this way), the parametrization and the richness of discriminator family play a vital role in the model collapsing issue. In fact, even with KL-divergence in which log operation is involved, if one can select reasonable parametrization, e.g., directly handling in function space, the saddle point optimization is convex-concave, which means under the same assumption made in the paper, there is only one global Nash Equilibrium. On the other hand, the richness of the discriminator also important in the training of GAN. I did not get the point about the drawback of III. If indeed as the paper considered in the ideal case, the discriminator is rich enough, III cannot happen. \n\nThe model collapsing is not just because loss function in training GAN. It is caused by the twist of these three issues listed above. Modifying the loss can avoid partially model collapsing, however, it is not appropriate to claim that the proposed algorithm is \'provable\'. The assumption in this paper is too restricted, and the discussion is unfair to the existing variants of GAN, e.g., GMMN or Wasserstein GAN, which under some assumptions, there is also only one global Nash Equilibrium. \n\n2, In the training procedure, the discriminator family is important as we discussed. The paper claims that the reason to introduce the extra discriminator is reducing variance. However, such parametrization will introduce bias too. The bias and variance tradeoff should be explicitly discussed here. Ideally, it should contain all the functions formed with Plummer kernel, but not too large (otherwise, it will increase the sample complexity.). Which function family used in the paper is not clear. \n\n\n3, As the authors already realized, the GMMN is one closely related model. It will be more convincing to add the comparison with GMMN. \n\nIn sum, this paper provides an interesting perspective modeling GAN from the potential field, however, there are several issues need to be addressed. I expect to see the reply of the authors regarding the mentioned issues. ']","[80, 70, -30]","[90, 80, 50]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'interesting', 'well written', and 'a good paper that provides a novel way of looking at and solving problems in GANs'. The overall tone is very positive, with only minor requests for clarification. The politeness score is 90 (very polite) due to the respectful and constructive language used throughout. The reviewer acknowledges their own limitations in understanding certain aspects, uses phrases like 'I would like some clarification' and 'I was hoping if you could', which are polite ways of requesting more information. The review maintains a professional and courteous tone throughout, offering praise and constructive feedback in a balanced manner."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'good, well-written,' 'technically rigorous,' and 'empirically convincing.' They also state it's an 'important step forward' and recommend it for publication. However, it's not 100 because they express some disagreement with certain claims and note that the image samples are not of very high quality. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and offers constructive criticism. They phrase their disagreements politely (e.g., 'I somewhat disagree') and balance negative points with positive ones. The tone is professional and courteous throughout, without any rude or harsh language."", ""The sentiment score is -30 because while the reviewer acknowledges some interesting aspects of the paper, they express several significant concerns and criticisms. The review begins with a neutral tone but quickly moves to pointing out multiple issues that need to be addressed, indicating a generally negative sentiment. However, it's not entirely negative as the reviewer sees some value in the work.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think', 'I agree', and 'I expect to see' which are polite ways of expressing opinions and expectations. The reviewer also acknowledges positive aspects of the paper before critiquing it. However, the score is not higher because the review is quite direct in its criticisms, without using many softening phrases or overly polite language.""]"
"['This paper proposes a network with the standard soft-attention mechanism for classification tasks, where the global feature is used to attend on multiple feature maps of local features at different intermediate layers of CNN. The attended features at different feature maps are then used to predict the final classes by either concatenating features or ensembling results from individual attended features. The paper shows that the proposed model outperforms the baseline models in classification and weakly supervised segmentation.\n\nStrength:\n- It is interesting idea to use the global feature as a query in the attention mechanism while classification tasks do not naturally involve a query unlike other tasks such as visual question answering and image captioning.\n\n- The proposed model shows superior performances over GAP in multiple tasks.\n\nWeakness:\n- There are a lot of missing references. There have been a bunch of works using the soft-attention mechanism in many different applications including visual question answering [A-C], attribute prediction [D], image captioning [E,F] and image segmentation [G]. Only two previous works using the soft-attention (Bahdanau et al., 2014; Xu et al., 2015) are mentioned in Introduction but they are not discussed while other types of attention models (Mnih et al., 2014; Jaderberg et al., 2015) are discussed more.\n\n- Section 2 lacks discussions about related work but is more dedicated to emphasizing the contribution of the paper.\n\n- The global feature is used as the query vector for the attention calculation. Thus, if the global feature contains information for a wrong class, the attention quality should be poor too. Justification on this issue can improve the paper.\n\n- [H] reports the performance on the fine-grained bird classification using different type of attention mechanism. Comparison and justification with this method can improve the paper. The performance in [H] is almost 10 % point higher accuracy than the proposed model.\n\n- In the segmentation experiments, the models are trained on extremely small images, which is unnatural in segmentation scenarios. Experiments on realistic settings should be included. Moreover, [G] introduces a method of using an attention model for segmentation, while the paper does not contain any discussion about it.\n\n\nOverall, I am concerned that the proposed model is not well discussed with important previous works. I believe that the comparisons and discussions with these works can greatly improve the paper.\n\nI also have some questions about the experiments:\n- Is there any reasoning why we have to simplify the concatenation into an addition in Section 3.2? They are not equivalent.\n\n- When generating the fooling images of VGG-att, is the attention module involved, or do you use the same fooling images for both VGG and VGG-att?\n\nMinor comments:\n- Fig. 1 -> Fig. 2 in Section 3.1. If not, Fig. 2 is never referred.\n\nReferences\n[A] Huijuan Xu and Kate Saenko. Ask, attend and answer: Exploring question-guided spatial attention for visual question answering. In ECCV, 2016.\n[B] Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, and Alex Smola. Stacked attention networks for image question answering. In CVPR, 2016.\n[C] Jacob Andreas, Marcus Rohrbach, Trevor Darrell, and Dan Klein. Deep compositional question answering with neural module networks. In CVPR, 2016.\n[D] Paul Hongsuck Seo, Zhe Lin, Scott Cohen, Xiaohui Shen, and Bohyung Han. Hierarchical attention networks. arXiv preprint arXiv:1606.02393, 2016.\n[E] Quanzeng You, Hailin Jin, Zhaowen Wang, Chen Fang, and Jiebo Luo. Image captioning with semantic attention. In CVPR, 2016.\n[F] Jonghwan Mun, Minsu Cho, and Bohyung Han. Text-Guided Attention Model for Image Captioning. AAAI, 2017.\n[G] Seunghoon Hong, Junhyuk Oh, Honglak Lee and Bohyung Han, Learning Transferrable Knowledge for Semantic Segmentation with Deep Convolutional Neural Network, In CVPR, 2016.\n[H] Max Jaderberg, Karen Simonyan, Andrew Zisserman, Koray Kavukcuoglu, Spatial Transformer Networks, NIPS, 2015\n\n\n', 'This paper proposes an end-to-end trainable attention module, which takes as input the 2D feature vector map and outputs a 2D matrix of scores for each map. The goal is to make the learned attention maps highlight the regions of interest while suppressing background clutter. Experiments conducted on image classification and weakly supervised segmentation show the effectiveness of the proposed method.\n\nStrength of this paper:\n1) Most previous work are all implemented as post-hoc additions to fully trained networks while this work is end-to-end trainable. Not only the newly added weights for attention will be learned, so are the original weights in the network.\n2) The generalization ability shown in Table 3 is very good, outperforming other existing network by a large margin.\n3) Visualizations shown in the paper are convincing. \n\nSome weakness:\n1) Some of the notations are unclear in this paper, vector should be bold, hard to differentiate vector and scalar.\n2) In equation (2), l_i and g should have different dimensionality, how does addition work? Same as equation (3)\n3) The choice of layers to add attention modules is unclear to me. The authors just pick three layers from VGG to add attention, why picking those 3 layers? Is it better to add attention to lower layers or higher layers? Why is it the case that having more layers with attention achieves worse performance?\n', 'This paper proposed an end-to-end trainable hierarchical attention mechanism for CNN. The proposed method computes 2d spatial attention map at multiple layers in CNN, where each attention map is obtained by computing compatibility scores between the intermediate features and the global feature. The proposed method demonstrated noticeable performance improvement on various discriminative tasks over existing approaches. \n\nOverall, the idea presented in the paper is simple yet solid, and showed good empirical performance. The followings are several concerns and suggestions.  \n\n1. The authors claimed that this is the first end-to-end trainable hierarchical attention model, but there is a previous work that also addressed the similar task:\nSeo et al, Progressive Attention Networks for Visual Attribute Prediction, in Arxiv preprint:1606.02393, 2016 \n\n2. The proposed attention mechanism seems to be fairly domain (or task ) specific, and may not be beneficial for strong generalization (generalization over unseen category). Since this could be a potential disadvantage, some discussions or empirical study on cross-category generalization seems to be interesting.\n\n3. The proposed attention mechanism is mainly demonstrated for single-class classification task, but it would be interesting to see if it can also help the multi-class classification (e.g. image classification on MS-COCO or PASCAL VOC datasets)\n\n4. The localization performance of the proposed attention mechanism is evaluated by weakly-supervised semantic segmentation tasks. In that perspective, it would be interesting to see the comparisons against other attention mechanisms (e.g. Zhou et al 2016) in terms of localization performance.\n']","[-20, 60, 60]","[60, 50, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they express significant concerns about missing references, lack of discussion on related work, and potential issues with the proposed model. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'It is interesting idea' and 'I believe that the comparisons and discussions with these works can greatly improve the paper', which maintain a polite and encouraging tone despite the criticisms."", ""The sentiment score is 60 (positive) because the reviewer begins by highlighting the strengths of the paper, noting its end-to-end trainability, good generalization ability, and convincing visualizations. While weaknesses are mentioned, they are presented as 'Some weakness' rather than major flaws, suggesting an overall positive view. The politeness score is 50 (somewhat polite) because the reviewer uses neutral, professional language throughout. They present both strengths and weaknesses objectively without harsh criticism. The use of phrases like 'The choice of layers... is unclear to me' shows a polite way of expressing confusion rather than direct criticism. However, the review doesn't go out of its way to be exceptionally polite, maintaining a professional, neutral tone overall."", ""The sentiment score is 60 (positive) because the reviewer starts by highlighting the paper's strengths, noting that the idea is 'simple yet solid' and showed 'good empirical performance'. The overall tone is constructive and appreciative of the work. The politeness score is 70 (polite) due to the reviewer's use of respectful language throughout. They offer suggestions and concerns in a constructive manner, using phrases like 'it would be interesting to see' and 'some discussions or empirical study... seems to be interesting'. The reviewer maintains a professional and courteous tone while providing specific, actionable feedback, which is indicative of a polite and considerate review.""]"
"['This paper tackles the problem of finding an optimal architecture for deep neural nets . They propose to solve it by training an auxiliary HyperNet to generate the main model. The authors propose the so called ""SMASH"" algorithm that ranks the neural net architectures based on their validation error. The authors adopt a memory-bank view of the network configurations for exploring a varied collection of network configurations. It is not clear whether this is a new contribution of this paper or whether the authors merely adopt this idea.  A clearer note on this would be welcome. My key concern is with the results as described in 4.1.; the correlation structure breaks down completely for ""low-budget"" SMASH in Figure 5(a) as compared Figure (4). Doesn\'t this then entail an investigation of what is the optimal size of the hyper network? Also I couldn\'t quite follow the importance of figure 5(b) - is it referenced in the text? The authors also note that SMASH is saves a lot of computation time; some time-comparison numbers would probably be more helpful to drive home the point especially when other methods out-perform SMASH. \nOne final point, for the uninitiated reader- sections 3.1 and 3.2 could probably be written somewhat more lucidly for better access.', 'This paper is about a new experimental technique for exploring different neural architectures. It is well-written in general, numerical experiments demonstrate the framework and its capabilities as well as its limitations. \n\nA disadvantage of the approach may be that the search for architectures is random. It would be interesting to develop a framework where the search for the architecture is done with a framework where the updates to the architecture is done using a data-driven approach. Nevertheless, there are so many different neural architectures in the literature and this paper is a step towards comparing various architectures efficiently. \n\nMinor comments:\n\n1) Page 7,  "".. moreso than domain specificity."" \n\nIt may be better to spell the word ""moreso"" as ""more so"", please see: https://en.wiktionary.org/wiki/moreso', 'Summary of paper - This paper presents SMASH (or the one-Shot Model Architecture Search through Hypernetworks) which has two training phases (one to quickly train a random sample of network architectures and one to train the best architecture from the first stage). The paper presents a number of interesting experiments and discussions about those experiments, but offers more exciting ideas about training neural nets than experimental successes. \n\nReview - The paper is very well written with clear examples and an excellent contextualization of the work among current work in the field. The introduction and related work are excellently written providing both context for the paper and a preview of the rest of the paper. The clear writing make the paper easy to read, which also makes clear the various weaknesses and pitfalls of SMASH. \n\nThe SMASH framework appears to provide more interesting contributions to the theory of training Neural Nets than the application of said training. While in some experiments SMASH offers excellent results, in others the results are lackluster (which the authors admit, offering possible explanations). \n\nIt is a shame that the authors chose to push their section on future work to the appendices. The glimmers of future research directions (such as the end of the last paragraph in section 4.2) were some of the most intellectually exciting parts of the paper. This choice may be a reflection of preferring to highlight the experimental results over possible contributions to theory of neural nets.  \n\n\nPros - \n* Strong related work section that contextualizes this paper among current work\n* Very interesting idea to more efficiently find and train best architectures \n* Excellent and thought provoking discussions of middle steps and mediocre results on some experiments (i.e. last paragraph of section 4.1, and last paragraph of section 4.2)\n* Publicly available code \n\nCons - \n* Some very strong experimental results contrasted with some mediocre results\n* The balance of the paper seems off, using more text on experiments than the contributions to theory. \n* (Minor) - The citation style is inconsistent in places. \n\n=-=-=-= Response to the authors\n\nI thank the authors for their thoughtful responses and for the new draft of their paper. The new draft laid plain the contribution of the memory bank which I had missed in the first version. As expected, the addition of the future work section added further intellectual excitement to the paper. \n\nThe expansion of section 4.1 addressed and resolved my concerns about the balance of the paper by effortless intertwining theory and application. I do have one question from this section -  In table 1, the authors report p-values but fail to include them in their interpretation; what is purpose of including these p-values, especially noting that only one falls under the typical threshold for significance?\n']","[-20, 60, 70]","[50, 80, 90]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, they express several concerns and criticisms. The reviewer points out unclear aspects, questions the importance of certain figures, and suggests areas for improvement. However, the tone is not entirely negative, as they also recognize the paper's efforts and provide constructive feedback. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, framing criticisms as suggestions or questions rather than direct attacks. They use phrases like 'It is not clear,' 'A clearer note would be welcome,' and 'could probably be written somewhat more lucidly,' which maintain a polite tone while conveying their concerns. The reviewer also acknowledges the potential benefits of the proposed method, showing a balanced approach."", ""The sentiment score is 60 (positive) because the reviewer starts by praising the paper as 'well-written' and acknowledges its demonstration of capabilities and limitations. They also mention it's 'a step towards comparing various architectures efficiently'. However, they do point out a disadvantage, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and even the disadvantage is framed as 'may be' rather than a definitive flaw. The minor comment is presented politely as a suggestion. The overall tone is professional and courteous."", ""The sentiment score is 70 (positive) because the reviewer expresses appreciation for the paper's clear writing, strong related work section, and interesting ideas. They note some weaknesses but overall seem impressed, especially with the revised draft. The politeness score is 90 (very polite) due to the respectful tone throughout, use of phrases like 'I thank the authors', and constructive framing of feedback. The reviewer balances praise with gentle criticism and asks questions rather than making demands.""]"
"['This paper proposes a novel regularization scheme for Wasserstein GAN based on a relaxation of the constraints on the Lipschitz constant of 1. The proposed regularization penalize the critic function only when its gradient has a norm larger than one using some kind of squared hinge loss. The reasons for this choice are discussed and linked to theoretical properties of OT. Numerical experiments suggests that the proposed regularization leads to better posed optimization problem and even a slight advantage in terms of inception score on the CIFAR-10 dataset.\n\nThe paper is interesting and well written, the proposed regularization makes sens since it is basically a relaxation of the constraints and the numerical experiments also suggest it\'s a good idea. Still as discussed below the justification do not address a lots of interesting developments and implications of the method and should better discuss the relation with regularized optimal transport.\n\nDiscussion:\n\n+ The paper spends a lot of time justifying the proposed method by discussing the limits of the ""Improved training of Wasserstein GAN"" from Gulrajani et al. (2017). The two limits (sampling from marginals instead of optimal coupling and differentiability of the critic) are interesting and indeed suggest that one can do better but the examples and observations are well known in OT and do not require proof in appendix. The reviewer believes that this space could be better spend discussing the theoretical implication of the proposed regularization (see next).\n\n+ The proposed approach is a relaxation of the constraints on the dual variable for the OT problem. As a matter of fact we can clearly recognize a squared hinge loss is the proposed loss. This approach (relaxing a strong constraint) has been used for years when learning support vector machines and ranking and a small discussion or at least reference to those venerable methods would position the paper on a bigger picture.\n\n+ The paper is rather vague on the reason to go from Eq. (6) to Eq. (7). (gradient approximation between samples to gradient on samples). Does it lead to better stability to choose one or the other? \n How is it implemented in practice? recent NN toolbox can easily compute the exact gradient and use it for the penalization but this is not clearly discussed even in appendix. Numerical experiments comparing the two implementation or at least a discussion is necessary.\n\n+ The proposed approach has a very strong relations to the recently proposed regularized OT (see [1] for a long list of regularizations) and more precisely to the euclidean regularization. I understand that GANS (and Wasserstein GAN) is a relatively young community and that references list can be short but their is a large number of papers discussing regularized optimal transport and how the resulting problems are easier to solve. A discussion of the links is necessary and will clearly bring more theoretical ground to the method. Note that a square euclidean regularization leads to a regularization term in the dual of the form max(0,f(x)+f(y)-|x-y|)^2 that is very similar to the proposed regularization. In other words the authors propose to do regularized OT (possibly with a new regularization term) and should discuss that.\n\n+ The numerical experiments are encouraging but a bit short. The 2D example seem to work very well and the convergence curves are far better with the proposed regularization. But the real data CIFAR experiments are much less detailed with only a final inception score (very similar to the competing method) and no images even in appendix. The authors should also define (maybe in appendix) the conditional and unconditional inception scores and why they are important (and why only some of them are computed in Table 1).\n\n+ This is more of a suggestion. The comparison of the dual critic to the true Wasserstein distance is very interesting. It would be nice to see the behavior for different values of lambda.\n\n\n[1] Dessein, A., Papadakis, N., & Rouas, J. L. (2016). Regularized Optimal Transport and the Rot Mover\'s Distance. arXiv preprint arXiv:1610.06447.\n\n\nReview update after reply:\n\nThe authors have responded to most of my concerns and I think the paper is much stronger now and discuss the relation with regularized OT. I change the rating to Accept. \n', 'The article deals with regularization/penalization in the fitting of GANs, when based on a L_1 Wasserstein metric. Basics on mass transportation are briefly recalled in section 2, while section 3 formulate the GANs approach in the Wasserstein context. Taking into account the Lipschitz constraint and (non-) differentiability of optimal critic functions f are discussed in section 4 and Section 5 proposes a way to penalize candidate functions f that do not satisfy the Lipschitz condition using a tuning parameter lambda, ruling a trade-off between marginal fitting and gradient control. The approach is illustrated by numerical experiments. Such results are hardly convincing, since the tuning of the parameter lambda plays a crucial role in the performance of the method. More importantly, The heuristic proposed in the paper is interesting and promising in some respects but there is a real lack of theoretical guarantees motivating the penalty form chosen, such a theoretical development could allow to understand what may rule the choice of an ideal value for lambda in particular.', 'This paper is proposing a new formulation for regularization of Wasserstein Generative Adversarial models (WGAN). The original min/max formulation of the WGAN aim at minimizing over all measures, the maximal dispersion of expectation for 1-Lipschitz with the one provided by the empirical measure. This problem is often regularized by adding a ""gradient penalty"", \\ie a  penalty of the form ""\\lambda E_{z~\\tau}}(||\\grad f (z)||-1)^2"" where \\tau is the distribution of (tx+(1-x)y) where x is drawn according to the empirical measure and y is drawn according to the target measure. In this work the authors consider substituting the previous penalty by ""\\lambda E_{z~\\tau}}(max( ||\\grad f (z)||-1,0)^2"".\n\nOverall the paper is too vague on the mathematical part, and the experiments provided are not particularly convincing in assessing the benefit of the new penalty.\nThe authors have tried to use mathematical formulations to motivate their choice, but they lack rigorous definitions/developments to make their point convincing.\nThey should also present early their model and their mathematical motivation: in what sense is their new penalty ""preferable""?\n\n\n\nPresentation issues:\n- in printed black and white versions most figures are meaningless.\n- red and green should be avoided on the same plots, as colorblind people will not perceived any difference...\n- format for images should be vectorial (eps or pdf), not jpg or png...\n- legend/sizes are not readable (especially in printed version).\n\nReferences issues:\n- harmonize citations: if you add first name for some authors add them for all of them: why writing Harold W. Kuhn and C. Vilani for instance?\n- cramer->Cramer\n- wasserstein->Wasserstein (2x)\n- gans-> GANs\n- Salimans et al. is provided twice, and the second is wrong anyway.\n\n\n\nSpecific comments:\n\npage 1:\n- ""different more recent contributions"" -> more recent contributions\n- avoid double brackets ""))""\n\npage 2:\n- Please rewrite the first sentence below Definition 1 in a meaningful way.\n- Section 3: if \\mu is an empirical distribution, it is customary to write it \\mu_n or \\hat \\mu_n (in a way that emphasizes the number of observations available).\n- d is used as a discriminator and then as a distance. This is confusing...\n\npage 3:\n- ""f that plays the role of an appraiser (or critic)..."": this paragraph could be extended and possibly elements of the appendix could be added here.\n- Section 4: the way clipping is presented is totally unclear and vague. This should be improved.\n- Eq (5): as written the distribution of \\tilde{x}=tx+(1-t)y is meaningless: What is x and y in this context? please can you describe the distributions in a more precise way?\n- Proof of Proposition 5 (cf. page 13): this is a sketch of proof to me. Please state precise results using mathematical formulation.\n- ""Observation 1"": real and generated data points are not introduced at this stage... data points are not even introduced neither!\n\npage 5:\n- the examples are hard to understand. It would be helpful to add the value of \\pi^* and f^* for both models, and explaining in details how they fit the authors model.\n- in Figure 2 the left example is useless to me. It could be removed to focus more extensively on the continuous case (right example).\n- the the -> the\n\npage 6:\n- deterministic coupling could be discussed/motivated when introduced. Observation 3 states some property of non non-deterministic coupling but the concept itself seems somehow to appear out of the blue.\n\npage 10:\n- Figure 6: this example should be more carefully described in terms of distribution, f*, etc.\n\npage 14:\n- Proposition 1: the proof could be shorten by simply stating in the proposition that f and g are distribution...\n\npage 15:\n- ""we wish to compute""-> we aim at showing?\n- f_1 is not defined sot the paragraph ""the latter equation..."" showing that almost surely x \\leq y is unclear to me, so is the result then.\nIt could be also interesting to (geometrically) interpret the coupling proposed. The would help understanding the proof, and possibly reuse the same idea in different context.\n\npage 16:\n- proof of Proposition 2 : key idea here is using the positive and negative part of (f-g). This could simplify the proof.']","[50, -20, -50]","[80, 50, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'interesting and well written' and notes that the proposed method 'makes sense' and shows promise in experiments. However, they also point out several areas for improvement and additional discussion needed, balancing the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as opportunities for improvement rather than flaws. They use phrases like 'The paper is interesting,' 'The reviewer believes,' and 'This is more of a suggestion,' which maintain a courteous tone. The reviewer also acknowledges the authors' response positively in the update, further demonstrating politeness."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the article's interesting and promising aspects, they express significant concerns about the lack of theoretical guarantees and the crucial role of parameter tuning. The phrase 'Such results are hardly convincing' indicates a notable criticism. However, the review isn't entirely negative, as it recognizes the potential of the approach.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to describe the paper's content and express their concerns without harsh or personal criticism. Phrases like 'interesting and promising in some respects' show a degree of politeness by acknowledging positive aspects. The reviewer also offers constructive suggestions for improvement, which is a polite way to provide feedback."", ""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper. The reviewer states that the paper is 'too vague on the mathematical part' and that the experiments are 'not particularly convincing'. However, it's not entirely negative as the reviewer provides constructive feedback for improvement. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer specific suggestions for improvement. Phrases like 'Please rewrite', 'It would be helpful to', and 'This should be improved' indicate a polite tone while still maintaining a critical stance. The reviewer also uses neutral language like 'Overall' and 'The authors have tried' which softens the criticism.""]"
"['The paper introduces XWORLD, a 2D virtual environment with which an agent can constantly interact via navigation commands and question answering tasks. Agents working in this setting therefore, learn the language of the ""teacher"" and efficiently ground words to their respective concepts in the environment. The work also propose a neat model motivated by the environment and outperform various baselines. \n\nFurther, the paper evaluates the language acquisition aspect via two zero-shot learning tasks -- ZS1) A setting consisting of previously seen concepts in unseen configurations ZS2) Contains new words that did not appear in the training phase. \n\nThe robustness to navigation commands in Section 4.5 is very forced and incorrect -- randomly inserting unseen words at crucial points might lead to totally different original navigation commands right? As the paper says, a difference of one word can lead to completely different goals and so, the noise robustness experiments seem to test for the biases learned by the agent in some sense (which is not desirable). Is there any justification for why this method of injecting noise was chosen ? Is it possible to use hard negatives as noisy / trick commands and evaluate against them for robustness ?  \n\nOverall, I think the paper proposes an interesting environment and task that is of interest to the community in general. The modes and its evaluation are relevant and intuitions can be made use for evaluating other similar tasks (in 3D, say). ', 'This paper introduces a new task that combines elements of instruction following\nand visual question answering: agents must accomplish particular tasks in an\ninteractive environment while providing one-word answers to questions about\nfeatures of the environment. To solve this task, the paper also presents a new\nmodel architecture that effectively computes a low-rank attention over both\npositions and feature indices in the input image. It uses this attention as a\ncommon bottleneck for downstream predictors that select actions and answers to\nquestions. The paper\'s main claim is that this model architecture enables strong\ngeneralization: it allows the model to succeed at the instruction following task\neven when given words it has only seen in QA contexts, and vice-versa.\nExperiments show that on the navigation task, the proposed approach outperforms\na variety of baselines under both a normal data condition and one requiring\nstrong generalization.\n\nOn the whole, I think this paper does paper does a good job of motivating the\nproposed modeling decisions. The approach is likely to be useful for other\nresearchers working on related problems. I have a few questions about the\nevaluation, but most of my comments are about presentation.\n\nEVALUATION\n\nIs it really the case that no results are presented for the QA task, or am I\nmisreading one of the charts here? Given that this paper spends a lot of time\nmotivating the QA task as part of the training scenario, I was surprised not to\nsee it evaluated. \n\nAdditionally, when I first read the paper I thought that the ZS1 experiments\nfeatured no QA training at all. However, your response to one of the sibling\ncomments suggests that it\'s still a ""mixed"" training setting where the sampled\nQA and NAV instances happen to cover the full space. This should be made more\nclear in the paper. It would be nice to know (1) how the various models perform\nat QA in both ZS1 and ZS2 settings, and (2) what the actual performance is NAV\nalone (even if the results are terrible).\n\nMODEL PRESENTATION\n\nI found section 2 difficult to read: in particular, the overloading of \\Phi\nwith different subscripts for different output types, the general fact that\ne.g. x and \\Phi_x are used interchangeably, and the large number of different\nvariables. My best suggestions are to drop the \\Phis altogether and consider\nusing text subscripts rather than coming up with a new name for every variable,\nbut there are probably other things that will also help.\n\nOTHER NOTES\n\n- This paper needs serious proofreading---just in the first few pages the errors\n  I noticed were ""in 2D environment"" (in the title!), ""such capability"", ""this\n  characteristics"", ""such language generalization problem"", ""the agent need to"",\n  ""some early pioneering system"", ""commands is"". I gave up on keeping track at\n  this point but there are many more.\n\n- \\phi in Fig 2 should be explained by the caption.\n\n- Here\'s another good paper to cite for the end of 2.2.1:\n  https://arxiv.org/pdf/1707.00683.pdf.\n\n- The mechanism in 2.2.4 feels a little like\n  http://aclweb.org/anthology/D17-1015\n\n- I don\'t think the content on pages 12, 13, and 14 adds much to the\n  paper---consider moving these to an appendix.', ""[Overview]\nIn this paper, the authors proposed a unified model for combining vision, language, and action. It is aimed at controlling an agent in a virtual environment to move to a specified location in a 2D map, and answer user's questions as well. To address this problem, the authors proposed an explicit grounding way to connect the words in a sentence and spatial regions in the images. Specifically, By this way, the model could exploit the outputs of concept detection module to perform the actions and question answering as well jointly. In the experiments, the authors compared with several previous attention methods to show the effectiveness of the proposed concept detection module and demonstrated its superiority on several configurations, including in-domain and out-of-domain cases.\n\n[Strengths]\n\n1. I think this paper proposed interesting tasks to combine the vision, language, and actions. As we know, in a realistic environment, all three components are necessary to complete a complex tasks which need the interactions with the physical environments. The authors should release the dataset to prompt the research in this area.\n\n2. The authors proposed a simple method to ground the language on visual input. Specifically, the authors grounded each word in a sentence to all locations of the visual map, and then perform a simple concept detection upon it. Then, the model used this intermediate representation to guide the navigation of agent in the 2D map and visual question answering as well.\n\n3. From the experiments, it is shown that the proposed model outperforms several baseline methods in both normal tasks and out-of-domain ones. According to the visualizations, the interpreter could generate meaningful attention map given a textual query.\n\n[Weakness]\n\n1. The definition of explicit grounding is a bit misleading. Though the grounding or attention is performed for each word at each location of the visual map. It is a still kind of soft-attention, except that is performed for each word in a sentence. As far as I know, this has been done in several previous works, such as: (a). Hierarchical question-image co-attention for visual question answering (https://scholar.google.com/scholar?oi=bibs&cluster=15146345852176060026&btnI=1&hl=en). Lu et al. NIPS 2016. (b). Graph-Structured Representations for Visual Question Answering. Teney et al. arXiv 2016. At most recent, we have seen some more explicit way for visual grounding like: (c). Bottom-up and top-down attention for image captioning and VQA (https://arxiv.org/abs/1707.07998). Anderson et al. arXiv 2017.\n\n2. Since the model is aimed at grounding the language on the vision based on interactions, it is worth to show how well the final model could ground the text words to each of the visual objects. Say, show the affinity matrix between the words and the objects to indicate the correlations.\n\n[Summary]\n\nI think this is a good paper which integrates vision, language, and actions in a virtual environment. I would foresee more and more works will be devoted to this area, considering its close connection to our daily life. To address this problem, the authors proposed a simple model to ground words on visual signals, which prove to outperform previous methods, such as CA, SAN, etc. According to the visualization, the model could attend the right region of the image for finishing a navigation and QA task. As I said, the authors should rephrase the definition of explicit grounding, to make it clearly distinguished with the previous work I listed above. Also, the authors should definitely show the grounding attention results of words and visual signal jointly, i.e., showing them together in one figure instead of separately in Figure 9 and Figure 10.\n""]","[60, 50, 60]","[50, 60, 80]","[""The sentiment score is 60 (positive) because the reviewer expresses overall positive views about the paper, praising the 'interesting environment and task' and noting its relevance to the community. They also commend the model and its performance. However, it's not extremely positive due to some criticisms, particularly about the robustness experiments. The politeness score is 50 (slightly polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms as questions or suggestions rather than direct attacks. The tone is professional and constructive, though not overly formal or deferential."", ""The sentiment score is 50 (slightly positive) because the reviewer states that the paper 'does a good job of motivating the proposed modeling decisions' and that the approach is 'likely to be useful for other researchers'. However, they also have some questions and concerns about the evaluation and presentation. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, such as 'I think' and 'I have a few questions', and offers constructive criticism. They also provide specific suggestions for improvement. The reviewer does point out numerous errors, but does so in a matter-of-fact way without being harsh. The overall tone is professional and aimed at improving the paper rather than criticizing the authors."", ""The sentiment score is 60 (positive) because the reviewer highlights several strengths of the paper, calling it 'interesting' and 'good', and praising its performance and potential impact. However, they also point out some weaknesses, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and balances positive and negative feedback. They use phrases like 'I think' to soften critiques and provide specific suggestions for improvement rather than harsh criticism. The tone is professional and courteous throughout.""]"
"['This paper presents a study on the Information Bottleneck (IB) theory of deep learning, providing results in contrasts to the main theory claims. According to the authors, the IB theory suggests that the network generalization is mainly due to a ‘compression phase’ in the information plane occurring after a ‘fitting phase’ and that the ‘compression phase’ is due to the stochastic gradient decent (SDG). Instead, the results provided by this paper show that: the generalization can happen even without compression; that SDG is not the primary factor in compression; and that the compression does not necessarily occur after the ‘fitting phase’. Overall, the paper tackles the IB theory claims with consistent methodology, thus providing substantial arguments against the IB theory. \n\nThe main concern is that the paper is built to argue against another theoretical work, raising a substantial discussion with the authors of the IB theory. This paper should carefully address all the raised arguments in the main text. \n\nThere are, moreover, some open questions that are not fully clear in this contribution:\n1)\tTo evaluate the mutual information in the ReLu networks (sec. 2) the authors discretize the output activity in their range. Should the non-linearity of ReLu be considered as a form of compression? Do you check the ratio of ReLus that are not active during training or the ratio of inputs that fall into the negative domain of each ReLu? \n2)\tSince one of today common topics is the training of deep neural networks with lower representational precision, could the quantization error due to the low precision be considered as a form of noise inserted in the network layers that influences the generalization performance in deep neural networks? \n3)\tWhat are the main conclusions or impact of the present study in the theory of neural networks? Is it the authors aim to just demonstrate that the IB theory is not correct? Perhaps, the paper should empathize the obtained results not just in contrast to the other theory, but proactively in agreement with a new proposal. \n\nFinally, a small issue comes from the Figures that need some improvement. In most of the cases (Figure 3 C, D; Figure 4 A, B, C; Figure 5 C, D; Figure 6) the axes font is too small to be read. Figure 3C is also very unclear.\n', ""A thorough investigation on Info Bottleneck and deep learning, nice to read with interesting experiments and references. Even though not all of the approach is uncontroversial (as the discussion shows), the paper contributes to much needed theory of deep learning rather than just another architecture. \nEstimating the mutual information could have been handled in a more sophisticated way (eg using a Kraskov estimator rather than simple binning), and given that no noise is usually added the discussion about noise and generalisation doesn't seem to make too much sense to me. \n\nIt would have been good to see a discussion whether another measurement that would be useful for single-sided saturating nonlinearities that do show a compression (eg information from a combination of layers), from learnt representations that are different to representations learnt using double-sided nonlinearities. \n\nRegarding the finite representation of units (as in the discussion) it might be helpful to also consider an implementation of a network with arbitrary precision arithmetic as an additional experiment. \n\nOverall I think it would be nice to see the paper accepted at the very least to continue the discussion. "", 'The authors address the issue of whether the information bottleneck (IB) theory can provide insight into the working of deep networks. They show, using some counter-examples, that the previous understanding of IB theory and its application to deep networks is limited.\n\nPROS: The paper is very well written and makes its points very clearly. To the extent of my knowledge, the content is original. Since it clearly elucidates the limitations of IB theory in its ability to analyse deep networks, I think it is a significant \ncontribution worthy of acceptance. The experiments are also well designed and executed. \n\nCONS: On the downside, the limitations exposed are done so empirically, but the underlying theoretical causes are not explored (although this could be potentially because this is hard to do). Also, the paper exposes the limitations of another paper published in a non-peer reviewed location (arXiv) which potentially limits its applicability and significance.\n\nSome detailed comments:\n\nIn section 2, the influence of binning on how the mutual information is calculated should be made clear. Since the comparison is between a bounded non-linearity and an unbounded one, it is not self-evident how the binning in the latter case should be done. A justification for the choice made for binning the relu case would be helpful.\n\nIn the same section, it is claimed that the dependence of the mutual information I(X; T) on the magnitude of the weights of the network explains why a tanh non-linearity shows the compression effect (non-monotonicity vs I(X; T)) in the information plane dynamics. But the claim that large weights are required for doing anything useful is unsubstantiated and would benefit from having citations to papaers that discuss this issue. If networks with small weights are able to learn most datasets, the arguments given in this section wouldn\'t be applicable in its entirety.\n\nAdditionally, figures that show the phase plane dynamics for other non-linearities e.g. relu+ or sigmoid, should be added, at \nleast in the supplementary section. This is important to complete the overall picture of how the compression effect depends on having specific activation functions.\n\nIn section 3, a sentence or two should be added to describe what a ""teacher-student setup"" is, and how it is relevant/interesting.\n\nAlso in section 3, the cases where batch gradient descent is used and where stochastic gradient descent is used should be \npointed out much more clearly. It is mentioned in the first line of page 7 that batch gradient descent is used, but it is not \nclear why SGD couldn\'t have been used to keep things consistent. This applies to figure 4 too. \n\nIn section 4, it seems inconsistent that the comparison of SGD vs BGD is done using linear network as opposed to a relu network which is what\'s used in Section 2. At the least, a comparison using relu should be added to the supplementary section.\n\nMinor comments \nThe different figure styles using in Fig 4A and C that have the same quantities plotted makes it confusing.\nAn additional minor comment on the figures: some of the labels are hard to read on the manuscript.']","[50, 60, 70]","[70, 70, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's consistent methodology and substantial arguments against the IB theory, but also raises concerns and open questions. The overall tone is balanced, recognizing both strengths and areas for improvement. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, phrases criticisms constructively, and offers suggestions for improvement rather than harsh judgments. The reviewer uses phrases like 'should carefully address' and 'need some improvement' instead of more direct or negative language. The open questions are posed in a curious, non-confrontational manner, further contributing to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer starts with praise, calling it a 'thorough investigation' that's 'nice to read' with 'interesting experiments'. They also appreciate the paper's contribution to theory. However, they do mention some criticisms and suggestions for improvement, which prevents a higher score. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. Phrases like 'it would have been good to see' and 'it might be helpful to' indicate a polite tone. The reviewer also ends on a positive note, recommending acceptance 'at the very least to continue the discussion', which is encouraging and polite."", ""The sentiment score is 70 (positive) because the reviewer starts by highlighting the paper's strengths, calling it 'very well written' and a 'significant contribution worthy of acceptance'. They mention the paper's clarity, originality, and well-designed experiments. While some limitations are noted, they are presented as minor issues rather than major flaws. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, balances praise with constructive criticism, and phrases suggestions in a non-confrontational manner (e.g., 'would benefit from', 'should be added'). The reviewer also acknowledges the potential difficulty in addressing some issues ('this could be potentially because this is hard to do'). The tone remains professional and courteous throughout, even when pointing out areas for improvement.""]"
"['(Summary)\nThis paper is about learning discriminative features for the target domain in unsupervised DA problem. The key idea is to use a critic which randomly drops the activations in the logit and maximizes the sensitivity between two versions of discriminators.\n\n(Pros)\nThe approach proposed in section 3.2 uses dropout logits and the sensitivity criterion between two softmax probability distributions which seems novel.\n\n(Cons)\n1. By biggest concern is that the authors avoid comparing the method to the most recent state of the art approaches in unsupervised domain adaptation and yet claims ""achieved state of the art results on three datasets."" in sec5. 1) Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks, Bousmalis et al. CVPR17, and 2) Learning Transferrable Representations for Unsupervised Domain Adaptation, Sener et al. NIPS16. Does the proposed method outperform these state of the art methods using the same network architectures?\n2. I suggest the authors to rewrite the method section 3.2 so that the loss function depends on the optimization variables G,C. In the current draft, it\'s not immediately clear how the loss functions depend on the optimization variables. For example, in eqns 2,3,5, the minimization is over G,C but G,C do not appear anywhere in the equation. \n3. For the digits experiments, appendix B states ""we used exactly the same network architecture"". Well, which architecture was it?\n4. It\'s not clear what exactly the ""ENT"" baseline is. The text says ""(ENT) obtained by modifying (Springenberg 2015)"". I\'d encourage the authors to make this part more explicit and self-explanatory.\n\n(Assessment)\nBorderline. The method section is not very well written and the authors avoid comparing the method against the state of the art methods in unsupervised DA.', '\nUnsupervised Domain adaptation is the problem of training a classifier without labels in some target domain if we have labeled data from a (hopefully) similar dataset with labels. For example, training a classifier using simulated rendered images with labels, to work on real images. \nLearning discriminative features for the target domain is a fundamental problem for unsupervised domain adaptation. The problem is challenging (and potentially ill-posed) when no labeled examples are given in the target domain. This paper proposes a new training technique called ADR, which tries to learn discriminative features for the target domain. The key idea of this technique is to move the target-domain features away from the source-domain decision boundary. ADR achieves this goal by encouraging the learned features to be robust to the dropout noise applied to the classifier.\n\nMy main concern about this paper is that the idea of ""placing the target-domain features far away from the source-domain decision boundary"" does not necessarily lead to *discriminative features* for the target domain. In fact, it is easy to come up with a counter-example: the target-domain features are far from the *source-domain* decision boundary, but they are all (both the positive and negative examples) on the same side of the boundary, which leads to poor target classification accuracy. The loss function (Equations 2-5) proposed in the paper does not prevent the occurrence of this counter-example.\n\nAnother concern comes from using the proposed idea in training a GAN (Section 4.3). Generating fake images that are far away from the boundary (as forced by the first term of Equation 9) is somewhat opposite to the objective of GAN training, which aims at aligning distributions of real and fake images. Although the second term of Equation 9 tries to make the generated and the real images similar, the paper does not explain how to properly balance the two terms of Equation 9. As a result, I am worried that the proposed method may lead to more mode-collapsing for GAN.\n\nThe experimental evaluation seems solid for domain adaptation. The semi-supervised GANs part seemed significantly less developed and might be weakening rather than strengthening the paper. \n\nOverall the performance of the proposed method is quite well done and the results are encouraging, despite the lack of theoretical foundations for this method. \n', ""I think the paper was mostly well-written, the idea was simple and great. I'm still wrapping my head around it and it took me a while to feel convinced that this idea helps with domain adaptation. A better explanation of the intuition would help other readers. The experiments were extensive and show that this is a solid new method for trying out for any adaptation problem. This also shows how to better utilize task models associated with GANs and domain adversarial training, as used eg. by Bousmalis et al., CVPR 2017, or Ganin et al, ICML 2015, Ghifary et al, ECCV 2016, etc.\n\nI think important work was missing in related work for domain adaptation. I think it's particularly important to talk about pixel/image-level adaptations eg CycleGAN/DiscoGAN etc and specifically as those were used for domain adaptation such as Domain Transfer Networks, PixelDA, etc. Other works like Ghifary et al, 2016, Bousmalis et al. 2016 could also be cited in the list of matching distributions in hidden layers of a CNN.\n\nSome specific comments: \n\nSect. 3 paragraph 2 should be much clearer, it was hard to understand.\n\nIn Sect. 3.1 you mention that each node of the network is removed with some probability; this is not true. it's each node within a layer associated with dropout (unless you have dropout on every layer in the network).  It also wasn't clear to me whether C_1 and C_2 are always different. If so, is the symmetric KL divergence still valid if it's minimizing the divergence of distributions that are different in every iteration? (Nit: capitalize Kullback Leibler)\n\nEq.3 I think the minus should be a plus?\n\nFig.3 should be improved, it wasn't well presented and a few labels as to what everything is could help the reader significantly. It also seems that neuron 3 does all the work here, which was a bit confusing to me. Could you explain that?\n\nOn p.6 you discuss that you don't use a target validation set as in Saito et al. Is one really better than the other and why? In other words, how do you obtain these fixed hyperparameters that you use? \n\nOn p. 9 you claim that the unlabeled images should be distributed uniformly among the classes. Why is that? ""]","[-50, 20, 50]","[20, 60, 70]","[""The sentiment score is -50 because the review is generally critical, with more cons than pros listed. The reviewer expresses concerns about the paper's comparisons, clarity, and methodology, using phrases like 'biggest concern' and 'borderline'. However, it's not entirely negative as it acknowledges some novel aspects. The politeness score is 20 because while the reviewer is direct in their criticisms, they use relatively polite language such as 'I suggest' and 'I'd encourage'. The tone is professional and constructive, offering specific recommendations for improvement, rather than being dismissive or harsh."", ""The sentiment score is slightly positive (20) because while the reviewer expresses some concerns, they also acknowledge the solid experimental evaluation and encouraging results. The overall tone is constructive rather than dismissive. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, presenting their concerns as 'main concern' and 'another concern' rather than outright criticisms. They also acknowledge the strengths of the paper, such as the 'solid' evaluation and 'encouraging' results. The reviewer maintains a professional and objective tone, offering specific feedback without using harsh or dismissive language."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by praising the paper as 'mostly well-written' with a 'simple and great' idea, and mentions 'extensive experiments' showing it's a 'solid new method'. However, they also point out areas for improvement, such as better explanation of intuition and missing related work. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'I think' to soften critiques and ask questions rather than making demands. The reviewer also acknowledges their own process of understanding ('I'm still wrapping my head around it'), which adds a humble tone. While direct in their feedback, they maintain a professional and courteous demeanor throughout the review.""]"
"[""This paper develops a novel method to use a neural network to infer statistical interactions between input variables without assuming any explicit interaction form or order. First the paper describes that an 'interaction strength' would be captured through a simple multiplication of the aggregated weight and the weights of the first hidden layers. Then, two simple networks for the main and interaction effects are modeled separately, and learned jointly with posing L1-regularization only on the interaction part to cancel out the main effect as much as possible. The automatic cutoff determination is also proposed by using a GAM fitting based on these two networks. A nice series of experimental validations demonstrate the various types of interactions can be detected, while it also fairly clarifies the limitations.\n\nIn addition to the related work mentioned in the manuscript, interaction detection is also originated from so-called AID, literally intended for 'automatic interaction detector' (Morgan & Sonquist, 1963), which is also the origin of CHAID and CART, thus the tree-based methods like Additive Groves would be the one of main methods for this. But given the flexibility of function representations, the use of neural networks would be worth rethinking, and this work would give one clear example.\n\nI liked the overall ideas which is clean and simple, but also found several points still confusing and unclear.\n\n1) One of the keys behind this method is the architecture described in 4.1. But this part sounds quite heuristic, and it is unclear to me how this can affect to the facts such as Theorem 4 and Algorithm 1. Absorbing the main effect is not critical to these facts? In a standard sense of statistics, interaction would be something like residuals after removing the main (additive) effect. (like a standard test by a likelihood ratio test for models with vs without interactions)\n\n2) the description about the neural network for the main effect is a bit unclear. For example, what does exactly mean the 'networks with univariate inputs for each input variable'? Is my guessing that it is a 1-10-10-10-1 network (in the experiments) correct...? Also, do g_i and g_i' in the GAM model (sec 4.3) correspond to the two networks for the main and interaction effects respectively?\n\n3) mu is finally fixed at min function, and I'm not sure why this is abstracted throughout the manuscript. Is it for considering the requirements for any possible criteria?\n\nPros:\n- detecting (any order / any form of) statistical interactions by neural networks is provided.\n- nice experimental setup and evaluations with comparisons to relevant baselines by ANOVA, HierLasso, and Additive Groves.\n\nCons:\n- some parts of explanations to support the idea has unclear relationship to what was actually done, in particular, for how to cancel out the main effect.\n- the neural network architecture with L1 regularization is a bit heuristic, and I'm not surely confident that this architecture can capture only the interaction effect by cancelling out the main effect.\n\n"", 'This paper presents a method to identify high-order interactions from the weights of feedforward neural networks.  \n\nThe main benefits of the method are:\n1)\tCan detect high order interactions and there’s no need to specify the order (unlike, for example, in lasso-based methods).\n2)\tCan detect interactions appearing inside of non-linear function (e.g. sin(x1 * x2))\n\nThe method is interesting, in particular if benefit #2 holds experimentally. Unfortunately, there are too many gaps in the experimental evaluation of this paper to warrant this claim right now.\n\nMajor:\n\n1)\tArguably, point 1 is not a particularly interesting setting. The order of the interactions tested is mainly driven by the sample size of the dataset considered, so in some sense the inability to restrict the order of the interaction found can actually be a problem in real settings. \nBecause of this, it would be very helpful to separate the evaluation of benefit 1 and 2 at least in the simulation setting. For example, simulate a synthetic function with no interactions appearing in non-linearities (e.g. x1+x2x3x4+x4x6) and evaluate the different methods at different sample sizes (e.g. 100 samples to 1e5 samples). The proposed method might show high type-1 error under this setting. Do the same for the synthetic functions already in the paper. By the way, what is the sample size of the current set of synthetic experiments?\n2)\tThe authors claim that the proposed method identifies interactions “without searching an exponential solution space of possible interactions”. This is misleading, because the search of the exponential space of interactions happens during training by moving around in the latent space identified by the intermediate layers. It could perhaps be rephrased as “efficiently”.\n3)\tIt’s not clear from the text whether ANOVA and HierLasso are only looking for second order interactions. If so, why not include a lasso with n-order interactions as a baseline?\n4)\tWhy aren’t the baselines evaluated on the real datasets and heatmaps similar to figure 5 are produced?\n5)\tIs it possible to include the ROC curves corresponding to table 2?\n\n\nMinor:\n\n1)\tHave the authors thought about statistical testing in this framework? The proposed method only gives a ranking of possible interactions, but does not give p-values or similar (e.g. FDRs).\n2)\t12 pages of text. Text is often repetitive and can be shortened without loss of understanding or reproducibility.\n', 'Based on a hierarchical hereditary assumption, this paper identifies pairwise and high-order feature interactions by re-interpreting neural network weights, assuming higher-order interactions exist only if all its induced lower-order interactions exist. Using a multiplication of the absolute values of all neural network weight matrices on top of the first hidden layer, this paper defines the aggregated strength z_r of each hidden unit r contributing to the final target output y. Multiplying z_r by some statistics of weights connecting a subset of input features to r and summing over r results in final interaction strength of each feature interaction subsets, with feature interaction order equal to the size of each feature subset. \n\nMain issues:\n\n1. Aggregating neural network weights to identify feature interactions is very interesting. However, completely ignoring \nactivation functions makes the method quite crude. \n\n2. High-order interacting features must share some common hidden unit somewhere in a hidden layer within a deep neural network. Restricting to the first hidden layer in Algorithm 1 inevitably misses some important feature interactions.\n\n3. The neural network weights heavily depends on the l1-regularized neural network training, but a group lasso penalty makes much more sense. See Group Sparse Regularization for Deep Neural Networks (https://arxiv.org/pdf/1607.00485.pdf).\n\n4. The experiments are only conducted on some synthetic datasets with very small feature dimensionality p. Large-scale experiments are needed.\n\n5. There are some important references missing. For example, RuleFit is a good baseline method for identifying feature interactions based on random forest and l1-logistic regression (Friedman and Popescu, 2005, Predictive learning via rule ensembles); Relaxing strict hierarchical hereditary constraints, high-order l1-logistic regression based on tree-structured feature expansion identifies pairwise and high-order multiplicative feature interactions (Min et al. 2014, Interpretable Sparse High-Order Boltzmann Machines); Without any hereditary constraint, feature interaction matrix factorization with l1 regularization identifies pairwise feature interactions on datasets with high-dimensional features (Purushotham et al. 2014, Factorized Sparse Learning Models with Interpretable High Order Feature Interactions). \n\n6. At least, RuleFit (Random Forest regression for getting rules + l1-regularized regression) should be used as a baseline in the experiments.\n\nMinor issues:\n\nRanking of feature interactions in Algorithm 1 should be explained in more details.\n\nOn page 3: b^{(l)} \\in R^{p_l}, l should be from 1, .., L. You have b^y.\n\n\nIn summary, the idea of using neural networks for screening pairwise and high-order feature interactions is novel, significant, and interesting.  However, I strongly encourage the authors to perform additional experiments with careful experiment design to address some common concerns in the reviews/comments for the acceptance of this paper.\n \n========\nThe additional experimental results are convincing, so I updated my rating score.\n  ']","[50, -30, 20]","[70, 50, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses appreciation for the overall ideas, calling them 'clean and simple,' and notes several pros of the paper. However, they also point out some cons and areas of confusion, balancing the positive aspects. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively pointing out areas for improvement. They use phrases like 'I liked' and 'nice experimental setup' to convey positive feedback, and frame criticisms as personal confusion (e.g., 'unclear to me') rather than direct attacks. The reviewer also provides detailed, thoughtful feedback, which is a polite way to engage with the authors' work."", ""The sentiment score is -30 because while the reviewer acknowledges the method as 'interesting' and notes some benefits, they express significant concerns about 'too many gaps in the experimental evaluation' and provide several major criticisms. This indicates a somewhat negative overall sentiment, though not entirely dismissive. The politeness score is 50 because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'it would be very helpful to...'), and acknowledges potential merits of the work. They maintain a professional tone without using harsh or rude language, even when pointing out flaws."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the novelty and significance of the idea, they also point out several major issues and recommend additional experiments. The overall tone suggests cautious optimism rather than strong approval or disapproval. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and encourages the authors to improve their work rather than dismissing it outright. Phrases like 'strongly encourage' and 'interesting' contribute to the polite tone, while still maintaining a professional, critical stance.""]"
"[""This paper introduces a VAE-based model for translating between images and text. The main way that their model differs from other multimodal methods is that their latent representation is well-suited to applying symbolic operations, such as AND and IGNORE, to the text. This gives them a more expressive language for sampling images from text.\n\nPros:\n- The paper is well written, and it provides useful visualizations and implementation details in the appendix.\n\n- The idea of learning compositional representations inside of a VAE framework is very appealing.\n\n- They provide a modular way of learning recombination operations.\n\nCons:\n- The experimental evaluation is limited. They test their model only on a simple, artificial dataset. It would also be helpful to see a more extensive evaluation of the model's ability to learn logical recombination operators, since this is their main contribution.\n\n- The approach relies on first learning a pretrained visual VAE model, but it is unclear how robust this is. Should we expect visual VAEs to learn features that map closely to the visual concepts that appear in the text? What happens if the visual model doesn't learn such a representation? This again could be addressed with experiments on more challenging datasets.\n\n- The paper should explain the differences and trade offs between other multimodal VAE models (such as their baselines, JMVAE and TrELBO) more clearly. It should also clarify differences between the SCAN_U baseline and SCAN in the main text.\n\n- The paper suggests that using the forward KL-divergence is important, but this does not seem to be tested with experiments.\n\n- The three operators (AND, IN COMMON, and IGNORE) can easily be implemented as simple transformations of a (binary) bag-of-words representation. What about more complex operations, such as OR, which seemingly cannot be encoded this way?\n\nOverall, I am borderline on this paper, due to the limited experimental evaluation, but lean slightly towards acceptance.\n"", 'Summary\n---\nThis paper proposes a new model called SCAN (Symbol-Concept Association Network) for hierarchical concept learning. It trains one VAE on images then another one on symbols and aligns their latent spaces. This allows for symbol2image and image2symbol inference. But it also allows for generalization to new concepts composed from existing concepts using logical operators. Experiments show that SCAN generates images which correspond to provided concept labels and span the space of concepts which match these labels.\n\nThe model starts with a beta-VAE trained on images (x) from the relevant domain (in this case, simple scenes generated from DeepMind Lab which vary across a few known dimensions). This is complemented by the SCAN model, which is a beta-VAE trained to reconstruct symbols (y; k-hot encoded concepts like {red, suitcase}) with a slightly modified objective. SCAN optimizes the ELBO plus a KL term which pushes the latent distribution of the y VAE toward the latent distribution of the x (image) VAE. This aligns the latent representations so now a symbol can be encoded into a latent distribution z and decoded as an image.\n\nOne nice property of the learned latent representation is that more specific concepts have more specific latent representations. Consider latent distributions z1 and z2 for a more general symbol {red} and a more specific symbol {red, suitcase}. Fewer dimensions of z2 have high variance than dimensions of z1. For example, the latent space could encode red and suitcase in two dimensions (as binary attributes). z1 would have high variance on all dimensions but the one which encodes red and z2 would have high variance on all dimensions but red and suitcase. In the reported experiments some of the dimensions do seem to be interpretable attributes (figure 5 right).\n\nSCAN also pays particular attention to hierarchical concepts. Another very simple model (1d convolution layer) is learned to mimic logical operators. Normally a SCAN encoder takes {red} as input and the decoder reconstructs {red}. Now another model is trained that takes ""{red} AND {suitcase}"" as input and reconstructs {red, suitcase}. The two input concepts {red} and {suitcase} are each encoded by a pre-trained SCAN encoder and then those two distributions are combined into one by a simple 1d convolution module trained to implement the AND operator (or IGNORE/IN COMMON). This allows images of concepts like {small, red, suitcase} to be generated even if small red suitcases are not in the training data.\n\nExperiments provide some basic verification and analysis of the method:\n1) Qualitatively, concept samples are correct and diverse, generating images with all configurations of attributes not specified by the input concept.\n2) As SCAN sees more diverse examples of a concept (e.g. suitcases of all colors instead of just red ones) it starts to generate more diverse image samples of that concept.\n3) SCAN samples/representations are more accurate (generate images of the right concept) and more diverse (far from a uniform prior in a KL sense) than JMVAE and TELBO baselines.\n4) SCAN is also compared to SCAN_U, which uses an image beta-VAE that learned an entangled (Unstructured) representation. SCAN_U performed worse than SCAN\nand baselines.\n5) Concepts expressed as logical combinations of other concepts generalize well for both the SCAN representation and the baseline representations.\n\n\nStrengths\n---\n\nThe idea of concept learning considered here is novel and satisfying. It imposing logical, hierarchical structure on latent representations in a general way. This suggests opportunities for inserting prior information and adds interpretability to the latent space.\n\n\nWeaknesses\n---\n\nI think this paper is missing some important evaluation.\n\nRole/Nature of Disentangled Features not Clear (major):\n\n* Disentangled features seem to be very important for SCAN to work well (SCAN vs SCAN_U). It seems that the only difference between the unstructured (entangled) and the structured (disentangled) visual VAE is the color space of the input (RGB vs HSV). If so, this should be stated more clearly in the main paper. What role did beta-VAE (tuning beta) as opposed to plain VAE play in learning disentangled features?\n\n* What color space was used for the JMVAE and TELBO baselines? Training these with HSV seems especially important for establishing a good comparison, but it would be good to report results for HSV and RGB for all models.\n\n* How specific is the HSV trick to this domain? Would it matter for natural images?\n\n* How would a latent representation learned via supervision perform? (Maybe explicitly align dimensions of z to red/suitcase/small with supervision through some mechanism. c.f. ""Discovering Hidden Factors of Variation in Deep Networks"" by Cheung et al.)\n\nEvaluation of sample complexity (major):\n\n* One of the main benefits of SCAN is that it works with less training data. There should be a more systematic evaluation of this claim. In particular, I would like to see a Number of Examples vs Performance (Accuracy/Diversity) plot for both SCAN and the baselines.\n\nMinor questions/comments/concerns:\n\n* What do the logical operators learn that the hand-specified versions do not?\n\n* Does training SCAN with the structure provided by the logical operators lead to improved performance?\n\n* There seems to be a mistake in figure 5 unless I interpreted it incorrectly. The right side doesn\'t match the left side. During the middle stage of training object hues vary on the left, but floor color becomes less specific on the right. Shouldn\'t object color become less specific?\n\n\nPrelimary Evaluation\n---\n\nThis clear and well written paper describes an interesting and novel way of learning a model of hierarchical concepts. It\'s missing some evaluation that would help establish the sample complexity benefit more precisely (a claimed contribution) and add important details about unsupervised disentangled representations. I would happy to increase my rating if these are addressed.', 'This paper proposed a novel neural net architecture that learns object concepts by combining a beta-VAE and SCAN. The SCAN is actually another beta-VAE with an additional term that minimizes the KL between the distribution of its latent representation and the first beta-VAE’s latent distribution. The authors also explored how this structure could be further expanded to incorporate another neural net that learns operators (and, in common, ignore), and demonstrated that the proposed system is able to generate accurate and diverse scenes given the visual descriptions.\n\nIn general, I think this paper is interesting. It’s studying an important problem with a newly proposed neural net structure. The experimental results are good and the model is compared with very recent baselines.\n\nI am, however, still lukewarm on this submission for its limited technical innovation and over-simplified experimental setup.\n\nThis paper does have technical innovations: the SCAN architecture and the way they learn “recombination operators” are newly proposed. However, there are in essence very straightforward extensions of VAE and beta-VAE (this is based on the fact that beta-VAE itself is a simple modification of VAE and the effect was discussed in a number of concurrent papers).\n\nThis would still be fine, as many small modifications of neural net architecture turn out to reveal fundamental insights that push the field forward. This is, however, not the case in this paper (at least not in the current manuscript) due to its over-simplified experiments. The authors are using images as input, but the images are all synthetic, and further, they are all synthesized to have highly regular structure. This suggests the network is likely to overfit the data and learn a straightforward mapping from input to the code. It’s unclear how well the system is able to generalize to real-world scenarios. Note that even datasets like MNIST has much higher complexity than the dataset used in this paper (though the dataset in this paper is more colorful).\n\nI agree that the proposed method performs better that its recent competitors. However, many of those methods like TripleELBO are not explicitly designed for these ‘recombination operators’. In contrast, they seem to perform well on real datasets. I would strongly suggest the authors perform additional experiments on standard benchmarks for a fair comparison.\n']","[20, -20, -20]","[60, 60, 50]","[""The sentiment score is slightly positive (20) because the reviewer lists several pros and expresses interest in the paper's concept, but also notes significant cons and is 'borderline' on acceptance. The overall tone leans slightly towards acceptance. The politeness score is moderately high (60) as the reviewer uses professional language, acknowledges positive aspects, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. The reviewer maintains a respectful tone throughout, even when pointing out limitations."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges strengths and novelty of the paper, they also point out significant weaknesses and missing evaluations. The review starts positively but then focuses more on criticisms and requests for additional work. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. They use phrases like 'I think', 'I would like to see', and 'I would be happy to increase my rating if these are addressed', which maintain a polite and collaborative tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting' and notes its good experimental results, they express being 'lukewarm' about the submission due to 'limited technical innovation and over-simplified experimental setup'. The reviewer also suggests significant improvements, indicating overall dissatisfaction with the current state of the paper. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, acknowledging positive aspects before presenting criticisms, and using phrases like 'I think', 'I would suggest', which soften the critique. The reviewer also provides constructive feedback and suggestions for improvement rather than outright dismissal.""]"
"['Summary: \nThe paper presents a modification of the Winograd convolution algorithm that enables a reduction of multiplications in a forward pass of 10.8x almost without loss of accuracy. \nThis modification combines the reduction of multiplications achieved by the Winograd convolution algorithm with weight pruning in the following way:\n- weights are pruned after the Winograd transformation, to prevent the transformation from filling in zeros, thus preserving weight sparsity\n- the ReLU activation function associated with the previous layer is applied to the Winograd transform of the input activations, not directly to the spatial-domain activations, also yielding sparse activations\n\nThis way sparse multiplication can be performed. Because this yields a network, which is not mathematically equivalent to a vanilla or Winograd CNN, the method goes through three stages: dense training, pruning and retraining. The authors highlight that a dimension increase in weights and ReLU activations provide a more powerful representation and that stable dynamic activation densities over layer depths benefit the representational power of ReLU layers.\n\nReview:\nThe paper shows good results using the proposed method and the description is easy to follow. I particularly like Figure 1. \nI only have a couple of questions/comments:\n1) I’m not familiar with the term m-specific (“Matrices B, G and A are m-specific.”) and didn’t find anything that seemed related in a very quick google search. Maybe it would make sense to add at least an informal description.\n2) Although small filters are the norm, you could add a note, describing up to what filter sizes this method is applicable. Or is it almost exactly the same as for general Winograd CNNs?\n3) I think it would make sense to mention weight and activation quantization in the intro as well (even if you leave a combination with quantization for future work), e.g. Rastegari et al. (2016), Courbariaux et al. (2015) and Lin et al. (2015)\n4) Figure 5 caption has a typo: “acrruacy”\n\nReferences:\nCourbariaux, Matthieu, Yoshua Bengio, and Jean-Pierre David. ""Binaryconnect: Training deep neural networks with binary weights during propagations."" In Advances in Neural Information Processing Systems, pp. 3123-3131. 2015.\nLin, Zhouhan, Matthieu Courbariaux, Roland Memisevic, and Yoshua Bengio. ""Neural networks with few multiplications."" arXiv preprint arXiv:1510.03009 (2015).\nRastegari, Mohammad, Vicente Ordonez, Joseph Redmon, and Ali Farhadi. ""Xnor-net: Imagenet classification using binary convolutional neural networks."" In European Conference on Computer Vision, pp. 525-542. Springer International Publishing, 2016.', 'This paper proposes to combine Winograd transformation with sparsity to reduce the computation for deep convolutional neural network. Specifically, ReLU nonlinearity was moved after Winograd transformation to increase the dynamic sparsity in the Winograd domain, while an additional pruning on low magnitude weights and re-training procedure based on pruning is used to increase static sparsity of weights, which decreases computational demand. The resulting Winograd-ReLU\nCNN shows strong performance in three scenarios (CIFAR10 with VGG, CIFAR100 with ConvPool-CNN-C, and ImageNEt with ResNet-18). The proposed method seems to improve over the two baseline approaches (Winograd and sparsity, respectively).\n\nOverall, the paper is well-written and the experiments seems to be quite thorough and clear. Note that I am not an expert in this field and I might miss important references along this direction. I am leaving it to other reviewers to determine its novelty. \n\nPutting ReLU in the Winograd domain (or any transformed domain, e.g., Fourier) seems to be an interesting idea, and deserves some further exploration. Also, I am curious about the performance after weight pruning but before retraining).', 'This paper proposes a method to build a CNN in the Winograd domain, where weight pruning and ReLU can be applied in this domain to improve sparsity and reduce the number of multiplication. The resultant CNN can achieve ~10x theoretical speedup with little performance loss.\n\nThe paper is well-written. It provides a new way to combine the Winograd transformation and the threshold-based weight pruning strategy. Rather than strictly keeping the architecture of ordinary CNNs, the proposed method applied ReLU to the transform domain, which is interesting.  \n\nThe results on Cifar-10 and ImageNet are promising. In particular, the pruned model in the Winograd domain performs comparably to the state-of-the-art dense neural networks and shows significant theoretical speedup. \nThe results on ImageNet using ResNet-18 architecture are also promising. However, no results are provided for deeper networks, so it is unclear how this method can benefit the computation of very deep neural networks \n\nA general limitation of the proposed method is the network architecture inconsistency with the ordinary CNNs. Due to the location change of ReLUs, it is unclear how to transform a pretrained ordinary CNNs to the new architectures accurately. It seems training from scratch using the transformed architectures is the simplest solution. \n\nThe paper does not report the actual speedup in the wall clock time. The actual implementation is what matters in the end. \n\nIt will be more informative to present Figure 2,3,4 with respect to the workload in addition to the weight density. \n\n']","[80, 70, 70]","[90, 80, 60]","[""The sentiment score is 80 (positive) because the reviewer starts by highlighting the good results and easy-to-follow description of the paper. They specifically mention liking Figure 1, which indicates a positive impression. The review is constructive and offers suggestions for improvement without any harsh criticism. The politeness score is 90 (very polite) due to the reviewer's use of respectful language throughout. They frame their comments as questions or suggestions rather than demands, using phrases like 'I think it would make sense' and 'Maybe it would make sense'. The reviewer also acknowledges their own potential lack of knowledge ('I'm not familiar with...') rather than assuming the authors made a mistake. The only slightly critical point is mentioning a typo, but this is presented neutrally as helpful feedback."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'well-written' with 'thorough and clear' experiments. They also mention that the proposed method 'seems to improve over the two baseline approaches.' The reviewer shows interest in the ideas presented, suggesting further exploration. The score is not higher because the reviewer admits to not being an expert in the field and defers judgment on novelty to other reviewers. The politeness score is 80 (polite) due to the reviewer's respectful and constructive tone throughout. They acknowledge their own limitations ('I am not an expert in this field') and offer suggestions for further exploration rather than criticism. The language used is professional and courteous, avoiding any harsh or negative phrasing."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'well-written' and notes that the results are 'promising' on multiple datasets. They highlight the novelty and interesting aspects of the proposed method. However, it's not a perfect score due to some limitations mentioned, such as the lack of results for deeper networks and the absence of actual speedup measurements. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while providing constructive criticism. They use phrases like 'it will be more informative' instead of more direct or harsh language when suggesting improvements. The tone is professional and balanced, offering both praise and areas for improvement without being overly effusive or critical.""]"
"['Theoretical contributions: None. Moreover, there is no clear theoretical explanation for why this approach ought to work. The authors cite (Chapelle et al., 2000) and actually most of the equations are taken from there, but the authors do not justify why the proposed distribution is a good approximation for the true p(x, y). \n\nPractical contributions: The paper introduces a new technique for training DNNs by forming a convex combination between two training data instances, as well as changing the associated label to the corresponding convex combination of the original 2 labels. \n\nExperimental results. The authors show mixup provides improvement over baselines in the following settings:\n  * Image Classification on Imagenet. CIFAR-10 and CIFAR-100, across architectures.\n  * Speech data \n  * Memorization of corrupted labels\n  * Adversarial robustness (white box and black box attacks)\n  * GANs (though quite a limited example, it is hard to generalize from this setting to the standard problems that GANs are used for).\n  * Tabular data.\n\nReproducibility: The provided website to access the source code is currently not loading. However, experiment hyperparameters are meticulously recorded in the paper. \n\nKey selling points:\n  * Good results across the board.\n  * Easy to implement.\n  * Not computationally expensive. \n\nWhat is missing:\n  * Convincing theoretical arguments for why combining data and labels this way is a good approach. Convex combinations of natural images does not result in natural images. \n * Baseline in which the labels are not mixed, in order to ensure that the gains are not coming from the data augmentation only. Combining the proposed data augmentation with label smoothing should be another baseline.\n  * A thorough discussion on mixing in feature space, as well as a baseline which mizes in feature space. \n  * A concrete strategy for obtaining good results using the proposed method. For example, for speech data the authors say that “For mixup, we use a warm-up period of five epochs where we train the network on original training examples, since we find it speeds up initial convergence.“ Would be good to see how this affects results and convergence speed. Apart from having to tune the lambda hyperparameter, one might also have to tune when to start mixup. \n  * Figure 2 seems like a test made to work for this method and does not add much to the paper. Yes, if one trains on convex combination between data, one expects the model to do better in that regime. \n  * Label smoothing baseline to put numbers into perspective, for example in Figure 4. \n\n\n\n', 'This paper studies an approach of data augmentation where a convex combination of multiple samples is used as a new sample.  While the use of such convex combination (mixing features) is not new, this paper proposes to use a convex combination of corresponding labels as the label of the new sample (mixing labels).  The authors motivate the proposed approach in the context of vicinal risk minimization, but the proposed approach is not well supported by theory.  Experimental results suggest that the proposed approach significantly outperforms the baseline of using only the standard data augmentation studied in Goyal et al. (2017).\n\nWhile the idea of mixing not only features but also labels is new and interesting, its advantage over the existing approach of mixing only features is not shown.  The authors mention ""interpolating only between inputs with equal label did not lead to the performance gains of mixup,"" but this is not shown in the experiments.  The authors cite recent work by DeVries & Taylor (2017) and Pereyra et al. (2017), but the technique of combining multiple samples for data augmentation have been a popular approach.  See for example a well cited paper by Chawla et al. (2002).  The baseline should thus be mixing only features, and this should be compared against the proposed approach of mixing both features and labels.\n\nN. V. Chawla et al., SMOTE: Synthetic Minority Over-sampling Technique, JAIR 16: 321-357 (2002).\n\nMinor comments:\n\nFigure 1(b): How should I read this figure?  For example, what does the color represent?\n\nTable 1: What is an epoch for mixup?  How does the per epoch complexity of mixup copare against that of ERM?\n\nTable 2: The test error seems to be quite sensitive to the number of epochs.  Why not use validation to determine when to stop training?\n\nTable 2: What is the performance of mixup + dropout?\n\n===\n\nI appreciate the thorough revision.  The empirical advantages over baselines including SMOTE and others are now well demonstrated in the experimental results.  It is also good to see that mixup is complementary to dropout, and the combined method works even better than either.\n\nI understand and appreciate the authors\' argument as to why mixup should work, but it is not sufficiently convincing to me why a convex combination in Euclidean space should produce good data distribution.  Convex combination certainly changes the manifold.  However, the lack of sufficient theoretical justification is now well complemented by extensive experiments, and it will motivate more theoretical work.\n', 'I enjoyed reading this well-written and easy-to-follow paper. The paper builds on the rather old idea of minimizing the empirical vicinal risk (Chapelle et al., 2000) instead of the empirical risk. The authors\' contribution is to provide a particular instance of vicinity distribution, which amounts to linear interpolation between samples. This idea of linear interpolation on the training sample to generate additional (adversarial, in the words of the authors) data is definitely appealing to prevent overfitting and improve generalization performance at a mild computational cost (note that this comment does not just apply to deep learning). This notion is definitely of interest to machine learning, and to the ICLR community in particular. I have several comments and remarks on the concept of mixup, listed below in no particular order. My overall opinion on the paper is positive and I stand for acceptance, provided the authors answer the points below. I would especially be interested in discussing those with the authors.\n\n1 - While data augmentation literature is well acknowledged in the paper, I would also like to see a comment on domain adaptation, which is a very closely related topic and of particular interest to the ICLR community.\n\n2 - Paragraph after Eq. (1), starting with ""Learning"" and ending with ""(Szegedy et al., 2014)"": I am not so familiar with the term memorization, is this just a fancy way of talking about overfitting? If so, you might want to rephrase this paragraph with terms more used in the machine learning community. When you write ""one trivial way to minimize [the empirical risk] is to memorize the training data"", do you mean output a predictor which only delivers predictions on $X_i$, equal to $Y_i$? If so, this is again not specific to deep learning and I feel this should be a bit more discussed.\n\n3 - I have not found in the paper a clear heuristics about how pairs of training samples should be picked to create interpolations. Picking at random is the simplest however I feel that a proximity measure on the space $\\mathcal{X}$ on which samples live would come in handy. For example, sampling with a probability decreasing as the Euclidean distance seems a natural idea. In any case, I strongly feel this discussion is missing in the paper.\n\n4 - On a related note, I would like to see a discussion on how many ""adversarial"" examples should be used. Since the computational overhead cost of computing one new sample is reasonable (sampling from a Beta distribution + one addition), I wonder why $m$ is not taken very large, yielding more accurate estimates of the empirical risk. A related question: under what conditions does the vicinal risk converge (in expectation for example) to the empirical risk? I think some comments would be nice.\n\n5 - I am intrigued by the last paragraph of Section 5. What do the authors exactly have in mind when they suggest that mixup could be generalized to regression problems? As far as I understood the paper, since $\\tilde{y}$ is defined as a linear interpolation between $y_i$ and $y_j$, this formulation only works for continuous $y$s, like in regression. This formulation is not straightforwardly transposable to classification for example. I therefore am quite confused about the fact that the authors present experiments on classification tasks, with a method that writes for regression.\n\n6 - Writing linear interpolations to generate new data points implicitly makes the assumption that the input and output spaces ($\\mathcal{X}$ and $\\mathcal{Y}$) are convex. I have no clear intuition wether this is a limitation of the authors\' proposed method but I strongly feel this should be carefully addressed by a comment in Section 2.']","[-20, 50, 70]","[50, 75, 80]","[""The sentiment score is slightly negative (-20) because the review starts by pointing out the lack of theoretical contributions and clear explanations. However, it does acknowledge practical contributions and positive experimental results. The overall tone is critical but balanced, recognizing both strengths and weaknesses. The politeness score is moderately positive (50) as the reviewer uses professional and neutral language throughout, avoiding harsh criticism or personal attacks. They provide constructive feedback and specific suggestions for improvement, which is a polite approach in academic peer review. The reviewer also acknowledges the paper's strengths, such as 'Good results across the board' and 'Easy to implement', which contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the review starts with a neutral tone, describing the paper's approach, but becomes more positive in the second part, appreciating the thorough revision and empirical advantages demonstrated. The reviewer acknowledges the paper's contributions while still noting some theoretical concerns. The politeness score is 75 (quite polite) due to the use of respectful language throughout, such as 'I appreciate' and 'It is good to see'. The reviewer offers constructive criticism and suggestions without using harsh or dismissive language. The tone is professional and courteous, even when pointing out areas for improvement."", ""The sentiment score is 70 (positive) because the reviewer expresses enjoyment in reading the paper, describes it as 'well-written and easy-to-follow', and states their 'overall opinion on the paper is positive' with a recommendation for acceptance. However, it's not 100 as they have several comments and points for the authors to address. The politeness score is 80 (polite) due to the reviewer's use of respectful language throughout, such as 'I enjoyed reading', 'I would be interested in discussing', and framing criticisms as requests for clarification or additional information. The reviewer maintains a professional and constructive tone, even when pointing out potential issues or requesting more information.""]"
"[""This paper introduces a new architecture for end to end neural machine translation. Inspired by the phrase based approach, the translation process is decomposed as follows : source words are embedded and then reordered; a bilstm then encodes the reordered source; a sleep wake network finally generates the target sequence as a phrase sequence built from left to right. \n\nThis kind of approach is more related to ngram based machine translation than conventional phrase based one.  \n\nThe idea is nice. The proposed approach does not rely on attention based model. This opens nice perpectives for better and faster inference. \n\nMy first concern is about the architecture description. For instance, the swan part is not really stand alone. For reader who does not already know this net, I'm not sure this is really clear. Moreover, there is no link between notations used for the swan part and the ones used in the reordering part. \n\nThen, one question arises. Why don't you consider the reordering of the whole source sentence. Maybe you could motivate your choice at this point. This is the main contribution of the paper, since swan already exists.\n\nFinally, the experimental part shows nice improvements but: 1/ you must provide baseline results with a well tuned phrase based mt system; 2/ the datasets are small ones, as well as the vocabularies, you should try with larger datasets and bpe for sake of comparison. "", 'The paper introduces a neural translation model that automatically discovers phrases.  This idea is very interesting and tries to marry phrase-based statistical machine translation with neural methods in a principled way. However, the clarity of the paper could be improved.\n\nThe local reordering layer has the ability to swap inputs, however, how do you ensure that it actually does swap inputs rather than ignoring some inputs and duplicating others?\n\nAre all segments translated independently, or do you carry over the hidden state of the decoder RNN between segments? In Figure 1 both a BRNN and SWAN layer are shown, is there another RNN in the SWAN layer, or does the BRNN emit the final outputs after the segments have been determined?', 'Authors proposed a new neural-network based machine translation method that generates the target sentence by generating multiple partial segments in the target sentence from different positions in the source information. The model is based on the SWAN architecture which is previously proposed, and an additional ""local reordering"" layer to reshuffle source information to adjust those positions to the target sentence.\n\nUsing the SWAN architecture looks more reasonable than the conventional attention mechanism when the ground-truth word alignment is monotone. Also, the concept of local reordering mechanism looks well to improve the basic SWAN model to reconfigure it to the situation of machine translation tasks.\n\nThe ""window size"" of the local reordering layer looks like the ""distortion limit"" used in traditional phrase-based statistical machine translation methods, and this hyperparameter may impose a similar issue with that of the distortion limit into the proposed model; small window sizes may drop information about long dependency. For example, verbs in German sentences sometimes move to the tail of the sentence and they introduce a dependency between some distant words in the sentence. Since reordering windows restrict the context of each position to a limited number of neighbors, it may not capture distant information enough. I expected that some observations about this point will be unveiled in the paper, but unfortunately, the paper described only a few BLEU scores with different window sizes which have not enough information about it. It is useful for all followers of this paper to provide some observations about this point.\nIn addition, it could be very meaningful to provide some experimental results on linguistically distant language pairs, such as Japanese and English, or simply reversing word orders in either source or target sentences (this might work to simulate the case of distant reordering).\n\nAuthors argued some differences between conventional attention mechanism and the local reordering mechanism, but it is somewhat unclear that which ones are the definite difference between those approaches.\n\nA super interesting and mysterious point of the proposed method is that it achieves better BLEU than conventional methods despite no any global language models (Table 1 row 8), and the language model options (Table 1 row 9 and footnote 4) may reduce the model accuracy as well as it works not so effectively. This phenomenon definitely goes against the intuitions about developing most of the conventional machine translation models. Specifically, it is unclear how the model correctly treats word connections between segments without any global language model. Authors should pay attention to explain more detailed analysis about this point in the paper.\n\nEq. (1) is incorrect. According to Fig. 2, the conditional probability in the product operator should be revised to p(a_t | x_{1:t}, a_{1:t-1}), and the independence approximation to remove a_{1:t-1} from the conditions should also be noted in the paper.\nNevertheless, the condition x_{1:t} could not be reduced because the source position is always conditioned by all previous positions through an RNN.\n\n']","[50, 50, 50]","[60, 75, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's 'nice' idea and its potential for 'better and faster inference'. However, they also express concerns about the architecture description and experimental part, balancing out the positive aspects. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, such as 'My first concern' and 'Why don't you consider', rather than using harsh or critical tones. They also offer constructive suggestions for improvement, which is a polite way to provide feedback. The reviewer maintains a professional and courteous tone while providing both positive feedback and areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by acknowledging the interesting and innovative aspects of the paper, describing it as 'very interesting' and praising its attempt to combine phrase-based statistical machine translation with neural methods. However, the reviewer also mentions that 'the clarity of the paper could be improved,' indicating some reservations. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as questions or suggestions rather than direct criticisms. The reviewer acknowledges the paper's strengths before mentioning areas for improvement, and uses phrases like 'could be improved' rather than more harsh language. The questions posed are genuine inquiries for clarification rather than aggressive challenges to the authors' work."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the strengths of the proposed method, such as its reasonableness and potential improvements over existing models. However, they also point out several areas for improvement and request additional analysis, indicating a balanced view. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions in a considerate manner (e.g., 'It is useful for all followers of this paper to provide...'). The reviewer also acknowledges the 'super interesting' aspects of the work. The tone is professional and courteous, avoiding harsh or dismissive language even when pointing out errors or areas for improvement.""]"
"['This manuscript makes the case for a particular parameterization of conditional GANs, specifically how to add conditioning information into the network.  It motivates the method by examining the form of the log density ratio in the continuous and discrete cases.\n\nThis paper\'s empirical work is quite strong, bringing to bare nearly all of the established tools we currently have for evaluating implicit image models (MS-SSIM, FID, Inception scores). \n\nWhat bothers me is mostly that, while hyperparameters are stated (and thank you for that), they seem to be optimized for the candidate method rather than the baseline. In particular, Beta1 = 0 for the Adam momentum coefficient seems like a bold choice based on my experience. It would be an easier sell if hyperparameter search details were included and a separate hyperparameter search were conducted for the candidate and control, allowing the baseline to put its best foot forward.\n\nThe sentence containing ""assume that the network model can be shared"" had me puzzled for a few minutes. I think what is meant here is just that we can parameterize the log density ratio directly (including some terms that belong to the data distribution to which we do not have explicit access). This could be clearer.', ""The paper proposes a simple modification to conditional GANs, obtaining impressive results on both the quality and diversity of samples on ImageNet dataset. Instead of concatenating the condition vector y to the input image x or hidden layers of the discriminator D as in the literature, the authors propose to project the condition y onto a penultimate feature space V of D (by simply taking an inner product between y and V) . This implementation basically restricts the conditional distribution p(y|x) to be really simple and seems to be posing a good prior leading to great empirical results.\n\n+ Quality:\n- Simple method leading to great results on ImageNet!\n- While the paper admittedly leaves theoretical work for future work, the paper would be much stronger if the authors could perform an ablation study to provide readers with more intuition on why this work. One experiment could be: sticking y to every hidden layer of D before the current projection layer, and removing these y's increasingly and seeing how performance changes.\n- Appropriate comparison with existing conditional models: AC-GANs and PPGNs.\n- Appropriate (extensive) metrics were used (Inception score/accuracy, MS-SSIM, FID)\n\n+ Clarity:\n- Should explicitly define p, q, r upfront before Equation 1 (or between Eq1 and Eq2).\n- PPG should be PPGNs.\n\n+ Originality:\nThis work proposes a simple method that is original compared existing GANs.\n\n+ Significance:\nWhile the contribution is significant, more experiments providing more intuition into why this projection works so well would make the paper much stronger.\n\nOverall, I really enjoy reading this paper and recommend for acceptance!\n\n\n\n\n"", ""\nI thank the authors for the thoughtful response and updated manuscript. After reading through both, my review score remains unchanged.\n\n=================\n\nThe authors describe a new variant of a generative adversarial network (GAN) for generating images. This model employs a 'projection discriminator' in order to incorporate image labels and demonstrate that the resulting model outperforms state-of-the-art GAN models.\n\nMajor comments:\n1) Spatial resolution. What spatial resolution is the model generating images at? The AC-GAN work performed an analysis to assess how information is being introduced at each spatial resolution by assessing the gains in the Inception score versus naively resizing the image. It is not clear how much the gains of this model is due to generating better lower resolution images and performing simple upscaling. It would be great to see the authors address this issue in a serious manner.\n\n2) FID in real data. The numbers in Table 1 appear favorable to the projection model. Please add error bars (based on Figure 4, I would imagine they are quite large). Additionally, would it be possible to compute this statistic for *real* images? I would be curious to know what the FID looks like as a 'gold standard'.\n\n3) Conditional batch normalization.  I am not clear how much of the gains arose from employing conditional batch normalization versus the proposed method for incorporating the projection based discriminator. The former has been seen to be quite powerful in accomodating multi-modal tasks (e.g. https://arxiv.org/abs/1709.07871, https://arxiv.org/abs/1610.07629\n). If the authors could provide some evidence highlighting the marginal gains of one technique, that would be extremely helpful.\n\nMinor comments:\n- I believe you have the incorrect reference for conditional batch normalization on Page 5.\nA Learned Representation For Artistic Style\nDumoulin, Shlens and Kudlur (2017)\nhttps://arxiv.org/abs/1610.07629\n\n- Please enlarge images in Figure 5-8. Hard to see the detail of 128x128 images.\n\n- Please add citations for Figures 1a-1b. Do these correspond with some known models?\n\nDepending on how the authors respond to the reviews, I would consider upgrading the score of my review.""]","[50, 90, -20]","[75, 80, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the strong empirical work and comprehensive evaluation methods used in the paper. However, they express concerns about hyperparameter optimization and clarity of certain explanations, which prevents a higher positive score. The politeness score is 75 (quite polite) due to the reviewer's constructive tone, use of phrases like 'thank you for that,' and the balanced approach in providing both positive feedback and areas for improvement. The reviewer maintains a professional and respectful tone throughout, offering suggestions rather than harsh criticisms."", ""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer uses phrases like 'impressive results', 'great empirical results', and 'I really enjoy reading this paper and recommend for acceptance!'. They highlight multiple strengths of the paper and only offer constructive suggestions for improvement. The politeness score is 80 because the reviewer uses respectful and encouraging language throughout. They offer suggestions in a constructive manner, using phrases like 'the paper would be much stronger if' rather than criticizing. The tone is professional and supportive, praising the work while also providing helpful feedback for improvement."", ""The sentiment score is slightly negative (-20) because the reviewer states their review score remains unchanged, implying they still have concerns. They also list several major comments and requests for additional information or analysis, indicating the paper needs significant improvements. However, the tone is not entirely negative as they thank the authors for their response and offer the possibility of upgrading their score.\n\nThe politeness score is moderately positive (60) because the reviewer begins by thanking the authors for their thoughtful response, which sets a respectful tone. They use polite language throughout, such as 'Please add...' and 'It would be great to see...'. The reviewer also offers constructive criticism and suggestions rather than harsh criticisms. The overall tone is professional and courteous, even when pointing out areas for improvement.""]"
"['Novelty: It looks quite straightforward to combine document ranking and query suggestion.  For the model architecture, it is a standard multi-task learning framework. For the “session encoder”, it is also proposed (at least, used) in (Sordoni et al., CIKM 2015). Therefore, I think the technical novelty of the work is limited. \n\nClarify: The paper is in general well written. One minor suggestion is to replace Figure 1 with Figure 3, which is more intuitive. \n\nExperiments: \n1.\tWhy don’t you try deep LSTM models and attention mechanisms (although you mentioned them as future work)? There are many open-source tools for deep LSTM/GRU and attention models, and I see no obstacle to implement your algorithms on their top. \n2.\tIn Table 2, M-NSRF with regularization significantly outperforms the version without regularization. This indicates that it might be the regularization that works rather than multi-task learning. For fair comparison, the regularization trick should also be applied to the baselines. \n3.\tFor the evaluation metric of query suggestion, why not using BLEU score? At least, you should compare with the metrics used in (Sordoni et al., 2015) for fairness. \n4.\tThe experiments are not very comprehensive – currently, there is only one experiment in the paper, from which one can hardly draw convincing conclusions.\n5.\tHow many words are there in your documents? What is the average length of each document? You only mention that “our goal is to rank candidate documents titles……” in Page 6, 2nd paragraph. It might be quite different for long document retrieval vs. short document retrievel. \n6.\tHow did you split the dataset into training, validation and test sets?  It seems that you used a different splitting rule from (Sordoni et al., 2015), why? ', 'The work is interesting and novel. The novelty lies not in the methods used (existing methods are used), but in the way these methods are combined to solve two problems (that so far have been treated separately in IR) simultaneously. The fitness of the proposed architecture and methodological choices to the task at hand is sufficiently argued. \n\nThe experimental evaluation is not the strongest, in terms of datasets and evaluation measures. While I understand why the AOL dataset was used, the document ranking experiments should also include runs on any of the conventional TREC datasets of documents, queries and actual (not simulated) relevance assessments. Simulating document relevance from clicks is a good enough approximation, but why not also use datasets with real human relevance assessments, especially since so many of them exist and are so easy to access?\n\nWhen evaluating ranking, MAP and NDCG are indeed two popular measures. But the choice of NDCG@1,3,10 seems a bit adhoc. Why not NDCG@5? Furthermore, as the aim seems to be to assess early precision, why not also report MRR? \n\nThe paper reports that the M-NSRF query suggestion method outperforms all baselines. This is not true. Table 2 shoes that M-NSRF is best for BLEU-1/2, but not for BLEU-3/4. \n\nThree final points:\n\n- Out of the contributions enumerated at the end of Section 1, only the novel model and the code & data release are contributions. The rigorous comparison to soa and its detailed analysis are the necessary evaluation parts of any empirical paper.  \n- The conclusion states that this work provides useful intuitions about the advantages of multi-task learning involving deep neural networks for IR tasks. What are these? Where were they discussed? They should be outlined here, or referred to somehow.\n- Although the writing is coherent, there are a couple of recurrent English language mistakes (e.g. missing articles). The paper should be proofread and corrected.', 'This paper presents a joint learning framework for document ranking and query suggestion. It introduces the session embeddings to capture the connections between queries in a session, and potential impact of previous queries in a session to the document ranking of the current query. I like the idea in general. \n\nHowever, I have a few comments as follows:\n\n- Multi-task Match Tensor model, which is important in the experiments (best results), is only briefly introduced in Section 3.4. It is not very clear how to extend from match tensor model to a multi-task match tensor model. This makes me feel like this paper is not self-contained. The setting for this model is not introduced either in Section 4.2. \n\n- Section 3 is written mostly about what has been done but not why doing this. More intuition should be added to better explain the idea. \n\n- I like the analysis about testing the impact of the different model components in Section 4.4, especially analyzing the impact of the session. It would be nice to have some real examples to see the impact of session embeddings on document ranking. One more related question is how the clicked documents of a previous query in the same session influence the document ranking of this current query? Would that be feasible to consider in this proposed framework?\n\n- Session seems to play an important role in this multi task learning framework. This paper used the fixed 30 minute window of idle time to define a session. It would be nice to know how sensitive this model is to the definition / segmentation of sessions. \n']","[-50, 20, 50]","[20, 60, 80]","[""The sentiment score is -50 because the reviewer expresses concerns about the novelty of the work, calling it 'limited', and points out several issues with the experiments. However, they do acknowledge that the paper is generally well-written. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and offer constructive feedback. They use phrases like 'One minor suggestion' and frame their points as questions or suggestions rather than harsh criticisms. The reviewer also provides specific recommendations for improvement, which is helpful and courteous in academic review contexts."", ""The sentiment score is slightly positive (20) because the reviewer starts by acknowledging the work as 'interesting and novel', and recognizes the novelty in combining existing methods. However, they also point out several weaknesses in the experimental evaluation and some inaccuracies in the reported results, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and providing constructive criticism. They use phrases like 'I understand why' and 'sufficiently argued', which show consideration. The reviewer also offers specific suggestions for improvement rather than just criticizing, which is a polite approach. The tone remains professional and objective throughout, without any harsh or rude language."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by expressing that they like the general idea of the paper, which is a positive sentiment. However, they follow this with several comments and suggestions for improvement, indicating a balanced view rather than overwhelmingly positive. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing their comments as suggestions rather than criticisms. They use phrases like 'I like' and 'It would be nice to' which maintain a constructive and polite tone. The reviewer also acknowledges positive aspects of the paper, such as the analysis in Section 4.4, which contributes to the polite tone. There are no rude or harsh statements, and the overall tone is professional and courteous.""]"
"['The paper is well written. The proposal is explained clearly. \nAlthough the technical contribution of this work is relevant for network learning, several key aspects are yet to be addressed thoroughly, particularly the experiments. \n\nWill there be any values of alpha, beta and gamma where eq(8) and eq(9) are equivalent. In other words, will it be the case that SharedPerturbation(alpha, beta, gamma, N) = Flipout(alpha1, beta1, gamma1, N1) for some choices of alpha, alpha1, beta, beta1, ...? This needs to be analyzed very thoroughly because some experiments seem to imply that Flip and NoFlip are giving same performance (Fig 2(b)). \nIt seems like small batch with shared perturbation should be similar to large batch with flipout? \nWill alpha and gamma depend on the depth of the network? Can we say anything about which networks are better? \nIt is clear that the perturbations E1 and E2 are to be uniform +/-1. Are there any benefits for choosing non-uniform sampling, and does the computational overhead of sampling them depend on the network depth/size. \n\nThe experiments seem to be inconclusive. \nFirstly, how would the proposed strategy work on standard vision problems including learning imagenet and cifar datasets (such experiments would put the proposal into perspective compared to dropout and residual net type procedures) ?\nSecondly, without confidence intervals (or significance tests of any kind), it is difficult to evaluate the goodness of Flipout vs. baselines, specifically in Figures 2(b,d). \nThirdly, it is known that small batch sizes give better performance guarantees than large ones, and so, what does Figure 1 really imply? (Needs more explanation here, relating back to description of alpha, beta and gamma; see above). \n', 'Typical weight perturbation algorithms (as used for e.g. Regularization, Bayesian NN, Evolution\nStrategies) suffer from a high variance of the gradient estimates. This is caused\nby sharing a weight perturbation by all training examples in a minibatch. More specifically\nsharing perturbed weights over samples in a minibtach induces correlations between gradients of each sample, which can\nnot be resolved by standard averaging. The paper introduces a simple idea, flipout, to\nperturb the weights quasi-independently within a minibatch: a base perturbation (shared\nby all sample in a minibatch) is multiplied by a random rank-one sign matrix (different\nfor every sample). Due to its special structure it is possible to vectorize this\nper-sample-operation such that only matrix-matrix products (as in the default forward\npropagation) are involved. The incurred computational cost is roughly twice as much\nas a standard forward propagation path. The paper also proves that this approach\nreduces the variance of the gradient estimates (and in practice, flipout should\nobtain the ideal variance reduction). In a set of experiments it is demonstrated\nthat a significant reduction in gradient variance is achieved, resulting\nin speedups for training time. Additionally, it is demonstrated that\nflipout allows evolution strategies utilizing GPUs.\n\nOverall this is a very nice paper. It clearly lays out the problem, describes\none solution to it and shows both theoretically as well as empirically\nthat the proposed solution is a feasable one. Given the increasing importance\nof Bayesian NN and Evolution Strategies, flipout is an important contribution.\n\nQuality: Overall very well written. Relevant literature is covered and an important\nproblem of current research in ML is tackled.\n\nClarity: Ideas/Reasons are clearly presented.\n\nSignificance: The presented work is highly significant for practical applicability\nof Bayesian NN and Evolution Strategies.', 'In this article, the authors offer a way to decrease the variance of the gradient estimation in the training of neural networks.\nThey start in the Introduction and Section 2 by explaining the multiple uses of random connection weights in deep learning and how the computational cost often restricts their use to a single randomly sampled set of weights per minibatch, which results to higher-variance gradient estimatos than could be achieved otherwise. In Section 3 the authors offer to get the benefits of multiple weights without most of the cost, when the distribution of the weights is symmetric and fully factorized, by multiplying sampled-once random perturbations of the weights by a rank-1 random sign matrix. This efficient mechanism is only twice as costly as a single random perturbation, and the authors show how to efficiently parallelize it on GPUs, thereby also allowing GPU-ization of evolution strategies (something so far difficult toachieve). Of note, they provide a theoretical analysis in Section 3.2, proving the actual variance reduction of their efficient pseudo-sampling scheme. In Section 4 they provide quite varied empirical analysis: they confirm their theoretical results on four architectures; they show its use it to regularise on language models; they apply it on large minibatch settings where high variance is a main problem; and on evolution strategies.\n\nWhile it is a rather simple idea which could be summarised much earlier in the  single equation (3), I really like the thoroughness and the clarity of the exposure of the idea. Too many papers in our community skimp on details and on formalism, and it is a delight to see things exposed so clearly -- even accompanied with a proof.\n\nHowever, the painful part: while I am convinced by the idea and love its detailed exposure, and the gradient variance reduction is made very clear, the experimental impact in terms of accuracy (or perplexity) is, sadly,  not very convincing. Nowhere in the text did I find a clear rationale of why it is beneficial to reduce the variance of the gradient. The numerical results in Table 1 and Table 2 also do not show a clear improvement: Flipout does not provide the best accuracy. The gain in wall clock could be a factor, but would need to be measured on the figures more clearly. And the validation errors in Figure 2 for Evolution strategies seem to be worse than backprop.The main text itself also only claims performance “comparable to the other methods”.  The only visible gain is on the lower part Figure 2.a on a ConvNet.\n\nThis makes me wonder if the authors could do a better job of putting forward the actual advantages of their methods on the end-results: could wall clock measure be put more forward, to justify the extra work? This would, in my mind, strongly improve the case for publication of this article.\n\n\nA few improvement suggestions:\n* Could put earlier more emphasis of superiority to Local Reparameterization Trick in terms of architecture, not wait until Section 2.2 and section 4.1\n*Should also put more emphasis on limitations, not wait until 3.1.\n* Proposition 1 is quite straightforward, not sure it deserves a proposition, but it’s elegant to put it forward.\n* Footnote 1 on re-using the matrices is indeed practical, but also somewhat surprising in terms of bias risks. Could it be explained in more depth, maybe by the random permutations of the minibatches making the bias non systematic and cancelling out?\n* Theorem 1: For readability could merge the expectations on the joint distribution as E_{x, \\hat \\delta W} , rather than separate expectations with the conditional distributions.\n* Theorem 1: could the authors provide a clearer intuitive explanation of the \\beta term alone, not only as part of \\alpha + \\beta, especially as it plays such a key role, being the only one that does not disappear? And how do they explain their empirical observation that \\beta is close to 0? Any intuition on that?\n* Experiments: I salute the authors for providing all the details in exhaustive manner in the Appendix. Very commendable.\n* Experiments: I like the empirical verification of the theory. Very neat to see.\n\nMinor typo:\n* page 2 last paragraph, “evolution strategies” is plural but the verbs are used in singular (“is black box”, “It doesn’t”, “generates”)\n']","[-20, 90, 50]","[50, 80, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and the proposal is clearly explained, they express several concerns about key aspects that need to be addressed, particularly in the experiments. The reviewer points out multiple areas that require further analysis or explanation, and describes the experiments as 'inconclusive'. This indicates a generally critical stance, albeit with some positive elements.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They begin with a positive comment about the paper being well-written, which sets a courteous tone. The criticisms are presented as questions or suggestions for improvement rather than harsh judgments. Phrases like 'This needs to be analyzed very thoroughly' and 'Needs more explanation here' are constructive in nature. The reviewer maintains a neutral, academic tone without using any rude or overly negative language."", ""The sentiment score is 90 (highly positive) because the reviewer describes the paper as 'a very nice paper' and states that it 'clearly lays out the problem' and is 'an important contribution'. They also mention that the work is 'highly significant' and 'very well written'. The politeness score is 80 (quite polite) as the reviewer uses respectful and professional language throughout, offering praise and constructive feedback without any harsh criticism. They use phrases like 'Overall this is a very nice paper' and 'Ideas/Reasons are clearly presented', which contribute to a polite tone. The reviewer maintains a balanced and objective stance while highlighting the paper's strengths."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses appreciation for the thoroughness and clarity of the paper, but also points out significant concerns about the experimental impact and lack of clear advantages in the results. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language, constructive criticism, and positive acknowledgments throughout. They use phrases like 'I really like', 'it is a delight to see', and 'I salute the authors', while also providing detailed suggestions for improvement in a professional manner. The reviewer maintains a balanced and courteous tone even when discussing the 'painful part' of their critique.""]"
"['The paper proposed a novel regularizer that is to be applied to the (rectifier) discriminators in GAN in order to encourage a better allocation of the ""model capacity"" of the discriminators over the (potentially multi-modal) generated / real data points, which might in turn helps with learning a more faithful generator.\n\nThe paper is in general very well written, with intuitions and technical details well explained and empirical studies carefully designed and executed.\n\nSome detailed comments / questions:\n\n1. It seems the concept of ""binarized activation patterns"", which the proposed regularizer is designed upon, is closely coupled with rectifier nets. I would therefore suggest the authors to highlight this assumption / constraint more clearly e.g. in the abstract.\n\n2. In order for the paper to be more self-contained, maybe list at least once the formula for ""rectifier net"" (sth. like ""a^T max(0, wx + b) + c"") ? This might also help the readers better understand where the polytopes in Figure 1 come from.\n\n3. In section 3.1, when presenting random variables (U_1, ..., U_d), I find the word ""Bernourlli"" a bit misleading because typically people would expect U_i to take values from {0, 1} whereas here you assume {-1, +1}. This can be made clear with just one sentence yet would greatly help with clearing away confusions for subsequent derivations.\nAlso, ""K"" is already used to denote the mini-batch size, so it\'s a slight abuse to reuse ""k"" to denote the ""kth marginal"".\n\n4. In section 3.2, it may be clearer to explicitly point out the use of the ""3-sigma"" rule for Gaussian distributions here. But I don\'t find it justified anywhere why ""leave 99.7% of i, j pairs unpenalized"" is sth. to be sought for here?\n\n5. In section 3.3, when presenting Corollary 3.3 of Gavinsky & Pudlak (2015), ""n"" abruptly appears without proper introduction / context.\n\n6. For the empirical study with 2D MoG, would an imbalanced mixture make it harder for the BRE-regularized GAN to escape from modal collapse?\n\n7. Figure 3 is missing the sub-labels (a), (b), (c), (d).', 'The paper proposes a regularizer that encourages a GAN discriminator to focus its capacity in the region around the manifolds of real and generated data points, even when it would be easy to discriminate between these manifolds using only a fraction of its capacity, so that the discriminator provides a more informative signal to the generator. The regularizer rewards high entropy in the signs of discriminator activations. Experiments show that this helps to prevent mode collapse on synthetic Gaussian mixture data and improves Inception scores on CIFAR10. \n\nThe high-level idea of guiding model capacity by rewarding high-entropy activations  is interesting and novel to my knowledge (though I am not an expert in this space). Figure `1 is a fantastic illustration that presents the core idea very clearly. That said I found the intuitive story a little bit difficult to follow -- it\'s true that in Figure 1b the discriminator won\'t communicate the detailed structure of the data manifold to the generator, but it\'s not clear why this would be a problem -- the gradients should still pull the generator *towards* the manifold of real data, and as this happens and the manifolds begin to overlap, the discriminator will naturally be forced to allocate its capacity towards finer-grained details. Is the implicit assumption that for real, high-dimensional data the generator and data manifolds will *never* overlap? But in that case much of the theoretical story goes out the window. I\'d also appreciate further discussion of the relationship of this approach to Wasserstein GANs, which also attempt to provide a clearer training gradient when the data and generator manifolds do not overlap.\n\nMore generally I\'d like to better understand what effect we\'d expect this regularizer to have. It appears to be motivated by improving training dynamics, which is understandably a significant concern. Does it also change the location of the Nash equilibria? (or equivalently, the optimal generator under the density-ratio-estimator interpretation of discriminators proposed by https://arxiv.org/abs/1610.03483). I\'d expect that it would but the effects of this changed objective are not discussed in the paper. \n\n The experimental results seem promising, although not earthshattering. I would have appreciated a comparison to other methods for guiding discriminator representation capacity, e.g. autoencoding (I\'d also imagine that learning an inference network (e.g. BiGAN) might serve as a useful auxiliary task?). \n\nOverall this feels like an cute hack, supported by plausible intuition but without deep theory or compelling results on real tasks (yet). As such I\'d rate it as borderline; though perhaps interesting enough to be worth presenting and discussing.\n\nA final note: this paper was difficult to read due to many grammatical errors and unclear or misleading constructions, as well as missing citations (e.g. sec 2.1). From the second paragraph alone:\n""impede their wider applications in new data domain"" -> domains\n""extreme collapse and heavily oscillation"" -> heavy oscillation\n""modes of real data distribution"" -> modes of the real data distribution\n""while D fails to exploit the failure to provide better training signal to G"" -> should be ""this failure"" to refer to the previously-described generator mode collapse, or rewrite entirely\n""even when they are their Jensen-Shannon divergence"" -> even when their Jensen-Shannon divergence\n I\'m sympathetic to the authors who are presumably non-native English speakers; many good papers contain mistakes, but in my opinion the level in this paper goes beyond what is appropriate for published work. I encourage the authors to have the work proofread by a native speaker; clearer writing will ultimately increase the reach and impact of the paper.  \n', ""The paper presents a method for improving the diversity of Generative Adversarial Network (GAN) by promoting the Gnet's weights to be as informative as possible. This is achieved by penalizing the correlation between responses of hidden nodes and promoting low entropy intra node. Numerical experiments that demonstrate the diversity increment on the generated samples are shown.\n\nConcerns.\n\nThe paper is hard do tear and it is deficit to identify the precise contribution of the authors. Such contribution can, in my opinion, be summarized  in a potential of the form\n\nwith\n\n$$\nR_BRE = a R_ME+ b R_AC = a \\sum_k  \\sum_i s_{ki}^2   +  b \\sum_{<k,l>} \\sum_i \\{ s_{ki} s_{li} \\}   \n$$\n(Note that my version of R_ME is different to the one proposed by the authors, but it could have the same effect)\n\nWhere a and b are parameters that weight the relative contribution of each term  (maybe computed as suggested in the paper).\n\nIn this formulation:\n\nThen R_ME has a high response if the node has saturated responses -1’s or 1``s, as one desire such saturated responses, a should be negative.\n\nThe R_AC, penalizes correlation between responses of different nodes.\n\nThe point is, \n\na) The second term will introduce  low correlation in saturated vectors, then the will be informative. \n \nb) why the authors use the softsign instead the tanh:  $tahnh \\in C^2 $! Meanwhile the derivative id softsign is discontinuous.\n\nc)  It is not clear is the softsign is used besides the activation function: In page 5 is said “R_BRE can be applied on ant rectified layer before the nolinearity” . This seems tt the authors propose to add a second activation function (the softsign), why not use the one is in teh layer?\n\nd) The authors found hard to regularize the gradient $\\nabla_x D(x)$, even they tray tanh and cosine based activations. It seems that effectively, the  introduce their additional softsign in the process.\n\ne) En the definition of R_AC, I denoted by <k,l> the pair of nodes (k \\ne l). However, I think that it should be for pair in the same layer. It is not clear in the paper.\n\nf) It is supposed that the L_1 regularization motes the weights to be informative, this work is doing something similar. How is it compared  the L_1 regularization vs. the proposal?\n\nRecommendation\nI tried to read the paper several times and I accept that it was very hard to me. The most difficult part is the lack of precision on the maths, it is hard to figure out what the authors contribution indeed are. I think there is some merit in the work. However, it is not very well organized and many points are not defined. In my opinion, the paper is in a preliminary stage and should be refined. I recommend a “SOFT” REJECT\n""]","[80, -20, -60]","[90, 50, 20]","[""The sentiment score is 80 (positive) because the reviewer starts by praising the paper as 'very well written' with 'intuitions and technical details well explained' and 'empirical studies carefully designed and executed.' This indicates a highly positive view of the paper. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, offering suggestions rather than demands (e.g., 'I would therefore suggest,' 'maybe list,' 'it may be clearer'). The reviewer also frames criticisms as questions or gentle observations, maintaining a courteous tone. The high scores are not 100 because there is still room for improvement, and the review does contain some critical feedback, albeit presented very politely."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting and novel', 'fantastic illustration', 'promising' results), they also express significant reservations. They describe it as a 'cute hack' with 'plausible intuition but without deep theory or compelling results', and rate it as 'borderline'. The overall tone suggests more criticism than praise.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and express sympathy for non-native English speakers. However, the criticism of the paper's writing quality, while valid, is quite direct, which slightly reduces the politeness score. The reviewer balances critique with positive feedback and uses phrases like 'I'd appreciate' and 'I encourage' which contribute to a polite tone."", ""The sentiment score is -60 because the reviewer expresses several concerns and recommends a 'SOFT REJECT'. The overall tone is critical, pointing out multiple issues with the paper's clarity and organization. However, it's not entirely negative as the reviewer acknowledges 'some merit in the work'. The politeness score is 20 because while the reviewer is critical, they use professional language and avoid harsh or rude expressions. They attempt to be constructive by offering specific points for improvement and explaining their reasoning. The reviewer also admits their own difficulty in understanding the paper, which shows a degree of humility. However, phrases like 'The paper is hard to tear' and 'deficit to identify' (likely meant to be 'difficult to identify') slightly reduce the politeness score.""]"
"['The paper proposed a generalized HMC by modifying the leapfrog integrator using neural networks to make the sampler to converge and mix quickly. Mixing is one of the most challenge problems for a MCMC sampler, particularly when there are many modes in a distribution. The derivations look correct to me. In the experiments, the proposed algorithm was compared to other methods, e.g., A-NICE-MC and HMC. It showed that the proposed method could mix between the modes in the posterior. Although the method could mix well when applied to those particular experiments, it lacks theoretical justifications why the method could mix well. ', 'In this work, the authors propose a procedure for tuning the parameters of an HMC algorithm (I guess, if I have understood correctly).\n\nI think this paper has a good and strong point: this work points out the difficulties in choosing properly the parameters in a HMC method (such as the step and the number of iterations in the leapfrog integrator, for instance). In the literature, specially in machine learning, there is ``fever’’ about HMC, in my opinion, partially unjustified.\n\nIf I have understood, your method is an adaptive HMC algorithm  where the parameters are updated online; or is the training  done in advance? Please, remark and clarify this point.\n\nHowever, I have other additional comments:\n\n- Eqs. (4) and (5) are quite complicated; I think a running toy example can help the interested reader.\n\n- I suggest to compare the proposed method to other efficient methods that do not use the gradient information (in some cases as multimodal posteriors, the use of the gradient information can be counter-productive for sampling purposes), such as Multiple Try Metropolis (MTM) schemes\n\nL. Martino, J. Read, On the flexibility of the design of Multiple Try Metropolis schemes, Computational Statistics, Volume 28, Issue 6, Pages: 2797-2823, 2013, \n\nadaptive techniques, \n\nH. Haario, E. Saksman, and J. Tamminen. An adaptive Metropolis algorithm. Bernoulli, 7(2):223–242, April 2001,\n\nand component-wise strategies as Gibbs Sampling, \n\nW. R. Gilks and P. Wild, Adaptive rejection sampling for Gibbs sampling, Appl. Statist., vol. 41, no. 2, pp. 337–348, 199.\u2028\n\nAt least, add a brief paragraph in the introduction citing and discussing this possible alternatives.', 'The paper introduces a non-volume-preserving generalization of HMC whose transitions are determined by a set of neural network functions. These functions are trained to maximize expected squared jump distance.\nThis works because each variable (of the state space) is modified in turn, so that the resulting update is invertible, with a tractable transformation inspired by Dinh et al 2016.\n\nOverall, I believe this paper is of good quality, clearly and carefully written, and potentially accelerates mixing in a state-of-the-art MCMC method, HMC, in many practical cases. A few downsides are commented on below.\n\nThe experimental section proves the usefulness of the method on a range of relevant test cases; in addition, an application to a latent variable model is provided sec5.2. \nFig 1a presents results in terms of numbers of gradient evaluations, but I couldn\'t find much in the way of computational cost of L2HMC in the paper. I can\'t see where the number ""124x"" in sec 5.1 stems from. As a user, I would be interested in the typical computational cost of both ""MCMC sampler training"" and MCMC sampler usage (inference?), compared to competing methods. This is admittedly hard to quantify objectively, but just an order of magnitude would be helpful for orientation. \nWould it be relevant, in sec5.1, to compare to other methods than just HMC, eg LAHMC?\n\nI am missing an intuition for several things: eq7, the time encoding defined in Appendix C\n\nAppendix Fig5, I cannot quite see how the caption claim is supported by the figure (just hardly for VAE, but not for HMC).\n\nThe number ""124x ESS"" in sec5.1 seems at odds with the number in the abstract, ""50x"".\n\n# Minor errors\n- sec1: ""The sampler is trained to minimize a variation"": should be maximize\n""as well as on a the real-world""\n- sec3.2 ""and 1/2 v^T v the kinetic"": ""energy"" missing\n- sec4: the acronym L2HMC is not expanded anywhere in the paper\nThe sentence ""We will denote the complete augmented...p(d)"" might be moved to after ""from a uniform distribution"" in the same paragraph. \nIn paragraph starting ""We now update x"":\n    - specify for clarity: ""the first update, which yields x\' ""/ ""the second update, which yields x\'\'  ""\n    - ""only affects $x_{\\bar{m}^t}$"": should be $x\'_{\\bar{m}^t}$  (prime missing)\n    - the syntax using subscript m^t is confusing to read; wouldn\'t it be clearer to write this as a function, eg ""mask(x\',m^t)""?\n    - inside zeta_2 and zeta_3, do you not mean $m^t"" and $\\bar{m}^t$ ?\n- sec5: add reference for first mention of ""A NICE MC""\n- Appendix A: \n    - ""Let\'s"" -> ""Let""\n    - eq12 should be x\'\'=...\n- Appendix C: space missing after ""Section 5.1""\n- Appendix D1: ""In this section is presented"" : sounds odd\n- Appendix D3: presumably this should consist of the figure 5 ? Maybe specify.']","[50, 20, 60]","[0, 60, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contribution to addressing a challenging problem in MCMC sampling and notes that the derivations appear correct. The reviewer also mentions positive experimental results showing the method's ability to mix between modes. However, the score is not higher due to the criticism about lacking theoretical justifications. The politeness score is 0 (neutral) because the language is professional and objective, without being particularly polite or rude. The reviewer presents both positive aspects and criticisms in a straightforward manner without using overly courteous or harsh language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges a 'good and strong point' in the paper, but also raises several concerns and suggestions for improvement. The overall tone is constructive rather than overtly critical. The politeness score is moderately high (60) as the reviewer uses polite language throughout, such as 'I think,' 'I suggest,' and 'Please, remark and clarify this point.' The reviewer also provides helpful suggestions and references, which is a courteous way to offer criticism. The language is professional and respectful, avoiding any harsh or rude phrasing."", ""The sentiment score is 60 (positive) because the reviewer states that the paper is 'of good quality, clearly and carefully written, and potentially accelerates mixing in a state-of-the-art MCMC method'. They also mention that the experimental section 'proves the usefulness of the method'. However, the score is not higher because the reviewer also points out some downsides and areas for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, such as 'I believe' and 'I am missing an intuition', and provides constructive feedback. They also acknowledge the difficulty in quantifying certain aspects. The reviewer maintains a professional tone even when pointing out errors, using phrases like 'Minor errors' instead of harsh criticism. The overall tone is supportive and aimed at improving the paper rather than being overly critical.""]"
"['The paper is interesting to read and gives valuable insights. \n\nHowever, the paper clearly breaks the submission guidelines. The paper is far too long, 14 pages (+refs and appendix, in total 19 pages), while the page limit is 8 pages (+refs and appendix). Therefore, the paper should be rejected. I can not foresee how the authors should be able to squeeze to content into 8 pages. The paper is more suitable for a journal, where page limit is less of an issue.', ""The authors propose a variant of the neural programmer-interpreter that can support so called combinators for composing an d structuring computations. In a sense, programs in this variant are at a higher level than those in the original neural programmer-interpreter. The distinguishing aspect of the neural programmer-interpreter is that it learns a generic core (which in the variant of the paper corresponds to an interpreter of the programming language) and programs for concrete tasks simultaneously. Increasing the expressivity of the language with combinators has a danger of making the training of core very difficult. The authors avoids this pitfall by carefully re-designing the deterministic part of the core. For instance, they separate out the evaluation of the detector from the LSTM used for the core. Also, they use a fixed routine for parsing the applier instruction. The authors describe two ways of training their variant of the neural programmer-interpreter. The first is similar to the existing methods, and trains the variant using traces. The second is different and trains the variant using just input-output pairs but under carefully designed curriculum. The authors experimentally show that their approach leads to a more stable core of the neural programmer-interpreter that is close to being universal, in the sense that the core knows how to interpret commands.\n\nI found the new architecture of the neural programmer-interpreter very interesting. It is carefully crafted so as to support expressive combinators without making the learning more difficult. I can't quite judge how strong their experimental evaluations are, but I think that learning a neural programmer-interpreter from just input-output pairs using RL techniques is new and worth being pursued further. I am generally positive about accepting this paper to ICLR'18.\n\nI have three complaints, though. First, the paper uses 14 pages well over 8 pages, the recommended limit. Second, it has many typos. Third, the authors claim universality of the approach. When I read this claim, I expected a theorem initially but later I realized that the claim was mostly about informal understanding and got disappointed slightly. I hope that the authors consider these complaints when they revise the paper.\n\n* abstract, p1: is is universal -> is universal\n* p2: may still intractable to provable -> may still be intractable to prove\n* p2: import abstraction -> important abstraction\n* p2: a_(t+1)are -> a_(t+1) are\n* p2: Algorithm 1 The -> Algorithm 1. The\n* Algorithm1, p3: f_lstm(c,p,h) -> f_lstm(s,p,h)\n* p3: learn to interpreting -> learn to interpret\n* p3: it it common -> it is common\n* p3: The two program share -> The two programs share\n* p3: that server as -> that serve as\n* p3: be interpret by -> be interpreted by\n* p3: (le 9 in our -> (<= 9 in our\n* Figure 1, p4: the type of linrec is wrong.\n* p6: f_d et -> f_det\n* p8: it+1 -> i_(t+1)\n* p8: detector. the -> detector. The\n* p9: As I mentioned, I suggest you to make clear that the claim about universality is mostly based on intuition, not on theorem.\n* p9: to to -> to\n* p10: the the set -> the set\n* p11: What are DETs?"", 'Quality\nThe paper is very interesting and clearly motivated. The idea of importing concepts from functional programming into neural programming looks very promising, helping to address a bit the somewhat naive approach taken so far in the deep learning community towards program induction. However, I found the model description difficult to fully understand and have significant unresolved questions - especially *why* exactly the model should be expected to have better universality compared to NPI and RNPI, given than applier memory is unbounded just like NPI/RNPI program memories are unbounded.\n\nClarity\nThe paper does a good job of summarizing NPI and motivating the universality property of the core module. \n\nI had a lot of questions while reading:\n\nWhat is the purpose of detectors? It is not clear what is being detected. From the context it seems to be encoding observations from the environment, which can vary according to the task and change during program execution. The detector memory is also confusing. In the original NPI, it is assumed that the caller knows which encoder is needed for each program. In CNPI, is this part learned or more general in some way?\n\nAppliers - is it the case that *every* program apart from the four combinators must be written as an applier? For example ADD1, BSTEP, BUBBLESORT, etc all must be implemented as an applier, and programs that cannot be implemented as appliers are not expressible by CNPI?\n\nMemory - combinator memory looks like a 4-way softmax over the four combinators, right? The previous NPI program memory is analogous then to the applier memory.\n\nEqn 3 - binarizing the detector output introduces a non-differentiable operation. How is the detector then trained e.g. from execution traces? Later I see that there is a notion of a “correct condition” for the detector to regress on, which makes me confused again about what exactly the output of a detector means.\n\nComputing the next subprogram - since the size of applier memory is unbounded, the core still needs to be aware of an unlimited number of subprograms. I must be missing something here - how does the proposed model therefore achieve better universality than the original NPI and RNPI models?\n\nAnalysis - for the claim of perfect generalization, I think this will not generally hold true for perceptual inputs. Will the proposed model only be useful in discrete domains for algorithmic tasks, or could it be more broadly applicable, e.g. to robotics tasks?\n\nOriginality\nThis methods proposed in this paper are quite novel and start to bridge an important gap between neural program induction and functional programming, by importing the concept of combinator abstraction into NPI.\n\nSignificance\nThe paper will be significant to people interested in NPI-related models and neural program induction generally, but on the other hand, there is currently not yet a “killer application” to this line of work. \n\nThe experiments appear to show significant new capabilities of CNPI compared to NPI and RNPI in terms of better generalization and universality, as well as being trainable by reinforcement learning.\n\nPros\n- Learns new programs without catastrophic forgetting in the NPI core, in particular where previous NPI models fail.\n- Detector training is decoupled from core and memory training, so that perfect generalization does not have to be re-verified after learning new behaviors.\n\nCons\n- So far lacking useful applications in the real world. Could the techniques in this paper help in robotics extensions to NPI? (see e.g. https://arxiv.org/abs/1710.01813)\n- Adds a significant amount of further structure into the NPI framework, which could potentially make broader applications more complex to implement. Do the proposed modifications reduce generality in any way?\n']","[-50, 70, 50]","[50, 60, 75]","[""The sentiment score is -50 because while the reviewer initially praises the paper as 'interesting' and 'valuable', they ultimately recommend rejection due to the paper's excessive length. This creates a mixed but overall negative sentiment. The politeness score is 50 because the reviewer uses polite language throughout, starting with positive comments and explaining the reason for rejection clearly without harsh criticism. However, the directness of the rejection prevents a higher politeness score. The reviewer maintains a professional tone, balancing critique with recognition of the paper's merits."", ""The sentiment score is 70 (positive) because the reviewer expresses strong interest in the paper's approach, stating it is 'very interesting' and 'worth being pursued further'. They are 'generally positive about accepting this paper'. However, they do have some complaints, which prevents a higher score. The politeness score is 60 (somewhat polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively. They frame their criticisms constructively, using phrases like 'I hope that the authors consider these complaints'. However, the directness of some comments (e.g., 'it has many typos') and the extensive list of corrections slightly reduce the politeness score. The review maintains a professional tone throughout, balancing praise with constructive criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by praising the paper as 'very interesting and clearly motivated' and mentions that the idea is 'very promising'. However, they also express significant concerns and unresolved questions, which balances out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while framing criticisms as questions or areas for clarification rather than direct attacks. They use phrases like 'I found... difficult to fully understand' instead of more aggressive language, and provide a balanced view of pros and cons.""]"
"['The main strength of this paper, I think, is the theoretical result in Theorem 1. This result is quite nice. I wish the authors actually concluded with the following minor improvement to the proof that actually strengthens the result further.\n\nThe authors ended the discussion on thm 1 on page 7 (just above Sec 2.3) by saying what is sufficiently close to w*. If one goes back to (10), it is easy to see that what converges to w* when one of three things happen (assuming beta is fixed once loss L is selected).\n\n1) k goes to infinity\n2) alpha goes to 1\n3) g(w*) goes to 0\n\nThe authors discussed how alpha is close to 1 by virtue of submodular optimization lower bounds there for what is close to w*. In fact this proof shows the situation is much better than that. \n\nIf we are really concerned about making what converge to w*, and if we are willing to tolerate the increasing computational complexity associated solving submodular problems with larger k, we can schedule k to increase over time which guarantees that both alpha goes to 1 and g(w*) goes to zero. \n\nThere is also a remark that G(A) tends to be modular when lambda is small which is useful.\nFrom the algorithm, it seems clear that the authors recognized these two useful aspects of the objective and scheduled lambda to decrease exponentially and k to increase linearly.\n\nIt would be really nice to complete the analysis of Thm1 with a formal analysis of convergence speed for ||what-w*|| as lambda and k are scheduled in this fashion. Such an analysis would help practitioners make better choices for the hyper parameters gamma and Delta.', 'This paper introduces MiniMax Curriculum learning, as an approach for adaptively train models by providing it different subsets of data. The authors formulate the learning problem as a minimax problem which tries to choose diverse example and ""hard"" examples, where the diversity is captured via a Submodular Loss function and the hardness is captured via the Loss function. The authors formulate the problem as an iterative technique which involves solving a minimax objective at every iteration. The authors argue the convergence results on the minimax objective subproblem, but do not seem to give results on the general problem. The ideas for this paper are built on existing work in Curriculum learning, which attempts to provide the learner easy examples followed by harder examples later on. The belief is that this learning style mimics human learners.\n\nPros:\n- The analysis of the minimax objective is novel and the proof technique introduces several interesting ideas.\n- This is a very interesting application of joint convex and submodular optimization, and uses properties of both to show the final convergence results\n- Even through the submodular objective is only approximately solvable, it still translates into a convergence result\n- The experimental results seem to be complete for the most part. They argue how the submodular optimization does not really affect the performance and diversity seems to empirically bring improvement on the datasets tried.\n\nCons:\n- The main algorithm MCL is only a hueristic. Though the MiniMax subproblem can converge, the authors use this in somewhat of a hueristic manner.\n- It seems somewhat hand wavy in the way the authors describe the hyper parameters of MCL, and it seems unclear when the algorithm converge and how to increase/decrease it over iterations\n- The objective function also seems somewhat non-intuitive. Though the experimental results seem to indicate that the idea works, I think the paper does not motivate the loss function and the algorithm well.\n- It seems to me the authors have experimented with smaller datasets (CIFAR, MNIST, 20NewsGroups). This being mainly an empirical paper, I would have expected results on a few larger datasets (e.g. ImageNet, CelebFaces etc.), particularly to see if the idea also scales to these more real world larger datasets.\n\nOverall, I would like to see if the paper could have been stronger empirically. Nevertheless, I do think there are some interesting ideas theoretically and algorithmically. For this reason, I vote for a borderline accept. ', 'Overview:\nThis paper proposes an approach to curriculum learning, where subsets of examples to train on are chosen during the training process. The proposed method is based on a submodular set function over the examples, which is intended to capture diversity of the included examples and is added to the training objective (eq. 2). The set is optimized to be as hard as possible (maximize loss), which results in a min-max problem. This is in turn optimized (approximately) by alternating between gradient-based loss minimization and submodular maximization. The theoretical analysis shows that if the loss is strongly convex, then the algorithm returns a solution which is close to the optimal solution. Empirical results are presented for several benchmarks.\nThe paper is mostly clear and the idea seems nice. On the downside, there are some limitations to the theoretical analysis and optimization scheme (see comments below).\n\nComments:\n- The theoretical result (thm. 1) studies the case of full optimization, which is different than the proposed algorithm (running a fixed number of weight updates). It would be interesting to show results on sensitivity to the number of updates (p).\n- The algorithm requires tuning of quite a few hyperparameters (sec. 3).\n- Approximating a cluster with a single sample (sec. 2.3) seems rather crude. There should be some theoretical and/or empirical study of its effect on quality of the solution.\n\nMinor/typos:\n- what is G(j|G\\j) in eq. (9)?\n- why cite Anonymous (2018) instead of Appendix...?\n- define V in Thm. 1.\n- in eq. (4) it may be clearer to denote g_k(w). Likewise in eq. (6) \\hat{g}_\\hat{A}(w), and in eq. (14) \\tilde{g}_{\\cal{A}}(w).\n- figures readability can be improved.']","[70, 20, 20]","[60, 60, 60]","[""The sentiment score is 70 (positive) because the reviewer starts by highlighting the main strength of the paper, praising the theoretical result in Theorem 1 as 'quite nice'. The reviewer then offers constructive suggestions to improve and extend the analysis, indicating a generally positive view of the work. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, such as 'I wish the authors' and 'It would be really nice', while offering suggestions. The tone is professional and constructive, without any harsh criticism. The reviewer also acknowledges the authors' efforts and insights, which contributes to the polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some pros of the paper, such as novel analysis and interesting ideas, while also noting several cons. The overall recommendation is a 'borderline accept', indicating a slightly positive sentiment. The politeness score is moderately high (60) as the reviewer uses professional and respectful language throughout, presenting both pros and cons in a balanced manner without using harsh or critical tones. The reviewer acknowledges the paper's strengths and provides constructive feedback for improvement, maintaining a polite and academic tone throughout the review."", ""The sentiment score is slightly positive (20) because the reviewer starts by acknowledging that the paper is 'mostly clear and the idea seems nice,' which indicates a generally favorable view. However, they also mention some limitations, which prevents the score from being higher. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'it would be interesting' and 'there should be' rather than more demanding language. The reviewer also provides helpful suggestions for improvements and points out minor typos in a neutral tone, which contributes to the polite impression.""]"
"['MAML (Finn+ 2017) is recast as a hierarchical Bayesian learning procedure. In particular the inner (task) training is initially cast as point-wise max likelihood estimation, and then (sec4) improved upon by making use of the Laplace approximation. Experimental evidence of the relevance of the method is provided on a toy task involving a NIW prior of Gaussians, and the (benchmark) MiniImageNet task.\n\nCasting MAML as HB seems a good idea. The paper does a good job of explaining the connection, but I think the presentation could be clarified. The role of the task prior and how it emerges from early stopping (ie a finite number of gradient descent steps) (sec 3.2) is original and technically non-trivial, and is a contribution of this paper. \nThe synthetic data experiment sec5.1 and fig5 is clearly explained and serves to additionally clarify the proposed method. \nRegarding the MiniImageNet experiments, I read the exchange on TCML and agree with the authors of the paper under review. However, I recommend including the references to Mukhdalai 2017 and Sung 2017 in the footnote on TCML to strengthen the point more generically, and show that not just TCML but other non-shallow architectures are not considered for comparison here. In addition, the point made by the TCML authors is fair (""nothing prevented you from..."") and I would also recommend mentioning the reviewed paper\'s authors\' decision (not to test deeper architectures) in the footnote. This decision is in order but needs to be stated in order for the reader to form a balanced view of methods at her disposal.\nThe experimental performance reported Table 1 remains small and largely within one standard deviation of competitor methods.\n\nI am assessing this paper as ""7"" because despite the merit of the paper, the relevance of the reformulation of MAML, and the technical steps involved in the reformulation, the paper does not eg address other forms (than L-MAML) of the task-specific subroutine ML-..., and the benchmark improvements are quite small. I think the approach is good and fruitful. \n\n\n# Suggestions on readability\n\n* I have the feeling the paper inverts $\\alpha, \\beta$ from their use in Finn 2017 (step size for meta- vs task-training). This is unfortunate and will certainly confuse readers; I advise carefully changing this throughout the entire paper (eg Algo 2,3,4, eq 1, last eq in sec3.1, eq in text below eq3, etc)\n\n* I advise avoiding the use of the symbol f, which appears in only two places in Algo 2 and the end of sec 3.1. This is in part because f is given another meaning in Finn 2017, but also out of general parsimony in symbol use. (could leave the output of ML-... implicit by writing ML-...(\\theta, T)_j in the $sum_j$; if absolutely needed, use another symbol than f)\n\n* Maybe sec3 can be clarified in its structure by re-ordering points on the quadratic error function and early stopping (eg avoiding to split them between end of 3.1 and 3.2).\n\n* sec6 ""Machine learning and deep learning"": I would definitely avoid this formulation, seems to tail in with all the media nonsense on ""what\'s the difference between ML and DL ?"". In addition the formulation seems to contrast ML with hierarchical Bayesian modeling, which does not make sense/ is wrong and confusing.\n\n# Typos\n\n* sec1 second parag: did you really mean ""in the architecture or loss function""? unclear.\n* sec2: over a family\n* ""common structure, so that"" (not such that)\n* orthgonal\n* sec2.1 suggestion: clarify that \\theta and \\phi are in the same space\n* sec2.2 suggestion: task-specific parameter $\\phi_j$ is distinct from ... parameters $\\phi_{j\'}, j\' \\neq j}\n* ""unless an approximate ... is provided"" (the use of the subjunctive here is definitely dated :-) )\n* sec3.1 task-specific parameters $\\phi_j$ (I would avoid writing just \\phi altogether to distinguish in usage from \\theta)\n* Gaussian-noised\n* approximation of the it objective\n* before eq9: ""that solves"": well, it doesn\'t really ""solve"" the minimisation, in that it is not a minimum; reformulate this?\n* sec4.1 innaccurate\n* well approximated\n* sec4.2 an curvature\n* (Amari 1989)\n* For the the Laplace\n* O(n^3) : what is n ?\n* sec5.2 (Ravi and L 2017)\n* for the the \n', 'The paper reformulates the model-agnostic meta-learning algorithm (MAML) in terms of inference for parameters of a prior distribution in a hierarchical Bayesian model. This provides an interesting and, as far as I can tell, novel view on MAML. The paper uses this view to improve the MAML algorithm. The writing of the paper is excellent. Experimental evalution is well done against a number of recently developed alternative methods in favor of the presented method, except for TCML which has been exluded using a not so convincing argument. The overview of the literature is also very well done. ', 'Summary\nThe paper presents an interesting view on the recently proposed MAML formulation of meta-learning (Finn et al). The main contribution is a) insight into the connection between the MAML procedure and MAP estimation in an equivalent linear hierarchical Bayes model with explicit priors, b) insight into the connection between MAML and MAP estimation in non-linear HB models with implicit priors, c) based on these insights, the paper proposes a variant of MALM using a Laplace approximation (with additional approximations for the covariance matrix. The paper finally provides an evaluation on the mini ImageNet problem without significantly improving on the MAML results on the same task.\n\nPro:\n-            The topic is timely and of relevance to the ICLR community continuing a current trend in building meta-learning system for few-shot learning.\n-            Provides valuable insight into the MAML objective and its relation to probabilistic models\n\nCon:\n-            The paper is generally well-written but I find (as a non-meta-learner expert) that certain fundamental aspects could have been explained better or in more detail (see below for details).\n-            The toy example is quite difficult to interpret the first time around and does not provide any empirical insight into the converge of the proposed method (compared to e.g. MAML)\n-            I do not think the empirical results provide enough evidence that it is a useful/robust method. Especially it does not provide insight into which types of problems (small/large, linear/ non-linear) the method is applicable to. \n\n\nDetailed comments/questions:\n-            The use of Laplace approximation is (in the paper) motivated from a probabilistic/Bayes and uncertainty point-of-view. It would, however, seem that the truncated iterations do not result in the approximation being very accurate during optimization as the truncation does not result in the approximation being created at a mode. Could the authors perhaps comment on:\na) whether it is even meaningful to talk about the approximations as probabilistic distribution during the optimization (given the psd approximation to the Hessian), or does it only make sense after convergence? \nb) the consequence of the approximation errors on the general convergence of the proposed method (consistency and rate)\n\n-            Sec 4.1, p5: Last equation: Perhaps useful to explain the term $log(\\phi_j^* | \\theta)$ and why it is not in subroutine 4 . Should $\\phi^*$  be $\\hat \\phi$ ?\n-            Sec 4.2: “A straightforward…”: I think it would improve readability to refer back to the to the previous equation (i.e. H) such that it is clear what is meant by “straightforward”.\n-            Sec 4.2: Several ideas are being discussed in Sec 4.2 and it is not entirely clear to me what has actually been adopted here; perhaps consider formalizing the actual computations in Subroutine 4 – and provide a clearer argument (preferably proof) that this leads to consistent and robust estimator of \\theta.\n-            It is not clear from the text or experiment how the learning parameters are set.\n-            Sec 5.1: It took some effort to understand exactly what was going on in the example and particular figure 5.1; e.g., in the model definition in the body text there is no mention of the NN mentioned/used in figure 5, the blue points are not defined in the caption, the terminology e.g.  “pre-update density” is new at this point. I think it would benefit the readability to provide the reader with a bit more guidance.\n-            Sec 5.1: While the qualitative example is useful (with a bit more text), I believe it would have been more convincing with a quantitative example to demonstrate e.g. the convergence of the proposal compared to std MAML and possibly compare to a std Bayesian inference method from the HB formulation of the problem (in the linear case)\n-            Sec 5.2: The abstract clams increased performance over MAML but the empirical results do not seem to be significantly better than MAML ? I find it quite difficult to support the specific claim in the abstract from the results without adding a comment about the significance.\n-            Sec 5.2: The authors have left out “Mishral et al” from the comparison due to the model being significantly larger than others. Could the authors provide insight into why they did not use the ResNet structure from the  tcml paper in their L-MLMA scheme ?\n-            Sec 6+7: The paper clearly states that it is not the aim to (generally) formulate the MAML as a HB. Given the advancement in gradient based inference for HB the last couple of years (e.g. variational, nested laplace , expectation propagation etc) for explicit models, could the authors perhaps indicate why they believe their approach of looking directly to the MAML objective is more scalable/useful than trying to formulate the same or similar objective in an explicit HB model and using established inference methods from that area ?\n\nMinor:\n-            Sec 4.1 “…each integral in the sum in (2)…” eq 2 is a product\n']","[60, 80, 20]","[80, 70, 70]","[""The sentiment score is 60 (moderately positive) because the reviewer expresses that the paper has merit, describes the approach as 'good and fruitful', and praises aspects like the explanation of connections and the synthetic data experiment. However, they also point out limitations such as small performance improvements and not addressing other forms of the task-specific subroutine. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions positively (e.g. 'I advise', 'Maybe ... can be clarified'). They also acknowledge the authors' perspective on a point of contention. The reviewer maintains a professional tone even when pointing out typos and areas for improvement."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They describe the work as 'interesting' and 'novel', praise the 'excellent' writing and 'well done' experimental evaluation, and commend the 'very well done' literature overview. The only slight criticism is about excluding TCML with a 'not so convincing argument', which slightly reduces the otherwise highly positive sentiment. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They offer praise generously and frame their sole criticism in a mild manner ('not so convincing' rather than stronger negative language). The tone is consistently courteous and constructive, indicative of a polite academic review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting view and valuable insights, while also providing constructive criticism. The review starts with positive points ('Pro') before moving to criticisms ('Con'), indicating a balanced but generally favorable view. However, the score is not higher due to several concerns raised about the paper's clarity and empirical results. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, phrases criticisms constructively, and often uses hedging language (e.g., 'I find', 'I think', 'perhaps'). The reviewer also asks questions and invites the authors to provide more information or clarification, which is a polite way of pointing out potential issues.""]"
"['Motivated via Talor approximation of the Residual network on a local minima, this paper proposed a warp operator that can replace a block of a consecutive number of residual layers. While having the same number of parameters as the original residual network, the new operator has the property that the computation can be parallelized. As demonstrated in the paper, this improves the training time with multi-GPU parallelization, while maintaining similar performance on CIFAR-10 and CIFAR-100.\n\nOne thing that is currently not very clear to me is about the rotational symmetry. The paper mentioned rotated filters, but continue to talk about the rotation in the sense of an orthogonal matrix applying to the weight matrix of a convolution layer. The rotation of the filters (as 2D images or images with depth) seem to be quite different from ""rotating"" a general N-dim vectors in an abstract Euclidean space. It would be helpful to make the description here more explicit and clear.', 'Paper proposes a shallow model for approximating stacks of Resnet layers, based on mathematical approximations to the Resnet equations and experimental insights, and uses this technique to train Resnet-like models in half the time on CIFAR-10 and CIFAR-100. While the experiments are not particularly impressive, I liked the originality of this paper. ', 'The main contribution of this paper is a particular Taylor expansion of the outputs of a ResNet which is shown to be exact at almost all points in the input space.  This expression is used to develop a new layer called a “warp layer” which essentially tries to compute several layers of the residual network using the Taylor expansion expression — however in this expression, things can be done in parallel, and interestingly, the authors show that the gradients also decouple when the (ResNet) model is close to a local minimum in a certain sense, which may motivate the decoupling of layers to begin with.  Finally the authors stack these warp layers to create a “warped resnet” which they show does about as well as an ordinary ResNet but has better parallelization properties.\n\nTo me the analytical parts of the paper are the most interesting, particularly in showing how the gradients approximately decouple.  However there are several weaknesses to the paper (or maybe just things I didn’t understand).  First,  a major part of the paper tries to make the case that there is a symmetry breaking property of the proposed model, which I am afraid I simply was not able to follow.  Some of the notation is confusing here — for example, presumably the rotations refer to image level rotations rather than literally multiplying the inputs by an orthogonal matrix, which the notation suggests to be the case.  It is also never precisely spelled out what the final theoretical guarantee is (preferably the authors would do this in the form of a proposition or theorem).\n\nThroughout, the authors write out equations as if the weights in all layers are equal, but this is confusing even if the authors say that this is what they are doing, since their explanation is not very clear.  The confusion is particularly acute in places where derivatives are taken, because the derivatives continue to be taken as if the weights were untied, but then written as if they happened to be the same.\n\nFinally the experimental results are okay but perhaps a bit preliminary.  I have a few recommendations here:\n* It would be stronger to evaluate results on a larger dataset like ILSVRC.  \n* The relative speed-up of WarpNet compared to ResNet needs to be better explained — the authors break the computation of the WarpNet onto two GPUs, but it’s not clear if they do this for the (vanilla) ResNet as well.  In batch mode, the easiest way to parallelize is to have each GPU evaluate half the batch.  Even in a streaming mode where images need to be evaluated one by one, there are ways to pipeline execution of the residual blocks, and I do not see any discussion of these alternatives in the paper.\n* In the experimental results, K is set to be 2, and the authors only mention in passing that they have tried larger K in the conclusion.  It would be good to have a more thorough experimental evaluation of the trade-offs of setting K to be higher values.\n\nA few remaining questions for the authors:\n* There is a parallel submission (presumably by different authors called “Residual Connections Encourage Iterative Inference”) which contains some related insights.  I wonder what are the differences between the two Taylor expansions, and whether the insights of this paper could be used to help the other paper and vice versa?\n* On implementation - the authors mention using Tensorflow’s auto-differentiation.  My question here is — are gradients being re-used intelligently as suggested in Section 3.1?  \n* I notice that the analysis about the vanishing Hessian could be applied to most of the popular neural network architectures available now.  How much of the ideas offered in this paper would then generalize to non-resnet settings?\n\n']","[60, 50, 20]","[70, 0, 60]","[""The sentiment score is 60 (positive) because the reviewer begins by acknowledging the paper's motivation and innovation, highlighting its benefits in terms of improved training time and maintained performance. The reviewer also provides constructive feedback, indicating engagement with the paper's content. The politeness score is 70 (polite) due to the respectful tone throughout the review. The reviewer uses phrases like 'as demonstrated in the paper' and 'it would be helpful,' which show consideration for the authors' work. The critique is presented as a request for clarification rather than a harsh criticism. The reviewer's language is professional and focused on improving the paper, without any rude or dismissive comments."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses appreciation for the originality of the paper ('I liked the originality of this paper'), despite noting that the experiments are not particularly impressive. This indicates a mixed but overall positive sentiment. The politeness score is 0 (neutral) because the language used is straightforward and professional, without being notably polite or impolite. The reviewer provides a balanced assessment, acknowledging both strengths and limitations of the paper without using overly courteous or harsh language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting analytical parts of the paper, particularly the gradient decoupling. However, they also point out several weaknesses and areas for improvement, balancing the positive aspects. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'To me...', 'I am afraid I simply was not able to follow'), and offers specific recommendations for improvement. The reviewer also asks thoughtful questions at the end, showing engagement with the work. The tone is professional and courteous, avoiding harsh or dismissive language even when pointing out flaws.""]"
"['The paper uses a lesser-known interpretation of the gradient step of a composite function (i.e., via reverse mode automatic differentiation or backpropagation), and then replaces one of the steps with a proximal step. The proximal step requries the solution of a positive-definite linear system, so it is approximated using a few iterations of CG. The paper provides theory to show that their proximal variant (even with the CG approximations) can lead to convergent algorithms (and since practical algorithms are not necessarily globally convergent, most of the theory shows that the proximal variant has similar guarantees to a standard gradient step).\n\nOn reading the abstract and knowing quite a bit about proximal methods, I was initially skeptical, but I think the authors have done a good job of making their case. It is a well-written, very clear paper, and it has a good understanding of the literature, and does not overstate the results. The experiments are serious, and done using standard state-of-the-art tools and architectures. Overall, it is an interesting idea, and due to the current focus on neural nets, it is of interest even though it is not yet providing substantial improvements.\n\nThe main drawback of this paper is that there is no theory to suggest the ProxProp algorithm has better worst-case convergence guarantees, and that the experiments do not show a consistent benefit (in terms of time) of the method. On the one hand, I somewhat agree with the authors that ""while the running time is higher... we expect that it can be improved through further engineering efforts"", but on the other hand, the idea of nested algorithms (""matrix-free"" or ""truncated Newton"") always has this issue. A very similar type of ideas comes up in constrained or proximal quasi-Newton methods, and I have seen many papers (or paper submissions) on this style of method (e.g., see the 2017 SIAM Review paper on FWI by Metivier et al. at https://doi.org/10.1137/16M1093239). In every case, the answer seems to be that it can work on *some problems* and for a few well chosen parameters, so I don\'t yet buy that ProxProp is going to make a huge savings on a wide-range of problems.\n\nIn brief: quality is high, clarity is high, originality is high, and significance is medium.\nPros: interesting idea, relevant theory provided, high-quality experiments\nCons: no evidence that this is a ""break-through"" idea\n\nMinor comments:\n\n- Theorems seemed reasonable and I have no reason to doubt their accuracy\n\n- No typos at all, which I find very unusual. Nice job!\n\n- In Algo 1, it would help to be more explicit about the updates (a), (b), (c), e.g., for (a), give a reference to eq (8), and for (b), reference equations (9,10).  It\'s nice to have it very clear, since ""gradient step"" doesn\'t make it clear what the stepsize is, and if this is done in a ""Jacob-like"" or ""Gauss-Seidel-like"" fashion. (c) has no reference equation, does it?\n\n- Similarly, for Algo 2, add references. In particular, tie in the stepsizes tau and tau_theta here.\n\n- Motivation in section 4.1 was a bit iffy. A larger stepsize is not always better, and smaller is not worse. Minimizing a quadratic f(x) = .5||x||^2 will converge in one step with a step-size of 1 because this is well-conditioned; on the flip side, slow convergence comes from lack of strong convexity, or with strong convexity, ill-conditioning of the Hessian (like a stiff ODE).\n\n- The form of equation (6) was very nice, and you could also point out the connection with backward Euler for finite-difference methods. This was the initial setting of analysis for most of original results that rely on the proximal operator (e.g., Lions and Mercier 1970s).\n\n- Eq (9), this is done component-wise, i.e., Hadamard product, right?\n\n- About eq (12), even if softmax cross-entropy doesn\'t have a closed-form prox (and check the tables of Combettes and Pesquet), because it is separable (if I understand correctly) then it ought to be amenable to solving with a handful of Newton iterations which would be quite cheap.\n\nProx tables (see also the new edition of Bauschke and Combettes\' book): P. L. Combettes and J.-C. Pesquet, ""Proximal splitting methods in signal processing,"" in: Fixed-Point Algorithms for Inverse Problems in Science and Engineering (2011) http://www4.ncsu.edu/~pcombet/prox.pdf\n\n- Below prop 4, discussing why not to make step (b) proximal, this was a bit vague to me. It would be nice to expand this.\n\n- Page 6 near the top, to apply the operator, in the fully-connected case, this is just a matrix multiply, right? and in a conv net, just a convolution? It would help the reader to be more explicit here.\n\n- Section 5.1, 2nd paragraph, did you swap tau_theta and tau, or am I just confused? The wording here was confusing.\n\n- Fig 2 was not that convincing since the figure with time showed that either usual BackProp or the exact ProxProp were best, so why care about the approximate ProxProp with a few CG iterations? The argument of better generalization is based on very limited experiments and without any explanation, so I find that a weak argument (and it just seems weird that inexact CG gives better generalization).  The right figure would be nice to see with time on the x-axis as well.\n\n- Section 5.2, this was nice and contributed to my favorable opinion about the work. However, any kind of standard convergence theory for usual SGD requires the stepsize to change per iteration and decrease toward zero. I\'ve heard of heuristics saying that a fixed stepsize is best and then you just make sure to stop the algorithm a bit early before it diverges or behaves wildly -- is that true here?\n\n- Final section of 5.3, about the validation accuracy, and the accuracy on the test set after 50 epochs. I am confused why these are different numbers. Is it just because 50 epochs wasn\'t enough to reach convergence, while 300 seconds was? And why limit to 50 epochs then? Basically, what\'s the difference between the bottom two plots in Fig 3 (other than scaling the x-axis by time/epoch), and why does ProxProp achieve better accuracy only in the right figure?', 'This work proposes to replace the gradient step for updating the network parameters to a proximal step (implicit gradient) so that a large stepsize can be taken.  Then to make it fast, the implicit step is approximated using conjugate gradient method because the step is solving a quadratic problem.  \n\nThe theoretical result of the ProxProp considers the full batch, and it can not be easily extended to the stochastic variant (mini-batch). The reason is that the gradient of proximal is evaluated at the future point, and different functions will have different future points. While for the explicit gradient, it is assessed at the current point, and it is an unbiased one.  \n\nIn the numerical experiment, the parameter \\tau_\\theta is sensitive to the final solution. Therefore, how to choose this parameter is essential. Given a new dataset, how to determine it for a good performance. \n\nIn Fig 3. The full batch loss of Adam+ProxProp is higher than Adam+BackProp regarding time, which is different from Fig. 2. Also, the figure shows that the performance of Adam+BackProp is worst than Adam+ProxProp even though the training loss of Adam+BackProp is smaller that of Adam+ProxProp. Does it happen on this dataset only or it is the case for many datasets? ', 'Summary:\n\nUsing a penalty formulation of backpropagation introduced in a paper of Carreira-Perpinan and Wang (2014), the current submission proposes to minimize this formulation using explicit step for the update of the variables corresponding to the backward pass, but implicit steps for the update of the parameters of the network. The implicit steps have the advantage that the choice of step-size is replaced by a choice of a proximity coefficient, which the advantage that while too large step-size can increase the objective, any value of the proximity coefficient yields a proximal mapping guaranteed to decrease the objective.\nThe implicit are potentially one order of magnitude more costly than an explicit step since they require\nto solve a linear system, but can be solved (exactly or partially) using conjugate gradient steps. The experiments demonstrate that the proposed algorithm are competitive with standard backpropagation and potentially faster if code is optimized further. The experiments show also that in on of the considered case the generalization accuracy is better for the proposed method.\n\nSummary of the review: \n\nThe paper is well written, clear, tackles an interesting problem. \nBut, given that the method is solving a formulation that leverages second order information, it would seem reasonable to compare with existing techniques that leverage second order information to learn neural networks, namely BFGS, which has been studied for deep learning (see the references to Li and Fukushima (2001) and Ngiam et al (2011) below).\n\nReview:\n\nUsing an implicit step leads to a descent step in a direction which is different than the gradient step.\nBased on the experiment, the step in the implicit direction seems to decrease faster the objective, but the paper does not make an attempt to explain why. The authors must nonetheless have some intuition about this. Is it because the method can be understood as some form of block-coordinate Newton with momentum? It would be nice to have an even informal explanation.\n\nSince a sequence of similar linear systems have to be solved could a preconditioner be gradually be solved and updated from previous iterations, using for example a BFGS approximation of the Hessian or other similar technique. This could be a way to decrease the number of CG iterations that must done at each step. Or can this replaced by a single BFGS style step?\n\nThe proposed scheme is applicable to the batch setting when most deep network are learned using stochastic gradient type methods. What is the relevance/applicability of the method given this context?\n \nIn fact given that the proposed scheme applies in the batch case, it seems that other contenders that are very natural are applicable, including BFGS variants for the non-convex case (\n\nsee e.g. Li, D. H., & Fukushima, M. (2001). On the global convergence of the BFGS method for nonconvex unconstrained optimization problems. SIAM Journal on Optimization, 11(4), 1054-1064.\n\nand\n\nJ. Ngiam, A. Coates, A. Lahiri, B. Prochnow, Q. V. Le, and A. Y. Ng,\n“On optimization methods for deep learning,” in Proceedings of the 28th\nInternational Conference on Machine Learning, 2011, pp. 265–272.\n\n) \n\nor even a variant of BFGS which makes a block-diagonal approximation to the Hessian with one block per layer. To apply BFGS, one might have to replace the RELU function by a smooth counterpart..\n \nHow should one choose tau_theta?\n\nIn the experiments the authors compare with classical backpropagation, but they do not compare with \nthe explicit step of Carreira-Perpinan and Wang? This might be a relevant comparison to add to establish more clearly that it is the implicit step that yields the improvement.\n\n\n\n\n\nTypos or question related to notations, details etc:\n\nIn the description of algorithm 2: the pseudo-code does not specify that the implicit step is done with regularization coefficient tau_theta\n\nIn equation (10) is z_l=z_l^k or z_l^(k+1/2) (I assume the former).\n\n6th line of 5.1 theta_l is initialised uniformly in an interval -> could you explain why and/or provide a reference motivating this ?\n\n8th line of 5.1 you mention Nesterov momentum method -> a precise reference and precise equation to lift ambiguities might be helpful.\n\nIn section 5.2 the reference to Table 5.2 should be Table 1.\n']","[70, -20, 50]","[80, 50, 70]","[""The sentiment score is 70 (positive) because the reviewer expresses an initially skeptical but ultimately favorable opinion of the paper. They praise the paper as 'well-written, very clear' with 'good understanding of the literature', and note its 'interesting idea' and 'high-quality experiments'. The reviewer acknowledges some drawbacks but overall seems impressed. The politeness score is 80 (quite polite) due to the reviewer's consistently respectful and constructive tone. They offer praise where due ('Nice job!') and frame criticisms diplomatically ('I somewhat agree... but'). The reviewer provides detailed, helpful feedback without using harsh or dismissive language, maintaining a professional and courteous tone throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the proposed method and its theoretical results, they raise several concerns and questions about its limitations and performance. The reviewer points out issues with extending the method to stochastic variants, sensitivity to parameter choice, and inconsistencies in the experimental results. These critiques suggest a somewhat skeptical view of the work's contributions and applicability.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and neutral tone throughout. They present their concerns as observations and questions rather than harsh criticisms. The language used is respectful and focuses on the work itself rather than making any personal comments. The reviewer uses phrases like 'This work proposes...' and asks questions like 'Does it happen on this dataset only...?' which maintain a courteous and constructive tone."", ""Sentiment Score (50): The review begins with positive comments, noting the paper is 'well written, clear, tackles an interesting problem.' The reviewer also mentions that the proposed method is 'competitive with standard backpropagation and potentially faster.' However, the reviewer suggests several improvements and comparisons that should be made, indicating a balanced view. The overall tone is more positive than negative, but not overwhelmingly positive, hence a score of 50.\n\nPoliteness Score (70): The language used throughout the review is professional and respectful. The reviewer uses phrases like 'it would seem reasonable,' 'it would be nice to have,' and asks questions rather than making demands. They offer suggestions and point out areas for improvement without being harsh or dismissive. The reviewer also acknowledges the authors' work and potential intuitions. However, it's not excessively polite or flattering, maintaining a professional tone, which is why it's scored at 70 rather than higher.""]"
"[""It is well known that the original GAN (Goodfellow et al.) suffers from instability and mode collapsing. Indeed, existing work has pointed out that the standard GAN training process may not converge if we insist on obtaining pure strategies (for the minmax game). The present paper proposes to obtain mixed strategy through an online learning approach. Online learning (no regret) algorithms have been used in finding an equilibrium for zero sum game. However, most theoretical convergence results are known for convex-concave loss. One interesting theoretical contribution of the paper is to show that convergence result can be proved if one player is a shallow network (and concave in M).In particular, the concave player plays the FTRL algorithm with standard L2 regularization term. The regret of concave player can be bounded using existing result for FTRL. The regret for the other player is more interesting: it uses the fact the adversary's strategy doesn't change too drastically. Then a lemma by Kalai and Vempala can be used. The theory part of the paper is reasonable and quite well written. \n\nBased on the theory developed, the paper presents a practical algorithm. Compared to the standard GAN training, the new algorithm returns mixed strategy and examine several previous models (instead of the latest) in each iteration. The paper claims that this may help to prevent model collapsing.\n\nHowever, the experimental part is less satisfying. From figure 2, I don't see much advantage of Checkhov GAN. In other experiments, I don't see much improvement neither (CIFAR10 and CELEBA).The paper didn't really compare other popular GAN models, especially WGAN and its improved version, which is already quite popular by now and should be compared with.\n\nOverall, I think it is a borderline paper.\n\n-------------------------\nI read the response and the new experimental results regarding WGAN.\nThe experimental results make more sense now.\nIt would be interesting to see whether the idea can be applied to more recent GAN models and still perform better.\nI raised my score to 7.\n\n"", 'This is an interesting paper, exploring GAN dynamics using ideas from online learning, in particular the pioneering ""sparring"" follow-the-regularized leader analysis of Freund and Schapire (using what is listed here as Lemma 4). By restricting the discriminator to be a single layer, the maximum player plays over a concave (parameter) space which stabilizes the full sequence of losses so that Lemma 3 can be proved, allowing proof of the dynamics\' convergence to a Nash equilibrium. The analysis suggests a practical (heuristic) algorithm incorporating two features which emerge from the theory: L2 regularization and keeping a history of past models. A very simple queue for the latter is shown to do quite competitively in practice.\n\nThis paper merits acceptance on theoretical merits alone, because the FTRL analysis for convex-concave games is a very robust tool from theory (see also the more recent sequel [Syrgkanis et al. 2016 ""Fast convergence of regularized learning in games""]) that is natural to employ to gain insight on the much more brittle GAN case. The practical aspects are also interesting, because the incorporation of added randomness into the mixed generation strategy is an area where theoretical justifications do motivate practical performance gains; these ideas could clearly be developed in future work.', 'The paper applies tools from online learning to GANs. In the case of a shallow discriminator, the authors proved some results on the convergence of their proposed algorithm (an adaptation of FTRL) in GAN games, by leveraging the fact that when D update is small, the problem setup meets the ideal conditions for no-regret algorithms. The paper then takes the intuition from the semi-shallow case and propose a heuristic training procedure for deep GAN game. \n\nOverall the paper is very well written. The theory is significant to the GAN literature, probably less so to the online learning community. In practice, with deep D, trained by single gradient update steps for G and D, instead of the ""argmin"" in Algo 1., the assumptions of the theory break. This is OK as long as sufficient experiment results verify that the intuitions suggested by the theory still qualitatively hold true. However, this is where I have issues with the work:\n\n1) In all quantitative results, Chekhov GAN do not significantly beat unrolled GAN. Unrolled GAN looks at historical D\'s through unrolled optimization, but not the history of G. So this lack of significant difference in results raise the question of whether any improvement of Chekhov GAN is coming from the online learning perspective for D and G, or simply due to the fact that it considers historical D models (which could be motivated by sth other than the online learning theory).\n\n2) The mixture GAN approach suggested in Arora et al. (2017) is very related to this work, as acknowledged in Sec. 2.1, but no in-depth analysis is carried out. I suggest the authors to either discuss why Chekhov GAN is obviously superior and hence no experiments are needed, or compare them experimentally. \n\n3) In the current state, it is hard to place the quantitative results in context with other common methods in the recent literature such as WGAN with gradient penalty. I suggest the authors to either report some results in terms of inception scores on cifar10 with similar architectures used in other methods for comparison. Alternatively please show WGAN-GP and/or other method results in at least one or two experiments using the evaluation methods in the paper. \n\nIn summary, almost all the experiments in the paper are trying to establish improvement over basic GAN, which would be OK if the gap between theory and practice is small. But in this case, it is not. So it is not entirely convincing that the practical Algo 2 works better for the reason suggested by the theory, nor it drastically improves practical results that it could become the standard technique in the literature. ']","[20, 80, -20]","[60, 70, 60]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges some strengths of the paper (e.g., 'The theory part of the paper is reasonable and quite well written'), they also express concerns about the experimental results and describe it as a 'borderline paper'. However, the updated score of 7 in the final paragraph indicates an overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses professional and respectful language throughout, offering constructive criticism without harsh or rude phrasing. They acknowledge both strengths and weaknesses of the paper in a balanced manner, and show willingness to reconsider their evaluation based on new information."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'interesting' and states that it 'merits acceptance on theoretical merits alone.' They also highlight the practical aspects as 'interesting' and suggest potential for future work. The overall tone is very supportive and appreciative of the paper's contributions. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They offer praise without being overly effusive, and provide constructive comments. The tone is consistently positive and encouraging, without any harsh criticism or rude remarks. The reviewer maintains a formal yet approachable style, which is appropriate for a peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('very well written', 'theory is significant'), they express several concerns about the paper's experimental results and comparisons. The reviewer points out that the proposed method doesn't significantly outperform existing techniques and questions whether the improvements come from the claimed theoretical basis. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions for improvement rather than harsh judgments. The reviewer uses phrases like 'I suggest' and 'please show' when requesting changes, maintaining a constructive tone.""]"
"['The paper is thorough and on the whole clearly presented. However, I think it could be improved by giving the reader more of a road map w.r.t. the guiding principle. The methods proposed are heuristic in nature, and it\'s not clear what the guiding principle is. E.g., ""momentum correction"". What exactly is the problem without this correction? The authors describe it qualitatively, ""When the gradient sparsity is high, the interval dramatically increases, and thus the significant momentum effect will harm the model performance"". Can the issue be described more precisely? Similarly for gradient clipping, ""The method proposed by Pascanu et al. (2013) rescales the gradients whenever the sum of their L2-norms exceeds a threshold. This step is conventionally executed after gradient aggregation from all nodes. Because we accumulate gradients over iterations on each node independently, we perform the gradient clipping locally before adding the current gradient... "" What exactly is the issue here? It reads like a story of what the authors did, but it\'s not really clear why they did it.\n\nThe experiments seem quite thorough, with several methods being compared. What is the expected performance of the 1-bit SGD method proposed by Seide et al.?\n\nre. page 2: What exactly is ""layer normalization""?\n\nre. page 4: What are ""drastic gradients""?', 'This paper proposes additional improvement over gradient dropping(Aji & Heafield) to improve communication efficiency.  \n\n- First of all, the experimental results are thorough and seem to suggest the advantage of the proposed techniques.\n- The result for gradient dropping(Aji & Heafield) should be included in the ImageNet experiment.\n- I am having a hard time understanding the intuition behind v_t introduced in the momentum correction. The authors should provide some form of justifications.\n   - For example, provide an equivalence provide to the original update rule or some error analysis would be great\n   - Did you keep a running sum of v_t overall history? Such sum without damping(the m term in momentum update) is likely lead to the growing dominance of noise and divergence.\n- The momentum masking technique seems to correspond to stop momentum when a gradient is synchronized. A discussion about the relation to asynchronous update is helpful.\n- Do you do non-sparse global synchronization of momentum term? It seems that local update of momentum is likely going to diverge,  and the momentum masking somehow reset that.\n- In the experiment, did you perform local aggregations of gradients between GPU cards before send out to do all0reduce in a network? since doing so will reduce bandwidth requirement.\n\nIn general, this is a paper shows good empirical results. But requires more work to justify the proposed correction techniques.\n\n\n---\n\nI have read the authors updates and changed my score accordingly(see series of discussions)\n', 'I think this is a good work that I am sure will have some influence in the near future. I think it should be accepted and my comments are mostly suggestions for improvement or requests for additional information that would be interesting to have.\n\nGenerally, my feeling is that this work is a little bit too dense, and would like to encourage the authors in this case to make use of the non-strict ICLR page limit, or move some details to appendix and focus more on more thorough explanations. With increased clarity, I think my rating (7) would be higher.\n\nSeveral Figures and Tables are never referenced in the text, making it a little harder to properly follow text. Pointing to them from appropriate places would improve clarity I think.\n\nAlgorithm 1 line 14: You never seem to explain what is sparse(G). Sec 3.1: What is it exactly that gets communicated? How do you later calculate the Compression Ratio? This should surely be explained somewhere.\n\nSec 3.2 you mention 1% loss of accuracy. A pointer here would be good, at that point it is not clear if it is in your work later, or in another paper. The efficient momentum correction is great!\n\nAs I was reading the paper, I got to the experiments and realized I still don\'t understand what is it that you refer to as ""deep gradient compression"". Pointer to Table 1 at the end of Sec 3 would probably be ideal along with some summary comments.\n\nI feel the presentation of experimental results is somewhat disorganized. It is not clear what is immediately clear what is the baseline, that should be somewhere stressed. I find it really confusing why you sometimes compare against Gradient Dropping, sometimes against TernGrad, sometimes against neither, sometimes include Gradient Sparsification with momentum correction (not clear again what is the difference from DGC). I recommend reorganizing this and make it more consistent for sake of clarity. Perhaps show here only some highlights, and point to more in the Appendix.\n\nSec 5: Here I feel would be good to comment on several other things not mentioned earlier. \nWhy do you only work with 99.9% sparsity? Does 99% with 64 training nodes lead to almost dense total updates, making it inefficient in your communication model? If yes, does that suggest a scaling limit in terms of number of training nodes? If not, how important is the 99.9% sparsity if you care about communication cost dominating the total runtime? I would really like to better understand how does this change and what is the point beyond which more sparsity is not practically useful. Put differently, is DGC with 600x size reduction in total runtime any better than DGC with 60x reduction?\n\n\nFinally, a side remark:\nUnder eq. (2) you point to something that I think could be more discussed. When you say what you do has the effect of increasing stepsize, why don\'t you just increase the stepsize? \nThere has recently been this works on training ImageNet in 1 hour, then in 24 minutes, latest in 15 minutes... You cite the former, but highlight different part of their work. Broader idea is that this is trend that potentially makes this kind of work less relevant. While I don\'t think that makes your work bad or misplaced, I think mentioning this would be useful as an alternative approach to the problems you mention in the introduction and use to motivate your contribution.\n...what would be your reason for using DGC as opposed to just increasing the batch size?']","[-20, 20, 60]","[50, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is 'thorough and on the whole clearly presented', they also point out several areas for improvement and express confusion about certain aspects of the paper. The reviewer asks multiple questions seeking clarification, indicating that the paper lacks clarity in some areas. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, starting with a positive comment and framing their criticisms as suggestions for improvement rather than harsh critiques. They use phrases like 'I think it could be improved' and ask questions rather than making accusatory statements. The tone is professional and constructive, albeit with clear expectations for improvement."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the thorough experimental results and the apparent advantages of the proposed techniques. However, they also point out several areas that need improvement or clarification, indicating a mixed but generally positive sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions without harsh or dismissive comments. They use phrases like 'should provide' and 'would be great' which are polite ways of requesting improvements. The overall tone is professional and collaborative, aiming to improve the paper rather than criticize it harshly."", ""The sentiment score is 60 (positive) because the reviewer starts by saying 'I think this is a good work' and recommends acceptance. They provide constructive feedback for improvement, which indicates a generally positive view. However, they also mention some concerns about clarity and organization, which prevents the score from being higher. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, often framing criticisms as suggestions or requests for additional information. Phrases like 'I think,' 'I would like to encourage,' and 'I recommend' contribute to a polite tone. The reviewer also acknowledges the potential influence of the work and provides detailed, constructive feedback, which is a polite way to help improve the paper.""]"
"['This paper describes an implementation of reduced precision deep learning using a 16 bit integer representation. This field has recently seen a lot of publications proposing various methods to reduce the precision of weights and activations. These schemes have generally achieved close-to-SOTA accuracy for small networks on datasets such as MNIST and CIFAR-10. However, for larger networks (ResNET, Vgg, etc) on large dataset such as ImageNET, a significant accuracy drop are reported. In this work, the authors show that a careful implementation of mixed-precision dynamic fixed point computation can achieve SOTA on 4 large networks on the ImageNET-1K datasets. Using a INT16 (as opposed to FP16) has the advantage of enabling the use of new SIMD mul-acc instructions such as QVNNI16. \n\nThe reported accuracy numbers show convincingly that INT16 weights and activations can be used without loss of accuracy in large CNNs. However, I was hoping to see a direct comparison between FP16 and INT16.  \n\nThe paper is written clearly and the English is fine.', ""This work presents a CNN training setup that uses half precision implementation that can get 2X speedup for training. The work is clearly presented and the evaluations seem convincing. The presented implementations are competitive in terms of accuracy, when compared to the FP32 representation.  I'm not an expert in this area but the contribution seems relevant to me, and enough for being published."", 'This paper is about low-precision training for ConvNets. It proposed a ""dynamic fixed point"" scheme that shares the exponent part for a tensor, and developed procedures to do NN computing with this format. The proposed method is shown to achieve matching performance against their FP32 counter-parts with the same number of training iterations on several state-of-the-art ConvNets architectures on Imagenet-1K. According to the paper, this is the first time such kind of performance are demonstrated for limited precision training.\n\nPotential improvements:\n\t\n  - Please define the terms like FPROP and WTGRAD at the first occurance.\n  - For reference, please include wallclock time and actual overall memory consumption comparisons of the proposed methods and other methods as well as the baseline (default FP32 training).']","[70, 80, 80]","[50, 50, 70]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper. They acknowledge the significance of the work, stating that it 'convincingly' shows INT16 weights and activations can be used without loss of accuracy in large CNNs. The reviewer also compliments the clear writing and good English. However, it's not a perfect score as the reviewer expresses a desire for a direct comparison between FP16 and INT16. The politeness score is 50 (somewhat polite) because the language used is professional and respectful. The reviewer offers constructive feedback without harsh criticism. They use phrases like 'I was hoping to see' rather than demanding changes. The tone is neutral to slightly positive throughout, maintaining a courteous academic discourse."", ""The sentiment score is 80 (positive) because the reviewer expresses a clearly positive view of the work. They state that the work is 'clearly presented', the evaluations are 'convincing', and the implementations are 'competitive'. The reviewer also explicitly states that the contribution seems 'relevant' and 'enough for being published'. The politeness score is 50 (somewhat polite) because while the reviewer uses neutral language overall, they do include some positive phrases like 'clearly presented' and 'convincing'. The reviewer also humbly acknowledges their own limitations ('I'm not an expert in this area'), which adds a polite tone. However, the review doesn't use overtly polite language or excessive praise, keeping it professionally neutral overall."", ""The sentiment score is 80 (positive) because the reviewer begins by summarizing the paper's content and contributions in a neutral tone, then highlights its significance by mentioning it's 'the first time such kind of performance are demonstrated'. This indicates a generally positive view of the paper. The politeness score is 70 (polite) because the reviewer uses respectful language throughout and frames their suggestions as 'Potential improvements' rather than criticisms. The reviewer also uses 'Please' when making requests, which adds to the politeness. The suggestions are constructive and specific, without any harsh or negative language.""]"
"['This paper deals with the estimation of the score function, i.e., the derivative of the log likelihood. Some methods were introduced and a new method using Stein identity was proposed. The setup of the trasnductive learning was introduced to add the prediction power to the proposed method. The method was used to several applications.\n\nThis is an interesting approach to estimate the score function for location models in a non-parametric way. I have a couple of minor comments below. \n\n- Stein identity is the formula that holds for the class of ellipsoidal distribution including Gaussian distribution. I\'m not sure the term ""Stein identity"" is appropriate to express the equation (8). \n- Some boundary condition should be assumed to assure that integration by parts works properly. Describing an explicit boundary condition to guarantee the proper estimation would be nice. ', 'In this paper, the authors proposed the Stein gradient estimator, which directly estimates the score function of the implicit distribution. Direct estimation of gradient is crucial in the context of GAN because it could potentially lead to more accurate updates. Motivated by the Stein’s identity, the authors proposed to estimate the gradient term by replacing expectation with the empirical counterpart and then turn the resulting formulation into a regularized regression problem. They also showed that the traditional score matching estimator (Hyvarinen 2005) can be obtained as a special case of their estimator. Moreover, they also showed that their estimator can be obtained by minimizing the kernelized Stein discrepancy (KSD) which has been used in goodness-of-fit test. In the experiments, the proposed method is evaluated on few tasks including Hamiltonian flow with approximate gradients, meta-learning of approximate posterior samplers, and GANs using entropy regularization. \n\nThe novelty of this work consists of an approach based on score matching and Stein’s identity to estimate the gradient directly and the empirical results of the proposed method on meta-learning for approximate inference and entropy regularized GANs. The proposed method is new and technically sound. The authors also demonstrated through several experiments that the proposed technique can be applied in a wide range of applications.\n\nNevertheless, I suspect that the drawback of this method compared to existing ones is computational cost. If it takes significantly longer to compute the gradient using proposed estimator compared to existing methods, the gain in terms of accuracy is questionable. By spending the same amount of time, we may obtain an equally accurate estimate using other methods. For example, the authors claimed in Section 4.3 that the Stein gradient estimator is faster than other methods, but it is not clear as to why this is the case. Hence, the comparison in terms of computational cost should also be included either in the text or in the experiment section.\n\nWhile the proposed Stein gradient estimator is technically interesting, the experimental results do not seem to evident that it significantly outperforms existing techniques. In Section 4.2, the authors only consider four datasets (out of six UCI datasets). Also, in Section 4.3, it is not clear what the point of this experiment is: whether to show that entropy regularization helps or the Stein gradient estimator outperforms other estimators.\n\nSome comments:\n\n- Perhaps, it is better to move Section 3.3 before Section 3.2 to emphasize the main contribution of this work, i.e., using Stein’s identity to derive an estimate of the gradient of the score function.\n- Stein gradient estimator vs KDE: What if the kernel is not translation invariant? \n- In Section 4.3, why did you consider the entropy regularizer? How does it help answer the main hypothesis of this paper?\n- The experiments in Section 4.3 seems to be a bit out of context.\n', ""Post rebuttal phase (see below for original comments)\n================================================================================\nI thank the authors for revising the manuscript. The methods makes sense now, and I think its quite interesting. While I do have some concerns (e.g. choice of eta, batching may not produce a consistent gradient estimator etc.), I  think the paper should be accepted. I have revised my score accordingly.\n\nThat said, the presentation (esp in Section 2) needs to be improved. The main problem is that many symbols have been used without being defined. e.g. phi, q_phi, \\pi,  and a few more. While the authors might assume that this is obvious, it can be tricky to a reader - esp. someone like me who is not familiar with GANs. In addition, the derivation of the estimator in Section 3 was also sloppy. There are neater ways to derive this using RKHS theory without doing this on a d' dimensional space.\n\nRevised summary: The authors present a method for estimating the gradient of some training objective for generative models used to sample data, such as GANs. The idea is that this can be used in a training procedure. The idea is based off the Stein's identity, for which the authors propose a kernelized solution. The key insight comes from rewriting the variational lower bound so that we are left with having to compute the gradients w.r.t a random variable and then applying Stein's identity. The authors present applications in Bayesian NNs and GANs.\n\n\nSummary\n================================================================\nThe authors present a method for estimating the gradient of some training objective\nfor generative models used to sample data, such as GANs. The idea is that this can be\nused in a training procedure. The idea is based off the Stein's identity, for which the\nauthors propose a kernelized solution. The authors present applications in Bayesian NNs\nand GANs.\n\n\n\n\nDetailed Reviews\n================================================================\n\nMy main concern is what I raised via a comment, for which I have not received a response\nas yet. It seems that you want the gradients w.r.t the parameters phi in (3). But the\nline immediately after claims that you need the gradients w.r.t the domain of a random\nvariable z and the subsequent sections focus on the gradients of the log density with\nrespect to the domain. I am not quite following the connection here.\n\nAlso, it doesn't help that many of the symbols on page 2 which elucidates the set up\nhave not been defined. What are the quantities phi, q, q_phi, epsilon, and pi?\n\nPresentation\n- Bottom row in Figure 1 needs to be labeled. I eventually figured that the colors\n  correspond to the figures above, but a reader is easily confused.\n- As someone who is not familiar with BNNs, I found the description in Section 4.2\n  inadequate.\n \nSome practical concerns:\n- The fact that we need to construct a kernel matrix is concerning. Have you tried\n  batch verstions of these estimator which update the gradients with a few data points?\n- How is the parameter \\eta chosen in practice? Can you comment on the values that you\n  used and how it compared to the eigenvalues of the kernel matrix?\n\nMinor\n- What is the purpose behind sections 3.1 and 3.2? They don't seem pertinent to the rest\n  of the exposition. Same goes for section 3.5? I don't see the authors using the\n  gradient estimators for out-of-sample points?\n\nI am giving an indifferent score mostly because I did not follow most of the details.""]","[50, 50, 50]","[75, 70, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as 'interesting' and provides constructive feedback. They don't express strong enthusiasm, but their tone is generally positive. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, such as 'This is an interesting approach' and 'I have a couple of minor comments'. They frame their suggestions as recommendations rather than criticisms. The reviewer maintains a professional and courteous tone while providing specific, constructive feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and technical soundness of the work, but also expresses some concerns about computational cost and experimental results. The review starts with positive comments about the proposed method being 'new and technically sound' and its wide applicability. However, it also raises questions about computational efficiency and the strength of experimental results, balancing the positive aspects with constructive criticism. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering suggestions and asking questions rather than making harsh criticisms. Phrases like 'Perhaps, it is better to...' and 'It is not clear...' indicate a polite approach to providing feedback. The reviewer also acknowledges the authors' contributions while presenting areas for improvement in a constructive manner."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by thanking the authors for revisions and recommends acceptance, which is positive. However, they still express some concerns and criticisms, which tempers the positivity. The politeness score is 60 (moderately polite) because the reviewer uses polite language like 'I thank the authors' and provides constructive criticism. They maintain a professional tone throughout, even when pointing out issues. The reviewer balances positive feedback with areas for improvement, which is a polite approach. However, some direct criticisms (e.g., calling the derivation 'sloppy') slightly reduce the politeness score.""]"
"[""1. This is a good paper, makes an interesting algorithmic contribution in the sense of joint clustering-dimension reduction for unsupervised anomaly detection\n2. It demonstrates clear performance improvement via comprehensive comparison with state-of-the-art methods\n3. Is the number of Gaussian Mixtures 'K' a hyper-parameter in the training process? can it be a trainable parameter?\n4. Also, it will be interesting to get some insights or anecdotal evidence on how the joint learning helps beyond the decoupled learning framework, such as what kind of data points (normal and anomalous) are moving apart due to the joint learning  "", 'Summary\n\nThis applications paper proposes using a deep neural architecture to do unsupervised anomaly detection by learning the parameters of a GMM end-to-end with reconstruction in a low-dimensional latent space. The algorithm employs a tailored loss function that involves reconstruction error on the latent space, penalties on degenerate parameters of the GMM, and an energy term to model the probability of observing the input samples.\n\nThe algorithm replaces the membership probabilities found in the E-step of EM for a GMM with the outputs of a subnetwork in the end-to-end architecture. The GMM parameters are updated with these estimated responsibilities as usual in the M-step during training.\n\nThe paper demonstrates improvements in a number of public datasets. Careful reporting of the tuning and hyperparameter choices renders these experiments repeatable, and hence a suitable improvement in the field. Well-designed ablation studies demonstrate the importance of the architectural choices made, which are generally well-motivated in intuitions about the nature of anomaly detection.\n\nCriticisms\n\nBased on the performance of GMM-EN, the reconstruction error features are crucial to the success of this method. Little to no detail about these features is included. Intuitively, the estimation network is given the latent code conditioned and some (probably highly redundant) information about the residual structure remaining to be modeled.\n\nSince this is so important to the results, more analysis would be helpful. Why did the choices that were made in the paper yield this success? How do you recommend other researchers or practitioners selected from the large possible space of reconstruction features to get the best results?\n\nQuality\n\nThis paper does not set out to produce a novel network architecture. Perhaps the biggest innovation is the use of reconstruction error features as input to a subnetwork that predicts the E-step output in EM for a GMM. This is interesting and novel enough in my opinion to warrant publication at ICLR, along with the strong performance and careful reporting of experimental design.\n\n', ""The paper presents a new technique for anomaly detection where the dimension reduction and the density estimation steps are jointly optimized. The paper is rigorous and ideas are clearly stated. The idea to constraint the dimension reduction to fit a certain model, here a GMM, is relevant, and the paper provides a thorough comparison with recent state-of-the-art methods. My main concern is that the method is called unsupervised, but it uses the class information in the training, and also evaluation. I'm also not convinced of how well the Gaussian model fits the low-dimensional representation and how well can a neural network compute the GMM mixture memberships.\n\n1. The framework uses the class information, i.e., “only data samples from the normal class are used for training”, but it is still considered unsupervised. Also, the anomaly detection in the evaluation step is based on a threshold which depends on the percentage of known anomalies, i.e., a priori information. I would like to see a plot of the sample energy as a function of the number of data points. Is there an elbow that indicates the threshold cut? Better yet it would be to use methods like Local Outlier Factor (LOF) (Breunig et al., 2000 – LOF:Identifying Density-based local outliers) to detect the outliers (these methods also have parameters to tune, sure, but using the known percentage of anomalies to find the threshold is not relevant in a purely unsupervised context when we don't know how many anomalies are in the data).\n2. Is there a theoretical justification for computing the mixture memberships for the GMM using a neural network? \n3. How do the regularization parameters \\lambda_1 and \\lambda_2 influence the results?\n4. The idea to jointly optimize the dimension reduction and the clustering steps was used before neural nets (e.g., Yang et al., 2014 -  Unsupervised dimensionality reduction for Gaussian mixture model). Those approaches should at least be discussed in the related work, if not compared against.\n5. The authors state that estimating the mixture memberships with a neural network for GMM in the estimation network instead of the standard EM algorithm works better. Could you provide a comparison with EM?\n6. In the newly constructed space that consists of both the extracted features and the representation error, is a Gaussian model truly relevant? Does it well describe the new space? Do you normalize the features (the output of the dimension reduction and the representation error are quite different)? Fig. 3a doesn't seem to show that the output is a clear mixture of Gaussians.\n7. The setup of the KDDCup seems a little bit weird, where the normal samples and anomalies are reversed (because of percentage), where the model is trained only on anomalies, and it detects normal samples as anomalies ... I'm not convinced that it is the best example, especially that is it the one having significantly better results, i.e. scores ~ 0.9 vs. scores ~0.4/0.5 score for the other datasets.\n8. The authors mention that “we can clearly see from Fig. 3a that DAGMM is able to well separate ...” - it is not clear to me, it does look better than the other ones, but not clear. If there is a clear separation from a different view, show that one instead. We don't need the same view for all methods. \n9. In the experiments the reduced dimension used is equal to 1 for two of the experiments and 2 for one of them. This seems very drastic!\n\nMinor comments:\n\n1. Fig.1: what dimension reduction did you use? Add axis labels.\n2. “DAGMM preserves the key information of an input sample” - what does key information mean?\n3. In Fig. 3 when plotting the results for KDDCup, I would have liked to see results for the best 4 methods from Table 1, OC-SVM performs better than PAE. Also DSEBM-e and DSEBM-r seems to perform very well when looking at the three measures combined. They are the best in terms of precision.\n4. Is the error in Table 2 averaged over multiple runs? If yes, how many?\n\nQuality – The paper is thoroughly written, and the ideas are clearly presented. It can be further improved as mentioned in the comments.\n\nClarity – The paper is very well written with clear statements, a pleasure to read.\n\nOriginality – Fairly original, but it still needs some work to justify it better.\n\nSignificance – Constraining the dimension reduction to fit a certain model is a relevant topic, but I'm not convinced of how well the Gaussian model fits the low-dimensional representation and how well can a neural network compute the GMM mixture memberships. \n""]","[80, 70, -20]","[50, 80, 60]","[""The sentiment score is 80 (positive) because the reviewer starts by calling it a 'good paper' and praises its 'interesting algorithmic contribution' and 'clear performance improvement'. The reviewer also shows interest in further insights, indicating a positive engagement with the work. The politeness score is 50 (moderately polite) because the language is professional and respectful, without being overly formal or effusive. The reviewer uses neutral, constructive language to ask questions and suggest additional areas of exploration, maintaining a collegial tone throughout the review."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper, highlighting its improvements, careful reporting, well-designed studies, and suitability for publication. They mention that the work is 'interesting and novel enough' to warrant publication. However, it's not 100 as there are some criticisms and requests for more analysis. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths before presenting criticisms, and frame their suggestions as recommendations rather than demands. The tone is professional and courteous, without any harsh or rude language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's rigor and clear presentation, they express several significant concerns and criticisms. The reviewer questions the method's classification as unsupervised, the appropriateness of the Gaussian model, and the effectiveness of using a neural network for GMM mixture memberships. They also request additional comparisons and justifications. However, the review is not entirely negative, as it recognizes the paper's relevance and thorough comparison with state-of-the-art methods. The politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I would like to see' and 'Could you provide' when making requests, and they balance criticisms with positive comments about the paper's clarity and writing quality. The reviewer also offers constructive suggestions for improvement rather than just pointing out flaws.""]"
"['The paper is written well and clear.   The core contribution of the paper is the illustration that: under the assumption of flat, or curved decision boundaries with positive curvature small universal adversarial perturbations exist.  \n\nPros: the intuition and geometry is rather clearly presented.  \n\nCons: \nReferences to ""CaffeNet""  and ""LeNet"" (even though the latter is well-known) are missing.  In the experimental section used to validate the main hypothesis that the deep networks have positive curvature decision boundaries, there is no description of how these networks were trained. \n\nIt is not clear why the authors have decided to use out-dated 5-layer ""LeNet""  and NiN (Network in network) architectures instead of more recent and much better performing architectures (and less complex than NiN architectures). It would be nice to see how the behavior and boundaries look in these cases.  \n\nThe conclusion is speculative:\n""Our analysis hence shows that to construct classifiers that are robust to universal perturbations, it\nis key to suppress this subspace of shared positive directions, which can possibly be done through\nregularization of the objective function. This will be the subject of future works."" \n\nIt is clear that regularization should play a significant role in shaping the decision boundaries. Unfortunately, the paper does not provide details at the basic level, which algorithms,  architectures, hyper-parameters or regularization terms are used. All these factors should play a very significant role in the experimental validation of their hypothesis.\n\nNotes: I did not check the proofs of the theorems in detail. \n', 'The paper develops models which attempt to explain the existence of universal perturbations which fool neural networks — i.e., the existence of a single perturbation which causes a network to misclassify most inputs. The paper develops two models for the decision boundary:\n\n(a) A locally flat model in which the decision boundary is modeled with a hyperplane and the normals two the hyperplanes are assumed to lie near a low-dimensional linear subspace.\n\n(b) A locally positively curved model, in which there is a positively curved outer bound for the collection of points which are assigned a given label. \n\nThe paper works out a probabilistic analysis arguing that when either of these conditions obtains, there exists a fooling perturbation which affects most of the data. \n\nThe theoretical analysis in the paper is straightforward, in some sense following from the definition. The contribution of the paper is to posit these two conditions which can predict the existence of universal fooling perturbations, argue experimentally that they occur in (some) neural networks of practical interest. \n\nOne challenge in assessing the experimental claims is that practical neural networks are nonsmooth; the quadratic model developed from the hessian is only valid very locally. This can be seen in some of the illustrative examples in Figure 5: there *is* a coarse-scale positive curvature, but this would not necessarily come through in a quadratic model fit using the hessian. The best experimental evidence for the authors’ perspective seems to be the fact that random perturbations from S_c misclassify more points than random perturbations constructed with the previous method. \n\nI find the topic of universal perturbations interesting, because it potentially tells us something structural (class-independent) about the decision boundaries constructed by artificial neural networks. To my knowledge, the explanation of universal perturbations in terms of positive curvature is novel. The paper would be much stronger if it provided an explanation of *why* there exists this common subspace of universal fooling perturbations, or even what it means geometrically that positive curvature obtains at every data point. \n\nVisually, these perturbations seem to have strong, oriented local high-frequency content — perhaps they cause very large responses in specific filters in the lower layers of a network, and conventional architectures are not robust to this? \n\nIt would also be nice to see some visual representations of images perturbed with the new perturbations, to confirm that they remain visually similar to the original images. \n', 'This paper discusses universal perturbations - perturbations that can mislead a trained classifier if added to most of input data points. The main results are two fold: if the decision boundary are flat (such as linear classifiers), then the classifiers tend to be vulnerable to universal perturbations when the decision boundaries are correlated. If the decision boundary are curved, then vulnerability to universal perturbations is directly resulted from existence of shared direction along with the decision boundary positively curved. The authors also conducted experiments to show that deep nets produces decision boundary that satisfies the curved model.\n\nThe main issue I am having is what are the applicable insight from the analysis:\n\n1. Why is universal perturbation an important topic (as opposed to adversarial perturbation).\n2. Does the result implies that we should make the decision boundary more flat, or curved but on different directions? And how to achieve that? It might be my mis-understanding but from my reading a prescriptive procedure for universal perturbation seems not attained from the results presented.']","[20, 50, -20]","[50, 75, 50]","[""The sentiment score is slightly positive (20) because the review starts with praise for the paper's clarity and presentation of intuition and geometry. However, it also lists several cons and criticisms, which temper the overall positive sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. The reviewer also frames suggestions as 'it would be nice' rather than demands. The criticisms are presented factually without harsh language. The use of phrases like 'unfortunately' and 'it is not clear why' maintain a professional tone while expressing concerns."", ""The sentiment score is 50 (slightly positive) because the reviewer finds the topic interesting and acknowledges the novelty of the paper's approach, but also points out some challenges and areas for improvement. The reviewer states that the paper's contribution is to posit conditions predicting universal fooling perturbations and provides experimental evidence. However, they also mention that the paper would be stronger with additional explanations and visual representations.\n\nThe politeness score is 75 (quite polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's contributions and express interest in the topic. When suggesting improvements or pointing out limitations, the reviewer uses phrases like 'It would be nice to see...' and 'The paper would be much stronger if...', which are polite ways of offering criticism. The reviewer also uses neutral, academic language and avoids any harsh or dismissive statements."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the main results of the paper, they express significant concerns about the applicability and insights derived from the analysis. The reviewer raises two major questions that suggest the paper may lack important context or practical implications. However, the score is not deeply negative as the reviewer does not outright reject the paper's findings.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They frame their concerns as questions rather than direct criticisms, using phrases like 'The main issue I am having is...' and 'It might be my mis-understanding...'. This approach is constructive and allows the authors room to address the concerns without feeling attacked. The reviewer also acknowledges the main results of the paper before presenting their questions, which is a polite way to structure feedback.""]"
"['The paper devises a sparse kernel for RNNs which is urgently needed because current GPU deep learning libraries (e.g., CuDNN) cannot exploit sparsity when it is presented and because a number of works have proposed to sparsify/prune RNNs so as to be able to run on devices with limited compute power (e.g., smartphones). Unfortunately, due to the low-level and GPU specific nature of the work, I would think that this work will be better critiqued in a more GPU-centric conference. Another concern is that while experiments are provided to demonstrate the speedups achieved by exploiting sparsity, these are not contrasted by presenting the loss in accuracy caused by introducing sparsity (in the main portion of the paper). It may be the case by reducing density to 1% we can speedup by N fold but this observation may not have any value if the accuracy becomes  abysmal.\n\nPros:\n- Addresses an urgent and timely issue of devising sparse kernels for RNNs on GPUs\n- Experiments show that the kernel can effectively exploit sparsity while utilizing GPU resources well\n\nCons:\n- This work may be better reviewed at a more GPU-centric conference\n- Experiments (in main paper) only show speedups and do not show loss of accuracy due to sparsity', ""The paper proposes improving performance of large RNNs by combing techniques of model pruning and persistent kernels. The authors further propose model-pruning optimizations which are aware of the persistent implementation.\n\nIt's not clear if the paper is relevant to the ICLR audience due to its emphasize on low-level optimization which has little insight in learning representations. The exposition in the paper is also not well-suited for people without a systems background, although I'll admit I'm mostly using myself as a proxy for the average machine learning researcher here. For instance, the authors could do more to explain Lamport Timestamps than a 1974 citation.\n\nModulo problems of relevance and expected audience, the paper is well-written and presents useful improvements in performance of large RNNs, and the work has potential for impact in industrial applications of RNNs. The work is clearly novel, and the contributions are clear and well-justified using experiments and ablations."", 'This paper introduces sparse persistent RNNs, a mechanism to add pruning to the existing work of stashing RNN weights on a chip. The paper describes the use additional mechanisms for synchronization and memory loading. \n\nThe evaluation in the main paper is largely on synthetic workloads (i.e. large layers with artificial sparsity).  With evaluation largely over layers instead of applications, I was left wondering whether there is an actual benefit on real workloads. Furthermore, the benefit over dense persistent RNNs for OpenNMT application (of absolute 0.3-0.5s over dense persistent rnns?) did not appear significant unless you can convince me otherwise. \n\nStoring weights persistent on chip should give a sharp benefit when all weights fit on the chip. One suggestion I have to strengthen the paper is to claim that due to pruning, now you can support a larger number of methods or method configurations and to provide examples of those.\n\nTo summarize, the paper adds the ability to support pruning over persistent RNNs. However, Narang et. al., 2017 already explore this idea, although briefly. Furthermore, the gains from the sparsity appear rather limited over real applications. I would encourage the authors to put the NMT evaluation in the main paper (and perhaps add other workloads). Furthermore, a host of techniques are discussed (Lamport timestamps, memory layouts) and implementing them on GPUs is not trivial. However, these are well known and the novelty or even the experience of implementing these on GPUs should be emphasized.']","[-20, -20, -30]","[50, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance and timeliness of the work, they express significant concerns about the paper's suitability for the current venue and the lack of accuracy loss information. The reviewer presents both pros and cons, but the cons seem to outweigh the pros in terms of the paper's current state. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the urgency and importance of the work, and frames criticisms constructively. They use phrases like 'Unfortunately' and 'Another concern is' to soften their critiques, and provide specific suggestions for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well-written', 'useful improvements', 'potential for impact'), they express concerns about the paper's relevance to the ICLR audience and its accessibility to those without a systems background. The reviewer also suggests that the paper could benefit from more explanations. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges their own potential bias ('I'll admit I'm mostly using myself as a proxy'), and balances criticism with praise. They offer constructive feedback without using harsh or dismissive language, maintaining a professional and courteous tone."", ""The sentiment score is -30 because the reviewer expresses some skepticism about the paper's contributions and impact. They question the significance of the results, especially on real workloads, and suggest that the gains appear limited. However, it's not entirely negative as they do acknowledge the paper's contribution of adding pruning to persistent RNNs. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'I would encourage the authors' and 'One suggestion I have,' which are polite ways of providing feedback. The reviewer also acknowledges the difficulty of implementing certain techniques on GPUs. While the review is critical, it maintains a professional and courteous tone throughout.""]"
"['\nIn this paper, the authors proposed an interesting algorithm for learning the l1-SVM and the Fourier represented kernel together. The model extends kernel alignment with random feature dual representation and incorporates it into l1-SVM optimization problem. They proposed algorithms based on online learning in which the Langevin dynamics is utilized to handle the nonconvexity. Under some conditions about the quality of the solution to the nonconvex optimization, they provide the convergence and the sample complexity. Empirically, they show the performances are better than random feature and the LKRF. \n\nI like the way they handle the nonconvexity component of the model. However, there are several issues need to be addressed. \n\n1, In Eq. (6), although due to the convex-concave either min-max or max-min are equivalent, such claim should be explained explicitly. \n\n2, In the paper, there is an assumption about the peak of random feature ""it is a natural assumption on realistic data that the largest peaks are close to the origin"". I was wondering where this assumption is used? Could you please provide more justification for such assumption?\n\n3, Although the proof of the algorithm relies on the online learning regret bound, the algorithm itself requires visit all the data in each update, and thus, it is not suitable for online learning. Please clarify this in the paper explicitly. \n\n4, The experiment is weak. The algorithm is closely related to boosting and MKL, while there is no such comparison. Meanwhile, Since the proposed algorithm requires extra optimization w.r.t. random feature, it is more convincing to include the empirical runtime comparison. \n\nSuggestion: it will be better if the author discusses some other model besides l1-SVM with such kernel learning. \n', 'The paper proposes to learn a custom translation or rotation invariant kernel in the Fourier representation to maximize the margin of SVM. Instead of using Monte Carlo approximation as in the traditional random features literature, the main point of the paper is to learn these Fourier features in a min-max sense. This perspective leads to some interesting theoretical results and some new interpretation. Synthetic and some simple real-world experiments demonstrate the effectiveness of the algorithm compared to random features given the fix number of bases.\n\nI like the idea of trying to formulate the feature learning problem as a two-player min-max game and its connection to boosting. As for the related work, it seems the authors have missed some very relevant pieces of work in learning these Fourier features through gradient descent [1, 2]. It would be interesting to compare these algorithms as well.\n\n[1] Zichao Yang, Marcin Moczulski, Misha Denil, Nando de Freitas, Alex Smola, Le Song, Ziyu Wang. Deep Fried Convnets. ICCV 2015.\n[2] Zichao Yang, Alexander J. Smola, Le Song, Andrew Gordon Wilson. A la Carte — Learning Fast Kernels. AISTATS 2015.', 'In this paper the authors consider learning directly Fourier representations of shift/translation invariant kernels for machine learning applications. They choose the alignment of the kernel to data as the objective function to optimize. They empirically verify that the features they learned lead to good quality SVM classifiers. My problem with that paper is that even though at first glance learning adaptive feature maps seems to be an attractive approach, authors\' contribution is actually very little. Below I list some of the key problems. First of all the authors claim in the introduction that their algorithm is very fast and with provable theoretical guarantees. But in fact later they admit that the problem of optimizing the alignment is a non-convex problem and the authors end up with a couple of heuristics to deal with it. They do not really provide any substantial theoretical justification why these heuristics work in practice even though they observe it empirically. The assumptions that large Fourier peaks happen close to origin is probably well-justified from the empirical point of view, but it is a hack, not a well established well-grounded theoretical method (the authors claim that in their experiments they found it easy to find informative peaks, even in hundreds of dimensions, but these experiments are limited to the SVM setting, I have no idea how these empirical findings would translate to other kernelized algorithms using these adaptive features).  The Langevin dynamics algorithm used by the authors to find the peaks (where the gradient is available) gives only weak theoretical guarantees (as the authors actually admit) and this is a well known method, certainly not a novelty of that paper. Finally, the authors notice that ""In the rotation-invariant case, where Ω is a discrete set, heuristics are available"". That is really not very informative (the authors refer to the Appendix so I carefully read that part of the Appendix, but it is extremely vague, it is not clear at all how the Langevin dynamics can be ""emulated"" by a discrete Markov chain that mixes fast; the authors do not provide any justification of that approach, what is the mixing time ?; how the ""good emulation property"" is exactly measured ?).  In the conclusions the authors admit that: ""Many theoretical questions remain, such as accelerating the search for Fourier peaks"". I think that the problem of accelerating this approach is a critical point that this publication is missing. Without this, it is actually really hard to talk about general mechanism of learning adaptive Fourier features for kernel algorithms (which is how the authors present their contribution); instead we have a method heavily customized and well-tailored to the (not particularly exciting) SVM scenario (with optimization performed by the standard annealing method; it is not clear at all whether for other downstream kernel applications this approach for optimizing the alignment would provide good quality models) that uses lots of task specific hacks and heuristics to efficiently optimize the alignment. Another problem is that it is not clear at all to me how authors\' approach can be extended to non shift-invariant kernels that do not benefit from Bochner\'s Theorem. Such kernels are very related to neural networks (for instance PNG kernels with linear rectifier nonlinearities correspond to random layers in NNs with ReLU) and in the NN context are much more interesting that radial basis function or in general shift-invariant kernels. A general kernel method should address this issue (the authors just claim in the conclusions that it would be interesting to explore the NN context in more detail).\n\nTo sum it up, it is a solid submission, but in my opinion without a substantial contribution and working only in a  very limited setting when it is heavily relying on many unproven hacks and heuristics.']","[20, 60, -60]","[60, 70, 20]","[""The sentiment score is slightly positive (20) because the reviewer starts by acknowledging the paper as 'interesting' and mentions liking the approach to handling nonconvexity. However, they also point out several issues that need to be addressed, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, such as 'I like the way...', 'Could you please...', and 'it will be better if...'. They frame their criticisms as suggestions or questions rather than direct attacks. The reviewer maintains a professional tone while providing constructive feedback, balancing positive comments with areas for improvement."", ""The sentiment score is 60 (positive) because the reviewer expresses appreciation for the paper's main idea and acknowledges its interesting theoretical results and effectiveness. The reviewer uses phrases like 'I like the idea' and mentions 'interesting theoretical results' and 'effectiveness of the algorithm.' However, it's not extremely positive as the reviewer also points out missed related work. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions. The tone is professional and courteous, using phrases like 'It would be interesting to compare' rather than demanding changes. The reviewer also acknowledges the paper's strengths before mentioning areas for improvement, which is a polite approach to criticism."", ""The sentiment score is -60 because the reviewer expresses significant criticism throughout the review. They state that the authors' contribution is 'very little' and highlight several key problems with the paper. The reviewer acknowledges it as a 'solid submission' but ultimately concludes it lacks 'substantial contribution' and is limited in scope. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone. They use phrases like 'My problem with that paper is...' and 'In my opinion...' rather than using harsh or rude language. The reviewer also acknowledges some positive aspects, such as calling it a 'solid submission', which contributes to a more polite overall tone despite the negative sentiment.""]"
"[""The paper basically propose keep using the typical data-augmentation transformations done during training also in evaluation time, to prevent adversarial attacks. In the paper they analyze only 2 random resizing and random padding, but I suppose others like random contrast, random relighting, random colorization, ... could be applicable.\n\nSome of the pros of the proposed tricks is that it doesn't require re-training existing models, although as the authors pointed out re-training for adversarial images is necessary to obtain good results.\n\n\nTypically images have different sizes, however in the Dataset are described as having 299x299x3 size, are all the test images resized before hand? How would this method work with variable size images?\n\nThe proposed defense requires increasing the size of the input images, have you analyzed the impact in performance? Also it would be good to know how robust is the method for smaller sizes.\n\nSection 4.6.2 seems to indicate that 1 pixel padding or just resizing 1 pixel is enough to get most of the benefit, please provide an analysis of how results improve as the padding or size increase. \n\nIn section 5 for the challenge authors used a lot more evaluations per image, could you provide how much extra computation is needed for that model?\n\n"", ""This paper proposes an extremely simple methodology to improve the network's performance by adding extra random perturbations (resizing/padding) at evaluation time.\n\nAlthough the paper is very basic, it creates a good baseline for defending about various types of attacks and got good results in kaggle competition.\n\nThe main merit of the paper is to study this simple but efficient baseline method extensively and shows how adversarial attacks can be mitigated by some extent.\n\nCons of the paper: there is not much novel insight or really exciting new ideas presented.\n\nPros: It gives a convincing very simple baseline and the evaluation of all subsequent results on defending against adversaries will need to incorporate this simple defense method in addition to any future proposed defenses, since it is very easy to implement and evaluate and seems to improve the defense capabilities of the network to a significant degree. So I assume that this paper will be influential in the future just by the virtue of its easy applicability and effectiveness.\n\n"", ""The authors propose a simple defense against adversarial attacks, which is to add randomization in the input of the CNNs. They experiment with different CNNs and published adversarial training techniques and show that randomized inputs mitigate adversarial attacks. \n\nPros:\n(+) The idea introduced is simple and flexible to be used for any CNN architecture\n(+) Experiments on ImageNet1k prove demonstrate its effectiveness\nCons:\n(-) Experiments are not thorougly explained\n(-) Novelty is extremely limited\n(-) Some baselines missing\n\n\nThe experimental section of the paper was rather confusing. The authors should explain the experiments and the settings in the table, as those are not very clear. In particular, it was not clear whether the defense model was trained with the input randomization layers? Also, in Tables 1-6, how was the target model trained? How do the training procedures of target vs. defense model differ? In those tables, what is the testing procedure for the target model and how does it compare to the defense model? \n\nThe gap between the target and defense model in Table 4 (ensemble pattern attack scenario) shrinks for single step attack methods. This means that when the attacker is aware of the randomization parameters, the effect of randomization might diminish. A baseline that reports the performance when the attacker is fully aware of the randomization of the defender (parameters, patterns etc.) is missing but is very useful.\n\nWhile the experiments show that the randomization layers mitigate the effect of randomization attacks, it's not clear whether the effectiveness of this very simple approach is heavily biased towards the published ways of generating adversarial attacks and the particular problem (i.e. classification). The form of attacks studied in the paper is that of additive noise. But there is many types of attacks that could be closely related to the randomization procedure of the input and that could lead to very different results.""]","[50, 60, -20]","[70, 70, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the pros of the proposed method, such as not requiring re-training of existing models. They also provide constructive feedback and questions, indicating interest in the work. The review is not overwhelmingly positive, but it's certainly not negative either. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, asking questions in a professional manner without any harsh criticism. They use phrases like 'could you provide' and 'please provide,' which are polite ways of requesting additional information. The reviewer also acknowledges the potential benefits of the work, which adds to the overall polite tone."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's merits, such as creating a good baseline, achieving good results, and being potentially influential. They mention it's 'very basic' but emphasize its efficiency and extensive study. The cons are minimal, noting only a lack of novel insights. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, balancing praise with constructive criticism. They use phrases like 'good baseline', 'convincing', and 'influential', while tactfully mentioning limitations without harsh language. The tone is professional and appreciative of the paper's contributions."", 'The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the paper, there are more cons listed and the overall tone suggests significant improvements are needed. The reviewer points out limited novelty, missing baselines, and confusing experimental explanations, which outweigh the positive aspects. The politeness score is moderately positive (50) as the reviewer uses professional language throughout, presents both pros and cons objectively, and phrases criticisms as suggestions for improvement rather than harsh judgments. The reviewer maintains a respectful tone while providing constructive feedback, which is indicative of polite academic discourse.']"
"['The paper presents a new approach for hierarchical reinforcement learning which aims at learning a versatile set of skills. The paper uses a variational bound for entropy regularized RL to learn a versatile latent space which represents the skill to execute. The variational bound is used to diversify the learned skills as well as to make the skills identifyable from their state trajectories. The algorithm is tested on a simple point mass task and on simulated robot manipulation tasks.\n\nThis is a very intersting paper which is also very well written. I like the presented approach of learning the skill embeddings using the variational lower bound. It represents one of the most principled approches for hierarchical RL. \n\nPros: \n- Interesting new approach for hiearchical reinforcement learning that focuses on skill versatility\n- The variational lower bound is one of the most principled formulations for hierarchical RL that I have seen so far\n- The results are convincing\n\nCons:\n- More comparisons against other DRL algorithms such as TRPO and PPO would be useful\n\nSummary: This is an interesting deep reinforcement learning paper that introduces a new principled framework for learning versatile skills. This is a good paper.\n\nMore comments:\n- There are several papers that focus on learning versatile skills in the context of movement primitive libraries, see [1],[2],[3]. These papers should be discussed.\n\n[1] Daniel, C.; Neumann, G.; Kroemer, O.; Peters, J. (2016). Hierarchical Relative Entropy Policy Search, Journal of Machine Learning Research (JMLR),\n[2] End, F.; Akrour, R.; Peters, J.; Neumann, G. (2017). Layered Direct Policy Search for Learning Hierarchical Skills, Proceedings of the International Conference on Robotics and Automation (ICRA).\n[3] Gabriel, A.; Akrour, R.; Peters, J.; Neumann, G. (2017). Empowered Skills, Proceedings of the International Conference on Robotics and Automation (ICRA).\n', 'In this paper, (previous states, action) pairs and task ids are embedded into the same latent space with the goal of generalizing and sharing across skill variations. Once the embedding space is learned, policies can be modified by passing in sampled or learned embeddings.\n\nNovelty and Significance: To my knowledge, using a variational approach to embedding robot skills is novel. Significantly, the embedding is learned from off-policy trajectories, indicating feasibility on a real-world setting. The manipulation experiments show nice results on non-trivial tasks. However, no comparisons are shown against prior work in multitask or transfer learning. Additionally, the tasks used to train the embedding space were tailored exactly to the target task, making it unclear that this method will work generally.\n\nQuestions:\n- I am not sure how to interpret Figure 3. Do you use Bernoulli in the experiments?\n- How many task IDs are used for each experiment? 2?\n- Are the manipulation experiments learned with the off-policy variant?\n- Figure 4b needs the colors to be labeled. Video clips of the samples would be a plus.\n- (Major) For the experiments, only exactly the useful set of tasks is used to train the embedding. What happens if a single latent space is learned from all the tasks, and Spring-wall, L-wall, and Rail-push are each learned from the same embedding. \n\nI find the method to be theoretically interesting and valuable to the learning community. However, the experiments are not entirely convincing.\n', 'The submission tackles an important problem of learning and transferring multiple motor skills. The approach relies on using an embedding space defined by latent variables and entropy-regularized policy gradient / variational inference formulation that encourages diversity and identifiability in latent space.\n\nThe exposition is clear and the method is well-motivated. I see no issues with the mathematical correctness of the claims made in the paper. The experimental results are both instructive of how the algorithm operates (in the particle example), and contain impressive robotic results. I appreciated the experiments that investigated cases where true number of tasks and the parameter T differ, showing that the approach is robust to choice of T.\n\nThe submission focuses particularly on discrete tasks and learning to sequence discrete tasks (as training requires a one-hot task ID input). I would like a bit of discussion on whether parameterized skills (that have continuous space of target location, or environment parameters, for example) can be supported in the current formulation, and what would be necessary if not.\n\nOverall, I believe this is in interesting piece of work at a fruitful intersection of reinforcement learning and variational inference, and I believe would be of interest to ICLR community.']","[80, -20, 90]","[70, 60, 80]","[""The sentiment score is 80 because the review is overwhelmingly positive. The reviewer describes the paper as 'very interesting' and 'well written', and states it's a 'good paper' with a 'principled approach'. They list several pros and only one con. The politeness score is 70 because the language is consistently respectful and constructive. The reviewer uses phrases like 'I like' and 'interesting', and provides balanced feedback with both pros and cons. They also offer helpful suggestions for improvement, such as additional comparisons and references, which is a polite way to provide criticism. The tone is professional and courteous throughout, without any harsh or rude language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty and significance of the work, they express concerns about the lack of comparisons to prior work and the limited scope of the experiments. The phrase 'the experiments are not entirely convincing' indicates a critical view. However, the reviewer does recognize positive aspects, which prevents the score from being more negative. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, poses questions politely, and balances criticism with recognition of the paper's strengths. The use of phrases like 'To my knowledge' and 'I find the method to be theoretically interesting and valuable' demonstrate a considerate tone, even when expressing concerns."", ""The sentiment score is 90 (highly positive) because the reviewer expresses strong approval of the submission. They describe it as 'an interesting piece of work' that tackles 'an important problem', with 'clear exposition', 'well-motivated' methods, and 'impressive robotic results'. The reviewer also states that the work 'would be of interest to ICLR community'. The only slight criticism is a request for more discussion on a specific point, which doesn't significantly detract from the overall positive sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout. They offer praise without being overly effusive, and frame their suggestion for additional discussion as a polite request ('I would like a bit of discussion...'). The tone is consistently constructive and appreciative, demonstrating courtesy towards the authors' work.""]"
"['The authors propose a method for performing transfer learning and domain adaptation via a clustering approach. The primary contribution is the introduction of a Learnable Clustering Objective (LCO) that is trained on an auxiliary set of labeled data to correctly identify whether pairs of data belong to the same class. Once the LCO is trained, it is applied to the unlabeled target data and effectively serves to provide ""soft labels"" for whether or not pairs of target data belong to the same class. A separate model can then be trained to assign target data to clusters while satisfying these soft labels, thereby ensuring that clusters are made up of similar data points. \n\nThe proposed LCO is novel and seems sound, serving as a way to transfer the general knowledge of what a cluster is without requiring advance knowledge of the specific clusters of interest. The authors also demonstrate a variety of extensions, such as how to handle the case when the number of target categories is unknown, as well as how the model can make use of labeled source data in the setting where the source and target share the same task.\n\nThe way the method is presented is quite confusing, and required many more reads than normal to understand exactly what is going on. To point out one such problem point, Section 4 introduces f, a network that classifies each data instance into one of k clusters. However, f seems to be mentioned only in a few times by name, despite seeming like a crucial part of the method. Explaining how f is used to construct the CCN could help in clarifying exactly what role f plays in the final model. Likewise, the introduction of G during the explanation of the LCO is rather abrupt, and the intuition of what purpose G serves and why it must be learned from data is unclear. Additionally, because G is introduced alongside the LCO, I was initially misled into understanding was that G was optimized to minimize the LCO. Further text explaining intuitively what G accomplishes (soft labels transferred from the auxiliary dataset to the target dataset) and perhaps a general diagram of what portions of the model are trained on what datasets (G is trained on A, CCN is trained on T and optionally S\') would serve the method section greatly and provide a better overview of how the model works.\n\nThe experimental evaluation is very thorough, spanning a variety of tasks and settings. Strong results in multiple settings indicate that the proposed method is effective and generalizable. Further details are provided in a very comprehensive appendix, which provides a mix of discussion and analysis of the provided results. It would be nice to see some examples of the types of predictions and mistakes the model makes to further develop an intuition for how the model works. I\'m also curious how well the model works if, you do not make use of the labeled source data in the cross-domain setting, thereby mimicking the cross-task setup.\n\nAt times, the experimental details are a little unclear. Consistent use of the A, T, and S\' dataset abbreviations would help. Also, the results section seems to switch off between calling the method CCN and LCO interchangeably. Finally, a few of the experimental settings differ from their baselines in nontrivial ways. For the Office experiment, the LCO appears to be trained on ImageNet data. While this seems similar in nature to initializing from a network pre-trained on ImageNet, it\'s worth noting that this requires one to have the entire ImageNet dataset on hand when training such a model, as opposed to other baselines which merely initialize weights and then fine-tune exclusively on the Office data. Similarly, the evaluation on SVHN-MNIST makes use of auxiliary Omniglot data, which makes the results hard to compare to the existing literature, since they generally do not use additional training data in this setting. In addition to the existing comparison, perhaps the authors can also validate a variant in which the auxiliary data is also drawn from the source so as to serve as a more direct comparison to the existing literature.\n\nOverall, the paper seems to have both a novel contribution and strong technical merit. However, the presentation of the method is lacking, and makes it unnecessarily difficult to understand how the model is composed of its parts and how it is trained. I think a more careful presentation of the intuition behind the method and more consistent use of notation would greatly improve the quality of this submission.\n\n=========================\nUpdate after author rebuttal:\n=========================\nI have read the author\'s response and have looked at the changes to the manuscript. I am satisfied with the improvements to the paper and have changed my review to \'accept\'. ', 'pros:\nThis is a great paper - I enjoyed reading it. The authors lay down a general method for addressing various transfer learning problems: transferring across domains and tasks and in a unsupervised fashion. The paper is clearly written and easy to understand. Even though the method combines the previous general learning frameworks, the proposed algorithm for  LEARNABLE CLUSTERING OBJECTIVE (LCO) is novel, and fits very well in this framework.  Experimental evaluation is performed on several benchmark datasets - the proposed approach outperforms state-of-the-art for specific tasks in most cases. \n\ncons/suggestions: \n- the authors should discuss in more detail the limitations of their approach: it is clear that when there is a high discrepancy between source and target domains, that the similarity prediction network can fail. How to deal with these cases, or better, how to detect these before deploying this method?\n- the pair-wise similarity prediction network can become very dense: how to deal with extreme cases?', ""(Summary)\nThis paper tackles the cross-task and cross-domain transfer and adaptation problems. The authors propose learning to output a probability distribution over k-clusters and designs a loss function which encourages the distributions from the similar pairs of data to be close (in KL divergence) and the distributions from dissimilar pairs of data to be farther apart (in KL divergence). What's similar vs dissimilar is trained with a binary classifier.\n\n(Pros)\n1. The citations and related works cover fairly comprehensive and up-to-date literatures on domain adaptation and transfer learning.\n2. Learning to output the k class membership probability and the loss in eqn 5 seems novel.\n\n(Cons)\n1. The authors overclaim to be state of the art. For example, table 2 doesn't compare against two recent methods which report results exactly on the same dataset. I checked the numbers in table 2 and the numbers aren't on par with the recent methods. 1) Unsupervised Pixel-Level Domain Adaptation with Generative Adversarial Networks, Bousmalis et al. CVPR17, and 2) Learning Transferrable Representations for Unsupervised Domain Adaptation, Sener et al. NIPS16. Authors selectively cite and compare Sener et al. only in SVHN-MNIST experiment in sec 5.2.3 but not in the Office-31 experiments in sec 5.2.2.\n2. There are some typos in the related works section and the inferece procedure isn't clearly explained. Perhaps the authors can clear this up in the text after sec 4.3.\n\n(Assessment)\nBorderline. Refer to the Cons section above.""]","[50, 80, -30]","[75, 70, 20]","[""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the novelty and strong technical merit of the paper, as well as its thorough experimental evaluation and strong results. However, they also express significant concerns about the clarity of presentation and some experimental details. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and balances negative feedback with positive observations. They also show willingness to change their opinion based on the authors' response, which indicates a fair and courteous approach. The reviewer's tone is professional and helpful, offering specific suggestions for improvement rather than just criticism."", ""The sentiment score is 80 (positive) because the reviewer starts with 'This is a great paper - I enjoyed reading it' and provides several positive comments about the paper's clarity, novelty, and performance. The few cons mentioned are framed as suggestions for improvement rather than major criticisms. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, praising the authors' work and offering constructive feedback. The suggestions are phrased politely, using phrases like 'the authors should discuss' rather than more demanding language. The overall tone is professional and courteous, maintaining a positive and supportive attitude while still providing valuable feedback."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('Pros'), they also list significant 'Cons' and give an overall 'Borderline' assessment. The criticism about overclaiming results and selective comparison suggests a negative leaning. The politeness score is 20 because the reviewer uses professional language and provides both pros and cons, showing a balanced approach. They offer specific suggestions for improvement, which is constructive. However, the directness of the criticism, while not impolite, prevents a higher politeness score.""]"
"['This paper proposes a new way to create adversarial examples. Instead of changing pixel values they perform spatial transformations. \n\nThe authors obtain a flow field that is optimized to fool a target classifier. A regularization term controlled by a parameter tau is ensuring very small visual difference between the adversarial and the original image. \n\nThe used spatial transformations are differentiable with respect to the flow field (as was already known from previous work on spatial transformations) it is easy to perform gradient descent to optimize the flow that fools classifiers for targeted and untargeted attacks. \n\nThe obtained adversarial examples seem almost imperceivable (at least for ImageNet). \nThis is a new direction of attacks that opens a whole new dimension of things to consider. \n\nIt is hard to evaluate this paper since it opens a new direction but the authors do a good job using numerous datasets, CAM attention visualization and also additional materials with high-res attacks. \n\nThis is a very creative new and important idea in the space of adversarial attacks. \n\nEdit: After reading the other reviews , the replies to the reviews and the revision of the paper with the human study on perception, I increase my score to 9. This is definitely in the top 15% of ICLR accepted papers, in my opinion.   \n\nAlso a remark: As far as I understand, a lot of people writing comments here have a misconception about what this paper is trying to do: This is not about improving attack rates, or comparing with other attacks for different epsilons, etc. \nThis is a new *dimension* of attacks. It shows that limiting l_inf of l_2 is not sufficient and we have to think of human perception to get the right attack model. Therefore, it is opening a new direction of research and hence it is important scholarship. It is asking a new question, which is frequently more important than improving performance on previous benchmarks. \n\n', 'This paper explores a new way of generating adversarial examples by slightly morphing the image to get misclassified by the model. Most other adversarial example generation methods tend to rely on generating high frequency noise patterns based by optimizing the perturbation on an individual pixel level. The new approach relies on gently changing the overall image by computing a flow an spatially transforming the image according to that flow. An important advantage of that approach is that the new attack is harder to protect against than to previous attacks according to the pixel based optimization methods.\n\nThe paper describes a novel model method that might become a new important line of attack. And the paper clearly demonstrates the advantages of this attack on three different data sets.\n\nA minor nitpick: the ""optimization based attack (Opt)"" was first employed in the original ""Intriguing Properties..."" 2013 paper using box-LBFGS as the method of choice predating FGSM.', ""This paper creates adversarial images by imposing a flow field on an image such that the new spatially transformed image fools the classifier. They minimize a total variation loss in addition to the adversarial loss to create perceptually plausible adversarial images, this is claimed to be better than the normal L2 loss functions.\n\nExperiments were done on MNIST, CIFAR-10, and ImageNet, which is very useful to see that the attack works with high dimensional images. However, some numbers on ImageNet would be helpful as the high resolution of it make it potentially different than the low-resolution MNIST and CIFAR.\n\nIt is a bit concerning to see some parts of Fig. 2. Some of Fig. 2 (especially (b)) became so dotted that it no longer seems an adversarial that a human eye cannot detect. And model B in the appendix looks pretty much like a normal model. It might needs some experiments, either human studies, or to test it against an adversarial detector, to ensure that the resulting adversarials are still indeed adversarials to the human eye. Another good thing to run would be to try the 3x3 average pooling restoration mechanism in the following paper:\n\nXin Li, Fuxin Li. Adversarial Examples Detection in Deep Networks with Convolutional Filter Statistics . ICCV 2017.\n\nto see whether this new type of adversarial example can still be restored by a 3x3 average pooling the image (I suspect that this is harder to restore by such a simple method than the previous FGSM or OPT-type, but we need some numbers).\n\nI also don't think FGSM and OPT are this bad in Fig. 4. Are the authors sure that if more regularization are used these 2 methods no longer fool the corresponding classifiers?\n\nI like the experiment showing the attention heat maps for different attacks. This experiment shows that the spatial transforming attack (stAdv) changes the attention of the classifier for each target class, and is robust to adversarially trained Inception v3 unlike other attacks like FGSM and CW. \n\nI would likely upgrade to a 7 if those concerns are addressed.\n\nAfter rebuttal: I am happy with the additional experiments and would like to upgrade to an accept.""]","[90, 80, 50]","[70, 70, 70]","[""The sentiment score is 90 because the reviewer expresses a highly positive view of the paper, describing it as 'very creative', 'new and important', and 'definitely in the top 15% of ICLR accepted papers'. The reviewer also increased their score after reading revisions, indicating strong approval. The politeness score is 70 because the language used is consistently respectful and constructive. The reviewer acknowledges the paper's strengths and importance without using overly effusive language. They also politely correct misconceptions about the paper's purpose, demonstrating a considerate approach to academic discourse. The tone is professional and supportive throughout, without being excessively formal or deferential."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as exploring a 'new way' of generating adversarial examples, calls it a 'novel model method', and states it 'might become a new important line of attack'. The reviewer also praises the paper for 'clearly demonstrating' the advantages of this attack. The only criticism is a 'minor nitpick' at the end. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's contributions, and frames the single criticism as a 'minor nitpick' rather than a major flaw. The reviewer also uses phrases like 'important advantage' and 'clearly demonstrates' which convey a positive and respectful tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths and contributions, such as the experiments on multiple datasets and the attention heat maps experiment. However, they also express concerns and suggest improvements, indicating a balanced view. The initial reluctance to fully accept the paper ('I would likely upgrade to a 7 if those concerns are addressed') followed by the acceptance after rebuttal also supports a moderately positive sentiment. The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and suggests improvements rather than simply criticizing. Phrases like 'I like the experiment' and 'I am happy with the additional experiments' demonstrate a positive and courteous tone. The reviewer also provides specific suggestions for improvement without being harsh or dismissive.""]"
"['This paper introduces a generative adversarial network (GAN) for estimating individualized treatment effects (ITEs) by (1) learning a generator that tries to fool a discriminator with feature, treatment, potential outcome- vectors, and (2) by learning a GAN for the treatment effect. In my view, the counterfactual component is the interesting and original component, and the results show that the ITE GAN component further improves performance (marginally but not significant). The analysis is conducted on semi-synthetic data sets created to match real data distributions with synthetically introduced selection bias and conducts extensive experimentation. While the results show worse performance compared to existing literature in the experiment with small data sizes, the work does show improvements in larger data sets. However, Table 5 in the appendix suggests these results are not significant when considering average treatment effect estimation (eATE and eATE).\n\nQuality: good. Clarity: acceptable. Originality: original. Significance: marginal.\n\nThe ITE GAN does not significantly outperform the counterfactual GAN alone (in the S and GAN loss regime), and in my understanding the counterfactual GAN is the particularly innovative component here, i.e., can the algorithm effectively enough generate indistinguishable counterfactual outcomes from x and noise. I wonder if the paper should focus on this in isolation to better understand and characterize this contribution.\n\nWhat is the significance of bold in the tables? I\'d remove it if it\'s just to highlight which method is yours.\n\nDiscussion section should be called ""Conclusion"" and a space permitting a Discussion section should be written.\nE.g. exploration of the form of the loss when k>2, or when k is exponential e.g. a {0,1}^c hypercube for c potentially related treatment options in an order set. \nE.g. implications of underperformance in settings with small data sets. We have lots of large data sets where ground truth is unknown, and relatively more small data sets where we can identify ground truth at some cost.\nE.g. discussion of Table 2 (ITEs) where GANITE is outperforming the methods (at least on large data sets) and Table 5 (ATEs) which does not show the same result is warranted. Why might we expect this to the case?', 'Summary:\nThis paper proposes to estimate the individual treatment effects (ITE) through\ntraining two separate conditional generative adversarial networks (GANs). \n\nFirst, a counterfactual GAN is trained to estimate the conditional distribution \nof the potential outcome vector, which consists of factual outcome and all \nother counterfactual outcomes, given 1) the feature vector, 2) the treatment \nvariable, and 3) the factual outcome. After training the counterfactual GAN, \nthe complete dataset containing the observed potential outcome vector can be \ngenerated by sampling from its generator.\n\nSecond, a ITE GAN is trained to estimate the conditional distribution of the\npotential outcome vector given only the feature vector. In this way, for any\ntest sample, its potential outcomes can be estimated using the generator of the\ntrained ITE GAN. Given its pontential outcome vector, its ITE can be estimated\nas well.\n\nExperimental results on the synthetic data shows the proposed approach, called\nGANITE, is more robust to the existence of selection bias, which is defined as\nthe mismatch between the treated and controlled distributions, compared to\nits competing alternatives. Experiments on three real world datasets show\nGANITE achieves the best performance on two datasets, including Twins and Jobs.\nIt does not perform very well on the IHDP dataset. The authors also run\nexperiments on the Twins dataset to show the proposed approach can estimate the\nmultiple treatment effects with better performance.\n\nComments\n1) This paper is well written. The background and related works are well\norganized. \n\n2) To the best of my knowledge, this is the first work that applies \nGAN to ITE estimation.\n\n3) Experiments on the synthetic data and the real-world data demonstrate the\nadvantage of the proposed approach.\n\n4) The authors directly present the formulation without providing sufficient \nmotivations. Could the authors provide more details or intuitions on why GAN \nwould improve the performance of ITE estimation compared to approaches that\nlearn representations to minimize the distance between the distributions of\ndifferent treatment groups, such as CFR_WASS?\n\n5) As is pointed out by the authors, the proposed approach does not perform\nwell when the dataset is small, such as the IHDP data. However, in practice, a\nlot of real-world datasets might have small sample size, such as the LaLonde\ndataset. Did the authors plan to extend the model to handle those small-sized \ndata sets without completely changing the model.\n\n6) When training the ITE GAN, the objective is to learn the conditional\ndistribution of the potential outcome vector given the feature vector. Did the\nauthors try the option of replacing ITE GAN with multi-task regression? Will\nthe performance become worse using multi-task regression?  I think this \ncomparison would be a sanity check on the utility of using GAN instead of \nregression models for ITE estimation.', 'This paper presents GANITE, a Generative Adversarial Network (GAN) approach for estimating Individualized Treatment Effects (ITE). This is achieved by utilising a GAN to impute the `missing` counterfactuals, i.e. the  outcomes of the treatments that were not observed in the training (i.e. factual) sample, and then using another GAN to estimate the ITE based on this `complete` dataset. The authors then proceed in combining the two GAN objectives with extra supervised losses to better account for the observed data; the GAN loss for the `G` network has an extra term for the `G` network to better predict the factual outcome `y_f` (which should be easy to do given the fact that y_f is an input to the network) and the GAN loss for the `I` network has an extra term w.r.t. the corresponding performance metric used for evaluation, i.e. PEHE for binary treatment and MSE for multiple treatments. This model is then evaluated on extensive experiments.\n\nThe paper is reasonably well-written with clear background and diagrams for the overall architecture. The idea is novel and seems to be relatively effective in practice although I do believe that it has a lot of moving parts and introduces a considerable amount of hyperameters (which generally are problematic to tune in causal inference tasks). Other than that, I have the following questions and remarks:\n- I might have misunderstood the motivation but the GAN objective for the `G` network is a bit weird; why is it a good idea to push the counterfactual outcomes close to the factual outcomes (which is what the GAN objective is aiming for)? Intuitively, I would expect that different treatments should have different outcomes and the distribution of the factual and counterfactual `y` should differ.\n- According to which metric did you perform hyper-parameter optimization on all of the experiments? \n- From the first toy experiment that highlights the importance of each of the losses it seems that the addition of the supervised loss greatly boosts the performance, compared to just using the GAN objectives. What was the relative weighting on those losses in general? \n- From what I understand the `I` network is necessary for out-of-sample predictions where you don’t have the treatment assignment, but for within sample prediction you can also use the `G` network. What is the performance gap between the `I` and `G` networks on the within-sample set? Furthermore, have you experimented with constructing `G` in a way that can represent `I` by just zeroing the contribution of `y_f` and `t`? In this way you can tie the parameters and avoid the two-step process (since `G` and `I` represent similar things).\n- For figure 2 what was the hyper parameters for CFR? CFR includes a specific knob to account for the larger mismatches between treated and control distributions. Did you do hyper-parameter tuning for all of the methods in this task?\n- I would also suggest to not use “between” when referring to the KL-divergence as it is not a symmetric quantity.\n\nAlso it should be pointed out that for IHDP the standard evaluation protocol is 1000 replications (rather than 100) so there might be some discrepancy on the scores due to that.']","[-20, 70, 50]","[50, 80, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'original component', 'improves performance'), there are several criticisms and suggestions for improvement. The reviewer points out underperformance in small datasets, lack of significant results in some areas, and suggests focusing on specific components. The overall tone suggests the paper has merit but needs substantial improvements.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They offer constructive criticism without being harsh or dismissive. Phrases like 'In my view,' 'I wonder if,' and 'Discussion section should be' indicate polite suggestions rather than demands. The reviewer also acknowledges the paper's strengths before discussing its weaknesses, which is a courteous approach in academic reviews."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, noting it is well-written, innovative, and demonstrates advantages through experiments. They also provide constructive feedback and suggestions for improvement. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as questions or suggestions rather than direct criticisms. The reviewer's tone is professional and courteous, offering balanced feedback that is both encouraging and constructive."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'reasonably well-written' with 'clear background and diagrams', and describes the idea as 'novel' and 'relatively effective in practice'. However, they also raise several questions and concerns, balancing the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions (e.g. 'I might have misunderstood', 'I would suggest'), and provides specific, constructive feedback. The reviewer maintains a professional tone while engaging critically with the content.""]"
"['This paper introduces a method for learning new tasks, without interfering previous tasks, using conceptors. This method originates from linear algebra, where a the network tries to algebraically infer the main subspace where previous tasks were learned, and make the network learn the new task in a new sub-space which is ""unused"" until the present task in hand.\n\nThe paper starts with describing the method and giving some context for the method and previous methods that deal with the same problem. In Section 2 the authors review conceptors. This method is algebraic method closely related to spanning sub spaces and SVD. The main advantage of using conceptors is their trait of boolean logics: i.e., their ability to be added and multiplied naturally. In section 3 the authors elaborate on reviewed ocnceptors method and show how to adapt this algorithm to SGD with back-propagation. The authors provide a version with batch SGD as well.\n\nIn Section 4, the authors show their method on permuted MNIST. They compare the method to EWC with the same architecture. They show that their method more efficiently suffers on permuted MNIST from less degradation. Also, they compared the method to EWC and IMM on disjoint MNIST and again got the best performance.\n\nIn general, unlike what the authors suggest, I do not believe this method is how biological agents perform their tasks in real life. Nevertheless, the authors show that their method indeed reduce the interference generated by a new task on the old learned tasks.\n\nI think that this work might interest the community since such methods might be part of the tools that practitioners have in order to cope with learning new tasks without destroying the previous ones.  What is missing is the following: I think that without any additional effort, a network can learn a new task in parallel to other task, or some other techniques may be used which are not bound to any algebraic methods. Therefore, my only concern is that in this comparison the work bounded to very specific group of methods, and the question of what is the best method for continual learning remained open.   ', '[Reviewed on January 12th]\n\nThis article applies the notion of “conceptors” -- a form of regulariser introduced by the same author a few years ago, exhibiting appealing boolean logic pseudo-operations -- to prevent forgetting in continual learning,more precisely in the training of neural networks on sequential tasks. It proposes itself as an improvement over the main recent development of the field, namely Elastic Weight Consolidation.  After a brief and clear introduction to conceptors and their application to ridge regression, the authors explain how to inject conceptors into Stochastic Gradient Descent and finally, the real innovation of the paper, into Backpropagation. Follows a section of experiments on variants of MNIST commonly used for continual learning.\n\nContinual learning in neural networks is a hot topic, and this article contributes a very interesting idea. The notion of conceptors is appealing in this particular use for its interpretation in terms of regularizer and in terms of Boolean logic.  The numeric examples, although quite toy, provide a clear illustration.\n\nA few things are still missing to back the strong claims of this paper:\n* Some considerations of the computational costs: the reliance on the full NxN correlation matrix R makes me fear it might be costly, as it is applied to every layer of the neural networks and hence is the largest number of units in a layer.  This is of course much lighter than if it were the covariance matrix of all the weights, which would be daunting, but still deserves to be addressed, if only with wall time measures.\n* It could also be welcome to use a more grounded vocabulary, e.g. on p.2 “Figure 1 shows examples of conceptors computer from three clouds of sample state points coming from a hypothetical 3-neuron recurrent network that was drive with input signals from three difference sources” could be much more simply said as “Figure 1 shows the ellipses corresponding to three sets of R^3 points”. Being less grandiose would make the value of this article nicely on its own.\n* Some examples beyond the contrived MNIST toy examples would be welcome. For example, the main method this article is compared to (EWC) had a very strong section on Reinforcement learning examples in the Atari framework, not only as an illustration but also as a motivation. I realise not everyone has the computational or engineering resources to try extensively on multiple benchmarks from classification to reinforcement learning. Nevertheless, without going to that extreme, it might be worth adding an extra demo on something bigger than MNIST. The authors transparently explain in their answer that they do not (yet!) belong to the deep learning community and hope finding some collaborations to pursue this further. If I may make a suggestion, I think their work would get much stronger impact by  doing it the reverse way: first finding the collaboration, then adding this extra empirical results, which then leads to a bigger impact publication.\n\nThe later point would normally make me attribute a score of ""6: Marginally above acceptance threshold"" by current DL community standards, but because there is such a pressing need for methods to tackle this problem, and because this article can generate thinking along new lines about this, I give it a 7 : Good paper, accept.\n', ""The paper leaves me guessing which part is a new contribution, and which one is already possible with conceptors as described in the Jaeger 2014 report. Figure (1) in the paper is identical to the one in the (short version of) the Jaeger report but is missing an explicit reference. Figure 2 is almost identical, again a reference to the original would be better.\nConceptors can be trained with a number of approaches (as described both in the 2014 Jaeger tech report and in the JMLR paper), including ridge regression. What I am missing here is a clear indication what is an original contribution of the paper, and what is already possible using the original approach. The fact that additional conceptors can be trained does not appear new for the approach described here. If the presented approach was an improvement over the original conceptors, the evaluation should compare the new and the original version.\n\nThe evaluation also leaves me a little confused in an additional dimension: the paper title and abstract suggested that the contribution is about overcoming catastrophic forgetting. The evaluation shows that the approach performs better classifying MNIST digits than another approach. This is nice but doesn't really tell me much about overcoming catastrophic forgetting. \n""]","[50, 60, -60]","[75, 70, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's potential interest to the community and its effectiveness in reducing interference between tasks. However, they express some skepticism about the method's biological plausibility and its comparison to a limited group of methods. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their concerns as suggestions rather than harsh criticisms. They use phrases like 'I think' and 'my only concern' to soften their critique, maintaining a professional and courteous tone."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as a 'good paper' with an 'interesting idea' that 'contributes' to a 'hot topic'. They recommend acceptance and give it a score of 7, which is above the acceptance threshold. However, it's not extremely positive as they do point out several missing elements. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offers constructive criticism, and even provides suggestions for improvement. They acknowledge the authors' transparency and offer collaboration ideas. The tone is professional and encouraging, though not excessively formal or deferential."", ""The sentiment score is -60 because the reviewer expresses significant confusion and criticism about the paper's originality and clarity. They point out missing references, unclear contributions, and a mismatch between the paper's title/abstract and its evaluation. These are substantial criticisms that indicate a negative sentiment, though not entirely dismissive. The politeness score is 20 because while the reviewer is critical, they use relatively neutral language and phrase their concerns as observations ('leaves me guessing', 'I am missing', 'leaves me a little confused') rather than direct accusations. They also acknowledge some positive aspects ('This is nice but...'). The reviewer maintains a professional tone throughout, avoiding harsh or rude language, but also doesn't use overtly polite phrases.""]"
"['This paper investigates the Predictive State Recurrent Neural Networks (PSRNN) model that embed the predictive states in a Reproducible Hilbert Kernel Space and then update the predictive states given new observation in this space.\nWhile PSRNN usually uses random features to project the map the states in a new space where dot product approximates the kernel well, the authors proposes to leverage orthogonal random features.\n\nIn particular, authors provide theoretical guarantee and show that the model using orthogonal features has a smaller upper bound on the failure probability regarding the empirical risk than the model using unstructured randomness. \n\nAuthors then empirically validate their model on several small-scale datasets where they compare their model with PSRNN and LSTM. They observe that PSRNN with orthogonal random features leads to lower MSE on test set than both PSRNN and LSTM and seem to reach lower value earlier in training.\n\nQuestion:\n-\tWhat is the cost of constructing orthogonal random features compared to RF?\n-\tWhat is the definition of H the Hadamard matrix in the discrete orthogonal joint definition?\n-\tWhat are the hyperparameters values use for the LSTM\n-\tEmpirical evaluations seem to use relatively small datasets composed by few dozens of temporal trajectories. Did you consider larger dataset for evaluation? \n-\tHow did you select the maximum number of epochs in Figure 5? It seems that the validation error is still decreasing after 25 epochs?\n\nPros:\n-\tProvide theoretical guarantee for the use of orthogonal random features in the context of PSRNN\nCons:\n-\tEmpirical evaluation only on small scale datasets.\n', 'I was very confused by some parts of the paper that are simple copy-past from the paper of Downey et al.  which has been accepted for publication in NIPS. In particular, in section 3, several sentences are taken as they are from the Downey et al.’s paper. Some examples :\n\n«\xa0provide a compact representation of a dynamical system\nby representing state as a set of predictions of features of future observations.\xa0» \n\n«\xa0a predictive state is defined as… , where…  is a vector of features of future observations and ...  is a vector of\nfeatures of historical observations. The features are selected such that ...  determines the distribution\nof future observations … Filtering is the process of mapping a predictive state…\xa0»\nEven the footnote has been copied & pasted: «\xa0For convenience we assume that the system is k-observable: that is, the distribution of all future observations\nis determined by the distribution of the next k observations. (Note: not by the next k observations\nthemselves.) At the cost of additional notation, this restriction could easily be lifted.\xa0»\n«\xa0 This approach is fast, statistically consistent, and reduces to simple\nlinear algebra operations.\xa0» \n\nNormally, I should have stopped reviewing, but I decided to continue  since those parts only concerned the preliminaries part.\n\nA key element in PSRNN is to used as an initialization a kernel ridge regression. The main result here, is to show that using orthogonal random features approximates well the original kernel comparing to random fourrier features as considered in PSRNN. This result is formally stated and proved in the paper.\n\nThe paper comes with some experiments in order to empirically demonstrate the superiority  orthogonal random features over RFF. Three data sets are considered (Swimmer,  Mocap and  Handwriting). \n\nI found it that the contribution of the paper is very limited. The connexion to PSRNN is very tenuous since the main results are about the regression part. in Theorems 2 and 3 there are no mention to PSRNN.\n\nAlso the experiment is not very convincing. The datasets are too small with observations in low dimensions, and I found it not very fair to consider LSTM in such settings.\n\nSome minor remarks:\n\n- p3: We use RFs-> RFFs\n- p5: ||X||, you mean |X| the size of the dataset\n- p12: Eq (9). You need to add «\xa0with probability $1-\\rho$ as in Avron’s paper.\n- p12: the derivation of Eq (10) from Eq (9) needs to be detailed.   \n\n\nI thank the author for their detailed answers. Some points have been clarified but other still raise issues. In particular, I continue thinking that the contribution is limited. Accordingly, I did not change my scores.', 'The paper tackles the problem of training predictive state recurrent neural networks (PSRNN), which \nuses large kernel ridge regression (KRR) problems as a subprimitive, and makes two main contributions:\n- the suggestion to use orthogonal random features (ORFs) in lieu of standard random fourier features (RFFs) to reduce the size of the KRR problems\n- a novel analysis of the risk of KRR using ORFs which shows that the risk of ORFs is no larger than that of using RFFs\n\nThe contribution to the practice of PSRNNs seems significant (to my non-expert eyes): when back-propagation through time is used, using ORFs to do the two-stage KRR training needed visibly outperforms using standard RFMs to do the KRR. I would like the authors to have provided results on more than the current three datasets, as well as an explanation of how meaningful the MSEs are in each dataset (is a MSE of 0.2 meaningful for the Swimmer Dataset, for instance? the reader does not know apriori). \n\nThe contribution in terms of the theory of using random features to perform kernel ridge regression is novel, and interesting. Specifically, the author argue that the moment-generating function for the pointwise kernel approximation error of ORF features grows slower than the moment-generating function for the pointwise kernel approximation error of RFM features, which implies that error bounds derived using the MGF of the RFM features will also hold for ORF features. This is a weaker result than their claim that ORFs satisfy better error, but close enough to be of interest and certainly indicates that their method is principled. Unfortunately, the proof of this result is poorly written:\n- equation (20) takes a long time to parse --- more effort should be put into making this clear\n- give a reference for the expressions given for A(k,n) in 24 and 25\n- (27) and (28) should be explained in more detail.\nMy staying power was exhausted around equation 31. The proof should be broken up into several manageable lemmas instead of its current monolithic and taxing form. \n']","[50, -70, 50]","[75, -20, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's theoretical contributions and empirical validations, while also pointing out some limitations. The review begins with a neutral summary of the paper's content, followed by a mix of positive points ('Pros') and areas for improvement ('Cons'). The questions posed are constructive and seek clarification rather than criticizing.\n\nThe politeness score is 75 (quite polite) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to describe the paper's content and findings, and frame their questions and suggestions in a non-confrontational manner. The use of bullet points for questions and pros/cons helps organize the feedback clearly and courteously. The reviewer doesn't use any harsh or dismissive language, even when pointing out limitations."", ""The sentiment score is -70 because the reviewer expresses significant confusion and disappointment with the paper. They point out multiple instances of plagiarism, state that the contribution is very limited, and find the experiments unconvincing. The only positive aspect mentioned is the formal proof of a result, but this is overshadowed by the numerous criticisms. The politeness score is -20 because while the reviewer uses some polite phrases ('I thank the author'), the overall tone is quite critical and direct. The reviewer states they 'should have stopped reviewing' due to plagiarism, which is a strongly negative statement. They also use phrases like 'not very fair' and 'very confused', which contribute to a somewhat impolite tone. However, the reviewer does provide specific feedback and recommendations, which prevents the score from being even lower."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the significance of the paper's contributions and finds the theoretical work interesting, despite some criticisms. They use phrases like 'significant contribution' and 'novel, and interesting,' indicating a generally positive view. However, they also point out areas for improvement, particularly in the presentation of the proof, which prevents a higher score. The politeness score is 60 (moderately polite) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I would like the authors to have provided' instead of making demands, and they acknowledge their own potential lack of expertise ('to my non-expert eyes'). The criticism is constructive and presented in a considerate manner, though not overly deferential or excessively polite.""]"
"['The authors propose an approach for training deep learning models for situation where there is not enough reliable annotated data.  This algorithm can be useful because correct annotation of enough cases to train a deep model in many domains is not affordable.  The authors propose to combine a huge number of weakly annotated data with a small set of strongly annotated cases to train a model in a student-teacher framework. The authors evaluate their proposed methods on one toy problem and two real-world problems. The paper is well written, easy to follow, and have good experimental study.  My main problem with the paper is the lack of enough motivation and justification for the proposed method; the methodology seems pretty ad-hoc to me and there is a need for more experimental study to show how the methodology work. Here are some questions that comes to my mind:  (1) Why first building a student model only using the weak data and why not all the data together to train the student model? To me, it seems that the algorithm first tries to learn a good representation for which lots of data is needed and the weak training data can be useful but why not combing with the strong data? (2) What are the sensitivity of the procedure to how weakly the weak data are annotated (this could be studied using both toy example and real-world examples)? (3) The authors explicitly suggest using an unsupervised method (check Baseline no.1) to annotate data weakly? Why not learning the representation using an unsupervised learning method (unsupervised pre training)? This should be at least one of the baselines.\n(4) the idea of using surrogate labels to learn representation is also not new. One example work is ""Discriminative Unsupervised Feature Learning with Exemplar Convolutional Neural Networks"". The authors didn\'t compare their method with this one.', 'This paper suggests a simple yet effective approach for learning with weak supervision. This learning scenario involves two datasets, one with clean data (i.e., labeled by the true function) and one with noisy data, collected using a weak source of supervision.  The suggested approach assumes a teacher and student networks, and builds the final representation incrementally, by taking into account the ""fidelity"" of the weak label when training the student at the final step. The fidelity score is given by the teacher, after being trained over the clean data, and it\'s used to build a cost-sensitive loss function for the students. The suggested method seems to work well on several document classification tasks. \n\nOverall, I liked the paper.  I would like the authors to consider the following questions - \n\n- Over the last 10 years or so, many different frameworks for learning with weak supervision were suggested (e.g., indirect supervision, distant supervision, response-based, constraint-based, to name a few).  First, I\'d suggest acknowledging these works and discussing the differences to your work. Second - Is your approach applicable to these frameworks?  It would be an interesting to compare to one of those methods  (e.g., distant supervision for relation extraction using a knowledge base), and see if by incorporating fidelity score, results improve. \n\n- Can this approach be applied to semi-supervised learning? Is there a reason to assume the fidelity scores computed by the teacher would not improve the student in a self-training framework?\n\n- The paper emphasizes that the teacher uses the student\'s initial representation, when trained over the clean data.  Is it clear that this step in needed? Can you add an additional variant of your framework when the fidelity score are  computed by the teacher when trained from scratch? using different architecture than the student?\n \n - I went over the authors comments and I appreciate their efforts to help clarify the issues raised.', 'The problem of interest is to train deep neural network models with few labelled training samples. The specific assumption is there is a large pool of unlabelled data, and a heuristic function that can provide label annotations, possibly with varying levels of noises, to those unlabelled data. The adopted learning model is of a student/teacher framework as in privileged learning/knowledge distillation/model compression, and also machine teaching. The student (deep neural network) model will learn from both labelled and unlabelled training data with the labels provided by the teacher (Gaussian process) model. The teacher also supplies an uncertainty estimate to each predicted label. How about the heuristic function? This is used for learning initial feature representation of the student model. Crucially, the teacher model will also rely on these learned features. Labelled data and unlabelled data are therefore lie in the same dimensional space. \n\nSpecific questions to be addressed:\n1)\tClustering of strongly-labelled data points. Thinking about the statement “each an expert on this specific region of data space”, if this is the case, I am expecting a clustering for both strongly-labelled data points and weakly-labelled data points. Each teacher model is trained on a portion of strongly-labelled data, and will only predict similar weakly-labelled data. On a related remark, the nice side-effect is not right as it was emphasized that data points with a high-quality label will be limited. As well, GP models, are quite scalable nowadays (experiments with millions to billions of data points are available in recent NIPS/ICML papers, though, they are all rely on low dimensionality of the feature space for optimizing the inducing point locations).  It will be informative to provide results with a single GP model. \n2)\tFrom modifying learning rates to weighting samples. Rather than using uncertainty in label annotation as a multiplicative factor in the learning rate, it is more “intuitive” to use it to modify the sampling procedure of mini-batches (akin to baseline #4); sample with higher probability data points with higher certainty. Here, experimental comparison with, for example, an SVM model that takes into account instance weighting will be informative, and a student model trained with logits (as in knowledge distillation/model compression). \n']","[50, 70, -20]","[75, 80, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer starts with positive comments about the paper's usefulness, writing quality, and experimental study. However, they also express concerns about the lack of motivation and justification for the proposed method, which balances out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting their concerns. They phrase their criticisms as questions rather than direct criticisms, which is a polite approach. The reviewer also uses phrases like 'My main problem with the paper is...' which is a gentle way to introduce criticism. The overall tone is constructive and professional, maintaining politeness while still providing critical feedback."", ""The sentiment score is 70 (positive) because the reviewer starts by saying they 'liked the paper' and describes the approach as 'simple yet effective'. The overall tone is constructive and appreciative of the work. The politeness score is 80 (polite) due to the respectful language used throughout. The reviewer uses phrases like 'I would like the authors to consider' and 'I appreciate their efforts', which are courteous ways of providing feedback. The questions are framed as suggestions rather than demands, and the reviewer acknowledges the authors' previous efforts to address concerns. The review maintains a professional and respectful tone while providing constructive criticism and suggestions for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting aspects of the work, they raise several critical points and suggest significant changes. The reviewer questions some of the assumptions and methods, and proposes alternative approaches, indicating that the paper needs substantial improvements. However, the tone is not entirely negative, as the reviewer also offers constructive suggestions.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'It will be informative to provide...' and 'Here, experimental comparison with... will be informative,' which suggest improvements in a polite manner. The reviewer also acknowledges the potential of the work and frames their criticisms as questions or suggestions rather than direct criticisms. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral, professional tone overall.""]"
"['This paper shows that learning sentence representations from a diverse set of tasks (skip-thought objective, MT, constituency parsing, and natural language inference) produces .\nThe main contribution of the paper is to show learning from multiple tasks improves the quality of the learned representations.\nExperiments on various text classification and sentiment analysis datasets show that the proposed method is competitive with existing approaches.\nThere is an impressive number of experiments presented in the paper, but the results are a bit mixed, and it is not always clear that adding more tasks help.\n\nI think this paper addresses an important problem of learning general purpose sentence representations. \nHowever, I am unable to draw a definitive conclusion from the paper. \nFrom Table 2, the best performing model is not always the one with more tasks. \nFor example, adding a parsing objective can either improve or lower the performance quite significantly.\nCould it be that datasets such as MRPC, SICK, and STSB require more understanding of syntax?\nEven if this is the case, why adding this objective hurt performance for other datasets?\nImportantly, it is also not clear whether the performance improvement comes from having more unlabeled data (even if it is trained with the same training objective) or having multiple training objectives.\nAnother question I have is that if there is any specific reason that language modeling is not included as one of the training objectives to learn sentence representations, given that it seems to be the easiest one to collect training data for.\n\nThe results for transfer learning and low resource settings are more positive.\nHowever, it is not surprising that pretraining parts of the model on a large amount of unlabeled data helps when there is not a lot of labeled examples.\n\nOverall, while the main contribution of the paper is that having multiple training objectives help learning better sentence, I am not yet convinced by the experiments that this is indeed the case.', 'Follow-Up Comments\n----\n\nI continue to argue that this paper makes a contribution to a major open question, and clearly warrants acceptance. \n\nI agree with R1 that the results do not tell a completely clear story, and that the benefits of pretraining are occasionally minimal or absent. However, R1 uses this as the basis to argue for rejection, which does not seem reasonable to me at all. This limitation is an empirical fact that the paper has done a reasonable job of revealing, and it does not take away the paper\'s reason for existence, since many of the results are still quite strong, and the trends do support the merit of the proposed approach.\n\nThe authors mostly addressed my main concern, which was the relatively weak ablation. More combinations would be nice, but assuming reasonable resource constraints, I think the authors have done their due diligence, and the paper makes a clear contribution. I disagree with the response, though, that the authors can lean on other papers to help fill in the ablation—every paper in this area uses subtly different configurations.\n\nI have one small lingering concern, which is not big enough to warrant acceptance: R2\'s point 10 is valid—the use of multiple RNNs trained on different objectives in the ablation experiments unexpected and unusual, and deserves mention in the body of the paper, rather than only in an appendix.\n\n----\nOriginal Review\n---\n\nThis paper explores a variety of tasks for the pretraining of a bidirectional GRU sentence encoder for use in data-poor downstream tasks. The authors find that the combination of supervised training with NLI, MT, and parsing, plus unsupervised training on the SkipThought objective yields a model that robustly outperforms the best prior method on every task included in the standard SentEval suite, and several others.\n\nThis paper isn\'t especially novel. The main results of the paper stem from a combination of a few ideas that were ripe for combination (SkipThought from Kiros, BiLSTM-max and S/MNLI from Conneau, MT from McCann, parsing following Luong, etc.). However, the problem that the paper addresses is a major open issue within NLP, and the paper is very well done, so it would be in the best interest of all involved to make sure that the results are published promptly. I strongly support acceptance.\n\nMy one major request would be a more complete ablation analysis. It would be valuable for researchers working on other languages (among others) to know which labeled or unlabeled datasets contributed the most. Your ablation does not offer enough evidence to one to infer this---among other things, NLI and MT are never presented in isolation, and parsing is never presented without those two. Minimally, this should involve presenting results for models trained separately on each of the pretraining tasks.\n\nI\'ll also echo another question from Samuel\'s comment: Could you say more about how you conducted the evaluation on the SentEval tasks? Did your task-specific model (or the training/tuning procedure for that model) differ much from prior work?\n\nDetails:\n\nThe paragraph starting ""we take a simpler approach"" is a bit confusing. If task batches are sampled *uniformly*, how is NLI be sampled less often than the other tasks?\n\nGiven how many model runs are presented, and that the results don\'t uniformly favor your largest/last model, it\'d be helpful to include some kind of average of performance across tasks that can be used as a single-number metric for comparison. This also applies to the word representation evaluation table.\n\nWhen comparing word embeddings, it would be helpful to include the 840B-word release of GloVe embeddings. Impressionistically, that is much more widely used than the older 6B-word release for which Faruqui reports numbers. This isn\'t essential to the paper, but it would make your argument in that section more compelling.\n\n""glove"" => GloVe; ""fasttext"" => fastText', '---- updates: ----\n\nI had a ton of comments and concerns, and I think the authors did an admirable job in addressing them.  I think the paper represents a solid empirical contribution to this area and is worth publishing in ICLR. \n\n---- original review follows: ----\n\nThis paper is about learning sentence embeddings by combining a bunch of training signals: predicting the next & previous sentences (skip-thought), predicting the sentence\'s translation, classifying entailment relationships between two sentences, and predicting the constituent parse of a sentence. This is a simple idea that combines a bunch of things from prior work into one framework and yields strong results, outperforming most prior work on most tasks. \n\nI think this paper is impressive in how it scales up training to use so many tasks and such large training sets for each task.  That and its strong experimental results make it worthy of publication. It\'s not very surprising that adding more tasks and data improves performance on average across downstream tasks, but it is nice to see the experimental results in detail. While many people would think of this idea, few would have the resources and expertise necessary to do it justice.  I also like how the authors move beyond the standard sentence tasks to evaluate also on the Quora question duplicate task with different amounts of training data and also consider the sentence characteristic / syntactic property tasks.  It would be great if the authors could release their pretrained sentence representation model so that other researchers could use it. \n\nI do have some nitpicks here and there with the presentation and exposition, and I am concerned that at times the paper appears to be minimizing its weaknesses, but I think these are things that can be addressed in the next revision. I understand that sometimes it\'s tempting to minimize one\'s weaknesses in order to get a paper accepted because the reviewers may not understand the area very well and may get hung up on the wrong things. I understand the area well and so all the feedback I offer below comes from a place of desiring this paper\'s publication while also desiring it to be as accurate and helpful for the community as possible. \n\nBelow I\'ll discuss my concerns with the experiments and description of the results.\n\nRegarding the results in Table 2:\n\nThe results in Table 2 seem a little bit unstable, as it is unclear which setting to use for the classification tasks; maybe it depends on the kind of classification being performed. One model seems best for the sentiment tasks (""+2L +STP"") while other models seem best for SUBJ and MPQA.  Adding parsing as a training task hurts performance on the sentence classification tasks while helping performance on the semantic tasks, as the authors note.  It is unclear which is the best general model.  In particular, when others write papers comparing to the results in this paper, which setting should they compare to?  It would be nice if the authors could discuss this. \n\nThe results reported for the CNN-LSTM of Gan et al. do not exactly match those of any single row from Gan et al, either v1 or v2 on arxiv or the published EMNLP version. How were those specific numbers selected? \n\nThe caption of Table 2 states ""All results except ours are taken from Conneau et al. (2017)."" However, Conneau et al (neither the latest arxiv version nor the published EMNLP version) does not include many of the results in the table, such as CNN-LSTM and DiscSent mentioned in the following sentence in the caption. Did the authors replicate the results of those methods themselves, or report them from other papers?\n\nWhat does bold and underlining indicate in Table 2?  I couldn\'t find this explained anywhere. \n\nAt the bottom of Table 2, in the section with approaches trained from scratch on these tasks, I\'d suggest including the 89.7 SST result of Munkhdalai and Yu (2017) and the 96.1 TREC result of Zhou et al. (2016) (as well as potentially other results from Zhou et al, since they report results on others of these datasets). The reason this is important is because readers may observe that the paper\'s new method achieves higher accuracies on SST and TREC than all other reported results and mistakenly think that the new method is SOTA on those tasks.  I\'d also suggest adding the results from Radford et al. (2017) who report 86.9 on MR and 91.4 on CR.  For other results on these datasets, including stronger results in non-fixed-dimensional-sentence-embedding transfer settings, see results and references in McCann et al. (2017).  While the methods presented in this paper are better than prior work in learning general purpose, fixed-dimensional sentence embeddings, they still do not produce state-of-the-art results on that many of these tasks, if any.  I think this is important to note. \n\nFor all tasks for which there is additional training, there\'s a confound due to the dimensionality of the sentence embeddings across papers. Using higher-dimensional sentence embeddings leads to more parameters in the linear model being trained on the task data. So it is unclear if the increase in hidden units in rows with ""+L"" is improving the results because of providing more weights for the linear model or whether it is learning a better sentence representation. \n\nThe main sentence embedding results are in Table 2, and use the SentEval framework. However, not all tasks are included. The STS Benchmark results are included, which use an additional layer trained on the STS Benchmark training data just like the SICK tasks. But the other STS results, which use cosine similarity on the embedding space directly without any retraining, are only included in the appendix (in Table 7). The new approach does not do very well on those unsupervised tasks. On two years of data it is better than InferSent and on two years it is worse. Both are always worse than the charagram-phrase results of Wieting et al (2016a), which has 66.1 on 2012, 57.2 on 2013, 74.7 on 2014, and 76.1 on 2015.  Charagram-phrase trains on automatically-generated paraphrase phrase pairs, but these are generated automatically from parallel text, the same type of resource used in the ""+Fr"" and ""+De"" models proposed in this submission, so I think it should be considered as a comparable model. \n\nThe results in the bottom section of Table 7, reported from Arora et al (2016), were in turn copied from Wieting et al (2016b), so I think it would make sense to also cite Wieting et al (2016b) if those results are to be included. Also, it doesn\'t seem appropriate to designate those as ""Supervised Approaches"" as they only require parallel text, which is a subset of the resources required by the new model. \n\nThere are some other details in the appendix that I find concerning:\n\nSection 8 describes how there is some task-specific tuning of which function to compute on the encoder to produce the sentence representation for the task.  This means that part of the improvement over prior work (especially skip-thought and InferSent) is likely due to this additional tuning. So I suppose to use these sentence representations in other tasks, this same kind of tuning would have to be done on a validation set for each task?  Doesn\'t that slightly weaken the point about having ""general purpose"" sentence representations?\n\nSection 9 provides details about how the representations are created for different training settings. I am confused by the language here. For example, the first setting (""+STN +Fr +De"") is described as ""A concatenation of the representations trained on these tasks with a unidirectional and bidirectional GRU with 1500 hidden units each."" I\'m not able to parse this. I think the authors mean ""The sentence representation h_x is the concatenation of the final hidden vectors from a forward GRU (with 1500-dimensional hidden vectors) and a bidirectional GRU (also with 1500-dimensional hidden vectors)"". Is this correct? \n\nAlso in Sec 9: I found it surprising how each setting that adds a training task uses the concatenation of a representation with that task and one without that task. What is the motivation for doing this? This seems to me to be an important point that should be discussed in Section 3 or 4. And when doing this, are the concatenated representations always trained jointly from scratch with the special task only updating a subset of the parameters, or do you use the fixed pretrained sentence representation from the previous row and just concatenate it with the new one?  To be more concrete, if I want to get the encoder for the second setting (""+STN +Fr +De +NLI""), do I have to train two times or can I just train once?  That is, the train-once setting would correspond to only updating the NLI-specific representation parameters when training on NLI data; on other data, all parameters would be updated. The train-twice setting would first train a representation on ""+STN +Fr +De"", then set it aside, then train a separate representation on ""+STN +Fr +De +NLI"", then finally concatenate the two representations as my sentence representation.  Do you use train-once or train-twice? \n\nRegarding the results in Table 3:\n\nWhat do bold and underline indicate?\n\nWhat are the embeddings corresponding to the row labeled ""Multilingual""?\n\nIn the caption, I can\'t find footnote 4. \n\nThe caption includes the sentence ""our embeddings have 1040 pairs out of 2034 for which atleast one of the words is OOV, so a comparison with other embeddings isn\'t fair on RW.""  How were those pairs handled?  If they were excluded, then I think the authors should not report results on RW.  I suspect that most of the embeddings included in the table also have many OOVs in the RW dataset but still compute results on it using either an unknown word embedding or some baseline similarity of zero for pairs with an OOV. I think the authors should find some way (like one of those mentioned, or some other way) of computing similarity of those pairs with OOVs. It doesn\'t make much sense to me to omit pairs with OOVs. \n\nThere are much better embeddings on SimLex than the embeddings whose results are reported in the table. Wieting et al. (2016a) report SimLex correlation of 0.706 and Mrkšić et al. (2017) report 0.751.  I\'d suggest adding the results of some stronger embeddings to better contextualize the embeddings obtained by the new method.  Some readers may mistakenly think that the embeddings are SOTA on SimLex since no stronger results are provided in the table. \n\n\nThe points below are more minor/specific:\n\nSec. 2:\n\nIn Sec. 2, the paper discusses its focus on fixed-length sentence representations to distinguish itself from other work that produces sentence representations that are not fixed-length. I feel the motivation for this is lacking. Why should we prefer a fixed-length representation of a sentence? For certain downstream applications, it might actually be easier for practitioners to use a representation that provides a representation for each position in a sentence (Melamud et al., 2016; Peters et al., 2017; McCann et al., 2017) rather than an opaque sentence representation. Some might argue that since sentences have different lengths, it would be appropriate for a sentence representation to have a length proportional to the length of the sentence.  I would suggest adding some motivation for the focus on fixed-length representations. \n\nSec. 4.1:\n\n""We take a simpler approach and pick a new task to train on after every parameter update sampled uniformly. An NLI minibatch is interspersed after every ten parameter updates on sequence-to-sequence tasks""\nThese two sentences seem contradictory. Maybe in the first sentence ""pick a new task"" should be changed to ""pick a new sequence-to-sequence task""?\n\nSec. 5.1:\n\ntypo: ""updating the parameters our sentence"" --> ""updating the parameters of our sentence""\n\nSec. 5.2:\n\ntypo in Table 4 caption: ""and The"" --> "". The""\n\ntypo: ""parsing improvements performance"" --> ""parsing improves performance""\n\n\nIn general, there are many missing citations for the tasks, datasets, and prior work on them. I understand that the authors are pasting in numbers from many places and just providing pointers to papers that provide more citation info, but I think this can lead to mis-attribution of methods. I would suggest including citations for all datasets/tasks and methods whose results are being reported. \n\n\nReferences:\n\nMcCann, Bryan, James Bradbury, Caiming Xiong, and Richard Socher. ""Learned in translation: Contextualized word vectors."" CoRR 2017.\n\nMelamud, Oren, Jacob Goldberger, and Ido Dagan. ""context2vec: Learning Generic Context Embedding with Bidirectional LSTM."" CoNLL 2016.\n\nMrkšić, Nikola, Ivan Vulić, Diarmuid Ó. Séaghdha, Ira Leviant, Roi Reichart, Milica Gašić, Anna Korhonen, and Steve Young. ""Semantic Specialisation of Distributional Word Vector Spaces using Monolingual and Cross-Lingual Constraints."" TACL 2017.\n\nMunkhdalai, Tsendsuren, and Hong Yu. ""Neural semantic encoders."" EACL 2017. \n\nPagliardini, Matteo, Prakhar Gupta, and Martin Jaggi. ""Unsupervised Learning of Sentence Embeddings using Compositional n-Gram Features."" arXiv preprint arXiv:1703.02507 (2017).\n\nPeters, Matthew E., Waleed Ammar, Chandra Bhagavatula, and Russell Power. ""Semi-supervised sequence tagging with bidirectional language models."" ACL 2017.\n\nRadford, Alec, Rafal Jozefowicz, and Ilya Sutskever. ""Learning to generate reviews and discovering sentiment."" arXiv preprint arXiv:1704.01444 2017.\n\nWieting, John, Mohit Bansal, Kevin Gimpel, and Karen Livescu. ""Charagram: Embedding words and sentences via character n-grams."" EMNLP 2016a.\n\nWieting, John, Mohit Bansal, Kevin Gimpel, and Karen Livescu. ""Towards universal paraphrastic sentence embeddings."" ICLR 2016b.\n\nZhou, Peng, Zhenyu Qi, Suncong Zheng, Jiaming Xu, Hongyun Bao, and Bo Xu. ""Text Classification Improved by Integrating Bidirectional LSTM with Two-dimensional Max Pooling."" COLING 2016.\n']","[-30, 80, 50]","[60, 70, 80]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the importance of the problem and the impressive number of experiments, they express significant doubts about the paper's conclusions. The reviewer states they are 'unable to draw a definitive conclusion' and are 'not yet convinced by the experiments.' However, it's not entirely negative as they do note some positive aspects. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as questions or observations rather than direct attacks. They use phrases like 'I think' and 'Could it be that' which soften the critique. The reviewer also balances negative points with positive ones, showing a fair and considerate approach."", ""The sentiment score is 80 (positive) because the reviewer strongly supports acceptance, calling the paper 'very well done' and stating it 'clearly warrants acceptance'. They note it makes a contribution to a major open question. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement rather than flaws. They use phrases like 'it would be valuable' and 'my one major request' when making recommendations. The tone is professional and collegial overall, though not excessively formal or deferential."", ""The sentiment score is 50 (moderately positive) because the reviewer begins by stating that the authors did an 'admirable job' addressing their concerns and that the paper represents a 'solid empirical contribution' worthy of publication. However, the review also contains numerous critiques and suggestions for improvement, balancing out the positive sentiment. The politeness score is 80 (quite polite) because the reviewer consistently uses respectful language, acknowledges the paper's strengths, and frames criticisms constructively. They express understanding of the authors' perspective and offer detailed feedback 'from a place of desiring this paper's publication'. The reviewer also uses phrases like 'I'd suggest' and 'It would be nice if' when making recommendations, maintaining a courteous tone throughout the detailed critique.""]"
"['This paper presents several theoretical results regarding the expressiveness and learnability of ReLU-activated deep neural networks. I summarize the main results as below:\n\n(1) Any piece-wise linear function can be represented by a ReLU-acteivated DNN. Any smooth function can be approximated by such networks.\n\n(2) The expressiveness of 3-layer DNN is stronger than any 2-layer DNN.\n\n(3) Using a polynomial number of neurons, the ReLU-acteivated DNN can represent a piece-wise linear function with exponentially many pieces\n\n(4) The ReLU-activated DNN can be learnt to global optimum with an exponential-time algorithm.\n\nAmong these results (1), (2), (4) are sort of known in the literature. This paper extends the existing results in some subtle ways. For (1), the authors show that the DNN has a tighter bound on the depth. For (2), the ""hard"" functions has a better parameterization, and the gap between 3-layer and 2-layer is proved bigger. For (4), although the algorithm is exponential-time, it guarantees to compute the global optimum.\n\nThe stronger results of (1), (2), (4) all rely on the specific piece-wise linear nature of ReLU. Other than that, I don\'t get much more insight from the theoretical result. When the input dimension is n, the representability result of (1) fails to show that a polynomial number of neurons is sufficient. Perhaps an exponential number of neurons is necessary in the worst case, but it will be more interesting if the authors show that under certain conditions a polynomial-size network is good enough.\n\nResult (3) is more interesting as it is a new result. The authors present a constructive proof to show that ReLU-activated DNN can represent many linear pieces.  However, the construction seems artificial and these functions don\'t seem to be visually very complex.\n\nOverall, this is an incremental work in the direction of studying the representation power of neural networks. The results might be of theoretical interest, but I doubt if a pragmatic ReLU network user will learn anything by reading this paper.', 'The paper presents an analysis and characterization of ReLU networks (with a linear final layer) via the set of functions these networks can model, especially focusing on the set of “hard” functions that are not easily representable by shallower networks.  It makes several important contributions, including extending the previously published bounds by Telgarsky et al. to tighter bounds for the special case of ReLU DNNs, giving a construction for a family of hard functions whose affine pieces scale exponentially with the dimensionality of the inputs, and giving a procedure for searching for globally optimal solution of a 1-hidden layer ReLU DNN with linear output layer and convex loss.  I think these contributions warrant publishing the paper at ICLR 2018.  The paper is also well written, a bit dense in places, but overall well organized and easy to follow. \n\nA key limitation of the paper in my opinion is that typically DNNs do not contain a linear final layer.  It will be valuable to note what, if any, of the representation analysis and global convergence results carry over to networks with non-linear (Softmax, e.g.) final layer.  I also think that the global convergence algorithm is practically unfeasible for all but trivial use cases due to terms like D^nw, would like hearing authors’ comments in case I’m missing some simplification.\n\nOne minor suggestion for improving readability is to explicitly state, whenever applicable, that functions under consideration are PWL.  For example, adding PWL to Theorems and Corollaries in Section 3.1 will help.  Similarly would be good to state, wherever applicable, the DNN being discussed is a ReLU DNN.', ""The paper presents a series of definitions and results elucidating details about the functions representable by ReLU networks, their parametrisation, and gaps between deep and shallower nets. \n\nThe paper is easy to read, although it does not seem to have a main focus (exponential gaps vs. optimisation vs. universal approximation). The paper makes a nice contribution to the details of deep neural networks with ReLUs, although I find the contributed results slightly overstated. The 1d results are not difficult to derive from previous results. The advertised new results on the asymptotic behaviour assume a first layer that dominates the size of the network. The optimisation method appears close to brute force and is limited to 2 layers. \n\nTheorem 3.1 appears to be easily deduced from the results from Montufar, Pascanu, Cho, Bengio, 2014. For 1d inputs, each layer will multiply the number of regions at most by the number of units in the layer, leading to the condition w’ \\geq w^{k/k’}. Theorem 3.2 is simply giving a parametrization of the functions, removing symmetries of the units in the layers. \n\nIn the list at the top of page 5. Note that, the function classes might be characterized in terms of countable properties, such as the number of linear regions as discussed in MPCB, but still they build a continuum of functions. Similarly, in page 5 ``Moreover, for fixed n,k,s, our functions are smoothly parameterized''. This should not be a surprise. \n\nIn the last paragraph of Section 3 ``m = w^k-1'' This is a very big first layer. This also seems to subsume the first condition, s\\geq  w^k-1 +w(k-1) for the network discussed in Theorem 3.9. In the last paragraph of Section 3 ``To the best of our knowledge''. In the construction presented here, the network’s size is essentially in the layer of size m. Under such conditions, Corollary 6 of MPCB also reads as s^n. Here it is irrelevant whether one artificially increases the depth of the network by additional, very narrow, layers, which do not contribute to the asymptotic number of units. \n\nThe function class Zonotope is a composition of two parts. It would be interesting to consider also a single construction, instead of the composition of two constructions. \n\nTheorem 3.9 (ii) it would be nice to have a construction where the size becomes 2m + wk when k’=k. \n\nSection 4, while interesting, appears to be somewhat disconnected from the rest of the paper. \n\nIn Theorem 2.3. explain why the two layer case is limited to n=1. \n\nAt some point in the first 4 pages it would be good to explain what is meant by ``hard’’ functions (e.g. functions that are hard to represent, as opposed to step functions, etc.) \n""]","[-20, 80, -20]","[50, 70, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the paper, they ultimately describe it as 'incremental' and express doubt about its practical value. The reviewer states that most results are 'sort of known in the literature' and only extended in 'subtle ways'. They also mention that they 'don't get much more insight from the theoretical result' and doubt if a 'pragmatic ReLU network user will learn anything by reading this paper'. However, the score is not deeply negative as the reviewer does recognize some merits and new contributions. The politeness score is moderately positive (50) because the reviewer maintains a professional and objective tone throughout. They provide a clear summary of the paper's contents and offer specific, constructive feedback. While critical, the language is not harsh or personal, using phrases like 'I doubt' rather than more direct criticisms. The reviewer also acknowledges the paper's contributions alongside its limitations."", ""The sentiment score is 80 (positive) because the reviewer expresses a clear positive sentiment towards the paper. They state that the paper makes 'several important contributions' and that these contributions 'warrant publishing the paper at ICLR 2018'. The reviewer also compliments the paper as 'well written' and 'well organized'. While they do mention some limitations, these are presented as constructive feedback rather than major criticisms. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They offer criticism in a constructive manner, using phrases like 'I think' and 'would like hearing authors' comments', which shows consideration for the authors' perspective. The reviewer also balances positive feedback with suggestions for improvement, maintaining a courteous tone throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice contribution', 'easy to read'), they also express several criticisms. They state that the results are 'slightly overstated', some parts are 'not difficult to derive from previous results', and the optimization method is 'close to brute force'. The overall tone suggests more criticism than praise. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'it would be nice to have' and 'it would be good to explain', which are polite ways of suggesting improvements. The reviewer also acknowledges positive aspects before offering criticisms, which is a polite approach to feedback.""]"
"['The paper introduces a new algorithm for training GANs based on the Earth Mover’s distance. In order to avoid biased gradients, the authors use the dual form of the distance on mini-batches, to make it more robust. To compute the distance between mini batches, they use the Sinkhorn distance. Unlike the original Sinkhorn distance paper, they use the dual form of the distance and do not have biased gradients. Unlike the Cramer GAN formulation, they use a mini-batch distance allowing for a better leverage of the two distributions, and potentially decrease variance in gradients.\n\nEvaluation: the paper shows good results a battery of tasks, including a standard toy example, CIFAR-10 and conditional image generation, where they obtain better results than StackGAN. \n\nThe paper is honest about its shortcomings, in the current set up the model requires a lot of computation, with best results obtained using a high batch size.\n\nWould like to see: \n  * a numerical comparison with Cramer GAN, to see whether the additional  computational cost is worth the gains. \n  * Cramer GAN shows an increase in diversity, would like to see an analog experiment for conditional generation, like figure 3 in the Cramer GAN paper.\n', ""There have recently been a set of interesting papers on adapting optimal transport to GANs. This makes a lot of sense. The paper makes some very good connections to the state of the art and those competing approaches. The proposal makes sense from the generative standpoint and it is clear from the paper that the key contribution is the design of the transport cost. I have two main remarks and questions.\n\n* Regarding the transport cost, the authors say that the Euclidean distance does not work well. Did they try to use normalised vectors with the squared Euclidean distance ? I am asking this question because solving the OT problem with cost defined as in c_eta is equivalent to using a *normalized squared* Euclidean distance in the feature space defined by v_eta. If the answer is yes and it did not work, then there is indeed a real contribution to using the DNN. Otherwise, the contribution has to be balanced. In either case, I would have been happy to see numbers for comparison.\n\n* The square mini batch energy distance looks very much like a maximum mean discrepancy criterion (see the work of A. Gretton), up to the sign, and also to regularised approached to MMD optimisation (see the paper of Kim, NIPS'16 and references therein). The MMD is the solution of an optimisation problem which, I suppose, has lots of connections with the dual Wasserstein GAN. The authors should elaborate on the relationships, and eventually discuss regularisation in this context.\n\n"", 'The paper presents a variant of GANs in which the distance measure between the generator\'s distribution and data distribution is a combination of two recently proposed metrics. In particular, a regularized Sinkhorn loss over a mini-batch is combined with Cramer distance ""between"" mini-batches. The transport cost (used by the Sinkhorn) is learned in an adversarial fashion. Experimental results on CIFAR dataset supports the usefulness of the method.\n\nThe paper is well-written and experimental results are supportive (state-of-the-art ?)\n\nA major practical concern with the proposed method is the size of mini-batch. In the experiment, the size is increased to 8000 instances for stable training. To what extent is this a problem with large models? The paper does not investigate the effect of small batch-size on the stability of the method. Could you please comment on this?\n\nAnother issue is the adversarial training of the transport cost. Could you please explain why this design choice cannot lead instability? \n']","[60, 60, 60]","[70, 80, 80]","[""The sentiment score is 60 (positive) because the review generally praises the paper's contributions and results, noting 'good results' and honesty about limitations. However, it's not extremely positive as it suggests areas for improvement. The politeness score is 70 (polite) due to the constructive and respectful tone throughout. The reviewer acknowledges the paper's strengths and frames suggestions as 'Would like to see' rather than demands. The language is professional and objective, avoiding harsh criticism while still providing valuable feedback."", ""The sentiment score is 60 (positive) because the reviewer expresses interest in the paper's topic, acknowledges its good connections to state-of-the-art approaches, and states that the proposal makes sense. The reviewer also provides constructive feedback and questions, indicating engagement with the work. The politeness score is 80 (quite polite) due to the use of respectful language throughout, such as 'interesting papers', 'makes a lot of sense', and 'I would have been happy to see'. The reviewer asks questions and makes suggestions in a non-confrontational manner, using phrases like 'Did they try' and 'The authors should elaborate', which maintain a collegial tone. The overall structure of providing positive comments before specific recommendations also contributes to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer starts with a neutral summary of the paper, then explicitly states that the paper is 'well-written' and the experimental results are 'supportive'. The reviewer even suggests the results might be 'state-of-the-art', indicating a positive view. However, it's not extremely positive as the reviewer raises some concerns and questions. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or concerns rather than direct criticisms (e.g., 'Could you please comment on this?', 'Could you please explain...'), and acknowledges the paper's strengths before raising concerns. The use of 'please' multiple times adds to the politeness.""]"
"['Summary:\nThe paper suggests to use a modular network with a controller which makes decisions, at each time step, regarding the next nodule to apply. This network is suggested a tool for solving multi-task scenarios, where certain modules may be shared and others may be trained independently for each task. It is proposed to learn the modules with standard back propagation and the controller with reinforcement learning techniques, mostly tabular. \n\n-\tpage 4: \nIn algorithm 2, line 6, I do not understand the reward computation. It seems that either a _{k+1} subscript index is missing for the right hand side R, or an exponent of n-k is missing on \\gamma. In the current formula, the final reward affects all decisions without a decay based on the distance between action and reward gain. This issue should be corrected or explicitly stated.\n\nThe ‘collaboration reward’ is not clearly justified: If I understand correctly, It is stated that actions which were chosen often in the past get higher reward when chosen again. This may create a ‘winner takes all’ effect, but it is not clear why this is beneficial for good routing. Specifically, this term is optimized when a single action is always chosen with high probability – but such a single winner does not seem to be the behavior we want to encourage.\n\n-\tPage 5: It is not described clearly (and better: defined formally) what exactly is the state representation. It is said to include the current network output (which is a vector in R^d), the task label and the depth, but it is not stated how this information is condensed into a single integer index for the tabular methods. If I understand correctly, the state representation used in the tabular algorithms includes only the current depth. If this is true, this constitutes a highly restricted controller, making decisions only based on depth without considering the current output. \n-\tThe functional approximation versions are even less clear: Again it is not clear what information is contained in the state and how it is represented. In addition it is not clear in this case what network architecture is used for computation of the policy (PG) or valkue (Q-learning), and how exactly they are optimized.\n-\tThe WPL algorithm is not clear to me\no\t In algorithm box 3, what is R_k? I do not see it defined anywhere. Is it related to \\hat{R}? how?\no\tIs it assumed that the actions are binary? \no\tI do not understand why positive gradients are multiplied with the action probability and negative gradients with 1 minus this probability. What is the source of a-symmetry between positive and negative gradients?  \n\n-\tPage 6:\no\tIt is not clear why MNist is tested over 200 examples, where there is a much larger test set available\no\tIn MIN-MTL I do not understand the motivation from creating superclasses composed of 5 random classes each: why do we need such arbitrary and un-natural class definitions? \n\n-\tPage 7: \nThe results on Cifar-100 are compared to several baselines, but not to the standard non-MTL solution: Solve the multi-class classification problem using a softmax loss and a unified, non routing architecture in which all the layers are shared by all classes, with the only distinction in the last classification layer. If the routing solution does not beat this standard baseline, there is no justification for its more complex structure and optimization.\n\n-\tPage 8: The author report that when training the controller with single agent methods the policy collapses into choosing a single module for most tasks. However, this is not-surprising, given that the action-based reward (whos strength is unclear) seems to promote such winner-takes-all behavior.\n\nOverall:\n-\tThe paper is highly unclear in its method representation\no\tThere is no unified clear notation. The essential symbols (states, actions, rewards) are not formally defined, and often it is not clear even if they are integers, scalars, or vectors. In notation existing, there are occasional notation errors. \no\tThe reward is a) not clear, and b) not well motivated when it is explained, and c) not explicitly stated anywhere: it is said that the action-specific reward may be up to 10 times larger than the final reward, but the actual tradeoff parameter between them is not stated. Note that this parameter is important, as using a 10-times larger action-related reward means that the classification-related reward becomes insignificant.\no\tThe state representation used is not clear, and if I understand correctly, it includes only the current depth. This is a severely limited state representation, which does not enable to learn actions based on intermediate results\no\tThe continuous versions of the RL algorithms are not explained at all: no state representation, nor optimization is described.\no\tThe presentation suffers from severe over-generalization and lack of clarity, which disabled my ability to understand the network and algorithms for a specific case. Instead, I would recommend that in future versions of this document a single network, with a specific router  and set of decisions, and  with a single algorithm, will be explained with clear notation end-to-end\n\nBeyond the clarity issues, I suspect also that the novelty is minor (if the state does not include any information about the current output) and that the empirical baseline is lacking. However, it is hard to judge these due to lack of clarity.\n\n\nAfter revision:\n- Most of the clarity issues were handled well, and the paper now read nicely\n- It is now clear that routing is not done based on the current input (an example is not dynamically routed based on its current representation). Instead routing depends on the task and depth only.  This is still interesting, but is far from reaching context-dependent routing.\n- The results presented are nice and show that task-dependent routing may be better than plain baseline or the stiching alternative.  However, since this is a task transfer issue, I believe several data size points should be tested. For example, as data size rises, the task-specific-all-fc alternative is expected to get stronger (as with more data, related task are less required for good performance).\n \n\n- ', 'The paper introduces a routing network for multi-task learning. The routing network consists of a router and a set of function blocks. Router makes a routing decision by either passing the input to a function block or back to the router. This network paradigm is tested on multi-task settings of MNIST, mini-imagenet and CIFAR-100 datasets.\n\nThe paper is well-organized and the goal of the paper is valuable. However, I am not very clear about how this paper improves the previous work on multi-task learning by reading the Related Work and Results sections.\n\nThe Related Work section includes many recent work, however, the comparison of this work and previous work is not clear. For example:\n""Routing Networks share a common goal with techniques for automated selective transfer learning\nusing attention (Rajendran et al., 2017) and learning gating mechanisms between representations\n(Stollenga et al., 2014), (Misra et al., 2016), (Ruder et al., 2017).  However, these techniques have\nnot been shown to scale to large numbers of routing decisions and task."" Why couldn\'t these techniques scale to large numbers of routing decisions and task? How could the proposed network in this paper scale?\n\nThe result section also has no comparison with the previously published work. Is it possible to set similar experiments with the previously published material on this topic and compare the results?\n\n\n-- REVISED\n\nThank you for adding the comparisons with other work and re-writing of the paper for clarity.\nI increase my rating to 7.\n\n', 'In this paper, the authors present a novel formulation for learning the optimal architecture of a neural network in a multi-task learning framework. Using multi-agent reinforcement learning to find a policy — a mapping from the input layer (and task indicator) to the function block that must be used at the next layer, the paper shows improvement over hard-coded architectures with shared layers. \n\nThe idea is very interesting and the paper is well-written. The extensive review of the existing literature, along with systematically presented qualitative and quantitative results make for a clear and communicative read. I do think that further scrutiny and research would benefit the work since there are instances when the presented approach enjoys some benefits when solving the problems considered. For example, the more general formulation that uses the dispatcher does not appear to work ver well (Fig. 5), and the situation is only improved by using a task specific router. \n\nOverall, I think the idea is worthy of wide dissemination and has great potential for furthering the applications of multi-task learning. ']","[-50, -20, 80]","[20, 60, 90]","[""The sentiment score is -50 because the review is generally critical, pointing out numerous issues with clarity, methodology, and presentation. However, it's not entirely negative as it acknowledges some improvements after revision. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout, offering specific suggestions for improvement and acknowledging positive changes. The language used is not rude, but rather constructive, even when pointing out significant flaws."", 'The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-organized and has a valuable goal, they express concerns about the clarity of improvements over previous work and the lack of comparisons in the results section. However, the final paragraph indicates some improvement after revisions, which mitigates the negativity somewhat. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects of the paper and framing criticisms as questions or suggestions rather than harsh statements. The reviewer also thanks the authors for their revisions in the final paragraph, which adds to the politeness.', ""The sentiment score is 80 (positive) because the reviewer expresses that the idea is 'very interesting,' the paper is 'well-written,' and the work has 'great potential.' They also praise the 'extensive review' and 'systematically presented results.' While they suggest some areas for improvement, the overall tone is highly positive. The politeness score is 90 (very polite) due to the reviewer's consistently respectful and constructive language. They use phrases like 'I think' to soften criticisms and offer balanced feedback, acknowledging both strengths and areas for improvement. The reviewer maintains a professional and courteous tone throughout, even when suggesting further scrutiny.""]"
"['The authors develops a framework interpreting GAN algorithms as performing a form of variational inference on a generative model reconstructing an indicator variable of whether a sample is from the true of generative data distributions. Starting from the ‘non-saturated’ GAN loss the key result (lemma 1) shows that GANs minimizes the KL divergence between the generator(inference) distribution and a posterior distribution implicitly defined by the discriminator. I found the paper IWGAN and especially the AAVAE experiments quite interesting.  However the paper is also very dense and quite hard to follow at times - In general I think the paper would benefit from moving some content (like the wake-sleep part of the paper) to the appendix and concentrating more on the key results and a few more experiments as detailed in the comments / questions below.\n\nQ1) What would happen if the KL-divergence minimizing loss proposed by Huszar (see e.g http://www.inference.vc/an-alternative-update-rule-for-generative-adversarial-networks/) was used instead of the “non-saturated” GAN loss - would the residial JSD terms in Lemma 1 cancel out then?\n\nQ2) In Lemma 1 the negative JSD term looks a bit nasty to me e.g. in addition to KL divergence the GAN loss also maximises the JSD between the data and generative distributions. This JSD term acts in a somewhat opposite direction of the KL-divergence that we are interested in minimizing. Can the authors provide some more detailed comments / analysis on these two somewhat opposed terms - I find this quite important to include given the opposed direction of the JSD versus the KL term and that the JSD is ignored in e.g. section 4.1? secondly did the authors do any experiments on the the relative sizes of these two terms? I imagine it would be possible to perform some low-dimensional toy experiments where both terms were tractable to compute numerically?\n\nQ3) I think the paper could benefit from some intuition / discussion of the posterior term q^r(x|y) in lemma 1 composed on the prior p_theta0(x) and discriminator q^r(y|x). The terms drops out nicely in math however i had a bit of a hard time wrapping my head around what minimizing the KL-divergence between this term and the inference distribution p(xIy). I know this is a kind of open ended question but i think it would greatly aid the reader in understanding the paper if more ‘guidance’ is provided instead of just writing “..by definition this is the posterior.’\n\nQ4) In a similar vein to the above. It would be nice with some more discussion / definitions of the terms in Lemma 2. e.g what does “Here most of the components have exact correspondences (and the same definitions) in GANs and InfoGAN (see Table 1)” mean? \n\nQ5) The authors state that there is ‘strong connections’ between VAEs and GANs. I agree that both (after some assumptions) both minimize a KL-divergence (table 1) however to me it is not obvious how strong this relation is. Could the authors provide some discussion / thoughts on this topic?\n\nOverall i like this work but also feel that some aspects could be improved: My main concern is that a lot of the analysis hinges on the JSD term being insignificant, but the authors to my knowledge does but provide any prof / indications that this is actually true. Secondly I think the paper would greatly benefit from concentration on fewer topics (e.g. maybe drop the RW topic as it feels a bit like an appendix) and instead provide a more throughout discussion of the theory (lemma 1 + lemma 2) as well as some more experiments wrt JSD term.\n', 'The paper provides a symmetric modeling perspective (""generation"" and ""inference"" are just different naming, the underlying techniques can be exchanged) to unify existing deep generative models, particularly VAEs and GANs. Someone had to formally do this, and the paper did a good job in describing the new view (by borrowing the notations from adversarial domain adaptation), and demonstrating its benefits (by exchanging the techniques in different research lines). The connection to weak-sleep algorithm is also interesting. Overall this is a good paper and I have little to add to it.\n\nOne of the major conclusions is GANs and VAEs minimize the KL Divergence in opposite directions, thus are exposed to different issues, overspreading or missing modes. This has been noted and alleviated in [1].\n\nIs it possible to revise the title of the paper to specifically reflect the proposed idea? Other papers have attempted to unify GAN and VAE from different perspectives [1,2].\n\n[1] Symmetric variational autoencoder and connections to adversarial learning. arXiv:1709.01846\n[2] Adversarial variational Bayes: Unifying variational autoencoders and generative adversarial networks. arXiv:1701.04722, 2017.\n\n\nMinor: In Fig. 1, consider to make “(d)” bold to be consistent with other terms.  ', 'Update 1/11/18:\n\nI\'m happy with the comments from the authors. I think the explanation of non-saturating vs saturating objective is nice, and I\'ve increased the score.\n\nNote though: I absolutely expect a revision at camera-ready if the paper gets accepted (we did not get one).\n\nOriginal review:\nThe paper is overall a good contribution. The motivation / insights are interesting, the theory is correct, and the experiments support their claims.\n\nI’m not sure I agree that this is “unifying” GANs and VAEs, rather it places them within the same graphical model perspective. This is very interesting and a valuable way of looking at things, but I don’t see this as reshaping how we think of or use GANs. Maybe a little less hype, a little more connection to other perspectives would be best. In particular, I’d hope the authors would talk a little more about f-GAN, as the variational lower-bound shown in this work is definitely related, though this work uniquely connects the GAN lower bound with VAE by introducing the intractable “posterior”, q(x | y).\n\nDetailed comments:\nP1: I see f-GAN as helping link adversarial learning with traditional likelihood-based methods, notably as a dual-formulation of the same problem. It seems like there should be some mention of this.\n\nP2:\nwhat does this mean: “generated samples from the generative model are not leveraged for model learning”. The wording is maybe a little confusing.\n\nP5:\nSo here I think the connection to f-GAN is even clearer, but it isn’t stated explicitly in the paper: the discriminator defines a lower-bound for a divergence (in this case, the JSD), so it’s natural that there is an alternate formulation in terms of the posterior (as it is called in this work). As f-GAN is fairly well-known, not making this connection here I think isolates this work in a critical way that makes it seem that similar observations haven’t been made.\n\nP6:\n""which blocks out fake samples from contributing to learning”: this is an interesting way of thinking about this. One potential issue with VAEs / other MLE-based methods (such as teacher-forcing) is that it requires the model to stay “close” to the real data, while GANs do not have such a restriction. Would you care to comment on this?\n\nP8:\nI think both the Hjelm (BGAN) and Che (MaliGAN) are using these weights to address credit assignment with discrete data, but BGAN doesn’t use a MLE generator, as is claimed in this work. \n\nGeneral experimental comments:\nGenerally it looks like IWGAN and AA-VAE do as is claimed: IWGANs have better mode coverage (higher inception scores), while AA-VAEs have better likelihoods given that we’re using the generated samples as well as real data. This last one is a nice result, as it’s a general issue with RNNs (teacher forcing) and is why we need things like scheduled sampling to train on the free-running phase. Do you have any comments on this?\n\nIt would have been nice to show that this works on harder datasets (CelebA, LSUN, ImageNet).']","[20, 80, 60]","[60, 70, 70]","[""The sentiment score is slightly positive (20) because the reviewer expresses interest in parts of the paper ('I found the paper IWGAN and especially the AAVAE experiments quite interesting') and likes the work overall ('Overall i like this work'). However, they also have significant concerns and suggestions for improvement, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms constructively ('I think the paper would benefit from...'), and acknowledges positive aspects before giving critiques. They also use polite phrases like 'Could the authors provide...' when asking questions. The review maintains a professional and courteous tone while still providing detailed critical feedback."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, calling it 'a good paper' and stating they have 'little to add to it'. They praise the paper's approach and its contribution to the field. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's merits and offering constructive suggestions rather than harsh criticisms. The reviewer's tone is professional and courteous, offering minor suggestions for improvement without being overly critical. The use of phrases like 'consider to make' for suggestions further indicates politeness."", ""The sentiment score is 60 (moderately positive) because the reviewer states the paper is 'overall a good contribution' with interesting insights, correct theory, and supportive experiments. They also mention being 'happy with the comments from the authors' in the update. However, they express some reservations about the paper's framing and connections to existing work, preventing a higher score. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as questions or gentle recommendations. They acknowledge the paper's strengths before offering critiques. The tone is professional and collegial, though not overly deferential, hence the score of 70 rather than higher.""]"
"['This paper continues a trend of incremental improvements to Wasserstein GANs (WGAN), where the latter were proposed in order to alleviate the difficulties encountered in training GANs. Originally, Arjovsky et al.  [1] argued that the Wasserstein distance was superior to many others typically used for GANs. An important feature of WGANs is the requirement for the discriminator to be 1-Lipschitz, which [1] achieved simply by clipping the network weights. Recently, Gulrajani et al. [2] proposed a gradient penalty ""encouraging"" the discriminator to be 1-Lipschitz. However, their approach estimated continuity on points between the generated and the real samples, and thus could fail to guarantee Lipschitz-ness at the early training stages. The paper under review overcomes this drawback by estimating the continuity on perturbations of the real samples. Together with various technical improvements, this leads to state-of-the-art practical performance both in terms of generated images and in semi-supervised learning.  \n\nIn terms of novelty, the paper provides one core conceptual idea followed by several tweaks aimed at improving the practical performance of GANs. The key conceptual idea is to perturb each data point twice and use a Lipschitz constant to bound the difference in the discriminator’s response on the perturbed points.  The proposed method is used in eq. (6) together with the gradient penalty from [2]. The authors found that directly perturbing the data with Gaussian noise led to inferior results and therefore propose to perturb the hidden layers using dropout. For supervised learning they demonstrate less overfitting for both MNIST and CIFAR 10.  They also extend their framework to the semi-supervised setting of Salismans et al 2016 and report improved image generation. \n\nThe authors do an excellent comparative job in presenting their experiments. They compare numerous techniques (e.g., Gaussian noise, dropout) and demonstrates the applicability of the approach for a wide range of tasks. They use several criteria to evaluate their performance (images, inception score, semi-supervised learning, overfitting, weight histogram) and compare against a wide range of competing papers. \n\nWhere the paper could perhaps be slightly improved is writing clarity. In particular, the discussion of M and M\' is vital to the point of the paper, but could be written in a more transparent manner. The same goes for the semi-supervised experiment details and the CIFAR-10 augmentation process. Finally, the title seems uninformative. Almost all progress is incremental, and the authors modestly give credit to both [1] and [2], but the title is neither memorable nor useful in expressing the novel idea. \n[1] Martin Arjovsky, Soumith Chintala, and Leon Bottou. Wasserstein gan.\n\n[2] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron Courville. Improved training of wasserstein gans. \n\n', ""Updates: thanks for the authors' hard rebuttal work, which addressed some of my problems/concerns. But still, without the analysis of the temporal ensembling trick [Samuli & Timo, 2017] and data augmentation, it is difficult to figure out the real effectiveness of the proposed GAN. I would insist my previous argument and score. \n\nOriginal review:\n-----------------------------------------------------------------------------------------------------------------------------------------------------------------------\nThis paper presented an improved approach for training WGANs, by applying some Lipschitz constraint close to the real manifold in the pixel level.  The framework can also be integrated to boost the SSL performances. In experiments, the generated data showed very good qualities, measured by inception score. Meanwhile, the SSL-GANs results were impressive on MNIST and CIFAR-10, demonstrating its effectiveness. \n\nHowever, the paper has the following weakness: \n\nMissing citations: the most related work of this one is the DRAGAN work. However, it did not cite it. I think the author should cite it, make a clear justification for the comparison and emphasize the main contribution of the method. Also, it suggested that the paper should discuss its relation to other important work, [Arjovsky & Bottou 2017], [Wu et al. 2016].\n\nExperiments: as for the experimental part, it is not solid. Firstly, although the SSL results are very good, it is guaranteed the proposed GAN is good [Dai & Almahairi, et al. 2017]. Secondly, the paper missed several details, such as settings, model configuration, hyper-parameters, making it is difficult to justify which part of the model works. Since the paper using the temporal ensembling trick [Samuli & Timo, 2017],  most of the gain might be from there. Data augmentation might also help to improve. Finally, except CIFAR-10, it is better to evaluate it on more datasets. \n\nGiven the above reason, I think this paper is not ready to be published in ICLR. The author can submit it to the workshop and prepare for next conference. "", 'Summary:\n\nThe paper proposes a new regularizer for wgans, to be combined with the traditional gradient penalty. The theoretical motivation is bleak, and the analysis contains some important mistakes. The results are very good, as noticed by the comments, the fact that the method is also less susceptible to overfitting is also an important result, though this might be purely due to dropout. One of the main problems is that the largest dataset used is CIFAR, which is small. Experiments on something like bedrooms or imagenet would make the paper much stronger. \n\nIf the authors fix the theoretical analysis and add evidence in a larger dataset I will raise the score.\n\nDetailed comments:\n\n- The motivation of 1.2 and the sentence ""Arguably, it is fairly safe to limit our scope to the manifold that supports the real data distribution P_r and its surrounding regions"" are incredibly wrong. First of all, it should be noted that the duality uses 1-Lip in the entire space between Pr and Pg, not in Pr alone. If the manifolds are not extremely close (such as in the beginning of training), then the discriminator can be almost exactly 1 in the real data, and 0 on the fake. Thus the discriminator would be almost exactly constant (0-Lip) near the real manifold, but will fail to be 1-lip in the decision boundary, this is where interpolations fix this issue. See Figure 2 of the wgan paper for example, in this simple example an almost perfect discriminator would have almost 0 penalty.\n\n- In the \'Potential caveats\' section, the implication that 1-Lip may not be enforced in non-examined samples is checkable by an easy experiment, which is to look for samples that have gradients of the critic wrt the input with norm > 1. I performed the exp in figure 8 and saw that by taking a slightly higher lambda, one reaches gradients that are as close to 1 as with ct-gan. Since ct-gan uses an extra regularizer, I think the authors need some stronger evidence to support the claim that ct-gan better battles this \'potential caveat\'.\n\n- It\'s important to realize that the CT regularizer with M\' = 1 (1-Lip constraint) will only be positive for an almost 1-Lip function if x and x\' are sampled when x - x\' has a very similar direction than the gradient at x. This is very hard in high dimensional spaces, and when I implemented a CT regularizer indeed the ration of eq (4) was quite less than the norm of the gradient. It would be useful to plot the value of the CT regularizer (the eq 4 version) as the training iterations progresses. Thus the CT regularizer works as an overall Lipschitz penalty, as opposed to penalizing having more than 1 for the Lipschitz constant. This difference is non-trivial and should be discussed.\n\n- Line 11 of the algorithm is missing L^(i) inside the sum.\n\n- One shouldn\'t use MNIST for anything else than deliberately testing an overfitting problem. Figure 4 is thus relevant, but the semi-supervised results of MNIST or the sample quality experiments give hardly any evidence to support the method.\n\n- The overfitting result is very important, but one should disambiguate this from being due to dropout. Comparing with wgangp + dropout is thus important in this experiment.\n\n- The authors should provide experiments in at least one larger dataset like bedrooms or imagenet (not faces, which is known to be very easy). This would strengthen the paper quite a bit.']","[70, -60, -30]","[80, 20, 20]","[""The sentiment score is 70 (positive) because the reviewer acknowledges the paper's contributions, praising its 'state-of-the-art practical performance' and 'excellent comparative job' in experiments. They note improvements and novel ideas, though they suggest some minor areas for improvement. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offering constructive criticism and balancing positive feedback with suggestions for improvement. They use phrases like 'could perhaps be slightly improved' and 'modestly give credit', which maintain a courteous tone even when pointing out potential weaknesses."", ""The sentiment score is -60 because the reviewer expresses significant concerns and weaknesses, stating the paper is 'not ready to be published' and recommending submission to a workshop instead. However, they do acknowledge some positive aspects like 'impressive' results, preventing an extremely negative score. The politeness score is 20 because the reviewer uses generally professional language and offers constructive feedback, but there are some blunt criticisms without much softening language. The reviewer acknowledges the authors' efforts in the update, which adds to the politeness, but maintains a critical stance overall."", ""The sentiment score is -30 because the review is generally critical, pointing out several theoretical and methodological issues. However, it's not entirely negative as it acknowledges some good results and provides constructive feedback. The reviewer also indicates willingness to raise the score if improvements are made. The politeness score is 20 because the language is professional and constructive, offering specific suggestions for improvement. The reviewer uses phrases like 'If the authors fix...' and 'It would be useful to...', which are polite ways of providing criticism. However, some statements like 'incredibly wrong' and 'One shouldn't use MNIST for anything else...' are more direct, preventing a higher politeness score.""]"
"['The authors present a model for unsupervised NMT which requires no parallel corpora between the two languages of interest. While the results are interesting I find very few original ideas in this paper. Please find my comments/questions/suggestions below:\n\n1) The authors mention that there are 3 important aspects in which their model differs from a standard NMT architecture. All the 3 differences have been adapted from existing works. The authors clearly acknowledge and cite the sources. Even sharing the encoder using cross lingual embeddings has been explored in the context of multilingual NER (please see https://arxiv.org/abs/1607.00198). Because of this I find the paper to be a bit lacking on the novelty quotient. Even backtranslation has been used successfully in the past (as acknowledged by the authors). Unsupervised MT in itself is not a new idea (again clearly acknowledged by the authors).\n\n2) I am not very convinced about the idea of denoising. Specifically, I am not sure if it will work for arbitrary language pairs. In fact, I think there is a contradiction even in the way the authors write this. On one hand, they want to ""learn the internal structure of the languages involved"" and on the other hand they deliberately corrupt this structure by adding noise. This seems very counter-intuitive and in fact the results in Table 1 suggest that it leads to a drop in performance. I am not very sure that the analogy with autoencoders holds in this case.\n\n3) Following up on the above question, the authors mention that ""We emphasize, however, that it is not possible to use backtranslation alone without denoising"". Again, if denoising itself leads to a drop in the performance as compared to the nearest neighbor baseline then why use backtranslation in conjunction with denoising and not in conjunction with the baseline itself. \n\n4) This point is more of a clarification and perhaps due to my lack of understanding. Backtranslation to generate a pseudo corpus makes sense only after the model has achieved a certain (good) performance. Can you please provide details of how long did you train the model (with denoising?) before producing the backtranslations ?\n\n5) The authors mention that 100K parallel sentences may be insufficient for training a NMT system. However, this size may be decent enough for  a PBSMT system. It would be interesting to see the performance of a PBSMT system trained on 100K parallel sentences. \n\n6) How did you arrive at the beam size of 12 ? Was this a hyperparameter? Just curious.\n\n7) The comparable NMT set up is not very clear. Can you please explain it in detail ? In the same paragraph, what exactly do you mean by ""the supervised system in this paper is relatively small?""', 'unsupervised neural machine translation\n\nThis is an interesting paper on unsupervised MT. It trains a standard architecture using:\n\n1) word embeddings in a shared embedding space, learned using a recent approach that works with only tens of bilingual word papers.\n\n2) A encoder-decoder trained using only monolingual data (should cite http://www.statmt.org/wmt17/pdf/WMT15.pdf). Training uses a “denoising” method which is not new: it uses the same idea as contrastive estimation (http://www.aclweb.org/anthology/P05-1044, a well-known method which should be cited). \n\n3) Backtranslation.\n\nAll though none of these ideas are new, they haven’t been combined in this way before, and that what’s novel here. The paper is essentially a neat application of (1), and is an empirical/ systems paper. It’s essentially a proof-of-concept that it is that it’s possible to get anything at all using no parallel data. That’s surprising and interesting, but I learned very little else from it. The paper reads as preliminary and rushed, and I had difficulty answering some basic questions:\n\n* In Table (1), I’m slightly puzzled by why 5 is better than 6, and this may be because I’m confused about what 6 represents. It would be natural to compare 5 with a system trained on 100K parallel text, since the systems would then (effectively) differ only in that 5 also exploits additional monolingual data. But the text suggests that 6 is trained on much more than 100K parallel sentences; that is, it differs in at least two conditions (amount of parallel text and use of monolingual text). Since this paper’s primary contribution is empirical, this comparison should be done in a carefully controlled way, differing each of these elements in turn.\n\n* I’m very confused by the comment on p. 8 that “the modifications introduced by our proposal are also limiting” to the “comparable supervised NMT system”. According to the paper, the architecture of the system is unchanged, so why would this be the case? This comment makes it seem like something else has been changed in the baseline, which in turn makes it somewhat hard to accept the results here.\n\nComment:\n* The qualitative analysis is not really an analysis: it’s just a few cherry-picked examples and some vague observations. While it is useful to see that the system does indeed generate nontrivial content in these cases, this doesn’t give us further insight into what the system does well or poorly outside these examples. The BLEU scores suggest that it also produces many low-quality translations. What is different about these particular examples? (Aside: since the cross-lingual embedding method is trained on numerals, should we be concerned that the system fails at translating numerals?)\n\nQuestions:\n* Contrastive estimation considers other neighborhood functions (“random noise” in the parlance of this paper), and it’s natural to wonder what would happen if this paper also used these or other neighborhood functions. More importantly, I suspect the the neighborhood functions are important: when translating between Indo-European languages as in these experiments, local swaps are reasonable; but in translating between two different language families (as would often be the case in the motivating low-resource scenario that the paper does not actually test), it seems likely that other neighborhood functions would be important, since structural differences would be much larger.\n\nPresentational comments (these don’t affect my evaluation, they’re mostly observations but they contribute to a general feeling that the paper is rushed and preliminary):\n\n* BPE does not “learn”, it’s entirely deterministic.\n\n* This paper is at best tangentially related to decipherment. Decipherment operates under two quite different assumptions: there is no training data for the source language ciphertext, only the ciphertext itself (which is often very small); and the replacement function is deterministic rather than probabilistic (and often monotonic). The Dou and Knight papers are interesting, but they’re an adaptation of ideas rather than decipherment per se. Since none of those ideas are used here this feels like hand-waving.\n\n* Future work is vague: “we would like to detect and mitigate the specific causes…” “we also think that a better handling of rare words…” That’s great, but how will you do these things? Do you have specific reasons to think this, or ideas on how to approach them? Otherwise this is just hand-waving.', 'This paper describes a first working approach for fully unsupervised neural machine translation. The core ideas being this method are: (1) train in both directions (French to English and English to French) in tandem; (2) lock the embedding table to bilingual embeddings induced from monolingual data; (3) share the encoder between two languages; and (3)  alternate between denoising auto-encoder steps and back-translation steps. The key to making this work seems to be using a denoising auto-encoder where noise is introduced by permuting the source sentence, which prevents the encoder from learning a simple copy operation. The paper shows real progress over a simple word-to-word baseline for WMT 2014 English-French and English-German. Preliminary results in a semi-supervised setting are also provided.\n\nThis is solid work, presenting a reasonable first working system for unsupervised NMT, which had never been done before now. That alone is notable, and overall, I like the paper. The work shares some similarities with He et al.’s NIPS 2016 paper on “Dual learning for MT,” but has more than enough new content to address the issues that arise with the fully unsupervised scenario. The work is not perfect, though. I feel that the paper’s abstract over-claims to some extent. Also, the experimental section shows clearly that in getting the model to work at all, they have created a model with a very real ceiling on performance. However, to go from not working to working a little is a big, important first step. Also, I found the paper’s notation and prose to be admirably clear; the paper was very easy to follow.\n\nRegarding over-claiming, this is mostly an issue of stylistic preference, but this paper’s use of the term “breakthrough” in both the abstract and the conclusion grates a little. This is a solid first attempt at a new task, and it lays a strong foundation for others to build upon, but there is lots of room for improvement. I don’t think it warrants being called a breakthrough - lots of papers introduce new tasks and produce baseline solutions. I would generally advise to let the readers draw their own conclusions.\n\nRegarding the ceiling, the authors are very up-front about this in Table 1, but it bears repeating here: a fully supervised model constrained in the same way as this unsupervised model does not perform very well at all. In fact, it consistently fails to surpass the semi-supervised baseline (which I think deserved some further discussion in the paper). The poor performance of the fully supervised model demonstrates that there is a very real ceiling to this approach, and the paper would be stronger if the authors were able to show to what degree relaxing these constraints harms the unsupervised system and helps the supervised one.\n\nThe semi-supervised experiment in Sections 2.3 and 4 is a little dangerous. With BLEU scores failing to top 22 for English-French, there is a good chance that a simple phrase-based baseline on the same 100k sentence pairs with a large target language model will outperform this technique. Any low-resource scenario should include a Moses baseline for calibration, as NMT is notoriously weak with small amounts of parallel data.\n\nFinally, I think the phrasing in Section 5.1 needs to be softened, where it states, “... it is not possible to use backtranslation alone without denoising, as the initial translations would be meaningless sentences produced by a random NMT model, ...” This statement implies that the system producing the sentences for back-translation must be a neural MT system, which is not the case. For example, a related paper co-submitted to ICLR, called “Unsupervised machine translation using monolingual corpora only,” shows that one can prime back-translation with a simple word-to-word system similar to the word-to-word baseline in this paper’s Table 1.']","[-30, -20, 60]","[50, 30, 80]","[""The sentiment score is -30 because the reviewer expresses skepticism about the novelty and effectiveness of the proposed approach, stating 'I find very few original ideas in this paper' and questioning key aspects of the methodology. However, they do acknowledge some interesting results, preventing a more negative score. The politeness score is 50 because the reviewer uses respectful language throughout, phrasing criticisms as questions or suggestions rather than direct attacks. They also acknowledge the authors' proper citations and use phrases like 'please find my comments/questions/suggestions' and 'perhaps due to my lack of understanding', showing courtesy. The tone is professional and constructive overall, though not overly warm or complimentary."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting' and 'surprising', they also express significant criticisms and confusion about key aspects of the work. They state they 'learned very little else from it' and describe it as 'preliminary and rushed'. The politeness score is moderately positive (30) as the reviewer uses polite language throughout, starting with positive acknowledgments and framing criticisms as questions or suggestions rather than direct attacks. They use phrases like 'I'm slightly puzzled' and 'I'm very confused' rather than more aggressive wording. The reviewer also provides constructive feedback and specific recommendations for improvement, which contributes to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as 'solid work' and 'notable', appreciating its contribution as the first working system for unsupervised NMT. They like the paper overall and find it clear and easy to follow. However, they also point out some limitations and areas for improvement, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'I feel that' and 'I would generally advise' when suggesting improvements, which maintains a courteous tone. The reviewer also balances critique with praise, showing consideration for the authors' efforts.""]"
"['This paper proposes Graph2Gauss (G2G), a node embedding method that embeds nodes in attributed graphs (can work w/o attributes as well) into Gaussian distributions rather than conventionally latent vectors. By doing so, G2G can reflect the uncertainty of a node\'s embedding. The authors then use these Gaussian distributions and neighborhood ranking constraints to obtain the final node embeddings. Experiments on link prediction and node classification showed improved performance over several strong embedding methods. Overall, the paper is well-written and the contributions are remarkable. The reason I am giving a less possible rating is that some statements are questionable and can severely affect the conclusions claimed in this paper, which therefore requires the authors\' detailed response. I am certainly willing to change my rating if the authors clarify my questions.\n\nMajor concern 1: Is the latent vector dimension L really the same for G2G and other compared methods? \nIn the first paragraph of Section 4, it is stated that ""in all experiments if the competing techniques use an embedding of\ndimensionality L, G2G’s embedding is actually only half of this dimensionality so that the overall number of ’parameters’ per node (mean vector + variance terms) matches L.""  This setting can be wrong since the degree of freedom of a L-dim Gaussian distribution should be L+L(L-1)/2, where the first term corresponds to the mean and the second term corresponds to the covariance. If I understand it correctly, when any compared embedding method used an L-dim vector, the authors used the dimension of L/2. But this setting is wrong if one wants the overall number of ’parameters’ per node (mean vector + variance terms) matches L, as stated by the authors. Fixing L, the equivalent dimension L_G2G for G2G should be set such that L_G2G +L_G2G (L_G2G -1)/2=L, not 2*L_G2G=L.  Since this setting is universal to the follow-up analysis and may severely degrade the performance of GSG due to less embedding dimensions, I hope the authors can clarify this point.\n\nMajor concern 2: The claim on inductive learning\nInductive learning is one of the major contributions claimed in this paper. The authors claim G2G can learn an embedding of an unseen node solely based on their attributes. However, is it not clear why this can be done. In the learning stage of Sec. 3.3, the attributes do not seem to play a role in the energy function. Also, since no algorithm descriptions are available, it\'s not clear how using only an unseen node\'s attributes can yield a good embedding under G2G work (so does Sec. 4.5). \nMoreover, how does it compare to directly using raw user attributes for these tasks?\n\nMinor concern/suggestions: The ""similarity"" measure in section 3.1 using KL divergence should be better rephased by ""dissimilarity"" measure. Otherwise, one has a similarity measure $Delta$ and wants it to increase as the hop distance k decreases (closer nodes are more similar). But the ranking constraints are somewhat counter-intuitive because you want $Delta$ to be small if nodes are closer. There is nothing wrong with the ranking condition, but rather an inconsistency between the use of ""similarity"" measure for KL divergence. \n', ""This paper is well-written and easy follow. I didn't find serious concern and therefore suggest an acceptance.\n\nPros\nMethodology\n1. inductive ability: can generalize to unseen nodes without any further training\n2. personalized ranking: the model uses natural ranking that embeddings of closer nodes (considers node pairs of any distance) should be closer in the embedding space, which is more general than prevailing first and second order proximity\n3. sampling strategy: the proposed node-anchored sampling method gives unbiased estimates of loss function and successfully reduces the time complexity\n\nExperiment\n1. Evaluation tasks including link prediction and node classification are conducted across multiple datasets with additional parameter sensitivity and missing-link robustness experiments\n2. Compared with various baselines with diverse model designs such as GCN and node2vec as well as compared with naive baseline (using original node attributes as model inputs)\n3. Demonstrated the model captures uncertainties and the learned uncertainties can be used to infer latent dimensions\nRelated Works\nThe survey of related work is sufficiently wide and complete.\n\nCons\nAuthors should include which kind of model is used to do the link prediction task given embedding vectors from different models as inputs."", 'The paper proposes to learn Gaussian embeddings for directed attributed graph nodes. Each node is associated to a Gaussian representation (mean and diagonal covariance matrix). The mean and diagonal representations for a node are learned as functions of the node attributes. The algorithm is unsupervised and optimizes a ranking loss: nodes at distance 1 in the graph are closer than nodes at distance 2, etc. Distance between nodes representation is measured via KL divergence. The ranking loss is a square exponential loss proposed in energy based models. In order to limit the complexity, the authors propose the use of a sampling scheme and show the convergence in expectation of this strategy towards the initial loss. Experiments are performed on two tasks: link prediction and node classification. Baselines are unsupervised projection methods and a (supervised) logistic regression. An analysis of the algorithm behavior is then proposed.\nThe paper reads well. Using a ranking loss based on the node distance together with Gaussian embeddings is probably new, even if the novelty is not that big.  The comparisons with unsupervised methods shows that the algorithm learns relevant representations.\nDo you have a motivation for using this specific loss Eq. (1), or is it a simple heuristic choice? Did you try other ranking losses?\nFor the link prediction experiments, it is not indicated how you rank candidate links for the different methods and how you proceed with the logistic. Did you compare with a more complex supervised model than the logistic? Fort the classification tasks, it would be interesting to compare to supervised/ semi-supervised embedding methods. The performance of unsupervised embeddings for graph node classification is usually much lower than supervised/ semi-supervised methods.  Having a measure of the performance gap on the different tasks would be informative. Concerning the analysis of uncertainity, discovering that uncertainty is higher for nodes with neighbors of distinct classes is interesting. In your setting this might simply be caused by the difference in the node attributes. I was not so convinced by the conclusions on the dimensionality of the hidden representation space. An immediate conclusion of this experiment would be that only a small dimensional latent space is needed. Did you experiment with this?\nDetailed comments:\nThe title of the paper is “Deep …”. There is nothing Deep in the proposed model since the NN are simple one layer MLPs. This is not a criticism, but the title should be changed.\nThere is a typo in KL definition (d should be replaced by the dimension of the embeddings). Probably another typo: the energy should be + D_KL and not –D_KL. The paragraph below eq (1) should be modified accordingly.\nAll the figures are too small to see anything and should be enlarged.\nOverall the paper brings some new ideas. The experiments are fine, but not so conclusive.\n']","[-20, 90, 20]","[70, 70, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is well-written and has remarkable contributions, they express major concerns that could 'severely affect the conclusions claimed in this paper'. The reviewer is 'giving a less possible rating' due to these concerns. However, they are open to changing their rating if the authors address their questions, which prevents the score from being more negative. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their concerns as questions or suggestions rather than harsh criticisms. They use phrases like 'I hope the authors can clarify this point' and 'I am certainly willing to change my rating', which contribute to a polite tone."", ""The sentiment score is 90 because the review starts with a positive statement that the paper is 'well-written and easy to follow' and suggests acceptance. The reviewer lists several pros and only one minor con, indicating a highly positive sentiment. The politeness score is 70 because the language used is professional and respectful throughout. The reviewer presents their thoughts in a constructive manner, listing the strengths of the paper without using overly effusive language. The single suggestion for improvement is phrased politely as 'Authors should include...' rather than using more demanding language. The overall tone is courteous and supportive, though not excessively formal or deferential, hence the score of 70 rather than higher."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some positive aspects of the paper, such as it reading well and bringing new ideas. However, they also point out limitations and areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, asks questions rather than making demands, and offers constructive criticism. They use phrases like 'it would be interesting to' and 'Did you experiment with' which are polite ways of suggesting improvements. The reviewer also balances critique with positive comments, which contributes to the polite tone.""]"
"['In the paper titled ""Parameterized Hierarchical Procedures for Neural Programming"", the authors proposed ""Parametrized Hierarchical Procedure (PHP)"", which is a representation of a hierarchical procedure by differentiable parametrization. Each PHP is represented with two multi-layer perceptrons with ReLU activation, one for its operation statement and one for its termination statement. With two benchmark tasks (NanoCraft and long-hand addition), the authors demonstrated that PHPs are able to learn neural programs accurately from smaller amounts of strong/weak supervision. \n\nOverall the paper is well-written with clear logic and accurate narratives. The methodology within the paper appears to be reasonable to me. Because this is not my research area, I cannot judge its technical contribution. ', 'Summary of paper: The goal of this paper is to be able to construct programs given data consisting of program input and program output pairs. Previous works by Reed & Freitas (2016) (using the paper\'s references) and Cai et al. (2017) used fully supervised trace data. Li et al. (2017) used a mixture of fully supervised and weakly supervised trace data. The supervision helps with discovering the hierarchical structure in the program which helps generalization to other program inputs. The method is heavily based on the ""Discovery of Deep Options"" (DDO) algorithm by Fox et al. (2017).\n\n---\n\nQuality: The experiments are chosen to compare the method that the paper is proposing directly with the method from Li et al. (2017).\nClarity: The connection between learning a POMDP policy and program induction could be made more explicit. In particular, section 3 describes the problem statement but in terms of learning a POMDP policy. The only sentence with some connection to learning programs is the first one.\nOriginality: This line of work is very recent (as far as I know), with Li et al. (2017) being the other work tackling program learning from a mixture of supervised and weakly supervised program trace data.\nSignificance: The problem that the paper is solving is significant. The paper makes good progress in demonstrating this on toy tasks.\n\n---\n\nSome questions/comments:\n- Is the Expectation-Gradient trick also known as the reinforce/score function trick?\n- This paper could benefit from being rewritten so that it is in one language instead of mixing POMDP language used by Fox et al. (2017) and program learning language. It is not exactly clear, for example, how are memory states m_t and states s_t related to the program traces.\n- It would be nice if the experiments in Figure 2 could compare PHP and NPL on exactly the same total number of demonstrations.\n\n---\n\nSummary: The problem under consideration is important and experiments suggest good progress. However, the clarity of the paper could be made better by making the connection between POMDPs and program learning more explicit or if the algorithm was introduced with one language.', ""I thank the authors for their updates and clarifications.  I stand by my original review and score.  I think their method and their evaluation has some major weaknesses, but I think that it still provides a good baseline to force work in this space towards tasks which can not be solved by simpler models like this.  So while I'm not super excited about the paper I think it is above the accept threshold.\n--------------------------------------------------------------------------\nThis paper extends an existing thread of neural computation research focused on learning resuable subprocedures (or options in RL-speak).  Instead of simply input and output examples, as in most of the work in neural computation, they follow in the vein of the Neural Programmer-Interpreter (Reed and de Freitas, 2016) and Li et. al., 2017, where the supervision contains the full sequence of elementary actions in the domain for all samples, and some samples also contain the hierarchy of subprocedure calls.\n\nThe main focus of their work is learning from fewer fully annotated samples than prior work.  They introduce two new ideas in order to enable this:\n1.  They limit the memory state of each level in the program heirarchy to simply a counter indicating the number of elementary actions/subprocedure calls taken so far (rather than a full RNN embedded hidden/cell state as in prior work).  They also limit the subprocedures such that they do not accept any arguments.\n2.  By considering this very limited set of possible hidden states, they can compute the gradients using a dynamic program that seems to be more accurate than the approximate dynamic program used in Li et. al., 2017.  \n\nThe main limitation of the work is this extremely limited memory state, and the lack of arguments.  Without arguments, everything that parameterizes the subprocedures must be in the visible world state.  In both of their domains, this is true, but this places a significant limitation on the algorithms which can be modeled with this technique.  Furthermore, the limited memory state means that the only way a subprocedure can remember anything about the current observation is to call a different subprocedure.  Again, their two evalation tasks fit into this paradigm, but this places very significant limitations on the set of applicable domains.  I would have like to see more discussion on how constraining these limitations would be in practice.  For example, it seems it would be impossible for this architecture to perform the Nanocraft task if the parameters of the task (width, height, etc.) were only provided in the first observation, rather than every observation.  \n\nNone-the-less I think this work is an important step in our understanding of the learning dynamics for neural programs.  In particular, while the RNN hidden state memory used by the prior work enables the learning of more complicted programs *in theory*, this has not been shown in practice. So, it's possible that all the prior work is doing is learning to approixmate a much simpler architecture of this form.  Specifically, I think this work can act as a great base-line by forcing future work to focus on domains which cannot be easily solved by a simpler architecture of this form.  This limitation will also force the community to think about which tasks require a more complicated form of memory, and which can be solved with a very simple memory of this form.\n\n\nI also have the following additional concerns about the paper:\n\n1.  I found the current explanation of the algorithm to be very difficult to understand.  It's extremely difficult to understand the core method without reading the appendix, and even with the appendix I found the explanation of the level-by-level decomposition to be too terse.\n\n2.  It's not clear how their gradient approximation compares to the technique used by Li et. al.  They obviously get better results on the addition and Nanocraft domains, but I would have liked a more clear explanation and/or some experiments providing insights into what enables these improvements (or at least an admission by the authors that they don't really understand what enabled the performance improvements).\n""]","[50, 50, -20]","[75, 75, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer states that the paper is 'well-written with clear logic and accurate narratives' and that the methodology 'appears to be reasonable'. However, they also mention that they cannot judge its technical contribution, which prevents a more strongly positive score. The politeness score is 75 (quite polite) due to the reviewer's use of respectful language throughout, acknowledging the paper's strengths, and diplomatically stating their inability to judge certain aspects rather than criticizing them. The reviewer maintains a professional and courteous tone without using overly effusive praise."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the significance of the problem and the progress made, while also pointing out areas for improvement in clarity. The review begins with positive aspects ('The problem that the paper is solving is significant. The paper makes good progress...') before moving on to constructive criticism. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions ('This paper could benefit from...', 'It would be nice if...') and asking questions rather than making accusations. The reviewer also balances critique with praise, acknowledging the paper's strengths alongside areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some value in the paper, they express significant concerns and limitations. The reviewer states they are 'not super excited about the paper' and points out 'major weaknesses', though they still believe it is 'above the accept threshold'. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, beginning with a thank you and using phrases like 'I would have liked to see' rather than making demands. They provide constructive criticism and acknowledge the paper's contributions while expressing concerns. The tone remains professional and courteous throughout, even when discussing limitations.""]"
"['Eigenoption Discovery Through the Deep Successor Representation\n\nThe paper is a follow up on previous work by Machado et al. (2017) showing how proto-value functions (PVFs) can be used to define options called “eigenoptions”. In essence, Machado et al. (2017) showed that, in the tabular case, if you interpret the difference between PVFs as pseudo-rewards you end up with useful options. They also showed how to extend this idea to the linear case: one replaces the Laplacian normally used to build PVFs with a matrix formed by sampling differences phi(s\') - phi(s), where phi are features. The authors of the current submission extend the approach above in two ways: they show how to deal with stochastic dynamics and how to replace a linear model with a nonlinear one. Interestingly, the way they do so is through the successor representation (SR). Stachenfeld et al. (2014) have showed that PVFs can be obtained as a linear transformation of the eigenvectors of the matrix formed by stacking all SRs of an MDP. Thus, if we have the SR matrix we can replace the Laplacian mentioned above. This provides benefits already in the tabular case, since SRs naturally extend to domains with stochastic dynamics. On top of that, one can apply a trick similar to the one used in the linear case --that is,  construct the matrix representing the diffusion model by simply stacking samples of the SRs. Thus, if we can learn the SRs, we can extend the proposed approach to the nonlinear case. The authors propose to do so by having a deep neural network similar to Kulkarni et al. (2016)\'s Deep Successor Representation. The main difference is that, instead of using an auto-encoder, they learn features phi(s) such that the next state s\' can be recovered from it (they argue that this way psi(s) will retain information about aspects of the environment the agent has control over).\n\nThis is a well-written paper with interesting (and potentially useful) insights. I only have a few comments regarding some aspects of the paper that could perhaps be improved, such as the way eigenoptions are evaluated.\n\nOne question left open by the paper is the strategy used to collect data in order to compute the diffusion model (and thus the options). In order to populate the matrix that will eventually give rise to the PVFs the agent must collect transitions. The way the authors propose to do it is to have the agent follow a random policy. So, in order to have options that lead to more direct, ""purposeful"" behaviour, the agent must first wander around in a random, purposeless, way, and hope that this will lead to a reasonable exploration of the state space. \n\nThis problem is not specific to the proposed approach, though: in fact, any method to build options will have to resolve the same issue. One related point that is perhaps more specific to this particular work is the strategy used to evaluate the options built: the diffusion time, or the expected number of steps between any two states of an MDP when following a random walk. First, although this metric makes intuitive sense, it is unclear to me how much it reflects control performance, which is what we ultimately care about. Perhaps more important, measuring performance using the same policy used to build the options (the random policy) seems somewhat unsatisfactory to me. To see why, suppose that the options were constructed based on data collected by a non-random policy that only visits a subspace of the state space. In this case it seems likely that the decrease in the diffusion time would not be as apparent as in the experiments of the paper. Conversely, if the diffusion time were measured under another policy, it also seems likely that options built with a random policy would not perform so well (assuming that the state space is reasonably large to make an exhaustive exploration infeasible). More generally, we want options built under a given policy to reduce the diffusion time of other policies (preferably ones that lead to good control performance).\n\nAnother point associated with the evaluation of the proposed approach is the method used to qualitatively assess options in the Atari experiments described in Section 4.2. In the last paragraph of page 7 the authors mention that eigenoptions are more effective in reducing the diffusion time than “random options” built based on randomly selected sub-goals. However, looking at Figure 4, the terminal states of the eigenoptions look a bit like randomly-selected  sub-goals. This is especially true when we note that only a subset of the options are shown: given enough random options, it should be possible to select a subset of them that are reasonably spread across the state space as well. \n\nInterestingly, one aspect of the proposed approach that seems to indeed be an improvement over random options is made visible by a strategy used by the authors to circumvent computational constraints. As explained in the second paragraph of page 8, instead of learning policies to maximize the pseudo-rewards associated with eigenoptions the authors used a myopic policy that only looks one step ahead (which is the same as having a policy learned with a discount factor of zero). The fact that these myopic policies are able to navigate to specific locations and stay there suggests that the proposed approach gives rise to dense pseudo-rewards that are very informative. As a comparison, when we define a random sub-goal the resulting reward is a very sparse signal that would almost certainly not give rise to useful myopic policies. Therefore, one could argue that the proposed approach not only generate useful options, it also gives rise to dense pseudo-rewards that make it easier to build the policies associated with them.', ""The paper extends the idea of eigenoptions, recently proposed by Machado et al. to domains with stochastic transitions and where state features are learned. An eigenoption is defined as an optimal policy for a reward function defined by an eigenvector of the matrix of successor representation (SR), which is an occupancy measure induced here by a uniform policy. In high-dimensional state space, the authors propose to approximate that matrix with a convolutional neural network (CNN). The approach is evaluated in a tabular domain (i.e., rooms) and Atari games.\n\nOverall the paper is well-written and quite clear. The proposed ideas for the extension seem natural (i.e., use of SR and CNN). The theorem stated in the paper seems to provide an interesting link between SR and the Laplacian. However, a few points are not clear to me:\n- Is the result new or not? If I understand correctly, Stachenfeld et al. discussed this result, but didn't prove it. Is that correct? So the provided proof is new?\n- Besides, how are D and W exactly defined? \n- Finally, as the matrix is not symmetric, do real eigenvalues always exist?\n\nThe execution of the proposed ideas in the experiments was a bit disappointing to me. The approximated eigenoption was simply computed as a one-step greedy policy. Besides, the eigenoptions seem to help for exploration (as a uniform policy was used) as indicated by plot 3(d), but could they help for other tasks (e.g., learn to play Atari games faster or better)? I think that would be a more useful measure for the learned eigenoptions.\n\nDuring learning SR and the features, what would be the impact if the gradient for SR estimation were also propagated?\n\nIn Figure 4, the trajectories generated by the different eigenoptions are barely visible.\n\nSome typos:\n- Section 2.1:\nin the definition of G_t, the expectation is taken over p as well\nI_w and T_w should be a subset of S\n\n- in (2), the hat is missing over \\Psi\nin the definition of v_\\pi(s), r only depends on s'? This seems inconsistent with the previous definition of \\psi\n\n- p. 6:\nin the definition of L_{SR}(s, s'), why \\psi takes \\phi(s) as argument?\n\n- in conclusion:\nthat that"", '- This paper shows an equivalence between proto value functions and successor representations. It then derives the idea of eigen options from the successor representation as a mechanism for option discovery. The paper shows that even under a random policy, the eigen options can lead to purposeful options\n\n- I think this is an important conceptual paper. Automatic option discovery from raw sensors is perhaps one of the biggest open problems in RL research. This paper offers a new conceptual setup to look at the problem and consolidates different views (successor repr, proto values, eigen decomposition) in a principled manner. \n\n- I would be keen to see eigen options being used inside of the agent. Have authors performed any experiments ? \n\n- How robust are the eigen options for the Atari experiments? Basically how hand picked were the options? \n\n- Is it possible to compute eigenoptions online? This seems crucial for scaling up this approach']","[60, 20, 80]","[80, 60, 60]","[""The sentiment score is 60 (positive) because the reviewer describes the paper as 'well-written' with 'interesting (and potentially useful) insights'. They also mention that the paper extends previous work in valuable ways. However, it's not extremely positive as the reviewer does raise some concerns and suggestions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as 'comments' and 'questions'. They use phrases like 'perhaps be improved' and 'it is unclear to me' rather than making blunt criticisms. The reviewer also acknowledges when issues aren't specific to this paper, showing fairness. The tone is professional and courteous throughout."", ""The sentiment score is slightly positive (20) because the reviewer starts by acknowledging that the paper is well-written and clear, and that the proposed ideas seem natural. However, they also express some disappointment with the experiments and raise several questions, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as personal opinions (e.g., 'to me'), and offers constructive feedback. They also politely point out typos at the end. The reviewer maintains a professional tone without being overly formal or informal."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'important' and 'conceptual', praising its approach to a significant problem in RL research. They express enthusiasm about the paper's contributions and consolidation of different views. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, framing their comments as suggestions or questions rather than criticisms. They use phrases like 'I would be keen to see' and 'Is it possible', which are polite ways of inquiring about potential improvements or extensions. The reviewer also acknowledges the paper's strengths before asking for clarifications, which is a courteous approach in academic discourse.""]"
"['This paper proposes to explain the benefits of skip connections in terms of eliminating the singularities of the loss function. The discussion is largely based on a sequence of experiments, some of which are interesting and insightful. The discussion here can be useful for other researchers. \n\nMy main concern is that the result here is purely empirical, with no concrete theoretical justification. What the experiments reveal is an empirical correlation between the Eigval index and training accuracy, which can be caused by lots of reasons (and cofounders), and does not necessarily establish a causal relation. Therefore, i found many of the discussion to be questionable. I would love to see more solid theoretical discussion to justify the hypothesis proposed in this paper.\n \nDo you have a sense how accurate is the estimation of the tail probabilities of the eigenvalues? Because the whole paper is based on the approximation of the eigval indexes, it is critical to exam the estimation is accurate enough to draw the conclusions in the paper. \n\nAll the conclusions are based on one or two datasets. Could you consider testing the result on more different datasets to verify if the results are generalizable? ', 'The authors show that two types of singularities impede learning in deep neural networks: elimination singularities (where a unit is effectively shut off by a loss of input or output weights, or by an overly-strong negative bias), and overlap singularities, where two or more units have very similar input or output weights. They then demonstrate that skip connections can reduce the prevalence of these singularities, and thus speed up learning.\n\nThe analysis is thorough: the authors explore alternative methods of reducing the singularities, and explore the skip connection properties that more strongly reduce the singularities, and make observations consistent with their overarching claims.\n\nI have no major criticisms.\n\nOne suggestion for future work would be to provide a procedure for users to tailor their skip connection matrices to maximize learning speed and efficacy. The authors could then use this procedure to make highly trainable networks, and show that on test (not training) data, the resultant network leads to high performance.', 'Paper examines the use of skip connections (including residual layers) in deep networks as a way of alleviating two perceived difficulties in training: 1) when a neuron does not contain any information, and 2) when two neurons in a layer compute the same function. Both of these cases lead to singularities in the Hessian matrix, and this work includes a number of experiments showing the effect of skip connections on the Hessian during training. \n\nThis is a significant and timely topic. While I may not be the best one to judge the originality of this work, I appreciated how the authors presented clear and concise arguments with experiments to back up their claims.\n\n']","[-20, 90, 80]","[50, 80, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting and insightful' experiments, 'useful for other researchers'), they express significant concerns about the paper's lack of theoretical justification and questionable discussions. The overall tone suggests the reviewer is not fully convinced by the paper's arguments. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, framing criticisms as concerns or suggestions rather than harsh judgments. They use phrases like 'My main concern is...' and 'I would love to see...' which maintain a constructive tone. The reviewer also asks questions politely, using 'Could you consider...' and 'Do you have a sense...', showing respect for the authors while pointing out areas for improvement."", ""The sentiment score is 90 because the reviewer expresses a very positive view of the paper, stating that the analysis is thorough and that they have 'no major criticisms'. The only suggestion provided is for future work, which is not a criticism of the current paper. The politeness score is 80 because the language used is professional and respectful throughout. The reviewer acknowledges the authors' work positively and offers a constructive suggestion for future research without any harsh or negative language. The tone is consistently polite and appreciative of the authors' efforts."", ""The sentiment score is 80 (positive) because the reviewer describes the topic as 'significant and timely' and expresses appreciation for the authors' clear and concise arguments and supporting experiments. The lack of criticism and the overall positive tone suggest a favorable view of the paper. The politeness score is 70 (polite) due to the respectful and professional language used throughout. The reviewer acknowledges their potential limitations ('I may not be the best one to judge the originality') and uses phrases like 'I appreciated' which convey a courteous and constructive tone. The review focuses on the paper's strengths without using overly effusive language, maintaining a polite but professional demeanor.""]"
"['This paper examines a distributed Deep RL system in which experiences, rather than gradients, are shared between the parallel workers and the centralized learner. The experiences are accumulated into a central replay memory and prioritized replay is used to update the policy based on the diverse experience accumulated by all the of the workers. Using this system, the authors are able to harness much more compute to learn very high quality policies in little time. The results very convincingly show that Ape-X far outperforms competing algorithms such as recently published Rainbow. \n\nIt’s hard to take issue with a paper that has such overwhelmingly convincing experimental results. However, there are a couple additional experiments that would be quite nice:\n•\tIn order to understand the best way for training a distributed RL agent, it would be nice to see a side-by-side comparison of systems for distributed gradient sharing (e.g. Gorila) versus experience sharing (e.g. Ape-X). \n•\tIt would be interesting to get a sense of how Ape-X performs as a function of the number of frames it has seen, rather than just wall-clock time. For example, in Table 1, is Ape-X at 200M frames doing better than Rainbow at 200M frames?\n\nPros:\n•\tWell written and clear.\n•\tVery impressive results.\n•\tIt’s remarkable that Ape-X preforms as well as it does given the simplicity of the algorithm.\n\nCons:\n•\tHard to replicate experiments without the deep computational pockets of DeepMind.\n', 'This paper proposes a distributed architecture for deep reinforcement learning at scale, specifically, focusing on adding parallelization in actor algorithm in Prioritized Experience Replay framework. It has a very nice introduction and literature review of Prioritized experience replay and also suggested to parallelize the actor algorithm by simply adding more actors to execute in parallel, so that the experience replay can obtain more data for the learner to sample and learn. Not surprisingly, as this framework is able to learn from way more data (e.g. in Atari), it outperforms the baselines, and Figure 4 clearly shows the more actors we have the better performance we will have. \n\nWhile the strength of this paper is clearly the good writing as well as rigorous experimentation, the main concern I have with this paper is novelty. It is in my opinion a somewhat trivial extension of the previous work of Prioritized experience replay in literature; hence the challenge of the work is not quite clear. Hence, I feel adding some practical learnings of setting up such infrastructure might add more flavor to this paper, for example. ', 'A parallel aproach to DQN training is proposed, based on the idea of having multiple actors collecting data in parallel, while a single learner trains the model from experiences sampled from a central replay memory. Experiments on Atari game playing and two MuJoCo continuous control tasks show significant improvements in terms of training time and final performance compared to previous baselines.\n\nThe core idea is pretty straightforward but the paper does a very good job at demonstrating that it works very well, when implemented efficiently over a large cluster (which is not trivial). I also appreciate the various experiments to analyze the impact of several settings (instead of just reporting a new SOTA). Overall I believe this is definitely a solid contribution that will benefit both practitioners and researchers... as long as they got the computational resources to do so!\n\nThere are essentially two more things I would have really liked to see in this paper (maybe for future work?):\n- Using all Rainbow components\n- Using multiple learners (with actors cycling between them for instance)\nSharing your custom Tensorflow implementation of prioritized experience replay would also be a great bonus!\n\nMinor points:\n- Figure 1 does not seem to be referenced in the text \n- « In principle, Q-learning variants are off-policy methods » => not with multi-step unless you do some kind of correction! I think it is important to mention it even if it works well in practice (just saying « furthermore we are using a multi-step return » is too vague)\n- When comparing the Gt targets for DQN vs DPG it strikes me that DPG uses the delayed weights phi- to select the action, while DQN uses current weights theta. I am curious to know if there is a good motivation for this and what impact this can have on the training dynamics.\n- In caption of Fig. 5 25K should be 250K\n- In appendix A why duplicate memory data instead of just using a smaller memory size?\n- In appendix D it looks like experiences removed from memory are chosen by sampling instead of just removing the older ones as in DQN. Why use a different scheme?\n- Why store rewards and gamma’s at each time step in memory instead of just the total discounted reward?\n- It would have been better to re-use the same colors as in Fig. 2 for plots in the appendix\n- Would Fig. 10 be more interesting with the full plot and a log scale on the x axis?']","[80, 20, 80]","[70, 60, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, praising its 'overwhelmingly convincing experimental results' and describing it as 'well written and clear' with 'very impressive results'. The few criticisms are minor and presented as suggestions for improvement rather than flaws. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing suggestions constructively. Phrases like 'It's hard to take issue with...' and 'it would be nice to see...' indicate a polite and considerate tone. The reviewer also balances praise with constructive feedback, maintaining a professional and courteous approach."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's strengths in writing and experimentation, and notes that the proposed method outperforms baselines. However, the reviewer expresses concerns about novelty, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms, and offers constructive suggestions for improvement. The reviewer avoids harsh language and frames concerns as personal opinions (e.g., 'in my opinion'), which contributes to the polite tone."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, calling it a 'solid contribution' and praising its thorough experimentation. They appreciate the paper's demonstration of effectiveness and its potential benefits to both practitioners and researchers. The few criticisms are framed as suggestions for future work rather than shortcomings. The politeness score is 70 (polite) due to the reviewer's consistently respectful and constructive tone. They use phrases like 'I appreciate' and 'I would have really liked to see,' which are polite ways of offering feedback. The reviewer also provides specific, helpful suggestions and points out minor issues in a non-confrontational manner. The language is professional and courteous throughout, without any rudeness or harsh criticism.""]"
"['\n-----UPDATE------\n\nThe authors addressed my concerns satisfactorily. Given this and the other reviews I have bumped up my score from a 5 to a 6.\n\n----------------------\n\n\nThis paper introduces two modifications that allow neural networks to be better at distinguishing between in- and out- of distribution examples: (i) adding a high temperature to the softmax, and (ii) adding adversarial perturbations to the inputs. This is a novel use of existing methods.\n\nSome roughly chronological comments follow:\n\nIn the abstract you don\'t mention that the result given is when CIFAR-10 is mixed with TinyImageNet.\n\nThe paper is quite well written aside from some grammatical issues. In particular, articles are frequently missing from nouns. Some sentences need rewriting (e.g. in 4.1 ""which is as well used by Hendrycks..."", in 5.2 ""performance becomes unchanged"").\n\n It is perhaps slightly unnecessary to give a name to your approach (ODIN) but in a world where there are hundreds of different kinds of GANs you could be forgiven.\n\nI\'m not convinced that the performance of the network for in-distribution images is unchanged, as this would require you to be able to isolate 100% of the in-distribution images. I\'m curious as to what would happen to the overall accuracy if you ignored the results for in-distribution images that appear to be out-of-distribution (e.g. by simply counting them as incorrect classifications). Would there be a correlation between difficult-to-classify images, and those that don\'t appear to be in distribution?\n\nWhen you describe the method it relies on a threshold delta which does not appear to be explicitly mentioned again.\n\nIn terms of experimentation it would be interesting to see the reciprocal of the results between two datasets. For instance, how would a network trained on TinyImageNet cope with out-of-distribution images from CIFAR 10?\n\nSection 4.5 felt out of place, as to me, the discussion section flowed more naturally from the experimental results. This may just be a matter of taste.\n\nI did like the observations in 5.1 about class deviation, although then, what would happen if the out-of-distribution dataset had a similar class distribution to the in-distribution one? (This is in part, addressed in the CIFAR80 20 experiments in the appendices).\n\nThis appears to be a borderline paper, as I am concerned that the method isn\'t sufficiently novel (although it is a novel use of existing methods).\n\nPros:\n- Baseline performance is exceeded by a large margin\n- Novel use of adversarial perturbation and temperature\n- Interesting analysis\n\nCons:\n- Doesn\'t introduce and novel methods of its own\n- Could do with additional experiments (as mentioned above)\n- Minor grammatical errors\n', 'The paper proposes a new method for detecting out of distribution samples. The core idea is two fold: when passing a new image through the (already trained) classifier, first preprocess the image by adding a small perturbation to the image pushing it closer to the highest softmax output and second, add a temperature to the softmax. Then, a simple decision is made based on the output of the softmax of the perturbed image - if it is able some threshold then the image is considered in-distribution otherwise out-distribution.\n\nThis paper is well written, easy to understand and presents a simple and apparently effective method of detecting out of distribution samples. The authors evaluate on cifar-10/100 and several out of distribution datasets and this method outperforms the baseline by significant margins. They also examine the effects of the temperature and step size of the perturbation. \n \nMy only concern is that the parameter delta (threshold used to determine in/out distribution) is not discussed much. They seem to optimize over this parameter, but this requires access to the out of distribution set prior to the final evaluation. Could the authors comment on how sensitive the method is to this parameter? How much of the out of distribution dataset is used to determine this value, and what are the effects of this size during tuning? What happens if you set the threshold using one out of distribution dataset and then evaluate on a different one? This seems to be the central part missing to this paper and if the authors are able to address it satisfactorily I will increase my score. ', 'Detecting out of distribution examples is important since it lets you know when neural network predictions might be garbage. The paper addresses this problem with a method inspired by adversarial training, and shows significant improvement over best known method, previously published in ICLR 2017.\n\nPrevious method used at the distribution of softmax scores as the measure. Highly peaked -> confidence, spread out -> out of distribution. The authors notice that in-distribution examples are also examples where it\'s easy to drive the confidence up with a small step. The small step is in the direction of gradient when top class activation is taken as the objective. This is also the gradient used to determine influence of predictors, and it\'s the gradient term used for adversarial training ""fast gradient sign"" method.\n\nTheir experiments show improvement across the board using DenseNet on collection of small size dataset (tiny imagenet, cifar, lsun). For instance at 95% threshold (detect 95% of out of distribution examples), their error rate goes down from 34.7% for the best known method, to 4.3% which is significant enough to prefer their method to the previous work.\n\n']","[50, 60, 80]","[70, 80, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by mentioning that the authors addressed their concerns satisfactorily and increased their score. The overall tone is constructive, acknowledging the paper's strengths while also pointing out areas for improvement. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering suggestions and observations without harsh criticism. They acknowledge the paper's strengths ('well written', 'baseline performance is exceeded', 'interesting analysis') and frame criticisms as suggestions for improvement rather than outright flaws. The use of phrases like 'I'm curious', 'It would be interesting', and 'This may just be a matter of taste' further contribute to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer expresses that the paper is 'well written, easy to understand' and presents an 'apparently effective method'. They also mention that the method 'outperforms the baseline by significant margins'. However, it's not extremely positive due to the concern raised about the parameter delta. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their concern as a request for clarification rather than a criticism. Phrases like 'Could the authors comment on...' and 'if the authors are able to address it satisfactorily I will increase my score' demonstrate a constructive and courteous approach to feedback."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper's contribution, highlighting its importance and significant improvement over previous methods. The reviewer notes the paper's novel approach and its superior performance across experiments. The politeness score is 50 (slightly positive) because while the review is professional and objective, it doesn't use overtly polite language. The tone is matter-of-fact and focused on the technical aspects of the paper, without personal comments or excessive praise. The reviewer presents information clearly and respectfully, but without going out of their way to be particularly courteous.""]"
"[""The paper presents a novel view of GCN that interprets graph convolutions as integral transforms of embedding functions. This addresses the issue of lack of sample independence in training and allows for the use of Monte Carlo methods. It further explores variance reduction to speed up training via importance sampling.  The idea comes with theoretical support and experimental studies.\n\nSome questions are as follows:\n\n1) could you elaborate on n/t_l  in (5) that accounts for the normalization difference between matrix form (1) and the integral form (2) ?\n\n2) In Prop.2., there seems no essential difference between the two parts, as e(v) also depends on how the u_j's are sampled.\n\n3) what loss g is used in experiments?"", ""Update:\n\nI have read the rebuttal and the revised manuscript. Additionally I had a brief discussion with the authors regarding some aspects of their probabilistic framework. I think that batch training of GCN is an important problem and authors have proposed an interesting solution to this problem. I appreciated all the work authors put into the revision. In this regard, I have updated my rating. However, I am not satisfied with how the probabilistic problem formulation was presented in the paper. I would appreciate if authors were more upfront about the challenges of the problem they formulated and limitations of their results. I briefly summarize the key missing points below, although I acknowledge that solution to such questions is out of scope of this work.\n\n1. Sampling of graph nodes from P is not iid. Every subsequent node can not be equal to any of the previous nodes. Hence, the distribution changes and subsequent nodes are dependent on previous ones. However, exchangeability could be a reasonable assumption to make as order (in the joint distribution) does not matter for simple choices of P. Example: let V be {1,2,3} and P a uniform distribution. First node can be any of the {1,2,3}, second node given first (suppose first node is '2') is restricted to {1,3}. There is clearly a dependency and change of distribution.\n\n2. Theorem 1 is proven under the assumption that it is possible to sample from P and utilize Monte Carlo type argument. However, in practice, sampling is done from a uniform distribution over observed samples. Also, authors suggest that V may be infinite. Recall that for Monte Carlo type approaches to work, sampling distribution is ought to contain support of the true distribution. Observed samples (even as sample size goes to infinity) will never be able to cover an infinite V. Hence, Theorem 1 will never be applicable (for the purposes of evaluating population loss). Also note that this is different from a more classical case of continuous distributions, where sampling from a Gaussian, for instance, will cover any domain of true distribution. In the probabilistic framework defined by the authors it is impossible to cover domain of P, unless whole V is observed.\n\n----------------------------------------------------------------------\nThis work addresses a major shortcoming of recently popularized GCN. That is, when the data is equipped with the graph structure, classic SGD based methods are not  straightforward to apply. Hence it is not clear how to deal with large datasets (e.g., Reddit). Proposed approach uses an adjacency based importance sampling distribution to select only a subset of nodes on each GCN layer. Resulting loss estimate is shown to be consistent and its gradient is used to perform the weight updates.\n\nProposed approach is interesting and the direction of the work is important given recent popularity of the GCN. Nonetheless I have two major question and would be happy to revisit my score if at least one is addressed.\n\nTheory:\nSGD requires an unbiased estimate of the gradient to converge to the global optima in the convex loss case. Here, the loss estimate is shown to be consistent, but not guaranteed to be unbiased and nothing is said about the gradient in Algorithm 1. Could you please provide some intuition about the gradient estimate? I might not be familiar with some relevant results, but it appears to me that Algorithm 1 will not converge to the same solution as full data GD would.\n\nPractice:\nPer batch timings in Fig. 3 are not enough to argue that the method is faster as it might have poor convergence properties overall. Could you please show the train/test accuracies against training time for all compared methods?\n\nSome other concerns and questions:\n- It is not quite cleat what P is. You defined it as distribution over vertices of some (potentially infinite) population graph. Later on, sampling from P becomes equivalent to uniform sampling over the observed nodes. I don't see how you can define P over anything outside of the training nodes (without defining loss on the unobserved data), as then you would be sampling from a distribution with 0 mass on the parts of the support of P, and this would break the Monte Carlo assumptions.\n- Weights disappeared in the majority of the analysis. Could you please make the representation more consistent.\n- a(v,u) in Eq. 2 and A(v,u) in Eq. 5 are not defined. Do they both correspond to entries of the (normalized) adjacency?"", 'This paper addresses the memory bottleneck problem in graph neural networks and proposes a novel importance sampling scheme that is based on sampling vertices (instead of sampling local neighbors as in [1]). Experimental results demonstrate a significant speedup in per-batch training time compared to previous works while retaining similar classification accuracy on standard benchmark datasets.\n\nThe paper is well-written and proposes a simple, elegant, and well-motivated solution for the memory bottleneck issue in graph neural networks.\n\nI think that this paper mostly looks solid, but I am a bit worried about the following assumption: “Specifically, we interpret that graph vertices are iid samples of some probability distribution”. As graph vertices are inter-connected and inter-dependent across edges of the graph, this iid assumption might be too strong. A short comment on why the authors take this particular interpretation would be helpful.\n\nIn the abstract the authors write: “Such a model [GCN], however, is transductive in nature because parameters are learned through convolutions with both training and test data.” — as demonstrated in Hamilton et al. (2017) [1], this class of models admits inductive learning as well as transductive learning, so the above statement is not quite accurate.\n\nFurthermore, a comment on whether this scheme would be useful for alternative graph neural network architectures, such as the one in MoNet [2] or the generic formulation of the original graph neural net [3] (nicely summarized in Gilmer et al. (2017) [4]) would be insightful (and would make the paper even stronger).\n\nI am very happy to see that the authors provide the code together with the submission (using an anonymous GitHub repository). The authors mention that “The code of GraphSAGE is downloaded from the accompany [sic] website, whereas GCN is self implemented.“ - Looking at the code it looks to me, however, as if it was based on the implementation by the authors of [5]. \n\nThe experimental comparison in terms of per-batch training time looks very impressive, yet it would be good to also include a comparison in terms of total training time per model (e.g. in the appendix). I quickly checked the provided implementation for FastGCN on Pubmed and compared it against the GCN implementation from [5], and it looks like the original GCN model is roughly 30% faster on my laptop (no batched training). This is not very surprising, as a fair comparison should involve batched training for both approaches. Nonetheless it would be good to include these results in the paper to avoid confusion.\n\nMinor issues:\n- The notation of the limit in Theorem 1 is a bit unclear. I assume the limit is taken to infinity with respect to the number of samples.\n- There are a number of typos throughout the paper (like “oppose to” instead of “opposed to”), these should be fixed in the revision.\n- It would be better to summarize Figure 3 (left) in a table, as the smaller values are difficult to read off the chart.\n\nOverall, I think that this paper can be accepted. The proposed scheme is a simple drop-in replacement for the way adjacency matrices are prepared in current implementations of graph neural nets and it promises to solve the memory issue of previous works while being substantially faster than the model in [1]. I expect the proposed approach to be useful for most graph neural network models.\n\nUPDATE: I would like to thank the authors for their detailed response and for adding additional experimental evaluation. My initial concerns have been addressed and I can fully recommend acceptance of this paper.\n\n[1] W.L. Hamilton, R. Ying, J. Leskovec, Inductive Representation Learning on Large Graphs, NIPS 2017\n[2] F. Monti, D. Boscaini, J. Masci, E. Rodala, J. Svoboda, M.M. Bronstein, Geometric deep learning on graphs and manifolds using mixture model CNNs, CVPR 2017\n[3] F. Scarselli, M. Gori, A.C. Tsoi, M. Hagenbuchner, G. Monfardini, The Graph Neural Network Model, IEEE Transactions on Neural Networks, 2009\n[4] J. Gilmer, S.S. Schoenholz, P.F. Riley, O. Vinyals, G.E. Dahl, Neural Message Passing for Quantum Chemistry, ICML 2017\n[5] T.N. Kipf, M. Welling, Semi-Supervised Classification with Graph Convolutional Networks, ICLR 2017', 'The paper focuses on the recently graph convolutional network (GCN) framework.\nThey authors identify a couple of issues with GCN: the fact that both training and test data need to be present at training time, making it transductive in nature and the fact that the notion of ‘neighborhood’ grows as the signal propagates through the network. The latter implies that GCNs can have a large memory footprint, making them impractical in certain cases. \nThe authors propose an alternative formulation that interprets the signals as vertex embedding functions; it also interprets  graph convolutions as integral transforms of said functions.\nStarting from mini-batches consisting purely of training data (during training) each layer performs Monte Carlo sampling on the vertices to approximate the embedding functions.\nThey show that this estimator is consistent and can be used for training the proposed architecture, FastGCN, via standard SGD. \nFinally, they analyze the estimator’s variance and propose an importance-sampling based estimator that has minimal layer-to-layer variance.\nThe experiments demonstrate that FastGCN is much faster than the alternatives, while suffering a small accuracy penalty.\n\nThis is a very good paper. The ideas are solid, the writing is excellent and the results convincing. I have a few comments and concerns listed below.\n\nComments:\n1. I agree with the anonymous commenter that the authors should provide detailed description of their experimental setup.\n2. The timing of GraphSAGE on Cora is bizarre. I’m even slightly suspicious that something might have been amiss in your setup. It is by far the smallest dataset. How do you explain GraphSAGE performing so much worse on Cora than on the bigger Pubmed and Reddit datasets? It is also on Cora that GraphSAGE seems to yield subpar accuracy, while it wins the other two datasets.\n3. As a concrete step towards grounding the proposed method on state of the art results, I would love to see at least one experiment with the same (original) data splits used in previous papers. I understand that semi-supervised learning is not the purpose of this paper, however matching previous results would dispel any concerns about setup/hyperparameter mismatch. \n4. Another thing missing is an exploration (or at least careful discussion) as to why FastGCN performs worse than the other methods in terms of accuracy and how much that relative penalty can be.\n\nMinor comments:\n5. Please add label axes to Figure 2; currently it is very hard to read. Also please label the y axis in Figure 3.\n6. The notation change in Section 3.1 was well intended, however I feel like it slowed me down significantly while reading the paper. I had already absorbed the original notation and had to go back and forth to translate to the new one. \n']","[70, -20, 70, 80]","[80, 60, 80, 70]","[""The sentiment score is 70 (positive) because the reviewer begins by highlighting the paper's novel approach, its theoretical support, and experimental studies. The reviewer acknowledges the paper's contribution to addressing a significant issue in the field. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, framing their questions as requests for elaboration rather than criticisms. The reviewer's tone is constructive and inquisitive, showing interest in understanding the work better rather than finding fault. The use of phrases like 'could you elaborate' and the absence of any harsh or dismissive language contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the work and appreciates the authors' efforts in revision, they express significant concerns about the probabilistic problem formulation and limitations of the results. The reviewer states they are 'not satisfied' with certain aspects and requests more upfront discussion of challenges and limitations. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the authors' work, and frames criticisms constructively. They use phrases like 'I would appreciate if' and 'I briefly summarize' which maintain a polite tone while providing critical feedback. The reviewer also offers to revisit their score if concerns are addressed, showing openness to dialogue."", ""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, stating it's 'well-written' with a 'simple, elegant, and well-motivated solution'. They recommend acceptance and expect the approach to be useful. However, they do raise some concerns and suggest improvements, which prevents a higher score. The politeness score is 80 (quite polite) due to the reviewer's constructive and respectful tone throughout. They use phrases like 'I think', 'would be helpful', and 'I am very happy to see', which maintain a courteous dialogue. They also thank the authors for their response in the update. The reviewer balances critique with praise and offers specific, actionable feedback without harsh language."", ""The sentiment score is 80 (positive) because the reviewer states 'This is a very good paper' and praises the ideas, writing, and results. They also use positive language like 'solid' and 'excellent'. The few concerns mentioned are presented as constructive feedback rather than major criticisms. The politeness score is 70 (polite) due to the respectful tone throughout. The reviewer uses phrases like 'I agree' and 'I would love to see', showing consideration for the authors' work. They also frame their comments as suggestions rather than demands. The slightly lower politeness score compared to sentiment is due to the direct questioning in point 2 about the bizarre timing results, which could be perceived as slightly confrontational.""]"
"['This paper presents a simple model-based RL approach, and shows that with a few small tweaks to more ""typical"" model-based procedures, the methods can substantially outperform model-free methods on continuous control tasks.  In particular, the authors show that by 1) using an ensemble of models instead of a single models, 2) using TRPO to optimize the policy based upon these models (rather that analytical gradients), and 3) using the model ensemble to validate when to stop policy optimization, then a simple model-based approach actually can outperform model-free methods.\n\nOverall, I think this is a nice paper, and worth accepting.  There is very little actually new here, of course: the actual model-based method is entirely standard except with the additions above (which are also all fairly standard approaches in isolation).  But at a higher level, the fact that such simple model-based approaches work better than somewhat complex model free approaches actually is the point of the paper to me.  While the general theme of model-based RL outperforming model-free RL is not new (Atkeson and Santamaria (1997) comes to a similar conclusion) its good to see this same pattern demonstrated ""officially"" on modern RL benchmarks, especially since the _completely_ naive strategy of using a single model and more standard policy optimization doesn\'t perform as well.\n\nNaturally, there is some question as to whether the work here is novel enough to warrant publication, but I think the overall message of the paper is strong enough to overcome fairly minimal contribution from an algorithmic perspective.  I did also have a few general concerns that I think could be discussed with a bit more detail in the paper:\n1) The choice of this particular model ensemble to represent uncertainty seems rather ad-how.  Why is it sufficient to simply learn N models with different initial weights?  It seems that the likely cause for this is that the random initial weights may lead to very different behavior in the unobserved parts of the space (i.e., portions of the state space where we have no samples), and thus.  But it seems like there are much more principled ways of overcoming this same problem, e.g. by using an actual Bayesian neural net, directly modeling uncertainty in the forward model, or using generative model approaches.  There\'s some discussion of this point in the introduction, but I think a bit more explanation about why the model ensemble is expected to work well for this purpose.\n2) Likewise, the fact the TRPO outperforms more standard gradient methods is somewhat surprising.  How is the model ensemble being treated during BPTT?  In the described TRPO method, the authors use a different model at each time step, sampling uniformly.  But it seems like a single model is used for each rollout in the proposed BPTT method?  If so, it\'s not surprising that this approach performs worse.  But it seems like one could backprop through the different per-timestep models just as easily, and it would remove one additional source of difference between the two settings.', 'The authors combine an ensemble of DNNs as model for the dynamics with TRPO. The ensemble is used in two steps:\nFirst to collect imaginary roll-outs for TRPO and secondly to estimate convergence of the algorithm. The experiments indicate superior performance over the baselines.\n\nThe paper is well-written and the experiments indicate good results. However, idea of using ensembles in the context of \n(model-based) RL  is not novel, and it comes at the cost of time complexity.  Therefore, the method should utilize \nthe advantage an ensemble provides to its full extent. \nThe main strength of an ensemble is to provide lower test error, but also some from of uncertainty estimate given by the spread of the predictions. The authors mainly utilize the first, but to a lesser extent the second advantage (the imaginary roll-outs will  utilize the spread to generate possible outcomes). Ideally the exploration should also be guided by the uncertainty (such as VIME).\n\nRelated, what where the arguments in favor of an ensemble compared to Bayesian neural networks (possibly even as simple as using MH-dropout)? BNNs provide a stronger theoretical justification that the predictive uncertainty is meaningful.\n\nCan the authors comment on the time-complexity of the proposed methods compared to the baselines? In Fig. 2  the x-axis is the time step of the  real data. But I assume it took a different amount of time for each method to reach step t. The same argument can be made for Fig. 4. It seems here that in snake the larger ensembles reach convergence the quickest, but I expect this effect to be reversed when considering actual training time.\n\nIn total I think this paper can provide a useful addition to the literature.  However, the proposed approach does not have strong novelty and I am not fully convinced if the additional burden on time complexity outweighs the improved performance.\n\nMinor:  In Sec. 2: ""Both of these approaches assume a fixed dataset of samples which are collected\nbefore the algorithm starts operating.""  This is incorrect, while these methods consider the domain of fixed datasets, the algorithms themselves are not limited to this context.\n', ""Summary:\nThe paper proposes to use ensembles of models to overcome a typical problem when training on a learned model: That the policy learns to take advantage of errors of the model.\nThe models use the same training data but are differentiated by a differente parameter initialization and by training on differently drawn minibatches.\nTo train the policy, at each step the next state is taken from an uniformly randomly drawn model.\nFor validation the policy is evaluated on all models and training is stopped early if it doesn't improve on enough of them. \n\nWhile the idea to use an ensemble of deep neural networks to estimate their uncertainty is not new, I haven't seen it yet in this context. They successfully show in their experiments that typical levels of performance can be achieved using much less samples from the real environment.\n\nThe reduction in required samples is over an order of magnitude for simple environments (Mujoco Swimmer). However, (as expected for model based algorithms) both the performance as well as the reduction in sample complexity gets worse with increasing complexity of the environment. It can still successfully tackle the Humanoid Mujoco task but my guess is that that is close to the upper limit of this algorithm?\n\nOverall the paper is a solid and useful contribution to the field.\n\n*Quality:*\nThe paper is clearly shows the advantage of the proposed method in the experimental section where it compares to several baselines (and not only one, thank you for that!). \n\nThings which in my opinion aren't absolutely required in the paper but I would find interesting and useful (e.g. in the appendix) are:\n1. How does the runtime (e.g. number of total samples drawn from both the models and the real environment, including for validation purpuses) compare?\nFrom the experiments I would guess that MB-TRPO is about two to three orders of magnitude slower, but having this information would be useful.\n2. For more complex environments it seems that training is becoming less stable and performance degradates, especially for the Humanoid environment. A plot like in figure 4 (different number of models) for the humanoid environment could be interesting? Additionally maybe a short discussion where the major problem for further scaling lies? For example: Expressiveness of the models? Required number of models / computation feasibility? Etc... This is not necessarily required for the paper but would be interesting.\n\n*Originality & Significance:*\nAs far as I can tell, none of the fundamental ideas are new. However, they are combined in an interesting, novel way that shows significant performance improvements.\nThe problem the authors tackle, namely learning a deep neural network model for model based RL, is important and relevant. As such, the paper contributes to the field and should be accepted.\n\n*Smaller questions and notes:*\n- Longer training times for MB-TRPO, in particular for Ant and Humanoid would have been intersting if computationionally feasibly.\n- Could this in principle be used with Q-learning as well (instead of TRPO) if the action space is discrete? Or is there an obvious reason why not that I am missing?""]","[70, 20, 80]","[80, 60, 70]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, stating it's 'a nice paper, and worth accepting.' They acknowledge the paper's strengths and its contribution to the field, despite noting that there is 'very little actually new here.' The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They offer praise where due and frame their concerns as suggestions for improvement rather than criticisms. The reviewer also uses phrases like 'I think' and 'it seems,' which softens their statements and shows consideration for the authors' perspective. The reviewer provides detailed, thoughtful feedback without using any harsh or dismissive language."", ""For the sentiment score, I assigned 20 (slightly positive) because the reviewer acknowledges the paper is well-written and has good results, and states it can provide a useful addition to the literature. However, they also express concerns about novelty and time complexity, which tempers the positive sentiment. For the politeness score, I assigned 60 (moderately polite) because the reviewer uses respectful language throughout, asks questions rather than making demands, and offers constructive criticism. They use phrases like 'Can the authors comment on...' and 'I think this paper can provide a useful addition...' which are polite ways of expressing their thoughts. The review maintains a professional tone without being overly formal or informal."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They describe it as a 'solid and useful contribution to the field' and state that it 'shows significant performance improvements.' The reviewer also appreciates the comprehensive experimental section and comparison to multiple baselines. The score is not 100 because the reviewer does suggest some additional information that could be included and notes some limitations with more complex environments. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, expresses gratitude ('thank you for that!'), and frames their suggestions as optional rather than demands ('aren't absolutely required'). The tone is professional and constructive, offering both praise and thoughtful recommendations for improvement. The score is not higher because while polite, it maintains a formal, neutral tone typical of academic reviews rather than being excessively deferential.""]"
"[""This paper proposes a novel method to solve the problem of active sensing from a new angle (Essentially, the active sensing is a kind of method that decides when (or where) to take new measurements and what measurements we should conduct at that time or (place)). By taking advantage of the characteristics of long-term memory and Bi-directionality of Bi-RNN and M-RNN, deep sensing can model multivariate time-series signals for predicting future labels and estimating the values of new measurements. The architecture of Deep Sensing basically consists of three components: \n1. Interpolation and imputation for each of channels where missing points exist;\n2. Prediction for the future labels in terms of the whole multivariate signals (The signal is a time-series data and made up of multiple channels, there is supposed to be a measured label for each moment of the signal); \n3. Active sensing for the future moments of each of the channels. \n\nPros\n\nThe novelty of this paper lies in using a neural network structure to solve a traditional statistical problem which was usually done by a Bayesian approach or using the idea of the stochastic process. \n\nA detailed description of the network architecture is provided and each of the configurations has been fully illustrated.  The explanation of the structure of the combined RNNs is rigorous but clear enough of understanding. \n\nThe method was tested on a large real dataset and got a really promising result based several rational assumptions (such as assuming some of the points are missing for evaluating the error of the interpolation & imputation).\n\nCons\n\nHow and why the architecture is designed in this way should be further discussed or explained. Some of the details of the design could be inferred indirectly. But somewhere like the structure of the interpolation in Fig.3 doesn't have any further discussion. For example, why using GRU based RNN, and how Bi-RNN benefits here. \n"", 'This is a very interesting submission that takes an interesting angle on clinical time series modeling, namely, actively choosing when to measure while simultaneously attempting to impute missing measurements and predict outcomes of interest. The proposed solution formulates everything as a giant learning problem that involves learning (a) an interpolation function that predicts a missing measurement from its past and present, (b) an imputation function that predicts a missing measurement from other variables at the same time step, (c) a prediction function that predicts outcomes of interest, including forecasting future measurements, (d) an error estimation function that estimates error of the forecasts in (c). These four pieces are then used in combination with a heuristic to decide when certain variables should be measured. This framework is used with a GRU-RNN architecture and in experiments with two datasets, outperforms a number of strong baselines.\n\nI am inclined toward accepting this paper due to the significance of the problem, the ingenuity of their proposed approach, and the strength of the empirical results. However, I think that there is a lot of room for improvement in the current manuscript, which is difficult to read and fully grasp. This will lessen its impact in the long run, so I encourage the authors to strive to make it clearer. If they succeed in improving it during the review period, I will gladly raise my score.\n\nNOTE: please do a thorough editorial pass for the next version -- I found at least one typo in the references (Yu, et al. ""Active sensin."")\n\nQUALITY\n\nThis is solid research, and I have few complaints about the work itself (most of my feedback will focus on clarity). I will list some strengths (+) and weaknesses (-) below and try to provide actionable feedback:\n\n+ Very important problem that receives limited attention from the community\n+ I like the formulation of active sensing as a prediction loss optimization problem\n+ The learning problem is pretty intuitive and is well-suited to deep learning architectures since it yields a differentiable (albeit complex) loss function\n+ The results speak for themselves -- for adverse event prediction in the MIMIC-III task, DS improves upon the nearest baseline by almost 9 points in AUC! More interestingly, using Deep Sensing to create a ""resampled"" version of the data set improves the performance of the baselines. It also achieves much more accurate imputation than standard approaches.\n\n- The proposed approach is pretty complex, and it\'s unclear what is the relative contribution of each component. I think it is incumbent to do an ablation study where different components are removed to see how performance degrades, if at all. For example, how would the model perform with interpolation but not imputation? Is bidirectional interpolation necessary, or would forward interpolation work sufficiently well (the obvious disadvantage of the bidirectional approach is the need to rerun inference at each new time step). Is it necessary to use both the actual AND predicted measurements as inputs (what if we instead used actual measurements when available and predicted otherwise)?\n- The experiments are thorough with a nice selection of baselines, but I wonder if perhaps Futoma, et al. [1] would be a stronger baseline than Choi, Che, or Lipton. They showed improvements over similar magnitude over baselines for predicting sepsis, and their approach (a differentiable GP-approximating layer) is conceptually simpler and has other benefits. I think it could be combined with the active sensing framework in this paper.\n- The one question this framework appears incapable of answering in a straightforward manner is WHEN the next set of measurements should be made. One could imagine a heuristic in which predictive loss/gain are assessed at different points in the future, but the search space will be huge, particularly if one wants to optimize over measurements at different points, e.g., maybe the optimal strategy is to take roughly hourly vitals but no labs until 12 hours from now. Indeed, it might be impossible to train such a model properly since the sampling times in the available training data are highly biased.\n- One thing potentially missing from this paper is a theoretical analysis to understand and analyze its behavior and performance. My very superficial analysis is that the prediction loss/gain framework is related to minimizing entropy and that the heuristic for choosing which variables to measure is a greedy search. A theoretical treatment to understand whether and how this approach might be sub-optimal would be very desirable.\n- Are the measurement and prediction ""confidence intervals"" proper confidence intervals (in the formal statistical sense)? I don\'t think so -- I wonder if there are alternatives for measuring uncertainty (formal CIs or maybe a Bayesian approach?).\n\nCLARITY\n\nMy main complaint about this paper is clarity -- it is not difficult to read per se, but it is difficult to fully grok the details of the approach and the experimental setup. From the current manuscript, I do not feel confident that I could re-implement Deep Sensing or reproduce the experiments. This is especially important in healthcare research, where there is a minor reproducibility crisis, even for resarch using MIMIC (see [2]). Of course, this can be alleviated by publishing the code and using a public benchmark [3], but it can\'t hurt to clarify these details in the paper itself (and to add an appendix if length is an issue).\n\nHere are some potential areas for improvement:\n\n- The structure of the paper is a bit weird. In particular section 2 (pages 2-4) seems to be a grab bag of miscellaneous topics, at least by the headers. I think the content is fine -- perhaps section 2 can be renamed as ""Background,"" subsection 2.1 renamed as ""Notation,"" and subsection 2.2 renamed as ""Problem Formulation"" (or similar). I\'d just combine subsection 2.3 with the previous one and explain that Figure 1 illustrates the problem formulation.\n- The active sensing procedure (subsection 2.2, page 3, equation 1 and the equations just above) is unclear. How are the minimization and maximization performed (gradient descent, line search, etc.)? How is the search for the subset of measurement variables performed (greedy search)? The latter is a discrete search, and I doubt it\'s, e.g., submodular, so it must be a nontrivial optimization.\n- Related, I\'m a little confused about equation 1: C_T is the set of variables that should be measured, but C_T is being used to index prediction targets -- is this a typo?\n- The related work section is pretty extensive, but I wonder if it should also include work on active learning (Bayesian active learning, in particular, has been applied to sensing), submodular optimization (for sensor placement, which can be thought of as a spatial version of active sensing), and reinforcement learning.\n- I don\'t understand how the training data for the interpolation and imputation functions are constructed. I *think* that is what is described in the Adaptive Sampling subsection on page 8, but that is unclear. The word ""representations"" is used here, but that\'s an overloaded term in machine learning, and its meaning here is unclear from context. It appears that maybe there\'s an iterative procedure in which we alternate between training a model and then resampling the data using the model -- starting with the full data set.\n- The distinction between training and inference is not clear to me, at least with respect to the active sensing component. Is selective sampling performed during training? If so, what happens if the model elects to sample a variable at time t that is not actually measured in the data?\n- I don\'t follow subsection 4.2 (pages 8-9) at all -- what is it describing? If by ""runtime"" the authors refer to the computational complexity of the algorithm, then I would expect a Big-O analysis (none is provided -- it\'s just a rather vague discussion of what happens). I\'d recommend removing this entire subsection and replacing it with, e.g., an Algorithm figure with pseudocode, as a more succinct description.\n- For the experiments, the authors provide insufficient detail about the data and task setup. Since MIMIC is publicly available, then readers ought (hypothetically) to be able to reproduce the experiments, but that is not currently possible. As an example, what adverse events are being predicted? How are they defined?\n- Figure 4 is nice, but it\'s not immediately obvious what the connection between observation rate and sampling cost. The authors should explain how a given observation rate is encoded as cost in the loss function.\n\nORIGINALITY\n\nWhile active sensing is not a new research topic per se, there has been very limited research into the specific question of choosing what clinical variables to measure when in the context of a given prediction problem. This is a topic that (in my experience) is frequently discussed but rarely studied in clinical informatics circles. Hence, this is a very original line of inquiry, and the prediction loss/gain framing is a unique angle.\n\nSIGNIFICANCE\n\nI anticipate this paper will generate significant interest and follow-up work, at least among clinical informaticists and machine learning + health researchers. The main blockers to a significant impact are the clarity of writing issues listed above -- and if the authors fail to publish their code.\n\nREFERENCES\n\n[1] Futoma, et al. An Improved Multi-Output Gaussian Process RNN with Real-Time Validation for Early Sepsis Detection. MLHC 2017.\n[2] Johnson, et al. Reproducibility in critical care: a mortality prediction case study. MLHC 2017\n[3] Harutyunyan, et al. Multitask Learning and Benchmarking with Clinical Time Series Data. arXiv.', 'This paper presents a new approach to determining what to measure and when to measure it, using a novel deep learning architecture. The problem addressed is important and timely and advances here may have an impact on many application areas outside medicine. The approach is evaluated on real-world medical datasets and has increased accuracy over the other methods compared against.\n\n+ A key advantage of the approach is that it continually learns from the collected data, using new measurements to update the model, and that it runs efficiently even on large real-world datasets.\n\n-However, the related work section is significantly underdeveloped, making it difficult to really compare the approach to the state of the art. The paper is ambitious and claims to address a variety of problems, but as a result each segment of related work seems to have been shortchanged. In particular, the section on missing data is missing a large amount of recent and related work. Normally, methods for handling missing data are categorized based on the missingness model (MAR/MCAR/MNAR). The paper seems to assume all data are missing at random, which is also a significant limitation of the methods.\n\n-The paper is organized in a nonstandard way, with the methods split across two sections, separated by the related work. It would be easier to follow with a more common intro/related work/methods structure.\n\nQuestions:\n-One of the key motivations for the approach is sensing in medicine. However, many tests come as a group (e.g. the chem-7 or other panels). In this case, even if the only desired measurement is glucose, others will be included as well. Is it possible to incorporate this? It may change the threshold for the decision, as a combination of measures can be obtained for the same cost.']","[60, 60, 20]","[70, 80, 60]","[""The sentiment score is 60 (positive) because the review begins by highlighting the novelty of the paper's approach and lists several pros, including a detailed description of the network architecture and promising results on a large dataset. However, it also mentions some cons, which prevents it from being extremely positive. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively pointing out areas for improvement. The reviewer avoids harsh criticism and instead suggests further discussion or explanation for certain aspects of the paper."", ""The sentiment score is 60 (positive) because the reviewer expresses a favorable inclination towards accepting the paper, praising its significance, ingenuity, and strong empirical results. However, they also note significant room for improvement in clarity, which tempers the overall positivity. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and balances positive and negative feedback. They use phrases like 'I encourage the authors' and 'I will gladly raise my score', which are particularly polite. The reviewer also provides detailed, actionable feedback in a professional manner, further contributing to the polite tone."", ""The sentiment score is slightly positive (20) because the review begins with positive comments about the paper's importance, timeliness, and potential impact. It also mentions key advantages of the approach. However, the reviewer then points out significant limitations and areas for improvement, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, balancing praise with constructive criticism. They use phrases like 'key advantage' when discussing positives and soften criticisms with phrases like 'it would be easier to follow' rather than using harsh language. The reviewer also poses a question at the end, which is a polite way of suggesting an area for improvement or further consideration.""]"
"[""This paper has proposed a new method for classifying nodes of a graph. Their method can be used in both semi-supervised scenarios where the label of some of the nodes of the same graph as the graph in training is missing (Transductive) and in the scenario that the test is on a completely new graph (Inductive).\nEach layer of the network consists of feature representations for all of the nodes in the Graph. A linear transformation is applied to all the features in one layer and the output of the layer is the weighted sum of the transformed neighbours (including the node). The attention logit between node i and its neighbour k is calculated by a one layer fully connected network on top of the concatenation of the transformed representation of node i and transformed representation of the neighbour k. They also can incorporate the multi-head attention mechanism and average/concatenate the output of each head.\n\nOriginality:\nAuthors improve upon GraphSAGE by replacing the aggregate and sampling function at each layer with an attention mechanism. However, the significance of the attention mechanism has not been studied in the experiments. For example by reporting the results when attention is turned off (1/|N_i| for every node) and only a 0-1 mask for neighbours is used. They have compared with GraphSAGE only on PPI dataset. I would change my rating if they show that the 33% gain is mainly due to the attention in compare to other hyper-parameters. [The experiments are now more informative. Thanks]\nAlso, in page 4 authors claim that GraphSAGE is limited because it samples a neighbourhood of each node and doesn't aggregate over all the neighbours in order to keep its computational footprint consistent. However, the current implementation of the proposed method is computationally equal to using all the vertices in GraphSAGE.\n\nPros:\n- Interesting combination of attention and local graph representation learning. \n- Well written paper. It conveys the idea clearly.\n- State-of-the-art results on three datasets.\n\nCons:\n- When comparing with spectral methods it would be better to mention that the depth of embedding propagation in this method is upper-bounded by the depth of the network. Therefore, limiting its adaptability to broader class of graph datasets. \n- Explaining how attention relates to previous body of work in embedding propagation and when it would be more powerful."", 'This is a paper about learning vector representations for the nodes of a graph. These embeddings can be used in downstream tasks the most common of which is node classification.\n\nSeveral existing approaches have been proposed in recent years. The authors provide a fair and almost comprehensive  discussion of state of the art approaches. There are a couple of exception that have already been mentioned in a comment from Thomas Kipf and Michael Bronstein. A more precise discussion of the differences between existing approaches (especially MoNets) should be a crucial addition to the paper. You provide such a  comparison in your answer to Michael\'s comment. To me, the comparison makes sense but it also shows that the ideas presented here are less novel than they might initially seem. The proposed method introduces two forms of (simple) attention. Nothing groundbreaking here but still interesting enough and well explained. It might also be a good idea to compare your method to something like LLE (locally linear embedding). LLE also learns a weight for each of neighbors of a node and computes the embedding as a weighted average of the neighbor embeddings according to these weights. Your approach is different since it is learned end-to-end (not in two separate steps) and because it is applicable to arbitrary graphs (not just graphs where every node has exactly k neighbors as in LLE). Still, something to relate to. \n\nPlease take a look at the comment by Fabian Jansen. I think he is on to something. It seems that the attention weight (from i to j) in the end is only a normalization operation that doesn\'t take the embedding of node i into account.  \n\nThere are two  issues with the experiments.\n\nFirst, you don\'t report results on Pubmed because your method didn\'t scale. Considering that Pubmed has less than 20,000 nodes this shows a clear weakness of your approach. You write (in an answer to a comment) that it *should* be parallelizable but somehow you didn\'t make it work. We have to, however, evaluate the approach on what it is able to do at the moment. Having a complexity that is quadratic in the number of nodes is terrible and one of the major reasons learning with graphs has moved from kernels to neural approaches. While it is great that you acknowledge this openly as a weakness, it is currently not possible to claim that your method scales to even moderately sized graphs. \n\nSecond, the experimental set-up on the Cora and Citeseer data sets should be properly randomized. As Thomas pointed out, for graph data the variance can be quite high. For some split the method might perform really well and less well for others. In your answer titled ""Requested clarifications"" to a different comment you provide numbers randomized over 10 runs. Did you randomize the parameter initialization only or also the the train/val/test splits? If you did the latter, this seems reasonable. In Kipf et al.\'s GCN paper this is what was done (not over 100 splits as some other commenter claimed. The average over 100 runs  pertained to the ICA method only.) ', 'The paper introduces a neural network architecture to operate on graph-structured\ndata named Graph Attention Networks.\nKey components are an attention layer and the possibility to learn how to\nweight different nodes in the neighborhood without requiring spectral decompositions\nwhich are costly to be computed.\n\nI found the paper clearly written and very well presented. I want to thank\nthe author for actively participating in the discussions and in clarifying already\nmany of the details that I was missing.\n\nAs also reported in the comments by T. Kipf I found the lack of comparison to previous\nworks on attention and on constructions of NN for graph data are missing.\nIn particular MoNet seems a more general framework, using features to compute node\nsimilarity is another way to specify the ""coordinate system"" for convolution.\nI would argue that in many cases the graph is given and that one would have\nto exploit its structure rather than the simple first order neighbors structure.\n\nI feel, in fact, that the paper deals mainly with ""localized metric-learning"" rather than\nusing the information in the graph itself. There is no\nexplicit usage of the graph beyond the selection of the local neighborhood.\nIn many ways when I first read it I though it would be a modified version of\nmemory networks (which have not been cited). Sec. 2.1 is basically describing\na way to learn a matrix W so that the attention layer produces the weights to be\nused for convolution, or the relative coordinate system, which is to me a\nmemory network like construction, where the memory is given by the neighborhood.\n\nI find the idea to use the multi-head attention very interesting, but one should\nconsider the increase in number of parameters in the experimental section.\n\nI agree that the proposed method is computationally efficient but the authors\nshould keep in mind that parallelizing across all edges involves lot of redundant\ncopies (e.g. in a distributed system) as the neighborhoods highly overlap, at\nleast for interesting graphs.\n\nThe advantage with respect to methods that try to use LSTM in this domain\nin a naive manner is clear, however the similarity function (attention) in this\nwork could be interpreted as the variable dictating the visit ordering.\n\nThe authors seem to emphasize the use of GPU as the best way to scale their work\nbut I tend to think that when nodes have varying degrees they would be highly\nunused. Main reason why they are widely used now is due to the structure in the\nrepresentation of convolutional operations.\nAlso in case of sparse data GPUs are not the best alternative.\n\nExperiments are very well described and performed, however as explained earlier\nsome comparisons are needed.\nAn interesting experiment could be to use the attention weights as adjacency\nmatrix for GCN.\n\nOverall I liked the paper and the presentation, I think it is a simple yet\neffective way of dealing with graph structure data. However, I think that in\nmany interesting cases the graph structure is relevant and cannot be used\njust to get the neighboring nodes (e.g. in social network analysis).']","[50, -20, 50]","[80, 60, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as its interesting combination of techniques, clear writing, and state-of-the-art results. However, they also point out some limitations and areas for improvement, balancing the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges improvements made by the authors ('The experiments are now more informative. Thanks'), and frames criticisms constructively as suggestions or areas for further exploration rather than harsh judgments. The reviewer also begins by summarizing the paper's contributions, showing engagement with the work, and ends with a balanced list of pros and cons, maintaining a professional and courteous tone throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('fair and almost comprehensive discussion', 'interesting enough and well explained'), they also point out several significant issues with the paper. These include lack of novelty ('less novel than they might initially seem'), scalability problems ('didn't scale' on Pubmed), and experimental setup concerns. The overall tone suggests the paper needs substantial improvements.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and constructive language throughout. They offer suggestions for improvement ('A more precise discussion... should be a crucial addition') and acknowledge the authors' openness about weaknesses ('it is great that you acknowledge this openly'). The reviewer also balances criticism with positive remarks and uses phrases like 'Please take a look' and 'It might also be a good idea' which maintain a collegial tone. However, the score is not higher as the review is still quite critical in content."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses appreciation for the paper's clarity and presentation, and finds the ideas interesting and effective. However, they also point out several areas for improvement and missing comparisons, balancing the positive aspects. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language, expressing gratitude to the authors, and framing criticisms constructively. They use phrases like 'I want to thank the author,' 'I found the paper clearly written,' and 'Overall I liked the paper,' which contribute to a polite tone throughout the review.""]"
"[""Strengths:\n* Very simple strategy for unsupervised learning of deep image features. Simplicity of approach is a good quality in my view.\n* The rationale for the effectiveness of the approach is explained well.\n* The representation learned from unlabeled data is shown to yield strong results on image categorization (albeit mostly in scenarios where the unsupervised features have been learned from the *same* dataset where classification is performed -- more on this below).\n* The image rotations are implemented in terms of flipping and transposition, which do not create visual artifacts easily recognizable by deep models.\n\nWeaknesses:\n* There are several obvious additional experiments that, in my view, would greatly strengthen this work:\n1. Nearly all of the image categorization results (with the exception of those in Table 4) are presented for the contrived scenario where the unsupervised representation is learned from the same training set as the one used for the final supervised training of the categorization model. This is a useless application scenario. If labels for the training examples are available, why not using them for feature learning given that this leads to improved performance (see results in Tables)? More importantly, this setup does not allow us to understand how general the unsupervised features are. Maybe they are effective  precisely because they have been learned from images of the 10 classes that the final classifier needs to distinguish... I would have liked to see some results involving unsupervised learning from a dataset that may contain classes different from those of the final test classification or, even better, from a dataset of randomly selected images that lack categorical coherence (e.g., photos randomly picked from the Web, such as Flickr pics).\n2. In nearly all the experiments, the classifier is built on top of the frozen unsupervised features. This is in contrast with the common practice of finetuning the entire pretrained unsupervised net on the supervised task. It'd be good to know why the authors opted for the different setup and to see in any case some supervised finetuning results.\n3. It would be useful to see the accuracy per class both when using unsupervised features as well as fully-supervised features. There are many objects that have a canonical pose/rotation in the world. Forcing the unsupervised features to distinguish rotations of such objects may affect the recognition accuracy for these classes. Thus, my request for seeing how the unsupervised learning affects class-specific accuracy.\n4. While the results in Table 2 are impressive, it appears that the different unsupervised learning methods reported in this table are based on different architectures. This raises the question of whether performance gains are due to the better mechanism for unsupervised learning or rather the better network architecture.\n5. I do understand that using only 0, 90, 180 and 270 degree rotations eliminates the issue of potentially recognizable artifacts. Nevertheless, it'd be interesting to see what happens empirically when the number of discrete rotations is increased, e.g., by including 45, 135, 225 and 315 degree rotations. And what happens if you use only 0 and 180? Or only 90 and 270?\n* While the paper is easy to understand, at times the writing is poor and awkward (e.g., opening sentence of intro, first sentence in section 2.2)."", '**Paper Summary**\n    This paper proposes a self-supervised method, RotNet, to learn effective image feature from images by predicting the rotation, discretized into 4 rotations of 0, 90, 180, and 270 degrees. The authors claim that this task is intuitive because a model must learn to recognize and detect relevant parts of an image (object orientation, object class) in order to determine how much an image has been rotated. \nThey visualize attention maps from the first few conv layers and claim that the attend to parts of the image like faces or eyes or mouths. They also visualize filters from the first convolutional layer and show that these learned filters are more diverse than those from training the same model in a supervised manner. \n\tThey train RotNet to learn features of CIFAR-10 and then train, in a supervised manner, additional layers that use RotNet feature maps to perform object classification. They achieve 91.16% accuracy, outperforming other unsupervised feature learning methods. They also show that in a semi-supervised setting where only a small number of images of each category is available at training time, their method outperforms a supervised method.\n\tThey next train RotNet on ImageNet and use the learned features for image classification on ImageNet and PASCAL VOC 2007 as well as object detection on PASCAL VOC 2007. They achieve an ImageNet and PASCAL classification score as well as an object detection score higher than other baseline methods.\n    This task requires the ability to understand the types, the locations, and the poses of the objects presented in images and therefore provides a powerful surrogate supervision signal for representation learning. To demonstrate the effectiveness of the proposed method, the authors evaluate it under a variety of tasks with different settings. \n    \n    \n\n**Paper Strengths**\n- The motivation of this work is well-written.\n- The proposed self-supervised task is simple and intuitive. This simple idea of using image rotation to learn features, easy to implement image rotations without any artifacts\n- Requiring no scale and aspect ratio image transformations, the proposed self-supervised task does not introduce any low-level visual artifacts that will lead the CNN to learn trivial features with no practical value for the visual perception tasks.\n- Training the proposed model requires the same computational cost as supervised learning which is much faster than training image reconstruction based representation learning frameworks.\n- The experiments show that this representation learning task can improve the performance when only a small amount of annotated examples is available  (the semi-supervised settings).\n- The implementation details are included, including the way of implementing image rotations, different network architectures evaluated on different datasets, optimizers, learning rates with weight decayed, batch sizes, numbers of training epochs, etc. \n- Outperforms all baselines and achieves performance close to, but still below, fully supervised methods\n- Plots rotation prediction accuracy and object recognition accuracy over time and shows that they are correlated\n\n\n\n**Paper Weaknesses**\n- The proposed method considers a set of different geometric transformations as discrete and independent classes and formulates the task as a classification task. However, the inherent relationships among geometric transformations are ignored. For example, rotating an image 90 degrees and rotating an image 180 degrees should be closer compared to rotating an image 90 degrees and rotating an image 270 degrees.\n- The evaluation of low-level perception vision task is missing. In particular, evaluating the learned representations on the task of image semantic segmentation is essential in my opinion. Since we are interested in assigning the label of an object class to each pixel in the image for the task, the ability to encode semantic image feature by learning from performing the self-supervised task can be demonstrated.\n- The figure presenting the visualization of the first layer filters is not clear to understand nor representative of any finding.\n- ImageNet Top-1 classification results produced by Split-Brain (Zhang et al., 2016b) and Counting (Noroozi et al., 2017) are missing which are shown to be effective in the paper [Representation Learning by Learning to Count](https://arxiv.org/abs/1708.06734).\n- An in-depth analysis of the correlation between the rotation prediction accuracy and the object recognition accuracy is missing. Showing both the accuracies are improved over time is not informative.\n- Not fully convinced on the intuition, some objects may not have a clear direction of what should be “up” or “down” (symmetric objects like balls), in Figure 2, rotated image X^3 could plausibly be believed as 0 rotation as well, do the failure cases of rotation relate to misclassified images?\n- “remarkably good performance”, “extremely good performance” – vague language choices (abstract, conclusion)\n- Per class breakdown on CIFAR 10 and/or PASCAL would help understand what exactly is being learned\n- In Figure 3, it would be better to show attention maps on rotated images as well as activations from other unsupervised learning methods. With this figure, it is hard to tell whether the proposed model effectively focuses on high level objects.\n- In Figure 4, patterns of the convolutional filters are not clear. It would be better to make the figures clear by using grayscale images and adjusting contrast.\n- In Equation 2, the objective should be maximizing the sum of losses or minimizing the negative. Also, in Equation 3, the summation should be computed over y = 1 ~ K, not i = 1 ~ N.\n\n\n\n**Preliminary Evaluation**\nThis paper proposes a self-supervised task which allows a CNN to learn meaningful visual representations without requiring supervision signal. In particular, it proposes to train a CNN to recognize the rotation applied to an image, which requires the understanding the types, the locations, and the poses of the objects presented in images. The experiments demonstrate that the learned representations are meaningful and transferable to other vision tasks including object recognition and object detection. Strong quantitative results outperforming unsupervised representation learning methods, but lacking qualitative results to confirm/interpret the effectiveness of the proposed method.', 'The paper proposes a simple classification task for learning feature extractors without requiring manual annotations: predicting one of four rotations that the image has been subjected to: by 0, 90, 180 or 270º. Then the paper shows that pre-training on this task leads to state-of-the-art results on a number of popular benchmarks for object recognition, when training classifiers on top of the resulting representation.\n\nThis is a useful discovery, because generating the rotated images is trivial to implement by anyone. It is a special case of the approach by Agrawal et al 2015, with more efficiency.\n\nOn the negative side, this line of work would benefit from demonstrating concrete benefits. The performance obtained by pre-training with rotations is still inferior to performance obtained by pre-training with ImageNet, and we do have ImageNet so there is no reason not to use it. It would be important to come up with tasks for which there is not one ImageNet, then techniques such as that proposed in the paper would be necessary. However rotations are somewhat specific to images. There may be opportunities with some type of medical data.\n\nAdditionally, the scope of the paper is a little bit restricted, there is not that much to take home besides the the following information: ""predicting rotations seems to require a lot of object category recognition"".\n\n\n\n']","[-20, 50, 20]","[50, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they also point out several weaknesses and suggest multiple additional experiments that they believe would greatly strengthen the work. The reviewer's tone suggests that they find the current state of the paper lacking in some important aspects. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing its weaknesses. They frame their criticisms as suggestions for improvement rather than outright dismissals. However, the reviewer does not use overly deferential language, maintaining a professional and direct tone."", ""The sentiment score is 50 (slightly positive) because the review acknowledges several strengths of the paper, including its well-written motivation, simple and intuitive approach, and strong experimental results. However, it also points out multiple weaknesses and areas for improvement, balancing the positive aspects. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the paper's contributions while offering constructive criticism. The reviewer avoids harsh or dismissive language, instead using phrases like 'not fully convinced' or suggesting improvements. The tone remains professional and objective throughout."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contribution as a 'useful discovery' and praises its efficiency. However, they also point out limitations, such as the performance being inferior to ImageNet pre-training and the restricted scope of the paper. The politeness score is moderately positive (50) as the reviewer uses neutral language and provides constructive criticism without harsh or dismissive statements. They balance positive aspects ('useful discovery') with areas for improvement ('would benefit from demonstrating concrete benefits') in a professional manner.""]"
"['Quality:\nThe paper appears to be correct\n\nClarity:\nthe paper is clear, although more formalization would help sometimes\n\nOriginality\nThe paper presents an analysis for unsupervised learning of mapping between 2 domains that is totally new as far as I know.\n\nSignificance\nThe points of view defended in this paper can be a basis for founding a general theory for unsupervised learning of mappings between domains.\n\nPros/cons\nPros\n-Adresses an important problem in representation learning\n-The paper proposes interesting assumptions and results for measuring the complexity of semantic mappings\n-A new cross domain mapping is proposed\n-Large set of experiments\nCons\n-Some parts deserve more formalization/justification\n-Too many materials for a conference paper\n-The cost of the algorithm seems high \n\nSummary:\nThis paper studies the problem of unsupervised learning of semantic mappings. It proposes a notion of low complexity networks in this context used for identifying  minimal complexity mappings which is assumed to be central for recovering the best cross domain mapping. A theoretical result shows that the number of low-discrepancy (between cross-domains) mappings of low complexity is rather small.\nA large set of experiments are provided to support the claims of the paper.\n\n\nComments:\n\n-The work is interesting, for an important problemin representation learning, while in machine learning in general with the unsupervised aspect.\n\n-In a sense, I find that the approach suggested by algorithm 1 has some connections with structural risk minimization: by increasing k1 and k2 - when looking for the mapping - you increase the complexity of the model searched while trying to optimize the risk which is measured by the discrepancies and loss.\nThe approach seems costly anyway and I wonder if the authors could think of a smoother version of the algorithm to make it more efficient.\n\n-For counting the minimal complexity mappings, I wonder if one can make a connection with Algorithm robustness of Xu&Mannor(COLT,2012) where instead of comparing losses, you work with discrepancies.\n\nTypo:\nSection 5.1 is build of -> is built of\n', 'This  paper is  on ab important topic : unsupervised learning on unaligned data. \n\nThe paper shows that is possible to learn the between domains mapping using GAN only without a reconstruction (cyclic) loss. The paper postulates that learning should happen on shallower networks first, then on a deeper network that uses the GAN cost function and regularizing discrepancy between the deeper and the small network.  I did not get the time to go through the proofs, but they handle the fully connected case as far as I understand. Please find my comments are below.\n\nOverall it is an interesting  but long paper, the claims are a bit strong for CNN and need further theoretical and experimental verification. The number of layer as a complexity is not appropriate , as we need to take in account many parameters:  the pooling or the striding for the resolution, the presence or the absence of residual connections (for content preservation), the number of feature maps. More experimentation is needed.  \n\n\n\nPros:\n\nImportant and challenging topic to analyze and any progress on unsupervised learning is interesting.\n\nCons:\n\nI have some questions on the shallow/deep in the context of CNN, and to what extent the cyclic cost is not needed, or it is just distilled from the shallow training: \n\n- Arguably the shallow to deep distillation can be understood as a reconstruction cost , since the shallow network will keep a lot of the spatial information. If the deep network match the shallow one , this can be understood as a form of “distilled content “ loss? and the disc of the deep one will take care of the texture , style content? is this intuition correct? \n\n- original cyclic reconstruction constraint is in the pixel space using l1 norm usually, the regularizer introduced matches in a feature space , which is known to produce better results as a “perceptual loss”, can the author comment on this? is this what is really happening here, moving from cyclic constraint on pixels to a  cyclic constraint in a feature space  (shallow network)?\n\n-  *Spatial resolution*: 1) The analysis seems to be done with respect to DNN not to a  CNN. did you study the effect of the architectures in terms of striding and pooling how it affects the results?  I think just counting number of layers as a complexity is not reasonable when we deal with images, with respect to  what preserves contents and what matches texture or style. \n\n2) - Have you tried resnets generators and discriminators  at various depths , with padding so that the spatial resolution is preserved?\n\n- Depth versus width: Another measure that is missing is also the number of feature maps how wide is the network , how does this interplays with the depth?\n\n3) Regularizing deeper networks: in the experiments of varying the length did you see if the results can be stabilized using dropout with deep networks and small feature maps?\n\n4) between training g and h ? how do you initialize h? fully at random ?\n\n5) seems the paper is following implementation by Kim et al. what happens if the discriminator is like in cycle GAN acting on pixels. Pixel GAN rather then only giving a global score for the whole image? ', ""The paper addresses the problem of learning mappings between different domains without any supervision. It belongs to the recent family of papers based on GANs.\nThe paper states three conjectures (predictions in the paper):\n1. GAN are sufficient to learn «\xa0semantic mappings\xa0» in an unsupervised way, if the considered networks are small enough\n2. Controlling the complexity of the network, i.e. the number of the layers, is crucial to come up with what is called «\xa0semantic\xa0» mappings when learning in an unsupervised way. \nMore precisely there is tradeoff to achieve between the complexity of the model and its simplicity. A rich model is required in order to minimize the discrepancy between the distributions of the domains, while a  not too complex model is necessary to avoid mappings that are not «\xa0meaningful\xa0».\n To this aim, the authors  introduce a new notion of function complexity which can be seen as a proxy of Kolmogorov complexity. The introduced notion is very simple and intuitive and is defined as  the depth of a network  which is necessary to  implement the considered function. \nBased on this definition, and assuming identifiability (i.e. uniqueness up to invariants), and for networks with Leaky ReLU activations,  the authors prove that if the number of mappings which preserve a degree of discrepancy (density preserving in the text) is small, then the  set of «\xa0minimal\xa0» mappings  of complexity C   that achieve the same degree of  discrepancy is also small. \nThis result is related to the third conjecture of the paper that is :\n3. the number of the number of mappings which preserve a degree of discrepancy  is small.\n\nThe authors also prove a byproduct result stating that identifiability holds for Leaky ReLU networks with one hidden layer.\n\nThe paper  comes with a series of experiments to empirically «\xa0demonstrate\xa0» the conjectures. \n\nThe paper is well written. The different ideas are clearly stated and discussed, and hence open interesting questions and debates.\n\nSome of these questions that need to be addressed IMHO:\n\n- A critical general question: if the addressed problem is the alignment between e.g. images and not image generation, why not formalizing the problem as a similarity search one (using e.g. EMD or any other transport metric). The alignment task  hence reduces to computing a ranking from this similarity. I have the impression that we use a jackhammer to break a small brick here (no offence). But maybe that I’m missing something here.\n- Several works consider the size and the depth of the network as hyper-parameters to optimize, and this is not new. What is the actual contribution of the paper w.r.t. to this body of work?\n- It is considered that the GAN are trained without any problem, and therefore work in an optimal regime. But the training of the GAN is in itself a problem. How does this affect the paper statements and results?\n- Are the results still valid for another measure of discrepancy based for instance on another measure, e.g. Wasserstein?\n\n\nSome minor remarks :\n- p3: the following sentence is not clear  «\xa0 Our hypothesis is that the lowest complexity small discrepancy mapping approximates the alignment of the target semantic function.\xa0»\n- p6: $C^{\\epsilon_0}_{A,B}$ is used (after Def. 2) before being defined. \n- p7: build->built\n\nSection II :\nA diagram explaining  the different mappings (h_A, h_B, h_AB, etc.) and their spaces (D_A, D_B, D_Z) would greatly help the understanding.\n\nPapers 's pros :\n- clarity\n- technical results\n\ncons:\n- doubts about the interest and originality\n\n\nThe authors provided detailed and convincing answers to my questions. I thank them for that.  My scores were changed accrodingly.\n""]","[70, 20, 50]","[80, 60, 80]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper, highlighting its originality, significance, and addressing an important problem. They mention several pros and only a few cons. The phrase 'The paper appears to be correct' and 'The work is interesting' further indicate a positive sentiment. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They offer balanced feedback, acknowledging both strengths and areas for improvement. The use of phrases like 'I wonder if' and 'I find that' shows a considerate approach to offering suggestions. The reviewer also provides helpful comments and even points out a typo in a non-critical manner."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the importance of the topic and finds the paper interesting, despite having some concerns and questions. The reviewer mentions both pros and cons, indicating a balanced but generally favorable view. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the paper's contributions. The reviewer's tone is professional and constructive, offering detailed feedback without being harsh or dismissive."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's clarity, technical results, and that it opens interesting questions and debates. However, they also express some doubts about the interest and originality of the work. The politeness score is 80 (quite polite) due to the reviewer's respectful tone throughout, use of phrases like 'IMHO' (in my humble opinion), and the acknowledgment of the authors' detailed and convincing answers. The reviewer also thanks the authors for their responses. The language is constructive and professional, even when raising concerns or doubts.""]"
"['The topic is of great interest to the community, and the ideas explored by the authors are reasonable, but I found the conclusion less-than-clear. Mainly, I was not sure how to interpret the experimental findings, and did not have a clear picture of the various models being investigated (e.g. ""base DNN regularized with l2""), or even of the criteria being examined. What is ""learning capacity""? (If it\'s number of model parameters, the authors should just say, ""number of parameters""). The relative performance of the different models examined, plotted in the top row of Figure 3, is quite different, and though the authors do devote a paragraph to interpreting the results, I found it slightly hard to follow, and was not sure what the bottom line was.\n\nWhat does the ""batch model"" refer to?\n\nre. "" 11.9%p − 51.8%p""; remove ""p""?\n\nReference for CIFAR-100? Explain abbreviation for both CIFAR-100 and AWA-Class?\n\nre. ""... but when the number of tasks is large, STL works better since it has larger learning capacity than MTL"": isn\'t the number of parameters matched? If so, why is the ""learning capacity"" different? What do the authors mean exactly by ""learning capacity""?\n\nre. Figure 3, e.g. ""Average per-task performance of the models over number of task t"": this is a general point, but usually the expression ""<f(x)> vs. <x>"" is used rather than ""<f(x)> over <x>"" when describing a plot.\n\n""DNN: dase (sic) DNN"": how is this trained?\n\n\n', 'The paper was clearly written and pleasant to read. I liked the use of sparsity- and group-sparsity-promoting regularizers to select connections and decide how to expand the network.\n\nA strength of the paper is that the proposed algorithm is interesting and intuitive, even if relatively complex, as it requires chaining a sequence of sub-algorithms. It was good to see the impact of each sub-algorithm studied separately (to some degree) in the experimental section. The results are overall strong.\n\nIt’s hard for me to judge the novelty of the approach though, as I’m not an expert on this topic.\n\nJust a few points below:\n- The experiments focus on a relevant continual learning problem, where each new task corresponds to learning a new class. In this setup, the method consistently outperforms EWC (e.g., Fig. 3), as well as the progressive network baseline.\nDid the authors also check the performance on the permuted MNIST benchmark, as studied by Kirkpatrick et al. and Zenke et al.? It would be important to see how the method fares in this setting, where the tasks are the same, but the inputs have to be remapped, and network expansion is less of an issue.\n\n- Fig. 4 would be clearer if the authors showed also the performance and how much the selected connection subsets would change if instead of using the last layer lasso + BFS, the full L1-penalized problem was solved, while keeping the rest of the pipeline intact.\n\n- Still regarding the proposed selective retraining, the special role played by the last hidden layer seems slightly arbitrary. It may well be that it has the highest task-specificity, though this is not trivial to me. This special role might become problematic when dealing with deeper networks.', 'In this paper, the authors propose a method (Dynamically Expandable Network) that addresses issues of training efficiency, how to dynamically grow the network, and how to prevent catastrophic forgetting.\n\nThe paper is well written with a clear problem statement and description of the method for preventing each of the described issues. Interesting points include the use of an L1 regularization term to enforce sparsity in the weights, as well as the method for identifying which neurons have “drifted” too far and should be split. The use of timestamps is a clever addition as well.\n\nOne question would be how sparse training is done, and how this saves computation, especially with the breadth-first search described on page 5. A critique would be that the base networks (a two layer FF net and LeNet) are not very compelling.\n\nExperiments indicate that the method works well, with a clear improvement over progressive networks. Thus, though there isn’t one particular facet of the paper that leaps out, overall the method and results seem solid and worthy of publication.']","[-20, 70, 70]","[60, 80, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the topic's interest and the reasonableness of the ideas, they express significant concerns about the clarity of the conclusion, interpretation of findings, and explanation of models and criteria. The reviewer points out several areas needing improvement or clarification, indicating a generally critical stance. However, the tone is not entirely negative, as they recognize some positive aspects of the work.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I found' and 'I was not sure' to express their concerns, which comes across as less confrontational. The reviewer also asks questions for clarification rather than making accusatory statements. The language is constructive and focused on improving the paper rather than criticizing the authors personally. However, it's not extremely polite, as it doesn't include overtly courteous language or praise beyond the initial acknowledgment of the topic's interest."", ""The sentiment score is 70 (positive) because the reviewer starts with praise for the paper's clarity and writing style, and expresses appreciation for the algorithm's intuitiveness and strong results. The reviewer also mentions the paper's strengths explicitly. However, it's not a perfect score as the reviewer expresses some uncertainty about the novelty of the approach and provides some constructive criticism. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions or questions rather than direct criticisms. Phrases like 'It was good to see...' and 'It would be important to see...' contribute to the polite tone. The reviewer also admits their own limitations in judging certain aspects, which is a humble and polite approach."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper. They describe it as 'well written' and state that the method and results seem 'solid and worthy of publication'. The reviewer also highlights several 'interesting points' and 'clever' aspects of the work. While there are some questions and critiques, these are minor and don't significantly detract from the overall positive sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They balance praise with gentle critique, using phrases like 'One question would be...' and 'A critique would be...' rather than harsh or dismissive language. The reviewer also acknowledges the paper's strengths before mentioning any weaknesses, which is a polite approach to feedback.""]"

reviews,sentiment_scores,politeness_scores,reasonings
"[""This paper abstracts two recently-proposed RNN variants into a family of RNNs called the Linear Surrogate RNNs which satisfy  Blelloch's criteria for parallelizable sequential computation. The authors then propose an efficient parallel algorithm for this class of RNNs, which produces speedups over the existing implements of Quasi-RNN, SRU, and LSTM. Apart from efficiency results, the paper also contributes a comparison of model convergence on a long-term dependency task due to (Hochreiter and Schmidhuber, 1997). A novel linearized version of the LSTM outperforms traditional LSTM on this long-term dependency task, and raises questions about whether RNNs and LSTMs truly need the nonlinear structure.\n\nThe paper is written very well, with explanation (as opposed to obfuscation) as the goal. Linear Surrogate RNNs is an important concept that is useful to understand RNN variants today, and potentially other future novel architectures.\n\nThe paper provides argument and experimental evidence against the rotation used typically in RNNs. While this is an interesting insight, and worthy of further discussion, such a claim needs backing up with more large-scale experiments on real datasets.\n\nWhile the experiments on toy tasks is clearly useful, the paper could be significantly improved by adding experiments on real tasks such as language modelling."", '# Summary and Assessment\n\nThe paper addresses an important issue–that of making learning of recurrent networks tractable for sequence lengths well beyond 1’000s of time steps. A key problem here is that processing such sequences with ordinary RNNs requires a reduce operation, where the output of the net at time step t depends on the outputs of *all* its predecessor. \nThe authors now make a crucial observation, namely that a certain class of RNNs allows evaluation in a non-linear fashion through a so-called SCAN operator. Here, if certain conditions are satisfied, the calculation of the output   can be parallelised massively.\nIn the following, the authors explore the landscape of RNNs satisfying the necessary conditions. The performance is investigated in terms of wall clock time. Further, experimental results of problems with previously untacked sequence lengths are reported.\n\nThe paper is certainly relevant, as it can pave the way towards the application of recurrent architectures to problems that have extremely long term dependencies.\nTo me, the execution seems sound. The experiments back up the claim.\n\n## Minor\n- I challenge the claim that thousands and millions of time steps are a common issue in “robotics, remote sensing, control systems, speech recognition, medicine and finance”, as claimed in the first paragraph of the introduction. IMHO, most problems in these domains get away with a few hundred time steps; nevertheless, I’d appreciate a few examples where this is a case to better justify the method.', 'This paper focuses on accelerating RNN by applying the method from Blelloch (1990). The application is straightforward and thus technical novelty of this paper is limited. But the results are impressive. \n\nOne concern is the proposed technique is only applied for few types of RNNs which may limit its applications in practice. Could the authors comment on this potential limitation?']","[70, 70, 50]","[80, 80, 75]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, praising its clear writing, important concepts, and interesting insights. They describe the paper as 'written very well' and the Linear Surrogate RNNs concept as 'important'. However, it's not a perfect score as the reviewer suggests improvements, such as adding more large-scale experiments and real tasks. The politeness score is 80 (polite) due to the reviewer's constructive and respectful tone throughout. They use phrases like 'The paper could be significantly improved' rather than harsh criticism, and they acknowledge the value of the work while suggesting enhancements. The language is professional and courteous, focusing on the paper's strengths while diplomatically pointing out areas for improvement."", ""The sentiment score is 70 (positive) because the reviewer expresses that the paper addresses an important issue, describes the authors' work as making a 'crucial observation', and states that the paper is 'certainly relevant' and can 'pave the way' for new applications. The execution is described as 'sound' and the experiments are said to 'back up the claim'. The only slight criticism is in the 'Minor' section, which doesn't significantly impact the overall positive sentiment. The politeness score is 80 (polite) because the reviewer uses respectful and professional language throughout. They acknowledge the importance and relevance of the work, and even when raising a minor challenge, they phrase it politely ('I challenge the claim...') and express interest in further justification ('I'd appreciate a few examples...'). The tone is constructive and collegial throughout."", ""The sentiment score is 50 (slightly positive) because while the reviewer notes limited technical novelty, they describe the results as 'impressive'. The overall tone is balanced but leans positive. The politeness score is 75 (quite polite) due to the constructive and respectful language used. The reviewer acknowledges the paper's strengths and frames their concern as a question, inviting the authors to comment rather than demanding changes. This approach is diplomatic and shows respect for the authors' work.""]"
"['The paper provides an approach to learning reward functions in high-dimensional domains, showing that it performs comparably to other recent approaches to this problem in the imitation-learning setting. It also argues that a key property to learning generalizable reward functions is for them to depend on state, but not state-action or state-action-state. It uses this property to produce ""disentangled rewards"", demonstrating that they transfer well to the same task under different transition dynamics.\n\nThe need for ""state-only"" rewards is a useful insight and is covered fairly well in the paper. The need for an ""adversarial"" approach is not justified as fully, but perhaps is a consequence of recent work. The experiments are thorough, although the connection to the motivation in the abstract (wanting to avoid reward engineering) is weak.\n\nDetailed feedback:\n\n""deployed in at test-time on environments"" -> ""deployed at test time in environments""?\n\n""which can effectively recover disentangle the goals"" -> ""which can effectively disentangle the goals""?\n\n""it allows for sub-optimality in demonstrations, and removes ambiguity between demonstrations and the expert policy"": I am not certain what is being described here and it doesn\'t appear to come up again in the paper. Perhaps remove it?\n\n""r high-dimensional (Finn et al., 2016b) Wulfmeier"" -> ""r high-dimensional (Finn et al., 2016b). Wulfmeier"".\n\n""also consider learning cost function with"" -> ""also consider learning cost functions with""?\n\n""o learn nonlinear cost function have"" -> ""o learn nonlinear cost functions have"".\n\n"" are not robust the environment changes"" -> "" are not robust to environment changes""?\n\n""We present a short proof sketch"": It is unclear to me what is being proven here. Please state the theorem.\n\n""In the method presented in Section 4, we cannot learn a state-only reward function"": I\'m not seeing that. Or, maybe I\'m confused between rewards depending on s vs. s,a vs. s,a,s\'. Again, an explicit theorem statement might remove some confusion here.\n\n""AIRLperforms"" -> ""AIRL performs"".\n\nFigure 2: The blue and green colors look very similar to me. I\'d recommend reordering the legend to match the order of the lines (random on the bottom) to make it easier to interpret.\n\n""must reach to goal"" -> ""must reach the goal""?\n\n""pointmass"" -> ""point mass"". (Multiple times.)\n\nAmin, Jiang, and Singh\'s work on efficiently learning a transferable reward function seems relevant here. (Although, it might not be published yet: https://arxiv.org/pdf/1705.05427.pdf.)\n\nPerhaps the final experiment should have included state-only runs. I\'m guessing that they didn\'t work out too well, but it would still be good to know how they compare.\n', 'SUMMARY:\nThis paper considers the Inverse Reinforcement Learning (IRL) problem, and particularly suggests a method that obtains a reward function that is robust to the change of dynamics of the MDP.\n\nIt starts from formulating the problem within the MaxEnt IRL framework of Ziebart et al. (2008). The challenge of MaxEnt IRL is the computation of a partition function. Guided Cost Learning (GCL) of Finn et al. (2016b) is an approximation of MaxEnt IRL that uses an adaptive importance sampler to estimate the partition function. This can be shown to be a form of GAN, obtained by using a specific discriminator [Finn et al. (2016a)].\n\nIf the discriminator directly works with trajectories tau, the result would be GAN-GCL. But this leads to high variance estimates, so the paper suggests using a single state-action formulation, in which the discriminator f_theta(s,a) is a function of (s,a) instead of the trajectory. The optimal solution of this discriminator is to have f(s,a) = A(s,a) — the advantage function.\nThe paper, however, argues that the advantage function is “entangled” with the dynamics, and this is undesirable. So it modified the discriminator to learn a function that is a combination of two terms, one only depends on state-action and the other depends on state, and has the form of shaped reward transformation.\n\n\nEVALUATION:\n\nThis is an interesting paper with good empirical results. As I am not very familiar with the work of Finn et al. (2016a) and Finn et al. (2016b), I have not verified the detail of derivations of this new paper very closely. That being said, I have some comments and questions:\n\n\n* The MaxEnt IRL formulation of this work, which assumes that p_theta(tau) is proportional to exp( r_theta (tau) ), comes from\n[Ziebart et al., 2008] and assumes a deterministic dynamics. Ziebart’s PhD dissertation [Ziebart, 2010] or the following paper show that the formulation is different for stochastic dynamics:\n\nZiebart, Bagnell, Dey, “The Principle of Maximum Causal Entropy for Estimating Interacting Processes,” IEEE Trans. on IT, 2013.\n\nIs it still a reasonable thing to develop based on this earlier, an inaccurate, formulation?\n\n\n* I am not convinced about the argument of Appendix C that shows that AIRL recovers reward up to constants.\nIt is suggested that since the only items on both sides of the equation on top of p. 13 depend on s’ are h* and V, they should be equal.\nThis would be true if s’ could be chosen arbitrararily. But s’ would be uniquely determined by s for a deterministic dynamics. In that case, this conclusion is not obvious anymore.\n\nConsider the state space to be integers 0, 1, 2, 3, … .\nSuppose the dynamics is that whenever we are at state s (which is an integer), at the next time step the state decreases toward 1, that is s’ = phi(s,a) = s - 1; unless s = 0, which we just stay at s’ = s = 0. This is independent of actions.\nAlso define r(s) = 1/s for s>=1 and r(0) = 0.\nSuppose the discount factor is gamma = 1 (note that in Appendix B.1, the undiscounted case is studied, so I assume gamma = 1 is acceptable).\n\nWith this choices, the value function V(s) = 1/s + 1/(s-1) + … + 1/1 = H_s, i.e., the Harmonic function.\nThe advantage function is zero. So we can choose g*(s) = 0, and h*(s) = h*(s’) = 1.\nThis is in contrast to the conclusion that h*(s’) = V(s’) + c, which would be H_s + c, and g*(s) = r(s) = 1/s.\n(In fact, nothing is special about this choice of reward and dynamics.)\n\nAm I missing something obvious here?\n\nAlso please discuss how ergodicity leads to the conclusion that spaces of s’ and s are identical. What does “space of s” mean? Do you mean the support of s? Please make the argument more rigorous.\n\n\n* Please make the argument of Section 5.1 more rigorous.', 'This paper revisits the generative adversarial network guided cost learning (GAN-GCL)  algorithm presented last year. The authors argue learning rewards from sampled trajectories has a high variance. Instead, they propose to learn a generative model wherein actions are sampled as a function of states. The same energy model is used for sampling actions: the probability of an action is proportional to the exponential of its reward. To avoid overfitting the expert\'s demonstrations (by mimicking the actions directly instead of learning a reward that can be generalized to different dynamics), the authors propose to learn rewards that depend only on states, and not on actions. Also, the proposed reward function includes a shaping term, in order to cover all possible transformations of the reward function that could have been behind the expert\'s actions. The authors argue formally that this is necessary to disentangle the reward function from the dynamics. Th paper also demonstrates this argument empirically (e.g. Figure 1).\n\nThis paper is well-written and technically sound. The empirical evaluations seem to be supporting the main claims of the paper. The paper lacks a little bit in novelty since it is basically a variante of GAN-GCL, but it makes it up with the inclusion of  a shaping term in the rewards and with the related formal arguments. The empirical evaluations could also be strengthened with experiments in higher-dimensional systems (like video games). \n\n""Under maximum entropy IRL, we assume the demonstrations are drawn from an optimal policy p(\\tau) \\propto exp(r(tau))"" This is not an assumption, it\'s the form of the solution we get by maximizing the entropy (for regularization).\n']","[50, 20, 60]","[80, 60, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and insights, particularly the 'state-only' rewards concept. They describe the experiments as 'thorough' but also point out some weaknesses, such as the weak connection to the motivation in the abstract. The overall tone is constructive rather than overtly critical or enthusiastic. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering suggestions rather than demands (e.g., 'Perhaps remove it?', 'I'd recommend'). They also phrase criticisms as questions or observations rather than direct accusations. The reviewer maintains a professional and courteous tone while providing detailed feedback, including pointing out typos and suggesting improvements."", ""The sentiment score is slightly positive (20) because the reviewer describes the paper as 'interesting' with 'good empirical results'. However, they also raise several significant questions and concerns, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, such as 'This is an interesting paper' and 'Am I missing something obvious here?', showing a willingness to consider their own potential misunderstandings. They also phrase their criticisms as questions or suggestions rather than direct criticisms. The reviewer maintains a professional tone, focusing on the content of the paper rather than making personal comments about the authors."", ""The sentiment score is 60 (positive) because the reviewer states that the paper is 'well-written and technically sound' and that the 'empirical evaluations seem to be supporting the main claims of the paper.' They also mention that while the paper 'lacks a little bit in novelty,' it makes up for this with additional contributions. The overall tone is approving, with some constructive criticism. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering suggestions for improvement in a considerate manner. They use phrases like 'could be strengthened' rather than more critical language. The reviewer also provides a specific, helpful correction without being harsh or dismissive.""]"
"['The authors consider the problem of dynamically choosing between several reinforcement learning algorithms for solving a reinforcement learning with discounted rewards and episodic tasks. The authors propose the following solution to the problem:\n- During epochs of exponentially increasing size (this technique is well known in the bandit litterature and is called a ""doubling trick""), the various reinforcement learning algorithms are ""frozen"" (i.e. they do not adapt their policy) and the K available algorithms are sampled using the UCB1 algorithm  in order to discover the one which yields the highest mean reward.\n\nOverall the paper is well written, and presents some interesting novel ideas on aggregating reinforcement learning algorithms. Below are some remarks:\n\n- An alternative and perhaps simpler formalization of the problem would be learning with expert advice (using algorithms such as ""follow the perturbed leader""), where each of the available reinforcement learning algorithms acts as an expert. What is more, these algorithms usually yield O(sqrt(T)log(T)), which is the regret obtained by the authors in the worse case (where all the learning algorithms do converge to the optimal policy at the optimal speed O(1/sqrt(T)). It would have been good to see how those approaches perform against the proposed algorithms. \n- The authors use UCB1, but they did not try KL-UCB, which is stricly better (in fact it is optimal for bounded rewards). In particular the numerical performance of the latter is usually vastly better than the former, especially when rewards have a small variance.\n- The performance measure used by the authors is rather misleading (""short sighted regret""): they compare what they obtain to what the policy discovered by the best reainforcement learning algorithm \\underline{based on the trajectories they have seen}, and the trajectories themselves are generated by the choices made by the algorthms at previous time. Ie in general, there might be cases in which one does not explore enough with this approach (i.e one does not try all state-action pairs enough), so that while this performance measure is low, the actual regret is very high and the algorithm does not learn the optimal policy at all (while this could be done by simply exploring at random log(T) times ...).\n', 'The paper considers the problem of online selection of RL algorithms. An algorithm selection (AS) strategy called ESBAS is proposed. It works in a sequence of epochs of doubling length, in the following way: the algorithm selection is based on a UCB strategy, and the parameters of the algorithms are not updated within each epoch (in order that the returns obtained by following an algorithm be iid). This selection allows ESBAS to select a sequence of algorithms within an epoch to generate a return almost as high as the return of the best algorithm, if no learning were made. This weak notion of regret is captured by the short-sighted pseudo regret. \n\nNow a bound on the global regret is much harder to obtain because there is no way of comparing, without additional assumption, the performance of a sequence of algorithms to the best algorithm had this one been used to generate all trajectories from the beginning. Here it is assumed that all algorithms learn off-policy. However this is not sufficient, since learning off-policy does not mean that an algorithm is indifferent to the behavior policy that has generated the data. Indeed even for the most basic off-policy algorithms, such as Q-learning, the way data have been collected is extremely important, and collecting transitions using that algorithm (such as epsilon-greedy) is certainly better than following an arbitrary policy (such as uniformly randomly, or following an even poorer policy which would not explore at all). However the authors seem to state an equivalence between learning off-policy and fairness of learning (defined in Assumption 3). For example in their conclusion they mention “Fairness of algorithm evaluation is granted by the fact that the RL algorithms learn off-policy”. This is not correct. I believe the main assumption made in this paper is the Assumption 3 (and not that the algorithms learn off-policy) and this should be dissociated from the off-policy learning. \n\nThis fairness assumption is very a strong assumption that does not seem to be satisfied by any algorithm that I can think of. Indeed, consider D being the data generated by following algorithm alpha, and let D’ be the data generated by following algorithm alpha’. Then it makes sense that the performance of algorithm alpha is better when trained on D rather than D’, and alpha’ is better when trained on D’ than on D. This contradicts the fairness assumption. \n\nThis being said, I believe the merit of this paper is to make explicit the actual assumptions required to be able to derive a bound on the global regret. So although the fairness assumption is unrealistic, it has the benefit of existing…\n\nSo in the end I liked the paper because the authors tried to address this difficult problem of algorithmic selection for RL the best way they could. Maybe future work will do better but at least this a first step in an interesting direction.\n\nNow, I would have liked a comparison with other algorithms for algorithm selection, like:\n- explore-then-exploit, where a fraction of T is used to try each algorithm uniformly, then the best one is selected and played for the rest of the rounds.\n- Algorithms that have been designed for curriculum learning, such as some described in [Graves et al., Automated Curriculum Learning for Neural Networks, 2017], where a proxy for learning progress is used to estimate how much an algorithm can learn from data.\n\nOther comments:\n- Table 1 is really incomprehensible. Even after reading the Appendix B, I had a hard time understanding these results.\n- I would suggest adding the fairness assumption in the main text and discussing it, as I believe this is crucial component for the understanding of how the global regret can be controlled.\n- you may want to include references on restless bandits in Section 2.4, as this is very related to AS of RL algorithms (arms follow Markov processes).\n- The reference [Best arm identification in multi-armed bandits] is missing an author.\n\n', 'SUMMARY\nThe paper considers a meta-algorithm, in the form of a UCB algorithms, that selects base-learners in a pool of reinforcement learning agents.\n\nHIGH LEVEL COMMENTS\nIn this paper, T refers to the total number of meta-decisions. This is very different from the total number of interactions with the system that corresponds to D_T=sum_{\\tau=1}^T |\\epsilon_tau|. Wouldn\'t it make more sense to optimize regret accumulated on this global time?\nThe proposed strategy thus seems a bit naive since different algorithms from the set \\cal P may generate trajectories of different length. \nFor instance, one algorithm may obtain relatively high rewards very fast with short trajectories and another one may get slightly higher cumulative rewards but on much longer trajectories.\nIn this case, the meta-algorithm will promote the second algorithm, while repeatedly selecting the first one would yield higher cumulative reward in total over all decision (and not meta-decision) time steps.\nThis also means that playing T1 meta-decision steps, where T1>>T, may corresponds to a total number of decision steps sum_{\\tau=1}^{T_1} |\\epsilon\'_tau| still not larger than D_T (where \\epsilon\'_\\tau are other trajectories).\nNow the performance of a specific learner with T1 trials may be much higher than with T trials, and thus even though the regret of the meta-learner is higher, the overall performance of the recommended policy learned at that point may be better than the one output with T meta-decisions.\n\nThus, it seems to me that a discussion about the total number of decision steps (versus meta-deciion steps) is missing in order to better motivate the choise of performance measure, and generates possibly complicated situations, with a non trivial trade-off that needs to be adressed. This also suggests the proposed algorithm may be quite sub-optimal in terms of total number of decision steps.\nMy feeling is that the reason you do not observe a too bad behavior in practice may be due to the discount factor.\n\nOTHER COMMENTS:\nPage 4: What value of \\xi do you use in ESBAS ? I guess it should depend on R/(1-\\gamma)?\n\nPage 5: ""one should notice that the first two bounds are obtained by summming up the gaps"": which bounds? which gaps? Can you be more precise?\nNext sentence also needs to be clarified. What is the budget issue involved here?\n\nCan you comment on the main reason why you indeed get O(sqrt{T}) and not O(\\sqrt{T poly-log(T)}) for instance?\n\nTheorem 3: ""with high probability delta_T in O(1/T)"": do you mean with probability higher than 1-delta_T, with delta_T = O(1/T) ?\n\nParagraph on Page 15 : Do you have a proof for the claim that such algorithms indeed satisfy these assumptions ?\nEspecially proving that assumption 3 holds may not be obvious since one may consider an algorithm may better learn using data collected from its played polocy rather than from other policies.\n\n(14b-c, 15d): should u be u^\\alpha ? I may simply be confused with the notations.\n\nDECISION\nEven though there seems to be an important missing discussion regarding optimization of performance with respect to the total number of decision steps rather than the total number of meta-decision steps,\nI would tend to accept the paper. Indeed, if we left apart the choice for this performance measure, the paper is relatively well written and provides both theoretical and practical results that are of interest. But this has to be clarified.\n']","[50, 50, -20]","[80, 75, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by acknowledging that the paper is well-written and presents interesting novel ideas. However, they also provide several critical remarks, suggesting areas for improvement. This balanced approach indicates a moderately positive sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh or dismissive comments. They use phrases like 'It would have been good to see' and 'The authors use... but they did not try,' which suggest improvements in a non-confrontational manner. The reviewer also acknowledges the positive aspects of the paper before presenting their critiques, which is a polite approach to peer review."", ""The sentiment score is 50 (slightly positive) because while the reviewer points out significant issues with the paper's assumptions and methodology, they also acknowledge the paper's merit in addressing a difficult problem and see it as a step in an interesting direction. The conclusion is generally positive, stating 'I liked the paper'. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms constructively. They use phrases like 'I believe', 'I would have liked', and 'you may want to', which maintain a polite tone while offering suggestions. The reviewer also balances critiques with positive remarks, showing consideration for the authors' work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('the paper is relatively well written and provides both theoretical and practical results that are of interest'), they raise significant concerns about the methodology and missing discussions. The reviewer points out a 'missing discussion' and suggests the proposed algorithm 'may be quite sub-optimal'. However, they still lean towards accepting the paper, which prevents the score from being more negative. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions ('Wouldn't it make more sense...', 'Can you comment on...'), and acknowledges positive aspects. They also use polite phrases like 'My feeling is...' and 'I would tend to accept...'. The tone is professional and constructive, even when pointing out issues.""]"
"[""The authors identify a new security threat for deep learning: Decision-based adversarial attacks. This new class of attacks on deep learning systems requires from an attacker only the knowledge of class labels (previous attacks required more information, e.g., access to a gradient oracle). Unsurprisingly, since the attacker has so few information, such kind of attacks involves quite a lot trial and error. The authors propose one specific attack instance out of this class of attacks. It works as follows.\n\nFirst, an initial point outside of the benign region is guessed. Then multiple steps towards the decision boundary is taken, finally reaching the boundary (I am not sure about the precise implementation, but it seems not crucial; the author may please check whether their description of the algorithm is really reproducable). Then, in a nutshell, a random walk on a sphere centered around the original, benign point is performed, where after each step, the radius of the sphere is slightly reduced (drawing the point closer to the original point), if and only if the resulting point still is outside of the benign region.\n\nThe algorithm is evaluated on the following datasets: MNIST, CIFAR, VGG19, ResNet50, and InceptionV3.\n\nThe paper is rather well written and structured. The text was easy to follow. I suggest that a self-contained description of the problem setting (assumptions on attacker and defender; aim?) shall be added to the camera-ready version (being not familiar with the area, I had to read a couple of papers to get a feeling for the setting, before reviewing this paper). As in many DL papers these days, there really isn't any math in it worth a mention; so no reason here to say anything about mathematical soundness. The authors employ a reasonable evaluation criterion in their experiments: the median squared Euclidean distance between the original and adversarially modified data point. The results show consistent improvement for most data sets. \n\nIn summary, this is an innovative paper, proposing a new class of attacks that totally makes sense in my opinion. Apart from some minor weaknesses in the presentation that can be easily fixed for the camera ready, this is a nice, fresh paper, that might spur more attacks (and of course new defenses) from the new class of decision-based attacks. It is worth to note that the authors show that distillation is not a useful defense against such attacks, so we may expect follow-up proposing useful defenses against the new attack (which BTW is shown to be about a factor of 10 in terms of iterations more costly than the SOTA)."", 'This is a nice paper proposing a simple but effective heuristic for generating adversarial examples from class labels with no gradient information or class probabilities. Highly relevant prior work was overlooked and there is no theoretical analysis, but I think this paper still makes a valuable contribution worth sharing with a broader audience.\n\nWhat this paper does well:\n- Suggests a type of attack that hasn\'t been applied to image classifiers\n- Proposes a simple heuristic method for performing this attack\n- Evaluates the attack on both benchmark neural networks and a commercial system \n\nProblems and limitations:\n\n1. No theoretical analysis. Under what conditions does the boundary attack succeed or fail? What geometry of the classification boundaries is necessary? How likely are those conditions to hold? Can we measure how well they hold on particular networks?\n\nSince there is no theoretically analysis, the evidence for effectiveness is entirely empirical. That weakens the paper and suggests an important area of future work, but I think the empirical evidence is sufficient to show that there\'s something interesting going. Not a fatal flaw.\n\n2. Poor framing. The paper frames the problem in terms of ""machine learning models"" in general (beginning with the first line of the abstract), but it only investigates image classification. There\'s no particular reason to believe that all machine learning algorithms will behave like convolutional neural network image classifiers. Thus, there\'s an implicit claim of generality that is not supported.\n\nThis is a presentation issue that is easily fixed. I suggest changing the title to reflect this, or at least revising the abstract and introduction to make the scope clearer.\n\nA minor presentation quibble/suggestion: ""adversarial"" is used in this paper to refer to any class that differs from the true class of the instance to be disguised. But an image of a dalmation that\'s labeled as a dalmation isn\'t adversarial -- it\'s just a different image that\'s labeled correctly. The adversarial process is about constructing something that will be mislabeled, exploiting some kind of weakness that doesn\'t show up on a natural distribution of inputs. I suggest rewording some of the mentions of adversarial.\n\n3. Ignorance of prior work. Finding deceptive inputs using only the classifier output has been done by Lowd and Meek (KDD 2005) for linear classifiers and Nelson et al. (AISTATS 2010, JMLR 2012) for convex-inducing classifiers. Both works include theoretical bounds on the number of queries required for near-optimal adversarial examples. Biggio et al. (ECML 2013) further propose training a surrogate classifier on similar training data, using the predictions of the target classifier to relabel the training data. In this way, decision information from the target model is used to help train a more similar surrogate, and then attacks can be transferred from the surrogate to the target.\n\nThus, ""decision-based attacks"" are not new, although the algorithm and experiments in this paper are. \n\n\nOverall, I think this paper makes a worthwhile contribution, but needs to revise the claims to match what\'s done in the paper and what\'s been done before.', 'In this paper, the authors propose a novel method for generating adversarial examples when the model is a black-box and we only have access to its decisions (and a positive example).  It iteratively takes steps along the decision boundary while trying to minimize the distance to the original positive example.\n\n\nPros:\n- Novel method that works under much stricter and more realistic assumptions.\n- Fairly thorough evaluation.\n- The paper is clearly written.\n\n\nCons:\n- Need a fair number of calls to generate a small perturbation.  Would like to see more analysis of this.\n- Attack works for making something outside the boundary (not X), but is less clear how to generate image to meet a specific classification (X).  3.2 attempts this slightly by using an image in the class, but is less clear for something like FaceID.\n- Unclear how often the images generated look reasonable.  Do different random initializations given different quality examples?\n']","[80, 50, 50]","[70, 75, 75]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'innovative', 'nice', and 'fresh'. They mention that it 'totally makes sense' and could 'spur more attacks (and of course new defenses)'. The reviewer also notes that the paper is 'rather well written and structured' and 'easy to follow'. While there are some minor criticisms, the overall tone is very positive.\n\nThe politeness score is 70 (polite) because the reviewer uses respectful language throughout. They offer constructive feedback and suggestions for improvement without being harsh or dismissive. Phrases like 'the authors may please check' and 'I suggest that' indicate a polite and considerate tone. The reviewer also acknowledges their own potential lack of familiarity with the field, which shows humility. While not excessively formal or deferential, the language is consistently professional and courteous."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by calling it a 'nice paper' and acknowledges its valuable contribution, but also points out several significant limitations and areas for improvement. The overall tone is constructive rather than dismissive. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions for improvement rather than harsh judgments. Phrases like 'I think this paper still makes a valuable contribution' and 'I suggest changing' indicate a polite and constructive approach to feedback."", ""The sentiment score is 50 (slightly positive) because the review begins with a neutral description of the paper's content, followed by a balanced list of pros and cons. The pros highlight novel aspects and clear writing, while the cons point out areas for improvement without being overly critical. The politeness score is 75 (quite polite) because the reviewer uses professional and respectful language throughout. They acknowledge the paper's strengths and frame criticisms as suggestions for improvement rather than harsh judgments. Phrases like 'Would like to see more analysis' and 'Unclear how often' indicate a constructive approach to feedback rather than blunt criticism.""]"
"[""The main significance of this paper is to propose the task of generating the lead section of Wikipedia articles by viewing it as a multi-document summarization problem. Linked articles as well as the results of an external web search query are used as input documents, from which the Wikipedia lead section must be generated. Further preprocessing of the input articles is required, using simple heuristics to extract the most relevant sections to feed to a neural abstractive summarizer. A number of variants of attention mechanisms are compared, including the transofer-decoder, and a variant with memory-compressed attention in order to handle longer sequences. The outputs are evaluated by ROUGE-L and test perplexity. There is also a A-B testing setup by human evaluators to show that ROUGE-L rankings correspond to human preferences of systems, at least for large ROUGE differences.\n\nThis paper is quite original and clearly written. The main strength is in the task setup with the dataset and the proposed input sources for generating Wikipedia articles. The main weakness is that I would have liked to see more analysis and comparisons in the evaluation.\n\nEvaluation:\nCurrently, only neural abstractive methods are compared. I would have liked to see the ROUGE performance of some current unsupervised multi-document extractive summarization methods, as well as some simple multi-document selection algorithms such as SumBasic. Do redundancy cues which work for multi-document news summarization still work for this task?\n\nExtractiveness analysis:\nI would also have liked to see more analysis of how extractive the Wikipedia articles actually are, as well as how extractive the system outputs are. Does higher extractiveness correspond to higher or lower system ROUGE scores? This would help us understand the difficulty of the problem, and how much abstractive methods could be expected to help. \n\nA further analysis which would be nice to do (though I have less clear ideas how to do it), would be to have some way to figure out which article types or which section types are amenable to this setup, and which are not. \n\nI have some concern that extraction could do very well if you happen to find a related article in another website which contains encyclopedia-like or definition-like entries (e.g., Baidu, Wiktionary) which is not caught by clone detection. In this case, the problem could become less interesting, as no real analysis is required to do well here.\n\nOverall, I quite like this line of work, but I think the paper would be a lot stronger and more convincing with some additional work.\n\n----\nAfter reading the authors' response and the updated submission, I am satisfied that my concerns above have been adequately addressed in the new version of the paper. This is a very nice contribution.\n"", 'This paper considers the task of generating Wikipedia articles as a combination of extractive and abstractive multi-document summarization task where input is the content of reference articles listed in a Wikipedia page along with the content collected from Web search and output is the generated content for a target Wikipedia page. The authors at first reduce the input size by using various extractive strategies and then use the selected content as input to the abstractive stage where they leverage the Transformer architecture with interesting modifications like dropping the encoder and proposing alternate self-attention mechanisms like local and memory compressed attention.   \n\nIn general, the paper is well-written and the main ideas are clear. However, my main concern is the evaluation. It would have been nice to see how the proposed methods perform with respect to the existing neural abstractive summarization approaches. Although authors argue in Section 2.1 that existing neural approaches are applied to other kinds of datasets where the input/output size ratios are smaller,  experiments could have been performed to show their impact. Furthermore, I really expected to see a comparison with Sauper & Barzilay (2009)\'s non-neural extractive approach of Wikipedia article generation, which could certainly strengthen the technical merit of the paper.\n\nMore importantly, it was not clear from the paper if there was a constraint on the output length when each model generated the Wikipedia content. For example, Figure 5-7 show variable sizes of the generated outputs. With a fixed reference/target Wikipedia article, if different models generate variable sizes of output, ROUGE evaluation could easily pose a bias on a longer output as it essentially counts overlaps between the system output and the reference. \n\nIt would have been nice to know if the proposed attention mechanisms account for significantly better results than the T-ED and T-D architectures. Did you run any statistical significance test on the evaluation results? \n\nAuthors claim that the proposed model can generate ""fluent, coherent"" output, however, no evaluation has been conducted to justify this claim. The human evaluation only compares two alternative models for preference, which is not enough to support this claim. I would suggest to carry out a DUC-style user evaluation (http://www-nlpir.nist.gov/projects/duc/duc2007/quality-questions.txt) methodology to really show that the proposed method works well for abstractive summarization.\n\nDoes Figure 8 show an example input after the extractive stage or before? Please clarify.\n\n---------------\nI have updated my scores as authors clarified most of my concerns.', 'This paper proposes an approach to generating the first section of Wikipedia articles (and potentially entire articles). \nFirst relavant paragraphs are extracted from reference documents and documents retrieved through search engine queries through a TD-IDF-based ranking. Then abstractive summarization is performed using a modification of Transformer networks (Vasvani et al 2017). A mixture of experts layer further improves performance. \nThe proposed transformer decoder defines a distribution over both the input and output sequences using the same self-attention-based network. On its own this modification improves perplexity (on longer sequences) but not the Rouge score; however the architecture enables memory-compressed attention which is more scalable to long input sequences. It is claimed that the transformer decoder makes optimization easier but no complete explanation or justification of this is given. Computing self-attention and softmaxes over entire input sequences will significantly increase the computational cost of training.\n\nIn the task setup the information retrieval-based extractive stage is crucial to performance, but this contribution might be less important to the ICLR community. It willl also be hard to reproduce without significant computational resources, even if the URLs of the dataset are made available. The training data is significantly larger than the CNN/DailyMail single-document summarization dataset.\n\nThe paper presents strong quantitative results and qualitative examples. Unfortunately it is hard to judge the effectiveness of the abstractive model due to the scale of the experiments, especially with regards to the quality of the generated output in comparison to the output of the extractive stage.\nIn some of the examples the system output seems to be significantly shorter than the reference, so it would be helpful to quantify this, as well how much the quality degrades when the model is forced to generate outputs of a given minimum length. While the proposed approach is more scalable, it is hard to judge the extend of this.\n\nSo while the performance of the overall system is impressive, it is hard to judge the significance of the technical contribution made by the paper.\n\n---\nThe additional experiments and clarifications in the updated version give substantially more evidence in support of the claims made by the paper, and I would like to see the paper accepted. \n']","[60, 20, 50]","[80, 60, 75]","[""The sentiment score is 60 (positive) because the reviewer describes the paper as 'quite original and clearly written' and mentions its 'main strength'. They also state it's a 'very nice contribution' in the final paragraph. However, they do point out some weaknesses and areas for improvement, which prevents a higher score. The politeness score is 80 (quite polite) due to the constructive and respectful tone throughout. The reviewer uses phrases like 'I would have liked to see' and 'I think the paper would be a lot stronger' instead of harsh criticisms. They also acknowledge the authors' response positively. The language is professional and courteous throughout, offering suggestions rather than demands."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper is 'well-written' and has 'clear' main ideas, they express several concerns about the evaluation and methodology. The reviewer suggests improvements and additional experiments, indicating a constructive but not overwhelmingly positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as suggestions ('It would have been nice to see...'), and asks questions rather than making blunt statements. The tone is professional and constructive, avoiding harsh or rude language. The final line indicating that the reviewer has updated their scores after clarifications from the authors also suggests a polite and fair approach to the review process."", ""The sentiment score is 50 (slightly positive) because while the reviewer acknowledges the paper's strong quantitative results and impressive overall system performance, they also express some reservations about judging the effectiveness of the abstractive model and the significance of the technical contribution. However, the final paragraph indicates a positive shift, recommending acceptance after additional experiments and clarifications. The politeness score is 75 (quite polite) because the reviewer uses respectful and constructive language throughout, offering specific suggestions for improvement and acknowledging the paper's strengths. They avoid harsh criticism and frame their concerns as areas for clarification rather than outright flaws. The use of phrases like 'it would be helpful' and 'it is hard to judge' maintain a polite tone while expressing concerns.""]"
"['This paper presents a variational inference algorithm for models that contain\ndeep neural network components and probabilistic graphical model (PGM)\ncomponents.\nThe algorithm implements natural-gradient message-passing where the messages\nautomatically reduce to stochastic gradients for the non-conjugate neural\nnetwork components. The authors demonstrate the algorithm on a Gaussian mixture\nmodel and linear dynamical system where they show that the proposed algorithm\noutperforms previous algorithms. Overall, I think that the paper proposes some\ninteresting ideas, however, in its current form I do not think that the novelty\nof the contributions are clearly presented and that they are not thoroughly\nevaluated in the experiments.\n\nThe authors propose a new variational inference algorithm that handles models\nwith deep neural networks and PGM components. However, it appears that the\nauthors rely heavily on the work of (Khan & Lin, 2017) that actually provides\nthe algorithm. As far as I can tell this paper fits inference networks into\nthe algorithm proposed in (Khan & Lin, 2017) which boils down to i) using an\ninference network to generate potentials for a conditionally-conjugate\ndistribution and ii) introducing new PGM parameters to decouple the inference\nnetwork from the model parameters. These ideas are a clever solution to work\ninference networks into the message-passing algorithm of (Khan & Lin, 2017),\nbut I think the authors may be overselling these ideas as a brand new algorithm.\nI think if the authors sold the paper as an alternative to (Johnson, et al., 2016)\nthat doesn\'t suffer from the implicit gradient problem the paper would fit into\nthe existing literature better.\n\nAnother concern that I have is that there are a lot of conditiona-conjugacy\nassumptions baked into the algorithm that the authors only mention at the end\nof the presentation of their algorithm. Additionally, the authors briefly state\nthat they can handle non-conjugate distributions in the model by just using\nconjugate distributions in the variational approximation. Though one could do\nthis, the authors do not adequately show that one should, or that one can do this\nwithout suffering a lot of error in the posterior approximation. I think that\nwithout an experiment the small section on non-conjugacy should be removed.\n\nFinally, I found the experimental evaluation to not thoroughly demonstrate the\nadvantages and disadvantages of the proposed algorithm. The algorithm was applied\nto the two models originally considered in (Johnson, et al., 2016) and the\nproposed algorithm was shown to attain lower mean-square errors for the two\nmodels. The experiments do not however demonstrate why the algorithm is\nperforming better. For instance, is the (Johnson, et al., 2016) algorithm\nsuffering from the implicit gradient? It also would have been great to have\nconsidered a model that the (Johnson, et. al., 2016) algorithm would not work\nwell on or could not be applied to show the added applicability of the proposed\nalgorithm.\n\nI also have some minor comments on the paper:\n- There are a lot of typos.\n- The first two sentences of the abstract do not really contribute anything\n  to the paper. What is a powerful model? What is a powerful algorithm?\n- DNN was used in Section 2 without being defined.\n- Using p() as an approximate distribution in Section 3 is confusing notation\n  because p() was used for the distributions in the model.\n- How is the covariance matrix parameterized that the inference network produces?\n- The phrases ""first term of the inference network"" are not clear. Just use The\n  DNN term and the PGM term of the inference networks, and better still throw\n  in a reference to Eq. (4).\n- The term ""deterministic parameters"" was used and never introduced.\n- At the bottom of page 5 the extension to the non-conjugate case should be\n  presented somewhere (probably the appendix) since the fact that you can do\n  this is a part of your algorithm that\'s important.\n', 'The authors adapts stochastic natural gradient methods for variational inference with structured inference networks. The variational approximation proposed is similar to SVAE by Jonhson et al. (2016), but rather than directly using the global variable theta in the local approximation for x the authors propose to optimize a separate variational parameter. The authors then extends and adapts the natural gradient method by Khan & Lin (2017) to optimize all the variational parameters. In the experiments the authors generally show improved convergence over SVAE.\n\nThe idea seems promising but it is still a bit unclear to me why removing dependence between global and local parameters that you know is there would lead to a better variational approximation. The main motivation seems to be that it is easier to optimize.\n\n- In the last two sentences of the updates for \\theta_PGM you mention that you need to do SVI/VMP to compute the function \\eta_x\\theta. Might this also suffer from non-convergence issues like you argue SVAE does? Or do you simply mean that computation of this is exact using regular message passing/Kalman filter/forward-backward?\n- It was not clear to me why we should use a Gaussian approximation for the \\theta_NN parameters? The prior might be Gaussian but the posterior is not? Is this more of a simplifying assumption?\n- There has recently been interest in using inference networks as part of more flexible variational approximations for structured models. Some examples of related work missing in this area is ""Variational Sequential Monte Carlo"" by Naesseth et al. (2017) / ""Filtering Variational Objectives"" by Maddison et al. (2017) / ""Auto-encoding sequential Monte Carlo"" Le et al. (2017).\n-  Section 2.1, paragraph nr 5, ""algorihtm"" -> ""algorithm""\n', 'The paper seems to be significant since it integrates PGM inference with deep models. Specifically, the idea is to use the structure of the PGM to perform efficient inference. A variational message passing approach is developed which performs natural-gradient updates for the PGM part and stochastic gradient updates for the deep model part. Performance comparison is performed with an existing approach that does not utilize the PGM structure for inference.\nThe paper does a good job of explaining the challenges of inference, and provides a systematic approach to integrating PGMs with deep model updates. As compared to the existing approach where the PGM parameters must converge before updating the DNN parameters, the proposed architecture does not require this, due to the re-parameterization which is an important contribution.\n\nThe motivation of the paper, and the description of its contribution as compared to existing methods can be improved. One of the main aspects it seems is generality, but the encodings are specific to 2 types PGMs. Can this be generalized to arbitrary PGM structures? How about cases when computing Z is intractable? Could the proposed approach be adapted to such cases. I was not very sure as to why the proposed method is more general than existing approaches.\n\nRegarding the experiments, as mentioned in the paper the evaluation is performed on two fairly small scale datasets. the approach shows that the proposed methods converge faster than existing methods. However, I think there is value in the approach, and the connection between variational methods with DNNs is interesting.']","[-30, 20, 50]","[50, 60, 75]","[""The sentiment score is -30 because while the reviewer acknowledges some interesting ideas, they express significant concerns about the novelty, clarity, and thoroughness of the paper. The reviewer states that 'in its current form I do not think that the novelty of the contributions are clearly presented and that they are not thoroughly evaluated in the experiments.' This indicates a generally negative sentiment, though not extremely so.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think' and 'Another concern that I have' to soften their criticisms. The reviewer also acknowledges positive aspects, such as 'clever solution' and 'interesting ideas,' before presenting their concerns. However, the score is not higher because the review is direct in its criticisms without excessive softening language.\n\nThe reasoning for these scores is based on the overall tone and content of the review. The reviewer presents a balanced view, acknowledging positives but focusing more on areas for improvement. The language used is consistently professional and constructive, even when pointing out flaws, which contributes to the positive politeness score despite the overall negative sentiment."", 'The sentiment score is slightly positive (20) because the reviewer acknowledges that the idea seems promising and the authors show improved convergence in experiments. However, they also express some uncertainty about the approach. The politeness score is moderately high (60) as the reviewer uses respectful language, asks questions for clarification rather than making accusations, and offers constructive feedback. They also point out a typo politely. The tone is professional and collaborative throughout, without any harsh criticism or rude remarks.', ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the significance of the paper and its contributions, praising its systematic approach and explanation of challenges. However, they also point out areas for improvement, such as motivation and generalizability, which prevents a higher score. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offering constructive criticism and balancing positive aspects with suggestions for improvement. They use phrases like 'The paper does a good job' and 'I think there is value in the approach,' which contribute to a polite tone while still providing honest feedback.""]"
"['Summary: The authors provide another type of GAN--the Sobolev GAN--which is the typical setup of a GAN but using a function class F for which f belongs to F iff \\grad f belongs to L^2(mu). They relate this MMD to the Cramer and Fisher distance and then produce a recipe for training GANs with this sort of function class. In their empirical examples, they show it has similar performance to the WGAN-GP.\n\nOverall, the paper has some interesting mathematical relationships to other MMDs. However, I finished reading the paper wondering why one would want to trust this GAN over any of the other GANs. I may have missed it, but I didn\'t see any compelling theoretical reason the gradients from this method would prove superior to many of the other GANs in existence today. The authors argue ""from [equation 5] we see that we are comparing CDFs, which are better behaved on discrete distributions,"" but I wasn\'t sure what exactly to make of this comment.\n\nNits:\n* The ""Stein metric"" is actually called the Stein discrepancy [see Gorham & Mackey (2015) Measuring Sample Quality using Stein\'s Method].', 'This paper designs a new IPM(Integral Probability Metric) that uses the gradient properties of the test function. The advantage of Sobolev IPM over the Fisher IPM is illustrated by the insight given in Section 4.2. This is convincing. For comparing the true distribution and the generated distribution, it is much better to provide a quantitative measurement, rather than a 0-1 dichotomy. This target is implicitly achieved by the reproducing kernel methods and the original phi-divergence.\n\nOn the other side, the paper is hard to follow, and it contains many long sentences, some 4-5 lines. The formulation of the Sobolev norm could be improved at the top of page 6.', 'The paper deals with the increasingly popular GAN approach to constructing generative models.  Following the first formulation of GANs in 2014, it was soon realized that the training dynamics was highly unstable, leading to significant difficulties in achieving stable results. The paper by Arjovsky et al (2017) provided a framework based on the Wasserstein distance, a distance measure between probability distributions belonging to the class of so-called Integral Probability Metrics (IPMs). This approach solved the stability issues of GANs and demonstrated improved empirical results. Several other works were then developed to deal with these stability issues, specifically the Fisher IPM. Both these methods relied on discriminating between distributions P and Q based on computing a function f, belonging to an appropriate function class {\\cal F}, that maximizes the deviation E_{x~P}f(x)-E_{x~Q}f(x). The main issue relates to the choice of the class {\\cal F}. For the Wasserstein distance this was the class of L_1 Lipschitz functions, while for the Fisher distance it was the class of square integrable functions. The present paper introduces a new notion of distance, where {\\cal F} is the defined through the Sobolev norm, based on the L_2 norm of the gradient of f(x), with respect to a measure \\mu(x), where the latter can be freely chosen under certain assumptions. \n\nThe authors prove a theorem related to the properties of the Sobolev norm, and express it in terms of the component-wise conditional distributions. Moreover, they show that the optimal critic f is obtained by solving a PDE subject to zero boundary conditions. They then use their suggested metric in order to develop a GAN algorithm, and present experimental results demonstrating its utility. The Sobolev IPM has two nice features. First, it is based on the component-wise conditional distribution of the CDFs, and, second, its relation to the Laplacian regularizer from manifold learning. Its 1D version also relates to the well-known von Mises Cramer statistics used in hypothesis testing. \n\nThe paper belongs to a class of recent papers attempting to suggest improvements to the original GAN algorithm, relying on the KL divergence. It is well conceived and articulated, and provides an interesting and potentially powerful new direction to improve GANs in practice. However, it is somewhat difficult to follow the paper, and would urge the authors to improve and augment their presentation of the following issues. \n1)\tOne often poses regularization schemes based on optimality criteria. Is there any optimality principle under which the Sobolev IPM is a desired choice? \n2)\tThe authors argue that their approach is especially well suited for discrete sequential data. This issue was not clear to me, and it would be good if the authors could expand on this issue and provide a clearer explanation. \n3)\tHow would the Sobolev norm behave under a change of coordinates or a homeomorphism of the space? Would it make sense to require some invariance in this respect? \n4)\tThe Lagrangian in eq. (9) contains both a Lagrange constraint on the Sobolev norm and a penalty term. Why are both needed? Why do the updates of  \\lambda and p in Algorithm 1 used different schemes (SGD and ADAM, respectively). \n5)\tTable 2, p. 13 – it would be nice to see a comparison to the recently introduced gradient penalty approach, Gulrajani et al., Improved training of wasserstein gans. arXiv preprint arXiv:1704.00028, 2017.\n6)\tThe integral defining F_p(x) on p. 3 has x as an argument on the LHS and as an integrand of the RHS. Please correct this. Also specify that x=(x_1,\\ldots,x_d).\n', 'The paper proposes a different gradient penalty for GAN critics.\nThe proposed penalty is forcing the expected squared norm of the gradient to be equal to 1.\nThe corresponding integral probability metric is well analysed.\n\nPros:\n- The paper provides a nice overview of WGAN-GP, Fisher GAN and Sobolev GAN.\nThe differences and similarities and mentioned.\n- The paper shows that Sobolev IPM is comparing coordinate-wise conditional CDFs.\n- The 1D example in Section 4.2 shows a limitation of Fisher GAN.\n\nCons:\n- The introduced gradient penalty is harder to optimize.\nAlgorithm 1 is using a biased estimate of the penalty.\nIf having independent samples in the minibatch,\nit would be possible to construct an unbiased estimate of the penalty.\n- An unbiased estimate of the gradient penalty\nwill be hard to construct when not having two independent real samples.\nE.g., when doing conditional modeling with a RNN.\n- The algorithm requires to train the critic well\nbefore using the critic.\nThe paper does not provide an improvement over WGAN-GP in this direction.\nMMD GAN and Cramer GAN may require less critic training steps.\n- The experimental results do not demonstrate an improvement over WGAN-GP.\n- Too much credit is given to implicit conditioning.\nThe Jensen Shanon divergence can be also written as a chain\nof coordinate-wise JS divergences. That does not guarantee non-zero gradients\nfrom the critic. A critic with non-zero gradients seems to be more important.\n\n\nMinor typos:\ns/pernalty/penalty/\ns/ccordinate/coordinate/']","[-20, 50, 60, 20]","[50, 20, 70, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting mathematical relationships in the paper, they express skepticism about the practical value of the proposed method. The reviewer states they are unsure why one would trust this GAN over others and mentions a lack of compelling theoretical reasons for its superiority. However, it's not entirely negative as they do recognize some positive aspects.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I may have missed it' and 'I wasn't sure what exactly to make of this comment,' which show a willingness to consider that they might have misunderstood something rather than outright criticizing. The use of 'Nits' to introduce minor criticisms is also a polite way to present feedback. The language is constructive and avoids harsh or personal criticism."", ""The sentiment score is 50 (moderately positive) because the reviewer starts by highlighting the paper's strengths, such as the design of a new IPM and the convincing illustration of its advantages. However, the reviewer also points out some significant weaknesses, like the paper being hard to follow and containing long sentences, which balances out the positive aspects. The politeness score is 20 (slightly polite) because while the reviewer uses neutral language and offers constructive criticism, there's no overtly polite phrasing. The critique is direct but not rude, maintaining a professional tone throughout."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as 'well conceived and articulated' and providing 'an interesting and potentially powerful new direction'. They acknowledge the paper's contribution to the field and its potential impact. However, it's not extremely positive as the reviewer also points out areas for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, such as 'would urge the authors to improve' instead of demanding changes. They also phrase their criticisms as suggestions or questions rather than direct criticisms. The reviewer maintains a professional and courteous tone while providing constructive feedback."", ""The sentiment score is slightly positive (20) because the review begins by acknowledging the paper's contribution and lists several pros, including a nice overview and interesting findings. However, it also presents several cons that balance out the positives. The politeness score is moderately positive (50) as the reviewer uses neutral language throughout, presents both pros and cons objectively, and offers constructive criticism without harsh language. The reviewer also politely points out minor typos at the end. The overall tone is professional and respectful, while still providing honest feedback.""]"
"['This paper aims to learn hierarchical policies by using a recursive policy structure regulated by a stochastic temporal grammar. The experiments show that the method is better than a flat policy for learning a simple set of block-related skills in minecraft (find, get, put, stack) and generalizes better to a modification of the environment (size of room). The sequence of subtasks generated by the policy are interpretable.\n\nStrengths:\n- The grammar and policies are trained using a sparse reward upon task completion. \n- The method is well ablated; Figures 4 and 5 answered most questions I had while reading.\n- Theoretically, the method makes few assumptions about the environment and the relationships between tasks.\n- The interpretability of the final behaviors is a good result. \n\nWeaknesses:\n- The implementation gives the agent a -0.5 reward if it generates a currently unexecutable goal g’. Providing this reward requires knowing the full state of the world. If this hack is required, then this method would not be useful in a real world setting, defeating the purpose of the sparse reward mentioned above. I would really like to see how the method performs without this hack. \n- There are no comparisons to other multitask or hierarchical methods. Progressive Networks or Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning seem like natural comparisons.\n- A video to show what the environments and tasks look like during execution would be helpful.\n- The performances of the different ablations are rather close. Please a standard deviation over multiple training runs. Also, why does figure 4.b not include a flat policy?\n- The stages are ordered in a semantically meaningful order (find is the first stage), but the authors claim that the order is arbitrary. If this claim is going to be included in the paper, it needs to be proven (results shown for random orderings) because right now I do not believe it. \n\nQuality:\nThe method does provide hierarchical and interpretable policies for executing instructions, this is a meaningful direction to work on.\n\nClarity:\nAlthough the method is complicated, the paper was understandable.\n\nOriginality and significance:\nAlthough the method is interesting, I am worried that the environment has been too tailored for the method, and that it would fail in realistic scenarios. The results would be more significant if the tasks had an additional degree of complexity, e.g. “put blue block next to the green block” “get the blue block in room 2”. Then the sequences of subtasks would be a bit less linear (e.g., first need to find blue, then get, then find green, then put). At the moment the tasks are barely more than the actions provided in the environment.\n\nAnother impedance to the paper’s significance is the number of hacks to make the method work (ordering of stages, alternating policy optimization, first training each stage on only tasks of previous stage). Because the method is only evaluated on one simple environment, it unclear which hacks are for the method generally, and which hacks are for the method to work on the environment.', ""This paper introduces an iterative method to build hierarchical policies. At every iteration, a new meta policy feeds in task id to the previous policy and mixes the results with an 'augmented' policy. The resulting policy is somewhat interpretable as the task id being sampled by the meta policy corresponds to one of the subgoals that are manually designed.\n\nOne of the limitation of the method is that appropriate subgoals and curriculum must be hand designed. Another one is that the model complexity grows linearly with the number of meta iterations. \n\nThe comparison to non-hierarchical models is not totally fair in my opinion. According to the experiment, the flat policy performs much worse than the hierarchical, but it is unclear how much of this is due to the extra capacity of the model of the unfolded hierarchical policy and how much of that is due to the hierarchy. In other words, it is unclear if hierarchy is actually useful, or just the task curriculum and model capacity staging.\n\nThe paper does not appear to be  fully self contained in term of notations, in particular regarding the importance sampling I could not find the definitions of mu, and regarding the STG I could not find the definition of q and rho. \n\nThe experimental results are a bit confusing. In the learning curves that are shown, it is not clear exactly when the set of task is expanded, nor when the hierarchical policy iteration occurs. Also, some curves are lacking the flat baseline."", 'Summary:\nThis paper proposes an approach to learning hierarchical policies in a lifelong learning context. This is achieved by stacking policies - an explicit ""switch"" policy is then used to decide whether to execute a primitive action or call the policy of the layer below it. Additionally, each task is encoded in a human-readable template, which provides interpretability.\nReview:\nOverall, I found the paper to be generally well-written and the core idea to be interesting. My main concern is about the performance against existing methods (no empirical results are provided), and while it does provide interpretability, I am not sure that other approaches (e.g. Tessler et al. 2017) could not be slightly modified to do the same. I think the paper could also benefit from at least one more experiment in a different, harder domain.\n\nI have a few questions and comments about the paper:\n\nThe first paragraph claims ""This precludes transfer of previously learned simple skills to a new policy defined over a space with differing states or actions"". I do not see how this approach avoids suffering from the same problem? Additionally, approaches such as agent-space options [Konidaris and Barto. Building Portable Options: Skill Transfer in Reinforcement Learning, IJCAI 2007] get around at least the state part.\n\nI do not quite follow what is meant by ""a global policy is assumed to be executable by only using local policies over specific options"". It sounds like this is saying that the inter-option policy can pick only options, and not primitive actions, which is obviously untrue. Can you clarify this sentence?\n\nIn section 3.1, it may be best to mention that the policy accepts both a state and task and outputs an action. This is stated shortly afterwards, but it was confusing because section 3.1 says that there is a single policy for a set of tasks, and so obviously a normal state-action policy would not work here.\n\nAt the bottom of page 6, are there any drawbacks to the instruction policy being defined as two independent distributions? What if not all skills are applicable to all items?\n\nIn section 5, what does the ""without grammar"" agent entail? How is the sampling from the switch and instruction policies done in this case?\n\nWhile the results in Figures 4 and 5 show improvement over a flat policy, as well as the value of using the grammar, I am *very* surprised there is no comparison to existing methods. For example, Tessler\'s H-DRLN seems like one obvious comparison here, since it learns when to execute a primitive action and when to reuse a skill.\n\nThere were also some typos/small issues (I may have missed some):\n\npg 3: ""In addition, previous work usually useS...""\npg 3. ""we encode a human instruction to LEARN A..."" (?)\npg 4. ""...with A stochastic temporal grammar...""\npg 4. ""... described above through A/THE modified...""\npg 6. ""...TOTALLING six colors...""\nThere are some issues with the references (capital letters missing e.g. Minecraft)\n\nIt also would be preferable if the figures could appear after they are referenced in the text, since it is quite confusing otherwise. For example, Figure 2 contains V(s,g), but that is only defined much later on. Also, I struggled to make out the yellow box in Figure 2, and the positioning of Figure 3 on the side is not ideal either.']","[-20, -20, 20]","[60, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they also point out several significant weaknesses and express concerns about the method's applicability in realistic scenarios. The review begins with a neutral summary and lists both strengths and weaknesses, but the weaknesses seem to outweigh the strengths in importance and number. The reviewer's concerns about the method's reliance on 'hacks' and its limited evaluation further contribute to the negative sentiment.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to describe the paper's content and provide constructive criticism. The reviewer acknowledges the paper's strengths before discussing its weaknesses, which is a polite approach. They also use phrases like 'I would really like to see' and 'Please' when making suggestions, which adds to the politeness. The reviewer avoids harsh or dismissive language, even when expressing concerns about the paper's significance."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution, they point out several limitations and criticisms. The reviewer mentions issues with the comparison to non-hierarchical models, lack of clarity in notations, and confusing experimental results. However, the tone is not entirely negative, as they also describe the paper's method and some potential benefits.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'in my opinion' and 'it is unclear' rather than making harsh or absolute statements. The criticism is presented constructively, focusing on the content rather than attacking the authors. The language is neutral to slightly formal, avoiding any rude or overly casual expressions."", ""The sentiment score is slightly positive (20) because the reviewer states the paper is 'generally well-written and the core idea to be interesting', but expresses concerns about performance comparisons and the need for more experiments. The overall tone is constructive rather than overtly critical. The politeness score is moderately high (60) as the reviewer uses polite language throughout, framing criticisms as questions or suggestions rather than direct criticisms (e.g. 'I think the paper could benefit from...'). The reviewer also acknowledges positive aspects before raising concerns. The language is professional and respectful, avoiding harsh or rude phrasing.""]"
"['The main contribution of this paper are:\n(a) a proposed extension to continuous stack model to allow multiple pop operation,\n(b) on a language model task, they demonstrate that their model gives better perplexity than comparable LSTM and attention model, and \n(c) on a syntactic task (non-local subject-verb agreement), again, they demonstrate better performance than comparable LSTM and attention model.\n\nAdditionally, the paper provides a nice introduction to the topic and casts the current models into three categories -- the sequential memory access, the random memory access and the stack memory access models. \n\nTheir analysis in section (3.4) using the Venn diagram and illustrative figures in (3), (4) and (5) provide useful insight into the performance of the model.', 'The authors propose to compare three different memory architecture for recurrent neural network language models:\nvanilla LSTM, random access based on attention and continuous stack. The second main contribution of the paper is to propose an extension of continuous stacks, which allows to perform multiple pop operations at a single time step.\nThe way to do that is to use a similar mechanism as the adaptive computation time from Graves (2016): all the pop operations are performed, and the final state of the continuous stack is weighted average of all the intermediate states. The different memory models are evaluated on two standard language modeling tasks: PTB and WikiText-2, as well as on the verb number prediction dataset from Linzen et al (2016). On the language modeling tasks, the stack model performs slightly better than the attention models (0-2 ppl points) which performs slightly better than the plain LSTM (2-3 ppl). On the verb number prediction tasks, the stack model tends to outperforms the two other models (which get similar results) for hard examples (2 or more attractors).\n\nOverall, I enjoy reading this paper: it is clearly written, and contains interesting analysis of different memory architecture for recurrent neural networks. As far as I know, it is the first thorough comparison of the different memory architecture for recurrent neural network applied to language modeling. The experiments on the Linzen et al. (2016) dataset is also interesting, as it shows that for hard examples, the different models do have different behavior (even when the difference are not noticeable on the whole test set).\n\nOne small negative aspect of the paper is that the substance might be a bit limited. The only technical contribution is to merge the ideas from the continuous stack with the adaptive computation time to obtain the ""multi-pop"" model. In the experimental section, which I believe is the main contribution of the paper, I would have liked to see more ""in-depth"" analysis of the different models. I found the experiments performed on the Linzen et al. (2016) dataset (Table 2) to be quite interesting, and would have liked more analysis like that. On the other hand, I found Figures 2 or 3 not very informative, as it is (would like to see more). For example, from Fig. 2, it would be interesting to get a better understanding of what errors are made by the different models (instead of just the distribution).\n\nFinally, I have a few questions for the authors:\n- In Figure 1. shouldn\'t there be an arrow from h_{t-1} to m_t instead of x_{t-1} to m_t?\n- What are the equations to update the stack? I assume something similar to Joulin & Mikolov (2015)?\n- Do you have any ideas why there is a sharp jump between 4 and 5 attractors (Table 2)?\n- Why no ""pop"" operations in Figure 3 and 4?\n\npros/cons:\n+ clear and easy to read\n+ interesting analysis\n- not very original\n\nOverall, while not groundbreaking, this is a serious paper with interesting analysis. Hence, I am weakly recommending to accept this paper.', ""The authors propose a new stack augmented recurrent neural network, which supports continuous push, stay and a variable number of pop operations at each time step. They thoroughly compare several typical neural language models (LSTM, LSTM+attention mechanism, etc.), and demonstrate the power of the stack baed recurrent neural network language model in the similar parameter scale with other models, and especially show the superiority when the long-range dependencies are more complex in NLP area.\n\nHowever the corpora they choose to test the ideas, are PTB and Wikitext-2, they're quite small, so the variance of the estimate is high, similar conclusions might not be valid on large corpora such as 1B token benchmark corpus. \n\nTable 1 only gives results with the same level of parameters, the ppls are worse than some other models. Another angle might be the proposed model use the similar size of hidden layer 1500 plus the stack, and see how much ppl reductions it could get.\n\nFinally the authors should do some experiments on machine translation or speech recognition and see whether the model could get performance improvement.\n\n\n""]","[80, 60, 50]","[50, 80, 75]","[""The sentiment score is 80 (positive) because the review highlights multiple positive aspects of the paper, including its main contributions, better performance on tasks, and useful insights provided. There are no negative comments or criticisms mentioned. The politeness score is 50 (slightly polite) because the language used is professional and respectful, with phrases like 'nice introduction' and 'useful insight'. However, it doesn't contain overtly polite language or personal compliments, maintaining a neutral, academic tone overall."", ""The sentiment score is 60 (positive) because the reviewer expresses enjoyment in reading the paper, praises its clarity, and finds the analysis interesting. They recommend acceptance, albeit weakly. The score is not higher due to some criticisms about limited substance and desire for more in-depth analysis. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'I enjoy reading this paper' and 'interesting analysis', and offer suggestions for improvement rather than harsh criticism. The reviewer also poses questions to the authors in a courteous manner."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by praising the authors' work, highlighting the thorough comparison and demonstration of the model's power. However, they also point out limitations and suggest additional experiments, balancing the positive aspects with constructive criticism. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and framing suggestions as recommendations rather than demands. They use phrases like 'the authors should' instead of more forceful language, maintaining a professional and courteous tone.""]"
"['I think this paper presents an interesting take on feature pooling. In particular, the idea is to look at pooling as some form of a lossy process, and try to find such a process such that it discards less information given some decimation criterion. Once formulating the problem like this, it becomes obvious that wavelets are a very good candidate.\n\nPros:\n- The nice thing about this method is that average pooling is in some sense a special case of this method, so we can see a clear connection.\n- Lots of experiments, and results, which show the method both performing the best in some cases, and not the best in others. I applaud the authors for publishing all the experiments they ran because some may have been tempted to ""forget"" about the experiments in which the proposed method did not perform the best.\n\nCons:\n- No comparison to non-wavelet methods. For example, one obvious comparison would have been to look at using a DCT or FFT transform where the output would discard high frequency components (this can get very close to the wavelet idea!).\n- This method has the potential to show its potential on larger pooling windows than 2x2. I would have loved to see some experiments that prove/disprove this.\n\nOther comments:\n- Given that this method\'s flexibility, I could imagine this generate a new class of pooling methods based on lossy transforms. For example, given a MxNxK input, the wavelet idea can be made to output (M/D)x(N/D)x(K/D) (where D is decimation factor). Of interest is the fact that channels can be treated just like any other dimension, since information will be preserved!\n\nFinal comments:\n- I like the idea and it seems novel it may lead to some promising research directions related to lossy pooling methods/channel aggregation. As such, I think it will be a nice addition to ICLR, especially if the authors decide to run some of the experiments I was suggesting, namely: show what happens when larger pooling windows are used (say 4x4 instead of 2x2), and compare to other lossy techniques (such as Fourier or cosine-transforms).', 'The paper proposes ""wavelet pooling"" as an alternative for traditional subsampling methods, e.g. max/average/global pooling, etc., within convolutional neural networks. \nExperiments on the MNIST, CIFAR-10, SHVN and KDEF datasets, shows the proposed wavelet-based method has\ncompetitive performance with existing methods while still being able to address the overfitting behavior of max pooling.\n\nStrong points\n- The method is sound and well motivated.\n- The proposes method achieves competitive performance.\n\nWeak points\n- No information about added computational costs is given.\n- Experiments are conducted in relatively low-scale datasets.\n\n\nOverall the method is well presented and properly motivated. The paper as a good flow and is easy to follow. The authors effectively demonstrate with few toy examples the weaknesses of traditional methods, i.e max pooling and average pooling. Moreover, their extended evaluation on several datasets show the performance of the proposed method in different scenarios.\n\nMy main concerns with the manuscript are the following.\n\nCompared to traditional methods, the proposed methods seems to require higher computation costs. In a deep neural network setting where operations are conducted a large number of times, this is a of importance. However, no indication is given on what are the added computation costs of the proposed method and how that compares to existing methods. A comparison on that regard would strengthen the paper.\n\nIn many of the experiments, the manuscript stresses the overfitting behavior of max pooling. This makes me wonder whether this is caused by the fact that experiments are conducted or relatively smaller datasets. While the currently tested datasets are a good indication of the performance of the proposed method, an evaluation on a large scale scenario, e.g. ILSVRC\'12, could solidify the message sent by this manuscript. Moreover, it would increase the relevance of this work in the computer vision community.\n\nFinally, related to the presentation, I would recommend presenting the plots, i.e. Fig. 8,10,12,14, for the training and validation image subsets in two separate plots. Currently, results for training and validation sets are mixed in the same plot, and due to the clutter it is not possible to see the trends clearly.\nSimilarly, I would recommend referring to the Tables added in the paper when discussing the performance of the proposed method w.r.t. traditional alternatives.\n\nI encourage the authors to address my concerns in their rebuttal', ""The paper proposes to use discrete wavelet transforms combined with downsampling to achieve arguably better pooling output compared to average pooling or max pooling. The idea is tested on small-scale datasets such as MNIST and CIFAR.\n\nOverall, a major issue of the paper is the linear nature of DWT. Unless I misunderstood the paper, linear DWT is being adopted in the paper, and combined with the downsampling and iDWT stage, the transform is linear with respect to the input: DWT and iDWT are by definition linear, and the downsampling can be viewed as multiplying by 0. As a result, if my understanding is correct, this explains why the wavelet pooling is almost the same as average pooling in the experiments (other than MNIST). See figures 10, 12 and 14.\n\nThe rest of the paper reads reasonable, but I am not sure if they offset the issue above.\n\nOther minor comments:\n\n- I am not sure if the issue in Figure 2 applies in general to image classification issues. It surely is a mathematical adversarial to the max pooling principle, but note that this only applies to the first input layer, as such behavior in later layers could be offset by switching the sign bits of the previous layer's filter.\n\n- The experiments are largely conducted with very small scale datasets. As a result I am not sure if they are representative enough to show the performance difference between different pooling methods.""]","[60, 60, -50]","[80, 80, 50]","[""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, praising its 'interesting take' and 'nice' aspects. They also applaud the authors for their comprehensive experiments. However, it's not extremely positive as they point out some cons and suggest additional experiments. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They use phrases like 'I applaud the authors' and 'I like the idea,' which are particularly polite. The reviewer also balances positive and negative feedback in a professional manner, without using any harsh or rude language."", ""The sentiment score is 60 (positive) because the reviewer begins by highlighting the paper's strong points and states that 'Overall the method is well presented and properly motivated.' They also mention that the paper has 'good flow and is easy to follow.' While the reviewer does raise some concerns, these are presented as constructive feedback rather than major criticisms. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their concerns as suggestions for improvement rather than harsh criticisms. Phrases like 'I encourage the authors to address my concerns' and 'I would recommend' demonstrate a polite and constructive tone. The reviewer also provides specific, actionable feedback, which is a courteous approach in academic peer review."", ""The sentiment score is -50 because the reviewer expresses a major concern about the paper's approach, stating that the linear nature of DWT is a 'major issue.' They also question the representativeness of the small-scale datasets used. However, the reviewer does acknowledge some positive aspects, noting that 'The rest of the paper reads reasonable.' This mix of significant criticism with some positive elements results in a moderately negative sentiment score. The politeness score is 50 because the reviewer uses professional and respectful language throughout. They present their concerns objectively, using phrases like 'Unless I misunderstood' and 'I am not sure if,' which show consideration for the authors' perspective. The reviewer also offers constructive feedback and specific points for improvement, which is a polite approach in academic review.""]"
"['The authors try to bring in two seemingly different areas and try\nto leverage the results in one for another.\nFirst authors show that the equivalence of the function realized(in\ntensor form, given in earlier work) by a ConvAC and\nthe function used to model n-body quantum system. After establishing\nthe equivalence of two, the authors argue that\nquantum entanglement measures used to measure correlations in n-body\nquantum systems can be used as an expressive measure\n(how much correlation in input they can handle) of the function\nrealized by a ConvAC. Separation Rank analysis, which was done\nearlier, becomes a special case. As the functional equivalence is\nestablished, authors adopt Tensor Network framework,\nto analyze the properties of the ConvAC. The main result being able\nto quantify the expressiveness to some extend to the min\ncut of the underlying Tensor Network graph corresponding to ConvAC.\nThis is further used to argue about guide-lining the\nwidth of various parts of ConvAC, if some prior correlation\nstructure is known about the input. This is also validated\nexperimentally.\n\nAlthough I do not see major results at this moment, this work can be\nof great significance. The attempt to bring in two areas\nhave to be appreciated. This work opens up a footing to do graph\ntheoretical analysis of deep learning architectures and from\nthe perspective of Quantum entanglement, this could lead to open up new directions. \nThe paper is lucidly written, comprehensively covering the\npreliminaries. I thoroughly enjoyed reading it, and I think the\npaper and the work would be of great contribution to the community.\n\n(There are some typos  (preform --> perform ))', 'This paper draws an interesting connection between deep neural networks and theories of quantum entanglement. They leveraged the tool for analyzing quantum entanglement to deep neural networks, and proposed a graph theoretical analysis for neural networks. They demonstrated how their theory can help designing neural network architectures on the MNIST dataset.\n\nI think the theoretical findings are novel and may contribute to the important problem on understanding neural networks theoretically. I am not familiar with the theory for quantum entanglement though.', 'The paper makes a striking connection between two apparently unrelated problems: the problem of designing neural networks to handle a certain type of correlation and the problem of designing a structure to represent wave-function with quantum entanglement. In the wave-function context, the Schmidt decomposition of the wave function is an inner product of tensors. Thus, the mathematical glue connecting the neural networks and quantum entanglement is shown to be tensor networks, which can represent higher order tensors through inner product of lower-order tensors. \n\nThe main technical contribution in the paper is to map convolutional networks with product pooling function (called ConvACs) to a tensor network. Given this mapping, the authors exploit results in tensor networks (in particular the quantum max-flow min-cut theorem) to calculate the rank of the matricized tensor between a pair of vertex sets using the (appropriately defined) min-cut. \n\nThe connection has potential to yield fruitful new results, however, the potential is not manifested (yet) in the paper. The main application in deep convolutional networks proposed by the paper is to model how much correlation between certain partition of input variables can be captured by a given convolutional network design. However, it is unclear how to use Theorem 1 to design neural networks that capture a certain correlation. \n\nA simple example is given in the experiment where the wider layers can be either early in the the neural network or at the later stages; demonstrating that one does better than the other in a certain regime. It seems that there is an obvious intuition that explains this phenomenon: wider base networks with large filters are better suited to the global task and narrow base networks that have more parameters later down have more local early filters suited to the local task. The experiments do not quite reveal the power of the proposed approach, and it is unclear how, if at all, the proposed approach can be applied to more complicated networks. \n\nIn summary, this paper is of high theoretical interest and has potential for future applications.', 'The paper proposes a structural equivalence between the function realised by a convolutional arithmetic circuit (ConvAC) and a quantum many-body wave function, which facilitates the use of quantum entanglement measures as quantifiers of a deep network’s expressive ability to model correlations. \n\nThe work is definitely worthwhile digging deeper, bridging some gap and discussions between physics and deep learning. The ultimate goal for this work, if I understands correctly, is a provide a theoretical explanation to the design of deep neural architectures. The paper is well-written (above most submissions, top 10%) with clear clarity. However, removing all the fancy stuff and looking into the picture further, I have several major concerns.\n\n+ Potential good research direction to connect physical sciences (via TN) to deep learning theories (via ConvAC).\n\n- [Novelty is limited and proof is vague] The paper uses physical concepts to establish a ""LAYER WIDTHS EFFECT ON THE EXPRESSIVENESS OF A DEEP NETWORK"", the core theory (proposed method) part is Section 5 alone and the rest (Section 2,3,4) is for introductory purposes. Putting Theorem 1 in simple, deep learning based English, it says for a dataset with features of a size D, there exists a partition of length scale \\epsilon \x18< D, which is guaranteed to separate between different parts of a feature. Based on this, they give a rule of thumb to design the width (i.e., channel numbers) of layers in a deep neural network: (a) layer l = logD is more important than those of deeper layers; (b) among these deeper layers, deeper ones need to be wider, which is derived from the min-cut in the ConvAC TN case. How (a) is derived or implied from theorem 1? \n\nIt seems to me that the paper goes with a rigorous manner till the proof of theorem 1, with all the concepts and denotations well demonstrated. Suddenly when it comes to connecting the practical design of deep networks, the conclusion becomes qualitative without much explanation via figures or visualisation of the learned features to prove the effectiveness of the proposed scheme.\n\n- [Experiments are super weak] The paper has a good motivation and a beautiful story and yet, the experiments are poor to verify them. The reason as to why authors use ConvAC is that it more resembles the tensor operations introduced in the paper. There is a sentence, ""Importantly, through the concept of generalized tensor decompositions, a ConvAC can be transformed to a standard convolutional network with ReLU activation and average/max pooling"", to tell the relation between ConvAC and traditional convolutions. The theory is based on the analysis of ConvAC, and all of a sudden the experiments are conducted on the traditional convolution. This is not rigorous and not professional for a ""technically-sound"" paper. How the generalized concepts of tensor decompositions can be applied from ConvAC to vanilla convolutions?\n\nThe experiments seem to extend the channel width of *all* layers in a hand-crafted manner (10, 4r, 4r, xxx). Based on the derived rule of thumb, the most important layer in MNIST should be layer 3 or 4 (log 10). Some simple ablative analysis should be:\n(i) baseline: fix layer 3, add more layers thereafter in the network;\n(ii) fix layer 3, reduce the channel numbers after layer 3.\nThe (ii) case should be at least comparable to (i) if theorem 1 is correct.\n\nMoreover, to verify conclusion (b) which I mentioned earlier, does the current setting (10, 4r, 4r, xx) consider ""deeper ones need to be wider""? What is the value of r? MNIST is a over-used dataset and quite small. I see the performance in Figure 4 (the only experiment result in the paper) just exceeds 90%. A simple trained NN (not CNN) could reach well 96% or so.\n\nMore ablative study (convAC or vanilla conv, other datasets, comparison components in width design, etc.) are seriously needed. Otherwise, it is just not convincing to me.\n\nIf the authors target on the network design in a more general manner (not just in layer width, but the design of number of filters, layers, etc.), there are already some neat work in this community and you should definitely compare them: e.g., Neural Architecture Search with Reinforcement Learning, ICLR 2017. I know the paper starts with building the connection from physics to deep learning and it is natural to solve the width design issue alone. This is not a major concern.\n\n-------------\nWe see lots of fancy conceptions, trying to bind interdisciplinary subjects to help analyse deep learning theories over the last few years, especially in ICLR 2017. This year same thing happens. I am not degrading the motivation/intuition of the work; instead, I think it is pretty novel to explain the design of neural nets, by way of quantum physics. But the experiments and the conclusion derived from the analysis make the paper not solid to me and I am quite skeptical about its actual effectiveness.\n']","[90, 70, 50, -50]","[80, 50, 75, 50]","[""The sentiment score is 90 (highly positive) because the reviewer expresses strong appreciation for the work, describing it as potentially 'of great significance' and a 'great contribution to the community'. They also mention enjoying reading it and praise its lucid writing. The politeness score is 80 (quite polite) due to the consistently respectful and encouraging tone. The reviewer uses phrases like 'have to be appreciated' and 'thoroughly enjoyed reading it', which are polite and supportive. They also constructively point out a typo without being critical. The language throughout is professional and courteous, avoiding any harsh or negative comments."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'interesting' and notes that the theoretical findings are 'novel' and may contribute to an important problem. They also mention the paper's potential to help in designing neural network architectures. The only slight reservation is the reviewer's unfamiliarity with quantum entanglement theory, which prevents a perfect score. The politeness score is 50 (somewhat polite) because the language is professional and respectful, using phrases like 'I think' to soften opinions. However, it doesn't go out of its way to be overly polite or encouraging, maintaining a neutral, academic tone overall."", ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the paper's 'striking connection' and 'high theoretical interest,' but also points out limitations such as unclear applications and experiments that 'do not quite reveal the power of the proposed approach.' The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's potential and contributions without harsh criticism. The reviewer offers constructive feedback and uses phrases like 'has potential for future applications,' which maintains a positive and encouraging tone."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('well-written', 'worthwhile digging deeper'), they express several major concerns and skepticism about the paper's effectiveness. The overall tone is more negative than positive, with phrases like 'novelty is limited', 'proof is vague', and 'experiments are super weak'. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positives before criticisms, and using phrases like 'if I understand correctly' to soften disagreements. However, some direct criticisms like 'not rigorous and not professional' prevent a higher politeness score. The reviewer maintains a professional tone while providing detailed, constructive feedback.""]"
"['******\nUpdate: revising reviewer score to 6 after acknowledging revisions and improved manuscript\n******\n\nThe authors propose a new regularization term modifying the VAE (Kingma et al 2013) objective to encourage learning disentangling representations.\nSpecifically, the authors suggest to add penalization to ELBO in the form of -KL(q(z)||p(z)) , which encourages a more global criterion than the local ELBOs.\nIn practice, the authors decide that the objective they want to optimize is unwieldy and resort to moment matching of covariances of q(z) and p(z) via gradient descent.\nThe final objective uses a persistent estimate of the covariance matrix of q and upgrades it at each mini-batch to perform learning.\n\nThe authors use this objective function to perform experiments measuring disentanglement and find minor benefits compared to other objectives in quantitative terms.\n\nComments:\n1. The originally proposed modification in Equation (4) appears to be rigorous and as far as I can tell still poses a lower bound to log(p(x)). The proof could use the result posed earlier: KL(q(z)||p(z)) is smaller than E_x KL(q(z|x)||p(z|x)).\n2. The proposed moment matching scheme performing decorrelation resembles approaches for variational PCA and especially independent component analysis. The relationship to these techniques is not discussed adequately. In addition, this paper could really benefit from an empirical figure of the marginal statistics of z under the different regularizers in order to establish what type of structure is being imposed here and what it results in.\n3. The resulting regularizer with the decorrelation terms could be studied as a modeling choice. In the probabilistic sense, regularizers can be seen as structural and prior assumptions on variables. As it stands, it is unnecessarily vague which assumptions this extra regularizer is making on variables.\n4. Why is using the objective in Equation (4) not tried and tested and compared to? It could be thought that subsampling would be enough to evaluate this extra KL term without any need for additional variational parameters \\psi. The reason for switching to the moment matching scheme seems not well motivated here without showing explicitly that Eq (4) has problems.\n5. The model seems to be making on minor progress in its stated goal, disentanglement. It would be more convincing to clarify the structural properties of this regularizer in a statistical sense more clearly given that experimentally it seems to only have a minor effect.\n6. Is there a relationship to NICE (Laurent Dinh et al)?\n7. The infogan is also an obvious point of reference and comparison here.\n8. The authors claim that there are no models which can combine GANs with inference in a satisfactory way, which is obviously not accurate nowadays given the progress on literature combining GANs and variational inference.\n\nAll in all I find this paper interesting but would hope that a more careful technical justification and derivation of the model would be presented given that it seems to not be an empirically overwhelming change.', ""This paper describes DIP-VAE, an improvement on the beta-VAE framework for learning a disentangled representation of the data generative factors in the visual domain. The authors propose to augment the standard VAE ELBO objective with an extra term that minimises the covariance between the latents. Unlike the original beta-VAE objective which implicitly minimises such covariance individually for each observation x, the DIP-VAE objective does so while marginalising over x. This difference removes the tradeoff between reconstruction quality and disentangling reported for beta-VAE, since DIP-VAE maintains sensitivity of q(z|x) to each observation x, and hence achieves disentangling while preserving the sharpness of reconstructions.\n\nPros:\n- the paper is well written\n- it makes a contribution to an important line or research (unsupervised disentangled representation learning)\n- the covariance minimisation proposed in the paper looks like an easy to implement yet impactful change to the VAE objective to encourage disentanglement while preserving reconstruction quality\n- it directly compares the performance of DIP-VAE to that of beta-VAE showing significant improvements in terms of disentangling metric and reconstruction error\n\nCons:\n- I am yet to be fully convinced how well the approach works. Table 1 and Figure 1 look good, but other figures are either tangental to the main point of the paper, or impossible to read due to the small scale. For example, the qualitative evaluation of the latent traversals is almost impossible due to the tiny scale of Table 5 (shouldn't this be a Figure rather than a Table?)\n- The authors concentrate a lot on the CelebA dataset, however I believe the comparison with beta-VAE would be a lot clearer on the dSprites dataset (https://github.com/deepmind/dsprites-dataset) (the authors call it 2D shapes). I would like to see latent traversals of the best DIP-VAE vs beta-VAE to demonstrate good disentangling and the improvements in reconstruction quality. This (and larger Table 5) would be better use of space compared to Table 2 and Figure 2 for example, which I feel are somewhat tangental to the main message of the paper and are better suited for the appendix. \n- I wonder how the authors calculated the disentanglement metric on CelebA, given that the ground truth attributes in the dataset are often rather qualitative (e.g. attractiveness), noisy (many can be considered an inaccurate description of the image), and often do not align with the data generative factors discoverable through unsupervised modeling of the data distribution\n- Table 3 - the legends for the axes are too small and are impossible to read. Also it would be helpful to normalise the scales of the heat plots in the second row.\n- Table 3 -  looking at the correlations with the ground truth factors, it seems like beta-VAE did not actually disentangle the latents. Would be nice to see the corresponding latent traversal plots to ensure that the baseline is actually trained well. \n\nI am willing to increase my score for the paper if the authors can address my points. In particular I would like to see a clear comparison in terms of latent traversals on dSprites between beta-VAE and DIP-VAE models presented in Table 3. I would also like to see where these particular models lie in Figure 1.\n\n---------------------------\n---- UPDATE ----------\n---------------------------\nI have increased my score after reading the revised version of the manuscript."", '########## UPDATED AFTER AUTHOR RESPONSE ##########\n\nThanks for the good revision and response that addressed most of my concerns. I am bumping up my score. \n\n###############################################\n\n\nThis paper presents a Disentangled Inferred Prior (DIP-VAE) method for learning disentangled features from unlabeled observations following the VAE framework. The basic idea of DIP-VAE is to enforce the aggregated posterior q(z) = E_x [q(z | x)] to be close to an identity matrix as implied by the commonly chosen standard normal prior p(z). The authors propose to moment-match q(z) given it is hard to minimize the KL-divergence between q(z) and p(z). This leads to one additional term to the regular VAE objective (in two parts, on- and off-diagonal). It has the similar property as beta-VAE (Higgins et al. 2017) but without sacrificing the reconstruction quality. Empirically the authors demonstrate that DIP-VAE can effectively learn disentangled features, perform comparably better than beta-VAE and at the same time retain the reconstruction quality close to regular VAE (beta-VAE with beta = 1). \n\nThe paper is overall well-written with minor issues (listed below). I think the idea of enforcing an aggregated (marginalized) posterior q(z) to be close to the standard normal prior p(z) makes sense, as opposed to enforcing each individual posterior q(z|x) to be close to p(z) as (beta-)VAE objective suggests. I would like to make some connection to some work on understanding VAE objective (Hoffman & Johnson 2016, ELBO surgery: yet another way to carve up the variational evidence lower bound) where they derived something along the same line of an aggregated posterior q(z). In Hoffman & Johnson, it is shown that KL(q(z) | p(z)) is in fact buried in ELBO, and the inequality gap in Eq (3) is basically a mutual information term between z and n (the index of the data point). Similar observations have led to the development of VAMP-prior (Tomczak & Welling 2017, VAE with a VampPrior). Following the derivation in Hoffman & Johnson, DIP-VAE is basically adding a regularization parameter to the KL(q(z) | p(z)) term in standard ELBO. I think this interpretation is complementary to (and in my opinion, more clear than) the one that’s described in the paper. \n\nMy concerns are mostly regarding the empirical studies: \n\n1. One of my main concern is on the empirical results in Table 1. The disentanglement metric score for beta-VAE is suspiciously lower than what’s reported in Higgins et al., where they reported a 99.23% disentanglement metric score on 2D shape dataset. I understand the linear classier is different, but still the difference is too large to ignore. Hence my current more neutral review rating. \n\n2. Regarding the correlational plots (the bottom row of Table 3 and 4), I don’t think I can see any clear patterns (especially on CelebA). I wonder what’s the point of including them here and if there is a point, please explain them clearly in the paper. \n\n3. Figure 2 is also a little confusing to me. If I understand the procedure correctly, a good disentangled feature would imply smaller correlations to other features (i.e., the numbers in Figure 2 should be smaller for better disentangled features). However, looking at Figure 2 and many other plots in the appendix, I don’t think DIP-VAE has a clear win here. Is my understanding correct? If so, what exactly are you trying to convey in Figure 2? \n\nMinor comments: \n\n1. In Eq (6) I think there are typos in terms of the definition of Cov_q(z)(z)? It appears as only the second term in Eq (5). \n\n2. Hyperparameter subsection in section 3: Shouldn’t \\lambda_od be larger if the entanglement is mainly reflected in the off-diagonal entries? Why the opposite? \n\n3. Can you elaborate on how a running estimate of Cov_p(x)(\\mu(x)) is maintained (following Eq (6)). It’s not very clear at the current state of the paper. \n\n4. Can we have error bars in Table 2? Some of the numbers are possibly hitting the error floor. \n\n5. Table 5 and 6 are not very necessary, unless there is a clear point. ']","[20, 50, 20]","[60, 80, 70]","[""The sentiment score is slightly positive (20) because while the reviewer finds the paper 'interesting' and acknowledges some merits, they also express several concerns and suggest the need for significant improvements. The initial update indicates a revised positive score, but the detailed comments are quite critical. The politeness score is moderately positive (60) as the reviewer uses professional and constructive language throughout, offering specific suggestions for improvement rather than harsh criticism. They use phrases like 'could benefit from', 'would hope that', and 'interesting but', which maintain a respectful tone while conveying areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and potential, but also expresses several concerns and requests for improvements. The initial pros indicate a positive view, while the cons and requests for clarification balance this out. The final update suggests an increase in score, indicating an overall positive sentiment.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. The criticisms are framed constructively, offering specific suggestions for improvement rather than harsh judgments. Phrases like 'I am willing to increase my score' and 'I would like to see' indicate a collaborative approach rather than a dismissive one."", ""The sentiment score is 20 (slightly positive) because while the reviewer acknowledges the paper is 'overall well-written' and the idea 'makes sense', they also express several concerns about the empirical studies and results. The reviewer states they are giving a 'more neutral review rating' due to these concerns. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, such as 'Thanks for the good revision', 'I would like to make some connection', and phrases like 'I think' and 'I wonder' when expressing concerns. They also provide constructive feedback and suggestions for improvement rather than harsh criticism. The reviewer maintains a professional and courteous tone while still clearly communicating their concerns and recommendations.""]"
"['The paper proposes to build a graph where the edge weight is defined using the road network distance which is shown to be more realistic than the Euclidean distance. The defined diffusion convolution operation is essentially conducting random walks over the road segment graph. To avoid the expensive matrix operation for the random walk, it empirically shows that K = 3 hops of the random walk can give a good performance. The outputs of the graph convolutionary operation are then fed into the sequence to sequence architecture with the GRU cell to model the temporal dependency. Experiments show that the proposed architecture can achieve good performance compared to classic time series baselines and several simplified variants of the proposed model. \n\nAlthough the paper argues that several existing deep-learning based approaches may not be directly applied in the current setting either due to using Euclidean distance or undirected graph structure, the comparisons are not persuasive. For example, the approach in the paper ""DeepTransport: Learning Spatial-Temporal Dependency for Traffic Condition Forecasting"" also consider directed graph and a diffusion effect from 2 or 3 hops away in the neighboring subgraph of a target road segment. \n\nFurthermore, the paper proposes to use two convolution components in Equation 2, each of which corresponds to out-degree and in-degree direction, respectively. This effectively increase the number of model parameters to learn. Compared to the existing spectral graph convolution approach, it is still not clear how its performance will be by using the same number of parameters. The experiments will be improved if it can compare with ""Spatio-temporal graph convolutional neural network: A deep learning framework for traffic forecasting"" using roughly the same number of parameters.', 'Summary of the reviews:\nPros:\n•\tA Novel Diffusion Convolutional Recurrent Neural Network framework for traffic forecasting\n•\tApply bidirectional random walks with nice theoretical analysis to capture the spatial dependency\n•\tNovel applications of sequence to sequence architecture and the scheduled sampling technique into modeling the temporal dependency in the traffic domain\n•\tThis work is very well written and easy to follow\nCons:\n•\tNeeds some minor re-organization of contents between the main sections and appendix\n\nDetailed comments:\nD1:  Some minor re-organization of contents between the main sections and the appendix will help the reader reduce cross-section references. Some examples:\n1.\tLemma 2.1 can be put into appendix since it is not proposed by this work while the new theoretical analysis of Appendix 5.2 (or at least a summary) can be moved to the main sections\n2.\tFigure 9 can be moved earlier to the main section since it well supports one of the contributions of the proposed method (using the DCRNN to capture the spatial correlation)\nD2: Some discussions regarding the comparison of this work to some state-of-the-arts graph embedding techniques using different deep neural network architectures would be a plus', ""The paper adresses an important task to build a data-driven model traffic forecasting model. The paper takes into consideration the spatio-temporal autocorralation and tackles this with a diffusion process for convolutional recurrent neural networks. The paper lacks a comparison to other models that aim to include spatio-temporal dependencies used for this problem - namely Gaussian Processes, spatial k-NN.\nThe paper motivates the goal to obtain smooth traffic predictions, but traffic is not a smooth process, e.g. traffic lights and intersections cause non smooth effects. therefore it is difficult to follow this argumentation. Statements as 'is usually better at predicting start and end of peak hours' (caption of Figure 6) should be supported by statistical test that stress significance of the statement.\nThe method performs well on the presented data - in comparison to the models that do not consider autocorrelation. This might be because tests were not performed with commonly used traffic models or the traffic data was in favour for this model - it remains unclear, whether the proposed method really contributes better predictions or higher scalibility or faster computation to the mentioned problem. How does the proposed model behave in case of a shift in the traffic distribution? How do sudden changes (accident, road closure, etc.) affect the performance?""]","[-20, 80, -20]","[50, 70, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'can achieve good performance'), they also raise significant concerns and criticisms. The reviewer points out that comparisons are 'not persuasive' and suggests that the experiments could be improved, indicating a somewhat critical stance. The politeness score is moderately positive (50) as the reviewer maintains a professional and objective tone throughout, avoiding harsh language or personal attacks. They use phrases like 'it is still not clear' and 'experiments will be improved if' which suggest constructive criticism rather than outright dismissal. The reviewer also acknowledges the paper's contributions before presenting their concerns, which is a polite approach in academic discourse."", ""The sentiment score is 80 (positive) because the review starts with a list of pros that highlight the novel aspects and strengths of the paper, using phrases like 'well written' and 'easy to follow'. The cons are minimal and described as 'minor'. The detailed comments are constructive suggestions rather than criticisms. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering suggestions for improvement rather than demands. The use of phrases like 'will help the reader' and 'would be a plus' indicate a considerate tone. The review maintains a professional and supportive stance, focusing on the paper's merits while providing helpful feedback for enhancement."", 'The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the task and some positive aspects of the paper, they also point out several significant limitations and areas for improvement. The review begins with positive comments but quickly moves to critiques, suggesting a overall slightly negative sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They offer constructive criticism without using harsh or rude language, maintaining a respectful tone while pointing out areas for improvement. The reviewer presents their concerns as observations and suggestions rather than direct attacks, which contributes to the polite tone.']"
"['ICLR I-Revnet\n\n\nThis paper build on top of ReVNets (Gomez et al., 2017)  and introduce a variant that is fully \ninvertible. The model performs comparable to its variants without any loss of information.\nThey analyze the model and its learned representations from multiple perspectives in detail. \n \nIt is indeed very interesting an thought provoking to see that contrary to popular belief in the community no information loss is necessary to learn good generalizable features. What is missing, is more motivation for why such a property is desirable. As the authors mentions the model size has almost doubled compared to comparable ResNet. And the study of the property of the learned futures might probably limited to this i-RevNet only. It would be good to see more motivation, beside the valuable insight of knowing it’s possible.\n\nGenerally the paper is well written and readable, but few minor comments:\n1-Better formatting such as putting results in model sizes, etc in tables will make them easier to find.\n2-Writing down more in detail 3.1, ideally in algorithm or equation than all in text as makes it hard to read in current format.', 'In this paper, the authors propose deep architecture that preserves mutual information between the input and the hidden representation and show that the loss of information can only occur at the final layer. They illustrate empirically that the loss of information can be avoided on large-scale classification such as ImageNet and propose to build an invertible deep network that is capable of retaining the information of the input signal through all the layers of the network until the last layer where the input could be reconstructed.\n\nThe authors demonstrate that progressive contraction and separation of the information can be obtained while at the same time allowing an exact reconstruction of the signal.\n\nAs it requires a special care to design an invertible architecture, the authors architecture is based on the recent reversible residual network (RevNet) introduced in (Gomez et al., 2017) and an invertible down-sampling operator introduced in (Shi et al., 2016). The inverse (classification) path of the network uses the same convolutions as the forward (reconstructing) one. It also uses subtraction operations instead of additions in the output computation in order to reconstruct intermediate and input layers.\n\nTo show the effectiveness of their approach on large-scale classification problem, the authors report top-1 error rates on the validation set of ILSVRC-2012. The obtained result is competitive with the original Resnet and the RevNet models. However, the proposed approach is expensive in terms of parameter budget as it requires almost 6.5 times more parameters than the RevNet and the Resnet architectures. Still, the classification and the reconstructing results are quite impressive as the work is the first empirical evidence that learning invertible representation that preserves information about the input is possible on large-scale classification tasks. Worth noting that recently, (Shwartz-Ziv and Tishby) demonstrated, not on large-scale datasets but on small ones, that an optimal representation for a classification task must reduce as much uninformative variability as possible while maximizing the mutual information between the desired output and its representation in order discriminate as much as possible between classes. This is called “information bottleneck principle”. The submitted paper shows that this principle is not a necessary condition large-scale classification.\n\nThe proposed approach is potentially of great benefit. It is also simple and easy to understand. The paper is well written and the authors position their work with respect to what has been done before. The spectral analysis of the differential operator in section 4.1 provide another motivation for the “hard-constrained” invertible architecture. Section 4.2 illustrates the ability of the network to reconstruct input signals. The visualization obtained suggests that network performs linear separation between complex learned factors. Section 5 shows that even when using either an SVM or a Nearest Neighbor classifier on n extracted features from a layer in the network, both classifiers progressively improve with deeper layers. When the d first principal components are used to summarize the n extracted features, the SVM and NN classifier performs better when d is bigger. This shows that the deeper the network gets, the more linearly separable and contracted the learned representations are.\n\nIn the conclusion, the authors state the following: “The absence of loss of information is surprising, given the wide believe, that discarding information is essential for learning representations that generalize well to unseen data”. Indeed, the authors have succeed in showing that this is not necessarily the case. However, the loss of information might be necessary to generalize well on unseen data and at the same time minimize the parameter budget for a given classification task.\n', '\n\nThe paper is well written and easy to follow. The main contribution is to propose a variant of the RevNet architecture that has a built in pseudo-inverse, allowing for easy inversion. The results are very surprising in my view: the proposed architecture is nearly invertible and is able to achieve similar performance as highly competitive variants: ResNets and RevNets.\n\nThe main contribution is to use linear and invertible operators (pixel shuffle) for performing downsampling, instead of non-invertible variants like spatial pooling. While the change is small, conceptually is very important.\n\nCould you please comment on the training time? Although this is not the point of the paper, it would be very informative to include learning curves. Maybe discarding information is not essential for learning (which is surprising), but the cost of not doing so is payed in learning time. Stating this trade-off would be informative. If I understand correctly, the training runs for about 150 epochs, which is maybe double of what the baseline ResNet would require?\n\nThe authors evaluate in Section 4.2 the show samples obtained by the pseudo inverse and study the properties of the representations learned by the model. I find this section really interesting. Further analysis will make the paper stronger.\n\nAre the images used for the interpolation train or test images?\n\nI assume that the network evaluated with the Basel Faces dataset, is the same one trained on Imagenet, is that the case?\n\nIn particular, it would be interesting (not required) to evaluate if the learned representation is able to linearize a variety of geometric image transformations in a controlled setting as done in:\n\nHénaff, O,, and Simoncelli, E. ""Geodesics of learned representations."" arXiv preprint arXiv:1511.06394 (2015).\n\nCould you please clarify, what do you mean with fine tuning the last layer with dropout?\n\nThe authors should cite the work on learning invertible functions with tractable Jacobian determinant (and exact and tractable log-likelihood evaluation) for generative modeling. Clearly the goals are different, but nevertheless very related. Specifically,\n\nDinh, L. et al  ""NICE: Non-linear independent components estimation."" arXiv preprint arXiv:1410.8516 (2014).\n\n\nDinh, L. et al ""Density estimation using Real NVP."" arXiv preprint arXiv:1605.08803 (2016).\n\nThe authors mention that the forward pass of the network does not seem to suffer from significant instabilities. It would be very good to empirically evaluate this claim.\n']","[50, 80, 70]","[70, 90, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'very interesting and thought provoking' and praises its well-written nature. However, they also point out some missing elements and areas for improvement, balancing the positive aspects. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'It would be good to see' and 'Generally the paper is well written' which maintain a polite tone while providing feedback."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, describing it as 'well written', 'potentially of great benefit', and 'simple and easy to understand'. They also praise the authors' empirical results as 'impressive' and 'competitive'. The slight reduction from 100 is due to the mention of the approach being expensive in terms of parameter budget. The politeness score is 90 (very polite) because the reviewer uses respectful and professional language throughout, acknowledging the authors' achievements and contributions without harsh criticism. They offer balanced feedback, noting both strengths and potential limitations of the work. The reviewer also uses phrases like 'worth noting' and 'the authors have succeeded in showing', which demonstrate respect for the authors' efforts."", ""The sentiment score is 70 (positive) because the reviewer begins by stating the paper is 'well written and easy to follow' and describes the results as 'very surprising'. They also call a section 'really interesting' and suggest ways to make the paper 'stronger', indicating they see value in the work. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrasing criticisms as questions or suggestions (e.g. 'Could you please comment on...', 'It would be very good to...') rather than demands. They also acknowledge the paper's strengths before offering constructive feedback. The tone is consistently professional and courteous.""]"
"['The paper shows an application of GANs to deciphering text. The goal is to arrive at a ```""hands free"" approach to this problem; i.e., an approach that does not require any knowledge of the language being deciphered such as letter frequency and such. The authors start from a CycleGAN architecture, which may be used to learn mapping between two probability spaces. They point out that using GANs for discrete distributions is a challenging problem since it can lead to uninformative discriminants. They propose to  resolve this issue by using a continuous embedding space to approximate (or convert) the discrete random variables into continuous random variables. The new proposed algorithm, called CipherGAN, is then shown to be stable and achieve deciphering of substitution ciphers and Vigenere ciphers.\n\nI did not completely understand how the embedding was performed, so perhaps the authors could elaborate on that a bit more. Apart from that, the paper is well written and well motivated. It used some recent ideas in deep learning such as Cycle GANs and shows how to tweak them to make them work for discrete problems and also make them more stable. One comment would be that the paper is decidedly an applied paper (and not much theory) since certain steps in the algorithm (such as training the discriminator loss along with the Lipschitz conditioning term) are included because it was experimentally  observed to lead to stability. ', ""The paper proposed to replace the 2-dim convolutions in CycleGAN by one dimension variant and reduce the filter sizes to 1, while leave the generator convex embedding and using L2 loss function.   \n\nThe proposed simple change help with the dealing of discrete GAN. The benefit of increased stability by adding Jacobian norm regularization term to the discriminator's loss is nice.  \n\nThe paper is well written. A few minor ones to improve: \n* The original GAN was proposed/stated as min_max, while in Equation 1 didn't defined F and was not clear about min_{F}. Similar for Equations 2 and 3. \n* Define abbreviation when first appear, e.g. WGAN (Wasserstein ...). \n* Clarify x- and y- axis label in Figure 3. "", 'SUMMARY\n\nThe paper considers the problem of using cycle GANs to decipher text encrypted with historical ciphers. Also it presents some theory to address the problem that discriminating between the discrete data and continuous prediction is too simple. The model proposed is a variant of the cycle GAN in which in addition embeddings helping the Generator are learned for all the values of the discrete variables. \nThe log loss of the GAN is replaced by a quadratic loss and a regularization of the Jacobian of the discriminator. Experiments show that the method is very effective.  \n\nREVIEW\n\nThe paper considers an interesting and fairly original problem and the overall discussion of ciphers is quite nice. Unfortunately, my understanding is that the theory proposed in section 2 does not correspond to the scheme used in the experiments (contrarily to what the conclusion suggest and contrarily to what the discussion of the end of section 3, which says that using embedding is assumed to have an equivalent effect to using the methodology considered in the theoretical part). Another important concern is with the proof: there seems to be an unmotivated additional assumption that appears in the middle of the proof of Proposition 1 + some steps need to be clarified (see comment 16 below).\nThe experiments do not have any simple baseline, which is somewhat unfortunate.\n\n\nDETAILED COMMENTS:\n\n1- The paper makes a few bold and debatable statements:\n\nline 9 of section 1\n""Such hand-crafted features have fallen out of favor (Goodfellow et al., 2016) as a\nresult of their demonstrated inferiority to features learned directly from data in end-to-end learning\nframeworks such as neural networks""\n\nThis is certainly an overstatement and although it might be true for specific types of inputs it is not universally true, most deep architectures rely on a human-in-the-loop and there are number of areas where human crafted feature are arguably still relevant, if only to specify what is the input of a deep network: there are many domains where the notion of raw data does not make sense, and, when it does, it is usually associated with a sensing device that has been designed by a human and which implicitly imposes what the data is based on human expertise. \n\n2- In the last paragraph of the introduction, the paper says that previous work has only worked on vocabularies of 26 characters while the current paper tackles word level ciphers with 200 words. But, isn\'t this just a matter of scalability and only possible with very large amounts of text? Is it really because of an intrinsic limitation or lack of scalability of previous approaches or just because the authors of the corresponding papers did not care to present larger scale experiments? \n\n\n3- The discussion at the top of page 5 is difficult to follow. What do you mean when you say ""this motivates the benefits of having strong curvature globally, as opposed to linearly between etc""\nWhich curvature are we talking about? and what how does the ""as opposed to linearly"" mean? Should we understand ""as opposed to having curvature linearly interpolated between etc"" or ""as opposed to having a linear function""? Please clarify.\n\n4- In the same paragraph: what does ""a region that has not seen the Jacobian norm applied to it"" mean? How is a norm applied to a region? I guess that what you mean is that the generator G might creates samples in a part of the space where the function F has not yet been learned and is essentially close to 0. Is this what you mean?\n\n5- I do not understand why the paper introduces WGAN since in the end it does not use them but uses a quadratic loss, introduced in the first display of section 4.3.\n\n6- The paper makes a theoretical contribution which supports replacing the sample y by a sample drawn from a region around y. But it seems that this is not used in the experiment and that the authors consider that the introduction of the embedding is a substitution for this. Indeed, in the last paragraph of section 3.1, the paper says ""we make the assumption that the training of the embedding vectors approximates random sampling similar to what is described in Proposition 1"". This does not make any sense to me because the embedding vectors map each y deterministically to a single point, and so the distribution on the corresponding vectors is still a fixed discrete distribution. This gives me this impression that the proposed theory does not match what is used in the experiments.\n(The last sentence of section 3.1, which is commenting on this and could perhaps clarify the situation is ill formed with two verbs.)\n\n7- In the definitions: ""A discriminator is said to perform uninformative discrimination"" etc. -> It seems that the choice of the word uninformative would be misleading: an uninformative discrimination would be a discrimination that completely fails, while what the condition is saying it that it cannot perform perfect discrimination. I would thus suggest to call this ""imperfect discrimination"". \n\n\n8- It seems that the same embedding is used in X space and in Y space (from equations 6 and 7). Is there any reason for that? I would seem more natural to me to introduce two different embeddings since the objects are a priori different...\nActually I don\'t understand how the embeddings can be the same in the Vignere code case since time taken into account one one side.\n\n9- On the 5th line after equation (7), the paper says ""the embeddings... are trained to minimize L_GAN and L_cyc, meaning... and are easy to discriminate"" -> This last part of the sentence seems wrong to me. The discriminator is trying to maximize L_GAN and so minimizing w.r.t. to the embedding is precisely trying to prevent to the discriminator to tell apart too easily the true elements from the estimated ones.\nIn fact the regularization of the Jacobian that will be preventing the discriminator to vary too quickly in space is more likely to explain the fact that the discrimination is not too easy to do between the true and mapped embeddings. This might be connected to the discussion at the top of page 5. Since there are no experiments with alpha different than the default value = 10, this is difficult to assess.\n\n10-The Vigenere cipher is explained again at the end of section 4.2 when it has already been presented in section 1.1\n\n11- Concerning results in Table 2: I do not see why it would not be possible to compare the performance of the method with classical frequency analysis, at least for the character case.\n\n12- At the beginning of section 4.3, the text says that the log loss was replaced with the quadratic loss, but without giving any reason. Could you explain why.\n\n13- The only comparison of results with and without embeddings is presented in the curves of figure 3, for Brown-W with a vocabulary of 200 words. In that case it helps. Could the authors report systematically results about all cases? (I guess this might however be the only hard case...)\n\n14- It would be useful to have a brief reminder of the architecture of the neural network (right now the reader is just refered to Zhu et al., 2017): how many layers, how many convolution layers etc.\nThe same comment applies for the way the position of the letter/word in the text appear is in encoded in a feature that is provided as input to the neural network: it would be nice if the paper could provide a few details here and be more self contained. (The fact that the engineering of the time feature can ""dramatically"" improve the performance of the network should be an argument to convince the authors that hand-crafted feature have not fallen out of favor completely yet...)\n\n15- I disagree with the statement made in the conclusion that the proposed work ""empirically confirms [...] that the use of continuous relaxation of discrete variable facilitates [...] and prevents [...]"" because for me the proposed implementation does not use at all the theoretical idea of continuous relaxation proposed in the paper, unless there is a major point that I am missing.\n\n\n16- I have two issues with the proof in the appendix\n\na) after the first display of the last page the paper makes an additional assumption which is not announced in the statement of the theorem, which is that two specific inequality hold...\nUnless I am mistaken this assumption is never proven (later or earlier). Given that this inequality is just ""the right inequality to get the proof go through"" and given that there are no explanation for why this assumption is reasonable, to me this invalidates the proof. The step of going from G(S_y) to S_(G(y)) seems delicate...\n\nb) If we accept these inequalities, the determinant of the Jacobian (the notation is not defined) of F at (x_bar) disappears from the equations, as if it could be assumed to be greater than one. If this is indeed the case, please provide a justification of this step.\n\n17- A way to address the issue of trivial discrimination in GANs with discrete data has been proposed in\n \nLuc, P., Couprie, C., Chintala, S., & Verbeek, J. (2016). Semantic segmentation using adversarial networks. arXiv preprint arXiv:1611.08408.\nThe authors should probably reference this paper.\n\n\n18- Clarification of the Jacobian regularization: in equation (3), the Jacobian computed seems to be w.r.t D composed with F while in equation (8) it is only the Jacobian of D. Which equation is the correct one?\n\nTYPOS:\n\nProposition 1: the if-then statement is broken into two sentences separated by a full point and a carriage return.\n\nsec. 4.3 line 10 we use a cycle loss *with a regularization coefficient* lambda=1 (a piece of the sentence is missing)\n\nsec. 4.3 lines 12-13 the learning rates given are the same at startup and after ""warming up""...\n\nIn the appendix: \n3rd line of proof of prop 1: I don\' understand ""countably infinite finite sequences of vectors lying in the vertices of the simplex"" -> what is countable infinite here? The vertices?\n\n\n\n\n\n\n\n  \n\n\n\n']","[60, 70, -30]","[80, 80, 50]","[""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'well written and well motivated' and praising its use of recent ideas in deep learning. However, it's not extremely positive as the reviewer mentions not fully understanding one aspect and notes that the paper is more applied than theoretical. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms gently (e.g., 'I did not completely understand' rather than 'This was unclear'). The reviewer also acknowledges the paper's strengths alongside areas for improvement, maintaining a courteous tone."", ""The sentiment score is 70 (positive) because the reviewer expresses approval of the paper's proposed changes, noting that they 'help with the dealing of discrete GAN' and praising the 'benefit of increased stability'. The overall tone is supportive, with only minor suggestions for improvement. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, acknowledging the paper as 'well written' and framing their suggestions as 'minor ones to improve'. The reviewer provides constructive feedback without harsh criticism, maintaining a professional and courteous tone."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('interesting and fairly original problem', 'quite nice' discussion of ciphers), there are significant criticisms and concerns raised. The reviewer points out mismatches between theory and experiments, issues with the proof, lack of baselines, and several other detailed critiques. This indicates an overall negative sentiment, though not extremely negative. The politeness score is 50 because the reviewer uses polite and professional language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'Unfortunately, my understanding is...', 'Could you explain why...', and 'It would be useful to...', which maintain a respectful tone. However, the review is not overly deferential or excessively polite, maintaining a neutral professional tone in many parts, hence the score is positive but not extremely high.""]"
"['While it is not very surprising that in a potential game it is easy to find Nash equilibria (compare to normal form static games, in which local maxima of the potential are pure Nash equilibria), the idea of approaching these stochastic games from this direction is novel and potentially (no pun intended) fruitful. The paper is well written, the motivation is clear, and some of the ideas are non-trivial. However, the connection to learning representations is a little tenuous. ', ""Summary:\nThis paper studies multi-agent sequential decision making problems that belong to the class of games called Markov Potential Games (MPG). It considers finding the optimal policy within a parametric space of policies, which can be represented by a function approximator such as a DNN.\nA main contribution of this work is that it shows that for MPG, instead of solving a multi-objective optimization problem (Eq. 8), which is difficult, it is sufficient to solve a scalar-valued optimization problem (Eq. 16).  Theorem 1 shows that under certain conditions on the reward function, the game is MPG. It also shows how one might find the potential function J, which is used in the single objective optimization problem.\nFinding J can be computationally expensive in general. So the paper provides some properties that lead to finding J easier. For example, obtaining J is easy if we have a cooperative game (Corollary 1) or the reward can be decomposed/decoupled in a certain way (Theorem 2).\n\n\nEvaluation:\n\nThis is a well-written paper that studies an important problem, but I don’t think ICLR is the right venue for it. There is not much about (representation) learning in this work. The use of TRPO as an RL algorithm in the Experiment does not play a critical role in this work either. Aside this general comment, I have several other more specific comments.\n\n\n- There is a significant literature on the use of RL for multi-agent systems. The paper does not do a good job comparing and positioning with respect to them. For example, refer to the following recent paper and references therein:\n\nPerolat, Strub, et al., “Learning Nash Equilibrium for General-Sum Markov Games from Batch Data,” AISTATS, 2017.\n\n\n- If I understand correctly, the policies are considered to be functions from the state of the system to a continuous action. So it is a function, and not a probability distribution. This means that the space of considered policies correspond to the space of pure strategies. We know that for some games, the Nash equilibrium is a mixed strategy. Isn’t this a big limitation of this approach?\n\n\n- I am unclear how this approach can handle stochastic dynamics. For example, the optimization (P1) depends on the realization of (theta_i)_i. But this is not available. The dependence is not only in the objective, but also in the constraints, which makes things more difficult.\n\nI understand that in the experiments the authors used two models (either the average of random realization, or solving a different optimization for each realization), but none of them is an appropriate solution for a stochastic system.\n\n\n- How large is the MPG class? Is there any structural result that positions them compared to other Markov Games? For example, is the class of zero-sum games an example of MPG?\n\n\n- There is a comment close to the end of Section 5 that when there is no prior knowledge of the dynamics and the reward, one can use the proposed approach to learn PCL-NE by using any DRL.\nThis is questionable because if the reward is not known, the conditions of Theorems 1 or 2 cannot be verifies, so it is not possible to use (P1) instead of (G2).\n\n\n- What comments can you make about the computational complexity? It seems that depending on the dynamics, the optimization problem P1 can be non-convex, hence computationally difficult to solve.\n\n\n- How is the work related to the following paper?\nMacua, Zazo, Zazo, “Learning in Constrained Stochastic Dynamic Potential Games,” ICASSP, 2016\n\n======\nI updated the score based on the authors' rebuttal.\n"", 'This manuscript considers a subclass of stochastic games named Markov potential games. It provides some assumptions that guarantee that a game is a Markov potential game and leads to some nice properties to solve the problem to approximately a Nash equilibrium. It is claimed that the work extends the state of the art by analysing the closed-loop version in a different manner, firstly constraining policies to a parametric family and then deriving conditions for that, instead of the other way around. As someone with no knowledge in the topic, I find the paper interesting to read, but I have not followed any proofs. The experimental setup is quite limited, even though I believe that the intention of the authors is to provide some theoretical ideas rather than applying them. Minor point: there are a few sentences with small errors, this could be improved.']","[50, -30, 60]","[75, 50, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and potential of the approach, praising the paper's writing and motivation. However, they also point out a weakness in the connection to learning representations. The politeness score is 75 (quite polite) due to the use of respectful language and constructive criticism. The reviewer begins with positive aspects, uses phrases like 'potentially fruitful' and 'well written', and even includes a light-hearted comment ('no pun intended'). The criticism is presented gently with 'However' rather than harsh language."", ""The sentiment score is -30 because while the reviewer acknowledges the paper as 'well-written' and studying 'an important problem', they express significant concerns about its suitability for the venue and list several major criticisms. The overall tone suggests more negative than positive sentiment, but not extremely negative. The politeness score is 50 because the reviewer uses respectful language throughout, starting with positive acknowledgments and framing criticisms as questions or suggestions rather than direct attacks. They use phrases like 'I don't think', 'I am unclear', and 'This is questionable' rather than more confrontational language. However, the review doesn't go out of its way to be overly polite either, maintaining a professional, neutral tone overall."", ""The sentiment score is 60 (positive) because the reviewer finds the paper 'interesting to read' and acknowledges that it 'extends the state of the art'. The reviewer also mentions some positive aspects like 'nice properties' and 'guarantees'. However, it's not extremely positive due to comments about limited experimental setup and small errors in sentences. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges their own lack of expertise in the field ('As someone with no knowledge in the topic'), and frames criticisms gently ('Minor point', 'this could be improved'). The reviewer also gives the authors the benefit of the doubt regarding their intentions ('I believe that the intention of the authors is to provide some theoretical ideas rather than applying them'). The language is consistently professional and constructive.""]"
"['\nThis paper proposes a ""temporal difference model learning"", a method that aims to combine the benefits of model-based and model-free RL.  The proposed method essentially learns a time-varying goal-conditional value function for a specific reward formulation, which acts as a surrogate for a model in an MPC-like setting.  The authors show that the method outperforms some alternatives on three continuous control domains and real robot system.\n\nI believe this paper to be borderline, but ultimately below the threshold for acceptance.  On the positive side, there are certainly some interesting ideas here: the notion of goal-conditioned value functions as proxies for a model, and as a means of merging model-free and model-based approaches is very really interesting, and hints at a deeper structure to goal-conditioned value functions in general.  Ultimately, though, I feel that there are two main issues that make this research feel as though it is still ultimately in the earlier stages: 1) the very large focus on the perspective that this approach is unifying model-based and model-free RL, when it fact this connection seems a bit tenuous; and 2) the rather lackluster experimental results, which show only marginal improvement over purely model-based methods (at the cost of much additional complexity), and which make me wonder if there\'s an issue with their implementation of prior work (namely the Highsight Experience Replay algorithm).\n\nTo address the first point, although the paper stresses it to a very high degree, I can\'t help but feel that the connection that the claimed advance of ""unifying model-based and model-free RL"" is overstated.  As far as I can tell, the connection is as follows: the learned quantity here is a time-varying goal-conditioned value function, and under some specific definition of reward, we can interpret the constraint that this value function equal zero as a proxy for the dynamics constraint in MPC.  But the exact correspondence between this and the MPC formulation only occurs for a horizon of size zero: longer horizons require a multi-step MPC for the definition of the model-free and model-based correspondence.  The fact that the action selection of a model-based method and this approach have some function which looks similar (but only under certain conditions), just seems like a fairly odd connection to highlight so heavily.\n\nRather, it seems to me that what\'s happening here is really quite simple: the authors are extending goal-conditioned value functions to the case of non-stationary finite horizon value functions (the claimed ""key insight"" in eq (5) is a completely standard finite-horizon MDP formulation).  This seems to describe perfectly well what is happening here, and it does also seem intuitive that this provides an advantage over stationary goal-conditioned value functions: just as goal conditioned value functions offer the advantage of considering ""every state as a goal"", this method can consider ""every state as a goal for every time horizon"".  This seems interesting enough on its own, and I admit I don\'t see the need for the method to be yet another claimed unification of model-free and model-based RL.\n\nI would also suggest that the authors look into the literature on how TD methods implicitly learn models (see e.g. Boyan 1997 ""Least-squares temporal difference learning"", and Parr et al., 2007 ""An analysis of linear models..."").  In these works it has been shown that least squares TD methods (at least in the linear feature setting), implicitly learn a dynamics model in feature space, but only the ""projection"" of the reward function is actually needed to learn the TD weights.  In building the proposed value functions, it seems like the authors are effectively solving for multiple rewards simultaneously, which would effectively preserve the learned dynamics model.  I feel like this may be an interesting line of analysis for the paper if the authors _do_ want to stick with the notion of the method as unifying model-free and model-based RL.\n\nAll these points may ultimately just be a matter of interpretation, though, if not for the second issue with the paper, which is that the results seem quite lackluster, and the claimed performance of HER seems rather suspicious.  But instead, the authors evaluate the algorithm on just three continuous control tasks (and a real robot, which is more impressive, but the task here is still so extremely simple for a real robot system that it really just qualifies as a real-world demonstration rather than an actual application).  And in these three settings, a model-based approach seems to work just as well on two of the tasks, and may soon perform just as well after a few more episodes on the last task (it doesn\'t appear to have converged yet).  And despite the HER paper showing improvement over traditional policy approaches, in these experiments plain DDPG consistently performs as well or better than HER.  ', 'The paper universal value function type ideas to learn models of how long the current policy will take to reach various states (or state features), and then incorporates these into model-predictive control. This looks like a reasonable way to approach the problem of model-based RL in a way that avoids the covariate shift produced by rolling learned transition models forward in time. Empirical results show their method outperforming Hindsight Experience Replay (which looks quite bad in their experiments), DDPG, and more traditional model-based learning. It also outperforms DDPG quite a bit in terms of sample efficiency on a real robotic arm. They also show the impact of planning horizon on performance, demonstrating a nice trade-off.\n\nThere are however a couple of relevant existing papers that the authors miss referencing / discussing:\n- ""Reinforcement Learning with Unsupervised Auxiliary Tasks"" (Jarderberg et al, ICLR 2017) - uses predictions about auxiliary tasks, such as effecting maximum pixel change, to obtain much better sample efficiency.\n- ""The Predictron: End-To-End Learning and Planning"" (Silver et al, ICML 2017), which also provides a way of interpolating between model-based and model-free RL.\n\nI don\'t believe that these pieces of work subsume the current paper, however the authors do need to discuss the relationship their method has with them and what it brings.\n\n** UPDATE Jan 9: Updated my rating in light of authors\' response and updated version. I recommend that the authors find a way to keep the info in Section 4.3 (Dynamic Goal and Horizon Resampling) in the paper though, unless I missed where it was moved to. **\n', 'This is an interesting direction. There is still much to understand about the relative strengths and limitations of model based and model free techniques, and how best to combine them, and this paper discusses a new way to address this problem. The empirical results are promising and the ablation studies are good, but it also makes me wonder a bit about where the benefit is coming from.\n\nCould you please put a bit of discussion in about the computational and memory cost. TDM is now parameterized with (state, action (goal) state, and the horizon tau). Essentially it is now computing the distance to each possible goal state after starting in state (s,a) and taking a fixed number of steps. \nIt seems like this is less compact than learning a 1-step dynamics model directly.\nThe results are better than models in some places. It seems likely this is because the model-based approach referenced doesn’t do multi-step model fitting, but essentially TDM is, by being asked to predict and optimize for C steps away. If models were trained similarly (using multi-step loss) would models do as well as TDM?\nHow might this be extended to the stochastic setting?\n']","[-40, 60, 50]","[50, 70, 80]","[""The sentiment score is -40 because the reviewer states the paper is 'below the threshold for acceptance' and points out several significant issues, though they do acknowledge some positive aspects. The overall tone is critical but not entirely negative. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positive aspects and framing criticisms constructively. They use phrases like 'I believe' and 'I feel' to soften critiques, and offer suggestions for improvement. However, the review doesn't go out of its way to be overly polite, maintaining a professional tone."", ""The sentiment score is 60 (positive) because the reviewer begins by praising the paper's approach as 'reasonable' and highlights its empirical results outperforming other methods. They also note the 'nice trade-off' demonstrated. However, it's not extremely positive as they point out missing references and suggest improvements. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively. They use phrases like 'looks like a reasonable way' and 'I don't believe that these pieces of work subsume the current paper,' which maintain a collegial tone. The update at the end also shows consideration for the authors' response, further indicating politeness."", ""The sentiment score is 50 (moderately positive) because the reviewer describes the paper as 'interesting' and having 'promising' results, while also expressing some reservations ('makes me wonder'). The overall tone is constructive and encouraging, but not overwhelmingly positive. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions ('Could you please...', 'It seems like...'), and acknowledges the paper's strengths before offering areas for improvement. The use of 'please' and the constructive nature of the feedback contribute to the high politeness score.""]"
"['The paper proposes to combine two approaches to compress deep neural networks - distillation and quantization. The authors proposed two methods, one largely relying on the distillation loss idea then followed by a quantization step, and another one that also learns the location of the quantization points. Somewhat surprisingly, nobody has combined the two approaches before, which makes this paper interesting. Experiments show that both methods work well in compressing large deep neural network models for applications where resources are limited, like on mobile devices. \n\nOverall I am mostly OK with this paper but not impressed by it.  Detailed comments below.\n\n1. Quantizing with respect to the distillation loss seems to do better than with the normal loss - this needs more discussion. \n2. The idea of using the gradient with respect to the quantization points to learn them is interesting but not entirely new (see, e.g., ""Matrix Recovery from Quantized and Corrupted Measurements"", ICASSP 2014 and ""OrdRec: An Ordinal Model for Predicting Personalized Item Rating Distributions"", RecSys 2011, although in a different context). I also wonder if it would work better if you can also allow the weights to move a little bit (it seems to me from Algorithm 2 that you only update the quantization points). How about learning them altogether? Also this differentiable quantization method does not really depend on distillation, which is kind of confusing given the title.\n3. I am a little bit confused by how the bits are redistributed in the second method, as in the end it seems to use more than the proposed number of bits shown in the table (as recognized in section 4.2). This makes the comparison a little bit unfair (especially for the CIFAR 100 case, where the ""2 bits"" differentiable quantization is actually using 3.23 bits). This needs more clarification.\n4. The writing can be improved. For example, the concepts of ""teacher"" and ""student"" is not clear at all in the abstract - consider putting the first sentence of Section 3 in there instead. Also, the first sentence of the paper reads as ""... have showed tremendous performance"", which is not proper English. At the top of page 3 I found ""we will restrict our attention to uniform and non-uniform quantization"". What are you not restricting to, then?\n\nSlightly increased my rating after reading the rebuttal and the revision. ', 'This paper presents a framework of using the teacher model to help the compression for the deep learning model in the context of model compression. It proposed both the quantized distillation and also the differentiable quantization. The quantized distillation method just simply adapt the distillation work for the task of model compression, and give good results to the baseline method. While the differentiable quantization optimise the quantization function in a unified back-propagation framework. It is interesting to see the performance improvements by using the one-step optimisation method. \n\nI like this paper very much as it is in good motivation to utilize the distillation framework for the task of model compression. The starting point is quite interesting and reasonable. The information from the teacher network is useful for constructing a better compressed model. I believe this idea is quite similar to the idea of Learning using Privileged Information, in which the information on teacher model is only used during training, but is not utilised during testing. \n\nSome minor comments:\nIn table 3, it seems that the results for 2 bits are not stable, and are there any explanations?\nWhat will be the results if the student model performs the same with the teacher model (e.g., use the teacher model as the student model to do the compression) or even better (reverse the settings)?\nWhat will be the prediction speed for each of models? We can also get the time of speedup for the compressed model.\n\nIt will be better if the authors could discuss the connections between distillation and the recent work for the Learning using Privileged Information setting:\nVladimir Vapnik, Rauf Izmailov:\nLearning using privileged information: similarity control and knowledge transfer. Journal of Machine Learning Research 16: 2023-2049 (2015)\nXinxing Xu, Joey Tianyi Zhou, IvorW. Tsang, Zheng Qin, Rick Siow Mong Goh, Yong Liu: Simple and Efficient Learning using Privileged Information. BeyondLabeler: Human is More Than a Labeler, Workshop of the 25th International Joint Conference on Artificial Intelligence (IJCAI-16). New York City, USA. July, 2016.\n', 'This paper proposes to learn small and low-cost models by combining distillation and quantization. Two strategies are proposed and the ideas are reasonable and clearly introduced. Experiments on various datasets are conducted to show the effectiveness of the proposed method.\n\nPros:\n(1) The paper is well written, the review of distillation and quantization is clear.\n(2) Extensive experiments on vision and neural machine translation are conducted.\n(3) Detailed discussions about implementations are provided.\n\nCons:\n(1) The differentiable quantization strategy seems not to be consistently better than the straightforward quantized distillation which may need more research.\n(2) The actual speedup is not clearly calculated. The authors claim that the inference times of 2xResNet18 and ResNet18 are similar which seems to be unreasonable. And it seems to need a lot of more work to make the idea really practical.\n\nFinally, I am curious whether the idea will work on object detection task.\n']","[20, 80, 60]","[50, 90, 70]","[""The sentiment score is slightly positive (20) because the reviewer states they are 'mostly OK with this paper' and acknowledges its interesting aspects, but also mentions not being impressed by it. The reviewer recognizes the novelty of combining two approaches and the effectiveness of the methods, which contributes to the positive side. However, the lack of enthusiasm ('not impressed') and the list of critiques balance this out, resulting in a mildly positive sentiment.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They offer constructive criticism and suggestions for improvement without using harsh language. Phrases like 'Somewhat surprisingly' and 'Overall I am mostly OK with this paper' indicate a polite approach to expressing opinions. The reviewer also acknowledges the authors' efforts in addressing concerns in the rebuttal. However, the directness of some statements (e.g., 'not impressed by it') prevents the score from being higher, as extremely polite language would use more hedging and positive reinforcement."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, stating 'I like this paper very much' and praising its motivation and ideas. The reviewer finds the approach interesting and reasonable, and believes it has similarities to other valuable research concepts. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer offers praise, uses phrases like 'It is interesting to see' and 'It will be better if', and frames suggestions as questions or gentle recommendations rather than demands. The minor comments and suggestions are presented in a helpful and non-confrontational manner, indicating a high level of politeness throughout the review."", ""The sentiment score is 60 (positive) because the reviewer starts with a neutral description of the paper's content, followed by a list of pros that outweigh the cons. The reviewer acknowledges the paper's clear writing, extensive experiments, and detailed discussions. While there are some concerns raised, they are presented as areas for improvement rather than major flaws. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, presenting both positive and negative points in a constructive manner. The use of phrases like 'I am curious' shows engagement with the work. The reviewer avoids harsh criticism and instead offers suggestions for further research and improvement.""]"
"['The problem of learning auto-regressive (data-driven) human motion models that have long-term stability\nis of ongoing interest. Steady progress is being made on this problem, and this paper adds to that.\nThe paper is clearly written. The specific form of training (a fixed number of self-conditioned predictions,\nfollowed by a fixed number of ground-truth conditioned steps) is interesting for simplicity and its efficacy.\nThe biggest open question for me is how it would compare to the equally simple stochastic version proposed\nby the scheduled sampling approach of [Bengio et al. 2015].\n\nPROS:  The paper provides a simple solution to a problem of interest to many.\nCONS:  It is not clear if it improves over something like scheduled sampling, which is a stochastic predecessor\n       of the main idea introduced here. The ""duration of stability"" is a less interesting goal than\n       actually matching the distribution of the input data.\n\nThe need to pay attention to the distribution-mismatch problem for sequence prediction problems\nhas been known for a while. In particular, the DAGGER (see below) and scheduled sampling algorithms (already cited) \ntarget this issue, in addition to the addition of progressively increasing amounts of noise during training\n(Fragkiadaki et al). Also see papers below on Professor Forcing, as well as ""Learning Human Motion Models\nfor Long-term Predictions"" (concurrent work?), which uses annealing over dropout rates to achieve stable long-term predictions.\n\n  DAGGER algorithm (2011):  http://www.jmlr.org/proceedings/papers/v15/ross11a/ross11a.pdf\n  ""A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning""\n\n  Professor Forcing (NIPS 2016)\n  http://papers.nips.cc/paper/6099-professor-forcing-a-new-algorithm-for-training-recurrent-networks.pdf\n\n  Learning Human Motion Models for Long-term Predictions (2017)\n  https://arxiv.org/abs/1704.02827\n  https://www.youtube.com/watch?v=PgJ2kZR9V5w\n  \nWhile the motions do not freeze, do the synthesized motion distributions match the actual data distributions?\nThis is not clear, and would be relatively simple to evaluate.  Is the motion generation fully deterministic?\nIt would be useful to have probabilistic transition distributions that match those seen in the data.\nAn interesting open issue (in motion, but also of course NLP domains) is that of how to best evaulate\nsequence-prediction models.  The duration of ""stable prediction"" does not directly capture the motion quality. \n\nFigure 1:  Suggest to make u != v for the purposes of clarity, so that they can be more easily distinguished.\n\nData representation:\nWhy not factor out the facing angle, i.e., rotation about the vertical axis, as done by Holden et al, and in a variety of\nprevious work in general?\nThe representation is already made translation invariant. Relatedly, in the Training section,\ndata augmentation includes translating the sequence: ""rotate and translate the sequence randomly"".\nWhy bother with the translation if the representation itself is already translation invariant?\n\nThe video illustrates motions with and without ""foot alignment"".\nHowever, no motivation or description of ""foot alignment"" is given in the paper.\n\nThe following comment need not be given much weight in terms of evaluation of the paper, given that the\ncurrent paper does not use simulation-based methods. However, it is included for completeness.\nThe survey of simulation-based methods for modeling human motions is not representative of the body of work in this area\nover the past 25 years.  It may be more useful to reference a survey, such as \n""Interactive Character Animation Using Simulated Physics: A State‐of‐the‐Art Review"" (2012)\nAn example of recent SOTA work for modeling dynamic motions from motion capture, including many\nhighly dynamic motions, is ""Guided Learning of Control Graphs for Physics-Based Characters"" (2016)\nMore recent work includes ""Learning human behaviors from motion capture by adversarial imitation"", \n""Robust Imitation of Diverse Behaviors"", and ""Deeploco: Dynamic locomotion skills using hierarchical deep reinforcement learning"", all of which demonstrate imitation of various motion styles to various degrees.\n\nIt is worthwhile acknowledging that the synthesized motions are still low quality, particular when rendered with more human-like looking models, and readily distinguishable from the original motions.  In this sense, they are not comparable to the quality of results demonstrated in recent works by Holden et al. or some other recent works.  However, the authors should be given credit for including some results with fully rendered characters, which much more readily exposes motion flaws.\n\nThe followup work on [Lee et al 2010 ""Motion Fields""] is quite relevant:\n""Continuous character control with low-dimensional embeddings""\nIn terms of usefulness, being able to provide some control over the motion output is a more interesting problem than\nbeing able to generate long uncontrolled sequences.  A caveat is that the methods are not applied to large datasets.\n', 'Paper presents an approach for conditional human (skeleton) motion generation using a form of the LSTM, called auto-conditioned LSTM (acLSTM). The key difference of acLSTM is that in it parts of the generated sequences, at regular intervals, are conditioned on generated data (as opposed to just ground truth data). In this way, it is claimed that acLSTM can anticipate and correct wrong predictions better than traditional LSTM models that only condition generation on ground truth when training. It is shown that trained models are more accurate at long-term prediction (while being a bit less accurate in short-term prediction). \n\nGenerally the idea is very sensible. The novelty is somewhat small, given the fact that a number of other methods have been proposed to address the explored challenge in other domains. The cited paper by Bengio et al., 2015 is among such, but by no means the only one. For example, “Professor Forcing: A New Algorithm  for Training Recurrent Nets” by Goyal et al. is a more recent variant that does away with the bias that the scheduled sampling of Bengio et al., 2015 would introduce. The lack of comparison to these different methods of training RNNs/LSTMs with generated or mixture of ground truth and generated data is the biggest shortcoming of the paper. That said, the results appear to be quite good in practice, as compared to other state-of-the-art methods that do not use such methods to train. \n\nOther comments and corrections:\n\n- The discussion about the issues addressed not arising in NLP is in fact wrong. These issues are prevalent in training of any RNN/LSTM model. In particular, similar approaches have been used in the latest image captioning literature.\n\n- In the text, when describing Figure 1, unrolling of u=v=1 is mentioned. This is incorrect; u=v=4 in the figure.\n\n- Daniel Holden reference should not contain et. al. (page 9)', 'This paper proposes acLSTM to synthesize long sequences of human motion. It tackles the challenge of error accumulation of traditional techniques to predict long sequences step by step. The key idea is to combine prediction and ground truth in training. It is impressive that this architecture can predict hundreds of frames without major artifacts.\n\nThe exposition is mostly clear. My only suggestion is to use either time (seconds) or frame number consistently. In the text, the paper sometimes use time, and other time uses frame index (e.g. figure 7 and its caption). It confuses me a bit since it is not immediate clear what the frame rate is.\n\nIn evaluation, I think that it is important to analyze the effect of condition length in the main text, not in the Appendix. To me, this is the most important quantitive evaluation that give me the insight of acLSTM. It also gives a practical guidance to readers how to tune the condition length. As indicated in Appendix B, ""Further experiments need to be conducted to say anything meaningful."" I really hope that in the next version of this paper, a detailed analysis about condition length could be added. \n\nIn summary, I like the method proposed in the paper. The result is impressive. I have not seen an LSTM based architecture predicting a complex motion sequence for that long. However, more detailed analysis about condition length is needed to make this paper complete and more valuable.']","[20, 20, 70]","[60, 60, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contribution to ongoing research and praises its clarity. However, they also raise concerns and suggest improvements, balancing the positive aspects. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and acknowledges the paper's merits. They provide detailed suggestions and additional references without being dismissive. The tone is professional and helpful, though not overly effusive in praise."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the sensibility of the idea and the good practical results, despite pointing out some shortcomings. The reviewer states that 'Generally the idea is very sensible' and 'the results appear to be quite good in practice'. However, they also mention limitations such as 'The novelty is somewhat small' and 'The lack of comparison to these different methods... is the biggest shortcoming of the paper'. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offering constructive criticism and specific suggestions for improvement. They balance positive comments with areas for improvement, and use phrases like 'Generally the idea is very sensible' which shows respect for the authors' work. The reviewer also provides specific, helpful corrections in a neutral tone, which contributes to the politeness of the review."", ""The sentiment score is 70 (positive) because the reviewer expresses appreciation for the paper's method and results, calling them 'impressive' and stating 'I like the method proposed in the paper.' However, it's not 100 as they also suggest improvements, particularly regarding the analysis of condition length. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. Phrases like 'My only suggestion is...' and 'I really hope that...' indicate a polite and encouraging tone. The reviewer balances praise with areas for improvement in a professional manner.""]"
"['The paper studies convolutional neural networks where the stride is smaller than the convolutional filter size; the so called overlapping convolutional architectures. The main object of study is to quantify the benefits of overlap in convolutional architectures.\n\nThe main claim of the paper is Theorem 1, which is that overlapping convolutional architectures are efficient with respect to non-overlapping architectures, i.e., there exists functions in the overlapping architecture which require an exponential increase in size to be represented in the non-overlapping architecture; whereas overlapping architecture can capture within a linear size the functions represented by the non-overlapping architectures. The main workhorse behind the paper is the notion of rank of matricized grid tensors following a paper of Cohen and Shashua which capture the relationship between the inputs and the outputs, the function implemented by the neural network. \n\n(1) The results of the paper hold only for product pooling and linear activation function except for the representation layer, which allows general functions. It is unclear why the generalized convolutional networks are stated with such generality when the results apply only to this special case. That this is the case should be made clear in the title and abstract. The paper makes a point that generalized tensor decompositions can be potentially applied to solve the more general case, but since it is left as future work, the paper should make it clear throughout.\n\n(2) The experiment is minimal and even the given experiment is not described well. What data augmentation was used for the CIFAR-10 dataset? It is only mentioned that the data is augmented with translations and horizontal flips. What is the factor of augmentation? How much translation? These are important because there maybe a much simpler explanation to the benefit of overlap: it is able to detect these translated patterns easily. Indeed, this simple intuition seems to be why the authors chose to make the problem by introducing translations and flips. \n\n(3) It is unclear if the paper resolves the mystery that they set out to solve, which is a reconciliation of the following two observations (a) why are non-overlapping architectures so common? (b) why only slight overlap is used in practice?  The paper seems to claim that since overlapping architectures have higher expressivity that answers (a). It appears that the paper does not answer (b) well: it points out that since there is exponential increase, there is no reason to increase it beyond a particular point. It seems the right resolution will be to show that after the overlap is set to a certain small value, there will be *only* linear increase with increasing overlap; i.e., the paper should show that small overlap networks are efficient with respect to *large* overlap networks; a comparison that does not seem to be made in the paper. \n\n(4) Small typo: the dimensions seem to be wrong in the line below the equation in page 3. \n\nThe paper makes important progress on a highly relevant problem using a new methodology (borrowed from a previous paper). However, the writing is hurried and the high-level conclusions are not fully supported by theory and experiments. ', 'The paper analyzes the expressivity of convolutional arithmetic circuits (ConvACs), where neighboring neurons in a single layer have overlapping receptive fields. To compare the expressivity of overlapping networks with non-overlapping networks, the paper employs grid tensors computed from the output of the ConvACs.  The grid tensors are matricized and the ranks of the resultant matrices are compared. The paper obtains a lower bound on the rank of the resultant grid tensors, and uses them to show that an exponentially large number of non-overlapping ConvACs are required to approximate the grid tensor of an overlapping ConvACs. Assuming that the result carries over to ConvNets, I find this result to be very interesting.  While overlapped convolutional layers are almost universally used, there has been very little theoretical justification for the same. This paper shows that overlapped ConvACs are exponentially more powerful than their non-overlapping counterparts. ', 'The paper studies the expressive power provided by ""overlap"" in convolution layers of DNNs.  Instead of ReLU networks with average/max pooling (as is standard in practice), the authors consider linear activations with product pooling.  Such networks, which have been known as convolutional arithmetic circuits, are easier to analyze (due to their connection to tensor decomposition), and provide insight into standard DNNs.\n\nFor these networks, the authors show that overlap results in the overall function having a significantly higher rank (exponentially larger) than a function obtained from a network with non-overlapping convolutions (where the stride >= filter width).  The key part of the proof is showing a lower bound on the rank for networks with overlap.  They do so by an argument well-known in this space: showing a lower bound for some particular tensor, and then inferring the bound for a ""generic"" tensor.\n\nThe results are interesting overall, but the paper has many caveats:\n1.  the results are only for ConvACs, which are arguably quite different from ReLU networks (the non-linearity in successive non-pooling layers could be important).\n2.  it\'s not clear if the importance of overlap is too surprising (or is a pressing question to understand, as in the case of depth).\n3.  the rank of the tensor being high does not preclude approximation (to a very good accuracy) by tensors of much smaller rank.\n\nThat said, the results could be of interest to those thinking about minimizing the number of connections in ConvNets, as it gives some intuition about how much overlap might \'suffice\'.  \n\nI recommend weak accept.']","[-20, 80, 20]","[50, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's importance and progress, they also point out several significant limitations and areas for improvement. The review begins positively but then lists multiple critiques, suggesting the paper falls short in some aspects. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, avoiding harsh criticism and acknowledging the paper's contributions. They use phrases like 'The paper makes important progress' and offer constructive feedback rather than outright dismissal. The tone is academic and objective, maintaining politeness while still clearly communicating areas of concern."", ""The sentiment score is 80 (positive) because the reviewer expresses strong interest in the paper's findings, describing them as 'very interesting' and highlighting the importance of the theoretical justification provided for overlapped convolutional layers. The reviewer also emphasizes the significance of the paper's results, noting that it shows 'overlapped ConvACs are exponentially more powerful than their non-overlapping counterparts.' The politeness score is 50 (slightly positive) because while the reviewer doesn't use overtly polite language, they maintain a professional and respectful tone throughout. The review focuses on the content and merits of the paper without any harsh criticism or personal remarks, which contributes to a polite and constructive atmosphere."", ""The sentiment score is slightly positive (20) because the reviewer finds the results 'interesting overall' and recommends a 'weak accept'. However, they also list several caveats, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's contributions while offering constructive criticism. They avoid harsh language and present their concerns as 'caveats' rather than outright flaws. The use of phrases like 'The results are interesting overall' and 'That said, the results could be of interest' demonstrate a polite and considerate tone.""]"
"['Clearly presented paper, including a number of reasonable techniques to improve LSTM-LMs. The proposed techniques are heuristic, but are reasonable and appear to yield improvements in perplexity. Some specific comments follow.\n\nre. ""ASGD"" for Averaged SGD: ASGD usually stands for Asynchronous SGD, have the authors considered an alternative acronym? AvSGD?\n\nre. Optimization criterion on page 2, note that SGD is usually taken to minimizing expected loss, not just empirical loss (Bottou thesis 1991).\n\nIs there any theoretical analysis of convergence for Averaged SGD?\n\nre. paragraph starting with ""To prevent such inefficient data usage, we randomly select the sequence length for the forward and backward pass in two steps"": the explanation is a bit unclear. What is the ""base sequence length"" exactly? Also, re. the motivation above this paragraph, I\'m not sure what ""elements"" really refers to, though I can guess.\n\nWhat is the number of training tokens of the datasets used, PTB and WT2?\n\nCan the authors provide more explanation for what ""neural cache models"" are, and how they relate to ""pointer models""?\n\nWhy do the sections ""Pointer models"", ""Ablation analysis"", and ""AWD-QRNN"" come after the Experiments section?', 'The paper sets a new state of the art on word level language modelling on the Penn Treebank and Wikitext-2 datasets using various optimization and regularization techniques. These already very good results are further improved, by a large margin, using a Neural Cache.\n\nThe paper is well written, easy to follow and the results speak for themselves. One possible criticism is that the experimental methodology does not allow for reliable conclusions to be drawn about contributions of all different techniques, because they seem to have been evaluated at a single hyperparameter setting (that was hand tuned for the full model?).\n\nA variant on the Averaged SGD method is proposed. This so called NT-ASGD optimizer switches to averaging mode based on recent validation losses. I would have liked to see a more thorough assessment of NT-ASGD, especially against well tuned SGD.\n\nI particularly liked Figure 3 which shows how the Neural Cache makes the model much better at handling rare words and UNK (!) at the expense of very common words. Speaking of the Neural Cache, a natural baseline would have been dynamic evaluation.\n\nAll in all, the paper is a solid contribution which deserves to be accepted. It could become even better, were the experiments to tease the various factors apart.\n', ""This is a well-written paper that proposes regularization and optimization strategies for word-based language modeling tasks.   The authors propose the use of DropConnect  on the hidden-hidden connections as a regularization method, in order to take advantage of high-speed LSTM implementations via the cuDNN LSTM libraries from NVIDIA.  The  focus of this work is on the prevention of overfitting on the recurrent connections of the LSTM.  The authors explore a variant of Average-SGD (NT-ASGD) as an optimization strategy which eliminates the need for tuning the average trigger and uses a constant learning rate.  Averaging is triggered when the validation loss worsens or stagnates for a few cycles, leading to two new hyper parameters: logging interval and non-monotone interval.  Other forms of well-know regularization methods were applied to the non-recurrent connections, input, output and embedding matrices.  \n\nAs the authors point out, all the methods used in this paper have been proposed before and theoretical convergence explained. The novelty of this work lies in its successful application to the language modeling task achieving state-of-the-art results.\n\nOn the PTB task, the proposed AWD-LSTM achieves a perplexity of 57.3 vs 58.3 (Melis et al 2017) and almost the same perplexity as Melis et el. on the Wiki-Text2 task (65.8 vs 65.9).  The addition of a cache model provides significant gains on both tasks.   \n\nIt would be useful, if authors had explored the behavior of the  AWD-LSTM algorithm with respect to various hyper parameters  and provided a few insights towards their choices for other large vocabulary language modeling tasks (1 million vocabulary sizes).  \n\nSimilarly, the choice of the average trigger and number of cycles seem arbitrary -  it would have been good to see a graph over a range of values, showing their impact on the model's performance.\n\nA 3-layer LSTM has been used for the experiments  - how was this choice made?  What is the impact of this algorithm if the net was a 2-layer net as is typical in most large-scale LMs?\n\nTable 3 is interesting to see how the cache model helps with rare words  and as such has applications in key word spotting tasks. Were the hyper parameters of the cache tuned to perform better on rare words?  More details on the design of the cache model would have been useful.\n\nYou state that the gains obtained using the cache model were far less than what was obtained in Graves et al 2016 - what do you attribute this to?\n\nAblation analysis in Table 4 is very useful - in particular it shows how lack of regularization of the recurrent connections can lead to maximum degradation in performance.\n\nMost of the results in this paper have been based on one choice of various model parameters. Given the emperical nature of this work, it would have made the paper even clearer if an analysis of their choices were presented.  Overall, it would be beneficial to the MLP community to see this paper accepted in the conference.\n""]","[60, 80, 80]","[70, 70, 70]","[""The sentiment score is 60 (positive) because the reviewer starts by describing the paper as 'clearly presented' and notes that the techniques are 'reasonable' and 'appear to yield improvements'. This indicates a generally positive view of the paper. However, it's not extremely high as the reviewer also points out several areas for improvement or clarification. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing their comments as questions or suggestions rather than criticisms. Phrases like 'have the authors considered' and 'Can the authors provide' demonstrate a polite approach to feedback. The reviewer also acknowledges the positive aspects of the paper before moving on to more specific comments, which is a courteous approach in academic review."", ""The sentiment score is 80 because the review is largely positive. The reviewer states that the paper sets a new state of the art, is well-written, and easy to follow. They recommend acceptance, calling it a 'solid contribution'. The only criticism is minor, regarding the experimental methodology. The politeness score is 70 because the language is consistently respectful and constructive. The reviewer uses phrases like 'I would have liked to see' and 'could become even better' when suggesting improvements, rather than using harsh or demanding language. They also balance criticism with praise, acknowledging the paper's strengths throughout."", ""The sentiment score is 80 (positive) because the review begins by calling it a 'well-written paper' and praises its 'successful application' and 'state-of-the-art results'. The reviewer recommends acceptance and notes it would be 'beneficial to the MLP community'. The score is not 100 as the reviewer does suggest some improvements. The politeness score is 70 (polite) due to the use of respectful language throughout, such as 'it would be useful if' and 'it would have been good to see'. The reviewer offers constructive criticism in a non-confrontational manner. However, it's not 100 as the language, while polite, is not excessively formal or deferential.""]"
"['MemoryGAN is proposed to handle structural discontinuity (avoid unrealistic samples) for the generator, and the forgetting behavior of the discriminator. The idea to incorporate memory mechanism into GAN is interesting, and the authors make nice interpretation why this needed, and clearly demonstrate which component helps (including the connections to previous methods).   \n\nMy major concerns:\n\nFigure 1 is questionable in demonstrating the advantage of proposed MemoryGAN. My understanding is that four z\'s used in DCGAN and MemoryGAN are ""randomly sampled"" and fixed, interpolation is done in latent space, and propagate to x to show the samples.  Take MNIST for example, It can be seen that the DCGAN has to (1) transit among digits in different classes, while MemoryGAN only (2) transit among digits in the same class. Task 1 is significantly harder than task 2, it is not surprise that DCGAN generate unrealistic images. A better experiment is to fix four digits from different class at first, find their corresponding latent codes, do interpolation, and propagate back to sample space to visualize results. If the proposed technique can truly handle structural discontinuity, it will ""jump"" over the sample manifold from one class to another, and thus avoid unrealistic samples. Also, the current illustration also indicates that the generated samples by MemoryGAN is not diverse.\n\nIt seems the memory mechanism can bring major computational overhead, is it possible to provide the comparison on running time?\n\nTo what degree the MemoryGAN can handle structural discontinuity? It can be seen from Table 2 that larger improvement is observed when tested on a more diverse dataset. For example, the improvement gap from MNIST to CIFAR is larger. If the MemoryGAN can truly deal with structural discontinuity, the results on generating a wide range of different images for ImageNet may endow the paper with higher impact.\n\nThe authors should consider to make their code reproducible and public. \n\n\nMinor comments:\n\nIn Section 4.3, Please fix ""Results in 2"" as ""Results in Table 2"".\n\n\n', ""In summary, the paper introduces a memory module to the GANs to address two existing problems: (1) no discrete latent structures and (2) the forgetting problem. The memory provides extra information for both the generation and the discrimination, compared with vanilla GANs. Based on my knowledge, the idea is novel and the Inception Score results are excellent. However, there are several major comments should be addressed, detailed as follows:\n\n1. The probabilistic interpretation seems not correct.\n\nAccording to Eqn (1), the authors define the likelihood of a sample x given a slot index c as p(x|c=i) = N(q; K_i, sigma^2), where q is the normalized output of a network mu given x. It seems that this is not a well defined probability distribution because the Gaussian distribution is defined over the whole space while the support of q is restricted within a simplex due to the normalization. Then, the integral over x should be not equal to 1 and hence all of the probabilistic interpretation including the equations in the Section 3. and results in the Section 4.1. are not reliable. I'm not sure whether there is anything misunderstood because the writing of the Section 3 is not so clear. \n\n2. The writing of the Section 3 should be improved.\n\nCurrently, the Section 3 is not easy to follow for me due to the following reasons. First, there lacks a coherent description of the notations. For instance, what's the difference between x and x', used in Section 3.1.1 and 3.1.2 respectively? According to the paper, both denote a sample. Second, the setting is somewhat unclear. For example,  it is not natural to discuss the posterior without the clear definition of the likelihood in Eqn (1). Third, a lot of details and comparison with other methods should be moved to other parts and the summary of the each part should be stated explicitly and clearly before going into details.\n\n3. Does the large memory hurt the generalization ability of the GANs?\n\nFirst of all, I notice that the random noise is much lower dimensional than the memory, e.g. 2 v.s. 256 on affine-MNIST. Does such large memory hurt the generalization ability of GANs? I suspect that most of the information are stored in the memory and only small change of the training data is allowed. I found that the samples in Figure 1 and Figure 5 are very similar and the interpolation only shows a very small local subspace near by a training data, which cannot show the generalization ability. Also note that the high Inception Score cannot show the generalization ability as well because memorizing the training data will obtain the highest score. I know it's hard to evaluate a GAN model but I think the authors can at least show the nearest neighbors in the training dataset and the training data that maximizes the activation of the corresponding memory slot together with the generated samples to see the difference.\n\nBesides, personally speaking, Figure 1 is not so fair because a MemoryGAN only shows a very small local subspace near by a training data while the vanilla GAN shows a large subspace, making the quality of the generation different. The MemoryGAN also has failure samples in the whole latent space as shown in Figure 4.\n\nOverall, I think this paper is interesting but currently it does not reach the acceptance threshold.\n\nI change the rating to 6 based on the revised version, in which most of the issues are addressed."", '[Overview]\n\nIn this paper, the authors proposed a novel model called MemoryGAN, which integrates memory network with GAN. As claimed by the authors, MemoryGAN is aimed at addressing two problems of GAN training: 1) difficult to model the structural discontinuity between disparate classes in the latent space; 2) catastrophic forgetting problem during the training of discriminator about the past synthesized samples by the generator. It exploits the life-long memory network and adapts it to GAN. It consists of two parts, discriminative memory network (DMN) and Memory Conditional Generative Network (MCGN). DMN is used for discriminating input samples by integrating the memory learnt in the memory network, and MCGN is used for generating images based on random vector and the sampled memory from the memory network. In the experiments, the authors evaluated memoryGAN on three datasets, CIFAR-10, affine-MNIST and Fashion-MNIST, and demonstrated the superiority to previous models. Through ablation study, the authors further showed the effects of separate components in memoryGAN. \n\n[Strengths]\n\n1. This paper is well-written. All modules in the proposed model and the experiments were explained clearly. I enjoyed much to read the paper.\n\n2. The paper presents a novel method called MemoryGAN for GAN training. To address the two infamous problems mentioned in the paper, the authors proposed to integrate a memory network into GAN. Through memory network, MemoryGAN can explicitly learn the data distribution of real images and fake images. I think this is a very promising and meaningful extension to the original GAN. \n\n3. With MemoryGAN, the authors achieved best Inception Score on CIFAR-10. By ablation study, the authors demonstrated each part of the model helps to improve the final performance.\n\n[Comments]\n\nMy comments are mainly about the experiment part:\n\n1. In Table 2, the authors show the Inception Score of images generated by DCGAN at the last row. On CIFAR-10, it is ~5.35. As the authors mentioned, removing EM, MCGCN and Memory will result in a conventional DCGAN. However, as far as I know, DCGAN could achieve > 6.5 Inception Score in general.  I am wondering what makes such a big difference between the reported numbers in this paper and other papers?\n\n2. In the experiments, the authors set N = 16,384, and M = 512, and z is with dimension 16. I did not understand why the memory size is such large. Take CIFAR-10 as the example, its training set contains 50k images. Using such a large memory size, each memory slot will merely count for several samples. Is a large memory size necessary to make MemoryGAN work? If not, the authors should also show ablated study on the effect of different memory size; If it is true, please explain why is that. Also, the authors should mention the training time compared with DCGAN. Updating memory with such a large size seems very time-consuming.\n\n3. Still on the memory size in this model. I am curious about the results if the size is decreased to the same or comparable number of image categories in the training set. As the author claimed, if the memory network could learn to cluster training data into different category, we should be able to see some interesting results by sampling the keys and generate categoric images.\n\n4. The paper should be compared with InfoGAN (Chen et al. 2016), and the authors should explain the differences between two models in the related work. Similar to MemoryGAN, InfoGAN also did not need any data annotations, but could learn the latent code flexibly.\n\n[Summary]\n\nThis paper proposed a new model called MemoryGAN for image generation. It combined memory network with GAN, and achieved state-of-art performance on CIFAR-10. The arguments that MemoryGAN could solve the two infamous problem make sense. As I mentioned above, I did not understand why the authors used such large memory size. More explanations and experiments  should be conducted to justify this setting. Overall, I think MemoryGAN opened a new direction of GAN and worth to further explore.\n\n']","[-20, -20, 70]","[60, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting idea and clear demonstration of the MemoryGAN approach, they express 'major concerns' about the experimental design and results interpretation. The reviewer questions the validity of Figure 1 and suggests alternative experiments, indicating skepticism about the claimed advantages. They also request additional comparisons and express doubts about the method's ability to handle structural discontinuity on more complex datasets.\n\nThe politeness score is moderately positive (60) as the reviewer uses respectful and constructive language throughout. They begin by acknowledging the interesting aspects of the work and provide detailed explanations for their concerns. The use of phrases like 'My understanding is...' and 'The authors should consider...' maintains a polite tone while offering criticism. The reviewer also provides specific suggestions for improvement rather than just pointing out flaws."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's novelty and excellent results, they also point out several major issues and ultimately conclude that the paper 'does not reach the acceptance threshold.' However, the final sentence indicates a slight improvement after revision, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positives before critiques, and uses phrases like 'I'm not sure whether there is anything misunderstood' and 'personally speaking' to soften criticisms. The reviewer also provides detailed, constructive feedback rather than dismissive comments, which contributes to the polite tone."", ""The sentiment score is 70 (positive) because the reviewer expresses overall positive sentiment towards the paper. They mention enjoying reading it, praising its clarity, and acknowledging the novelty and promise of the proposed method. The reviewer also highlights the paper's strengths and its achievement of state-of-the-art performance. However, it's not a perfect 100 as they do raise some questions and suggest areas for improvement.\n\nThe politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They begin with positive comments, use phrases like 'I enjoyed much to read the paper', and frame their criticisms as questions or suggestions rather than direct criticisms. The tone is professional and courteous, offering a balanced view of the paper's strengths and areas for improvement. The reviewer also uses phrases like 'I am wondering' and 'I am curious about' which maintain a polite, inquisitive tone rather than a demanding one.""]"
"['The authors of this manuscript transformed the k-mer representation of DNA fragments to a 2D image representation using the space-filling Hilbert curves for the classification of chromatin occupancy. In generally, this paper is easy to read. The components of the proposed model mainly include Hilbert curve theory and CNN which are existing technologies. But the authors make their combination useful in applications. Some specific comments are:\n\n1. In page 5, I could not understand the formula d_kink < d_out. d_link ;\n2. There may exist some new histone modification data that were captured by the next-generation sequencing (e.g. ChIP-seq) and are more accurate;  \n3. It seems that the authors treat it as a two-class problem for each data set. It would be more useful in real applications if all the data sets are combined to form a multi-class problem.\n', 'There are functional elements attached on the DNA sequence, such as transcription factors and different kinds of histones as stated in this ms. A hidden assumption is that the binding sites of these functional elements over the genome share some common features. It is therefore biologically interesting to predict if a new DNA sequence could be a binding site. Naturally this is is classification problem where the input is the DNA sequence and the output is whether the give sequence is a binding site.\n\nThis ms makes a novel way to transform the DNA sequence into a 3-dimensional tensor which could be easily utilised by CNN for images. The DNA sequence is first made into a a list of 4-mers. Then then each 4-mer is coded as a 4^4=256 dimensional vector. The order of the 4-mers is then coded into a image using Hilbert curve which presumably has nice properties to keep spatial information.\n\nI am not familiar with neural networks and do not comment on the methods but rather from the application point of view. \n\nFirst to my best knowledge, it is still controversial if the binding sites of different histones carries special features. I mean it could be possible that the assumption I mentioned in the beginning may not hold for this special application, especially for human data. I feel this method is more suitable for transcription factor motif data. see https://www.nature.com/articles/nbt.3300\n\nSecond, the experiments data in 2005 is measured using microarray, which uses probes of 500bp long. But the whole binding site for a nucleosome (or histone complex) is 147bp, which is much shorter than the probe. Nowadays we have more accurate sequencing data for nucleosome (check https://www.ncbi.nlm.nih.gov/pubmed/26411474). I am not sure whether this result will generalised to some other similar dataset. \n\nThird, the results only list the accuracy, it will be interesting to see the proportion of false negatives.\n\nIn general I feel the transformation is quite useful, it nicely reserves the spatial information, also can be seen from the improved results over all datasets. The result, in my opinion, is not sufficient to support the assumption that we could predict the DNA structures solely base on the sequence.\n\n', 'Dear editors,\n\nthe authors addressed all of my comments and clearly improved their manuscript over multiple iterations. I therefore increased my rating from ‘6: Marginally above acceptance threshold’ to ‘7: Good paper, accept’.\nPlease note that the authors made important edits to their manuscript after the ICLR deadline and could hence not upload their most current version, which you can from https://file.io/WIiEw9. If you decided to publish the manuscript, I hence highly suggest using this (https://file.io/WIiEw9) version.\n\nBest,\n\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n\nThe authors present Hilbert-CNN, a convolutional neural network for DNA sequence classification. Unlike existing methods, their model does not use the raw one-dimensional (1D) DNA sequence as input, but two-dimensional (2D) images obtained by mapping sequences to images using spacing-filling Hilbert-Curves. They further present a model (Hilbert-CNN) that is explicitly designed for Hilbert-transformed DNA sequences. The authors show that their approach can increase classification accuracy and decrease training time when applied to predicting histone-modification marks and splice junctions. \n\nMajor comments\n=============\n1. The motivation of transforming sequences into images is unclear and claimed benefits are not sufficiently supported by experiments. The essence of deep neural networks is to learn a hierarchy of features from the raw data instead of engineering features manually. Using space filling methods such as Hilbert-curves to transform (DNA) sequences into images can be considered as unnecessary feature-engineering. \n\nThe authors claim that ‘CNNs have proven to be most powerful when operating on multi-dimensional input, such as in image classification’, which is wrong. Sequence-based convolutional and recurrent models have been successfully applied for modeling natural languages (translation, sentiment classification, …), acoustic signals (speech recognition, audio generation), or biological sequences (e.g. predicting various epigenetic marks from DNA as reviewed in Angermueller et al).    \n\nThey further claim that their method can ‘better take the spatial features of DNA sequences into account’ and  can better model ‘long-term interactions’ between distant regions. This is not obvious since Hilbert-curves map adjacent sequence characters to pixels that are close to each other as described by the authors, but distant characters to distant pixels. Hence, 2D CNN must be deep enough for modeling interactions between distant image features, in the same way as a 1D CNN.\n\nTransforming sequences to images has several drawbacks. 1) Since the resulting images have a small width and height but many channels, existing 2D CNNs such as ResNet or Inception can not be applied, which also required the authors to design a specific model (Hilbert-CNN). 2) Hilbert-CNN requires more memory due to empty image regions. 3) Due to the high number of channels, convolutional filters have more parameters. 4) The sequence-to-image transformation makes model-interpretability hard, which is in particular important in biology. For example, motifs of the first convolutional layers can not be interpreted as sequence motifs (as described in Angermueller et al) and it is unclear how to analyze the influence of sequence characters using attention or gradient-based methods.\n\nThe authors should more clearly motivate their model in the introduction, tone-down the benefit of sequence-to-image transformations, and discuss drawbacks of their model. This requires major changes of introduction and discussion.\n\n2. The authors should more clearly describe which and how they optimized hyper-parameters. The authors should optimize the most important hyper-parameters of their model (learning rate, batch size, weight decay, max vs. average pooling, ELU vs. ReLU, …) and baseline models on a holdout validation set. The authors should also report the validation accuracy for different sequence lengths, k-mer sizes, and space filling functions. Can their model be applied to longer sequences (>= 1kbp) which had been shown to improve performance (e.g. 10.1101/gr.200535.115)? Does Figure 4 show the performance on the training, validation, or test set?\n\n3. It is unclear if the performance gain is due the proposed sequence-to-image transformation, or due to the proposed network architecture (Hilbert-CNN). It is also unclear if Hilbert-CNNs are applicable to DNA sequence classification tasks beyond predicting chromatin states and splice junctions. To address these points, the authors should compare Hilbert-CNN to models of the same capacity (number of parameters) and optimize hyper-parameters (k-mer size, convolutional filter size, learning rate, …) in the same way as they did for Hilbert-CNN. The authors should report the number of parameters of all models (Hilbert-CNN, Seq-CNN, 1D-sequence-CNN (Table 5), and LSTM (Table 6), …) in an additional table. The authors should also compare Hilbert-CNN to the DanQ architecture on predicting epigenetic markers using the same dataset as reported in the DanQ publication (DOI: 10.1093/nar/gkw226). The authors should also compare Hilbert-CNNs to gapped-kmer SVM, a shallow model that had been successfully applied for genomic prediction tasks.\n\n4. The authors should report the AUC and area under precision-recall curve (APR) in additional to accuracy (ACC) in Table 3.\n\n5. It is unclear how training time was measured for baseline models (Seq-CNN, LSTM, …). The authors should use the same early stopping criterion as they used for training Hilber-CNNs. The authors should also report the training time of SVM and gkm-SVM (see comment 3) in Table 3.\n\n\nMinor comments\n=============\n1. The authors should avoid uninformative adjectives and clutter throughout the manuscript, for example ‘DNA is often perceived’, ‘Chromatin can assume’,  ‘enlightening’, ‘very’, ‘we first have to realize’, ‘do not mean much individually’, ‘very much like the tensor’, ‘full swing’, ‘in tight communication’, ‘two methods available in the literature’.\n\nThe authors should point out in section two that k-mers can be overlapping.\n\n2. Section 2.1: One-hot vectors is not the only way for embedding words. The authors should also mention Glove and word2vec. Similar approaches had been applied to protein sequences (DOI: 10.1371/journal.pone.0141287)\n\n3. The authors should more clearly describe how Hilbert-curves map sequences to images and how images are cropped. What does ‘that is constructed in a recursive manner’ mean? Simply cropping the upper half of Figure 1c would lead to two disjoint sequences. What is the order of Figure 1e?\n\n4. The authors should consistently use ‘channels’ instead of ‘full vector of length’ to denote the dimensionality of image pixels.\n\n5. The authors should use ‘Batch norm’ instead of ‘BN’ in Figure 2 for clarification.\n\n6. Hilber-CNN is similar to ResNet (DOI: 10.1371/journal.pone.0141287), which consists of multiple ‘residual blocks’, where each block is a sequence of ‘residual units’. A ‘computational block’ in Hilbert-CNN contains two parallel ‘residual blocks’ (Figure 3) instead of a sequence of ‘residual units’. The authors should use ‘residual block’ instead of ‘computational block’, and ‘residual units’ as in the original ResNet publication. The authors should also motivate why two residual units/blocks are applied parallely instead of sequentially.\n\n7. Caption table 1: the authors should clarify if ‘Output size’ is ‘height, width, channels’, and explain the notation in ‘Description’ (or refer to the text.)']","[50, 20, 50]","[70, 60, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer starts with a neutral description of the paper's content, then mentions that it's 'easy to read' and that the authors make existing technologies 'useful in applications'. This indicates a generally positive view, though not overwhelmingly so. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively. They phrase their criticisms as 'specific comments' rather than harsh critiques, and use polite language like 'It would be more useful' instead of demanding changes. The reviewer maintains a professional and constructive tone throughout, which contributes to the high politeness score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and potential usefulness of the method, particularly in the transformation of DNA sequences into 3D tensors. They note improved results across datasets. However, they also express several concerns and limitations, which temper the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges their own limitations ('I am not familiar with neural networks'), and frames criticisms as suggestions or areas for improvement rather than outright dismissals. They use phrases like 'I feel' and 'it will be interesting to see' which maintain a collegial tone. The reviewer also provides helpful references to support their points, which is a courteous way to offer constructive criticism."", ""The sentiment score is 50 (moderately positive) because the reviewer starts by stating that the authors addressed all comments and improved the manuscript, leading to an increased rating. However, the review then lists several major comments and criticisms, balancing out the initial positivity. The politeness score is 60 (somewhat polite) because the reviewer uses respectful language throughout, such as 'Dear editors' and 'The authors present', and offers constructive criticism. However, the tone remains professional rather than overtly friendly. The reviewer also uses some direct language when pointing out flaws, such as 'which is wrong' and 'This is not obvious', which slightly reduces the politeness score.""]"
"['This paper introduces a new exploration policy for Reinforcement Learning for agents on the web called ""Workflow Guided Exploration"". Workflows are defined through a DSL unique to the domain.\n\nThe paper is clear, very well written, and well-motivated. Exploration is still a challenging problem for RL. The workflows remind me of options though in this paper they appear to be hand-crafted. In that sense, I wonder if this has been done before in another domain. The results suggest that WGE sometimes helps but not consistently. While the experiments show that DOMNET improves over Shi et al, that could be explained as not having to train on raw pixels or not enough episodes.', 'SUMMARY\n\nThe paper deals with the problem of training RL algorithms from demonstration and applying them to various web interfaces such as booking flights.  Specifically, it is applied to the Mini world of Bids benchmark (http://alpha.openai.com/miniwob/).\n\nThe difference from existing work is that rather than training an agent to directly mimic the demonstrations, it uses demonstrations to constrain exploration. By pruning away bad exploration directions. \n\nThe idea is to  build a lattice of workflows from demonstration and randomly sample sequence of actions from this lattice that satisfy the current goal.    Use the sequences of actions to sample trajectories and use the trajectories to learn the RL policy.\n\n\n\nCOMMENTS\n\n\nIn effect, the workflow sequences provide more generalization than simply mimicking, but It not obvious, why they don’t run into overfitting problems.  However experimentally the paper performs better than the previous approach.\n\nThere is a big literature on learning from demonstrations that the authors could compare with, or explain why their work is different.  \n\nIn addition, they make general comparison to RL literature such as hierarchy rather than more concrete comparisons with the problem at hand (learning from demonstrations.)\n\nWhat does DOM stand for?  The paper is not self-contained.  For example, what does DOM stand for?  \n\n\nIn the results of table 1 and Figure 3.  Why more steps mean success?\n\nIn equation 4 there seems to exist an environment model.  Why do we need to use this whole approach in the paper then?  Couldn’t  we just do policy iteration?\n', 'Summary:\n\nThe authors propose a method to make exploration in really sparse reward tasks more efficient. They propose a method called Workflow Guided Exploration (WGE) which is learnt from demonstrations but is environment agnostic. Episodes are generated by first turning demonstrations to a workflow lattice. This lattice encodes actions which are in some sense similar to those in the demonstration. By rolling out episodes which are randomly sampled from this set of similar actions for each encountered state, it is claimed that other methods like Behavor Cloning + RL (BC-then-RL) can be outperformed in terms of number of sample complexity since high reward episodes can be sampled with much higher probability.\n\nA novel NN architecture (DOMNet) is also presented which can embed structured documents like HTML webpages.\n\nComments:\n\n- The paper is well-written and relevant literature is cited and discussed.\n- My main concern is that while imitation learning and inverse reinforcement learning are mentioned and discussed in related work section as classes of algorithms for incorporating prior information there is no baseline experiment using either of these methods. Note that the work of Ross and Bagnell, 2010, 2011 (cited in the paper) establish theoretically that Behavior Cloning does not work in such situations due to the non-iid data generation process in such sequential decision-making settings (the mistakes grow quadratically in the length of the horizon). Their proposed algorithm DAgger fixes this (the mistakes by the policy are linear in the horizon length) by using an iterative procedure where the learnt policy from the previous iteration is executed and expert demonstrations on the visited states are recorded, the new data thus generated is added to the previous data and a new policy retrained. Dagger and related methods like Aggrevate provide sample-efficient ways of exploring the environment near where the initial demonstrations were given. WGE is aiming to do the same: explore near demonstration states.\n- The problem with putting in the replay buffer only episodes which yield high reward is that extrapolation will inevitably lead the learnt policy towards parts of the state space where there is actually low reward but since no support is present the policy makes such mistakes. \n- Therefore would be good to have Dagger or a similar imitation learning algorithm be used as a baseline in the experiments.\n- Similar concerns with IRL methods not being used as baselines.\n\nUpdate: Review score updated after discussion with authors below. \n']","[50, -20, -20]","[80, 20, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer starts with positive comments about the paper being 'clear, very well written, and well-motivated.' However, they also express some doubts and criticisms, such as questioning if this approach has been done before and noting that the results are not consistently beneficial. This mix of positive and critical comments suggests a moderately positive sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting their concerns. They phrase their criticisms as questions or observations rather than direct attacks, maintaining a professional and courteous tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'experimentally the paper performs better than the previous approach'), there are several critical comments and questions raised. The reviewer points out missing comparisons, lack of self-containment, and questions the necessity of the approach. However, the tone is not entirely negative, as the reviewer seems interested in understanding the work better.\n\nThe politeness score is slightly positive (20) because the reviewer maintains a professional and neutral tone throughout. They don't use harsh language or direct criticisms, instead framing their concerns as questions or suggestions (e.g., 'There is a big literature on learning from demonstrations that the authors could compare with'). The reviewer also acknowledges the paper's experimental success. However, the review doesn't go out of its way to be overtly polite or complimentary, hence the moderate positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is well-written and relevant literature is cited and discussed'), they express several concerns about the methodology and lack of certain baseline comparisons. The reviewer's main critique is the absence of imitation learning and inverse reinforcement learning baselines, which they consider important for a fair comparison.\n\nThe politeness score is relatively high (70) because the reviewer uses respectful and professional language throughout. They begin with positive comments and frame their criticisms as 'concerns' rather than outright flaws. The tone is constructive, suggesting improvements rather than dismissing the work. Phrases like 'would be good to have' indicate polite suggestions rather than demands.\n\nOverall, the review maintains a balance between highlighting the paper's strengths and pointing out areas for improvement, using language that is consistently professional and courteous.""]"
"[""The authors present an in-depth study of discretizing / quantizing the input as a defense against adversarial examples. The idea is that the threshold effects of discretization make it harder to find adversarial examples that only make small alterations of the image, but also that it introduces more non-linearities, which might increase robustness. In addition, discretization has little negative impact on the performance on clean data. The authors also propose a version of single-step or multi-step attacks against models that use discretized inputs, and present extensive experiments on MNIST, CIFAR-10, CIFAR-100 and SVHN, against standard baselines and, on MNIST and CIFAR-10, against a version of quantization in which the values are represented by a small number of bits.\n\nThe merits of the paper is that the study is rather comprehensive: a large number of datasets were used, two types of discretization were tried, and the authors propose an attack mechanism better that seems reasonable considering the defense they consider. The two main claims of the paper, namely that discretization doesn't hurt performance on natural test examples and that better robustness (in the author's experimental setup) is achieved through the discretized encoding, are properly backed up by the experiments.\n\nYet, the applicability of the method in practice is still to be demonstrated. The threshold effects might imply that small perturbations of the input (in the l_infty sense) will not have a large effect on their discritized version, but it may also go the other way: an opponent might be able to greatly change the discretized input without drastically changing the input. Figure 8 in the appendix is a bit worrysome on that point, as the performance of the discretized version drops rapidly to 0 when the opponents gets a bit stronger. Did the authors observe the same kind of bahavior on other datasets? What would the authors propose to mitigate this issue? To what extend the good results that are exhibited in the paper are valid over the wide range of opponent's strengths?\n\nminor comment:\n- the experiments on CIFAR-100 in Appendix E are carried out by mixing adversarial / clean examples while training, whereas those on SVHN in Appendix F use adversarial examples only.\n"", 'This is a beautiful work that introduces both (1) a novel way of defending against adversarial examples generated in a black-box or white-box setting, and (2) a principled attack to test the robustness of defenses based on discretized input domains. Using a binary encoding of the input to reduce the attack surface is a brilliant idea. Even though the dimensionality of the input space is increased, the intrinsic dimensionality of the data is drastically reduced. The direct relationship between robustness to adversarial examples and intrinsic dimensionality is well known (paper by Fawzi.). This article exploits this property nicely by designing an encoding that preserves pairwise distances by construction. It is well written overall, and the experiments support the claims of the authors. \n\nThis work has a crucial limitation: scalability.\nThe proposed method scales the input space dimension linearly with the number of discretization steps. Consequently, it has a significant impact on the number of parameters of the model when the dimensionality of the inputs is large. All the experiments in the paper report use relatively small dimensional datasets. For larger input spaces such as Imagenet, the picture could be entirely different:\n\n\t- How would thermometer encoding impact the performance on clean examples for larger dimensionality data (e.g., Imagenet)?\n\t- Would the proposed method be significantly different from bit depth reduction in such setting? \n\t- What would be the impact of the hyper-parameter k in such configuration?\n\t- Would the proposed method still be robust to white box attack?\n\t- The DGA and LS-PGA attacks look at all buckets that are\nwithin ε of the actual value, at every step. Would this be feasible in a large dimensional setting? More generally, would the resulting adversarial training technique be practically possible?\n\nWhile positive results on Imagenet would make this work a home run,  negative results would not affect the beauty of the proposal and would shed critical light on the settings in which thermometer encoding is applicable. I lean on the accept side, and I am willing to increase the score greatly if the above questions are answered.', 'This paper studies input discretization and white-box attacks on it to make deep networks robust to adversarial examples. They propose one-hot and thermometer encodings as input discretization and  \nalso propose DGA and LS-PGA as white-box attacks on it.\nRobustness to adversarial examples for thermometer encoding is demonstrated through experiments.\n\nThe empirical fact that thermometer encoding is more robust to adversarial examples than one-hot encoding,\nis interesting. The reason why thermometer performs better than one-hot should be pursued more.\n\n[Strong points]\n* Propose a new type of input discretization called thermometer encodings.\n* Propose new white-box attacks on discretized inputs.\n* Deep networks with thermometer encoded inputs empirically have higher accuracy on adversarial examples.\n\n[Weak points]\n* No theoretical guarantee for thermometer encoding inputs.\n* The reason why thermometer performs better than one-hot has not unveiled yet.\n\n[Detailed comments]\nThermometer encodings do not preserve pairwise distance information.\nConsider the case with b_1=0.1, b_2=0.2, b_3=0.3, b_4=0.4 and x_i=0.09, x_j=0.21 and x_k=0.39.\nThen, 0.12=|x_j-x_i|<|x_k-x_j|=0.18 but ||tau(b(x_i))-tau(n(x_j))||_2=sqrt(2)>1=||tau(b(x_k))-tau(n(x_j))||_2.']","[50, 60, 50]","[70, 80, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the merits of the paper, praising its comprehensive study and properly backed claims. However, they also express concerns about the practical applicability of the method and raise questions about potential issues. This balanced view indicates a moderately positive sentiment. The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively and framing criticisms as questions or suggestions rather than direct attacks. They use phrases like 'The merits of the paper is...' and 'Did the authors observe...' which maintain a courteous tone. The minor comment at the end is presented neutrally without any harsh criticism."", ""The sentiment score is 60 (positive) because the reviewer starts by calling it a 'beautiful work' and praising the novel ideas and principles. They mention it's 'well written' and that experiments support the claims. However, the score is not higher due to the 'crucial limitation' of scalability mentioned and the several questions raised about its applicability to larger datasets. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, praising the work's strengths before discussing limitations. They frame criticisms as questions rather than direct criticisms, and use phrases like 'I lean on the accept side' to soften their overall stance. The tone is constructive and encouraging, even when pointing out potential issues."", 'The sentiment score is 50 (slightly positive) because the review acknowledges both strong and weak points of the paper. It praises the novelty of the proposed methods and the empirical results, but also points out the lack of theoretical guarantees and unexplained aspects. The overall tone is constructive and interested in the work.\n\nThe politeness score is 75 (quite polite) because the reviewer uses neutral, professional language throughout. They present their comments in an organized manner (strong points, weak points, detailed comments) without using harsh or critical language. The reviewer acknowledges the interesting aspects of the work and suggests areas for improvement in a respectful manner.']"
"['The submitted manuscript describes an exercise in performance comparison for neural language models under standardization of the hyperparameter tuning and model selection strategies and costs.  This type of study is important to give perspective to non-standardized performance scores reported across separate publications, and indeed the results here are interesting as they favour relatively simpler structures.\n\nI have a favourable impression of this paper but would hope another reviewer is more familiar with the specific application domain than I am.', ""The authors did extensive tuning of the parameters for several recurrent neural architectures. The results are interesting. However the corpus the authors choose are quite small, the variance of the estimate will be quite high, I suspect whether the same conclusions could be drawn.\n\nIt would be more convincing if there are experiments on the billion word corpus or other larger datasets, or at least on a corpus with 50 million tokens. This will use significant resources and is much more difficult, but it's also really valuable, because it's much more close to real world usage of language models. And less tuning is needed for these larger datasets. \n\nFinally it's better to do some experiments on machine translation or speech recognition and see how the improvement on BLEU or WER could get. "", 'The authors perform a comprehensive validation of LSTM-based word and character language models, establishing that recent claims that other structures can consistently outperform the older stacked LSTM architecture result from failure to fully explore the hyperparameter space. Instead, with more thorough hyperparameter search, LSTMs are found to achieve state-of-the-art results on many of these language modeling tasks.\nThis is a significant result in language modeling and a milestone in deep learning reproducibility research. The paper is clearly motivated and authoritative in its conclusions but it\'s somewhat lacking in detailed model or experiment descriptions.\n\nSome further points:\n\n- There are several hyperparameters set to the ""standard"" or ""default"" value, like Adam\'s beta parameter and the batch size/BPTT length. Even if it would be prohibitive to include them in the overall hyperparameter search, the community is curious about their effect and it would be interesting to hear if the authors\' experience suggests that these choices are indeed reasonably well-justified.\n\n- The description of the model is ambiguous on at least two points. First, it wasn\'t completely clear to me what the down-projection is (if it\'s simply projecting down from the LSTM hidden size to the embedding size, it wouldn\'t represent a hyperparameter the tuner can set, so I\'m assuming it\'s separate and prior to the conventional output projection). Second, the phrase ""additive skip connections combining outputs of all layers"" has a couple possible interpretations (e.g., skip connections that jump from each layer to the last layer or (my assumption) skip connections between every pair of layers?).\n\n- Fully evaluating the ""claims of Collins et al. (2016), that capacities of various cells are very similar and their apparent\ndifferences result from trainability and regularisation"" would likely involve adding a fourth cell to the hyperparameter sweep, one whose design is more arbitrary and is neither the result of human nor machine optimization.\n\n- The reformulation of the problem of deciding embedding and hidden sizes into one of allocating a fixed parameter budget towards the embedding and recurrent layers represents a significant conceptual step forward in understanding the causes of variation in model performance.\n\n- The plot in Figure 2 is clear and persuasive, but for reproducibility purposes it would also be nice to see an example set of strong hyperparameters in a table. The history of hyperparameter proposals and their perplexities would also make for a fantastic dataset for exploring the structure of RNN hyperparameter spaces. For instance, it would be helpful for future work to know which hyperparameters\' effects are most nearly independent of other hyperparameters.\n\n- The choice between tied and clipped (Sak et al., 2014) LSTM gates, and their comparison to standard untied LSTM gates, is discussed only minimally, although it represents a significant difference between this paper and the most ""standard"" or ""conventional"" LSTM implementation (e.g., as provided in optimized GPU libraries). In addition to further discussion on this point, this result also suggests evaluating other recently proposed ""minor changes"" to the LSTM architecture such as multiplicative LSTM (Krause et al., 2016)\n\n- It would also have been nice to see a comparison between the variational/recurrent dropout parameterization ""in which there is further sharing of masks between gates"" and the one with ""independent noise for the gates,"" as described in the footnote. There has been some confusion in the literature as to which of these parameterizations is better or more standard; simply justifying the choice of parameterization a little more would also help.']","[60, -20, 70]","[80, 50, 80]","[""The sentiment score is 60 (positive) because the reviewer expresses a 'favourable impression' of the paper and notes that the results are 'interesting'. They also highlight the importance of the study. However, it's not extremely positive as they suggest another reviewer might be more suitable. The politeness score is 80 (quite polite) due to the respectful and constructive tone throughout. The reviewer acknowledges the paper's value and expresses their limitations politely. They use phrases like 'I have a favourable impression' and 'would hope' which are courteous ways of providing feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the extensive work and interesting results, they express significant concerns about the small corpus size and the validity of the conclusions. The reviewer suggests major improvements, indicating that the current work is not entirely satisfactory. The politeness score is moderately positive (50) as the reviewer uses respectful language, acknowledges the authors' efforts, and provides constructive feedback. They use phrases like 'It would be more convincing' and 'it's better to' rather than using harsh or demanding language. The reviewer also recognizes the difficulty of the suggested improvements, which adds to the politeness."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'significant' and 'a milestone', praising its comprehensive validation and authoritative conclusions. However, it's not 100 as the reviewer also points out some lacking aspects. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. The reviewer acknowledges the paper's strengths before delving into areas for improvement, and uses phrases like 'it would be interesting' and 'it would be nice' when making suggestions, indicating a polite and considerate tone.""]"
"['This work investigates sensitivity and generalisation properties of neural networks with respect to a number of metrics aimed at quantifying the robustness with respect to data variability, varying parameters and representativity of training/testing data. \nThe validation is based on the Jacobian of the network, and in the detection of the “transitions” associated to the data space. These measures are linked, as the former quantifies the sensitivity of the network respect to infinitesimal data variations, while the latter quantifies the complexity of the modelled data space. \nThe study explores a number of experimental setting, where the behaviour of the network is analysed on synthetic paths around training data, from pure random data points, to curves interpolating different/same data classes.\nThe experimental results are performed on CIFAR10,CIFAR100, and MNIST. Highly-parameterised networks seem to offer a better generalisation, while lower Jacobian norm are usually associated to better generalisation and fewer transitions, and can be obtained with data augmentation.\n\nThe paper proposes an interesting analysis aimed at the empirical exploration of neural network properties, the proposed metrics provide relevant insights to understand the behaviour of a network under varying data points. \n\nMajor remarks.\n\nThe proposed investigation is to my opinion quite controversial. Interesting data variation does not usually corresponds to linear data change. When considering the linear interpolation of training data, the authors are actually creating data instances not compatible with the original data source: for example, the pixel-wise intensity average of digits is not a digit anymore. For this reason, the conclusions drawn about the model sensitivity are to my opinion based a potentially uninteresting experimental context. Meaningful data variation can be way more complex and high-dimensional, for example by considering spatial warps of digits, or occlusions and superpositions of natural images. This kind of variability is likely to correspond to real data changes, and may lead to more reliable conclusions. For this reason, the proposed results may provide little indications of the true behaviour of the models data in case of meaningful  data variations. \n\nMoreover, although performed within a cross-validation setting, training and testing are still applied to the same dataset. Cross-validation doesn’t rule out validation bias, while it is also known that the classification performance significantly drops when applied to independent “unseen” data, provided for example in different cohorts. I would expect that highly parameterised models would lead to worse performance when applied to genuinely independent cohorts, and I believe that this work should extend the investigation to this experimental setting.\n\nMinor remarks.\n\nThe authors should revise the presentation of the proposed work. The 14 figures(!) of main text are not presented in the order of appearance. The main one (figure 1) is provided in the first paragraph of the introduction and never discussed in the rest of the paper. \n', ""This paper proposes an analysis of the robustness of deep neural networks with respect to data perturbations. \n\n*Quality*\nThe quality of exposition is not satisfactory. Actually, the paper is pretty difficult to evaluate at the present stage and it needs a drastic change in the writing style.\n\n*Clarity*\nThe paper is not clear and highly unstructured.\n\n*Originality* \nThe originality is limited for what regards Section 3: the proposed metrics are quite standard tools from differential geometry. Also, the idea of taking into account the data manifold is not brand new since already proposed in “Universal Adversarial Perturbation” at CVPR 2017.\n\n*Significance*\nDue to some flaws in the experimental settings, the relevance of the presented results is very limited. First, the authors essentially exploit a customized architecture, which has been broadly fine-tuned regarding hyper-parameters, gating functions and optimizers. Why not using well established architectures (such as DenseNets, ResNets, VGG, AlexNet)? \nMoreover, despite having a complete portrait of the fine-tuning process is appreciable, this compromises the clarity of the figures which are pretty hard to interpret and absolutely not self-explanatory: probably it’s better to only consider the best configuration as opposed to all the possible ones.\nSecond, authors assume that circular interpolation is a viable way to traverse the data manifold. The reviewer believes that it is an over-simplistic assumption. In fact, it is not guaranteed a priori that such trajectories are geodesic curves so, a priori, it is not clear why this could be a sound technique to explore the data manifold.\n\nCONS:\nThe paper is difficult to read and needs to be thoroughly re-organized. The problem is not stated in a clear manner, and paper’s contribution is not outlined. The proposed architectures should be explained in detail. The results of the sensitivity analysis should be discussed in detail. The authors should explain the approach of traversing the data manifold with ellipses (although the reviewer believes that such approach needs to be changed with something more principled). Figures and results are not clear.\nThe authors are kindly asked to shape their paper to match the suggested format of 8 pages + 1 of references (or similar). The work is definitely too long considered its quality. Additional plots and discussion can be moved to an appendix.\nDespite the additional explanation in Footnote 6, the graphs are not clear. Probably authors should avoid to present the result for each possible configuration of the hyper-parameters, gatings and optimizers and just choose the best setting.\nApart from the customized architecture, authors should have considered established deep nets, such as DenseNets, ResNets, VGG, AlexNet.\nThe idea of considering the data manifold within the measurement of complexity is a nice claim, which unfortunately is paired with a not convincing experimental analysis. Why ellipses should be a proper way to explore the data manifold? In general, circular interpolation is not guaranteed to be geodesic curves which lie on the data manifold.\n\nMinor Comments: \nSentence to rephrase: “We study common in the machine learning community ways to ...”\nPlease, put the footnotes in the corresponding page in which it is referred.\nThe reference to ReLU is trivially wrong and need to be changed with [Nair & Hinton ICML 2010]\n\n**UPDATED EVALUATION AFTER AUTHORS' REBUTTAL**\nWe appreciated the effort in providing specific responses and we also inspected the updated version of the paper. Unfortunately, despite the authors' effort, the reviewer deems that the conceptual issues that have been highlighted are still present in the paper which, therefore, is not ready for acceptance yet.   "", 'The authors have undertaken a large scale empirical evaluation on sensitivity and generalization for DNNs within the scope of image classification. They are investigating the suitability of the F-norm of the input-output Jacobian in large scale DNNs and they evaluate sensitivity and generalization metrics across the input space, both on and of the data manifold. They convincingly present strong empirical evidence for the F-norm of the Jacobian to be predictive and informative of generalization of the DNN within the image classification domain.\n\nThe paper is well written. The problem is clearly presented and motivated. Most potential questions of a reader as well as interesting details are supplied by footnotes and the appendix.\nThe contributions are to my knowledge both novel and significant.\nThe paper seem to be technically correct. The methodology and conclusions are reasonable.\nI believe that this is important work and applaud the authors for undertaking it. I hope that the interesting leads will be further investigated and that similar studies will be conducted beyond the scope of image classification. \'\nThe research and further investigations would be strengthened if they would include a survey on the networks presented in the literature in a similar manner as the authors did with the generated networks within the presented study. For example compare networks from benchmark competitions in terms of sensitivity and generalization using the metrics presented here.\n\nPlease define ""generalization gap"" and show how you calculate/estimate it. The term us used differently in much of the machine learning literature(?). Given this and that the usually sought after generalization error is unobtainable due to the unknown joint distribution over data and label, it is necessary to clarify the precise meaning of ""generalization gap"" and how you calculated it. I intuitively understand but I am not sure that the metric I have in mind is the same as the one you use. Such clarification will also improve the accessibility for a wider audience.\n\nFigure 4:\nI find Figure 4:Center a bit confusion. Is it there to show where on the x-axis of Figure 4:Top,the three points are located? Does this mean that the points are not located at pi/3, pi, 5pi/3 as indicated in the figure and the vertical lines of the figure grid? If it is not, then is it maybe possible to make the different sub-figure in Figure 4 more distinctive, as to not visually float into each other?\n\nFigure 5:\nThe figure makes me curious about what the regions look like close to the training points, which is currently hidden by the content of the inset squares. Maybe the square content can be made fully transparent so that only the border is kept? The three inset squares could be shown right below each sub-figure, aligned at the x-axis with the respective position of each of the data points.']","[-20, -80, 90]","[50, -20, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'interesting' and provides some positive feedback, they also express significant concerns about the methodology and conclusions. The reviewer states that the investigation is 'quite controversial' and that the conclusions may be based on 'potentially uninteresting experimental context'. They also suggest that the work should be extended to include additional experimental settings. These criticisms outweigh the initial positive remarks, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'to my opinion' when expressing criticisms, which softens the impact. The reviewer also balances negative feedback with positive acknowledgments of the work's interesting aspects. The language is not overly formal or polite, but it avoids any rudeness or harsh criticism, maintaining a constructive tone."", ""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer criticizes the paper's quality, clarity, originality, and significance. They use phrases like 'not satisfactory', 'difficult to evaluate', 'needs a drastic change', 'highly unstructured', 'originality is limited', and 'relevance of the presented results is very limited'. Even after the authors' rebuttal, the reviewer states the paper is 'not ready for acceptance yet'. The politeness score is -20 because while the reviewer uses some polite language ('kindly asked', 'appreciated the effort'), the overall tone is quite critical and direct. They use strong negative language without much softening, such as 'flaws', 'over-simplistic assumption', and 'trivially wrong'. The reviewer does not make much effort to balance negative feedback with positive comments, which contributes to the slightly impolite tone."", ""The sentiment score is 90 because the reviewer expresses strong positive sentiment throughout the review. They describe the paper as 'well written', the contributions as 'novel and significant', and state that 'this is important work' and they 'applaud the authors'. The only slight criticism is a request for additional clarification and suggestions for improvements, which is typical in peer reviews. The politeness score is 80 because the reviewer uses respectful and encouraging language throughout. They offer praise and constructive feedback in a polite manner, using phrases like 'I believe', 'I hope', and 'Please define'. The tone is professional and supportive, without any harsh or rude comments.""]"
"[""SUMMARY.\n\nThe paper presents a novel approach to procedural language understanding.\nThe proposed model reads food recipes and updates the representation of the entities mentioned in the text in order to reflect the physical changes of the entities in the recipe.\nThe authors also propose a manually annotated dataset where each passage of a recipe is annotated with entities, actions performed over the entities, and the change in state of the entities after the action.\nThe authors tested their model on the proposed dataset and compared it with several baselines.\n\n\n----------\n\nOVERALL JUDGMENT\nThe paper is very well written and easy to read.\nI enjoyed reading this paper, I found the proposed architecture very well thought for the proposed task.\nI would have liked to see a little bit more of analysis on the results, it would be interesting to see what are the cases the model struggles the most.\n\nI am wondering how the model would perform without intermediate losses i.e., entity selection loss and action selection loss.\nIt would also be interesting to see the impact of the amount of 'intermediate' supervision on the state change prediction.\n\nThe setup for generation is a bit unclear to me.\nThe authors mentioned to encode entity vectors with a biGRU, do the authors encode it in order of appearance in the text? would not it be better to encode the entities with some structure-agnostic model like Deep Sets?\n\n"", 'Summary\n\nThis paper presents Neural Process Networks, an architecture for capturing procedural knowledge stated in texts that makes use of a differentiable memory, a sentence and word attention mechanism, as well as learning action representations and their effect on entity representations. The architecture is tested for tracking entities in recipes, as well as generating the natural language description for the next step in a recipe. It is compared against a suit of baselines, such as GRUs, Recurrent Entity Networks, Seq2Seq and the Neural Checklist Model. While I liked the overall paper, I am worried about the generality of the model, the qualitative analysis, as well as a fair comparison to Recurrent Entity Networks and non-neural baselines.\n\nStrengths\n\nI believe the authors made a good effort in comparing against existing neural baselines (Recurrent Entity Networks, Neural Checklist Model) *for their task*. That said, it is unclear to me how generally applicable the method is and whether the comparison against Recurrent Entity Networks is fair (see Weaknesses).\nI like the ablation study.\n\nWeaknesses\n\nWhile I find the Neural Process Networks architecture interesting and I acknowledge that it outperforms Recurrent Entity Networks for the presented tasks, after reading the paper it is not clear to me how generally applicable the architecture is. Some design choices seem rather tailored to the task at hand (manual collection of actions MTurk annotation in section 3.1) and I am wondering where else the authors see their method being applied given that the architecture relies on all entities and actions being known in advance. My understanding is that the architecture could be applied to bAbI and CBT (the two tasks used in the Recurrent Entity Networks paper). If that is the case, a fair comparison to Recurrent Entity Networks would have been to test against Recurrent Entity Networks on these tasks too. If they the architecture cannot be applied in these tasks, the authors should explain why.\nI am not convinced by the qualitative analysis. Table 2 tells me that even for the best model the entity selection performance is rather unreliable (only 55.39% F1), yet all examples shown in Table 3 look really good, missing only the two entities oil (1) and sprinkles (3). This suggests that these examples were cherry-picked and I would like to see examples that are sampled randomly from the dev set. I have a similar concern regarding the generation task. First, it is not mentioned where the examples in Table 6 are taken from – is it the train, dev or test set? Second, the overall BLEU score seems quite low even for the best model, yet the examples in Table 6 look really good. In my opinion, a good qualitative analysis should also discuss failure cases. Since the BLEU score is so low here, you might also want to compare perplexity of the models.\nThe qualitative analysis in Table 5 is not convincing either. In Appendix A.1 it is mentioned that word embeddings are initialized from word2vec trained on the training set. My suspicion is that one would get the clustering in Table 4 already from those pretrained vectors, maybe even when pretrained on the Google news corpus. Hence, it is not clear what propagating gradients through the Neural Process Networks into the action embeddings adds, or put differently, why does it have to be a differentiable architecture when an NLP pipeline might be enough? This could easily be tested by another ablation where action embeddings are pretrained using word2vec and then fixed during training of the Neural Process Network. Moreover, in 3.3 it is mentioned that even the Action Selection is pretrained, which makes me wonder what is actually trained jointly in the architecture and what is not.\nI think the difficulty of the task at hand needs to be discussed at some point, ideally early in the paper. Until examples on page 7 are shown, I did not have a sense for why a neural architecture is chosen. For example, in 2.3 it is mentioned that for ""wash and cut"" the two functions fwash and fcut need to be selected. For this example, this seems trivial as the functions have the same name (and you could even have a function per name!). As far as I understand, the point of the action selector is to only have a fixed number of learned actions and multiple words (cut, slice etc.) should select the same action fcut. Otherwise (if there is little language ambiguity) I would not see the need for a complex neural architecture. Related to that, a non-neural baseline for the entity selection task that in my opinion definitely needs to be added is extracting entities using a pretrained NER system and returning all of them as the selection.\np2 Footnote 1: So if I understand this correctly, this work builds upon a dataset of over 65k recipes from Kiddon et al. (2016), but only for 875 of those detailed annotations were created?\n\nMinor Comments\n\np1: The statement ""most natural language understanding algorithms do not have the capacity …"" should be backed by reference.\np2: ""context representation ht"" – I would directly mention that this is a sentence encoding.\np3: 2.4: I have the impression what you are describing here is known in the literature as entity linking.\np3 Eq.3: Isn\'t c3*0 always a vector of zeros?\np4 Eq.6: W4 is an order-3 tensor, correct?\np4 Eq.8: What is YC and WC here and what are their dimensions? I am confused by the softmax, as my understanding (from reading the paragraph on the Action Selection Loss on p.5) was that the expression in the softmax here is a scalar (as it is done for every possible action), so this should be a sigmoid to allow for multiple actions to attain a probability of 1?\np5: ""See Appendix for details"" -> ""see Appendix C for details""\np5 3.3: Could you elaborate on the heuristic for extracting verb mentions? Is only one verb mention per sentence extracted?\np5: ""trained to minimize cross-entropy loss"" -> ""trained to minimize the cross-entropy loss""\np5 3.3: What is the global loss?\np6: ""been read (§2.5."" -> ""been read (§2.5).""\np6: ""We encode these vectors using a bidirectional GRU"" – I think you composing a fixed-dimensional vector from the entity vectors? What\'s eI?\np7: For which statement is (Kim et al. 2016) the reference? Surely, they did not invent the Hadamard product.\np8: ""Our model, in contrast"" use"" -> ""Our model, in contrast, uses"".\np8 Related Work: I think it is important to mention that existing architectures such as Memory Netwroks could, in principle, learn to track entities and devote part of their parameters to learn the effect of actions. What Neural Process Networks are providing is a strong inductive bias for tracking entities and learning the effect of actions that is useful for the task considered in this paper. As mentioned in the weaknesses, this might however come at the price of a less general model, which should be discussed.\n\n# Update after the rebuttal\nThanks for the clarifications and updating the paper. I am increasing my score by two points and expect to see the ablations as well as the NER baseline mentioned in the rebuttal in the next revision of the paper. Furthermore, I encourage the authors to include the analysis of pretrained word2vec embeddings vs the embeddings learned by this architecture into the paper. ', 'The paper studies procedural language, which can be very useful in applications such as robotics or online customer support. The system is designed to model knowledge of the procedural task using actions and their effect on entities. The proposed solution incorporates a structured representation of domain-specific knowledge that appears to improve performance in two evaluated tasks: tracking entities as the procedure evolves, and generating sentences to complete a procedure. The method is interesting and presents a good amount of evidence that it works, compared to relevant baseline solutions. \n\nThe proposed tasks of tracking entities and generating sentences are also interesting given the procedural context, and the authors introduce a new dataset with dense annotations for evaluating this task. Learning happens in a weakly supervised manner, which is very interesting too, indicating that the model introduces the right bias to produce better results.\n\nThe manual selection and curation of entities for the domain are reasonable assumptions, but may also limit the applicability or generality from the learning perspective. This selection may also explain part of the better performance, as the right bias is not just in the model, but in the construction of the ""ontologies"" to make it work.']","[80, -20, 80]","[90, 60, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses enjoyment in reading the paper, praises it as 'very well written and easy to read', and describes the proposed architecture as 'very well thought'. The reviewer also offers constructive suggestions for improvement, indicating overall positive sentiment with room for minor enhancements. The politeness score is 90 (very polite) due to the reviewer's use of respectful and encouraging language throughout. They begin with positive feedback, use phrases like 'I enjoyed reading this paper', and frame their suggestions as polite inquiries ('I am wondering...', 'It would be interesting to see...'). The reviewer maintains a professional and courteous tone while providing both praise and constructive feedback."", ""Sentiment score: The review expresses mixed feelings, with some positive aspects ('I liked the overall paper', 'I believe the authors made a good effort') but also significant concerns and weaknesses. The reviewer lists more weaknesses than strengths and expresses worry about several aspects of the paper. The overall tone leans slightly negative, hence a score of -20.\n\nPoliteness score: The reviewer maintains a professional and respectful tone throughout. They use polite phrases like 'I believe', 'I like', and 'I am not convinced' rather than harsh criticisms. They offer constructive feedback and suggestions for improvement. However, the review is not overly effusive or deferential, maintaining a balanced, objective tone. Therefore, a score of 60 is given for politeness.\n\nThe reasoning is based on a careful analysis of the language used, the balance of positive and negative comments, and the overall tone of the review."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe the work as 'very useful', 'interesting', and presenting 'a good amount of evidence'. The reviewer also praises the new dataset and the weakly supervised learning approach. The score is not 100 as there is a mild criticism about the manual selection of entities potentially limiting applicability. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout, focusing on the merits of the work. They offer constructive feedback without harsh criticism. The tone is consistently positive and encouraging, though not excessively formal or deferential, hence the score of 70 rather than 100.""]"
"['In their paper ""CausalGAN: Learning Causal implicit Generative Models with adv. training"" the authors address the following issue: Given a causal structure between ""labels"" of an image (e.g. gender, mustache, smiling, etc.), one tries to learn a causal model between these variables and the image itself from observational data. Here, the image is considered to be an effect of all the labels. Such a causal model allows us to not only sample from conditional observational distributions, but also from intervention distributions. These tasks are clearly different, as nicely shown by the authors\' example of ""do(mustache = 1)"" versus ""given mustache = 1"" (a sample from the latter distribution contains only men). The paper does not aim at learning causal structure from data (as clearly stated by the authors). The example images look convincing to me.\n\nI like the idea of this paper. IMO, it is a very nice, clean, and useful approach of combining causality and the expressive power of neural networks. The paper has the potential of conveying the message of causality into the ICLR community and thereby trigger other ideas in that area. For me, it is not easy to judge the novelty of the approach, but the authors list related works, none of which seems to solve the same task. The presentation of the paper, however, should be improved significantly before publication. (In fact, because of the presentation of the paper, I was hesitating whether I should suggest acceptance.) Below, I give some examples (and suggest improvements), but there are many others. There is a risk that in its current state the paper will not generate much impact, and that would be a pity. I would therefore like to ask the authors to put a lot of effort into improving the presentation of the paper. \n\n\n- I believe that I understand the authors\' intention of the caption of Fig. 1, but ""samples outside the dataset"" is a misleading formulation. Any reasonable model does more than just reproducing the data points. I find the argumentation the authors give in Figure 6 much sharper. Even better: add the expression ""P(male = 1 | mustache = 1) = 1"". Then, the difference is crystal clear.\n- The difference between Figures 1, 4, and 6 could be clarified.    \n- The list of ""prior work on learning causal graphs"" seems a bit random. I would add Spirtes et al 2000, Heckermann et al 1999, Peters et al 2016, and Chickering et al 2002. \n- Male -> Bald does not make much sense causally (it should be Gender -> Baldness)... Aha, now I understand: The authors seem to switch between ""Gender"" and ""Male"" being random variables. Make this consistent, please. \n- There are many typos and comma mistakes. \n- I would introduce the do-notation much earlier. The paragraph on p. 2 is now written without do-notation (""intervening Mustache = 1 would not change the distribution""). But this way, the statements are at least very confusing (which one is ""the distribution""?).\n- I would get rid of the concept of CiGM. To me, it seems that this is a causal model with a neural network (NN) modeling the functions that appear in the SCM. This means, it\'s ""just"" using NNs as a model class. Instead, one could just say that one wants to learn a causal model and the proposed procedure is called CausalGAN? (This would also clarify the paper\'s contribution.)\n- many realizations = one sample (not samples), I think. \n- Fig 1: which model is used to generate the conditional sample?  \n- The notation changes between E and N and Z for the noises. I believe that N is supposed to be the noise in the SCM, but then maybe it should not be called E at the beginning. \n- I believe Prop 1 (as it is stated) is wrong. For a reference, see Peters, Janzing, Scholkopf: Elements of Causal Inference: Foundations and Learning Algorithms (available as pdf), Definition 6.32. One requires the strict positivity of the densities (to properly define conditionals). Also, I believe the Z should be a vector, not a set. \n- Below eq. (1), I am not sure what the V in P_V refers to.\n- The concept of data probability density function seems weird to me. Either it is referring to the fitted model, then it\'s a bad name, or it\'s an empirical distribution, then there is no pdf, but a pmf.\n- Many subscripts are used without explanation. r -> real? g -> generating? G -> generating? Sometimes, no subscripts are used (e.g., Fig 4 or figures in Sec. 8.13)\n- I would get rid of Theorem 1 and explain it in words for the following reasons. (1) What is an ""informal"" theorem? (2) It refers to equations appearing much later. (3) It is stated again later as Theorem 2. \n- Also: the name P_g does not appear anywhere else in the theorem, I think. \n- Furthermore, I would reformulate the theorem. The main point is that the intervention distributions are correct (this fact seems to be there, but is ""hidden"" in the CIGN notation in the corollary).\n- Re. the formulation in Thm 2: is it clear that there is a unique global optimum (my intuition would say there could be several), thus: better write ""_a_ global minimum""?\n- Fig. 3 was not very clear to me. I suggest to put more information into its caption. \n- In particular, why is the dataset not used for the causal controller? I thought, that it should model the joint (empirical) distribution over the labels, and this is part of the dataset. Am I missing sth?\n- IMO, the structure of the paper can be improved. Currently, Section 3 is called ""Background"" which does not say much. Section 4 contains CIGMs, Section 5 Causal GANs, 5.1. Causal Controller, 5.2. CausalGAN, 5.2.1. Architecture (which the causal controller is part of) etc. An alternative could be: \nSec 1: Introduction \nSec 1.1: Related Work\nSec 2: Causal Models\nSec 2.1: Causal Models using Generative Models (old: CIGM)\nSec 3: Causal GANs\nSec 3.1: Architecture (including controller)\nSec 3.2: loss functions \n...\nSec 4: Empricial Results (old: Sec. 6: Results)\n- ""Causal Graph 1"" is not a proper reference (it\'s Fig 23 I guess). Also, it is quite important for the paper, I think it should be in the main part. \n- There are different references to the ""Appendix"", ""Suppl. Material"", or ""Sec. 8"" -- please be consistent (and try to avoid ambiguity by being more specific -- the appendix contains ~20 pages). Have I missed the reference to the proof of Thm 2?\n- 8.1. contains copy-paste from the main text.\n- ""proposition from Goodfellow"" -> please be more precise\n- What is Fig 8 used for? Is it not sufficient to have and discuss Fig 23? \n- IMO, Section 5.3. should be rewritten (also, maybe include another reference for BEGAN).\n- There is a reference to Lemma 15. However, I have not found that lemma.\n- I think it\'s quite interesting that the framework seems to also allow answering counterfactual questions for realizations that have been sampled from the model, see Fig 16. This is the case since for the generated realizations, the noise values are known. The authors may think about including a comment on that issue.\n- Since this paper\'s main proposal is a methodological one, I would make the publication conditional on the fact that code is released. \n\n\n', ""The paper describes a way of combining a causal graph describing the dependency structure of labels with two conditional GAN architectures (causalGAN and causalBEGAN) that generate  images conditioning on the binary labels. Ideally, this type of approach should allow not only to generate images from an observational distribution of labels (e.g. P(Moustache=1)), but also from unseen interventional distributions (e.g. P(Male=0 | do(Moustache =1)).\n\nMaybe I misunderstood something, but one big problem I have with the paper is that for a “causalGAN” approach it doesn’t seem to do much causality. The (known) causal graph is only used to model the dependencies of the labels, which the authors call the “Causal Controller”. On this graph, one can perform interventions and get a different distribution of labels from the original causal graph (e.g. a distribution of labels in which women have the same probability as men of having moustaches). Given the labels, the rest of the architecture are extensions of conditional GANs, a causalGAN with a Labeller and an Anti-Labeller (of which I’m not completely sure I understand the necessity) and an extension of a BEGAN. The results are not particularly impressive, but that is not an issue for me.\n\nMoreover sometimes the descriptions are a bit imprecise and unstructured. For example, Theorem 1 is more like a list of desiderata and it already contains a forward reference to page 7. The definition of intervention in the Background applies only to do-interventions (Pearl 2009) and not to general interventions (e.g. consider soft, uncertain or fat-hand interventions). \n\nOverall, I think the paper proposes some interesting ideas, but it doesn’t explore them yet in detail. I would be interested to know what happens if the causal graph is not known, and even worse cannot be completely identified from data (so there is an equivalence class of possible graphs), or potentially is influenced by latent factors. Moreover, I would be very curious about ways to better integrate causality and generative models, that don’t focus only on the label space. \n\n\nMinor details:\nPersonally I’m not a big fan of abusing colons (“:”) instead of points (“.”). See for example the first paragraph of the Related Work.\n\nEDIT: I read the author's rebuttal, but it has not completely addressed my concerns, so my rating has not changed."", 'This should be the first work which introduces in the causal structure into the GAN, to solve the label dependency problem. The idea is interesting and insightful. The proposed method is theoretically analyzed and experimentally tested.  Two minor concerns are 1) what is the relationship between the anti-labeler and and discriminator? 2) how the tune related weight of the different objective functions.  ']","[50, -20, 80]","[70, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses liking the idea of the paper and sees potential in it, but also has significant concerns about the presentation that need to be addressed. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. The reviewer also uses polite phrases like 'I would like to ask the authors' and 'please'. However, the extensive list of critiques and corrections keeps the politeness from being extremely high."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting ideas in the paper, they express significant concerns about the paper's approach to causality and the lack of detailed exploration of the proposed ideas. The reviewer points out several issues, such as the limited use of causality and imprecise descriptions, which contribute to the negative sentiment. However, the score is not deeply negative as the reviewer still finds some value in the paper's ideas.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'Maybe I misunderstood something' and 'I would be interested to know' which show consideration for the authors' perspective. The reviewer also balances criticism with positive remarks, such as acknowledging that the unimpressive results are 'not an issue' for them. The language is constructive rather than harsh, offering suggestions for improvement and areas of further exploration."", ""The sentiment score is 80 (positive) because the reviewer describes the work as 'interesting and insightful', and notes that it's the first to introduce causal structure into GAN to solve a specific problem. They also mention that the method is both theoretically analyzed and experimentally tested, which are positive aspects. The only slight negative is the mention of 'two minor concerns', but these are framed as questions rather than criticisms. The politeness score is 50 (somewhat polite) because the language is professional and respectful, with no harsh criticisms. The reviewer uses phrases like 'should be the first work' and 'the idea is interesting', which are polite ways of giving praise. The concerns are framed as questions rather than demands, which is a polite approach to giving feedback. However, the review doesn't go out of its way to be exceptionally polite, maintaining a neutral, professional tone overall.""]"
"['This paper builds on Binary-NET [Hubara et al. 2016] and expands it to CNN architectures. It also provides optimizations that substantially improve the speed of the forward pass: packing layer bits along the channel dimension, pre-allocation of CUDA resources and binary-optimized CUDA kernels for matrix multiplications. The authors compare their framework to BinaryNET and Nervana/Neon and show a 8x speedup for 8092 matrix-matrix multiplication and a 68x speedup for MLP networks. For CNN, they a speedup of 5x is obtained from the GPU to binary-optimizimed-GPU. A gain in memory size of 32x is also achieved by using binary weight and activation during the forward pass.\n\nThe main contribution of this paper is an optimized code for Binary CNN. The authors provide the code with permissive licensing. As is often the case with such comparisons, it is hard to disentangle from where exactly come the speedups. The authors should provide a table with actual numbers instead of the hard-to-read bar graphs. Otherwise the paper is well written and relatively clear, although the flow is somewhat unwieldy. \n\nOverall, i think it makes a good contribution to a field that is gaining importance for mobile and embedded applications of deep convnets. I think it is a good fit for a poster.', 'The paper presents a library written in C/CUDA that features all the functionalities required for the forward propagation of BCNNs. The library is significantly faster than existing implementations of optimized binary neural networks (≈ 2 orders of magnitude), and will be released on github.\n\nBCNNs have been able to perform well on large-scale datasets with increased speed and decreased  energy consumption, and implementing efficient kernels for them can be very useful for mobile applications. The paper describes three implementations CPU, GPU and GPU_opt, but it is not entirely clear what the differences are and why GPU_opt is faster than GPU implementation.\n\nAre BDNN and BCNN used to mean the same concept? If yes, could you please use only one of them?\n\nThe subsection title “Training Espresso” should be changed to “Converting a network to Espresso”, or “Training a network for Espresso”.\n\nWhat is the main difference between GPU and GPU_opt implementations?\n\nThe unrolling and lifting operations are shown in Figure 2. Isn’t accelerating convolution by this method a very well known one which is implemented in many deep learning frameworks for both CPU and GPU?\n\nWhat is the main contribution that makes the framework here faster than the other compared work? In Figure1, Espresso implementations are compared with other implementations in (a)dense binary matrix multiplication and (b)BMLP and not (c)BCNN. Can others ( BinaryNet\n(Hubara et al., 2016) or Intel Nervana/neon (NervanaSystems)) run CNNs?\n\n6.2 MULTI-LAYER PERCEPTRON ON MNIST – FIGURE 1B AND FIGURE 1E. It should be Figure 1d instead of 1e? \n\nAll in all, the novelty in this paper is not very clear to me. Is it bit-packing?\n\n\nUPDATE: \nThank you for the revision and clarifications. I increase my rating to 6.\n\n', 'The paper presents an implementation strategy (with code link anonymized for review) for fast computations of binary forward inference. The paper makes the approach seem straightforward (clever?) and there has been lots of work on fast inference of quantized, low-bit-width neural networks, but if indeed the implementation is significantly faster than commercial alternatives (e.g. from Intel) then I expect the authors have made a novel and useful contribution.\n\nThe paper is written clearly, but I am not an expert in alternative approaches in this area.']","[60, 20, 60]","[50, 60, 50]","[""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's contributions, noting it 'makes a good contribution to a field that is gaining importance' and recommends it for a poster presentation. The reviewer also praises the code provision and licensing. However, it's not extremely positive due to some criticisms about data presentation and paper flow. The politeness score is 50 (somewhat polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. The tone is professional and not overly formal or informal. The reviewer provides balanced feedback without harsh language, but also doesn't use explicitly polite phrases or compliments."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions, such as the library's speed and potential usefulness for mobile applications. However, they also express some concerns and ask for clarifications, indicating a mixed but generally positive sentiment. The initial paragraph highlights the paper's strengths, but subsequent paragraphs raise questions and point out areas for improvement. The final 'UPDATE' section indicates an increase in rating, further supporting a positive sentiment.\n\nThe politeness score is moderately high (60) because the reviewer uses respectful language throughout, phrasing criticisms as questions or suggestions rather than direct criticisms. They use phrases like 'could you please' and 'isn't it' to soften their inquiries. The reviewer also acknowledges the paper's strengths before diving into areas for improvement. The tone is professional and constructive throughout, without any harsh or rude language."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting that it presents a potentially novel and useful contribution, especially if the implementation is significantly faster than commercial alternatives. The reviewer also compliments the clarity of the paper. However, the score is not higher as the reviewer expresses some uncertainty and is not an expert in the field. The politeness score is 50 (somewhat polite) because the reviewer uses respectful language throughout, acknowledging the potential value of the work and the clarity of the writing. The tone is professional and constructive, without any harsh criticism. However, the review doesn't go out of its way to be exceptionally polite, maintaining a fairly neutral, objective tone overall.""]"
"[""This paper consolidates and builds on recent work on adversarial examples and adversarial training for image classification. Its contributions:\n\n - Making the connection between adversarial training and robust optimization more explicit.\n\n - Empirical evidence that:\n   * Projected gradient descent (PGD) (as proposed by Kurakin et al. (2016)) reasonably approximates the optimal attack against deep convolutional neural networks\n   * PGD finds better adversarial examples, and training with it yields more robust models, compared to FGSM \n\n - Additional empirical analysis:\n   * Comparison of weights in robust and non-robust MNIST classifiers\n   * Vulnerability of L_infty-robust models to to L_2-bounded attacks\n\nThe evidence that PGD consistently finds good examples is fairly compelling -- when initialized from 10,000 random points near the example to be disguised, it usually finds examples of similar quality. The remaining variance that's present in those distributions shouldn't hurt learning much, as long as a significant fraction of the adversarial examples are close enough to optimal.\n\nGiven the consistent effectiveness of PGD, using PGD for adversarial training should yield models that are reliably robust (for a specific definition of robustness, such as bounded L_infinity norm). This is an improvement over purely heuristic approaches, which are often less robust than claimed.\n\nThe comparison to R+FGSM is interesting, and could be extended in a few small ways. What would R+FGSM look like with 10,000 restarts? The distribution should be much broader, which would further demonstrate how PGD works better on these models. Also, when generating adversarial examples for testing, how well would R+FGSM work if you took the best of 2,000 random restarts? This would match the number of gradient computations required by PGD with 100 steps and 20 restarts. Again, I expect that PGD would be better, but this would make that point clearer. I think this analysis would make the paper stronger, but I don't think it's required for acceptance, especially since R+FGSM itself is such a recent development.\n\nOne thing not discussed is the high computational cost: performing a 40-step optimization of each training example will be ~40 times slower than standard stochastic gradient descent. I suspect this is the reason why there are results on MNIST and CIFAR, but not ImageNet. It would be very helpful to add some discussion of this.\n\nThe title seems unnecessarily vague, since many papers have been written with the same goal -- make deep learning models resistant to adversarial attacks. (This comment does not affect my opinion about whether or not the paper should be accepted, and is merely a suggestion for the authors.)\n\nAlso, much of the paper's content is in the appendices. This reads like a journal article where the references were put in the middle. I don't know if that's fixable, given conference constraints."", ""- The authors investigate a minimax formulation of deep network learning to increase their robustness, using projected gradient descent as the main adversary. The idea of formulating the threat model as the inner maximization problem is an old one. Many previous works on dealing with uncertain inputs in classification apply this minimax approach using robust optimization, e.g.: \n\nhttps://www2.eecs.berkeley.edu/Pubs/TechRpts/2003/CSD-03-1279.pdf\nhttp://www.jmlr.org/papers/volume13/ben-tal12a/ben-tal12a.pdf\n\nIn the case of convex uncertainty sets, many of these problems can be solved efficiently to a global minimum. Generalization bounds on the adversarial losses can also be proved. Generalizing this approach to non-convex neural network learning makes sense, even when it is hard to obtain any theoretical guarantees. \n\n- The main novelty is the use of projected gradient descent (PGD) as the adversary. From the experiments it seems training with PGD is very robust against a set of adversaries including fast gradient sign method (FGSM), and the method proposed in Carlini & Wagner (CW). Although the empirical results are promising, in my opinion they are not sufficient to support the bold claim that PGD is a 'universal' first order adversary (on p2, in the contribution list) and provides broad security guarantee (in the abstract). For example, other adversarial example generation methods such as DeepFool and Jacobian-based Saliency Map approach are missing from the comparison. Also it is not robust to generalize from two datasets MNIST and CIFAR alone.  \n\n- Another potential issue with using projected gradient descent as adversary is the quality of the adversarial example generated. The authors show empirically that PGD finds adversarial examples with very similar loss values on multiple runs. But this does not exclude the possibility that PGD with different step sizes or line search procedure, or the use of randomization strategies such as annealing, can find better adversarial examples under the same threat model. This could make the robustness of the network rather dependent on the specific implementation of PGD for the inner maximization problem. \n\n- In Tables 3, 4, and 5 in the appendix, in most cases models trained with PGD are more robust than models trained with FGSM as adversary, modulo the phenomenon of label leakage when using FGSM as attack. However in the bottom right corner of Table 4, FGSM training seems to be more robust than PGD training against black box PGD attacks. This raises the question on whether PGD is truly 'universal' and provides broad security guarantees, once we add more first order attacks methods to the mix. \n\n"", 'This paper proposes to look at making neural networks resistant to adversarial loss through the framework of saddle-point problems. They show that, on MNIST, a PGD adversary fits this framework and allows the authors to train very robust models. They also show encouraging results for robust CIFAR-10 models, but with still much room for improvement. Finally, they suggest that PGD is an optimal first order adversary, and leads to optimal robustness against any first order attack.\n\nThis paper is well written, brings new ideas and perfoms interesting experiments, but its claims are somewhat bothering me, considering that e.g. your CIFAR-10 results are somewhat underwhelming. All you\'ve really proven is that PGD on MNIST seems to be the ultimate adversary. You contrast this to the fact that the optimization is non-convex, but we know for a fact that MNIST is fairly simple in that regime; iirc a linear classifier gets something like 91% accuracy on MNIST. So my guess is that the optimization problem on MNIST is in fact pretty convex and mostly respects the assumptions of Danskin\'s theorem, but not so much for CIFAR-10 (maybe even less so for e.g. ImageNet, which is what Kurakin et al. seem to find).\n\nConsidering your CIFAR-10 results, I don\'t think anyone should ""suggest that secure neural networks are within reach"", because 1) there is still room for improvement 2) it\'s a safe bet that someone will always just come up with a better attack than whatever defense we have now. It has been this way in many disciplines (crypto, security) for centuries, I don\'t see why deep learning should be exempt. Simply saying ""we believe that our robust models are significant progress on the defense side"" was enough, because afaik you did improve on CIFAR-10\'s SOTA; don\'t overclaim. \nYou make these kinds of claims in a few other places in this paper, please be careful with that.\n\nThe contributions in your appendix are interesting. \nAppendix A somewhat confirms one of the postulates in Goodfellow et al. (2014): ""The direction of perturbation, rather than the specific point in space, matters most. Space is not full of pockets of adversarial examples that finely tile the reals like the rational numbers"".\nAppendix B and C are not extremely novel in my mind, but definitely add more evidence. \nAppendix E is quite nice since it gives an insight into what actually makes the model resistant to adversarial examples.\n\n\nRemarks:\n- The update for PGD should be using \\nabla_{x_t} L(\\theta,x_t,y), (rather than only \\nabla_x)?\n- In table 2, attacking a with 20-step PGD is doing better than 7-step.  When you say ""other hyperparameter choices didn’t offer a significant decrease in accuracy"", does that include the number of steps? If not why stop there? What happens for more steps? (or is it too computationally intensive?)\n- You only seem to consider adversarial examples created from your dataset + adv. noise. What about rubbish class examples? (e.g. rgb noise)\n']","[70, -20, 20]","[80, 50, 50]","[""The sentiment score is 70 (positive) because the reviewer provides mostly positive feedback about the paper's contributions and findings. They describe the evidence as 'compelling' and note improvements over previous approaches. The few criticisms are constructive and presented as suggestions rather than major flaws. The politeness score is 80 (polite) due to the reviewer's respectful and professional tone throughout. They use phrases like 'it would be very helpful' and 'I think this analysis would make the paper stronger' when offering suggestions, indicating a courteous approach. The reviewer also acknowledges that some suggestions are not required for acceptance, showing consideration for the authors' work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty and potential of the approach, they express several concerns and criticisms. They point out that the main idea is not entirely new, question the boldness of some claims, and highlight potential issues with the method. However, they also recognize the promising empirical results, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'in my opinion' and 'raises the question', which soften their criticisms. The reviewer also acknowledges the strengths of the work alongside the weaknesses, demonstrating a balanced and courteous approach to the review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is well-written, brings new ideas, and performs interesting experiments. However, they express concerns about some of the claims and results, particularly for CIFAR-10. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive criticism, and provides specific suggestions for improvement. They balance praise with critique and use phrases like 'please be careful' rather than harsh criticism. The reviewer also asks questions and offers insights, showing engagement with the work while maintaining a professional tone.""]"
"['This paper focuses on the problem of ""machine teaching"", i.e., how to select a good strategy to select training data points to pass to a machine learning algorithm, for faster learning. The proposed approach leverages reinforcement learning by defining the reward as how fast the learner learns, and use policy gradient to update the teacher parameters. I find the definition of the ""state"" in this case very interesting. The experimental results seem to show that such a learned teacher strategy makes machine learning algorithms learn faster. \n\nOverall I think that this paper is decent. The angle the authors took is interesting (essentially replacing one level of the bi-level optimization problem in machine teaching works with a reinforcement learning setup). The problem formulation is mostly reasonable, and the evaluation seems quite convincing. The paper is well-written: I enjoyed the mathematical formulation (Section 3). The authors did a good job of using different experiments (filtration number analysis, and teaching both the same architecture and a different architecture) to intuitively explain what their method actually does. \n\nAt the same time, though, I see several important issues that need to be addressed if this paper is to be accepted. Details below. \n\n1. As much as I enjoyed reading Section 3, it is very redundant. In some cases it is good to outline a powerful and generic framework (like the authors did here with defining ""teaching"" in a very broad sense, including selecting good loss functions and hypothesis spaces) and then explain that the current work focuses on one aspect (selecting training data points). However, I do not see it being the case here. In my opinion, selecting good loss functions and hypothesis spaces are much harder problems than data teaching - except maybe when one use a pre-defined set of possible loss functions and select from it. But that is not very interesting (if you can propose new loss functions, that would be way cooler). I also do not see how to define an intuitive set of ""states"" in that case. Therefore, I think this section should be shortened. I also think that the authors should not discuss the general framework and rather focus on ""data teaching"", which is the only focus of the current paper. The abstract and introduction should also be modified accordingly to more honestly reflect the current contributions. \n2. The authors should do a better job at explaining the details of the state definition, especially the student model features and the combination of data and current learner model. \n3. There is only one definition of the reward - related to batch number when the accuracy first exceeds a threshold. Is accuracy stable, can it drop back down below the threshold in the next epoch? The accuracy on a held-out test set is not guaranteed to be monotonically increasing, right? Is this a problem in practice (it seems to happen on your curves)? What about other potential reward definitions? And what would they potentially lead to? \n4. Experimental results are averaged over 5 repeated runs - a bit too small in my opinion. \n5. Can the authors show convergence of the teacher parameter \\theta? I think it is important to see how fast the teacher model converges, too. \n6. In some of your experiments, every training method converges to the same accuracy after enough training (Fig.2b), while in others, not quite (Fig. 2a and 2c). Why is this the case? Does it mean that you have not run enough iterations for the baseline methods? My intuition is that if the learner algorithm is convex, then ultimately they will all get to the same accuracy level, so the task is just to get there quicker. I understand that since the learner algorithm is an NN, this is not the case - but more explanation is necessary here - does your method also reduces the empirical possibility to get stuck in local minima? \n7. More explanation is needed towards Fig.4c. In this case, using a teacher model trained on a harder task (CIFAR10) leads to much improved student training on a simpler task (MNIST). Why?\n8. Although in terms of ""effective training data points"" the proposed method outperforms the other methods, in terms of time (Fig.5) the difference between it and say, NoTeach, is not that significant (especially at very high desired accuracy). More explanation needed here. \n\nRead the rebuttal and revision and slightly increased my rating.', 'This paper suggests a ""learning to teach"" framework. Following a similar intuition as self-paced learning and curriculum learning, the authors suggest to learn a teaching strategy,  corresponding to choices over the data presented to the learner (and potentially other decisions  about the learner, such as the  algorithm used).   The problem is framed as RL problem, where the state space corresponds to learning configurations, and teacher actions change the state.  Supervision is obtained by observing the learner\'s performance. \n\nI found it very difficult to understand the evaluation.  \nFirst, there is quite a bit of recent work on learning to teach and curriculum learning.  It would be helpful if there are comparisons to these models, and use similar datasets.  It\'s not clear if an evaluation on the MNIST data set is particularly meaningful.   The implementation of SPL seems to hurt performance in some cases (slower convergence on the IMDB dataset), can you explain it?  In other text learning task (e.g., [1]) SPL showed improved performance.   The results over the IMDB dataset in the original paper [2] are higher than the ones reported here, using a simple model (BoW). \nSecond, in non-convex problems, one can expect curriculum learning approaches to also perform better, not just converge faster.  This aspect is not really discussed.  Finally,  I\'m not sure I understand the X axis in Figure 2, the (effective) number of examples is much higher than the size of the dataset. Does it indicate the number of  iterations over the same dataset? \n\nI would also like to see some analysis of what\'s actually being learned by the teacher. Some qualitative analysis, or even feature ablation study would be helpful.\n\n[1] Easy Questions First? A Case Study on Curriculum Learning for Question Answering. Sachan et-al.\n[2] Learning Word Vectors for Sentiment Analysis. Maas et-al.', 'The authors define a deep learning model composed of four components:  a student model, a teacher model, a loss function, and a data set. The student model is a deep learning model (MLP, CNN, and RNN were used in the paper). The teacher model learns via reinforcement learning which items to include in each minibatch of the data set. The student model learns according to a standard stochastic gradient descent technique (Adam for MLP and CNN, Momentum-SGD for RNN), appropriate to the data set (and loss function), but only uses the data items of the minibatch chosen by teacher model. They evaluate that their method can learn to provide learning items in an efficient manner in two situations: (1) the same student model-type on a different part of the same data set, and (2) adapt the teaching model to teach a new model-type for a different data set. In both circumstances, they demonstrate the efficacy of their technique and that it performs better than other reasonable baseline techniques: self-paced learning, no teaching, and a filter created by randomly reordering the data items filtered out from a teaching model.\n\nThis is an extremely impressive manuscript and likely to be of great interest to many researchers in the ICLR community. The research itself seems fine, but there are some issues with the discussion of previous work. Most of my comments focuses on this.\n\nThe authors write that artificial intelligence has mostly overlooked the role of teaching, but this claim is incorrect. There is a long history of research on teaching in artificial intelligence. Two literatures of note are intelligent tutoring and machine teaching in the computational learnability literature. A good historical hook to intelligent tutoring is Anderson, J. R., Boyle, C. F., & Reiser, B. J. (1985). Intelligent tutoring systems. Science, 228. 456-462. The literature is still healthy today. One offshoot of it has its own society with conferences and a journal devoted to it (The International Artificial intelligence in Education Society: http://iaied.org/about/). \n\nFor the computational learnability literature, complexity analysis for teaching has a subliterature devoted to it (analogous to the learning literature). Here is a hook into that literature: Goldman, S., & Kerns. M. (1995). On the complexity of teaching. Journal of Computer and Systems Sciences, 50(1), 20-31.\n\nOne last related literature is pedagogical teaching from computational cognitive science. This one is a more recent development. Here are two articles, one that provides a long and thorough discussion that is a definitive start to the literature, and another that is most relevant to the current paper, on applying pedagogical teaching to inverse reinforcement learning (a talk at NIPS 2016).\n\nShafto, P., Goodman, N. D., & Griffiths, T. L. (2014). A rational account of pedagogical reasoning: Teaching by, and learning from, examples. Cognitive Psychology, 71, 55-89.\n\nHo, M. K., Littman, M., MacGlashan, J., Cushman, F., & Austerweil, J. L. (NIPS 2016). \n\nI hope all of this makes it clear to the authors that it is inappropriate to claim that artificial intelligence has “largely overlooked” or “largely neglected”. \n\nOne other paper of note given that the authors train a MLP is an optimal teaching analysis of a perceptron: (Zhang, Ohannessian, Sen, Alfeld, & Zhu, 2016; NIPS).\n\n\n']","[20, -20, 80]","[60, 50, 90]","[""The sentiment score is slightly positive (20) because the reviewer finds the paper 'decent' and acknowledges its interesting aspects, well-written mathematical formulation, and convincing evaluation. However, they also point out 'several important issues that need to be addressed,' which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'I enjoyed reading,' 'the authors did a good job,' and frame their criticisms as suggestions for improvement rather than harsh judgments. The reviewer maintains a professional tone, balancing praise with constructive feedback, which contributes to the polite impression."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution, they express significant concerns about the evaluation and understanding of the results. The reviewer finds it 'very difficult to understand the evaluation' and raises several questions and issues. However, the tone is not entirely negative, as they also offer suggestions for improvement. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, framing their concerns as questions or suggestions rather than direct criticisms. They use phrases like 'It would be helpful if...' and 'I would also like to see...', which maintain a constructive and polite tone even while expressing concerns. The reviewer also acknowledges the paper's basic premise and contribution at the beginning, which adds to the overall politeness."", ""The sentiment score is 80 (positive) because the reviewer describes the manuscript as 'extremely impressive' and 'likely to be of great interest to many researchers'. They state that 'the research itself seems fine', indicating overall approval. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, offers constructive criticism, and provides helpful suggestions and references. They phrase their concerns diplomatically, such as 'there are some issues with the discussion of previous work'. The reviewer also uses phrases like 'I hope all of this makes it clear' which shows a considerate tone. The high scores are not 100 because the reviewer does point out some flaws and disagrees with certain claims made by the authors, but does so in a very professional and courteous manner.""]"
"[""Overall: Authors defined a new learning task that requires a DNN to predict mixing ratio between sounds from two different classes. Previous approaches to training data mixing are (1) from random classes, or (2) from the same class. The presented approach mixes sounds from specific pairs of classes to increase discriminative power of the final learned network. Results look like significant improvements over standard learning setups.\n\nDetailed Evaluation: The approach presented is simple, clearly presented, and looks effective on benchmarks. In terms of originality, it is different from warping training example for the same task and it is a good extension of previously suggested example mixing procedures with a targeted benefit for improved discriminative power. The authors have also provided extensive analysis from the point of views (1) network architecture, (2) mixing method, (3) number of labels / classes in mix, (4) mixing layers -- really well done due-diligence across different model and task parameters.\n\nMinor Asks:\n(1) Clarification on how the error rates are defined. Especially since the standard learning task could be 0-1 loss and this new BC learning task could be based on distribution divergence (if we're not using argmax as class label).\n(2) #class_pairs targets as analysis - The number of epochs needed is naturally going to be higher since the BC-DNN has to train to predict mixing ratios between pairs of classes. Since pairs of classes could be huge if the total number of classes is large, it'll be nice to see how this scales. I.e. are we talking about a space of 10 total classes or 10000 total classes? How does num required epochs get impacted as we increase this class space?\n(3) Clarify how G_1/20 and G_2/20 is important / derived - I assume it's unit conversion from decibels.\n(4) Please explain why it is important to use the smoothed average of 10 softmax predictions in evaluation... what happens if you just randomly pick one of the 10 crops for prediction?"", 'This manuscript proposes a method to improve the performance of a generic learning method by generating ""in between class"" (BC) training samples. The manuscript motivates the necessity of such technique and presents the basic intuition. The authors show how the so-called BC learning helps training different deep architectures for the sound recognition task.\n\nMy first remark regards the presentation of the technique. The authors argue that it is not a data augmentation technique, but rather a learning method. I strongly disagree with this statement, not only because the technique deals exactly with augmenting data, but also because it can be used in combination to any learning method (including non-deep learning methodologies). Naturally, the literature review deals with data augmentation technique, which supports my point of view.\n\nIn this regard, I would have expected comparison with other state-of-the-art data augmentation techniques. The usefulness of the BC technique is proven to a certain extent (see paragraph below) but there is not comparison with state-of-the-art. In other words, the authors do not compare the proposed method with other methods doing data augmentation. This is crucial to understand the advantages of the BC technique.\n\nThere is a more fundamental question for which I was not able to find an explicit answer in the manuscript. Intuitively, the diagram shown in Figure 4 works well for 3 classes in dimension 2. If we add another class, no matter how do we define the borders, there will be one pair of classes for which the transition from one to another will pass through the region of a third class. The situation worsens with more classes. However, this can be solved by adding one dimension, 4 classes and 3 dimensions seems something feasible. One can easily understand that if there is one more class than the number of dimensions, the assumption should be feasible, but beyond it starts to get problematic. This discussion does not appear at all in the manuscript and it would be an important limitation of the method, specially when dealing with large-scale data sets.\n\nOverall I believe the paper is not mature enough for publication.\n\nSome minor comments:\n- 2.1: We introduce --> We discussion\n- Pieczak 2015a did not propose the extraction of MFCC.\n- the x_i and t_i of section 3.2.2 should not be denoted with the same letters as in 3.2.1.\n- The correspondence with a semantic feature space is too pretentious, specially since no experiment in this direction is shown.\n- I understand that there is no mixing in the test phase, perhaps it would be useful to recall it.', 'The propose data augmentation and BC learning is relevant, much robust than frequency jitter or simple data augmentation. \n\nIn equation 2, please check the measure of the mixture. Why not simply use a dB criteria ?\n\nThe comments about applying a CNN to local features or novel approach to increase sound recognition could be completed with some ICLR 2017 work towards injected priors using Chirplet Transform.\n\nThe authors might discuss more how to extend their model to image recognition, or at least of other modalities as suggested.\n\nSection 3.2.2 shall be placed later on, and clarified.\n\nDiscussion on mixing more than two sounds leads could be completed by associative properties, we think... ?\n']","[80, -60, 50]","[70, 20, 20]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, describing the approach as 'simple, clearly presented, and looks effective.' They also praise the 'extensive analysis' and 'due-diligence' of the authors. The minor asks are framed as requests for clarification rather than criticisms. The politeness score is 70 (polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'well done' and frames their requests as 'Minor Asks,' which is a polite way to suggest improvements. The language throughout is professional and courteous, without any harsh or rude expressions."", ""The sentiment score is -60 because the reviewer expresses several significant criticisms and concludes that the paper is 'not mature enough for publication'. They disagree with key claims, point out missing comparisons, and raise fundamental questions about the method's limitations. However, it's not entirely negative as they acknowledge some usefulness of the technique. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and offer constructive feedback. They use phrases like 'I would have expected' and 'I believe' to soften their critiques, and provide specific suggestions for improvement. The tone is firm but not rude, maintaining a respectful academic discourse."", ""The sentiment score is 50 (slightly positive) because the reviewer starts with a positive comment about the relevance and robustness of the proposed method. However, the rest of the review consists of suggestions for improvement, which tempers the overall positivity. The politeness score is 20 (slightly polite) because the reviewer uses neutral language and phrases suggestions as questions or possibilities ('could be', 'might discuss', 'shall be') rather than direct commands. The reviewer also acknowledges the authors' work positively. However, the brevity and directness of some comments prevent a higher politeness score.""]"
"['The fundamental contribution of the article is the explicit use of compositionality in the definition of the search space. Instead of merely defining an architecture as a Directed Acyclic Graph (DAG), with nodes corresponding to feature maps and edges to primitive operations, the approach in this paper introduces a hierarchy of architectures of this form. Each level of the hierarchy utilises the existing architectures in the preceding level as candidate operations to be applied in the edges of the DAG. As a result, this would allow the evolutionary search algorithm to design modules which might be then reused in different edges of the DAG corresponding to the final architecture, which is located at the top level in the hierarchy.\n\nManually designing novel neural architectures is a laborious, time-consuming process. Therefore, exploring new approaches to automatise this task is a problem of great relevance for the field. \n\nOverall, the paper is well-written, clear in its exposition and technically sound. While some hyperparameter and design choices could perhaps have been justified in greater detail, the paper is mostly self-contained and provides enough information to be reproducible. \n\nThe fundamental contribution of this article, when put into the context of the many recent publications on the topic of automatic neural architecture search, is the introduction of a hierarchy of architectures as a way to build the search space. Compared to existing work, this approach should emphasise modularity, making it easier for the evolutionary search algorithm to discover architectures that extensively reuse simpler blocks as part of the model. Exploiting compositionality in model design is not novel per se (e.g. [1,2]), but it is to the best of my knowledge the first explicit application of this idea in neural architecture search. \n\nNevertheless, while the idea behind the proposed approach is definitely interesting, I believe that the experimental results do not provide sufficiently compelling evidence that the resulting method substantially outperforms the non-hierarchical, flat representation of architectures used in other publications. In particular, the results highlighted in Figure 3 and Table 1 seem to indicate that the difference in performance between both paradigms is rather small. Moreover, the performance gap between the flat and hierarchical representations of the search space, as reported in Table 1, remains smaller than the performance gap between the best performing of the approaches proposed in this article and NASNet-A (Zoph et al., 2017), as reported in Tables 2 and 3.\n\nAnother concern I have is regarding the definition of the mutation operators in Section 3.1. While not explicitly stated, I assume that all sampling steps are performed uniformly at random (otherwise please clarify it). If that was indeed the case, there is a systematic asymmetry between the probability to add and remove an edge, making the former considerably more likely. This could bias the architectures towards fully-connected DAGs, as indeed seems to occur based on the motifs reported in Appendix A.\n\nFinally, while the main motivation behind neural architecture search is to automatise the design of new models, the approach here presented introduces a non-negligible number of hyperparameters that could potentially have a considerable impact and need to be selected somehow. This includes, for instance, the number of levels in the hierarchy (L), the number of motifs at each level in the hierarchy (M_l), the number of nodes in each graph at each level in the hierarchy (| G^{(l)} |), as well as the set of primitive operations. I believe the paper would be substantially strengthened if the authors explored how robust the resulting approach is with respect to perturbations of these hyperparameters, and/or provided users with a principled approach to select reasonable values.\n\nReferences:\n\n[1] Grosse, Roger, et al. ""Exploiting compositionality to explore a large space of model structures."" UAI (2012).\n[2] Duvenaud, David, et al. ""Structure discovery in nonparametric regression through compositional kernel search."" ICML (2013).\n', 'This work fits well into a growing body of research concerning the encoding of network topologies and training of topology via evolution or RL. The experimentation and basic results are probably sufficient for acceptance, but to this reviewer, the paper spins the actual experiments and results a too strongly.\n\nThe biggest two nitpicks:\n\n> In our work we pursue an alternative approach: instead of restricting the search space directly, we allow the architectures to have flexible network topologies (arbitrary directed acyclic graphs)\n\nThis is a gross overstatement. The architectures considered in this paper are heavily restricted to be a stack of cells of uniform content interspersed with specifically and manually designed convolution, separable convolution, and pooling layers. Only the topology of the cells themselves are designed. The work is still great, but this misleading statement in the beginning of the paper left the rest of the paper with a dishonest aftertaste. As an exercise to the authors, count the hyperparameters used just to set up the learning problem in this paper and compare them to those used in describing the entire VGG-16 network. It seems fewer hyperparameters are needed to describe VGG-16, making this paper hardly an alternative to the ""[common solution] to restrict the search space to reduce complexity and increase efficiency of architecture search.""\n\n> Table 1\n\nWhy is the second best method on CIFAR (“Hier. repr-n, random search (7000 samples)”) never tested on ImageNet? The omission is conspicuous. Just test it and report.\n\nSmaller nitpicks:\n\n> “New state of the art for evolutionary strategies on this task”\n\n“Evolutionary Strategies”, at least as used in Salimans 2017, has a specific connotation of estimating and then following a gradient using random perturbations which this paper does not do. It may be more clear to change this phrase to “evolutionary methods” or similar.\n\n> Our evolution algorithm is similar but more generic than the binary tournament selection (K = 2) used in a recent large-scale evolutionary method (Real et al., 2017).\n\nA K=5% tournament does not seem more generic than a binary K=2 tournament. They’re just different.', 'The authors present a novel evolution scheme applied to neural network architecture search. It relies on defining an expressive search space for conducting optimization, with a constrained search space that leads to a lighter and more efficient algorithm. To balance these constraints, they grow sub-modules in a hierarchical way to form more and more complex cells. Hence, each level is limited to a small search space while the system as a whole converges toward a complex structure. To speed up the search, they focus on finding cells instead of an entire network. In evaluation time, they insert these cells between layers of a network comparable in size to known networks. They find complex cells that lead to state-of-the-art performance on benchmark dataset CIFAR-10 and ImageNet. They also claim that their method is reaching a new milestone in evolutionary search strategies performance.\n\nThe method proposed for an hierarchical representation for optimizing over neural network designs is well thought and sound. It could lead to new insight on automating design of neural networks for given problems. In addition, the authors present results that appear to be on par with the state-of-the-art with architecture search on CIFAR-10 and ImageNet benchmark datasets. The paper presents a good work and is well articulated. However, it could benefit from additional details and a deeper analysis of the results.\n\nThe key idea is a smart evolution scheme. It circumvents the traditional tradeoff between search space size and complexity of the found models. The method is also appealing for its use of some kind of emergence between two levels of hierarchy. In fact, it could be argued that nature tends to exploit the same phenomenon when building more and more complex molecules. Thought, the paper could benefit from a more detailed analysis of the architectures found by the algorithm. Do the modules always become more complex as they jump from a level to another or there is some kind of inter-level redundancy? Are the cells found interpretable? The authors should try to give their opinion about the design obtained.\n\nThe implementation seems technically sound. The experiments and results section shows that the authors are confident and the evaluation seems correct. However, paragraphs on the architectures could be a bit clearer for the reader. The diagram could be more complete and reflect better the description. During evaluation, what is a step? A batch or an epoch or other?\n\nThe method seems relatively efficient as it took 36 hours to converge in a field traditionally considered as heavy in terms of computation, but at the requirement of using 200 GPU. It raises questions on the usability of the method for small labs. At some point, we will have to use insights from this search to stop early, when no improvement is expected. Also, authors claim that their method consume less computation time than reinforcement learning. This should be supported by some quantitative results.\n\nThe paper would greatly benefit from a deeper comparison over other techniques. For instance, it could describe more the advantages over reinforcement learning. An important contribution is to show that a well-defined architecture representation could lead to efficient cells with a simple randomized search. It could have taken more spaces in the paper.\n\nI am also concerned the computational efficiency of the results obtained with this method on current processors. Indeed, the randomness of the found cells could be less efficient in terms of computation that what we can get from a well-structured network designed by hand. Exploiting the structure of the GPUs (cache size, sequential accesses, etc.) allows to get best possible performance from the hardware at hand. Does the solution obtained with the optimization can be run as efficiently? A short analysis forward pass time of optimized cells vs. popular models could be an interesting addition to the paper. This is a general comment over this kind of approach, but I think it should be addressed. \n']","[50, -30, 60]","[80, 20, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contribution as 'interesting' and 'well-written', but also expresses concerns about the experimental results and robustness of the approach. The overall tone is balanced, recognizing both strengths and limitations. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout. They use phrases like 'I believe' and 'to the best of my knowledge', which soften criticisms. The reviewer also acknowledges the paper's merits before presenting concerns, maintaining a constructive tone. The language is formal and professional, avoiding any harsh or dismissive statements."", ""The sentiment score is -30 because while the reviewer acknowledges that the work fits well into existing research and the experiments are probably sufficient for acceptance, they express significant concerns about the paper overstating its claims and results. The reviewer uses phrases like 'spins the actual experiments and results a too strongly' and 'gross overstatement', indicating a negative sentiment. However, they do mention some positive aspects, which is why the score isn't lower. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'to this reviewer' and 'nitpicks' to soften criticism. They also offer constructive feedback and suggestions for improvement. However, some phrases like 'dishonest aftertaste' are quite direct, preventing a higher politeness score."", ""The sentiment score is 60 (positive) because the reviewer generally praises the paper, calling it 'well thought and sound' and stating that it 'presents a good work and is well articulated.' They mention that the results are 'on par with the state-of-the-art' and that the method is 'appealing.' However, it's not a perfect score because the reviewer also suggests areas for improvement, such as 'additional details and a deeper analysis of the results.' The politeness score is 80 (very polite) because the reviewer uses respectful and constructive language throughout. They offer praise where due and frame their criticisms as suggestions for improvement rather than harsh critiques. Phrases like 'The paper would greatly benefit from...' and 'I am also concerned...' show a polite and considerate tone. The reviewer maintains a professional and courteous demeanor while providing thorough feedback.""]"
"[""This paper utilizes ACOL algorithm for unsupervised learning. ACOL can be considered a type of semi-supervised learning where the learner has access only to parent-class information (for example in digit recognition whether a digit is bigger than 5 or not) and not the sub-class information (number between 0-9). Given that in many applications such parent-class supervised information is not available, the authors of this paper propose domain specific pseudo parent-class labels (for example transformed images of digits) to adapt ACOL for unsupervised learning. The authors also modified affinity and balance term utilized in GAR (as part of ACOL algorithm) to improve it. The authors use multiple data sets to study different aspects of the proposed approach.\n\nI updated my scores based on the reviewers responses. It turned out that ACOL and GAR are also originally proposed by the same authors and was only published in arxiv! Because of the double-blind review nature of ICLR, I didn't know these ideas came from the same authors and is being published for the first time in a peer-reviewed venue (ICLR). So my main problem with this paper, lack of novelty, is addressed and my score has changed. Thanks to the reviewer for clarifying this.\n"", 'This paper presents a method for clustering based on latent representations learned from the classification of transformed data after pseudo-labellisation corresponding to applied transformation. Pipeline: -Data are augmented with domain-specific transformations. For instance, in the case of MNIST, rotations with different degrees are applied. All data are then labelled as ""original"" or ""transformed by ...(specific transformation)"". -Classification task is performed with a neural network on augmented dataset according to the pseudo-labels. -In parallel of the classification, the neural network also learns the latent representation in an unsupervised fashion. -k-means clustering is performed on the representation space observed in the hidden layer preceding the augmented softmax layer. \n\nDetailed Comments:\n(*) Pros\n-The method outperforms the state-of-art regarding unsupervised methods for handwritten digits clustering on MNIST.\n-Use of ACOL and GAR is interesting, also the idea to make ""labeled"" data from unlabelled ones by using data augmentation.\n\n(*) Cons\n-minor: in the title, I find the expression ""unsupervised clustering"" uselessly redundant since clustering is by definition unsupervised.\n-Choice of datasets: we already obtained very good accuracy for the classification or clustering of handwritten digits. This is not a very challenging task.\nAnd just because something works on MNIST, does not mean it works in general. \nWhat are the performances on more challenging datasets like colored images (CIFAR-10, labelMe, ImageNet, etc.)?\n-This is not clear what is novel here since ACOL and GAR already exist. The novelty seems to be in the adaptation to GAR from the semi-supervised to the unsupervised setting with labels indicating if data have been transformed or not.\n\n\nMy main problem  was about the lack of novelty. The authors clarified this point, and it turned out that ACOL and GAR have never published elsewhere except in ArXiv.  The other issue concerned the validation of the approach on databases other than MNIST. The author also addressed this point, and I changed my scores accordingly. ', 'The paper is well written and clear. The main idea is to exploit a schema of semisupervised learning based on ACOL and GAR for an unsupervised learning task. The idea is to introduce the notion of pseudo labelling. \nPseudo labelling can be obtained by transformations of original input data.\nThe key point is the definition of the transformations. \nOnly whether the design of transformation captures the latent representation of the input data, the pseudo-labelling might improve the performance of the unsupervised learning task.\nSince it is not known in advance what might be a good set of transformations, it is not clear what is the behaviour of the model when the large portion of transformations are not encoding the latent representation of clusters.']","[50, 50, 20]","[80, 70, 50]","[""The sentiment score is 50 (moderately positive) because the reviewer initially had concerns about novelty but updated their score positively after receiving clarification from the authors. The reviewer acknowledges the value of the work and its application to multiple datasets. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges their misunderstanding, and thanks the authors for their clarification. The reviewer also provides a detailed explanation of the paper's content without using harsh or critical language."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges both pros and cons of the paper. They praise the method's performance and interesting use of techniques, but also point out issues with novelty and dataset choice. The initial concerns seem to have been addressed by the authors, leading to a more positive overall sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, presenting criticisms as constructive feedback rather than harsh judgments. They use phrases like 'This is not clear' instead of more accusatory language, and acknowledge when their concerns have been addressed. The review maintains a professional and courteous tone throughout."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges that the paper is 'well written and clear' and describes the main idea of the paper without criticism. However, the reviewer also raises concerns about the effectiveness of the proposed method, particularly when transformations don't encode the latent representation of clusters. This balanced view suggests a cautiously positive sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They begin with a positive statement and present their concerns as observations rather than direct criticisms, maintaining a respectful tone. The absence of harsh or dismissive language contributes to the polite impression.""]"
"['This paper presents a reinforcement learning method for learning complex tasks by dividing the state space into slices, learning local policies within each slice, while ensuring that they don\'t deviate too far from each other, while simultaneously learning a central policy that works across the entire state space in the process. The most closely related works to this one are Guided Policy Search (GPS) and ""Distral"", and the authors compare and contrast their work with the prior work suitably.\n\nThe paper is written well, has good insights, is technically sound, and has all the relevant references. The authors show through several experiments that the divide and conquer (DnC) technique can solve more complex tasks than can be solved with conventional policy gradient methods (TRPO is used as the baseline). The paper and included experiments are a valuable contribution to the community interested in solving harder and harder tasks using reinforcement learning.\n\nFor completeness, it would be great to include one more algorithm in the evaluation: an ablation of DnC which does not involve a central policy at all. If the local policies are trained to convergence, (and the context omega is provided by an oracle), how well does this mixture of local policies perform? This result would be instructive to see for each of the tasks.\n\nThe partitioning of each task must currently be designed by hand. It would be interesting (in future work) to explore how the partitioning could perhaps be discovered automatically.', 'This paper presents a method for learning a global policy over multiple different MDPs (referred to as different ""contexts"", each MDP having the same dynamics and reward, but different initial state).  The basic idea is to learn a separate policy for each context, but regularized in a manner that keeps all of them relatively close to each other, and then learn a single centralized policy that merges the multiple policies via supervised learning.  The method is evaluated on several continuous state and action control tasks, and shows improvement over existing and similar approaches, notably the Distral algorithm.\n\nI believe there are some interesting ideas presented in this paper, but in its current form I think that the delta over past work (particularly Distral) is ultimately too small to warrant publication at ICLR.  The authors should correct me if I\'m wrong, but it seems as though the algorithm presented here is virtually identical to Distral except that:\n1) The KL divergence term regularizes all policies together in a pairwise manner.\n2) The distillation step happens episodically every R steps rather than in a pure SGD manner.\n3) The authors possibly use a TRPO type objective for the standard policy gradient term, rather than REINFORCE-like approach as in Distral (this one point wasn\'t completely clear, as the authors mention that a ""centralized DnC"" is equivalent to Distral, so they may already be adapting it to the TRPO objective? some clarity on this point would be helpful).\nThus, despite better performance of the method over Distral, this doesn\'t necessarily seem like a substantially new algorithmic development.  And given how sensitive RL tasks are to hyperparameter selection, there needs to be some very substantial treatment of how the regularization parameters are chosen here (both for DnC and for the Distral and centralized DnC variants).  Otherwise, it honestly seems that the differences between the competing methods could be artifacts of the choice of regularization (the alpha parameter will affect just how tightly coupled the control policies actually are).\n\nIn addition to this point, the formulation of the problem setting in many cases was also somewhat unclear.  In particular, the notion of the contextual MDP is not very clear from the presentation.  The authors define a contextual MDP setting where in addition to the initial state there is an observed context to the MDP that can affect the initial state distribution (but not the transitions or reward).  It\'s entirely unclear to me why this additional formulation is needed, and ultimately just seems to confuse the nature of the tasks here which is much more clearly presented just as transfer learning between identical MDPs with different state distributions; and the terminology also conflicts with the (much more complex) setting of contextual decision processes (see: https://arxiv.org/abs/1610.09512).  It doesn\'t seem, for instance, that the final policy is context dependent (rather, it has to ""infer"" the context from whatever the initial state is, so effectively doesn\'t take the context into account at all).  Part of the reasoning seems to be to make the work seem more distinct from Distral than it really is, but I don\'t see why ""transfer learning"" and the presented contextual MDP are really all that different.\n\nFinally, the experimental results need to be described in substantially more detail.  The choice of regularization parameters, the precise nature of the context in each setting, and the precise design of the experiments is all extremely opaque in the current presentation.  Since the methodology here is so similar to previous approaches, much more emphasis is required to better understand the (improved) empirical results in this eating.\n\nIn summary, while I do think the core ideas of this paper are interesting: whether it\'s better to regularize policies to a single central policy as in Distral or whether it\'s better to use joint regularization, whether we need two different timescales for distillation versus policy training, and what policy optimization method works best, as it is right now the algorithmic choices in the paper seem rather ad-hoc compared to Distral, and need substantially more empirical evidence.\n\nMinor comments:\n• There are several missing words/grammatical errors throughout the manuscript, e.g. on page 2 ""gradient information can better estimated"".', 'The submission tackles an important problem of learning highly varied skills. The approach relies on dividing the task space into subareas (defined by task context vectors) over which individual policies are trained, but are still required to operate well on tasks outside their context.\n\nThe exposition is clear and the method is well-motivated. I see no issues with the mathematical correctness of the claims made in the paper. The experimental results show a convincing benefit over TRPO and Distral on a number of manipulation and locomotion tasks. I would like to have seen more discussion of the computational costs and scaling of the method over TRPO or Distral, as the pairwise KL divergence terms grow quadratically in the number of contexts. \n\nWhile the method is well-motivated, the division of tasks into subareas seems arbitrarily chosen. It would be very useful for readers to see performance of the algorithm under other task decompositions to alleviate the worries that the algorithm is not sensitive to the decomposition choice.\n\nI would also like to see more discussion of curriculum learning, which also aims at tackling a similar problem of reducing complexity in early stages of training by choosing on simper tasks and progressing to more complex. Would such progressive tasks decompositions work better in your framework? Does your framework remove the need for curriculum learning?\n\nOverall, I believe this is in interesting piece of work and I believe would be of interest to ICLR community.']","[80, -50, 70]","[90, 50, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, describing it as 'well written', having 'good insights', being 'technically sound', and a 'valuable contribution'. The reviewer also praises the experiments and the paper's comparison with related work. The score is not 100 as the reviewer does suggest some additional work that could be done. The politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They offer praise where due and frame their suggestions as opportunities for improvement rather than criticisms. Phrases like 'For completeness, it would be great to include...' and 'It would be interesting (in future work)...' demonstrate a particularly courteous approach to providing feedback."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's contribution and novelty, stating that the 'delta over past work is ultimately too small to warrant publication'. However, they do acknowledge some 'interesting ideas', preventing the score from being more negative. The politeness score is 50 because the reviewer uses respectful language throughout, such as 'I believe', 'The authors should correct me if I'm wrong', and offers constructive feedback. They also balance criticism with positive remarks. The reviewer maintains a professional tone, avoiding harsh or rude language, but also doesn't go out of their way to be overly polite, hence the moderate positive score."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'an interesting piece of work' that would be 'of interest to ICLR community'. They praise the clear exposition, well-motivated method, and convincing experimental results. However, it's not a perfect score as the reviewer does raise some concerns and requests for additional information. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths before offering suggestions for improvement, and phrase their criticisms as requests for more information rather than direct attacks. The use of phrases like 'I would like to have seen' and 'It would be very useful' contribute to the polite tone.""]"
"['Summary:\nThe manuscript introduces a principled way of network to network compression, which uses policy gradients for optimizing two policies which compress a strong teacher into a strong but smaller student model. The first policy, specialized on architecture selection, iteratively removes layers, starting with architecture of the teacher model. After the first policy is finished, the second policy reduces the size of each layer by iteratively outputting shrinkage ratios for hyperparameters such as kernel size or padding. This organization of the action space, together with a smart reward design achieves impressive compression results, given that this approach automates tedious architecture selection. The reward design favors low compression/high accuracy over high compression/low performance while the reward still monotonically increases with both compression and accuracy. As a bonus, the authors also demonstrate how to include hard constraints such as parameter count limitations into the reward model and show that policies trained on small teachers generalize to larger teacher models.\n\nReview:\nThe manuscript describes the proposed algorithm in great detail and the description is easy to follow. The experimental analysis of the approach is very convincing and confirms the author’s claims. \nUsing the teacher network as starting point for the architecture search is a good choice, as initialization strategies are a critical component in knowledge distillation. I am looking forward to seeing work on the research goals outlined in the Future Directions section.\n\nA few questions/comments:\n1) I understand that L_{1,2} in Algorithm 1 correspond to the number of layers in the network, but what do N_{1,2} correspond to? Are these multiple rollouts of the policies? If so, shouldn’t the parameter update theta_{{shrink,remove},i} be outside the loop over N and apply the average over rollouts according to Equation (2)? I think I might have missed something here.\n2) Minor: some of the citations are a bit awkward, e.g. on page 7: “algorithm from Williams Williams (1992). I would use the \\citet command from natbib for such citations and \\citep for parenthesized citations, e.g. “... incorporate dark knowledge (Hinton et al., 2015)” or “The MNIST (LeCun et al., 1998) dataset...” \n3) In Section 4.6 (the transfer learning experiment), it would be interesting to compare the performance measures for different numbers of policy update iterations.\n4) Appendix: Section 8 states “Below are the results”, but the figure landed on the next page. I would either try to force the figures to be output at that position (not in or after Section 9) or write ""Figures X-Y show the results"". Also in Section 11, Figure 13 should be referenced with the \\ref command\n5) Just to get a rough idea of training time: Could you share how long some of the experiments took with the setup you described (using 4 TitanX GPUs)?\n6) Did you use data augmentation for both teacher and student models in the CIFAR10/100 and Caltech256 experiments?\n7) What is the threshold you used to decide if the size of the FC layer input yields a degenerate solution?\n\nOverall, this manuscript is a submission of exceptional quality and if minor details of the experimental setup are added to the manuscript, I would consider giving it the full score.', 'On the positive side the paper is well written and the problem is interesting. \n\nOn the negative side there is very limited innovation in the techniques proposed, that are indeed small variations of existing methods. \n', 'This paper proposes to use reinforcement learning instead of pre-defined heuristics to determine the structure of the compressed model in the knowledge distillation process.\n\nThe draft is well-written, and the method is clearly explained. However, I have the following concerns for this draft:\n\n1. The technical contribution is not enough. First, the use of reinforcement learning is quite straightforward. Second, the proposed method seems not significantly different from the architecture search method in [1][2] – their major difference seems to be the use of “remove” instead of “add” when manipulating the parameters. It is unclear whether this difference is substantial, and whether the proposed method is better than the architecture search method.\n\n2. I also have concern with the time efficiency of the proposed method. Reinforcement learning involves multiple rounds of knowledge distillation, and each knowledge distillation is an independent training process that requires many rounds of forward and backward propagations. Therefore, the whole reinforcement learning process seems very time-consuming and difficult to be generalized to big models and large datasets (such as ImageNet). It would be necessary for the authors to make direct discussions on this issue, in order to convince others that their proposed method has practical value.\n\n[1] Zoph, Barret, and Quoc V. Le. ""Neural architecture search with reinforcement learning."" ICLR (2017).\n[2] Baker, Bowen, et al. ""Designing Neural Network Architectures using Reinforcement Learning."" ICLR (2017).\n']","[90, -20, -20]","[80, 50, 60]","[""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer describes the manuscript as 'exceptional quality' and states they would consider 'giving it the full score' with minor additions. They praise the detailed description, convincing experimental analysis, and confirm the author's claims. The politeness score is 80 because the reviewer uses respectful and constructive language throughout. They frame their questions and comments as suggestions rather than criticisms, using phrases like 'I understand that...' and 'Could you share...'. The reviewer also expresses enthusiasm for future work. The score is not 100 as there is still a professional distance maintained, but the tone is consistently polite and encouraging."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges positive aspects ('well written', 'interesting problem'), they emphasize a significant negative point ('very limited innovation'). The criticism outweighs the praise, but the overall tone is not severely negative. The politeness score is moderately positive (50) as the reviewer uses balanced language, starting with positive comments before presenting criticism. They avoid harsh or accusatory language, instead presenting their concerns in a professional manner. The use of phrases like 'On the positive side' and 'On the negative side' shows an effort to provide a balanced review, which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and the method is clearly explained, they express significant concerns about the technical contribution and time efficiency of the proposed method. The reviewer questions the novelty and practicality of the approach, which outweighs the initial positive comments.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful language throughout. They begin with positive comments about the writing and clarity, and frame their concerns as suggestions or questions rather than harsh criticisms. Phrases like 'I have the following concerns' and 'It would be necessary for the authors to' indicate a constructive tone. The reviewer also provides specific references to support their points, which is a courteous way to offer critique in academic discourse.""]"
"['- Summary\n\nThe paper is well written and proves how deep, wide, fully connected NNs are equivalent to GPs in the limit. This result, which was well known for single-layer NNs, is now extended to the multilayer case. Although there was already previous work suggesting GP this behavior, there was no formal proof under the specific conditions presented here.\n\nThe convergence to a GP is also verified experimentally on some toy examples.\n\n\n- Relevance\n\nThe result itself does not feel very novel because variants of it were already available.\n\nUnfortunately, although making other researchers aware of this is worthy, the application of this result seems limited, since in fact it describes and lets us know more about a regime that we would rather avoid, rather than one we want to exploit. Most of the applications of deep learning benefit from strong structured priors that cannot be represented as a GP. This is properly acknowledged in the paper.\n\nThe lack of practical relevance combined with the not-groundbreaking novelty of the result makes this paper less appealing.\n\n\n- Other comments\n\nPage 6: ""It does mean however that our empirical study does not extend to larger datasets where such inference is prohibitively expensive (...) prior dominated problems are generally regarded as an area of strength for Bayesian approaches and in this context our results are directly relevant.""\n\nAlthough that argument can hold for datasets that are large in terms of amount of data points, it doesn\'t for datasets that are large in terms of number of dimensions. The empirical study could have used very high-dimensional datasets with comparatively low amounts of training data. That would maintain a regime were the prior does matter but and better show the generality of the results.\n\nPage 6: ""We use rectified linear units and correct the variances to avoid a loss of prior variance as depth is increased as discussed in Section 3"" \n\nAre you sure this is discussed in Section 3?\n\nPage 4: ""This is because for finite H the input activations do not have a multivariate normal distribution"". \n\nCan you elaborate on this? Since we are interested in the infinite limit, why is this a problem?', 'The authors study the limiting behaviour for wide Bayesian neural networks, comparing to Gaussian processes. \n\nThe paper is well written, and the experiments are enlightening. This work is a nice follow up to Neal (1994), and recent work considering similar results for neural networks with more than one hidden layer. It does add to our understanding of this body of work.\n\nThe weakness of this paper is in its significance and practical value. This infinite limit loses much of the interesting representation in neural networks because the variance of the weights goes to zero. Thus it’s unclear whether these formulations will have many of the benefits of standard neural networks, and whether they’re particularly related to standard neural networks at all. There also don’t seem to be many practical takeaways from the experiments, and the experiments themselves do not consider any predictive tasks at all. It would be nice to see some practical benefit for a predictive task actually demonstrated in the paper. I am not sure what exactly I would do differently in training large neural networks based on the results of this paper, and the possible takeaways are not tested here on real applications.\n\nThis paper also seems to erroneously attribute this limitation of the Neal (1994) limit, and its multilayer extensions, to Gaussian processes in the section “avoiding Gaussian process behaviour”. The problems with that construction are not a profound limitation of Gaussian processes in general. If we can learn the kernel function, then we can learn an interesting representation that does not have these limitations and still use a GP. We could alternatively treat the kernel parameters probabilistically, but the fact that in this case we would not marginally have a GP any longer is mostly incidental. The discussed limitations are more about specific kernel choices, and lack of kernel learning, than about “GP behaviour”.\n\nIndeed, while the discussion of related work is mostly commendable, the authors should also discuss the recent papers on “deep kernel learning”:\ni) http://proceedings.mlr.press/v51/wilson16.pdf\nii) https://papers.nips.cc/paper/6426-stochastic-variational-deep-kernel-learning.pdf\niii) http://www.jmlr.org/papers/volume18/16-498/16-498.pdf\n\nIn particular, these papers do indeed learn flexible representations with Gaussian processes by using kernels constructed with neural networks. They avoid the behaviour discussed in the last section of your paper, but still use a Gaussian process. The network structures themselves are trained through the marginal likelihood of the Gaussian process. This approach effectively learns an infinite number of adaptive basis functions, parametrized through the structural properties of a neural network. Computations are made scalable and practical through exploiting algebraic structure. \n\t\t\t\nOverall I enjoyed reading your paper.', 'In part 1, the authors introduce motivation for studying wide neural networks and summarize related work. \nIn part 2,  they present a theorem (main theoretical result) stating that under conditions on the weight priors, the output function of a multi-layer neural network (conditionally to a given input) weakly converges to a gaussian process as the size of the hidden layers go to infinity.\nremark on theorem 1: This result generalizes a result proven in 2015 stating that the normality of a layer propagates to the next as the size of the first layer goes to infinity. The result stated in this paper is proven by bounding the gap between the output distribution and the corresponding gaussian process, and by propagating this bound across layers (appendix). \nIn part 3, the authors discuss the choice of a nonlinearity function that enables easy computation of the kernels introduced in the covariance matrix of the limit normal distribution. Their choice lands on ReLU.\nIn part 4, the focus is on the speed of the convergence presented in theorem 1. Experiments are conducted to show how the distance (maximum mean disrepancy) between the output distribution and its theoretical gaussian process limit vary when the sizes of the hidden layers increase. The results show that the convergence (in MMD) happens consistently, although it is slower when the number of hidden layers gets bigger.\nIn part 5, the authors compare the distributions (finite Bayesian deep networks and their analogues Gaussian processes) in yet another way: by studying their agreement in terms of inference. For this purpose, the authors chose several crieteria: the first two moments of the posterior, the log marginal likelihood and the predictive log-likelihood. The authors judge that the distributions agree on those criteria, but do not provide further analysis.\nIn part 6, now that It has been shown that the output distributions of Bayesian neural nets do not only weakly converge to Gaussian processes but also behave similarly in terms of inference, the authors discuss ways to avoid the gaussian process behaviour. Indeed, it seems that Gaussian processes with a fixed kernel cannot learn hierarchical representations, that are essential in deep learning.\nThe idea to avoid the Gaussian process behaviour is to contradict one of the hypothesis of the CLT (so that it does not hold anymore), either by controlling the size of intermediate layers, by using networks with infinite variance in the activities, or by choosing non-independent weights.\nIn part 7, it is concluded that the result that has been proven for size of layers going to infinity (Theorem 1) seems to empirically be verified on finite networks similar to those used in the literature. This can be used to simplify inference in cases were the gaussian process behaviour is desired, and opens questions on how to avoid this behaviour the rest of the time.\n\nPros: The authors line of thought of the authors is overall quite easy to follow. The main theoretical convergence result is stated early on, and the remaining of the article is dedicated to observing this result empirically from different angles (MMD, inference, predictive capability..). The last part contains a discussion concerning the extent to which it is actually a desired or a undesired result in classical deep learning use-cases, and the authors provide intuitive conditions under which the convergence would not hold. The stated theorem is a clear improvement on the past literature and is promising in a context where multi-layers neural networks are more and more studied.\nFinally, the work is well documented.\n\nCons: \nI have a some concerns with the main result (Theorem 1) and found that some of the notations / formulas were not very clear.\n Concerns with Theorem 1:\n* at the end of the proof of Lemma 2, H_\\mu is to be chosen large enough in order to get the \\epsilon bound of the statement. However, I think that  H_\\mu is constrained by the statement of Proposition 2, not to be larger than a constant times 2^(H_{\\mu+1}). Isn\'t that a problem?\n* In the proof of Lemma 4, it looks like matrix \\Psi, from the schur decomposition of \\tilde f, actually depends on H_{\\mu-2}, thus making \\psi_max depend on it too, as well as the final \\beta bound, which would contradict the statement that it depends only on n and H_{\\mu}. Could you please double check?\n\nUnclear statements/notations:\n* end of page 3, notations are not entirely consist with previous notations\n* I do not understand which distribution is assumed on epsilon and gamma when taking the expectancy in equation (9).\n* the notation x^(i) (in the theorem and the proof notably) could be changed, for the ^(i) index refers to the depth of the layer in the rest of the notations, and is here surprisingly referring to a set of observations.\n* the statement of Theorem 1:\n    * I would change ""for a countable input set"" to ""for any countable input set"", if this holds true.\n    * does not say that the width has to go to infinity for the convergence to happen, which goes a bit in contradiction with the adjective ""wide"". However, the authors say that in practice, they use the identity as width function.\n* I understood that the conclusion of part 3 was that the expectation of eq (9) was elegantly computable for certain non-linearity (including ReLU). However I don\'t see the link with the ""recursive kernel"" idea (maybe it\'s just the way to do the computation described in Cho&Saul(2009) ?)\n\nSome places where it appears that there are minor mistakes:\n* 7th line from the bottom of page 3, the vector f^{(2)}(x) contains f_i^{(1)}(x) but should contain f_i^{(2)}(x)\n* last display of page 3: change x and x\', and indicate upper limit of the sum\n* please double check variances C_w and/or \\hat{C}_w appearing in equations in (9) and (13).\n* line 2 of second paragraph after equations (8) and (9). The authors refer to equation (8) concerning the independence of the components of the output. I think they rather wanted to refer to (9). Same for first sentence before eq (14).\n* middle of page 12: matrix LY should be RY.']","[-20, 20, 50]","[50, 80, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is well-written and proves an important result, they also express concerns about its novelty and practical relevance. The reviewer states that 'The lack of practical relevance combined with the not-groundbreaking novelty of the result makes this paper less appealing.' This indicates a overall slightly negative sentiment towards the paper's contribution.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They begin with positive comments about the paper being 'well written' and acknowledge the value of the work. Even when expressing criticisms, the reviewer maintains a polite tone, using phrases like 'Unfortunately' and 'Although that argument can hold...' rather than using harsh or dismissive language. The reviewer also offers constructive suggestions for improvement, which is a polite way to provide criticism."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is well-written and adds to the understanding of the field. However, they also point out significant weaknesses, such as lack of practical value and missing experiments on predictive tasks. The overall tone is constructive but with substantial criticisms. The politeness score is high (80) as the reviewer uses respectful language throughout, offers specific suggestions for improvement, and ends on a positive note saying they enjoyed reading the paper. They also use phrases like 'It would be nice to see' and 'Overall I enjoyed reading your paper' which contribute to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer provides a balanced assessment with both pros and cons. They acknowledge the paper's strengths, such as the clear line of thought, improvement on past literature, and well-documented work. However, they also express concerns about the main result and some unclear statements/notations. The overall tone is constructive rather than overly critical or enthusiastic. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as 'concerns' or suggestions for improvement, and uses phrases like 'please double check' when pointing out potential errors. The reviewer also acknowledges the positive aspects of the work before delving into criticisms, which is a polite approach to peer review.""]"
"['I have read the comments and clarifications from the authors. They have added extra experiments, and clarified the speed-ups concern raised by others. I keep my original rating of the paper.\n\n---------------\nORIGINAL REVIEW:\n\nThis paper introduces a multi-bit quantization method for recurrent neural networks, which is built on alternating the minimization formulated by Guo et al. 2017 by first fixing the \\alpha values and then finding the optimal binary codes b_i with a BST, to then estimate \\alpha with the refined approximation by Guo et al. 2017, iteratively. The observation that the optimal binary code can be computed with a BST is simple and elegant.\n\nThe paper is easy to follow and the topic of reducing memory and speeding up computations for RNN and DNN is interesting and relevant to the community.\n\nThe overall contribution on model quantization is based on existing methods, which makes the novelty of the paper suffer a bit. Said that, applying it to RNN is a convincing and a strong motivation. Also, in the paper it is shown how the matrix multiplications of the quantized model can be speeded up using 64 bits operation in CPU. This is, not only saves memory storage and usage, but also on runtime calculation using CPU, which is an important characteristic when there are limited computational resources.\n\nResults on language models show that the models with quantized weights with 3 bits obtain the same or even slightly better performance on the tested datasets with impressive speed-ups and memory savings.\n\nFor completeness, it would be interesting, and I would strongly encourage to add a discussion or even an experiment using feedforward DNN with a simple dataset as MNIST, as most of previous work discussed in the paper report experiments on DNN that are feedforward. Would the speed-ups and memory savings obtained for RNN hold also for feedforward networks?\n\n\n\n\n', ""Revision:\n\nThe authors have addressed my concerns around the achievable speedup. I am increasing my score to 7.\n\nOriginal Review:\n\nThe paper proposes a technique for quantizing neural network weight matrices by representing columns of weight matrices as linear combinations of binary (+1/-1) vectors. Given a weight vector, the paper proposes an alternating optimization procedure to estimate the set of k binary vectors and coefficients that best represent (in terms of MSE) the original vector. This yields a k-bit quantization. First, the coefficients/binary weights are initialized using a greedy procedure proposed in prior work. Then, the binary weights are updated using a clever binary search procedure, followed by updates to the coefficients. Experiments are conducted in an RNN context for some language modeling tasks.\n\nThe paper is relatively easy to read, and the technique is clearly explained. The technique is as far as I can tell novel, and does seem to represent an improvement over existing approaches for similar multi-bit quantization strategies.\n\nI have a few questions/concerns. First, I am quite skeptical of many of the speedup calculations: These are rather delicate to do properly, and depend on the specific instructions available, SIMD widths, the number of ALUs present in a core, etc. All of these can easily shift numbers around by a factor of 2-8x. Without an implementation in hand, comparing against a well-optimized reference GEMM for full floating point, it's not clear how much faster this approach really would be in practice. Also, the online quantization of activations doesn't seem to be factored into the speedup calculations, and no benchmarks are provided demonstrating how fast the quantization is (unless I'm missing something). This is concerning since the claimed speedups aren't possible without the online quantization of actiations.\n\nIt would have been nice to have more discussion of/comparison with other approaches capable of 2-4 bit quantization, such as some of the recent work on ternary quantization, product quantization approaches, or at least scalar (per-dimension) k-means (non-uniform quantization).\n\nFinally, the experiments are reasonable, but the choice of RNN setting isn't clear to me. It would have been easier to compare to prior work if the experiments also included some standard image classification tasks (e.g., CIFAR10).\n\nOverall though, I think the paper does just enough to warrant acceptance."", '\nSummary of the paper\n-------------------------------\n\nThe authors propose a new way to perform multi-bit quantization based on greedy approximation and binary search tree for RNNs. They first show how this method, applied to the parameters only, performs on pre-trained networks and show great performances compared to other existing techniques on PTB. Then they present results with the method applied to both parameters and activations during training on 3 NLP datasets, showing again great performances compared to existing technique.\n\nClarity, Significance and Correctness\n--------------------------------------------------\n\nClarity: The paper is clearly written.\n\nSignificance: I\'m not familiar with the quantization literature, so I\'ll let more knowledgeable reviewers evaluate this point.\n\nCorrectness: The paper is technically correct.\n\nQuestions\n--------------\n\n1. It would be nice to have those memory and speed gains for training as well. Is it possible to use those quantization methods to train networks from scratch, i.e. without using a pre-train model?\n\nPros\n------\n\n1. The paper defines clear goals and contributions.\n2. Existing methods (and their differences) are clearly and concisely presented.\n3. The proposed method is well explained.\n4. The experimental setup shows clear results compared to the non-quantized baselines and other quantization techniques.\n\nCons\n-------\n\n1. It would be nice to have another experiment not based on text (speech recognition / synthesis, audio, biological signals, ...) to see how it generalizes to other kind of data (although I can\'t see why it wouldn\'t).\n\nTypos\n--------\n\n1. abstract: ""gate recurrent unit"" -> ""gated recurrent unit""\n2. equation (6): remove parenthesis in c_(t-1)\n3. section 4, paragraph 1: ""For the weight matrices, instead of on the whole, we quantize them row by row."" -> ""We don\'t apply quantization on the full matrices but rather row by row.""\n4. section 4, paragraph 2: Which W matrix is it? W_h? (2x)\n\nNote\n-------\n\nSince I\'m not familiar with the quantization literature, I\'m flexible with my evaluation based on what other reviewers with more expertise have to say.']","[60, 60, 70]","[80, 70, 80]","[""The sentiment score is 60 (positive) because the reviewer expresses overall approval of the paper, noting its ease of follow, relevance, and impressive results. They mention some minor concerns about novelty but still keep their original positive rating. The politeness score is 80 (quite polite) due to the reviewer's constructive tone, use of phrases like 'interesting and relevant,' and the encouraging suggestion for additional experiments. The reviewer balances critique with praise and offers suggestions in a respectful manner, avoiding harsh language or direct criticism."", ""The sentiment score is 60 (positive) because the reviewer starts by acknowledging that their concerns have been addressed and they are increasing their score. The overall tone is constructive, noting the paper's strengths (novel technique, clear explanation, improvement over existing approaches) while also raising some questions and concerns. The reviewer concludes that the paper warrants acceptance, indicating a generally positive sentiment. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits and framing criticisms as questions or areas for improvement rather than harsh judgments. Phrases like 'I have a few questions/concerns' and 'It would have been nice to have' demonstrate a considerate approach to providing feedback. The reviewer also balances critiques with positive observations, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper. They highlight several pros, including clear goals, well-explained methods, and strong experimental results. The only significant con mentioned is a suggestion for additional experiments. The reviewer also notes the paper is clearly written and technically correct. The politeness score is 80 (polite) due to the reviewer's constructive and respectful tone throughout. They offer suggestions and point out minor typos in a helpful manner, and express openness to other reviewers' opinions. The language used is professional and courteous, avoiding any harsh criticism.""]"
"['This paper proposes to add new inductive bias to neural network architecture - namely a divide and conquer strategy know from algorithmics. Since introduced model has to split data into subsets, it leads to non-differentiable paths in the graph, which authors propose to tackle with RL and policy gradients. The whole model can be seen as an RL agent, trained to do splitting action on a set of instances in such a way, that jointly trained predictor T quality is maximised (and thus its current log prob: log p(Y|P(X)) becomes a reward for an RL agent). Authors claim that model like this (strengthened with pointer networks/graph nets etc. depending on the application) leads to empirical improvement on three tasks - convex hull finding, k-means clustering and on TSP.  However, while results on convex hull task are good, k-means ones use a single, artificial problem (and do not test DCN, but rather a part of it), and on TSP DCN performs significantly worse than baselines in-distribution, and is better when tested on bigger problems than it is trained on. However the generalisation scores themselves are pretty bad thus it is not clear if this can be called a success story.\n\nI will be happy to revisit the rating if the experimental section is enriched.\n\nPros:\n- very easy to follow idea and model\n- simple merge or RL and SL in an end-to-end trainable model\n- improvements over previous solutions\n\nCons:\n- K-means experiments should not be run on artificial dataset, there are plenty of benchmarking datasets out there. In current form it is just a proof of concept experiment rather than evaluation (+ if is only for splitting, not for the entire architecture proposed). It would be also beneficial to see the score normalised by the cost found by k-means itself (say using Lloyd\'s method), as otherwise numbers are impossible to interpret. With normalisation, claiming that it finds 20% worse solution than k-means is indeed meaningful. \n- TSP experiments show that ""in distribution"" DCN perform worse than baselines, and when generalising to bigger problems they fail more gracefully, however the accuracies on higher problem are pretty bad, thus it is not clear if they are significant enough to claim success. Maybe TSP is not the best application of this kind of approach (as authors state in the paper - it is not clear how merging would be applied in the first place). \n- in general - experimental section should be extended, as currently the only convincing success story lies in convex hull experiments\n\nSide notes:\n- DCN is already quite commonly used abbreviation for ""Deep Classifier Network"" as well as ""Dynamic Capacity Network"", thus might be a good idea to find different name.\n- please fix \\cite calls to \\citep, when authors name is not used as part of the sentence, for example:\nGraph Neural Network Nowak et al. (2017) \nshould be\nGraph Neural Network (Nowak et al. (2017))\n\n# After the update\n\nEvaluation section has been updated threefold:\n- TSP experiments are now in the appendix rather than main part of the paper\n- k-means experiments are Lloyd-score normalised and involve one Cifar10 clustering\n- Knapsack problem has been added\n\nPaper significantly benefited from these changes, however experimental section is still based purely on toy datasets (clustering cifar10 patches is the least toy problem, but if one claims that proposed method is a good clusterer one would have to beat actual clustering techniques to show that), and in both cases simple problem-specific baseline (Lloyd for k-means, greedy knapsack solver) beats proposed method. I can see the benefit of trainable approach here, the fact that one could in principle move towards other objectives, where deriving Lloyd alternative might be hard; however current version of the paper still does not show that.\n\nI increased rating for the paper, however in order to put the ""clear accept"" mark I would expect to see at least one problem where proposed method beats all basic baselines (thus it has to either be the problem where we do not have simple algorithms for it, and then beating ML baseline is fine; or a problem where one can beat the typical heuristic approaches).\n\n', 'Summary of paper:\n\nThe paper proposes a unique network architecture that can learn divide-and-conquer strategies to solve algorithmic tasks.\n\nReview:\n\nThe paper is clearly written. It is sometimes difficult to communicate ideas in this area, so I appreciate the author\'s effort in choosing good notation. Using an architecture to learn how to split the input, find solutions, then merge these is novel. Previous work in using recursion to solve problems (Cai 2017) used explicit supervision to learn how to split and recurse. The ideas and formalism of the merge and partition operations are valuable contributions. \n\nThe experimental side of the paper is less strong. There are good results on the convex hull problem, which is promising. There should also be a comparison to a k-means solver in the k-means section as an additional baseline. I\'m also not sure TSP is an appropriate problem to demonstrate the method\'s effectiveness. Perhaps another problem that has an explicit divide and conquer strategy could be used instead. It would also be nice to observe failure cases of the model. This could be done by visually showing the partition constructed or seeing how the model learned to merge solutions.\n\nThis is a relatively new area to tackle, so while the experiments section could be strengthened, I think the ideas present in the paper are important and worth publishing.\n\nQuestions:\n\n1. What is \\rho on page 4? I assume it is some nonlinearity, but this was not specified.\n2. On page 5, it says the merge block takes as input two sequences. I thought the merge block was defined on sets? \n\nTypos:\n1. Author\'s names should be enclosed in parentheses unless part of the sentence.\n2. I believe ""then"" should be removed in the sentence ""...scale invariance, then exploiting..."" on page 2.', 'This paper studies problems that can be solved using a dynamic programming approach and proposes a neural network architecture called Divide and Conquer Networks (DCN) to solve such problems. The network has two components: one component learns to split the problem and the other learns to combine solutions to sub-problems. Using this setup, the authors are able to beat sequence to sequence baselines on problems that are amenable to such an approach. In particular the authors test their approach on computing convex hulls, computing a minimum cost k-means clustering, and the Euclidean Traveling Salesman Problem (TSP) problem. In all three cases, the proposed solution outperforms the baselines on larger problem instances. ']","[-20, 50, 80]","[50, 80, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('very easy to follow idea', 'simple merge of RL and SL', 'improvements over previous solutions'), they express significant concerns about the experimental section and results. The reviewer states that only the convex hull experiments are convincing, while the k-means and TSP experiments have notable limitations. Even after updates, the reviewer still finds the experimental section lacking, noting that it's based on 'purely toy datasets' and the proposed method doesn't beat simple baselines. The politeness score is moderately positive (50) because the reviewer uses professional and constructive language throughout. They offer specific suggestions for improvement, use phrases like 'I will be happy to revisit the rating', and acknowledge improvements made in the updated version. The tone remains respectful even when critiquing, using phrases like 'it would be beneficial' and 'please fix' rather than harsh commands."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's clear writing, novel ideas, and valuable contributions, while also pointing out areas for improvement in the experimental section. The overall tone suggests the paper is worth publishing despite some weaknesses. The politeness score is 80 (quite polite) due to the reviewer's respectful language, appreciation of the author's efforts, and constructive feedback. The reviewer uses phrases like 'I appreciate the author's effort' and offers specific suggestions for improvement rather than harsh criticism. The review also includes polite questions for clarification and helpfully points out typos."", ""The sentiment score is 80 (positive) because the review highlights the strengths of the paper without any explicit criticism. It describes the proposed method (DCN) as outperforming baselines on multiple problems, especially for larger instances. The reviewer seems impressed by the approach and its results. The politeness score is 50 (slightly polite) because the language is professional and neutral, without any overtly polite phrases or personal compliments, but also without any rudeness or harsh criticism. The reviewer objectively describes the paper's content and findings without using emotional or judgmental language.""]"
"['This paper introduces LAX/RELAX, a method to reduce the variance of the REINFORCE gradient estimator. The method builds on and is directly inspired by REBAR. Similarly to REBAR, RELAX is an unbiased estimator, and the idea is to introduce a control variate that leverages the reparameterization gradient. In contrast to REBAR, RELAX learns a free-from control variate, which allows for low-variance gradient estimates for both discrete and continuous random variables. The method is evaluated on a toy experiment, as well as the discrete VAE and reinforcement learning. It effectively reduces the variance of state-of-the-art methods (namely, REBAR and actor-critic).\n\nOverall, I enjoyed reading the paper. I think it is a neat idea that can be of interest for researchers in the field. The paper is clearly explained, and I found the experiments convincing. I have minor comments only.\n\n+ Is there a good way to initialize c_phi prior to optimization? Given that c_phi must be a proxy for f(), maybe you can take advantage of this observation to find a good initialization for phi?\n\n+ I was confused with the Bernoulli example in Appendix B. Consider the case theta=0.5. Then, b=H(z) takes value 1 if z>0, and 0 otherwise. Thus, p(z|b,theta) should assign mass zero to values z>0 when b=0, which does not seem to be the case with the proposed sampling scheme in page 11, since v*theta=0.5*v, which gives values in [0,0.5]. And similarly for the case b=1.\n\n+ Why is the method called LAX? What does it stand for?\n\n+ In Section 3.3, it is unclear to me why rho!=phi. Given that c_phi(z)=f(sigma_lambda(z))+r_rho(z), with lambda being a temperature parameter, why isn\'t rho renamed as phi? (the first term doesn\'t seem to have any parameters). In general, this section was a little bit unclear if you are not familiar with the REBAR method; consider adding more details.\n\n+ Consider adding a brief review of the REBAR estimator in the Background section for those readers who are less familiar with this approach.\n\n+ In the abstract, consider adding two of the main ideas that the estimator relies on: control variates and reparameterization gradients. This would probably be more clear than ""based on gradients of a learned function.""\n\n+ In the first paragraph of Section 3, the sentence ""f is not differentiable or not computable"" may be misleading, because it is unclear what ""not computable"" means (one may think that it cannot be evaluated). Consider replacing with ""not analytically computable.""\n\n+ In Section 3.3, it reads ""differentiable function of discrete random variables,"" which does not make sense.\n\n+ Before Eq. 11, it reads ""where epsilon_t does not depend on theta"". I think it should be the distribution over epsilon_t what doesn\'t depend on theta.\n\n+ In Section 6.1, it was unclear to me why t=.499 is a more challenging setting.\n\n+ The header of Section 6.3.1 should be removed, as Section 6.3 is short.\n\n+ In Section 6.3.1, there is a broken reference to a figure.\n\n+ Please avoid contractions (doesn\'t, we\'ll, it\'s, etc.)\n\n+ There were some other typos; please read carefully the paper and double-check the writing. In particular, I found some missing commas, some proper nouns that are not capitalized in Section 5, and others (e.g., ""an learned,"" ""gradient decent"").', 'This paper suggests a new approach to performing gradient descent for blackbox optimization or training discrete latent variable models. The paper gives a very clear account of existing gradient estimators and finds a way to combine them so as to construct and optimize a differentiable surrogate function. The resulting new gradient estimator is then studied both theoretically and empirically. The empirical study shows the benefits of the new estimator for training discrete variational autoencoders and for performing deep reinforcement learning.\n\nTo me, the main strengths of the paper is the very clear account of existing gradient estimators (among other things it helped me understand obscurities of the Q-prop paper) and a nice conceptual idea. The empirical study itself is more limited and the paper suffers from a few mistakes and missing information, but to me the good points are enough to warrant publication of the paper in a good conference like ICLR.\n\nBelow are my comments for the authors.\n\n---------------------------------\nGeneral, conceptual comments:\n\nWhen reading (6), it is clear that the framework performs regression of $c_\\phi$ towards the unknown $f$ simultaneously with optimization over $c_\\phi$.\nTaking this perspective, I would be glad to see how the regression part performs with respect to standard least square regression,\ni.e. just using $||f(b)-c_\\phi(b)||^2$ as loss function. You may compare the speed of convergence of $c_\\phi$ towards $f$ using (6) and the least squared error.\nYou may also investigate the role of this regression part into the global g_LAX optimization by studying the evolution of the components of (6).\n\nRelated to the above comment, in Algo. 1, you mention ""f(.)"" as given to the algo. Actually, the algo does not know f itself, otherwise it would not be blackbox optimization. So you may mean different things. In a batch setting, you may give a batch of [x,f(x) (,cost(x)?)] points to the algo. You more probably mean here that you have an ""oracle"" that, given some x, tells you f(x) on demand. But the way you are sampling x is not specified clearly.\n\nThis becomes more striking when you move to reinforcement learning problems, which is my main interest. The RL algorithm itself is not much specified. Does it use a replay buffer (probably not)? Is it on-policy or off-policy (probably on-policy)? What about the exploration policy? I want to know more... Probably you just replace (10) with (11) in A2C, but this is not clearly specified.\n\nIn Section 4, can you explain why, in the RL case, you must introduce stochasticity to the inputs? Is this related to the exploration issue (see above)?\n\nLast sentence of conclusion: you are too allusive about the relationship between your learned control variate and the Q-function. I don\'t get it, and I want to know more...\n\n-----------------------------------\nLocal comments:\n\nBackpropagation through the void: I don\'t understand why this title. I\'m not a native english speaker, I\'m probably missing a reference to something, I would be glad to get it.\n\nFigure 1 right. Caption states variance, but it is log variance. Why does it oscillate so much with RELAX?\n\nBeginning of 3.1: you may state more clearly that optimizing $c_\\phi$ the way you do it will also ""minimize"" the variance, and explain better why (""we require the gradient of the variance of our gradient estimator""...). It took me a while to get it.\n\nIn 3.1.1 a weighting based on $\\d/\\d\\theta log p(b)$ => shouldn\'t you write $... log p(b|\\theta)$ as before?\n\nFigure 2 is mentioned in p.3, it should appear much sooner than p6.\n\nIn Figure 2, there is nothing about the REINFORCE PART. Why?\n\nIn 3.4 you alternate sums over an infinite horizon and sums over T time steps. You should stick to the T horizon case, as you mention the case T=1 later.\n\np6 Related work\n\nThe link to the work of Salimans 2017 is far from obvious, I would be glad to know more...\n\nQ-prop (Haarnoja et al.,2017): this is not the adequate reference to Q-prop, it should be (Gu et al. 2016), you have it correct later ;)\n\nFigure 3: why do you stop after so few epochs? I wondered how expensive is the computation of your estimator, but since in the RL case you go up to 50 millions (or 4 millions?), it\'s probably not the issue. I would be glad to see another horizontal lowest validation error for your RELAX estimator (so you need to run more epochs).\n""ELBO"" should be explained here (it is only explained in the appendices).\n\n6.2, Table 1: Best obtained training objective: what does this mean? Should it be small or large? You need to explain better. How much is the modest improvement (rather give relative improvement in the text?)? To me, you should not defer Table 3 to an appendix (nor Table 4).\n\nFigure 4: Any idea why A2C oscillates so much on inverted pendulum? Any idea why variance starts to decrease after 500 episodes using RELAX? Isn\'t related to the combination of regression and optimization, as suggested above?\n\nAbout Double Inverted Pendulum, Appendix E3 mentions 50 million frames, but the figure shows 4 millions steps. Where is the truth?\n\nWhy do you give steps for the reward, and episodes for log-variance? The caption mentions ""variance (log-scale)"", but saying ""log-variance"" would be more adequate.\n\np9: the optimal control variate: what is this exactly? How do you compare a control variate over another? This may be explained in Section 2.\n\nGAE (Kimura, 2000). I\'m glad you refer to former work (there is a very annoying tendency those days to refer only to very recent papers from a small set of people who do not correctly refer themselves to previous work), but you may nevertheless refer to John Schulman\'s paper about GAEs anyways... ;)\n\nAppendix E.1 could be reorganized, with a common hat and then E.1.1 for one layer model(s?) and E.1.2 for the two layer model(s?)\n\nA sensitivity analysis wrt to your hyper-parameters would be welcome, this is true for all empirical studies.\n\nIn E2, is the output layer linear? You just say it is not ReLU...\n\nThe networks used in E2 are very small (a standard would be 300 and 400 neurons in hidden layers). Do you have a constraint on this?\n\n""As our control variate does not have the same interpretation as the value function of A2C, it was not directly clear how to add reward bootstrapping and other variance reduction techniques common in RL into our model. We leave the task of incorporating these and other variance reduction techniques to future work.""\nFirst, this is important, so if this is true I would move this to the main text (not in appendix).\nBut also, it seems to me that the first sentence of E3 contradicts this, so where is the truth?\n\n{0.01,0.003,0.001} I don\'t believe you just tried these values. Most probably, you played with other values before deciding to perform grid search on these, right?\nThe same for 25 in E3.\n\nGlobally, you experimental part is rather weak, we would expect a stronger methodology, more experiments also with more difficult benchmarks (half-cheetah and the whole gym zoo ;)), more detailed analyses of the results, but to me the value of your paper is more didactical and conceptual than experimental, which I really appreciate, so I will support your paper despite these weaknesses.\n\nGood luck! :)\n\n---------------------------------------\nTypos:\n\np5\nmonte-carlo => Monte(-)Carlo (no - later...)\ntaylor => Taylor\nyou should always capitalize Section, equation, table, figure, appendix, ...\n\ngradient decent => descent (twice)\n\np11: probabalistic\n\np15 ELU(Djork-... => missing space\n\n', 'The paper considers the problem of choosing the parameters of distribution to maximize an expectation over that distribution. This setting has attracted a huge interest in ML communities (that is related to learning policy in RL as well as variational inference with hidden variables). The paper provides a framework for such optimization, by interestingly combining three standard ways. \n\nGiven Tucker et al, its contribution is somehow incremental, but I think it is an interesting idea to use neural networks for control variate to handle the case where f is unknown.  \n\nThe main issue of this paper seems to be in limited experimental results; they only showed three quite simple experiments (I guess they need to focus one setting; RL or VAE). Moreover, it would be good to actually show if the variation of g_hat is much smaller than other standard methods.\n   \nThere is missing reference at page 8.\n\n']","[70, 70, 20]","[80, 80, 50]","[""The sentiment score is 70 (positive) because the reviewer expresses enjoyment in reading the paper, describes it as 'clearly explained' and the experiments as 'convincing'. They also mention it's a 'neat idea' that can be of interest to researchers. The overall tone is positive, with only 'minor comments' mentioned. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms as suggestions or questions rather than direct criticisms. They use phrases like 'Consider adding...' and 'I was confused with...' which maintain a polite tone. The reviewer also balances positive feedback with areas for improvement, which is a hallmark of polite academic discourse."", ""The sentiment score is 70 (positive) because the reviewer expresses that the paper has clear strengths, particularly in its clear explanation of existing gradient estimators and its novel conceptual idea. The reviewer explicitly states that these good points are 'enough to warrant publication of the paper in a good conference like ICLR'. However, it's not a perfect score as the reviewer also mentions some limitations in the empirical study and notes some mistakes and missing information. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and even wishes the authors 'Good luck!' at the end. The reviewer also uses phrases like 'I would be glad to see' and 'I want to know more', showing interest and engagement rather than harsh criticism. The tone is generally encouraging and helpful, though not overly formal or deferential, hence the high but not perfect score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting idea and contribution, albeit incremental. They mention the paper 'provides a framework' and uses an 'interesting' combination of methods. However, they also point out limitations in experimental results, which prevents a higher positive score. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, avoiding harsh criticism. They use phrases like 'I think it is an interesting idea' and 'it would be good to', which suggest constructive feedback rather than blunt criticism. The reviewer also balances positive aspects with areas for improvement, maintaining a professional and courteous tone.""]"
"['Reading this paper feels like reading at least two closely-related papers compressed into one, with overflow into the appendix (e.g. one about the EMS module, one about the the recurrent voting, etc).\n\nThere were so many aspects/components, that I am not entirely confident I fully understood how they all work together, and in fact I am pretty confident there was at least some part of this that I definitely did not understand. Reading it 5-20 more times would most likely help.\n\nFor example, consider the opening example of Section 3. In principle, this kind of example is great, and more of these would be very useful in this paper. This particular one raises a few questions:\n-Eq 5 makes it so that $(W \\Psi)$ and $(a_x)$ need to be positive or negative together.  Why use ReLu\'s here at all? Why not just $sign( (W \\Psi) a_x) $? Multiplying them will do the same thing, and is much simpler. I am probably missing something here, would like to know what it is... (Or, if the point of the artificial complexity is to give an example of the 3 basic principles, then perhaps point this out, or point out why the simpler version I just suggested would not scale up, etc)\n-what exactly, in this example, does $\\Psi$ correspond to? In prev discussion, $\\Psi$ is always written with subscripts to denote state history (I believe), so this is an opportunity to explain what is different here. \n-Nitpick: why is a vector written as $W$? (or rather, what is the point of bold vs non-bold here?)\n-a non-bold version of $Psi$, a few lines below, seems to correspond to the 4096 features of VGG\'s FC6, so I am still not sure what the bold version represents\n\n-The defs/eqns at the beginning of section 3.1 (Sc, CReLu, etc) were slightly hard to follow and I wonder whether there were any typos, e.g. was CReS meant to refer directly to Sc, but used the notation ${ReLu}^2$ instead? \n\nEach of these on its own would be easier to overlook, but there is a compounding effect here for me, as a reader, such that by further on in the paper, I am rather confused.\n\nI also wonder whether any of the elements described, have more ""standard"" interpretations/notations. For example, my slight confusion propagated further: after above point, I then did not have a clear intuition about $l_i$ in the EMS module. I get that symmetry has been built in, e.g. by the definitions of CReS and CReLu, etc, but I still don\'t see how it all works together, e.g. are late bottleneck architectures *exactly* the same as MLPs, but where inputs have simply been symmetrized, squared, etc? Nor do I have intuition about multiplicative symmetric interactions between visual features and actions, although I do get the sense that if I were to spend several hours implementing/writing out toy examples, it would clarify it significantly (in fact, I wouldn\'t be too surprised if it turns out to be fairly straightforward, as in my above comment indicating a seeming equivalence to simply multiplying two terms and taking the resulting sign). If the paper didn\'t need to be quite as dense, then I would suggest providing more elucidation for the reader, either with intuitions or examples or clearer relationships to more familiar formulations.\n\nLater, I did find that some of the info I *needed* in order to understand the results (e.g. exactly what is meant by a ""symmetry ablation"", how was that implemented?) was in fact in the appendices (of which there are over 8 pages).\n\nI do wonder how sensitive the performance of the overall system is to some of the details, like, e.g. the low-temp Boltzmann sampling rather than identity function, as described at the end of S2.\n\nMy confidence in this review is somewhere between 2 and 3.\n\nThe problem is an interesting one, the overall approach makes sense, it is clear the authors have done a very substantial  amount of work, and very diligently so (well-done!), some of the ideas are interesting and seem creative, but I am not sure I understand the glue of the details, and that might be very important here in order to assess it effectively.', 'The paper comprises several ideas to study the continual learning problem. First, they show an ad-hoc designed environment, namely the Touchstream environment, in which both inputs and actions are represented in a huge space: as it happens with humans – for example when they are using a touch screen – the resolution of the input space, i.e. the images, is at least big as the resolution of the action space, i.e. where you click on the screen. This environment introduces the interesting problem of a direct mapping between input and actions. Second, they introduce an algorithm to solve this mapping problem in the Touchstream space. Specifically, the ReMaP algorithm learns to solve typical neuroscience tasks, by optimizing a computational module that facilitates the mapping in this space. The Early Bottleneck Multiplicative Symmetric (EMS) module extends the types of computation you might need to solve the tasks in the Touchstream space. Third, the authors introduce another module to learn how to switch from task to task in a dynamical way.\nThe main concern with this paper is about its length. While the conference does not provide any limits in terms of number of pages, the 13 pages for the main text plus other 8 for the supplementary material is probably too much. I am wondering if the paper just contains too much information for a single conference publication. \nAs a consequence, either the learning of the single tasks and the task switching experiments could have been addressed with further details. In case of single task learning, the tasks are relatively simple where k_beta = 1 (memory) and k_f = 2 (prediction) are sufficient to solve the tasks. It would have been interesting to evaluate the algorithm on more complex tasks, and how these parameters affect the learning. In case of the task switching a more interesting question would be how the network learns a sequence of tasks (more than one switch). \nOverall, the work is interesting, well described and the results are consistent. \nSome questions:\n- the paper starts with clear inspiration from Neuroscience, but nothing has been said on the biological plausibility of the ReMap, EMS and the recurrent neural voting;\n- animals usually learn in continuous-time, thus such tasks usually involve a time component, while this work is designed in a time step framework; could the author argument on that? (starting from Doya 2000)\n- specifically, the MTS and the Localization tasks involve working memory, thus a comparison with other working memory with reinforcement learning would make more sense that different degree of ablated modules. (for example Bakker 2002)\n\nMinor:\n- Fig 6 does not have letters\n- TouchStream is sometimes written as Touchstream\n\nRef.\nDoya, K. (2000). Reinforcement learning in continuous time and space. Neural Computation, 12(1), 219–245.\nBakker, B. (2002). Reinforcement Learning with Long Short-Term Memory. In T. G. Dietterich, S. Becker, & Z. Ghahramani (Eds.), (pp. 1475–1482). Presented at the Advances in Neural Information Processing Systems 14, MIT Press.\n\n\n\n', 'The authors propose a kind of framework for learning to solve elemental tasks and then learning task switching in a multitask scenario. The individual tasks are inspired by a number of psychological tasks. Specifically, the authors use a pretrained convnet as raw statespace encoding together with previous actions and learn through stochastic optimization to predict future rewards for different actions. These constitute encapsulated modules for individual tasks. The authors test a number of different ways to construct the state representations as inputs to these module and report results from extensive simulations evaluating them. The policy is obtained through a heuristic, selecting actions with highest reward prediction variance across multiple steps of lookahead. Finally, two variants of networks are presented and evaluated, which have the purpose of selecting the appropriate module when a signal is provided to the system that a new task is starting.\n\nI find it particularly difficult to evaluate this manuscript. The presented simulation results are based on the described system, which is very complex and contains several, non-standard components and heuristic algorithms. \n\nIt would be good to motivate the action selection a bit further. E.g., the authors state that actions are sampled proportionally to the reward predictions and assure properties that are not necessarily intuitive, e.g. that a few reward in the future can should be equated to action values. It is also not clear under which conditions the proposed sampling of actions and the voting results in reward maximization. No statements are made on this other that empirically this worked best.  \n\nIs the integral in eq. 1 appropriate or should it be a finite sum?\n\nIt seems, that the narrowing of the spatial distribution relative to an \\epsilon -greedy policy would highly depend on the actual reward landscape, no? Is the maximum variance as well suited for exploration as for exploitation and reward maximization?\n\nWhat I find a bit worrisome is the ease with which the manuscript switches between  “inspiration” from psychology and neuroscience to plausibility of proposing algorithms to reinterpreting aimpoints as “salience” and feature extraction as “physical structure”. This necessarily introduces a number of \n\nOverall, I am not sure what I have learned with this paper. Is this about learning psychological tasks? New exploration policies? Arbitration in mixtures of experts? Or is the goal to engineer a network that can solve tasks that cannot be solved otherwise? I am a bit lost.\n\n\nMinor points:\n“can from”']","[-20, 50, -30]","[60, 75, 20]","[""The sentiment score is slightly negative (-20) because the reviewer expresses confusion and difficulty understanding parts of the paper, mentioning that it feels like 'reading at least two closely-related papers compressed into one' and that they are 'not entirely confident' they fully understood how all components work together. However, the reviewer also acknowledges the interesting problem, substantial work done, and creative ideas, which prevents the score from being more negative. The politeness score is moderately positive (60) as the reviewer maintains a respectful tone throughout, using phrases like 'I am probably missing something here, would like to know what it is' and 'well-done!' when acknowledging the authors' efforts. The reviewer also offers constructive feedback and suggestions for improvement, rather than harsh criticism. The language is professional and considerate, even when pointing out areas of confusion or potential issues."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting ideas and consistent results, but also expresses concerns about its length and suggests areas for improvement. The overall tone is balanced, with both positive and constructive feedback. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as suggestions or questions, and acknowledges the paper's strengths. The reviewer uses phrases like 'I am wondering if' and 'it would have been interesting' to soften critiques, and concludes with a positive overall assessment. The use of 'could' and 'would' also contributes to the polite tone."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the extensive simulations and evaluations, they express significant concerns and confusion about the paper's purpose and methodology. Phrases like 'I find it particularly difficult to evaluate this manuscript,' 'It would be good to motivate...,' and 'I am a bit lost' indicate a lack of clarity and some skepticism. The politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout, using phrases like 'It would be good to...' instead of more direct criticisms. They also acknowledge the authors' efforts in conducting 'extensive simulations.' However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a mostly neutral, academic tone.""]"
"['This paper present the application of the memory buffer concept to speech synthesis, and additionally learns a ""speaker vector"" that makes the system adaptive and work reasonably well on ""in-the-wild"" speech data. This is a relevant problem, and a novel solution, but synthesis is a wicked problem to evaluate, so I am not sure if ICLR is the best venue for this paper. I see two competing goals:\n\n- If the focus is on showing that the presented approach outperforms other approaches under given conditions, a different task would be better (for example recognition, or some sort of trajectory reconstruction)\n- If the focus is on showing that the system outperforms other synthesis systems, then a speech oriented venue might be best (and it is unfortunate that optimized hyper-parameters for the other systems are not available for a fair comparsion)\n- If fair comparisons with the other appraoches cannot be made, my sense is that the multi-speaker (post-training fitting) option is really the most interesting and novel contribution here, which could be discussed in mroe detail\n\nStill, the approach is creative and interesting and deserves to be presented. I have a few questions/ suggestions:\n\nIntroduction\n\n- The link to Baddeley\'s ""phonological loop"" concept seems weak at best. There is nothing phonological about the features that this model stores and retrieves, and no evidence that the model behaves in a way consistent with ""phonologcial"" (or articulatory) assumptions or models - maybe best to avoid distracting the reader with this concept and strengthen the speaker adaptation aspect?\n- The memory model is not an RNN, but it is a recurrently called structure (as the name ""phonological loop"" also implies) - so I would also not highlight this point much\n- Why would the four properties of the proposed method (mid of p. 2, end of introduction: memory buffer, shared memory, shallow fully connected networks, and simple reader mechanism) lead to better robustness and improve performance on noisy and limited training data? Maybe the proposed approach works better for any speech synthesis task? Why specifically for ""in-the-wild"" data? The results in Table 2 show that the proposed system outperforms other systems on Blizzard 2013, but not Blizzard 2011 - does this support the previous argument?\n- Why not also evaluate MCD scores? This should be a quick and automatic way to diagnose what the system is doing? Or is this not meaningful with the noisy training data?\n\nPrevious work\n\n- Please introduce abbreviations the first time they are used (""CBHG"" for example)\n- There is other work on using ""in-the-wild"" speech as well: Pallavi Baljekar and Alan W Black. Utterance Selection Techniques for TTS Systems using Found Speech, SSW 2016, Sunnyvale, USA Sept 2016\n\nThe architecture\n- Please explain the ""GMM"" (Gaussian Mixture Model?) attention mechanism in a bit more detail, how does back-propagation work in this case?\n- Why was this approach chosen? Does it promise to be robust or good for low data situations specifically?\n- The fonts in Figure 2 are very small, please make them bigger, and the Figure may not print well in b/w. Why does the mean of the absolute weights go up for high buffer positions? Is there some ""leaking"" from even longer contexts?\n- I don\'t understand ""However, human speech is not deterministic and one cannot expect [...] truth"". You are saying that the model cannot be excepted to reproduce the input exactly? Or does this apply only to the temporal distribution of the sequence (but not the spectral characteristics)? The previous sentence implies that it does. And how does teacher-forcing help in this case?\n- what type of speed is ""x5""? Five times slower or faster than real-time?\n\nExperiments\n- Table 2: maybe mention how these results were computed, i.e. which systems use optimized hyper parameters, and which don\'t? How do these results support the interpretation of hte results in the introruction re in-the-wild data and found data?\n- I am not sure how to read Figure 4. Maybe it would be easier to plot the different phone sequences against each other and show how the timings are off, i.e. plot the time of the center of panel one vs the time of the center of panel 2 for the corresponding phone, and show how this is different from a straight line. Or maybe plot phones as rectangles that get deformed from square shape as durations get learned?\n- Figure 5: maybe provide spectrograms and add pitch contours to better show the effect of the dfifferent intonations? \n- Figure 4 uses a lot of space, could be reduced, if needed\n\nDiscussion\n- I think the first claim is a bit to broad - nowhere is it shown that the method is inherently more robust to clapping and laughs, and variable prosody. The authors will know the relevant data-sets better than I do, maybe they can simply extend the discussion to show that this is what happens. \n- Efficiency: I think Wavenet has also gotten much faster and runs in less than real-time now - can you expand that discussion a bit, or maybe give estimates in times of FLOPS required, rather than anecdotal evidence for systems that may or may not be comparable?\n\nConclusion\n- Now the advantage of the proposed model is with the number of parameters, rather than the computation required. Can you clarify? Are your models smaller than competing models?\n', 'This paper studies the problem of text-to-speech synthesis (TTS) ""in the wild"" and proposes to use the shifting buffer memory. \n\nSpecifically, an input text is transformed to phoneme encoding and then context vector is created with attention mechanism. With context, speaker ID, previous output, and buffer, the new buffer representation is created with a shallow fully connected neural network and inserted into the buffer memory. Then the output is created by buffer and speaker ID with another fully connected neural network. A novel speaker can be adapted just by fitting it with SGD while fixing all other components.\n\nIn experiments, authors try single-speaker TTS and multi-speaker TTS along with speaker identification (ID), and show that the proposed approach outperforms baselines, namely, Tacotron and Char2wav. Finally, they use the challenging Youtube data to train the model and show promising results.\n\nI like the idea in the paper but it has some limitations as described below:\n\nPros:\n1. It uses relatively simple and less number of parameters by using shallow fully-connected neural networks. \n2. Using shifting buffer memory looks interesting and novel.\n3. The proposed approach outperforms baselines in several tasks, and the ability to fit to a novel speaker is nice. But there are some issues as well (see Cons.)\n\nCons:\n1. Writing is okay but could be improved. Some notations were not clearly described in the text even though it was in the table. \n2. Baselines. The paper says Deep Voice 2 (Arik et al., 2017a) is only prior work for multi-speaker TTS. However, it was not compared to. Also for multi-speaker TTS, in (Arik et al., 2017a), Tacotron (Wang et al., 2017) was used as a baseline but in this paper only Char2wav was employed as a baseline. Also for Youtube dataset, it would be great if some baselines were compared with like  (Arik et al., 2017a).\n\n\nDetailed comment:\n1. To demonstrate the efficiency of the proposed model, it would be great to have the numbers of parameters for the proposed model and baseline models.\n2. I was not so clear about how to fit a new speaker and adding more detail would be good.\n3. Why do you think your model is better than VCTK test split, and even VCTK85 is better than VCTK101?', ""This is an interesting paper investigating a novel neural TTS strategy that can generate speech signals by sampling voices in the wild.  The main idea here is to use a working memory with a shifting buffer.  I also listened to the samples posted on github and the quality of the generated voices seems to be OK considering that the voices are actually sampled in the wild. Compared to other state-of-the-art systems like wavenet, deep voice and tacotron, the proposed approach here is claimed to be simpler and relatively easy to deploy in practice.   Globally this is a good piece of work with solid performance. However, I have some (minor) concerns.\n\n1.  Although the authors claim that there is no RNNs involved in the architectural design of the system,  it seems to me that  the working memory with a shifting buffer which takes the previous output as one of its inputs is a network with recurrence. \n\n2. Since the working memory is the key in the architectural design of VoiceLoop, it would be helpful to show its behavior under various configurations and their impact to the performance. For instance,  how will  the length of the running buffer affect the final quality of the voice? \n\n3. A new speaker's voice is generated by only providing the speaker's embedding vector to the system.  This will require a large number of speakers in the training data in the first place to get the system learn the spread of speaker embeddings in the latent (embedding) space.  What will happen if a new speaker's acoustic characteristics are obvious far away from the training speakers?  For instance, a girl voice vs. adult male training speakers.  In this case, the embedding of the girl's voice will show up in the sparse region of the embedding space of training speakers.  How does it affect the performance of the system?  It would be interesting to know. ""]","[-20, 50, 70]","[60, 70, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's creativity and interesting approach, they express doubts about its suitability for the ICLR venue and suggest alternative focuses or venues. They also point out several areas for improvement and clarification. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their suggestions as questions or recommendations rather than demands. They acknowledge the paper's merits while providing detailed feedback for improvement, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses liking the idea of the paper and notes several pros, but also points out significant limitations and cons. The overall tone is balanced, leaning slightly positive. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. Phrases like 'I like the idea' and 'it would be great if' contribute to the polite tone. The reviewer maintains a professional and courteous demeanor while providing both positive and negative feedback."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'interesting' and 'a good piece of work with solid performance'. They praise the novel approach and the quality of generated voices. However, it's not 100 as they express some 'minor concerns'. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting concerns. They use phrases like 'it would be helpful' and 'it would be interesting to know', which are polite ways of suggesting improvements. The concerns are framed as questions or observations rather than direct criticisms, maintaining a courteous tone.""]"
"['The authors proposed to supplement adversarial training with an additional regularization that forces the embeddings of clean and adversarial inputs to be similar. The authors demonstrate on MNIST and CIFAR that the added regularization leads to more robustness to various kinds of attacks. The authors further propose to enhance the network with cascaded adversarial training, that is, learning against iteratively generated adversarial inputs, and showed improved performance against harder attacks. \n\nThe idea proposed is fairly straight-forward. Despite being a simple approach, the experimental results are quite promising.  The analysis on the gradient correlation coefficient and label leaking phenomenon provide some interesting insights.  \n\nAs pointed out in section 4.2, increasing the regularization coefficient leads to degenerated embeddings. Have the authors consider distance metrics that are less sensitive to the magnitude of the embeddings, for example, normalizing the inputs before sending it to the bidirectional or pivot loss, or use cosine distance etc.?\n\nTable 4 and 5 seem to suggest that cascaded adversarial learning have more negative impact on test set with one-step attacks than clean test set, which is a bit counter-intuitive. Do the authors have any insight on this? \n\nComments:\n1. The writing of the paper could be improved. For example, ""Transferability analysis"" in section 1 is barely understandable;\n2. Arrow in Figure 3 are not quite readable;\n3. The paper is over 11 pages. The authors might want to consider shrink it down the recommended length. ', 'The paper presents a novel adversarial training setup, based on distance based loss of the feature embedding.\n\n+ novel loss\n+ good experimental evaluation\n+ better performance\n- way too long\n- structure could be improved\n- pivot loss seems hacky\n\nThe distance based loss is novel, and significantly different from prior work. It seems to perform well in practice as shown in the experimental section.\nThe experimental section is extensive, and offers new insights into both the presented algorithm and baselines. Judging the content of the paper alone, it should be accepted.\n\nHowever, the exposition needs significant improvements to warrant acceptance. First, the paper is way too long and unfocused. The recommended length is 8 pages + 1 page for citations. This paper is 12+1 pages long, plus a 5 page supplement. I\'d highly recommend the authors to cut a third of their text, it would help focus the paper on the actual message: pushing their new algorithm. Try to remove any sentence or word that doesn\'t serve a purpose (help sell the algorithm).\nThe structure of the paper could also be improved. For example the cascade adversarial training is buried deep inside the experimental section. Considering that it is part of the title, I would have expected a proper exposition of the idea in the technical section (before any results are presented). While condensing the paper, consider presenting all technical material before evaluation.\nFinally, the pivot ""loss"" seems a bit hacky. First, the pivot objective and bidirectional loss are exactly the same thing. While the bidirectional loss is a proper loss and optimized as such (by optimizing both E^adv and E), the pivot objective is no loss function, as it does not correspond to any function any optimization algorithm could minimize. I\'d recommend the just remove the pivot objective, or at least not call it a loss.\n\nIn summary, the results and presented method are good, and eventually deserve publication. However the exposition needs to significantly improve for the paper to be ready for ICLR.', 'This paper improves adversarial training by adding to its traditional objective a regularization term forcing a clean example and its adversarial version to be close in the embedding space. This is an interesting idea which, from a robustness point of view (Xu et al, 2013) makes sense. Note that a similar strategy has been used in the recent past under the name of stability training. The proposed method works well on CIFAR and MNIST datasets. My main concerns are:\n\n\t- The adversarial objective and the stability objective are potentially conflicting. Indeed when the network misclassifies an example, its adversarial version is forced to be close to it in embedding space while the adversarial term promotes a different prediction from the clean version (that of the ground truth label). Have the authors considered this issue? Can they elaborate more on how they with this?\n\n\t- It may be significantly more difficult to make this work in such setting due to the dimensionality of the data. Did the authors try such experiment? It would be interesting to see these results. \n\nLastly, The insights regarding label leaking are not compelling.  Label leaking is not a mysterious phenomenon. An adversarially trained model learns on two different distributions. Given the fixed size of the hypothesis space explored (i.e., same architecture used for vanilla and adversarial training), It is natural that the statistics of the simpler distribution are captured better by the model. Overall, the paper contains valuable information and a method that can contribute to the quest of more robust models. I lean on accept side.  \n\n\n']","[60, 20, 50]","[70, 50, 70]","[""The sentiment score is 60 (positive) because the reviewer describes the idea as 'fairly straight-forward' but with 'quite promising' results. They also mention that the analysis provides 'interesting insights'. The overall tone is positive, with some constructive suggestions for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, asking questions rather than making demands, and offering suggestions in a considerate manner. They acknowledge the strengths of the paper while providing constructive feedback. The reviewer's comments about improving the writing and readability are presented as helpful suggestions rather than harsh criticisms."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and good performance of the proposed method, as well as the extensive experimental evaluation. However, they also point out significant issues with the paper's length, structure, and some technical aspects. The overall tone suggests the paper has merit but needs substantial improvements. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and balance criticism with praise. The language is not overly formal or deferential, but it remains respectful and focused on the paper's content rather than personal attacks."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting idea and its good performance on certain datasets. They also lean towards accepting the paper. However, they express some concerns and criticisms, which prevent a higher positive score. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the paper's contributions. They maintain a professional tone without using harsh or dismissive language. The reviewer also provides constructive feedback and explains their reasoning, which contributes to the polite tone.""]"
"['This paper proposed a framework to connect the solving of GAN with finding the saddle point of a minimax problem.\nAs a result, the primal-dual subgradient methods can be directly introduced to calculate the saddle point.\nAdditionally, this idea not only fill the relatviely lacking of theoretical results for GAN or WGAN, but also provide a new perspective to modify the GAN-type models.\nBut this saddle point model reformulation  in section 2 is quite standard, with limited theoretical analysis in Theorem 1.\nAs follows, the resulting algorithm 1 is also standard primal-dual method for a saddle point problem.\nMost important I think, the advantage of considering GAN-type model as a saddle point model is that first--order methods can be designed to solve it. But the numerical experiments part seems to be a bit weak, because the MINST or CIFAR-10 dataset is not large enough to test the extensibility for large-scale cases. ', 'In this paper, the authors study the relationship between training GANs and primal-dual subgradient methods for convex optimization. Their technique can be applied on top of existing GANs and can address issues such as mode collapse. The authors also derive a GAN variant similar to WGAN which is called the Approximate WGAN. Experiments on synthetic datasets demonstrate that the proposed formulation can avoid mode collapse. This is a strong contribution\n\nIn Table 2 the difference between inception scores for DCGAN and this approach seems significant to ignore. The authors should explain more possibly.\nThere is a typo in Page 2 – For all these varaints, -variants.\n', 'This paper formulates GAN as a Lagrangian of a primal convex constrained optimization problem. They then suggest to modify the updates used in the standard GAN training to be similar to the primal-dual updates typically used by primal-dual subgradient methods.\n\nTechnically, the paper is sound. It mostly leverages the existing literature on primal-dual subgradient methods to modify the GAN training procedure. I think this is a nice contribution that does yield to some interesting insights. However I do have some concerns about the way the paper is currently written and I find some claims misleading.\n\nPrior convergence proofs: I think the way the paper is currently written is misleading. The authors quote the paper from Ian Goodfellow: “For GANs, there is no theoretical prediction as to\nwhether simultaneous gradient descent should converge or not.”. However, the f-GAN paper gave a proof of convergence, see Theorem 2 here: https://arxiv.org/pdf/1606.00709.pdf. A recent NIPS paper by (Nagarajan and Kolter, 2017) also study the convergence properties of simultaneous gradient descent. Another problem is of course the assumptions required for the proof that typically don’t hold in practice (see comment below).\n\nConvex-concave assumption: In practice the GAN objective is optimized over the parameters of the neural network rather than the generative distribution. This typically yields a non-convex non-concave optimization problem. This should be mentioned in the paper and I would like to see a discussion concerning the gap between the theory and the practical algorithm.\n\nRelation to existing regularization techniques: Combining Equations 11 and 13, the second terms acts as a regularizer that minimizes [\\lapha f_1(D(x_i))]^2. This looks rather similar to some of the recent regularization techniques such as\nImproved Training of Wasserstein GANs, https://arxiv.org/pdf/1704.00028.pdf\nStabilizing Training of Generative Adversarial Networks through Regularization, https://arxiv.org/pdf/1705.09367.pdf\nCan the authors comment on this? I think this would also shed some light as to why this approach alleviates the problem of mode collapse.\n\nCurse of dimensionality: Nonparametric density estimators such as the KDE technique used in this paper suffer from the well-known curse of dimensionality. For the synthetic data, the empirical evidence seem to indicate that the technique proposed by the authors does work but I’m not sure the empirical evidence provided for the MNIST and CIFAR-10 datasets is sufficient to judge whether or not the method does help with mode collapse. The inception score fails to capture this property. Could the authors explore other quantitative measure? Have you considered trying your approach on the augmented version of the MNIST dataset used in Metz et al. (2016) and Che et al. (2016)?\n\nExperiments\nTypo: Should say “The data distribution is p_d(x) = 1{x=1}”.\n']","[20, 80, 20]","[50, 60, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and potential, but also points out significant limitations. The review starts with positive comments about the framework and its theoretical contributions, but then shifts to criticisms about the standard nature of the methods and weak numerical experiments. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents criticisms constructively without harsh or rude phrasing. They use phrases like 'I think' to soften critiques and maintain a professional tone throughout the review."", ""The sentiment score is 80 (positive) because the review starts with a strong positive statement, calling the paper a 'strong contribution' and praising its ability to address issues like mode collapse. The reviewer also highlights the paper's novel approach and successful experiments. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively. However, the score is not higher because the reviewer directly points out a typo and asks for more explanation without softening the language. The review maintains a professional tone without being overly formal or deferential."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper as 'technically sound' and a 'nice contribution' with 'interesting insights'. However, they also express concerns about how the paper is written and find some claims misleading, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases concerns as suggestions or questions rather than direct criticisms. They use phrases like 'I think', 'Could the authors', and 'I would like to see' which maintain a polite tone while providing feedback. The reviewer also acknowledges the paper's strengths before discussing areas for improvement, which is a polite approach to peer review.""]"
"[""The authors describe a variant of the negotiation game in which agents of different type, selfish or prosocial, and with different preferences. The central feature is the consideration of a secondary communication (linguistic) channel for the purpose of cheap talk, i.e. talk whose semantics are not laid out a priori. \n\nThe essential findings include that prosociality is a prerequisite for effective communication (i.e. formation of meaningful communication on the linguistic channel), and furthermore, that the secondary channel helps improve the negotiation outcomes.\n\nThe paper is well-structured and incrementally introduces the added features and includes staged evaluations for the individual additions, starting with the differentiation of agent characteristics, explored with combination of linguistic and proposal channel. Finally, agent societies are represented by injecting individuals' ID into the input representation.\n\nThe positive:\n- The authors attack the challenging task of given agents a means to develop communication patterns without apriori knowledge.\n- The paper presents the problem in a well-structured manner and sufficient clarity to retrace the essential contribution (minor points for improvement).\n- The quality of the text is very high and error-free.\n- The background and results are well-contextualised with relevant related work. \n\nThe problematic:\n- By the very nature of the employed learning mechanisms, the provided solution provides little insight into what the emerging communication is really about. In my view, the lack of interpretable semantics hardly warrants a reference to 'cheap talk'. As such the expectations set by the well-developed introduction and background sections are moderated over the course of the paper.\n- The goal of providing agents with richer communicative ability without providing prior grounding is challenging, since agents need to learn about communication partners at runtime. But it appears as of the main contribution of the paper can be reduced to the decomposition of the learnable feature space into two communication channels. The implicit relationship of linguistic channel on proposal channel input based on the time information (Page 4, top) provides agents with extended inputs, thus enabling a more nuanced learning based on the relationship of proposal and linguistic channel. As such the well-defined semantics of the proposal channel effectively act as the grounding for the linguistic channel. This, then, could have been equally achieved by providing agents with a richer input structure mediated by a single channel. From this perspective, the solution offers limited surprises. The improvement of accuracy in the context of agent societies based on provided ID follows the same pattern of extending the input features.\n- One of the motivating factors of using cheap talk is the exploitation of lying on the part of the agents. However, apart from this initial statement, this feature is not explicitly picked up. In combination with the previous point, the necessity/value of the additional communication channel is unclear.\n\nConcrete suggestions for improvement:\n\n- Providing exemplified communication traces would help the reader appreciate the complexity of the problem addressed by the paper.\n- Figure 3 is really hard to read/interpret. The same applies to Figure 4 (although less critical in this case).\n- Input parameters could have been made explicit in order to facilitate a more comprehensive understanding of technicalities (e.g. in appendix).\n- Emergent communication is effectively unidirectional, with one agent as listener. Have you observed other outcomes in your evaluation?\n\nIn summary, the paper presents an interesting approach to combine unsupervised learning with multiple communication channels to improve learning of preferences in a well-established negotiation game. The problem is addressed systematically and well-presented, but can leave the reader with the impression that the secondary channel, apart from decomposing the model, does not provide conceptual benefit over introducing a richer feature space that can be exploited by the learning mechanisms. Combined with the lack of specific cheap talk features, the use of actual cheap talk is rather abstract. Those aspects warrant justification."", ""The experimental setup is clear, although the length of the utterances and the number of symbols in them is not explicitly stated in the text (only the diagrams).\n\nExperiment 1 confirms that agents who seek only to maximise their own rewards fail to coordinate over a non-binding communication channel. The exposition of the experiments, however, is unclear.\nIn Fig 1, it is not clear what Agent 1 and Agent 2 are. Do they correspond to arbitrary labels or the turns that the agent takes in the game?\nWhy is Agent 1 the one who triumphs in the no-communication channel game? Is there any advantage to going first generally? Where are the tests of robustness on the curves demonstrated in Figure 2a?\nHas figure 2b been cherry picked? This should be demonstrated over many different negotiations with error bars.\nIn the discussion of the agents being unable to ground cheap talk, the symbolic nature of the linguistic channel clouds the fact that it is not the symbolic, ungrounded aspect but the non-binding nature of communication on this channel. This would be more clearly demonstrated and parsimonious by using a non-binding version of the proposal channel and saving the linguistic discussion for later.\n\nExperiment 2 shows that by making the agents prosocial, they are able to learn to communicate on the linguistic channel to achieve pretty much optimal rewards, a very nice result.\nThe agents are not able to reach the same levels of cooperation on the proposal channel, in fact performing worse than the no-communication baseline. Protocols could be designed that would allow the agents to communicate their utilities over this channel (within 4 turns), so the fact they don't suggests it is the learning procedure that is not able to find this optimum. Presenting this as a result about the superiority of communication over the linguistic channel is not well supported.\nWhy do they do worse with random termination than 10 turns in the proposal channel? 4 proposals should contain enough information to determine the utilities.\nWhy are the 10 turn games even included in this table? It seems that this was dismissed in the environment setup section, due to the first mover advantage.\nWhy do no-communication baselines change so much between random termination and 10 turns in the prosocial case?\nWhy do self-interested agents for 10 turns on the linguistic channel terminate early?\nTable 1 might be better represented using the median and quartiles, since the data is skewed.\n\nAnalysis of the communication, i.e. what is actually sent, is interesting and the division into speaker and listener suggests that this is a simple protocol that is easy for agents to learn.\n\nExperiment 3 aims to determine whether an agent is able to negotiate against a community of other agents with mixed levels of prosociality. It is shown that if the fixed agent is able to identify who they are playing against they can do better than not knowing, in the case where the fixed agent is self interested.\nThe pca plot of agent id embeddings related is good.\nBoth Figure 4 and Table 3 use Agent 1 and Agent 2 rather than Agent A and Agent B and is not clear whether this is a mistake or Agent 1 is different from Agent A.\nThe no-communication baseline is referred to in the text but the results are not shown in the table.\nThere are no estimates of the uncertainty of the results in table 3, how robust are these results to different initial conditions?\nThis section seems like a bit of an add-on to address criticisms that might arise about the initial experiment being only two agents.\n\nOverall, the paper has some nice results and an interesting ideas but could do with some tightening up of the results to make it really good.\n"", 'This paper explores how agents can learn to communicate to solve a negotiation task. They explore several settings: grounded vs. ungrounded communication, and self-interested vs. prosocial agents. The main findings are that prosocial agents are able to learn to ground symbols using RL, but self-interested agents are not. The work is interesting and clearly described, and I think this is an interesting setting for studying emergent communication.\n\nMy only major comment is that I’m a bit skeptical about the claim that “self-interested agents cannot ground cheap talk to exchange meaningful information”. Given that the agents’ rewards would be improved if they were able to make agreements, and humans can use ‘cheap talk’ to negotiate, surely the inability to do so here shows a failure of the learning algorithm (rather than a general property of self-interested agents)?\n\nI am also concerned about the dangers posed by robots inventing their own language, perhap the authors should shut this down :-)\n']","[20, -20, 60]","[80, 50, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges several positive aspects of the paper, such as its well-structured presentation, high-quality text, and good contextualization. However, the reviewer also points out some significant issues, which tempers the overall positive sentiment. The politeness score is high (80) as the reviewer uses respectful language throughout, balancing criticism with praise, and offering constructive suggestions for improvement. The reviewer's tone remains professional and courteous, even when discussing problematic aspects of the paper."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some 'nice results' and 'interesting ideas', they also point out several issues and areas for improvement throughout the review. The overall tone suggests that the paper needs significant work to be 'really good'. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive criticism, and balances negative points with positive observations. They use phrases like 'very nice result' and 'interesting' to soften critiques, and frame most criticisms as questions or suggestions rather than direct attacks. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional tone."", ""The sentiment score is 60 (moderately positive) because the reviewer describes the work as 'interesting and clearly described' and states it's 'an interesting setting for studying emergent communication'. However, they express some skepticism about one of the main claims, which prevents a higher score. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their criticism as a 'comment' rather than a flaw. The humorous comment at the end about 'dangers posed by robots' also contributes to a friendly tone. However, the direct questioning of a main claim keeps it from being extremely polite.""]"
"[""\nThe authors show empirically that formulating multitask RL itself as an active learning and ultimately as an RL problem can be very fruitful.  They design and explore several approaches  to the active learning (or active sampling) problem, from a basic \nchange to the distribution to UCB to feature-based neural-network based RL. The domain is video games.   All proposed approaches beat the uniform sampling baselines and the more sophisticated approaches do better in the scenarios with more tasks (one multitask  problem had 21 tasks).\n\n\nPros:\n\n- very promising results with an interesting active learning approach to multitask RL\n\n- a number of approaches developed for the basic idea\n\n- a variety of experiments, on challenging multiple task problems (up to 21 tasks/games)\n\n- paper is overall well written/clear\n\nCons:\n\n- Comparison only to a very basic baseline (i.e. uniform sampling)\nCouldn't comparisons be made, in some way, to other multitask work?\n\n\n\nAdditional  comments:\n\n- The assumption of the availability of a target score goes against\nthe motivation that one need not learn individual networks ..  authors\nsay instead one can use 'published' scores, but that only assumes\nsomeone else has done the work (and furthermore, published it!).\n\nThe authors do have a section on eliminating the need by doubling an\nestimate for each task) which makes this work more acceptable (shown\nfor 6 tasks or MT1, compared to baseline uniform sampling).\n\nClearly there is more to be done here for a future direction (could be\nmentioned in future work section).\n\n- The averaging metrics (geometric, harmonic vs arithmetic, whether\n  or not to clip max score achieved) are somewhat interesting, but in\n  the main paper, I think they are only used in section 6 (seems like\n  a waste of space). Consider moving some of the results, on showing\n  drawbacks of arithmetic mean with no clipping (table 5 in appendix E), from the appendix to\n  the main paper.\n\n\n- The can be several benefits to multitask learning, in particular\n  time and/or space savings in learning new tasks via learning more\n  general features. Sections 7.2 and 7.3 on specificity/generality of\n  features were interesting.\n\n\n\n--> Can the authors show that a trained network (via their multitask\n    approached) learns significantly faster on a brand new game\n    (that's similar to games already trained on), compared to learning from\n    scratch?\n\n--> How does the performance improve/degrade (or the variance), on the\n    same set of tasks, if the different multitask instances (MT_i)\n    formed a supersets hierarchy, ie if MT_2 contained all the\n    tasks/games in MT_1, could training on MT_2 help average\n    performance on the games in MT_1 ? Could go either way since the network\n   has to allocate resources to learn other games too.  But is there a pattern?\n\n\n\n- 'Figure 7.2' in section 7.2 refers to Figure 5.\n\n\n- Can you motivate/discuss better why not providing the identity of a\n  game as an input is an advantage? Why not explore both\n  possibilities? what are the pros/cons? (section 3)\n\n\n\n\n"", 'In this paper active learning meets a challenging multitask domain: reinforcement learning in diverse Atari 2600 games. A state of the art deep reinforcement learning algorithm (A3C) is used together with three active learning strategies to master multitask problem sets of increasing size, far beyond previously reported works.\n\nAlthough the choice of problem domain is particular to Atari and reinforcement learning, the empirical observations, especially the difficulty of learning many different policies together, go far beyond the problem instantiations in this paper. Naive multitask learning with deep neural networks fails in many practical cases, as covered in the paper. The one concern I have is perhaps the choice of distinct of Atari games to multitask learn may be almost adversarial, since naive multitask learning struggles in this case; but in practice, the observed interference can appear even with less visually diverse inputs.\n\nAlthough performance is still reduced compared to single task learning in some cases, this paper delivers an important reference point for future work towards achieving generalist agents, which master diverse tasks and represent complementary behaviours compactly at scale.\n\nI wonder how efficient the approach would be on DM lab tasks, which have much more similar visual inputs, but optimal behaviours are still distinct.\n', ""The paper present online algorithms for learning multiple sequential problems. The main contribution is to introduce active learning principles for sampling the sequential tasks in an online algorithm. Experimental results are given on different multi-task instances. The contributions are interesting and experimental results seem promising. But the paper is difficult to read due to many different ideas and because some algorithms and many important explanations must be found in the Appendix (ten sections in the Appendix and 28 pages). Also, most of the paper is devoted to the study of algorithms for which the expected target scores are known. This is a very strong assumption. In my opinion, the authors should have put the focus on the DU4AC algorithm which get rids of this assumption. Therefore, I am not convinced that the paper is ready for publication at ICLR'18.\n* Differences between BA3C and other algorithms are said to be a consequence of the probability distribution over tasks. The gap is so large that I am not convinced on the fairness of the comparison. For instance, BA3C (Algorithm 2 in Appendix C) does not have the knowledge of the target scores while others heavily rely on this knowledge.\n* I do not see how the single output layer is defined.\n* As said in the general comments, in my opinion Section 6 should be developped and more experiments should be done with the DUA4C algorithm.\n* Section 7.1. It is not clear why degradation does not happen. It seems to be only an experimental fact.""]","[70, 80, -20]","[80, 70, 50]","[""The sentiment score is 70 (positive) because the reviewer begins by highlighting the promising results and interesting approach of the paper. They list several pros, including the variety of experiments and overall clarity of writing. While there are some cons and additional comments, these are presented more as suggestions for improvement rather than major criticisms. The politeness score is 80 (polite) due to the constructive and respectful tone throughout. The reviewer uses phrases like 'consider moving' and poses questions for the authors to think about, rather than making demands. They also balance critique with praise, acknowledging the paper's strengths before suggesting improvements. The language is professional and objective throughout, without any harsh or dismissive comments."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They highlight the importance of the work, its relevance beyond the specific domain, and its potential as a reference point for future research. The only mild concern mentioned doesn't significantly detract from the overall positive sentiment. The politeness score is 70 (polite) as the reviewer uses respectful and professional language throughout. They offer constructive feedback and express their thoughts in a considerate manner, even when raising a concern. The reviewer also shows engagement by suggesting potential future directions for the research, which adds to the polite and collaborative tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting contributions and promising results, they express significant concerns about the paper's readability, structure, and focus. The reviewer states they are 'not convinced that the paper is ready for publication,' which is a clear negative sentiment. However, the presence of some positive comments prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positive aspects before presenting criticisms. They phrase their concerns as opinions ('In my opinion...') rather than harsh statements. The reviewer also provides specific, constructive feedback for improvement, which is a polite approach to criticism. The language is professional and avoids any rudeness or personal attacks.""]"
"['This paper presents Variational Network Quantization; a variational Bayesian approach for quantising neural network weights to ternary values post-training in a principled way. This is achieved by a straightforward extension of the scale mixture of Gaussians perspective of the log-uniform prior proposed at [1]. The authors posit a mixture of delta peaks hyperprior over the locations of the Gaussian distribution, where each peak can be seen as the specific target value for quantisation (including zero to induce sparsity). They then further propose an approximation for the KL-divergence, necessary for the variational objective, from this multimodal prior to a factorized Gaussian posterior by appropriately combining the approximation given at [2] for each of the modes. At test-time, the variational posterior for each weight is replaced by the target quantisation value that is closest, w.r.t. the squared distance, to the mean of the Gaussian variational posterior. Encouraging experimental results are shown with performance comparable to the state-of-the-art for ternary weight neural networks.\n\nThis paper presented a straightforward extension of the work done at [1, 2] for ternary networks through a multimodal quantising prior. It is generally well-written, with extensive preliminaries and clear equations. The visualizations also serve as a nice way to convey the behaviour of the proposed approach. The idea is interesting and well executed so I propose for acceptance. I only have a couple of minor questions: \n- For the KL-divergence approximation you report a maximum difference of 1 nat per weight that seems a bit high; did you experiment with the `naive` Monte Carlo approximation of the bound (e.g. as done at Bayes By Backprop) during optimization? If yes, was there a big difference in performance?\n- Was pre-training necessary to obtain the current results for MNIST? As far as I know, [1] and [2] did not need pre-training for the MNIST results (but did employ pre-training for CIFAR 10).\n- How necessary was each one of the constraints during optimization (and what did they prevent)? \n- Did you ever observe posterior means that do not settle at one of the prior modes but rather stay in between? Or did you ever had issues of the variance growing large enough, so that q(w) captures multiple modes of the prior (maybe the constraints prevent this)? How sensitive is the quantisation scheme?\n\nOther minor comments / typos:\n(1) 7th line of section 2.1 page 2, ‘a unstructured data’ -> ‘unstructured data’\n(2) 5th line on page 3, remove ‘compare Eq. (1)’ (or rephrase it appropriately).\n(3) Section 2.2, ’Kullback-Leibler divergence between the true and the approximate posterior’; between implies symmetry (and the KL isn’t symmetric) so I suggest to change it to e.g. ‘from the true to the approximate posterior’ to avoid confusion. Same for the first line of Section 3.3.\n(4) Footnote 2, the distribution of the noise depends on the random variable so I would suggest to change it to a general \\epsilon \\sim p(\\epsilon).\n(5) Equation 4 is confusing.\n\n[1] Louizos, Ullrich & Welling, Bayesian Compression for Deep Learning.\n[2] Molchanov, Ashukha & Vetrov, Variational Dropout Sparsifies Deep Neural Networks.', '\nThe goal of this work is to infer weights of a neural network, constrained to a discrete set, where each weight can be represented by a few bits. This is a quite important and hot topic in deep learning. As a direct optimization would lead to a highly nontrivial combinatorial optimization problem, the authors propose a so-called \'quantizing prior\' (actually a relaxed spike and slab prior to induce a sparsity enforcing heavy tail prior) over weights and derive a differentiable variational KL approximation. One important advantage of the current method is that this approach does not require fine-tuning after quantization. The paper presents ternary quantization for LeNet-5 (MNIST) and DenseNet-121 (CIFAR-10).\n\nThe paper is mostly well written and cites carefully the recent relevant literature. While there are a few glitches here and there in the writing, overall the paper is easy to follow. One exception is that in section 2, many ideas are presented in a sequence without providing any guidance where all this will lead.\nThe idea is closely related to sparse Bayesian learning but the variational approximation is achieved via the local reparametrization trick of Kingma 2015, with the key idea presented in section 3.3.\n\n\n\nMinor\n\nIn the introduction, the authors write ""... weights with a large variance can be pruned as they do not contribute much to the overall computation"". What does this mean? Is this the marginal posterior variance as in ARD? \n\nThe authors write: ""Additionally, variational Bayesian inference  is known to automatically reduce parameter redundancy by penalizing overly complex models."" I would argue that \nit is Bayesian inference; variational inference sometimes retains this property, but not always.\n\nIn Eq (10), z needs also subscripts, as otherwise the notation may suggest parameter tying. Alternatively, drop the indices entirely, as later in the paper.\n\nSec. 3.2. is not very well written. This seems to be the MAP of the product of the marginals,\nor the mode of the variational distribution, not the true MAP configuration of the weight posterior. Please be more precise. \n\nThe abbreviation P&Q (probably Post-training Quantization) seems to be not defined in the paper.\n', 'This paper proposes to use a mixture of continuous spikes propto 1/abs(w_ij-c_k) as prior for a Bayesian neural network and demonstrates good performance with relatively sparsified convnets for minist and cifar-10. The paper is building quite a lot upon Kingma et al 2015 and  Molchanov et al 2017. \n\nThe paper is of good quality, clearly written with an ok level of originality and significance.\n\nPros:\n1. Demonstrates a sparse Bayesian approach that scales.\n2. Really a relevant research area for being able to make more efficient and compact deployment.\nCons:\n1. Somewhat incremental relative to the papers mentioned above.\n2. Could have taken the experimental part further. For example can we learn something about what part of the network has  the biggest potential for being pruned and use that to come up with modifications of the architecture?    ']","[80, 60, 60]","[90, 70, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, proposing it for acceptance and describing it as 'interesting and well executed'. They mention 'encouraging experimental results' and that the paper is 'generally well-written'. The few questions and comments are framed as minor and constructive. The politeness score is 90 (very polite) due to the reviewer's consistently respectful and constructive tone. They use phrases like 'I only have a couple of minor questions' and offer specific, helpful suggestions for improvements. The reviewer also acknowledges the paper's strengths before offering critiques, which is a polite approach. The language throughout is professional and courteous, without any harsh or dismissive comments."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the importance and relevance of the topic, praises the paper as 'mostly well written' and 'easy to follow', and recognizes the advantages of the proposed method. However, they also point out some minor issues and areas for improvement, which prevents a higher score. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as 'minor' points or suggestions for improvement. The use of phrases like 'please be more precise' indicates a polite tone. The reviewer maintains a professional and courteous demeanor while providing both positive feedback and constructive criticism."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as 'of good quality, clearly written with an ok level of originality and significance.' They also list several pros, including the demonstration of a scalable sparse Bayesian approach and its relevance to efficient deployment. The cons mentioned are relatively mild, suggesting incremental improvements rather than major flaws. The politeness score is 50 (slightly polite) as the reviewer uses neutral, professional language throughout. They offer constructive criticism and suggestions for improvement without using harsh or negative language. The tone is respectful and balanced, acknowledging both strengths and areas for potential enhancement.""]"
"['The paper describes the problem of continual learning, the non-iid nature of most real-life data and point out to the catastrophic forgetting phenomena in deep learning. The work defends the point of view that Bayesian inference is the right approach to attack this problem and address difficulties in past implementations. \n\nThe paper is well written, the problem is described neatly in conjunction with the past work, and the proposed algorithm is supported by experiments. The work is a useful addition to the community.\n\nMy main concern focus on the validity of the proposed model in harder tasks such as the Atari experiments in Kirkpatrick et. al. (2017) or the split CIFAR experiments in Zenke et. al. (2017). Even though the experiments carried out in the paper are important, they fall short of justifying a major step in the direction of the solution for the continual learning problem.', 'Overall, the idea of this paper is simple but interesting. Via performing variational inference in a kind of online manner, one can address continual learning for deep discriminative or generative networks with considerations of model uncertainty.\n\nThe paper is written well, and literature review is sufficient. My comment is mainly about its importance for large-scale computer vision applications. The neural networks in the experiments are shallow. \n', 'This paper proposes a new method, called VCL, for continual learning. This method is a combination of the online variational inference for streaming environment with Monte Carlo method. The authors further propose to maintain a coreset which consists of representative data points from the past tasks. Such a coreset is used for the main aim of avoiding the catastrophic forgetting problem in continual learning. Extensive experiments shows that VCL performs very well, compared with some state-of-the-art methods. \n\nThe authors present two ideas for continual learning in this paper: (1) Combination of online variational inference and sampling method, (2) Use of coreset to deal with the catastrophic forgetting problem. Both ideas have been investigated in Bayesian literature, while (2) has been recently investigated in continual learning. Therefore, the authors seems to be the first to investigate the effectiveness of (1) for continual learning. From extensive experiments, the authors find that the first idea results in VCL which can outperform other state-of-the-art approaches, while the second idea plays little role. \n\nThe finding of the effectiveness of idea (1) seems to be significant. The authors did a good job when providing a clear presentation, a detailed analysis about related work, an employment to deep discriminative models and deep generative models, and a thorough investigation of empirical performance.\n\nThere are some concerns the authors should consider:\n- Since the coreset plays little role in the superior performance of VCL, it might be better if the authors rephrase the title of the paper. When the coreset is empty, VCL turns out to be online variational inference [Broderich et al., 2013; Ghahramani & Attias, 2000]. Their finding of the effectiveness of online variational inference for continual learning should be reflected in the writing of the paper as well.\n- It is unclear about the sensitivity of VCL with respect to the size of the coreset. The authors should investigate this aspect.\n- What is the trade-off when the size of the coreset increases?\n']","[60, 50, 70]","[80, 75, 80]","[""The sentiment score is 60 (positive) because the reviewer expresses overall approval of the paper, calling it 'well written' and 'a useful addition to the community'. However, it's not extremely positive due to the main concern raised about the validity of the model in harder tasks. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticism. The critique is framed constructively as a 'concern' rather than a harsh criticism. The reviewer also uses phrases like 'the work defends the point of view' which shows respect for the authors' perspective."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper's idea as 'simple but interesting' and mentions that it is 'written well' with 'sufficient' literature review. However, they also express concerns about its importance for large-scale applications, which tempers the positive sentiment. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. They avoid harsh or dismissive language, instead framing their main comment as a consideration rather than a direct criticism."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its significance, clear presentation, and thorough investigation. They state that the authors 'did a good job' and that their findings seem 'significant'. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, acknowledging the authors' contributions and framing their concerns as suggestions ('The authors should consider'). The reviewer provides constructive feedback without using harsh or critical language. The positive tone and polite phrasing of the concerns contribute to both the high sentiment and politeness scores.""]"
"['In this work, the objective is to analyze the robustness of a neural network to any sort of attack.\n\nThis is measured by naturally linking the robustness of the network to the local Lipschitz properties of the network function. This approach is quite standard in learning theory, I am not aware of how original this point of view is within the deep learning community.\n\nThis is estimated by obtaining values of the norm of the gradient (also naturally linked to the Lipschitz properties of the function) by backpropagation. This is again a natural idea.', 'Summary\n========\n\nThe authors present CLEVER, an algorithm which consists in evaluating the (local) Lipschitz constant of a trained network around a data point. This is used to compute a lower-bound on the minimal perturbation of the data point needed to fool the network.\n\nThe method proposed in the paper already exists for classical function, they only transpose it to neural networks. Moreover, the lower bound comes from basic results in the analysis of Lipschitz continuous functions.\n\n\nClarity\n=====\n\nThe paper is clear and well-written.\n\n\nOriginality\n=========\n\nThis idea is not new: if we search for ""Lipschitz constant estimation"" in google scholar, we get for example\nWood, G. R., and B. P. Zhang. ""Estimation of the Lipschitz constant of a function."" (1996)\nwhich presents a similar algorithm (i.e., estimation of the maximum slope with reverse Weibull).\n\n\nTechnical quality\n==============\n\nThe main theoretical result in the paper is the analysis of the lower-bound on \\delta, the smallest perturbation to apply on\na data point to fool the network. This result is obtained almost directly by writing the bound on Lipschitz-continuous function\n | f(y)-f(x) | < L || y-x ||\nwhere x = x_0 and y = x_0 + \\delta.\n\nComments:\n- Lemma 3.1: why citing Paulavicius and Zilinskas for the definition of Lipschitz continuity? Moreover, a Lipschitz-continuous function does not need to be differentiable at all (e.g. |x| is Lipschitz with constant 1 but sharp at x=0). Indeed, this constant can be easier obtained if the gradient exists, but this is not a requirement.\n\n- (Flaw?) Theorem 3.2 : This theorem works for fixed target-class since g = f_c - f_j for fixed g. However, once g = min_j f_c - f_j, this theorem is not clear with the constant Lq. Indeed, the function g should be \ng(x) = min_{k \\neq c} f_c(x) - f_k(x).\nThus its Lipschitz constant is different, potentially equal to\nL_q = max_{k} \\| L_q^k \\|, \nwhere L_q^k is the Lipschitz constant of f_c-f_k. If the theorem remains unchanged after this modification, you should clarify the proof. Otherwise, the theorem will work with the maximum over all Lipschitz constants but the theoretical result will be weakened.\n\n- Theorem 4.1: I do not see the purpose of this result in this paper. This should be better motivated.\n\n\nNumerical experiments\n====================\n\nGlobally, the numerical experiments are in favor of the presented method. The authors should also add information about the time it takes to compute the bound, the evolution of the bound in function of the number of samples and the distribution of the relative gap between the lower-bound and the best adversarial example.\n\nMoreover, the numerical experiments look to be realized in the context of targeted attack. To show the real effectiveness of the approach, the authors should also show the effectiveness of the lower-bound in the context of non-targeted attack.\n\n\n#######################################################\n\nPost-rebuttal review\n---------------------------\n\nGiven the details the authors provided to my review, I decided to adjust my score. The method is simple and shows to be extremely effective/accurate in practice.\n\nDetailed answers:\n\n1) Indeed, I was not aware that the paper only focuses on one dimensional functions. However, they still work with less assumption, i.e., with no differential functions. I was pointing out the similarities between their approach and your: the two algorithms (CLEVER and Slope) are basically the same, and using a limit you can go from ""slope"" to ""gradient norm"".\nIn any case, I have read the revision and the additional numerical experiment to compare Clever with their method is a good point.\n\n2) "" Overall, our analysis is simple and more intuitive, and we further facilitate numerical calculation of the bound by applying the extreme value theory in this work. ""\nThis is right. I am just surprised is has not been done before, since it requires only few lines of derivation. I searched a bit but it is not possible to find any kind of similar results. Moreover, this leads to good performances, so there is no needs to have something more complex.\n\n3) ""The usual Lipschitz continuity is defined in terms of L2 norm and the extension to an arbitrary Lp norm is not straightforward""\nIndeed, people usually use the Lipschitz continuity using the L2norm, but the original definition is wider.\nQuickly, if you have a differential, scalar function from a space E -> R, then the gradient is a function from space E to E*, the dual of the space E.\nLet || . || the norm of space E. Then, || . ||* is the dual norm of ||.||, and also the norm of E*.\nIn that case, Lipschitz continuity writes\nf(x)-f(y) <= L || x-y ||, with L >= max_{x in E*} || f\'(x) ||*\nIn the case where || . || is an \\ell-p norm, then || . ||* is an \\ell-q norm; with 1/p+1/q = 1.\n\nIf you are interested, there is a clear and concise explanation in the introduction of this paper: Accelerating the cubic regularization of Newton’s method on convex problems, by Yurii Nesterov.\n\nI have no additional remarks for 4) -> 9), since everything is fixed in the new version of the paper.\n\n', 'The work claims a measure of robustness of networks that is attack-agnostic. Robustness measure is turned into the problem of finding a local Lipschitz constant which is given by the maximum of the norm of the gradient of the associated function. That quantity is then estimated by sampling from the domain of maximization and observing the maximum value of the norm out of those samples. Such a maximum process is then described by the reverse Weibull distribution which is used in the estimation.\n\nThe paper closely follows Hein and Andriushchenko (2017). There is a slight modification that enlarges the class of functions for which the theory is applicable (Lemma 3.3). As far as I know, the contribution of the work starts in Section 4 where the authors show how to practically estimate the maximum process through back-prop where mini-batching helps increase the number of samples. This is a rather simple idea that is shown to be effective in Figure 3. The following section (the part starting from 5.3) presents the key to the success of the proposed measure. \n\nThis is an important problem and the paper attempts to tackle it in a computationally efficient way. The fact that the norms of attacks are slightly above the proposed score is promising, however, there is always the risk of finding a lower bound that is too small (zeros and large gaps in Figure 3). It would be nice to be able to show that one can find corresponding attacks that are not too far away from the proposed score.\n\nFinally, a minor point: Definition 3.1 has a confusing notation, f is a K-valued vector throughout the paper but it also denotes the number that represents the prediction in Definition 3.1. I believe this is just a typo.\n\nEdit: Thanks for the fixes and clarification of essential parts in the paper.\n']","[20, 20, 50]","[50, 50, 75]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the work's objective and describes the approach as 'quite standard' and 'natural', which implies a level of acceptance. However, the reviewer also notes that they are 'not aware of how original this point of view is', suggesting some reservation about the novelty of the work. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language without any harsh criticism. They describe the methods as 'natural' and 'standard', which is respectful. The reviewer also uses phrases like 'I am not aware' instead of more direct criticism, which maintains a polite tone."", ""The sentiment score is slightly positive (20) because while the reviewer points out some issues and suggests improvements, they also acknowledge the paper's clarity, effectiveness of the method, and good numerical experiments. The initial review was more critical, but the post-rebuttal section indicates the reviewer adjusted their score positively after receiving more information. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, offering constructive criticism without harsh wording. They acknowledge the authors' responses and show willingness to adjust their views based on new information, which is a polite and open-minded approach in academic discourse."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance of the problem and the paper's attempt to tackle it efficiently. They also note promising aspects of the work, such as the effectiveness of the proposed measure. However, they also point out some limitations and areas for improvement, which prevents the score from being higher. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's contributions, and offers constructive feedback. They also thank the authors for fixes and clarifications in the edit, which adds to the politeness. The reviewer maintains a professional tone while providing both positive feedback and suggestions for improvement.""]"
"[""This paper revisits a subject that I have not seen revisited empirically since the 90s: the relative performance of TD and Monte-Carlo style methods under different values for the rollout length. Furthermore, the paper performs controlled experiments using the VizDoom environment to investigate the effect of a number of other environment characteristics, such as reward sparsity or perceptual complexity. The most interesting and surprising result is that finite-horizon Monte Carlo performs competitively in most tasks (with the exception of problems where terminal states play a big role (it does not do well at all on Pong!), and simple gridworld-type representations), and outperforms TD approaches in many of the more interesting settings. There is a really interesting experiment performed that suggests that this is the case due to finite-horizon MC having an easier time with learning perceptual representations. They also show, as a side result, that the reward decomposition in Dosvitskiy & Koltun (oral presentation at ICLR 2017) is not necessary for learning a good policy in VizDoom.\n\nOverall, I find the paper important for furthering the understanding of fundamental RL algorithms. However, my main concern is regarding a confounding factor that may have influenced the results: Q_MC uses a multi-headed model, trained on different horizon lengths, whereas the other models seem to have a single prediction head. May this helped Q_MC have better perceptual capabilities?\n\nA couple of other questions:\n- I couldn't find any mention of eligibility traces - why?\n- Why was the async RL framework used? It would be nice to have a discussion on whether this choice may have affected the results."", 'The authors present a testing framework for deep RL methods in which difficulty can be controlled along a number of dimensions, including: reward delay, reward sparsity, episode length with terminating rewards, binary vs real rewards and perceptual complexity. The authors then experiment with a variety of TD and MC based deep learners to explore which methods are most robust to increases in difficulty along these dimensions. The key finding is that MC appears to be more robust than TD in a number of ways, and in particular the authors link this to domains with greater perceptual challenges. \n\nThis is a well motivated and explained paper, in which a research agenda is clearly defined and evaluated carefully with the results reflected on thoughtfully and with intuition. The authors discover some interesting characteristics of MC based Deep-RL which may influence future work in this area, and dig down a little to uncover the principles a little. The testing framework will be made public too, which adds to the value of this paper. I recommend the paper for acceptance and expect it will garner interest from the community.\n\nDetailed comments\n  • [p4, basic health gathering task] ""The goal is to survive and maintain as much health\nas possible by collecting health kits...The reward is +1 when the agent collects a health kit and 0 otherwise."" The reward suggests that the goal is to collect as many health kits as possible, for which surviving and maintaining health are secondary.\n  • [p4, Delayed rewards] It might be interesting to have a delay sampled from a distribution with some known mean. Otherwise, the structure of the environment might support learning even when the reward delay would otherwise not.\n  • [p4, Sparse rewards] I am not sure it is fair to say that the general difficulty is kept fixed. Rather, the average achievable reward for an oracle (that knows whether health packs are) is fixed.\n  • [p6] ""Dosovitskiy & Koltun (2017) have not tested DFP on Atari games."" Probably fairer/safer to say: did not report results on Atari games.\n', 'This paper includes several controlled empirical studies comparing MC and TD methods in predicting of value function with complex DNN function approximators. Such comparison has been carried out both in theory and practice for simple low dimensional environments with linear (and RKHS) value function approximation showing how TD methods can have much better sample complexity and overall performance compared to pure MC methods. This paper shows some results to the contrary when applying RL to complex perceptual observation space.\n\nThe main results include:\n(1) In a rollout update a mix of MC and TD update (i.e. a rollout of > 1 and < horizon) outperforms either extreme. This is inline with TD-lambda analysis in previous work.\n(2) Pure MC methods can outperform TD methods when the rewards becomes noisy.\n(3) TD methods can outperform pure MC methods when the return is mostly dominated by the reward in the terminal state.\n(4) MC methods tend to degrade less when the reward signal is delayed.\n(5) Somewhat surprising: MC methods seems to be on-par with TD methods when the reward is sparse and even longer than the rollout horizon.\n(6) MC methods can outperform TD methods with more complex and high dimensional perceptual inputs.\n\nThe authors conjecture that several of the above observations can be explained by the fact that the training target in MC methods is ""ground truth"" and do not rely on bootstrapping from the current estimates as is done in a TD rollout. They suggest that training on such signal can be beneficial when training deep models on complex perceptual input spaces.\n\nThe contributions of the paper are in parts surprising and overall interesting. I believe there are far more caveats in this analysis than what is suggested in the paper and the authors should avoid over-generalizing the results based on a few domains and the analysis of a small set of algorithms. Nonetheless I find the results interesting to the RL community and a starting point to further analysis of the MC methods (or adaptations of TD methods) that work better with image observation spaces. Publishing the code, as the authors mentioned, would certainly help with that. \n\nNotes:\n- I find the description of the Q_MC method presented in the paper very confusing and had to consult the reference to understand the details. Adding a couple of equations on this would improve the readability of the paper.\n\n- The first mention of partial observability can be moved to the introduction.\n\n- Adding results for m=3 to table 2 would bring further insight to the comparison.\n\n- The results for the perceptual complexity experiment seem contradictory and inconclusive. One would expect Q_MC to work well in Grid Map domain if the conjecture put forth by the authors was to hold universally.\n\n- In the study on reward sparsity, although a prediction horizon of 32 is less than the average steps needed to get to a rewarding state, a blind random walk might be enough to take the RL agent to a close-enough neighbourhood from which a greedy MC-based policy has a direct path to the goal. What is missing from this picture is when a blind walk cannot reach such a state, e.g. when a narrow corridor is present in the environment. Such a case cannot be resolved by a short horizon MC method. In other words, a sparse reward setting is only ""difficult"" if getting into a good neighbourhood requires long term planning and cannot be resolved by a (pseudo) blind random walk.\n\n- The extrapolation of the value function approximator can also contribute to why the limited horizon MC method can see beyond its horizon in a sparse reward setting. That is, even if there is no way to reach a reward state in 32 steps, an MC value function approximation with horizon 32 can extrapolate from similar looking observed states that have a short path to a rewarding state, enough to be better than a blind random walk. It would have been nice to experiment with increasing model complexity to study such effect. ']","[70, 90, 60]","[80, 80, 80]","[""The sentiment score is 70 (positive) because the reviewer describes the paper as 'important for furthering the understanding of fundamental RL algorithms' and finds the results 'interesting and surprising'. They provide detailed positive feedback on the paper's contributions. However, it's not 100 as the reviewer does express some concerns and questions. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their concerns as questions rather than criticisms. They use phrases like 'I find the paper important' and 'It would be nice to have a discussion', which are polite ways of providing feedback. The tone is professional and constructive throughout, without any rude or harsh language."", ""The sentiment score is 90 because the reviewer expresses a very positive view of the paper, recommending it for acceptance and praising it as 'well motivated and explained' with 'interesting characteristics' that 'may influence future work'. The reviewer also expects it to 'garner interest from the community'. The politeness score is 80 because the reviewer uses respectful and constructive language throughout, offering praise where due and providing specific, helpful feedback in the 'Detailed comments' section. The tone is professional and courteous, avoiding any harsh criticism and instead offering suggestions for improvement or clarification."", ""The sentiment score is 60 (positive) because the reviewer describes the paper's contributions as 'surprising and overall interesting' and believes the results are 'interesting to the RL community'. They also mention that publishing the code would be helpful. However, they do express some reservations, noting 'there are far more caveats in this analysis than what is suggested'. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's contributions while offering constructive criticism. They use phrases like 'I believe', 'I find', and 'It would have been nice' when making suggestions, which maintains a polite tone. The reviewer also balances positive comments with areas for improvement, demonstrating a considerate approach to feedback.""]"
"['Summary:\nThis paper presents a very interesting perspective on why deep neural networks may generalize well, in spite of their high capacity (Zhang et al, 2017). It does so from the perspective of ""Bayesian model comparison"", where two models are compared based on their ""marginal likelihood"" (aka, their ""evidence"" --- the expected probability of the training data under the model, when parameters are drawn from the prior).  It first shows that a simple weakly regularized (linear) logistic regression model over 200 dimensional data can perfectly memorize a random training set with 200 points, while also generalizing well when the class labels are not random (eg, when a simple linear model explains the class labels); this provides a much simpler example of a model generalizing well in spite of high capacity, relative to the experiments presented by Zhang et al (2017). It shows that in this very simple setting, the ""evidence"" of a model correlates well with the test accuracy, and thus could explain this phenomena (evidence is low for model trained on random data, but high for model trained on real data).\n\nThe paper goes on to show that if the evidence is approximated using a second order Taylor expansion of the cost function around a minimia $w_0$, then the evidence is controlled by the cost at the minimum, and by the logarithm of the ratio of the curvature at the minimum compared to the regularization constant (eg, standard deviation of gaussian prior).  Thus, Bayesian evidence prefers minima that are both deep and broad.  This provides a way of comparing models in a way which is independent of the model parametrization (unfortunately, however, computing the evidence is intractable for large networks). The paper then discusses how SGD can be seen as an algorithmic way of finding minima with large ""evidence"" --- the ""noise"" in the gradient estimation helps the model avoid ""sharp"" minima, while the gradient helps the model find ""deep"" minima.  The paper shows that SGD can be understood using stochastic differential equations, where the noise scale is approximately aN/((1-m)B) (a = learning rate, N = size of training set, B = batch size, m = momentum).  It argues that because there should be an optimal noise scale (which maximizes test performance), the batch size should be taken proportional to the learning rate, as well as the training set size, and proportional to 1/(1-m).  These scaling rules are confirmed experimentally (DNN trained on MNIST).  Thus, this Bayesian perspective can also help explain the observation that models trained with smaller batch sizes (noisier gradient estimates) often generalize better than those with larger batch sizes (Kesker et al, 2016). These scaling rules provide guidance on how to increase the batch size, which is desirable for increasing the parralelism of SGD training.\n\nReview:\nQuality: The quality of the work is high.  Experiments and analysis are both presented clearly.\n\nClarity: The paper is relatively clear, though some of the connections between the different parts of the paper felt unclear to me:\n1) It would be nice if the paper were to explain, from a theoretical perspective, why large evidence should correspond to better generalization, or provide an overview of the work which has shown this (eg, Rissanen, 1983).\n2) Could margin-based generalization bounds explain the superior generalization performance of the linear model trained on random vs. non-random data?  It seems to me that the model trained on meaningful data should have a larger margin.\n3) The connection between the work on Bayesian evidence, and the work on SGD, felt very informal. The link seems to be purely intuitive (SGD should converge to minima with high evidence, because its updates are noisy).  Can this be formalized?  There is a footnote on page 7 regarding Bayesian posterior sampling -- I think this should be brought into the body of the paper, and explained in more detail.\n4) The paper does not give any background on stochastic differential equations, and why there should be an optimal noise scale \'g\', which remains constant during the stochastic process, for converging to a minima with high evidene.  Are there any theoretical results which can be leveraged from the stochastic processes literature? For example, are there results which prove anything regarding the convergence of a stochastic process under different amounts of noise?\n5) It was unclear to me why momentum was used in the MNIST experiments.  This seems to complicate the experimental setting.  Does the generalization gap not appear when no momentum is used?  Also, why is the same learning rate used for both small and large batch training for Figures 3 and 4?  If the learning rate were optimized together with batch size (eg, keeping aN/B constant), would the generalization gap still appear?  Figure 5a seems to suggest that it would not appear (peaks appear to all have the same test accuracy).\n6) It was unclear to me whether the analysis of SGD as a stochastic differential equation with noise scale aN/((1-m)B) was a contribution of this paper.  It would be good if it were made clearer which part of the mathematical analysis in sections 2 and 5 are original.\n7) Some small feedback: The notation $< x_i > = 0$ and $< x_i^2 > = 1$ is not explained.  Is each feature being normalized to be zero mean, unit variance, or is each training example being normalized?\n\nOriginality: The works seems to be relatively original combination of ideas from Bayesian evidence, to deep neural network research.  However, I am not familiar enough with the literature on Bayesian evidence, or the literature on sharp/broad minima, and their generalization properties, to be able to confidently say how original this work is.\n\nSignificance: I believe that this work is quite significant in two different ways:\n1) ""Bayesian evidence"" provides a nice way of understanding why neural nets might generalize well, which could lead to further theoretical contributions.\n2) The scaling rules described in section 5 could help practitioners use much larger batch sizes during training, by simultaneously increasing the learning rate, the training set size, and/or the momentum parameter.  This could help parallelize neural network training considerably.\n\nSome things which could limit the significance of the work:\n1) The paper does not provide a way of measuring the (approximate) evidence of a model.  It simply says it is prohibitively expensive to compute for large models.  Can the ""Gaussian approximation"" to the evidence (equation 10) be approximated efficiently for large neural networks?\n2) The paper does not prove that SGD converges to models of high evidence, or formally relate the noise scale \'g\' to the quality of the converged model, or relate the evidence of the model to its generalization performance.\n\nOverall, I feel the strengths of the paper outweight its weaknesses.  I think that the paper would be made stronger and clearer if the questions I raised above are addressed prior to publication.', 'The paper takes a recent paper of Zhang et al 2016 as the starting point to investigate the generalization capabilities of models trained by stochastic gradient descent. The main contribution are scaling rules that relate the batch size k used in SGD with the learning rate \\epsilon, most notably \\epsilon/k = const for optimal scaling.\n\nFirst of all, I have to say that the paper is very much focussed on the aforementioned paper, its experiments as well as its (partially speculative) claims. This, in my opinion, is a biased and limited starting point, which ignores much of the literature in learning theory. \n\nChapter 2 provides a sort of a mini-tutorial to (Bayesian) model selection based on standard Bayes factors. I find this of limited usefulness. First of all, I find the execution poor in the details: \n(i) Why is \\omega limited to a scalar? Nothing major really depends on that. Later the presentation switches to a more general case. \n(ii) What is a one-hot label? ""One-hot"" is the encoding of a categorical label. \n(iii) In which way is a Gaussian prior uncorrelated, if there is just a scalar random variable? \n(iv) How can one maximize a probability density function? \n(v) Why is an incorrect ""pseudo""-set notation used instead of the correct vectorial one? \n(vi) ""Exponentially large"", ""reasonably prior"" model etc. is very vague terminology\n(vii) No real credit is given for the Laplace approximation presented up to Eq. 10. For instance, why not refer to the seminal paper by Kass & Raferty? Why spend so much time on a step-by-step derivation anyway, as this is all ""classic"" and has been carried out many times before (in a cleaner write-up)? \n(viii) ""P denotes the number of model parameters"" (I guess it should be a small p? hard to decipher)\n(ix) Usually, one should think of the Laplace approximation and the resulting Bayes factors more in terms of a ""volume"" of parameters  close to the MAP estimate, which is what the matrix determinant expresses, more than any specific direction of ""curvature"". \n\nChapter 3 constructs a simple example with synthetic data to demonstrate the effect of Bayes factors. I feel the discussion to be too much obsessed by the claims made in Zhang et al 2016 and in no way suprising. In fact, the ""toy"" example is so much of a ""toy"" that I am not sure what to make of it. Statistics has for decades successfully used criteria for model selection, so what is this example supposed to proof (to whom?).\n\nChapter 4 takes the work of Mandt et al as a starting point to understand how SGD with constant step size effectively can be thought of as gradient descent with noise, the amplitude of which is controlled by the step size and the mini-batch size. Here, the main goal is to use evidence-based arguments to distinguish good from poor local minima. There is some experimental evidence presented on how to resolve the tradeoff between too much noise (underfitting) and too little (overfitting).\n\nChapter 5 takes a stochastic differential equation as a starting point. I see several issues:\n(i) It seems that you are not doing much with a SDE, as you diredctly jump to the discretized version (and ignore discussions of it\'s discretization). So maybe one should not feature the term SDE so prominently.\n(ii) While it is commonly done, it would be nice to get some insights on why a Gaussian approx. is a good assumption. Maybe you can verify this experimentally (as much of the paper consists of experimental findings)\n(iii) Eq. 13. Maybe you want this form to indicate a direction you want to move towards,  by I find adding and subtracting the gradient in itself not a very interesting manner of illustartion.\n(iv) I am not sure in whoch way g is ""measured"", but I guess you are determining it by comparing coefficients. \n(v) I am confused by the B_opt \\propto \\eps statement. It seems you are scaling to mini-batrch gradient to be in expectation equal to the full gradient (not normalized by N), e.g. it scales ~N. Now, if we think of a mini-batch as being a batched version of single pattern updates, then clearly the effective step length should scale with the batch size, which - because of the batch size normalization with N/B - means \\epsilon needs to scale with B. Maybe there is something deeper going on here, but it is not obvious to me.\n(vi) The argument why B ~ N is not clear to me. Is there one or are just making a conjecture?\n\nBottom line: The paper may contribute to the current discussion of the Zhang et al 2016 paper, but I feel  it does not make a significant contribution to the state of knowledge in machine learning. On top of that, I feel the execution of the paper leaves much to be desired. \n', 'This paper builds on Zhang et al. (2016) (Understanding deep learning requires rethinking generalization). Firstly, it shows experimentally that the same effects appear even for simple models such as linear regression.  It also shows that the phenomenon that sharp minima lead to worse result can be explained by Bayesian evidence.  Secondly, it views SGD with different settings as introducing different levels of noises that favors different minima. With both theoretical and experimental analysis, it suggests the optimal batch-size given learning rate and training data size. The paper is well written and provides excellent insights. \n\nPros:\n1. Very well written paper with good theoretical and experimental analysis.\n2. It provides useful insights of model behaviors which are attractive to a large group of people in the community. \n3. The result of optimal batch size setting is useful to wide range of learning methods.\n\nCons and mainly questions:\n1. Missing related work. \nOne important contribution of the paper is about optimal batch sizes, but related work in this direction is not discussed. There are many related works concerning adaptive batch sizes, such as [1] (a summary in section 3.2 of [2]). \n\n2. It will be great if the author could provide some discussions with respect to the analysis of information bottleneck [3] which also discuss the generalization ability of the model. \n\n3. The result of the optimal mini-batch size depends on the training data size. How about real online learning with streaming data where the total number of data points are unknown?\n\n4. The results are reported mostly concerning the training iterations, not the CPU time such as in figure 3. It will be fair/interesting to see the result for CPU time where small batch maybe favored more.   \n\n\n[1] Balles, Lukas, Javier Romero, and Philipp Hennig. ""Coupling Adaptive Batch Sizes with Learning Rates."" arXiv preprint arXiv:1612.05086 (2016).\n[2] Zhang, Cheng, Judith Butepage, Hedvig Kjellstrom, and Stephan Mandt. ""Advances in Variational Inference."" arXiv preprint arXiv:1711.05597 (2017).\n[3] Tishby, Naftali, and Noga Zaslavsky. ""Deep learning and the information bottleneck principle."" In Information Theory Workshop (ITW), 2015 IEEE, pp. 1-5. IEEE, 2015.\n\n—————-\nUpdate: I lowered my rating considering other ppl s review and comments. ']","[70, -70, 70]","[80, -20, 80]","[""The sentiment score is 70 (positive) because the reviewer expresses that the paper is 'very interesting', of 'high quality', and 'quite significant'. They state that the strengths outweigh the weaknesses, indicating a generally positive view. However, it's not 100 as they do raise several questions and areas for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively pointing out areas for clarification. They use phrases like 'It would be nice if...' and 'Could...?' when suggesting improvements, which is a polite way of giving feedback. The reviewer also balances criticism with praise, showing consideration for the authors' work."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer criticizes the paper's focus, execution, and overall contribution. They use phrases like 'biased and limited starting point', 'poor in the details', and 'leaves much to be desired'. The reviewer also states that the paper doesn't make a 'significant contribution'. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical. They use phrases like 'I find this of limited usefulness' and 'I am confused by', which are not particularly polite. The reviewer does occasionally use softer language like 'Maybe you want' or 'Maybe you can verify', which prevents the score from being lower. However, the overall tone is more critical than polite, especially in the concluding paragraph."", ""The sentiment score is 70 (positive) because the reviewer starts with praise, calling the paper 'well written' and providing 'excellent insights'. They list several pros before mentioning cons, which are framed more as questions than criticisms. The update at the end slightly lowers the overall positivity. The politeness score is 80 (very polite) due to the respectful tone throughout. The reviewer uses phrases like 'It will be great if' and 'It will be fair/interesting', showing consideration. They also frame criticisms as questions or suggestions rather than direct critiques, maintaining a courteous tone.""]"
"[""This paper proposes replacing the weights of the final classifier layer in a CNN with a fixed projection matrix.  In particular a Hadamard matrix can be used, which can be represented implicitly.\n\nI'd have liked to see some discussion of how to efficiently implement the Hadamard transform when the number of penultimate features does not match the number of classes, since the provided code does not do this.\n\nHow does this approach scale as the number of classes grows very large (as it would in language modeling, for example)?\n\nAn interesting experiment to do here would be to look this technique interacts with distillation, when used in the teacher or student network or both.   Does fixing the features make it more difficult to place dog than on boat when classifying a cat?  Do networks with fixed classifier weights make worse teachers for distillation?\n"", 'The paper proposes to use a fixed weight matrix to replace the final linear projection in a deep neural network.\nThis fixed classifier is combined with a global scaling and per output shift that are learned.\nThe authors claim that this can be used as a drop in replacement for standard architectures and does not result in reduced performance.\nThe key advantage is that it generates a reduction in parameters (e.g. for resent 50 8% of parameters are eliminated).\n\nThe idea is extremely simple and I like it conceptually.\nCurrently it looks like my reimplementation on resent 50 is working. \nI do lose a about 1% in accuracy compared to my baseline learned projection implementation.\nIs the scale and bias regularized?\n\nI have assigned a score of 6 now.  but I will wait for my final rating when I get the actual results.\nOverall the evaluation is seems reasonably thorough many tasks were presented and the model was applied to different architectures.\n\nI also think the manuscript could benefit from the following experiments:\n- how does the chosen projection matrix affect performance.\n- is the scale needed\nI assume the authors did these experiments when they developed the method but it is unclear how important these choices are. \nIncluding these experiments would make it a more scientific contribution.\n\nThe amount of computation saved seems rather limited? Especially since the gradient of the scale parameter has to go through the weight vector?\nTherefore my assumption is that only the application of the gradients save a limited amount of time and memory?\nAt least in my experiments reproducing these results, the computational benefit is not there/obvious.\n\nWhile I like the idea, the way the manuscript is written is a bit strange at times. \nThe introduction appears to be there to be because you need a introduction, not to explain the background. \nFor this reason some of the cited work seems a bit out of place.\nEspecially the universal approximation and data memorization references.\nWhat I find interesting is that this work is the complement of the reservoir computing/extreme learning machines approach.\nThere the final output layer is trained but the network itself uses random weights.\n \nIt would be nice if Fig 2 had a better caption. Which dataset, model, ….\nIs there an intuition why the training error remains higher but the validation error is identical? This is difficult to get my head round.\nAlso, it would be nice if an analysis was provided where the computational cost of not doing the gradient update was computed.\n', 'Revised Review:\n\nThe authors have largely addressed my concerns with the revised manuscript. I still have some doubts about the C > N setting (the new settings of C / N of 4 and 2 aren\'t C >> N, and the associated results aren\'t detailed clearly in the paper), but I think the paper warrants acceptance.\n\nOriginal Review:\n\nThe paper proposes fixing the classification layers of neural networks, replacing the traditional learned affine transformation with a fixed (e.g., Hadamard) matrix. This is motivated by the observation that classification layers frequently constitute a non-trivial fraction of a network\'s overall parameter count, compute requirements, and memory usage, and by the observation that removal of pre-classification fully-connected layers has often been found to have minimal impact on performance. Experiments are performed on a range of datasets and network architectures, in both image classification and NLP settings.\n\nFirst, I\'d like to note that the empirical component of this paper is strong: I was impressed by the breadth of architectures and settings covered, and the experiments left me reasonably convinced that the classification layer can often be fixed, at least for image classification tasks, without significant loss of accuracy.\n\nI have two general concerns. For one, removing the fully connected classification layer is not a novel idea; All Convolutional Networks (https://arxiv.org/abs/1412.6806) reported excellent results without an additional fully connected affine transform (just a global average pooling after the last convolutional layer). I think it would be worth at least referencing/discussing differences with this and other all-convolutional architectures. Including a fixed Hadamard matrix for the classification layer is I believe new (although related to an existing literature on using structured matrices in neural networks).\n\nHowever, I have doubts about the ability of the approach to scale to problems with a larger number of classes, which arguably is a primary motivation of the paper (""parameters ... grow linearly with the number of classes""). Specifically, the idea of using a fixed N x C matrix with C orthogonal columns (such as Hadamard) is only possible when N > C. This is a critical point: in the N > C regime, a final hidden representation with N dimensions can be chosen to achieve *any* C-dimensional output, regardless of the projection matrix used (so long as it is full rank). This makes it seem fairly reasonable to me that the network can (at least approximately, and complicated by the ReLU nonlinearities) fold the ""desired"" classification layer into the previous layer, especially with a learned scaling and bias term. In fact it\'s not clear to me that the fixed\xa0classification layer accomplishes anything here, beyond projecting from N -> C (i.e., if N = C, I\'d guess it could be removed entirely similar to all convolutional nets, as long as the learned scaling and bias were retained).\n\nOn the other hand, when C > N, it is not possible to have mutually orthogonal columns, and in general the output is constrained to lie in an N-dimensional subspace of the overall C-dimensional output space. Picking somewhat randomly a *fixed* N-dimensional subspace seems like a bad idea when N << C, since it is unlikely to select a subspace in which it is possible to adequately capture correlations between the different classes. This makes the proposed technique much less appealing for precisely the family of problems where it would be most effective in reducing compute/memory requirements. It also provides (in my view) a clearer explanation for the failure of the approach in the NLP setting. These issues were not discussed anywhere in the text as far as I can tell, and I think it\'s necessary to at least acknowledge that mutually orthogonal columns can\'t be chosen when C > N in section 2.2 (and probably include a longer discussion on the probable implications).\n\nOverall, I think the paper provides a useful observation that clearly isn\'t common knowledge, since classification layers persist in many popular recent architectures. But the notion of fixing or removing the classification layer isn\'t particularly novel, and I don\'t believe the proposed technique would scale well to settings with many classes. As is I think the paper falls slightly short.']","[20, 50, 20]","[50, 60, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's proposal and offers suggestions for improvement, indicating interest in the work. However, the lack of strong positive language keeps the score from being higher. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout and phrases suggestions as questions or potential areas of interest rather than direct criticisms. The reviewer's tone is constructive and respectful, offering ideas for further exploration without being overly effusive or negative."", ""Sentiment Score (50): The review expresses a generally positive sentiment towards the paper. The reviewer likes the idea conceptually and finds the evaluation reasonably thorough. However, there are some concerns and suggestions for improvement, which prevent a higher score. The reviewer is waiting for final results before giving a definitive rating, indicating a cautiously positive stance.\n\nPoliteness Score (60): The language used in the review is generally polite and constructive. The reviewer uses phrases like 'I like it conceptually' and 'It would be nice if...' which are courteous. They offer suggestions for improvement in a respectful manner. However, some critiques are presented directly without softening language, which prevents a higher politeness score. The overall tone is professional and appropriate for a peer review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the strong empirical component and breadth of experiments, and states the paper warrants acceptance despite some remaining doubts. However, they also express significant concerns about scalability and novelty, tempering the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging strengths ('I was impressed') and framing criticisms constructively ('I think it would be worth...'). They maintain a professional tone without harsh or rude phrasing, even when expressing doubts or criticisms.""]"
"['This paper proposes to apply the obverter technique of Batali (1998) to a multi-agent communication game. The main novelty with respect to Batali\'s orginal work is that the agents in this paper have to communicate about images represented at the raw pixel level. The paper presents an extensive analysis of the patterns learnt by the agents, in particular in terms of how compositional they are.\n\nI greatly enjoyed reading the paper: while the obverter idea is not new, it\'s nice to see it applied in the context of modern deep learning architectures, and the analysis of the results is very interesting.\n\nThe writeup is somewhat confusing, and in particular the reader has to constantly refer to the supplementary materials to make sense of the models and experiments. At least the model architecture could be discussed in more detail in the main text.\n\nIt\'s a pity that there is no direct quantitative comparison between the obverter technique and a RL architecture.\n\nSome more detailed comments:\n\nIt would be good if a native speaker could edit the paper for language and style (I only annotated English problems in the abstract, since there were just too many of them).\n\nAbstract:\n\ndistinguishing natures -> aspects\n\ndescribe the complex environment -> describe complex environments\n\nwith the accuracy -> with accuracy\n\nIntroduction:\n\nhave shown great progress -> has...\n\nThe claim that language learning in humans is entirely based on communication needs hedging. See, e.g., cultures where children must acquire quite a bit of their language skills from passive listening to adult conversations (Schieffelin & Ochs 1983; Shore 1997).\n\nAlso, while it\'s certainly the case that humans do not learn from the neatly hand-crafted features favored in early language emergence studies, their input is most definitely not pixels (and, arguably, it is something more abstract than raw visual stimuli, see, e.g., the work on ""object biases"" in language acquisition).\n\nMethod:\n\nThe description of the experiment sometimes refers to the listener having to determine whether it is seeing the same image as the speaker, whereas the game consists in the listener telling whether it sees the same object as the speaker. This is important, since, crucially, the images can present the same object in different locations.\n\nSection 2.2 is very confusing, since the obverter technique has not been introduced, yet, so I kept wondering why you were only describing the listener architecture. Perhaps, current section 2.3 should be moved before 2.2.\n\nAlso in 2.2: what is the ""meaning vector"" that BAtali\'s RNN hidden vector has to be close to?\n\nIt\'s confusing to refer to the binary 0 and 1 vectors as outputs of the sigmoid: they are rather the binary categories you want the agents to approximate with the sigmoid function.\n\nThe obverter technique should be described in more detail in the main text. In particular, with max message length 20 and a vocabulary of 5 symbols, you\'ll have an astronomical number of possible inputs to evaluate at each step: is this really what you\'re doing?\n\nExperiments:\n\ndistinctness: better call it distinctiveness\n\nIs training accuracy in Fig 4 averaged across both agents? And what were the values the Jaccard similarity was computed over?\n\nIt\'s nice that the agents discovered some non-strictly agglutinative morphology, consisting in removing symbols from the prefix. Also, it looks like they are developing some notion of ""inflectional class"" (Aronoff 1994) (the color groups), which is also intriguing. However, I did not understand rules such as: ""remove two as and add one a""... isn\'t that the same as: ""add one a""?\n\nDiscussion and future work:\n\nI didn\'t follow the discussion about partial truth and using negations.\n\nThere is another ICLR submission that proposes a quantitative measure of compositionality you might find interesting: https://openreview.net/pdf?id=HJGv1Z-AW\n', 'Pros:\n1. Extend the input from disentangled feature to raw image pixels\n2. Employ “obverter” technique, showing that it can be an alternative approach comparing to RL \n3. The authors provided various experiments to showcase their approach\n\nCons:\n1. Comparing to previous work (Mordatch & Abbeel, 2018), the task is relatively simple, only requiring the agent to perform binary prediction.\n2. Sharing the RNN for speaking and consuming by picking the token that maximizes the probability might decrease the diversity.\n3. This paper lack original technical contribution from themselves.  \n\nThe paper is well-written, clearly illustrating the goal of this work and the corresponding approach. The “obverter” technique is quite interesting since it incorporates the concept from the theory of mind which is similar to human alignment or AGI approach. Authors provided complete experiments to prove their concept; however, the task is relatively easy compared to Mordatch & Abbeel (2018). Readers would be curious how this approach scales to a more complex problem.\n\nWhile the author sharing the RNN for speaking and consuming by picking the token that maximizes the probability, the model loses its diversity since it discards the sampling process. The RL approach in previous works can efficiently explore sentence space by sampling from policy distribution. However, I can not see how the author tackles this issue. One of the possible reason is that the task is relatively easy, therefore, the agent does not need explicitly exploration to tackle this task. Otherwise, some simple technique like “beam search” or perform MC rollout at each time could further improve the performance.\n\nIn conclusion, this paper does not have a major flaw. The “obverter” approach is interesting; however, it is originally proposed in Batali (1998). Generating language based only on raw image pixels is not difficult. The only thing you need to do is replacing FC layers with CNN layers. Though this paper employs an interesting method, it lacks some technical contribution from themselves.  \n\n\n[1] Igor Mordatch and Pieter Abbeel. Emergence of grounded compositional language in multi-agent populations. AAAI 2018\n\n[2] John Batali. Computational simulations of the emergence of grammar. Approaches to the evolution of language: Social and cognitive bases, 405:426, 1998.', 'This paper presents a technique for training a two-agent system to play a simple reference game involving recognition of synthetic images of a single object.  Each agent is represented by an RNN that consumes an image representation and sequence of tokens as input, and generates a binary decision as output. The two agents are initialized independently and randomly. In each round of training, one agent is selected to be the speaker and the other to be the listener. The speaker generates outputs by greedily selecting a sequence of tokens to maximize the probability of a correct recognition w/r/t the speaker\'s model. The listener then consumes these tokens, makes a classification decision, incurs a loss, and updates its parameters. Experiments find that after training, the two agents converge to approximately the same language, that this language contains some regularities, and that agents are able to successfully generalize to novel combinations of properties not observed during training.\n\nWhile Table 3 is suggestive, this paper has many serious problems. There isn\'t an engineering contribution---despite the motivation at the beginning, there\'s no attempt to demonstrate that this technique could be used either to help comprehension of natural language or to improve over the numerous existing techniques for automatically learning communication protocols.  But this also isn\'t science: ""generalization"" is not the same thing as compositionality, and there\'s no testable hypothesis articulated about what it would mean for a language to be compositional---just the post-hoc analysis offered in Tables 2 & 3. I also have some concerns about the experiment in Section 3.3 and the overall positioning of the paper.\n\nI want to emphasize that these results are cool, and something interesting might be going on here! But the paper is not ready to be published. I apologize in advance for the length of this review; I hope it provides some useful feedback about how future versions of this work might be made more rigorous.\n\nWHAT IS COMPOSITIONALITY?\n\nThe title, introduction, and first three sections of this paper emphasize heavily the extent to which this work focuses on discovering ""compositional"" language. However, the paper doesn\'t even attempt to define what is meant by compositionality until the penultimate page, where it asserts that the ability to ""accurately describe an object [...] not seen before"" is ""one of the marks of compositional language"". Various qualitative claims are made that model outputs ""seem to be"" compositional or ""have the strong flavor of"" compositionality. Finally, the conclusion notes that ""the exact definition of compositional language is somewhat debatable, and, to the best of our knowledge, there was no reliable way to check for the compositionality of an arbitrary language.""\n\nThis is very bad.\n\nIt is true that there is not a universally agreed-upon definition of compositionality. In my experience, however, most people who study these issues do not (contra the citation-less 5th sentence of section 4) think it is simply an unstructured capacity for generalization.  And the implication that nobody else has ever attempted to provide a falsifiable criterion, or that this paper is exempt from itself articulating such a criterion, is totally unacceptable.  (You cannot put ""giving the reader the tools to evaluate your current claims"" in future work!)\n\nIf this paper wishes to make any claims about compositionality, it must _at a minimum_:\n\n1. Describe a test for compositionality.\n\n2. Describe in detail the relationship between the proposed test and other definitions of compositionality that exist in the literature.\n\n3. If this compositionality is claimed to be ""language-like"", extend and evaluate the definition of compositionality to more complex concepts than conjunctions of two predicates.\n\nSome thoughts to get you started: when talking about string-valued things, compositionality almost certainly needs to say something about _syntax_. Any definition you choose will be maximally convincing if it can predict _without running the model_ what strings will appear in the gray boxes in Figure 3.  Similarly if it can consistently generate analyses across multiple restarts of the training run.  The fact that analysis relies on seemingly arbitrary decisions to ignore certain tokens is a warning sign. The phenomenon where every color has 2--3 different names depending on the shape it\'s paired with would generally be called ""non-compositional"" if it appeared in a natural language.\n\nThis SEP article has a nice overview and bibliography: https://plato.stanford.edu/entries/compositionality/. But seriously, please, talk to a linguist.\n\nMODEL\n\nThe fact that the interpretation model greedily chooses symbols until it reaches a certain confidence threshold would seem to strongly bias the model towards learning a specific communication strategy. At the same time, it\'s not actually possible to guarantee that there is a greedily-discoverable sequence that ever reaches the threshold! This fact doesn\'t seem to be addressed.\n\nThis approach also completely rules out normal natural language phenomena (consider ""I know Mary"" vs ""I know Mary will be happy to see you""). It is at least worth discussing these limitations, and would be even more helpful to show results for other architectures (e.g. fixed-length codes or loss functions with an insertion penalty) as well.\n\nThere\'s some language in the appendix (""We noticed that a larger vocabulary and a longer message length helped the agents achieve a high communication accuracy more easily. But the resulting messages were challenging to analyze for compositional patterns."") that suggests that even the vague structure observed is hard to elicit, and that the high-level claim made in this paper is  less robust than the body suggests. It\'s _really_ not OK to bury this kind of information in the supplementary material, since it bears directly on your core claim that compositional structure does arise in practice. If the emergence of compositionality is sensitive to vocab size & message length, experiments demonstrating this sensitivity belong front-and-center in the paper.\n\nEVALUATION\n\nThe obvious null hypothesis here is that unseen concepts are associated with an arbitrary (i.e. non-compositional) description, and that to succeed here it\'s enough to recognize this description as _different_ without understanding anything about its structure. So while this evaluation is obviously necessary, I don\'t think it\'s powerful enough to answer the question that you\'ve posed. It would be helpful to provide some baselines for reference: if I understand correctly, guessing ""0"" identically gives 88% accuracy for the first two columns of Table 4, and guessing based on only one attribute gives 94%, which makes some of the numbers a little less impressive. \n\nPerhaps more problematically, these experiments don\'t rule out the possibility that the model always guesses ""1"" for unseen objects. It would be most informative to hold out multiple attributes for each held-out color (& vice-versa), and evaluate only with speakers / listeners shown different objects from the held-out set.\n\nPOSITIONING AND MOTIVATION\n\nThe first sentence of this paper asserts that artificial general intelligence requires the ability to communicate with humans using natural language. This paper has nothing to do with AGI, humans, or human language; to be blunt, this kind of positioning is at best inappropriate and at worst irresponsible. It must be removed. For the assertion that ""natural language processing has shown great progress"", the paper provides a list of citations employing neural networks exclusively and beginning in 2014 (!). I would gently remind the authors that NLP research did not begin with deep learning, and that there might be slightly earlier evidence for their claim.\n\nThe attempt to cite relevant work in philosophy and psychology is commendable!  However, many of these citations are problematic, and some psycho-/historico-linguistic claims are still missing citations. A few examples: Ludwig Wittgenstein died in 1951, so it is somewhat surprising to see him cited for a 2010 publication (PI appeared in 1953); similarly Zipf (2016).  The application of this Zipf citation is dubious; the sentence preceded by footnote 7 is false and has nothing to do with the processes underlying homophony in natural languages. I would encourage you to consult with colleagues in the relevant fields.']","[60, 20, -70]","[70, 60, -20]","[""The sentiment score is 60 (positive) because the reviewer expresses that they 'greatly enjoyed reading the paper' and finds the analysis 'very interesting'. However, they also point out some issues like confusing writeup and lack of direct comparison, which prevents a higher score. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'It would be good if...' and 'It's nice that...' which contribute to a polite tone. The score is not higher because the review maintains a professional, somewhat neutral tone rather than being overtly deferential or excessively polite."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some pros of the paper and describes it as 'well-written' and 'clearly illustrating' its goals. However, they also point out several cons and limitations, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively pointing out areas for improvement. They use phrases like 'Readers would be curious' and 'I can not see how the author tackles this issue' instead of more direct criticisms. The review maintains a professional tone, offering balanced feedback without using harsh or dismissive language."", ""The sentiment score is -70 because the reviewer expresses significant criticism of the paper, stating it has 'many serious problems' and is 'not ready to be published'. They point out major issues with the paper's approach to compositionality, experimental design, and positioning. The politeness score is -20 because while the reviewer does apologize for the length of the review and acknowledges that the results are 'cool', the overall tone is quite harsh and direct. The reviewer uses strong language like 'This is very bad' and 'totally unacceptable'. They also make somewhat condescending remarks like 'But seriously, please, talk to a linguist.' However, the reviewer does offer constructive feedback and expresses hope that their comments will be useful, which prevents the score from being even lower.""]"
"['This paper presents a novel method for spike based learning that aims at reducing the needed computation during learning and testing when classifying temporal redundant data. This approach extends the method presented on Arxiv on Sigma delta quantized networks (Peter O’Connor and Max Welling. Sigma delta quantized networks. arXiv preprint arXiv:1611.02024, 2016b.). Overall, the paper is interesting and promising; only a few works tackle the problem of learning with spikes showing the potential advantages of such form of computing. The paper, however, is not flawless. The authors demonstrate the method on just two datasets, and effectively they show results of training only for Feed-Forward Neural Nets (the authors claim that “the entire spiking network end-to-end works” referring to their pre-trained VGG19, but this paper presents only training for the three top layers). Furthermore, even if suitable datasets are not available, the authors could have chosen to train different architectures. The first dataset is the well-known benchmark MNIST also presented in a customized Temporal-MNIST. Although it is a common base-line, some choices are not clear: why using a FFNN instead that a CNN which performs better on this dataset; how data is presented in terms of temporal series – this applies to the Temporal MNIST too; why performances for Temporal MNIST – which should be a more suitable dataset — are worse than for the standard MNIST; what is the meaning of the right column of Figure 5 since it’s just a linear combination of the GOps results. For the second dataset, some points are not clear too: why the labels and the pictures seem not to match (in appendix E); why there are more training iterations with spikes w.r.t. the not-spiking case. Overall, the paper is mathematically sound, except for the “future updates” meaning which probably deserves a clearer explanation. Moreover, I don’t see why the learning rule equations (14-15) are described in the appendix, while they are referred constantly in the main text. The final impression is that the problem of the dynamical range of the hidden layer activations is not fully resolved by the empirical solution described in Appendix D: perhaps this problem affects CCNs more than FFN. \nFinally, there are some minor issues here and there (the authors show quite some lack of attention for just 7 pages):\n-\tTwo times “get” in “we get get a decoding scheme” in the introduction;\n-\tTwo times “update” in “our true update update as” in Sec. 2.6;\n-\tPag3 correct the capital S in 2.3.1\n-\tPag4 Figure 1 increase font size (also for Figure2); close bracket after Equation 3; N (number of spikes) is not defined\n-\tPag5 “one-hot” or “onehot”; \n-\tin the inline equation the sum goes from n=1 to S, while in eq.(8) it goes from n=1 to N;\n-\tEq(10)(11)(12) and some lines have a typo (a \\cdot) just before some of the ws;\n-\tPag6 k_{beta} is not defined in the main text;\n-\tPag7 there are two “so that” in 3.1; capital letter “It used 32x10^12..”; beside, here, why do not report the difference in computation w.r.t. not-spiking nets?\n-\tPag7 in 3.2 “discussed in 1” is section 1?\n-\tPag14 Appendix E, why the labels don’t match the pictures;\n-\tPag14 Appendix F, explain better the architecture used for this experiment.', 'This paper applies a predictive coding version of the Sigma-Delta encoding scheme to reduce a computational load on a deep learning network. Whereas neither of these components are new, to my knowledge, nobody has combined all three of them previously. The paper is generally clearly written and represents a valuable contribution. The authors may want to consider the following comments:\n\n1. I did not really understand the analogy with STDP in neuroscience because it relies on the assumption that spiking of the post-synaptic neuron encodes the backpropagating error signal. I am not aware of any evidence for this. Given that the authors’ algorithm does not reproduce the sign-flip in the STDP rule I would suggest revise the corresponding part of the paper. Certainly, the claim in the Discussion “show these to be equivalent to a form of STDP – a learning rule first observed in neuroscience.” is inappropriate.\n\n2.  If the authors’ encoding scheme really works I feel that they could beef up their experimental results to demonstrate its unqualified advantage.\n\n3. The paper could benefit greatly from better integration with the existing literature.\na. Sigma-Delta model of spiking neurons has a long history in neuroscience starting with the work of Shin. Please note that these papers are much older than the ones you cite: \nShin, J., Adaptive noise shaping neural spike encoding and decoding. Neurocomputing, 2001. 38-40: p. 369-381. \nShin, J., The noise shaping neural coding hypothesis: a brief history and physiological implications. Neurocomputing, 2002. 44: p. 167-175. \nShin, J.H., Adaptation in spiking neurons based on the noise shaping neural coding hypothesis. Neural Networks, 2001. 14(6-7): p. 907-919.\nMore recently, the noise-shaping hypothesis has been tested with physiological data:\nChklovskii, D. B., & Soudry, D. (2012). Neuronal spike generation mechanism as an oversampling, noise-shaping a-to-d converter. In Advances in Neural Information Processing Systems (pp. 503-511). (see Figure 5A for the circuit implementing a Predictive Sigma-Delta encoder discussed by you)\n\nb. It is more appropriate to refer to encoding a combination of the current value and the increment as a version of predictive coding in signal processing rather than the proportional derivative scheme in control theory because the objective here is encoding, not control. Also, predictive coding has been commonly used in neuroscience:\nSrinivasan MV, Laughlin SB, Dubs A (1982) Predictive coding: a fresh view of inhibition in the retina. Proc R Soc Lond B Biol Sci 216: 427–459. pmid:6129637\nUsing leaky neurons for encoding and decoding is standard, see e.g.:\nBharioke, Arjun, and Dmitri B. Chklovskii. ""Automatic adaptation to fast input changes in a time-invariant neural circuit."" PLoS computational biology 11.8 (2015): e1004315. \nFor the application of these ideas to spiking neurons including learning please see a recent paper:\nDenève, Sophie, Alireza Alemi, and Ralph Bourdoukan. ""The brain as an efficient and robust adaptive learner."" Neuron 94.5 (2017): 969-977.\n\nMinor:\nPenultimate paragraph of the introduction section: “get get” -> get\nFirst paragraph of the experiments section: ”so that so that” -> so that\n', 'The principal problem that the paper addresses is how to integrate error-backpropagation learning in a network of spiking neurons that use a form of sigma-delta coding. The main observation is that static sigma-delta coding as proposed in OConnor and Welling (2016b), is not correct when the weights change during training, as past activations are taken into account with the old rather than the new weights.\n\nThe solution proposed in this work is to have past activations decay exponentially, to reduce this problem. The coding scheme then mimics the proporitional-integral-derivative idea from control-theory. The result, spikes having an exponentially decaying effect on the postsynaptic neuron, is similar to that observed in biological spiking neurons. \n\nThe authors show how spike-based learning can be implemented with spiking neurons using such coding, and demonstrate the results on an MLP with one hidden layer applied to the temporal MNIST dataset, and to the Youtube-BB dataset. \n\nThis approach is original and significant, though the presented results are a bit on the thin side. As presented, the spiking networks are not exactly ""deep"": I am puzzled by the statement that in the youtube-bb dataset only the top 3 layers are ""spiking"". The network for the MNIST dataset is similarly only 3 layers deep (input, hidden, output). Is there a particular reason for this?  The presentation right now suggests that the scheme does in practise not work for deep networks...\n\nWith regard to the learning rule: while the rule is formulated in terms of spikes, it should be noted that for neuron with many inputs and outputs, this update will have to be computed very very often, even for networks with low average firing rates. \n\nThe paper is clear in most points, with some parts that could use further elucidation. In particular, in Sec 2.5 the feedback pass for weight updating is computed. It is unclear from the text that this is an ongoing process, in parallel to the feedforward pass. In Sec 2.6 e_t is termed the postsynaptic (pre-nonlinearity) activation, which is confusing as the computation is going the other way (post-to-pre). These two sections would benefit from a more careful layout of the process, what is going on in a forward pass, a backward pass, how does this interact. \n\nSection 2.7 tries to relate the spike-based learning rule to the biologically observed STDP phenomenon. While the formulation in terms of pre-post spike-times is interesting, the result is clearly different from STDP, and ignores the fact that e_t refers to the backpropagating error (which presumably would be conveyed by a feedback network): applying the plotted pre-post spike-time rule in the same setting as where STDP is observed will not achieve error-backpropagation. \n\nThe shorthand notation in the paper is hard to follow in the first place btw, perhaps this could be elaborated/remedied in an appendix, there is also some rather colloquial writing in places: ""obscene wast of energy"" (abstract), ""There\'s"" ""aren\'t"" (2.6, p5). \n\nThe correspondence of spiking neurons to sigma-delta modulation is incorrectly attributed to Zambrano and Bohte (2016), but is rather presented in Yoon (2017/2016, check original date of publication!). \n\n']","[20, 50, -20]","[50, 75, 50]","[""The sentiment score is slightly positive (20) because the reviewer starts by calling the paper 'interesting and promising', acknowledging its novel approach. However, they also point out several flaws and areas for improvement, which tempers the positivity. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'Overall, the paper is interesting' and 'The paper, however, is not flawless.' They provide constructive criticism without harsh language. The reviewer also offers specific suggestions for improvement, which is a polite way to address shortcomings. The list of minor issues at the end is presented factually without negative commentary. Overall, the review balances positive acknowledgment with critical feedback in a respectful manner."", ""The sentiment score is 50 (slightly positive) because the reviewer states that the paper 'represents a valuable contribution' and is 'generally clearly written'. However, they also provide several suggestions for improvement, indicating it's not entirely positive. The politeness score is 75 (fairly polite) as the reviewer uses respectful language throughout, such as 'The authors may want to consider' and 'The paper could benefit greatly from'. They provide constructive criticism without harsh language. The reviewer also acknowledges the novelty of the work and offers detailed suggestions for improvement, which is a polite way to provide feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the originality and significance of the approach, they express several concerns and criticisms. They mention that the results are 'a bit on the thin side', question the depth of the networks used, and point out areas that need clarification or correction. The overall tone suggests more criticism than praise, but it's not overwhelmingly negative.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I am puzzled by' and 'could use further elucidation' rather than harsh criticisms. They also acknowledge the positive aspects of the work before presenting their concerns. However, the score isn't higher because there are a few instances of more direct criticism and some colloquial language that slightly reduces the overall politeness.""]"
"['Summary: This works proposes strategies to make neural networks less sensitive to adversarial attacks. They consist into applying different transformations to the images, such as quantization, JPEG compression, total variation minimization and image quilting. Four adversarial attacks strategies are considered to attack a Resnet50 model for classification of Imagenet images.\nExperiments are conducted in a black box setting (when the model to attack is unknown by the adversary) or white box setting (the model and defense strategy are known by the adversary).\n60% of attacks are countered in this last most difficult setting.\nThe previous best approach for this task consists in ensemble training and is attack specific. It is therefore pretty robust to the attack it was trained on but is largely outperformed by the authors methods that manage to reduce the classifier error drop below 25%.  \n\nComments: The paper is well written, the proposed methods are well adapted to the task and lead to satisfying results.\n \nThe discussion remarks are particularly interesting: the non differentiability of the total variation and image quilting methods seems to be the key to their best performance in practice.\nMinor: the bibliography should be uniformed.', ""To increase robustness to adversarial attacks, the paper fundamentally proposes to transform an input image before feeding it to a convolutional network classifier. The purpose of the transformation is to erase the high-frequency signals potentially embedded by an adversarial attack.\n\nStrong points:\n\n* To my knowledge, the proposed defense strategy is novel (even if the idea of transformation has been introduced at https://arxiv.org/abs/1612.01401). \n\n* The writing is reasonably clear (up to the terminology issues discussed among the weak points), and introduces properly the adversarial attacks considered in the work.\n\n* The proposed approach really helps in a black-box scenario (Figure 4). As explained below, the presented investigation is however insufficient to assess whether the proposed defense helps in a true white-box scenario. \n\n\nWeak points:\n\n* The black-box versus white-box terminology is not appropriate, and confusing. In general, black-box means that the adversary ignores everything from the decision process. Hence, in this case, the adversary does not know about the classification model, nor the defensive method, when used. This corresponds to Figure 3. On the contrary, white-box means that the adversary knows everything about the classification method, including the transformation implemented to make it more robust to attacks. Assimilating the parameters of the transform to a secret key is not correct because those parameters could be inferred by presenting many image samples to the transform and looking at the outcome of the transformation (which is supposed to be available in a 'white-box' paradigm) for those samples. \n\n* Using block diagrams would definitely help in presenting the training/testing and attack/defense schemes investigated in Figure 3, 4, and 5.\n\n* The paper does not discuss the impact of the denfense strategy on the classification performance in absence of adversity.\n\n* The paper lacks of positioning with respect to recent related works, e.g. 'Adversary Resistant Deep Neural Networks with an Application to Malware Detection' in KDD 2017, or 'Building Adversary-Resistant Deep Neural Networks without\nSecurity through Obscurity' at https://arxiv.org/abs/1612.01401. \n\n* In a white-box scenario, the adversary knows about the transformation and the classification model. Hence, an effective and realistic attack should exploit this knowledge. Designing an attack in case of a non differentiable transformation is obviously not trivial since back-propagation can not be used. However, since the proposed transformation primarily aim at removing the high frequency pattern induced by the attack, one could for example design an attack that account for a (linear and differentiable) low-pass filter transformation. Another example of attack that account for transformation knowledge (and would hopefully be more robust than the attacks considered in the manuscript) could be one that alternates between a conventional attack and the transformation.\n\n* If I understand correctly, the classification model considered in Figure 3 has been trained on original images, while the one in Figure 4 has been trained on transformed images. However, in absence of attack, they both achieve 76% accuracy. Is it correct? Does it mean that the transformation does not affect the classification accuracy at all?\n\n\nOverall, the works investigates an interesting idea, but lacks maturity to be accepted. Therefore, I would only recommend acceptation if room.\n\nMinor issues:\n\nTypo on p7: to change*s*\nClarify poor formulations:\n* p1: 'enforce model-specific strategies that enforce model properties such as invariance and smoothness via the learning algorithm or regularization schemes'. \n* p1: 'too simple to remove adversarial perturbations from input images sufficiently'"", ' The paper investigates using input transformation techniques as a defence against adversarial examples. The authors evaluate a number of simple defences that are based on input transformations such TV minimization and image quilting and compare it against previously proposed ideas of JPEG compression and decompression and random crops.  The authors have evaluated their defences against four main kinds of adversarial attacks.\n\nThe main takeaways of the paper are to incorporate transformations that are non-differentiable and randomised. Both TV minimisation and image quilting have that property and show good performance in withstanding adversarial attacks in various settings. \n\nOne argument that I am not sure would be applicable perhaps and could be used by adversarial attacks is as follows: If the defence uses image quilting for instance and obtains an image $P$ that approximates the original observation $X$, it could be possible to use a model based approach that obtains an observation $Q$ that is close to $P$ which can be attacked using adversarial attacks. Would this observation then be vulnerable to such attacks? This could perhaps be explored in future.\n\nThe paper provides useful contributions in forming model agnostic defences that could be further investigated. The authors show that the simple input transformations advocated work against the major kind of attacks. The input transformations of TV minimization and image quilting share varying characteristics in terms of being sensitive to various kinds of attacks and therefore can be combined. The evaluation is carried out on ImageNet dataset with large number of examples.']","[80, -30, 70]","[50, 60, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They state that the paper is 'well written', the methods are 'well adapted to the task', and lead to 'satisfying results'. The reviewer also highlights that the authors' methods outperform previous approaches. The politeness score is 50 (somewhat polite) because the language used is professional and respectful, without being overly formal or effusive. The reviewer provides constructive feedback and acknowledges the paper's strengths without using particularly warm or enthusiastic language. The only slightly critical comment is a minor point about uniforming the bibliography, which is presented neutrally."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some strong points and the interesting idea, they ultimately recommend acceptance only if there's room and state the work 'lacks maturity'. There are more weak points listed than strong points, indicating an overall negative sentiment. However, it's not extremely negative as the reviewer sees potential in the work. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and provides constructive criticism. Phrases like 'to my knowledge', 'reasonably clear', and 'interesting idea' contribute to the polite tone. The reviewer also offers specific suggestions for improvement rather than just criticizing, which is a polite approach. The language is professional and objective, avoiding any harsh or rude phrasing."", ""The sentiment score is 70 (positive) because the reviewer generally speaks favorably about the paper, highlighting its 'useful contributions' and the effectiveness of the proposed defenses against major attacks. The reviewer also suggests areas for future exploration, which indicates engagement with the work. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames potential improvements as suggestions rather than criticisms. The phrase 'I am not sure' when presenting a potential counterargument shows a considerate approach to offering critique.""]"
"[""The paper proposes “fraternal dropout”, which passes the same input twice through a model with different dropout masks. The L2 norm of the differences is then used as an additional regulariser. As the authors note, this implicitly minimises the variance of the model under the dropout mask.\n\nThe method is well presented and adequately placed within the related work. The text is well written and easy to follow.\n\nI have only two concerns. The first is that the method is rather incremental and I am uncertain how it will stand the test of time and will be adopted.\n\nThe second is that of the experimental evaluation. They authors write that a full hyper parameter search was not conducted in the fear of having a more thorough evaluation than the base lines, erroneously reporting superior results.\n\nTo me, this is not an acceptable answer. IMHO, the evaluation should be thorough for both the base lines and the proposed method. If authors can get away with a sub standard evaluation because the competing method did, the field might converge to sub standard evaluations overall. This is clearly not in anyones interest. I am open to the author's comments on this, as I understand that spending weeks on tuning a competing method is also not unbiased and work that could be avoided if all software was published.\n"", 'The authors present Fraternal dropout as an improvement over Expectation-linear dropout (ELD) in terms of convergence and demonstrate the utility of Fraternal dropout on a number of tasks and datasets.\n\nAt test time, more often than not, people apply dropout in deterministic mode while at training time masks are sampled randomly. The paper addresses this issue by trying to reduce the gap.\n\nI have 1.5 high level comments:\n\n- Dropout can be applied by averaging results corresponding to randomly sampled masks (\'MC eval\'). This should not be ignored, and preferrably included in the evaluation.\n\n- It could be made clearer why the proposed regularization would make the aforementioned gap smaller. Intuitively, the bias of the deterministic approximation (compared to the MC eval) should also play a role. It may be worth asking whether the bias changes? A possibility is that MC and deterministic evaluations meet halfway and with fraternal dropout MC eval is worse than without.\n\nDetails:\n\n- The notation is confusing: p() looks like a probability distribution, z looks like a latent variable, p^t and l^t have superscripts instead of Y having a subscript, z^t is a function of X. Wouldn\'t f(X_t) be preferrable to p^t(z_t)?\n\n- The experiments are set up and executed with care, but section 4 could be improved by providings details (as much as in section 5). The results on PTB and Wikitext-2 are really good. However, why not compare to ELD here? Section 5 leads the reader to believe that ELD would be equally good.\n\n- Section 5 could be the most interesting part of the paper. This is where different regularization methods are compared (by the way, this is not ""ablation""). It is somewhat unfortunate that due to lack of computational resources the comparisons are made at a single hyperparameter setting.\n\nAll in all, the results of section 4 are clearly good, but are they better than those of ELD? Evaluation and interpretation of results in section 5 is made difficult by the omission of the most informative quantity which Fraternal dropout is supposed to be approximating.\n', ""The proposed method fraternal dropout is a stochastic alternative of the expectation-linear dropout method, where part of the objective is for the dropout mask to have low variance. The first order way to achieve lower variance is to have smaller weights. The second order is by having more evenly spread weights, so there is more concentration around the mean. As a result, it seems that at least part of the effect of explicitly reducing the variance is just stronger weight penalty. The effect of dropout in the first place is the opposite, where variance is introduced deliberately. So I would like to see some comparisons between this method and various dropout rates, and regular weight penalty combinations.\n\nThis work is very closely related to expectation linear dropout, except that you are now actually minimizing the variance: 1/2E[ ||f(s) - f(s')|| ] is used instead of E [ ||f(s) - f_bar|| ].  Eq 5 is very close to this, except the f_bar is not quite the mean, but the value with the mean dropout mask. So all the results should be compared with ELD.\n\nI do not think the method is theoretically well-motivated as presented, but the empirical results seem solid.\nIt is somewhat alarming how the analysis has little to do with the neural networks and how dropout works, let along RNNs, while the strength of the empirical results are all on RNNs.\n\nI feel the ideas interesting and valuable especially in light of strong empirical results, but the authors should do more to clarify what is actually happening.\n\nMinor: why use s_i and s_j, when there is never any reference to i and j? As far as I can tell, i and j serve as constants, more like s_1 and s_2.\n""]","[20, 20, -20]","[60, 60, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's good presentation and writing quality, but expresses concerns about its incrementality and experimental evaluation. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and expresses openness to their comments. The reviewer's concerns are presented constructively, using phrases like 'I have only two concerns' and 'I am open to the author's comments,' which maintain a polite tone while providing critical feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the good results and careful execution of experiments, particularly in section 4. However, they also raise several concerns and suggestions for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'could be improved' and 'it may be worth asking' which maintain a polite tone while still conveying their points. The reviewer also acknowledges the authors' efforts, such as noting that 'experiments are set up and executed with care', which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting ideas and solid empirical results, they express several concerns and criticisms. The reviewer states that the method is not theoretically well-motivated, the analysis has little to do with neural networks and RNNs, and they request more clarification and comparisons. However, it's not entirely negative as they recognize the value of the ideas and the strong empirical results.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I would like to see,' 'I feel the ideas interesting and valuable,' and 'the authors should do more to clarify,' which are polite ways of suggesting improvements. The reviewer also acknowledges positive aspects of the work alongside their criticisms. However, the score is not higher because the review is quite direct in its criticisms without much softening language.""]"
"['Summary:\n\nThe paper proposes a mixture of  generators to train GANs. The generators used have tied weights except the first layer that maps the random codes is generator specific, hence no extra computational cost is added.\n\n\nQuality/clarity:\n\nThe paper is well written and easy to follow.\n\nclarity: The appendix states how the weight tying is done , not the main paper, which might confuse the reader, would be better to state this weight tying that keeps the first layer free in the main text.\n\nOriginality:\n\n Using multiple generators for GAN training has been proposed in many previous work that are cited in the paper, the difference in this paper is in weight tying between generators of the mixture, the first layer is kept free for each generator.\n\nGeneral review:\n\n- when only the first layer is free between generators, I think it is not suitable to talk about multiple generators, but rather it is just a multimodal prior on the z, in this case z is a mixture of Gaussians with learned covariances (the weights of the first layer). This angle should be stressed in the paper, it is in fine, *one generator* with a multimodal learned prior on z!\n\n- Taking the multimodal z further , can you try adding a mean to be learned, together with the covariances also? see if this also helps?  \n \n- in the tied weight case, in the synthetic example, can you show what each ""generator"" of the mixture learn? are they really learning modes of the data? \n\n- the theory is for general untied generators, can you comment on the tied case? I don\'t think the theory is any more valid, for this case, because again your implementation is one generator with a multimodal z prior.  would be good to have some experiments and  see how much we loose for example in term of inception scores, between tied and untied weights of generators.\n', 'The present manuscript attempts to address the problem of mode collapse in GANs using a constrained mixture distribution for the generator, and an auxiliary classifier which predicts the source mixture component, plus a loss term which encourages diversity amongst components.\n\nAll told the proposed method is quite incremental, as mixture GANs/multi-generators have been done before. The Inception scores are good but it\'s widely known now that Inception scores are a deeply flawed measure, and presenting it as the only quantitative measure in a manuscript which makes strong claims about mode collapse unfortunately will not suffice. If the generator were to generate one template per class for which the Inception network\'s p(y|x) had low entropy, the Inception score would be quite high even though the model had only memorized one image per class. For claims surrounding mode collapse in particular, evaluation against a parameter count matched baseline using the AIS log likelihood estimation procedure in Wu et al (2017) would be the gold standard. Frechet Inception distance has also been proposed which at least has some favourable properties relative to Inception score.\n\nThe mixing proportions are fixed to the uniform distribution, and therefore this method also makes the unrealistic assumption that modes are equiprobable and require an equal amount of modeling capacity. This seems quite dubious.\n\nFinally, their own qualitative results indicate that they\'ve simply moved the problem, with clear evidence of mode collapse in one of their mixture components in figure 5c, 4th row from the bottom. Indeed, this does nothing to address the problem of mode collapse in general, as there is nothing preventing individual mixture component GANs from collapsing.\n\nUncited prior work includes Generative Adversarial Parallelization of Im et al (2016). Also, if I\'m not mistaken this is quite similar to an AC-GAN, where the classes are instead randomly assigned and the generator conditioning is done in a certain way; namely the first layer activations are the sum of K embeddings which are gated by the active mixture component. More discussion of this would be warranted.\n\nOther notes:\n- The introduction contains no discussion of the ill-posedness of the GAN game as it is played in practice.\n- ""As a result, the optimization order in 1 can be reversed"" this does not accurately characterize the source of the issues, see, e.g. Goodfellow (2015) ""On distinguishability criteria..."".\n- Section 3: the second last sentence of the third paragraph is vague and doesn\'t really say anything. Of course parameter sharing leverages common information. How does this help to train the model effectively?\n- Section 3: Since JSD is defined between two distributions, it is not clear what JSD_pi(P_G1, P_G2, ...) refers to. The last line of the proof of theorem 2 leaps to calling this term a Jensen-Shannon divergence but it\'s not clear what the steps are; it looks like a regular KL divergence to me.\n- Section 3: Also, is the classifier being trained to maximize this divergence or just the generator? I assume the latter.\n- The proof of Theorem 3 makes unrealistic assumptions that we know the number of components a priori as well as their mixing proportions (pi).\n- ""... which further minimizes the objective value"" -- it minimizes a term that you introduced which is constant with respect to your learnable parameters. This is not a selling point, and I\'m not sure why you bothered mentioning it.\n- There\'s no mention of the substitution of log (1 - D(x)) for -log(D(x)) and its effect on the interpretation as a Jensen-Shannon divergence (which I\'m not sure was quite right in the first place)\n- Section 4: does the DAE introduced in DFM really introduce that much of a computational burden? \n- ""Symmetric Kullback Liebler divergence"" is not a well-known measure. The standard KL is asymmetric. Please define it.\n- Figure 2 is illegible in grayscale.\n- Improved-GAN score in Table 1 is misleading, as this was their no-label baseline. It\'s fine to include it but indicate it as such.\n\nUpdate: many of my concerns were adequately addressed, however I still feel that calling this an avenue to ""overcome mode collapse"" is misleading. This seems aimed at improving coverage of the support of the data distribution; test log likelihood bounds via AIS (there are GAN baselines for MNIST in the Wu et al manuscript I mentioned) would have been more compelling quantitative evidence. I\'ve raised my score to a 5.', 'MGAN aims to overcome model collapsing problem by mixture generators. Compare to traditional GAN, there is a classifier added to minimax formulation. In training, MGAN is optimized towards minimizing the Jensen-Shannon Divergence between mixture distributions from generator and data distribution. The author also present that using MGAN to achive state-of-art results.\n\nThe paper is easy to follow.\n\nComment:\n\n1. Seems there still no principle to choose correct number of generators but try different setting. Although most parameters of generators are shared, the result various.\n2. Parameter sharing seems is a trick in MGAN model. Could you provide experiment results w/o parameter sharing.\n\n']","[50, -20, 50]","[75, 50, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper is well-written and easy to follow, and provides constructive feedback. However, they also point out some limitations and areas for improvement. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offers suggestions rather than demands, and balances criticism with positive remarks. The reviewer uses phrases like 'would be better to' and 'can you try' which are polite ways of suggesting improvements. The overall tone is professional and constructive, without being overly critical or harsh."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Inception scores are good', 'many of my concerns were adequately addressed'), the overall tone is critical. The reviewer points out several limitations and issues with the manuscript, such as the method being 'quite incremental', the use of flawed measures, and unrealistic assumptions. The final update suggests some improvement but still maintains reservations about the main claim.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement, cite relevant literature, and provide detailed explanations for their criticisms. The language used is not harsh or personal, but rather focuses on the content of the manuscript. The reviewer also acknowledges when their concerns have been addressed, showing a fair and balanced approach."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's aims and achievements, noting it's 'easy to follow' and achieves 'state-of-art results'. However, they don't express strong enthusiasm. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, framing their comments as suggestions ('Could you provide...') rather than demands. They also start with positive observations before moving to constructive feedback, which is a polite approach. The lack of strongly positive language or effusive praise prevents higher scores, but the overall tone is professional and courteous.""]"
"['The authors propose a generative method that can produce images along a hierarchy of specificity, i.e. both when all relevant attributes are specified, and when some are left undefined, creating a more abstract generation task. \n\nPros:\n+ The results demonstrating the method\'s ability to generate results for (1) abstract and (2) novel/unseen attribute descriptions, are generally convincing. Both quantitative and qualitative results are provided. \n+ The paper is fairly clear.\n\nCons:\n- It is unclear how to judge diversity qualitatively, e.g. in Fig. 4(b).\n- Fig. 5 could be more convincing; ""bushy eyebrows"" is a difficult attribute to judge, and in the abstract generation when that is the only attribute specified, it is not clear how good the results are.\n', 'This paper presented a multi-modal extension of variational autoencoder (VAE) for the task ""visually grounded imagination.""  In this task,  the model learns a joint embedding of the images and the attributes. The proposed model is novel but incremental comparing to existing frameworks.  The author also introduced new evaluation metrics to evaluate the model performance concerning correctness, coverage, and compositionality. \n\nPros:\n1. The paper is well-written, and the contribution (both the model and the evaluation metric) potentially can to be very useful in the community.  \n2. The discussion comparing the related work/baseline methods is insightful. \n3. The proposed model addresses many important problems, such as attribute learning, disentanged representation learning, learning with missing values, and proper evaluation methods. \n\nCons/questions:\n1. The motivation of the model choice of q is not clear.\nComparing to BiVCCA, apart from the differences that the author discussed, a big difference is the choice of q.  BiVCCA uses two inference networks q(z|x) and q(z|y), while the proposed method uses three. q(z|x), q(z|y), and q(z|x,y).  How does such model choice affect the final performance? \n\n2. Baselines are not necessarily sufficient. \nThe paper compared the vanilla version of BiVCCA but not the one with factorized representation version. In the original VAECCA paper, the extension of using factorized representation (private and shared) improved the performance]. The author should also compare this extension of VAECCA.\n\n3. Some details are not clear. \na) How to set/learn the scaling parameter \\lambda_y and \\beta_y? If it is set as hyper-parameter, how does the performance change concerning them? \nb) Discussion of the experimental results is not sufficient. For example, why JMVAE performs much better than the proposed model when all attributes are given.  What is the conclusion from Figure 4(b)? The JMVAE seems to generate more diverse (better coverage) results which are not consistent with the claims in the related work.  The same applies to figure 5. \n', ""The paper proposes a method for generating images from attributes. The core idea is to learn a shared latent space for images and attributes with variational auto-encoder using paired samples, and additionally learn individual inference networks from images or attributes to the latent space using unpaired samples. During training the auto-encoder is trained on paired data (image, attribute) whereas during testing one uses the unpaired data to generate an image corresponding to an attribute or vice versa. The authors propose handling missing data using a product of experts where the product is taken over available attributes, and it sharpens the prior distribution. The authors evaluate their method using correctness i.e. if the generated images have the desired attributes, coverage i.e. if the generated images sample unspecified attributes well, and compositionality i.e. if  images can be generated from unseen attributes. Although the proposed method performs slightly poor compared to JMVAE in terms of concreteness when all attributes are provided, it outperforms when some of the attributes are missing (Figure 4a). It also outperforms existing methods in terms of coverage and compositionality.\n\nMajor comments:\n\nThe paper is well written, and summarizes its contribution succinctly.\n\nI did not fully understand the 'retrofitting' idea. If I understood correctly, the authors first train \\theta and \\phi and then fix \\theta to train \\phi_x and \\phi_y. If that is true, then is \\calL(\\theta, \\phi, \\phi_x, \\phi_y) are right cost function since one does not maximize all three ELBO terms when optimizing \\theta? Please clarify?\n\nMinor comments:\n\n- 'in order of increasing abstraction', does the order of gender-> smiling or not -> hair color matter? Or, is male, *, blackhair a valid option?\n\n- what are the image sizes for the CelebA dataset\n\n- page 5: double the\n\n- Which multi-label classifier is used to classify images in attributes?""]","[50, 50, 70]","[75, 80, 80]","[""The sentiment score is 50 (slightly positive) because the review begins with a neutral description of the authors' work, followed by a balanced list of pros and cons. The pros highlight convincing results and clarity, while the cons point out areas for improvement without being overly critical. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the work and framing criticisms as suggestions for improvement rather than harsh judgments. The use of phrases like 'fairly clear' and 'could be more convincing' maintains a constructive tone without being overly deferential."", ""The sentiment score is 50 (slightly positive) because the review begins with a neutral description of the paper's content, followed by a balanced list of pros and cons. The pros highlight the paper's well-written nature, potential usefulness, and insightful discussion. However, the cons raise several questions and concerns, which temper the overall positive sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. The cons are framed as questions or suggestions rather than harsh criticisms, maintaining a constructive tone. Phrases like 'The paper is well-written' and 'The discussion... is insightful' contribute to the polite tone, while the questions and suggestions are presented in a professional manner without any rude or dismissive language."", ""The sentiment score is 70 (positive) because the reviewer begins by summarizing the paper's main ideas and contributions in a neutral tone, then states that the paper is 'well written' and 'summarizes its contribution succinctly'. The reviewer also notes that the proposed method outperforms existing methods in some aspects. There are some questions and minor comments, but they are presented constructively rather than critically. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, frames their comments as questions or suggestions rather than demands, and acknowledges the paper's strengths. The use of phrases like 'Please clarify?' and the constructive nature of the minor comments contribute to the polite tone. The reviewer also balances positive feedback with areas for improvement, maintaining a professional and courteous approach.""]"
"['This paper firstly proposes a GAN architecture that aim at decomposing the underlying distribution of a particular class into ""content"" and ""view"". The content can be seen as an intrinsic instantiation of the class that is independent of certain types of variation (eg viewpoint), and a view is the observation of the object under a particular variation. The authors additionally propose a second conditional GAN that learns to generate different views given a specific content. \n\nI find the idea of separating content and view interesting and I like the GMV and CGMV architectures. Not relying on manual attribute/class annotation for the views is also positive. The approach seems to work well for a relatively clean setup such as the chair dataset, but for the other datasets the separation is not so apparent. For example, in figure 5, what does each column represent in terms of view? It seems that it depends heavily on the content. That raises the question of how useful it is to have such a separation between content and views; for some datasets their diversity can be a bottleneck for this partition, making the interpretation of views difficult. \n\nA missing (supervised) reference that considers also the separation of content and views.\n[A] Learning to generate chairs with convolutional neural networks, Alexey Dosovitskiy, Jost Tobias Springenberg, Thomas Brox, CVPR 15\n\nQ:Figure 5, you mean ""all images in a column were generated with the same view vector""\nQ: Why on Figure 7 you use different examples for CGAN?', 'The paper proposes a new generative model based on the Generative Adversarial Network (GAN). The method disentangles the content and the view of objects without view supervision. The proposed Generative Multi-View (GMV) model can be considered to be an extension of the traditional GAN, where the GMV takes the content latent  vector and the view latent vector as input. In addition, the GMV is trained to generate a pair of objects that share the content but with different views. In this way, the GMV successfully models the content and the view of the objects without using view labels. The paper also extends GMV into a conditional generative model that takes an input image and generates different views of the object in the input image. Experiments are conducted on four different datasets to show the generative ability of the proposed method.\n\nPositives:\n- The proposed method is novel in disentangling the content and the view of objects in a GAN and training the GAN with pairs of objects. By using pairs that share the content but with different views, the model can be trained successfully without using view labels.\n\n- The experimental results on the four datasets show that the proposed network is able to model the context and the view of objects when generating images of these objects.\n\nNegatives:\n- The paper only shows comparison between the proposed method and several baselines: DCGAN and CGAN. There is no comparison with methods that also disentangle the content from the view such as Mathieu et al. 2016.\n\n- For the comparison with CGAN in Figure 7, it would be better to show the results of C-GMV and CGAN on the same input images. Then it is easier for the readers to see the differences in the results from the two methods. ', 'The paper proposes a GAN-based method for image generation that attempts to separate latent variables describing fixed ""content"" of objects from latent variables describing properties of ""view"" (all dynamic properties such as lighting, viewpoint, accessories, etc). The model is further extended for conditional generation and demonstrated on a range of image benchmark data sets.\n\nThe core idea is to train the model on pairs of images corresponding to the same content but varying in views, using adversarial training to discriminate such examples from generated pairs. This is a reasonable procedure and it seems to work well, but also conceptually quite straightforward -- this is quite likely how most people working in the field would solve this problem, standard GAN techniques are used for training the generator and discriminator, and the network architecture is directly borrowed from Radford et al. (2015) and not even explained at all in the paper. The conditional variant is less obvious, requiring two kinds of negative images, and again the proposed approach seems technically sound.\n\nGiven the simplicity of the algorithmic choices, the potential novelty of the paper lies more in the problem formulation itself, which considers the question of separating two sets of latent variables from each other in setups where one of them (the ""view"") can vary from pair to pair in arbitrary manner and no attributes characterising the view are provided. This is an interesting problem setup, but not novel as such and unfortunately the paper does not do a very good job in putting it into the right context. The work is contrasted only against recent GAN-based image generation literature (where covariates for the views are often included) and the aspects related to multi-view learning are described only at the level of general intuition, instead of relating to the existing literature on the topic. The only relevant work cited from this angle is Mathieu et al. (2016), but even that is dismissed lightly by saying it is worse in generative tasks. How about the differences (theoretical and empirical) between the proposed approach and theirs in disentangling the latent variables? One would expect to see more discussion on this, given the importance of this property as motivation for the method.\n\nThe generative story using three sets of latent variables, one shared, to describe a pair of objects corresponds to inter-battery factor analysis (IBFA) and is hence very closely related to canonical correlation analysis as well (Tucker ""An inter-battery method of factor analysis"", Psychometrika, 1958; Klami et al. ""Bayesian canonical correlation analysis"", JMLR, 2013). Linear CCA naturally would not be sufficient for generative modeling and its non-linear variants (e.g. Wang et al. ""Deep variational canonical correlation analysis"", arXiv:1610.03454, 2016; Damianou et al. ""Manifold relevance determination"", ICML, 2012) would not produce visually pleasing generative samples either, but the relationship is so close that these models have even been used for analysing setups identical to yours (e.g. Li et al. ""Cross-pose face recognition by canonical correlation analysis"", arXiv:1507.08076, 2015) but with goals other than generation. Consequently, the reader would expect to learn something about the relationship between the proposed method and the earlier literature building on the same latent variable formulation. A particularly interesting question would be whether the proposed model actually is a direct GAN-based extension of IBFA, and if not then how does it differ. Use of adversarial training to encourage separation of latent variables is clearly a reasonable idea and quite likely does better job than the earlier solutions (typically based on some sort of group-sparsity assumption in shared-private factorisation) with the possible or even likely exception of Mathieu at al. (2016), and aspects like this should be explicitly discussed to extend the contribution from pure image generation to multi-view literature in general.\n\nThe empirical experiments are somewhat non-informative, relying heavily on visual comparisons and only satisfying the minimum requirement of demonstrating that the method does its job. The results look aesthetically more pleasing than the baselines, but the reader does not learn much about how the method actually behaves in practice; when does it break down, how sensitive it is to various choices (network structure, learning algorithm, amount of data,  how well the content and view can be disentangled from each other, etc.). In other words, the evaluation is a bit lazy somewhat in the same sense as the writing and treatment of related work; the authors implemented the model and ran it on a collection of public data sets, but did not venture further into scientific reporting of the merits and limitations of the approach.\n\nFinally, Table 1 seems to have some min/max values the wrong way around.\n\n\nRevision of the review in light of the author response:\nThe authors have adequately addressed my main remarks, and while doing so have improved both the positioning of the paper amongst relevant literature and the somewhat limited empirical comparisons. In particular, the authors now discuss alternative multi-view generative models not based on GANs and the revised paper includes considerably extended set of numerical comparisons that better illustrate the advantage over earlier techniques. I have increased my preliminary rating to account for these improvements.']","[50, 60, 20]","[70, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer finds the idea interesting and likes the proposed architectures, but also expresses some concerns about the approach's effectiveness on diverse datasets. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms as questions or observations rather than direct attacks. The reviewer also provides a helpful reference and asks clarifying questions, which is constructive and polite behavior in academic discourse."", ""The sentiment score is 60 (positive) because the review begins with a detailed description of the paper's proposed method and highlights several positives, such as the novelty of the approach and successful experimental results. However, it also mentions some negatives, which prevents it from being extremely positive. The politeness score is 50 (somewhat polite) because the reviewer uses neutral, professional language throughout and presents both positive and negative aspects in a balanced manner. The critique is constructive and not personally directed, but it also doesn't go out of its way to be overly polite or complimentary."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's contributions and improvements made after the author response, they also point out several limitations and areas for improvement. The review begins with a neutral tone, becomes more critical in the middle, but ends on a more positive note after the author response. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout, using phrases like 'reasonable procedure', 'technically sound', and 'interesting problem setup'. They offer constructive criticism without being harsh or dismissive, and acknowledge the authors' efforts to address their concerns in the revision. The language is formal and academic, avoiding any rudeness or overly emotional expressions.""]"
"['This paper interprets deep residual network as a dynamic system, and proposes a novel training algorithm to train it in a constructive way. On three image classification datasets, the proposed algorithm speeds up the training process without sacrificing accuracy. The paper is interesting and easy to follow. \n\nI have several comments:\n1.\tIt would be interesting to see a comparison with Stochastic Depth, which is also able to speed up the training process, and gives better generalization performance. Moreover, is it possible to combine the proposed method with Stochastic Depth to obtain further improved efficiency?\n2.\tThe mollifying networks [1] is related to the proposed method as it also starts with shorter networks, and ends with deeper models. It would be interesting to see a comparison or discussion. \n[1] C Gulcehre, Mollifying Networks, 2016\n3.\tCould you show the curves (on Figure 6 or another plot) for training a short ResNet (same depth as your starting model) and a deep ResNet (same depth as your final model) without using your approach?', 'I enjoyed reading the paper. This is a very well written paper, the authors propose a method for speeding up the training time of Residual Networks based on the dynamical system view interpretation of ResNets. In general I have a positive opinion about the paper, however, I’d like to ask for some clarifications.\n\nI’m not fully convinced by the interpretation of Eq. 5: “… d is inversely proportional to the norm of the residual modules G(Yj)”. Since F(Yj) is not a constant, I think that d is inversely proportional to ||G(Yj)||/||F(Yj)||, however, in the interpretation the dependence on ||F(Yj)|| is ignored. Could the authors comment on that?\n\nSection 4. 1 “ Each cycle itself can be regarded as a training process, thus we need to reset the learning rate value at the beginning of each training cycle and anneal the learning rate during that cycle.” Is there any empirical evidence for this? What would happen if the learning rate is not reset at the beginning of each cycle? \n\nQuestions with respect to dynamical systems point of view: Eq. 4 assumes small value of h. However, for ResNet there is no guarantee that the h would be small (e. g. in Appendix C the values between 0.25 and 1 are used). Would the authors be willing to comment on the importance of the value of h? In figure 1, pooling (strided convolutions) are not depicted between network stages. I have one question w.r.t. feature maps dimensionality changes inside a CNN: how does pooling (or strided convolution) fit into dynamical systems view?\n\nTable 3 and 4. I assume that the training time unit is a minute, I couldn’t find this information in the paper. Is the batch size the same for all models (100 for CIFAR and 32 for STL-10)? I understand that the models with different #Blocks have different capacity, for clarity, would it be possible to add # of parameters to each model? For multilevel method, would it be possible to show intermediate results in Table 3 and 4, e. g. at the end of cycle 1 and 2? I see these results in Figure 6, however, the plots are condensed and it is difficult to see the exact number at the end of each cycle. \n\nThe citation (E, 2017) seems to be wrong, could the authors check it?\n', ""\n\nThis paper proposes a new method to train residual networks in which one starts by training shallow ResNets, doubling the depth and warm starting from the previous smaller model in a certain way, and iterating.  The authors relate this idea to a recent dynamical systems view of ResNets in which residual blocks are viewed as taking steps in an Euler discretization of a certain differential equation.  This interpretation plays a role in the proposed training method by informing how the “step sizes” in the Euler discretization should change when doubling the depth of the network.  The punchline of the paper is that the authors are able to achieve similar performance as “full ResNet training” but with significantly reduced training time.\n\nOverall, the proposed method is novel — even though this idea of going from shallow to deep is natural for residual networks, tying the idea to the dynamical systems perspective is elegant.  Moreover the paper is clearly written.  Experimental results are decent — there are clear speedups to be had based on the authors' experiments.  However it is unclear if these gains in training speed are significant enough for people to flock to using this (more complicated) method of training.\n\nI only have a few small questions/comments:\n* A more naive way to do multi-level training would be to again iteratively double the depth, but perhaps not halve the step size.  This might be a good baseline to compare against to demonstrate the value of the dynamical systems viewpoint.\n* One thing I’m unclear on is how convergence was assessed… my understanding is that the training proceeds for a fixed number of epochs (?) - but shouldn’t this also depend on the depth in some way? \n* Would the speedups be more dramatic for a larger dataset like Imagenet?\n* Finally, not being very familiar with multigrid methods from the numerical methods literature — I would have liked to hear about whether there are deeper connections to these methods.\n\n\n""]","[70, 60, 60]","[80, 80, 70]","[""The sentiment score is 70 (positive) because the reviewer describes the paper as 'interesting and easy to follow' and acknowledges that the proposed algorithm speeds up the training process without sacrificing accuracy. The overall tone is positive, but not overwhelmingly enthusiastic. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, framing their comments as suggestions and inquiries rather than criticisms. Phrases like 'It would be interesting to see' and 'Could you show' indicate a constructive and courteous approach to feedback. The reviewer also acknowledges the paper's strengths before offering suggestions for improvement, which is a polite way to structure feedback."", ""The sentiment score is 60 (positive) because the reviewer starts by saying they 'enjoyed reading the paper' and have a 'positive opinion about the paper'. However, they also express some doubts and request clarifications, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or requests for clarification, and acknowledges the paper's strengths. They use phrases like 'Could the authors comment on that?' and 'Would the authors be willing to comment...?' which are polite ways of requesting more information. The overall tone is constructive and collaborative rather than critical."", ""The sentiment score is 60 (moderately positive) because the reviewer describes the proposed method as 'novel' and 'elegant', praises the clear writing, and notes 'clear speedups'. However, they also express some reservations about whether the gains are significant enough for widespread adoption. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as 'questions/comments'. They avoid harsh language and maintain a professional tone. The reviewer balances positive feedback with constructive criticism in a courteous manner.""]"
"['The paper ‘Deep learning for Physical Process: incorporating prior physical knowledge’ proposes\nto question the use of data-intensive strategies such as deep learning in solving physical \ninverse problems that are traditionally solved through assimilation strategies. They notably show\nhow physical priors on a given phenomenon can be incorporated in the learning process and propose \nan application on the problem of estimating sea surface temperature directly from a given \ncollection of satellite images.\n\nAll in all the paper is very clear and interesting. The results obtained on the considered problem\nare clearly of great interest, especially when compared to state-of-the-art assimilation strategies\nsuch as the one of Béréziat. While the learning architecture is not original in itself, it is \nshown that a proper physical regularization greatly improves the performance. For these reasons I \nbelieve the paper has sufficient merits to be published at ICLR. That being said, I believe that \nsome discussions could strengthen the paper:\n - Most classical variational assimilation schemes are stochastic in nature, notably by incorporating\nuncertainties in the observation or physical evolution models. It is still unclear how those uncertainties \ncan be integrated in the model;\n - Assimilation methods are usually independent of the type of data at hand. It is not clear how the model\nlearnt on one particular type of data transpose to other data sequences. Notably, the question of transfer\nand generalization is of high relevance here. Does the learnt model performs well on other dataset (for instance,\nacquired on a different region or at a distant time). I believe this type of issue has to be examinated \nfor this type of approach to be widely use in inverse physical problems. \n', 'The authors use deep learning to learn a surrogate model for the motion vector in the advection-diffusion equation that they use to forecast sea surface temperature. In particular, they use a CNN encoder-decoder to learn a motion field, and a warping function from the last component to provide forecasting. \n\nI like the idea of using deep learning for physical equations. I would like to see a description of the algorithm with the pseudo-code in order to understand the flow of the method. I got confused at several points because it was not clear what was exactly being estimated with the CNN. Having an algorithmic environment would make the description easier. I know that authors are going to publish the code, but this is not enough at this point of the revision. \n\nPhysical processes in Machine learning have been studied from the perspective of Gaussian processes. Just to mention a couple of references “Linear latent force models using Gaussian processes” and ""Numerical Gaussian Processes for Time-dependent and Non-linear Partial Differential Equations""\n\nIn Theorem 2, do you need to care about boundary conditions for your equation? I didn’t see any mention to those in the definition for I(x,t). You only mention initial conditions. How do you estimate the diffusion parameter D? Are you assuming isotropic diffusion? Is that realistic? Can you provide more details about how you run the data assimilation model in the experiments? Did you use your own code?\n', ""In this paper, the authors show how a Deep Learning model for sea surface temperature prediction can be designed to incorporate the classical advection diffusion model. The architecture includes a differentiable warping scheme which allows back propagation of the error and is inspired by the fundamental solution of the PDE model. They evaluate the suggested model on synthetic data and outperform the current state of the art in terms of accuracy.\n\npros\n- the paper is written in a clear and concise manner\n- it suggests an interesting connection between a traditional model and Deep Learning techniques\n- in the experiments they trained the network on 64 x 64 patches and achieved convincing results\n\ncons\n- please provide the value of the diffusion coefficient for the sake of reproducibility\n- medium resolution of the resulting prediction\n\n\nI enjoyed reading this paper and would like it to be accepted.\n\nminor comments:\n- on page five in the last paragraph there is a left parenthesis missing in the inline formula nabla dot w_t(x))^2.\n- on page nine in the last paragraph there is the word 'flow' missing: '.. estimating the optical [!] between 2 [!] images.'\n- in the introduction (page two) the authors refer to SST prediction as a 'relatively complex physical modeling problem', whereas in the conclusion (page ten) it is referred to as 'a problem of intermediate complexity'. This seems to be inconsistent.""]","[80, 20, 80]","[90, 60, 90]","[""The sentiment score is 80 (positive) because the reviewer expresses a clearly favorable view of the paper, stating it is 'very clear and interesting' and has 'sufficient merits to be published'. They praise the results as being 'of great interest' and highlight the improvement over state-of-the-art methods. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'I believe' to soften criticisms and offers suggestions for improvement rather than harsh critiques. They acknowledge the paper's strengths before providing additional points for consideration, maintaining a balanced and courteous approach throughout the review."", ""The sentiment score is slightly positive (20) because the reviewer expresses interest in the idea ('I like the idea of using deep learning for physical equations') and offers constructive feedback. However, they also point out several areas of confusion and request more information, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses polite language throughout, such as 'I would like to see' and 'Can you provide more details', and frames their criticisms as questions or suggestions rather than direct criticisms. The reviewer also acknowledges the authors' intention to publish code, showing consideration. The overall tone is professional and respectful, while still providing thorough feedback."", 'The sentiment score is 80 (positive) because the reviewer expresses enjoyment in reading the paper, recommends acceptance, and provides more pros than cons. The overall tone is appreciative of the work. The politeness score is 90 (very polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as suggestions rather than demands. The reviewer also balances critique with praise. The reasoning for these scores is based on the positive opening statement, the clear list of pros outweighing the cons, the polite phrasing of suggestions, and the explicit statement of enjoyment and recommendation for acceptance.']"
"[""Pros: \nThe paper proposes a “Densely Interactive Inference Network (DIIN)” for NLI or NLI alike tasks. Although using tensors to capture high-order interaction and performing dimension reduction over that are both not novel, the paper explores them for NLI. The paper is written clearly and is very easy to follow. The ablation experiments in Table 5 give a good level of details to help observe different components' effectiveness.\nCons:\n1) The differences of performances between the proposed model and the previous models are not very clear. With regard to MultiNLI, since the previous results (e.g., those in Table 2) did not use cross-sentence attention and had to represent a premise or a hypothesis as a *fixed-length* vector, is it fair to compare DIIN with them? Note that the proposed DIIN model does represent a premise or a hypothesis by variable lengths (see interaction layer in Figure 1), and tensors provide some sorts of attention between them. Can this (Table 2) really shows the advantage of the proposed models? However, when a variable-length representation is allowed (see Table 3 on SNLI), the advantage of the model is also not observed, with no improvement as a single model (compared with ESIM) and being almost same as previous models (e.g., model 18 in Table 3) in ensembling.\n2) Method-wise, as discussed above, using tensors to capture high-order interaction and performing dimension reduction over that are both not novel.\n3) The paper mentions the use of untied parameters for premise and hypothesis, but it doesn’t compare it with tied version in the experiment section. \n4) In Table 6, for CONDITIONAL tag, why the baseline models (lower total accuracies) have a 100% accuracy, but DIIN only has about a 60% accuracy?\n"", 'Thank you for this paper! It is very nice piece of work and the problem of coding the ""necessary semantic information required for understanding the text"" is really a very important one.\n\nYet, as many papers, it fails to be clear in describing what is its real novelty and the introduction does not help in focussing what is this innovation. \n\nThe key point of the paper seems to demonstrate that the ""interaction tensor contains the necessary semantic information required for understanding the text"". This is a clear issue as this demostration is given only using 1) ablation studies removing gates and non capabilities; 2) analyzing the behavior of the model in the annotated subpart of the MultiNLI corpus; 3) a visual representation of the alignment produced by the model. Hence, there is not a direct analysis of what\'s inside the interaction tensors. This is the major limitation of the study. According to this analysis, DIIN seems to be a very good paraphrase detector and word aligner. In fact, Table 6 reports the astonishing 100% in paraphrase detection for the Mismatch examples. It seems also that examples where rules are necessary are not correctly modeled by DIIN: this is shown by the poor result on Conditional and Active Passive. Hence, DIIN seems not to be able to capture rules. \n\nFor a better demostration, there should be a clearer analysis of these ""interaction tensors"". The issue of the interpretability of what is in these tensors is gaining attention and should be taken into consideration if the main claim of the paper is that: ""interaction tensor contains the necessary semantic information required for understanding the text"". Some interesting attempts have been made in ""Harnessing Deep Neural Networks with Logic Rules"", ACL 2016 and in ""Can we explain natural language inference decisions taken with neural networks? Inference rules in distributed representations"", IJCNN 2017.\n\n\nMinor issues\n======\nCapital letters are used in the middle of some sentences, e.g. ""On the other hand, A mul"",  ""powerful capability, We hypothesize""\n\n\n\n', ""This paper proposes Densely Interactive Inference Network to solve recognizing textual entailment via extracting a semantic feature from interaction tensor end-to-end. Their results show that this model has better performance than others.\n\nEven though the results of this paper is interesting, I have the problem with paper writing and motivation for their architecture:\n\n- Paper pages are well beyond 8-page limits for ICLR. The paper should be 8-pages + References. This paper has 11 pages excluding the references.\n-  The introduction text in the 2nd page doesn't have smooth flow and sometimes hard to follow.\n-  In my view section, 3.1 is redundant and text in section 3.2 can be improved\n-  Encoding layer in section 3.2 is really hard to follow in regards to equations and naming e.g p_{itr att} and why choose \\alpha(a,b,w)? \n-  Encoding layer in section 3.2, there is no motivation why it needs to use fuse gate.\n-  Feature Extraction Layer is very confusing again. What is FSDR or TSDR?\n-  Why the paper uses Eq. 8? the intuition behind it?\n-  One important thing which is missing in this paper, I didn't understand what is the motivation behind using each of these components? and how each of these components is selected?\n- How long does it take to train this network? Since it needs to works with other models (GLOV+ char features + POS tagging,..), it requires lots of effort to set up this network.\n\nEven though the paper outperforms others, it would be useful to the community by providing the motivation and intuition why each of these components was chosen. This is important especially for this paper because each layer of their architecture uses multiple components, i.e. embedding layer [Glov+ Character Features + Syntactical features].  In my view, having just good results are not enough and will not guarantee a publication in ICLR, the paper should be well-written and well-motivated in order to be useful for the future research and the other researchers.\nIn summary, I don't think the paper is ready yet and it needs significant revision.\n\n\n\n---------------------------------------------------------------------------------------------------------------------------------------------------------------\n---------------------------------------------------------------------------------------------------------------------------------------------------------------\nComments after the rebuttal and revision :\nI'd like thanks the authors for the revision and their answers. \nHere are my comments after reading the revised version and considering the rebuttal:\n- It is fair to say that the paper presentation is much better now. That said I am still having issues with 11 pages.\n- The authors imply on page 2, end of paragraph 5,  that this is the first work that shows attention weight contains rich semantic and previous works are used attention merely as a medium for alignment.  Referring to the some of the related works (cited in this paper), I am not sure this is a correct statement.\n- The authors claim to introduce a new class of architectures for NLI and generability of for this problem. In my view, this is a very strong statement and unsupported in the paper, especially considering ablation studies (table 5). In order for the model to show the best performance, all these components should come together. I am not sure why this method can be considered a class of architecture and why not just a new model?\n\nsome other comments:\n- In page 4, the citation is missing for highway networks\n- Page 5, equation 1, the parenthesis should close after \\hat{P}_j.\n\nSince the new version has been improved, I have increased my review score.  However, I'm still not convinced that this paper would be a good fit at ICLR given novelty and contribution.""]","[-20, -20, -50]","[60, 60, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is written clearly', 'good level of details'), they raise several significant concerns and criticisms. The cons outweigh the pros, indicating an overall negative sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, frames criticisms as questions or observations rather than direct attacks, and begins with positive comments before moving to criticisms. They maintain a professional tone without using harsh or rude language."", ""The sentiment score is slightly negative (-20) because while the reviewer starts with praise, calling it a 'very nice piece of work', they go on to point out several significant limitations and issues with the paper. The reviewer states that the paper 'fails to be clear', has a 'major limitation', and doesn't adequately demonstrate its main claim. However, the criticism is balanced with some positive remarks, preventing a more negative score. The politeness score is moderately positive (60) as the reviewer uses polite language throughout, starting with 'Thank you for this paper!' and phrasing criticisms constructively. They offer specific suggestions for improvement and use phrases like 'for a better demonstration' rather than harsh criticism. The reviewer maintains a professional and respectful tone, even when pointing out flaws."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper, stating it 'needs significant revision' and is 'not ready yet'. However, they do acknowledge some positive aspects like interesting results and improved presentation after revision, preventing an extremely negative score. The politeness score is 20 because the reviewer uses generally polite language, thanking the authors for their revision and providing constructive feedback. They avoid harsh criticism and use phrases like 'in my view' to soften their comments. However, the overall critical nature of the review prevents a higher politeness score.""]"
"['Learning sparse neural networks through L0 regularisation\n\nSummary: \n\nThe authors introduce a gradient-based approach to minimise an objective function with an L0 sparse penalty. The problem is relaxed onto a continuous optimisation by changing an expectation over discrete variables (representing whether a variable is present or not) to an expectation over continuous variables, inspired by earlier work from Maddison et al (ICLR 2017) where a similar transformation was used to learn over discrete variable prediction tasks with neural networks. Here the application is to learn sparse feedforward networks in standard classification tasks, although the framework described is quite general and could be used to impose L0 sparsity to any objective function in principal. The method provides equivalent accuracy and sparsity to published state-of-the-art results on these datasets but it is argue that learning sparsity during the training process will lead to significant speed-ups - this is demonstrated by comparing to a theoretical benchmark (standard training with dropout) rather than through empirical testing against other implementations. \n\nPros:\n\nThe paper is well written and the derivation of the method is easy to follow with a good explanation of the underlying theory. \n\nOptimisation under L0 regularisation is a difficult and generally important topic and certainly has advantages over other sparse inference objective functions that impose shrinkage on non-sparse parameters. \n\nThe work is put in context and related to some previous relaxation approaches to sparsity. \n\nThe method allows for sparsity to be learned during training rather than after training (as in standard dropout approaches) and this allows the algorithm to obtain significant per-iteration speed-ups, which improves through training. \n\nCons:\n\nThe method is applied to standard neural network architectures and performance in terms of accuracy and final achieved sparsity is comparable to the state-of-the-art methods. Therefore the main advance is in terms of learning speed to obtain this similar performance. However, the learning speed-up is presented against a theoretical FLOPs estimate per iteration for a similar network with dropout. It would be useful to know whether the number of iterations to achieve a particular performance is equivalent for all the different architectures considered, e.g. does the proposed sparse learning method converge at the same rate as the others? I felt a more thorough experimental section would have greatly improved the work, focussing on this learning speed aspect. \n\nIt was unclear how much tuning of the lambda hyper-parameter, which tunes the sparsity, would be required in a practical application since tuning this parameter would increase computation time. It might be useful to provide a full Bayesian treatment so that the optimal sparsity can be chosen through hyper-parameter learning. \n\nMinor point: it wasn’t completely clear to me why the fact (3) is a variational approximation to a spike-and-slab is important (Appendix). I don’t see why the spike-and-slab is any more fundamental than the L0 norm prior in (2), it is just more convenient in Bayesian inference because it is an iid prior and potentially allows an informative prior over each parameter. In the context here this didn’t seem a particularly relevant addition to the paper. \n\n', 'This paper presents a continuous surrogate for the ell_0 norm and focuses on its applications in regularized empirical regularized minimization. The proposed continuous relaxation scheme allows for gradient based-stochastic optimization for binary discrete variables under the reparameterization trick, and extends the original binary concrete distribution by allowing the parameter taking values of exact zeros and ones, with additional stretching and thresholding operations. Under a compound construction of sparsity, the proposed approach can easily incorporate group sparsity by sharing supports among the grouped variables, or be combined with other types of regularizations on the magnitude of non-zero components. The efficacy of the proposed method in sparsification and speedup is demonstrated in two experiments with comparisons against a few baseline methods. \n\nPros: \n\n- The paper is clearly written, self-contained and a pleasure to read. \n- Based on the evidence provided, the procedure seems to be a useful continuous relaxation scheme to consider in handling optimization with spike and slab regularization\n\nCons: \n\n- It would be interesting to see how the induced penalty behaves in terms shrinkage comparing against ell_0 and other ell_p choices \n- It is unclear what properties does the proposed hard-concrete distribution have, e.g., closed-form density, convexity, etc.   \n- If the authors can offer a rigorous analysis on the influence of base concrete distribution and provide more guidance on how to choose the stretching parameters in practice, this paper would be more significant\n', 'The paper introduces a technique for optimizing an L0 penalty on the weights of a neural network. The basic problem is empirical risk minimization with a incremental penalty for each non zero weight. To tackle this problem, this paper proposes an expected surrogate loss that is then relaxed using a method related to recently introduced relaxations of discrete random variables. The authors note that this loss can also be seen as a specific variational bound of a Bayesian model over the weights. The key advantage of this method is that it gives a training time technique for sparsifying neural network computation, leading to potential wins in computation time during training. \n\nThe results presented in the paper are convincing. They achieve results competitive with previous methods, with the additional advantage that their sparse models are available during training time. They show order of magnitude reductions in computation time for small models, and more modest constant improvements for large models. The hard concrete distribution is a small but nice contribution on its own.\n\nMy only concern is the lack of discussion on the relationship between this method and Concrete Dropout (https://arxiv.org/abs/1705.07832). Although the focus is apparently different, these methods are clearly closely related. A discussion of this relationship seems really important.\n\nSpecific comments/questions:\n- The reduction of computation time is the key advantage, and it would have been nice to see a more thorough investigation of this. For example, it would have been interesting to see whether this method would work with structured L0 penalties that removed entire units (as opposed to single weights) or other subsets of the computation. This would give a stronger sense of the kind of wins that are possible in this framework.\n- Hard concrete is a nice contribution, but there are clearly many possibilities for these relaxations. Extra evaluations of different relaxations would be appreciated. At the very least a comparison to concrete would be nice.\n- In equation 2, the equality of the L0 norm with the sum of z assumes that tilde{theta} is not 0.']","[50, 60, 80]","[80, 80, 70]","[""The sentiment score is 50 (slightly positive) because the review begins with a balanced summary and lists both pros and cons. The reviewer acknowledges the paper's strengths, such as being well-written and addressing an important topic, but also points out areas for improvement. The overall tone is constructive rather than overly critical or enthusiastic. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits and framing criticisms as suggestions for improvement rather than harsh judgments. Phrases like 'It would be useful to know' and 'I felt a more thorough experimental section would have greatly improved the work' demonstrate a considerate approach to providing feedback."", ""The sentiment score is 60 (positive) because the review begins with a neutral summary of the paper's content, followed by a list of pros that highlight the paper's clarity and usefulness. The cons are presented as constructive suggestions rather than harsh criticisms. The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the paper as 'a pleasure to read' and offering suggestions for improvement in a considerate manner. The reviewer's comments are framed as opportunities for enhancement rather than criticisms, maintaining a professional and courteous tone."", ""The sentiment score is 80 (positive) because the reviewer describes the paper's contribution as 'convincing' and notes that the results are 'competitive with previous methods' with 'additional advantage'. The reviewer also mentions that the 'hard concrete distribution is a small but nice contribution'. The only negative point is a 'concern' about lack of discussion on a related method, which is presented as a suggestion rather than a major criticism. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions. The reviewer acknowledges the paper's strengths before mentioning areas for improvement, and phrases criticisms as 'concerns' or questions rather than direct attacks. The use of phrases like 'it would have been nice' and 'would be appreciated' further contribute to the polite tone.""]"
"[""This paper proposes a new method to train DNNs with quantized weights, by including the quantization as a constraint in a proximal quasi-Newton algorithm, which simultaneously learns a scaling for the quantized values (possibly different for positive and negative weights). \n\nThe paper is very clearly written, and the proposal is very well placed in the context of previous methods for the same purpose. The experiments are very clearly presented and solidly designed.\n\nIn fact, the paper is a somewhat simple extension of the method proposed by Hou, Yao, and Kwok (2017), which is where the novelty resides. Consequently, there is not a great degree of novelty in terms of the proposed method, and the results are only slightly better than those of previous methods.\n\nFinally, in terms of analysis of the algorithm, the authors simply invoke a theorem from Hou, Yao, and Kwok (2017), which claims convergence of the proposed algorithm. However, what is shown in that paper is that the sequence of loss function values converges, which does not imply that the sequence of weight estimates also converges, because of the presence of a non-convex constraint ($b_j^t \\in Q^{n_l}$). This may not be relevant for the practical results, but to be accurate, it can't be simply stated that the algorithm converges, without a more careful analysis."", 'In this paper, the authors propose a method of compressing network by means of weight ternarization. The network weights ternatization is formulated in the form of loss-aware quantization, which originally proposed by Hou et al. (2017).\n\nTo this reviewer’s understanding, the proposed method can be regarded as the extension of the previous work of LAB and TWN, which can be the main contribution of the work.\n\nWhile the proposed method achieved promising results compared to the competing methods, it is still necessary to compare their computational complexity, which is one of the main concerns in network compression.\n\nIt would be appreciated to have discussion on the results in Table 2, which tells that the performance of quantized networks is better than the full-precision network.\n', 'This paper extends the loss-aware weight binarization scheme to ternarization and arbitrary m-bit quantization and demonstrate its promising performance in the experiments.\n\nReview:\n\nPros\nThis paper formulates the weight quantization of deep networks as an optimization problem in the perspective of loss and solves the problem with a proximal newton algorithm.  They extend the scheme to allow the use of different scaling parameters and to m-bit quantization. Experiments demonstrate the proposed scheme outperforms the state-of-the-art methods. \n\nThe experiments are complete and the writing is good.\n\nCons\nAlthough the work seems convincing, it is a little bit straight-forward derived from the original binarization scheme (Hou et al., 2017) to tenarization or m-bit since there are some analogous extension ideas (Lin et al., 2016b, Li & Liu, 2016b). Algorithm 2 and section 3.2 and 3.3 can be seen as additive complementary. \n']","[50, 50, 50]","[80, 75, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's clear writing, solid experimental design, and good contextualization. However, they also note limited novelty and only slightly improved results. The politeness score is 80 (quite polite) due to the use of respectful language throughout, positive acknowledgments of the paper's strengths, and constructive criticism presented in a professional manner. The reviewer uses phrases like 'very clearly written,' 'very well placed,' and 'solidly designed,' which contribute to both the positive sentiment and polite tone. Even when pointing out limitations, the language remains respectful and objective."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contribution and promising results, but also points out areas for improvement. The review is not overwhelmingly positive or negative. The politeness score is 75 (quite polite) due to the use of respectful language throughout. The reviewer uses phrases like 'To this reviewer's understanding' and 'It would be appreciated,' which are courteous. The suggestions for improvement are framed constructively rather than critically."", ""The sentiment score is 50 (slightly positive) because the review begins with a list of pros, highlighting the paper's contributions and experimental results. However, it also includes some cons, noting that the work is somewhat straightforward and derived from previous schemes. This balanced approach suggests a moderately positive sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths ('experiments are complete', 'writing is good') and framing criticisms constructively ('Although the work seems convincing...'). The reviewer maintains a professional tone without using harsh or dismissive language, even when pointing out limitations.""]"
"['The paper analyzes the the effect of increasing the batch size in stochastic gradient descent as an alternative to reducing the learning rate, while keeping the number of training epochs constant. This has the advantage that the training process can be better parallelized, allowing for faster training if hundreds of GPUs are available for a short time. The theory part of the paper briefly reviews the relationship between learning rate, batch size, momentum coefficient, and the noise scale in stochastic gradient descent. In the experimental part, it is shown that the loss function and test accuracy depend only on the schedule of the decaying noise scale over training time, and are independent of whether this decaying noise schedule is achieved by a decaying learning rate or an increasing batch size. It is shown that simultaneously increasing the momentum parameter and the batch size also allows for fewer parameters, albeit at the price of some loss in performance.\n\nCOMMENTS:\n\nThe paper presents a simple observation that seems very relevant especially as computing resources are becoming increasingly available for rent on short time scales. The observation is explained well and substantiated by clear experimental evidence. The main issue I have is with the part about momentum. The paragraph below Eq. 7 provides a possible explanation for the performance drop when $m$ is increased. It is stated that at the beginning of the training, or after increasing the batch size, the magnitude of parameter updates is suppressed because $A$ has to accumulate gradient signals over a time scale $B/(N(1-m))$. The conclusion in the paper is that training at high momentum requires additional training epochs before $A$ reaches its equilibrium value. This effect is well known, but it can easily be remedied. For example, the update equations in Adam were specifically designed to correct for this effect. The mechanism is called ""bias-corrected moment estimate"" in the Adam paper, arXiv:1412.6980. The correction requires only two extra multiplications per model parameter and update step. Couldn\'t the same or a very similar trick be used to correctly rescale $A$ every time one increases the batch size? It would be great to see the equivalent of Figure 7 with correctly rescaled $A$.\n\nMinor issues:\n* The last paragraph of Section 5 refers to a figure 8, which appears to be missing.\n* In Eqs. 4 & 5, the momentum parameter $m$ is not yet defined (it will be defined in Eqs. 6 & 7 below).\n* It appears that a minus sign is missing in Eq. 7. The update steps describe gradient ascent.\n* Figure 3 suggests that most of the time between the first and second change of the noise scale (approx. epochs 60 to 120) are spent on overfitting. This suggests that the number of updates in this segment was chosen unnecessarily large to begin with. It is therefore not surprising that reducing the number of updates does not deteriorate the test set accuracy.\n* It would be interesting to see a version of figure 5 where the horizontal axis is the number of epochs. While reducing the number of updates allows for faster training if a large number of parallel hardware instances are available, the total cost of training is still governed by the number of training epochs.\n* It appears like the beginning of the second paragraph in Section 5.2 describes figure 1. Is this correct?', 'The paper represents an empirical validation of the well-known idea (it was published several times before) \nto increase the batch size over time. Inspired by recent works on large-batch studies, the paper suggests to adapt the learning rate as a function of the batch size.\n\nI am interested in the following experiment to see how useful it is to increase the batch size compared to fixed batch size settings. \n\n1) The total budget / number of training samples is fixed. \n2) Batch size is scheduled to change between B_min and B_max\n3) Different setting of B_min and B_max>=B_min are considered, e.g., among [64, 128, 256, 512, ...] or [64, 256, 1024, ...] if it is too expensive.\n4) Drops of the learning rates are scheduled to happen at certain times represented in terms of the number of training samples passed so far (not parameter updates).\n5) Learning rates and their drops should be rescaled taking into account the schedule of the batch size and the rules to adapt learning rates in large-scale settings as by Goyal. ', '## Review Summary\n\nOverall, the paper\'s paper core claim, that increasing batch sizes at a linear\nrate during training is as effective as decaying learning rates, is\ninteresting but doesn\'t seem to be too surprising given other recent work in\nthis space. The most useful part of the paper is the empirical evidence to\nbackup this claim, which I can\'t easily find in previous literature. I wish\nthe paper had explored a wider variety of dataset tasks and models to better\nshow how well this claim generalizes, better situated the practical benefits\nof the approach (how much wallclock time is actually saved? how well can it be\nintegrated into a distributed workflow?), and included some comparisons with\nother recent recommended ways to increase batch size over time.\n\n\n## Pros / Strengths\n\n+ effort to assess momentum / Adam / other modern methods\n\n+ effort to compare to previous experimental setups\n\n\n## Cons / Limitations\n\n- lack of wallclock measurements in experiments\n\n- only ~2 models / datasets examined, so difficult to assess generalization\n\n- lack of discussion about distributed/asynchronous SGD\n\n\n## Significance\n\nMany recent previous efforts have looked at the importance of batch sizes\nduring training, so topic is relevant to the community. Smith and Le (2017)\npresent a differential equation model for the scale of gradients in SGD,\nfinding a linear scaling rule proportional to eps N/B, where eps = learning\nrate, N = training set size, and B = batch size. Goyal et al (2017) show how\nto train deep models on ImageNet effectively with large (but fixed) batch\nsizes by using a linear scaling rule.\n\nA few recent works have directly tested increasing batch sizes during\ntraining. De et al (AISTATS 2017) have a method for gradually increasing batch\nsizes, as do Friedlander and Schmidt (2012). Thus, it is already reasonable to\npractitioners that the proposed linear scaling of batch sizes during training\nwould be effective.\n\nWhile increasing batch size at the proposed linear scale is simple and seems\nto be effective, a careful reader will be curious how much more could be\ngained from the backtracking line search method proposed in De et al.\n\n\n## Quality\n\nOverall, only single training runs from a random initialization are used. It\nwould be better to take the best of many runs or to somehow show error bars,\nto avoid the reader wondering whether gains are due to changes in algorithm or\nto poor exploration due to bad initialization. This happens a lot in Sec. 5.2.\n\nSome of the experimental setting seem a bit haphazard and not very systematic.\nIn Sec. 5.2, only two learning rate scales are tested (0.1 and 0.5). Why not\nexamine a more thorough range of values?\n\nWhy not report actual wallclock times? Of course having reduced number of\nparameter updates is useful, but it\'s difficult to tell how big of a win this\ncould be.\n\nWhat about distributed SGD or asyncronous SGD (hogwild)? Small batch sizes\nsometimes make it easier for many machines to be working simultaneously. If we\nscale up to batch sizes of ~ N/10, we can only get 10x speedups in\nparallelization (in terms of number of parameter updates). I think there is\nsome subtle but important discussion needed on how this framework fits into\nmodern distributed systems for SGD.\n\n\n## Clarity\n\nOverall the paper reads reasonably well.\n\nOffering a related work ""feature matrix"" that helps readers keep track of how\nprevious efforts scale learning rates or minibatch sizes for specific\nexperiments could be valueable. Right now, lots of this information is just\nprovided in text, so it\'s not easy to make head-to-head comparisons.\n\nSeveral figure captions should be updated to clarify which model and dataset\nare studied. For example, when skimming Fig. 3\'s caption there is no such\ninformation.\n\n## Paper Summary\n\nThe paper examines the influence of batch size on the behavior of stochastic\ngradient descent to minimize cost functions. The central thesis is that\ninstead of the ""conventional wisdom"" to fix the batch size during training and\ndecay the learning rate, it is equally effective (in terms of training/test\nerror reached) to gradually increase batch size during training while fixing\nthe learning rate. These two strategies are thus ""equivalent"". Furthermore,\nusing larger batches means fewer parameter updates per epoch, so training is\npotentially much faster.\n\nSection 2 motivates the suggested linear scaling using previous SGD analysis\nfrom Smith and Le (2017). Section 3 makes connections to previous work on\nfinding optimal batch sizes to close the generaization gap. Section 4 extends\nanalysis to include SGD methods with momentum.\n\nIn Section 5.1, experiments training a 16-4 ResNet on CIFAR-10 compare three\npossible SGD schedules: * increasing batch size * decaying learning rate *\nhybrid (increasing batch size and decaying learning rate) Fig. 2, 3 and 4 show\nthat across a range of SGD variants (+/- momentum, etc) these three schedules\nhave similar error vs. epoch curves. This is the core claimed contribution:\nempirical evidence that these strategies are ""equivalent"".\n\nIn Section 5.3, experiments look at Inception-ResNet-V2 on ImageNet, showing\nthe proposed approach can reach comparable accuracies to previous work at even\nfewer parameter updates (2500 here, vs. ∼14000 for Goyal et al 2007)\n']","[60, 20, 20]","[80, 50, 60]","[""The sentiment score is 60 (positive) because the reviewer starts by praising the paper as presenting a 'simple observation that seems very relevant' and states that it is 'explained well and substantiated by clear experimental evidence.' The reviewer does have some issues with the paper, particularly regarding the momentum part, but these are presented as constructive criticism rather than major flaws. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms as suggestions or questions (e.g., 'Couldn't the same or a very similar trick be used...'). The reviewer also acknowledges the paper's strengths before diving into areas for improvement. The use of phrases like 'It would be great to see...' and 'It would be interesting to see...' further contribute to the polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper as an empirical validation of a known idea and shows interest in further experiments. However, they don't express strong enthusiasm or praise for the work. The politeness score is moderately positive (50) as the reviewer maintains a professional and neutral tone throughout, without using any harsh or overly critical language. They express their interest and provide suggestions in a constructive manner, which contributes to the polite tone. The reviewer doesn't use explicitly polite phrases, but the overall tone is respectful and collegial."", ""The sentiment score is slightly positive (20) because while the reviewer finds the paper's core claim interesting and acknowledges its empirical evidence, they also express several limitations and areas for improvement. The reviewer states the paper is 'interesting but doesn't seem to be too surprising' and notes both pros and cons. The politeness score is moderately high (60) as the reviewer uses professional and respectful language throughout, offering constructive criticism without harsh or rude phrasing. They acknowledge the paper's strengths and frame limitations as suggestions for improvement rather than outright criticisms. The reviewer maintains an objective tone, balancing positive and negative aspects, which contributes to both the slightly positive sentiment and the polite tone.""]"
"['The paper proposes a new algorithm, where they claim to use Hessian implicitly and are using a motivation from power-series. In general, I like the paper.\n\nTo me, Algorithm 1 looks like some kind of proximal-point type algorithm. Algorithm 2 is more heuristic approach, with a couple of parameters to tune it.  Given the fact that there is convergence analysis or similar theoretical results, I would expect to have much more numerical experiments. E.g. there is no results of Algorithm 1. I know it serves as a motivation, but it would be nice to see how it works.\n\nOtherwise, the paper is clearly written.\nThe topic is important, but I am a bit afraid of significance. One thing what I do not understand is, that why they did not compare with Adam? (they mention Adam algorithm soo many times, that it should be compared to).\n\nI am also not sure, how sensitive the results are for different datasets? Algorithm 2 really needs so many parameters (not just learning rate). How \\alpha, \\beta, \\gamma, \\mu, \\eta, K influence the speed? how sensitive is the algorithm for different choices of those parameters?\n\n\n ', 'Summary: \nThe paper proposes Neumman optimizer, which makes some adjustments to the idealized Neumman algorithm to improve performance and stability in training. The paper also provides the effectiveness of the algorithm by training ImageNet models (Inception-V3, Resnet-50, Resnet-101, and Inception-Resnet-V2). \n \nComments:\nI really appreciate the author(s) by providing experiments using real models on the ImageNet dataset. The algorithm seems to be easily used in practice. \n\nI do not have many comments for this paper since it focuses only in practical view without theory guarantee rigorously. \n\nAs you mention in the paper that the algorithm uses the same amount of computation and memory as Adam optimizer, but could you please provide the reason why you only compare Neumann Optimizer with Baseline RMSProp but not with Adam? As we know, Adam is currently very well-known algorithm to train DNN. Do you think it would be interesting if you could compare the efficiency of Neumann optimizer with Adam? I understand that you are trying to improve the existing results with their optimizer, but this paper also introduces new algorithm.  \n\nThe question is that, with the given architectures and dataset, what algorithm should people consider to use between Neumann optimizer and Adam? Why should people use Neumann optimizer but not Adam, which is already very well-known? If Neumann optimizer can surpass Adam on ImageNet, I think your algorithm will be widely used after being published.  \n \nMinor comments:\nPage 3, in eq. (3): missing “-“ sign\nPage 3, in eq. (6): missing “transpose” on \\nabla \\hat{f}\nPage 4, first equation: O(|| \\eta*mu_t ||^2)\nPage 5, in eq. (9): m_{k-1}\n', ' \nThis paper presents a new 2nd-order algorithm that implicitly uses curvature information, and it shows the intuition behind the approximation schemes in the algorithms and also validates the heuristics in various experiments.  The method involves using Neumann Series and Richardson iteration to avoid Hessian-vector product in second order method for NN.  In the actual performance, the paper presents both practical efficiency and better generalization error in different deep neural networks for image classification tasks, and the authors also show differences according to different settings, e.g., Batch Size, Regularization.  The numerical examples are relatively clear and easy to figure out details.\n\n1. While the paper presents the algorithm as an optimization algorithm, although it gets better learning performance, it would be interesting to see how well it is as an optimizer.  For example, one simple experiment would be showing how it works for convex problems, e.g., logistic regression.  Realistic DNN systems are very complex, and evaluating the method in a simple setting would help a lot in determining what if anything is novel about the method.\n\n2. Also, for deep learning problems, it would be more convincing to see how different initialization can affect the performances. \n\n3. Although the authors present their algorithm as a second order method at beginning, the final algorithm is kind of like a complex momentum SGD with limited memory.  Rather than simply throwing out a new method with a new name, it would be helpful to understand what the steps of this method are implicitly doing.  Please explain more about this.\n\n4. It said that the algorithm is hyperparameter free except for learning rate.  However, it is hard to see why there is no need to tune other hyperparameters, e.g., Cubic Regularizer, Repulsive Regularizer.  The effect/sensitivity of hyperparameters for second order methods are quite different than hyperparameters for first order methods, and it is of interest to know how hyperparameters for implicit second order methods perform.\n\n5. For Section 4.2, the well know benefit by using large batch size to train models is that it could reduce training time and epochs.  However, from Table 3, there is no such phenomenon.  Please explain.\n\n']","[50, 50, 50]","[75, 80, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by saying 'In general, I like the paper' and mentions that it is 'clearly written'. However, they also express concerns about the lack of numerical experiments and comparisons with Adam, which balances out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'it would be nice to see' and 'I am a bit afraid of' which soften their criticisms. The reviewer also acknowledges the importance of the topic and provides specific questions for improvement, showing engagement with the paper's content in a professional manner."", ""The sentiment score is 50 (slightly positive) because the reviewer starts with appreciation for the authors' work, particularly the practical experiments. They mention not having many comments, which could be seen as positive. However, they also raise questions about comparisons with Adam optimizer, suggesting some reservations. The politeness score is 80 (quite polite) due to the respectful tone throughout. The reviewer uses phrases like 'I really appreciate' and 'could you please', maintaining a courteous and constructive approach. They frame their suggestions as questions rather than demands, and acknowledge the authors' efforts. The minor comments are presented neutrally without criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and the clarity of its numerical examples, while also providing constructive criticism and suggestions for improvement. The overall tone is balanced, recognizing both strengths and areas for further development. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, framing suggestions as recommendations rather than demands. Phrases like 'it would be interesting to see' and 'it would be helpful to understand' indicate a courteous approach to feedback. The reviewer also acknowledges the authors' work positively before offering critiques, which contributes to the polite tone.""]"
"['The paper proposes training ``inference networks,\'\' which are neural network structured predictors. The setup is analogous to generative adversarial networks, where the role of the discriminator is played by a structured prediction energy network (SPEN) and the generator is played by an inference network.\n\nThe idea is interesting. It could be viewed as a type of adversarial training for large-margin structured predictors, where counterexamples, i.e., structures with high loss and low energy, cannot be found by direct optimization. However, it remains unclear why SPENs are the right choice for an energy function.\n\nExperiments suggest that it can result in better structured predictors than training models directly via backpropagation gradient descent. However, the experimental results are not clearly presented. The clarity is poor enough that the paper might not be ready for publication.\n\nComments and questions:\n\n1) It is unclear whether this paper is motivated by training SPENs or by training structured predictors. The setup focuses on using SPENs as an inference network, but this seems inessential. Experiments with simpler energy functions seem to be absent, though the experiments are unclear (see below).\n\n2) The confusion over the motivation is confounded by the fact that the experiments are very unclear. Sometimes predictions are described as the output of SPENs (Tables 2, 3, 4, and 7), sometimes as inference networks (Table 5), and sometimes as a CRF (Tables 4 and 6). In 7.2.2 it says that a BiLSTM is used for the inference network in Twitter POS tagging, but Tables 4 and 6 indicate both CRFs and BiLSTMS? It is also unclear when a model, e.g., BiLSTM or CRF is the energy function (discriminator) or inference network (generator).\n\n3) The third and fourth columns of Table 5 are identical. The presentation should be made consistent, either with dev/test or -retuning/+retuning as the top level headers.\n\n4) It is also unclear how to compare Tables 4 and 5. The second to bottom row of Table 5 seems to correspond with the first row of Table 5, but other methods like slack rescaling have higher performance. What is the takeaway from these two tables supposed to be?\n\n5) Part of the motivation for the work is said to be the increasing interest in inference networks: ""In these and related settings, gradient descent has started to be replaced by inference networks. Our results below provide more evidence for making this transition."" However, no other work on inference networks is directly cited.', ""This paper proposes an improvement in the speed of training/inference with structured prediction energy networks (SPENs) by replacing the inner optimization loop with a network trained to predict its outputs.\n\nSPENs are an energy-based structured prediction method, where the final prediction is obtained by optimizing min_y E_theta(f_phi(x), y), i.e., finding the label set y with the least energy, as computed by the energy function E(), using a set of computed features f_phi(x) which comes from a neural network. The key innovation in SPENs was representing the energy function E() as an arbitrary neural network which takes the features f(x) and candidate labels y and outputs a value for the energy. At inference time y can be optimized by gradient descent steps. SPENs are trained using maximum-margin loss functions, so the final optimization problem is max -loss(y, y') where y' = argmin_y E(f(x), y).\n\nThe key idea of this paper is to replace the minimization of the energy function min_y E(f(x), y) with a neural network which is trained to predict the resulting output of this minimization. The resulting formulation is a min-max problem at training time with a striking similarity to the GAN min-max problem, where the y-predicting network learns to predict labels with low energy (according to the E-computing network) and high loss while the energy network learns to assign a high energy to predicted labels which have a higher loss than true labels (i.e. the y-predicting network acts as a generator and the E-predicting network acts as a discriminator).\n\nThe paper explores multiple loss functions and techniques to train these models. They seem rather finnicky, and the experimental results aren't particularly strong when it comes to improving the quality over SPENs but they have essentially the same test-time complexity as simple feedforward models while having accuracy comparable to full inference-requiring energy-based models. The improved understanding of SPENs and potential for further work justify accepting this paper."", '= Quality = \nOverall, the authors do a good job of placing their work in the context of related research, and employ a variety of non-trivial technical details to get their methods to work well. \n\n= Clarity = \n\nOverall, the exposition regarding the method is good. I found the setup for the sequence tagging experiments confusing, tough. See more comments below.\n\n= Originality / Significance = \n\nThe paper presents a clever idea that could help make SPENs more practical. The paper\'s results also suggest that we should be thinking more broadly about how to using complicated structured distributions as teachers for model compression.\n\n= Major Comment =\n\nI\'m concerned by the quality of your results and the overall setup of your experiments. In particular, the principal contribution of the sequence tagging experiments seems top be different than what is advertised earlier on in the paper. \n\nMost of your empirical success is obtained by taking a pretrained CRF energy function and using this as a teacher model to train a feed-forward inference network. You have have very few experiments using a SPEN energy function parametrization that doesn\'t correspond to a CRF, even though you could have used an arbitrary convnet, RNN, etc. The one exception is when you use the tag language model. This is a good idea, but it is pretrained, not trained using the saddle-point objective you introduce. In fact, you don\'t have any results demonstrating that the saddle-point approach is better than simpler alternatives.\n\nIt seems that you could have written a very different paper about model compression with CRFs that would have been very interesting and you could\'ve have used many of the same experiments. It\'s unclear why SPENs are so important. The idea of amortizing inference is perhaps more general. My recommendation is that you either rebrand the paper to be more about general methods for amortizing structured prediction inference using model compression or do more fine-grained experiments with SPENs that demonstrate empirical gains that leverage their flexible deep-network-based energy functions.\n\n\n= Minor Comments = \n\n* You should mention \'Energy Based GANs""\n\n* I don\'t understand ""This approach performs backpropagation through each step of gradient descent, permitting more stable training but also evidently more overfitting."" Why would it overfit more? Simply because training was more stable? Couldn\'t you prevent overfitting by regularizing more?\n\n* You spend too much space talking about specific hyperparameter ranges, etc. This should be moved to the appendix. You should also add a short summary of the TLM architecture to the main paper body.\n\n* Regarding your footnote discussing using a positive vs. negative sign on the entropy regularization term, I recommend checking out ""Regularizing neural networks by penalizing confident output distributions.""\n\n* You should add citations for the statement ""In these and related settings, gradient descent has started to be replaced by inference networks.""\n\n* I didn\'t find Table 1 particularly illuminating. All of the approaches seem to perform about the same. What conclusions should I make from it?\n\n* Why not use KL divergence as your \\Delta function?\n\n* Why are the results in Table 5 on the dev data?\n\n* I was confused by Table 4. First of all, it took me a very long time to figure out that the middle block of results corresponds to taking a pretrained CRF energy and amortizing inference by training an inference network. This idea of training with a standard loss (conditional log lik.) and then amortizing inference post-hoc was not explicitly introduced as an alternative to the saddle point objective you put forth earlier in the paper. Second, I was very surprised that the inference network outperformed Viterbi (89.7 vs. 89.1 for the same CRF energy). Why is this?\n\n* I\'m confused by the difference between Table 6 and Table 4? Why not just include the TLM results in Table 4?\n\n\n\n\n\n\n']","[-30, 60, -20]","[20, 50, 50]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the idea as 'interesting', they express several concerns about the clarity of the paper and its experimental results. The reviewer states that 'the paper might not be ready for publication' due to poor clarity, which significantly contributes to the negative sentiment. However, it's not entirely negative as the reviewer sees potential in the idea.\n\nThe politeness score is slightly positive (20) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'It could be viewed as...' and 'It is unclear whether...' which are polite ways of expressing criticism. The reviewer also provides specific, detailed feedback which is helpful to the authors. However, the politeness is not extremely high as the criticism is quite direct in places, particularly when stating the paper might not be ready for publication."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's contribution to improving the speed of training/inference with SPENs and states that the 'improved understanding of SPENs and potential for further work justify accepting this paper.' However, it's not overwhelmingly positive as the reviewer notes that 'experimental results aren't particularly strong.' The politeness score is 50 (slightly polite) because the reviewer uses neutral, professional language throughout and doesn't use any harsh criticism. They present both strengths and limitations of the paper in a balanced manner, which is respectful to the authors. The reviewer also uses phrases like 'key idea' and 'key innovation' which show appreciation for the authors' work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('good job', 'clever idea'), they express significant concerns about the quality of results and experimental setup. The reviewer recommends major changes, suggesting the paper may need to be rebranded or include more experiments. This indicates an overall negative sentiment, though not extremely so. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive criticism, and frames concerns as recommendations rather than harsh criticisms. They use phrases like 'I'm concerned' and 'My recommendation is' rather than more confrontational language. The review maintains a professional tone while clearly communicating areas for improvement.""]"
"['This paper studies the problem of learning a single convolutional filter using SGD. The main result is: if the ""patches"" of the convolution are sufficiently aligned with each other, then SGD with a random initialization can recover the ground-truth parameter of a convolutional filter (single filter, ReLU, average pooling). The convergence rate, and how ""sufficiently aligned"" depend on some quantities related to the underlying data distribution. A major strength of the result is that it can work for general continuous distributions and does not really rely on the input distribution being Gaussian; the main weakness is that some of the distribution dependent quantities are not very intuitive, and the alignment requirement might be very high.\n\nDetailed comments:\n1. It would be good to clarify what the angle requirement means on page 2. It says the angle between Z_i, Z_j is at most \\rho, is this for any i,j? From the later part it seems that each Z_i should be \\rho close to the average, which would imply pairwise closeness (with some constant factor).\n2. The paper first proves result for a single neuron, which is a clean result. It would be interesting to see what are values of \\gamma(\\phi) and L(\\phi) for some distributions (e.g. Gaussian, uniform in hypercube, etc.) to give more intuitions. \n3. The convergence rate depends on \\gamma(\\phi_0), from the initialization, \\phi_0 is probably very close to \\pi/2 (the closeness depend on dimension), which is  also likely to make \\gamma(\\phi_0) depend on dimension (this is especially true of Gaussian). \n4. More precisely, \\gamma(\\phi_0) needs to be at least 6L_{cross} for the result to work, and L_{cross} seems to be a problem dependent constant that is not related to the dimension of the data. Also \\gamma(\\phi_0) depends on \\gamma_{avg}(\\phi_0) and \\rho, when \\rho is reasonable (say a constant), \\gamma(\\phi_0) really needs to be a constant that is independent of dimension. On the other hand, in Theorem 3.4 we can see that the upperbound on \\alpha (the quality of initialization) depends on the dimension. \n5. Even assuming \\rho is a constant strictly smaller than \\pi/2 seems a bit strong. It is certainly plausible that nearby patches are highly correlated, but what is required here is that all patches are close to the average. Given an image it is probably not too hard to find an almost all white patch and an almost all dark patch so that they cannot both be within a good angle to the average. \n\nOverall I feel the result is interesting but hard to interpret correctly. The details of the theorem do not really support the high level claims very strongly. The paper would be much better if it goes over several example distributions and show explicitly what are the guarantees. The reviewer tried to do that for Gaussian and as I mentioned above (esp. 4) the result does not seem very impressive, maybe there are other distributions where this result works better?\n\nAfter reading the response, I feel the contribution for the single neuron case does not require too much assumptions and is itself a reasonable result. I am still not convinced by the convolution case (which is the main point of this paper), as even though it does not require Gaussian input (a major plus), it still seems very far from ""general distribution"". Overall this is a first step in an interesting direction, so even though it is currently a bit weak I think it is OK to be accepted. I hope the revised version will clearly discuss the limitations of the approach and potential future directions as the response did.', 'This paper considers the convergence of (stochastic) gradient descent for learning a convolutional filter with ReLU activations. It doesn\'t assume the input is Gaussian as in most previous work and shows that starting from random initialization, the (stochastic) gradient descent can learn the underlying convolutional filter in polynomial time. It is also shown that the convergence rate depends on the smoothness of the input distribution and the closeness of the patches. \n\nThe main contribution and the most intriguing part is that the result doesn\'t require assuming the input is Gaussian. Also, the guarantee holds for random initialization. The analysis that achieves these results can potentially provide better techniques for analyzing more general deep learning optimizations. \n\nThe main drawback is that the assumptions are somewhat difficult to interpret, though significantly more general than those made in previous work. It will be great if more explanations/comments are provided for these assumptions. It will be even better if one can get a simplified set of assumptions. \n\nThe presentation is clear but can be improved. Especially, more remarks would help readers to understand the paper. \n\nminor:\n-- Thm 2.1: what are w_1 w_2 here? \n-- Assumption 3.1: the statement seems incomplete. I guess it should be ""max_... \\lambda_max(...) \\geq \\beta for some beta > 0""?\n-- Just before Section 2.1: "" This is also consistent with empirical evidence in which more data are helpful for optimization."" \nI don\'t see any evidence that more data help the optimization by filling in the holds in the distribution; they may help for other reasons. This statement here is not rigorous. \n', '(a) Significance\nThis is an interesting theoretical deep learning paper, where the authors try to provide the theoretical insights why SGD can learn the neural network well. The motivation is well-justified and clearly presented in the introduction and related work section. And the major contribution of this work is the generalization to the non-Gaussian case, which is more in line with the real world settings. Indeed, this is the first work analyzing the input distribution beyond Gaussian, which might be an important work towards understanding the empirical success of deep learning. \n\n(b) Originality\nThe division of the input space and the analytical formulation of the gradient are interesting, which are also essential for the convergence analysis. Also, the analysis framework relies on novel but reasonable distribution assumptions, and is different from the relevant literature, i.e., Li & Yuan 2017, Soltanolkotabi 2017, Zhong et al. 2017. I curious whether the angular smoothness assumptions can be applied to a more general network architecture, say two-layer neural network.\n\n(c) Clarity & Quality \nOverall, this is a well-written paper. The theoretical results are well-presented and followed by insightful explanations or remarks. And the experiments are demonstrated to justify the theoretical findings as well. The authors did a really good job in explaining the intuitions behind the imposed assumptions and justifying them based on the theoretical and experimental results. I think the quality of this work is above the acceptance bar of ICLR and it should be published in ICLR 2018.\n\nMinor comments: \n1. Figure 3 looks a little small. It is better to make them clearer.\n2. In the appendix, ZZ^{\\top} and the indicator function are missing in the first equation of page 13.\n']","[20, 60, 90]","[60, 70, 80]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's strengths and finds the result interesting, they also point out several weaknesses and areas for improvement. The overall tone suggests a cautious acceptance rather than strong enthusiasm or rejection. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and balances positive and negative feedback. They use phrases like 'It would be good to clarify' and 'The paper would be much better if' which are polite ways of suggesting improvements. The reviewer also acknowledges the authors' response and shows willingness to accept the paper despite reservations, which is a polite gesture."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's main contribution as 'intriguing' and potentially useful for analyzing deep learning optimizations. They praise the paper for not requiring Gaussian input assumptions and for providing guarantees for random initialization. However, they also point out some drawbacks, such as difficult-to-interpret assumptions, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'It will be great if...' and 'It will be even better if...', which are polite ways of suggesting changes. The reviewer also balances positive feedback with areas for improvement, maintaining a professional and courteous tone. The minor points are presented as questions or observations rather than harsh criticisms."", ""The sentiment score is 90 because the reviewer expresses a very positive view of the paper, describing it as 'interesting', 'well-justified', and 'clearly presented'. They state that it's 'above the acceptance bar' and 'should be published'. The only slight hesitation is a curiosity about broader applicability, but this doesn't detract significantly from the overall positive sentiment. The politeness score is 80 because the reviewer uses respectful and encouraging language throughout, praising the authors' work ('did a really good job', 'well-written'). The minor comments are presented constructively. The tone is professional and courteous, though not excessively formal or deferential, hence not a perfect 100.""]"
"[""This paper presents a domain adaptation algorithm based on the self-ensembling method proposed by [Tarvainen & Valpola, 2017]. The main idea is to enforce the agreement between the predictions of the teacher and the student classifiers on the target domain samples while training the student to perform well on the source domain. The teacher network is simply an exponential moving average of different versions of the student network over time.   \n\nPros:\n+ The paper is well-written and easy to read\n+ The proposed method is a natural extension of the mean teacher semi-supervised learning model by [Tarvainen & Valpola, 2017]\n+ The model achieves state-of-the-art results on a range of visual domain adaptation benchmarks (including top performance in the VisDA17 challenge)\n\nCons:\n- The model is tailored to the image domain as it makes heavy use of the data augmentation. That restricts its applicability quite significantly. I’m also very interested to know how the proposed method works when no augmentation is employed (for fair comparison with some of the entries in Table 1).\n- I’m not particularly fond of the engineering tricks like confidence thresholding and the class balance loss. They seem to be essential for good performance and thus, in my opinion, reduce the value of the main idea.\n- Related to the previous point, the final VisDA17 model seems to be engineered too heavily to work well on a particular dataset. I’m not sure if it provides many interesting insights for the scientific community at large.\n\nIn my opinion, it’s a borderline paper. While the best reported quantitative results are quite good, it seems that achieving those requires a significant engineering effort beyond just applying the self-ensembling idea. \n\nNotes:\n* The paper somewhat breaks the anonymity of the authors by mentioning the “winning entry in the VISDA-2017”. Maybe it’s not a big issue but in my opinion it’s better to remove references to the competition entry.\n* Page 2, 2.1, line 2, typo: “stanrdard” -> “standard”\n\nPost-rebuttal revision:\nAfter reading the authors' response to my review, I decided to increase the score by 2 points. I appreciate the improvements that were made to the paper but still feel that this work a bit too engineering-heavy, and the title does not fully reflect what's going on in the full pipeline."", ""The paper was very well-written, and mostly clear, making it easy to follow. The originality of the main method was not immediately apparent to me. However, the authors clearly outline the tricks they had to do to achieve good performance on multiple domain adaptation tasks: confidence thresholding, particular data augmentation, and a loss to deal with imbalanced target datasets, all of which seem like good tricks-of-the-trade for future work. The experimentation was extensive and convincing.\n\nPros:\n* Winning entry to the VISDA 2017 visual domain adaptation challenge competition.\n* Extensive experimentation on established toy datasets (USPS<>MNIST, SVHN<>MNIST, SVHN, GTSRB) and other more real-world datasets (including the VISDA one)\n\nCons:\n* Literature review on domain adaptation was lacking. Recent CVPR papers on transforming samples from source to target should be referred to, one of them was by Shrivastava et al., Learning from Simulated and Unsupervised Images through Adversarial Training, and another by Bousmalis et al., Unsupervised Pixel-level Domain Adaptation with GANs. Also you might want to mention Domain Separation Networks which uses gradient reversal (Ganin et al.) and autoencoders (Ghifary et al.). There was no mention of MMD-based methods, on which there are a few papers. The authors might want to mention non-Deep Learning methods also, or that this review relates to neural networks,\n* On p. 4 it wasn't clear to me how the semi-supervised tasks by Tarvainen and Laine were different to domain adaptation. Did you want to say that the data distributions are different? How does this make the task different. Having source and target come in different minibatches is purely an implementation decision.\n* It was unclear to me what  footnote a. on p. 6 means. Why would you combine results from Ganin et al. and Ghifary et al. ?\n* To preserve anonymity keep acknowledgements out of blind submissions. (although not a big deal with your acknowledgements)"", ""The paper addresses the problem of domain adaptation: Say you have a source dataset S of labeled examples and you have a target dataset T of unlabeled examples and you want to label examples from the target dataset. \n\nThe main idea in the paper is to train two parallel networks, a 'teacher network' and a 'student network', where the student network has a loss term that takes into account labeled examples and there is an additional loss term coming from the teacher network that compares the probabilities placed by the two networks on the outputs. This is motivated by a similar network introduced in the context of semi-supervised learning by Tarvainen and Valpola (2017). The parameters are then optimized by gradient descent where the weight of the loss-term associated with the unsupervised learning part follows a Gaussian curve (with time). No clear explanation is provided for why this may be a good thing to try. The authors also use other techniques like data augmentation to enhance their algorithms.\n\nThe experimental results in the paper are quite nice. They apply the methodology to various standard vision datasets with noticeable improvements/gains and in one case by including additional tricks manage to better than other methods for VISDA-2017 domain adaptation challenge. In the latter, the challenge is to use computer-generated labeled examples and use this information to label real photographic images. The present paper does substantially better than the competition for this challenge. ""]","[-20, 70, 60]","[60, 80, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they express significant concerns ('Cons') and describe it as a 'borderline paper'. The final statement about increasing the score but still feeling it's 'too engineering-heavy' indicates a somewhat negative overall sentiment. The politeness score is moderately positive (60) because the reviewer uses professional and respectful language throughout, acknowledging both strengths and weaknesses without harsh criticism. They offer constructive feedback and even note improvements after the rebuttal, showing a willingness to reconsider their initial assessment."", ""The sentiment score is 70 (positive) because the reviewer starts with praise for the paper being 'very well-written' and 'mostly clear'. They highlight the extensive experimentation and the paper's status as a winning entry in a challenge. While some cons are mentioned, they are presented as suggestions for improvement rather than major flaws. The politeness score is 80 (quite polite) due to the reviewer's constructive tone throughout. They begin with positive comments and frame criticisms as suggestions or areas for improvement. The language used is professional and respectful, avoiding harsh or dismissive phrasing. Even when pointing out issues like the lacking literature review, the reviewer offers specific recommendations for improvement rather than just criticism."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's 'quite nice' experimental results, noting 'noticeable improvements/gains' and that it does 'substantially better than the competition' in one challenge. However, it's not extremely positive as the reviewer points out some unexplained aspects. The politeness score is 50 (slightly polite) because the language is professional and respectful, without harsh criticisms. The reviewer uses phrases like 'The main idea in the paper is...' and 'The experimental results in the paper are quite nice,' which are neutral to positive in tone. There are no rude or overly critical comments, but also no exceptionally polite phrases, resulting in a moderately positive politeness score.""]"
"['Update:\n\nI have read the rebuttal and the revised manuscript. Paper reads better and comparison to Auto-regression was added. This work presents a novel way of utilizing GCN and I believe it would be interesting to the community. In this regard, I have updated my rating.\n\nOn the downside, I still remain uncertain about the practical impact of this work. Results in Table 1 show that proposed method is capable of forecasting next hour temperature with about 0.45C mean absolute error. As no reference to any state of the art temperature forecasting method is given (i.e. what is the MAE of a weather app on a modern smartphone), I can not judge whether 0.45C is good or bad. Additionally, it would be interesting to see how well proposed method can deal with next day temperature forecasting.\n\n---------------------------------------------\nIn this paper authors develop a notion of data quality as the function of local variation of the graph nodes. The concept of local variation only utilizes the signals of the neighboring vertices and GCN is used to take into account broader neighborhoods of the nodes. Data quality then used to weight the loss terms for training of the LSTM network to forecast temperatures at weather stations.\n\nI liked the idea of using local variations of the graph signals as quality of the signal. It was new to me, but I am not very familiar with some of the related literature. I have one methodological and few experimental questions.\n\nMethodology:\nWhy did you decide to use GCN to capture the higher order neighborhoods? GCN does so intuitively, but it is not clear what exactly is happening due to non-linearities. What if you use graph polynomial filter instead [1] (i.e. linear combination of powers of the adjacency)? It can more evidently capture the K-hop neighborhood of a vertex.\n\nExperiments:\n- Could you please formalize the forecasting problem more rigorously. It is not easy to follow what information is used for training and testing. I\'m not quite certain what ""Temperature is used as a target measurement, i.e., output of LSTM, and others including Temperature are used as input signals."" means. I would expect that forecasting of temperature tomorrow is solely performed based on today\'s and past information about temperature and other measurements.\n- What are the measurement units in Table 1?\n- I would like to see comparison to some classical time series forecasting techniques, e.g. Gaussian Process regression and Auto-regressive models. Also some references and comparisons are needed to state-of-the-art weather forecasting techniques. These comparisons are crucial to see if the method is indeed practical.\n\nPlease consider proofreading the draft. There are occasional typos and excessively long wordings.\n\n[1] Aliaksei Sandryhaila and José MF Moura. Discrete signal processing on graphs. IEEE transactions\non signal processing, 61(7):1644–1656, 2013.', ""The paper is an application of neural nets to data quality assessment. The authors introduce a new definition of data quality that relies on the notion of local variation defined in (Zhou and Schölkopf, 2004), and they extend it to multiple heterogenous data sources. The data quality function is learned using a GCN as defined in (Kipf and Welling, 2016).\n \n1) How many neighbors are used in the experiments? Is this fixed or is defined purely by the Gaussian kernel weights as mentioned in 4.2? Setting all weights less than 0.9 to zero seems quite abrupt. Could you provide a reason for this? How many neighbors fit in this range?\n2) How many data points? What is the temporal resolution of your data (every day/hour/minute/etc.)? What is the value of N, T? \n3) The bandwidth of the Gaussian kernel (\\gamma) is quite different (0.2 and 0.6) for the two datasets from Weather Underground (WU) and Weather Bug (WB) (sect. 4.2). The kernel is computed on the features (e.g., latitude, longitude, vegetation fraction, etc.). Location, longitude, distance from coast, etc. are the same no matter the data source (WU or WB). Maybe the way they compute other features (e.g., vegetation fraction) vary slightly, but I would guess the \\gamma should be (roughly) the same. \n4) Are the features (e.g., latitude, longitude, vegetation fraction, etc.) normalized in the kernel? If they are given equal weight (which is in itself questionable) they should be normalized, otherwise some of them will always dominate the distances. If they were indeed normalized, that should be made clear in the paper.\n5) Why do you choose the summer months? How does the framework perform on other months and other meteorological signals except temperature? The application is very nice and complex, but I find that the experiments are a little bit too limited. \n6) The notations w and W are used for different things, and that is slightly confusing. Usually one is used as a matrix notation of the other.\n7) I would tend to associate data quality with how noisy observations are at a certain node, and not heterogeneity. It would be good to add some discussion on noise in the paper. How do you define an anomaly in 5.2? Is it a spatial or temporal anomaly? Not sure I understand the difference between an anomaly and a bridge node. \n8) “A bridge node highly likely has a lower data quality level due to the heterogeneity”. I would think a bridge node is very relevant, and I don't necessarily see it as having a lower data quality. This approach seems to give more weight to very similar data, while discarding the transitions, which in a meteorological setting, could be the most relevant ?! \n9) Update the references, some papers have updated information (e.g., Bruna et al. - ICLR 2014, Kipf and Welling – ICLR 2017, etc.).\n\nQuality – The experiments need more work and editing as mentioned in the comments.  \nClarity – The framework is fairly clearly presented, however the English needs significant improvement. \nOriginality – The paper is a nice application of machine learning and neural nets to data quality assessment, and the forecasting application is relevant and challenging. However the paper mostly provides a framework that relies on existing work.\nSignificance – While the paper could be relevant to data quality applications by introducing advanced machine learning techniques, it has limited reach outside the field. Maybe publish it in a data quality conference/journal."", 'Summary of the reviews:\nPros:\n•\tA novel way to evaluate the quality of heterogeneous data sources.\n•\tAn interesting way to put the data quality measurement as a regularization term in the objective function.\nCons:\n•\tSince the data quality is a function of local variation, it is unclear about the advantage of the proposed data quality regularization versus using a simple moving average regularization or local smoothness regularization.\n•\tIt is unclear about the advantage of using the Multi-layer graph convolutional networks versus two naïve settings for graph construction + simple LSTM, see detailed comments D1\n\nDetailed comments:\nD1: Compared to the proposed approaches, there are two alternative naïve ways: 1) Instead of construct the similarity graph with Gaussian kernel and associated each vertex with different types of time-series, we can also construct one unified similarity graph that is a weighted combination of different types of data sources and then apply traditional LSTM; 2) During the GCN phases, one can apply type-aware random walk as an extension to the deep walk that can only handle a single source of data. It is unclear about the advantage of using the Multi-layer graph convolutional networks versus these two naïve settings. Either some discussions or empirical comparisons would be a plus.\n']","[20, -20, 0]","[60, 50, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges improvements in the revised manuscript and believes the work would be interesting to the community. However, they still express uncertainty about the practical impact and request additional comparisons. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases requests as polite questions. They also balance positive feedback with areas for improvement. The reviewer's tone is professional and helpful, avoiding harsh criticism while still pointing out areas that need addressing."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice application', 'relevant and challenging'), they also point out several limitations and areas for improvement. The overall tone suggests that significant revisions are needed. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout, asking questions and providing specific suggestions rather than using harsh criticism. The language is respectful, using phrases like 'Could you provide a reason for this?' and 'It would be good to add some discussion on...', which contribute to the polite tone. However, it's not overly effusive or extremely polite, hence the moderate score."", ""The sentiment score is 0 (neutral) because the review presents a balanced view with both pros and cons. The reviewer acknowledges the novel aspects of the work but also raises significant concerns and questions. The politeness score is 50 (somewhat polite) because the language used is professional and constructive. The reviewer uses phrases like 'it is unclear' rather than directly criticizing, and offers suggestions for improvement. The review maintains a respectful tone throughout, focusing on the work rather than the authors personally.""]"
"['This paper extends the previous results on differentially private SGD to user-level differentially private recurrent language models. It experimentally shows that the proposed differentially private LSTM achieves comparable utility compared to the non-private model.\n\nThe idea of training differentially private neural network is interesting and very important to the machine learning + differential privacy community. This work makes a pretty significant contribution to such topic. It adapts techniques from some previous work to address the difficulties in training language model and providing user-level privacy. The experiment shows good privacy and utility.\n\nThe presentation of the paper can be improved a bit. For example, it might be better to have a preliminary section before Section2 introducing the original differentially private SGD algorithm with clipping, the original FedAvg and FedSGD, and moments accountant as well as privacy amplification; otherwise, it can be pretty difficult for readers who are not familiar with those concepts to fully understand the paper. Such introduction can also help readers understand the difficulty of adapting the original algorithms and appreciate the contributions of this work.\n', '\nSummary of the paper\n-------------------------------\n\nThe authors propose to add 4 elements to the \'FederatedAveraging\' algorithm to provide a user-level differential privacy guarantee. The impact of those 4 elements on the model\'a accuracy and privacy is then carefully analysed.\n\nClarity, Significance and Correctness\n--------------------------------------------------\n\nClarity: Excellent\n\nSignificance: I\'m not familiar with the literature of differential privacy, so I\'ll let more knowledgeable reviewers evaluate this point.\n\nCorrectness: The paper is technically correct.\n\nQuestions\n--------------\n\n1. Figure 1: Adding some noise to the updates could be view as some form of regularization, so I have trouble understand why the models with noise are less efficient than the baseline.\n2. Clipping is supposed to help with the exploding gradients problem. Do you have an idea why a low threshold hurts the performances? Is it because it reduces the amplitude of the updates (and thus simply slows down the training)?\n3. Is your method compatible with other optimizers, such as RMSprop or ADAM (which are commonly used to train RNNs)?\n\nPros\n------\n\n1. Nice extensions to FederatedAveraging to provide privacy guarantee.\n2. Strong experimental setup that analyses in details the proposed extensions.\n3. Experiments performed on public datasets.\n\nCons\n-------\n\nNone\n\nTypos\n--------\n\n1. Section 2, paragraph 3 : ""is given in Figure 1"" -> ""is given in Algorithm 1""\n\nNote\n-------\n\nSince I\'m not familiar with the differential privacy literature, I\'m flexible with my evaluation based on what other reviewers with more expertise have to say.', 'Summary: The paper provides the first evidence of effectively training large RNN based language models under the constraint of differential privacy. The paper focuses on the user-level privacy setting, where the complete contribution of a single user is protected as opposed to protecting a single training example. The algorithm is based on the Federated Averaging and Federated Stochastic gradient framework.\n\nPositive aspects of the paper: The paper is a very strong empirical paper, with experiments comparable to industrial scale. The paper uses the right composition tools like moments accountant to get strong privacy guarantees. The main technical ideas in the paper seem to be i) bounding the sensitivity for weighted average queries, and ii) clipping strategies for the gradient parameters, in order to control the norm. Both these contributions are important in the effectiveness of the overall algorithm.\n\nConcern: The paper seems to be focused on demonstrating the effectiveness of previous approaches to the setting of language models. I did not find strong algorithmic ideas in the paper. I found the paper to be lacking in that respect.  ']","[80, 80, 50]","[60, 90, 75]","[""The sentiment score is 80 (positive) because the reviewer expresses a very positive view of the paper, calling it a 'significant contribution' and praising its 'good privacy and utility'. The only criticism is a minor suggestion for improvement in presentation. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the importance and quality of the work. The suggestion for improvement is framed constructively ('it might be better'). However, it doesn't reach the highest levels of politeness as it doesn't include explicit praise or overly deferential language."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, noting its 'Excellent' clarity, technical correctness, and 'Nice extensions' to the algorithm. They list several pros and no cons, indicating a highly positive sentiment. The score isn't 100 as the reviewer admits unfamiliarity with some aspects of the field. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer offers praise, asks thoughtful questions, and even notes flexibility in their evaluation. They provide helpful feedback (including noting a typo) without any harsh criticism. The language is professional and courteous throughout, showing respect for the authors' work."", ""The sentiment score is 50 (slightly positive) because the review begins with a neutral summary and then highlights several positive aspects of the paper, including its strong empirical nature and important technical contributions. However, it also expresses a concern about the lack of strong algorithmic ideas, which prevents the sentiment from being more positive. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before expressing concerns. The reviewer avoids harsh criticism and uses phrases like 'The paper seems to be' when expressing the main concern, which softens the critique. The overall tone is professional and constructive, maintaining a polite discourse while still providing honest feedback.""]"
"['[After author feedback]\nI think the approach is interesting and warrants publication. However, I think some of the counter-intuitive claims on the proposal learning are overly strong, and not supported well enough by the experiments. In the paper the authors also need to describe the differences between their work and the concurrent work of Maddison et al. and Naesseth et al. \n\n[Original review]\nThe authors propose auto-encoding sequential Monte Carlo (SMC), extending the VAE framework to a new Monte Carlo objective based on SMC. The authors show that this can be interpreted as standard variational inference on an extended space, and that the true posterior can only be obtained if we can target the true posterior marginals at each step of the SMC procedure. The authors argue that using different number of particles for learning the proposal parameters versus the model parameters can be beneficial.\n\nThe approach is interesting and the paper is well-written, however, I have some comments and questions:\n\n- It seems clear that the AESMC bound does not in general optimize for q(x|y) to be close to p(x|y), except in the IWAE special case. This seems to mean that we should not expect for q -> p when K increases?\n- Figure 1 seems inconclusive and it is a bit difficult to ascertain the claim that is made. If I\'m not mistaken K=1 is regular ELBO and not IWAE/AESMC? Have you estimated the probability for positive vs. negative gradient values for  K=10? To me it looks like the probability of it being larger than zero is something like 2/3. K>10 is difficult to see from this plot alone.\n- Is there a typo in the bound given by eq. (17)? Seems like there are two identical terms. Also I\'m not sure about the first equality in this equatiion, is I^2 = 0 or is there a typo?\n- The discussion in section 4.1 and results in the experimental section 5.2 seem a bit counter-intuitive, especially learning the proposals for SMC using IS. Have you tried this for high-dimensional models as well? Because IS suffers from collapse even in the time dimension I would expect the optimal proposal parameters learnt from a IWAE-type objective will collapse to something close to the the standard ELBO. For example have you tried learning proposals for the LG-SSM in Section 5.1 using the IS objective as proposed in 4.1? Might this be a typo in 4.1? You still propose to learn the proposal parameters using SMC but with lower number of particles? I suspect this lower number of particles might be model-dependent.\n\nMinor comments:\n- Section 1, first paragraph, last sentence, ""that"" -> ""than""?\n- Section 3.2, ""... using which..."" formulation in two places in the firsth and second paragraph was a bit confusing\n- Page 7, second line, just ""IS""?\n- Perhaps you can clarify the last sentence in the second paragraph of Section 5.1 about computational graph not influencing gradient updates?\n- Section 5.2, stochastic variational inference Hoffman et al. (2013) uses natural gradients and exact variational solution for local latents so I don\'t think K=1 reduces to this?', 'Overall:\nI had a really hard time reading this paper because I found the writing to be quite confusing. For this reason I cannot recommend publication as I am not sure how to evaluate the paper’s contribution. \n\nSummary\nThe authors study state space models in the unsupervised learning case. We have a set of observed variables Y, we posit a latent set of variables X, the mapping from the latent to the observed variables has a parametric form and we have a prior over the parameters. We want to infer a posterior density given some data.\n\nThe authors propose an algorithm which uses sequential Monte Carlo + autoencoders. They use a REINFORCE-like algorithm to differentiate through the Monte Carlo. The contribution of this paper is to add to this a method which uses 2 different ELBOs for updating different sets of parameters.\n\nThe authors show the AESMC works better than importance weighted autoencoders and the double ELBO method works even better in some experiments. \n\nThe proposed algorithm seems novel, but I do not understand a few points which make it hard to judge the contribution. Note that here I am assuming full technical correctness of the paper (and still cannot recommend acceptance).\n\nIs the proposed contribution of this paper just to add the double ELBO or does it also include the AESMC (that is, should this paper subsume the anonymized pre-print mentioned in the intro)? This was very unclear to me.\n\nThe introduction/experiments section of the paper is not well motivated. What is the problem the authors are trying to solve with AESMC (over existing methods)? Is it scalability? Is it purely to improve likelihood of the fitted model (see my questions on the experiments in the next section)? \n\nThe experiments feel lacking. There is only one experiment comparing the gains from AESMC, ALT to a simpler (?) method of IWAE. We see that they do better but the magnitude of the improvement is not obvious (should I be looking at the ELBO scores as the sole judge? Does AESMC give a better generative model?). The authors discuss the advantages of SMC and say that is scales better than other methods, it would be good to show this as an experimental result if indeed the quality of the learned representations is comparable.', ""Update:\nOn further consideration (and reading the other reviews), I'm bumping my rating up to a 7. I think there are still some issues, but this work is both valuable and interesting, and it deserves to be published (alongside the Naesseth et al. and Maddison et al. work).\n\n-----------\n\nThis paper proposes a version of IWAE-style training that uses SMC instead of classical importance sampling. Going beyond the several papers that proposed this simultaneously, the authors observe a key issue: the variance of the gradient of these IWAE-style bounds (w.r.t. the inference parameters) grows with their accuracy. They therefore propose using a more-biased but lower-variance bound to train the inference parameters, and the more-accurate bound to train the generative model.\n\nOverall, I found this paper quite interesting. There are a few things I think could be cleared up, but this seems like good work (although I'm not totally up to date on the very recent literature in this area).\n\nSome comments:\n\n* Section 4: I found this argument extremely interesting. However, it’s worth noting that your argument implies that you could get an O(1) SNR by averaging K noisy estimates of I_K. Rainforth et al. suggest this approach, as well as the approach of averaging K^2 noisy estimates, which the theory suggests may be more appropriate if the functions involved are sufficiently smooth, which even for ReLU networks that are non-differentiable at a finite number of points I think they should be.\n\nThis paper would be stronger if it compared with Rainforth et al.’s proposed approaches. This would demonstrate the real tradeoffs between bias, variance, and computation. Of course, that involves O(K^2) or O(K^3) computation, which is a weakness. But one could use a small value of K (say, K=5).\n\nThat said, I could also imagine a scenario where there is no benefit to generating multiple noisy samples for a single example versus a single noisy sample for multiple examples. Basically, these all seem like interesting and important empirical questions that would be nice to explore in a bit more detail.\n\n* Section 3.3: Claim 1 is an interesting observation. But Propositions 1 and 2 seem to just say that the only way to get a perfectly tight SMC ELBO is to perfectly sample from the joint posterior. I think there’s an easier way to make this argument:\n\nGiven an unbiased estimator \\hat{Z} of Z, by Jensen’s inequality E[log \\hat{Z}] ≤ log Z, with equality iff the variance of \\hat{Z} = 0. The only way to get an SMC estimator’s variance to 0 is to drive the variance of the weights to 0. That only happens if you perfectly sample each particle from the true posterior, conditioned on all future information.\n\nAll of which is true as far as it goes, but I think it’s a bit of a distraction. The question is not “what’s it take to get to 0 variance” but “how quickly can we approach 0 variance”. In principle IS and SMC can achieve arbitrarily high accuracy by making K astronomically large. (Although [particle] MCMC is probably a better choice if one wants extremely low bias.)\n\n* Section 3.2: The choice of how to get low-variance gradients through the ancestor-sampling choice seems seems like an important technical challenge in getting this approach to work, but there’s only a very cursory discussion in the main text. I would recommend at least summarizing the main findings of Appendix A in the main text.\n\n* A relevant missing citation: Turner and Sahani’s “Two problems with variational expectation maximisation for time-series models” (http://www.gatsby.ucl.ac.uk/~maneesh/papers/turner-sahani-2010-ildn.pdf). They discuss in detail some examples where tighter variational bounds in state-space models lead to worse parameter estimates (though in a quite different context and with a quite different analysis).\n\n* Figure 1: What is the x-axis here? Presumably phi is not actually 1-dimensional?\n\nTypos etc.:\n\n* “learn a particular series intermediate” missing “of”.\n\n* “To do so, we generate on sequence y1:T” s/on/a/, I think?\n\n* Equation 3: Should there be a (1/K) in Z?""]","[20, -60, 60]","[60, 20, 70]","[""The sentiment score is slightly positive (20) because the reviewer states the approach is 'interesting and warrants publication', but also expresses several concerns and questions about the claims and methodology. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges positive aspects. The reviewer maintains a professional tone, balancing praise with constructive criticism. They use polite phrases like 'I think' and 'perhaps you can clarify' when making suggestions, rather than being overly directive."", ""The sentiment score is -60 because the reviewer states they 'cannot recommend publication' and had a 'really hard time reading this paper', indicating a strongly negative view. However, they do acknowledge some positive aspects like the algorithm seeming novel, so it's not maximally negative. The politeness score is 20 because the reviewer uses polite language like 'I cannot recommend' rather than harsh criticisms, and frames issues as their own difficulty understanding rather than attacking the authors. However, the overall tone is still critical, so it's only slightly positive on politeness. The reasoning is based on the reviewer's opening statement about not recommending publication, their difficulty understanding the paper, and their critiques of the motivation and experiments, balanced against their acknowledgment of novel contributions and use of respectful language."", ""The sentiment score is 60 (moderately positive) because the reviewer starts by stating they found the paper 'quite interesting' and 'good work', and even increased their rating upon further consideration. They provide constructive feedback and suggestions for improvement, indicating they see value in the work. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms as suggestions or areas for improvement rather than harsh judgments. They use phrases like 'This paper would be stronger if...' and 'I think there's an easier way to make this argument' which offer critique in a considerate manner. The reviewer also acknowledges their own potential limitations ('although I'm not totally up to date on the very recent literature in this area'). The overall tone is professional and constructive.""]"
"['This work proposes to use the value function V^e of some expert policy \\pi^e in order to speed up learning of an RL agent which should eventually do better than the expert. The emphasis is put on using k-steps (with k>1) Bellman updates using bootstrapping from V^e. \n\nIt is claimed that the case k=1 does not allow the agent to outperform the expert policy, whereas k>1 does (Section 3.1, paragraph before Lemma 3.2).\n\nI disagree with this claim. Indeed a policy gradient algorithm (similar to (10)) with a 1-step advantage c(s,a) + gamma V^e(s_{t+1}) - V^e(s_t) will converge (say in the tabular case, or in the case you consider of a rich enough policy space \\Pi) to the greedy policy with respect to V^e, which is strictly better than V^e (if V^e is not optimal). So you don’t need to use k>1 to improve the expert policy. Now it’s true that this will not converge to the optimal policy (since you keep bootstrapping with V^e instead of the current value function), but neither the k-step advantage will. \n\nSo I don’t see any fundamental difference between k=1 and k>1. The only difference being that the k-step bootstrapping will implement a k-step Bellman operator which contracts faster (as gamma^k) when k is large. But the best choice of k has to be discussed in light of a bias-variance discussion, which is missing here. So I find that the main motivation for this work is not well supported. \n\nAlgorithmic suggestion:\nInstead of bootstrapping with V^e, why not bootstrap with min(V^e, V), where V is your current approximation of the value function. In that way you would benefit from (1) fast initialization with V^e at the beginning of learning, (2) continual improvement once you’ve reached the performance of the expert. \n\nOther comments:\nRequiring that we know the value function of the expert on the whole state space is a very strong assumption that we do not usually make in Imitation learning. Instead we assume we have trajectories from expert (from which we can compute value function along those trajectories only). Generalization of the value function to other states is a hard problem in RL and is the topic of important research.\n\nThe overall writing lacks rigor and the contribution is poor. Indeed the lower bound (Theorem 3.1) is not novel (btw, the constant hidden in the \\Omega notation is 1/(1-gamma)). Theorems 3.2 and 3.3 are not novel either. Please read [Bertsekas and Tsitsiklis, 96] as an introduction to dynamic programming with approximation.\n\nThe writing could be improved, and there are many typos, such as:\n- J is not defined (Equation (2))\n- Why do you call A a disadvantage function whereas this quantity is usually called an advantage?\n- You are considering a finite (ie, k) horizon setting, so the value function depend on time. For example the value functions defined in (11) depend on time. \n- All derivations in Section 4, before subsection 4.1 are very approximate and lack rigor.\n- Last sentence of Proof of theorem 3.1. I don’t understand H -> 2H epsilon. H is fixed, right? Also your example does not seem to be a discounted problem.\n', '=== SUMMARY ===\n\nThe paper considers a combination of Reinforcement Learning (RL) and Imitation Learning (IL), in the infinite horizon discounted MDP setting.\nThe IL part is in the form of an oracle that returns a value function V^e, which is an approximation of the optimal value function. The paper defines a new cost (or reward) function based on V^e, through shaping (Eq. 1). It is known that shaping does not change the optimal policy.\n\nA key aspect of this paper is to consider a truncated horizon problem (say horizon k) with the reshaped cost function, instead of an infinite horizon MDP.\nFor this truncated problem, one can write the (dis)advantage function as a k-step sum of reward plus the value returned by the oracle at the k-th step (cf. Eq. 5).\nTheorem 3.3 shows that the value of the optimal policy of the truncated MDP w.r.t. the original MDP is only O(gamma^k eps) worse than the optimal policy of the original problem (gamma is the discount factor and eps is the error between V^e and V*).\n\nThis suggests two things: \n1) Having an oracle that is accurate (small eps) leads to good performance. If oracle is the same as the optimal value function, we do not need to plan more than a single step ahead.\n2) By planning for k steps ahead, one can decrease the error in the oracle geometrically fast. In the limit of k —> inf, the error in the oracle does not matter.\n\nBased on this insight, the paper suggests an actor-critic-like algorithm called THOR (Truncated HORizon policy search) that minimizes the total cost over a truncated horizon with a modified cost function.\n\nThrough a series of experiments on several benchmark problems (inverted pendulum, swimmer, etc.), the paper shows the effect of planning horizon k.\n\n\n\n=== EVALUATION & COMMENTS ===\n\nI like the main idea of this paper. The paper is also well-written. But one of the main ideas of this paper (truncating the planning horizon and replacing it with approximation of the optimal value function) is not new and has been studied before, but has not been properly cited and discussed.\n\nThere are a few papers that discuss truncated planning. Most closely is the following paper:\n\nFarahmand, Nikovski, Igarashi, and Konaka, “Truncated Approximate Dynamic Programming With Task-Dependent Terminal Value,” AAAI, 2016.\n\nThe motivation of AAAI 2016 paper is different from this work. The goal there is to speedup the computation of finite, but large, horizon problem with a truncated horizon planning. The setting there is not the combination of RL and IL, but multi-task RL. An approximation of optimal value function for each task is learned off-line and then used as the terminal cost. \nThe important point is that the learned function there plays the same role as the value provided by the oracle V^e in this work. They both are used to shorten the planning horizon. That paper theoretically shows the effect of various error terms, including terms related to the approximation in the planning process (this paper does not do that).\n\nNonetheless, the resulting algorithms are quite different. The result of this work is an actor-critic type of algorithm. AAAI 2016 paper is an approximate dynamic programming type of algorithm.\n\nThere are some other papers that have ideas similar to this work in relation to truncating the horizon. For example, the multi-step lookahead policies and the use of approximate value function as the terminal cost in the following paper:\n\nBertsekas, “Dynamic Programming and Suboptimal Control: A Survey from ADP to MPC,” European Journal of Control, 2005.\n\nThe use of learned value function to truncate the rollout trajectory in a classification-based approximate policy iteration method has been studied by\n\nGabillon, Lazaric, Ghavamzadeh, and Scherrer, “Classification-based Policy Iteration with a Critic,” ICML, 2011.\n\nOr in the context of Monte Carlo Tree Search planning, the following paper is relevant:\n\nSilver et al., “Mastering the game of Go with deep neural networks and tree search,” Nature, 2016.\n\nTheir “value network” has a similar role to V^e. It provides an estimate of the states at the truncated horizon to shorten the planning depth.\n\nNote that even though these aforementioned papers are not about IL, this paper’s stringent requirement of having access to V^e essentially make it similar to those papers.\n\n\nIn short, a significant part of this work’s novelty has been explored before. Even though not being completely novel is totally acceptable, it is important that the paper better position itself compared to the prior art.\n\n\nAside this main issue, there are some other comments:\n\n\n- Theorem 3.1 is not stated clearly and may suggest more than what is actually shown in the proof. The problem is that it is not clear about the fact the choice of eps is not arbitrary.\nThe proof works only for eps that is larger than 0.5. With the construction of the proof, if eps is smaller than 0.5, there would not be any error, i.e., J(\\hat{pi}^*) = J(pi^*).\n\nThe theorem basically states that if the error is very large (half of the range of value function), the agent does not not perform well. Is this an interesting case?\n\n\n- In addition to the papers I mentioned earlier, there are some results suggesting that shorter horizons might be beneficial and/or sufficient under certain conditions. A related work is a theorem in the PhD dissertation of Ng:\n\nAndrew Ng, Shaping and Policy Search in Reinforcement Learning, PhD Dissertation, 2003.\n(Theorem 5 in Appendix 3.B: Learning with a smaller horizon).\n\nIt is shown that if the error between Phi (equivalent to V^e here) and V* is small, one may choose a discount factor gamma’ that is smaller than gamma of the original MDP, and still have some guarantees. As the discount factor has an interpretation of the effective planning horizon, this result is relevant. The result, however, is not directly comparable to this work as the planning horizon appears implicitly in the form of 1/(1-gamma’) instead of k, but I believe it is worth to mention and possibly compare.\n\n- The IL setting in this work is that an oracle provides V^e, which is the same as (Ross & Bagnell, 2014). I believe this setting is relatively restrictive as in many problems we only have access to (state, action) pairs, or sequence thereof, and not the associated value function. For example, if a human is showing how a robot or a car should move, we do not easily have access to V^e (unless the reward function is known and we estimate the value with rollouts; which requires us having a long trajectory). This is not a deal breaker, and I would not consider this as a weakness of the work, but the paper should be more clear and upfront about this.\n\n\n- The use of differential operator nabla instead of gradient of a function (a vector field) in Equations (10), (14), (15) is non-standard.\n\n- Figures are difficult to read, as the colors corresponding to confidence regions of different curves are all mixed up. Maybe it is better to use standard error instead of standard deviation.\n\n\n===\nAfter Rebuttal: Thank you for your answer. The revised paper has been improved. I increase my score accordingly.\n', ""This paper proposes a new theoretically-motivated method for combining reinforcement learning and imitation learning for acquiring policies that are as good as or superior to the expert. The method assumes access to an expert value function (which could be trained using expert roll-outs) and uses the value function to shape the reward function and allow for truncated-horizon policy search. The algorithm can gracefully handle suboptimal demonstrations/value functions, since the demonstrations are only used for reward shaping, and the experiments demonstrate faster convergence and better performance compared to RL and AggreVaTeD on a range of simulated control domains. The paper is well-written and easy to understand.\n\nMy main feedback is with regard to the experiments:\nI appreciate that the experiments used 25 random seeds! This provides a convincing evaluation.\nIt would be nice to see experimental results on even higher dimensional domains such as the ant, humanoid, or vision-based tasks, since the experiments seem to suggest that the benefit of the proposed method is diminished in the swimmer and hopper domains compared to the simpler settings.\nSince the method uses demonstrations, it would be nice to see three additional comparisons: (a) training with supervised learning on the expert roll-outs, (b) initializing THOR and AggreVaTeD (k=1) with a policy trained with supervised learning, and (c) initializing TRPO with a policy trained with supervised learning. There doesn't seem to be any reason not to initialize in such a way, when expert demonstrations are available, and such an initialization should likely provide a significant speed boost in training for all methods.\nHow many demonstrations were used for training the value function in each domain? I did not see this information in the paper.\n\nWith regard to the method and discussion:\nThe paper discusses the connection between the proposed method and short-horizon imitation and long-horizon RL, describing the method as a midway point. It would also be interesting to see a discussion of the relation to inverse RL, which considers long-term outcomes from expert demonstrations. For example, MacGlashn & Littman propose a midway point between imitation and inverse RL [1].\nTheoretically, would it make sense to anneal k from small to large? (to learn the most effectively from the smallest amount of experience)\n\n[1] https://www.ijcai.org/Proceedings/15/Papers/519.pdf\n\n\nMinor feedback:\n- The RHS of the first inequality in the proof of Thm 3.3 seems to have an error in the indexing of i and exponent, which differs from the line before and line after\n\n**Edit after rebuttal**: I have read the other reviews and the authors' responses. My score remains the same.""]","[-70, 20, 70]","[-20, 60, 80]","[""The sentiment score is -70 because the reviewer expresses strong disagreement with the main claims of the paper, points out several flaws in the methodology and writing, and states that the contribution is poor. The reviewer also mentions that the work lacks rigor and contains many typos. However, it's not entirely negative as the reviewer does offer some constructive suggestions for improvement. The politeness score is -20 because while the reviewer maintains a professional tone overall, the language is quite direct and critical. Phrases like 'I disagree with this claim', 'the main motivation for this work is not well supported', and 'the overall writing lacks rigor and the contribution is poor' are quite blunt and could be perceived as impolite in academic discourse. The reviewer does not use overtly rude language, but also does not employ many politeness markers or soften their criticisms."", ""Sentiment Score (20): The review begins positively, stating 'I like the main idea of this paper' and 'The paper is also well-written.' However, it then points out several significant issues, particularly the lack of novelty and proper citation of previous work. The reviewer provides constructive criticism and suggestions for improvement, indicating a generally positive but cautious sentiment. The final note about the revised paper being improved suggests a slight increase in positive sentiment.\n\nPoliteness Score (60): The reviewer maintains a professional and respectful tone throughout. They use phrases like 'I like the main idea' and 'Thank you for your answer,' which are polite. The criticism is presented constructively, with the reviewer offering specific suggestions and references to improve the paper. The language is not overly formal or deferential, but it remains courteous and appropriate for academic discourse. The reviewer also acknowledges the authors' efforts in the rebuttal, which is a polite gesture."", ""The sentiment score is 70 (positive) because the reviewer starts by praising the paper as 'well-written and easy to understand', and appreciates the thorough experiments with 25 random seeds. The overall tone is constructive and supportive, with suggestions for improvements rather than criticisms. The politeness score is 80 (quite polite) due to the use of respectful language throughout. The reviewer uses phrases like 'I appreciate', 'It would be nice to see', and frames suggestions as questions or possibilities rather than demands. The feedback is detailed and specific, showing engagement with the work, while maintaining a courteous tone. The reviewer also acknowledges the authors' rebuttal at the end, showing further respect for the dialogue process.""]"
"['The authors propose to learn the rigid motion group (translation and rotation) from a latent representation of image sequences without the need for explicit labels.\nWithin their data driven approach they pose minimal assumptions on the model, requiring the group properties (associativity, invertibility, identity) to be fulfilled.\nTheir model comprises CNN elements to generate a latent representation in motion space and LSTM elements to compose these representations through time.\nThey experimentally demonstrate their method on sequences of MINST digits and the KITTI dataset.\n\nPros:\n- interesting concept of combining algebraic structure with a data driven method\n- clear idea development and well written\n- transparent model with enough information for re-implementation\n- honest pointers to scenarios where the method might not work well\n\nCons:\n- the method is only intrinsically evaluated (Tables 2 and 3), but not compared with results from other motion estimation methods', 'Paper proposes an approach for learning video motion features in an unsupervised manner. A number of constraints are used to optimize the neural network that consists of CNN + RNN (LSTM). Constraints stem from group structure of sequences and include associativity and inevitability. For example, forward-backward motions should cancel each other out and motions should be additive. Optimized network is illustrated to produce features that can be used to regress odometry. \n\nOverall the approach is interesting from the conceptual point of view, however, experimental validation is very preliminary. This makes it difficult to asses the significance and viability of the approach. In particular, the lack of direct comparison, makes it difficult to asses whether the proposed group constraints are competitive with brightness constancy (or similar) constraints used to learn motion in an unsupervised manner in other papers. \n\nIt is true that proposed model may be able to learn less local motion information, but it is not clear if this is what happens in practice. In order to put the findings in perspective authors should compare to unsupervised optical flow approach (e.g., unsupervised optical flow produced by one of the proposed CNN networks and used to predict odometer on KITTI for fair comparison). Without a comparison of this form the paper is incomplete and the findings are difficult to put in the context of state-of-the-art.\n\nAlso, saying that learned features can predict odometry “better than chance” (Section 4.2 and Table 2) seems like a pretty low bar for a generic feature representation. ', 'The paper presents a method that given a sequence of frames, estimates a corresponding motion embedding to be the hidden state of an RNN (over convolutional features) at the last frame of the sequence. The parameters of the motion embedding are trained to preserve properties of associativity  and invertibility of motion, where the frame sequences have been recomposed (from video frames) in various way to create pairs of frame sequences with those -automatically obtained- properties. This means, the motion embedding is essentially trained without any human annotations.\nExperimentally, the paper shows that in synthetic moving MNIST frame sequences motion embedding discovers different patterns of motion, while it ignores image appearance (i.e., the digit label). The paper also shows that linear regressor trained in KITTI on top of the unsupervised motion embedding to estimate camera motion performs better than chance. \nQ to the authors: what labelled data were used to train the linear regressor in the KITTI experiment? \nEmpirically, it appears that supervision by preserving group transformations may not  be immensely valuable for learning motion representations. \n\n\n\nPros\n1)The neural architecture for motion embedding computation appears reasonable\n2)The paper tackles an interesting problem\n\nCons\n1)For a big part of the introduction the paper refers to the problem of `` ````""learning motion” or `\'\'understanding motion”  without being specific what it means by that. \n2)The empirical results are not convincing of the strength of imposing group transformations for self-supervised learning of motion embeddings.\n3)The KITTI experiment is not well explained as it is not clear how this regressor was trained to predict egomotion out of the motion embedding.\n']","[70, -30, -20]","[50, 50, 50]","[""The sentiment score is 70 (positive) because the review begins with a neutral summary of the paper's content, followed by a list of pros that outweigh the cons. The reviewer highlights the 'interesting concept,' 'clear idea development,' and 'transparent model' as positive aspects. There is only one con mentioned, which is relatively minor. The politeness score is 50 (slightly polite) because the language used is professional and objective throughout. The reviewer presents both pros and cons in a balanced manner without using harsh or overly critical language. The use of phrases like 'interesting concept' and 'honest pointers' indicates a respectful tone. However, the review doesn't go out of its way to be exceptionally polite, maintaining a neutral professional tone overall."", ""The sentiment score is -30 because while the reviewer acknowledges the approach as 'interesting from the conceptual point of view', they express significant concerns about the experimental validation being 'very preliminary' and the lack of direct comparisons. The reviewer also states that the paper is 'incomplete' without certain comparisons, indicating a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism while clearly stating their concerns. They use phrases like 'it is difficult to assess' and 'authors should compare' rather than making blunt criticisms. The reviewer also acknowledges positive aspects before presenting critiques, which is a polite approach to reviewing."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('pros'), they also express significant concerns ('cons') and skepticism about the effectiveness of the method ('Empirically, it appears that supervision by preserving group transformations may not be immensely valuable...'). The overall tone suggests more criticism than praise. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout, using neutral language to express criticisms and asking a clarifying question politely. They also acknowledge the positive aspects of the paper before listing the cons, which is a courteous approach in peer reviews.""]"
"['The idea on which the paper is based - that the limit of the entropic regularisation over Birkhoff polytope is on the vertices = permutation matrices -, and the link with optimal transport, is very interesting. The core of the paper, Section 3, is interesting and represents a valuable contribution.\n\nI am wondering whether the paper\'s approach and its Theorem 1 can be extended to other regularised versions of the optimal transport cost, such as this family (Tsallis) that generalises the entropic one:\n\nhttps://aaai.org/ocs/index.php/AAAI/AAAI17/paper/view/14584/14420\n\nAlso, it would be good to keep in mind the actual proportion of errors that would make a random choice of a permutation matrix for your Jigsaws. When you look at your numbers, the expected proportion of parts wrong for a random assignment could be competitive with your results on the smallest puzzles (typically, 2x2). Perhaps you can put the *difference* between your result and the expected result of a random permutation; this will give a better understanding of what you gain from the non-informative baseline.\n(also, it would be good to define ""Prop. wrong"" and ""Prop. any wrong"". I think I got it but it is better to be written down)\n\nThere should also be better metrics for bigger jigsaws -- for example, I would accept bigger errors if pieces that are close in the solution tend also to be put close in the err\'ed solution.\n\nTypos:\n\n* Rewrite definition 2 in appendix. Some notations do not really make sense.', 'Learning latent permutations or matchings is inherently difficult because the marginalization and partition function computation problems at its core are intractable. The authors propose a new method that approximates the discrete max-weight matching by a continuous Sinkhorn operator, which looks like an analog of softmax operator on matrices. They extend the Gumbel softmax method (Jang et al., Maddison et al. 2016) to define a Gumbel-Sinkhorn method for distributions over latent matchings. Their empirical study shows that this method outperforms competitive baselines for tasks such as sorting numbers, solving jigsaw puzzles etc.\n\nIn Theorem 1, the authors show that Sinkhorn operator solves a certain entropy-regularized problem over the Birkhoff polytope (doubly stochastic matrices). As the regularization parameter or temperature \\tau tends to zero, the continuous solution approaches the desired best matching or permutation. An immediate question is, can one show a convergence bound to determine a reasonable choice of \\tau?\n\nThe authors use the Gumbel trick that recasts a difficult sampling problem as an easier optimization problem. To get around non-differentiable re-parametrization under the Gumbel trick, they extend the Gumbel softmax distribution idea (Jang et al., Maddison et al. 2016) and consider Gumbel-Sinkhorn distributions. They illustrate that at low temperature \\tau, Gumbel-matching and Gumbel-Sinkhorn distributions are indistinguishable. This is still not sufficient as Gumbel-matching and Gumbel-Sinkhorn distributions have intractable densities. The authors address this with variational inference (Blei et al., 2017) as discussed in detail in Section 5.4.\n\nThe empirical results do well against competitive baselines. They significantly outperform Vinyals et al. 2015 by sorting up to N = 120 uniform random numbers in [0, 1] with great accuracy < 0.01, as opposed to Vinyals et al. who used a more complex recurrent neural network even for N = 15 and accuracy 0.9. \n\nThe empirical study on jigsaw puzzles over MNIST, Celeba, Imagenet gives good results on Kendall tau, l1 and l2 losses, is slightly better than Cruz et al. (arxiv 2017) for Kendall tau on Imagenet 3x3 but does not have a significant literature to compare against. I hope the other reviewers point out references that could make this comparison more complete and meaningful.\n\nThe third empirical study on the C. elegans neural inference problem shows significant improvement over Linderman et al. (arxiv 2017).\n\nOverall, I feel the main idea and the experiments (especially, the sorting and C. elegance neural inference) merit acceptance. I am not an expert in this line of research, so I hope other reviewers can more thoroughly examine the heuristics discussed by the authors in Section 5.4 and Appendix C.3 to get around the intractable sub-problems in their approach.    ', 'Quality: The paper is built on solid theoretical grounds and supplemented by experimental demonstrations. Specifically, the justification for using the Sinkhorn operator is given by theorem 1 with proof given in the appendix. Because the theoretical limit is unachievable, the authors propose to truncate the Sinkhorn operator at level $L$. The effect of approximation for the truncation level $L$ as well as the effect of temperature $\\tau$ are demonstrated nicely through figures 1 and 2(a). The paper also presents a nice probabilistic approach to permutation learning, where the doubly stochastic matrix arises from Gumbel matching distribution. \n\nClarity: The paper has a good flow, starting out with the theoretical foundation, description of how to construct the network, followed by the probabilistic formulation. However, I found some of the notation used to be a bit confusing.\n\n1. The notation $l$ appears in Section 2 to denote the number of iterations of Sinkhorn operator. In Section 3, the notation $l$ appears as $g_l$, where in this case, it refers to the layers in the neural network. This led me to believe that there is one Sinkhorn operator for each layer of neural network. But after reading the paper a few times, it seemed to me that the Sinkhorn operator is used only at the end, just before the final output step (the part where it says the truncation level was set to $L=20$ for all of the experiments confirmed this). If I\'m correct in my understanding, perhaps different notation need to be used for the layers in the NN and the Sinkhorn operator. Additionally, it would have been nice to see a figure of the entire network architecture, at least for one of the applications considered in the paper. \n\n2. The distinction between $g$ and $g_l$ was also a bit unclear. Because the input to $M$ (and $S$) is a square matrix, the function $g$ seems to be carrying out the task of preparing the final output of the neural network into the input formate accepted by the Sinkhorn operator. However, $g$ is stated as ""the output of the computations involving $g_l$"". I found this statement to be a bit unclear and did not really describe what $g$ does; of course my understanding may be incorrect so a clarification on this statement would be helpful.\n\nOriginality: I think there is enough novelty to warrant publication.  The paper does build on a set of previous works, in particular Sinkhorn operator, which achieves continuous relaxation for permutation valued variables. However, the paper proposes how this operator can be used with standard neural network architectures for learning permutation valued latent variable. The probabilistic approach also seems novel. The applications are interesting, in particular, it is always nice to see a machine learning method applied to a unique application; in this case from computational neuroscience.\n\nOther comments:\n\n1. What are the differences between this paper and the paper by Adams and Zemel (2011)? Adams and Zemel also seems to propose Sinkhorn operator for neural network. Although they focus only on the document ranking problem, it would be good to hear the authors\' view on what differentiates their work from Adams and Zemel.\n\n2. As pointed out in the paper, there is a concurrent work: DeepPermNet. Few comments regarding the difference between their work and this work would also be helpful as well.\n\nSignificance: The Sinkhorn network proposed in the paper is useful as demonstrated in the experiments. The methodology appears to be straight forward  to implement using the existing software libraries, which should help increase its usability. \n\nThe significance of the paper can greatly improve if the methodology is applied to other popular machine learning applications such as document ranking, image matching, DNA sequence alignment, and etc. I wonder how difficult it is to extend this methodology to bipartite matching problem with uneven number of objects in each partition, which is the case for document ranking. And for problems such as image matching (e.g., matching landmark points), where each point is associated with a feature (e.g., SIFT), how would one formulate such problem in this setting? \n']","[50, 70, 60]","[70, 80, 80]","[""The sentiment score is 50 (moderately positive) because the reviewer starts by praising the paper's core idea as 'very interesting' and acknowledges that Section 3 is 'interesting and represents a valuable contribution.' However, the review also includes several suggestions for improvement, which tempers the overall positivity. The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, framing suggestions as questions or gentle recommendations (e.g., 'I am wondering whether...', 'it would be good to...') rather than demands. The reviewer also offers constructive feedback and explains their reasoning for suggestions. The mention of typos is done matter-of-factly without harsh criticism. Overall, the tone is professional, constructive, and courteous."", ""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, noting that the 'main idea and the experiments... merit acceptance'. They highlight several strengths, including outperforming baselines and significant improvements over previous work. The score is not higher because the reviewer does express some reservations and suggests areas for improvement or further clarification. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('I am not an expert in this line of research'), and frames criticisms constructively ('I hope other reviewers can more thoroughly examine...'). The reviewer also uses phrases like 'I hope' and 'I feel', which soften any potential criticisms and maintain a collegial tone."", ""The sentiment score is 60 (positive) because the reviewer generally expresses a favorable view of the paper, noting its solid theoretical grounds, good flow, and enough novelty to warrant publication. They also highlight the paper's usefulness and potential for wider application. However, it's not a perfect score as the reviewer does point out some areas for improvement, particularly in clarity of notation and comparison with related work. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths, offer suggestions for improvement in a considerate manner, and use phrases like 'it would be nice to see' and 'a clarification on this statement would be helpful'. The reviewer also asks questions and expresses interest in potential extensions of the work, showing engagement and respect for the authors' expertise.""]"
"['The authors consider the metrics for evaluating disentangled representations. They define three criteria: Disentanglement, Informativeness, and Completeness. They  learning a linear mapping from the latent code to an idealized set of disentangled generative factors, and then define information-theoretic measures based on pseudo-distributions calculated from the relative magnitudes of weights. Experimental evaluation considers a dataset of 200k images of a teapot with varying pose and color.\n\nI think that defining metrics for evaluating the degree of disentanglement in representations is  great problem to look at. Overall, the metrics approached by the authors are reasonable, though the way pseudo-distribution are define in terms of normalized weight magnitudes is seems a little ad hoc to me.  \n\nA second limitation of the work is the reliance on a ""true"" set of disentangled factors. We generally want to learn learning disentangled representations in an unsupervised or semi-supervised manner, which means that we will in general not have access supervision data for the disentangled factors. Could the authors perhaps comment on how well these metrics would work in the semi-supervised case?\n\nOverall, I would say this is somewhat borderline, but I could be convinced to argue for acceptance based on the other reviews and the author response. \n\nMinor Commments:\n\n- Tables 1 and 2 would be easier to unpack if the authors were to list the names of the variables (i.e. azimuth instead of z_0) or at least list what each variable is in the caption. \n\n- It is not entirely clear to me how the proposed metrics, whose definitions all reference magnitudes of weights, generalize to the case of random forests. ', '****\nI acknowledge the author\'s comments and improve my score to 7.\n****\n\nSummary:\nThe authors propose an experimental framework and metrics for the quantitative evaluation of disentangling representations.\nThe basic idea is to use datasets with known factors of variation, z, and measure how well in an information theoretical sense these are recovered by a representation trained on a dataset yielding a latent code c.\nThe authors propose measures disentanglement, informativeness and completeness to evaluate the latent code c, mostly through learned nonlinear mappings between z and c measuring the statistical relatedness of these variables.\nThe paper ultimately is light on comprehensive evaluation of popular models on a variety of datasets and as such does not quite yield the insights it could.\n\nSignificance:\nThe proposed methodology is relevant, because disentangling representations are an active field of research and currently are not evaluated in a standardized way.\n\nClarity:\nThe paper is lucidly written and very understandable.\n\nQuality:\nThe authors use formal concepts from information theory to underpin their basic idea of recovering latent factors and have spent a commendable amount of effort on clarifying different aspects on why these three measures are relevant.\nA few comments:\n1. How do the authors propose to deal with multimodal true latent factors? What if multiple sets of z can generate the same observations and how does the evaluation of disentanglement fairly work if the underlying model cannot be uniquely recovered from the data?\n2. Scoring disentanglement against known sources of variation is sensible and studied well here, but how would the authors evaluate or propose to evaluate in datasets with unknown sources of variation?\n3. the actual sources of variation are interpretable and explicit measurable quantities here. However, oftentimes a source of variation can be a variable that is hard or impossible to express in a simple vector z (for instance the sentiment of a scene) even when these factors are known. How do the authors propose to move past narrow definitions of factors of variation and handle more complex variables? Arguably, disentangling is a step towards concept learning and concepts might be harder to formalize than the approach taken here where in the experiment the variables are well-behaved and relatively easy to quantify since they relate to image formation physics.\n4. For a paper introducing a formal experimental framework and metrics or evaluation I find that the paper is light on experiments and evaluation. I would hope that at the very least a broad range of generative models and some recognition models are used to evaluate here, especially a variational autoencoder, beta-VAE and so on. Furthermore the authors could consider applying their framework to other datasets and offering a benchmark experiment and code for the community to establish this as a means of evaluation to maximize the impact of a paper aimed at reproducibility and good science.\n\nNovelty:\nPrevious papers like ""beta-VAE"" (Higgins et al. 2017) and ""Bayesian Representation Learning With Oracle Constraints"" by Karaletsos et al (ICLR 16) have followed similar experimental protocols inspired by the same underlying idea of recovering known latent factors, but have fallen short of proposing a formal framework like this paper does. It would be good to add a section gathering such attempts at evaluation previously made and trying to unify them under the proposed framework.\n', ""The paper addresses the problem of devising a quantitative benchmark to evaluate the capability of algorithms to disentangle factors of variation in the data. \n\n*Quality* \nThe problem addressed is surely relevant in general terms. However, the contributed framework did not account for previously proposed metrics (such as equivariance, invariance and equivalence). Within the experimental results, only two methods are considered: although Info-GAN is a reliable competitor, PCA seems a little too basic to compete against. The choice of using noise-free data only is a limiting constraint (in [Chen et al. 2016], Info-GAN is applied to real-world data). \nFinally, in order to corroborate the quantitative results, authors should have reported some visual experiments in order to assess whether a change in c_j really correspond to a change in the corresponding factor of variation z_i according to the learnt monomial matrix.\n\n*Clarity*\nThe explanation of the theoretical framework is not clear. In fact, Figure 1 is straight in identifying disentanglement and completeness as a deviation from an ideal bijective mapping. But, then, the authors missed to clarify how the definitions of D_i and C_j translate this requirement into math. \nAlso, the criterion of informativeness of Section 2 is split into two sub-criteria in Section 3.3, namely test set NRMSE and Zero-Shot NRMSE: such shift needs to be smoothed and better explained, possibly introducing it in Section 2.\n\n*Originality*\nThe paper does not allow to judge whether the three proposed criteria are original or not with respect to the previously proposed ones of [Goodfellow et al. 2009, Lenc & Vedaldi 2015, Cohen & Welling 2014, Jayaraman & Grauman 2015]. \n\n*Significance*\nThe significance of the proposed evaluation framework is not fully clear. The initial assumption of considering factors of variations related to graphics-generated data undermines the relevance of the work. Actually, authors only consider synthetic (noise-free) data belonging to one class only, thus not including the factors of variations related to noise and/or different classes.\n\nPROS: \nThe problem faced by the authors is interesting\n\nCONS:\nThe criteria of disentanglement, informativeness & completeness are not fully clear as they are presented.\nThe proposed criteria are not compared with previously proposed ones - equivariance, invariance and equivalence [Goodfellow et al. 2009, Lenc & Vedaldi 2015, Cohen & Welling 2014, Jayaraman & Grauman 2015]. Thus, it is not possible to elicit from the paper to which extent they are novel or how they are related..\nThe dataset considered is noise-free and considers one class only. Thus, several factors of variation are excluded a priori and this undermines the significance of the analysis.\nThe experimental evaluation only considers two methods, comparing Info-GAN, a state-of-the-art method, with a very basic PCA.\n\n\n**FINAL EVALUATION**\nThe reviewer rates this paper with a weak reject due to the following points.\n1) The novel criteria are not compared with existing ones [Goodfellow et al. 2009, Lenc & Vedaldi 2015, Cohen & Welling 2014, Jayaraman & Grauman 2015].\n2) There are two flaws in the experimental validation:\n\t2.1) The number of methods in comparison (InfoGAN and PCA) is limited.\n\t2.2) A synthetic dataset is only considered.\n\nThe reviewer is favorable in rising the rating towards acceptance if points 1 and 2 will be fixed. \n\n**EVALUATION AFTER AUTHORS' REBUTTAL**\nThe reviewer has read the responses provided by the authors during the rebuttal period. In particular, with respect to the highlighted points 1 and 2, point 1 has been thoroughly answered and the novelty with respect previous work is now clearly stated in the paper. Despite the same level of clarification has not been reached for what concerns point 2, the proposed framework (although still limited in relevance due to the lack of more realistic settings) can be useful for the community as a benchmark to verify the level of disentanglement than newly proposed deep architectures can achieve. Finally, by also taking into account the positive evaluation provided by the fellow reviewers, the rating of the paper has been risen towards acceptance.   \n""]","[-20, 50, -40]","[60, 80, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem and finds the metrics 'reasonable', they also point out limitations and describe the paper as 'somewhat borderline'. The overall tone suggests hesitation about fully endorsing the work. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their concerns as suggestions or questions rather than harsh criticisms. They use phrases like 'I think', 'Could the authors perhaps comment', and 'I could be convinced', which maintain a polite and collaborative tone even while expressing reservations."", ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the paper's relevance, clarity, and commendable effort. They describe the writing as 'lucidly written and very understandable'. However, they also point out areas for improvement and suggest the paper is 'light on comprehensive evaluation', which prevents a higher score. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout. They use phrases like 'I acknowledge', 'commendable amount of effort', and frame criticisms as questions or suggestions rather than direct criticisms. The reviewer maintains a professional and constructive tone, offering specific recommendations for improvement without being harsh or dismissive."", ""The sentiment score is -40 because the review is overall negative, with a 'weak reject' recommendation and several criticisms of the paper's methodology and significance. However, it's not entirely negative as it acknowledges the interesting nature of the problem and offers suggestions for improvement. The politeness score is 20 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They offer constructive feedback and explain their reasoning clearly. The reviewer also shows flexibility by indicating willingness to change their rating if certain issues are addressed, which adds to the politeness. However, the score is not higher as the review is still quite critical and doesn't use overtly polite language or praise.""]"
"[""The paper presents both a novel large dataset of sketches and a new rnn architecture to generate new sketches.\n\n+ new and large dataset\n+ novel algorithm\n+ well written\n- no evaluation of dataset\n- virtually no evaluation of algorithm\n- no baselines or comparison\n\nThe paper is well written, and easy to follow. The presented algorithm sketch-rnn seems novel and significantly different from prior work.\nIn addition, the authors collected the largest sketch dataset, I know of. This is exciting as it could significantly push the state of the art in sketch understanding and generation. \n\nUnfortunately the evaluation falls short. If the authors were to push for their novel algorithm, I'd have expected them to compare to prior state of the art on standard metrics, ablate their algorithm to show that each component is needed, and show where their algorithm shines and where it falls short.\nFor ablation, the bare minimum includes: removing the forward and/or reverse encoder and seeing performance drop. Remove the variational component, and phrasing it simply as an auto-encoder. Table 1 is good, but not sufficient. Training loss alone likely does not capture the quality of a sketch.\nA comparison the Graves 2013 is absolutely required, more comparisons are desired.\nFinally, it would be nice to see where the algorithm falls short, and where there is room for improvement.\n\nIf the authors wish to push their dataset, it would help to first evaluate the quality of the dataset. For example, how well do humans classify these sketches? How diverse are the sketches? Are there any obvious modes? Does the discretization into strokes matter?\nAdditionally, the authors should present a few standard evaluation metrics they would like to compare algorithms on? Are there any good automated metrics, and how well do they correspond to human judgement?\n\nIn summary, I'm both excited about the dataset and new architecture, but at the same time the authors missed a huge opportunity by not establishing proper baselines, evaluating their algorithm, and pushing for a standardized evaluation protocol for their dataset. I recommend the authors to decide if they want to present a new algorithm, or a new dataset and focus on a proper evaluation."", 'This paper introduces a neural network architecture for generating sketch drawings. The authors propose that this is particularly interesting over generating pixel data as it emphasises more human concepts. I agree. The contribution of this paper of this paper is two-fold. Firstly, the paper introduces a large sketch dataset that future papers can rely on. Secondly, the paper introduces the model for generating sketch drawings.\n\nThe model is inspired by the variational autoencoder. However, the proposed method departs from the theory that justifies the variational autoencoder. I believe the following things would be interesting points to discuss / follow up:\n- The paper preliminarily investigates the influence of the KL regularisation term on a validation data likelihood. It seems to have a negative impact for the range of values that are discussed. However, I would expect there to be an optimum. Does the KL term help prevent overfitting at some stage? Answering this question may help understand what influence variational inference has on this model.\n- The decoder model has randomness injected in it at every stage of the RNN. Because of this, the latent state actually encodes a distribution over drawings, rather than a single drawing. It seems plausible that this is one of the reasons that the model cannot obtain a high likelihood with a high KL regularisation term. Would it help to rephrase the model to make the mapping from latent representation to drawing more deterministic? This definitely would bring it closer to the way the VAE was originally introduced.\n- The unconditional generative model *only* relies on the ""injected randomness"" for generating drawings, as the initial state is initialised to 0. This also is not in the spirit of the original VAE, where unconditional generation involves sampling from the prior over the latent space.\n\nI believe the design choices made by the authors to be valid in order to get things to work. But it would be interesting to see why a more straightforward application of theory perhaps *doesn\'t* work as well (or whether it works better). This would help interesting applications inform what is wrong with current theoretical views.\n\nOverall, I would argue that this paper is a clear accept.', 'The paper aims tackles the problem of generate vectorized sketch drawings by using a RNN-variational autoencoder. Each node is represented with (dx, dy) along with one-hot representation of three different drawing status. A bi-directional LSTM is used to encode latent space in the training stage. Auto-regressive VAE is used for decoding. \n\nSimilar to standard VAEs, log-likelihood has bee used as the data-term and the KL divergence between latent space and Gaussian prior is the regularisation term. \n\nPros:\n- Good solution to an interesting problem. \n- Very interesting dataset to be released.\n- Intensive experiments to validate the performance. \n\nCons:\n- I am wondering whether the dataset contains biases regarding (dx, dy). In the data collection stage, how were the points lists generated from pen strokes?  Did each points are sampled from same travelling distance or according to the same time interval?  Are there any other potential biases brought because the data collection tools?\n- Is log-likelihood a good loss here? Think about the case where the sketch is exactly the same but just more points are densely sampled along the pen stroke. How do you deal with this case?\n- Does the dataset contain more meta-info that could be used for other tasks beyond generation, e.g. segmentation, classification, identification, etc.? ']","[-20, 80, 50]","[50, 70, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges positive aspects like the novel dataset and algorithm, they express significant disappointment with the lack of proper evaluation. The review starts positively but becomes increasingly critical, ending with a recommendation for major revisions. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'unfortunately' and 'I recommend' rather than harsh directives, maintaining a professional and constructive tone even when pointing out shortcomings."", ""The sentiment score is 80 (positive) because the reviewer expresses agreement with the paper's approach, describes the contribution as two-fold, and concludes with a 'clear accept' recommendation. The reviewer also offers constructive suggestions for improvement, indicating engagement with the work. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledges the authors' design choices as valid, and frames suggestions as interesting points to discuss rather than criticisms. The reviewer also uses phrases like 'I believe' and 'I would argue' to soften opinions. The score is not 100 as the review maintains a professional tone rather than being overly deferential."", ""The sentiment score is 50 (slightly positive) because the review begins with a neutral description of the paper's approach, followed by a balanced list of pros and cons. The pros highlight the 'good solution', 'interesting dataset', and 'intensive experiments', indicating positive aspects. However, the cons raise important questions and potential issues, balancing out the positive elements. The politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout. They frame their criticisms as questions or wonderings (e.g., 'I am wondering whether...', 'Is log-likelihood a good loss here?') rather than direct criticisms. The reviewer also acknowledges the positive aspects of the work before presenting concerns, which is a polite approach in academic reviews.""]"
"[""This paper proposes a method to learn networks invariant to translation and equivariant to rotation and scale of arbitrary precision. The idea is to jointly train\n- a network predicting a polar origin,\n- a module transforming the image into a log-polar representation according to the predicted origin,\n- a final classifier performing the desired classification task.\nA (not too large) translation of the input image therefore does not change the log-polar representation.\nRotation and scale from the polar origin result in translation of the log-polar representation. As convolutions are translation equivariant, the final classifier becomes rotation and scale equivariant in terms of the input image. Rotation and scale can have arbitrary precision, which is novel to the best of my knowledge.\n\n(+) In my opinion, this is a simple, attractive approach to rotation and scale equivariant CNNs.\n\n(-) The evaluation, however, is quite limited. The approach is evaluated on:\n 1) several variants of MNIST. The authors introduce a new variant (SIM2MNIST), which is created by applying random similitudes to the images from MNIST. This variant is of course very well suited to the proposed method, and a bit artificial.\n 2) 3d voxel occupancy grids with a small resolution. The objects can be rotated around the z-axis, and the method is used to be equivariant to this rotation.\n\n(-) Since the method starts by predicting the polar origin, wouldn't it be possible to also predict rotation and scale? Then the input image could be rectified to a canonical orientation and scale, without needing equivariance. My intuition is that this simpler approach would work better. It should at least be evaluated.\n\nDespite these weaknesses, I think this paper should be interesting for researchers looking into equivariant CNNs.\n"", 'This paper presents a new convolutional network architecture that is invariant to global translations and equivariant to rotations and scaling. The method is combination of a spatial transformer module that predicts a focal point, around which a log-polar transform is performed. The resulting log-polar image is analyzed by a conventional CNN.\n\nI find the basic idea quite compelling. Although this is not mentioned in the article, the proposed approach is quite similar to human vision in that people choose where to focus their eyes, and have an approximately log-polar sampling grid in the retina. Furthermore, dealing well with variations in scale is a long-standing and difficult problem in computer vision, and using a log-spaced sampling grid seems like a sensible approach to deal with it.\n\nOne fundamental limitation of the proposed approach is that although it is invariant to global translations, it does not have the built-in equivariance to local translations that a ConvNet has. Although we do not have data on this, I would guess that for more complex datasets like imagenet / ms coco, where a lot of variation can be reasonably well modelled by diffeomorphisms, this will result in degraded performance.\n\nThe use of the heatmap centroid as the prediction for the focal point is potentially problematic as well. It would not work if the heatmap is multimodal, e.g. when there are multiple instances in the same image or when there is a lot of clutter.\n\nThere is a minor conceptual confusion on page 4, where it is written that ""Group-convolution requires integrability over a group and identification of the appropriate measure dg. We ignore this detail as implementation requires application of the sum instead of integral.""\nWhen approximating an integral by a sum, one should generally use quadrature weights that depend on the measure, so the measure cannot be ignored. Fortunately, in the chosen parameterization, the Haar measure is equal to the standard Lebesque measure, and so when using equally-spaced sampling points in this parameterization, the quadrature weights should be one. (Please double-check this - I\'m only expressing my mathematical intuition but have not actually proven this).\n\nIt does not make sense to say that ""The above convolution requires computation of the orbit which is feasible with respect to the finite rotation group, but not for general rotation-dilations"", and then proceed to do exactly that (in canonical coordinates). Since the rotation-dilation group is 2D, just like the 2D translation group used in ConvNets, this is entirely feasible. The use of canonical coordinates is certainly a sensible choice (for the reason given above), but it does not make an infeasible computation feasible.\n\nThe authors may want to consider citing\n- Warped Convolutions: Efficient Invariance to Spatial Transformations, Henriques & Vedaldi.\nThis paper also uses a log-polar transform, but lacks the focal point prediction / STN.\nLikewise, although the paper makes a good effort to rewiev the literature on equivariance / steerability, it missed several recent works in this area:\n- Steerable CNNs, Cohen & Welling\n- Dynamic Steerable Blocks in Deep Residual Networks, Jacobsen et al.\n- Learning Steerable Filters for Rotation Equivariant CNNs, Weiler et al.\nThe last paper reports 0.71% error on MNIST-rot, which is slightly better than the PTN-CNN-B++ reported on in this paper.\n\nThe experimental results presented in this paper are quite good, but both MNIST and ModelNet40 seem like simple / toyish datasets. For reasons outlined above, I am not convinced that this approach in its current form would work very well on more complicated problems. If the authors can show that it does (either in its current form or after improving it, e.g. with multiple saccades, or other improvements) I would recommend this paper for publication.\n\n\nMinor issues & typos\n- Section 3.1, psi_gh = psi_g psi_h. I suppose you use psi for L and L\', but this is not very clear.\n- L_h f = f(h^{-1}), p. 4\n- ""coordiantes"", p. 5', 'The authors introduce the Polar Transformer, a special case of the Spatial Transformer (Jaderberg et al. 2015) that achieves rotation and scale equivariance by using a log-polar sampling grid. The paper is very well written, easy to follow and substantiates its claims convincingly on variants of MNIST. A weakness of the paper is that it does not attempt to solve a real-world problem. However, I think because it is a conceptually novel and potentially very influential idea, it is a valuable contribution as it stands.\n\nIssues:\n\n- The clutter in SIM2MNIST is so small that predicting the polar origin is essentially trivially solved by a low-pass filter. Although this criticism also applies to most previous work using ‘cluttered’ variants of MNIST, I still think it needs to be considered. What happens if predicting the polar origin is not trivial and prone to errors? These presumably lead to catastrophic failure of the post-transformer network, which is likely to be a problem in any real-world scenario.\n\n- I’m not sure if Section 5.5 strengthens the paper. Unlike the rest of the paper, it feels very ‘quick & dirty’ and not very principled. It doesn’t live up to the promise of rotation and scale equivariance in 3D. If I understand it correctly, it’s simply a polar transformer in (x,y) with z maintained as a linear axis and assumed to be parallel to the axis of rotation. This means that the promise of rotation and scale equivariance holds up only along (x,y). I guess it’s not possible to build full 3D rotation/scale equivariance with the authors’ approach (spherical coordinates probably don’t do the job), but at least the scale equivariance could presumably have been achieved by using log-spaced samples along z and predicting the origin in 3D. So instead of showing a quick ‘hack’, I would have preferred an honest discussion of the limitations and maybe a sketch of a path forward even if no implemented solution is provided.\n']","[20, 20, 60]","[60, 60, 80]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's novel and attractive approach, they also point out significant limitations in the evaluation. The positive aspects ('simple, attractive approach') are balanced against the criticisms ('evaluation, however, is quite limited'). The overall tone suggests the paper has merit but needs improvement.\n\nThe politeness score is moderately positive (60) as the reviewer uses respectful and constructive language throughout. They begin with positive points, use phrases like 'in my opinion' to soften criticisms, and end on a positive note about the paper's potential interest to researchers. The criticisms are presented as objective observations rather than harsh judgments. The reviewer also uses parenthetical (+) and (-) symbols to clearly separate positive and negative points, which is a polite way to structure feedback."", ""The sentiment score is slightly positive (20) because the reviewer finds the basic idea 'quite compelling' and acknowledges the good experimental results. However, they also express several concerns and limitations, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and suggests improvements. They acknowledge the paper's strengths while politely pointing out areas for improvement. The reviewer also uses phrases like 'The authors may want to consider' and 'Please double-check this', which are polite ways of offering suggestions. The tone is professional and academic throughout, without any rudeness or harsh criticism."", ""The sentiment score is 60 (positive) because the reviewer starts by praising the paper as 'very well written, easy to follow' and states that it 'substantiates its claims convincingly'. They also mention it's a 'potentially very influential idea' and 'a valuable contribution'. However, they do point out some weaknesses and issues, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing its limitations. They phrase criticisms as 'Issues' rather than flaws, and use phrases like 'I'm not sure if' and 'I would have preferred' to soften their critiques. The reviewer also offers constructive suggestions, which is a polite way to address perceived shortcomings.""]"
"['Summary: The paper proposes a learnable skimming mechanism for RNN. The model decides whether to send the word to a larger heavy-weight RNN or a light-weight RNN. The heavy-weight and the light-weight RNN each controls a portion of the hidden state. The paper finds that with the proposed skimming method, they achieve a significant reduction in terms of FLOPS. Although it doesn’t contribute to much speedup on modern GPU hardware, there is a good speedup on CPU, and it is more power efficient.\n\nContribution:\n- The paper proposes to use a small RNN to read unimportant text. Unlike (Yu et al., 2017), which skips the text, here the model decides between small and large RNN.\n\nPros:\n- Models that dynamically decide the amount of computation make intuitive sense and are of general interests.\n- The paper presents solid experimentation on various text classification and question answering datasets.\n- The proposed method has shown reasonable reduction in FLOPS and CPU speedup with no significant accuracy degradation (increase in accuracy in some tasks).\n- The paper is well written, and the presentation is good.\n\nCons:\n- Each model component is not novel. The authors propose to use Gumbel softmax, but does compare other gradient estimators. It would be good to use REINFORCE to do a fair comparison with (Yu et al., 2017 ) to see the benefit of using small RNN.\n- The authors report that training from scratch results in unstable skim rate, while Half pretrain seems to always work better than fully pretrained ones. This makes the success of training a bit adhoc, as one need to actively tune the number of pretraining steps.\n- Although there is difference from (Yu et al., 2017), the contribution of this paper is still incremental.\n\nQuestions:\n- Although it is out of the scope for this paper to achieve GPU level speedup, I am curious to know some numbers on GPU speedup.\n- One recommended task would probably be text summarization, in which the attended text can contribute to the output of the summary.\n\nConclusion:\n- Based on the comments above, I recommend Accept', 'This paper proposes a skim-RNN, which skims unimportant inputs with a small RNN while normally processes important inputs with a standard RNN for fast inference.\n\nPros.\n-\tThe idea of switching small and standard RNNs for skimming and full reading respectively is quite simple and intuitive.\n-\tThe paper is clearly written with enough explanations about the proposal method and the novelty.\n-\tOne of the most difficult problems of this approach (non-differentiable) is elegantly solved by employing gumbel-softmax\n-\tThe effectiveness (mainly inference speed improvement with CPU) is validated by various experiments. The examples (Table 3 and Figure 6) show that the skimming process is appropriately performed (skimmed unimportant words while fully read relevant words etc.)\nCons.\n-\tThe idea is quite simple and the novelty is incremental by considering the difference from skip-RNN.\n-\tNo comments about computational costs during training with GPU (it would not increase the computational cost so much, but gumbel-softmax may require more iterations).\n\nComments:\n-\tSection 1, Introduction, 2nd paragraph: ‘peed’ -> ‘speed’(?)\n-\tEquation (5): It would be better to explain why it uses the Gumbel distribution. To make (5) behave like argmax, only temperature parameter seems to be enough.\n-\tSection 4.1: What is “global training step”?\n-\tSection 4.2, “We also observe that the F1 score of Skim-LSTM is more stable across different configurations and computational cost.”: This seems to be very interesting phenomena. Is there some discussion of why skim-LSTM is more stable?\n-\tSection 4.2, the last paragraph: “Table 6 shows” -> “Figure 6 shows”\n', ""The paper proposes a way to speed up the inference time of RNN via Skim mechanism where only a small part of hidden variable is updated once the model has decided a corresponding word token seems irrelevant w.r.t. a given task. While the proposed idea might be too simple, the authors show the importance of it via thorough experiments. It also seems to be easily integrated into existing RNN systems without heavy tuning as shown in the experiments. \n\n* One advantage of proposed idea claimed against the skip-RNN is that the Skim-RNN can generate the same length of output sequence given input sequence. It is not clear to me whether the output prediction on those skimmed tokens is made of the full hidden state (updated + copied) or a first few dimensions of the hidden state. I assume that the full hidden states are used for prediction. It is somehow interesting because it may mean the prediction heavily depends on small (d') part of the hidden state. In the second and third figures of Figure 10, the model made wrong decisions when the adjacent tokens were both skimmed although the target token was not skimmed, and it might be related to the above assumption. In this sense, it would be more beneficial if the skimming happens over consecutive tokens (focus on a region, not on an individual token).\n\n* This paper would gain more attention from practitioners because of its practical purpose. In a similar vein, it would be also good to have some comments on training time as well. In a general situation where there is no need of re-training, training time would be meaningless, however, if one requires updating the model on the fly, it would be also meaningful to have some intuition on training time.\n\n* One obvious way to reduce the computational complexity of RNN is to reduce the size of the hidden state. In this sense, it makes this manuscript more comprehensive if there are some comparisons with RNNs with limited-sized hidden dimensions (say 10 or 20). So that readers can check benefits of the skim RNN against skip-RNN and small-sized RNN.\n""]","[70, 70, 60]","[80, 80, 80]","[""The sentiment score is 70 (positive) because the review begins with a summary of the paper's contributions and lists several pros, indicating a generally favorable view. The reviewer acknowledges the paper's solid experimentation, reasonable results, and good writing. However, it's not 100 because there are some cons mentioned and the contribution is described as 'incremental'. The politeness score is 80 (polite) because the reviewer uses respectful and professional language throughout. They offer constructive criticism and suggestions without harsh or dismissive language. The use of phrases like 'it would be good to' and 'I am curious to know' show a collaborative and respectful tone. The conclusion recommends acceptance, further indicating a positive and polite approach."", 'The sentiment score is 70 (positive) because the review starts with a clear list of pros that outweigh the cons. The reviewer highlights several positive aspects such as the simplicity and intuitiveness of the idea, clear writing, elegant problem-solving, and validated effectiveness. The cons are relatively minor, mentioning incremental novelty and lack of GPU training cost information. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They provide balanced feedback, acknowledging both strengths and areas for improvement. The comments section offers specific, helpful suggestions for enhancing the paper without using harsh or critical language. The overall tone is professional and supportive, aimed at improving the work rather than criticizing it.', ""The sentiment score is 60 (positive) because the reviewer acknowledges the importance of the proposed idea and its potential for easy integration, despite noting it might be 'too simple'. They also commend the thorough experiments. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offering constructive feedback and suggestions without harsh criticism. They use phrases like 'it would be more beneficial' and 'it would be also good to have' when making recommendations, which maintains a polite and professional tone.""]"
"['This paper proposes two contributions: first, applying CNNs+self-attention modules instead of LSTMs, which could result in significant speedup and good RC performance; second, enhancing the RC model training with passage paraphrases generated by a neural paraphrasing model, which could improve the RC performance marginally.\n\nFirstly, I suggest the authors rewrite the end of the introduction. The current version tends to mix everything together and makes the misleading claim. When I read the paper, I thought the speeding up mechanism could give both speed up and performance boost, and lead to the 82.2 F1. But it turns out that the above improvements are achieved with at least three different ideas: (1) the CNN+self-attention module; (2) the entire model architecture design; and (3) the data augmentation method. \n\nSecondly, none of the above three ideas are well evaluated in terms of both speedup and RC performance, and I will comment in details as follows:\n\n(1) The CNN+self-attention was mainly borrowing the idea from (Vaswani et al., 2017a) from NMT to RC. The novelty is limited but it is a good idea to speed up the RC models. However, as the authors hoped to claim that this module could contribute to both speedup and RC performance, it will be necessary to show the RC performance of the same model architecture, but replacing the CNNs with LSTMs. Only if the proposed architecture still gives better results, the claims in the introduction can be considered correct.\n\n(2) I feel that the model design is the main reason for the good overall RC performance. However, in the paper there is no motivation about why the architecture was designed like this. Moreover, the whole model architecture is only evaluated on the SQuAD dataset. As a result, it is not convincing that the system design has good generalization. If in (1) it is observed that using LSTMs in the model instead of CNNs could give on par or better results, it will be necessary to test the proposed model architecture on multiple datasets, as well as conducting more ablation tests about the model architecture itself.\n\n(3) I like the idea of data augmentation with paraphrasing. Currently, the improvement is only marginal, but there seems many other things to play with. For example, training NMT models with larger parallel corpora; training NMT models with different language pairs with English as the pivot; and better strategies to select the generated passages for data augmentation.\n\nI am looking forward to the test performance of this work on SQuAD.', 'This paper presents a reading comprehension model using convolutions and attention. This model does not use any recurrent operation but it is not per se simpler than a recurrent model. Furthermore, the authors proposed an interesting idea to augment additional training data by paraphrasing based on off-the-shelf neural machine translation.  On SQuAD dataset, their results show some small improvements using the proposed augmentation technique. Their best results, however, do not outperform the best results reported on the leader board.\n\nOverall, this is an interesting study on SQuAD dataset. I would like to see results on more datasets and more discussion on the data augmentation technique. At the moment, the description in section 3 is fuzzy in my opinion. Interesting information could be:\n- how is the performance of the NMT system? \n- how many new data points are finally added into the training data set?\n- what do ‘data aug’ x 2 or x 3 exactly mean?\n', 'Summary:\n\nThis paper proposes a non-recurrent model for reading comprehension which used only convolutions and attention. The goal is to avoid recurrent which is sequential and hence a bottleneck during both training and inference. Authors also propose a paraphrasing based data augmentation method which helps in improving the performance. Proposed method performs better than existing models in SQuAD dataset while being much faster in training and inference.\n\nMy Comments:\n\nThe proposed model is convincing and the paper is well written.\n\n1. Why don’t you report your model performance without data augmentation in Table 1? Is it because it does not achieve SOTA? The proposed data augmentation is a general one and it can be used to improve the performance of other models as well. So it does not make sense to compare your model + data augmentation against other models without data augmentation. I think it is ok to have some deterioration in the performance as you have a good speedup when compared to other models.\n\n2. Can you mention your leaderboard test accuracy in the rebuttal?\n\n3. The paper can be significantly strengthened by adding at least one more reading comprehension dataset. That will show the generality of the proposed architecture. Given the sufficient time for rebuttal, I am willing to increase my score if authors report results in an additional dataset in the revision.\n\n4. Are you willing to release your code to reproduce the results?\n\n\nMinor comments:\n\n1. You mention 4X to 9X for inference speedup in abstract and then 4X to 10X speedup in Intro. Please be consistent.\n2. In the first contribution bullet point, “that exclusive built upon” should be “that is exclusively built upon”.\n']","[-20, 50, 50]","[50, 75, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('good idea', 'I like the idea'), they express several criticisms and concerns about the paper's claims, methodology, and evaluation. The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive feedback, and expresses interest in future results ('I am looking forward to the test performance'). They also use phrases like 'I suggest' and 'it will be necessary' rather than more forceful language. The reviewer maintains a professional tone while clearly communicating areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as 'interesting' and acknowledges some improvements, but also points out limitations and areas for improvement. The tone is generally positive, but not overwhelmingly so. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' contributions, and frames suggestions as requests for more information rather than criticisms. Phrases like 'I would like to see' and 'Interesting information could be' contribute to the polite tone. The reviewer also balances positive comments with constructive feedback in a professional manner."", ""The sentiment score is 50 (slightly positive) because the reviewer states 'The proposed model is convincing and the paper is well written,' indicating a generally positive view. However, they also provide several suggestions for improvement and request additional results, which tempers the overall positivity. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrases suggestions as questions or polite requests (e.g., 'Can you mention...', 'Are you willing to...'), and even offers to increase their score if the authors address certain points. The tone is constructive and encouraging rather than critical or demanding.""]"
"[""This paper presents the comparison of a list of algorithms for contextual bandit with Thompson sampling subroutine. The authors compared different methods for posterior estimation for Thompson sampling. Experimental comparisons on contextual bandit settings have been performed on a simple simulation and quite a few real datasets.\n\nThe main paper + appendix are clearly written and easy to understand. The main paper itself is very incomplete. The experimental results should be summarized and presented in the main context. There is a lack of novelty of this study. Simple comparisons of different posterior estimating methods do not provide insights or guidelines for contextual bandit problem. \n\nWhat's the new information provided by running such methods on different datasets? What are the newly observed advantages and disadvantages of them? What could be the fundamental reasons for the variety of behaviors on different datasets? No significant conclusions are made in this work.\n\nExperimental results are not very convincing. There are lots of plots show linear cumulative regrets within the whole time horizon. Linear regrets represent either trivial methods or not long enough time horizon.\n"", 'If two major questions below are answered affirmatively, I believe this article could be very good contribution to the field and deserve publication in ICLR.\n\nIn this article the authors provide a service to the community by comparing the current most used algorithms for Thompson Sampling-based contextual (parametric) bandits on clear empirical benchmark. They reimplement the key algorithms, investing time to make up for the lack of published source code for some. \n\nAfter a clear exposure of the reasons why Thompson Sampling is attractive, they overview concisely the key ideas behind 7 different families of algorithms, with proper literature review. They highlight some of the subtleties of benchmarking bandit problems (or any active learning algorithms for that matter): the lack of counterfactual and hence the difference in observed datasets. They explain their benchmark framework and datasets, then briefly summarise the results for each class of algorithms. Most of the actual measures from the benchmark are provided in a lengthy appendix 12 pages appendix choke-full of graphs and tables.\n\nIt is refreshing to see an article that does not boast to offer the new ""bestest-ever"" algorithm in town, overcrowding a landscape, but instead tries to prune the tree of possibilities and wading through other people\'s inflated claims. To the authors: thank you! It is too easy to dismiss these articles as ""pedestrian non-innovative groundwork"": if there were more like it, our field would certainly be more readable and less novelty-prone.\n\nOf course, there is no perfect benchmark, and like every benchmark, the choices made by the authors could be debated to no end. At least, the authors try to explain them, and the tradeoffs they faced, as clearly as possible (except for two points mentioned below), which again is too rare in our field. \n\nMajor clarifications needed:\n\nMy two key questions are:\n* Is the code of good quality, with exact  reproducibility and good potential extension in a standard language (e.g. Python)? This benchmark only gets its full interest if the code is publicised and well engineered. The open-sourcing is planned, according to footnote 1, is planned -- but this should be made clearer in the main text. There is no discussion of the engineering quality, not even of the language used, and this is quite important if the authors want the community to build upon this work. The code was not submitted for review, and as such its accessibility to new contributors is unknown to this reviewer. That could be a make or break feature of this work. \n* Is the hyper parameter tuning reproducible? Hyperparameter tuning should be discussed much more clearly (in the Appendix): while I appreciate the discussion page 8 of how they were frozen across datasets, ""they were chosen through careful tuning"" is way too short. What kind of tuning? Was it  manual, and hence not reproducible? Or was it a clear, reproducible grid search or optimiser? I thoroughly hope for the later, otherwise an unreproducible benchmark would be very \n\nIf the answers to the two questions above is ""YES"", then brilliant article, I am ready to increase my score. However, if either is a ""NO"", I am afraid that would limit to how much this benchmark will serve as a reference (as opposed to ""just one interesting datapoint"").\n\n\nMinor improvements:\n* Please proofread some obvious typos: \n  - page 4 ""suggesed"" -> ""suggested"",  \n  - page 8 runaway math environment wreaking the end of the sentence.\n  - reference ""Meire Fortunato (2017)"" should be  ""Fortunato et al. (2017)"", throughout.\n* Improve readability of figures\' legends, e.g. Figure 2.(b) key is un-readable. \n* A simple table mapping the name of the algorithm to the corresponding article is missing. Not everyone knows what BBB and BBBN stands for.\n* A measure of wall time would be needed: while computational cost is often mentioned (especially as a drawback to getting proper performance out of variational inference), it is nowhere plotted. Of course that would partly depend on the quality of the implementation, but this is somewhat mitigated if all the algorithms have been reimplemented by the authors (is that the case? please clarify).', 'The paper ""DEEP BAYESIAN BANDITS SHOWDOWN"" proposes a comparative study about bandit approaches using deep neural networks. \n\nWhile I find that such a study is a good idea, and that I was really interested by the listing of the different possibilities in the algorithms section, I regret that the experimental results given and their analysis do not allow the reader to well understand the advantages and issues of the approaches. The given discussion is not enough connected to the presented results from my point of view and it is difficult to figure out what is the basis of some conclusion.\n\nAlso, the considered algorithms are not enough described to allow the reader to have enough insights to fully understand the proposed arguments. Maybe authors should have focused on less algorithms but with more implementation details. Also, what does not help is that it is very hard to conect the names in the result table with the corresponding approaches (some abbreviations are not defined at all - BBBN or RMS for instances).\n\nAt last, the experimental protocol should be better described. For instance it is not clear on how the regret is computed : is it based on the best expectation (as done in most os classical studies) or on the best actual score of actions? The wheel bandit protocol is also rather hard to follow (and where is the results analysis?).\n\nOther remarks:\n   - It is a pitty that expectation propagation approaches have been left aside since they correspond to an important counterpart to variational ones. It would have been nice to get a comparaison of both; \n   - Variational inference decsription in section algorithms is not enough developped w.r.t. the importance of this family of approaches\n   - Neural Linear is strange to me. Uncertainty does not consider the neural representation of inputs ? How does it work then ?\n   - That is strange that \\Lambda_0 and \\mu_0 do not belong to the stated asumptions in the linear methods part (ok they correspond to some  prior but it should be clearly stated)\n   - Figure 1 is referenced very late (after figure 2)\n\n\n']","[-50, 70, -30]","[20, 80, 20]","[""The sentiment score is -50 because while the reviewer acknowledges that the paper is clearly written and easy to understand, they express significant criticisms. They point out a lack of novelty, incomplete presentation of results in the main paper, and unconvincing experimental results. The reviewer also states that no significant conclusions are made, which is a strong negative point. However, the review isn't entirely negative, as it does mention some positive aspects, hence the score isn't at the extreme negative end.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout and begins with some positive comments about the clarity of writing. They express their criticisms in a direct but not rude manner, using phrases like 'There is a lack of' rather than more confrontational language. The reviewer asks questions to prompt the authors to think about improvements rather than making harsh statements. However, the politeness is not overly effusive, maintaining a neutral to slightly positive tone, hence the modest positive score."", ""The sentiment score is 70 (positive) because the reviewer expresses appreciation for the authors' work, calling it a 'very good contribution' and 'refreshing.' They thank the authors and praise the clarity of explanations. However, it's not 100 due to some major clarifications needed. The politeness score is 80 because the reviewer uses respectful language throughout, expresses gratitude, and frames criticisms constructively. They use phrases like 'thank you' and 'please,' and offer encouragement. The score isn't 100 as the review maintains a professional tone rather than being overly deferential. The reasoning is based on the overall positive tone, constructive feedback, and polite phrasing used throughout the review."", ""The sentiment score is -30 because while the reviewer acknowledges that the study is a good idea and shows interest in parts of it, they express several significant criticisms. They regret the lack of depth in the experimental results and analysis, find the discussion insufficient, and point out issues with algorithm descriptions and experimental protocol. The overall tone suggests disappointment with the paper's execution despite its potential.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I find that,' 'I regret that,' and 'Maybe authors should have' which soften the criticism. The reviewer also acknowledges positive aspects before presenting criticisms. However, the score is not higher because the review is direct in its criticisms without excessive softening language, maintaining a balance between politeness and frankness.""]"
"[""Summary and significance: The authors prove that for expressing simple multivariate monomials over n variables, networks of depth 1 require exp(n) many neurons, whereas networks of depth n can represent these monomials using only O(n) neurons. \nThe paper provides a simple and clear explanation for the important problem of theoretically explaining the power of deep networks, and quantifying the improvement provided by depth.\n\n+ves:\nExplaining the power of depth in NNs is fundamental to an understanding of deep learning. The paper is very easy to follow. and the proofs are clearly written. The theorems provide exponential gaps for very simple polynomial functions.\n\n-ves:\n1. My main concern with the paper is the novelty of the contribution to the techniques. The results in the paper are more general than that of Lin et al., but the proofs are basically the same, and it's difficult to see the contribution of this paper in terms of the contributing fundamentally new ideas. \n2. The second concern is that the results apply only to non-linear activation functions with sufficiently many non-zero derivatives (same requirements as for the results of Lin et al.).\n3. Finally, in prop 3.3, reducing from uniform approximations to Taylor approximations, the inequality |E(δx)| <= δ^(d+1) |N(x) - p(x)| does not follow from the definition of a Taylor approximation.\n\nDespite these criticisms, I contend that the significance of the problem, and the clean and understandable results in the paper make it a decent paper for ICLR."", 'Experimental results have shown that deep networks (many hidden layers) can approximate more complicated functions with less neurons compared to shallow (single hidden layer) networks. \nThis paper gives an explicit proof when the function in question is a sparse polynomial, ie: a polynomial in n variables, which equals a sum J of monomials of degree at most c. \nIn this setup, Theorem 4.3 says that a shallow network need at least ~ (1 + c/n)^n many neurons, while the optimal deep network (whose depth is optimized to approximate this particular input polynomial) needs at most  ~ J*n, that is, linear in the number of terms and the number of variables. The paper also has bounds for neural networks of a specified depth k (Theorem 5.1), and the authors conjecture this bound to be tight (Conjecture 5.2). \n\nThis is an interesting result, and is an improvement over Lin 2017 (where a similar bound is presented for monomial approximation). \nOverall, I like the paper.\n\nPros: new and interesting result, theoretically sound. \nCons: nothing major.\nComments and clarifications:\n* What about the ability of a single neural network to approximate a class of functions (instead of a single p), where the topology is fixed but the network weights are allowed to vary? Could you comment on this problem?\n* Is the assumption that \\sigma has Taylor expansion to order d tight? (That is, are there counter examples for relaxations of this assumption?) \n* As noted, the assumptions of your theorems 4.1-4.3 do not apply to ReLUs, but ReLUs network perform well in practice. Could you provide some further comments on this?\n\n', ""The paper investigates the representation of polynomials by neural networks up to a certain degree and implied uniform approximations. It shows exponential gaps between the width of shallow and deep networks required for approximating a given sparse polynomial. \n\nBy focusing on polynomials, the paper is able to use of a variety of tools (e.g. linear algebra) to investigate the representation question. Results such as Proposition 3.3 relate the representation of a polynomial up to a certain degree, to the approximation question. Here it would be good to be more specific about the domain, however, as approximating the low order terms certainly does not guarantee a global uniform approximation. \n\nTheorem 3.4 makes an interesting claim, that a finite network size is sufficient to achieve the best possible approximation of a polynomial (the proof building on previous results, e.g. by Lin et al that I did not verify). The idea being to construct a superposition of Taylor approximations of the individual monomials. Here it would be good to be more specific about the domain. Also, in the discussion of Taylor series, it would be good to mention the point around which the series is developed, e.g. the origin. \n\nThe paper mentions that ``the theorem is false for rectified linear units (ReLUs), which are piecewise linear and do not admit a Taylor series''. However, a ReLU can also be approximated by a smooth function and a Taylor series. \n\nTheorem 4.1 seems to be implied by Theorem 4.2. Similarly, parts of Section 4.2 seem to follow directly from the previous discussion. \n\nIn page 1 ```existence proofs' without explicit constructions'' This is not true, with numerous papers providing explicit constructions of functions that are representable by neural networks with specific types of activation functions. \n\n""]","[50, 80, 20]","[70, 70, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the significance of the problem and the clarity of the paper, calling it a 'decent paper for ICLR'. However, they also express concerns about novelty and some technical aspects, balancing out the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging positives before presenting criticisms, and uses phrases like 'My main concern' and 'Despite these criticisms' to soften their critique. The reviewer maintains a professional tone without using harsh or dismissive language."", ""The sentiment score is 80 (positive) because the reviewer expresses a clear positive sentiment towards the paper. They state 'Overall, I like the paper' and list 'new and interesting result, theoretically sound' as pros, with no major cons. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's contributions, and frames their comments as questions or suggestions rather than criticisms. The reviewer's tone is professional and constructive, offering thoughtful comments and asking for clarifications without being overly effusive or deferential."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting claims and thorough investigation of polynomial representation by neural networks. However, they also point out several areas for improvement and clarification, which prevents a higher positive score. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or dismissive comments. They use phrases like 'it would be good to' when suggesting improvements, which maintains a polite tone. The reviewer also acknowledges the paper's strengths, such as its 'interesting claim' in Theorem 3.4, before offering suggestions for enhancement. The balance of positive acknowledgment and constructive criticism contributes to the overall polite tone of the review.""]"
"['This paper presents an exploration method for model-free RL that generalizes the counter-based exploration bonus methods and takes into account long term exploratory value of actions rather than a single step look-ahead. This generalization is achieved by relying on the convergence rate of SARSA updates on an auxiliary MDP.\n\nThe method presented in the paper trains a parallel ""E-value"" MDP, with initial value of 1 for all state-action pairs. It applies SARSA (on-policy) update rule to the E-value MDP, where the acting policy is selected on the original MDP. While the E-value MDP is training, the proposed method uses a 1/log transformation applied to E-values to get the corresponding exploration bonus term for the original MDP. This bonus term is shown to be equivalent counter-based methods for finite MDPs when the discount factor of the E-MDP is set to 0. The paper has minimal theoretical analysis of the proposed algorithm, essentially only showing convergence with infinite visiting. In that regard, the presented method seems like a useful heuristic with anecdotal empirical benefits.\n\nWhat is crucially lacking from the paper is any reference to model-free Bayesian methods that have very similar intuition behind them: taking into account the long term exploratory benefits of actions (passed on through the Bayesian inference). A comparison would have been trivial to do (with a generic non-informative prior) for the finite MPD setting (section 3.4). Even for the function approximation case one could use Gaussian process methods as the Bayesian baseline. There are also several computationally tractable approximations of Bayesian RL that can be used as baseline for empirical analysis.\n\nIt would have also been nice to do some analysis on how the update rule in a function approximation case is affecting the bonus terms. Unlike the finite case, updates to the value of one E-value can change the value for another state-action pair and the convergence could be faster than (1-alpha)^n. Given the lack of any theory on this, an empirical analysis is certainly valuable. (Update: experiment added in the a later revision to study this effect)\n\nNotes:\n- The plots are horrible in a print. I had to zoom 400% into the PDF file to be able to read the plots. Please scale them at least by 200% and use a larger font for the legends.\n\n- Add a minimal description of the initial setup for E-value neural network to section 4.1 (i.e. how the initializing is achieved to have a constant value for all state-action pairs as described in the appendix).\n\n* Note: This review and rating has been partially revised with the updates to the paper after the initial comments. ', 'The paper proposes an approach to exploration based on initializing a value function to 1 everywhere, then letting the value decay back toward zero as the state space is explored. I like the idea a lot. I don\'t really like the paper, though. I\'d really like to see a strong theoretical and/or empirical justification for it, and both are lacking. On the theoretical side, can a bound be proven for this approach, even in the tabular case? On the empirical side, there are more (and more recent!) testbeds that have come to define the field---the mountain car problem is just not sufficient to convincingly argue that the method scales and generalizes. My intuition is that such an approach ought to be effective, but I really want to see additional evidence. Given the availability of so many RL testbeds, I worry that it had been tried but failed.\n\nDetailed comments:\n\n""Where γ is"" -> "", <newline> where γ is"".\n\n""The other alternative"" -> ""The alternative""?\n\n""without learning a model (Mongillo et al., 2014)."": Seems like an odd choice for a citation for model-free RL. Perhaps select \nthe paper that first used the term? Or an RL survey?\n\nRight before Section 1.1, put a period after the Q-learning update equation.\n\n""new states may"" -> ""new states, may"".\n\n""such approaches leads"" -> ""such approaches lead"".\n\n""they still fails"" -> ""they still fail"".\n\n""evaluated with respect only to its immediate outcome"": Not so. Several of the cited papers use counters to determine which \nstates are ""known"" and then solve an MDP to direct exploration past immediate outcomes.\n\n"" exploration bonus(Little & Sommer, 2014)"" -> "" exploration bonus (Little & Sommer, 2014)"".\n\n""n a model-free settings."" -> ""n model-free settings."".\n\n"" Therefore, a satisfying approach for propagating directed exploration in model-free reinforcement learning is still missing. "": I think you should cite http://research.cs.rutgers.edu/~nouri/papers/nips08mre.pdf , which also combines a kind of counter \nidea with function approximation to improve exploration.\n\n""initializing E-values to 1"": I like this idea. I wonder if one could prove bounds similar to the delayed Q-learning algorithm with \nthis approach. It is reminiscent of https://arxiv.org/pdf/1205.2606.pdf , which also drives exploration by beginning with an \noverly optimistic estimate and letting the data (in a function approximation setting) decay the influence of this initialization.\n\n""So after visited n times"" -> ""So after being visited n times"".\n\n""figure 1a"" -> ""Figure 1a"". (And, in other places.)\n\n""An important property of E-values is that it decreases over repetition"" -> ""An important property of E-values is that they decrease over repetition"".\n\n""t utilize counters, can"" -> ""t utilize counters can"".\n\n"" hence we were interested a convergence measure"": Multiple problems in this sentence, please fix.\n\nFigure 2: How many states are in this environment? Some description is needed.\n\nFigure 3: The labels in this figure (and all the figures) are absurdly small and, hence, unreadable.\n\n""now turn to show that by using counters,"" -> ""now turn to showing that, by using counters,"".\n\nTheorem 3.1: I\'m not quite getting why we want to take a stochastic rule and make it deterministic. Note that standard PAC-MDP algorithms choose deterministically. It\'s not clear why we\'d want to start from a stochastic rule.\n\n"" models(Bellemare"" -> "" models (Bellemare"".\n\n""Efficient memory-based learning for robot control"": This reference is incomplete. (I\'m skeptical that it represents the first use of this problem, but I can\'t check it.)\n\n""Softmax exploration fail"" -> ""Softmax exploration fails"".\n\n""whom also analyzed"" -> ""who also analyzed"".\n\n""non-Markovity"" -> ""non-Markovianness""?\n', '\n\nThe paper proposes a novel way for trading of exploration and exploitation in model-free reinforcement learning. The idea is to learn a second (kind of) Q function, which could be called E-function, which captures the value of exploration (E-value). In contrast to the Q-function of the problem at hand, the E-function assumes no preferences among actions. \nThis is makes sense in my opinion as exploration is exactly “no preferences among actions”. \n\nActually, to be more precise, the paper shows that the logarithm of E-Values can be thought of as a generalization of visit counters, with propagation\nof the values along state-action pairs. This is important, as E-values should actually decrease with repetition. Moreover, the paper shows that by using counters for stochastic action-selection rules commonly employed within the RL community, for every stochastic rule there exist equivalent deterministic rules. Once turned to deterministic counter-based rules, it is again possible improve them using E-values. This provides a nice story for a simple (in a positive sense) approach to tackle the exploration-exploitation tradeoff. The experimental results demonstrate this is a sufficient number of domains. To summarize, for an informed outsider such as the reviewer, the paper makes a simple but strong contribution to an important problem. Overall the paper is well writing and structured. ']","[20, -50, 90]","[60, 20, 70]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's contributions and potential benefits, they also point out significant limitations and areas for improvement. The review begins with a neutral description of the paper's content, then highlights both positive aspects ('useful heuristic with anecdotal empirical benefits') and critical points ('crucially lacking', 'minimal theoretical analysis'). The addition of an experiment in a later revision is noted positively.\n\nThe politeness score is moderately high (60) as the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement without using harsh language. The critique is presented in a matter-of-fact manner, focusing on the content rather than making personal comments. The use of phrases like 'It would have been nice' and 'Please scale them' contributes to the polite tone. The reviewer also acknowledges updates made in response to initial comments, showing a fair and collaborative approach."", ""The sentiment score is -50 because while the reviewer likes the initial idea ('I like the idea a lot'), they express significant dissatisfaction with the paper overall ('I don't really like the paper, though'). They point out major shortcomings in both theoretical and empirical justifications, which suggests a generally negative view. The politeness score is 20 because the reviewer uses relatively polite language throughout, such as 'I'd really like to see' and 'My intuition is that', even when criticizing. They also provide detailed, constructive feedback. However, some direct criticisms ('The mountain car problem is just not sufficient') and the overall negative tone prevent a higher politeness score."", ""The sentiment score is 90 (highly positive) because the reviewer expresses strong approval of the paper's contribution, describing it as 'simple but strong' and praising its approach to an 'important problem'. They also commend the paper's writing and structure. The politeness score is 70 (quite polite) as the reviewer uses respectful language throughout, acknowledging their position as an 'informed outsider' and using phrases like 'This makes sense in my opinion' rather than making blunt assertions. The tone is professional and constructive, without any harsh criticism or rude language.""]"
"['The authors use a recurrent neural network to build generative models of sequences in domains where the vast majority of sequences is invalid. The basic idea, outlined in Eq. 2, is moderately straightforward: at each step, use an approximation of the Q function for subsequences of the appropriate length to pick a valid extension. There are numerous details to get right. The writing is mostly clear, and the examples are moderately convincing. I wish the paper had more detailed arguments and discussions.\n\nI question the appropriateness of Eq. 2 as a target. A correctly learned model will put positive weight on valid sequences, but it may be an arbitrarily slow way to generate diverse sequences, depending on the domain. For instance, imagine a domain of binary strings where the valid sequences are the all 1 sequence, or any sequence beginning with a 0. Half the generated sequences would be all 1\'s in this situation, right? And it\'s easy to construct further examples that are much worse than this?\n\nThe use of Bayesian active learning to generate the training set feels like an elegant idea. However, I wish there were more clarity about what was ad hoc and what wasn\'t. For instance, I think the use of  dropout to get q is suspect (see for instance https://arxiv.org/abs/1711.02989), and I\'d prefer a little more detail on statements like ""The nonlinearity of g(·) means that our Monte\nCarlo approximation is biased, but still consistent."" Do we have any way of quantifying the bias? Is the statement about K=16 being reasonable a statement about bias, variance, or both?\n\nFor Python strings: \n- Should we view the fact that high values of tau give a validity of 1.0 as indicative that the domain\'s constraints are fairly easy to learn?\n- ""The use of a Boltzmann policy allows us to tune the temperature parameter to identify policies\nwhich hit high levels of accuracy for any learned Q-function approximation."" This is only true to the extent the domain is sufficiently ""easy"" right? Is the argument that even in very hard domains, you might get this by just having an RNN which memorized a single valid sequence (assuming at least one could be found)?\n- What\'s the best explanation for *why* the active model has much higher diversity? I understand that the active model is picking examples that tell us more about the uncertainty in w, but it\'s not obvious to me that means higher diversity. Do we think this is a universal property of domains?\n- The highest temperature active model is exploring about half of valid sequences (modulo the non-tightness of the bound)? Have you tried gaining some insight by generating thousands of valid sequences manually and seeing which ones the model is rejecting?\n- The coverage bound is used only for for Python expressions, right? Why not just randomly sample a few thousand positives and use that to get a better estimate of coverage? Since you can sample from the true positive set, it seems that your argument from the appendix about the validation set being ""too similar to the training set"" doesn\'t apply?\n- It would be better to see a comparison to a strong non-NN baseline. For instance, I could easily make a PCFG over Python math expressions, and use rejection sampling to get rid of those that aren\'t exactly length 25, etc.?\n\nI question how easy the Python strings example is. In particular, it might be that it\'s quite an easy example (compared to the SMILES) example. For SMILES, it seems like the Bayesian active learning technique is not by itself sufficient to create a good model? It is interesting that in the solubility domain the active model outperforms, but it would be nice to see more discussion / explanation.\n\nMinor note: The incidence of valid strings in the Python expressions domain is (I believe) > 1/5000, although I guess 1 in 10,000 is still the right order of magnitude.\n\nIf I could score between ""marginal accept"" and ""accept"" I would. ', 'SUMMARY:\nThis work is about learning the validity of a sequences in specific application domains like SMILES strings for chemical compounds. In particular, the main emphasis is on predicting if a prefix sequence could possibly be extended to a complete valid sequence. In other words, one tries to predict if there exists a valid suffix sequence, and based on these predictions, the goal is to train a generative model that always produces valid sequences.  In the proposed reinforcement learning setting, a neural network models the probability that a certain action (adding a symbol) will result in a valid full sequence. For training the network, a large set of (validity-)labelled sequences would be needed. To overcome this problem, the authors introduce an active learning strategy, where the information gain is re-expressed as the conditional mutual information between the the label y and the network weights w, and this mutual information is maximized in a greedy sequential manner.    \nEVALUATION:\nCLARITY & NOVELTY: In principle, the paper is easy to read. Unfortunately, however, for the reader is is not easy to find out what the authors consider their most relevant contribution. Every single part of the model seems to be quite standard (basically a network that predicts the probability of a valid sequence and an information-gain based active learning strategy) - so is the specific application to SMILES strings what makes the difference here?   Or is is the specific greedy approximation to the mutual information criterion in the active learning part? Or is it the way how you augment the dataset? All these aspects might be interesting, but somehow I am missing a coherent picture.\nSIGNIFICANCE: it is not entirely clear to me if the proposed ""pruning"" strategy for the completion of prefix sequences can indeed be generally applied to sequence modelling problems, because in more general domains it might be very difficult to come up with reasonable validity estimates for prefixes that are significantly shorter than the whole sequence. I am not so familiar with SMILES strings -- but could it be that the experimental success reported here is mainly a result of the very specific structure of valid SMILES strings?  But then, what can be learned for general sequence validation problems?\n     \nUPDATE: Honestly, outside the scope of SMILES strings, I still have some concerns regarding reasonable validity estimates for prefixes that are significantly shorter than the whole sequence...  \n\n', ""Overall: Authors casted discrete structure generation as a planning task and they used Q-learning + RNNs to solve for an optimal policy to generate valid sequences. They used RNN for sequential state representation and Q-learning for encoding expected value of sub-actions across trajectory - constraining each step's action to valid subsequences that could reach a final sequence with positive reward (valid whole sequences).\n\nEvaluation: The approach centers around fitting a Q function with an oracle that validates sub-sequences. The Q function is supported by a sequence model for state representation. Though the approach seems novel and well crafted, the experiments and results can't inform me which part of the modeling was critical to the results, e.g. was it the (1) LSTM, (2) Q-function fitting? Are there other simpler baseline approaches to compare against the proposed method? Was RL really necessary for the planning task? The lack of a baseline approach for comparison makes it hard to judge both results on Python Expressions and SMILES. The Python table gives me a sense that the active learning training data generation approach provides competitive validity scores with increased discrete space coverage. However the SMILES data set is a little mixed for active vs passive - authors should try to shed some light into that as well.\n\nIn conclusion, the approach seems novel and seem to fit well with the RL planning framework. But the lack of baseline results make it hard to judge significance of the work.""]","[20, -20, -20]","[60, 50, 50]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's merits ('The writing is mostly clear, and the examples are moderately convincing'), they also express several concerns and wish for more detailed arguments. The overall tone suggests a cautious acceptance rather than strong enthusiasm or rejection. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrasing criticisms as questions or suggestions ('I wish the paper had...', 'I question...') rather than direct criticisms. The reviewer also acknowledges positive aspects and uses polite phrases like 'I wish' and 'It would be better to see'. The language is professional and constructive, avoiding any rudeness or harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'easy to read', 'might be interesting'), they express several concerns and uncertainties. The reviewer questions the novelty and significance of the work, and expresses doubts about its general applicability. The update at the end reinforces these concerns. However, the tone is not entirely negative, which is why the score is only slightly below neutral.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They phrase their criticisms as questions or observations rather than direct attacks (e.g., 'it is not entirely clear to me', 'I am missing a coherent picture'). The reviewer also acknowledges potential positives and uses phrases like 'in principle' and 'unfortunately' to soften criticisms. However, the politeness doesn't reach the highest levels as the review doesn't include explicit praise or overly deferential language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty and potential of the approach, they express significant concerns about the lack of baseline comparisons and the inability to determine which aspects of the model were critical to the results. The reviewer concludes that it's 'hard to judge significance of the work' due to these limitations. The politeness score is moderately positive (50) as the reviewer uses respectful and professional language throughout, acknowledging the strengths of the work while constructively pointing out areas for improvement. They use phrases like 'seems novel and well crafted' and 'the approach seems novel' which maintain a polite tone even while expressing criticisms.""]"
"['This paper aims to learn a single policy that can perform a variety of tasks that were experienced sequentially. The approach is to learn a policy for task 1, then for each task k+1: copy distilled policy that can perform tasks 1-k, finetune to task k+1, and distill again with the additional task. The results show that this PLAID algorithm outperforms a network trained on all tasks simultaneously. \n\nQuestions:\n- When distilling the policies, do you start from a randomly initialized policy, or do you start from the expert policy network?\n- What data do you use for the distillation? Section 4.1 states""We use a method similar to the DAGGER algorithm"", but what is your method. If you generate trajectories form the student network, and label them with the expert actions, does that mean all previous expert policies need to be kept in memory?\n- I do not understand the purpose of ""input injection"" nor where it is used in the paper. \n\nStrengths:\n- The method is simple but novel. The results support the method\'s utility.\n- The testbed is nice; the tasks seem significantly different from each other. It seems that no reward shaping is used.\n- Figure 3 is helpful for understanding the advantage of PLAID vs MultiTasker.\n\nWeaknesses:\n- Figure 2: the plots are too small.\n- Distilling may hurt performance ( Figure 2.d)\n- The method lacks details (see Questions above)\n- No comparisons with prior work are provided. The paper cites many previous approaches to this but does not compare against any of them. \n- A second testbed (such as navigation or manipulation) would bring the paper up a notch. \n\nIn conclusion, the paper\'s approach to multitask learning is a clever combination of prior work. The method is clear but not precisely described. The results are promising. I think that this is a good approach to the problem that could be used in real-world scenarios. With some filling out, this could be a great paper.', 'This paper describes PLAID, a method for sequential learning and consolidation of behaviours via policy distillation; the proposed method is evaluated in the context of bipedal motor control across several terrain types, which follow a natural curriculum.\n\nPros:\n- PLAID masters several distinct tasks in sequence, building up “skills” by learning “related” tasks of increasing difficulty.\n- Although the main focus of this paper is on continual learning of “related” tasks, the authors acknowledge this limitation and convincingly argue for the chosen task domain.\n\nCons:\n- PLAID seems designed to work with task curricula, or sequences of deeply related tasks; for this regime, classical transfer learning approaches are known to work well (e.g finetunning), and it is not clear whether the method is applicable beyond this well understood case.\n- Are the experiments single runs? Due to the high amount of variance in single RL experiments it is recommended to perform several re-runs and argue about mean behaviour.\n\nClarifications:\n- What is the zero-shot performance of policies learned on the first few tasks, when tested directly on subsequent tasks?\n- How were the network architecture and network size chosen, especially for the multitasker? Would policies generalize to later tasks better with larger, or smaller networks?\n- Was any kind of regularization used, how does it influence task performance vs. transfer?\n- I find figure 1 (c) somewhat confusing. Is performance maintained only on the last 2 tasks, or all previously seen tasks? That’s what the figure suggests at first glance, but that’s a different goal compared to the learning strategies described in figures 1 (a) and (b).\n', ""Hi, \n\nThis was a nice read. I think overall it is a good idea. But I find the paper lacking a lot of details and to some extend confusing. \nHere are a few comments that I have:\n\nFigure 2 is very confusing for me. Please first of all make the figures much larger. ICLR does not have a strict page limit, and the figures you have are hard to impossible to read. So you train in (a) on the steps task until 350k steps? Is (b), (d),(c) in a sequence or is testing moving from plain to different things? The plot does not explicitly account for the distillation phase. Or at least not in an intuitive way. But if the goal is transfer, then actually PLAID is slower than the MultiTasker because it has an additional cost to pay (in frames and times) for the distillation phase right? Or is this counted. \n\nGoing then to Figure 3, I almost fill that the MultiTasker might be used to simulate two separate baselines. Indeed, because the retention of tasks is done by distilling all of them jointly, one baseline is to keep finetuning a model through the 5 stages, and then at the end after collecting the 5 policies you can do a single consolidation step that compresses all. So it will be quite important to know if the frequent integration steps of PLAID are helpful (do knowing 1,2 and 3 helps you learn 4 better? Or knowing 3 is enough). \n\nWhere exactly is input injection used? Is it experiments from figure 3. What input is injecting? What do you do when you go back to the task that doesn't have the input, feed 0? What happens if 0 has semantics ? \n\nPlease say in the main text that details in terms of architecture and so on are given in the appendix. And do try to copy a bit more of them in the main text where reasonable. \n\nWhat is the role of PLAID? Is it to learn a continual learning solution? So if I have 100 tasks, do I need to do 100-way distillation at the end to consolidate all skills? Will this be feasible? Wouldn't the fact of having data from all the 100 tasks at the end contradict the traditional formulation of continual learning? \n \nOr is it to obtain a multitask solution while maximizing transfer (where you always have access to all tasks, but you chose to sequentilize them to improve transfer)?  And even then maximize transfer with respect to what? Frames required from the environment? If that are you reusing the frames you used during training to distill? Can we afford to keep all of those frames around? If not we have to count the distillation frames as well. Also more baselines are needed. A simple baseline is just finetunning as going from one task to another, and just at the end distill all the policies found through out the way.  Or at least have a good argument of why this is suboptimal compared to PLAID. \n\nI think the idea of the paper is interesting and I'm willing to increase (and indeed decrease) my score. But I want to make sure the authors put a bit more effort into cleaning up the paper, making it more clear and easy to read. Providing at least one more baseline (if not more considering the other things cited by them). \n\n""]","[50, 50, -20]","[80, 75, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as the novel method and promising results, while also pointing out weaknesses and areas for improvement. The overall tone is constructive and suggests potential for a 'great paper' with some additions. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, frames criticisms as questions or suggestions, and concludes with positive encouragement. The reviewer maintains a professional and courteous tone, even when pointing out weaknesses or requesting clarifications."", ""The sentiment score is 50 (slightly positive) because the review begins with a neutral description of the paper and then lists both pros and cons. The pros highlight the method's ability to master several tasks and build up skills, which is positive. However, the cons point out limitations and areas for improvement, balancing the overall sentiment. The politeness score is 75 (fairly polite) because the reviewer uses professional and respectful language throughout. They acknowledge the authors' arguments and use phrases like 'convincingly argue' which shows respect. The cons and clarifications are presented as constructive feedback rather than harsh criticism. The reviewer asks questions for clarification instead of making accusatory statements, which is a polite approach to scientific discourse."", ""The sentiment score is slightly negative (-20) because while the reviewer starts by saying it was a 'nice read' and a 'good idea', they immediately follow with criticisms, stating the paper is 'lacking a lot of details' and is 'confusing'. The bulk of the review consists of questions and requests for clarification or improvement, indicating significant concerns with the current state of the paper. However, the reviewer does express willingness to increase their score if improvements are made, which prevents the score from being more negative. The politeness score is moderately positive (60) because the reviewer uses polite language throughout, such as 'Please', 'I think', and 'I'm willing to'. They also sandwich their criticisms between positive comments at the beginning and end. The tone is constructive rather than harsh, even when pointing out flaws. However, the directness of some criticisms prevents the score from being higher.""]"
"[""In this paper, the expressive power of neural networks characterized by tensor train (TT) decomposition, a chain-type tensor decomposition, is investigated. Here, the expressive power refers to the rank of tensor decomposition, i.e., the number of latent components. The authors compare the complexity of TT-type networks with networks structured by CP decomposition, which corresponds to shallow networks. It is proved that the space of TT-type networks with rank O(r)  can be complex as the same as the space of CP-type networks with rank poly(r).\n\nThe paper is clearly written and easy to follow. \n\nThe contribution is clear and it is distinguished from previous studies.\n\nThough I enjoyed reading this paper, I have several concerns.\n\n1. The authors compare the complexity of TT representation with CP representation (and HT representation). However, CP representation does not have universality (i.e., some tensors cannot be expressed by CP representation with finite rank, see [1]), this comparison may not make sense. It seems the comparison with Tucker-type representation makes much more sense because it has universality. \n\n2. Connecting RNN and TT representation is a bit confusing. Specifically, I found two gaps.\n   (a) RNNs reuse the same parameter against all the input x_1 to x_d. This means that G_1 to G_d in Figure 1 are all the same. That's why RNNs can handle size-varying sequences. \n   (b) Standard RNNs do not use the multilinear units shown in Figure 3, but use a simple addition of an input and the output from the previous layer (i.e., h_t = f(Wx_t + Vh_{t-1}), where h_t is the t-th hidden unit, x_t is the t-th input, W and V are weights, and f is an activation function.) \nDue to the gaps, the analysis used in this paper seems not applicable to RNNs. If this is true, the story of this paper is somewhat misleading. Or, is your theory still applicable?\n\n[1] Hackbusch, Wolfgang. Tensor spaces and numerical tensor calculus. Vol. 42. Springer Science & Business Media, 2012."", 'This paper investigates an expressive power of the tensor train decomposition relative to the CP-decomposition. The result of this paper is interesting and also important from a viewpoint on analysis for the tensor train decomposition.\n\nHowever, I think there is some room for improvement on this paper. Comments are as follow.\n\nC1.\nCould you describe more details about the importance of an irreducible algebraic variety? Especially, it will be nice if authors provide practical examples of tensors in $\\mathcal{M}_r$ and tensors not in $\\mathcal{M}_r$. The present description about $\\mathcal{M}_r$ is too simple and thus I cannot judge whether the restriction on $\\mathcal{M}_r$ is critical or not.\n\nC2. \nI wonder that the experiment for comparing TT-decomposition and CP-decomposition is fair, since CP-decomposition does not have the universal approximation property. Is it possible to conduct numerical experiments for comparing the ranks directly? For example, given a tensor with known CP-rank, could you measure the TT-rank of the tensor? Such experiments will improve persuasiveness of the main result presented in this paper.', 'The authors of this paper first present a class of networks inspired by various tensor decomposition models. Then they focus on one particular decompostion known as the tensor train decomposition and points out an analogy between tensor train networks and recurrent neural networks. Finally the authors show that almost all tensor train networks (exluding a set of measure zero) require exponentially large width to represent in CP networks, which is analogous to shallow networks.\n\nWhile I enjoyed reading the gentle introduction, nice overview of past work, and the theoretical analysis that relates the rank of tensor train networks to that of CP netowkrs, I wasn\'t sure how to translate the finding into the corresponding neural network models, namely, recurrent neural networks and shallow MLPs.\n\nFor example, \n * How does the ""bad"" example (low TT-rank but exponentially large CP-rank) translate into a recurrent neural network?\n * For both TT-networks and CP-networks, there are multilinear interaction of the inputs/previous hidden states. How precise is the analogy? Can we somehow restrict the interactions to additive ones so that we can exactly recover MLPs or RNNs?\n\nI also did not find the experiments illuminating. First of all the authors need to provide more details about how CP or TT networks are applies to MNIST and CIFAR-10 datasets. For example, the number of input patches and the number of hidden units, etc. In addition, I would like to see the performance of RNNs and MLPs with the same number of units/rank in order to validate the analogy between these networks. Finally I think it makes sense to try some sequence datasets for which RNNs are typically used.\n\nMinor comments:\n * In p7 it would help readers to point out that B^{(s,t)} is an algebraic subset because it is an intersection of M_r and the set of matrices of rank at most q^{d/2} - 1, which is known to be algebraic.']","[-20, 50, -20]","[60, 80, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is clearly written and easy to follow', 'The contribution is clear'), they express 'several concerns' and point out potential flaws in the paper's approach and comparisons. This indicates a overall slightly negative sentiment towards the paper's content. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames their concerns as questions or suggestions rather than harsh criticisms. Phrases like 'I enjoyed reading this paper' and the use of 'may' and 'seems' when expressing concerns contribute to the polite tone. The reviewer also provides specific references and explanations for their concerns, which is a constructive approach."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by acknowledging the paper's interesting and important results, but then mentions there is 'room for improvement'. This indicates a balanced view with a slight positive lean. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, such as 'Could you describe...', 'it will be nice if...', and 'I wonder...'. The reviewer also frames criticisms as suggestions for improvement rather than direct criticisms. The overall tone is constructive and courteous, maintaining a professional and respectful demeanor throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer mentions enjoying parts of the paper ('I enjoyed reading the gentle introduction, nice overview of past work, and the theoretical analysis'), they express significant concerns and uncertainties about the paper's content and experiments. The reviewer asks several questions indicating gaps in understanding or explanation, and states that they 'did not find the experiments illuminating.' These critiques outweigh the initial positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledging positive aspects of the paper, and framing criticisms as questions or suggestions rather than direct attacks. Phrases like 'I enjoyed reading' and 'it would help readers' contribute to the polite tone. The reviewer also provides constructive feedback and specific recommendations for improvement, which is a polite and professional approach in academic peer review.""]"
"['The authors propose to train neural networks with 1bit weights by storing and updating full precision weights in training, but using the reduced 1bit version of the network to compute predictions and gradients in training. They add a few tricks to keep the optimization numerically efficient. Since right now more and more neural networks are deployed to end users, the authors make an interesting contribution to a very relevant question.\n\nThe approach is precisely described although the text sometimes could be a bit clearer (for example, the text contains many important references to later sections).\n\nThe authors include a few other methods for comparision, but I think it would be very helpful to include also some methods that use a completely different approach to reduce the memory footprint. For example, weight pruning methods sometimes can give compression rates of around 100 while the 1bit methods by definition are limited to a compression rate of 32. Additionally, for practical applications, methods like weight pruning might be more promising since they reduce both the memory load and the computational load.\n\nSide mark: the manuscript has quite a few typos.\n', 'This paper introduces several ideas: scaling, warm-restarting learning rate, cutout augmentation. \n\nI would like to see detailed ablation studies: how the performance is influenced by the warm-restarting learning rates, how the performance is influenced by cutout. Is the scaling scheme helpful for existing single-bit algorithms?\n\nQuestion for Table 3: 1-bit WRN 20-10 (this paper) outperforms WRN 22-10 with the same #parameters on C100. I would like to see more explanations. \n', 'The paper trains wide ResNets for 1-bit per weight deployment.\nThe experiments are conducted on CIFAR-10, CIFAR-100, SVHN and ImageNet32.\n\n+the paper reads well\n+the reported performance is compelling \n\nPerhaps the authors should make it clear in the abstract by replacing:\n""Here, we report methodological innovations that result in large reductions in error rates across multiple datasets for deep convolutional neural networks deployed using a single bit for each weight""\nwith\n""Here, we report methodological innovations that result in large reductions in error rates across multiple datasets for wide ResNets deployed using a single bit for each weight""\n\nI am curious how the proposed approach compares with SqueezeNet (Iandola et al.,2016) in performance and memory savings.\n\n']","[50, 0, 70]","[60, 50, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the interesting contribution and relevance of the work, but also points out areas for improvement and some criticisms. The politeness score is 60 (moderately polite) as the reviewer uses respectful language, offers constructive feedback, and balances positive comments with suggestions for improvement. The reviewer's tone is professional and courteous throughout, even when mentioning typos or suggesting additional comparisons."", ""The sentiment score is 0 (neutral) because the reviewer neither explicitly praises nor criticizes the paper. They introduce the paper's main ideas neutrally and then request additional information and explanations, which is typical in academic reviews. The politeness score is 50 (somewhat polite) because the reviewer uses respectful language like 'I would like to see' when making requests for additional information. They don't use harsh or critical language, but also don't use overtly polite phrases, maintaining a professional and neutral tone throughout."", ""The sentiment score is 70 (positive) because the reviewer explicitly mentions two positive aspects of the paper: it 'reads well' and has 'compelling' performance. There are no negative comments, only suggestions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering suggestions rather than demands ('Perhaps the authors should...'), and expressing curiosity about comparisons with other work. The reviewer also acknowledges the paper's strengths before offering suggestions, which is a polite approach to feedback.""]"
"['This paper proposes training binary and ternary weight distribution networks through the local reparametrization trick and continuous optimization. The argument is that due to the central limit theorem (CLT) the distribution on the neuron pre-activations is approximately Gaussian, with a mean given by the inner product between the input and the mean of the weight distribution and a variance given by the inner product between the squared input and the variance of the weight distribution. As a result, the parameters of the underlying discrete distribution can be optimized via backpropagation by sampling the neuron pre-activations with the reparametrization trick. The authors further propose appropriate initialisation schemes and regularization techniques to either prevent the violation of the CLT or to prevent underfitting. The method is evaluated on multiple experiments.\n\nThis paper proposed a relatively simple idea for training networks with discrete weights that seems to work in practice. My main issue is that while the authors argue about novelty, the first application of CLT for sampling neuron pre-activations at neural networks with discrete r.v.s is performed at [1]. While [1] was only interested in faster convergence and not on optimization of the parameters of the underlying distribution, the extension was very straightforward. I would thus suggest that the authors update the paper accordingly. \n\nOther than that, I have some other comments:\n- The L2 regularization on the distribution parameters for the ternary weights is a bit ad-hoc; why not penalise according to the entropy of the distribution which is exactly what you are trying to achieve? \n- For the binary setting you mentioned that you had to reduce the entropy thus added a “beta density regulariser”. Did you add R(p) or log R(p) to the objective function? Also, with alpha, beta = 2 the beta density is unimodal with a peak at p=0.5; essentially this will force the probabilities to be close to 0.5, i.e. exactly what you are trying to avoid. To force the probability near the endpoints you have to use alpha, beta < 1 which results into a “bowl” shaped Beta distribution. I thus wonder whether any gains you observed from this regulariser are just an artifact of optimization.  \n- I think that a baseline (at least for the binary case) where you learn the weights with a continuous relaxation, such as the concrete distribution, and not via CLT would be helpful. Maybe for the network to properly converge the entropy for some of the weights needs to become small (hence break the CLT). \n\n[1] Wang & Manning, Fast Dropout Training.\n\nEdit: After the authors rebuttal I have increased the rating of the paper: \n- I still believe that the connection to [1] is stronger than what the authors allude to; eg. the first two paragraphs of sec. 3.2 could easily be attributed to [1].\n- The argument for the entropy was to include a term (- lambda * H(p)) in the objective function with H(p) being the entropy of the distribution p. The lambda term would then serve as an indicator to how much entropy is necessary.\n- There indeed was a misunderstanding with the usage of the R(p) regularizer at the objective function (which is now resolved).\n- The authors showed benefits compared to a continuous relaxation baseline.', 'Summary of the paper:\nThe paper suggests to use stochastic parameters in combination with the local reparametrisation trick (previously introduced by Kingma et al. (2015)) to train neural networks with binary or ternary wights. Results on MNIST, CIFAR-10 and ImageNet are very competitive. \n\nPros:\n- The proposed method leads to state of the art results .\n- The paper is easy to follow and clearly describes the implementation details needed to reach the results. \n\nCons:\n- The local reprarametrisation trick it self is not new and applying it to a multinomial distribution (with one repetition) instead of a Gaussian is straight forward, but its application for learning discrete networks is to my best knowledge novel and interesting. \n\nIt could be nice to include the results of Zuh et al (2017) in the results table and to indicate the variance for different samples of weights resulting from your methods in brackets. \n\n\nMinor comments:\n- Some citations have a strange format: e.g. “in Hubara et al. (2016); Restegari et al. (2016)“ would be better readable as   “by Hubara et al. (2016) and Restegari et al. (2016)“\n-  To improve notation, it could be directly written that W is the set of all w^l_{i,j} and \\mathcal{W} is the joint distribution resulting from independently sampling from  \\mathcal{W}^l_{i,j}. \n- page 6: “on the last full precision network”: should probably be “on the last full precision layer”\n                    “ distributions has” ->  “ distributions have” \n', 'This paper introduces the LR-Net, which uses the reparametrization trick inspired by a similar component in VAE. Although the idea of reparametrization itself is not new, applying that for the purpose of training a binary or ternary network, and sample the pre-activations instead of weights is novel.  From the experiments, we can see that the proposed method is effective. \n\nIt seems that there could be more things to show in the experiments part. For example, since it is using a multinomial distribution for weights, it makes sense to see the entropy w.r.t. training epochs. Also, since the reparametrization is based on the Lyapunov Central Limit Theorem, which assumes statistical independence, a visualization of at least the correlation between the pre-activation of each layer would be more informative than showing the histogram. \n\nAlso, in the literature of low precision networks, people are concerning both training time and test time computation demand. Since you are sampling the pre-activations instead of weights, I guess this approach is also able to reduce training time complexity by an order. Thus a calculation of train/test time computation could highlight the advantage of this approach more boldly. ']","[20, 70, 60]","[60, 80, 70]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's contribution ('relatively simple idea... that seems to work in practice'), they raise several concerns and suggest improvements. The initial criticism about novelty is somewhat mitigated by the reviewer's edit after the authors' rebuttal, indicating an improved opinion. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and acknowledges the authors' responses. They use phrases like 'I would suggest' and 'I think that' which maintain a polite tone while expressing their views. The reviewer also shows willingness to adjust their opinion based on the authors' rebuttal, which demonstrates respect and open-mindedness."", ""The sentiment score is 70 (positive) because the reviewer starts by highlighting the paper's strengths, including 'state of the art results' and clear implementation details. They mention only one con, which is framed more as a neutral observation than a criticism. The reviewer also offers constructive suggestions for improvement, indicating an overall positive view of the paper. The politeness score is 80 (polite) due to the reviewer's respectful tone throughout. They use phrases like 'It could be nice to include' and 'To improve notation' when making suggestions, rather than demanding changes. The reviewer also acknowledges the novelty and interest of the work. The minor comments are presented constructively without harsh criticism. The overall language is professional and courteous, maintaining a positive and supportive tone while still providing valuable feedback."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the novelty and effectiveness of the proposed method, stating 'applying that for the purpose of training a binary or ternary network, and sample the pre-activations instead of weights is novel' and 'the proposed method is effective.' However, it's not extremely positive as the reviewer suggests additional experiments and improvements. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive suggestions rather than harsh criticisms. Phrases like 'It seems that there could be more things to show' and 'I guess this approach is also able to' indicate a polite and considerate tone. The reviewer also acknowledges the paper's strengths before suggesting improvements, which is a polite approach to feedback.""]"
"['This is a wonderful and a self-contained paper. In fact, it introduces a very important problem and it solves it. \n\nThe major point of the paper is demonstrating that it is possible to model logical entailment in neural networks. Hence, a corpus and a NN model are introduced. The corpus is used to demonstrate that the model, named PossibleWorld, is nearly perfect for the task. A comparative analysis is done with respect to state of the art recurrent NN. So far, so good.\n\nYet, what is the take home message? In my opinion, the message is that generic NN should not be used for specific formal tasks whereas specific neural networks that model the task are desirable. This seems to be a trivial claim, but, since the PossibleWorld nearly completely solves the task, it is worth to be investigated. \n\nThe point that the paper leaves unexplained is: what is in the PossibleWorld Network that captures what we need? The description of the network is in fact very criptic. No examples are given and a major effort is required to the reader. Can you provide examples and insights on why this is THE needed model?\n\nFinally, the paper does not discuss a large body of research that has been done in the past by Plate. Plate has investigated how symbolic predicates can be described in distributed representations. This is strictly related to the problem this paper investigates. As discussed in ""Symbolic, Distributed and Distributional Representations for Natural Language Processing in the Era of Deep Learning: a Survey"", 2017, the link between symbolic and distributed representations has to be better investigated in order to propose innovative NN models. Your paper can be one of the first NN model that takes advantage of this strict link.', 'SUMMARY \n\nThe paper is fairly broad in what it is trying to achieve, but the approach is well thought out. The purpose of the paper is to investigate the effectiveness of prior machine learning methods with predicting logical entailment and then provide a new model designed for the task. Explicitly, the paper asks the following questions: ""Can neural networks understand logical formula well enough to detect entailment?"", and ""Which architectures are best at inferring, encoding, and relating features in a purely structural sequence-based problem?"". The goals of the paper is to understand the learning bias of current architectures when they are tasked with learning logical entailment. The proposed network architecture, PossibleWorldNet, is then viewed as an improvement on an earlier architecture TreeNet.\n\nPOSITIVES \n\nThe structure of this paper was very well done. The paper attempts to do a lot, and succeeds on most fronts. The generated dataset used for testing logical entailment is given a constructive description which allows for future replication. The baseline benchmark networks are covered in depth and the reader is provided with a deep understanding on the limitations of some networks with regard to exploiting structure in data. The PossibleWorldNets is also given good coverage, and the equations provided show the means by which it operates.\n• A clear methodological approach to the research. The paper covers how they created a dataset which can be used for logical entailment learning, and then explains clearly all the previous network models which will be used in testing as well as their proposed model.\n• The background information regarding each model was exceptionally thorough. The paper went into great depth describing the pros and cons of earlier network models and why they may struggle with recognizing logical entailment.\n• The section describing the creation of a dataset captures the basis for the research, learning logical entailment. They describe the creation of the data, as well as the means by which they increase the difficulty for learning.\n• The paper provides an in depth description of their PossibleWorldNet model, and during experimentation we see clear evidence of the models capabilities.\n\nNEGATIVES\n\nOne issue I had with the paper is regarding the creation of the logical entailment dataset. Not so much for how they explained the process of creating the dataset, that was very thorough, but the fact that this dataset was the only means to test the previous network models and their new proposed network model. I wonder if it would be better to find non-generated datasets which may contain data that have entailment relationships. It is questionable if their hand crafted network model is learned best on their hand crafted dataset.\n\nThe use of a singular dataset for learning logical entailment. The dataset was also created by the researchers for the express purpose of testing neural network capacity to learn logical entailment. I am hesitant to say their proposed network is an incredible achievement since PossibleWorldNet effectively beat out other methods on a dataset that they created expressly for it.\n\nRELATED WORK \n\nThe paper has an extensive section dedicated to covering related work. I would say the research involved was very thorough and the researchers understood how their method was different as well as how it was improving on earlier approaches.\n\nCONCLUSION \n\nGiven the thorough investigation into previous networks’ capabilities in logical entailment learning, I would accept this paper as a valid scientific contribution. The paper performs a thorough analysis on the limitations that previous networks face with regard to exploiting structure from data. The paper also covers results of the experiments by not only pointing out their proposed network’s success, but by analyzing why certain earlier network models were able to achieve competitive learning results. The structure of the PossibleWorldNet was also explained well, and during ex- perimentation demonstrated its ability to learn structure from data. The paper would have been improved through testing of multiple datasets, and not just on there self generated dataset, but the contribution of their research on their network and older networks is still justification enough for this paper.', 'Overall, the paper is well-written and the proposed model is quite intuitive. Specifically, the idea is to represent entailment as a product of continuous functions over possible worlds. Specifically, the idea is to generate possible worlds, and compute the functions that encode entailment in those worlds. The functions themselves are designed as tree neural networks to take advantage of logical structure. Several different encoding benchmarks of the entailment task are designed to compare against the performance of the proposed model, using a newly created dataset. The results seem very impressive with > 99% accuracy on tests sets.\n\nOne weakness with the paper was that it was only tested on 1 dataset. Also, should some form of cross-validation be applied to smooth out variance in the evaluation results. I am not sure if there are standard ""shared"" datasets for this task, which would make the results much stronger.\nAlso how about the tradeoff, i.e., does training time significantly increase when we ""imagine"" more worlds. Also, in general, a discussion on the efficiency of training the proposed model as compared to TreeNN would be helpful.\nThe size of the world vectors, I would believe is quite important, so maybe a more detailed analysis on how this was chosen is important to replicate the results.\nThis problem, I think, is quite related to model counting. There has been a lot of work on model counting. a discussion on how this relates to those lines of work would be interesting.\n\n\nAfter revision\n\nI think the authors have improved the experiments substantially.']","[60, 70, 60]","[80, 80, 70]","[""The sentiment score is 60 (positive) because the reviewer starts by calling the paper 'wonderful and self-contained' and praises its importance. They also mention that the model 'nearly completely solves the task'. However, the score is not higher because the reviewer raises some concerns and asks for clarifications, indicating room for improvement. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions, and acknowledges the paper's strengths before pointing out areas for improvement. The reviewer's tone is constructive and encouraging, using phrases like 'Can you provide' and 'Your paper can be' which invite dialogue rather than demanding changes."", ""The sentiment score is 70 (positive) because the reviewer provides many positive comments about the paper's structure, methodology, and thoroughness. They use phrases like 'well thought out', 'very well done', and 'exceptionally thorough'. While there are some criticisms, they are presented as minor issues and the overall tone is approving. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'I wonder if' and 'I am hesitant to say' when presenting potential issues, which softens the critique. The review maintains a professional and courteous tone throughout, even when discussing limitations of the study."", ""The sentiment score is 60 (moderately positive) because the reviewer starts by praising the paper as 'well-written' and the model as 'quite intuitive', and notes 'very impressive' results. However, they also point out several weaknesses and areas for improvement, balancing the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions (e.g., 'should some form of cross-validation be applied') and asking questions rather than making demands. The reviewer also acknowledges the authors' efforts in the revision ('the authors have improved the experiments substantially'). The tone is professional and constructive throughout, without any harsh or rude language.""]"
"['This paper considers the problem of private learning and uses the PATE framework to achieve differential privacy. The dataset is partitioned and multiple learning algorithms produce so-called teacher classifiers. The labels produced by the teachers are aggregated in a differentially private manner and the aggregated labels are then used to train a student classifier, which forms the final output. The novelty of this work is a refined aggregation process, which is improved in three ways:\na) Gaussian instead of Laplace noise is used to achieve differential privacy.\nb) Queries to the aggregator are ""filtered"" so that the limited privacy budget is only expended on queries where the teachers are confident and the student is uncertain or wrong.\nc) A data-dependent privacy analysis is used to attain sharper bounds on the privacy loss with each query.\n\nI think this is a nice modular framework form private learning, with significant refinements relative to previous work that make the algorithm more practical. On this basis, I think the paper should be accepted. However, I think some clarification is needed with regard to item c above:\n\nTheorem 2 gives a data-dependent privacy guarantee. That is, if there is one label backed by a clear majority of teachers, then the privacy loss (as measured by Renyi divergence) is low. This data-dependent privacy guarantee is likely to be much tighter than the data-independent guarantee.\nHowever, since the privacy guarantee now depends on the data, it is itself sensitive information. How is this issue resolved? If the final privacy guarantee is data-dependent, then this is very different to the way differential privacy is usually applied. This would resemble the ""privacy odometer"" setting of Rogers-Roth-Ullman-Vadhan [ https://arxiv.org/abs/1605.08294 ]. \nAnother way to resolve this would be to have an output-dependent privacy guarantee. That is, the privacy guarantee would depend only on public information, rather than the private data. The widely-used ""sparse vector"" technique [ http://www.cis.upenn.edu/~aaroth/Papers/privacybook.pdf#page=59 ] does this.\nIn any case, this is an important issue that needs to be clarified, as it is not clear to me how this is resolved.\n\nThe algorithm in this work is similar to the so-called median mechanism [ https://www.cis.upenn.edu/~aaroth/Papers/onlineprivacy.pdf ] and private multiplicative weights [ http://mrtz.org/papers/HR10mult.pdf ]. These works also involve a ""student"" being trained using sensitive data with queries being answered in a differentially private manner. And, in particular, these works also filter out uninformative queries using the sparse vector technique. It would be helpful to add a comparison.\n', 'The paper proposes novel techniques for private learning with PATE framework. Two key ideas in the paper include the use of Gaussian noise for the aggregation mechanism in PATE instead of Laplace noise and selective answering strategy by teacher ensemble. In the experiments, the efficacy of the proposed techniques has been demonstrated. I am not familiar with privacy learning but it is interesting to see that more concentrated distribution (Gaussian) and clever aggregators provide better utility-privacy tradeoff. \n\n1. As for noise distribution, I am wondering if the variance of the distribution also plays a role to keep good utility-privacy trade-off. It would be great to discuss and show experimental results for utility-privacy tradeoff with different variances of Laplace and Gaussian noise.\n\n2. It would be great to have an intuitive explanation about differential privacy and selective aggregation mechanisms with examples. \n\n3. It would be great if there is an explanation about the privacy cost for selective aggregation. Intuitively, if teacher ensemble does not answer, it seems that it would reveal the fact that teachers do not agree, and thus spend some privacy cost.\n\n\n\n\n\n\n\n\n\n', 'Summary:\nIn this work, PATE, an approach for learning with privacy,  is modified to scale its application to real-world data sets. This is done by leveraging the synergy between privacy and utility, to make better use of the privacy budget spent when transferring knowledge from teachers to the student. Two aggregation mechanisms are introduced for this reason.  It is demonstrated that sampling from a Gaussian distribution (instead from a Laplacian distribution) facilitates the aggregation of teacher votes in tasks with large number of output classes. \n\non the positive side:\n\nHaving scalable models is important, especially models that can be applied to data with privacy concerns. The extension of an approach for learning with privacy to make it scalable is of merit. The paper is well written, and the idea of the model is clear. \n\n\non the negative side:\n\nIn the introduction, the authors introduce the problem by the importance of privacy issues in medical and health care data. This is for sure an important topic. However, in the following paper, the model is applied no neither medical nor healthcare data. The authors mention that the original model PATE was applied to medical record and census data with the UCI diabetes and adult data set. I personally would prefer to see the proposed model applied to this kind of data sets as well. \n\nminor comments: \n\nFigure 2, legend needs to be outside the Figure, in the current Figure a lot is covered by the legend']","[60, 60, 50]","[80, 70, 70]","[""The sentiment score is 60 (positive) because the reviewer states that the paper 'should be accepted' and describes it as a 'nice modular framework' with 'significant refinements'. However, it's not extremely positive as the reviewer also points out areas needing clarification. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits while constructively suggesting improvements. Phrases like 'I think' and 'It would be helpful' contribute to the polite tone. The reviewer also provides helpful references, showing a collaborative approach rather than a critical one."", ""The sentiment score is 60 (positive) because the reviewer expresses interest in the paper's novel techniques and acknowledges the efficacy of the proposed methods. The reviewer uses phrases like 'it is interesting to see' and notes the demonstration of the techniques' effectiveness. However, it's not extremely positive as the reviewer also mentions not being familiar with privacy learning. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, employing phrases like 'It would be great' when making suggestions. The reviewer offers constructive feedback and asks questions in a courteous manner, without using any harsh or critical language. The overall tone is supportive and encouraging, while still providing valuable feedback for improvement."", ""The sentiment score is 50 (slightly positive) because the review acknowledges the importance and merit of the work, praising its scalability and clear presentation. However, it also points out a significant negative aspect regarding the mismatch between the introduced problem domain and the actual application. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging positive aspects before presenting criticisms, and framing negative points as personal preferences ('I personally would prefer...'). The reviewer also uses phrases like 'on the positive side' and 'minor comments' to soften critiques. The overall tone is constructive and professional, without any harsh or rude language.""]"
"['This paper demonstrates that a competitive multi-agent environment trained with self-play can produce behaviors that are far more complex than the environment itself and such environments come with a natural curriculum by introducing several multi-agent tasks with competing goals in a 3D world with simulated physics. It utilizes a decentralized training approach and use distributed implementation of PPO for very large scale multiagent training. This paper addresses the challenges in applying distributed PPO to train multiple competitive agents, including the problem of exploration with sparse reward by using full roll-outs and use the dense exploration reward which is gradually annealed to zero in favor of the sparse competition reward. It makes training more stable by selecting random old parameters for the opponent. \n \nAlthough the technical contributions seem to be not quite significant, this paper is well written and introduces a few new domains which are useful for studying problems in multiagent reinforcement learning. The paper also makes it clear regarding the connections and distinctions to many existing work. \n\nMinor issues:\n\nE[Loss] in table 1 is undefined.\n\nIn the notation section, the observation model is missing, and the policy is restricted to be reactive.\n \nUniform (v, \\deta v) -> Uniform (\\deta v, v)\n', 'In this paper, the authors produced quite cool videos showing the acquisition of highly complex skills, and they are happy about it. If you read the conclusion, this is the only message they put forward, and to me this is not a scientific message.\n\nA more classical summary is that the authors use PPO, a state-of-the-art deep RL method, in a context where two agents are trained to perform competitive games against each other. They reuse a very recent ""dense reward"" technique to bootstrap the agent skills, and then anneal it to zero so that the competitive rewards obtained from defeating the opponent takes the lead. They study the effect of this annealing process (considered as a curriculum) and of various strategies for sampling the opponents. The main outcome is the acquisition of a large variety of useful skills, just observed from videos of the competitions.\n\nThe main issue with this paper is the lack of scientific analysis of the results, together with many local issues in the presentation of these results.\nBelow, I talk directly to the authors.\n\n---------------------------------\n\nThe related work subsection is just a list of works, it should explain how the proposed work position itself with respect to these works.\n\n\nIn Section 5.2, you are just describing ""cool"" behaviors observed from your videos.\nScience is about producing quantitative results, analyzing them and discussing them.\nI would be glad to read more science about these cool behaviors. Can you define a repertoire of such behaviors?\nDetermine how often they are discovered? Study how the are represented in the networks?\nAnything beyond ""look, that\'s great!"" would make the paper better...\n\nBy the end of Section 5.2, you allude to transfer learning phenomena.\nIt would be nice to study these transfer effects in your results with a quantitative methodology.\n\nSection 5.3 is more scientific, but it has serious issues.\n\nIn all subfigures in Figure 3, the performance of opponents should be symmetric around 50%. This is not the case for subfigures (b) and (c-1). Why?\nDo they correspond to non-zero sum game? The x-label is ""version"". Don\'t you mean ""number of epochs"", or something like this? Why do the last 2 images\nshare the same caption?\n\nI had a hard time understanding the message from Table 1. It really needs a line before the last row and a more explicative caption.\n\nStill in 5.3, ""These results echo""...: can you characterize this echo? What is the relationship to this other work?\n\nAgain, ""These results shed further light"": further with respect to what? Can you be more explicit about what we learn?\n\nAlso, I find that annealing a kind of reward with respect to another is a weak form of curriculum learning. This should be further discussed.\n\nIn Section 5.4, the idea of using many opponents from many stages of learning in not new.\nIf I\'m correct, the same was done in evolutionary method to escape the ""arms race"" dead-end in prey-predator races quite a while ago  (see e.g. ""Coevolving predator and prey robots: Do “arms races” arise in artificial evolution?"" Nolfi and Floreano, 1998)\n\nSection 5.5.1 would deserve a more quantitative presentation of the effect of randomization.\nActually, in Fig5: the axes are not labelled. I don\'t believe it shows a win-rate. So probably the caption (or the image) is wrong.\n\nIn Section 5.5.2, you ""suspect this is because..."".\nThe role of a scientific paper is to clearly establish results and explanation from solid quantitative analysis. \n\n-------------------------------------------\nMore local comments:\n\nAbstract:\n\n""Normally, the complexity of the trained agent is closely related to the complexity of the environment."" Here you could cite Herbert Simon (1962).\n\n""In this paper, we point out that a competitive multi-agent environment trained with self-play can produce behaviors that are far more complex than the environment itself.""\nWell, for an agent, the other agent(s) are part of its environment, aren\'t they? So I don\'t like this perspective that the environment itself is ""simple"".\n\nIntro:\n\n""RL is exciting because good RL exists."" I don\'t believe this is a strong argument. There are many good things that exist which are not exciting.\n\n""In general, training an agent to perform a highly complex task requires a highly complex environment, and these can be difficult to create."" Well, the standard perspective is the other way round: in general, you face a complex problem, then you need to design a complex agent to solve it, and this is difficult. \n\n""This happens because no matter how weak or strong an agent is, an environment populated with other agents of comparable strength provides the right challenge to the agent, facilitating maximally rapid learning and avoiding getting stuck."" This is not always true. The literature is full of examples where two-players competition end-up with oscillations between to solutions rather than ever-increasing skill performance. See the prey-predator literature pointed above.\n\n""in the domain of continuous control, where balance, dexterity, and manipulation are the key skills."" In robotics, dexterity, and manipulation usually refer to using the robot\'s hand(s), a capability which is not shown here.\n\nIn preliminaries, notation, what you describe corresponds to the framework of Dec-POMDPs, you should position yourself with respect to this framework (see e.g. Memory-Bounded Dynamic Programming for DEC-POMDPs. S Seuken, S Zilberstein)\n\nIn PPO description : Let l_t(\\theta) ... denote the likelihood ratio: of what?\n\np5:\nwould train on the dense reward for about 10-15% of the trainig epochs. So how much is \\alpha_t? How did you tune it? Was it hard?\n\np6:\n\nyou give to the agent the mass: does the mass change over time???\n\nIn observations: Are both agents given different observations? Could you specify which is given what?\n\nIn Algorithms parameters: why do you have to anneal longer for kick-and-defend? What is the underlying phenomenon?\n\nIn Section 5, the text mentions Fig5 before Fig4.\n\n-------------------------------------------------\nTypos:\n\np4:\nresearch(Andrychowicz => missing space\nstraight forward => straightforward\n\np5:\nagent like humanoid(s)\nfrom exi(s)ting work\n\np6:\neq. 1 => Eq. (1) (you should use \\eqref{})\nIn section 4.1 => In Section 4.1 (same p7 for Section 4.2)\n\n""One question that arises is the extent to which the outcome of learning is affected by this exploration reward and to explore the benefit of this exploration reward. As already argued, we found the exploration reward to be crucial for learning as otherwise the agents are unable to explore the sparse competition reward."" => One question that arises is the extent to which the outcome of learning is affected by this exploration reward and to explore its benefit. As already argued, we found it to be crucial for learning as otherwise the agents are unable to explore the sparse competition reward.\n\np8:\nin a local minima => minimum\n\np9:\nin references, you have Jakob Foerster and Jakob N Foerster => try to be more consistent.\n\np10, In Laetitia Matignon et al.  ... markov => Markov\n\np11, I would rename C_{alive} as C_{standing}', 'Understanding how-and-why complex motion skills emerge is an complex and interesting problem.\nThe method and results of this paper demonstrate some good progress on this problem, and focus on\nthe key point that competition introduces a natural learning curriculum.\nMulti-agent competitive learning has seen some previous work in setting involving physics-based skills\nor actual robots. However, the results in this paper are compelling in taking this another good step forward.\nOverall the paper is clearly written and I believe that it will have impact.\n\nlist of pros & cons\n+ informative and unique experiments that demonstrate emergent complexity coming from the natural curriculum\n  provided by competitive play, for physics-based settings\n+ likely to be of broad interest\n- likely large compute resources needed to replicate or build on the results\n- paper is not anonymous to this reviewer, given the advance publicity for this work when it was released\n==> overall this paper will have impact and advances the state of the art, particular wrt to curriculums\n    In many ways, it is what one might expect. But executing on the idea is very much non-trivial.\n\nother comments\n\nCan you comment on the difficulty of designing the ""games"" themselves?\nIt is often difficult to decide apriori when a game is balanced; game designers of any kind\nspend significant time on this. Perhaps it is easier for some of the types of games investigated in\nthis paper, but if you did have any issues with games becoming unbalanced, that would be worthwhile commenting on.\nGame design is also the next level of learning in many ways.  :-)\n\nThe opponent sampling strategy is one of the key results of the paper.\nIt could be brought to the fore earlier, i.e., in the abstract.\n\nHow much do the exploration rewards matter?\nIf two classes of agents are bootstrapped with different flavours of exploration rewards, how much would it matter?\n\nIt would be generally interesting to describe when during the learning various ""strategies"" emerged,\nand in what order.\n\nAdding sensory delays might enable richer decoy strategies.\n\nThe paper could comment on the further additional complexity that might result from situations\nthat allow for collaboration as well as competition. (ok, I now see that this is mentioned in the conclusions)\n\nThe Robocup tournaments for robot soccer (real and simulated) have for a long time provided\na path to growing skills and complexity, although under different constraints, and perhaps less interesting\nin terms of one-on-one movement skills.\n\nSection 2, ""Notation""\nwhy are the actions described as being discrete here, when the paper uses continuous actions?\nAlso, ""$\\pi_{\\theta}$ can be Gaussian"":   better to say that it *is* Gaussian in this paper.\n\n""lead to different algorithm*s*""\n\nAre there torque limits, and if so, what are they?\n\nsec 4: ""We do multiple rollouts for each agent *pair*"" (?)\n\n""Such rewards have been previously researched for simple tasks like walking forward and standing up""\nGiven the rather low visual quality and overly-powerful humanoids of the many of the published ""solutions"", \nperhaps ""simple"" is the wrong qualifer.\n\nFigure 2:  curve legend?\n\n""exiting work"" (sic)\n\n4.2 Opponent sampling:\n""simultaneously training""  should add ""in opponent pairs"" (?)\n\n5.1 ""We use both MLP and LSTM""\nshould be ""We compare MLP and LSTM ..."" (?)\n\nFor ""kick and defend"" and ""you shall not pass"", are there separate attack and defend policies?\nIt seems that these are unique in that the goals are not symmetric, whereas for the other tasks they are.\nWould be worthwhile to comment on this aspect.\n\nepisodic length T, eqn (1)\nIt\'s not clear at this point in the paper if T is constant or not.\n\nObservations: ""we also give the centre-of-mass based inertia *tensor*"" (?)\n\n""distance from the edge of the ring""\nHow is this defined?\n\n""none of the agents observe the complete global state""\nDoes this really make much of a difference?  Most of the state seems visible.\n\n""But these movement strategies"" -> ""These movement strategies ...""\n\nsec 5.4  suggest to use $\\mathrm{Uniform}(...)$\n\n""looses by default"" (sic)\n']","[60, -30, 80]","[70, 20, 70]","[""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's strengths, such as being well-written, introducing useful new domains, and clearly explaining connections to existing work. However, it's not extremely positive as the reviewer notes that the technical contributions are not quite significant. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms constructively as 'minor issues'. The reviewer also uses phrases like 'this paper demonstrates' and 'this paper addresses', which show respect for the authors' work. The overall tone is professional and courteous, without being overly effusive."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('quite cool videos', 'main outcome is the acquisition of a large variety of useful skills'), the overall tone is critical. The reviewer points out a 'lack of scientific analysis' and numerous issues with the paper. However, it's not extremely negative as the reviewer offers constructive feedback. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I would be glad to read' and 'It would be nice to study'. The reviewer also directly addresses the authors in a respectful manner. However, some phrases like 'I don't believe this is a strong argument' are more direct, preventing a higher politeness score."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its 'good progress', 'compelling results', and potential impact. They use phrases like 'clearly written' and 'will have impact' which indicate a favorable opinion. The politeness score is 70 (polite) due to the constructive and respectful tone throughout. The reviewer offers suggestions and critiques in a considerate manner, using phrases like 'Can you comment on...' and 'It would be generally interesting...'. They also balance criticism with praise, acknowledging both strengths and limitations of the work. The language is professional and courteous throughout, without any harsh or rude comments.""]"
"[""This work proposes non-autoregressive decoder for the encoder-decoder framework in which the decision of generating a word does not depends on the prior decision of generated words. The key idea is to model the fertility of each word so that copies for source words are fed as input to the encoder part, not the generated target words as inputs. To achieve the goal, authors investigated various techniques: For inference, sample fertility space for generating multiple possible translations. For training, apply knowledge distilation for better training followed by fine tuning by reinforce. Experiments for English/German and English/Romanian show comparable translation qualities with speedup by non-autoregressive decoding.\n\nThe motivation is clear and proposed methods are very sound. Experiments are carried out very carefully.\n\nI have only minor concerns to this paper:\n\n- The experiments are designed to achieve comparable BLEU with improved latency. I'd like to know whether any BLUE improvement might be possible under similar latency, for instance, by increasing the model size given that inference is already  fast enough.\n\n- It'd also like to see other language pairs with distorted word alignment, e.g., Chinese/English, to further strengthen this work, though  it might have little impact given that attention already capture sort of alignment.\n\n- What is the impact of the external word aligner quality? For instance, it would be possible to introduce a noise in the word alignment results or use smaller data to train a model for word aligner. \n\n- The positional attention is rather unclear and it would be better to revise it. Note that equation 4 is simply mentioning attention computation, not the proposed positional attention."", 'This paper describes an approach to decode non-autoregressively for neural machine translation (and other tasks that can be solved via seq2seq models). The advantage is the possibility of more parallel decoding which can result in a significant speed-up (up to a factor of 16 in the experiments described). The disadvantage is that it is more complicated than a standard beam search as auto-regressive teacher models are needed for training and the results do not reach (yet) the same BLEU scores as standard beam search. \n\nOverall, this is an interesting paper. It would have been good to see a speed-accuracy curve which plots decoding speed for different sized models versus the achieved BLUE score on one of the standard benchmarks (like WMT14 en-fr or en-de) to understand better the pros and cons of the proposed approach and to be able to compare models at the same speed or the same BLEU scores. Table 1 gives a hint of that but it is not clear whether much smaller models with standard beam search are possibly as good and fast as NAT -- losing 2-5 BLEU points on WMT14 is significant.  While the Ro->En results are good, this particular language pair has not been used much by others; it would have been more interesting to stay with a single well-used language pair and benchmark and analyze why WMT14 en->de and de->en are not improving more. Finally it would have been good to address total computation in the comparison as well -- it seems while total decoding time is smaller total computation for NAT + NPD is actually higher depending on the choice of s.\n ', 'This paper can be seen as an extension of the paper ""attention is all you need"" that will be published at nips in a few weeks (at the time I write this review). \n\nThe goal here is to make the target sentence generation non auto regressive. The authors propose to introduce a set of latent variables to represent the fertility of each source words. The number of target words can be then derived and they\'re all predicted in parallel.\n\nThe idea is interesting and trendy. However, the paper is not really stand alone. A lot of tricks are stacked to reduce the performance degradation. However, they\'re sometimes to briefly described to be understood by most readers. \n\nThe training process looks highly elaborate with a lot of hyper parameters. Maybe you could comment on this. \n\nFor instance, the use fertility supervision during training could be better motivated and explained. Your choice of IBM 2 is wired since it doesn\'t include fertility. Why not IBM 4, for instance ? How you use IBM model for supervision. This a simple example, but a lot of things in this paper is too briefly described and their impact not really evaluated. ']","[80, 50, -20]","[70, 75, 20]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, stating that the motivation is clear, the methods are sound, and the experiments are carried out carefully. The only criticisms are described as 'minor concerns'. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing their suggestions as requests for additional information or clarification rather than demands. Phrases like 'I'd like to know' and 'It'd be better to' contribute to the polite tone. The reviewer also acknowledges the strengths of the work before presenting their concerns, which is a polite approach to peer review."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as 'interesting' and acknowledges its advantages, but also points out significant disadvantages and areas for improvement. The overall tone is balanced, leaning slightly positive. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement without harsh or dismissive comments. Phrases like 'It would have been good to see' and 'it would have been more interesting' are polite ways of suggesting improvements. The reviewer also acknowledges the paper's strengths before discussing its limitations, which is a polite approach to criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting and trendy', they express several concerns. They mention that the paper is not stand-alone, many techniques are briefly described, and the training process is complex. The reviewer also questions some choices made by the authors and suggests areas for improvement. However, the criticism is not harsh, hence the score is only mildly negative.\n\nThe politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout. They use neutral language and phrase their criticisms as suggestions or questions rather than direct attacks. For example, they say 'Maybe you could comment on this' and ask 'Why not IBM 4, for instance?' This approach is more polite than blunt criticism. However, the review doesn't go out of its way to be exceptionally polite or encouraging, which is why the score is only mildly positive.""]"
"['The authors introduce scattering transforms as image generative models in the context of Generative Adversarial Networks and suggest why they could be seen as Gaussianization transforms with controlled information loss and invertibility.\nWriting is suggestive and experimental results are interesting, so I clearly recommend acceptation. \n\nI would appreciate more intuition on some claims (e.g. relation between Lipschitz continuity and wavelets) but they refer to the appropriate reference to Mallat, so this is not a major problem for the interested reader.\n\nHowever, related to the above non-intuitive claim, here is a question on a related Gaussianization transform missed by the authors that (I feel) fulfils the conditions defined in the paper but it is not obviously related to wavelets. Authors cite Chen & Gopinath (2000) and critizise that their approach suffers from the curse of dimensionality because of the ICA stage. However, other people [Laparra et al. Iterative Gaussianization from ICA to random rotations IEEE Trans.Neural Nets 2011] proved that the ICA stage is not required (but only marginal operations followed by even random rotations). That transform seems to be Lipschitz continuous as well -since it is smooth and derivable-. In fact it has been also used for image synthesis. However, it is not obviously related to wavelets... Any comment?\n\nAnother relation to previous literature: in the end, the proposed analysis (or Gaussianization) transform is basically a wavelet transform where the different scale filters are applied in a cascade (fig 1). This is similar to Gaussian Scale Mixture  models for texture analysis [Portilla & Simoncelli Int. J. Comp. Vis. 2000] in which after wavelet transform, local division is performed to obtain Gaussian variables, and these can be used to synthesize the learned textures. That is similar to Divisive Normalization models of visual neuroscience that perform similar normalization alfter wavelets to factorize the PDF (e.g. [Lyu&Simoncelli Radial Gaussianization Neur.Comput. 2009], or [Malo et al. Neur.Comput. 2010]).\n\nMinor notation issues: authors use a notation for functions that seems confusing (to me) since it looks like linear products. For instance: GZ for G(Z) [1st page] and phiX for phi(X) [2nd page] Sx for S(x) [in page 5]... \n', '\nThe paper proposes a generative model for images that does no require to learn a discriminator (as in GAN’s) or learned embedding. The proposed generator is obtained by learning an inverse operator for a scattering transform.\n\nThe paper is well written and clear. The main contribution of the work is to show that one can design an embedding with some desirable properties and recover, to a good degree, most of the interesting aspects of generative models. However, the model doesn’t seem to be able to produce high quality samples. In my view, having a learned pseudo-inverse for scattering coefficients is interesting on its own right. The authors should show more clearly the generalization capabilities to test samples. Is the network able to invert images that follow the train distribution but are not in the training set?\n\nAs the authors point out, the representation is non-invertible. It seems that using an L2 loss in pixel space for training the generator would necessarily lead to blurred reconstructions (and samples) (as it produces a point estimate). Unless the generator overfits the training data, but then it would not generalize. The reason being that many images would lie in the level set for a given feature vector, and the generator cannot deterministically disambiguate which one to match. \n\nThe sampling method described in Section 3.2 does not suffer from this problem, although as the authors point out, a good initialization is required. Would it make sense to combine the two? Use the generator network to produce a good initial condition and then refine it with the iterative procedure.\n\nThis property is exploited in the conditional generation setting in:\n\nBruna, J. et al ""Super-resolution with deep convolutional sufficient statistics."" arXiv preprint arXiv:1511.05666 (2015).\n\nThe samples produced by the model are of poorer quality than those obtained with GAN’s. Clearly the model is assigning mass to regions of the space where there are not valid images.  (similar effect that suffer models train with MLE). Could you please comment on this point?\n\nThe title is a bit misleading in my view. “Analyzing GANs” suggests analyzing the model in general, this is, its architecture and training method (e.g. loss functions etc). However the analysis concentrates in the structure of the generator and the particular case of inverting scattering coefficients.\n\nHowever, I do find very interesting the analysis provided in Section 3.2. The idea of using meaningful intermediate (and stable) targets for the first two layers seems like a very good idea. Are there any practical differences in terms of quality of the results? This might show in more complex datasets.\n\nCould you please provide details on what is the dimensionality of the scattering representation at different scales? Say, how many coefficients are in S_5?\n\nIn Figure 3, it would be good to show some interpolation results for test images as well, to have a visual reference.\n\nThe authors mention that considering the network as a memory storage would allow to better recover known faces from unknown faces. It seems that it would be known from unknown images. Meaning, it is not clear why this method would generalize to novel image from the same individuals. Also, the memory would be quite rigid, as adding a new image would require adapting the generator.\n\nOther minor points:\n\nLast paragraph of page 1, “Th inverse \\Phi…” is missing the ‘e’.\n\nSome references (to figures or citations) seem to be missing, e.g. at the end of page 4, at the beginning of page 5, before equation (6). \n\nAlso, some citations should be corrected, for instance, at the end of the first paragraph of Section 3.1: \n\n“… wavelet filters Malat (2016).” \n\nSould be:\n\n“... wavelet filters (Malat, 2016).” \n\nFirst paragraph of Section 3.3. The word generator is repeated.\n', 'After a first manuscript that needed majors edits, the revised version\noffers an interesting GAN approach based the scattering transform.\n\nApproach is well motivated with proper references to the recent literature.\n\nExperiments are not state of the art but clearly demonstrate that the\nproposed approach does provide meaningful results.']","[70, 20, 60]","[60, 70, 50]","[""The sentiment score is 70 (positive) because the reviewer clearly recommends acceptance, stating 'I clearly recommend acceptation.' They also praise the writing as 'suggestive' and the experimental results as 'interesting.' However, it's not a perfect score as they do have some questions and suggestions for improvement. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, such as 'I would appreciate' and 'Any comment?' when asking for clarification. They also acknowledge that their concerns are not major problems. However, the tone is professional rather than overtly friendly, preventing a higher politeness score. The reviewer provides constructive feedback and asks questions in a courteous manner, maintaining a respectful dialogue with the authors."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is well-written and clear, and finds some aspects of the work interesting. However, they also point out several limitations and areas for improvement, which tempers the overall positive sentiment. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, asks questions politely, and offers constructive criticism. They use phrases like 'Could you please...' and 'It would be good to...', which contribute to a polite tone. The reviewer also acknowledges the interesting aspects of the work while providing detailed feedback, maintaining a professional and courteous approach throughout the review."", ""The sentiment score is 60 (positive) because the reviewer describes the revised manuscript as 'interesting' and states that it 'offers' a new approach, which is 'well motivated'. The experiments are described as 'clearly demonstrate' meaningful results, although they are 'not state of the art'. This indicates a generally positive view with some reservations. The politeness score is 50 (somewhat polite) because the language is professional and constructive, acknowledging improvements from the first version and highlighting positive aspects. The reviewer uses neutral language without overly effusive praise or harsh criticism, maintaining a respectful tone throughout the review.""]"
"['PAPER SUMMARY\n\nThis paper aims to address two limitations of spectral clustering: its scalability to large datasets and its generalizability to new samples. The proposed solution is based on designing a neural network called SpectralNet that maps the input data to the eigenspace of the graph Laplacian and finds an orthogonal basis for this eigenspace. The network is trained by alternating between orthogonalization and gradient descent steps, where scalability is achieved by using a stochastic optimization scheme that instead of computing an eigendecomposition of the entire data (as in vanilla spectral clustering) uses a Cholesky decomposition of the mini batch to orthogonalize the output. The method can also handle out-of-sample data by applying the learned embedding function to new data. Experiments on the MNIST handwritten digit database and the Reuters document database demonstrate the effectiveness of the proposed SpectralNet.\n\nCOMMENTS\n\n1) I find that the output layer (i.e. the orthogonalization layer) is not well-justified. In principle, different batches require different weights on the output layer. Although the authors observe empirically that orthogonalization weights are roughly shared across different batches, the paper lacks a convincing argument for why this can happen. Moreover, it is not clear why an output layer designed to orthogonalized batches from the training set would also orthogonalize batches from the test set?\n\n2) One claimed contribution of this work is that it extends spectral clustering to large scale data. However, the paper could have commented more on what makes spectral clustering not scalable, and how the method in this paper addresses that. The authors did mention that spectral clustering requires computing eigenvectors for large matrices, which is prohibitive. However, this argument is not entirely true, as eigen-decomposition for large sparse matrices can be carried out efficiently by tools such as ARPACK. On the other hand, computing the nearest neighbor affinity or Gaussian affinity is N^2 complexity, which could be the bottleneck of computation for spectral clustering on large scale data. But this issue can be addressed using approximate nearest neighbors obtained, e.g., via hashing. Overall, the paper compares only to vanilla spectral clustering, which is not representative of the state of the art. The paper should do an analysis of the computational complexity of the proposed method and compare it to the computational complexity of both vanilla as well as scalable spectral clustering methods to demonstrate that the proposed approach is more scalable than the state of the art. \n\n3)  Continuing with the point above, an experimental comparison with prior work on large scale spectral clustering (see, e.g. [a] and the references therein) is missing. In particular, the result of spectral clustering on the Reuters database is not reported, but one could use other scalable versions of spectral clustering as a baseline.\n\n4)  Another benefit of the proposed method is that it can handle out-of-sample data. However, the evaluation of such benefit in experiments is rather limited. In reporting the performance on out-of-sample data, there is no other baseline to compare with. One can at least compare with the following baseline: apply k-means to the training data in input space, and classify each test data to the nearest centroid.\n\n5) The reason for using an autoencoder to extract features is unclear. In subspace clustering, it has been observed that features extracted from a scattering transform network [b] can significantly improve clustering performance, see e.g. [c] where all methods have >85% accuracy on MNIST. The methods in [c] are also tested on larger datasets.\n\n[a] Choromanska, et. al., Fast Spectral Clustering via the Nystrom Method, International conference on algorithmic learning theory, 2013\n\n[b] Bruna, Mallat, Invariant Scattering Convolution Networks, arXiv 2012\n\n[c] You, et. al., Oracle Based Active Set Algorithm for Scalable Elastic Net Subspace Clustering, CVPR 2016', 'Brief Summary:\nThe paper introduces a deep learning based approach that approximates spectral clustering. The basic idea is to train a neural network to map a representation of input in the eigenspace where k-means clustering can be performed as usual. The method is more scalable than the vanilla spectral clustering algorithm and it can also be used to cluster a new incoming data point without redoing the whole spectral clustering procedure. The authors have proved worst case lower bounds on the size of neural network required to perform the task using VC dimension theory. Experiments on MNIST and Reuters dataset show state of the art performance (On Reuter\'s there is a significant performance improvement under one measure).\n\nMain Contributions:\nIntroduced SpectralNet - a neural network that maps input points to their embeddings in the eigenspace\nUsed constraint optimization (using Cholesky decomposition) to train the final layer of neural network to make sure that the output ""eigenvectors"" are orthonormal\nSolves the problem of scalability by using stochastic optimization (basically using mini-batches to train neural network)\nSolves the problem of generalization to new data points as the neural network can be used to directly compute the embedding for the incoming data point in the eigenspace\nProved a lower bound for VC dimension of spectral clustering (linear in n as opposed to linear in input dimension d for k-means, which explains the expressive power of spectral clustering)\nDerived a worst-case lower bound for the size of neural network that is needed to realize the given objective\nExperimented by using Gaussian kernel similarity and similarity learned using a Siamese neural network (trained in an unsupervised way) on both input space and code space (auto-encoder representation)\n\nOverall:\nThe paper is very clearly written. The idea is simple yet clever. Incorporating the ortho-normalization constraint in the final layer of the neural network is interesting.\nThe VC dimension based result are interesting but useless as the authors themselves argue that in practical cases the size of neural network required will be much less than the worst case lower bound proved in the paper.\nThe experiments demonstrate the effectiveness of the proposed approach.\nThe unsupervised training of Siamese is based on code k-nearest neighbor approach to get positive and negative examples. It is not clear why the learned matrix should outperform Gaussian kernel, but the experiments show that it does.\n\n\n\n', 'The authors study deep neural networks for spectral clustering in combination with stochastic optimization for large datasets. They apply VC theory to find a lower bound on the size of the network. \n\nOverall it is an interesting study, though the connections with the existing literature could be strengthened:\n\n- The out-of-sample extension aspects and scalability is stressed in the abstract and introduction to motivate the work.\nOn the other hand in Table 1 there is only compared with methods that do not possess these properties.\nIn the literature also kernel spectral clustering has been proposed, possessing out-of-sample properties\nand applicable to large data sets, see\n\n``Multiway Spectral Clustering with Out-of-Sample Extensions through Weighted Kernel PCA, IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 32, no. 2, pp. 335-347, 2010\n\nSparse Kernel Spectral Clustering Models for Large-Scale Data Analysis, Neurocomputing, vol. 74, no. 9, pp. 1382-1390, 2011\n\nThe latter also discussed incomplete Cholesky decomposition which seems related to section 3.1 on p.4.\n\n- related to the neural networks aspects, it would be good to comment on the reproducability of the results with respect to the training results (local minima) and the model selection aspects. How is the number of clusters and number of neurons selected?\n\n']","[-30, 80, 20]","[20, 50, 60]","[""The sentiment score is -30 because while the reviewer acknowledges the paper's aims and some positive aspects, they raise several significant concerns and limitations. The review points out multiple areas where the paper falls short, such as lack of justification for the output layer, insufficient comparison with state-of-the-art methods, and limited evaluation of out-of-sample performance. These criticisms outweigh the initial neutral summary, resulting in a slightly negative overall sentiment. The politeness score is 20 because the reviewer maintains a professional and objective tone throughout. They use phrases like 'I find that' and 'The paper could have commented more on' rather than making blunt criticisms. The reviewer also provides constructive suggestions and references to improve the paper. However, the score is not higher as the review doesn't include explicitly positive or encouraging language, maintaining a mostly neutral, academic tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They describe the idea as 'simple yet clever' and note that the paper is 'very clearly written'. The reviewer also highlights the effectiveness of the proposed approach and the interesting aspects of the work, such as the ortho-normalization constraint. While there are some critiques (e.g., the VC dimension results being 'useless' in practical cases), these are minor compared to the overall positive tone. The politeness score is 50 (slightly positive) because the reviewer maintains a professional and respectful tone throughout. They offer balanced feedback, acknowledging both strengths and limitations of the work without using harsh or overly critical language. The review is direct and objective, focusing on the content of the paper rather than making personal comments about the authors."", ""The sentiment score is slightly positive (20) because the reviewer describes the study as 'interesting' and provides constructive feedback. However, they also point out areas for improvement, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, such as 'Overall it is an interesting study' and phrases suggestions politely like 'it would be good to comment on'. The reviewer maintains a professional tone without using harsh or critical language, instead offering specific recommendations for improvement in a courteous manner.""]"
"['Paper studies an interesting phenomenon of overparameterised models being able to learn well-generalising solutions. It focuses on a setting with three crucial simplifications:\n- data is linearly separable\n- model is 1-hidden layer feed forward network with homogenous activations\n- **only input-hidden layer weights** are trained, while the hidden-output layer\'s weights are fixed to be (v, v, v, ..., v, -v, -v, -v, ..., -v) (in particular -- (1,1,...,1,-1,-1,...,-1))\nWhile the last assumption does not limit the expressiveness of the model in any way, as homogenous activations have the property of f(ax)=af(x) (for positive a) and so for any unconstrained model in the second layer, we can ""propagate"" its weights back into first layer and obtain functionally equivalent network. However, learning dynamics of a model of form \n z(x) = SUM( g(Wx+b) ) - SUM( g(Vx+c) ) + d\nand ""standard"" neural model\n z(x) = Vg(Wx+b)+c\ncan be completely different.\nConsequently, while the results are very interesting, claiming their applicability to the deep models is (at this point) far fetched. In particular, abstract suggests no simplifications are being made, which does not correspond to actual result in the paper. The results themselves are interesting, but due to the above restriction it is not clear whether it sheds any light on neural nets, or simply described a behaviour of very specific, non-standard shallow model.\n\nI am happy to revisit my current rating given authors rephrase the paper so that the simplifications being made are clear both in abstract and in the text, and that (at least empirically) it does not affect learning in practice. In other words - all the experiments in the paper follow the assumption made, if authors claim is that the restriction introduced does not matter, but make proofs too technical - at least experimental section should show this. If the claims do not hold empirically without the assumptions made, then the assumptions are not realistic and cannot be used for explaining the behaviour of models we are interested in.\n\nPros:\n- tackling a hard problem of overparametrised models, without introducing common unrealistic assumptions of activations independence\n- very nice result of ""phase change"" dependend on the size of hidden layer in section 7\n\nCons:\n- simplification with non-trainable second layer is currently not well studied in the paper; and while not affecting expressive power - it is something that can change learning dynamics completely\n\n# After the update\n\nAuthors addressed my concerns by:\n- making simplification assumption clearer in the text\n- adding empirical evaluation without the assumption\n- weakening the assumptions\n\nI find these modifications satisfactory and rating has been updated accordingly. \n', ""This paper shows that on linearly separable data, SGD on a overparametrized network (one hidden layer, with leaky ReLU activations) can still lean a classifier that provably generalizes. The assumption on data and structure of network is a bit strong, but this is the first result that achieves a number of desirable properties\n``1. Works for overparametrized network\n2. Finds global optimal solution for a non-convex network.\n3. Has generalization guarantees (and generalization is related to the SGD algorithm).\n4. Number of samples need not depend on the number of neurons. \n\nThere have been several papers achieving 1 and 2 (with much weaker assumptions), but they do not have 3 and 4. The proof of the optimization part is very similar to the proof of perceptron algorithm, and really relies on linear separability. The proof of generalization is based on a compression argument, where if an algorithm does not take many nonzero steps, then it must have good generalization. Ideally, one would also want to see a result where overparametrization actually helps (in the main result the whole data can be learned by a linear classifier). This is somewhat achieved when the activation is replaced with standard ReLU, where the paper showed with a small number of hidden units the algorithm is likely to get stuck at a local minima, but with enough hidden units the algorithm is likely to converge (but even in this case, the data is still linearly separable and can be learned just by a perceptron). \n\nThe main concern about the paper is the possibility of generalizing the result. The algorithm part seems to heavily rely on the linear separable assumption. The generalization part relies on not making many non-zero updates, which is not really true in realistic settings (where the data is accessed in multiple passes) [After author response: Yes in the linearly separable case with hinge loss it is quite possible that the number of updates is sublinear. However what I meant here is that with more complicated data and different loss functions it is hard to believe that this can still hold.]. The related work section is also a bit unfair to some of the other generalization results (e.g. Bartlett et al. Neyshabur et al.): those results work on more general network settings, and it's not completely clear that they cannot be related to the algorithm because they rely on certain solution specific quantities (such as spectral/Frobenius norms of the weight matrices) and it could be possible that SGD tends to find a solution with small norm (which can be proved in linear setting and might also be provable for the setting of this paper) [This is addressed in the author response].\n\nOverall, even though the assumptions might be a bit strong, I think this is an interesting result working towards a good direction and should be accepted."", 'Summary:\nThis paper considers the problem of classifying linearly separable data with a two layer \\alpha- Leaky ReLU network, in the over-parametrized setting with 2k hidden units. The algorithm used for training is SGD which minimizes the hinge loss error over the training data. The parameters in the top layer are fixed in advance and only the parameters in the hidden layer are updated using SGD. First result shows that the loss function does not have any sub-optimal local minima. Later, for the above method, the paper gives a bound proportional to ||w*||^2/\\alpha^2, on the number of non-zero updates made by the algorithm (similar to perceptron analysis), before converging to a global minima - w*. Using this a generalization error bound independent of number of hidden units is presented. Later the paper studies ReLU networks and shows that loss in this case can have sub-optimal local minima. \n\nComments:\n\nThis paper considers a simpler setting to study why SGD is successful in recovering solutions that generalize well even though the neural networks used are typically over-parametrized. While the paper considers a simpler setting of classifying linearly separable data and training only the hidden layer, it nevertheless provides a useful insight on the role of SGD in recovering solutions that generalize well (independent of number of hidden units \'k\'). \n\nOne confusing aspect in the paper is the optimization and generalization results hold for any global minima w* of the L_s(w). There is a step missing of taking the minimum over all such w*, which will give the tightest bounds for SGD, and it will be useful to clear this up in the paper. \n\nMore importantly I am curious how close the updates are when, 1)SGD is updating only the hidden units  and 2) SGD is updating both the layers. Simple intuition suggests SGD might update the top layer ""more"" that the hidden layer as the gradients tend to decay down the layers. It is useful to discuss this in the paper and may be have some experiments on linearly separable data but with updates in both layers.']","[50, 60, 60]","[75, 70, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the interesting aspects of the paper and its contributions, while also pointing out significant limitations. The initial review was critical, but the updated section shows that the authors addressed the concerns satisfactorily, leading to a more positive overall sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and offers constructive criticism. Phrases like 'I am happy to revisit my current rating' and 'I find these modifications satisfactory' demonstrate a collegial and open-minded approach. The reviewer also clearly outlines pros and cons, providing balanced feedback in a professional manner."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's contributions and novelty, stating it's 'the first result that achieves a number of desirable properties' and 'an interesting result working towards a good direction.' They recommend acceptance despite some concerns. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively presenting concerns. They use phrases like 'ideally, one would also want to see' and 'the main concern' rather than harsh criticisms. The review concludes with a positive recommendation, further indicating a polite and constructive tone."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting that it provides 'useful insight' and considers it a valuable contribution despite its simplified setting. The reviewer acknowledges the paper's merits in studying why SGD is successful in recovering solutions that generalize well. However, it's not extremely positive as the reviewer also points out some confusing aspects and suggests improvements. The politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They offer suggestions for improvement in a considerate manner, using phrases like 'it will be useful to clear this up' and 'I am curious'. The reviewer balances positive feedback with constructive criticism, maintaining a professional and courteous tone throughout the review.""]"
"['This paper presents the SliceNet architecture, an sequence-to-sequence model based on super-dilated convolutions, which allow to reduce the computational cost of the model compared to standard convolution. The proposed model is then evaluated on machine translation and yields competitive performance compared to state-of-the-art approaches.\n\nIn terms of clarity, the paper is overall easy to follow, however I am a bit confused by Section 2 about what is related work and what is a novel contribution, although the section is called “Our Contribution”. For instance, it seems that the separable convolution presented in Section 2.1 were introduced by (Chollet, 2016) and are not part of the contribution of this paper. The authors should thus clarify the contributions of the paper.\n\nIn terms of significance, the SliceNet architecture is interesting and is a solid contribution for reducing computation cost of sequence-to-sequence models. The experiments on NMT are convincing and gives interesting insights, although I would like to see some pointers about why in Table 3 the Transformer approach (Vaswani et al. 2017) outperforms SliceNet.\n\nI wonder if the proposed approach could be applied to other sequence-to-sequence tasks in NLP or even in speech recognition ? \n\nMinor comment: \n* The equations are not easy to follow, they should be numbered. The three equations just before Section 2.2 should also be adapted as they seem redundant with Table 1.\n', 'The paper proposes to use depthwise separable convolution layers in a fully convolutional neural machine translation model. The authors also introduce a new ""super-separable"" convolution layer, which further reduces the computational cost of depthwise separable convolutions. Results are presented on the WMT English to German translation task, where the method is shown to perform second-best behind the Transformer model.\n\nThe paper\'s greatest strength is in my opinion the quality of its exposition of the proposed method. The relationship between spatial convolutions, pointwise convolutions, depthwise convolutions, depthwise separable convolutions, grouped convolutions, and super-separable convolutions is explained very clearly, and the authors properly introduce each model component.\n\nPerhaps as a consequence of this, the experimental section feels squeezed in comparison. Quantitative results are presented in two fairly dense tables (especially Table 2) which, although parsable after reading the paper carefully, could benefit from a little bit more information on how they should be read. The conclusions that are drawn in the text are stated without citing metrics or architectural configurations, leaving it up to the reader to connect the conclusions to the table contents.\n\nOverall, I feel that the results presented make a compelling case both for the effectiveness of depthwise separable convolutions and larger convolution windows, as well as the overall performance achievable by such an architecture. I think the paper constitutes a good contribution, and adjustments to the experimental section could make it a great contribution.', 'Pros:\n- new module\n- good performances (not state-of-the-art)\nCons:\n- additional experiments\n\nThe paper is well motivated, and is purely experimental and proposes a new architecture. However, I believe that more experiments should be performed and the explanations could be more concise.\n\nThe section 3 is difficult to read because the notations of the different formula are a little bit heavy. They were nicely summarised on the Figure 1: each of the formula\' block could be replaced by a figure, which would make this section faster to read and understand.\n\nI would have enjoyed a parameter comparison in Table 3 as it is claimed this architecture has less parameters and additional experiments would be welcome. As it does not reach the state-of-the-art, ""super separable convolutions"" could be compared on other tasks?\n\nminor:\n""In contrast, regular convolutional layers break\nthis creed by learning filters that must simultaneously perform the extraction of spatial features and\ntheir merger into channel dimensions; an inefficient and ineffective use of parameters."" - a verb is missing?\n']","[50, 70, -20]","[70, 80, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and finds the experiments convincing, while also providing constructive criticism and suggestions for improvement. The overall tone is balanced, recognizing both strengths and areas for clarification. The politeness score is 70 (fairly polite) due to the reviewer's use of respectful language throughout. They frame their criticisms as suggestions or questions rather than direct criticisms, using phrases like 'I am a bit confused,' 'I would like to see,' and 'I wonder if.' The reviewer also acknowledges the paper's strengths and significance, which contributes to the polite tone. The language is professional and constructive throughout, without any harsh or rude comments."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper, highlighting its strengths in exposition and the compelling case made by the results. They describe it as a 'good contribution' with potential to be 'great' with some adjustments. The politeness score is 80 (polite) due to the reviewer's constructive and respectful tone throughout. They acknowledge the paper's strengths, offer suggestions for improvement without harsh criticism, and use phrases like 'in my opinion' to soften their statements. The reviewer maintains a professional and courteous tone while providing balanced feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well motivated', 'good performances'), they also express several concerns and suggest significant improvements. The overall tone indicates that the paper needs substantial work before it can be considered acceptable. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or dismissive comments. They use phrases like 'I believe' and 'I would have enjoyed' to soften their critiques, and they balance negative points with positive observations. The reviewer also provides specific, actionable feedback, which is a polite way to help the authors improve their work.""]"
"['This paper proposes an empirical measure of the intrinsic dimensionality of a neural network problem. Taking the full dimensionality to be the total number of parameters of the network model, the authors assess intrinsic dimensionality by randomly projecting the network to a domain with fewer parameters (corresponding to a low-dimensional subspace within the original parameter), and then training the original network while restricting the projections of its parameters to lie within this subspace. Performance on this subspace is then evaluated relative to that over the full parameter space (the baseline). As an empirical standard, the authors focus on the subspace dimension that achieves a performance of 90% of the baseline. The authors then test out their measure of intrinsic dimensionality for fully-connected networks and convolutional networks, for several well-known datasets, and draw some interesting conclusions.\n\nPros:\n\n* This paper continues the recent research trend towards a better characterization of neural networks and their performance. The authors show a good awareness of the recent literature, and to the best of my knowledge, their empirical characterization of the number of latent parameters is original. \n\n* The characterization of the number of latent variables is an important one, and their measure does perform in a way that one would intuitively expect. For example, as reported by the authors, when training a fully-connected network on the MNIST image dataset, shuffling pixels does not result in a change in their intrinsic dimensionality. For a convolutional network the observed 3-fold rise in intrinsic dimension is explained by the authors as due to the need to accomplish the classification task while respecting the structural constraints of the convnet.\n\n* The proposed measures seem very practical - training on random projections uses far fewer parameters than in the original space (the baseline), and presumably the cost of determining the intrinsic dimensionality would presumably be only a fraction of the cost of this baseline training.\n\n* Except for the occasional typo or grammatical error, the paper is well-written and organized. The issues are clearly identified, for the most part (but see below...).\n\nCons:\n\n* In the main paper, the authors perform experiments and draw conclusions without taking into account the variability of performance across different random projections. Variance should be taken into account explicitly, in presenting experimental results and in the definition and analysis of the empirical intrinsic dimension itself. How often does a random projection lead to a high-quality solution, and how often does it not?\n\n* The authors are careful to point out that training in restricted subspaces cannot lead to an optimal solution for the full parameter domain unless the subspace intersects the optimal solution region (which in general cannot be guaranteed). In their experiments (FC networks of varying depths and layer widths for the MNIST dataset), between projected and original solutions achieving 90% of baseline performance, they find an order of magnitude gap in the number of parameters needed. This calls into question the validity of random projection as an empirical means of categorizing the intrinsic dimensionality of a neural network.\n\n* The authors then go on to propose that compression of the network be achieved by random projection to a subspace of dimensionality greater than or equal to the intrinsic dimension. However, I don\'t think that they make a convincing case for this approach. Again, variation is the difficulty: two different projective subspaces of the same dimensionality can lead to solutions that are extremely different in character or quality. How then can we be sure that our compressed network can be reconstituted into a solution of reasonable quality, even when its dimensionality greatly exceeds the intrinsic dimension?\n\n* The authors argue for a relationship between intrinsic dimensionality and the minimum description length (MDL) of their solution, in that the intrinsic dimensionality should serve as an upper bound on the MDL. However they don\'t formally acknowledge that there is no standard relationship between the number of parameters and the actual number of bits needed to represent the model - it varies from setting to setting, with some parameters potentially requiring many more bits than others. And given this uncertain connection, and given the lack of consideration given to variation in the proposed measure of intrinsic dimensionality, it is hard to accept that ""there is some rigor behind"" their conclusion that LeNet is better than FC networks for classification on MNIST because its empirical intrinsic dimensionality score is lower.\n\n* The experimental validation of their measure of intrinsic dimension could be made more extensive. In the main paper, they use three image datasets - MNIST, CIFAR-10 and ImageNet. In the supplemental information, they report intrinsic dimensions for reinforcement learning and other training tasks on four other sets.\n\nOverall, I think that this characterization does have the potential to give insights into the performance of neural networks, provided that variation across projections is properly taken into account. For now, more work is needed.\n\n====================================================================================================\nAddendum:\n\nThe authors have revised their paper to take into account the effect of variation across projections, with results that greatly strengthen their results and provide a much better justification of their approach. I\'m satisfied too with their explanations, and how they incorporated them into their revised version. I\'ve adjusted my rating of the paper accordingly.\n\nOne point, however: the revisions seem somewhat rushed, due to the many typos and grammatical errors in the updated sections. I would like to encourage the authors to check their manuscript once more, very carefully, before finalizing the paper.\n====================================================================================================', '[ =============================== REVISION =========================================================]\nMy questions are answered, paper undergone some revision to clarify the presentation. I still maintain that it is a good paper and argue for acceptance - it provides a witty way of checking whether the network is overparameterized. Mnist  with shuffled labels is a great example that demonstrates the value of the approach, I would though have moved the results of it into the main paper, instead of supplemental materials\n[ ======================== END OF REVISION =========================================================]\n\nAuthors introduce ransom subspace training (random subspace neural nets) where for a fixed architecture, only a subset of the parameters is trained, and the update for all the parameters is derived via random projection which is fixed for the duration of the training. Using this type of a network, authors introduce a notion of intrinsic dimension of optimization problems - it is minimal dimension of a subset, for which random subset neural net already reaches best (or comparable) performance.\nAuthors mention that this can be used for compressing networks - one would need to store the seed for the random matrix and the # of params equal to the intrinsic dimension of the net. \nThey then demonstrate that the intrinsic dimension for the same problem stays the same when different architectures are chosen. Finally they mention neural nets with comparable number of params to intrinsic dimension but that don’t use random subspace trick don’t achieve comparable performance. This does not always hold for CNNs\nModel with smaller intrinsic dimension is suggested to be better . They also suggest that intrinsic dimension might be a good approximation to Minimum Description Length metric\n\nMy main concern is computational efficiency. They state that if used for compressing, their method  is different from post-train compression, and the authors state that they train once end-to-end. It is indeed the case that once they found model that performs well, it is easy to compress, however they do train a number of models (up to a number of intrinsic dimension) until they get to this admissible model, which i envision would be computationally very expensive.\n\nQuestions:\n- Are covets always better on MNIST: didn’t understand when authors said that intrinsic dimension of FC on shuffled data stayed the same (why) and then say that it becomes 190K - which one is correct?\n- MNIST - state the input dimension size, not clear how you got to that number of parameters overall\n', 'While deep learning usually involves estimating a large number of variable, this paper suggests to reduce its number by assuming that these variable lie in a low-dimensional subspace. In practice, this subspace is chosen randomly. Simulations show the promise of the proposed method.  In particular, figure 2 shows that the number of parameters could be greatly reduced while keeping 90% of the performance; and figure 4 shows that this method outperforms the standard method. The method is clearly written and the idea looks original. \n\nA con that I have is about the comparison in figure 4. While the proposed subspace method might have the same number of parameters as the direct method, I wonder if it is a fair comparison since the subspace method could still be more computational expensive, due to larger number of latent variables.\n\n']","[50, 70, 80]","[80, 60, 60]","[""The sentiment score is 50 (slightly positive) because the review begins with a balanced overview of the paper's proposal and lists both pros and cons. The reviewer acknowledges the paper's originality and potential contributions, but also points out several significant issues. The addendum indicates that the authors addressed some concerns, leading to a more positive overall sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts, and provides constructive criticism. The reviewer uses phrases like 'to the best of my knowledge' and 'I think that' to soften criticisms, and the addendum shows appreciation for the authors' revisions. The only slightly impolite element is the final comment about typos and grammatical errors, but it's framed as encouragement rather than harsh criticism."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, stating it's a 'good paper' and arguing for its acceptance. They praise the paper's 'witty way' of checking network overparameterization and call the MNIST example 'great'. The reviewer does raise some concerns and questions, but these are presented as constructive feedback rather than major criticisms. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively. They frame their concerns as questions or suggestions rather than direct criticisms. The reviewer maintains a professional tone, balancing praise with constructive feedback. However, the review doesn't go out of its way to be excessively polite, maintaining a straightforward, academic tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They highlight the promise of the proposed method, its clear writing, and originality. The reviewer mentions that simulations show good results, particularly in figures 2 and 4. The only con mentioned is a question about fair comparison, which doesn't significantly detract from the overall positive sentiment. The politeness score is 60 (moderately polite) because the reviewer uses respectful and professional language throughout. They acknowledge the paper's strengths and frame their concern as a question rather than a criticism. However, the review doesn't go out of its way to be exceptionally polite, maintaining a neutral, professional tone.""]"
"[""This paper focuses on imitation learning with intentions sampled \nfrom a multi-modal distribution. The papers encode the mode as a hidden \nvariable in a stochastic neural network and suggest stepping around posterior \ninference over this hidden variable (which is generally required to \ndo efficient maximum likelihood) with a biased importance \nsampling estimator. Lastly, they incorporate attention for large visual inputs. \n\nThe unimodal claim for distribution without randomness is weak. The distribution \ncould be replaced with a normalizing flow. The use of a latent variable \nin this setting makes intuitive sense, but I don't think multimodality motivates it.\n\nMoreover, it really felt like the biased importance sampling approach should be \ncompared to a formal inference scheme. I can see how it adds value over sampling \nfrom the prior, but it's unclear if it has value over a modern approximate inference \nscheme like a black box variational inference algorithm or stochastic gradient MCMC.\n\nHow important is using the pretrained weights from the deterministic RNN?\n\nFinally, I'd also be curious about how much added value you get from having \naccess to extra rollouts.\n"", 'The authors propose a new sampling based approach for inference in latent variable models. They apply this approach to multi-modal (several ""intentions"") imitation learning and demonstrate for a real visual robotics task that the proposed framework works better than deterministic neural networks and stochastic neural networks. \n\nThe proposed objective is based upon sampling from the latent prior and truncating to the largest alpha-percentile likelihood values sampled. The scheme is motivated by the fact that this estimator has a lower variance than pure sampling from the prior. The objective to be maximized is a lower bound to 1/alpha * the likelihood. \n\nQuality: The empirical results (including a video of an actual robotic arm system performing the task) looks good. This reviewer is a bit sceptical to the methodology. I am not convinced that the proposed bound will have low enough variance. It is mentioned in a footnote that variational autoencoders were tested but that they failed. Since the variational bound has much better sampling properties (due to recognition network, reparameterization trick and bounding to get log likelihoods instead of likelihoods) it is hard to believe that it is harder to get to work than the proposed framework. Also, the recently proposed continuous relaxation of random variables seemed relevant. \n\nClarity: The paper is fairly clearly written but there are many steps of engineering that somewhat dilutes the methodological contribution.\n\nSignificance: Hard to say. New method proposed and shown to work well in one case. Too early to tell about significance.\n\nPro:\n1. Challenging and relevant problem solved better than other approaches.\n2. New latent variable model bound that might work better than classic approaches.\nCon:\n1. Not entirely convincing that it should work better than already existing methods.\n2. Missing some investigation of the properties of the estimator on simple problem to be compared to standard methods.     ', 'The authors provide a method for learning from demonstrations where several modalities of the same task are given. The authors argue that in the case where several demonstrations exists and a deterministic (i.e., regular network) is given, the network learns some average policy from the demonstrations.\n\nThe paper begins with the authors stating the motivation and problem of how to program robots to do a task based only on demonstrations rather on explicit modeling or programming. They put the this specific work in the right context of imitation learning and IRL. Afterward, the authors argue that deterministic network cannot adequately several modalities. The authors cover in Section 2 related topics, and indeed the relevant literature includes behavioral cloning, IRL , Imitation learning, GAIL, and VAEs. I find that recent paper by Tamar et al 2016. on Value Iteration Networks is highly relevant to this work: the authors there learn similar tasks (i.e., similar modalities) using the same network. Even the control task is very similar to the current proposed task in this paper.\n\nThe authors argue that their contribution is 3-fold: (1) does not require robot  rollouts, (2) does not require label for a task, (3) work within raw image inputs. Again, Tamar et al. 2016 deals with this 3 points.\n\nI went over the math. It seems right and valid. Indeed, SNN is a good choice for adding (Bayesian) context to a task. Also, I see the advantage of referring only to the ""good"" quantiles when needed. It is indeed a good method for dealing with the variance. \n\nI must say that I was impressed with the authors making the robot succeed in the tasks in hand (although reaching to an object is fairly simple task). \n\nMy concerns are as follows:\n1) Seems like that the given trajectories are naturally divided with different tasks, i.e., a single trajectory consists only a single task. For me, this is not the pain point in this tasks. the pain point is knowing when tasks are begin and end. \n2) I\'m not sure, and I haven\'t seen evidence in the paper (or other references) that SNN is the only (optimal?) method for this context. Why not adding (non Bayesian) context (not label) to the task will not work as well? \n3) the robot task is impressive. but proving the point, and for the ease of comparing to different tasks, and since we want to show the validity of the work on more than 200 trials, isn\'t showing the task on some simulation is better for understanding the different regimes that this method has advantage? I know how hard is to make robotic tasks work...   \n4) I’m not sure that the comparison of the suggested architecture to one without any underlying additional variable Z or context (i.e., non-Bayesian setup) is fair. ""Vanilla"" NN indeed may fail miserably . So, the comparison should be to any other work that can deal with ""similar environment but different details"".\n\nTo summarize, I like the work and I can see clearly the motivation. But I think some more work is needed in this work: comparing to the right current state of the art, and show that in principal (by demonstrating on other simpler simulations domains) that this method is better than other methods.  \n\n']","[-20, -20, 20]","[50, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's focus and approach, they express several criticisms and doubts about the methodology. They describe the unimodal claim as 'weak', question the motivation for using a latent variable, and suggest that the approach should be compared to formal inference schemes. The reviewer also raises questions about the importance of certain aspects of the method.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns, such as 'I don't think' and 'I'd be curious about', rather than using harsh or dismissive language. The reviewer also acknowledges the intuitive sense of some aspects of the paper. However, the score is not higher because the review is primarily focused on critiques and doesn't offer much positive feedback or encouragement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('empirical results... looks good'), they express skepticism about the methodology and are not fully convinced of its superiority over existing methods. The reviewer also mentions cons and areas for improvement, indicating a somewhat critical stance. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They present their concerns as personal opinions ('This reviewer is a bit skeptical') and use phrases like 'Hard to say' and 'Too early to tell' which soften potential negative feedback. The review maintains a balanced tone, acknowledging both pros and cons of the work."", ""The sentiment score is slightly positive (20) because while the reviewer expresses some appreciation for the work ('I was impressed', 'I like the work'), they also raise several concerns and suggest that 'more work is needed'. The overall tone is constructive but not overwhelmingly positive. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms as 'concerns' rather than outright flaws. They use phrases like 'I must say', 'I'm not sure', and 'I think' which soften their critiques. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback.""]"
"['Summary: The authors show that using visual modality as a pivot they can train a model to translate from L1 to L2. \n\nPlease find my detailed comments/questions/suggestions below:\n\n1) IMO, the paper could have been written much better. At the core, this is simply a model which uses images as a pivot for learning to translate between L1 and L2 by learning a common representation space for {L1, image} or {L2, image}. There are several works on such multimodal representation learning but the authors present their work in a way which makes it look very different from these works. IMO, this leads to unnecessary confusion and does more harm than good. For example, the abstract gives an impression that the authors have designed a game to collect data (and it took me a while to set this confusion aside).\n\n2) Continuing on the above point, this is essentially about learning a common multimodal representation and then decode from this common representation. However, the authors do not cite enough work on such multimodal representation learning (for example, look at Spandana et. al.: Image Pivoting for Learning Multilingual Multimodal Representations, EMNLP 2017 for a good set of references)\n\n3) This omission of related work also weakens the experimental section. At least for the word translation task many of these common representation learning frameworks could have been easily evaluated. For example, find the nearest german neighbour of the word ""dog"" in the common representation space. The authors instead compare with very simple baselines.\n\n4) Even when comparing with simple baselines, the proposed model does not convincingly outperform them. In particular,  the P@5 and P@20 numbers are only slightly better. \n\n5) Some of the choices made in the Experimental setup seem questionable to me:\n   - Why  use a NMT model without attention? That is not standard and does not make sense to use when a better baseline model (with attention) is available ?\n   - It is mentioned that ""While their model unit-normalizes the output of every encoder, we found this to consistently hurt performance, so do not use normalization for fair comparison with our models."" I don\'t think this is a fair comparison. The authors can mention their results without normalization if that works well for them but it is not fair to drop normalization from the model of N&N if that gives better performance. Please mention the numbers with unit normalization to give a better picture. It does not make sense to weaken an existing baseline and then compare with it.\n\n6) It would be good to mention the results of the NMT model in Table 1 itself instead of mentioning them separately in a paragraph. This again leads to poor readability and it is hard to read and compare the corresponding numbers from Table 1.  I am not sure why this cannot be accommodated in the Table itself.\n\n7) In Figure 2, what exactly do you mean by ""Results are averaged over 30 translation scenarios"". Can you please elaborate ?', 'Summary: \n\nThis paper proposes a multi-agent communication task where the agents learn to translate as a side-product to solving the communication task. Authors use the image modality as a bridge between two different languages and the agents learn to ground different languages to same image based on the similarity. This is achieved by learning to play the game in both directions. Authors show results in a word-level translation task and also a sentence-level translation task. They also show that having more languages help the agent to learn better.\n\nMy comments:\n\nThe paper is well-written and I really enjoyed reading this paper. While the idea of pivot based common representation learning for language pairs with no parallel data is not new, adding the communication aspect as an additional supervision is novel. However I would encourage authors to rephrase their claim of emergent translation (the title is misleading) as the authors pose this as a supervised problem and the setting has enough constraints to learn a common representation for both languages (bridged by the image) and hence there is no autonomous emergence of translation out of need. I see this work as adding communication to improve the translation learning.\n\nIs your equation 1 correct? I understand that your logits are reciprocal of mean squared error. But don’t you need a softmax before applying the NLL loss mentioned in equation 1? In current form of equation 1, I think you are not including the distractor images into account while computing the loss? Please clarify.\n\nWhat is the size of the vocabulary used in all the experiments? Because Gumbel Softmax doesn’t scale well to larger vocabulary sizes and it would be worth mentioning the size of your vocabulary in all the experiments.\n\nAre you willing to release the code for reproducing the results?\n\nMinor comments:\n\nIn appendix C, Table 4 caption: you say target sentence is “Trg” but it is “Ref” in the table. Also is the reference sentence for skateboard example typo-free?\n', ""--------------\nSummary and Evaluation:\n--------------\nThis work present a novel multi-agent reference game designed to train monolingual agents to perform translation between their respective languages -- all without parallel corpora. The proposed approach closely mirrors that of Nakayama and Nishida, 2017 in that image-aligned text is encouraged to map to similarly to the grounded image. Unlike in this previous work, the approach proposed here induces this behavior though a multi-agent reference game. The key distinction being that in this gamified setting, the agents sample many more descriptions from their stochastic policies than would otherwise be covered by the human ground truth. The authors demonstrate that this change results in significantly improved BLEU scores across a number of translation tasks. Furthermore, increasing the number of agents/languages in this setting seems to \n\nOverall I think this is an interesting paper. The technical novelty is somewhat limited to a minor (but powerful) change in approach from Nakayama and Nishida, 2017; however, the resulting translators outperform this previous method. I have a few things listed in the weaknesses section that I found unclear or think would make for a stronger submission.\n\n\n--------------\nStrengths:\n--------------\n\n- The paper is fairly clearly written and the figures appropriately support the text.\n\n- Learning translation without parallel corpora is a useful task and leveraging a pragmatic reference game to induce additional semantically valid samples of a source language is an interesting approach to do so.\n\n- I'm also excited by the result that multi-agent populations tend to improve the rate of convergence and final translation abilities of these models; though I'm slightly confused about some of the results here (see weaknesses).\n\n--------------\nWeaknesses:\n--------------\n\n- Perhaps I'm missing something, but shouldn't the Single EN-DE/DE-EN results in Table 2 match the not pretrained EN-DE/DE-EN Multi30k Task 1 results? I understand that this is perhaps on a different data split into M1/2 but why is there such a drastic difference?\n\n- I would have liked to see some context as how these results compare to an approach trained with aligned corpora. Perhaps a model trained on the human-translated pairs from Task 1 of Multi30k? Obviously, outperforming such a model is not necessary for this approach to be interesting, but it would provide useful context on how well this is doing.\n\n- A great deal of the analysis and qualitative examples are pushed to the supplement which is a bit of a shame given they are quite interesting.\n\n\n""]","[-50, 60, 60]","[20, 80, 70]","[""The sentiment score is -50 because the reviewer expresses several criticisms and concerns about the paper, including poor writing, omission of related work, questionable experimental choices, and unconvincing results compared to baselines. However, it's not entirely negative as the reviewer acknowledges the core idea and provides constructive feedback. The politeness score is 20 because while the reviewer is direct in their criticisms, they use polite language like 'IMO' (in my opinion) and 'please' when making requests. They also provide detailed explanations for their concerns, which is a respectful approach. The reviewer maintains a professional tone throughout, even when pointing out significant issues."", ""The sentiment score is 60 (positive) because the reviewer expresses enjoyment in reading the paper and acknowledges its novelty, while also providing constructive criticism. The overall tone is supportive, but not overwhelmingly positive due to some concerns raised. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offers praise where due, and frames criticisms as suggestions or questions rather than direct attacks. Phrases like 'I really enjoyed reading this paper' and 'I would encourage authors to' demonstrate a courteous approach. The reviewer also asks politely about code release and uses 'please clarify' when seeking information, further indicating a respectful tone."", ""The sentiment score is 60 (moderately positive) because the reviewer states 'Overall I think this is an interesting paper' and notes several strengths, while also mentioning some weaknesses. They seem generally positive about the work despite some criticisms. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. Phrases like 'I would have liked to see' and 'Perhaps I'm missing something' maintain a polite tone even when pointing out potential issues.""]"
"['This paper aims at better understanding the functional role of grid cells found in the entorhinal cortex by training an RNN to perform a navigation task.\n\nOn the positive side: \n\nThis is the first paper to my knowledge that has shown that grid cells arise as a product of a navigation task demand. I enjoyed reading the paper which is in general clearly written. I have a few, mostly cosmetic, complaints but this can easily be addressed in a revision.\n\nOn the negative side: \n\nThe manuscript is not written in a way that is suitable for the target ICLR audience which will include, for the most part, readers that are not expert on the entorhinal cortex and/or spatial navigation. \n\nFirst, the contributions need to be more clearly spelled out. In particular, the authors tend to take shortcuts for some of their statements. For instance, in the introduction, it is stated that previous attractor network type of models (which are also recurrent networks) “[...] require hand-crafted and fined tuned connectivity patterns, and the evidence of such specific 2D connectivity patterns has been largely absent.” This statement is problematic for two reasons: \n\n(i) It is rather standard in the field of computational neuroscience to start from reasonable assumptions regarding patterns of neural connectivity then proceed to show that the resulting network behaves in a sensible way and reproduces neuroscience data. This is not to say that demonstrating that these patterns can arise as a byproduct is not important, on the contrary. These are just two complementary lines of work. In the same vein, it would be silly to dismiss the present work simply because it lacks spikes. \n\n(ii) the authors do not seem to address one of the main criticisms they make about previous work and in particular ""[a lack of evidence] of such specific 2D connectivity patterns"". My understanding is that one of the main assumptions made in previous work is that of a center-surround pattern of lateral connectivity. I would argue that there is a lot of evidence for local inhibitory connection in the cortex. Somewhat related to this point, it would be insightful to show the pattern of local connections learned in the RNN to see how it differs from the aforementioned pattern of connectivity.\n\nSecond, the navigation task used needs to be better justified. Why training a network to predict 2D spatial location from velocity inputs? Why is this a reasonable starting point to study the emergence of grid cells? It might be obvious to the authors but it will not be to the ICLR audience. Dead-reckoning (i.e., spatial localization from velocity inputs) is of critical ecological relevance for many animals. This needs to be spelled out and a reference needs to be added.  As a side note, I would have expected the authors to use actual behavioral data but instead, the network is trained using artificial trajectories based on ""modified Brownian motion”. This seems like an important assumption of the manuscript but the issue is brushed off and not discussed. Why is this a reasonable assumption to make? Is there any reference demonstrating that rodent locomotory behavior in a 2D arena is random?\n\nFigure 4 seems kind of strange. I do not understand how the “representative units” are selected and where the “late” selectivity on the far right side in panel a arises if not from “early” units that would have to travel “far” from the left side… Apologies if I am missing something obvious.\n\nI found the study of the effect of regularization to be potentially the most informative for neuroscience but it is only superficially treated. It would have been nice to see a more systematic treatment of the specifics of the regularization needed to get grid cells. ', 'Congratulations on a very interesting and clear paper.  While ICLR is not focused on neuroscientific studies, this paper clearly belongs here as it shows what representations develop in recurrent networks that are trained on spatial navigation. Interestingly, these include representations that have been observed in mammals and that have attracted considerable attention, even honored with a Nobel prize. \n\nI found it is very interesting that the emergence of these representations was contingent on some regularization constraint. This seems similar to the visual domain where edge detectors emerge easily when trained on natural images with sparseness constraints as in Olshausen&Field and later reproduced with many other models that incorporate sparseness constraints. \n\nI do have some questions about the training itself. The paper mentions a metabolic cost that is not specified in the paper. This should be added. \n\nMy biggest concern is about Figure 6a. I am puzzled why is the error is coming down before the boundary interaction? Even more puzzling, why does this error go up again for the blue curve (no interaction)? Shouldn’t at least this curve be smooth?\n', 'The authors train an RNN to perform deduced reckoning (ded reckoning) for spatial navigation, and then study the responses of the model neurons in the RNN. They find many properties reminiscent of neurons in the mammalian entorhinal cortex (EC): grid cells, border cells, etc. When regularization of the network is not used during training, the trained RNNs no longer resemble the EC. This suggests that those constraints (lower overall connectivity strengths, and lower metabolic costs) might play a role in the EC\'s navigation function. \n\nThe paper is overall quite interesting and the study is pretty thorough: no major cons come to mind. Some suggestions / criticisms are given below.\n\n1) The findings seem conceptually similar to the older sparse coding ideas from the visual cortex. That connection might be worth discussing because removing the regularizing (i.e., metabolic cost) constraint from your RNNS makes them learn representations that differ from the ones seen in EC. The sparse coding models see something similar: without sparsity constraints, the image representations do not resemble those seen in V1, but with sparsity, the learned representations match V1 quite well. That the same observation is made in such disparate brain areas (V1, EC) suggests that sparsity / efficiency might be quite universal constraints on the neural code.\n\n2) The finding that regularizing the RNN makes it more closely match the neural code is also foreshadowed somewhat by the 2015 Nature Neuro paper by Susillo et al. That could be worthy of some (brief) discussion.\n\nSussillo, D., Churchland, M. M., Kaufman, M. T., & Shenoy, K. V. (2015). A neural network that finds a naturalistic solution for the production of muscle activity. Nature neuroscience, 18(7), 1025-1033.\n\n3) Why the different initializations for the recurrent weights for the hexagonal vs other environments? I\'m guessing it\'s because the RNNs don\'t ""work"" in all environments with the same initialization (i.e., they either don\'t look like EC, or they don\'t obtain small errors in the navigation task). That seems important to explain more thoroughly than is done in the current text.\n\n4) What happens with ongoing training? Animals presumably continue to learn throughout their lives. With on-going (continous) training, do the RNN neurons\' spatial tuning remain stable, or do they continue to ""drift"" (so that border cells turn into grid cells turn into irregular cells, or some such)? That result could make some predictions for experiment, that would be testable with chronic methods (like Ca2+ imaging) that can record from the same neurons over multiple experimental sessions.\n\n5) It would be nice to more quantitatively map out the relation between speed tuning, direction tuning, and spatial tuning (illustrated in Fig. 3). Specifically, I would quantify the cells\' direction tuning using the circular variance methods that people use for studying retinal direction selective neurons. And I would quantify speed tuning via something like the slope of the firing rate vs speed curves. And quantify spatial tuning somehow (a natural method would be to use the sparsity measures sometimes applied to neural data to quantify how selective the spatial profile is to one or a few specific locations). Then make scatter plots of these quantities against each other. Basically, I\'d love to see the trends for how these types of tuning relate to each other over the whole populations: those trends could then be tested against experimental data (possibly in a future study).']","[20, 80, 80]","[60, 70, 90]","[""The sentiment score is slightly positive (20) because the reviewer starts with positive comments, acknowledging the paper's novelty and clarity. However, they also express several criticisms and areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, even when expressing criticisms. They use phrases like 'I enjoyed reading the paper' and 'Apologies if I am missing something obvious,' which contribute to a polite tone. The reviewer also frames their criticisms constructively, suggesting improvements rather than simply pointing out flaws. The balance of positive and negative feedback, along with the consistently respectful language, informs both the sentiment and politeness scores."", ""The sentiment score is 80 (positive) because the review starts with congratulations and describes the paper as 'very interesting and clear'. The reviewer expresses strong interest in the findings and their relevance to the field. While there are some questions and concerns raised, they are presented as constructive feedback rather than criticisms. The politeness score is 70 (polite) due to the congratulatory opening, the use of positive language throughout ('very interesting', 'clearly belongs here'), and the respectful way in which questions and concerns are raised. The reviewer maintains a professional and courteous tone, even when pointing out areas that need clarification or improvement. The scores are not 100 because there is some critique present, but overall the review is very positive and politely worded."", ""The sentiment score is 80 (positive) because the reviewer starts by stating that the paper is 'overall quite interesting' and the study is 'pretty thorough'. They mention that 'no major cons come to mind', which is a strong positive indicator. The suggestions are framed as constructive feedback rather than criticisms. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, such as 'suggestions / criticisms are given below' instead of demanding changes. They use phrases like 'might be worth discussing' and 'could be worthy of some (brief) discussion', which are polite ways of making suggestions. The reviewer also asks questions and makes recommendations in a non-confrontational manner, using phrases like 'Why the different initializations' and 'It would be nice to more quantitatively map out'. The overall tone is collaborative and supportive, aiming to improve the paper rather than criticize it harshly.""]"
"['The paper addresses the important problem of planning in partially observable environments with sparse rewards, and the empirical verification over several domains is convincing. My main concern is that the structure of these domains is very similar - essentially, a graph where only neighboring vertices are directly observable, and because of this, the proposed architecture might not be applicable to planning in general POMDPs (or, in their continuous counterparts, state-space models). The authors claim that what is remembered by the planner does not take the form of a map, but isn\'t the map estimate \\hat{m} introduced at the end of Section 2.1 precisely such a map? From Section 2.4, it appears that these map estimates are essential in computing the low-level policies from which the final, high-level policy is computed. If the ability to maintain and use such local maps is essential for this method, its applicability is likely restricted to this specific geometric structure of domains and their observability. \n\nSome additional comments:\n\nP. 2, Section 2.1: does H(s) contain 0s for non-observable and 1s for observable states? If yes, please state it.\n\nP. 3: the concatenation of state and observation histories is missing from the definition of the transition function.\n\nP. 3, Eq. 1: overloaded notation - if T is the transition function for the large MDP on histories, it should not be used for the transition function between states. Maybe the authors meant to use f() for that transition?\n\nP. 3, Eq. 3: the sum is over i, but it is not clear what i indexes.\n\nP.3, end of Section 2.1: when computing the map estimate \\hat{m}, shouldn\'t the operator be min, that is, a state is assumed to be open (0), unless one or more observations show that it is blocked (-1)?\n\nP.5: the description of the reward function is inconsistent - is it 0 at the goal state, or >0?\n\nP. 11, above Fig. 9: typo, ""we observe that the in the robot world""\n \n ', 'Summary:\n\nA method is proposed for robot navigation in partially observable scenarios. E.g. 2D navigation in a grid world from start to goal but the robot can only sense obstacles in a certain radius around it. A learning-based method is proposed here which takes the currently discovered partial map as input to convolutional layers and then passes through K-iterations of a VIN module to a final controller. The controller takes as input both the convolutional features, the VIN module and has access to a differential memory module. A linear layer takes inputs from both the controller and memory and predicts the next step of the robot. This architecture is termed as MACN.\n\nIn experiments on 2D randomly generated grid worlds, general graphs and a simulated ground robot with a lidar, it is shown that memory is important for navigating partially observable environments and that the VIN module is important to the architecture since a CNN replacement doesn\'t perform as well. Also larger start-goal distances can be better handled by increasing the memory available.\n\nComments:\n\n- My main concern is that there are no non-learning based obvious baselines like A*, D*, D*-Lite and related motion planners which have been used for this exact task very successfully and run on real-world robots like the Mars rover. In comparison to the size of problems that can be handled by such planners the experiments shown here are much smaller and crucially the network can output actions which collide with obstacles while the search-based planners by definition will always produce feasible paths and require no training data. I would like to see in the experimental tables, comparison to path lengths produced by MACN vs. those produced by D*-Lite or Multi-Heuristic A*. While it is true that motion-planning will keep the entire discovered map in memory for the problem sizes shown here (2D maps: 16x16, 32x32, 64x64 bitmaps, general graphs: 9, 16, 25, 36 nodes) that is on the order of a few kB memory only. For the 3D simulated robot which is actually still treated as a 2D task due to the line lidar scanner MxN bitmap is not specified but even a few Mb is easily handled by modern day embedded systems. I can see that perhaps when map sizes exceed say tens of Gbs then perhaps MACN\'s memory will be smaller to obtain similar performance since it may learn better map compression to better utilize the smaller budget available to it. But experiments at that scale have not been shown currently.\n\n- Figure 1: There is no sensor (lidar or camera or kinect or radar) which can produce the kind of sensor observations shown in 1(b) since they can\'t look beyond occlusions. So such observations are pretty unrealistic.\n\n- ""The parts of the map that lie within the range of the laser scanner are converted to obstacle-free ..."": How are occluded regions marked?', 'The paper presents a method for navigating in an unknown and partially observed environment is presented. The proposed approach splits planning into two levels: 1) local planning based on the observed space and 2) a global planner which receives the local plan, observation features, and access to an addressable memory to decide on which action to select and what to write into memory. \n\nThe contribution of this work is the use of value iteration networks (VINs) for local planning on a locally observed map that is fed into a learned global controller that references history and a differential neural computer (DNC), local policy, and observation features select an action and update the memory. The core concept of learned local planner providing additional cues for a global, memory-based planner is a clever idea and the thorough analysis clearly demonstrates the benefit of the approach.\n\nThe proposed method is tested against three problems: a gridworld, a graph search, and a robot environment. In each case the proposed method is more performant than the baseline methods.  The ablation study of using LSTM instead of the DNC and the direct comparison of CNN + LSTM support the authors’ hypothesis about the benefits of the two components of their method. While the author’s compare to DRL methods with limited horizon (length 4), there is no comparison to memory-based RL techniques. Furthermore, a comparison of related memory-based visual navigation techniques on domains for which they are applicable should be considered as such an analysis would illuminate the relative performance over the overlapping portions problem domains  For example, analysis of the metric map approaches on the grid world or of MACN on their tested environments.\n\nPrior work in visual navigation in partially observed and unknown environments have used addressable memory (e.g., Oh et al.) and used VINs (e.g., Gupta et al.) to plan as noted. In discussing these methods, the authors state that these works are not comparable as they operate strictly on discretized 2d spaces. However, it appears to the reviewer that several of these methods can be adapted to higher dimensions and be applicable at least a subclass (for the euclidean/metric map approaches) or the full class of the problems (for Oh et al.), which appears to be capable to solve non-euclidean tasks like the graph search problem. If this assessment is correct, the authors should differentiate between these approaches more thoroughly and consider empirical comparisons. The authors should further consider contrasting their approach with “Neural SLAM” by Zhang et al.\n\nA limitation of the presented method is requirement that the observation “reveals the labeling of nearby states.” This assumption holds in each of the examples presented: the neighborhood map in the gridworld and graph examples and the lidar sensor in the robot navigation example. It would be informative for the authors to highlight this limitation and/or identify how to adapt the proposed method under weaker assumptions such as a sensor that doesn’t provide direct metric or connectivity information such as a RGB camera. \n\nMany details of the paper are missing and should be included to clarify the approach and ensure reproducible results. The reviewer suggests providing both more details in the main section of the paper and providing the precise architecture including hyperparameters in the supplementary materials section. \n']","[-20, -30, 50]","[60, 20, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem and the convincing empirical verification, they express a 'main concern' about the applicability of the proposed architecture to general POMDPs. This concern forms a significant part of the review and is followed by several additional comments and questions, indicating areas that need clarification or improvement.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They frame their main concern as a question rather than a direct criticism, and their additional comments are presented as constructive feedback rather than harsh critiques. The use of phrases like 'please state it' and the identification of a typo at the end show a helpful and courteous approach. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional tone throughout."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the work (e.g., showing the importance of memory and the VIN module), they express significant concerns about the lack of comparison to non-learning baselines and unrealistic sensor observations. The overall tone suggests the reviewer is not fully convinced by the approach. The politeness score is 20 because the reviewer uses professional and respectful language throughout, framing criticisms as suggestions (e.g., 'I would like to see...') rather than direct attacks. However, the review is not overly effusive or polite, maintaining a neutral, professional tone focused on scientific critique."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and clever ideas, noting that it 'clearly demonstrates the benefit of the approach.' However, they also point out limitations and areas for improvement, balancing the positive aspects. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'the authors should consider' and 'it would be informative,' which maintain a professional and courteous tone. The review is thorough and detailed, providing specific recommendations for improvement without being confrontational or dismissive.""]"
"[""This paper investigates numerically and theoretically the reasons behind the empirical success of binarized neural networks. Specifically, they observe that:\n\n(1) The angle between continuous vectors sampled from a spherical symmetric distribution and their binarized version is relatively small in high dimensions (proven to be about 37 degrees when the dimension goes to infinity), and this demonstrated empirically to be true for the binarized weight matrices of a convenet.\n\n(2) Except the first layer, the dot product of weights*activations in each layer is highly correlated with the dot product of (binarized weights)*activations in each layer. There is also a strong correlation between (binarized weights)*activations and (binarized weights)*(binarized activations). This is claimed to entail that the continuous weights of the binarized neural net approximate the continuous weights of a non-binarized neural net trained in the same manner.\n\n(3) To correct the issue with the first layer in (2) it is suggested to use a random rotation, or simply use continues weights in that layer.\n\nThe first observation is interesting, is explained clearly and convincingly, and is novel to the best of my knowledge.\n\nThe second observation is much less clear to me. Specifically,\na.\tThe author claim that “A sufficient condition for \\delta u to be the same in both cases is L’(x = f(u)) ~ L’(x = g(u))”. However, I’m not sure if I see why this is true: in a binarized neural net, u also changes, since the previous layers are also binarized. \nb.\tRelated to the previous issue, it is not clear to me if in figure 3 and 5, did the authors binarize the activations of that specific layer or all the layers? If it is the first case, I would be interested to know the latter: It is possible that if all layers are binarized, then the differences between the binarized and non-binarized version become more amplified.\nc.\tFor BNNs, where both the weights and activations are binarized, shouldn’t we compare weights*activations to (binarized weights)*(binarized activations)?\nd.\tTo make sure, in figure 4, the permutation of the activations was randomized (independently) for each data sample? If not, then C is not proportional the identity matrix, as claimed in section 5.3.\ne.\tIt is not completely clear to me that batch-normalization takes care of the scale constant (if so, then why did XNOR-NET needed an additional scale constant?), perhaps this should be further clarified. \n\nThe third observation seems less useful to me. Though a random rotation may improve angle preservation in certain cases (as demonstrated in Figure 4), it may hurt classification performance (e.g., distinguishing between 6 and 9 in MNIST). Furthermore, since it uses non-binary operations, it is not clear if this rotation may have some benefits (in terms of resource efficiency) over simply keeping the input layer non-binarized.\n\nTo summarize, the first part is interesting and nice, the second part was not clear to me, and the last part does not seem very useful. \n\n%%% After Author's response %%%\na. My mistake. Perhaps it should be clarified in the text that u are the weights. I thought that g(u) is a forward propagation function, and therefore u is the neural input (i.e., pre-activation).\n\nFollowing the author's response and revisions, I have raised my grade.\n"", 'This paper presents three observations to understand binary network in Courbariaux, Hubara et al. (2016). My main concerns are on the usage of the given observations. \n\n1. Can the observations be used to explain more recent works?\n\nIndeed, Courbariaux, Hubara et al. (2016) is a good and pioneered work on the binary network. However, as the authors mentioned, there are more recent works which give better performance than this one. For example, we can use +1, 0, -1 to approximate the weights. Besides, [a] has also shown a carefully designed post-processing binary network can already give very good performance. So, how can the given observations be used to explain more recent works?\n\n2. How can the given observations be used to improve Courbariaux, Hubara et al. (2016)?\n\nThe authors call their findings theory. From this perspective, I wish to see more mathematical analysis rather than just doing experiments and showing some interesting observations. Besides, giving interesting observations is not good enough. I wish to see how they can be used to improve binary networks.\n\nReference\n[a]. Network sketching: exploiting binary structure in deep CNNs. CVPR 2017', 'This paper tries to analyze the effectiveness of binary nets from a perspective originated from the angular perturbation that binarization process brings to the original weight vector. It further explains why binarization is able to preserve the model performance by analyzing the weight-activation dot product with ""Dot Product Proportionality Property."" It also proposes ""Generalized Binarization Transformation"" for the first layer of a neural network.\n\nIn general, I think the paper is written clearly and in detail. Some typos and minor issues are listed in the ""Cons"" part below.\n\nPros:\nThe authors lead a very nice exploration into the binary nets in the paper, from the most basic analysis on the converging angle between original and binarized weight vectors, to how this convergence could affect the weight-activation dot product, to pointing out that binarization affects differently on the first layer. Many empirical and theoretical proofs are given, as well as some practical tricks that could be useful for diagnosing binary nets in the future.\n\nCons:\n* it seems that there are quite some typos in the paper, for example:\n    1. Section 1, in the second contribution, there are two ""then""s.\n    2. Section 1, the citation format of ""Bengio et al. (2013)"" should be ""(Bengio et al. 2013)"".\n* Section 2, there is an ordering mistake in introducing Han et al.\'s work, DeepComporession actually comes before the DSD. \n* Fig 2(c), the correlation between the theoretical expectation and angle distribution from (b) seems not very clear.\n* In appendix, Section 5.1, Lemma 1. Could you include some of the steps in getting g(\\row) to make it clearer? I think the length of the proof won\'t matter a lot since it is already in the appendix, but it makes the reader a lot easier to understand it.\n']","[20, -30, 70]","[60, 50, 80]","[""The sentiment score is 20 (slightly positive) because while the reviewer finds the first part of the paper 'interesting and nice', they express confusion about the second part and find the third part not very useful. The overall tone is constructive but with significant reservations. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms as personal confusion or uncertainty (e.g., 'it is not clear to me') rather than direct attacks. They also provide detailed feedback and suggestions for improvement, which is considerate. The reviewer maintains a professional tone even when expressing doubts about parts of the paper."", ""The sentiment score is -30 because the reviewer expresses several concerns and criticisms about the paper, indicating a somewhat negative sentiment. However, it's not extremely negative as the reviewer acknowledges the paper's contributions and suggests improvements rather than outright rejecting it. The politeness score is 50 because the reviewer uses respectful language and phrases criticisms as questions or suggestions, which is more polite than direct criticism. The reviewer also acknowledges the paper's contributions and the pioneering work it builds upon. However, it doesn't reach the highest levels of politeness as it doesn't include explicit praise or overly deferential language."", ""The sentiment score is 70 (positive) because the reviewer starts with a generally positive tone, stating that the paper is 'written clearly and in detail.' They also list several 'Pros,' praising the authors for their 'nice exploration' and mentioning 'many empirical and theoretical proofs' as well as 'practical tricks.' The 'Cons' section, while present, focuses mainly on minor issues like typos and suggestions for clarity, rather than significant criticisms of the content. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, even when pointing out issues. They use phrases like 'I think' to soften criticisms and frame suggestions as questions (e.g., 'Could you include...?'). The reviewer also balances positive and negative feedback, starting with the positives before moving to the 'Cons,' which is a polite approach to giving feedback.""]"
"['The paper proposes a general neural network structure that includes TC (temporal convolution) blocks and Attention blocks for meta-learning, specifically, for episodic task learning. Through intensive experiments on various settings including few-shot image classification on Omniglot and Mini-ImageNet, and four reinforcement learning applications, the authors show that the proposed structure can achieve highly comparable performance wrt the corresponding specially designed state-of-the-art methods. The experiment results seem solid and the proposed structure is with simple design and highly generalizable. The concern is that the contribution is quite incremental from the theoretical side though it involves large amount of experimental efforts, which could be impactful. Please see the major comment below.\n\nOne major comment:\n- Despite that the work is more application oriented, the paper would have been stronger and more impactful if it includes more work on the theoretical side. \nSpecifically, for two folds: \n(1) in general, some more work in investigating the task space would be nice. The paper assumes the tasks are “related” or “similar” and thus transferrable; also particularly in Section 2, the authors define that the tasks follow the same distribution. But what exactly should the distribution be like to be learnable and how to quantify such “related” or “similar” relationship across tasks? \n(2) in particular, for each of the experiments that the authors conduct, it would be nice to investigate some more on when the proposed TC + Attention network would work better and thus should be used by the community; some questions to answer include: when should we prefer the proposed combination of TC + attention blocks over the other methods? The result from the paper seems to answer with “in all cases” but then that always brings the issue of “overfitting” or parameter tuning issue. I believe the paper would have been much stronger if either of the two above are further investigated.\n\nMore detailed comments:\n- On Page 1, “the optimal strategy for an arbitrary range of tasks” lacks definition of “range”; also, in the setting in this paper, these tasks should share “similarity” or follow the same “distribution” and thus such “arbitrariness” is actually constrained.\n\n- On Page 2, the notation and formulation for the meta-learning could be more mathematically rigid; the distribution over tasks is not defined. It is understandable that the authors try to make the paradigm very generalizable; but the ambiguity or the abstraction over the “task distribution” is too large to be meaningful. One suggestion would be to split into two sections, one for supervised learning and one for reinforcement learning; but both share the same design paradigm, which is generalizable.\n\n- For results in Table 1 and Table 2, how are the confidence intervals computed? Is it over multiple runs or within the same run? It would be nice to make clear; in addition, I personally prefer either reporting raw standard deviations or conduct hypothesis testing with specified tests. The confidence intervals may not be clear without elaboration; such is also concerning in the caption for Table 3 about claiming “not statistically-significantly different” because no significance test is reported. \n\n- At last, some more details in implementation would be nice (package availability, run time analysis); I suppose the package or the source code would be publicly available afterwards?', ""This work proposes an approach to meta-learning in which temporal convolutions and attention are used to synthesize labeled examples (for few-shot classification) or action-reward pairs (for reinforcement learning) in order to take the appropriate action. The resulting model is general-purpose and experiments demonstrate efficacy on few-shot image classification and a range of reinforcement learning tasks.\n\nStrengths\n\n- The proposed model is a generic meta-learning useful for both classification and reinforcement learning.\n- A wide range of experiments are conducted to demonstrate performance of the proposed method.\n\nWeaknesses\n\n- Design choices made for the reinforcement learning setup (e.g. temporal convolutions) are not necessarily applicable to few-shot classification.\n- Discussion of results relative to baselines is somewhat lacking.\n\nThe proposed approach is novel to my knowledge and overcomes specificity of previous approaches while remaining efficient.\n\nThe depth of the TC block is determined by the sequence length. In few-shot classification, the sequence length can be known a prior. How is the sequence length determined for reinforcement learning tasks? In addition, what is done at test-time if the sequence length differs from the sequence length at training time?\n\nThe causality assumption does not seem to apply to the few-shot classification case. Have the authors considered lifting this restriction for classification and if so does performance improve?\n\nThe Prototypical Networks results in Tables 1 and 2 do not appear to match the performance reported in Snell et al. (2017).\n\nThe paper is well-written overall. Some additional discussion of the results would be appreciated (for example, explaining why the proposed method achieves similar performance to the LSTM/OPSRL baselines).\n\nI am not following the assertion in 5.2.3 that MAML adaption curves can be seen as an upper bound on the performance of gradient-based methods. I am wondering if the authors can clarify this point.\n\nOverall, the proposed approach is novel and achieves good results on a range of tasks.\n\nEDIT: I have read the author's comments and am satisfied with their response. I believe the paper is suitable for publication in ICLR."", 'The authors propose a model for sequence classification and sequential decision making. The model interweaves attention layers, akin to those used by Vaswani et al, with temporal convolution. The authors demonstrate superior performance on a variety of benchmark problems, including those for supervised classification and for sequential decision making.\n\nUnfortunately, I am not an expert in meta-learning, so I cannot comment on the difficulty of the tasks (e.g. Omniglot) used to evaluate the model or the appropriateness of the baselines the authors compare against (e.g. continuous control).\n\nThe experiment section definitely demonstrate the effort put into this work. However, my primary concern is that the model seems somewhat lacking in novelty. Namely, it interweaves the Vaswani style attention with with temporal convolutions (along with TRPO. The authors claim that Vaswani model does not incoporate positional information, but from my understanding, it actually does so using positional encoding. I also do not see why the Vaswani model cannot be lightly adapted for sequential decision making. I think comparison to such a similar model would strengthen the novelty of this paper (e.g. convolution is a superior method of incorporating positional information).\n\nMy second concern is that the authors do not provide analysis and/or intuitions on why the proposed models outperform prior art in few-shot learning. I think this information would be very useful to the community in terms of what to take away from this paper. In retrospect, I wish the authors would have spent more time doing ablation studies than tackling more task domains.\n\nOverall, I am inclined to accept this paper on the basis of its experimental results. However I am willing to adjust my review according to author response and the evaluation of the experiment section by other reviewers (who are hopefully more experienced in this domain).\n\nSome minor feedback/questions for the authors:\n- I would prefer mathematical equations as opposed to pseudocode formulation\n- In the experiment section for Omniglot, when the authors say ""1200 classes for training and 432 for testing"", it sounds like the authors are performing zero-shot learning. How does this particular model generalize to classes not seen during training?']","[50, 60, -20]","[75, 70, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the solid experimental results, simple design, and high generalizability of the proposed method. However, they express concerns about the incremental theoretical contribution, which balances out the positive aspects. The politeness score is 75 (quite polite) due to the reviewer's use of respectful language throughout, such as 'Please see,' 'it would be nice,' and 'I believe.' They offer constructive criticism and suggestions for improvement without using harsh or dismissive language. The reviewer also acknowledges the potential impact of the work while providing detailed, thoughtful feedback."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the novelty and efficacy of the proposed approach, noting its strengths in being general-purpose and performing well on various tasks. They also state it's suitable for publication. However, they do point out some weaknesses and areas for improvement, which prevents a higher score. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as questions or suggestions rather than harsh statements. They also express satisfaction with the authors' response. The tone is professional and courteous, though not overly formal or deferential."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the effort put into the work and is inclined to accept the paper, they express significant concerns about the novelty of the model and the lack of analysis on why it outperforms prior art. The reviewer also mentions being unable to comment on certain aspects due to lack of expertise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges their own limitations, and offers constructive feedback. They use phrases like 'Unfortunately, I am not an expert...', 'I think this information would be very useful...', and 'I am willing to adjust my review...' which demonstrate politeness and openness to dialogue. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism.""]"
"[""The paper introduces a graph based memory for navigation agents. The memory graph is constructed using nearest neighbor heuristics based on temporal adjacency and visual similarity. The agent uses Dijkstra's algorithm to plan a a path through the graph in order to solve the navigation task. \n\nThere are several major problems with this paper. My overall impression is that the the proposed agent is a nearly hard-coded solution (which I think might be the correct approach to such problems), but a poorly implemented one. Specific points: 1-There are only 5 test mazes, and the proposed agent doesn't even solve all of them. 2-The way in which the maze is traversed in the exploration phase determines the accuracy of the graph that is constructed (i.e. traversing each location exactly once using a space-filling curve). 3-Of the two heuristics used in Equation 1 how many edges are actually constructed using the visual similarity heuristic? 4-How does the visual similarity heuristic handle visually similar map elements that correspond to distinct locations? 5- The success criteria of solving a maze is arbitrarily defined -- why exactly 2.4 min?   "", ""*** Revision: based on the author's work, we have switched the score to accept (7) ***\n\nClever ideas but not end-to-end navigation.\n\nThis paper presents a hybrid architecture that mixes parametric (neural) and non-parametric (Dijkstra's path planning on a graph of image embeddings) elements and applies it to navigation in unseen 3D environments (Doom). The path planning in unseen environments is done in the following way: first a human operator traverses the entire environment by controlling the agent and collecting a long episode of 10k frames that are put into a chain graph. Then loop closures are automatically detected using image similarity in feature space, using a localization feed-forward ResNet (trained using a DrLIM-like triplet loss on time-similar images), resulting in a topological graph where edges correspond to similar viewpoints or similar time points. For a given target position image and agent start position image, a nearest neighbor search-powered Dijkstra path planning is done on the graph to create a list of waypoint images. The pairs of (current image, next waypoint) images are then fed to a feed-forward locomotion (policy) network, trained in a supervised manner.\n\nThe paper does not discuss at all the problems arising when the images are ambiguous: since the localisation network is feed-forward, surely there must be images that are ambiguously mapped to different graph areas and are closing loops erroneously? The problem is mitigated by the fact that a human operator controls the agent, making sure that the agent's viewpoint is clear, but the method will probably fail if the agent is learning to explore the maze autonomously, bumping into walls and facing walls. The screenshots on Figure 3 suggest that the walls have a large variety of textures and decorations, making each viewpoint potentially unique, unlike the environments in (Mirowski et al, 2017), (Jaderberg et al, 2017) and (Mnih et al, 2016).\n\nMost importantly, the navigation is not based on RL at all, and ignores the problem of exploration altogether. A human operator labels 10k frames by playing the game and controlling the agent, to show it how the maze looks like and what are the paths to be taken. As a consequence, comparison to end-to-end RL navigation methods is unclear, and should be stressed upon in the manuscript. This is NOT a proper navigation agent.\n\nAdditional baselines should be evaluated: 1) a fully Dijkstra-based baseline where the direction of motion of the agent along the edge is retrieved and used to guide the agent (i.e., the policy becomes a lookup table on image pairs) and 2) the same but the localization network replaced by image similarities in pixel space or some image descriptor space (e.g., SURF, ORB, etc…). It seems to me that those baselines would be very strong.\n\nAnother baseline is missing: (Oh et al, 2016, “Control of Memory, Active Perception, and Action in Minecraft”).\n\nThe paper is not without merit: the idea of storing experiences in a graph and in using landmark similarity rather than metric embeddings is interesting. Unfortunately, that episodic memory is not learned (e.g., Neural Turing Machines or Memory Networks).\n\nIn summary, just like the early paper released in 2010 about Kinect-based RGBD SLAM: lots of excitement but potential disappointment when the method is applied on an actual mobile robot, navigating in normal environments with visual ambiguity and white walls. The paper should ultimately be accepted to this conference to provide a baseline for the community  (once the claims are revised), but I street that the claims of learning to navigate in unseen environments are unsubstantiated, as the method is neither end-to-end learned (as it relies on human input and heuristic path planning) nor capable of exploring unseen environments with visual ambiguity."", ""The paper presents for learning to visually navigate using a topological map is presented. The method combines an algorithmic approach to generate topological graphs, which is indexed by observations with Dijkstra's algorithm to determine a global path from which a waypoint observation is selected. The waypoint along with the current observation is fed to a learned local planner that transitions the agent to the target waypoint. A learned observation similarity mapping localizes the agent and indexes targets in the graph.\n\nThe novelty of the approach in context of prior visual navigation and landmark-based robotics research is the hybrid algorithmic and learned approach that builds a graph purely from observations without ego motion or direct state estimation. Most of the individual components have previously appeared in the literature including graph search (also roadmap methods), learned similarity metrics, and learned observation-based local planners. However, the combination of these approaches along with some of the presented nuanced enhancements including the connectivity shortcuts (a simple form of loop closure) to visual topological navigation and are compelling contributions. The results while not thorough do support the ability of the method effectively plan on novel and unseen environments.\n\nThe approach has potential limitations including the linear growth in the size of the memory, and it is unclear how the method handles degenerate observations (e.g., similar looking hallways on opposite sides of the environment). The authors should consider including examples or analysis illustrating the method’s performance in such scenarios.\n\nThe impact of the proposed approach would be better supported if compared against stronger baselines including recent research that address issues with learning long sequences in RNNs. Furthermore, additional experiments over a greater number and more diverse set of environments along with additional results showing the performance of the method based on variation environment parameters including number of exploration steps and heuristic values would help the reader understand the sensitivity and stability of the method.\n\nThe work in “Control of Memory, Active Perception, and Action in Minecraft” by Oh et al. have a learned memory that is used recall previous observations for planning. This method’s memory architecture can be considered to be nonparametric, and, while different from the proposed method, this similarity merits additional discussion and consideration for empirical comparison. \n\nSome of the the details for the baseline methods are unclear. The reviewer assumes that when the authors state they use the same architecture as Mnih et al. and Mirowski et al. that this also includes all hyper parameters including the size of each layer and training method. However, Mirowski et al. use RGB while the stated baseline is grayscale. \n\nThe reviewer wonders whether the baselines may be disadvantaged compared to the proposed method. The input for the baselines are restricted to a 84x84 input image in addition to being grayscale vs the proposed methods 160x120 RGB image. It appears the proposed method is endowed with a much greater capacity with a ResNet-18 in the retrieval network compared to the visual feature layers (two layers of CNNs) of the baseline networks. Finally the proposed method is provided with demonstrations (the human exploration) that effectively explore the environment. The authors should consider bootstrapping the baseline methods with similar experience. ""]","[-70, -50, 50]","[-20, 20, 75]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states there are 'several major problems' with the paper and describes the proposed agent as 'poorly implemented'. They list multiple criticisms and shortcomings of the work without mentioning any positive aspects. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and critical. The reviewer doesn't use any softening language or acknowledge any merits of the work. Phrases like 'nearly hard-coded solution' and 'poorly implemented' are particularly harsh. However, the reviewer does maintain a professional tone and provides specific, constructive feedback, which prevents the score from being even lower."", ""The sentiment score is -50 because while the reviewer acknowledges some merits of the paper ('Clever ideas', 'The paper is not without merit'), the overall tone is critical. The reviewer points out significant limitations of the approach, such as not being end-to-end navigation, relying on human input, and potential issues with visual ambiguity. The politeness score is 20 because the reviewer uses relatively polite language ('Clever ideas', 'The paper is not without merit') and provides constructive criticism with specific suggestions for improvement. However, some phrases are more direct ('This is NOT a proper navigation agent'), which prevents a higher politeness score. The reviewer also balances criticism with acknowledgment of the paper's potential value to the community."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and potential while also pointing out limitations and areas for improvement. The review begins by highlighting the novelty of the approach and its compelling contributions, which is positive. However, it also mentions potential limitations and suggests additional comparisons and experiments, indicating a balanced perspective. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. The reviewer uses phrases like 'The authors should consider' and 'The reviewer wonders' which maintain a polite and professional tone. The review also acknowledges the strengths of the paper before delving into areas for improvement, which is a courteous approach.""]"
"[""The paper presents a study on the use of density embedding for modeling hierarchical semantic relations, and in particular on the hypernym one. The goal is to capture hypernyms of some synsets, even if their occurrence is scarce on the training data.\n+++pros: 1) potentially a good idea, capable of filling an ontology of relations scarcely present in a given repository 2) solid theoretical background, even if no methodological novelty has been introduced (this is also a cons!)\n---cons: 1) Badly presented: the writing of the paper fails in let the reader aware of what the paper actually serves\n\nCOMMENTS:\nThe introduction puzzled me:  the authors, once they stated the problem (the scarceness of the hypernyms' occurrences in the texts w.r.t. their hyponyms), proposed a solution which seems not to directly solve this problem. So I suggest the authors to better explain the connection between the told problem and their proposed solution, and how this can solve the problem.\n\nThis aspect is also present in the experiments section, since it is not possible to understand how much the problem (the scarceness of the hypernyms) is present in the HYPERLEX dataset.\n\nHow the 4000 hypernyms have been selected? Why a diagonal covariance has been estimated, and not a full covariance one? \n\nn Figure 4 middle, it is not clear whether the location and city concepts are intersecting the other synsets. It shouldn't be, but the authors should spend a little on this.\n\nApart from these comments, I found the paper interesting especially for the big amount fo comparisons carried out. \n\nAs a final general comment, I would have appreciated a paper more self explanative, without referring to the paper [Vilnis & McCallum, 2014] which makes appear the paper a minor improvement of what it is actually. "", ""The paper presents a method for hierarchical object embedding by Gaussian densities for lexical entailment tasks.Each word is represented  by a diagonal Gaussian and the KL divergence is used as a directional distance measure. if D(f||g) < gamma then the concept represented by f entails the concept represented by g.\n\nThe main technical difference of the present work compared from the  main prior work (Vendrov, 2015) is that in addition to mean vector representation they use here also a variance component. The main modeling challenge here to to define a  good directional measure that can be suitable for lexical entailment. in Vendrov work they defined a partial ordering. Here,  the KL is not symmetric but its directional aspect is not significant.\nFor example if we set all the variances to be a unit matrix than the KL is collapsed to be a simple symmetrical Euclidean distance. We can also see from Table 1 that if we replace KL by its symmetrical variant we get similar results. Hence, I was not convinced that the propose KL+Gaussian modeling is suitable for directional relations.\n\nThe paper also presents several methods for negative samplings and according to table 4 there is a lot of performance variability based on the method that is used for selecting negative sampling. I find this component of the proposed algorithm  very heuristic.\n\nTo summarize, I don't think there is enough interesting novelty in this paper. If the focus of the  paper is on  obtaining good entailment results, maybe an NLP conference can be a more suitable venue.\n"", 'The paper introduces a novel method for modeling hierarchical data. The work builds on previous approaches, such as Vilnis and McCallum\'s Word2Gauss and Vendrov\'s Order Embeddings, to establish a partial order over probability densities via encapsulation, which allows it to model hierarchical information. The aim is to learn embeddings from supervised structured data, such as WordNet. The work also investigates various schemes for selecting negative samples. The evaluation consists of hypernym detection on WordNet and graded lexical entailment, in the shape of HyperLex. This is good work: it is well written, the experiments are thorough and the proposed method is original and works well.\n\nSection 3 could use some more signposting. Especially for 3.3 it would be good to explain (either at the beginning of section 3, or the beginning of section 3.3) why these measures matter and what is going to be done with them.\n\nIt\'s good that LEAR is mentioned and compared against, even though it was very recently published. Please do note that the authors\' names are misspelled: Vuli\\\'c not Vulic, Mrk\\v{s}i\\\'c instead of Mrksic.\n\nIf I am not mistaken, the Vendrov WordNet test set is a set of positive pairs. I would like to see more details on how the evaluation is done here: presumably, the lower I set the threshold, the higher my score? Or am I missing something?\n\nIt would be useful to describe exactly the extent to which supervision is used - the method only needs positive and negative links, and does not require any additional order information (i.e., WordNet strictly contains more information than what is being used).\n\nI don\'t see what Socher et al. (2013) has to do with the loss in equation (7). Or did they invent the margin loss?\n\nWord2gauss also evaluates on similarity and relatedness datasets. Did you consider doing that here too?\n\n""hypothesis proposed by Santus et al. which says"" is not a valid reference.']","[-20, -60, 80]","[50, 20, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer finds some positive aspects ('potentially a good idea', 'solid theoretical background', 'interesting'), there are significant criticisms ('Badly presented', 'puzzled me', 'not possible to understand'). The overall tone suggests more concerns than praise. The politeness score is moderately positive (50) as the reviewer uses respectful language, offers constructive feedback, and balances criticism with positive comments. They use phrases like 'I suggest', 'I would have appreciated', and acknowledge the paper's strengths alongside its weaknesses, maintaining a professional and courteous tone throughout."", ""The sentiment score is -60 because the reviewer expresses several criticisms and doubts about the paper's novelty and suitability. They state they are 'not convinced' by the proposed modeling, find a component 'very heuristic', and conclude there isn't 'enough interesting novelty'. However, it's not entirely negative as they do acknowledge some aspects of the work. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'I don't think' and 'I find' to soften their criticisms, and provide explanations for their views. The language is not overtly polite, but it avoids rudeness and maintains a respectful, academic tone."", ""The sentiment score is 80 (positive) because the reviewer describes the work as 'good', 'well written', with 'thorough' experiments and an 'original' method that 'works well'. The overall tone is very positive, with only minor suggestions for improvement. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering constructive feedback and asking questions politely (e.g., 'If I am not mistaken...'). The reviewer also acknowledges positive aspects (e.g., 'It's good that LEAR is mentioned') before suggesting improvements. The language is professional and courteous, without being overly formal or effusive.""]"
"['Quality: The work focuses on a novel problem of generating text sample using GAN and a novel in-filling mechanism of words. Using GAN to generate samples in adversarial setup in texts has been limited due to the mode collapse and training instability issues. As a remedy to these problems an in-filling-task conditioning on the surrounding text has been proposed. But, the use of the rewards at every time step (RL mechanism) to employ the actor-critic training procedure could be challenging computationally challenging.\n\nClarity: The mechanism of generating the text samples using the proposed methodology has been described clearly. However the description of the reinforcement learning step could have been made a bit more clear.\n\nOriginality: The work indeed use a novel mechanism of in-filling via a conditioning approach to overcome the difficulties of GAN training in text settings. There has been some work using GAN to generate adversarial examples in textual context too to check the robustness of classifiers. How this current work compares with the existing such literature?\n\nSignificance: The research problem is indeed significant since the use of GAN in generating adversarial examples in image analysis has been more prevalent compared to text settings. Also, the proposed actor-critic training procedure via RL methodology is indeed significant from its application in natural language processing.\n\npros:\n(a) Human evaluations applications to several datasets show the usefulness of MaskGen over the maximum likelihood trained model in generating more realistic text samples.\n(b) Using a novel in-filling procedure to overcome the complexities in GAN training.\n(c) generation of high quality samples even with higher perplexity on ground truth set.\n\ncons:\n(a) Use of rewards at every time step to the actor-critic training procure could be computationally expensive.\n(b) How to overcome the situation where in-filling might introduce implausible text sequences with respect to the surrounding words?\n(c) Depending on the Mask quality GAN can produce low quality samples. Any practical way of choosing the mask?', 'This paper proposes MaskGAN, a GAN-based generative model of text based on\nthe idea of recovery from masked text. \nFor this purpose, authors employed a reinceforcement learning approach to\noptize a prediction from masked text. Moreover, authors argue that the \nquality of generated texts is not appropriately measured by perplexities,\nthus using another criterion of a diversity of generated n-grams as well as\nqualitative evaluations by examples and by humans.\n\nWhile basically the approach seems plausible, the issue is that the result is\nnot compared to ordinary LSTM-based baselines. While it is better than a \nconterpart of MLE (MaskedMLE), whether the result is qualitatively better than\nordinary LSTM is still in question.\n\nIn fact, this is already appearent both from the model architectures and the\ngenerated examples: because the model aims to fill-in blanks from the text\naround (up to that time), generated texts are generally locally valid but not\nalways valid globally. This issue is also pointed out by authors in Appendix\nA.2. \nWhile the idea of using mask is interesting and important, I think if this\nidea could be implemented in another way, because it resembles Gibbs sampling\nwhere each token is sampled from its sorrounding context, while its objective\nis still global, sentence-wise. As argued in Section 1, the ability of \nobtaining signals token-wise looks beneficial at first, but it will actually\nbreak a global validity of syntax and other sentence-wise phenoma.\n\nBased on the arguments above, I think this paper is valuable at least\nconceptually, but doubt if it is actually usable in place of ordinary LSTM\n(or RNN)-based generation.\nMore arguments are desirable for the advantage of this paper, i.e. quantitative\nevaluation of diversity of generated text as opposed to LSTM-based methods.\n\n*Based on the rebuttals and thorough experimental results, I modified the global rating.', 'Generating high-quality sentences/paragraphs is an open research problem that is receiving a lot of attention. This text generation task is traditionally done using recurrent neural networks. This paper proposes to generate text using GANs. GANs are notorious for drawing images of high quality but they have a hard time dealing with text due to its discrete nature. This paper\'s approach is to use an actor-critic to train the generator of the GAN and use the usual maximum likelihood with SGD to train the discriminator. The whole network is trained on the ""fill-in-the-blank"" task using the sequence-to-sequence architecture for both the generator and the discriminator. At training time, the generator\'s encoder computes a context representation using the masked sequence. This context is conditioned upon to generate missing words. The discriminator is similar and conditions on the generator\'s output and the masked sequence to output the probability of a word in the generator\'s output being fake or real. With this approach, one can generate text at test time by setting all inputs to blanks. \n\nPros and positive remarks: \n--I liked the idea behind this paper. I find it nice how they benefited from context (left context and right context) by solving a ""fill-in-the-blank"" task at training time and translating this into text generation at test time. \n--The experiments were well carried through and very thorough.\n--I second the decision of passing the masked sequence to the generator\'s encoder instead of the unmasked sequence. I first thought that performance would be better when the generator\'s encoder uses the unmasked sequence. Passing the masked sequence is the right thing to do to avoid the mismatch between training time and test time.\n\nCons and negative remarks:\n--There is a lot of pre-training required for the proposed architecture. There is too much pre-training. I find this less elegant. \n--There were some unanswered questions:\n            (1) was pre-training done for the baseline as well?\n            (2) how was the masking done? how did you decide on the words to mask? was this at random?\n            (3) it was not made very clear whether the discriminator also conditions on the unmasked sequence. It needs to but \n                  that was not explicit in the paper.\n--Very minor: although it is similar to the generator, it would have been nice to see the architecture of the discriminator with example input and output as well.\n\n\nSuggestion: for the IMDB dataset, it would be interesting to see if you generate better sentences by conditioning on the sentiment as well.\n']","[60, -20, 60]","[80, 60, 80]","['The sentiment score is 60 (positive) because the reviewer acknowledges the novelty and significance of the work, highlighting several pros such as the usefulness of MaskGen and the novel in-filling procedure. While there are some cons mentioned, they are presented as areas for improvement rather than major flaws. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They offer balanced feedback, acknowledging both strengths and potential areas for improvement without using harsh or critical language. The reviewer also asks questions to encourage further thought and development, which is a polite way of suggesting improvements.', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's conceptual value and interesting approach, they express significant doubts about its practical usability and comparative advantages over existing methods. The reviewer points out several limitations and suggests that more evidence is needed to support the paper's claims. The politeness score is moderately positive (60) as the reviewer uses respectful and professional language throughout, acknowledging the paper's merits while constructively pointing out areas for improvement. They use phrases like 'While basically the approach seems plausible' and 'I think this paper is valuable at least conceptually' which maintain a polite tone even when expressing criticism."", ""The sentiment score is 60 (positive) because the reviewer starts with acknowledging the importance of the research problem and provides several positive remarks about the paper's approach and experiments. They use phrases like 'I liked the idea' and 'The experiments were well carried through and very thorough.' However, the score is not higher due to the presence of some criticisms and unanswered questions. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, balances positive and negative feedback, and frames criticisms as 'cons' rather than direct attacks. They also offer suggestions for improvement in a constructive manner. The use of phrases like 'I find it nice' and 'I second the decision' contribute to the polite tone.""]"
"[""Thank you for the feedback, and I have read the revision.\n\nI would say the revised version has more convincing experimental results (although I'm not sure about the NLP part). The authors have also addressed my concerns on variance reduction, although it's still mysterious to me that the density ratio estimation method seems to work very well even at the begining stage.\n\nAlso developing GAN approaches for discrete variables is an important and unsolved problem.\n\nConsidering all of the above, I would like to raise the rating to 7, but lower my confidence to 3 (as I'm not an expert for NLP which is the main task for discrete generative models).\n\n==== original review ====\n\nThank you for an interesting read.\n\nMy understanding of the paper is that:\n\n1. the paper proposes a density-ratio estimator via the f-gan approach;\n2. the paper proposes a training criterion that matches the generator's distribution to a self-normalised importance sampling (SIS) estimation of the data distribution;\n3. in order to reduce the variance of the REINFORCE gradient, the paper seeks out to do matching between conditionals instead.\n\nThere are a few things that I expect to see explanations, which are not included in the current version:\n\n1. Can you justify your variance reduction technique either empirically or experimentally? Because your method requires sampling multiple x for a single given z, then in the same wall-clock time I should be able to obtain more samples for the vanilla version eq (8). How do they compare?\n\n2. Why your density ratio estimation methods work in high dimensions, even when at the beginning p and q are so different?\n\n3. It's better to include some quantitative metrics for the image and NLP experiments rather than just showing the readers images and sentences!\n\n4. Over-optimising generators is like solving a max-min problem instead. You showed your method is more robust in this case, can you explain it from the objective you use, e.g. the convex/concavity of your approach in general?\n\nTypo: eq (3) should be min max I believe?\n\nBTW I'm not an expert of NLP so I won't say anything about the quality of the NLP experiment."", 'The paper introduces a new method for training GANs with discrete data. To this end, the output of the discriminator is interpreted as importance weight and REINFORCE-like updates are used to train the generator.\n\nDespite making interesting connections between different ideas in GAN training, I found the paper to be disorganized and hard to read. My main concern is the fact that the paper does not make any comparison with other methods for handling of discrete data in GANs. In particular, (Gulrajani et al.’17) show that it is possible to train Wasserstein GANs without sampling one-hot vectors for discrete variables during the training. Is there a reason to use REINFORCE-like updates when such a direct approach works?\n\nMinor: \ncomplex conjugate => convex conjugate ', 'Thanks for the feedback and for clarifying the 1) algorithm and the assumptions in the multivariate case 2) comparison to RL based methods 3) connection to estimating importance sampling weights using GAN discriminator.\n\nI think the paper contribution is now more clear and strengthened with additional convincing experiments and I am increasing my score to 7.\n\nThe paper would still benefit from doing the experiment with importance weights by pixel , rather then a global one as done in the paper now. I encourage the authors to still do the experiment, see if there is any benefit.\n\n\n\n==== Original Review =====\nSummary of the paper:\n\nThe paper presents a method based on importance sampling and reinforcement learning to learn discrete generators in the GAN framework. The GAN uses an  f-divergence cost function for  training the discriminator. The generator is trained to minimize the KL distance between the  discrete generator q_{\\theta}(x|z), and the importance weight discrete real distribution estimator w(x|z)q(\\theta|z). where w(x|z) is estimated in turn using the discriminator. \nThe methodology is also extended to the continuous case. Experiments are conducted on quantized image generation, and text generation.\n\nQuality:\n\nthe paper is overall well written and supported with reasonable experiments.\n\nClarity:\n\nThe paper has a lot of typos that make sometimes the paper harder to follow:\n- page (2) Eq 3 max , min should be min, max if we want to keep working with f-divergence\n- Definition 2.1 \\mathbb{Q}_{\\theta} --> \\mathbb{Q}\n- page 5 the definition of \\tilde{w}(x^{(m})) in the normalization it is missing \\tilde{w}\n- Equation (10) \\nabla_{\\theta}\\log(x|z) --> \\nabla_{\\theta}\\log(x^{(m)}|z)\n- In algorithm 1, again missing indices in the update of theta  --> \\nabla_{\\theta}\\log(x^{(m|n)}|z^{n})\n \nOriginality:\n\nThe main ingredients of the paper are well known and already used in the literature (Reinforce for discrete GAN with Disc as a reward for e.g GAN for image captioning Dai et al). The perspective from importance sampling coming from f-divergence for discrete GAN has some novelty although the foundations of this work relate also to previous work:\n- Estimating ratios using the discriminator is well known for e.g learning implicit models , Mohamed et al \n- The relation of  importance sampling to  reinforce is also well known"" On a Connection between Importance Sampling and the Likelihood Ratio Policy Gradient,"" Tang and Abbeel.\n\nGeneral Review:\n\n- when the generator is producing only *one* discrete distribution the theory is presented in Section 2.3. When we move to experiments, for image generation for example, we need to have a generator that produces a distribution by pixel. It would be important for 1) understanding the work 2) the reproducibility of the work to parallel algorithm 1 and have it *in the paper*, for this \'multi discrete distribution \' generation case.  If we have N pixels    \\log(p(x_1,...x_N|z))= \\Pi_i g_{\\theta}(x_i|z) (this should be mentioned in the paper if it is the case ), it would be instructive to comment on the assumptions on independence/conditional dependence of this model, also to state clearly how the generator is updated in this case and what are importance sampling weights. \n\n- Would it make sense in this N pixel discrete case generation to have also the discriminator produce N probabilities of real and fake as in PixelGAN in Isola et al? then see in this case what are the importance sampling weights this would parallel the instantaneous reward in RL?\n\n\n\n \n']","[60, -30, 60]","[80, 20, 80]","[""The sentiment score is 60 (moderately positive) because the reviewer raises their rating to 7 out of 10 and acknowledges improvements in the revised version, while still expressing some reservations. They note more convincing experimental results and that the authors addressed their concerns, indicating a generally positive view. The politeness score is 80 (quite polite) because the reviewer consistently uses respectful language, begins with 'Thank you for the feedback' and 'Thank you for an interesting read', and frames criticisms as requests for explanation rather than direct attacks. They also acknowledge their own limitations in expertise for certain aspects. The tone throughout is professional and constructive, offering specific suggestions for improvement without being harsh or dismissive."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the paper's 'interesting connections,' they express significant concerns about the paper being 'disorganized and hard to read' and lacking important comparisons. The lack of enthusiasm and the focus on criticisms suggest a negative sentiment, though not extremely so. The politeness score is slightly positive (20) as the reviewer uses relatively neutral language and frames criticisms as concerns rather than harsh judgments. They also acknowledge positive aspects before presenting criticisms. The use of phrases like 'I found' and 'Is there a reason' maintains a respectful tone while still conveying critical feedback."", ""The sentiment score is 60 (positive) because the reviewer expresses a clear positive shift in their evaluation, stating 'I am increasing my score to 7' and noting that the paper's contribution is 'now more clear and strengthened'. However, it's not extremely positive as they still suggest an additional experiment. The politeness score is 80 (quite polite) due to the reviewer's constructive and respectful tone throughout. They use phrases like 'Thanks for the feedback', 'I encourage the authors', and provide detailed, helpful feedback without harsh criticism. The reviewer maintains a professional and courteous tone while offering both praise and suggestions for improvement.""]"
"['After reading rebuttals from the authors: The authors have addressed all of my concerns. THe additional experiments are a good addition.\n\n************************\nThe authors provide an algorithm-agnostic active learning algorithm for multi-class classification. The core technique is to construct a coreset of points whose labels inform the labels of other points.  The coreset construction requires one to construct a set of  points which can cover the entire dataset. While this is NP-hard problem in general, the greedy algorithm is 2-approximate. The authors use a variant of the greedy algorithm along with bisection search to solve a series of feasibility problems to obtain a good cover of the dataset each time.  This cover tells us which points are to be queried. The reason why choosing the cover is a good idea is because under suitable Lipschitz continuity assumption the generalization error can be controlled via an appropriate value of the covering radius in the data space.  The authors use the coreset construction with a CNN to demonstrate an active learning algorithm for multi-class classification. \nThe experimental results are convincing enough to show that it outperforms other active learning algorithms. However, I have a few major and minor comments.\n\nMajor comments:\n\n1. The proof of Lemma 1 is incomplete. We need the Lipschitz constant of the loss function. The loss function is a function of the CNN function and the true label. The proof of lemma 1 only establishes the Lipschitz constant of the CNN function. Some more extra work is needed to derive the lipschitz constant of the loss function from the CNN function. \n\n2. The statement of Prop 1 seems a bit confusing to me. the hypothsis says that the loss on the coreset = 0. But the equation in proposition 1 also includes the loss on the coreset. Why is this term included. Is this term not equal to 0?\n\n3. Some important works are missing.  Especially works related to pool based active learning, and landmark results on labell complexity of agnostic active learning.\nUPAL: Unbiased Pool based active learning by Ganti & Gray. http://proceedings.mlr.press/v22/ganti12/ganti12.pdf\nEfficient active learning of half-spaces by Gonen et al. http://www.jmlr.org/papers/volume14/gonen13a/gonen13a.pdf\nA bound on the label complexity of agnostic active learning. http://www.machinelearning.org/proceedings/icml2007/papers/375.pdf\n\n4.  The authors use L_2 loss as their objective function. This is a bit of a weird choice given that they are dealing with multi-class classification and the output layer is a sigmoid layer, making it a natural fit to work with something like a cross-entropy loss function. I guess the theoretical results do not extend to cross-entropy loss, but the authors do not mention these points anywhere in the paper. For example, the ladder network, which is one of the networks used by the authors is a network that uses cross-entropy for training.\n\nMinor-comment: \n1. The feasibility program in (6) is an MILP. However, the way it is written it does not look like an MILP. It would have been great had the authors mentioned that u_j \\in {0,1}. \n\n2. The authors write on page 4, ""Moreover, zero training error can be enforced by converting average loss into maximal loss"". It is not clear to me what the authors mean here. For example, can I replace the average error in proposition 1, by maximal loss? Why can I do that? Why would that result in zero training error?\n\nOn the whole this is interesting work and the results are very nice. But, the proof for Lemma 1 seems incomplete to me, and some choices (such as choice of loss function) are unjustified. Also, important references in active learning literature are missing.', 'This paper studies active learning for convolutional neural networks. Authors formulate the active learning problem as core-set selection and present a novel strategy.\n\nExperiments are performed on three datasets to validate the effectiveness of the proposed method comparing with some baselines.\n\nTheoretical analysis is presented to show the performance of any selected subset using the geometry of the data points.\n\nAuthors are suggested to perform experiments on more datasets to make the results more convincing.\n\nThe initialization of the CNN model is not clearly introduced, which however, may affect the performance significantly.\n', 'Active learning for deep learning is an interesting topic and there is few useful tool available in the literature. It is happy to see such paper in the field. This paper proposes a batch mode active learning algorithm for CNN as a core-set problem. The authors provide an upper bound of the core-set loss, which is the gap between the training loss on the whole set and the core-set. By minimizing this upper bound, the problem becomes a K-center problem which can be solved by using a greedy approximation method, 2-OPT. The experiments are performed on image classification problem (CIFAR, CALTECH, SVHN datasets), under either supervised setting or weakly-supervised setting. Results show that the proposed method outperforms the random sampling and uncertainty sampling by a large margin. Moreover, the authors show that 2-OPT can save tractable amount of time in practice with a small accuracy drop.\n\nThe proposed algorithm is new and writing is clear. However, the paper is not flawless. The proposed active learning framework is under ERM and cover-set, which are currently not supported by deep learning. To validate such theoretical result, a non-deep-learning model should be adopted. The ERM for active learning has been investigated in the literature, such as ""Querying discriminative and representative samples for batch mode active learning"" in KDD 2013, which also provided an upper bound loss of the batch mode active learning and seems applicable for the problem in this paper. Another interesting question is most of the competing algorithm is myoptic active learning algorithms. The comparison is not fair enough. The authors should provide more competing algorithms in batch mode active learning.']","[50, 50, 50]","[70, 75, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by acknowledging that the authors have addressed all their concerns and that the additional experiments are a good addition. However, the review then goes on to list several major and minor comments, indicating that there are still some issues with the paper. The overall tone is constructive and appreciative of the work, but not overwhelmingly positive.\n\nThe politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the interesting nature of the work and the quality of the results. They phrase their criticisms as 'comments' rather than flaws, and use phrases like 'It would have been great' and 'I have a few major and minor comments' instead of more direct criticisms. The reviewer also ends on a positive note, stating 'On the whole this is interesting work and the results are very nice.' However, it's not extremely polite as it does directly point out several issues with the paper."", ""The sentiment score is 50 (slightly positive) because the review acknowledges the paper's contributions and theoretical analysis, but also points out areas for improvement. The first three paragraphs highlight positive aspects of the paper, while the last two suggest improvements. This balance indicates a moderately positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses neutral language and makes suggestions rather than criticisms. Phrases like 'Authors are suggested to' and 'is not clearly introduced' are polite ways of pointing out areas for improvement without being harsh or confrontational. The review maintains a professional and respectful tone throughout."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by acknowledging the importance of the topic and expressing happiness to see such a paper. They also praise the novelty of the algorithm and clarity of writing. However, they point out some flaws and areas for improvement, which balances out the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. They use phrases like 'It is happy to see such paper' and 'The proposed algorithm is new and writing is clear,' which contribute to a polite tone. The criticism is presented in a professional manner without harsh language.""]"
"[""This is a very clearly written paper, and a pleasure to read.\n\nIt combines some mechanisms known from previous work for summarization (intra-temporal attention; pointing mechanism with a switch) with novel architecture design components (intra-decoder attention), as well as a new training objective drawn from work from reinforcement learning, which directly optimizes ROUGE-L. The model is trained by a policy gradient algorithm. \n\nWhile the new mechanisms are simple variants of what is taken from existing work, the entire combination is well tested in the experiments. ROUGE results are reported for the full hybrid RL+ML model, as well as various versions that drop each of the new components (RL training; intra-attention). The best method finally outperforms the lea-3d baseline for summarization. What makes this paper more compelling is that they compared against a recent extractive method (Durret et al., 2016), and the fact that they also performed human readability and relevance assessments to demonstrate that their ML+RL model doesn't merely over-optimize on ROUGE. It was a nice result that only optimizing ROUGE directly leads to lower human evaluation scores, despite the fact that that model achieves the best ROUGE-1 and ROUGE-L performance on CNN/Daily Mail.\n\nSome minor points that I wonder about:\n - The heuristic against repeating trigrams seems quite crude. Is there a more sophisticated method that can avoid redundancy without this heuristic?\n - What about a reward based on a general language model, rather than one that relies on L_{ml} in Equation (14)? If the LM part really is to model grammaticality and coherence, a general LM might be suitable as well.\n - Why does ROUGE-L seem to work better than ROUGE-1 or ROUGE-2 as the reward? Do you have any insights are speculations regarding this?"", 'The paper proposes a model for abstractive document summarization using a self-critical policy gradient training algorithm, which is mixed with maximum likelihood objective. The Seq2seq architecture incorporates both intra-temporal and intra-decoder attention, and a pointer copying mechanism. A hard constraint is imposed during decoding to avoid trigram repetition. Most of the modelling ideas already exists, but this paper show how they can be applied as a strong summarization model.\n\nThe approach obtains strong results on the CNN/Daily Mail and NYT datasets. Results show that intra-attention improves performance for only one of the datasets. RL results are reported with only the best-performing attention setup for each dataset. My concern with that is that the authors might be using the test set for model selection; It is not a priori clear that the setup that works better for ML should also be better for RL, especially as it is not the same across datasets. So I suggest that results for RL should be reported with and without intra-attention on both datasets, at least on the validation set.\n\nIt is shown that intra-decoder attention decoder improves performance on longer sentences. It would be interesting to see more analysis on this, especially analyzing what the mechanism is attending to, as it is less clear what its interpretation should be than for intra-temporal attention. Further ablations such as the effect of the trigram repetition constraint will also help to analyse the contribution of different modelling choices to the performance. \n\nFor the mixed decoding objective, how is the mixing weight chosen and what is its effect on performance? If it is purely a scaling factor, how is the scale quantified? It is claimed that readability correlates with perplexity, so it would be interesting to see perplexity results for the models. The lack of correlation between automatic and human evaluation raises interesting questions about the evaluation of abstractive summarization that should be investigated further in future work.\n\nThis is a strong paper that presents a significant improvement in document summarization.\n', 'The paper is generally well-written and the intuition is very clear. It combines the advanced attention mechanism, pointer networks and REINFORCE learning signal to train a sequence-to-sequence model for text summarization. The experimental results show that the model is able to achieve the state-of-the-art performance on CNN/Daily Main and New York Times datasets. It is a good incremental research, but the downside of this paper is lack of innovations since most of the methods proposed in this paper are not new to us.\n\nI would like to see the model ablation w.r.t. repetition avoidance trick by muting the second trigram at test time. Intuitively, if the repetition issue is prominent to having decent summarization performance, it might affect our judgement on the significance of using intra-attention or combined RL signal.\nAnother thought on this: is it possible to integrate the trigram occurrence with summarization reward? so that the recurrent neural networks with attention could capture the learning signal to avoid the repetition issue and the heuristic function in the test time can be removed. \n\nIn addition, as the encoder-decoder structure gradually becomes the standard choice of sequence prediction, I would suggest the authors to add the sum of parameters into model ablation for reference.\n\nSuggested References:\nBahdanau et al. (2016) An Actor-critic Algorithm for Sequence Prediction. (actor-critic on machine translation)\nMiao & Blunsom (2016) Language as a Latent Variable: Discrete Generative Models for Sentence Compression. (mixture pointer mechanism + REINFORCE)\n']","[90, 60, 50]","[80, 70, 75]","[""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer describes the paper as 'very clearly written' and 'a pleasure to read'. They praise the combination of known and novel mechanisms, the comprehensive experiments, and the compelling comparisons with other methods. The only slightly critical points are phrased as questions in the 'minor points' section, which doesn't significantly detract from the overall positive sentiment. The politeness score is 80 because the language used is consistently respectful and constructive. The reviewer uses phrases like 'It was a nice result' and frames their questions politely ('I wonder about'). While not excessively formal, the tone is professional and courteous throughout, avoiding any harsh or critical language."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as 'strong' and notes that it presents 'significant improvement in document summarization'. They also praise the strong results obtained. However, it's not extremely positive as the reviewer does raise some concerns and suggestions for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. Phrases like 'It would be interesting to see' and 'I suggest' indicate a polite and collaborative tone. The reviewer also acknowledges the paper's strengths while providing feedback, which is a hallmark of polite academic discourse."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by praising the paper as 'generally well-written' with 'very clear' intuition and mentions that it achieves 'state-of-the-art performance'. However, they also note a 'downside' in the lack of innovations, balancing the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticism. They use phrases like 'I would like to see' and 'I would suggest' which are polite ways of making recommendations. The reviewer also acknowledges the paper's strengths before mentioning areas for improvement, which is a courteous approach to feedback.""]"
"['The paper concerns distributions used for the code space in implicit models, e.g. VAEs and GANs. The authors analyze the relation between the latent space dimension and the normal distribution which is commonly used for the latent distribution. The well-known fact that probability mass concentrates in a shell of hyperspheres as the dimensionality grows is used to argue for the normal distribution being sub-optimal when interpolating between points in the latent space with straight lines. To correct this, the authors propose to use a Gamma-distribution for the norm of the latent space (and uniform angle distribution). This results in more mass closer to the origin, and the authors show both that the midpoint distribution is natural in terms of the KL divergence to the data points, and experimentally that the method gives visually appealing interpolations.\n\nWhile the contribution of using a standard family of distributions in a standard implicit model setup is limited, the paper does make interesting observations, analyses and an attempt to correct the interpolation issue. The paper is clearly written and presents the theory and experimental results nicely. I find that the paper can be accepted but the incremental nature of the contribution prevents a higher score.', 'The authors propose the use of a gamma prior as the distribution over \nthe latent representation space in GANs. The motivation behind it is that \nin GANs interpolating between sampled points is common in the process of generating examples but the use of a normal prior results in samples that fall in low probability mass regions. The use of the proposed gamma distribution, as a simple alternative, overcomes this problem. \n\nIn general, the proposed work is very interesting and the idea is neat. \nThe paper is well presented and I want to underline the importance of this. \nThe authors did a very good job presenting the problem, motivation and solution in a coherent fashion and easy to follow. \n\nThe work itself is interesting and can provide useful alternatives for the distribution over the latent space. \n', ""The authors discuss a direct Gamma sampling method for the interpolated samples in GANs, and show the improvements over usual normal sampling for CelebA, MNIST, CIFAR and SVHN datasets.\n\nThe method involves a nice, albeit minor, trick, where the chi-squared distribution of the sum of the z_{i}^{2} has its dependence on the dimensionality removed. However I am not convinced by the distribution of \\|z^\\prime\\|^{2} in the first place (eqn (2)): the samples from the gaussian will be approximately orthogonal in high dimensions, but the inner product will be at least O(1). Thus although the \\|z_{0}\\|^{2} and \\|z_{1}\\|^{2} are chi-squared/gamma, I don't think \\|z^\\prime\\|^{2} is exactly gamma in general.\n\nThe experiments do show that the interpolated samples are qualitatively better, but a thorough empirical analysis for different dimensionalities would be welcome. Figures 2 and 3 do not add anything to the story, since 2 is just a plot of gamma pdfs and 3 shows the difference between the constant KL and the normal case that is linear in d. \n\nOverall I think the trick needs to be motivated better, and the experiments improved to really show the import of the d-independence of the KL. Thus I think this paper is below the acceptance threshold.""]","[50, 90, -60]","[75, 80, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting observations, clear writing, and nice presentation of theory and results. They recommend acceptance, but note the contribution is incremental, preventing a higher score. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'interesting observations,' 'clearly written,' and 'presents the theory and experimental results nicely,' which contribute to a polite tone. The reviewer also provides a balanced perspective, noting both positive aspects and limitations without using harsh or dismissive language."", ""The sentiment score is 90 because the reviewer expresses a very positive view of the paper. They describe the work as 'very interesting' and 'neat', and emphasize that the paper is 'well presented'. The reviewer also underlines 'the importance of this' and praises the authors for doing 'a very good job'. There are no negative comments, only positive ones. The politeness score is 80 because the language used is consistently respectful and appreciative. The reviewer uses phrases like 'I want to underline the importance of this' and 'The authors did a very good job', which are polite ways of giving praise. The tone is professional and constructive throughout, without any harsh or critical language."", ""The sentiment score is -60 because the reviewer expresses significant doubts about the paper's methodology and conclusions, stating it is 'below the acceptance threshold'. However, they do acknowledge some positive aspects like the 'nice trick' and 'qualitatively better' results, preventing an extremely negative score. The politeness score is 20 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They offer constructive feedback and suggestions for improvement, which is polite. However, the tone remains largely neutral and academic rather than overtly friendly or complimentary, hence the moderate positive score.""]"
"['I have evaluated this paper for NIPS 2017 and gave it an ""accept"" rating at the time, but the paper was ultimately not accepted. This resubmission has been massively improved and definitely deserves to be published at ICLR.\n\nThis paper formulates the problem localisation on a known map using a belief network as an RL problem. The goal of the agent is to minimise the number of steps to localise itself (the agent needs to move around to accumulate evidence about its position), which corresponds to reducing the entropy of the joint distribution over a discretized grid over theta (4 orientations), x and y. The model is evaluated on a grid world, on textured 3D mazes with simplified motion (Doom environment) and on a photorealistic environment using the Unreal engine. Optimisation is done through A3C RL. Transfer from the crude simulated Doom environment to the photorealistic Unreal environment is achieved.\n\nThe belief network consists of an observation model, a motion prediction model that allows for translations along x or y and 90deg rotation, and an observation correction model that either perceives the depth in front of the agent (a bold and ambiguous choice) and matches it to the 2D map, or perceives the image in front of the agent. The map is part of the observation.\n\nThe algorithm outperforms Bayes filters for localisation in 2D and 3D and the idea of applying RL to minimise the entropy of position estimation is brilliant. Minor note: I am surprised that the cognitive map reference (Gupta et al, 2017) was dropped, as it seemed relevant.', 'This is an interesting paper that builds a parameterized network to select actions for a robot in a simulated environment, with the objective of quickly reaching an internal belief state that is predictive of the true state.  This is an interesting idea and it works much better than I would have expected.  \n\nIn more careful examination it is clear that the authors have done a good job of designing a network that is partly pre-specified and partly free, in a way that makes the learning effective.  In particular\n- the transition model is known and fixed (in the way it is used in the belief update process)\n- the belief state representation is known and fixed (in the way it is used to decide whether the agent should be rewarded)\n- the reward function is known and fixed (as above)\n- the mechanics of belief update\nBut we learn\n- the observation model\n- the control policy\n\nI\'m not sure that global localization is still an open problem with known models.  Or, at least, it\'s not one of our worst.\n\nEarly work by Cassandra, Kurien, et al used POMDP models and solvers for active localization with known transition and observation models.   It was computationally slow but effective.\n\nSimilarly, although the online speed of your learned method is much better than for active Markov localization, the offline training cost is dramatically higher;  it\'s important to remember to be clear on this point.\n\nIt is not obvious to me that it is sensible to take the cosine similarity between the feature representation of the observation and the feature representation of the state to get the entry in the likelihood map.   It would be good to make it clear this is the right measure.\n\nHow is exploration done during the RL phase?  These domains are still not huge.\n\nPlease explain in more detail what the memory images are doing.\n\nIn general, the experiments seem to be well designed and well carried out, with several interesting extensions.\n\nI have one more major concern:  it is not the job of a localizer to arrive at a belief state with high probability mass on the true state---it is the job of a localizer to have an accurate approximation of the true posterior under the prior and observations.   There are situations (in which, for example, the robot has gotten an unusual string of observations) in which it is correct for the robot to have more probability mass on a ""wrong"" state.  Or, it seems that this model may earn rewards for learning to make its beliefs overconfident.  It would be very interesting to see if you could find an objective that would actually cause the model to learn to compute the appropriate posterior.\n\nIn the end, I have trouble making a recommendation:\nCon:  I\'m not convinced that an end-to-end approach to this problem is the best one\nPro: It\'s actually a nice idea that seems to have worked out well\nCon: I remain concerned that the objective is not the right one\n\nMy rating would really be something like 6.5 if that were possible.\n\n\n\n\n', 'The paper describes a neural network-based approach to active localization based upon RGB images. The framework employs Bayesian filtering to maintain an estimate of the agent\'s pose using a convolutional network model for the measurement (perception) function. A convolutional network models the policy that governs the action of the agent. The architecture is trained in an end-to-end manner via reinforcement learning. The architecture is evaluated in 2D and 3D simulated environments of varying complexity and compared favorably to traditional (structured) approaches to passive and active localization.\n\nAs the paper correctly points out, there is large body of work on map-based localization, but relatively little attention has been paid to decision theoretic formulations to localization, whereby the agent\'s actions are chosen in order to improve localization accuracy. More recent work instead focuses on the higher level objective of navigation, whereby any effort act in an effort to improve localization are secondary to the navigation objective. The idea of incorporating learned representations with a structured Bayesian filtering approach is interesting, but it\'s utility could be better motivated. What are the practical benefits to learning the measurement and policy model beyond (i) the temptation to apply neural networks to this problem and (ii) the ability to learn these in an end-to-end fashion? That\'s not to say that there aren\'t benefits, but rather that they aren\'t clearly demonstrated here. Further, the paper seems to assume (as noted below) that there is no measurement uncertainty and, with the exception of the 3D evaluations, no process noise.\n\nThe evaluation demonstrates that the proposed method yields estimates that are more accurate according to the proposed metric than the baseline methods, with a significant reduction in computational cost. However, the environments considered are rather small by today\'s standards and the baseline methods almost 20 years old. Further, the evaluation makes a number of simplifying assumptions, the largest being that the measurements are not subject to noise (the only noise that is present is in the motion for the 3D experiments). This assumption is clearly not valid in practice. Further, it is not clear from the evaluation whether the resulting distribution that is maintained is consistent (e.g., are the estimates over-/under-confident?). This has important implications if the system were to actually be used on a physical system. Further, while the computational requirements at test time are significantly lower than the baselines, the time required for training is likely very large. While this is less of an issue in simulation, it is important for physical deployments. Ideally, the paper would demonstrate performance when transferring a policy trained in simulation to a physical environment (e.g., using diversification, which has proven effective at simulation-to-real transfer).\n\nComments/Questions:\n\n* The nature of the observation space is not clear.\n\n* Recent related work has focused on learning neural policies for navigation, and any localization-specific actions are secondary to the objective of reaching the goal. It would be interesting to discuss how one would balance the advantages of choosing actions that improve localization with those in the context of a higher-level task (or at least including a cost on actions as with the baseline method of Fox et al.).\n\n* The evaluation that assigns different textures to each wall is unrealistic.\n\n* It is not clear why the space over which the belief is maintained flips as the robot turns and shifts as it moves.\n\n* The 3D evaluation states that a 360 deg view is available. What happens when the agent can only see in one (forward) direction?\n\n* AML includes a cost term in the objective. Did the author(s) experiment with setting this cost to zero?\n\n* The 3D environments rely upon a particular belief size (70 x 70) being suitable for all environments. What would happen if the test environment was larger than those encountered in training?\n\n* The comment that the PoseNet and VidLoc methods ""lack a strainghtforward method to utilize past map data to do localization in a new environment"" is unclear.\n\n* The environments that are considered are quite small compared to the domains currently considered for\n\n* Minor: It might be better to move Section 3 into Section 4 after introducing notation (to avoid redundancy).\n* The paper should be proofread for grammatical errors (e.g., ""bayesian"" --> ""Bayesian"", ""gaussian"" --> ""Gaussian"")\n\n\nUPDATES FOLLOWING AUTHORS\' RESPONSE\n\n(Apologies if this is a duplicate. I added a comment in light of the authors\' response, but don\'t see it and so I am updating my review for completeness).\n\nI appreciate the authors\'s response to the initial reviews and thank them for addressing several of my comments.\n\nRE: Consistency\nMy concerns regarding consistency remain. For principled ways of evaluating the consistency of an estimator, see Bar-Shalom ""Estimation with Applications to Tracking and Navigation"".\n\nRE: Measurement/Process Noise\nThe fact that the method assumes perfect measurements and, with the exception of the 3D experiments, no process noise is concerning as neither assumptions are valid for physical systems. Indeed, it is this noise in particular that makes localization (and its variants) challenging.\n\nRE: Motivation\nThe response didn\'t address my comments about the lack motivation for the proposed method. Is it largely the temptation of applying an end-to-end neural method to a new problem? The paper should be updated to make the advantages over traditional approaches to active localization.']","[90, 50, -30]","[80, 70, 50]","[""The sentiment score is 90 (highly positive) because the reviewer explicitly states that the paper 'definitely deserves to be published' and describes the work as 'brilliant'. They also mention that the resubmission has been 'massively improved'. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and provides constructive feedback. The only slightly critical comment is phrased as a 'minor note', maintaining a polite tone. The reviewer's language is professional and supportive, indicating a high level of respect for the authors' work."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as 'interesting' and notes that it 'works much better than I would have expected.' They also praise the authors for doing 'a good job' in designing the network. However, the reviewer also expresses some concerns and hesitation in making a final recommendation, which prevents the score from being higher. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the work and framing criticisms as suggestions or questions (e.g., 'Please explain in more detail...'). The reviewer also balances critiques with positive comments and uses phrases like 'it would be good to' and 'it would be very interesting' when suggesting improvements, which contributes to a polite tone."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The idea of incorporating learned representations with a structured Bayesian filtering approach is interesting'), they express several significant concerns and criticisms. These include lack of clear motivation, simplifying assumptions in the evaluation, and outdated baselines. The overall tone suggests the reviewer is not fully convinced by the paper's contributions.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'It would be interesting to discuss...' and 'The paper should be proofread for grammatical errors' which offer constructive feedback without being harsh. The reviewer also acknowledges the authors' response and thanks them for addressing some comments. However, the score is not higher as the critique is direct and doesn't use overly polite language or praise.""]"
"['This paper thoroughly analyzes an algorithmic task (determining if two points in a maze are connected, which requires BFS to solve) by constructing an explicit ConvNet solution and analytically deriving properties of the loss surface around this analytical solution. They show that their analytical solution implements a form of BFS algorithm, characterize the probability of introducing ""bugs"" in the algorithm as the weights move away from the optimal solution, and how this influences the error surface for different depths. This analysis is conducted by drawing on results from the field of critical percolation in physics.\n\nOverall, I think this is a good paper and its core contribution is definitely valuable: it provides a novel analysis of an algorithmic task which sheds light on how and when the network fails to learn the algorithm, and in particular the role which initialization plays. The analysis is very thorough and the methods described may find use in analyzing other tasks. In particular, this could be a first step towards better understanding the optimization landscape of memory-augmented neural networks (Memory Networks, Neural Turing Machines, etc) which try to learn reasoning tasks or algorithms. It is well-known that these are sensitive to initialization and often require running the optimizer with multiple random seeds and picking the best one. This work actually explains the role of initialization for learning BFS and how certain types of initialization lead to poor solutions. I am curious if a similar analysis could be applied to methods evaluated on the bAbI question-answering tasks (which can be represented as graphs, like the maze task) and possibly yield better initialization or optimization schemes that would remove the need for multiple random seeds.  \n\nWith that being said, there is some work that needs to be done to make the paper clearer. In particular, many parts are quite technical and may not be accessible to a broader machine learning audience. It would be good if the authors spent more time developing intuition (through visualization for example) and move some of the more technical proofs to the appendix. Specifically:\n- I think Figure 3 in the appendix should be moved to the main text, to help understand the behavior of the analytical solution. \n- Top of page 5, when you describe the checkerboard BFS: please include a visualization somewhere, it could be in the Appendix.\n- Section 6: there is lots of math here, but the main results don\'t obviously stand out. I would suggest highlighting equations 2 and 4 in some way (for example, proposition/lemma + proof), so that the casual reader can quickly see what the main results are. Interested readers can then work through the math if they want to. Also, some plots/visualizations of the loss surface given in Equations 4 and 5 would be very helpful. \n\nAlso, although I found their work to be interesting after finishing the paper, I was initially confused by how the authors frame their work and where the paper was heading. They claim their contribution is in the analysis of loss surfaces (true) and neural nets applied to graph-structured inputs. This second part was confusing - although the maze can be viewed as a graph, many other works apply ConvNets to maze environments [1, 2, 3], and their work has little relation to other work on graph CNNs. Here the assumptions of locality and stationarity underlying CNNs are sensible and I don\'t think the first paragraph in Section 3 justifying the use of the CNN on the maze environment is necessary. However, I think it would make much more sense to mention how their work relates to other neural network architectures which learn algorithms (such as the Neural Turing Machine and variants) or reasoning tasks more generally (for example, memory-augmented networks applied to the bAbI tasks). \n\nThere are lots of small typos, please fix them. Here are a few:\n- ""For L=16, batch size of 20, ..."": not a complete sentence. \n- Right before 6.1.1: ""when the these such"" -> ""when such""\n- Top of page 8: ""it also have a"" -> ""it also has a"", ""when encountering larger dataset"" -> ""...datasets""\n-  First sentence of 6.2: ""we turn to the discuss a second"" -> ""we turn to the discussion of a second""\n- etc. \n\nQuality: High\nClarity: medium-low\nOriginality: high\nSignificance: medium-high\n\nReferences:\n[1] https://arxiv.org/pdf/1602.02867.pdf\n[2] https://arxiv.org/pdf/1612.08810.pdf\n[3] https://arxiv.org/pdf/1707.03497.pdf', 'The authors are motivated by two problems: Inputting non-Euclidean data (such as graphs) into deep CNNs, and analyzing optimization properties of deep networks. In particular, they look at the problem of maze testing, where, given a grid of black and white pixels, the goal is to answer whether there is a path from a designated starting point to an ending point. \n\nThey choose to analyze mazes because they have many nice statistical properties from percolation theory. For one, the problem is solvable with breadth first search in O(L^2) time, for an L x L maze. They show that a CNN can essentially encode a BFS, so theoretically a CNN should be able to solve the problem. Their architecture is a deep feedforward network where each layer takes as input two images: one corresponding to the original maze (a skip connection), and the output of the previous layer. Layers alternate between convolutional and sigmoidal. The authors discuss how this architecture can solve the problem exactly. The pictorial explanation for how the CNN can mimic BFS is interesting but I got a little lost in the 3 cases on page 4. For example, what is r? And what is the relation of the black/white and orange squares? I thought this could use a little more clarity. \n\nThough experiments, they show that there are two kinds of minima, depending on whether we allow negative initializations in the convolution kernels. When positive initializations are enforced, the network can more or less mimic the BFS behavior, but never when initializations can be negative. They offer a rigorous analysis into the behavior of optimization in each of these cases, concluding that there is an essential singularity in the cost function around the exact solution, yet learning succumbs to poor optima due to poor initial predictions in training. \n\nI thought this was an impressive paper that looked at theoretical properties of CNNs. The problem was very well-motivated, and the analysis was sharp and offered interesting insights into the problem of maze solving. What I thought was especially interesting is how their analysis can be extended to other graph problems; while their analysis was specific to the problem of maze solving, they offer an approach -- e.g. that of finding ""bugs"" when dealing with graph objects -- that can extend to other problems. I would be excited to see similar analysis of other toy problems involving graphs.\n\nOne complaint I had was inconsistent clarity: while a lot was well-motivated and straightforward to understand, I got lost in some of the details (as an example, the figure on page 4 did not initially make much sense to me). Also, in the experiments, the authors mention multiple attempt with the same settings -- are these experiments differentiated only by their initialization? Finally, there were various typos throughout (one example is ""neglect minimua"" on page 2 should be ""neglect minima"").\n\nPros: Rigorous analysis, well motivated problem, generalizable results to deep learning theory\nCons: Clarity ', 'This paper studies a toy problem: a random binary image is generated, and treated as a maze (1=wall, 0=freely moveable space). A random starting point is generated. The task is to learn whether the center pixel is reachable from the starting point.\n\nA deep architechture is proposed to solve the problem: see fig 1. A conv net on the image is combined with that on a state image, the state being interpreted as rechable pixels. This can work if each layer expands the reachable region (the state) by one pixel if the pixel is not blocked.\n\nTwo local minima are observed: 1) the network ignores stucture and guesses if the task is solvable by aggregate statistics 2) it works as described above but propagates the rechable region on a checkerboard only.\n\nThe paper is chiefly concerned with analysing these local minima by expanding the cost function about them. This analysis is hard to follow for non experts graph theory. This is partly because many non-trivial results are mentioned with little or no explanation.\n\nThe paper is hard to evaluate. The actual setup seems somewhat arbitrary, but the method of analysing the failure modes is interesting. It may inspire more useful research in the future.\n\nIf we trust the authors, then the paper seems good because it is fairly unusual. But it is hard to determine whether the analysis is correct.']","[70, 80, -20]","[80, 70, 20]","[""The sentiment score is 70 (positive) because the reviewer states 'Overall, I think this is a good paper and its core contribution is definitely valuable' and provides several positive comments about the paper's thorough analysis and potential impact. However, it's not 100 as the reviewer also points out areas for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. Phrases like 'I think', 'I would suggest', and 'I am curious' indicate a collegial tone. The reviewer also balances critique with praise, showing consideration for the authors' work."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, calling it 'impressive' and noting its 'rigorous analysis' and 'well-motivated problem'. They mention being 'excited to see similar analysis' in the future. The few criticisms (inconsistent clarity, some confusing details) are minor compared to the overall positive assessment. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts and contributions. They frame criticisms constructively, using phrases like 'I thought this could use a little more clarity' rather than harsh language. The reviewer balances praise with gentle suggestions for improvement, maintaining a professional and courteous tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the paper, they express several concerns. The reviewer states that the paper is 'hard to evaluate,' the setup seems 'somewhat arbitrary,' and the analysis is 'hard to follow for non experts.' They also mention that it's 'hard to determine whether the analysis is correct.' However, they do note that the method of analyzing failure modes is interesting and may inspire future research, which prevents the score from being more negative. The politeness score is slightly positive (20) because the reviewer uses neutral language and avoids harsh criticism. They present their concerns in a professional manner, using phrases like 'if we trust the authors' and acknowledging potential future value. The reviewer also balances critique with positive observations, which contributes to a polite tone.""]"
"['The paper describes reinforcement learning techniques for digital asset search.  The RL techniques consist of A3C and DQN.  This is an application paper since the techniques described already exist.  Unfortunately, there is a lack of detail throughout the paper and therefore it is not possible for someone to reproduce the results if desired.  Since there is no corpus of message response pairs to train the model, the paper trains a simulator from logs to emulate user behaviours.  Unfortunately, there is no description of the algorithm used to obtain the simulator.  The paper explains that the simulator is obtained from log data, but this is not sufficient.  The RL problem is described at a very high level in the sense that abstract states and actions are listed, but there is no explanation about how those abstract states are recognized from the raw text and there is no explanation about how the actions are turned into text.  There seems to be some confusion in the notion of state.  After describing the abstract states, it is explained that actions are selected based on a history of states.  This suggests that the abstract states are really abstract observations.   In fact, this becomes obvious when the paper introduces the RNN where a hidden belief is computed by combining the observations.  The rewards are also described at a hiogh level, but it is not clear how exactly they are computed.  The digital search application is interesting, however a detailed description with comprehensive experiments are needed for the publication of an application paper.', 'The paper ""IMPROVING SEARCH THROUGH A3C REINFORCEMENT LEARNING BASED CONVERSATIONAL AGENT"" proposes to define an agent to guide users in information retrieval tasks. By proposing refinements of the query, categorizations of the results or some other bookmarking actions, the agent is supposed to help the user in achieving his search. The proposed agent is learned via reinforcement learning. \n\nMy concern with this paper is about the experiments that are only based on simulated agents, as it is the case for learning. While it can be questionable for learning (but we understand why it is difficult to overcome), it is very problematic for the experiments to not have anything that demonstrates the usability of the approach in a real-world scenario. I have serious doubts about the performances of such an artificially learned approach for achieving real-world search tasks. Also, for me the experimental section is not sufficiently detailed, which lead to not reproducible results. Moreover, authors should have considered baselines (only the two proposed agents are compared which is clearly not sufficient). \n\nAlso, both models have some issues from my point of view. First, the Q-learning methods looks very complex: how could we expect to get an accurate model with 10^7 states ? No generalization about the situations is done here, examples of trajectories have to be collected for each individual considered state, which looks very huge (especially if we think about the number of possible trajectories in such an MDP). The second model is able to generalize from similar situations thanks to the neural architecture that is proposed. However, I have some concerns about it: why keeping the history of actions in the inputs since it is captured by the LSTM cell ? It is a redondant information that might disturb the process. Secondly, the proposed loss looks very heuristic for me, it is difficult to understand what is really optimized here. Particularly, the loss entropy function looks strange to me. Is it classical ? Are there some references of such a method to maintain some exploration ability. I understand the need of exploration, but including it in the loss function reduces the interpretability of the objective (wouldn\'t it be preferable to use a more classical loss but with an epsilon greedy policy?).\n\n\nOther remarks: \n   - In the begining of ""varying memory capacity"" section, what is ""100, 150 and 250"" ? Time steps ? What is the unit ? Seconds ?   \n   - I did not understand the ""Capturing seach context at local and global level"" at all\n   - In the loss entropy formula, the two negation signs could be removed\n  \n', 'This paper proposes to use RL (Q-learning and A3C) to optimize the interaction strategy of a search assistant. The method is trained against a simulated user to bootstrap the learning process. The algorithm is tested on some search base of assets such as images or videos. \n\nMy first concern is about the proposed reward function which is composed of different terms. These are very engineered and cannot easily transfer to other tasks. Then the different algorithms are assessed according to their performance w.r.t. to these rewards. They of course improve with training since this is the purpose of RL to optimize these numbers. Assessment of a dialogue system should be done according to metrics obtained through actual interactions with users, not according to auxiliary tasks etc. \n\nBut above all, this paper incredibly lacks of context in both RL and dialogue systems. The authors cite a 2014 paper when it comes to refer to Q-learning (Q-learning was first published in 1989 by Watkins). The first time dialogue has been casted into a RL problem is in 1997 by E. Levin and R. Pieraccini (although it has been suggested before by M. Walker). User simulation has been proposed at the same time and further developed in the early 2000 by Schatzmann, Young, Pietquin etc. Using LSTMs to build user models has been proposed in 2016 (Interspeech) by El Asri et al. Buiding efficient reward functions for RL-based conversational systems has also been studied for more than 20 years with early work by M. Walker on PARADISE (@ACL 1997) but also via inverse RL by Chandramohan et al (2011). A2C (which is a single-agent version of A3C) has been used by Strub et al (@ IJCAI 2017) to optimize visually grounded dialogue systems. RL-based recommender systems have also been studied before (e.g. Shani in JMLR 2005).   \n\nI think the authors should first read the state of the art in the domain before they suggest new solutions. ']","[-60, -60, -70]","[0, 20, -20]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several significant issues with the paper, such as lack of detail, inability to reproduce results, and confusion in key concepts. The phrase 'Unfortunately' is used twice, emphasizing the negative aspects. However, it's not entirely negative as the reviewer acknowledges the interesting application, which prevents the score from being lower.\n\nThe politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout without using overtly polite or rude language. The criticism is direct but not personal or insulting. The reviewer states facts and observations without sugar-coating or being unnecessarily harsh.\n\nThe reasoning for these scores is based on the overall tone, specific phrases used, and the balance between positive and negative comments in the review. The lack of personal attacks or overly courteous language supports the neutral politeness score."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper, particularly regarding the experimental setup and the lack of real-world testing. The reviewer uses phrases like 'very problematic,' 'serious doubts,' and 'not sufficiently detailed,' indicating a largely negative view of the paper. However, the score is not at the extreme negative end because the reviewer does acknowledge some understanding of the difficulties in overcoming certain limitations.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively courteous tone throughout. They use phrases like 'My concern is...' and 'From my point of view...' which soften the criticism. The reviewer also provides specific suggestions for improvement, which is constructive. However, the score is only slightly positive because the language, while not rude, is also not overtly polite or complimentary."", ""The sentiment score is -70 because the reviewer expresses significant concerns about the paper, particularly its lack of context in RL and dialogue systems, and criticizes the authors for not being aware of existing literature. The reviewer points out multiple issues with the paper's approach and cites numerous prior works that the authors seem to have overlooked. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite critical and dismissive. Phrases like 'incredibly lacks context' and 'I think the authors should first read the state of the art in the domain before they suggest new solutions' come across as condescending and impolite. The reviewer does not attempt to soften their criticism or provide encouragement, which contributes to the negative politeness score.""]"
"['The authors have addressed the problem of translating natural language queries to SQL queries. They proposed a deep neural network based solution which combines the attention based neural semantic parser and pointer networks. They also released a new dataset WikiSQL for the problem. The proposed method outperforms the existing semantic parsing baselines on WikiSQL dataset.\n\nPros:\n1. The idea of using pointer networks for reducing search space of generated queries is interesting. Also, using extrinsic evaluation of generated queries handles the possibility of paraphrasing SQL queries.\n2. A new dataset for the problem.\n3. The experiments report a significant boost in the performance compared to the baseline. The ablation study is helpful for understanding the contribution of different component of the proposed method.\n\nCons:\n1. It would have been better to see performance of the proposed method in other datasets (wherever possible). This is my main concern about the paper.\n2. Extrinsic evaluation can slow down the overall training. Comparison of running times would have been helpful.\n3. More details about training procedure (specifically for the RL part) would have been better.', ""This work introduces a new semantic parsing dataset, which focuses on generating SQL from natural language. It also proposes a reinforcement-learning based model for this task.\n\nFirst of all, I'd like to emphasize that the creation of a large scale semantic parsing dataset is fantastic, and it is a much appreciated contribution. However, I find its presentation problematic. It claims to supplant existing semantic parsing and language-to-SQL datasets, painting WikiSQL as a more challenging dataset overall. Given the massive simplifications to what is considered SQL in this dataset (no joins, no subqueries, minimal lexical grounding problem), I am reluctant to accept this claim without empirical evidence. For example, how well does the proposed model work when evaluated on an existing dataset containing full SQL queries, such as ATIS? That being said, I am sympathetic to making simplifications to a dataset for the sake of scalability, but it shouldn't be presented as representative of SQL.\n\nOn the modeling side, the role of reinforcement learning seems oddly central in the paper, even though though the added complexity is not well motivated. RL is typically needed when there are latent decisions that can affect the outcome in ways that are not known a priori. In this case, we know the reward is invariant to the ordering of the tokens in the WHERE clause. There are far simpler solutions that would achieve the same result, such as optimizing the marginal likelihood or even simply including all orderings as training examples. These should be included as baselines.\n\nWhile the data contribution is great, the claims of the paper need to be revised."", 'This paper presents a new approach to support the conversion from natural language to database queries. \n\nOne of the major contributions of the work is the introduction of a new real-world benchmark dataset based on questions over Wikipedia. The scale of the data set is significantly larger than any existing ones. However, from the technical perspective, the reviewer feels this work has limited novelty and does not advance the research frontier by much. The detailed comments are listed below.\n\n1) Limitation of the dataset: While the authors claim this is a general approach to support seq2sql, their dataset only covers simple queries in form of aggregate-where-select structure. Therefore, their proposed approach is actually an advanced version of template filling, which considers the expression/predicate for one of the three operators at a time, e.g., (Giordani and Moschitti, 2012).\n\n2) Limitation of generalization: Since the design of the algorithms is purely based on their own WikiSQL dataset, the reviewer doubts if their approach could be generalized to handle more complicated SQL queries, e.g., (Li and Jagadish, 2014). The high complexity of real-world SQL stems from the challenges on the appropriate connections between tables with primary/foreign keys and recursive/nested queries. \n\n3) Comparisons to existing approaches: Since it is a template-based approach in nature, the author should shrink the problem scope in their abstract/introduction and compare against existing template approaches. While there are tons of semantic parsing works, which grow exponentially fast in last two years, these works are actually handling more general problems than this submission does. It thus makes sense when the performance of semantic parsing approaches on a constrained domain, such as WikiSQL, is not comparable to the proposal in this submission. However, that only proves their method is fully optimized for their own template.\n\nAs a conclusion, the reviewer believes the problem scope they solve is much smaller than their claim, which makes the submission slightly below the bar of ICLR. The authors must carefully consider how their proposed approach could be generalized to handle wider workload beyond their own WikiSQL dataset. \n\nPS, After reading the comments on OpenReview, the reviewer feels recent studies, e.g., (Guu et al., ACL 2017), (Mou et al, ICML 2017) and (Yin et al., IJCAI 2016), deserve more discussions in the submission because they are strongly relevant and published on peer-reviewed conferences.']","[70, -20, -60]","[50, 60, 20]","[""The sentiment score is 70 (positive) because the review starts with a neutral summary of the paper's content, followed by a list of pros that outweigh the cons. The reviewer acknowledges the paper's contributions, innovative approach, and significant performance improvements. The cons are presented as constructive suggestions rather than severe criticisms. The politeness score is 50 (slightly positive) because the reviewer uses neutral, professional language throughout. They offer balanced feedback, presenting both pros and cons without using overly critical or praising language. The suggestions for improvement are phrased politely, using phrases like 'It would have been better' and 'would have been helpful', indicating a respectful tone while providing constructive feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the value of the dataset creation ('fantastic' and 'much appreciated contribution'), they express significant concerns about the paper's claims and methodology. The reviewer is 'reluctant to accept' some claims, finds the presentation 'problematic', and suggests the claims 'need to be revised'. However, the criticism is balanced with some positive remarks, preventing a more negative score. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positives ('fantastic', 'much appreciated') and using softening phrases ('I am sympathetic', 'I'd like to emphasize'). They offer constructive criticism and suggestions rather than harsh dismissals, maintaining a professional and courteous tone even when expressing disagreement."", ""The sentiment score is -60 because the reviewer expresses significant criticisms and limitations of the paper, stating it has 'limited novelty' and is 'slightly below the bar of ICLR'. The reviewer questions the generalizability and scope of the work, which contributes to the negative sentiment. However, the score is not at the extreme negative end because the reviewer does acknowledge some positive aspects, such as the large-scale dataset. The politeness score is 20 because while the reviewer's tone is generally professional and constructive, offering specific feedback and suggestions, there are instances of direct criticism that could be perceived as slightly harsh. The reviewer uses phrases like 'the reviewer feels this work has limited novelty' and 'the reviewer doubts if their approach could be generalized', which are honest but not overly polite. Overall, the review maintains a respectful tone while delivering critical feedback.""]"
"['The paper proposes a method for identifying representative examples for program\nsynthesis to increase the scalability of existing constraint programming\nsolutions. The authors present their approach and evaluate it empirically.\n\nThe proposed approach is interesting, but I feel that the experimental section\ndoes not serve to show its merits for several reasons. First, it does not\ndemonstrate increased scalability. Only 1024 examples are considered, which is\nby no means large. Even then, the authors approach selects the highest number of\nexamples (figure 4). CEGIS both selects fewer examples and has a shorter median\ntime for complete synthesis. Intuitively, the authors\' method should scale\nbetter, but they fail to show this -- a missed opportunity to make the paper\nmuch more compelling. This is especially true as a more challenging benchmark\ncould be created very easily by simply scaling up the image.\n\nSecond, there is no analysis of the representativeness of the found sets of\nconstraints. Given that the results are very close to other approaches, it\nremains unclear whether they are simply due to random variations, or whether the\nproposed approach actually achieves a non-random improvement.\n\nIn addition to my concerns about the experimental evaluation, I have concerns\nabout the general approach. It is unclear to me that machine learning is the\nbest approach for modeling and solving this problem. In particular, the\nselection probability of any particular example could be estimated through a\nheuristic, for example by simply counting the number of neighbouring examples\nthat have a different color, weighted by whether they are in the set of examples\nalready, to assess its ""borderness"", with high values being more important to\nachieve a good program. The border pixels are probably sufficient to learn the\nprogram perfectly, and in fact this may be exactly what the neural net is\nlearning. The above heuristic is obviously specific to the domain, but similar\nheuristics could be easily constructed for other domains. I feel that this is\nsomething the authors should at least compare to in the empirical evaluation.\n\nAnother concern is that the authors\' approach assumes that all parameters have\nthe same effect. Even for the example the authors give in section 2, it is\nunclear that this would be true.\n\nThe text says that rand+cegis selects 70% of examples of the proposed approach,\nbut figure 4 seems to suggest that the numbers are very close -- is this initial\nexamples only?\n\nOverall the paper appears rushed -- the acknowledgements section is left over\nfrom the template and there is a reference to figure ""blah"". There are typos and\ngrammatical mistakes throughout the paper. The reference to ""Model counting"" is\nincomplete.\n\nIn summary, I feel that the paper cannot be accepted in its current form.', 'General-purpose program synthesizers are powerful but often slow, so work that investigates means to speed them up is very much welcome—this paper included. The idea proposed (learning a selection strategy for choosing a subset of synthesis examples) is good. For the most paper, the paper is clearly-written, with each design decision justified and rigorously specified. The experiments show that the proposed algorithm allows a synthesizer to do a better job of reliably finding a solution in a short amount of time (though the effect is somewhat small).\n\nI do have some serious questions/concerns about this method:\n\nPart of the motivation for this paper is the goal of scaling to very large sets of examples. The proposed neural net setup is an autoencoder whose input/output size is proportional to the size of the program input domain. How large can this be expected to scale (a few thousand)? \n\nThe paper did not specify how often the neural net must be trained. Must it be trained for each new synthesis problem? If so, the training time becomes extremely important (and should be included in the “NN Phase” time measurements in Figure 4). If this takes longer than synthesis, it defeats the purpose of using this method in the first place.\nAlternatively, can the network be trained once for a domain, and then used for every synthesis problem in that domain (i.e. in your experiments, training one net for all possible binary-image-drawing problems)? If so, the training time amortizes to some extent—can you quantify this?\nThese are all points that require discussion which is currently missing from the paper.\n\nI also think that this method really ought to be evaluated on some other domain(s) in addition to binary image drawing. The paper is not an application paper about inferring drawing programs from images; rather, it proposes a general-purpose method for program synthesis example selection. As such, it ought to be evaluated on other types of problems to demonstrate this generality. Nothing about the proposed method (e.g. the neural net setup) is specific to images, so this seems quite readily doable.\n\nOverall: I like the idea this paper proposes, but I have some misgivings about accepting it in its current state.\n\n\n\n\nWhat follows are comments on specific parts of the paper:\n\n\nIn a couple of places early in the paper, you mention that the neural net computes “the probability” of examples. The probability of what? This was totally unclear until fairly deep into Section 3.\n - Page 2: “the neural network computes the probability for other examples not in the subset”\n - Page 3: “the probability of all the examples conditioned on…”\n\nOn a related note, I don’t like the term “Selection Probability” for the quantity it describes. This quantity is ‘the probability of an input being assigned the correct output.’ That happens to be (as you’ve proven) a good measure by which to select examples for the synthesizer. The first property (correctness) is a more essential property of this quantity, rather than the second (appropriateness as an example selection measure).\n\nPage 5: “Figure blah shows our neural network architecture” - missing reference to Figure 3.\n\nPage 5: “note that we do not suggest a specific neural network architecture for the middle layers, one should select whichever architecture that is appropriate for the domain at hand” - such as? What are some architectures that might be appropriate for different domains? What architecture did you use in your experiments?\n\nThe description of the neural net in Section 3.3 (bottom of page 5) is hard to follow on first read-through. It would be better to lead with some high-level intuition about what the network is supposed to do before diving into the details of how it’s set up. The first sentence on page 6 gives this intuition; this should come much earlier.\n\nPage 5: “a feed-forward auto-encoder with N input neurons…” Previously, N was defined as the size of the input domain. Does this mean that the network can only be trained when a complete set of input-output examples is available (i.e. outputs for all possible inputs in the domain)? Or is it fine to have an incomplete example set?\n\n', 'This paper presents a method for choosing a subset of examples on which to run a constraint solver\nin order to solve program synthesis problems. This problem is basically active learning for\nprogramming by example, but the considerations are slightly different than in standard active\nlearning. The assumption here is that labels (aka outputs) are easily available for all possible\ninputs, but we don\'t want to give a constraint solver all the input-output examples, because it will\nslow down the solver\'s execution.\n\nThe main baseline technique CEGIS (counterexample-guided inductive synthesis) addresses this problem\nby starting with a small set of examples, solving a constraint problem to get a hypothesis program,\nthen looking for ""counterexamples"" where the hypothesis program is incorrect.\n\nThis paper instead proposes to learn a surrogate function for choosing which examples to select. The\npaper isn\'t presented in exactly these terms, but the idea is to consider a uniform distribution\nover programs and a zero-one likelihood for input-output examples (so observations of I/O examples\njust eliminate inconsistent programs). We can then compute a posterior distribution over programs\nand form a predictive distribution over the output for all the remaining possible inputs. The paper\nsuggests always adding the I/O example that is least likely under this predictive distribution\n(i.e., the one that is most ""surprising"").\n\nForming the predictive distribution explicitly is intractable, so the paper suggests training a\nneural net to map from a subset of inputs to the predictive distribution over outputs.  Results show\nthat the approach is a bit faster than CEGIS in a synthetic drawing domain.\n\nThe paper starts off strong. There is a start at an interesting idea here, and I appreciate the\nthorough treatment of the background, including CEGIS and submodularity as a motivation for doing\ngreedy active learning, although I\'d also appreciate a discussion of relationships between this approach \nand what is done in the active learning literature.Once getting into the details of the proposed approach, \nthe quality takes a downturn, unfortunately. \n\nMain issues:\n- It\'s not generally scalable to build a neural network whose size scales with the number\nof possible inputs. I can\'t see how this approach would be tractable in more standard program\nsynthesis domains where inputs might be lists of arrays or strings, for example.  It seems that this\napproach only works due to the peculiarities of the formulation of the only task that is considered,\nin which the program maps a pixel location in 32x32 images to a binary value.\n\n- It\'s odd to write ""we do not suggest a specific neural network architecture for the\nmiddle layers, one should seelect whichever architecture that is appropriate for the domain at\nhand."" Not only is it impossible to reproduce a paper without any architectural details, but the\nresult is then that Fig 3 essentially says inputs -> ""magic"" -> outputs. Given that I don\'t even\nthink the representation of inputs and outputs is practical in general, I don\'t see what the \ncontribution is here.\n\n- This paper is poor in the reproducibility category. The architecture is never described,\nit is light on details of the training objective, it\'s not entirely clear what the DSL used in the\nexperiments is (is Figure 1 the DSL used in experiments), and it\'s not totally clear how the random\nimages were generated (I assume values for the holes in Figure 1 were sampled from some\ndistribution, and then the program was executed to generate the data?).\n\n- Experiments are only presented in one domain, and it has some peculiarities relative to \nmore standard program synthesis tasks (e.g., it\'s tractable to enumerate all possible inputs).  It\'d\nbe stronger if the approach could also be demonstrated in another domain.\n\n- Technical point: it\'s not clear to me that the training procedure as described is consistent\nwith the desired objective in sec 3.3. Question for the authors: in the limit of infinite training\ndata and model capacity, will the neural network training lead to a model that will reproduce the\nprobabilities in 3.3?\n\nTypos:\n- The paper needs a cleanup pass for grammar, typos, and remnants like ""Figure blah shows our \nneural network architecture"" on page 5.\n\nOverall: There\'s the start of an interesting idea here, but I don\'t think the quality is high enough\nto warrant publication at this time.\n']","[-70, 20, -60]","[20, 70, 20]","[""The sentiment score is -70 because the reviewer expresses significant concerns about the paper's experimental section, methodology, and overall quality. They state that the paper 'cannot be accepted in its current form' and point out several missed opportunities and weaknesses. However, they do acknowledge that the proposed approach is 'interesting', preventing the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I feel that' and 'it is unclear to me' rather than making blunt accusations. They also offer constructive suggestions for improvement. However, the overall negative feedback and the directness of some statements (e.g., 'Overall the paper appears rushed') prevent the score from being higher."", ""Sentiment score (20): The review starts positively, praising the paper's topic as 'welcome' and the idea as 'good'. The reviewer also compliments the clear writing and rigorous specifications. However, the reviewer expresses 'serious questions/concerns' and 'misgivings about accepting it in its current state', which significantly tempers the initial positivity. The overall tone is cautiously positive but with substantial reservations.\n\nPoliteness score (70): The reviewer maintains a professional and respectful tone throughout. They use phrases like 'I like the idea' and 'the paper is clearly-written', showing appreciation for the authors' work. Even when expressing concerns, the language remains constructive and non-confrontational, using phrases like 'I do have some serious questions/concerns' rather than outright criticism. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback. The high level of detail in the feedback also shows respect for the authors' work."", ""The sentiment score is -60 because the review starts with some positive aspects but ultimately concludes that the paper is not of high enough quality for publication. The reviewer mentions 'The paper starts off strong' and acknowledges 'the start of an interesting idea,' but then lists several major issues and concludes with 'I don't think the quality is high enough to warrant publication at this time.' This indicates a predominantly negative sentiment, though not entirely negative due to the initial positive remarks. The politeness score is 20 because the reviewer uses generally polite language, acknowledging positives and using phrases like 'I appreciate' and 'It'd be stronger if.' However, some direct criticisms like 'This paper is poor in the reproducibility category' and the mention of typos and grammar issues slightly reduce the politeness score. The reviewer maintains a professional tone throughout, avoiding personal attacks or overly harsh language.""]"
"['This paper describes techniques for training semantic segmentation networks. There are two key ideas:\n\n- Attach a pixel-level GAN loss to the output semantic segmentation map. That is, add a discriminator network that decides whether each pixel in the label map belongs to a real label map or not. Of course, this loss alone is unaware of the input image and would drive the network to produce plausible label maps that have no relation to the input image. An additional cross-entropy loss (the standard semantic segmentation loss) is used to tie the network to the input and the ground-truth label map, when available.\n\n- Additional unlabeled data is utilized by using a trained semantic segmentation network to produce a label map with associated confidences; high-confidence pixels are used as ground-truth labels and are fed back to the network as training data.\n\nThe paper is fine and the work is competently done, but the experimental results never quite come together. The technical development isn’t surprising and doesn’t have much to teach researchers working in the area. Given that the technical novelty is rather light and the experimental benefits are not quite there, I cannot recommend the paper for publication in a first-tier conference.\n\nSome more detailed comments:\n\n1. The GAN and the semi-supervised training scheme appear to be largely independent. The GAN can be applied without any unlabeled data, for example. The paper generally appears to present two largely independent ideas. This is fine, except they don’t convincingly pan out in experiments.\n\n2. The biggest issue is that the experimental results do not convincingly indicate that the presented ideas are useful.\n2a. In the “Full” condition, the presented approach does not come close to the performance of the DeepLab baseline, even though the DeepLab network is used in the presented approach. Perhaps the authors have taken out some components of the DeepLab scheme for these experiments, such as multi-scale processing, but the question then is “Why?”. These components are not illegal, they are not cheating, they are not overly complex and are widely used. If the authors cannot demonstrate an improvement with these components, their ideas are unlikely to be adopted in state-of-the-art semantic systems, which do use these components and are doing fine.\n2b. In the 1/8, 1/4, and 1/2 conditions, the performance of the baselines is not quoted. This is wrong. Since the authors are evaluating on the validation sets, there is no reason not to train the baselines on the same amount of labeled data (1/8, 1/4, 1/2) and report the results. The training scripts are widely available and such training of baselines for controlled experiments is commonly done in the literature. The reviewer is left to suspect, with no evidence given to the contrary, that the presented approach does not outperform the DeepLab baseline even in the reduced-data conditions.\n\nA somewhat unflattering view of the work would be that this is another example of throwing a GAN at everything to see if it sticks. In this case, the experiments do not indicate that it did.', 'This paper proposed an approach for semi-supervised semantic segmentation based on adversarial training. Built upon a popular segmentation network, the paper integrated adversarial loss to incorporate unlabeled examples in training. The outputs from the discriminator are interpreted as indicators for the reliability of label prediction, and used to filter-out non-reliable predictions as augmented training data from unlabeled images.  The proposed method achieved consistent improvement over existing state-of-the-art on two challenging segmentation datasets.\n\nAlthough the motivation is reasonable and the results are impressive, there are some parts that need more clarification/discussion as described below.\n\n1) Robustness of discriminator output:\nThe main contribution of the proposed model is exploiting the outputs from the discriminator as the confidence score maps of the predicted segmentation labels. However, the outputs from the discriminator indicate whether its inputs are from ground-truth labels or model predictions, and may not be directly related to ‘correctness’ of the label prediction. For instance, it may prefer per-pixel score vectors closed to one-hot encoded vectors. More thorough analysis/discussions are required to show how outputs from discriminator are correlated with the correctness of label prediction.     \n\n2) Design of discriminator\nI wonder if conditional discriminator fits better for the task. i.e. D(X,P) instead of D(P). It may prevent the model generating label prediction P non-relevant to input X by adversarial training, and makes the score prediction from the discriminator more meaningful. Some ablation study or discussions would be helpful.\n\n3) Presentations\nThere are several abused notations; notations for the ground-truth label P and the prediction from the generator S(X) should be clearly separated in Eq. (1) and (4). Also, it would better to find a better notation for the outputs from D instead of D^(*,0) and D^(*,1).  \nTraining details in semi-supervised learning would be helpful. For instance, the proposed semi-supervised learning strategy based on Eq. (5) may be suffered by noise outputs from the discriminator in early training stages. I wonder how authors resolved the issues (e.g. training the generator and discriminator are with the labeled example first and extending it to training with unlabeled data.) \n', 'The paper presents an alternative adversarial loss function for image segmentation, and an additional loss for unlabeled images.\n\n+ well written\n+ good evaluation\n+ good performance compared to prior state of art\n- technical novelty\n- semi-supervised loss does not yield significant improvement\n- missing citations and comparisons\n\nThe paper is well written, structured, and easy to read.\nThe experimental section is extensive, and shows a significant improvement over prior state of the art in semi-supervised learning.\nUnfortunately, it is unclear what exactly lead to this performance increase. Is it a better baseline model? Is the algorithm tuned better, or is there something fundamentally different compared to prior work (e.g. Luc 2016).\n\nFinally, it would help if the authors could highlight their technical difference compared to prior work. The presented adversarial loss is similar to Luc 2016 and ""Image-to-Image Translation with Conditional Adversarial Networks, Isola etal 2017"". What is different, and why is it important?\nThe semi-supervised loss is similar to Pathak 2015a, it would help to highlight the difference, and show experimentally why it matters.\n\nIn summary, the authors should highlight the difference to prior work, and show why the proposed changes matter.']","[-60, 20, 20]","[20, 60, 60]","[""The sentiment score is -60 because the reviewer expresses significant criticism and does not recommend the paper for publication. They state that the 'experimental results never quite come together', the 'technical novelty is rather light', and the 'experimental benefits are not quite there'. However, it's not entirely negative as they acknowledge the work is 'competently done'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'The paper is fine' and provide detailed, constructive feedback. However, some phrases like 'A somewhat unflattering view of the work' slightly reduce the politeness score. Overall, the review is critical but expressed in a relatively polite and professional manner."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's reasonable motivation and impressive results, but also points out several areas needing clarification or improvement. The overall tone is constructive rather than critical. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, employing phrases like 'I wonder' and 'it would be helpful' rather than making demands. The reviewer also balances positive comments with constructive criticism, maintaining a professional and courteous tone. The review provides specific, actionable feedback without being harsh or dismissive, which contributes to its politeness."", ""The sentiment score is slightly positive (20) because the review starts with positive points about the paper being well-written, having good evaluation, and showing good performance. However, it also mentions several criticisms, such as lack of technical novelty and missing citations, which balance out the positives. The overall tone suggests the reviewer sees merit in the work but has significant reservations.\n\nThe politeness score is moderately high (60) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. The reviewer offers constructive suggestions for improvement rather than harsh criticism. Phrases like 'it would help if' and 'the authors should' are polite ways of suggesting changes. The review maintains a professional tone without using overly formal or informal language.""]"
"[""The paper describes a method for generating so called ground truth adversarial examples: adversaries that have minimal (L1 or L_inf) distance to the training example used to generate them. The technique uses the recently developed reluplex, which can be used to verify certian properties of deep neural networks that use ReLU activations. The authors show how the L1 distance can be formulated using a ReLU and therefore extend the reluplex also work with L1 distances. The experiments on MNIST suggest that the C&W attack produces close to optimal adversarial examples, although it is not clear if these findings would transfer to larger more complex networks. The evaluation also suggests that training with iterative adversarial examples does not overfit and does indeed harden the network to attacks in many cases.\n\nIn general, this is a nice idea, but it seems like the inherent computational cost will limit the applicability of this approach to small networks and datasets for the time being. Incidentally, it would have been useful if the authors provided indicative information on the computational cost (e.g. in the form of time on a standard GPU) for generating these ground truths and carrying out experiments.\n\nThe experiments are quite small scale, which I expect is due to the computational cost of generating the adversarial examples. It is difficult to say how far the findings can be generalized from MNIST to more realistic situations. Tests on another dataset would have been welcomed.\n\nAlso, while interesting, are adversarial examples that have minimal L_p distance from training examples really that useful in practice? Of course, it's nice that we can find these, but it could be argued that L_p norms are not a good way of judging the similarity of an adversarial example to a true example. I think it would be more useful to investigate attacks that are perceptually insignificant, or attacks that operate in the physical world, as these are more likely to be a concern for real world systems. \n\nIn summary, while I think the paper is interesting, I suspect that the applicability of this technique is possibly limited at present, and I'm unsure how much we can really read into the findings of the paper when the experiments are based on MNIST alone.\n"", 'The authors propose to employ provably minimal-distance examples as a tool to evaluate the robustness of a trained network. This is demonstrated on a small-scale network using the MNIST data set.\n\nFirst of all, I find it striking that a trained network with 97% accuracy (as claimed by the authors) seems extremely brittle -- considering the fact that all the adversarial examples in Figure 1 are hardly borderline examples at all, at least to my eyes. This does reinforce the (well-known?) weakness of neural networks in general. I therefore find the authors\' statement on page 3 disturbing: ""... they are trained over a small set of inputs, and can then perform well, in general, on previously-unseen inputs"" -- which seems false (with high probability over all possible worlds).\n\nSecondly, the term ""ground truth"" example seems very misleading to me. Perhaps ""closest misclassified examples""?\n\nFinally, while the idea of ""closest misclassified examples"" seems interesting, I am not convinced that they are the right way to go when it comes to both building and evaluating robustness. All such examples shown in the paper are indeed within-class examples that are misclassified. But we could equally consider another extreme, where the trained network is ""over-regularized"" in the sense that the closest misclassified examples are indeed from another class, and therefore ""correctly"" misclassified. Adding these as adversarial examples could seriously degrade the accuracy.\n\nAlso, for building robustness, one could argue that adding misclassified examples that are ""furthest"" (i.e. closest to the true decision boundary) is a much more efficient training approach, since a few of these can possibly subsume a large number of close examples.\n\n', 'Summary: The paper proposes a method to compute adversarial examples with minimum distance to the original inputs, and to use the method to do two things: Show how well heuristic methods do in finding ""optimal/minimal"" adversarial examples (how close the come to the minimal change that flips the label) and to assess how a method that is designed to make the model more robust to adversarial examples actually works.\n\nPros:\n\nI like the idea and the proposed applications. It is certainly highly relevant, both in terms of assessing models for critical use cases as well as a tool to better understand the phenomenon.\n\nSome of the suggested insights in the analysis of defense techniques are interesting.\n\nCons:\n\nThe is not much technical novelty. The method boils down to applying Reluplex (Katz et al. 2017b) in a binary search (although I acknowledge the extension to L1 as distance metric).\n\nThe practical application of the method is very limited since the search is very slow and is only feasible at all for relatively small models. State-of-the-art practical models that achieve accuracy rates that make them interesting for deployment in potentially safety critical applications are out of reach for this analysis. The network analysed here does not reach the state-of-the-art on MNIST from almost two decades ago. The analysis also has to be done for each sample. The long runtime does not permit to analyse large amounts of input samples, which makes the analysis in terms of the increase in robustness rather weak. The statement can only be made for the very limited set of tested samples.\n\nIt is also unclear whether it is possible to include distance metrics that capture more sophisticated attacks that fool network even under various transformations of the input.\nThe paper does not consider the more recent and highly relevant Moosavi-Dezfooli et al. “Universal Adversarial Perturbations” CVPR 2017.\n\nThe distance metrics that are considered are only L_inf and L1, whereas it would be interesting to see more relevant “perceptual losses” such as those used in style transfer and domain adaptation with GANs.\n\nMinor details:\n* I would consider calling them “minimal adversarial samples” instead of “ground-truth”.\n* I don’t know if the notation in the Equation in the paragraph describing Carlini & Wagner comes from the original paper, but the inner max would be easier to read as \\max_{i \\neq t} \\{Z(x’)_i \\}\n* Page 3 “Neural network verification”: I dont agree with the statement that neural networks commonly are trained on “a small set of inputs”.\n* Algorithm 1 is essentially only a description of binary search, which should not be necessary.\n* What is the timeout for the computation, mentioned in Sec 4?\n* Page 7, second paragraph: I wouldn’t say the observation is in line with Carlini & Wagner, because they take a random step, not necessarily one in the direction of the optimum? That’s also the conclusion two paragraphs below, no?\n* I don’t fully agree with the conclusion that the defense of Madry does not overfit to the specific method of creating adversarial examples. Those were not created with the CW attack, but are related because CW was used to initialize the search.\n\n']","[-20, -50, -20]","[50, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting' and 'a nice idea', they express several concerns about its limitations and applicability. The reviewer questions the generalizability of the findings, the usefulness of the approach in practice, and the small scale of the experiments. The overall tone suggests that the reviewer sees potential in the work but has significant reservations.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'nice idea' and 'interesting' to acknowledge the paper's merits. Even when expressing criticisms, the language is constructive and not personally directed at the authors. The reviewer offers suggestions for improvement, such as providing computational cost information and testing on another dataset, which is a polite way of pointing out shortcomings."", ""The sentiment score is -50 because the reviewer expresses several criticisms and concerns about the paper. They find the network's brittleness 'striking,' describe a statement by the authors as 'disturbing,' and are 'not convinced' by the proposed approach. However, they do acknowledge that the idea is 'interesting,' which prevents the score from being more negative. The politeness score is 20 because while the reviewer is direct in their criticisms, they use relatively polite language such as 'I find it striking' and 'I am not convinced' rather than more aggressive phrasing. They also offer constructive suggestions for improvement, which is a polite approach to criticism. The language is professional and academic throughout, without any rudeness, but also without overtly polite expressions."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('I like the idea and the proposed applications', 'Some of the suggested insights... are interesting'), they raise several significant concerns about the paper's novelty, practical applicability, and limitations. The cons outweigh the pros in the review.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I like the idea' and 'I acknowledge the extension', showing appreciation for aspects of the work. Even when criticizing, they use neutral language like 'It is unclear whether' and 'I don't fully agree' rather than harsh or dismissive statements. The reviewer also offers constructive suggestions for improvement, which is a polite approach to criticism.""]"
"['The paper proposes an architecture for efficient deep lifelong learning. The key idea is to use recollection generator (autoencoder) to remember the previously processed data in a compact representation. Then when training a reasoning model, recollections generated from the recollection generator are used with real-world examples as input data. Using the recollection, it can avoid forgetting previous data. In the experiments, it has been shown that the proposed approach is efficient for transfer knowledge with small data compared to random sampling approach.\n\nIt is an interesting idea to remember previous examples using the compact representation from autoencoder and use it for transfer learning. However, I think the paper would be improved if the following points are clarified.\n\n1. It seems that reconstructed data from autoencoder does not contain target values. It is not clear to me how the reasoning model can use the reconstructed data (recollections) for supervised learning tasks. \n\n2. It seems that the proposed framework can be better presented as a method for data compression for deep learning. Ideally, for lifelong learning, the reasoning model should not forget previously learned kwnoledge embeded in their weights. \nHowever, under the current architecture, it seems that the reasoning model does not have such mechanisms.\n\n3. For lifelong learning, it would be interesting to test if the same reasoning model can deal with increasing number of tasks from different datasets using the recollection mechanisms.\n\n \n\n\n\n', 'This paper presents an approach to lifelong learning with episodic experience storage under resource constraints. The key idea of the approach is to store the latent code obtained from a categorical Variational Autoencoder as opposed to the input example itself. When a new task is learnt, catastrophic forgetting is avoided by randomly sampling stored codes corresponding to past experience and adding the corresponding reconstruction to a batch of data from a new problem. The authors show that explicitly storing data provides better results than random sampling from the generative model. Furthermore, the method is compared to other techniques relying on episodic memory and as expected, achieves better results given a fixed effective buffer size due to being able to store more experience.\n\nWhile the core idea of this paper is reasonable, it provides little insight into how episodic experience storage compares to related methods as an approach to lifelong learning. While the authors compare their method to other techniques based on experience replay, I feel that a comparison to other techniques is important. A natural choice would be a model which introduces task-specific parameters for each problem (e.g.  (Li & Hoiem, 2016) or (Rusu et al., 2016)).\n\nA major concern is the fact that the VAE with categorical latents itself suffers from catastrophic forgetting. While the authors propose to ""freeze decoder parameters right before each incoming experience and train multiple gradient descent iterations over randomly selected recollection batches before moving on to the next experience"", this makes the approach both less straight-forward to apply and more computationally expensive. \n\nMoreover, the authors only evaluate the approach on simple image recognition tasks (MNIST, CIFAR-100, Omniglot). I feel that an experiment in Reinforcement Learning  (e.g. as proposed in (Rusu et al., 2016)) would provide more insight into how the approach behaves in more challenging settings. In particular, it is not clear whether experience replay may lead to negative transfer when subsequent tasks are more diverse.\n\nFinally, the manuscript lacks clarity. As another reviewer noted, detailed sections of weakly related motivations fail to strengthen the reader\'s understanding. As a minor point, the manuscript contains several grammar and spelling mistakes.', 'This paper addresses lifelong learning setting under resource constraints, i.e. how to efficiently manage the storage and how to generalise well with a relatively small diversity of prior experiences. The authors investigate how to avoid storing a lot of original training data points while avoiding catastrophic forgetting at the same time.\nThe authors propose a complex neural network architecture that has several components. One of the components is a variational autoencoder with discrete latent variables, where the recently proposed Gumbel-softmax distribution is used to efficiently draw samples from a categorical distribution (Jang et al ICLR 2017). Discrete variables are categorical latent variables using 1-hot encoding of the class variables. In fact, in the manuscript, the authors describe one-hot encoding of c classes as l-dimensional representation. Why is it not c-dimentional? Also the class probabilities p_i are not defined in (7). \nThis design choice is reasonable, as autoencoder with categorical latent variables can achieve more storage compression of input observations in comparison with autoencoders with continuos variables. \nAnother component of the proposed model is a recollection buffer/generator, a generative module (alongside the main model) which produces pseudo-experiences. These self generated pseudo experiences are sampled from the buffer and are combined with available real samples during training to avoid catastrophic forgetting of prior experiences. This module is inspired by episodic training proposed by Lopez-Paz and Ranzato in ICLR2017 for continual learning. In fact, a recollection buffer for MNIST benchmark has 50K codes to store. How fast would it grow with more tasks/training data? Is it suitable for lifelong learning? \n\nMy main concern with this paper is that it is not easy to grasp the gist of it. The paper is 11 pages long and often has sections with weakly related motivations described in details (essentially it would be good to cut the first 6 pages into half and concentrate on the relevant aspects only). It is easy to get lost in unimportant details, where as important details on model components are not very clear and not structured. Second concern is limited novelty (from what I understood). \n\n\n']","[20, -30, -30]","[60, 20, 50]","[""The sentiment score is 20 (slightly positive) because the reviewer describes the paper's idea as 'interesting' and acknowledges its efficiency in transfer knowledge. However, they also point out several areas for improvement, which tempers the positive sentiment. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, such as 'I think the paper would be improved if...' and 'It would be interesting to...'. They offer constructive criticism without harsh language. The reviewer maintains a professional tone while providing specific recommendations for improvement, which is typical of polite academic discourse."", ""The sentiment score is -30 because while the reviewer acknowledges the paper's 'reasonable' core idea, they express several major concerns and criticisms. These include the lack of comparison to other lifelong learning methods, issues with the VAE suffering from catastrophic forgetting, limited evaluation on simple tasks, and overall lack of clarity in the manuscript. However, the tone is not entirely negative, as the reviewer does note some positive aspects. The politeness score is 20 because the reviewer uses generally respectful language, avoiding harsh criticism and using phrases like 'I feel that' to soften their critiques. They also acknowledge the paper's strengths before diving into concerns. However, the review is not overly polite, maintaining a professional and direct tone throughout."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'This design choice is reasonable'), they express significant concerns about the paper's clarity, structure, and novelty. The reviewer states that 'it is not easy to grasp the gist of it' and mentions 'limited novelty' as a main concern, indicating an overall negative sentiment. However, the criticism is not entirely harsh, hence the score is not extremely negative.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns (e.g., 'My main concern with this paper is...') rather than using harsh or dismissive language. The reviewer also acknowledges positive aspects of the work and provides constructive feedback. However, the score is not extremely high as the review doesn't go out of its way to be exceptionally polite or complimentary.""]"
"['Paper is well written and clearly explained. The paper is a experimental paper as it has more content on the experimentation and less content on problem definition and formulation. The experimental section is strong and it has evaluated across different datasets and various scenarios. However, I feel the contribution of the paper toward the topic is incremental and not significant enough to be accepted in this venue. It only considers a slight modification into the loss function by adding a trace norm regularization.', 'The problem considered in the paper is of compressing large networks (GRUs) for faster inference at test time. \n\nThe proposed algorithm uses a two step approach: 1)  use trace norm regularization (expressed in variational form) on dense parameter matrices at training time without constraining the number of parameters, b) initializing from the SVD of parameters trained in stage 1, learn a new network with reduced number of parameters.\n\nThe experiments on WSJ dataset are promising towards achieving a trade-off between number of parameters and accuracy. \n\nI have the following questions regarding the experiments:\n1. Could the authors confirm that the reported CERS are on validation/test dataset and not on train/dev data? It is not explicitly stated. I hope it is indeed the former, else I have a major concern with the efficacy of the algorithm as ultimately, we care about the test performance of the compressed models in comparison to uncompressed model. \n\n2. In B.1 the authors use an increasing number units in the hidden layers of the GRUs as opposed to a fixed size like in Deep Speech 2, an obvious baseline that is missing from the  experiments is the comparison with *exact* same GRU (with  768, 1024, 1280, 1536 hidden units) *without any compression*. \n\n3.  What do different points in Fig 3 and 4 represent. What are the values of lamdas that were used to train (the l2 and trace norm regularization) the Stage 1 of models shown in Fig 4. I want to understand what is the difference in the  two types of  behavior of orange points (some of them seem to have good compression while other do not - it the difference arising from initialization or different choice of lambdas in stage 1. \n\nIt is interesting that although L2 regularization does not lead to low \\nu parameters in Stage 1, the compression stage does have comparable performance to that of trace norm minimization. The authors point it out, but a further investigation might be interesting. \n\nWriting:\n1. The GRU model for which the algorithm is proposed is not introduced until the appendix. While it is a standard network, I think the details should still be included in the main text to understand some of the notation referenced in the text like “\\lambda_rec” and “\\lambda_norec”', 'The authors propose a strategy for compressing RNN acoustic models in order to deploy them for embedded applications. The technique consists of first training a model by constraining its trace norm, which allows it to be well-approximated by a truncated SVD in a second fine-tuning stage. Overall, I think this is interesting work, but I have a few concerns which I’ve listed below:\n\n1. Section 4, which describes the experiments of compressing server sized acoustic models for embedded recognition seems a bit “disjoint” from the rest of the paper. I had a number of clarification questions spefically on this section:\n- Am I correct that the results in this section do not use the trace-norm regularization at all? It would strengthen the paper significantly if the experiments presented on WSJ in the first section were also conducted on the “internal” task with more data.\n- How large are the training/test sets used in these experiments (for test sets, number of words, for training sets, amount of data in hours (is this ~10,000hrs), whether any data augmentation such as multi-style training was done, etc.)\n- What are the “tier-1” and “tier-2” models in this section? It would also aid readability if the various models were described more clearly in this section, with an emphasis on structure, output targets, what LMs are used, how are the LMs pruned for the embedded-size models, etc. Also, particularly given that the focus is on embedded speech recognition, of which the acoustic model is one part, I would like a few more details on how decoding was done, etc.\n- The details in appendix B are interesting, and I think they should really be a part of the main paper. That being said, the results in Section B.5, as the authors mention, are somewhat preliminary, and I think the paper would be much stronger if the authors can re-run these experiments were models are trained to convergence.\n- The paper focuses fairly heavily on speech recognition tasks, and I wonder if it would be more suited to a conference on speech recognition. \n\n2. Could the authors comment on the relative training time of the models with the trace-norm regularizer, L2-regularizer and the unconstrained model in terms of convergence time.\n\n3. Clarification question: For the WSJ experiments was the model decoded without an LM? If no LM was used, then the choice of reporting results in terms of only CER is reasonable, but I think it would be good to also report WERs on the WSJ set in either case.\n\n4. Could the authors indicate the range of values of \\lambda_{rec} and \\lambda_{nonrec} that were examined in the work? Also, on a related note, in Figure 2, does each point correspond to a specific choice of these regularization parameters?\n\n5. Figure 4: For the models in Figure 4, it would be useful to indicate the starting CER of the stage-1 model before stage-2 training to get a sense of how stage-2 training impacts performance.\n\n6. Although the results on the WSJ set are interesting, I would be curious if the same trends and conclusions can be drawn from a larger dataset -- e.g., the internal dataset that results are reported on later in the paper, or on a set like Switchboard. I think these experiments would strengthen the paper.\n\n7. The experiments in Section 3.2.3 were interesting, since they demonstrate that the model can be warm-started from a model that hasn’t fully converged. Could the authors also indicate the CER of the model used for initialization in addition to the final CER after stage-2 training in Figure 5.\n\n8. In Section 4, the authors mention that quantization could be used to compress models further although this is usually degrades WER by 2--4% relative. I think the authors should consider citing previous works which have examined quantization for embedded speech recognition [1], [2]. In particular, note that [2] describes a technique for training with quantized forward passes which results in models that have smaller performance degradation relative to quantization after training.\nReferences:\n[1] Vincent Vanhoucke, Andrew Senior, and Mark Mao, “Improving the speed of neural networks on cpus,” in Deep Learning and Unsupervised Feature Learning Workshop, NIPS, 2011.\n[2] Raziel Alvarez, Rohit Prabhavalkar, Anton Bakhtin, “On the efficient representation and execution of deep acoustic models,” Proc. of Interspeech, pp. 2746 -- 2750, 2016.\n\n9. Minor comment: The authors use the term “warmstarting” to refer to the process of training NNs by initializing from a previous model. It would be good to clarify this in the text.']","[0, 50, 20]","[50, 80, 80]","[""The sentiment score is 0 (neutral) because the review contains both positive and negative aspects. The reviewer praises the paper's writing, clarity, and strong experimental section, but also criticizes its contribution as incremental and not significant enough for the venue. These balanced comments result in a neutral overall sentiment. The politeness score is 50 (somewhat polite) because the language used is professional and constructive. The reviewer acknowledges the paper's strengths before presenting criticisms, and uses phrases like 'I feel' to soften the negative feedback. However, the review doesn't go out of its way to be exceptionally polite, maintaining a neutral, professional tone throughout."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the problem as interesting and the experiments as promising. However, they also raise several questions and concerns, indicating a balanced view. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases their concerns as questions or suggestions, and acknowledges positive aspects of the work. They use phrases like 'Could the authors confirm...' and 'It is interesting that...' which maintain a courteous tone. The reviewer also offers constructive feedback and suggestions for improvement, which is a polite way to address potential issues in the paper."", ""The sentiment score is slightly positive (20) because the reviewer starts by saying 'Overall, I think this is interesting work,' indicating a generally positive view. However, they follow this with 'but I have a few concerns,' which tempers the positivity. The review then lists several detailed questions and suggestions for improvement, which shows engagement with the work but also indicates areas needing clarification or enhancement. The politeness score is high (80) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions (e.g., 'Could the authors comment on...', 'I think it would be good to...'), and acknowledges interesting aspects of the work. The reviewer also provides constructive feedback and additional references to help improve the paper, which is a polite and helpful approach.""]"
"['This paper proposes a ranking-based similarity metric for distributional semantic models. The main idea is to learn ""baseline"" word embeddings, retrofitting those and applying localized centering, to then calculate similarity using a measure called ""Ranking-based Exponential Similarity Measure"" (RESM), which is based on the recently proposed APSyn measure.\n\nI think the work has several important issues:\n\n1. The work is very light on references. There is a lot of previous work on evaluating similarity in word embeddings (e.g. Hill et al, a lot of the papers in RepEval workshops, etc.); specialization for similarity of word embeddings (e.g. Kiela et al., Mrksic et al., and many others); multi-sense embeddings (e.g. from Navigli\'s group); and the hubness problem (e.g. Dinu et al.). For the localized centering approach, Hara et al.\'s introduced that method. None of this work is cited, which I find inexcusable.\u2028\n\n2. The evaluation is limited, in that the standard evaluations (e.g. SimLex would be a good one to add, as well as many others, please refer to the literature) are not used and there is no comparison to previous work. The results are also presented in a confusing way, with the current state of the art results separate from the main results of the paper. It is unclear what exactly helps, in which case, and why.\u2028\n\n3. There are technical issues with what is presented, with some seemingly factual errors. For example, ""In this case we could apply the inversion, however it is much more convinient [sic] to take the negative of distance. Number 1 in the equation stands for the normalizing, hence the similarity is defined as follows"" - the 1 does not stand for normalizing, that is the way to invert the cosine distance (put differently, cosine distance is 1-cosine similarity, which is a metric in Euclidean space due to the properties of the dot product). Another example, ""are obtained using the GloVe vector, not using PPMI"" - there are close relationships between what GloVe learns and PPMI, which the authors seem unaware of (see e.g. the GloVe paper and Omer Levy\'s work).\u2028\n\n4. Then there is the additional question, why should we care? The paper does not really motivate why it is important to score well on these tests: these kinds of tests are often used as ways to measure the quality of word embeddings, but in this case the main contribution is the similarity metric used *on top* of the word embeddings. In other words, what is supposed to be the take-away, and why should we care?\n\nAs such, I do not recommend it for acceptance - it needs significant work before it can be accepted at a conference.\n\nMinor points:\n- Typo in Eq 10\n- Typo on page 6 (/cite instead of \\cite)', ""The paper suggests taking GloVe word vectors, adjust them, and then use a non-Euclidean similarity function between them. The idea is tested on very small data sets (80 and 50 examples, respectively). The proposed techniques are a combination of previously published steps, and the new algorithm fails to reach state-of-the-art on the tiny data sets.\n\nIt isn't clear what the authors are trying to prove, nor whether they have successfully proven what they are trying to prove. Is the point that GloVe is a bad algorithm? That these steps are general? If the latter, then the experimental results are far weaker than what I would find convincing. Why not try on multiple different word embeddings? What happens if you start with random vectors? What happens when you try a bigger data set or a more complex problem?"", 'I hate to say that the current version of this paper is not ready, as it is poorly written. The authors present some observations of the weaknesses of the existing vector space models and list a 6-step approach for refining existing word vectors (GloVe in this work), and test the refined vectors on 80 TOEFL questions and 50 ESL questions. In addition to the incoherent presentation, the proposed method lacks proper justification. Given the small size of the datasets, it is also unclear how generalizable the approach is.\n\nPros:\n  1. Experimental study on retrofitting existing word vectors for ESL and TOEFL lexical similarity datasets\n\nCons:\x0b  1. The paper is poorly written and the proposed methods are not well justified.\n  2. Results on tiny datasets\n']","[-80, -60, -70]","[-20, -20, -20]","[""The sentiment score is -80 because the reviewer expresses several major concerns with the paper and does not recommend it for acceptance, stating it 'needs significant work'. They list 4 substantial issues and use strong negative language like 'inexcusable' and 'factual errors'. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism ('I find inexcusable', 'seemingly factual errors') and questioning the paper's relevance ('why should we care?') without much softening language. The reviewer does offer some constructive feedback and uses 'I think' to frame opinions, which prevents the score from being lower."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer criticizes the small dataset size, lack of novelty in the proposed techniques, and failure to achieve state-of-the-art results. The reviewer also expresses confusion about the paper's objectives and questions the validity of the experimental approach. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without any positive reinforcement or constructive suggestions. The reviewer uses phrases like 'It isn't clear' and 'far weaker than what I would find convincing,' which come across as somewhat dismissive. The tone is more critical and questioning rather than supportive or encouraging, which contributes to the slightly negative politeness score."", ""The sentiment score is -70 because the review starts with a strongly negative statement ('I hate to say') and continues to criticize the paper as 'poorly written' and 'incoherent'. The reviewer lists more cons than pros and expresses doubt about the generalizability of the approach. The politeness score is -20 because while the language is not overtly rude, it is quite direct and harsh in its criticism. The reviewer does not soften their negative feedback with any positive language or constructive suggestions, which comes across as somewhat impolite in academic discourse. The use of phrases like 'I hate to say' and 'poorly written' contribute to the negative politeness score.""]"
"['This paper is concerned with the mismatch between the input distribution used for training and interpolated input. It extends the discussion on this phenomenon and the correction method proposed by White (2016), and proposes an optimal transport-based approach, which essentially makes use of the trick of change of variables. The discussion of the phenomenon is interesting, and the proposed method seems well motivated and useful. There are a number of errors or inconsistencies in the paper, and the experiments results, compared to those given by SLERP, see rather weak. My big concern about the paper is that it seems to be written in a rush and needs a lot of improvement before being published. Below please see more detailed comments.\n\n- In Introduction, the authors claim that ""This is problematic, since the generator G was trained on a fixed prior and expects to see inputs with statistics consistent with that distribution."" Here the learned generative network might still apply even if the input distribution changes (e.g., see the covariate shift setting); should one claim that the support of the test input distribution may not be contained in the support of the input distribution for training? Is there any previous result supporting this? \n- Moreover, I am wondering whether Sections 2.2 and 2.3 can be simplified or improved--the underlying idea seems intuitive, but some of the statements seem somewhat confusing. For instance, what does equation (6) mean?\n- Note that a parenthesis is missing in line 3 below (4). In (6), the dot should follow the equation.\n- Line 1 of page 7: here it would be nice to make it clear what p_{y|x} means. How did you obtain values of f(x) from this conditional distribution?\n- Theorem 2: here does one assume that F_Y is invertible? (Maybe this is not necessary according to the definition of F_Y^{[-1]}...)\n- Line 4 above Section 4.2: the sentence is not complete.\n- Section 4.2: It seems that Figure 3 appears in the main text earlier than Figure 2. Please pay attention to the organization.\n- Line 3, page 10: ""slightly different, however...""\n- Line 3 below Figure 2: I failed to see ""a slight loss in detain for the SLERP version."" Perhaps the authors could elaborate on it?\n- The paragraph above Figure 3 is not complete.', 'The authors demonstrate experimentally a problem with the way common latent space operations such as linear interpolation are performed for GANs and VAEs. They propose a solution based on matching distributions using optimal transport. Quite heavy machinery to solve a fairly simple problem, but their approach is practical and effective experimentally (though the gain over the simple SLERP heuristic is often marginal). The problem they describe (and so the solution) deserves to be more widely known.\n\nMajor comments:\n\nThe paper is quite verbose, probably unnecessarily so. Firstly, the authors devote over 2 pages to examples that distribution mismatches can arise in synthetic cases (section 2). This point is well made by a single example (e.g. section 2.2) and the interesting part is that this is also an issue in practice (experimental section). Secondly, the authors spend a lot of space on the precise derivation of the optimal transport map for the uniform distribution. The fact that the optimal transport computation decomposes across dimensions for pointwise operations is very relevant, and the matching of CDFs, but I think a lot of the mathematical detail could be relegated to an appendix, especially the detailed derivation of the particular CDFs.\n\nMinor comments:\n\nIt seems worth highlighting that in practice, for the common case of a Gaussian, the proposed method for linear interpolation is just a very simple procedure that might be called ""projected linear interpolation"", where the generated vector is multiplied by a constant. All the optimal transport theory is nice, but it\'s helpful to know that this is simple to apply in practice.\n\nMight I suggest a very simple approach to fixing the distribution mismatch issue? Train with a spherical uniform prior. When interpolating, project the linear interpolation back to the sphere. This matches distribution, and has the attractive property that the entire geodesic between two points lies in a region with typical probability density. This would also work for vicinity sampling.\n\nIn section 1, overfitting concerns seem like a strange way to motivate the desire for smoothness. Overfitting is relatively easy to compensate for, and investigating the latent space is interesting regardless.\n\nWhen discussing sampling from VAEs as opposed to GANs, it would be good to mention that one has to sample from p(x | z) not just p(z).\n\nLots of math typos such as t - 1 should be 1 - t in (2), ""V times a times r"" instead of ""Var"" in (3) and ""s times i times n"" instead of ""sin"", etc, sqrt(1) * 2 instead of sqrt(12), inconsistent bolding of vectors. Also strange use of blackboard bold Z to mean a vector of random variables instead of the integers.\n\nCould cite an existing source for the fact that most mass for a Gaussian is concentrated on a thin shell (section 2.2), e.g. David MacKay Information Theory, Inference and Learning Algorithms.\n\nAt the end of section 2.4, a plot of the final 1D-to-1D optimal transport function (for a few different values of t) for the uniform case would be incredibly helpful.\n\nSection 3 should be a subsection of section 2.\n\nFor both SLERP and the proposed method, there\'s quite a sudden change around the midpoint of the interpolation in Figure 2. It would be interesting to plot more points around the midpoint to see the transition in more detail. (A small inkling that samples from the proposed approach might change fastest qualitatively near the midpoint of the interpolation perhaps maybe be seen in Figure 1, since the angle is changing fastest there??)\n\n', 'Authors note that models may be trained for a certain distribution (e.g. uniform or Gaussian) but then ""used"" by interpolating or jittering known examples, which has a different distribution.  While the authors are clear about the fact that this is a mismatch, I did not find it well-motivated why it was  ""the right thing to do"" to match the training prior, given that the training prior is potentially not at all representative or relevant. The fact that a Gaussian/prior distribution is used in the first place seems like a matter of convenience rather than it being the ""right"" distribution for the problem goals, and that makes it less clear that it\'s important to match this ""convenience"" distribution. The key issue I had throughout is ""what is the real-world problem metric or evaluation criteria and how does this proposal directly help""?\n\nFor example, authors cover the usual story that random Gaussian examples  lie on a thin sphere shell in high-d space, and thus interpolation of those examples will like on a thin shell of slightly less radius.  In contrast, the Uniform distribution on a hypercube [-1,1]^D in D dimensions ""looks"" like a sharp-pointy star with 2^D sharp points and all the mass in those 2^D corners. But the key question is, what are these examples being used for, and what are the trade-offs between interpolation (which tends to be fairly safe) and extrapolation of the given examples?\n\nThis is echoed in the experiments, which I found unsatsifactory for the same key issue: ""What is the criteria for “higher-quality interpolated samples”? in the examples they give, it seems to be the sharpness of the images. Is that realistic/relevant? These are pretty images, but the evaluation criteria is unclear.\n\n\n']","[-20, 60, -50]","[50, 70, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The discussion of the phenomenon is interesting, and the proposed method seems well motivated and useful'), they express significant concerns about the paper's quality ('My big concern about the paper is that it seems to be written in a rush and needs a lot of improvement before being published'). The reviewer also points out numerous errors and inconsistencies, which contributes to the negative sentiment. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, offering constructive criticism and specific suggestions for improvement. They use phrases like 'please see more detailed comments' and 'It would be nice to make it clear', which maintain a polite tone while providing feedback. The reviewer also balances criticism with positive remarks, which is a polite approach to peer review."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the importance of the problem addressed and the effectiveness of the proposed solution, stating that it 'deserves to be more widely known.' However, they also point out that the gain over existing methods is often marginal, which tempers the positivity somewhat. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They use phrases like 'Might I suggest' and 'It seems worth highlighting,' which are polite ways of offering feedback. The reviewer also balances criticism with praise, acknowledging the paper's strengths while pointing out areas for improvement. The use of 'Major comments' and 'Minor comments' helps structure the feedback in a professional manner."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's motivation and evaluation criteria. They use phrases like 'I did not find it well-motivated' and 'I found unsatisfactory', indicating a negative sentiment. However, it's not entirely negative as they acknowledge some clarity in the authors' presentation. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and constructive manner. They use phrases like 'The key issue I had' and 'Authors note that' rather than making personal attacks. The language is direct but maintains a respectful tone throughout, avoiding rudeness while also not being overly polite.""]"
"['This paper performs an analysis of shortcut connections in ResNet-like architectures. The authors hypothesize that the success of shortcut connections comes from the combination of linear and non-linear features at each layer and propose to substitute the identity shortcuts with a convolutional one (without non-linearity). This alternative is referred to as tandem block. Experiments are performed on a variety of image classification tasks such as CIFAR-10, CIFAR-100, SVHN and Fashion MNIST.\n\nThe paper is well structured and easy to follow. The main contribution of the paper is the comparison between identity skip connections and skip connections with one convolutional layer.\n\nMy main concerns are related to the contribution of the paper and experimental pipeline followed to perform the comparison. First, the idea of having convolutional shortcuts was already explored in the ResNet paper (see https://arxiv.org/pdf/1603.05027.pdf). Second, given Figures 3-4-5-6, it would seem that the authors are monitoring the performance on the test set during training. Moreover, results on Table 2 are reported as the ones with “the highest test accuracy achieved with each tandem block”. Could the authors give more details on how the hyperparameters of the architectures/optimization were chosen and provide more information on how the best results were achieved?\n\nIn section 3.5, the authors mention that batchnorm was not useful in their experiments, and was more sensitive to the learning rate value. Do the authors have any explanation/intuition for this behavior?\n\nIn section 4, authors claim that their results are competitive with the best published results for a similar number of parameters. It would be beneficial to add the mentioned best performing models in Table 2 to back this statement. Moreover, it seems that in some cases such as SVHN the differences between all the proposed blocks are too minor to draw any strong conclusions. Could those differences be due to, for example, luck in picking the initialization seed? How many times was each experiment run? If more than once, what was the std?\n\nThe experiments were performed on relatively shallow networks (8 to 26 layers). I wonder how the conclusions drawn scale to much deeper networks (of 100 layers for example) and on larger datasets such as ImageNet.\n\nFigures 3-5 are not referenced nor discussed in the text.\n\nFollowing the design of the tandem blocks proposed in the paper, I wonder why the tandem block B3x3(2,w) was not included.\n\nFinally, it might be interesting to initialize the convolutions in the shortcut connections with the identity, and check what they have leant at the end of the training.\n\nSome typos that the authors might want to fix:\n\n- backpropegation -> backpropagation (Introduction, paragraph 3)\n- dropout is a kind of regularization as well (Introduction, second to last paragraph)\n- nad -> and (Sect 3.1. paragraph 1)\n', 'The paper is well written, has a good structure and is easy to follow. The paper investigates the importance of having the identity skip connections in residual block. The authors hypothesize that changing the identity mapping into a linear function would be beneficial. The main contribution of the paper is the Tandem Block, that is composed of two paths, linear and nonlinear, the outcome of two paths is summed at the end of the block. Similarly, as for residual blocks in ResNets, one can stack together multiple Tandem Blocks. However, this contribution seems to be rather limited. He at. al. (2016) introduces a Tandem Block like structure, very similar to B_(1x1)(2,w), see Fig. 2(e) in He at. al. (2016). Moreover, He et. al (2016) shows in Tab 1 that for a ResNet 101 this tandem like structure performs significantly worse than identity skip connections. This should be properly mentioned, discussed and reflected in the contributions of the paper. \n\nResult section: \nMy main concern is that it seems that the comparison of different Tandem Blocks designs has been performed on test set (e. g. Table 2 displays the highest test accuracies) . Figs 3, 4, 5 and 6 together with Tab. 2 monitors test set. The architectural search together with hyperparameters selection should be performed on validation set. \n\n\nOther issues:\n- Section 1: “… ResNets have overcome the challenging technical obstacles of vanishing/exploding gradients… “. It is clear how ResNet address the issue of vanishing gradients, however, I’m not sure if ResNet can also address the problem of exploding gradients. Can authors provide reference for this statement?\n- Experiments: The authors show that on small size networks Tandem Block outperforms Residual Blocks, since He at. al. (2016) in Tab 1 showed a contrary effect, does it mean that the observations do not scale to higher capacity networks? Could the authors comment on that? ', 'This paper investigates the effect of replacing identity skip connections with trainable convolutional skip connections in ResNet. The authors find that in their experiments, performance improves. Therefore, the power of skip connections is due to their linearity rather than due to the fact that they represent the identity.\n\nOverall, the paper has a clear and simple message and is very readable. The paper contains a good amount of experiments, but in my opinion not quite enough to conclude that identity skip connections are inherently worse. The question is then: how non-trivial is it that tandem networks work? For someone who understands and has worked with ResNet and similar architectures, this is not a surprise. Therefore, the paper is somewhat marginal but, I think, still worth accepting.\n\nWhy did you choose a single learning rate for all architectures and datasets instead of choosing the optimal one for each archtitecture and dataset? Was it a question of computational resources? Using custom step sizes would strenghten your experimental results significantly. In the absence of this, I would still ask that you create an appendix where you specify exactly how hyperparameters were chosen.\n\nOther comments:\n\n- ""and that it’s easier for a layer to learn from a starting point of keeping things the same (the identity map) than from the zero map"" I don\'t understand this comment. Networks without skip connections are not initialized to the zero map but have nonzero, usually Gaussian, weights.\n- in section 2, reason (ii), you seem to imply that it is a good thing if a network behaves as an ensemble of shallower networks. In general, this is a bad thing. Therefore, the fact that ResNet with tandom networks is an ensemble of shallower networks is a reason for why it might perform badly, not well. I would suggest removing reason (ii).\n- in section 3, reason (iii), you state that removing nonlinearities from the skip path can improve performance. However, using tandom blocks instead of identity skip connections does not change the number of nonlinearity layers. Therefore, I do not see how reason (iii) applies to tandem networks.\n- ""The best blocks in each challenge were competitive with the best published results for their numbers of parameters; see Table 2 for the breakdown."" What are the best published results? I do not see them in table 2.']","[-20, -20, 20]","[60, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is well structured and easy to follow'), they express several concerns and criticisms about the paper's contribution, experimental methodology, and conclusions. The reviewer raises questions about the novelty of the work, the experimental process, and the strength of the conclusions drawn.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'Could the authors give more details...', 'It would be beneficial to...', and 'I wonder...' which are polite ways of suggesting improvements or asking for clarification. The reviewer also offers constructive suggestions and even points out typos in a helpful manner. However, the score is not extremely high as the review is still critical in nature, albeit expressed politely."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'good structure'), they express significant concerns about the paper's contribution and methodology. The reviewer points out limitations in the novelty of the work and issues with the experimental design, which outweigh the initial positive comments. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, framing criticisms as 'concerns' and asking for clarification rather than making harsh judgments. They also begin with positive feedback before moving to critiques. The reviewer maintains a professional tone, avoiding personal attacks or overly negative language, while still clearly communicating their concerns about the paper."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's clear message, readability, and good amount of experiments. They suggest the paper is 'worth accepting' despite being 'somewhat marginal'. However, they also express some reservations about the conclusions and experimental design. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions politely (e.g., 'I would still ask that you...'). They maintain a professional tone while providing both positive feedback and areas for improvement. The reviewer's comments are direct but not harsh, and they offer explanations for their concerns, which contributes to the overall polite tone.""]"
"['1) I would like to ask for the clarification regarding the generalization guarantees. The original Entropy-SGD paper shows improved generalization over SGD using uniform stability, however the analysis of the authors rely on an unrealistic assumption regarding the eigenvalues of the Hessian (they are assumed to be away from zero, which is not true at least at local minima of interest). What is the enabling technique in this submission that avoids taking this assumption? (to clarify: the analysis is all-together different in both papers, however this aspect of the analysis is not fully clear to me).\n2) It is unclear to me what are the unrealistic assumptions made in the paper. Please, list them all in one place in the paper and discuss in details.\n', 'Brief summary:\n    Assume any neural net model with weights w. Assume a prior P on the weights. PAC-Bayes risk bound show that for ALL other distributions Q on the weights, the the sample risk (w.r.t to the samples in the data set) and expected risk (w.r.t distribution generating samples) of the random classifier chosen according to Q, averaged over Q, are close by a fudge factor that is KL divergence of P and Q scaled by m^{-1} + some constant.\n\nNow, the authors first show that optimizing the objective of the Entropy SGD algorithm is equivalent to optimizing the empiricial risk term + fudge term over all data dependent priors P and the best Q for that prior. However, PAC-Bayes bound  holds only when P is NOT dependent on the data. So the authors invoke results from differential privacy to show that as long as the prior choosing mechanism in the optimization algorithm is differentially private with respect to data, differentially private priors can be substituted for valid PAC-Bayes bounds rectifying the issue. They show that when entrop SGD is implemented with pure gibbs sampling steps (as in Algorithm 3), the bounds hold.\n\nWeakness that remains is that the gibbs sampling step in Entropy SGD (as in algo 3 in the appendix) is actually approximated by samples from SGLD that converges to this gibbs distribution when run for infinite hops. The authors leave this hole unsolved. But under the very strong sampling assumption, the bound holds. The authors do some experiments with MNIST to demonstrate that their bounds are not trivial. \n\nStrengths:\n  Simple connections between PAC-Bayes bound and entropy SGD objective is the first novelty. Invoking results from differential privacy for fixing the issue of validity of PAC-Bayes bound is the second novelty. Although technically the paper is not very deep, leveraging existing results (with strong assumptions) to show generalization properties of entropy-SGD is good.\n\nWeakness:\n  a) Obvious issue : that analysis assumes the strong gibbs sampling step.\n  b) Experimental results are ok. I see that the bounds computed are non-vacuous. - but can the authors clarify what exactly they seek to justify ? \n c) Typos: \n   Page 4 footnote ""the local entropy should not be <with>.."" - with is missing.\n   Eq 14 typo - r(h) instead of e(h) \n   Definition A.2 in appendix - must have S and S\' in the inequality -both seem S.\n\nd) Most important clarification: The way Thm 5.1, 5.2 and the exact gibbs sampling step connect with each other to produce Thm 6.1 is in Thm B.1. How do multiple calls on the same data sample do not degrade the loss ? Explanation is needed. Because the whole process of optimization in TRAIN with may steps is the final \'data dependent prior choosing mechanism\' that has to be shown to be differentially private. Can the authors argue why the number of iterations of this does not matter at all ?? If I get run this long enough, and if I get several w\'s in the process (like step 8 repeated many times in algorithm 3) I should have more leakage about the data sample S intuitively right ?\n\ne) The paper is unclear in many places. Intro could be better written to highlight the connection at the expression level of PAC-Bayes bound and entropy SGD objective and the subsequent fix using differentially private prior choosing mechanism to make the connection provably correct. Why are all the algorithms in the appendix on which the theorems are claimed in the paper ??\n\nFinal decision: I waver between 6 and 7 actually. However I am willing to upgrade to 7 if the authors can provide sound arguments to my above concerns.', ""This paper connects Entropy-SGD with PAC-Bayes learning. It shows that maximizing the local entropy during the execution of Entropy-SGD essentially minimize a PAC-Bayes bound on the risk of the Gibbs posterior. Despite this connection, Entropy-SGD could lead to dependence between prior and data and thus violate the requirement of PAC-Bayes theorem. The paper then proposes to use a differentially private prior to get a valid PAC-Bayes bound with SGLD. Experiments on MNIST shows such algorithm does generalize better.\n\nLinking Entropy-SGD to PAC-Bayes learning and making use of differential privacy to improve generalization is quite interesting. However, I'm not sure if the ideas and techniques used to solve the problem are novel enough.\nIt would be better if the presentation of the paper is improved. The result in Section 4 can be presented in a theorem, and any related analysis can be put into the proof. Section 5 about previous work on differentially private posterior sampling and stability could follow other preliminaries in Section 2. The figures are a bit hard to read. Adding sub-captions and re-scaling y-axis might help.\n""]","[-20, 50, 50]","[50, 70, 60]","[""The sentiment score is slightly negative (-20) because the reviewer is asking for clarifications and pointing out unclear aspects of the paper, which suggests some concerns about the work. However, it's not strongly negative as the reviewer is seeking information rather than outright criticizing. The politeness score is moderately positive (50) because the reviewer uses respectful language, such as 'I would like to ask' and 'Please', and frames their comments as requests for clarification rather than direct criticisms. The reviewer also acknowledges their own potential misunderstanding ('this aspect of the analysis is not fully clear to me'), which adds to the politeness. The language is professional and constructive, without any harsh or rude elements."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges both strengths and weaknesses of the paper. They describe the paper's contributions as 'good' and 'novel', but also point out several areas for improvement. The final decision suggests a score of 6-7 out of 10, which is above average but not overwhelmingly positive. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'can the authors clarify...', 'Explanation is needed'), and offers to upgrade their score if concerns are addressed. The tone is professional and collaborative rather than harsh or dismissive."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the interesting aspects of the paper, such as linking Entropy-SGD to PAC-Bayes learning and using differential privacy to improve generalization. However, they express some doubts about the novelty of the ideas and techniques. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement without harsh or negative phrasing. They use phrases like 'It would be better if' and 'might help' which are polite ways of suggesting changes. The review maintains a professional and courteous tone while providing both positive feedback and areas for improvement.""]"
"[""This paper proposes a novel way of embedding graph structure into a sequence that can have an unbounded length. \n\nThere has been a significant amount of prior work (e.g. d graph convolutional neural networks) for signals supported on a specific graph. This paper on the contrary tries to encode the topology of a graph using a dynamical system created by the graph and randomization. \n\nThe main theorem is that the created dynamical system can be used to reverse engineer the graph topology for any digraph. \nAs far as I understood, the authors are doing essentially reverse directed graphical model learning. In classical learning of directed graphical models (or causal DAGs) one wants to learn the structure of a graph from observed data created by this graph inducing conditional independencies on data. This procedure is creating a dynamical system that (following very closely previous work) estimates conditional directed information for every pair of vertices u,v and can find if an edge is present from the observed trajectory. \nThe recovery algorithm is essentially previous work (but the application to graph recovery is new).\n\nThe authors state:\n``Estimating conditional directed information efficiently from samples is itself an active area of research Quinn et al. (2011), but simple plug-in estimators with a standard kernel density estimator will be consistent.''\n\nOne thing that is missing here is that the number of samples needed could be exponential in the degrees of the graph. Therefore, it is not clear at all that high-dimensional densities or directed information can be estimated from a number of samples that is polynomial in the dimension (e.g. graph degree).\n\nThis is related to the second limitation, that there is no sample complexity bounds presented only an asymptotic statement. \n\nOne remark is that there are many ways to represent a finite graph with a sequence that can be decoded back to the graph (and of course if there is no bound on the graph size, there will be no bound on the size of the sequence). For example, one could take the adjacency matrix and sequentially write down one row after the other (perhaps using a special symbol to indicate 'next row'). Many other simple methods can be obtained also, with a size of sequence being polynomial (in fact linear) in the size of the graph. I understand that such trivial representations might not work well with RNNs but they would satisfy stronger versions of Theorem 1 with optimal size. \nOn the contrary it was not clear how the proposed sequence will scale in the graph size. \n\n\nAnother remark is that it seems that GCNN and this paper solve different problems. \nGCNNs want to represent graph-supported signals (on a fixed graph) while this paper tries to represent the topology of a graph, which seems different. \n\n\nThe experimental evaluation was somewhat limited and that is the biggest problem from a practical standpoint. It is not clear why one would want to use these sequences for solving MVC. There are several graph classification tasks that try to use the graph structure (as well as possibly other features) see eg the bioinformatics \nand other applications. Literature includes for example:\nGraph Kernels by S.V.N. Vishwanathan et al. \nDeep graph kernels (Yanardag & Vishwanathan and graph invariant kernels (Orsini et al.),\nwhich use counts of small substructures as features. \n\nThe are many benchmarks of graph classification tasks where the proposed representation could be useful but significantly more validation work would be needed to make that case. \n\n"", 'The paper proposes GRAPH2SEQ that represents graphs as infinite time-series of vectors, one for\neach vertex of the graph and in an invertible representation of a graph.  By not having the restriction of representation to a fixed dimension, the authors claims their proposed method is much more scalable. They also define a formal computational model, called LOCAL-Gather that includes GRAPH2SEQ and other classes of GCNN representations, and show that GRAPH2SEQ is capable of computing certain graph functions that fixed-depth GCNNs cannot. They experiment on graphs of size at most 800 nodes to discover minimum vertex cover and show that their method perform much better than GCNNs but is comparable with greedy heuristics for minimum vertex cover.\n\nI find the experiments to be hugely disappointing. Claiming that this particular representation helps in scalability and then doing experiment on graphs of extremely small size does not reflect well. It would have been much more desirable if the authors had conducted experiments on large graphs and compare the results with greedy heuristics. Also, the authors need to consider other functions, not only minimum vertex cover. In general, lack of substantial experiments makes it difficult to appreciate the novelty of the work. I am not at all sure, if this representation is indeed useful for graph optimization problems practically.\n\n\n\n\n', ""This paper proposes to represent nodes in graphs by time series. This is an interesting idea but the results presented in the paper are very preliminary.\nExperiments are only conducted on synthetic data with very small sizes.\nIn Section 5.1, I did not understand the construction of the graph. What means 'all the vertices are disjoint'? Then I do not understand why the vertices of G_i form the optimum.""]","[-20, -50, -50]","[50, 0, 0]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty of the approach and its potential applications, they also point out several limitations and areas where the paper falls short. The reviewer mentions missing sample complexity bounds, limited experimental evaluation, and questions the practical utility of the method for solving MVC. However, the tone is not entirely negative, as the reviewer also recognizes the paper's contributions and potential. The politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms and offer constructive feedback, suggesting additional literature and benchmarks that could improve the paper. The reviewer also acknowledges the paper's contributions and novel aspects, demonstrating a balanced approach to the review."", ""The sentiment score is -50 because the reviewer expresses significant disappointment with the experiments and questions the practical usefulness of the proposed method. The first paragraph is neutral, describing the paper's content, but the second paragraph is largely critical. The reviewer uses phrases like 'hugely disappointing' and 'not at all sure, if this representation is indeed useful', indicating a negative sentiment. However, it's not entirely negative as the reviewer acknowledges some aspects of the work and suggests improvements.\n\nThe politeness score is 0 (neutral) because the reviewer's language is neither particularly polite nor rude. The criticism is direct and professional, without personal attacks or overly harsh language. The reviewer uses phrases like 'I find' and 'It would have been much more desirable', which are neutral ways of expressing criticism. The tone is matter-of-fact and focused on the content of the paper rather than on the authors themselves."", ""The sentiment score is -50 because the review starts with a positive note about the paper's interesting idea, but quickly shifts to criticism. The reviewer states that the results are 'very preliminary' and experiments are only conducted on 'synthetic data with very small sizes'. The reviewer also expresses confusion about certain aspects of the paper, indicating significant issues. This mix of mild praise and substantial criticism suggests a moderately negative sentiment.\n\nThe politeness score is 0 because the language used is neutral and professional. The reviewer doesn't use overly polite language, but also doesn't use rude or harsh words. They state their concerns directly but without aggression, maintaining a neutral tone throughout the review.""]"
"['The authors revised the paper according to all reviewers suggestions, I am satisfied with the current version.\n\nSummary: this works proposes to employ recurrent gated convnets to solve graph node labeling problems on arbitrary graphs. It build upon several previous works, successively introducing convolutional networks, gated edges convnets on graphs, and LSTMs on trees. The authors extend the tree LSTMs formulation to perform graph labeling on arbitrary graphs, merge convnets with residual connections and edge gating mechanisms. They apply the 2 proposed models to 3 baselines also based on graph neural networks on two problems: sub-graph matching (expressing the problem of sub-graph matching as a node classification problem), and semi supervised clustering.  \n\nMain comments:\nIt would strengthen the paper to also compare all these network learning based approaches to variational ones. For instance, to a spectral clustering method for the semi supervised clustering, or\nsolving the combinatorial Dirichlet problem as in Grady: random walks for image segmentation, 2006.\n\nThe abstract and the conclusion should be revised, they are very vague.\n- The abstract should be self contained and should not contain citations.\n- The authors should clarify which problem they are dealing with.\n- instead of the ""numerical result show the performance of the new model"", give some numerical results here, otherwise, this sentence is useless.\n- we propose ... as propose -> unclear: what do you propose?\n \n\nMinor comments:\n- You should make sentences when using references with the author names format. Example: ... graph theory, Chung (1997) -> graph theory by Chung (1997)\n- As Eq 2 -> As the minimization of Eq 2 (same with eq 4)\n- Don\'t start sentences with And, or But\n\n', 'The paper proposes an adaptation of existing Graph ConvNets and evaluates this formulation on a several existing benchmarks of the graph neural network community. In particular, a tree structured LSTM is taken and modified. The authors describe this as adapting it to general graphs, stacking, followed by adding edge gates and residuality.\n\nMy biggest concern is novelty, as the modifications are minor. In particular, the formulation can be seen in a different way. As I see it, instead of adapting Tree LSTMs to arbitary graphs, it can be seen as taking the original formulation by Scarselli and replacing the RNN by a gated version, i.e. adding the known LSTM gates (input, output, forget gate). This is a minor modification. Adding stacking and residuality are now standard operations in deep learning, and edge-gates have also already been introduced in the literature, as described in the paper.\n\nA second concern is the presentation of the paper, which can be confusing at some points. A major example is the mathematical description of the methods. When reading the description as given, one should actually infer that Graph ConvNets and Graph RNNs are the same thing, which can be seen by the fact that equations (1) and (6) are equivalent.\n\nAnother example, after (2), the important point to raise is the difference to classical (sequential) RNNs, namely the fact that the dependence graph of the model is not a DAG anymore, which introduces cyclic dependencies. \n\nGenerally, a clear introduction of the problem is also missing. What are the inputs, what are the outputs, what kind of problems should be solved? The update equations for the hidden states are given for all models, but how is the output calculated given the hidden states from variable numbers of nodes of an irregular graph?\n\nThe model has been evaluated on standard datasets with a performance, which seems to be on par, or a slight edge, which could probably be due to the newly introduced residuality.\n\nA couple of details :\n\n- the length of a graph is not defined. The size of the set of nodes might be meant.\n\n- at the beginning of section 2.1 I do not understand the reference to word prediction and natural language processing. RNNs are not restricted to NLP and I think there is no need to introduce an application at this point.\n\n- It is unclear what does the following sentence means: ""ConvNets are more pruned to deep networks than RNNs""?\n\n- What are ""heterogeneous graph domains""?\n', 'The paper proposes a new neural network model for learning graphs with arbitrary length, by extending previous models such as graph LSTM (Liang 2016), and graph ConvNets. There are several recent studies dealing with similar topics, using recurrent and/or convolutional architecture. The Related work part of this paper makes a good description of both topics. \n\nI would expect the paper elaborate more (at least in a more explicit way) about the relationship between the two models (the proposed graph LSTM and the proposed Gated Graph ConvNets). The authors claim that the innovative of the graph Residual ConvNets architecture, but experiments and the model section do not clearly explain the merits of Gated Graph ConvNets over Graph LSTM. The presentation may raise some misunderstanding. A thorough analysis or explanation of the reasons why the ConvNet-like architecture is better than the RNN-like architecture would be interesting. \n\nIn the section of experiments, they compare 5 different methods on two graph mining tasks. These two proposed neural network models seem performing well empirically. \n\nIn my opinion, the two different graph neural network models are both suitable for learning graphs with arbitrary length, \nand both models worth future stuies for speicific problems. ']","[60, -50, 50]","[50, 50, 75]","[""The sentiment score is 60 (positive) because the reviewer starts by stating they are satisfied with the current version after revisions. They provide a detailed summary of the work and offer constructive feedback for improvement, which indicates a generally positive view. The politeness score is 50 (slightly polite) because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They offer suggestions for improvement in a constructive manner, using phrases like 'It would strengthen the paper...' and 'The authors should clarify...'. However, the review is not overly effusive or excessively polite, maintaining a professional tone. The combination of satisfaction with the revisions, constructive feedback, and professional language justifies these scores."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's novelty and presentation, describing the modifications as 'minor' and the presentation as 'confusing at some points'. However, they do acknowledge some positive aspects, such as the performance being 'on par, or a slight edge'. The politeness score is 50 because while the reviewer is critical, they express their concerns in a professional and constructive manner, using phrases like 'My biggest concern is...' and 'A second concern is...'. They also provide specific examples and suggestions for improvement, which is helpful and courteous. The language is not overly formal or polite, but it maintains a respectful tone throughout."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and good performance in experiments, but also points out areas for improvement. The review is not overwhelmingly positive or negative. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as expectations or recommendations rather than demands. The reviewer also acknowledges the paper's strengths alongside areas for improvement, maintaining a balanced and professional tone.""]"
"['[Main comments]\n\n* I would advice the authors to explain in more details in the intro\nwhat\'s new compared to Li & Malik (2016) and Andrychowicz et al. (2016).\nIt took me until section 3.5 to figure it out.\n\n* If I understand correctly, the only new part compared to Li & Malik (2016) is\nsection 3.5, where block-diagonal structure is imposed on the learned matrices.\nIs that correct?\n\n* In the experiments, why not comparing with Li & Malik (2016)? (i.e., without\n  block-diagonal structure)\n\n* Please clarify whether the objective value shown in the plots is wrt the training\n  set or the test set. Reporting the training objective value makes little\nsense to me, unless the time taken to train on MNIST is taken into account in\nthe comparison. \n\n* Please clarify what are the hyper-parameters of your meta-training algorithm\n  and how you chose them.\n\nI will adjust my score based on the answer to these questions.\n\n[Other comments]\n\n* ""Given this state of affairs, perhaps it is time for us to start practicing\n  what we preach and learn how to learn""\n\nThis is in my opinion too casual for a scientific publication...\n\n* ""aim to learn what parameter values of the base-level learner are useful\n  across a family of related tasks""\n\nIf this is essentially multi-task learning, why not calling it so?  ""Learning\nwhat to learn"" does not mean anything.  I understand that the authors wanted to\nhave ""what"", ""which"" and ""how"" sections but this is not clear at all.\n\nWhat is a ""base-level learner""? I think it would be useful to define it more\nprecisely early on.\n\n* I don\'t see the difference between what is described in Section 2.2\n  (""learning which model to learn"") and usual machine learning (searching for\nthe best hypothesis in a hypothesis class).\n\n* Typo: p captures the how -> p captures how\n\n* The L-BFGS results reported in all Figures looked suspicious to me.  How do you\n  explain that it converges to a an objective value that is so much worse?\nMoreover, the fact that there are huge oscillations makes me think that the\nauthors are measuring the function value during the line search rather than\nthat at the end of each iteration.\n', 'This paper proposed a reinforcement learning (RL) based method to learn an optimal optimization algorithm for training shallow neural networks. This work is an extended version of [1], aiming to address the high-dimensional problem.\n\n\n\nStrengths:\n\nThe proposed method has achieved a better convergence rate in different tasks than all other hand-engineered algorithms.\nThe proposed method has better robustess in different tasks and different batch size setting.\nThe invariant of coordinate permutation and the use of block-diagonal structure improve the efficiency of LQG.\n\n\nWeaknesses:\n\n1. Since the batch size is small in each experiment, it is hard to compare convergence rate within one epoch. More iterations should be taken and the log-scale style figure is suggested. \n\n2. In Figure 1b, L2LBGDBGD converges to a lower objective value, while the other figures are difficult to compare, the convergence value should be reported in all experiments.\n\n3. “The average recent iterate“ described in section 3.6 uses recent 3 iterations to compute the average, the reason to choose “3”, and the effectiveness of different choices should be discussed, as well as the “24” used in state features.\n\n4. Since the block-diagonal structure imposed on A_t, B_t, and F_t, how to choose a proper block size? Or how to figure out a coordinate group?\n\n5. The caption in Figure 1,3, “with 48 input and hidden units” should clarify clearly.\nThe curves of different methods are suggested to use different lines (e.g., dashed lines) to denote different algorithms rather than colors only.\n\n6. typo: sec 1 parg 5, “current iterate” -> “current iteration”.\n\n\nConclusion:\n\nSince RL based framework has been proposed in [1] by Li & Malik, this paper tends to solve the high-dimensional problem. With the new observation of invariant in coordinates permutation in neural networks, this paper imposes the block-diagonal structure in the model to reduce the complexity of LQG algorithm. Sufficient experiment results show that the proposed method has better convergence rate than [1]. But comparing to [1], this paper has limited contribution.\n\n[1]: Ke Li and Jitendra Malik. Learning to optimize. CoRR, abs/1606.01885, 2016.', 'Summary of the paper\n---------------------------\nThe paper derives a scheme for learning optimization algorithm for high-dimensional stochastic problems as the one involved in shallow neural nets training. The main motivation is to learn to optimize with the goal to design a meta-learner able to generalize across optimization problems (related to machine learning applications as learning a neural network) sharing the same properties. For this sake, the paper casts the problem into reinforcement learning framework and relies on guided policy search (GPS) to explore the space of states and actions. The states are represented by the iterates, the gradients, the objective function values, derived statistics and features, the actions are the update directions of parameters to be learned. To make the formulated problem tractable, some simplifications are introduced (the policies are restricted to gaussian distributions family, block diagonal structure is imposed on the involved parameters). The mean of the stationary non-linear policy of GPS is modeled as a recurrent network with parameters to be learned. A hatch of how to learn the overall process is presented. Finally experimental evaluations on synthetic or real datasets are conducted to show the effectiveness of the approach.\n\nComments\n-------------\n- The overall idea of the paper, learning how to optimize, is very seducing and the experimental evaluations (comparison to normal optimizers and other meta-learners) tend to conclude the proposed method is able to learn the behavior of an optimizer and to generalize to unseen problems.\n- Materials of the paper sometimes appear tedious to follow, mainly in sub-sections 3.4 and 3.5. It would be desirable to sum up the overall procedure in an algorithm. Page 5, the term $\\omega$ intervening in the definition of the policy $\\pi$ is not defined.\n- The definitions of the statistics and features (state and observation features) look highly elaborated. Can authors provide more intuition on these precise definitions? How do they impact for instance changing the time range in the definition of $\\Phi$) in the performance of the meta-learner?\n- Figures 3 and 4 illustrate some oscillations of the proposed approach. Which guarantees do we have that the algorithm will not diverge as L2LBGDBGD does? How long should be the training to ensure a good and stable convergence of the method?\n- An interesting experience to be conducted and shown is to train the meta-learner on another dataset (CIFAR for example) and to evaluate its generalization ability on the other sets to emphasize the effectiveness of the method. ']","[-20, 20, 50]","[50, 60, 80]","[""The sentiment score is slightly negative (-20) because the reviewer raises several critical points and questions about the paper, indicating areas that need improvement or clarification. The reviewer states they will 'adjust my score based on the answer to these questions', suggesting current dissatisfaction. However, the tone is not entirely negative, as the reviewer is open to revising their opinion.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful language throughout, phrasing criticisms as questions or suggestions rather than harsh statements. For example, 'I would advice the authors to explain...' and 'Please clarify...' are polite ways of pointing out issues. The reviewer also acknowledges their own potential misunderstandings ('If I understand correctly...'), which is a polite approach. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional tone."", ""The sentiment score is slightly positive (20) because the review acknowledges several strengths of the paper, such as better convergence rate and robustness. However, it also points out multiple weaknesses and suggests that the paper has 'limited contribution' compared to previous work. The overall tone is balanced but leans slightly positive. The politeness score is moderately high (60) because the reviewer uses neutral, professional language throughout. They present criticisms as suggestions for improvement rather than harsh judgments, using phrases like 'should be discussed' and 'is suggested to use'. The reviewer also acknowledges the paper's strengths before discussing its weaknesses, which is a polite approach in academic reviews."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by praising the overall idea as 'very seducing' and notes that experimental evaluations show the method's effectiveness. However, they also point out some areas for improvement, creating a balanced review. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as suggestions (e.g., 'It would be desirable to...'), and asks questions rather than making blunt statements. The reviewer also acknowledges the positive aspects of the work before offering constructive feedback.""]"
"['This paper presents MAd-RL, a method for decomposition of a single-agent RL problem into a simple sub-problems, and aggregating them back together. Specifically, the authors propose a novel local planner - emphatic, and analyze the newly proposed local planner along of two existing ones - egocentric and agnostic. The MAd-RL, and theoretical analysis, is evaluated on the Pac-Boy task, and compared to DQN and Q-learning with function approximation.\n\nPros:\n1. The paper is well written, and well-motivated.\n2. The authors did an extraordinary job in building the intuition for the theoretical work, and giving appropriate examples where needed.\n3. The theoretical analysis of the paper is extremely interesting. The observation that a linearly weighted reward, implies linearly weighted Q function, analysis of different policies, and local minima that result is the strongest and the most interesting points of this paper.\n\nCons:\n1. The paper is too long. 14 pages total - 4 extra pages (in appendix) over the 8 page limit, and 1 extra page of references. That is 50% overrun in the context, and 100% overrun in the references. The most interesting parts and the most of the contributions are in the Appendix, which makes it hard to assess the contributions of the paper. There are two options: \n  1.1 If the paper is to be considered as a whole, the excessive overrun gives this paper unfair advantage over other ICLR papers. The flavor and scope and quality of the problems that can be tackled with 50% more space is substantially different from what can be addressed within the set limit. If the extra space is necessary, perhaps this paper is better suited for another publication? \n  1.2 If the paper is assessed only based on the main part without Appendix, then the only novelty is emphatic planner, and the theoretical claims with no proofs. The results are interesting, but are lacking implementation details. Overall, a substandard paper.\n2. Experiments are disjoint from the method’s section. For example:\n  2.1 Section 5.1 is completely unrelated with the material presented in Section 4.\n  2.2 The noise evaluation in Section 5.3 is nice, but not related with the Section 4. This is problematic because, it is not clear if the focus of the paper is on evaluating MAd-RL and performance on the Ms.PacMan task, or experimentally demonstrating claims in Section 4.\n\nRecommendations:\n1. Shorten the paper to be within (or close to the recommended length) including Appendix.\n2. Focus paper on the analysis of the advisors, and Section 5. on demonstrating the claims.\n3. Be more explicit about the contributions.\n4. How does the negative reward influence the behavior the agent? The agent receives negative reward when near ghosts.\n5. Move the short (or all) proofs from Appendix into the main text.\n6. Move implementation details of the experiments (in particular the short ones) into the main text.\n7. Use the standard terminology (greedy and random policies vs. egoistic and agnostic) where possible. The new terms for well-established make the paper needlessly more complex. \n8. Focus the literature review on the most relevant work, and contrast the proposed work with existing peer reviewed methods.\n9. Revise the literature to emphasize more recent peer reviewed references. Only three references are recent (less than 5 years), peer reviewed references, while there are 12 historic references. Try to reduce dependencies on non-peer reviewed references (~10 of them).\n10. Make a pass through the paper, and decouple it from the van Seijen et al., 2017a\n11. Minor: Some claims need references:\n  11.1 Page 5: “egocentric sub-optimality  does not come from the actions that are equally good, nor from the determinism of the policy, since adding randomness…” - Wouldn’t adding epsilon-greediness get the agent unstuck?\n  11.2 Page 1. “It is shown on the navigation task ….” - This seems to be shown later in the results, but in the intro it is not clear if some other work, or this one shows it.  \n12. Minor:\n  12.1 Mix genders when talking about people. Don’t assume all people that make “complex and important problems”, or who are “consulted for advice”, are male.\n  12.2 Typo: Page 5: a_0 sine die\n  12.3 Page 7 - omit results that are not shown\n  12.4 Make Figures larger - it is difficult, if not impossible to see\n  12.5 What is the difference between Pac-Boy and Ms. Pacman task? And why not use Ms. Packman?\n \n', 'The paper presents Multi-Advisor RL (MAd-RL), a formalized view of many forms of performing RL by training multiple learners, then aggregating their results into a single decision-making agent.  Previous work and citations are plentiful and complete, and the field of study is a promising approach to RL.  Through MAd-RL, the authors analyze the effects of egocentric, agnostic, and empathic planning at the sub-learner level on the resulting applied aggregated policy.  After this theoretical discussion, the different types of sub-learners are used on a Pac-Man problem.\n\nI believe an interesting paper lies within this, and were this a journal, would recommend edits and resubmission.  However, in its current state, the paper is too disorganized and unclear to merit publication.  It took quite a bit of time for me to understand what the authors wanted me to focus on - the paper needs a clearer statement early summarizing its intended contributions.  In addition, more care to language usage is needed - for example, ""an attractor"" refers to an MDP in Figure 3, a state in Theorem 2, and a set in the Theorem 2 discussion.  Additionally, the theoretical portion focuses on the effects of the three different sub-learner types, but the experiments are ""intend[ed] to show that the value function is easier to learn with the MAd-RL architecture,"" which is an entirely different goal.\n\nI recommend the authors decide what to focus on, rethink how paper space is allocated, and take care to more clearly drive home their intended point.', ""Summary\n\nThe paper is well-written but does not make deep technical contributions and does not present a comprehensive evaluation or highly insightful empirical results.\n\nAbstract / Intro\n\nI get the entire focus of the paper is some variant of Pac-Man which has received attention in the RL literature for Atari games, but for the most part the impressive advances of previous Atari/RL papers are in the setting that the raw video is provided as input, which is much different than solving the underlying clean mathematically abstracted problem (as a grid world with obstacles) as done here and evident in the videos.  Further it is honestly hard for me to be strongly motivated about a paper that focuses on the need to decompose Pac-man into sub-agents/advisor value functions.\n\nSection 2\n\nAnother historically well-cited paper for MDP decomposition:\n\n  Flexible Decomposition Algorithms for Weakly Coupled Markov Decision Problems, Ronald Parr. UAI 98.\n  https://dslpitt.org/uai/papers/98/p422-parr.pdf\n\nSection 3\n\nIs the additive reward decomposition a required part of the problem specification?  It seems so, i.e., there is no obvious method for automatically decomposing a monolithic reward function over advisors.\n\nSection 4\n\n* Egocentric:\n\nDefinition 1: Sure, the problem will have local optima (attractors) when decomposed suboptimally -- I'm not sure what new insight we've gained from this analysis... it is a general problem with any function approximation scheme that does not guarantee that the rank ordering of actions for a state is preserved.\n\n* Agnostic\n\nOther than approximating some type of myopic rollout, I really don't see why this approach would be reasonable?  I am surprised it works at all though my guess is that this could simply be an artifact of evaluating on a single domain with a specific structure.\n\n* Empathic\n\nThis appears to be the key contribution though related work certainly infringes on its novelty.  Is this paper then an empirical evaluation of previous methods in a single Pac-man grid world variant?\n\nI wonder if the theory of DEC-MDPs would have any relevance for novel analysis here?\n\nSection 5\n\nI'm disappointed that the authors only evaluate on a single domain; presumably the empathic approach has applications beyond Pac-Man?\n\nThe fact that empathic generally performs better is not at all surprising.  The fact that a modified discount factor for egocentric can also perform well is not surprising given that lower discount factors have often been shown to improve approximated MDP solutions, e.g.,\n\n  Biasing Approximate Dynamic Programming with a Lower Discount Factor\n\n  Marek Petrik, Bruno Scherrer (NIPS-08).\t\n  http://marek.petrik.us/pub/Petrik2009a.pdf\n\n***\n\nSide note:\n\nThe following part is somewhat orthogonal to the review above in that I would not expect the authors to address this on revision, *but* at the same time I think it provides a connection to the special case of concurrent action decomposition into advisors, which could potentially provide a high impact direction of application for this work (i.e., concurrent problems are hard and show up in numerous operations research problems covering inventory control, logistics, epidemic response).\n\nFor the special case that each advisor is assigned to one action in a factored space of concurrent actions, the egocentric algorithm would be very close to the Hindsight approximation in Section 6 of this paper (including an additive decomposition of rewards):\n\n  Planning in Factored Action Spaces with Symbolic Dynamic Programming\n  Aswin Nadamuni Raghavan, Alan Fern, Prasad Tadepalli, Roni Khardon, and Saket Joshi (AAAI-12).\n  https://www.aaai.org/ocs/index.php/AAAI/AAAI12/paper/download/5012/5336\n\nThis simple algorithm is hard to beat for the following reason that connects some details of your egocentric and empathic settings: rather than decomposing a concurrent MDP into independent problems per concurrent action, the optimization of each action (by each advisor) is done in sequence (advisors are ordered) and gets to condition on the previously selected advisor actions.  So it provides an alternate paradigm where advisors actually get to see and condition their policy on what other advisors are doing.  In my own work comparing optimal concurrent solutions to this approach, I have found this approach to be near-optimal and much more efficient to solve since it exploits decomposition.\n\nWhy is this relevant to this work?  Because (a) it suggests another variant of the advisor decomposition that at least makes sense in the case of concurrent actions (and perhaps shared actions though this would require some extension) and (b) it suggests there are more options than just the full egocentric and empathic settings in this important class of concurrent action problems that are necessarily solved in practice for large action spaces by some form of decomposition.  This could be an interesting direction for future exploration of the ideas in this work, where there might be additional technical novelty and more space for empirical contributions and observations.""]","[20, -50, -30]","[60, 50, 20]","[""The sentiment score is slightly positive (20) because the reviewer begins with several strong pros, praising the paper as well-written, well-motivated, and containing extremely interesting theoretical analysis. However, this is balanced by significant cons and a long list of recommendations for improvement. The overall tone suggests the reviewer sees potential in the work but feels substantial revisions are needed. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the authors' efforts (e.g., 'extraordinary job'), and framing criticisms constructively as recommendations. The reviewer maintains a professional tone, even when pointing out significant issues like the paper's length. The use of phrases like 'please' and the detailed, helpful nature of the recommendations further contribute to the polite tone."", ""The sentiment score is -50 because while the reviewer acknowledges the potential of the paper ('I believe an interesting paper lies within this'), they ultimately recommend against publication in its current state due to disorganization and lack of clarity. The reviewer points out several issues that need addressing, indicating a generally negative sentiment. However, it's not entirely negative as they see potential in the work. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They avoid harsh or dismissive language, instead framing their feedback as recommendations ('I recommend the authors...'). The tone is professional and aimed at helping the authors improve their work, which is indicative of politeness in academic peer review."", ""The sentiment score is -30 because the review is generally critical of the paper, pointing out several limitations and lack of novelty. The reviewer states that the paper 'does not make deep technical contributions' and expresses disappointment with the limited evaluation. However, it's not entirely negative as the reviewer acknowledges that the paper is 'well-written' and offers some constructive suggestions. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I'm disappointed' rather than harsh criticism. The reviewer also offers additional insights and suggestions for improvement, which is a polite way to provide feedback. However, some phrases like 'honestly hard for me to be strongly motivated' slightly reduce the politeness score.""]"
"['The work proposed a generic framework for end-to-end transfer learning / domain adaptation with deep neural networks. The idea is to learn a joint autoencoders, containing private branch with task/domain-specific weights, as well as common branch consisting of shared weights used across tasks/domains, as well as task/domain-specific weights.  Supervised losses are added after the encoders to utilize labeled samples from different tasks. Experiments on the MNIST and CIFAR datasets showed improvements over baseline models. Its performance is comparable to / worse than several existing deep domain adaptation works on the MNIST, USPS and SVHN digit datasets.\n\nThe structure of the paper is good, and easy to read.  The idea is fairly straight-forward. It reads as an extension of ""frustratingly easy domain adaptation"" to DNN (please cite this work). Different from most existing work on DNN for multi-task/transfer learning, which focuses on weight sharing in bottom layers, the work emphasizes the importance of weight sharing in deeper layers. The overall novelty of the work is limited though. \n\nThe authors brought up two strategies on learning the shared and private weights at the end of section 3.2. However, no follow-up comparison between the two are provided. It seems like most of the results are coming from the end-to-end learning. \n\nExperimental results:\nsection 4.1: Figure 2 is flawed. The colors do not correspond to the sub-tasks. For example, there are digits 1, 4 in color magenta, which is supposed to be the shared branch of digits of 5~9. Vice versa. \nFrom reducing the capacity of JAE to be the same as the baseline, most of the improvement is gone. It is not clear how much of the improvement will remain if the baseline model gets to see all the samples instead of just those from each sub-task. \n\nsection 4.2.1: The authors demonstrate the influence of shared layer depth in table 2. While it does seem to matter for tasks of dissimilar inputs, have the authors compare having a completely shared branch or sharing more than just a single layer?\n\nThe authors suggested in section 4.1 CIFAR experiment that the proposed method provides more performance boost when the two tasks are more similar, which seems to be contradicting to the results shown in Figure 3, where its performance is worse when transferring between USPS and MNIST, which are more similar tasks vs between SVHN and MNIST. Do the authors have any insight?', '\n\nThe paper focuses on learning common features from multiple domains data in a unsupervised and supervised learning scheme. Setting this as a general multi task learning, the idea consists in jointly learning autoecnoders, one for each domain, for the multiples domain data in such a way that parts of the parameters of the domain autoencoder are shared. Each domain/task autoencoder  then consists in a shared part and a private part. The authors propose a variant of the model in the case of supervised learning and end up with a general architecture for multi-task, semi-supervised and transfer learning.\n\nThe presentation of the paper is good and the paper is easy to follow and explores the rather intuitive and simple idea of sharing parameters between related tasks.\n\nExperimental show some interesting results. First unsupervised experiments on Mnist data show improved MSe of joint autoecnoders but are these differences really significant (e.g. from 0.56 to 5.52) ?  Moreover i am not sure to understand the meaning of separation criterion computed on t-sne of hidden representations. Results of Table 1 show improved reconstruction performance (MSE?) of joint auto encoders over independent ones for unrelated pairs such as airplane and horses. I a not sure ti understand why this improvement occurs even with very different classes.    The investigation on the depth where sharing should occur is quite interesting and related to the usual idea of higher transferable property low level features. Results on transfer are the most interesting ones actually but do not seem to improve so much over baselines. \n\n', ""The paper addresses the question of identifying 'shared features' in neural networks trained on different datasets.  Concretely, suppose you have two datasets X1, X2 and you would like to train auto-encoders (with potential augmentation with labeled examples) for the two datasets. One could work on the two separately; here, the authors propose sharing some of the weights to try and exploit/identify common features between the two datasets. The authors formalize by essentially looking to optimize an auto-encoder that take inputs of the form (x1, x2) and employing architectures that allow few nodes to interact with both x1,x2. The authors then try to minimize an appropriate loss function by standard methods. \n\nThe authors then apply the above methodology to transfer learning between various datasets. The empirical results here are interesting but not particularly striking; the most salient feature perhaps is that the architectures and training algorithms are perhaps a bit simpler but the overall improvements over existing methods are not too exciting. ""]","[-20, 20, -20]","[60, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects (e.g., 'The structure of the paper is good, and easy to read'), they also point out several limitations and issues with the work. The reviewer notes that 'The overall novelty of the work is limited' and identifies several flaws in the experiments and results. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and ask clarifying questions rather than making harsh criticisms. The language used is respectful and focuses on the work itself rather than making personal comments about the authors."", 'The sentiment score is slightly positive (20) because the reviewer acknowledges some strengths of the paper, such as good presentation, interesting results, and an intuitive idea. However, they also raise several questions and concerns about the significance and interpretation of results. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, avoids harsh criticism, and frames concerns as questions or areas for clarification rather than outright flaws. The reviewer maintains a professional and constructive tone while providing balanced feedback.', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting approach, they express that the results are 'not particularly striking' and the improvements are 'not too exciting'. This indicates a somewhat underwhelmed response to the work. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They objectively describe the paper's methodology and findings without using harsh or overly critical language. The reviewer also acknowledges the 'interesting' aspects of the work, which adds a polite tone. However, the review lacks overtly polite phrases or strong praise, keeping it from scoring higher on politeness.""]"
"['Summary:\n\nThe paper proposes to learn new priors for latent codes z  for GAN training.  for this the paper shows that there is a mismatch between the gaussian prior and an estimated of the latent codes of real data by reversal of the generator . To fix this the paper proposes to learn a second GAN to learn the prior distributions of ""real latent code"" of the first GAN. The first GAN then uses the second GAN as prior to generate the z codes. \n \nQuality/clarity:\n\nThe paper is well written and easy to follow.\n\nOriginality:\n\npros:\n-The paper while simple sheds some light on important problem with the prior distribution used in GAN.\n- the second GAN solution trained on reverse codes from real data is interesting \n- In general the topic is interesting, the solution presented is simple but needs more study\n\ncons:\n\n- It related to adversarial learned inference and BiGAN, in term of learning the mapping  z ->x, x->z and seeking the agreement. \n- The solution presented is not end to end (learning a prior generator on learned models have been done in many previous works on encoder/decoder)\n\nGeneral Review:\n\nMore experimentation with the latent codes will be interesting:\n\n- Have you looked at the decay of the singular values of the latent codes obtained from reversing the generator? Is this data low rank? how does this change depending on the dimensionality of the latent codes? Maybe adding plots to the paper can help.\n\n- the prior agreement score is interesting but assuming gaussian prior also for the learned latent codes from real data is maybe not adequate.  Maybe computing the entropy of the codes using a nearest neighbor estimate of the entropy  can help understanding the entropy difference wrt to the isotropic gaussian prior?\n\n- Have you tried to multiply the isotropic normal noise with the learned singular values and generate images from  this new prior  and compute inceptions scores etc? Maybe also rotating the codes with the singular vector matrix V or \\Sigma^{0.5} V?\n\n- What architecture did you use for the prior generator GAN?\n\n- Have you thought of an end to end way to learn the prior generator GAN? \n\n****** I read the authors reply. Thank you for your answers and for the SVD plots this is  helpful.  *****\n\n', 'The paper demonstrates the need and usage for flexible priors in the latent space alongside current priors used for the generator network. These priors are indirectly induced from the data - the example discussed is via an empirical diagonal covariance assumption for a multivariate Gaussian. The experimental results show the benefits of this approach. \nThe paper provides for a good read. \n\nComments:\n\n1. How do the PAG scores differ when using a full covariance structure? Diagonal covariances are still very restrictive. \n2. The results are depicted with a latent space of 20 dimensions. It will be informative to see how the model holds in high-dimensional settings. And when data can be sparse. \n3. You could consider giving the Discriminator, real data etc in Fig 1 for completeness as a graphical summary. \n', 'The paper proposes, under the GAN setting, mapping real data points back to the latent space via the ""generator reversal"" procedure on a sample-by-sample basis (hence without the need of a shared recognition network) and then using this induced empirical distribution as the ""ideal"" prior targeting which yet another GAN network might be trained to produce a better prior for the original GAN.\n\nI find this idea potentially interesting but am more concerned with the poorly explained motivation as well as some technical issues in how this idea is implemented, as detailed below.\n\n1. Actually I find the entire notion of an ""ideal"" prior under the GAN setting a bit strange. To start with, GAN is already training the generator G to match the induced P_G(x) (from P(z)) with P_d(x), and hence by definition, under the generator G, there should be no better prior than P(z) itself (because any change of P(z) would then induce a different P_G(x) and hence only move away from the learning target).\n\nI get it that maybe under different P(z) the difficulty of learning a good generator G can be different, and therefore one may wish to iterate between updating G (under the current P(z)) and updating P(z) (under the current G), and hopefully this process might converge to a better solution. But I feel this sounds like a new angle and not the one that is adopted by the authors in this paper.\n\n2. I think the discussions around Eq. (1) are not well grounded. Just as you said right before presenting Eq. (1), typically the goal of learning a DGM is just to match Q_x with the true data distrubution P_x. It is **not** however to match Q(x,z) with P(x,z). And btw, don\'t you need to put E_z[ ... ] around the 2nd term on the r.h.s. ?\n\n3. I find the paper mingles notions from GAN and VAE sometimes and misrepresents some of the key differences between the two.\n\nE.g. in the beginning of the 2nd paragraph in Introduction, the authors write ""Generative models like GANs, VAEs and others typically define a generative model via a deterministic generative mechanism or generator ..."". While I think the use of a **deterministic** generator is probably one of the unique features of GAN, and that is certainly not the case with VAE, where typically people still need to specify an explicit probabilistic generative model.\n\nAnd for this same reason, I find the multiple references of ""a generative model P(x|z)"" in this paper inaccurate and a bit misleading.\n\n4. I\'m not sure whether it makes good sense to apply an SVD decomposition to the \\hat{z} vectors. It seems to me the variances \\nu^2_i shall be directly estimated from \\hat{z} as is. Otherwise, the reference ""ideal"" distribution would be modeling a **rotated** version of the \\hat{z} samples, which imo only introduces unnecessary discrepancies.\n\n5. I don\'t quite agree with the asserted ""multi-modal structure"" in Figure 2. Let\'s assume a 2d latent space, where each quadrant represents one MNIST digit (e.g. 1,2,3,4). You may observe a similar structure in this latent space yet still learn a good generator under even a standard 2d Gaussian prior. I guess my point is, a seemingly well-partitioned latent space doesn\'t bear an obvious correlation with a multi-modal distribution in it.\n\n6. The generator reversal procedure needs to be carried out once for each data point separately, and also when the generator has been updated, which seems to be introducing a potentially significant bottleneck into the training process.']","[50, 70, -50]","[80, 80, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths ('well written', 'sheds some light on important problem', 'interesting') while also pointing out some limitations ('not end to end', 'needs more study'). The overall tone is constructive and encouraging. The politeness score is 80 (quite polite) due to the respectful language used throughout. The reviewer uses phrases like 'thank you for your answers' and frames criticisms as suggestions or questions rather than direct criticisms. The review maintains a professional and courteous tone, offering constructive feedback and showing appreciation for the authors' work and responses."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, stating it 'demonstrates the need and usage for flexible priors' and 'provides for a good read.' The experimental results are also noted to show benefits. The score is not higher as there are some suggestions for improvement. The politeness score is 80 (polite) because the language used is professional and constructive. The reviewer offers suggestions in a respectful manner, using phrases like 'It will be informative to see' and 'You could consider,' which are polite ways of suggesting improvements without being demanding. The overall tone is supportive and aimed at enhancing the paper rather than criticizing it."", ""The sentiment score is -50 because while the reviewer finds the idea 'potentially interesting', they express significant concerns about the paper's motivation and technical implementation. The review lists several major issues and disagreements with the authors' approach, indicating a generally negative sentiment. However, it's not entirely negative as the reviewer acknowledges some potential in the idea.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I find' and 'I think' to express opinions, and 'I'm not sure' to express uncertainty, which softens the criticism. The reviewer also explains their concerns in detail, which is helpful and considerate. However, the language is not overly polite or deferential, maintaining a neutral to slightly positive politeness level.""]"
"['Summary: \n\nI like the general idea of learning ""output stochastic"" noise models in the paper, but the idea is not fully explored (in terms of reasonable variations and their comparative performance).  I don\'t fully understand the rationale for the experiments: I cannot speak to the reasons for the GAN\'s failure (GANs are not easy to train and this seems to be reflected in the results); the newly proposed model seems to improve with samples simply because the evaluation seems to reward the best sample.  I.e., with enough throws, I can always hit the bullseye with a dart even when blindfolded.\n\nComments:\n\nThe model proposes to learn a conditional stochastic deep model by training an output noise model on the input x_i and the residual y_i - g(x_i).  The trained residual function can be used to predict a residual z_i for x_i.  Then for out-of-sample prediction for x*, the paper appears to propose sampling a z uniformly from the training data {z_i}_i (it is not clear from the description on page 3 that this uniformly sampled z* = z_i depends on the actual x* -- as far as I can tell it does not).  The paper does suggest learning a p(z|x) but does not provide implementation details nor experiment with this approach.\n\nI like the idea of learning an ""output stochastic"" model -- it is much simpler to train than an ""input stochastic"" model that is more standard in the literature (VAE, GAN) and there are many cases where I think it could be quite reasonable.  However, I don\'t think the authors explore the idea well enough -- they simply appear to propose a non-parametric way of learning the stochastic model (sampling from the training data z_i\'s) and do not compare to reasonable alternative approaches.  To start, why not plot the empirical histogram of p(z|x) (for some fixed x\'s) to get a sense of how well-behaved it is as a distribution.  Second, why not simply propose learning exponential family models where the parameters of these models are (deep nets) conditioned on the input?  One could even start with a simple Gaussian and linear parameterization of the mean and variance in terms of x.  If the contribution of the paper is the ""output stochastic"" noise model, I think it is worth experimenting with the design options one has with such a model.\n\nThe experiments range over 4 video datasets.  PSNR is evaluated on predicted frames -- PSNR does not appear to be explicitly defined but I am taking it to be the metric defined in the 2nd paragraph from the bottom on page 7.  The new model ""EEN"" is compared to a deterministic model and conditional GAN.  The GAN never seems to perform well -- the authors claim mode collapse, but I wonder if the GAN was simply hard to train in the first place and this is the key reason?  Unsurprisingly (since the EEN noise does not seem to be conditioned on the input), the baseline deterministic model performs quite well.  If I understand what is being evaluated correctly (i.e., best random guess) then I am not surprised the EEN can perform better with enough random samples.  Have we learned anything?\n', 'This paper introduce a times-series prediction model that works in two phases. First learns a deterministic mapping from x to y. And then train another net to predict future frames given the input and residual error from the first network. And does sampling for novel inputs by sampling the residual error collected from the training set. \n\nPros:\nThe paper is well written and easy to follow.\nGood cover of relevant work in sec 3.\n\nCons\nThe paper emphasis on the fact the their modeling multi-modal time series distributions, which is almost the case for most of the video sequence data. But unfortunately doesn’t show any results even qualitative like generated samples for other  work on next frame video prediction. The shown samples from model looks extremely, low quality and really hard to see the authors interpretations of it.\n\nThere are many baselines missing. One simple one would be what if they only used the f and draw z samples for N(0,1)? VAE is very power latent variable model which also not being compared against. It is not clear what implantation of GAN they are using?.Vanilla GAN is know to be hard to train and there has been many variants recently that overcome some of those difficulties and its mode collapse problem. \n', ""The paper proposes a model for prediction under uncertainty where the separate out deterministic component prediction and uncertain component prediction.\nThey propose to have a predictor for deterministic information generation using a standard transformer trained via MSE.\nFor the non-deterministic information, they have a residual predictor that uses a low-dimensional latent space. This low-dim latent space is first predicted from the residual of the (deterministic prediction - groundtruth), and then the low-dim encoding goes into a network that predicts a corrected image.\nThe subtleness of this work over most other video prediction work is that it isn't conditioned on a labeled latent space (like text to video prediction, for example). Hence inferring a structured latent space is a challenge.\nThe training procedure follows an alternative minimization in EM style.\n\nThe biggest weakness of the paper (and the reason for my final decision) is that the paper completely goes easy on baseline models. It's only baseline is a GAN model that isn't even very convincing (GANs are finicky to train, so is this a badly tuned GAN model? or did you spend a lot of time tuning it?).\n\nBecause of the plethora of VAE models used in video prediction [1] (albeit, used with pre-structured latent spaces), there has to be atleast one VAE baseline. Just because such a baseline wasn't previously proposed in literature (in the narrow scope of this problem) doesn't mean it's not an obvious baseline to try. In fact, a VAE would be nicely suited when proposing to work with low-dimensional latent spaces.\n\nThe main signal I lack from reading the paper is whether the proposed model actually does better than a reasonable baseline.\nIf the baselines are stronger and this point is more convincing, I am happy to raise my rating of the paper.\n\n[1] http://openaccess.thecvf.com/content_ICCV_2017/papers/Marwah_Attentive_Semantic_Video_ICCV_2017_paper.pdf""]","[-30, -30, -30]","[20, 50, 50]","[""The sentiment score is slightly negative (-30) because while the reviewer likes the general idea, they express several criticisms and doubts about the paper's execution and experimental design. The reviewer states 'I like the general idea' but follows with multiple critiques, suggesting the paper doesn't fully explore the concept, lacks comparisons to alternatives, and has questionable experimental rationale. The politeness score is mildly positive (20) as the reviewer maintains a professional tone throughout, using phrases like 'I like the idea' and 'I don't fully understand' rather than harsh criticisms. They offer constructive suggestions for improvement, which is polite. However, the review isn't overly complimentary, keeping the score from being higher."", 'The sentiment score is -30 because while the reviewer acknowledges some pros (well-written paper, good coverage of relevant work), they express significant concerns about the quality of results, missing baselines, and lack of comparisons with other models. The cons outweigh the pros, indicating a slightly negative sentiment. The politeness score is 50 because the reviewer uses professional and respectful language throughout, acknowledging positive aspects before presenting criticisms. They phrase their concerns as observations rather than direct attacks, maintaining a polite tone while still conveying their critiques clearly.', ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'subtleness of this work'), they express significant concerns about the lack of strong baselines, which is described as the 'biggest weakness'. This criticism forms the core of the review and leads to a negative overall sentiment. However, the score is not extremely negative as the reviewer leaves room for improvement ('If the baselines are stronger... I am happy to raise my rating'). The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and express willingness to reconsider their evaluation. The language is not overly formal or deferential, but it's respectful and focuses on the work rather than making personal criticisms. The use of phrases like 'I am happy to raise my rating' contributes to the polite tone.""]"
"['Summary:\nThis paper considers a learning method for the ResNet using the boosting framework. More precisely, the authors view the structure of the ResNet as a (weighted) sum of base networks (weak hypotheses) and apply the boosting framework. The merit of this approach is to decompose the learning of complex networks to that of small to large networks in a moderate way and it uses less computational costs. The experimental results are good. The authors also show training and generalization error bounds for the proposed approach.\n\nComments: \nThe idea of the paper is natural and interesting. Experimental results are somewhat impressive. However, I am afraid that theoretical results in the paper contain several mistakes and does not hold. The details are below.\n\nI think the proof of Theorem 4.2 is wrong. More precisely, there are several possibly wrong arguments as follows:\n- In the proof, \\alpha_t+1 is chosen so as to minimize an upper bound of Z_t, while the actual algorithm is chosen to minimize Z_t. The minimizer of Z_t and that of an upper bound are different in general. So, the obtained upper bound does not hold for the training error of the actual algorithm. \n- It is not a mistake, but, there is no explanation why the equality between (27) and (28) holds. Please add an explanation. Indeed, equation (21) matters. \n\nAlso, the statement of Theorem 4.2 looks somewhat cheating: The statement seems to say that it holds for any iteration T and the training error decays exponentially w.r.t. T. However, the parameter T is determined by the parameter gamma, so it is some particular iteration, which might be small and the bound could be large. \n\nThe generalization error bound Corollary 4.3 seems to be wrong, too. More precisely, Lemma 2 of Cortes et al. is OK, but the application of Lemma 2 is not. In particular, the proof does not take into account of the function \\sigma. In other words, the proof considers the Rademacher complexity R_m(\\calF_t), of the class \\calF_t, but, acutually, I think it should consider R_m(\\sigma(\\calF_t)), where the class \\sigma(\\calF_t) consists of the composition of functions \\sigma and f_t in \\calF_t. Talagrand’s lemma (see, e.g., Mohri et al.’ s book: Foundation of Machine Learning) can be used to analyze the complexity of the composite class. But, the resulting bound would depend on the Lipschizness of \\sigma in an exponential way. \n\nThe explanation of the generalization ability is not sufficient. While the latter weak hypotheses are complex enough and would have large edges, the complexity of the function class of weak hypotheses grows exponentially w.r.t. the iteration T, which should be mentioned. \n\nAs a summary, the paper contains nice ideas and experimental results are promising, but has non-negligible mistakes in theoretical parts which degrade the contribution of the paper.\n\nMinor Comments:\n-In Algorithm 1, \\gamma_t is not defined when a while-loop starts. So, the condition of the while-loop cannot be checked.\n\n \n', 'Disclaimer: I reviewed this paper for NIPS as well and many of comments made by reviewers at that time still apply to this version of the paper as well, although presentation has overall improved.\n\nThe paper presents a boosting-style algorithm for training deep residual networks. Convergence analysis for training error is presented and analysis of generalization ability is also provided. Paper concludes with some experimental results.\n\nThe main contribution of this work is interpretation of ResNet as a telescoping sum of differences between the intermediate layers and treating these differences as weak learners that are then boosted. This indeed appears to an interesting insight about ResNet training.\n\nOn the other hand, one of the main objections during NIPS reviews was the relation of this work to work of Cortes et al. on Adanet. In particular, generalization bounds presented in this work are results taken from that paper (which authors admit). What is less clear is the distinction between the algorithmic approaches which makes it hard to judge the novelty of this work. There is a paragraph at the end of section 2 but it seems rather vague.\n\nOne other objection during NIPS reviews was experimental setup explanation of which is omitted from the current version. In particular, same learning rate and mini-batch size was used both for boosting and backprop algorithms which seems strange since boosting is supposed to train much smaller classifiers.\n\nAnother concern is practicality of the proposed method which seems to require maintaining explicit distribution over all examples which would not be practical for modern datasets where NNs are typically applied.\n', 'This paper formulates the deep ResNet as a boosting algorithm. Based on this formulation, the authors prove that the generalization error bound decays exponentially with respect to the number of residual blocks. Further, a greedy block-wise training procedure is proposed to optimized ResNet-like neural networks. The authors claim that this algorithm is more efficient than standard end-to-end backpropagation (e2eBP) algorithm in terms of time and memory consumption.\nOverall, the paper is well organized and easy to follow. I find that using the boosting theory to analyze the ResNet architecture quite interesting. My concerns are mainly on the proposed BoostResNet algorithm.\n1.\tI don’t quite understand why the sequentially training procedure is more time efficient than e2eBP.  It is true that BoostResNet trains each block quite efficiently. However, there are T blocks need to be trained sequentially. In comparison, e2eBP updates *all* the blocks at each training iteration.\n2.\tThe claim that BoostResNet is memory efficient may not hold in practice. I agree that the GPU memory consumption is much lower than in e2eBP. However, this only holds *under the assumption that the intermediate outputs of a previous block are stored to disk*. Unfortunately, this assumption is not practical for real problems: the intermediate outputs usually requires much more space of the original datasets. What makes thing worse, the widely used data augmentation techniques (horizontal flip, shift, etc.) would further make the space requirement hundreds of or even thousands of times larger.\n3.\tThe results in Figure 2 seem quite surprising to me, as the ResNet architectures is supposed to be quite robust when the network goes deeper. Have you tried the convolutional ResNet structure used in their original paper?\n4.\tIn Figure 3, how did you measure the number of gradient updates? In the original ResNet paper, the number of iterations required to train a model is 164(epochs)*50000(training samples)/128(batch-size)=6.4x10^5, which is far less than that showing in this figure.\n5.\tIn Figure 3, it seems that the algorithms are not fully converged, and on CIFAR-10 the e2eBP outperforms BoostResNet eventually. Is there any explanations? ']","[-30, -20, -20]","[50, 50, 60]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('The idea of the paper is natural and interesting. Experimental results are somewhat impressive.'), they express significant concerns about theoretical mistakes and issues that 'degrade the contribution of the paper.' This indicates an overall negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses respectful language throughout, such as 'I am afraid that' and 'I think,' and provides detailed explanations for their concerns. They also acknowledge positive aspects before critiquing. However, the review doesn't go out of its way to be overly polite, maintaining a professional tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting insight', 'presentation has overall improved'), there are several critical points raised about novelty, experimental setup, and practicality. The overall tone suggests more concerns than praise. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges improvements, and frames criticisms as 'concerns' or 'objections' rather than direct attacks. The reviewer also uses phrases like 'seems strange' instead of more harsh language when questioning choices made by the authors."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper interesting and well-organized, they express several significant concerns about the proposed BoostResNet algorithm. The reviewer questions the efficiency claims, practical applicability, and some of the results presented. However, the tone is not entirely negative, as they acknowledge positive aspects of the paper.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They begin with positive comments about the paper's organization and interesting approach. When expressing concerns, they use phrases like 'I don't quite understand' and 'My concerns are mainly on...' rather than harsh criticism. The reviewer also asks questions for clarification rather than making accusatory statements. The language is consistently polite and constructive, even when pointing out potential issues with the research.""]"
"['The paper presents a multi-modal CNN model for sentiment analysis that combines images and text.  The model is trained on a new dataset collected from Tumblr.\n\nPositive aspects:\n+ Emphasis in model interpretability and its connection to psychological findings in emotions\n+ The idea of using Tumblr data seems interesting, allowing to work with a large set of emotion categories, instead of considering just the binary task positive vs. negative. \n\nWeaknesses:\n- A deeper analysis of previous work on the combination of image and text for sentiment analysis (both datasets and methods) and its relation with the presented work is necessary. \n- The proposed method is not compared with other methods that combine text and image for sentiment analysis.\n-  The study is limited to just one dataset.\n\nThe paper presents interesting ideas and findings in an important challenging area. The main novelties of the paper are: (1) the use of Tumblr data, (2) the proposed CNN architecture, combining images and text (using word embedding. \n\nI missed a ""related work section"", where authors clearly mention previous works on similar datasets. Some related works are mentioned in the paper, but those are spread in different sections. It\'s hard to get a clear overview of the previous research: datasets, methods and contextualization of the proposed approach in relation with previous work. I think authors should cite Sentibanks. Also, at some point authors should compare their proposal with previous work. \n\nMore comments:\n\n- Some figures could be more complete: to see more examples in Fig 1, 2, 3 would help to understand better the dataset and the challenges. \n- In table 4, for example, it would be nice to see the performance on the different emotion categories.\n- It would be interesting to see qualitative visual results on recognitions.\n\nI like this work, but I think authors should improve the aspects I mention for its publication.\n', '\nThe authors present a study that aims at inferring the ""emotional"" tags provided by Thumblr users starting from images and texts in the captions. For text processing the authors use a standard LSTM taking as input GLOVE vectors of words in a sentence. For visual information, authors use a pretrained CNN (with fine tuning). A fully connected layer is used to fuse the multimodal information. Experimental results are reported in a self generated data set. \n\nThe contribution from the RL perspective is limited, in the sense that the authors simply applied standard models to predict a bunch of labels (in this case, emotion labels). It is interesting the ""psychological"" analysis that the authors present in Section 6. Still, I think the contribution in that part is a: sentiment-psychologically inspired analysis of the Thumbrl data set. \n\nI think the author\'s statement on that this study leads to a more plausible psychological model of emotion is not well founded (they also mention to learn to recognize the latent emotional state). Whereas it is true that psychological studies rely on self - filled questionnaires, comparing a questionnaire (produced by expert psychologist) to the tags provided by users in a social network is to ambitious. (in some parts the authors make explicit this is an approximation, this should be stressed in every part of the paper)\n', 'This paper presents a method for classifying Tumblr posts with associated images according to associated single emotion word hashtags.  The method relies on sentiment pre-processing from GloVe and image pre-processing from Inception.  \n \nMy strongest criticism for this paper is against the claim that Tumblr post represent self-reported emotions and that this method sheds new insight on emotion representation and my secondary criticism is a lack of novelty in the method, which seems to be simply a combination of previously published sentiment analysis module and previously published image analysis module, fused in an output layer. \n\nThe authors claim that the hashtags represent self-reported emotions, but this is not true in the way that psychologists query participants regarding emotion words in psychology studies.  Instead these are emotion words that a person chooses to broadcast along with an associated announcement.  As the authors point out, hashtags and words may be used sarcastically or in different ways from what is understood in emotion theory.  It is quite common for everyday people to use emotion words this way e.g. using #love to express strong approval rather than an actual feeling of love.   \n\nIn their analysis the authors claim:\n“The 15 emotions retained were those with high relative frequencies on Tumblr among the PANAS-X scale (Watson & Clark, 1999)”.\nHowever five of the words the authors retain: bored, annoyed, love, optimistic, and pensive are not in fact found in the PANAS-X scale:\n\nReference: The PANAS-X Scale: https://wiki.aalto.fi/download/attachments/50102838/PANAS-X-scale_spec.pdf Also the longer version that the authors cited: \nhttps://www2.psychology.uiowa.edu/faculty/clark/panas-x.pdf\n\nIt should also be noted that the PANAS (Positive and Negative Affect Scale) scale and the PANAS-X (the “X” is for eXtended) scale are questionnaires used to elicit from participants feelings of positive and negative affect, they are not collections of ""core"" emotion words, but rather words that are colloquially attached to either positive or negative sentiment.  For example PANAS-X includes words like:“strong” ,“active”, “healthy”, “sleepy” which are not considered emotion words by psychology.  \n\nIf the authors stated goal is ""different than the standard sentiment analysis goal of predicting whether a sentence expresses positive or negative sentiment"" they should be aware that this is exactly what PANAS is designed to do - not to infer the latent emotional state of a person, except to the extent that their affect is positive or negative.\n\n\nThe work of representing emotions had been an field in psychology for over a hundred years and it is still continuing.  https://en.wikipedia.org/wiki/Contrasting_and_categorization_of_emotions.\n\nOne of the most popular theories of emotion is the theory that there exist “basic” emotions: Anger, Disgust, Fear, Happiness (enjoyment), Sadness and Surprise (Paul Ekman, cited by the authors).  These are short duration sates lasting only seconds.  They are also fairly specific, for example “surprise” is sudden reaction to something unexpected, which is it exactly the same as seeing a flower on your car and expressing “what a nice surprise.”  The surprise would be the initial reaction of “what’s that on my car?  Is it dangerous?” but after identifying the object as non-threatening, the emotion of “surprise” would likely pass and be replaced with appreciation.  \n\nThe Circumplex Model of Emotions (Posner et al 2005) the authors refer to actually stands in opposition to the theories of Ekman.  From the cited paper by Posner et al : \n""The circumplex model of affect proposes that all affective states arise from cognitive interpretations of core neural sensations that are the product of two independent neurophysiological systems. This model stands in contrast to theories of basic emotions, which posit that a discrete and independent neural system subserves every emotion.""\nFrom my reading of this paper, it is clear to me that the authors do not have a clear understanding of the current state of psychology’s view of emotion representation and this work would not likely contribute to a new understanding of the latent structure of peoples’ emotions.\n\nIn the PCA result, it is not ""clear"" that the first axis represents valence, as ""sad"" has a slight positive on this scale and ""sad"" is one of the emotions most clearly associated with negative valence.\n\nWith respect to the rest of the paper, the level of novelty and impact is ""ok, but not good enough.""  This analysis does not seem very different from Twitter analysis, because although Tumblr posts are allowed to be longer than Twitter posts, the authors truncate the posts to 50 characters.  Additionally, the images do not seem to add very much to the classification.  The authors algorithm also seems to be essentially a combination of two other, previously published algorithms.\n\nFor me the novelty of this paper was in its application to the realm of emotion theory, but I do not feel there is a contribution here.  This paper is more about classifying Tumblr posts according to emotion word hashtags than a paper that generates a new insights into emotion representation or that can infer latent emotional state. \n\n\n\n\n\n\n\n\n\n\n\n']","[20, -20, -70]","[60, 50, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges interesting ideas and findings in the paper, and mentions several positive aspects. However, they also point out significant weaknesses and areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and expresses appreciation for the work while suggesting improvements. They use phrases like 'I like this work' and 'I think authors should improve' which maintain a polite and professional tone. The reviewer balances positive feedback with areas for improvement, demonstrating a courteous approach to the review process."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the study, they also point out several limitations and criticisms. The reviewer states that the contribution from the RL perspective is limited, questions the authors' claims about psychological modeling, and suggests that comparing social network tags to expert questionnaires is too ambitious. However, the tone is not entirely negative, as the reviewer does mention some positive aspects like the 'interesting psychological analysis'. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout. They present their criticisms in a constructive manner, using phrases like 'I think' to soften their statements, and acknowledge the authors' efforts even when pointing out limitations. The reviewer maintains a balanced and objective tone, which contributes to the overall politeness of the review."", ""The sentiment score is -70 because the review is predominantly critical. The reviewer expresses strong criticism against the paper's main claims, points out inaccuracies in the use of psychological concepts, and questions the novelty and impact of the work. Phrases like 'strongest criticism', 'lack of novelty', and 'not good enough' indicate a negative sentiment. However, it's not entirely negative as the reviewer acknowledges some aspects as 'ok' and finds some novelty in the application. The politeness score is 20 because while the reviewer is critical, they maintain a professional and academic tone throughout. They provide detailed explanations for their criticisms and use phrases like 'from my reading' and 'for me' to soften some statements. The reviewer also acknowledges positive aspects, which adds to the politeness. However, the overall critical nature of the review prevents a higher politeness score.""]"
"['This paper describes AdvGAN, a conditional GAN plus adversarial loss. AdvGAN is able to generate adversarial samples by running a forward pass on generator. The authors evaluate AdvGAN on semi-white box and black box setting.\n\nAdvGAN is a simple and neat solution to for generating adversary samples. The author also reports state-of-art results.\n\nComment:\n\n1. For MNIST samples, we can easily find the generated sample is a mixture of two digitals. Eg, for digital 7 there is a light gray 3 overlap. I am wondering this method is trying to mixture several samples into one to generate adversary samples. For real color samples, it is harder to figure out the mixture.\n2. Based on mixture assumption, I suggest the author add one more comparison to other method, which is relative change from original image, to see whether AdvGAN is the most efficient model to generate the adversary sample (makes minimal change to original image).\n\n\n\n', ""The paper proposes a way of generating adversarial examples that fool classification systems.\nThey formulate it for a blackbox and a semi-blackbox setting (semi being, needed for training their own network, but not to generate new samples).\n\nThe model is a residual gan formulation, where the generator generates an image mask M, and (Input + M) is the adversarial example.\nThe paper is generally easy to understand and clear in their results.\nI am not awfully familiar with the literature on adversarial examples to know if other GAN variants exist. From this paper's literature survey, they dont exist. \nSo this paper is innovative in two parts:\n- it applies GANs to adversarial example generation\n- the method is a simple feed-forward network, so it is very fast to compute\n\nThe experiments are pretty robust, and they show that their method is better than the proposed baselines.\nI am not sure if these are complete baselines or if the baselines need to cover other methods (again, not fully familiar with all literature here).\n"", ""I thank the authors for the thoughtful response and rebuttal. The authors have substantially updated their manuscript and improved the presentation.\n\nRe: Speed. I brought up this point because this was a bulleted item in the Introduction in the earlier version of the manuscript. In the revised manuscript, this bullet point is now removed. I will take this point to be moot.\n\nRe: High resolution. The authors point to recent GAN literature that provides some first results with high resolution GANs but I do not see quantitative evidence in the high resolution setting for this paper. (Figure 4 provides qualitative examples from ImageNet but no quantitative assessment.)\n\nBecause the authors improved the manuscript, I upwardly revised my score to 'Ok but not good enough - rejection'. I am not able to accept this paper because of the latter point.\n==========================\n\nThe authors present an interesting new method for generating adversarial examples. Namely, the author train a generative adversarial network (GAN) to adversarial examples for a target network. The authors demonstrate that the network works well in the semi-white box and black box settings.\n\nThe authors wrote a clear paper with great references and clear descriptions.\n\nMy primary concern is that this work has limited practical benefit in a realistic setting. Addressing each and every concern is quite important:\n\n1) Speed. The authors suggest that training a GAN provides a speed benefit with respect to other attack techniques. The FGSM method (Goodfellow et al, 2015) is basically 1 inference operation and 1 backward operation. The GAN is 1 forward operation. Granted this results in a small difference in timing 0.06s versus 0.01s, however it would seem that avoiding a backward pass is a somewhat small speed gain.\n \nFurthermore, I would want to question the practical usage of having an 'even faster' method for generating adversarial examples. What is the reason that we need to run adversarial attacks 'even faster'? I am not aware of any use-cases, but if there are some, the authors should describe the rationales at length in their paper.\n\n2) High spatial resolution images. Previous methods, e.g. FGSM, may work on arbitrarily sized images. At best, GANs generate reasonable images that are lower resolutions (e.g. < 128x128). Building GAN's that operate above-and-beyond moderate spatial resolution is an open research topic. The best GAN models for generating high resolution images are  difficult to train and it is not clear if they would work in this setting. Furthermore, images with even higher resolutions, e.g. 512x512, which is quite common in ImageNet, are difficult to synthesizes using current techniques.\n\n3) Controlling the amount of distortion. A feature of previous optimization based methods is that a user may specify the amount of perturbation (epsilon). This is a key feature if not requirement in an adversarial perturbation because a user might want to examine the performance of a given model as a function of epsilon. Performing such an analysis with this model is challenging (i.e. retraining a GAN) and it is not clear if a given image generated by a GAN will always achieve a given epsilon perturbation/\n\nOn a more minor note, the authors suggest that generating a *diversity* of adversarial images is of practical import. I do not see the utility of being able to generate a diversity of adversarial images. The authors need to provide more justification for this motivation.""]","[70, 70, -50]","[60, 50, 50]","[""The sentiment score is 70 (positive) because the reviewer describes the paper's approach as 'a simple and neat solution' and mentions that it reports 'state-of-art results'. This indicates a generally positive view of the work. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions without harsh criticism. The reviewer uses phrases like 'I am wondering' and 'I suggest' which are polite ways to express thoughts and recommendations. The overall tone is professional and courteous, though not excessively formal or deferential."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper. They describe it as 'easy to understand and clear in their results', 'innovative', and note that the experiments are 'pretty robust'. The reviewer also highlights the paper's contributions and strengths. However, it's not a perfect score as the reviewer expresses some uncertainty about the completeness of the literature review and baselines.\n\nThe politeness score is 50 (slightly polite) because the reviewer maintains a professional and respectful tone throughout. They use neutral language and focus on the paper's content rather than making personal comments. The reviewer acknowledges their own limitations in knowledge ('I am not awfully familiar with the literature') which shows humility. However, the review doesn't go out of its way to be exceptionally polite or use particularly warm language, hence the moderate positive score."", ""The sentiment score is -50 because while the reviewer acknowledges improvements in the manuscript and describes the paper as 'interesting' with 'clear descriptions', they ultimately recommend rejection due to unaddressed concerns. The overall tone is mixed, with positive elements but a negative conclusion. The politeness score is 50 because the reviewer uses respectful language throughout, thanking the authors for their response and using phrases like 'I thank the authors' and 'The authors wrote a clear paper'. However, the critique is direct and doesn't use overly deferential language, keeping it from scoring higher on politeness. The reviewer maintains a professional tone while clearly stating their concerns and reasons for rejection.""]"
"['This paper presents a procedure to efficiently do K-shot learning in a classification setting by creating informative priors from information learned from a large, fully labeled dataset.  Image features are learned using a standard convolutional neural network---the last layer form image features, while the last set of weights are taken to be image ""concepts"".  The method treats these weights as data, and uses these data to construct an informative prior over weights for new features.\n\n- Sentence two: would be nice to include a citation from developmental psychology.\n\n- Probabilistic modeling section: treating the trained weights like ""data"" is a good way to convey intuition about your method.  It might be good to clarify some specifics earlier on in the ""Probabilistic Modeling"" paragraph, e.g. how many ""observations"" are associated with this matrix. \n \n- In the second phase, concept transfer, is the only information from the supervised weights the mean and estimated covariance?  For instance, if there are 80 classes and 256 features from the supervised phase, the weight ""data"" model is 80 conditionally IID vectors of length 256 ~ Normal(\\mu, \\Sigma).  The posterior MAP for \\mu and \\Sigma are then used as a prior for weights in the K-shot task.  How many parameters are estimated for \n\n  * gauss iso: mu = 256-length vector, \\sigma = scalar variance value of weights\n  * log reg: mu = 256-length zero vector, \\sigma = scalar variance value of weights\n  * log reg cross val: mu = 256-length zero vector, \\sigma = cross validated value\n\nIf the above is correct, the information boosts K-shot accuracy is completely contained in the 256-length posterior mean vector and the scalar weight variance value?\n\n- Is any uncertainty about \\mu_MAP or \\Sigma_MAP propagated through to uncertainty in the K-shot weights?  If not, would this influence the choice of covariance structure for \\Sigma_MAP? How sensitive are inferences to the choice of Normal inverse-Wishart hyper parameters? \n\n- What do you believe is the source of the mis-calibration in the ""predictied probability vs. proportion of times correct"" plot in Figure 2?  \n\nTechnical: The method appears to be technically correct.\n\nClarity: The paper is pretty clearly written, however some specific details of the method are difficult to understand.\n\nNovel: I am not familiar with K-shot learning tasks to assess the novelty of this approach. \n\nImpact: While the reported results seem impressive and encouraging, I believe this a relatively incremental approach. ', 'Authors present a k-shot learning method that is based on generating representations with a pre-trained network and learning a regularized logistic regression using the available data.  The regularised regression is formulated as a MAP estimation problem with the prior estimated from the weights of the original network connected final hidden layer to the logits — before the soft-max layer.  \n\nThe motivation of the article regarding “concepts” is interesting.  It seems especially justified when the training set that is used to train the original network has similar objects as the smaller set that is used for k-shot learning.  Maps shown in Figures 6 and 7 provide good motivation for this approach. \n\nDespite the strong motivation, the article raises some concerns regarding the method. \n1. The assumption about independence of w vectors across classes is a very strong one and as far as I can see, it does not have a sound justification.  The original networks are trained to distinguish between classes.  The weight vectors are estimated with this goal. Therefore, it is very likely that vectors of different classes are highly correlated. Going beyond this assumption also seems difficult.  The proposed model estimates $\\theta^{MAP}$ using only one W matrix, the one that is estimated by training the original network in the most usual way.  In this case, the prior over $\\theta$ would have a large influence on the MAP estimate and setting it properly becomes important.  As far as I can see, there is no good recipe presented in the article for setting this prior. \n2. How is the prior model defined?  It is the most important component of the method while precise details are not provided.  How are the hyperparameters set?  Furthermore, this detail needs to be in the main text. \n3. With the isotropic assumption on the covariance matrix, the main difference between logistic regression, which is regularized by L2 norm and coefficient set proportional to the empirical variance, and the proposed method seems to be the mean vector $\\mu^{MAP}$.  From the details provided in the appendix — which should be in the main text in my opinion — I believe this vector is a combination of the prior and mean of w_c across classes.  If the prior is set to 0, how different is this vector from 0?  Authors should focus on this in my opinion to explain why methods work differently in 1-shot learning.  In the other problems, the results suggest they are pretty much the same. \n4. Authors’ motivation about concepts is interesting however, if the model bases its prediction on mean of w_c vectors over classes, then I am not sure if authors really achieve what they motivate for.  \n5. Results are not very convincing.  If the method was substantially different than baseline, I believe this would have been no problem.  Given the proximity of the proposed method to the baseline with regularised logistic regression, lack of empirical advantage is an issue.  If the proposed model works better in the 1-shot scenario, then authors should delve into it to explain the advantage. \n\nMinor comments: \nEvaluation in an online setting section is unclear.  It needs to be rewritten in my opinion. ', 'The authors introduce a probabilistic k-shot learning model based on previous training of a CNN on a large dataset. The weights of the softmax layer of the CNN are then used as the MAP solution in a concept learning scenario to put a prior over the soft-max weights of the classifier (logistic regression) for the dataset with k-shot examples. The model is compared against other models for doing k-shot learning in miniImageNet, and against different versions of the same model for CIFAR-100.\n\nThe paper introduces a very simple idea that allows transfer knowledge from a network trained with a large-dataset to a network-trained with a smaller amount of data, the data with k-shot examples per class. This is not a general way to do k-shot learning, because it heavily depends on the availability of the large dataset where the weights of the soft-max function can be extracted. But it seems to work for natural image data. \n\nHow many data observations are necessary to estimate \\widetilde{W}_{MAP} such that it is still possible to obtain superior performance in the k-shot learning problem? Did you try the methods of Table 1 for CIFAR-100? The experiments on this dataset use models that are variations of the same proposed model. \n']","[50, -50, 50]","[75, 20, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as presenting an efficient procedure for K-shot learning and having technically correct methods. The reviewer also mentions that the results seem impressive and encouraging. However, they also point out areas for improvement and clarification, and describe the approach as 'relatively incremental,' which tempers the overall positivity.\n\nThe politeness score is 75 (quite polite) because the reviewer uses respectful and constructive language throughout. They offer suggestions for improvement using phrases like 'would be nice to include,' 'it might be good to clarify,' and asking thoughtful questions about the methodology. The reviewer also balances critique with praise, acknowledging the paper's strengths alongside areas for improvement. There are no rude or harsh comments, and the tone remains professional and supportive throughout."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('strong motivation', 'interesting' concept), they express several significant concerns about the method and results. The review lists 5 major concerns, indicating a generally negative sentiment towards the paper's execution and findings. The politeness score is 20 because the reviewer uses respectful language throughout, acknowledging positive aspects before critiquing, and phrases criticisms as concerns rather than outright dismissals. They also offer constructive suggestions for improvement. However, the tone remains professional rather than overtly polite, hence the moderate positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contribution as a 'very simple idea' that works for natural image data, while also pointing out limitations. The tone is generally appreciative of the work, but not overly enthusiastic. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, asks questions for clarification rather than making accusations, and provides balanced feedback. The reviewer acknowledges both strengths and limitations of the work without using harsh or dismissive language.""]"
"[""The authors propose a variational auto encoder architecture to generate graphs.  \n\nPros:\n- the formulation of the problem as the modeling of a probabilistic graph is of interest \n- some of the main issues with graph generation are acknowledged (e.g. the problem of invariance to node permutation) and a solution is proposed (the binary assignment  matrix)\n- notions for measuring the quality of the output graphs are of interest: here the authors propose some ways to use domain knowledge to check simple properties of molecular graphs \n\nCons: \n- the work is quite preliminary\n- many crucial elements  in graph generation are not dealt with: \n a) the adjacency matrix and the label tensors are not independent of each other, the notion of a graph is in itself a way to represent the 'relational links' between the various components\n b) the boundaries between a feasible and an infeasible graph are sharp: one edge or one label can be sufficient for acting the transition independently of the graph size, this makes it a difficult task for a continuous model. The authors acknowledge this but do not offer ways to tackle the issue\n c) conditioning on the label histogram should make the problem easy: one is giving away the number of nodes and the label identities after all; however even in this setup the approach fails more often than not \n d) the graph matching procedure proposed is a rough patch for a much deeper problem\n- the evaluation should include a measure of the capacity of the architecture to :\n a) reconstruct perfectly the input\n b) denoise perturbations over node labels and additional/missing  edges  "", 'This work proposed an interesting graph generator using a variational autoencoder. The work should be interesting to researchers in the various areas. However, the work can only work on small graphs. The search space of small graph generation is usually very small, is there any other traditional methods can work on this problem? Moreover, the notations are a little confusing.  ', 'This paper studies the problem of learning to generate graphs using deep learning methods. The main challenges of generating graphs as opposed to text or images are said to be the following:\n(a) Graphs are discrete structures, and incrementally constructing them would lead to non-differentiability (I don\'t agree with this; see below)\n(b) It\'s not clear how to linearize the construction of graphs due to their symmetries. Based on this motivation, the paper decides to generate a graph in ""one shot"", directly  outputting node and edge existence probabilities, and node attribute vectors.\n\nA graph is represented by a soft adjacency matrix A (entries are probability of existence of an edge), an edge attribute tensor E (entries are probability of each edge being one of d_e discrete types), and a node attribute matrix F, which has a node vector for each  potential node. A cross entropy loss is developed to measure the loss between generated A, E, and F and corresponding targets.\n\nThe main issue with training models in this formulation is the alignment of the generated graph to the ground truth graph. To handle this, the paper proposes to use a simple graph  matching algorithm (Max Pooling Matching) to align nodes and edges. A downside to the algorithm is that it has complexity O(k^4) for graphs with k nodes, but the authors argue that this is not a problem when generating small graphs. Once the best correspondence is found, it is treated as constant and gradients are propagated appropriately.\n\nExperimentally, generative models of chemical graphs are trained on two datasets. Qualitative results and ELBO values are reported as the dimensionality of the embeddings is varied. No baseline results are presented. A further small set of experiments evaluates the quality of the matching algorithm on a synthetic setup.\n\nStrengths:\n- Generating graphs is an interesting problem, and the proposed approach seems like an easy-to-implement, mostly reasonable way of approaching the problem.\n\n- The exposition is clear (although a bit more detail on MPM matching would be appreciated)\n\nHowever, there are some significant weaknesses. First, the motivation for one-shot graph construction is not very strong:\n\n- I don\'t understand why the non-differentiability argued in (a) above is an issue. If training uses a maximum likelihood objective, then we should be able to decompose the generation of a graph into a sequence of decisions and maximize the sum of the logprobs of the conditionals. People do this all the time with sequence data and non-differentiability is not an issue.\n\n- I also don\'t agree that the one shot graph construction sidesteps the issue of how to linearize the construction of a graph. Even after doing so, the authors need to solve a matching problem to resolve the alignment issue. I see this as equivalent to choosing an order in which to linearize the order of nodes and edges in the graph.\n\nSecond, the experiments are quite weak. No baselines are presented to back up the claims motivating the formulation. I don\'t know how to interpret whether the results are good or bad. I would have at least liked to see a comparison to a method that generated SMILES format in an autoregressive manner (similar to previous work on chemical graph generation), and would ideally have liked to see an attempt at solving the alignment problem within an autoregressive formulation (e.g., by greedily constructing the alignment as the graph was generated). If one is willing to spend O(k^4) computation to solve the alignment problem, then there seem like many possibilities that could be easily applied to the autoregressive formulation. The authors might also be interested in a concurrent ICLR submission that approaches the problem from an autoregressive angle (https://openreview.net/pdf?id=Hy1d-ebAb). \n\nFinally, I would have expected to see a discussion and comparison to ""Learning Graphical State Transitions"" (Johnson, 2017). Please also don\'t make statements like ""To the best of our knowledge, we are the first to address graph generation using deep learning."" This is very clearly not true. Even disregarding Johnson (2017), which the authors claim to be unaware of, I would consider approaches that generate SMILES format (like Gomez-Bombarelli et al) to be doing graph generation using deep learning.\n\nOverall, the paper is about an interesting subject, but in my opinion the execution isn\'t strong enough to warrant publication at this point.\n']","[-30, -20, -60]","[50, 50, 50]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('pros') of the work, the 'cons' section is more extensive and points out several significant issues. The reviewer describes the work as 'quite preliminary' and lists multiple crucial elements that are not adequately addressed. This indicates a generally negative sentiment, though not extremely so due to the recognition of some positive aspects. The politeness score is 50 because the reviewer maintains a professional and objective tone throughout, presenting both pros and cons without using harsh language. The reviewer acknowledges the authors' efforts and uses phrases like 'of interest' when discussing positive aspects. Even when pointing out limitations, the language remains constructive rather than critical, suggesting a polite approach to feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'interesting', they raise several concerns and limitations. The reviewer points out that the method only works on small graphs, questions if traditional methods could solve the problem, and mentions confusion with notations. These criticisms outweigh the initial positive comment, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses polite language throughout. They start with a positive comment, use phrases like 'interesting' and 'should be interesting to researchers', and frame criticisms as questions or observations rather than direct attacks. The tone is professional and constructive, avoiding harsh or rude language."", ""The sentiment score is -60 because the review is overall negative. The reviewer points out several significant weaknesses in the paper, including weak motivation for the approach, lack of baselines in experiments, and inaccurate claims about novelty. The reviewer concludes that the paper isn't strong enough for publication. However, the score isn't extremely negative because the reviewer does acknowledge some strengths, like the interesting problem and clear exposition. The politeness score is 50 because the reviewer uses professional and respectful language throughout, even when criticizing. They use phrases like 'I don't agree' and 'I would have expected' rather than harsh or dismissive language. The reviewer also acknowledges the paper's strengths before discussing weaknesses, which is a polite approach. However, the score isn't extremely high because the criticism, while politely phrased, is quite direct and extensive.""]"
"[""Summary: This paper explores how to handle two practical issues in reinforcement learning. The first is including time remaining in the state, for domains where episodes are cut-off before a terminal state is reached in the usual way. The second idea is to allow bootstrapping at episode boundaries, but cutting off episodes to facilitate exploration. The ideas are illustrated through several well-worked micro-world experiments.\n\nOverall the paper is well written and polished. They slowly worked through a simple set of ideas trying to convey a better understanding to the reader, with a focus on performance of RL in practice.\n\nMy main issue with the paper is that these two topics are actually not new and are well covered by the existing RL formalisms. That is not to say that an empirical exploration of the practical implications is not of value, but that the paper would be much stronger if it was better positioned in the literature that exists.\n\nThe first idea of the paper is to include time-remaining in the state. This is of course always possible in the MDP formalism. If it was not done, as in your examples, the state would not be Markov and thus it would not be an MDP at all. In addition, the technical term for this is finite horizon MDPs (in many cases the horizon is taken to be a constant, H). It is not surprising that algorithms that take this into account do better, as your examples and experiments illustrate. The paper should make this connection to the literature more clear and discuss what is missing in our existing understanding of this case, to motivate your work. See Dynamic Programming and Optimal Control and references too it.\n\nThe second idea is that episodes may terminate due to time out, but we should include the discounted value of the time-out termination state in the return. I could not tell from the text but I assume, the next transition to the start state is fully discounted to zero, otherwise the value function would link the values of S_T and the next state, which I assume you do not want. The impact of this choice is S_T is no longer a termination state, and there is a direct fully discounted transition to the start states. This is in my view is how implementations of episodic tasks with a timeout should be done and is implemented this way is classic RL frameworks (e.g., RL glue). If we treat the value of S_T as zero or consider gamma on the transition into the time-out state as zero, then in cost to goal problems the agent will learn that these states are good and will seek them out leading to suboptimal behavior. The literature might not be totally clear about this, but it is very well discussed in a recent ICML paper: White 2017 [1]\n\nAnother way to pose and think about this problem is using the off-policy learning setting---perhaps best described in the Horde paper [2]. In this setting the behavior policy can have terminations and episodes in the classic sense (perhaps due to time outs). However, the agent's continuation function (gamma : S -> [0,1]) can specify weightings on states representing complex terminations (or not), completely independent of the behavior policy or actual state transition dynamics of the underlying MDP. To clearly establish your contributions, the authors must do a better job of relating their work to [1] and [2].\n\n[1] White. Unifying task specification in reinforcement learning. Martha White. International Conference on Machine Learning (ICML), 2017.\n\n[2] Sutton, R. S., Modayil, J., Delp, M., Degris, T., Pilarski, P. M., White, A., & Precup, D. (2011). Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction. In The 10th International Conference on Autonomous Agents and Multiagent Systems: 2, 761--768. \n\nSmall comments that did not impact paper scoring:\n1) eq 1 we usually don't use the superscript \\gamma\n2) eq2, usually we talk about truncated n-step returns include the value of the last state to correct the return. You should mention this\n3) Last paragraph of page 2 should not be in the intro\n4) in section 2.2 why is the behavior policy random instead of epsilon greedy?\n5) It would be useful to discuss the average reward setting and how it relates to your work.\n6) Fig 5. What does good performance look like in this domain. I have no reference point to understand these graphs\n7) page 9, second par outlines alternative approaches but they are not presented as such. Confusing "", 'The majority of the paper is focused on the observation that (1) making policies that condition on the time step is important in finite horizon problems, and a much smaller component on that (2) if episodes are terminated early during learning (say to restart and promote exploration) that the values should be bootstrapped to reflect that there will be additional rewards received in the true infinite-horizon setting.\n\n1 is true and is well known. This is typically described as finite horizon MDP planning and learning and the optimal policy is well known to be nonstationary and depend on the number of remaining time steps. There are a number of papers focusing on this for both planning and learning though these are not cited in the current draft. \n\nI don’t immediately know of work that suggests bootstrapping if an episode is terminated early artificially during training but it seems a very reasonable and straightforward thing to do. \n\n', ""This paper considers the problem of Reinforcement Learning in time-limited domains. It begins by observing that in time-limited domains, an agent unaware of the remaining time can experience state-aliasing. To combat this problem, the authors suggest modifying the state representation of the policy to include an indicator of the amount of remaining time. The time-aware agent shows improved performance in a time-limited gridworld and several control domains. Next, the authors consider the problem of learning a time-unlimited policy from time-limited episodes. They show that by bootstrapping from the final state of the time-limited domain, they are able to learn better policies for the time-unlimited case.\n\nPros:\nThe paper is well-written and clear, if a bit verbose. \nThe paper has extensive experiments in a variety of domains.\n\nCons:\nIn my opinion, the substance of the contribution is not enough to warrant a full paper and the problem of time-limited learning is not well motivated: \n\n1) It's not clear how frequently RL agents will encounter time-limited domains of interest. Currently most domains are terminated by failure/success conditions rather than time. The author's choice of tasks seem somewhat artificial in that they impose time limits on otherwise unlimited domains in order to demonstrate experimental improvement. Is there good reason to think RL agents will need to contend with time-limited domains in the future? \n\n2) The inclusion of remaining-time as a part of the agent's observations and resulting improvement in time-limited domains is somewhat obvious. It's well accepted that in any partially observed domain, inclusion of the latent variable(s) as a part of the agent's observation will result in a fully observed domain, less state-aliasing, more accurate value estimates, and better performance. The author's inclusion of the latent time variable as a part of the agent's observations reconfirms this well-known fact, but doesn't tell us anything new.\n\n3) I have the same questions about Partial Episode bootstrapping: Is there a task in which we find our RL agents learning in time-limited settings and then evaluated in unlimited ones? The experiments in this direction again feel somewhat contrived by imposing time limits and then removing them. The proposed solution of bootstrapping from the value of the terminal state v(S_T) clearly works, and I suspect that any RL-practitioner faced with training time-limited policies that are evaluated in time-unlimited settings might come up with the same solution. While the experiments are well done, I don't think the substance of the algorithmic improvement is enough.\n\nI think this paper would improve by demonstrating how time-aware policies can help in domains of interest (which are usually not time-limited). I could imagine a line of experiments that investigate the idea of selectively stopping episodes when the agent is no longer experiencing useful transitions, and then showing that the partial episode bootstrapping can save on overall sample complexity compared to an agent that must experience the entirety of every episode.  ""]","[-20, -20, -50]","[60, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is 'well written and polished', they express significant concerns about the novelty of the ideas presented and how the work is positioned within existing literature. The reviewer states 'My main issue with the paper is that these two topics are actually not new and are well covered by the existing RL formalisms.' This critique forms the core of the review and suggests substantial revisions are needed. However, the tone is not entirely negative, as the reviewer does see some value in the empirical exploration. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges positive aspects of the paper, and frames criticisms constructively. They use phrases like 'the paper would be much stronger if...' and provide specific suggestions for improvement. The reviewer also offers detailed explanations for their critiques and provides relevant references, which is helpful and courteous to the authors."", ""The sentiment score is slightly negative (-20) because the reviewer points out that the main focus of the paper (point 1) is 'well known' and not novel. They also mention that the second point, while reasonable, seems straightforward. This implies that the paper's contributions are limited. However, the tone is not entirely dismissive, as the reviewer acknowledges the validity of the points made.\n\nThe politeness score is moderately positive (50) because the reviewer uses neutral and professional language throughout. They avoid harsh criticism and use phrases like 'I don't immediately know of work...' which shows a willingness to consider the authors' perspective. The reviewer also describes the second point as 'very reasonable', which is a polite way of acknowledging its merit. The overall tone is constructive rather than confrontational."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('well-written', 'clear', 'extensive experiments'), they express significant concerns about the paper's contribution and motivation. The cons outweigh the pros, with the reviewer stating that 'the substance of the contribution is not enough to warrant a full paper'. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positives before presenting criticisms, and offering constructive suggestions for improvement. They use phrases like 'in my opinion' and 'I think' to soften their criticisms. However, the review doesn't go out of its way to be overly polite, maintaining a professional tone.""]"
"['This paper propose a simple extension of the adversarial auto-encoders for (conditional) image generation. The general idea is that instead of using Gaussian prior, the propose algorithm uses a ""code generator"" network  to warp the gaussian distribution, such that the internal prior of the latent encoding space is more expressive and complicated. \n\nPros:\n- The proposed idea is simple and easy to implement\n- The results show improvement in terms of visual quality\n\nCons:\n- I agree that the proposed prior should better capture the data distribution. However, incorporating a generic prior over the latent space plays a vital role as regularisation, this helps avoid model collapse. Adding a complicated code generation network brings too much flexibility for the prior part. This makes the prior and posterior learnable, which makes it easier to fool the regularisation discriminator (think about the latent code and prior code collapsed to two different points). As a result, this weakens the regularisation over the latent encoder space.  \n- The above mentioned could be verified through qualitative results. As shown in Fig. 5. I believe this is a result due to the fact that the adversarial loss in the regularisation phase does not a significant influence there. \n- I have some doubts over why AAE works so poorly when the latent dimension is 2000. How to make sure it\'s not a problem of implementation or the model wasn\'t trapped into a bad local optima / saddle points. Could you justify this?\n- Contributions; this paper propose an improvement over a existing model. However, neither the idea/insights it brought can be applied onto other generative models, nor the improvement bring a significant improvement over the-state-of-the-arts. I am wondering what the community will learn from this paper, or what the author would like to claim as significant contributions. ', 'Recently some interesting work on a role of prior in deep generative models has been presented. The choice of prior may have an impact on the expressiveness of the model [Hoffman and Johnson, 2016]. A few existing work presents methods for learning priors from data for variational autoencoders [Goyal et al., 2017][Tomczak and Welling, 2017].  The work, ""VAE with a VampPrior,"" [Tomczak and Welling, 2017] is missing in references.\n\nThe current work focuses on adversarial autoencoder (AAE) and introduces a code generator network to transform a simple prior into one that together with the generator can better fit the data distribution. Adversarial loss is used to train the code generator network, allowing the output of the network could be any distribution. I think the method is quite simple but interesting approach to improve AAEs without hurting the reconstruction. The paper is well written and is easy to read. The method is well described. However, what is missing in this paper is an analysis of learned priors, which help us to better understand its behavior. \n\nThe model is evaluated qualitatively only. What about quantitative evaluation? \n\n', ""This paper proposes an interesting idea--to learn a flexible prior from data by maximizing data likelihood.\n\nIt seems that in the prior improvement stage, what you do is training a GAN with CG+dec as the generator while D_I as the discriminator (since you also update dec at the prior improvement stage). So it can also be regarded as GAN trained with an additional enc and D_c, and additional objective. In my opinion, this may explain why your model can generate sharper images.\n\nThe experiments do demonstrate the power of their model compared to AAE. However, only the qualitative analysis may not persuade me and more thorough analysis is needed.\n\n1. About the latent space for z. The motivation in AAE is to impose aggregated posterior regularization $D(q(z),p(z))$ where $p(z)$ is chosen as a simple one, e.g., Gaussian. I'm curious how the geometry of the latent space will be, when the code generator is introduced. Maybe some visualization like t-sne will be helpful.\n2. Any quantitative analysis? Doing a likelihood analysis like that in the AAE paper will be very informative. \n""]","[-30, 50, 50]","[50, 75, 70]","[""The sentiment score is -30 because while the reviewer acknowledges some pros (simple idea, easy implementation, improved visual quality), they express significant concerns about the method's effectiveness and contributions. The cons outweigh the pros, indicating a slightly negative sentiment. The politeness score is 50 because the reviewer uses professional and respectful language throughout, presenting their concerns as observations and questions rather than harsh criticisms. They use phrases like 'I agree,' 'I believe,' and 'I am wondering,' which maintain a polite tone while expressing doubts. The review is constructive and balanced, avoiding overly negative or confrontational language."", ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the work as 'interesting' and 'well written', and appreciates the simplicity of the approach. However, they also point out some missing elements, which prevents a higher score. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. They use phrases like 'I think' to soften their opinions and frame suggestions as questions rather than demands. The reviewer maintains a professional and courteous tone while providing feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper's idea as 'interesting' and acknowledges that the experiments 'demonstrate the power of their model'. However, they also express some reservations and request more thorough analysis, indicating a balanced view. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'more thorough analysis is needed'), and offers suggestions for improvement rather than harsh criticism. The use of phrases like 'I'm curious' and 'Maybe some visualization... will be helpful' further contribute to the polite tone.""]"
"['I personally warmly welcome any theoretically grounded methods to perform deep learning. I read the paper with interest, but I have two concerns about the main theoretical result (Theorem 1, lifelong learning PAC-Bayes bound).\n* Firstly, the bound is valid for a [0,1]-valued loss, which does not comply with the losses used in the experiments (Euclidean distance and cross-entropy). This is not a big issue, as I accept that the authors are mainly interested in the learning strategy promoted by the bound. However, this should clearly appear in the theorem statement.\n* Secondly, and more importantly, I doubt that the uaw of the meta-posterior as a distribution over priors for each task is valid. In Proposition 1 (the classical single-task PAC-Bayes bound), the bound is valid with probability 1-delta for one specific choice of prior P, and this choice must be independent of the learning sample S. However, it appears that the bound should be valid uniformly for all P in order to be used in Theorem 1 proof (see Equation 18). From a learning point of view, it seems counterintuitive that the prior used in the KL term to learn from a task relies on the training samples (i.e., the same training samples are used to learn the meta-posterior over priors, and the task specific posterior).  \n\nA note about the experiments:\nI am slightly disappointed that the authors compared their algorithm solely with methods learning from fewer tasks. I would like to see the results obtained by another method using five tasks. A simple idea would be to learn a network independently for each of the five tasks, and consider as a meta-prior an isotropic Gaussian distribution centered on the mean of the five learned weight vectors.\n\nTypos and minor comments:\n- Equation 1: \\ell is never explicitly defined.\n- Equation 4: Please explicitly define m in this context (size of the learning sample drawn from tau).\n- Page 4, before Equation 5: A dot is missing between Q and ""This"".\n- Page 7, line 3: Missing parentheses around equation number 12.\n- Section 5.1.1, line 5: ""The hypothesis class is a the set of...""\n- Equation 17: Q_1, ... Q_n are irrelevant.\n\n=== UPDATE ===\nI increased my score after author\'s rebuttal. See my other post.', 'The paper considers multi-task setting of machine learning. The first contribution of the paper is a novel PAC-Bayesian risk bound. This risk bound serves as an objective function for multi-task machine learning. A second contribution is an algorithm, called LAP, for minimizing a simplified version of this objective function. LAP algorithm uses several training tasks to learn a prior distribution P over hypothesis space. This prior distribution P is then used to find a posterior distribution Q that minimizes the same objective function over the test task. The third contribution is an empirical evaluation of LAP over toy dataset of two clusters and over MNIST.\n\nWhile the paper has the title of ""life-long learning"", the authors admit that all experiments are in multi-task setting, where\nthe training is done over all tasks simultaneously. The novel risk bound and LAP algorithm can definitely be applied to life-long setting, where training tasks are available sequentially. But since there is no empirical evaluation in this setting, I suggest to adjust the title of the paper. \n \nThe novel risk bound of the paper is an extension of the bound from [Pentina & Lampert, ICML 2014]. The extension seems to be quite significant. Unlike the bound of [Pentina & Lampert, ICML 2014], the new bound allows to re-use many different PAC-Bayesian complexity terms that were published previously. \n\nI liked risk bound and optimization sections of the paper. But I was less convinced by the empirical experiments. Since \nthe paper improves the risk bound of [Pentina & Lampert, ICML 2014], I expected to see an empirical comparison of LAP and optimization  algorithm from the latter paper. To make such comparison fair, both optimization algorithms should use the same base algorithm, e.g. ridge regression, as in [Pentina & Lampert, ICML 2014]. Also I suggest to use the datasets from the latter paper.  \n\nThe experiment with multi-task learning over MNIST dataset looks interesting, but it is still a toy experiment. This experiment  will be more convincing with more sophisticated datasets (CIFAR-10, ImageNet) and architectures (e.g. Inception-V4, ResNet). \n\nMinor remarks:\nSection 6, line 4: ""Combing"" -> ""Combining""\nPage 14, first equation: There should be ""="" before the second expectation.', 'The author extends existing PAC-Bayes bounds to multi-task learning, to allow the prior to be adapted across different tasks. Inspired by the variational bayes literature, a probabilistic neural network is used to minimize the bound. Results are evaluated on a toy dataset and a synthetically modified version of MNIST. \n\nWhile this paper is well written and addresses an important topic, there are a few points to be discussed:\n\n* Experimental results are really week. The toy experiment only compares the mean of two gaussians. Also, on the synthetic MNIST experiments, no comparison is done with any external algorithms. Neural Statistician, Model-Agnostic Meta-Learning and matching networks all provide decent results on such setup. While it is tolerated to have minimal experiments in a theoretical papers, the theory only extends Pentina & Lampert (2014). Also, similar algorithms can be obtain through variational-bayes evidence lower bound. \n\n* The bound appears to be sub-optimal. A bound where the KL term vanishes by 1/n would probably be tighter. I went in appendix to try to see how the proof could be adapted but it’s definitively not as well written as the rest of the paper. I’m not against putting proofs in appendix but only when it helps clarity. In this case it did not.\n\n* The paper is really about multi-task learning. Lifelong learning implies some continual learning and addressing the catastrophic forgetting issues. I would recommend against overuse of the lifelong learning term.\n\nMinors:\n* Define KLD\n* Section 5.1 : “to toy”\n* Section 5.1.1: “the the”\n']","[-20, 20, -30]","[60, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer starts by warmly welcoming the approach, they express two significant concerns about the main theoretical result and disappointment with the experimental comparisons. However, it's not deeply negative as they show interest and provide constructive feedback. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, starting with a warm welcome and using phrases like 'I read the paper with interest' and 'I accept that the authors are mainly interested in...'. They also provide specific, constructive feedback and even suggest improvements, which is polite in academic contexts. The language is professional and courteous, even when expressing concerns."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and expresses interest in certain aspects ('I liked risk bound and optimization sections'). However, they also express some reservations and suggest improvements, indicating a mixed but generally positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and makes suggestions rather than demands ('I suggest to adjust the title', 'I suggest to use the datasets'). The reviewer also acknowledges positive aspects before offering critiques, which is a polite approach. The language is professional and courteous, avoiding any harsh or rude expressions."", ""The sentiment score is -30 because while the reviewer acknowledges that the paper is well-written and addresses an important topic, they express several significant concerns about the experimental results, the optimality of the bound, and the use of terminology. These criticisms outweigh the initial positive comments, resulting in a slightly negative overall sentiment. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positive aspects before presenting criticisms, and phrases their concerns as points for discussion rather than outright flaws. They also offer constructive suggestions for improvement. However, the directness of some criticisms (e.g., 'Experimental results are really week') prevents a higher politeness score.""]"
"['This paper studies off-policy learning in the bandit setting. It develops a new learning objective where the empirical risk is regularized by the squared Chi-2 divergence between the new and old policy. This objective is motivated by a bound on the empirical risk, where this divergence appears. The authors propose to solve this objective by using generative adversarial networks for variational divergence minimization (f-GAN). The algorithm is then evaluated on settings derived from supervised learning tasks and compared to other algorithms.\n\nI find the paper well written and clear. I like that the proposed method is both supported by theory and empirical results. \n\nMinor point: I do not really agree with the discussion on the impact of the stochasticity of the logging policy in section 5.6. Based on Figure 5 a and b, it seems that the learned policy is performing equally well no matter how stochastic the logging policy is. So I find it a bit misleading to suggest that the learned policy are not being improved when the logging policy is more deterministic. Rather, the gap reduces between the two policies because the logging policy gets better. In order to better showcase this mechanism, perhaps you could try using a logging policy that does not favor the best action.\n\nquality and clarity:\n++ code made available\n+ well written and clear\n- The proof of theorem 2 is not in the paper nor appendix (the authors say it is similar to another work).\n\n\noriginality\n+ good extension of the work by Swaminathan & Joachims (2015a): derivation of an alternative objective and use of a deep networks\n. This paper leverages a set of diverse results\n\nsignificance\n- The proposed method can only be applied if propensity scores were recorded when the data was generated.\n- no test on a real setting\n++ The proposed method is supported both by theoretical insights and empirical experiments.\n+ empirical improvement with respect to previous methods\n\n\ndetails/typos:\n\n3.1, p3: R^(h) has an indexed parenthesis\n5.2; and we more details\n5.3: so that results more comparable', 'The paper proposes an interesting alternative to recent approaches to learning from logged bandit feedback, and validates their contribution in a reasonable experimental comparison. The clarity of writing can be improved (several typos in the manuscript, notation used before defining, missing words, poorly formatted citations, etc.).\nImplementing the approach using recent f-GANs is an interesting contribution and may spur follow-up work. There are several lingering concerns about the approach (detailed below) that detract from the quality of their contributions.\n\n[Major] In Lemma 1, L(z) is used before defining it. Crucially, additional assumptions on L(z) are necessary (e.g. |L(z)| <= 1 for all z. If not, a trivial counter-example is: set L(z) >> 1 for all z and Lemma 1 is violated). It is unclear how crucially this additional assumption is required in practice (their expts with Hamming losses clearly do not satisfy such an assumption).\n\n[Minor] Typo: Section 3.2, first equation; the integral equals D_f(...) + 1 (not -1).\n\n[Crucial!] Eqn10: Expected some justification on why it is fruitful to *lower-bound* the divergence term, which contributes to an *upper-bound* on the true risk.\n\n[Crucial!] Algorithm1: How is the condition of the while loop checked in a tractable manner?\n\n[Minor] Typos: Initilization -> Initialization, Varitional -> Variational\n\n[Major] Expected an additional ""baseline"" in the expts -- Supervised but with the neural net policy architecture (NN approaches outperforming Supervised on LYRL dataset was baffling before realizing that Supervised is implemented using a linear CRF).\n\n[Major] Is there any guidance for picking the new regularization hyper-parameters (or at least, a sensible range for them)?\n\n[Minor] The derived bounds depend on M, an a priori upper bound on the Renyi divergence between the logging policy and any new policy. It\'s unclear that such a bound  can be tractably guessed (in contrast, prior work uses an upper bound on the importance weight -- which is simply 1/(Min action selection prob. by logging policy) ).', ""In this paper the authors studied the problem of off-policy learning, in the bandit setting when a batch log of data generated by the baseline policy is given. Here they first summarize the surrogate objective functions derived by existing approaches such as importance sampling and variance regularization (Swaminathan et. al). Then they extend the results in Theorem 2 of the paper by Cortes et. al (which also uses the empirical Bernstein inequality by Maurer and Pontil), and derive a new surrogate objective function that involves the chi-square divergence. Furthermore, the authors also show that the lower bound of this objective function can be iteratively approximated by variational f-GAN techniques, which could potentially be more numerically stable and empirically has lower variance. \n\nIn general, I think the problem studied in this paper is very interesting, and the topic of counterfactual learning, especially policy optimization with the use of offline and off-policy log data, is important. However, I think the theoretical contribution in this paper on off-policy learning is quite incremental. Also the parts that involve f-GAN is still questionable to me.\n\nDetailed comments:\nIn these variance regularization formulations (for example the one proposed in this paper, or the one derived in Swaminathan's paper), \\lambda can be seen as a regularization parameter that trades-off bias and variance of the off-policy value estimator R(h) (for example the RHS of equation 6). To exactly calculate \\lambda either requires the size of the policy class (when the policy class is finite), or the complexity constants (which exists in C_1 and C_2 in equation 7, but it is not clearly defined in this paper). Then the main question is on how to choose \\lambda such that the surrogate objective function is reasonable. For example in the safety setting (off-policy policy learning with baseline performance guarantees, for example see the problem setting in the paper by P. Thomas 2015: High Confidence off-policy improvement), one always needs the upper-bound in 6) to hold. This makes the choice of \\lambda crucial and challenging. Unfortunately I don't see much discussions in this paper about choosing \\lambda, even in the context of bias-variance trade-offs. This makes me uncomfortable in believing that the results in experiments hold for other (reasonable) choices of \\lambda.\n\nThe contribution of this paper is of two-fold: 1) the authors extend the results from Cortes's paper to derive a new surrogate objective function, and 2) they show how this objective can be approximated by f-GAN techniques. The first contribution is rather incremental as it's just a direct application of Theorem 2 in Cortes's paper. Regarding the second contribution, I am a bit concerned about the derivations of Equation 9, especially the first inequality and the second equality. I see that the first inequality is potentially an application of the conjugate function inequality, but more details are needed (f^* is not even defined). For the second equality, it's unclear to me how one can swap the sup and the E_x operators. More explanations are definitely needed to show their mathematical correctness, especially when this part is a main contribution.  Even if the derivations are right, the f-GAN surrogate objective is a lower bound of the surrogate objective function, while the surrogate function is an upper bound of the true objective function (which is inaccessible). How does one guarantees that the f-GAN surrogate objective is a reasonable one? \n\nNumerical comparisons between the proposed approach, and the approach from Swaminathan's paper are required to demonstrate the superiority of the proposed approach. Are there comparisons in performance between the approach from the original chi-square surrogate function and the one from the f-GAN objective (in order to showcase the need of using f-GAN) as well?\n\nMinor comments:\nIn experimental section, method POEM is not defined.\nThe paper is in an okay status. But there are several minor typos, for example \\hat{R}_{(} in page 3, and several typos in Algorithm 1 and Algorithm 2.\n\nIn general, I think this paper is studying an interesting topic, but the aforementioned issues make me feel that the paper's current status is still unsuitable for publication. ""]","[70, -20, -30]","[60, 50, 50]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, stating it is 'well written and clear' and praising its theoretical and empirical support. They also highlight several positive aspects using '++' and '+' notations. However, it's not 100 as there are some minor criticisms and suggestions for improvement. The politeness score is 60 (polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'I find' and 'perhaps you could' which are polite ways to express opinions and suggestions. The score isn't higher because the review maintains a professional, somewhat neutral tone rather than being overtly polite or deferential."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting contribution and reasonable experimental comparison, they also highlight several concerns and areas for improvement. The review begins positively but then lists multiple issues, including major concerns about the approach and clarity of writing. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's merits while providing constructive criticism. They use phrases like 'interesting contribution' and 'reasonable experimental comparison', and frame their concerns as suggestions for improvement rather than harsh criticisms. The reviewer also categorizes their comments as 'Major', 'Minor', or 'Crucial', which helps the authors prioritize their revisions in a helpful manner."", ""The sentiment score is -30 because while the reviewer acknowledges the interesting nature of the problem and the importance of the topic, they express several concerns about the paper's contributions and methodologies. The reviewer states that the theoretical contribution is 'quite incremental' and questions parts involving f-GAN. They also point out issues with the choice of λ and the need for more explanations and comparisons. The overall tone suggests the paper is not yet suitable for publication, indicating a somewhat negative sentiment.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think' and 'In general' to soften criticisms, and they acknowledge positive aspects of the paper before presenting concerns. The reviewer also offers constructive feedback and suggestions for improvement, which is a polite approach. However, the score is not higher because the review is direct in its criticisms and does not use overly deferential language.""]"
"['A neural network model consisting of recurrently connected neurons and one or more readouts is introduced which aims to retain some output over time. A plasticity rule for this goal is derived. Experiments show the robustness of the network with respect to noisy weight updates, number of non-plastic connections, and sparse connectivity. Multiple consecutive runs increase the performance; furthermore, remembering multiple stimuli is possible. Finally, ideas for the biological implementation of the rule are suggested.\n\nWhile the presentation is generally comprehensible a number of errors and deficits exist (see below). In general, this paper addresses a question that seems only relevant from a neuroscience perspective. Therefore, I wonder whether it is relevant in terms of the scope of this conference. I also think that the model is rather speculative. The authors argue that the resulting learning rule is biologically plausible. But even if this is the case, it does not imply that it is implemented in neuronal circuits in the brain. As far as I can see, there exists no experimental evidence for this rule. \n\nThe paper shows the superiority of the proposed model over the approach of Druckmann & Chkolvskii (2012), however, it lacks in-depth analysis of the network behavior. Specifically, it is not clear how the information is stored. Do neurons show time-varying responses as in Druckmann & Chkolvskii (2012) or do all neuron stabilize within the first 50 ms (as in Fig. 2A, it is not detailed how the neurons shown there have been selected)? Do the weights change continuously within the delay period or do they also converge rapidly? This question is particularily important when considering multiple consecutive trials (cf. Fig. 5) as it seem that a specific but constant network architecture can retain the desired stimulus without further plasticity. Weight histograms should be presented for the different cases and network states. Also, since autapses are allowed, an analysis of their role should be performed. This information is vital to compare the model to findings from neuroscience and judge the biologic realism.\n\nThe target used is \\hat{s}(t) / \\hat{s}(t = 0), this is dubbed ""fraction of stimulus retained"". In most plots, the values for this measure are <= 1, but in Fig. 3A, the value (for the FEVER network) is > 1. Thus, the name is arguably not well-chosen: how can a fraction of remembrance be greater than one? Also, in a realistic environment, it is not clear that the neuronal activities decay to zero (resulting in \\hat{s}(t) also approaching zero). A squared distances measure should therefore be considered.\n\nIt is not clear from the paper when and how often weight updates are performed. Therefore, the biologic plausability cannot be assessed, since the learning rule might lead to much more rapid changes of weights than the known learning rules in biological neural networks. Since the goal seems to be biologic realism, generally, spiking neurons should be used for the model. This is important as spiking neural networks are much more fragile than artificial ones in terms of stability.\n\nFurther remarks:\n\n- In Sec. 3.2.1, noise is added to weight updates. The absolute values of alpha are hard to interpret since it is not clear in what range the weights, activities, and weight updates typically lie.\n\n- In Sec. 3.2.2 it is shown that 10% plastic synapses is enough for reasonable performance. In this case, it should be investigated whether the full network is essential for the memory task at all (especially since later, it is argued that 100 neurons can store up to 100 stimuli).\n\n- For biologic realism, just assuming that the readout value at t = 0 is the target seems a bit too simple. How does this output arise in the first place? At least, an argument for this choice should be presented.\n\n\nRemarks on writing:\n\n- Fig. 1A is too small to read.\n\n- The caption of Fig. 4C is missing.\n\n- In Fig. 7AB, q_i and q_j are swapped. Also, it is unclear in the figure to which connection the ds and qs belong.\n\n- In 3.6.1, Fig. 7 is referenced, but in the figure the terminology of Eq. 5 is used, which is only introduced in Sec. 3.6.2. This is confusing.\n\n- The beginning of Sec. 3.6 claims that all information is local except d\\hat{s}_k / dt, but this is not the case as d_i is not local (which is explained later).\n\n- The details of the ""stimulus presentation"" (i.e. it is not performed explicitly) should be emphasised in 2.1. Also, the description of the target \\hat{s} is much clearer in 3.4 than in 2.1 (where it should primarily be explained).\n\n- The title of the citation Cowan (2010) is missing.\n\n- In Fig. 2A, the formulas are too small too read in a printed version.\n\n- In Sec. 3.6.1 some sums are given over k, but k is also the index of a neuron in Fig. 7A (which is referenced there), this can be ambiguous and could be changed. ', 'This is a great discussion on an interesting problem in computational neuroscience, that of holding an attractor memory stable even though individual neurons fluctuate. The previously published idea is that this is possible when the sum of all these memory neurons remain constant for the specific readout network, which is possible with the right dependency of the memory neurons. While this previous work relied on fine tuned weights to find such solutions, this work apparently shows that a gradient-based learning rule can finds easily robust solutions.\n\nUnfortunately, I am a bit puzzled about this paper in several ways. To start with I am not completely sure why this paper is submitted to ICLR. While it seems to address a technical issue in computational neuroscience, the discussion on the impact on machine learning is rather limited. Maybe some more discussion on that would be good.\n\nMy biggest concern is that I do not understand the model as presented. A recurrent network of the form in eq 1 is well known as an attractor network with symmetric weights. However, with the proposed learning rate this might be different as I guess this is not even symmetric. Shouldn’t dr_i/da_i = 1 for positive rates as a rectified linear function is used? I guess the derivation of the learning rule (eq.3) is not really clear to me. Does this not require the assumption of stationary single recurrent neuron activities to get  a_i=\\sum L_ij r_j? How do the recurrent neurons fluctuate in the first experiments before noise is introduced? I see that the values change at the beginning as shown in Fig1a, but do they continue to evolve or do the asymptotic? I think a more careful presentation of this important part of the paper would be useful.\n\nAlso, I am puzzled about the readout, specifically when it comes to multiple memories. It seems that separate memories have different readout nodes as the readout weights has an additional index k in this case. I think the challenge should be to have multiple stable states that can be read out in the same pathway. I might miss here something, though I think that without a more clear explanation the paper is not clear for a novel reader. \n\nAnd how about Figure 3a? Why is the fever model suddenly shooting up? This looks rather than a numerical error.\nIn summary, while I might be missing some points here, I can not make sense of this paper at this point.', ""This paper presents a self-organizing (i.e. learned) memory mechanism in a neural model.   The model is not so much an explicit mechanism, rather the paper introduces an objective function that minimizes changes in the signal to be memorized. \n\nThe model builds on the FEVER model (Druckmann and Chklowskii, 2012) and stays fairly close to the framework and goals laid out in this paper. The contribution offered in this paper is a gradient-based weight update (corresponding to the objective function being the square of the temporal derivative of the signal to memorize). This naturally extends the FEVER framework to non-linear dynamics and allows the model to learn to be more robust to weight noise than the original FEVER model. \n\nThe paper goes on to show a few properties of the new memory model including it's ability to remember multiple stimuli and sensitivity to various degrees of connectivity and plasticity. The authors also demonstrate that the update rule can be implemented with a certain degree of biological plausibility. In particular, they show that the need for the same weights to be used in the forward propagation of activity and the backward propagation of gradient can be relaxed. This result is consistent with similar findings in the deep learning literature (Lillicrap et al., 2016).\n\nFor the reader interested in models of working memory and how it can be implemented in dynamic neural hardware, I believe this paper does contribute something interesting to this field of study.\n\nI have two principle concerns with the paper. First, it seems that ICLR is not the right venue for this work. While ICLR has certainly published work with a strong neuro-scientific orientation, I believe this paper offers relatively little of interest to those that are not really invested in the models under consideration. The task that is considered is trivial - maintain a constant projection of the activity of the network activations. I would expect the model to attempt to do this in the service of another, more clearly useful task. In the RNN literature, there exists tasks such as the copy task that test memory, this model is really at a layer below this level of task sophistication. \n\nSecond, while the set of experiments are fair and appropriate, they also seem quite superficial. There is a lack of analysis of the consequences of the learning objective on the network dynamics. There just does not seem to be the same level of contribution as I would expect from an ICLR paper. ""]","[-30, -50, -30]","[50, 20, 50]","[""The sentiment score is -30 because the reviewer expresses several concerns and criticisms about the paper, such as questioning its relevance to the conference, calling the model 'speculative', and pointing out various deficits. However, they also acknowledge some positive aspects, like the comprehensibility of the presentation and the superiority of the proposed model over a previous approach. The overall tone is more negative than positive, but not extremely so.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I wonder whether' and 'As far as I can see' to soften their criticisms. The reviewer also provides constructive feedback and specific suggestions for improvement, which is considerate. While not overly warm or friendly, the language is consistently polite and appropriate for a peer review."", ""The sentiment score is -50 because while the reviewer starts with positive comments about the paper being 'a great discussion on an interesting problem', they quickly transition to expressing significant concerns and confusion about the paper's content and methodology. Phrases like 'I am a bit puzzled', 'My biggest concern', and 'I can not make sense of this paper at this point' indicate a predominantly negative sentiment. The politeness score is 20 because the reviewer uses polite language throughout, such as 'Unfortunately', 'I might miss here something', and frames criticisms as personal confusion rather than direct attacks. However, the politeness is not extremely high as the criticism is still quite direct and the overall tone is one of skepticism rather than encouragement."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects of the paper ('contributes something interesting'), they express two 'principle concerns' that significantly impact their overall assessment. They question the paper's suitability for the ICLR venue and describe the experiments as 'superficial', indicating a lack of depth in the contribution. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's contributions and explaining their concerns in a professional manner without using harsh or dismissive language. They offer constructive criticism and explain their reasoning, which contributes to the polite tone.""]"
"['The paper proposes to improve the kernel approximation of random features by using quadratures, in particular, stochastic spherical-radial rules. The quadrature rules have smaller variance given the same number of random features, and experiments show its reconstruction error and classification accuracies are better than existing algorithms.\n\nIt is an interesting paper, but it seems the authors are not aware of some existing works [1, 2] on quadrature for random features. Given these previous works, the contribution and novelty of the paper is limited.\n\n[1] Francis Bach. On the Equivalence between Kernel Quadrature Rules and Random Feature Expansions. JMLR, 2017.\n[2] Tri Dao, Christopher De Sa, Christopher Ré. Gaussian Quadrature for Kernel Features. NIPS 2017', 'This paper shows that techniques due to Genz & Monahan (1998) can be used to achieve low kernel approximation error under the framework of random fourier feature.\n\nPros\n\n1. It is new to apply quadrature rules to improve kernel approximation. The only other work I found is\nGaussian Quadrature for Kernel Features NIPS 2017. \nThe work is pretty recent so the author might not know it when submitting the paper. But in either case, it will be good to discuss the connections.\n\n2. The proposed method is shown to outperform a few baselines empirically.\n\nCons\n\n1. I don’t find the theoretical analysis to be very useful. In particular, the theorem shows that the kernel approximation error is O(1/D), which is the same as the original RFF paper. Unless the paper can provide a better characterization of the constants (like the ORF paper), it does not provide much insight in the proposed method. Unlike deep neural networks, since RFF is such a simple model, I think providing precise theoretical understanding is crucial. \n\n2. Approximating an integral is a well-studied topic. I do not find a good discussion on all the possible methods. Why is Genz & Monahan 1998 better than other alternatives such as Monte-Carlo, QMC etc? One argument seems to be “for kernels with specific specific integrand one can improve on its properties”. But this trick can be used for Monte-Carlo as well. And I do not see benefit of this trick in the curves.\n\n3. When choosing the orthogonal matrix, I think one obvious choice is to sample a matrix from the Stiefel manifold (the Q matrix of a random Gaussian). This baseline should be added in additional to H and B.\n\n4. A wall-time experiment is needed to justify the speedup.\n\nMinor comments:\n“For kennels with q(w) other than Gaussian… obtain very accurate results with little effort by using Gaussian approximation of q(w)”. What is the citation of this in the kernel approximation context?', 'The authors offer a novel version of the random feature map approach to approximately solving large-scale kernel problems: each feature map evaluates the ""fourier feature"" corresponding to the kernel at a set of randomly sampled quadrature points. This gives an unbiased kernel estimator; they prove a bound its variance and provide experiment evidence that for Gaussian and arc-cos kernels, their suggested qaudrature rule outperforms previous random feature maps in terms of kernel approximation error and in terms of downstream classification and regression tasks. The idea is straightforward, the analysis seems correct, and the experiments suggest the method has superior accuracy compared to prior RFMs for shift-invariant kernels. The work is original, but I would say incremental, and the relevant literature is cited.\n\nThe method seems to give significantly lower kernel approximation errors, but the significance of the performance difference in downstream ML tasks is unclear --- the confidence intervals of the different methods overlap sufficiently to make it questionable whether the relative complexity of this method is worth the effort. Since good performance on downstream tasks is the crucial feature that we want RFMs to have, it is not clear that this method represents a true improvement over the state-of-the-art. The exposition of the quadrature method is difficult to follow, and the connection between the quadrature rules and the random feature map is never explicitly stated: e.g. equation 6 says how the kernel function is approximated as an integral, but does not give the feature map that an ML practitioner should use to get that approximate integral.\n\nIt would have been a good idea to include figures showing the time-accuracy tradeoff of the various methods, which is more important in large-scale ML applications than the kernel approximation error. It is not clear that the method is *not* more expensive in practice than previous methods (Table 1 gives superior asymptotic runtimes, but I would like to see actual run times, as evaluating the feature maps sound relatively complicated compared to other RFMs). On a related note, I would also like to have seen this method applied to kernels where the probability density in the Bochner integral was not the Gaussian density (e.g., the Laplacian kernel): the authors suggested that their method works there as well when one uses a Gaussian approximation of the density (which is not clear to me),  --- and it may be the case that sampling from their quadrature distribution is faster than sampling from the original non-Gaussian density.']","[-20, -20, 20]","[50, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting', they also state that 'the contribution and novelty of the paper is limited' due to existing works the authors seem unaware of. This criticism outweighs the initial positive comment. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, starting with a positive note and using phrases like 'it is an interesting paper'. They also present their criticism in a constructive manner, citing specific references rather than making broad negative statements. The reviewer maintains a professional and respectful tone throughout, even when pointing out limitations."", ""The sentiment score is slightly negative (-20) because while the reviewer notes some pros, there are more cons listed and the overall tone suggests the paper needs significant improvements. The reviewer points out theoretical weaknesses, lack of discussion on alternative methods, and missing experiments. However, it's not extremely negative as the reviewer acknowledges some positive aspects. The politeness score is moderately positive (50) because the reviewer uses professional language throughout, provides specific and constructive feedback, and balances criticism with positive comments. The reviewer avoids harsh language and frames suggestions politely (e.g., 'it will be good to discuss', 'should be added'). The tone remains respectful while still conveying critical feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and potential of the method, citing its 'original' nature and 'superior accuracy' in some aspects. However, they also express reservations about its practical significance and complexity, which tempers the positivity. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout, offering constructive criticism and suggestions without using harsh language. They acknowledge the authors' contributions while also pointing out areas for improvement, which is a balanced and courteous approach in academic peer review.""]"
"['\nSummary: This paper leverages an explicit program format and proposes a stack based RNN to solve question answering. The paper shows state-of-the art performance on the CLEVR dataset.\n\nClarity:\n- The description of the model is vague: I have to looking into appendix on what are the Cell and Controller function.\n- The authors should also improve the intro and related work section. Currently there is a sudden jump between deep learning and the problem of interest. Need to expand the related work section to go over more literature on structured RNN.\n\nPros:\n- The model is fairly easy to understand and it achieves state-of-the-art performance on CLEVR.\n- The model fuses text and image features in a single model.\n\nCons:\n- This paper doesn’t mention recursive NN (Socher et al., 2011) and Tree RNN (Tai et al., 2015). I think they have fairly similar structure, at least conceptually, the stack RNN can be thought as a tree parser. And since the push/pop operations are static (based on the inputs), it’s no more different than encoding the question structure in the tree edges.\n- The IEP (Cells) module (Johnson et al., 2017) seems to do all the heavy-lifting in my opinion. That’s why the proposed method only uses 9M parameters. The task isn’t very challenging to learn because all the stack operations are already given. Table 1 should note clearly which methods use problem specific parsing information to train and which use raw text. Based on my understanding of FiLM at least, they use raw words instead of groundtruth parse trees. So it’s not very surprising that the proposed method can outperform FiLM (by a little bit).\n- I don’t fully agree with the title - the stack operations are not differentiable. So whatever network that outputs the stack operation cannot be jointly learned with gradients. This is based on the if-else statements I see in Algorithm 1.\n\nConclusion:\n- Since the novelty is limited and it requires explicit program supervision, and the performance is only on par with the state-of-the-art (FiLM), I am not convinced that this paper brings enough contribution to be accepted. Weak reject.\n\nReferences:\n- Socher, R., Lin, C., Ng, A.Y., Manning, C.D. Parsing Natural Scenes and Natural Language with Recursive Neural Networks. The 28th International Conference on Machine Learning (ICML 2011).\n- Tai, K.S., Socher, R., Manning C.D. Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks. The 53rd Annual Meeting of the Association for Computational Linguistics (ACL 2015).', 'Summary:\nThe paper presents a generic dynamic architecture for CLEVR VQA and Reverse Polish notation problems. Experiments on CLEVR show that the proposed model DDRprog outperforms existing models, but it requires explicit program supervision. The proposed architecture for RPN, called DDRstack outperforms an LSTM baseline.\n\nStrengths:\n— For CLEVR VQA task, the proposed model outperforms the state-of-the-art with significantly less number of parameters.\n— For RPN task, the proposed model outperforms baseline LSTM model by a large margin.\n\nWeaknesses:\n— The paper doesn’t describe the model clearly. After reading the paper, it’s not clear to me what the components of the model are, what each of them take as input and produce as output, what these modules do and how they are combined. I would recommend to restructure the paper to clearly mention each of the components, describe them individually and then explain how they are combined for both cases - DDRprog and DDRstack. \n— Is the “fork” module the main contribution of the paper? If so, at least this should be described in detail. So, if no fork module is required for a question, the model architecture is effectively same as IEP?\n— Machine accuracy is already par with human accuracy on CLEVR and very close to 100%. Why is this problem still important? \n— Given that the performance of state-on-art on CLEVR dataset is already very high ( <5% error) and the performance numbers of the proposed model are not very far from the previous models, it is very important to report the variance in accuracies along with the mean accuracies to determine if the performance of the proposed model is statistically significantly better than the previous models or not.\n— In Figure 4, why are the LSTM32/128 curves different for Length 10 and Length 30 till subproblem index 10? They are both trained on the same training data, only test data is of different length and ideally both models should achieve similar accuracy for the first 10 subproblems (same trend as DDRstack).\n— Why is DDRstack not compared to StackRNN?\n— Can the authors provide training time comparison of their model and other/baseline models? Because that is more important than the number of epochs required in training.\n— There are only 3 curves (instead of 4) in Figure 3.\n— In a number of places, the authors are referring to left and right program branches. What are they? These names have not being defined formally in the paper.\n\nOverall:\nI think the research work in the paper is interesting and significant, but given the current presentation and level of detail in the paper, I don’t think it will be helpful for the research community. By proper restructuring of paper and adding more details, the paper can be converted to a solid submission.', 'Summary:\nThe paper proposes a novel model architecture for the visual question answering task in the CLEVR dataset. The main novelty of the proposed model lies in its problem specific differentiable forking mechanism that is designed to encode complex assumptions about the data structure in the given problem. The proposed model is also applied on the task of solving Reverse Polish Notation (RPN) expression. On the CLEVR dataset, the proposed model beats the state of the art by 0.7% with ~5 times fever learning parameters and in about ~1/2 as many epochs. For the RPN task, the proposed model beats an LSTM baseline by 0.07 in terms of L1 error with ~10 times fewer parameters. \n\t\nStrengths:\n1.\tThe proposed model is novel and interesting.\n2.\tThe performance of the proposed model on the “Count” questions in the CLEVR dataset is especially better than existing models and is worth noting.\n3.\tThe discussion on the tradeoff between tacking difficult problems and using the knowledge of program structure is engaging. \n\nWeaknesses:\n1.\tThe paper writing about the model architecture can be improved. As of now, it is not easy to follow.\n2.\tThe motivation behind the proposed model for the CLEVR task has been explained example of one type of questions – “How many objects are red or spheres?”. It is not clear how the proposed model is better than existing models (in terms of model architecture) for other types of questions.\n3.\tThe motivation behind the proposed model for the RPN task is not strong enough. It is not clear why is machine learning needed for the RPN task? Is the idea that we do not want to use domain knowledge about which symbols correspond to operations vs. which correspond to numbers? Or is there more to it?\n4.\tThe proposed model needs to use the information about program structure. It would be good if authors could comment on how can the proposed model be used to answer natural language questions about images, such as, those in the VQA dataset (Antol et al., ICCV 2015).\n5.\tThe paper does not have any qualitative examples for either of the two tasks. Qualitative examples of successes and failures would be helpful to better position proposed model against existing models.\n\nOverall: The experimental results look good, however, the proposed model needs to be better motivated. The paper writing, especially the “DDR Architecture” section needs improvement to make it easy to follow. A discussion on how the existing model can be adapted for natural language questions would be good to add.\n']","[-60, -20, 20]","[20, 60, 60]","[""The sentiment score is -60 because the reviewer concludes with a 'Weak reject' recommendation and lists several significant criticisms, including limited novelty, requirement of explicit program supervision, and performance only on par with state-of-the-art. However, they do acknowledge some positive aspects like state-of-the-art performance and an easy-to-understand model, preventing an extremely negative score. The politeness score is 20 because the reviewer uses professional and neutral language throughout, avoiding harsh criticism. They provide balanced feedback, mentioning both pros and cons. The reviewer also uses phrases like 'I don't fully agree' and 'I am not convinced' rather than more confrontational language, maintaining a respectful tone while expressing disagreement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they also point out several significant weaknesses and areas for improvement. The overall tone suggests that the paper needs substantial revision before it can be considered a solid submission. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I would recommend' and 'Can the authors provide' which are polite ways of suggesting improvements. The reviewer also balances criticism with positive feedback, noting that the research is 'interesting and significant' despite the current presentation issues."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the strengths of the paper, such as its novelty and good performance, while also pointing out several weaknesses. The overall tone suggests that the paper has potential but needs improvements. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement without being harsh or dismissive. The reviewer balances positive comments with areas for improvement, and uses phrases like 'it would be good if' and 'would be helpful' when making suggestions, which contributes to the polite tone.""]"
"['The paper provides an empirical study of different  reward schemes for cooperative multi-agent reinforcement learning.  A number of alternative reward schemes are proposed, partly based on existing literature. These reward schemes are evaluated empirically in a packet routing problem.  \n\nThe approach taken by this paper is very ad-hoc. It is not clear to me that this papers offers any general insights or methodologies for reward design for MARL. The only conclusions that can be drawn from this paper is which reward performs best on these specific problem instances(and even this is hard to conclude from the paper).  \n\nIn general, it seems strange to propose the packet routing problems as benchmark environments for reward design. From the descriptions in the paper these environments seem relatively complex and make it difficult to study the actual learning dynamics. The results shown provide global performance but do not allow to study specific properties.\n\nThe paper is also quite hard to read.  It is littered with non-intuitive abbreviations. The methods and experiments are poorly explained. It claims to study rewards for multi-agent reinforcement learning, but never properly details the learning setting that is considered or how this affects the choice of rewards.  Experiments are mostly described in terms of method A outperforms method B. No effort is made to investigate the cause of these results or to design experiments that would offer deeper insights. The graphs are not properly labelled, poorly described in general and are almost impossible to interpret. The main results are presented simply as a large table of raw performance numbers. This paper does not seem to offer any major fundamental or applied contributions. \n', 'The authors study the problem of distributed routing in a network, where the goal is to minimize the maximal load (i.e. the load of the link with the highest utilization). The authors advocate to use multi-agent reinforcement learning. The main idea put forward by the authors is that by designing artificial rewards (to guide the agents), one can achieve faster exploration, in order to reduce convergence time.\n\nWhile the authors put forward several interesting ideas, there are some shortcomings to the present version of the paper, including:\n- The design objective seems flawed from the networking point of view: while minimizing the maximal load of a link is certainly a good starting point (to avoid instable queues) one typically wants to minimize delay (or maximize flow throughput). Indeed, it is possible to have a larger maximal load while reducing delay in many cases.\n- Furthermore, the authors do not provide a baseline to which the outcome of the learning algorithms they propose: for instance how does their approach compare to simple policies (those are commonplace in networking) such as MaxWeight, Backpressure and so on ?\n- The authors argue that using multi-agent learning is more desirable than single agent (i.e. with a single reward signal which is common to all agents). However, is multi-agent guaranteed to converge in such a setting ? If some versions of the problem (for some particular reward signal) are not guaranteed to converge, it is difficult to understand whether ""convergence""  is slow due to an inefficient exploration, or simply because convergence cannot occur in the first place.\n- The learning algorithms used are not clearly explained: the authors simply state that they use ""ACCNet"" (from some unpublished prior work), but to readers unfamiliar with this algorithm, it is difficult to judge the contents of the paper. \n- In the numerical experiments, what is the ""convergence rate"" ? is it the ratio between the mean reward of the learnt policy and that of the optimal ? For how many time steps are the learning algorithm run before evaluating their outcome ? What are the meaning of the various input parameter of ACCnet, and is the performance sensitive to those parameters ?', 'The authors suggest using a mixture of shared and individual rewards within a MARL environment to induce cooperation among independent agents. They show that on their specific application this can lead to a better overall global performance than purely sharing the global signal, or using just the independent rewards.\n\nThe paper is a little too focused on the packet routing example domain and fails to deliver much in terms of a general theory of reward design for cooperative behaviours beyond showing that mixed rewards can lead to improved results in their domain. They discuss what and how rewards, and this could be made more formal, as well as (at the very least) some guiding principles to follow when mixing rewards. It feels like there is a missing section between sections 2 and 3, where this methodological content could be described.\n\nThe rest of the paper has similar issues, with key intuition and concepts either missing entirely or under-represented. The technical content often assumes that the reader is familiar with certain terms, and it is difficult to see what meaningful conclusions can be drawn from the evaluation.\n\n\nOn a minor note, the use of the term cooperative in this paper could be better defined. In game theory, cooperative games are those in which agents share rewards. Non-cooperative (game theory) games are those where agents have general reward signals (not necessarily cooperature or adversarial). Conventionally (yes there is existing reward design/shaping literature for MARL) people have used the same terms in MARL. Perhaps the authors could define their approach as weakly cooperative, or emergent cooperation.\n\nThe related work could be better described. There are existing papers on MARL and the issues with cooperation among independent learners, and this could be referenced. This includes reward shaping and reward potential. I would also have expected to see brief mention of empowerment in this section too (the agent favouring states where it has the power to control outcomes in an information theoretic sense), as an underyling principle for intrinsic reward. However, more importantly, the authors really needed to do more to synthesize this into an overall picture of what principles are at play and what ideas/methods exist that have tried to exploit some of these principles.\n\nDetailed comments:\n  • [p2] the authors say ""We set the meta reward signals as 1 - max(U l )."", before they define what U_l is.\n  • [p2] we have ""As many applications in the real world can be modeled using similar\nmethods, we expect that other fields can also benefit from this work."" This statement is too vague, and the authors could do more to identify which application areas might benefit.\n  • [p3, first para] ""However, the reward design studies for MARL is so limited."" Drop the word \'so\'. Also, I would argue that there have been quite a few (non-deep) discussions about reward design in MARL, cooperative, non-cooperative and competitive domains. \n  • [p3, sec 2.2] ""This makes the diligent agents confuse about..."" should be ""confused"", and I would advise against anthropomorphism at least when the meaning is obscured.\n  • [p3, sec 3] ""After having considered several other options, we finally choose the Packet Routing Domain as our experimental environments."" Not sure what useful information is being conveyed here.\n  • [sec 3] THe domain could be better described with intuition and formal descriptions, e.g. link utilization ratio, etc, before.\n  • [p6] ""Importantly, the proposed blR seems to have similar capacity with dlR,"" The discussion here is all in terms of the reward acronyms with very little call on intuition or other such assistance to the reader.\n  • [p7] ""We firstly try gR without any thinking"" The language could be better here.']","[-80, -50, -40]","[-20, 50, 20]","[""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer criticizes the paper's approach as 'very ad-hoc', states that it doesn't offer 'any general insights or methodologies', and concludes that it doesn't 'offer any major fundamental or applied contributions'. The reviewer also points out numerous issues with the paper's readability, methodology, and presentation of results. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite harsh and dismissive. The reviewer uses phrases like 'it seems strange', 'poorly explained', and 'almost impossible to interpret', which come across as somewhat impolite. However, the reviewer does maintain some level of professional language, preventing the score from being even lower."", ""The sentiment score is -50 because while the reviewer acknowledges some 'interesting ideas' in the paper, they primarily focus on several significant shortcomings and issues with the current version. The review lists multiple criticisms and areas for improvement, indicating a generally negative sentiment towards the paper's current state. However, it's not entirely negative as the reviewer does recognize some positive aspects.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'the authors put forward several interesting ideas' and frame their criticisms as observations or questions rather than direct attacks. The language is constructive and aimed at improving the paper, without being overly harsh or personal. While not excessively polite, the reviewer's tone is consistently professional and courteous."", ""The sentiment score is -40 because the review is generally critical, pointing out several shortcomings of the paper. The reviewer mentions that the paper is too focused on a specific domain, lacks general theory, and has missing or under-represented key concepts. However, it's not entirely negative as the reviewer acknowledges some positive aspects, such as the authors' suggestion of using mixed rewards leading to improved results. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'could be better defined' and 'could do more to identify' rather than harsh language. The reviewer also offers constructive suggestions for improvement. However, there are a few instances where the language could be more polite, such as 'Drop the word 'so'' and commenting on the authors' use of 'without any thinking'.""]"
"['The authors claim three contributions in this paper. (1) They introduce the framework of softmax Q-distribution estimation, through which they are able to interpret the role the payoff distribution plays in RAML. Specifically, the softmax Q-distribution serves as a smooth approximation to the Bayes decision boundary. The RAML approximately estimates the softmax Q-distribution, and thus approximates the Bayes decision rule. (2) Algorithmically, they further propose softmax Q-distribution maximum likelihood (SQDML) which improves RAML by achieving the exact Bayes decision boundary asymptotically. (3) Through one experiment using synthetic data on multi-class classiﬁcation and one using real data on image captioning, they show that SQDML is consistently as good or better than RAML on the task-speciﬁc metrics that is desired to optimize. \n\nI found the first contribution is sound, and it reasonably explains why RAML achieves better performance when measured by a specific metric. Given a reward function, one can define the Bayes decision rule. The softmax Q-distribution (Eqn. 12) is defined to be the softmax approximation of the deterministic Bayes rule. The authors show that the RAML can be explained by moving the expectation out of the nonlinear function and replacing it with empirical expectation (Eqn. 17). Of course, the moving-out is biased but the replacing is unbiased. \n\nThe second contribution is partially valid, although I doubt how much improvement one can get from SQDML. The authors define the empirical Q-distribution by replacing the expectation in Eqn. 12 with empirical expectation (Eqn. 15). In fact, this step can result in biased estimation because the replacement is inside the nonlinear function. When x is repeated sufficiently in the data, this bias is small and improvement can be observed, like in the synthetic data example. However, when x is not repeated frequently, both RAML and SQDML are biased. Experiment in section 4.1.2 do not validate significant improvement, either.\n\nThe numerical results are relatively weak. The synthetic experiment verifies the reward-maximizing property of RAML and SQDML. However, from Figure 2, we can see that the result is quite sensitive to the temperature \\tau. Is there any guidelines to choose \\tau? For experiments in Section 4.2, all of them are to show the effectiveness of RAML, which are not very relevant to this paper. These experiment results show very small improvement compared to the ML baselines (see Table 2,3 and 5).  These results are also lower than the state of the art performance. \n\nA few questions:\n(1). The author may want to check whether (8) can be called a Bayes decision rule. This is a direct result from definition of conditional probability. No Bayesian elements, like prior or likelihood appears here.\n(2). In the implementation of SQDML, one can sample from (15) without exactly computing the summation in the denominator. Compared with the n-gram replacement used in the paper, which one is better?\n(3). The authors may want to write Eqn. 17 in the same conditional form of Eqn. 12 and Eqn. 14. This will make the comparison much more clear.\n(4). What is Theorem 2 trying to convey? Although \\tau goes to 0, there is still a gap between Q and Q\'. This seems to suggest that for small \\tau, Q\' is not a good approximation of Q. Are the assumptions in Theorem 2 reasonable? There are several typos in the proof of Theorem 2. \n(5). In section 4.2.2, the authors write ""the rewards we directly optimized in training (token-level accuracy for NER and UAS for dependency parsing) are more stable w.r.t. τ than the evaluation metrics (F1 in NER), illustrating that in practice, choosing a training reward that correlates well with the evaluation metric is important"". Could you explain it in more details?\n\n', 'This paper interprets reward augmented maximum likelihood followed by decoding with the most likely output as an approximation to the Bayes decision rule.\n\nI have a few questions on the motivation and the results.\n- In the section ""Open Problems in RAML"", both (i) and (ii) are based on the statement that the globally optimal solution of RAML is the exponential payoff distribution q. This is not true. The globally optimal solution is related to both the underlying data distribution P and q, and not the same as q. It is given by q\'(y | x, \\tau) = \\sum_{y\'} P(y\' | x) q(y | y\', \\tau).\n- Both Theorem 1 and Theorem 2 do not directly justify that RAML has similar reward as the Bayes decision rule. Can anything be said about this? Are the KL divergence small enough to guarantee similar predictive rewards?\n- In Theorem 2, when does the exponential tail bound assumption hold?\n- In Table 1, the differences between RAML and SQDML do not seem to support the claim that SQDML is better than RAML. Are the differences actually significant? Are the differences between SQDML/RAML and ML significant? In addition, how should \\tau be chosen in these experiments?\n', 'This paper dives deeper into understand reward augmented maximum likelihood training. Overall, I feel that the paper is hard to understand and that it would benefit from more clarity, e.g., section 3.3 states that decoding from the softmax q-distribution is similar to the Bayes decision rule. Please elaborate on this.\n\nDid you compare to minimum bayes risk decoding which chooses the output with the lowest expected risk amongst a set of candidates?\n\nSection 4.2.2 says that Ranzato et al. and Bahdanau et al. require sampling from the model distribution. However, the methods analyzed in this paper also require sampling (cf. Appendix D.2.4 where you mention a sample size of 10). Please explain the difference.']","[-20, -20, -30]","[60, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('I found the first contribution is sound'), they express several doubts and criticisms. They question the significance of the second contribution ('I doubt how much improvement one can get from SQDML'), describe the numerical results as 'relatively weak', and point out that the improvements shown are 'very small' and 'lower than the state of the art performance'. The overall tone suggests more concerns than praise.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms ('The numerical results are relatively weak') rather than harsh or dismissive phrasing. The reviewer also poses questions and suggestions in a constructive manner ('The author may want to check...', 'Could you explain it in more details?') rather than making demands. The use of 'I found' and 'I doubt' also softens the critique by framing it as personal opinion rather than absolute fact. While not overly effusive, the language is consistently polite and appropriate for academic discourse."", ""The sentiment score is slightly negative (-20) because the reviewer raises several critical questions and points out potential inaccuracies in the paper's claims. However, it's not strongly negative as the tone is constructive and aimed at improving the paper. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language and frames criticisms as questions rather than direct accusations. The review begins with a neutral summary and then lists specific questions and concerns, which is a standard, respectful format for academic peer reviews."", ""The sentiment score is slightly negative (-30) because the reviewer expresses that the paper is 'hard to understand' and 'would benefit from more clarity'. They also point out some inconsistencies and ask for elaboration on certain points, indicating that the paper needs improvement. However, the tone is not entirely negative as the reviewer seems interested in understanding more about the work.\n\nThe politeness score is slightly positive (20) because the reviewer uses polite language throughout. They frame their criticisms as suggestions ('would benefit from') and use questions to request clarification rather than making blunt statements. The tone is professional and constructive, avoiding harsh or rude language. However, it's not overly polite or effusive, maintaining a neutral, academic tone overall.""]"
"[""1) This paper conducts an empirical study of different unsupervised metrics' correlations in task-oriented dialogue generation. This paper can be considered as an extension of Liu, et al, 2016 while the later one did an empirical study in non-task-oriented dialogue generation.  \n\n2)My questions are as follows:\ni) The author should give the more detailed definition of what is non-task-oriented and task-oriented dialogue system. The third paragraph in the introduction should include one use case about non-task-oriented dialogue system, such as chatbots.\nii) I do not think DSTC2 is good dataset here in the experiments. Maybe the dataset is too simple with limited options or the training/testing are very similar to each other, even the random could achieve very good performance in table 1 and 2. For example, the random solution is only 0.005 (out of 1) worse then d-scLSTM, and it also has a close performance compared with other metrics. Even the random could achieve 0.8 (out of 1) in BLEU, this is a very high performance.\niii) About the scatter plot Figure 3, the authors should include more points with a bad metric score (similar to Figure 1 in Liu 2016). \niv) About the correlations in figure b, especially for BLEU and METEOR, I do not think they have good correlations with human's judgments. \nv) BLEU usually correlates with human better when 4 or more references are provided. I suggest the authors include some dataset with 4 or more references instead of just 2 references.\n"", 'This paper\'s main thesis is that automatic metrics like BLEU, ROUGE, or METEOR is suitable for task-oriented natural language generation (NLG). In particular, the paper presents a counterargument to ""How NOT To Evaluate Your Dialogue System..."" where Wei et al argue that automatic metrics are not correlated or only weakly correlated with human eval on dialogue generation. The authors here show that the performance of various NN models as measured by automatic metrics like BLEU and METEOR is correlated with human eval.\n\nOverall, this paper presents a useful conclusion: use METEOR for evaluating task oriented NLG. However, there isn\'t enough novel contribution in this paper to warrant a publication. Many of the details unnecessary: 1) various LSTM model descriptions are unhelpful given the base LSTM model does just as well on the presented tasks 2) Many embedding based eval methods are proposed but no conclusions are drawn from any of these techniques.', 'The authors present a solid overview of unsupervised metrics for NLG, and perform a correlation analysis between these metrics and human evaluation scores on two task-oriented dialog generation datasets using three LSTM-based models. They find weak but statistically significant correlations for a subset of the evaluated metrics, an improvement over the situation that has been observed in open-domain dialog generation.\nOther than the necessarily condensed model section (describing a model explained at greater length in a different work) the paper is quite clear and well-written throughout, and the authors\' explication of metrics like BLEU and greedy matching is straightforward and readable. But the novel work in the paper is limited to the human evaluations collected and the correlation studies run, and the authors\' efforts to analyze and extend these results fall short of what I\'d like to see in a conference paper.\nSome other points:\n1. Where does the paper\'s framework for response generation (i.e., dialog act vectors and delexicalized/lexicalized slot-value pairs) fit into the landscape of task-oriented dialog agent research? Is it the dominant or state-of-the-art approach?\n2. The sentence ""This model is a variant of the “ld-sc-LSTM” model proposed by Sharma et al. (2017) which is based on an encoder-decoder framework"" is ambiguous; what is apparently meant is that Sharma et al. (2017) introduced the hld-scLSTM, not simply the ld-scLSTM.\n3. What happens to the correlation coefficients when exact reference matches (a significant component of the highly-rated upper right clusters) are removed?\n4. The paper\'s conclusion naturally suggests the question of whether these results extend to more difficult dialog generation datasets. Can the authors explain why the datasets used here were chosen over e.g. El Asri et al. (2017) and Novikova et al. (2016)?']","[-20, -20, 20]","[50, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution as an extension of previous work, they raise several critical points and questions about the methodology and results. The reviewer expresses doubts about the dataset choice, the effectiveness of the metrics, and suggests improvements. However, the tone is not entirely negative, as they offer constructive feedback. The politeness score is moderately positive (50) because the reviewer uses polite language throughout, framing their criticisms as questions or suggestions (e.g., 'I suggest', 'The author should'). They maintain a professional tone without using harsh or rude language, even when pointing out potential flaws in the study."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper presents a 'useful conclusion', they also state there isn't enough novel contribution to warrant publication and criticize unnecessary details. This indicates an overall negative view despite some positive aspects. The politeness score is moderately positive (50) as the reviewer uses neutral language and provides specific, constructive feedback without harsh criticism. They acknowledge positive aspects before presenting critiques, which is a polite approach. The reviewer maintains a professional tone throughout, avoiding rudeness while still clearly communicating their concerns."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's strengths ('solid overview', 'clear and well-written', 'straightforward and readable') but also points out limitations ('novel work in the paper is limited', 'efforts to analyze and extend these results fall short'). The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as suggestions for improvement rather than harsh judgments. The reviewer maintains a professional tone while balancing praise with areas for enhancement.""]"
"[""This paper proposed the combination of topic model and seq2seq conversational model.\nThe idea of this combination is not surprising but the attendee of ICLR might be interested in the empirical results if the model clearly outperforms the existing method in the experimental results.\nHowever, I'm not sure that the empirical evaluation shows the really impressive results.\nIn particular, the difference between LV-S2S and LTCM seem to be trivial.\nThere are many configurations in the LSTM-based model.\nCan you say that there is no configuration of LV-S2S that outperforms your model?\nMoreover, the details of human evaluation are not clear, e.g., the number of users and the meaning of each rating.\n\n"", 'I enjoyed this paper a lot. The paper addresses the issue of enduring topicality in conversation models. The model proposed here is basically a mash-up between a neural topic model and a seq2seq-based dialog system. The exposition is relatively clear and a reader with sufficient background in ML should have no following the model. My only concern about the paper is that is very incremental in nature -- the authors combine two separate models into a relatively straight-forward way. The results do are good and validate the approach, but the paper has little to offer beyond that.  ', 'The paper proposes a conversational model with topical information, by combining seq2seq model with neural topic models. The experiments and human evaluation show the model outperform some the baseline model seq2seq and the other latent variable model variant of seq2seq.\n\nThe paper is interesting, but it also has certain limitations:\n\n1) To my understanding, it is a straightforward combination of seq2seq and one of the neural topic models without any justification.\n2) The evaluation doesn\'t show how the topic information could influence word generation. No of the metrics in table 2 could be used to justify the effect of topical information.\n3) There is no analysis about the model behavior, therefore there is no way we could get a sense about how the model actually works. One possible analysis is to investigate the values $l_t$ and the corresponding words, which to some extent will tell us how the topical information be used in generation. In addition, it could be even better if there are some analysis about topics extracted by this model.\n\nThis paper also doesn\'t pay much attention to the existing work on topic-driven conversational modeling. For example ""Topic Aware Neural Response Generation"" from Xing et al., 2017.\n\nSome additional issues:\n\n1) In the second line under equation 4, y_{t-1} -> y_{t}\n2) In the first paragraph of section 3, two ""MLP""\'s are confusing\n3) In the first paragraph of page 6, words with ""highest inverse document frequency"" are used as stop words?']","[-20, 50, -20]","[50, 75, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges potential interest in the topic, they express skepticism about the impressiveness of the results and raise several concerns. The reviewer states that the empirical evaluation doesn't show 'really impressive results' and questions whether the proposed model truly outperforms existing methods. The politeness score is moderately positive (50) as the reviewer uses neutral language and phrases their criticisms as questions rather than direct statements. They avoid harsh language and present their concerns in a professional manner, asking for clarification rather than outright dismissing the work."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by saying they 'enjoyed this paper a lot' and praises the clear exposition and good results. However, they also express concern about the paper being 'very incremental in nature' and having 'little to offer beyond' the validation of the approach, which tempers the overall positivity. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering criticism. They phrase their concerns diplomatically, using phrases like 'My only concern' rather than harsh or dismissive language. The review maintains a professional and constructive tone throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting', they immediately follow with 'but it also has certain limitations'. The review then lists several criticisms and issues with the paper, indicating an overall negative sentiment despite the initial positive comment. The politeness score is moderately positive (50) as the reviewer uses neutral language and phrases criticisms as observations or suggestions rather than harsh judgments. They use phrases like 'To my understanding' and 'it could be even better if' which soften the critique. The reviewer also provides specific, constructive feedback which is a polite way to offer criticism. However, the review doesn't use overtly polite language or praise, keeping it from scoring higher on politeness.""]"
"['*Paper summary*\n\nThe paper considers GANs from a theoretical point of view. The authors approach GANs from the 2-Wasserstein point of view and provide several insights for a very specific setting. In my point of view, the main novel contribution of the paper is to notice the following fact:\n\n(*) It is well known that the 2-Wasserstein distance W2(PY,QY) between multivariate Gaussian PY and its empirical version QY scales as $n^{-2/d}$, i.e. converges very slow as the dimensionality of the space $d$ increases. In other words, QY is not such a good way to estimate PY in this setting. A somewhat better way is use a Gaussian distribution PZ with covariance matrix S computed as a sample covariance of QY. In this case W2(PY, PZ) scales as $\\sqrt{d/n}$.\n\nThe paper introduces this observation in a very strange way within the context of GANs. Moreover, I think the final conclusion of the paper (Eq. 19) has a mistake, which makes it hard to see why (*) has any relation to GANs at all.\n\nThere are several other results presented in the paper regarding relation between PCA and the 2-Wasserstein minimization for Gaussian distributions (Lemma 1 & Theorem 1). This is indeed an interesting point, however the proof is almost trivial and I am not sure if this provides any significant contribution for the future research.\n\nOverall, I think the paper contains several novel ideas, but its structure requires a *significant* rework and in the current form it is not ready for being published. \n\n*Detailed comments*\n\nIn the first part of the paper (Section 2) the authors propose to use the optimal transport distance Wc(PY, g(PX)) between the data distribution PY (or its empirical version QY) and the model as the objective for GAN optimization. This idea is not novel: WGAN [1] proposed (and successfully implemented) to minimize the particular case of W1 distance by going through the dual form, [2] proposed to approach any Wc using auto-encoder reformulation of the primal (and also shoed that [5] is doing exactly W2 minimization), and [3] proposed the same using Sinkhorn algorithm. So this point does not seem to be novel.\n\nThe rest of the paper only considers 2-Wasserstein distance with Gaussian PY and Gaussian g(PX) (which I will abbreviate with R), which looks like an extremely limited scenario (and certainly has almost no connection to the applications of GANs).\n\nSection 3 first establishes a relation between PCA and minimizing 2-Wasserstein distance for Gaussian distributions (Lemma 1, Theorem 1). Then the authors show that if R minimizes W2(PY, R) and QR minimizes W2(QY, QR) then the excess loss W2(PY, QR) - W2(PY, R) approaches zero at the rate $n^{-2/d}$ (both for linear and unconstrained generators). This result basically provides an upper bound showing that GANs need exponentially many samples to minimize W2 distance. I don\'t find these results novel, as they already appeared in [4] with a matching lower bound for the case of Gaussians (Theorem B.1 in Appendix can be modified easily to show this). As the authors note in the conclusion of Section 3, these results have little to do with GANs, as GANs are known to learn quite quickly (which contradicts the theory of Section 3).\n\nFinally, in Section 4 the authors approach the same W2 problem from its dual form and notice that for the LQG model the optimal discriminator is quadratic. Based on this they reformulate the W2 minimization for LQG as the constrained optimization with respect to p.d. matrix A (Eq 16). The same conclusion does not work unfortunately for W2(QY, R), which is the real training objective of GANs. Theorem 3 shows that nevertheless, if we still constrain discriminator in the dual form of W2(QY, R) to be quadratic, the resulting soliton QR* performs the empirical PCA of Pn. \n\nThis leads to the final conclusion of the paper, which I think contains a mistake. In Eq 19 the first equation, according to the definitions of the authors, reads\n\\[\nW2(PY, QR) = W2(PY, PZ),   (**)\n\\]\nwhere QR is trained to minimize min_R W2(QY, R) and PZ is as defined in (*) in the beginning of these notes. \nHowever, PZ is not the solution of min_R W2(QY, R) as the authors notice in the 2nd paragraph of page 8. Thus (**) is not true (at least, it is not proved in the current version of the text). PZ is a solution of min_R W2(QY, R) *where the discriminator is constrained to be quadratic*. This mismatch is especially strange, given the authors emphasize in the introduction that they provide bounds on divergences which are the same as used during the training (see 2nd paragraph on page 2) --- here the bound is on W2, but the empirical GAN actually does a regularized training (with constrained discriminator).\n\nFinally, I don\'t think the experiments provide any convincing insights, because the authors use W1-minimization to illustrate properties of the W2. Essentially the authors say ""we don\'t have a way to perform W2 minimization, so we rather do the W1 minimization and assume that these two are kind of similar"".\n\n* Other comments *\n(1) Discussion in Section 2.1 seems to never play a role in the paper.\n(2) Page 4: in p-Wasserstein distance, ||.|| does not need to be a Euclidean metric. It can be any metric.\n(3) Lemma 2 seems to repeat the result from (Canas and Rosasco, 2012) as later cited by authors on page 7?\n(4) It is not obvious how does Theorem 2 translate to the excess loss? \n(5) Section 4. I am wondering how exactly the authors are going to compute the conjugate of the discriminator, given the discriminator most likely is a deep neural network?\n\n\n[1] Arjovsky et al., Wasserstein GAN, 2017\n[2] Bousquet et al, From optimal transport to generative modeling: the VEGAN cookbook, 2017\n[3] Genevay et al., Learning Generative Models with Sinkhorn Divergences, 2017\n[4] Arora et al, Generalization and equilibrium in GANs, 2017\n[5] Makhazani et al., Adversarial Autoencoders, 2015', 'First of all, let me state this upfront: despite the sexy acronym ""GAN"" in the title, this paper does not provide any genuine understanding of GANs. Conceptually, GANs are an algorithmic instantiation of a classic idea in statistics, mamely minimum-distance estimation, originally introduced by Jacob Wolfowitz in 1957 (*). This provides the \'min\' part. The \'max\' part comes from considering distances that can be expressed as a supremum over a class of test functions. Again, this is not new -- for instance, empirical risk minimization, in both supervised and unsupervised learning, can be phrased as precisely such a minimax problem by casting the convergence analysis in terms of suprema of suitable empirical processes (see, e.g., ""Empirical Processes in M-Estimation"" by Sara Van De Geer). Moreover, even the minimax (and, more broadly, game-theoretic) criteria go back all the way to the foundational papers of Abraham Wald.\n\nNow, the conceptual innovation of GANs is that this minimax formulation can be turned into a zero-sum game played by two algorithmic architectures, the generator and the discriminator. The generator proposes a model (which is assumed to be easy to sample from) and generates a sample starting from a fixed instrumental distribution; the discriminator evaluates the current proposal against a class of test functions, which, again, are assumed to be easily computable, e.g., by a neural net. One can also argue that the essence of GANs is precisely the architectural constraints on both the generator and the discriminator that make their respective problems amenable to \'differentiable\' approaches, e.g., gradient descent/ascent with backpropagation. Without such a constraint, the saddle point is either trivial or reduces to finding a worst-case Bayes estimate, as classical statistical theory would predict.\n\nThis paper essentially strips away the essence of GANs and considers a stylized minimum-distance estimation problem, where both the target and the instrumental distributions are Gaussian, and the \'distance\' between statistical models is the quadratic Wasserstein distance induced by the Euclidean norm. This, essentially, stacks the deck in favor of linear strategies, and it is not surprising at all that PCA emerges as the solution. It is very hard to see how any of this helps our understanding of either strengths or shortcomings of GANs (such as mode collapse or stability issues). Moreover, the discussion of supervised and unsupervised paradigms is utterly unconvincing, especially in light of the above comment on minimum-distance estimation underlying both of these paradigms. In either setting, a learning algorithm is obtained from the population version of the problem by substituting the empirical distribution of the observed data for the unknown population law.\n\nAdditional minor comments on proper attribution and novelty of results:\n\n1) Lemma 3 (structural result for optimal transport with L_2 Wasserstein cost) is not due to Chernozhukov et al., it is a classic result in the theory of optimal transportation, in various forms due to Brenier, McCann, and others -- cf., e.g., Chapters 2 and  3 of C. Villani, ""Topics in Optimal Transportation.""\n\n2) The rate-distortion formulation with fixed input and output marginal in Appendix A, while interesting, is also not new. Precise characterizations in terms of optimal transport are available, see, e.g., N. Saldi, T. Linder, and S. Yuksel, ""Randomized Quantization and Source Coding With Constrained Output Distribution,"" IEEE Transactions on Information Theory, vol. 61, no. 1., pp. 91-106, January 2015.\n\n(*) The method of Wolfowitz is not restricted to distance functions in the mathematical sense; it can work equally well with monotone functions of metrics -- e.g., the square of a metric.', ""\nSummary:\nThis paper studies GANs in the following LQG setting: Input data distribution (P_Y) is Gaussian with zero mean and Identity covariance. Loss function is quadratic. Generator is also considered to be a Gaussian distribution (linear function of the input Gaussian noise). The paper considers two settings for discriminator: 1)Unconstrained and 2) Quadratic function. For these settings, the paper studies the generalization error rates, or the gap between Wasserstein loss of the population version (P_Y) and the finite sample version (Q_n(Y)). The paper shows that when the discriminator is unconstrained, even though the generator is constrained to be linear, the convergence rates are exponentially slow in the dimension. However constraining the discriminator improves the rates to 1/\\sqrt{#samples}. This is shown by establishing the equivalence of this setting to PCA.\n\n\nComments:\n\n\n1) This paper studies the statistical aspects of GANs, essentially the sample complexity required for small generalization error, for the simpler LQG setting. The LQG setting reduces the GAN optimization to essentially PCA and I believe is too simple to give insights into more complex GANs. \n\n2)The results show that using high capacity neural network architectures can result in having solutions with high variance/generalization error. However, it is known even for classification that neural networks used in practice have high capacity (https://arxiv.org/abs/1611.03530) yet generalize well on *real* tasks. So, having slow worst case convergence may not necessarily be an issue with higher capacity GANs, and this paper does not address this issue with the results.\n\n3) The discussion on what is natural loss is very confusing and doesn't add to the results. While least squares loss is the simplest to study and generally offers good insights, I don't think it is either natural or the right loss to consider for GANs.\n\n4) Also the connection to supervised learning seems very weak. In supervised learning generally Y is smaller dimensional compared to X, and generalization of g(X) depends on its ability to compress X, but still represent Y. On the contrary, in GANs, X is much smaller dimensional than Y.""]","[-50, -80, -50]","[20, -50, 20]","[""The sentiment score is -50 because the reviewer expresses several criticisms and states that the paper requires 'significant rework' and is 'not ready for being published'. However, they also acknowledge some 'novel ideas', preventing the score from being more negative. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'in my point of view' and 'I think', which soften criticisms. They also acknowledge positive aspects alongside negatives. However, some direct criticisms like mentioning a 'mistake' and calling the paper's approach 'very strange' prevent a higher politeness score."", ""The sentiment score is -80 because the review is highly critical and dismissive of the paper's contribution. The reviewer states upfront that the paper doesn't provide 'any genuine understanding of GANs' and goes on to criticize the paper's conceptual basis, novelty, and relevance. The tone is consistently negative throughout, with phrases like 'strips away the essence of GANs', 'stacks the deck', and 'utterly unconvincing'. The politeness score is -50 because while the reviewer doesn't use explicitly rude language, the tone is quite harsh and dismissive. The review starts with a blunt criticism and maintains a condescending tone, using phrases like 'it is not surprising at all' and 'it is very hard to see how any of this helps'. The reviewer also implies that the authors lack understanding of fundamental concepts, which is impolite in academic discourse."", ""The sentiment score is -50 because the review is generally critical of the paper's approach and findings. The reviewer points out several limitations, such as the simplicity of the LQG setting, the lack of insight into more complex GANs, and the questionable relevance of the results to real-world scenarios. However, the score is not extremely negative as the reviewer acknowledges some value in studying the statistical aspects of GANs. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'I believe' and 'I don't think' to soften their criticisms, and they provide specific reasons for their concerns. The language is not overtly polite, but it avoids rudeness and maintains a respectful, academic tone.""]"
"['This paper looks at a specific aspect of the learning-to-teach problem, where the learner is assumed to have a teacher that selects training examples for the student according to a strategy. The teacher\'s strategy should also be  learned from data.  In this case the authors look at finding interpretable teaching strategies.  The authors define the ""good"" strategies as similar to intuitive strategies (based on human intuition about the structure of the domain) or strategies that are effective for teaching humans.  \nThe suggested method follow an iterative process in which the student and teacher are interchangeably used. At each iteration the teacher generates  examples based on the students current concept. \n\nI found it very difficult to follow the claims in the paper. Why is it assumed that human intuition is necessarily good?  The experiments do not answer these questions, but are designed to show that the suggested approach follows human intuition. There are not enough details to get a good grasp of the suggested method and the different choices for it,  and similarly the experiments are not described in a very convincing way. Specifically - the domains picked seem very contrived,  there actual results are not reported, the size of the data seems minimal so it\'s not clear what is actually learned.\nHow would you analyze the teaching strategy in realistic cases, where there is no simple intuitive strategy? This would be more convincing.', 'The authors define a novel method for creating a pair of models, a student and a teacher model, that are co-trained in a manner such that the teacher provides useful examples to the student to communicate a concept that is interpretable to people. They do this by adapting a technique from computational cognitive science called rational pedagogy. Rather than jointly optimize the student and teacher (as done previously), they have form a coupled relation between the student and teacher where each is providing a best response to the other. The authors demonstrate that their method provides interpretable samples for teaching in commonly used psychological domains and conduct human experiments to argue it can be used to teach people in a better manner than random teaching. \n\nUnderstanding how to make complex models interpretable is an extremely important problem in ML for a number of reasons (e.g., AI ethics, explainable AI). The approach proposed by the authors is an excellent first step in this direction, and they provide a convincing argument for why a previous approach (joint optimization) did not work. It is an interesting approach that builds on computational cognitive science research and the authors provide strong evidence their method creates interpretable examples. They second part of their article, where they test the examples created by their models using behavioral experiments was less convincing. This is because they used the wrong statistical tests for analyzing the studies and it is unclear whether their results would stand with proper tests (I hope they will! – it seems clear that random samples will be harder to learn from eventually, but I also hoped there was a stronger baseline.).\n\nFor analysis, the authors use t-tests directly on KL-divergence and accuracy scores; however, this is inappropriate (see Jaeger, 2008; Categorical data analysis: Away from ANOVAs (transformation or not) and towards logit mixed models. Journal of Memory and Language, 59(4), 434-446.). This is especially applicable to the accuracy score results and the authors should reanalyze their data following the paper referenced above. With respect to KL-divergence, a G-test can be used (see https://en.wikipedia.org/wiki/G-test#Relation_to_Kullback.E2.80.93Leibler_divergence). I suspect the results will still be meaningful, but the appropriate analysis is essential to be able to interpret the human results.\n\nAlso, a related article: One article testing rational pedagogy in more ML contexts and using it to train ML models that is\nHo, M. K., Littman, M., MacGlashan, J., Cushman, F., & Austerweil, J. L. (NIPS 2016). Showing versus Doing. Teaching by Demonstration.\n\nFor future work, it would be nice to show that the technique works for finding interpretable examples in more complex deep learning networks, which motivated the current push for explainable AI in the first place.', 'This is a well written paper on a compelling topic: how to train ""an automated teacher"" to use intuitive strategies  that would also apply to humans. \n\nThe introduction is fairly strong, but this reviewer wishes that the authors would have come up with an intuitive example that illustrates why the strategy ""1) train S on random exs; 2) train T to pick exs for S"" makes sense. Such an example would dramatically improve the paper\'s readability.\n\nThe paper appears to be original, and the related work section is quite extensive.\n\nA second significant improvement would be to add an in-depth  running example in section 3, so that the authors could illustrate why the BR strategy makes sense (Algorithm 2).']","[-50, 60, 70]","[0, 80, 80]","[""The sentiment score is -50 because the reviewer expresses significant criticism and skepticism about the paper. They state that it was 'very difficult to follow the claims', question the assumption that human intuition is good, and criticize the lack of details and convincing experiments. However, it's not entirely negative as they do describe the paper's content neutrally at the beginning. The politeness score is 0 (neutral) because the reviewer's language is neither particularly polite nor rude. They express their criticisms directly but professionally, without using overly harsh language or personal attacks. The reviewer maintains a formal, academic tone throughout, focusing on the content of the paper rather than making it personal."", ""The sentiment score is 60 (positive) because the reviewer describes the work as 'an excellent first step' and 'an interesting approach', providing 'strong evidence'. They express hope for the results and acknowledge the importance of the problem. However, they also point out some weaknesses in the statistical analysis, which prevents a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and expresses hope for the authors' results. They provide specific suggestions for improvement and additional resources, which is helpful and courteous. The tone is professional and encouraging, even when pointing out areas for improvement."", ""The sentiment score is 70 (positive) because the reviewer starts by calling it a 'well written paper on a compelling topic,' which is a strong positive statement. They also mention that the introduction is 'fairly strong' and the related work section is 'quite extensive.' The reviewer does suggest improvements, but these are framed as ways to make the paper even better rather than criticisms of major flaws. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, such as 'this reviewer wishes' and 'would dramatically improve,' rather than using more direct or harsh language. They also balance their suggestions for improvement with positive comments about the paper's strengths. The reviewer's tone is constructive and aimed at helping the authors improve their work, rather than being critical or dismissive.""]"
"[""This manuscript raises an important issue regarding the current lack of standardization regarding methods for evaluating and reporting algorithm performance in deep learning research.  While I believe that raising this issue is important and that the method proposed is a step in the right direction, I have a number of concerns which I will list below.  One risk is that if the proposed solution is not adequate or widely agreeable then we may find a proliferation of solutions from which different groups might pick and choose as it suits their results!\n\nThe method of choosing the best model under 'internal' cross-validation to take through to 'external' cross-validation against a second hold-out set should be regarded as one possible stochastic solution to the optimisation problem of hyper-parameter selection.  The authors are right to emphasize that this should be considered part of the cost of the technique, but I would not suggest that one specify a 'benchmark' number of trials (n=5) for comparison.  Rather I would suggest that this is a decision that needs to be explored and understood by the researchers presenting the method in order to understand the cost/benefit ratio for their algorithm provided by attempting to refine their guess of the optimal hyperparameters.  This would then allow for other methods not based on internal cross-validation to be compared on a level footing.\n\nI think that the fundamental issue of stochasticity of concern for repeatability and generalisability of these performance evaluation exercises is not in the stochastic optimisation search but in the use of a single hold-out sample.  Would it not be wise to insist on a mean performance (a mean Boo_n or other) over multiple random partitions of the entire dataset into training and hold-out?  I wonder if in theory both the effect of increasing n and the mean hold-out performance could be learnt efficiently with a clever experimental design. \n\nFinally, I am concerned with the issue of how to compute the suggested Boo_n score.  Use of a parameteric Gaussian approximation is a strong assumption, while bootstrap methods for order statistics can be rather noisy.  It would be interesting to see a comparison of the results from the parametric and non-parameteric Boo_n versions applied to the test problems.  "", 'The authors propose a new measure to capture the inherent randomness of the performance of a neural net under different random initialisations and/or data inputs. Just reporting the best performance among many random realisations is clearly flawed yet still widely adopted. Instead, the authors propose to compute the so-called best-out-of-n performance, which is the expected best performance under n random initialisations. \n\nPros:\n- The widespread reporting of just the best model is clearly leading to very biased results and does not help with reproducibility. Any effort to mitigate this problem is thus welcome.\n- The proposed quantity is simple to compute if we have m realisations of the same model under different random inputs (random initialisation or random data) and will converge to a stable limit even if m is very large. \n\nCons:\n- The best-out-of-n performance is well grounded if we have different random inputs such as random initial parameters or random batch processing. Arguably, there is even larger variance if the model parameters such as number of layers, layer size etc are varied. Yet these variations cannot really be captured by the best-out-of-n performance indicator unless modelled as random variables (which would lead to different sorts of problems).\n- Computationally it requires to have a large number m of replications which is not always feasible. \n- Most importantly: the proposed way is just one of many ways to reduce the distribution of performances to a single scalar quantity. Why is it better than just reporting a specific quantile, for example? Perhaps any such attempt to reduce to a single scalar is flawed and we should report the full distribution (or first and second moment, or several quantiles). For example: the boo-n performance gets better if the outcome is highly variable compared to a model where the mean performance is identical but the outcome much less variable. High variance of the performance can be negative or positive, depending on the application and the choice of boo-n is making a singular choice just as if we chose the mean or min or max or a specific quantile. \n\n\n\n\n\n\n\n\n\n\n\n\n', 'This paper addresses multiple issues arising from the fact that commonly reported best model performance numbers are a single sample from a performance distribution. These problems are very real, and they deserve significant attention from the ML community.  However, I feel that the proposed solution may actually compound the issues highlighted.\n\nFirstly, the proposed metric requires calculation of multiple test set experiments for every evaluation. In the paper up to 100 experiments were used. This may be reasonable in scenarios where the test set is hidden, and individual test numbers are never revealed. It also may be reasonable if we cynically assume that researchers are already running many test-set evaluations. But I am very opposed to any suggestion that we should relax the maxim that the test set should be used only once, or as close to once as is possible. Even the idea of researchers knowing their test set variance makes me very uneasy.\n\nSecondly, this paper tries to account for variation in results due to different degrees of hyper-parameter tuning. This is certainly an admirable aim, since different research groups have access to very different types of resources. However, the suggested approach relies on randomly picking hyper-parameters from ""a range that we previously found to work reasonably well"". This randomization does not account for the many experiments that were required to find this range. And the randomization is also not extended to parameters controlling the model architecture (I suspect that a number of experiments went into picking the 32 layers in the ResNet used by this paper). Without a solid and consistent basis for these hyper-parameter perturbations, I worry that this approach will fail to normalize the effect of experiment numbers while also giving researchers an excuse to avoid reporting their experimental process.\n\nI think this is a nice idea and the metric does merge the stability and low variance of mean score with the aspirations of best score. The metric may be very useful at development time in helping researchers build a reasonable expectation of test time performance in cases where the dev and test sets are strongly correlated. However, for the reasons outlined above, I don\'t think the proposed approach solves the problems that it addresses. Ultimately, the decision about this paper is a subjective one. Are we willing to increase the risk of inadvertent hyper-parameter tuning on the test set for the sake of a more stable metric?']","[-20, 20, -20]","[60, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the issue raised, they express several concerns about the proposed method. The review begins positively but quickly shifts to listing multiple issues, indicating an overall cautious or skeptical stance. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the importance of the work and offering constructive criticism. They use phrases like 'I believe,' 'I would suggest,' and 'I wonder,' which maintain a polite tone while expressing concerns. The reviewer also offers alternative suggestions and asks thoughtful questions, demonstrating engagement with the work in a courteous manner."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the importance of the problem the authors are addressing and sees value in their effort. They mention pros of the proposed method, such as its simplicity and stability. However, the reviewer also points out several cons and limitations, which tempers the overall positive sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They present their critique in a constructive manner, using phrases like 'Pros:' and 'Cons:' to organize their thoughts, and avoid using harsh or dismissive language. The reviewer also uses phrases like 'Arguably' and 'Perhaps' when presenting alternative viewpoints, which adds to the polite tone. The review is balanced, offering both positive and negative points, which contributes to its overall professional and courteous nature."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the issues addressed in the paper, they express significant concerns about the proposed solution. The reviewer states that the solution may 'compound the issues highlighted' and is 'opposed' to certain implications of the method. However, they also mention some positive aspects, like calling it a 'nice idea' and potentially useful in some contexts, which prevents the score from being more negative. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's merits and framing criticisms constructively. They use phrases like 'I feel that,' 'I am very opposed,' and 'I think,' which maintain a polite tone while expressing disagreement. The reviewer also balances criticism with positive comments, further contributing to the polite tone.""]"
"['This paper introduces recurrent relational networks: a deep neural network for structured prediction (or relational reasoning). The authors use it to achieve state-of-the-art performance on Soduku puzzles and the BaBi task (a text based QA dataset designed as a set of to toy prerequisite tasks for reasoning).\n\nOverall I think that by itself the algorithm suggested in the paper is not enough to be presented in ICLR, and on the other hand the authors didn\'t show it has a big impact (could do so by adding more tasks - as they suggest in the discussion). This is why I think the paper is marginally below the acceptance threshold but could be convinced otherwise.\n\nC an the authors give experimental evidences for their claim: ""As such, the network could use a small part of the hidden state for retaining a current best guess, which might remain constant over several steps, and other parts of the hidden state for running a non-greedy..."" - \n\nPros\n- The idea of the paper is clearly presented, the algorithm is easy to follow.\n- The motivation to do better relational reasoning is clear and the network suggested in this paper succeeds to achieve it in the challenging tasks.\n\nCons\n- The recurrent relational networks is basically a complex learned message passing algorithm. As the authors themselves state there are several works from recent years which also tackle this (one missing reference is Deeply Learning the Messages in Message Passing Inference of Lin et al from NIPS 2016). It would been interesting to compare results to these algorithms.\n- For the Sudoku the proposed architecture of the network seems a bit to complex, for example why do a 16 embedding is needed for representing a digit between 0-9? Some other choices (batch size of 252) seem very specific.', ""The paper introduced recurrent relational network (RRNs), an enhanced version of the\nexisting relational network, that can be added to any neural networks to add\nrelational reasoning capacity. RRNs are illustrated on sudoku puzzles and textual QA.\n\nOverall the paper is well written and structured. It also addresses an important research question: combining relational reasoning and neural networks is currently receiving a lot of attention, in particular when generally considering the question of bridging sub-symbolic and symbolic methods. Unfortunately, it is current form, the paper has two major downsides. First of all,  the sudoku example does not illustrate “complex relational reasoning” as claimed in the title. The problem is encoded at a positional level where \nmessages encoded as MLPs and LSTMs implement the constraints for sudoko. Indeed, \nthis allows to realise end-to-end learning but does not illustrate complex reasoning. \nThis is also reflected in the considered QA task, which is essentially coded as a positional problem. Consequently, the claim of the conclusions, namely that “we have\nproposed a general relational reasoning model” is not validated, unfortunately. Such\na module that can be connected to any existing neural network would be great. However, \nfor that one should show capabilities of relational logic. Some standard (noisy) \nreasoning capabilities such as modus ponens. This also leads me to the second downside. \nUnfortunately, the paper falls short on discussion related work. First of all, \nthere is the large field of statistical relational learning, see \n\nLuc De Raedt, Kristian Kersting, Sriraam Natarajan, David Poole:\nStatistical Relational Artificial Intelligence: Logic, Probability, and Computation. Synthesis Lectures on Artificial Intelligence and Machine Learning, Morgan & Claypool Publishers 2016\n\nfor a recent overview. As it has the very same goals, while not using a neural architecture for implementation, it is very much related and has to be discussed. That\none can also use a neural implementation can be seen in \n\nIvan Donadello, Luciano Serafini, Artur S. d'Avila Garcez:\nLogic Tensor Networks for Semantic Image Interpretation. IJCAI 2017: 1596-1602\n\nMatko Bosnjak, Tim Rocktäschel, Jason Naradowsky, Sebastian Riedel:\nProgramming with a Differentiable Forth Interpreter. ICML 2017: 547-556\n\nLuciano Serafini, Artur S. d'Avila Garcez:\nLearning and Reasoning with Logic Tensor Networks. AI*IA 2016: 334-348\n\nGustav Sourek, Vojtech Aschenbrenner, Filip Zelezný, Ondrej Kuzelka:\nLifted Relational Neural Networks. CoCo@NIPS 2015\n\nTim Rocktäschel, Sebastian Riedel:\nEnd-to-end Differentiable Proving. CoRR abs/1705.11040 (2017)\n\nWilliam W. Cohen, Fan Yang, Kathryn Mazaitis:\nTensorLog: Deep Learning Meets Probabilistic DBs. CoRR abs/1707.05390 (2017)\n\nto list just some approaches. There are also (deep) probabilistic programming \napproaches such as Edward that should be mentioned as CPS like problems (Sudoku) can\ndefinitely be implement there. Moreover, there is a number of papers that discuss \nembeddings of relational data and rules such as \n\nWilliam Yang Wang, William W. Cohen:\nLearning First-Order Logic Embeddings via Matrix Factorization. IJCAI 2016: 2132-2138\n\nThomas Demeester, Tim Rocktäschel, Sebastian Riedel:\nLifted Rule Injection for Relation Embeddings. EMNLP 2016: 1389-1399\n\nand even neural-symbolic approaches with a long publication history. Unfortunately, \nnon of these approaches has been cited, giving the wrong impression that this is \nthe first paper that tackles the long lasting question of merging sub-symbolic and symbolic reasoning. BTW, there have been also other deep networks for optimisation, see e.g. \n\nBrandon Amos, J. Zico Kolter:\nOptNet: Differentiable Optimization as a Layer in Neural Networks. \nICML 2017: 136-145\n\nthat have also considered Sudoku. To summarise, I like very much the direction of the paper but it seems to be too early to be published. "", 'This paper describes a method called relational network to add relational reasoning capacity to deep neural networks. The previous approach can only perform a single step of relational reasoning, and was evaluated on problems that require at most three steps. The current method address the scalability issue and can solve tasks with orders of magnitude more steps of reasoning. The proposed methods are evaluated on two problems, Sudoku and Babi, and achieved state-of-the-art results. \n\nThe proposed method should be better explained. What’s the precise definition of interface? It’s claimed that other constraint propagation-based methods can solve Sudoku problems easily, but don’t respect the interface. It is hard to appreciate without a precise definition of interface. The proposed recurrent relational networks are only defined informally. A definition of the model as well as related algorithms should be defined more formally. \n\n\n\n']","[-20, -50, 50]","[50, 20, 0]","[""The sentiment score is slightly negative (-20) because the reviewer states that the paper is 'marginally below the acceptance threshold' and lists several cons. However, they also mention some pros and indicate they could be convinced otherwise, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'I think' and 'could do so' which maintain a polite tone. The reviewer also balances critique with positive feedback, demonstrating professional courtesy."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('well written and structured', 'addresses an important research question'), they express significant criticisms. The reviewer points out 'two major downsides' and states that the paper 'falls short' in discussing related work, suggesting the paper is 'too early to be published'. These criticisms outweigh the initial positive comments, resulting in a negative overall sentiment. The politeness score is 20 because the reviewer uses generally polite language ('Unfortunately', 'I like very much the direction of the paper') and provides constructive feedback. However, the criticism is direct and doesn't use overly softening language, keeping the score only slightly positive rather than highly polite."", ""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the paper's contributions and achievements, noting that it addresses scalability issues and achieves state-of-the-art results. However, the score is not higher due to the criticisms in the second paragraph. The politeness score is 0 (neutral) as the language is direct and professional, neither particularly polite nor rude. The reviewer provides both positive feedback and constructive criticism without using overly courteous or harsh language.""]"
"['The manuscript advocates to study the weight sharing in a more systematic way by proposing ArbNets which defines the weight sharing function as a hash function. In this framework, any existing neural network architectures, including CNN and RNN, could be incorporated into ArbNets.\n\nThe manuscript is not well written. There are multiple grammar errors and typos. Content-wise, it is already well known that CNN and RNN can be expressed as general MLP with weight sharing. The introduction of ArbNets does not bring much value or insight to this area. So it seems that most content before experimental section is common sense.\n\nIn the experimental section, it is interesting to see how different hash function with different level of entropy can affect the performance of neural nets. However, this single observation cannot enrich the whole manuscript. Two questions:\n(1) What is the definition of sparsity here, and how is it controlled?\n(2) There seems to be a step change in Figure 3. All the results are either between 10 to 20, or near 50. And the blue line goes up and down. Is this expected?', 'This paper proposes a general framework for studying weight sharing in neural networks. They further suggest two hash functions and study the role of different properties of these hash functions in the performance.\n\nThe paper is well-written and clear. It is a follow-up on Chen et al. (2015) which introduced HashedNets. Therefore, the idea of using hash functions is not novel. This paper suggests a framework to study different hash functions. However, the experimental results do not seem adequate to validate this framework. One issue here is lack of a baseline for performance comparison. Otherwise, the significance of the results is not clear.\n\n\n', ""This paper has limited novelty, the ideas has been previously proposed in HashedNet and Deep Compression. The experimental section is week, with only mnist and cifar results it's not convincing to the community whether this method is general. ""]","[-50, 20, -70]","[-20, 60, -20]","[""The sentiment score is -50 because the reviewer expresses significant criticism of the manuscript. They state that it is 'not well written' with 'multiple grammar errors and typos', and that the content before the experimental section is 'common sense' without bringing 'much value or insight'. The single interesting observation in the experimental section is deemed insufficient to 'enrich the whole manuscript'. These criticisms outweigh the initial neutral description of the manuscript's content, resulting in a negative sentiment overall. The politeness score is -20 because while the reviewer doesn't use overtly rude language, their criticisms are quite direct and blunt without much attempt to soften the blow. Phrases like 'it is already well known' and 'does not bring much value' come across as somewhat dismissive. The reviewer does ask questions at the end, which shows some engagement, but overall the tone is more critical than constructive or polite."", ""For the sentiment score, I assigned 20 (slightly positive) because the reviewer starts with a neutral description of the paper's content and then mentions that it is 'well-written and clear'. However, they also point out some limitations, such as lack of novelty and inadequate experimental results, which prevents a higher positive score. For the politeness score, I assigned 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths ('well-written and clear') before offering constructive criticism. They avoid harsh or dismissive language, instead using phrases like 'do not seem adequate' and 'the significance of the results is not clear', which maintain a professional and courteous tone."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper has 'limited novelty' and that the ideas have been proposed before. They also describe the experimental section as 'weak' and 'not convincing'. These are strong criticisms that indicate a negative view of the paper. The politeness score is -20 because while the language is not overtly rude, it is quite blunt and lacks any positive reinforcement or constructive suggestions. The use of phrases like 'limited novelty' and 'not convincing' without any softening language or positive aspects mentioned makes the tone somewhat impolite. However, it doesn't use explicitly rude language, so it's not at the extreme end of impoliteness.""]"
"['The authors approach the task of labeling histology images with just a single global label, with promising results on two different data sets. This is of high relevance given the difficulty in obtaining expert annotated data. At the same time the key elements of the presented approach remain identical to those in a previous study, the main novelty is to replace the final step of the previous architecture (that averages across a vector) with a multiplayer perceptron.  As such I feel that this would be interesting to present if there is interest in the overall application (and results of the 2016 CVPR paper), but not necessarily as a novel contribution to MIL and histology image classification.\n\nComments to the authors:\n\n* The intro starts from a very high clinical level. A introduction that points out specifics of the technical aspects of this application, the remaining technical challenges, and the contribution of this work might be appreciated by some of your readers.\n* There is preprocessing that includes feature extraction, and part of the algorithm that includes the same feature extraction. This is somewhat confusing to me and maybe you want to review the structure of the sections.  You are telling us you are using the first layer (P=1) of the ResNet50 in the method description, and you mention that you are using the pre-final layer in the preprocessing section. I assume you are using the latter, or is P=1 identical to the prefinal layer in your notation?  Tell us. Moreover, not having read Durand 2016, I would appreciate a few more technical details or formal description here and there.  Can you detail about the ranking method in Durand 2016, for example?\n* Would it make sense to discuss Durand 2016 in the base line methods section? \n* To some degree this paper evaluates WELDON (Durand 2016) on new data, and compares it against and an extended WELDON algorithm called CHOWDER that features the final MLP step. Results in table 1 suggest that this leads to some 2-5% performance increase which is a nice result.  I would assume that experimental conditions (training data, preprocessing, optimization, size of ensemble) are kept constant in between those two comparisons? Or is there anything of relevance that also changed (like size of the ensemble, size of training data) because the WELDON results are essentially previously generated results? Please comment in case there are differences. ', 'This paper proposes a deep learning (DL) approach (pre-trained CNNs) to the analysis of histopathological images for disease localization.\nIt correctly identifies the problem that DL usually requires large image databases to provide competitive results, while annotated histopathological data repositories are costly to produce and not on that size scale.\nIt also correctly identifies that this is a daunting task for human medical experts and therefore one that could surely benefit from the use of automated methods like the ones proposed.\n\nThe study seems sound from a technical viewpoint to me and its contribution is incremental, as it builds on existing research, which is correctly identified.\nResults are not always too impressive, but authors seem intent on making them useful for pathogists in practice (an intention that is always worth the effort).\nI think the paper would benefit from a more explicit statement of its original contributions (against contextual published research)\n\nMinor issues:\nRevise typos (e.g. title of section 2)\nPlease revise list of references (right now a mess in terms of format, typos, incompleteness', 'This paper describes a semi-supervised method to classify and segment WSI histological images that are only labeled at the whole image level. Images are tiled and tiles are sampled and encoded into a feature vector via a ResNET-50 pretrained on ImageNET. A 1D convolutional layer followed by a min-max layer and 2 fully connected layer compose the network. The conv layer produces a single value per tile. The min-max layer selects the R min and max values, which then enter the FC layers. A multi-instance (MIL) approach is used to train the model by backpropagating only instances that generate min and max values at the min-max layer. Experiments are run on 2 public datasets achieving potentially top performance. Potentially, because all other methods supposedly make use of segmentation labels of tumor, while this method only uses the whole image label.\n\nPrevious publications have used MIL training on tiles with only top-level labels [1,2] and this is essentially an incremental improvement on the MIL approach by using several instances (both min-negative and max-positive) instead of a single instance for backprop, as described in [3]. So, the main contribution here, is to adapt min-max MIL to the histology domain. Although the result are good and the method interesting, I think that the technical contribution is a bit thin for a ML conference and this paper may be a better fit for a medical imaging conference.\n\nThe paper is well written and easy to understand. \n\n\n\n[1] Hou, L., Samaras, D., Kurc, T. M., Gao, Y., Davis, J. E., & Saltz, J. H. (2016). Patch-based convolutional neural network for whole slide tissue image classification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 2424-2433).\n[2]  Cosatto, E., Laquerre, P. F., Malon, C., Graf, H. P., Saito, A., Kiyuna, T., ... (2013). Automated gastric cancer diagnosis on H&E-stained sections; training a classifier on a large scale with multiple instance machine learning. Medical Imaging, 2. 2013.\n[3] Durand, T., Thome, N., & Cord, M. (2016). Weldon: Weakly supervised learning of deep convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (pp. 4743-4752).']","[-20, 50, 50]","[60, 70, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the relevance and promising results of the work, they express doubts about its novelty and contribution to the field. The reviewer states that the key elements remain identical to a previous study and suggests it might not be a novel contribution to MIL and histology image classification. However, they do recognize the potential interest in the application and results.\n\nThe politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and ask clarifying questions rather than making harsh criticisms. The language used is respectful, using phrases like 'I would appreciate' and 'Please comment' when requesting additional information. The reviewer also acknowledges the positive aspects of the work, such as the 'promising results' and the 'nice result' of performance increase, which contributes to the overall polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's sound technical approach and its potential usefulness for pathologists, while also noting that the results are not always impressive and suggesting improvements. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and offering constructive criticism. The reviewer uses phrases like 'correctly identifies' and 'seems sound' to convey positive aspects, while politely suggesting improvements with phrases like 'would benefit from' and 'please revise'. The tone is professional and courteous, even when pointing out minor issues."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the good results and interesting method, but also points out that the technical contribution is 'a bit thin' and suggests it might be better suited for a medical imaging conference. The overall tone is constructive and appreciative of the work, despite some reservations. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and provides constructive feedback. The reviewer also compliments the paper as being 'well written and easy to understand'. The critique is presented in a professional and considerate manner, without harsh or dismissive language.""]"
"['This paper presents AMPNet, that addresses parallel training for dynamic networks. This is accomplished by building a static graph like IR that can serve as a target for compilation for high-level libraries such as tensor flow. In the IR each node of the computation graph is a parallel worker, and synchronization occurs when a sufficient number of gradients have been accumulated. The IR uses constructs such as concat, split, broadcast,.. allowing dynamic, instance dependent control flow decisions. The primary improvement in training performance is from reducing synchronization costs.\n\nComments for the author:\n\nThe paper proposes a solution to an important problem of model parallel training especially over dynamic batching that is increasingly important as we see more complex models where batching is not straightforward. The proposed solution can be effective. However, this is not really evident from the evaluation. Furthermore, the paper can be a little dense read for the ICLR audience. I have the following additional concerns:\n\n1) The paper stresses new hardware throughout the paper. The paper also alludes to “simulator"" of a 1 TFLOPs FPGA in the conclusion. However, your entire evaluation is over CPU. The said simulator is a bunch of sleep() calls (unless some details are skipped). I would encourage the authors to remove these references since these new devices have very different hardware behavior. For example, on a real constrained device, you may not enjoy a large L2 cache which you are benefitting from by doing an entire evaluation over CPUs. Likewise, the vector instruction processing behavior is also very different since these devices have limited power budgets and may not be able to support AVX style instructions. Unless an actual simulator like GEM5 is used, a correct representation of what hardware environment is being used is necessary before making claims that this is ideal for emerging hardware.\n\n2) To continue on the hardware front and the evaluation, I feel for this paper to be accepted or appreciated, a simulated hardware is not necessary. Personally, I found the evaluation with simulated sleep functions more confusing than helpful. An appropriate evaluation for this paper can be just benefits over CPU or GPUs, For example, you have a 7 TFLOPS device (e.g. a GPU or a CPU). Existing algorithms extract X TFLOPs of processing power and using your IR/system one gets Y effective TFLOPs and Y>X. This is all that is required. Currently, looking at your evaluation riddled with hypothetical hardware, it is unclear to me if this is helpful for existing hardware. For example, in Table 1, are Tensorflow numbers only provided over the 1 TFLOPs device (they correspond to the 1 TFLOPs column for all workloads except for MNIST)?  Do you use the parallelism at all in your Tensorflow baseline?  Please clarify.\n\n3) How do you compare for dynamic batching with dynamic IR platforms like pytorch? Furthermore, more details about how dynamic batching is happening in benchmarks mentioned in Table 1 will be nice to have. Finally, an emphasis on the novel contributions of the paper will also be appreciated.\n\n4) Finally, the evaluation appears to be sensitive to the two hyper-parameters introduced. Are they dataset specific? I feel tuning them would be rather cumbersome for every model given how sensitive they are (Figure 5).\n', 'The paper describes a model-parallel training framework/algorithm that is specialized for new devises including FPGA. Because of the small memory of those devices, model-parallel training is necessary. Most current other frameworks are for model parallelism, so in this sense, the framework proposed by the authors is different and original. The framework includes a few interesting ideas including using intermediate representation (IR) to express static computation graph and execute it as dynamic control flow, combining pipeline model parallelism and data parallelism by splitting or replicating certain layers, and enabling asynchronous training, etc.  \n\nSome concerns/questions are \n1) The framework is targeted at devices like FPGA, but the implementation is a multicore CPU SMP. It makes the computational result less convincing. Also, does the implementation use threading or message passing?\n2) Pipeline model parallelism seems need a lot of load balance tuning. The reported speedup results confirm this conjecture. Can the limitation of pipeline model parallelism be improved?\n\nPage 4, in the ""min_update_interval"" paragraph, why ""Small min update interval may increase gradient staleness.""? I would think it decreases staleness. \n\nThe paper is clearly written and easy to follow. \n\n', 'This paper proposes new direction for asynchronous training. While many synchronous and asynchronous approaches for data parallelism have been proposed and implemented in the past, the space of asynchronous model parallelism hasn\'t really been explored before. This paper discusses an implementation of this approach and compares the results on dynamic neural networks as compared to existing parallel approaches.\n\nPros:\n- Paper seems to cover and contrast well with the existing approaches and is able to clarify where it differs from existing papers.\n- The new approach seems to show positive results on certain dynamic neural network problems.\n\nCons:\n- Data parallelism is a very commonly used technique for scaling. While the paper mentions support for it, the results are only showed on a toy problem, and it is unclear that it will work well for real problems. It will be great to see more results that use multiple replicas.\n- As the authors mention the messages also encapsulate meta-data or ""state"" as the authors refer to it. This does seem to make their compiler more complex. This doesn\'t seem to be a requirement for their design and proposal, and it will be good to see explorations to improve on this in the future.\n- Comparisons with Dynet (somewhat hidden away) that offers auto-batching in a dynamic mode aren\'t very positive.\n\nQuestions: \n- It appears that only a single copy of the parameters is kept, thus it is possible that some of the gradients may be computed with newer values than what the forward computation used. Is this true? Does this cause convergence issues?\n\nOverall it seems like a valuable area for exploration, especially given the growing interest in dynamic neural networks.\n\n[Update] Lowered rating based on other feedback and revisiting empirical results. The ideas are still interesting, but the empirical results are less convincing.']","[-20, 60, 20]","[60, 80, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem and potential effectiveness of the solution, they express several concerns and criticisms about the evaluation, hardware claims, and comparison with existing platforms. The overall tone suggests that significant improvements are needed before the paper can be accepted.\n\nThe politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I would encourage the authors' and 'Please clarify' which are polite ways of suggesting improvements. The reviewer also acknowledges the potential of the work before diving into criticisms, which is a courteous approach. However, the score is not higher because the review is direct in pointing out flaws and doesn't use overly deferential language."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the originality and interesting ideas of the paper, describing it as 'different and original' with 'a few interesting ideas'. They also mention that the paper is 'clearly written and easy to follow'. However, the score is not higher due to the 'concerns/questions' raised, which indicate some limitations in the study. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before raising concerns. They phrase their criticisms as questions or concerns rather than direct criticisms, and use neutral language like 'Some concerns/questions are...' The reviewer also ends on a positive note about the paper's clarity, which contributes to the polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's value and novelty, stating it 'proposes new direction' and is a 'valuable area for exploration'. However, the score is tempered by several cons and questions raised. The reviewer also mentions lowering their initial rating based on revisiting empirical results. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, balances pros and cons, and phrases criticisms constructively. They use phrases like 'it will be great to see' and 'it will be good to see' when suggesting improvements, which maintains a polite and encouraging tone.""]"
"[""UPDATED COMMENT\nI've improved my score to 6 to reflect the authors' revisions to the paper and their response to my and R2's comments. I still think the work is somewhat incremental, but they have done a good job of exploring the idea (which is nice).\n\nORIGINAL REVIEW BELOW\n\nThe paper introduces an architecture that linearly interpolates between ResNets and vanilla deep nets (without skip connections). The skip connections are penalized by Lagrange multipliers that are gradually phased out during training. The resulting architecture outperforms vanilla deep nets and sometimes approaches the performance of ResNets.\n\nIt’s a nice, simple idea. However, I don’t think it’s sufficient for acceptance. Unfortunately, this seems to be a simple idea that doesn't work as well as the simpler idea (ResNets) that inspired it. Moreover, the experiments are weak in two senses: (i) there are lots of obvious open questions that should have been explored and closed, see below, and (ii) the results just aren’t that good. \n\nComments:\n\n1. Why force the Lag. multipliers to 1 at the end of training? It seems easy enough to treat the alphas as just more parameters to optimize with gradient descent. I would expect the resulting architecture to perform at least as well as variable action nets. If not, I’d be curious as to why.\n\n2.Similarly, it’s not obvious that initializing the multipliers at 0.5 is the best choice. The “looks linear” initialization proposed in “The shattered gradients problem” (Balduzzi et al) implies that alpha=0 may work better. Did the authors try any values besides 0.5? \n\n3. The final paragraph of the paper discusses extending the approach to architectures with skip-connections. Firstly, it’s not clear to me what this would add, since the method is already interpolating in some sense between vanilla and resnets. Secondly, why not just do it? \n\n"", 'Update (original review below):\nThe authors have addressed several of the reviewers\' comments and improved the paper.\nThe motivation has certainly been clarified, but in my opinion it is still hazy. The paper does use skip connections, but the difference is that they are phased out over training. So I think that the motivation behind introducing this specific difference should be clear. Is it to save the additional (small) overhead of using skip connections?\nNevertheless, the additional experiments and clarifications are very welcome.\n\nFor the newly added case of VAN(lambda=0), please note the strong similarity to https://arxiv.org/abs/1611.01260 (ICLR2017 reviews at https://openreview.net/forum?id=Sywh5KYex). In that report \\alpha_l is a scalar instead of a vector. \n\nAlthough it is interesting, the above case case also calls into question the additional value brought by the use of constrained optimization, a main contribution of the paper.\n \nIn light of the above, I have increased my score since I find this to be an interesting approach, but in my opinion the significance of the results as they stand is low. The paper demonstrates that it is possible to obtain very deep plain networks (without skip connections) with improved performance  through the use of constrained optimization that gradually removes skip connections, but the value of this demonstration is unclear because a) consistent improvements over past work or the \\lambda=0 case were not found, and b) The technique still relies on skip connections in a sense so it\'s not clear that it suggests a truly different method of addressing the degradation problem. \n\nOriginal Review\n=============\nSummary:\nThe contribution of this paper is a method for training deep networks such that skip connections are present at initialization, but gradually removed during training, resulting in a final network without any skip connections.\nThe paper first proposes an approach based on a formulation of deep networks with (non-parameterized, non-gated) skip connections with an equality constraint that effectively removes the skip connections when satisfied. It is proposed to optimize the formulation using the method of Lagrange multipliers.\nA toy model with a single unit is used to illustrate the basic ideas behind the method. Finally, experimental results for the task of image classification are reported using the MNIST, Fashion-MNIST, and CIFAR datasets.\n\nQuality and significance:\nThe proposed methodology is simple and straightforward. The analysis with the toy network is interesting and helps illustrate the method. However, my main concerns with this paper are related to motivation and experiments.\n\nThe motivation of the work is not clear at all. The stated goal is to address some of the issues related to the role of depth in deep networks, but I think it should be clarified which specific issues in particular are relevant to this method and how they are addressed. One could additionally consider that removing the skip connections at the end of training reduces the computational expense (slightly), but beyond that the expected utility of this investigation is very hazy from the description in the paper.\n\nFor MNIST and MNIST-Fashion experiments, the motivation is mentioned to be similar to Srivastava et al. (2015), but in that study the corresponding experiment was designed to test if deeper networks could be optimized. Here, the generalization error is measured instead, which is heavily influenced by regularization. Moreover, only some architectures appear to employ batch normalization, which is a potent regularizer. The general difference between plain and non-plain networks is very likely due to optimization difficulties alone, and due to the above issues further comparisons can not be made from the results. \n\nFor the CIFAR experiments, the experiment design is reasonable for a general comparison. Similar experimental setups have been used in previous papers to report that a proposed method can achieve good results, but there is no doubt that this does not make a rigorous comparison without employing expensive hyper-parameter searches. This is not the fault of the present paper but an unfortunate tradition in the field. Nevertheless, it is important to note that direct comparison should not be made among approaches with key differences. For the reported results, Fitnets and Highway Networks did not use Batch Normalization (which is a powerful regularizer) while VANs and Resnets do. Moreover, it is important to report the training performance of deeper VANs (which have a worse generalization error) to clarify if the VANs suffered difficulties in optimization or generalization.\n\nClarity:\nThe paper is generally well-written and easy to read. There are some clarity issues related to the use of the term ""activation function"" and a typo in an equation but the authors are already aware of these.', 'EDIT: The rating has been changed. See thread below for explanation / further comments.\n\nORIGINAL REVIEW: In this paper, the authors present a new training strategy, VAN, for training very deep feed-forward networks without skip connections (henceforth called VDFFNWSC) by introducing skip connections early in training and then gradually removing them. \n\nI think the fact that the authors demonstrate the viability of training VDFFNWSCs that could have, in principle, arbitrary nonlinearities and normalization layers, is somewhat valuable and as such I would generally be inclined towards acceptance, even though the potential impact of this paper is limited because the training strategy proposed is (by deep learning standards) relatively complicated, requires tuning two additional hyperparameters in the initial value of \\lambda as well as the step size for updating \\lambda, and seems to have no significant advantage over just using skip connections throughout training. So my rating based on the message of the paper would be 6/10.\n\nHowever, there appear to be a range of issues. As long as those issues remain unresolved, my rating is at is but if those issues were resolved it could go up to a 6.\n\n+++ Section 3.1 problems +++\n\n- I think the toy example presented in section 3.1 is more confusing than it is helpful because the skip connection you introduce in the toy example is different from the skip connection you introduce in VANs. In the toy example, you add (1 - \\alpha)wx whereas in the VANs you add (1 - \\alpha)x. Therefore, the type of vanishing gradient that is observed when tanh saturates, which you combat in the toy model, is not actually combated at all in the VAN model. While it is true that skip connections combat vanishing gradients in certain situations, your example does not capture how this is achieved in VANs.\n- The toy example seems to be an example where Lagrangian relaxation fails, not where it succeeds. Looking at figure 1, it appears that you start out with some alpha < 1 but then immediately alpha converges to 1, i.e. the skip connection is eliminated early in training, because wx is further away from y than tanh(wx). Most of the training takes place without the skip connection. In fact, after 10^4 iterations, training with and without skip connection seem to achieve the same error. It appears that introducing the skip connection was next to useless and the model failed to recognize the usefulness of the skip connection early in training.\n- Regarding the optimization algorithm involving \\alpha^* at the end of section 3: It looks to me like a hacky, unprincipled method with no guarantees that just happened to work in the particular example you studied. You motivate the choice of \\alpha^* by wanting to maximize the reduction in the local linear approximation to \\mathcal{C} induced by the update on w. However, this reduction grows to infinity the larger the update is. Does that mean that larger updates are always better? Clearly not. If we wanted to reduce the size of the objective according to the local linear approximation, why wouldn\'t we choose infinitely large step sizes? Hence, the motivation for the algorithm you present is invalid. Here is an example where this algorithm fails: consider the point (x,y,w,\\alpha,\\lambda) = (100, \\sigma(100), 1.0001, 1, 1). Here, w has almost converged to its optimum w* = 1. Correspondingly, the derivative of C is a small negative value. However, \\alpha* is actually 0, and this choice would catapult w far away from w*.\n\nIf I haven\'t made a mistake in my criticisms above, I strongly suggest removing section 3.1 entirely or replacing it with a completely new example that does not suffer from the above issues.\n\n+++ ResNet scaling +++\n\nThere is a crucial difference between VANs and ResNets. In the VAN initial state (alpha = 0.5), both the residual path and the skip path are multiplied by 0.5 whereas for ResNet, neither is multiplied by 0.5. Because of this, the experimental results between the two architectures are incomparable.\n\nIn a question I posed earlier, you claimed that this scaling makes no difference when batch normalization is used. I disagree. Let\'s look at an example. Consider ResNet first. It can be written as x + r_1 + r_2 + .. + r_B, where r_b is the value computed by residual block b. Now let\'s assume we insert a scaling constant after each residual block, say c = 0.5. Then the result is c^{B}x + c^{B-1}r_1 + c^{B-2}r_2 + .. + r_B. Therefore, contributions of lower blocks vanish exponentially. This effect is not combated by batch normalization.\n\nSo the learning dynamics for VAN and ResNet are very different because of this scaling. Therefore, there is an open question: are the differences in results between VAN and ResNet in your experiments caused by the removal of skip connections during training or by this scaling? Without this information, the experiments have limited value. In fact, I suspect that the vanishing of the contribution of lower blocks bears more responsibility for the declining performance of VAN at higher depths than the removal of skip connections.\n\nIf my assessment of the situation is correct, I would like to ask you to repeat your experiments with the following two settings: \n\n- ResNet where after each block you multiply the result of the addition by 0.5, i.e. x_{l+1} = 0.5\\mathcal{F}(x_l) + 0.5x_l\n- VAN with the following altered equation: x_{l+1} = \\mathcal{F}(x_l) + (1-\\alpha)x_l, i.e. please remove the alpha in front of \\mathcal{F}. Also, initialize \\alpha to zero. This ensures that VAN starts out as a regular ResNet.\n\n+++ writing issues +++\n\nTitle:\n\n- ""VARIABLE ACTIVATION NETWORKS: A SIMPLE METHOD TO TRAIN DEEP FEED-FORWARD NETWORKS WITHOUT SKIP-CONNECTIONS"" This title can be read in two different ways. (A) [Train] [deep feed-forward networks] [without skip-connections] and (B) [Train] [deep feed-forward networks without skip connections]. In (A), the `without skip-connections\' modifies the `train\' and suggests that training took place without skip connections. In (B), the `without skip-connections\' modifies `deep feed-forward networks\' and suggests that the network trained has no skip connections. You must mean (B), because (A) is false. Since it is not clear from reading the title whether (A) or (B) is true, please reword it.\n\nAbstract:\n\n- ""Part of the success of ResNets has been attributed to improvements in the conditioning of the optimization problem (e.g., avoiding vanishing and shattered gradients). In this work we propose a simple method to extend these benefits to the context of deep networks without skip-connections."" Again, this is ambiguous. To me, this sentence implies that you extend the benefit of avoiding vanishing and exploding gradients to fully-connected networks without skip connections. However, nowhere in your paper do you show that trained VANs have less exploding / vanishing gradients than fully-connected networks trained the old-fashioned way. Again, please reword or include evidence.\n- ""where the proposed method is shown to outperform many architectures without skip-connections"" Again, this sentence makes no sense to me. It seems to imply that VAN has skip connections. But in the abstract you defined VAN as an architecture without skip connections. Please make this more clear.\n\nIntroduction:\n- ""Indeed, Zagoruyko & Komodakis (2016) demonstrate that it is better to increase the width of ResNets than the depth, suggesting that perhaps only a few layers are learning useful representations."" Just because increasing width may be better than increasing depth does not mean that deep layers don\'t learn useful representations. In fact, the claim that deep layers don\'t learn useful representations is directly contradicted by the paper.\n\nsection 3.1:\n- replace ""to to"" by ""to"" in the second line\n\nsection 4:\n- ""This may be a result of the ensemble nature of ResNets (Veit et al., 2016), which does not play a significant role until the depth of the network increases."" The ensemble nature of ResNet is a drawback, not an advantage, because it causes a lack of high-order co-adaptataion of layers. Therefore, it cannot contribute positively to the performance or ResNet.\n\nAs mentioned in earlier comments, please reword / clarify your use of ""activation function"". It is generally used a synonym for ""nonlinearity"", so please use it in this way. Change your claim that VAN is equivalent to PReLU. Please include your description of how your method can be extended to networks which do allow for skip connections.\n\n+++ Hyperparameters +++\n\nSince the initial values of \\lambda and \\eta\' are new hyperparameters, include the values you chose for them, explain how you arrived at those values and plot the curve of how \\lambda evolves for at least some of the experiments.']","[-20, -20, -50]","[50, 60, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges it's a 'nice, simple idea', they ultimately state it's 'not sufficient for acceptance' and that 'the results just aren't that good'. They also mention that the experiments are 'weak'. However, the score isn't deeply negative because the reviewer does note some positive aspects and provides constructive feedback. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, such as 'It's a nice, simple idea' and frames criticisms constructively. They also use phrases like 'I would expect' and 'I'd be curious' which maintain a respectful tone. The reviewer provides specific, actionable feedback without using harsh or dismissive language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some improvements and interesting aspects of the paper, they still express significant concerns about the motivation, significance, and results. The reviewer states that 'the significance of the results as they stand is low' and questions the value of the demonstration. However, it's not entirely negative as they mention that it's an 'interesting approach' and have 'increased my score'. The politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They acknowledge improvements, use phrases like 'please note' and 'it is interesting', and provide constructive feedback without harsh criticism. The tone is academic and objective, maintaining politeness while still expressing concerns."", ""Sentiment score: The review starts with a somewhat positive tone, acknowledging the value of the authors' work. However, it quickly shifts to a more critical stance, pointing out numerous issues with the paper's methodology, experiments, and writing. The reviewer suggests major revisions and expresses significant concerns, which outweigh the initial positive sentiment. This results in a negative overall sentiment score of -50.\n\nPoliteness score: The reviewer maintains a professional and respectful tone throughout, using phrases like 'I think,' 'I suggest,' and 'If my assessment is correct.' They provide detailed explanations for their criticisms and offer constructive suggestions for improvement. However, the review is not overly polite or deferential, maintaining a neutral to slightly positive politeness level. This results in a politeness score of 20.\n\nThe scores are based on the overall tone, language use, and balance between criticism and constructive feedback throughout the review.""]"
"['This paper presents a variant of auto-encoder that relaxes the decoder targets to be neighbors of a data point. Different from original auto-encoder, where data point x and the decoder output \\hat{x} are forced to be close, the neighbor-encoder encourage the decoder output to be similar to the neighbors of the input data point. By considering the neighbor information, the decoder targets would have smaller intra-class distances, thus larger inter-class distances, which helps to learn better separated latent representation of data in terms of data clusters. The authors conduct experiments on several real but relative small-scale data sets, and demonstrate the improvements of learned latent representations by using neighbors as targets. \n\nThe method of neighbor prediction is a simple and small modification of the original auto-encoder, but seems to provide a way to augment the targets such that intra-class distance of decoder targets can be tightened. Improvements in the conducted experiments seem significant compared to the most basic auto-encoder.\n\nMajor issues:\n\nThere are some unaddressed theoretical questions. The optimal solution to predict the set of neighbor points in mean-squared metric is to predict the average of those points, which is not well justified as the averaged image can easily fall off the data manifold. This may lead to a more blurry reconstruction when k increases, despite the intra-class targets are tight. It can also in turn harm the latent representation when euclidean neighbors are not actually similar (e.g. images in cifar10/imagenet that are not as simple as 10 digits). This seems to be a defect of the neighbor-encoder method and is not discussed in the paper.\n\nThe data sets used in the experiments  are relatively small and simple, larger-scale experiments should be conducted. The fluctuations in Figure 9 and 10 suggest the significant variances in the results. Also, more complicated data/images can decrease the actual similarities of euclidean neighbors, thus affecting the results.\n\nThe baselines are weak. Only the most basic auto-encoder is compared, no additional variants or other data augmentation techniques are compared. It is possible other variants improve the basic auto-encoder in similar ways. \n\nSome results are not very well explained. It seems the performance increases monotonically as the number of neighbors increases (Figure 5, 9, 10). Will this continue or when will the performance decrease? I would expect it to decrease as the far away neighbors will be dissimilar. The authors can either attach the nearest neighbors figures or their statistics, and provide explanations on when and why the performance decrease is expected.\n\nSome notations are confusing and need to be improved. For example, X and Y are actually the same set of images, the separation is a bit confusing; y_i \\in y in last paragraph of page 4 is incorrect, should use something like y_i in N(y).', 'A representation learning framework from unsupervised data, based not on auto-encoding (x in, x out), but on neighbor-encoding (x in, N(x) out, where N(.) denotes the neighbor(s) of x) is introduced. \n\nThe underlying idea is interesting, as such, each and every degree of freedom do not synthesize itself similar to the auto-encoder setting, but rather synthesize a neighbor, or k-neighbors. The authors argue that this form of unsupervised learning is more powerful compared to the standard auto-encoder setting, and some preliminary experimental proof is also provided. \n\nHowever, I would argue that this is not a completely abstract - unsupervised representation learning setting since defining what is ""a neighbor"" and what is ""not a neighbor"" requires quite a bit of domain knowledge. As we all know, the euclidian distance, or any other comparable norm, suffers from the ""Curse of Dimensionality"" as the #-of-Dimensions increase. \n\nFor instance, in section 4.3, the 40-dimensional feature vector space is used to define neighbors in. It would be great how the neighborhood topology in that space looks like.\n\nAll in all, I do like the idea as a concept but I am wary about its applicability to real data where defining a good neighborhood metric might be a major challenge of its own. ', ""This paper describes a generalization of autoencoders that are trained to reconstruct a close neighbor of its input, instead of merely the input itself. Experiments on 3 datasets show that this yields better representations in terms of post hoc classification with a linear classifier or clustering, compared to a regular autoencoder.\n\nAs the authors recognize, there is a long history of research on variants of autoencoders. Unfortunately this paper compares with none of them. While the authors suggest that, since these variations can be combined with the proposed neighbor reconstruction variant, it's not necessary to compare with these other variations, I disagree. It could very well be that this neighbor trick makes other methods worse for instance. \n\nAt the very least, I would expect a comparison with denoising autoencoders, since they are similar if one thinks of the use of neighbors as a structured form of noise added to the input. It could very well be in fact that simply adding noise to the input is sufficient to force the autoencoder to learn a valuable representation, and that the neighbor reconstruction approach is simply an overly complicated approach of achieving the same results. This is an open question right now that I'd expect this paper to answer.\n\nFinally, I think results would be more impressive and likely to have impact if the authors used datasets that are more commonly used for representation learning, so that a direct performance comparison can be made with previously published results. CIFAR 10 and SVHN would be good alternatives.\n\nOverall, I'm afraid I must recommend that this paper be rejected.\n""]","[20, 20, -60]","[60, 60, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the method's improvements and potential, but also raises several major issues and concerns. The initial paragraphs express interest in the approach and its results, but the subsequent 'Major issues' section outlines significant criticisms and limitations of the work. The politeness score is moderately high (60) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'seems to provide' and 'It is possible' which soften criticisms, and they offer specific suggestions for improvement rather than just pointing out flaws. The language is consistently respectful and focused on the work rather than the authors personally."", ""The sentiment score is slightly positive (20) because the reviewer expresses interest in the idea and acknowledges its potential ('The underlying idea is interesting', 'I do like the idea as a concept'). However, they also raise concerns about its applicability and limitations, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the merits of the work while offering constructive criticism. They use phrases like 'It would be great' and 'I would argue' which maintain a polite tone while presenting their views. The reviewer balances positive comments with concerns in a professional manner, avoiding harsh or dismissive language."", ""The sentiment score is -60 because the reviewer recommends rejection and points out several significant shortcomings of the paper. The reviewer acknowledges some positive aspects (e.g., 'Experiments on 3 datasets show that this yields better representations'), but the overall tone is critical. The politeness score is 20 because the reviewer uses polite language and constructive criticism throughout, such as 'I would expect' and 'I think results would be more impressive if...'. However, the final recommendation is direct without softening language, which prevents a higher politeness score. The reviewer also uses phrases like 'I'm afraid I must recommend' which adds a polite tone to the negative conclusion.""]"
"['Summary: This work proposes a way to create 3D objects to fool the classification of their pictures from different view points by a neural network.\nRather than optimizing the log-likelihood of a single example, the optimization if performed over a the expectation of a set of transformations of sample images. Using an inception v3 net, they create adversarial attacks on a subset of the imagenet validation set transformed by translations, lightening conditions, rotations, and scalings among others, and observe a drop of the classifier accuracy performance from 70% to less than 1%. They also create two 3D printed objects which most pictures taken from random viewpoints are fooling the network in its class prediction.\n \n\nMain comments:\n- The idea of building 3D adversarial objects is novel so the study is interesting. However, the paper is incomplete, with a very low number of references, only 2 conference papers if we assume the list is up to date. \nSee for instance Cisse et al. Houdini: fooling Deep Structured Prediction Models, NIPS 2017 for a recent list of related work in this research area.\n- The presentation of the results is not very clear. See specific comments below.\n- It would be nice to include insights to improve neural nets to become less sensitive to these attacks.\n\n\nMinor comments:\nFig1 : a bug with color seems to have been fixed\nModel section: be consistent with the notations. Bold everywhere or nowhere\nResults: The tables are difficult to read and should be clarified:\nWhat does the l2 metric stands for ? \nHow about min, max ?\nAccuracy -> classification accuracy\nModels -> 3D models\nDescribe each metric (Adversarial, Miss-classified, Correct)\n', 'The paper proposes a method to synthesize adversarial examples that remain robust to different 2D and 3D perturbations. The paper shows this is effective by transferring the examples to 3D objects that are color 3D-printed and show some nice results.\n\nThe experimental results and video showing that the perturbation is effective for different camera angles, lighting conditions and background is quite impressive. This work convincingly shows that adversarial examples are a real-world problem for production deep-learning systems rather than something that is only academically interesting.\n\nHowever, the authors claim that standard techniques require complete control and careful setups (e.g. in the camera case) is quite misleading, especially with regards to the work by Kurakin et. al. This paper also seems to have some problems of its own (for example the turtle is at relatively the same distance from the camera in all the examples, I expect the perturbation wouldn\'t work well if it was far enough away that the camera could not resolve the HD texture of the turtle).\n\nOne interesting point this work raises is whether the algorithm is essentially learning universal perturbations (Moosavi-Dezfooli et. al). If that\'s the case then complicated transformation sampling and 3D mapping setup would be unnecessary. This may already be the case since the training set already consists of multiple lighting, rotation and camera type transformations so I would expect universal perturbations to already produce similar results in the real-world.\n\nMinor comments:\nSection 1.1: ""a affine"" -> ""an affine""\nTypo in section 3.4: ""of a of a""\nIt\'s interesting in figure 9 that the crossword puzzle appears in the image of the lighthouse.\n\nMoosavi-Dezfooli, S. M., Fawzi, A., Fawzi, O., & Frossard, P. Universal adversarial perturbations. CVPR 2017.', 'The authors present a method to enable robust generation of adversarial visual\ninputs for image classification.\n\nThey develop on the theme that \'real-world\' transformations typically provide a\ncountermeasure against adversarial attacks in the visual domain, to show that\ncontextualising the adversarial exemplar generation by those very\ntransformations can still enable effective adversarial example generation.\n\nThey adapt an existing method for deriving adversarial examples to act under a\nprojection space (effectively a latent-variable model) which is defined through\na transformations distribution.\n\nThey demonstrate the effectiveness of their approach in the 2D and 3D\n(simulated and real) domains.\n\nThe paper is clear to follow and the objective employed appears to be sound. I\nlike the idea of using 3D generation, and particularly, 3D printing, as a means\nof generating adversarial examples -- there is definite novelty in that\nparticular exploration for adversarial examples.\n\nI did however have some concerns:\n\n1. What precisely is the distribution of transformations used for each\n   experiment? Is it a PCFG? Are the different components quantised such that\n   they are discrete rvs, or are there still continuous rvs? (For example, is\n   lighting discretised to particular locations or taken to be (say) a 3D\n   Gaussian?) And on a related note, how were the number of sampled\n   transformations chosen?\n\n   Knowing the distribution (and the extent of it\'s support) can help situate\n   the effectiveness of the number of samples taken to derive the adversarial\n   input.\n\n2. While choosing the distance metric in transformed space, LAB is used, but\n   for the experimental results, l_2 is measured in RGB space -- showing the\n   RGB distance is perhaps not all that useful given it\'s not actually being\n   used in the objective. I would perhaps suggest showing LAB, maybe in\n   addition to RGB if required.\n\n3. Quantitative analysis: I would suggest reporting confidence intervals;\n   perhaps just the 1st standard deviation over the accuracies for the true and\n   \'adversarial\' labels -- the min and max don\'t help too much in understanding\n   what effect the monte-carlo approximation of the objective has on things.\n\n   Moreover, the min and max are only reported for the 2D and rendered 3D\n   experiments -- it\'s missing for the 3D printing experiment.\n\n4. Experiment power: While the experimental setup seems well thought out and\n   structured, the sample size (i.e, the number of entities considered) seems a\n   bit too small to draw any real conclusions from. There are 5 exemplar\n   objects for the 3D rendering experiment and only 2 for the 3D printing one.\n\n   While I understand that 3D printing is perhaps not all that scalable to be\n   able to rattle off many models, the 3D rendering experiment surely can be\n   extended to include more models? Were the turtle and baseball models chosen\n   randomly, or chosen for some particular reason? Similar questions for the 5\n   models in the 3D rendering experiment.\n\n5. 3D printing experiment transformations: While the 2D and 3D rendering\n   experiments explicitly state that the sampled transformations were random,\n   the 3D printing one says ""over a variety of viewpoints"". Were these\n   viewpoints chosen randomly?\n\nMost of these concerns are potentially quirks in the exposition rather than any\nissues with the experiments conducted themselves. For now, I think the\nsubmission is good for a weak accept –- if the authors address my concerns, and/or\ncorrect my potential misunderstanding of the issues, I\'d be happy to upgrade my\nreview to an accept.']","[-20, 50, 50]","[50, 75, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty of the idea ('The idea of building 3D adversarial objects is novel so the study is interesting'), they also point out several significant shortcomings. These include the paper being 'incomplete, with a very low number of references', unclear presentation of results, and lack of insights for improvement. The overall tone suggests the paper needs substantial work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use polite language such as 'It would be nice to include...' and frame criticisms as suggestions for improvement rather than harsh judgments. The reviewer also balances negative feedback with positive acknowledgments of the paper's strengths. However, the review doesn't go out of its way to be exceptionally polite, maintaining a fairly neutral professional tone overall."", 'The sentiment score is 50 (slightly positive) because the reviewer acknowledges the impressive aspects of the work, such as the effectiveness of the method and its real-world implications. However, they also point out some limitations and misleading claims, balancing the positive with critical feedback. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the strengths of the paper before presenting criticisms. They offer constructive feedback and suggestions for improvement, and even point out minor typos in a helpful manner. The tone remains professional and courteous throughout the review.', ""The sentiment score is 50 (slightly positive) because the reviewer expresses appreciation for aspects of the paper ('I like the idea...', 'there is definite novelty...') and suggests a 'weak accept', indicating overall positive sentiment. However, they also raise several concerns, which tempers the positivity. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively ('I would suggest...', 'I did however have some concerns:'), and expresses willingness to upgrade their review if concerns are addressed. The reviewer also acknowledges potential misunderstandings on their part, which is a polite approach to criticism.""]"
"['Paper Summary:\n\nThis paper looks at empirically measuring neural network architecture expressivity by examining performance on a variety of complex datasets, measuring dataset complexity with algebraic topology. The paper first introduces the notion of topological equivalence for datasets -- a desirable measure to use as it is invariant to superficial differences such as rotation, translation and curvature. The definition of homology from algebraic topology can then be used as a robust measure of the ""complexity"" of a dataset. This notion of difficulty focuses roughly on determining the number of holes of dimension n (for varying n) there are in the dataset, with more holes roughly leading to a more complex connectivity pattern to learn. They provide a demonstration of this on two synthetic toy datasets in Figure 1, training two (very small -- 12 and 26 neuron) single hidden layer networks on these two datasets, where the smaller of the two networks is unable to learn the data distribution of the second dataset. These synthetic datasets have a well defined data distribution, and for an empirical sample of N points, a (standard) method of determining connectivity by growing epsilon balls around each datapoint in section 2.3.\n\nThe authors give a theoretical result on the importance of homology: if a binary classifier has support homology not equal to the homology of the underlying dataset, then there is at least one point that is misclassified by the classifier. Experiments are then performed with single hidden layer networks on synthetic datasets, and a phase transition is observed: if h_phase is the number of hidden units where the phase transition happens, and h\' < h < h_phase, h\' has higher error and takes longer to converge than h. Finally, the authors touch on computing homology of real datasets, albeit with a low dimensional projection (e.g. down to 3 dimensions for CIFAR-10).\n\nMain Comments\n\nThe motivation to consider algebraic topology and dataset difficulty is interesting, but I think this method is ultimately ill suited and unable to be adapted to more complex and interesting settings. In particular, the majority of experiments and justification of this method comes from use on a low dimensional manifold with either known data distribution, or with a densely sampled manifold. (The authors look at using CIFAR-10, but project this down to 3 dimensions -- as current methods for persistent homology cannot scale -- which somewhat invalidates the goal of testing this out on real data.) This is an important and serious drawback because it seems unlikely that the method described in Figure 3 of determining the connectivity patterns of a dataset are likely to yield insightful results in a high dimensional space with very few datapoints (in comparison to 2^{dimension}), where distance between datapoints is unlikely to have any nice class related correspondence.\n\nFurthermore, while part of the motivation of this paper is to use dataset complexity measured with topology to help select architectures, experiments demonstrating that this might be useful are very rudimentary. All experiments only look at single hidden layers, and the toy task in Figure 1 and in section 3.2.1 and Figure 5 use extremely small networks (hidden size 12-26). It\'s hard to be convinced that these results necessarily generalize even to other larger hidden layer models. On real datasets, exploring architectures does not seem to be done at all (Section 4).\n\n\nMinor Comments\nSome kind of typo in Thm 1? (for all f repeated twice)\nSmall typos (missing spaces) in related work and conclusion\nHow is h_phase determined? Empirically? (Or is there a construction?)\n\nReview Summary:\n\nThis paper is not ready to be accepted.', 'The authors propose to use the homology of the data as a measurement of the expressibility of a deep neural network. The paper is mostly experimental. The theoretical section (3.1) is only reciting existing theory (Bianchini et al.). Theorem 3.1 is not surprising either: it basically says spaces with different topologies differ at some parts. \n\nAs for the experiments, the idea is tested on synthetic and real data. On synthetic data, it is shown that the number of neurons of the network is correlated with the homology it can express. On real data, the tool of persistent homology is applied. It is observed that the data in the final layer do have non-trivial signal in terms of persistent homology.\n\nI do like the general idea of the paper. It has great potentials. However, it is much undercooked. In particular, it could be improved as follows:\n\n* 1) the main message of the paper is unclear to me.  Results observed in the synthetic experiments seem to be a confirmation of the known results by Bianchini et al.: the Betti number a network can express is linear to the number of hidden units, h, when the input dimension n is a constant. \n\nTo be convinced, I would like to see much stronger experimental evidence: Reporting results on a single layer network is unsettling. It is known that the network expressibility is highly related to the depth (Eldan & Shamir 2016). So what about networks with more layers? Is the stratification observation statistically significant? These experiments are possible for synthetic data. \n\n* 2) The usage of persistent homology is not well justified. A major part of the paper is devoted to persistent homology. It is referred to as a robust computation of the homology and is used in the real data experiments. However, persistent homology itself was not originally invented to recover the homology of a fixed space. It was intended to discover homology groups at all different scales (in terms of the function value). Even with the celebrated stability theorem (Cohen-Steiner et al. 2007) and statistical guarantees (Chazal et al. 2015), the relationship between the Vietoris-Rips filtration persistent homology and the homology of the classifier region/boundary is not well established. To make a solid statement, I suggest authors look into the following papers\n\nHomology and robustness of level and interlevel sets\nP Bendich, H Edelsbrunner, D Morozov, A Patel, Homology, Homotopy and Applications 15 (1), 51-72, 2013\n\nHerbert Edelsbrunner, Michael Kerber: Alexander Duality for Functions: the Persistent Behavior of Land and Water and Shore. Proceedings of the 28th Annual Symposium on Computational Geometry, pp. 249-258 (SoCG 2012)\n\nThere are also existing work on how the homology of a manifold or stratified space can be recovered using its samples. They could be useful. But the settings are different: in this problem, we have samples from the positive/negative regions, rather than the classification boundary. \n\nFinally, the gap in concepts carries to experiments. When persistent homology of different real data are reported. It is unclear how they reflect the actually topology of the classification region/boundary. There are also significant amount of approximation due to the natural computational limitation of persistent homology. In particular, LLE and subsampling are used for the computation. These methods can significantly hurt persistent homology computation. A much more proper way is via the sparsification approach. \n\nSimBa: An Efficient Tool for Approximating Rips-Filtration Persistence via Simplicial Batch-Collapse\nT. K. Dey, D. Shi and Y. Wang. Euro. Symp. Algorithms (ESA) 2016, 35:1--35:16\n\n* 3) Finally, to support the main thesis, it is crucial to show that the topological measure is revealing information existing ones do not. Some baseline methods such as other geometric information (e.g., volume and curvature) are quite necessary.\n\n* 4) Important papers about persistent homology in learning could be cited:\n\nUsing persistent homology in deep convolutional neural network:\n\nDeep Learning with Topological Signatures\nC. Hofer, R. Kwitt, M. Niethammer and A. Uhl, NIPS 2017\n\nUsing persistent homology as kernels:\n\nSliced Wasserstein Kernel for Persistence Diagrams\nMathieu Carrière, Marco Cuturi, Steve Oudot, ICML 2017.\n\n* 5) Minor comments:\n\nSmall typos here and there: y axis label of Fig 5, conclusion section.\n\n', ""General comments:\n\nThe paper is largely inspired by a recent work of Bianchini et al. (2014) on upper bounds of Betti number sums for decision super-level sets of neural networks in different architectures. It explores empirically the relations between Betti numbers of input data and hidden unit complexity in a single hidden layer neural network, in a purpose of finding closer connections on topological complexity or expressibility of neural networks.  \n\nThey report the phenomenon of phase transition or turning points in training error as the number of hidden neurons changes in their experiment. The phenomenon of turning points has been observed in many experiments, where usually researchers investigate it through the critical points of training loss such as local optimality and/or saddle points. For the first time, the paper connects the phenomenon with topological complexity of input data and decision super-level sets, as well as number of hidden units, which is inspiring. \n\nHowever, a closer look at the experimental study finds some inconsistencies or incompleteness which deserves further investigations. The following are some examples. \n\nThe paper tries to identify a phase transition in number of hidden units, h_phase(D_2) = 10 from the third panel of Figure 4. However, when h=12 hidden units, the curve is above h=10 rather than below it in expectation. Why does the order of errors disagree with the order of architectures if the number of hidden neurons is larger then h_phase?\n\nThe author conjecture that if b0 = m, then m+2 hidden neurons are sufficient to get 0 training error.\nBut the second panel of fig4 seems to be a counterexample of the conjecture. In fact h_phase(D_0 of b_0=2)=4 and h_phase (D_1 of b_0 = 3) = 6, as pointed out by the paper, has a mismatch on such a numerical conjecture.  \n\nIn Figure 5, the paper seems to relate the homological complexities of data to the hidden dimensionality in terms of zero training error. What are the relations between the homological complexities of data and homological complexities of decision super-level sets of neural networks in training? Is there any correspondence between them in terms of topological transitions. \n\nThe study is restricted to 2-dimensional synthetic datasets. Although they applied topological tools to low-dimensional projection of some real data, it's purely topological data analysis. They didn't show any connection with the training or learning of neural networks. So this part is just preliminary but incomplete to the main topic of the paper.\n\nThe authors need to provide more details about their method and experiments. For example, The author didn't show from which example fig6 is generated. For other figures appended at the end of the paper, there should also be detailed descriptions of the underlying experiments.\n\n\nSome Details:\n\nLines in fig4 are difficult to read, there are too many similar colors. Axis labels are also missing.\n\nIn fig5, the (4, 0)-item appears twice, but they are different. They should be the same, but they are not.\nAny mistake here?\n\nFig6(a) has the same problem as fig4. Besides, the use of different x-axis makes it difficult to compare with fig4.\nfig6(b) needs a color bar to indicate the values of correlations. \n\nSome typos, e.g. Page 9 Line 2, 'ofPoole' should be 'of Poole'; Line 8, 'practical connectio nbetween' should be 'practical connection between'; line 3 in the 4th paragraph of page 9, 'the their are' seems to be 'there are'. Spell check is recommended before final version. \n""]","[-70, -30, -20]","[20, 50, 50]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper is 'not ready to be accepted' and points out several major flaws, including that the method is 'ill suited and unable to be adapted to more complex and interesting settings' and that experiments are 'very rudimentary'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'interesting, but' and 'it's hard to be convinced' rather than harsh or dismissive language. They also acknowledge positive aspects, such as the 'interesting' motivation, before critiquing. The reviewer provides constructive feedback and specific suggestions for improvement, which contributes to the slightly positive politeness score."", ""The sentiment score is -30 because while the reviewer likes the general idea of the paper and sees potential, they describe it as 'much undercooked' and provide a long list of significant improvements needed. This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses respectful language throughout, starting with positive aspects before critiques, and phrases suggestions as 'could be improved' rather than using harsh language. They also use phrases like 'I do like the general idea' and 'I suggest' which maintain a polite tone. However, the review doesn't go out of its way to be excessively polite either, maintaining a professional tone focused on the content."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'inspiring' connections), they also point out several inconsistencies, incompleteness, and areas needing further investigation. The review highlights more criticisms than praises, indicating a somewhat negative overall sentiment.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'deserves further investigations' and 'The authors need to provide more details' rather than harsh criticisms. The reviewer also acknowledges the paper's contributions before presenting their concerns.\n\nThe language used is constructive and aimed at improving the paper, rather than being dismissive or overly critical. The reviewer provides specific examples and suggestions, which is helpful and courteous. However, the score is not extremely high as the review is primarily focused on pointing out issues rather than offering extensive praise.""]"
"['This paper proposes a model of ""structured alignments"" between sentences as a means of comparing two sentences by matching their latent structures. Overall, this paper seems a straightforward application of the model first proposed by Kim et al. 2017 with latent tree attention.\n\nIn section 3.1, the formula for p(c|x) looks wrong: c_{ijk} are indicator variables. but where are the scores for each span? I think it should be c_{ijk} * \\delta_{ijk} under the summations instead.\n\nIn the same section, the expression for \\alpha_{ij} seems to assume that \\delta_{ijk} = \\dlta_{ij} regardless of k. I.e. there are no production rule scores (transitions). This seems rather limiting, can you comment on that?\n\nIn the answer selection and NLI experiments, the proposed model does not beat the SOTA, and is only marginally better than unstructured decomposable attention. This is rather disappointing.\n\nThe plots in Fig 2 with the marginals on CKY charts are not very enlightening. How do this marginals help solving the NLI task?\n\nMinor comments:\n- Sec. 3: ""Language is inherently tree structured"" -- this is debatable...\n- page 8: (laf, 2008): bad formatted reference', 'This paper describes the use of latent context-free derivations, using\na CRF-style neural model, as a latent level of representation in neural\nattention models that consider pairs of sentences. The model implicitly\nlearns a distribution over derivations, and uses marginals under this\ndistribution to bias attention distributions over spans in one sentence\ngiven a span in another sentence.\n\nThis is an intriguing idea. I had a couple of reservations however:\n\n* The empirical improvements from the method seem pretty marginal, to the\npoint that it\'s difficult to know what is really helping the model. I would\nliked to have seen more explanation of what the model has learned, and\nmore comparisons to other baselines that make use of attention over spans.\nFor example, what happens if every span is considered as an independent random\nvariable, with no use of a tree structure or the CKY chart?\n\n* The use of the \\alpha^0 vs. \\alpha^1 variables is not entirely clear. Once they\nhave been calculated in Algorithm 1, how are they used? Do the \\rho values\nsomewhere treat these two quantities differently?\n\n* I\'m skeptical of the type of qualitative analysis in section 4.3, unfortunately.\nI think something much more extensive would be interesting here. As one\nexample, the PP attachment example with ""at a large venue"" is highly suspect;\nthere\'s a 50/50 chance that any attachment like this will be correct, there\'s\nabsolutely no way of knowing if the model is doing something interesting/correct\nor performing at a chance level, given a single example. ', 'Summary:\nThis paper introduces a structured attention mechanisms to compute alignment scores among all possible spans in two given sentences. The span representations are weighted by the spans marginal scores given by the inside-outside algorithm. Experiments on TREC-QA and SNLI show modest improvement over the word-based structured attention baseline (Parikh et al., 2016).\n\nStrengths:\nThe idea of using latent syntactic structure, and computing cross-sentence alignment over spans is very interesting. \n\nWeaknesses:\nThe paper is 8.5 pages long.\n\nThe method did not out-perform other very related structured attention methods (86.8, Kim et al., 2017, 86.9, Liu and Lapata, 2017)\n\nAside from the time complexity from the inside-outside algorithm (as mentioned by the authors in conclusion), the comparison among all pairs of spans is O(n^4), which is more expensive. Am I missing something about the algorithm?\n\nIt would be nice to show, quantitatively, the agreement between the latent trees and gold/supervised syntax. The paper claimed “the model is able to recover tree structures that very closely mimic syntax”, but it’s hard to draw this conclusion from the two examples in Figure 2.\n']","[-30, -20, -20]","[20, 60, 50]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the paper as a 'straightforward application' of an existing model, they express disappointment with the results ('rather disappointing') and point out several issues with formulas and assumptions. The politeness score is mildly positive (20) as the reviewer uses neutral language and phrases criticisms as questions or suggestions ('can you comment on that?', 'This seems rather limiting') rather than direct attacks. They also offer some positive framing ('Overall, this paper seems...') before diving into critiques. The review maintains a professional tone throughout, avoiding harsh language while still clearly communicating areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea as 'intriguing', they express several reservations and criticisms. They mention 'marginal' improvements, skepticism about the analysis, and request more explanations and comparisons. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, framing criticisms as personal opinions ('I had a couple of reservations', 'I'm skeptical') and suggestions ('I would liked to have seen'). They also begin with a positive note about the 'intriguing idea'. The tone is professional and constructive, avoiding harsh or dismissive language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper ('very interesting' idea), they list several weaknesses and areas for improvement. The reviewer points out that the method didn't outperform related methods, questions the time complexity, and suggests additional quantitative analysis. However, the tone isn't entirely negative, which is why the score isn't lower. The politeness score is moderately positive (50) because the reviewer uses neutral language and phrases criticisms as questions or suggestions ('Am I missing something?', 'It would be nice to show...') rather than direct criticisms. The reviewer also acknowledges the paper's strengths before discussing weaknesses, which is a polite approach in academic reviews.""]"
"['\n- Paper summary\n\nThe paper proposes a GAN training method for improving the training stability. The key idea is to let a GAN generator competes with multiple GAN discriminators where each discriminator takes a random low-dimensional projection of an input image for differentiate whether the input image is a real or generated one. Visual generation results from the proposed method with comparison to those generated by the DCGAN were used as the main experimental validation for the merit of the proposed method. Due to poor experimental validation and inconclusive results, the reviewer does not recommend the acceptance of the paper.\n\n- Inconclusive results\n\nThe paper fails to compare the proposed method with the GMAN framework [a], which was the first work proposing utilizing multiple discriminators for more stable GAN training. Without comparing to the GMAN work, we do not know whether the benefit is from using multiple discriminators proposed in the GMAN work or from using the random low dimensional projections proposed in this paper. If it is former, then the proposed method has no merits at all.\n\nIn addition, the generator loss curve shown in Figure 2 is not making much sense. The generator loss curve will be meaningful if each discriminator update is optimal. However, this is not the case in the proposed method. There is little to conclude from Figure 2.\n\n[a] Durugkar et al. ""Generative multi-adversarial networks."" ICLR 2017\n\n- Poor experimental validation\n\nThe paper fails to utilize more established performance metrics such as the inception loss or human evaluation score to evaluate its benefit. It does not compare to other approaches for stabilizing GAN training such as WGAN or LSGAN. The main results shown in the paper are generating 64x64 human face images, which is not impressive.', 'The paper proposes a new approach to GAN training whereby they train one generator against an ensemble of discriminative that each receive a randomly projected version of the data. The authors show that this approach provides stable gradients to train the generator. \n\nThis is a nice idea, and both the theoretical analysis presented and the experiments on image data sets are interesting. Although the idea to train an ensemble of learning machines is not new, see e,.g. [1,2] -- and it would be useful to add some background on this, and the regularisation effect that emerges from it --  it does become new in the new context considered here, as the paper shows that such ensemble can also fulfil the role of stabilising GAN training. \nThe results are quite convincing that the proposed method is useful in practice,\n\nIt would be interesting to know if weighting the discriminators, or discarding the unlucky random projections as it was done in [1] would have potential in this context?\n\n[1] Timothy I. Cannings, Richard J. Samworth. Random-projection ensemble classification. Journal of the Royal Statistical Society B, 79(4), 2017, Pages 959-1035.     \n[2] Robert J. Durrant, Ata Kabán. Random projections as regularizers: learning a linear discriminant from fewer observations than dimensions. Machine Learning 99(2), 2015, Pages 257-286.\n\n\n', '\nThe paper proposes to stabilize GAN training by using an ensemble of discriminators, each workin on a random projection of the input data, to provide the training signal for the generator model.\n\nQ1: “In relation to “Theorem 3.1. … will produce samples from a distribution whose marginals along each of the projections W_k match those of the true distribution”.. I presume an infinite number of generator distributions could give rise to the correct marginals however not necessarily be converged to the data distribution. In Theorem A.2 the authors upperbound this residual as a function of the smoothness and support of the distributions as well as the projections presented to the discriminators. Can the authors comment on how tight this bound is e.g. as a function the number of used discriminators or the choosen projection methods ? \n\nQ2: Related to the above. Did the authors do or considered any frequency analysis of the ensemble of random projection? I guess you could easily do a numeric simulation of the expected frequency spectrum of the combined set discriminators?\n\n\nQ3: My primary concern with the work is the above mentioned computational complexity of running K discriminators in parallel. This is especially in relation to the experimental results showing significant high-frequency artefacts when running with K=12 classifiers (K=12 celebA results and “Random Imagenet-Canine Images: Proposed Method” in suplementary results). I think this is as expected as the authors are effectively fitting each classifier to the distributions of smoothed  (with 8x8 random kernel)  subsampled version of the input image. I would expect that each discriminator sees none or only a very limited amount  the high frequency component in the images.  Do the authors have any comments on how the sampling of the projection kernels affects the image results especially if the number of needed classifiers can be reduced somehow? I would expect that a combination of smoothing and high frequency filters would be needed to remove the high frequency artefacts?\n\nQ4: Whats the explanation of the oscilating patterns in figure 2?\n\nQ5: In the conclusion the authors mention that their framework is currently limited by the computational of running K discriminators and proposes:\n\n“In our current framework, the number of discriminators is limited by computational cost. In future work, we plan to investigate training with a much larger set of discriminators, employing only a small subset of them at each iteration, or every set of iterations”\n\nIn the extreme case of only using a single randomly discriminator the approach is quite similar to the quite widely used input dropout to the discriminator?\n\nOverall I like the simplicity of the proposed idea. However i’m not completely convinced that the “marginal” convergence proof holds for the relative low number of discriminators possible to use in practice. At least i would like the authors to touch on this key aspect of the method both theoretically and with experiments/simulations. Also several other methods have recently been proposed to improve stability of GANs, however no experimental comparisons is made with these methods (WGAN, EGAN, LSGAN etc.)\n']","[-80, 70, 20]","[-20, 80, 60]","[""The sentiment score is -80 because the review is predominantly negative. The reviewer explicitly states they 'do not recommend the acceptance of the paper' due to 'poor experimental validation and inconclusive results'. They criticize the paper's lack of comparison with relevant work, question the meaningfulness of presented data, and describe the results as 'not impressive'. The politeness score is -20 because while the reviewer maintains a professional tone, the language is quite direct and critical without much attempt to soften the criticism. Phrases like 'fails to compare', 'little to conclude', and 'not impressive' are particularly blunt. However, the reviewer does not use overtly rude language, which prevents the score from being lower."", ""The sentiment score is 70 (positive) because the reviewer describes the paper's idea as 'nice' and 'interesting', and states that the results are 'quite convincing'. They also mention that the approach is 'useful in practice'. However, it's not a perfect score as they suggest some improvements and additional background information. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames suggestions as constructive feedback rather than criticism. Phrases like 'it would be useful to add' and 'it would be interesting to know' are particularly polite ways of offering suggestions. The reviewer also cites relevant literature, showing respect for the broader scientific context."", ""The sentiment score is slightly positive (20) because the reviewer begins by acknowledging the paper's proposal and shows interest in the work, stating 'Overall I like the simplicity of the proposed idea.' However, they also express several concerns and questions, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing their concerns as questions and suggestions rather than criticisms. They use phrases like 'Can the authors comment on...' and 'Do the authors have any comments on...' which are polite ways of requesting clarification. The reviewer also provides constructive feedback and suggestions for improvement, which is a polite approach to peer review.""]"
"['The paper proposes Tensor-Train RNN and Tensor-Train LSTM (TT-RNN/TLSTM), a RNN/LSTM architecture whose hidden unit at time t h_t is computed from the tensor-vector product between a tensor of weights and a concatenation of hidden units from the previous L time steps. The motivation is to incorporate previous hidden states and high-order correlations among them to better predict long-term temporal dependencies for seq2seq problems. To address the issue of the number of parameters growing exponentially in the rank of the tensor, the model uses a low rank decomposition called the ‘tensor-train decomposition’ to make the number of parameters linear in the rank. Some theoretical analysis on the number of hidden units required for a given estimation error, and experimental results have been provided for synthetic and real sequential data.\n\nFirst of all, the presentation of the method in section 2.1 is confusing and there seem to be various ambiguities in the notation that harms understanding of the method. The tensor-vector product in equation (6) appears problematic. The notation that I think is standard is as follows: given a tensor W \\in R^{n_1 \\times … \\times n_P} and vectors v_p \\in R^{n_p}, the tensor-vector product W \\times_{p=1}^P v_p = vec(W) \\otimes_{p=1}^P v_p = \\sum{i_1,...,i_P} \\prod_{p=1}^P v_{p,i_p}. So I’m guessing you want to get rid of the \\otimes signs (the kronecker products) in (6) or you want to remove the summation and write W \\times_{p=1}^P s_{t-1}. Also \\alpha that appears in (6) is never defined. Is it another index? This is confusing because you say W is P-dimensional but have P+1 indices for it including alpha (W_{\\alpha i_1 … i_p}). Moreover the dimensionality of W^{hx} x_t in (6) is R^H judging from the notation in page 2, but isn’t the tensor-vector product a scalar? Also am I correct in thinking that s_{t-1} should be [1, h_{t-1}^T, …, h_{t-L}^T], i.e. a vector of length LH+1 rather than a matrix? The notation from page 2 implies that you are using column vectors, so the definition of s_{t-1} makes it appear as an (L+1) by H matrix, which could make the reader interpret s_{t-1;i_1} in (6) as vectors instead of scalars (this is reinforced by the kronecker product between these s_{t-1;i_p}). I had to work this out from the number of parameters (HL+1)^P in section 2.2. The diagram of s_{t-1} in Figure 3 is also confusing, because it isn’t obvious that the unlabelled grey bars are copies of s_{t-1}. Also I notice that the name ‘Tensor Train RNN/LSTM’ has been used in Yang et al, 2017. You probably want to avoid using the same name since the models are different. It would be nice if you could explain in a bit more detail about how they are different in the related work section.\n\nAssuming I have understood the method correctly, the idea of using tensor products to incorporate higher order interactions between the hidden states at different times appears sensible. From the theoretical analysis, you claim that 1) smoother f is easier to approximate, and 2) polynomial interactions are more efficient than linear ones. The first point seems fairly self-explanatory and doesn’t seem to require a proof. The second point isn’t so convincing because you have two additive terms on the right hand side of the inequality in Theorem 3.1 (btw I’m guessing you want the inequality to be the other way round): the first term is independent of p, and the second decreases exponentially with p. Your second point would only hold if this first term is reasonably small, but this doesn’t seem obvious to me.\n\nRegarding the experiments, I’m sceptical as to whether a grid search over hyperparameters for TLSTM vs grid search over the same hyperparameters for (M)LSTM provides a fair comparison. You probably want to compare the models given the same number of parameters, since given the same state size, TLSTM will have many more parameters than (M)LSTM. A plot of x-axis: # parameters, y-axis: average RMSE at convergence would be informative. Moreover for figure 8, you probably want to control the time taken for training instead of just comparing validation loss at the same number of steps. I imagine the best performing TLSTM model will have many more parameters and hence take much longer to train than the best performing LSTM model. \nMoreover, it seems as though the increased prediction accuracy from LSTM is marginal considering you have 3 more hyperparameters to tune (L,S,P - what was the value of P used for the experiments?) and that tuning them is important to prevent overfitting.\n\nI’m also curious as to how TLSTM compares to hierarchical RNN approaches for modelling long-term dependencies. It will be interesting to compare against models like Stacked LSTM (Graves, 2013), Grid LSTM (Kalchbrenner, 2015) and HM LSTM (Chung, 2017). These models have mostly been evaluated on text, but I don’t see any reason they can’t be extended to sequential forecasting on time series data. Also regularisation techniques such as batch-norm for LSTMs (Cooijmans et al, 2016) and layer-norm (Ba et al, 2016) seem to help a lot for increasing prediction accuracy. Did you investigate these techniques to control overfitting?\n\nOther minor comments on presentation:\nFor figure 6, the legends are inconsistent with the caption. Also you might want to overlay predictions on top of the ground truth for better comparison and also to save space.\n\nOverall, I think there are vast scopes for improvement in presentation and comparisons with other methods, and hence find the paper not yet ready for publication.\n', 'For method: \nthough it is known that RNN lacks the ability to capture long term dependency, it is designed to take infinite order of history (e.g., dimension of h is large enough, or f(x, h_t-1) is flexible enough). So the claim that RNN only learns a Markov Model is improper. For example, in “Recurrent Marked Temporal Point Processes: Embedding Event History to Vector”, it shows that RNN has the ability to fit the intensity function of Hawkes process (which has infinite order dependency).\n\nDecomposing tensor operator as a layer in neural network is not new. For example, “Tensor Contraction Layers for Parsimonious Deep Nets”. The technique used in this paper is tensor-trains, which is also proposed previously.\n\nAlso the author only talked about # parameters. A more important issue is the time cost. The author should also explicitly analyze the computation cost. \n\nFor writing: \n\nSome sections needs more explanations. In Section 2.1, it seems S_{t-1} is an (1 + L x H)-dimensional vector, according to your definition. Then how is S_{t-1; i_1} defined? Figure 2 has little information about proposed architecture. While Figure 3 is also very vague. \n\nNotations are not quite consistent. In Figure 3, the S_{t-1} contains K history vectors. What is K here? I suppose it is the same as L. In Figure 6, the legend says red curve is LSTM, but the caption says the green one is LSTM. \n\nFor experiment:\n\nThe datasets used are small, with a few number of not quite long sequences. But for demonstration purpose this might be ok. The doubt is whether this method is scalable to large datasets? Analysis like time cost, memory consumption needs to be included, in order for people to get an idea of its scalability. \n\nFigure 8 shows the convergence. I would say the difference is not significant. Consider its computation cost, I would doubt the ‘much faster’ claim in Page 7. \n\nAlso it seems the proposed method has more parameters than traditional RNN. To get a fair comparison, higher dimensionality of latent state should be used in LSTM. \n\nOverall the paper tries to tackle an important problem, which is good. However, both methods and experiments need improvement.', 'This work addresses an important and outstanding problem: accurate long-term forecasting using deep recurrent networks.  The technical approach seems well motivated, plausible, and potentially a good contribution, but the experimental work has numerous weaknesses which limit the significance of the work in current form.\n\nFor one, the 3 datasets tested are not established as among the most suitable, well-recognized benchmarks for evaluating long-term forecasting.  It would be far more convincing if the author’s used well-established benchmark data, for which existing best methods have already been well-tuned to get their best results.  Otherwise, the reader is left with concerns that the author’s may not have used the best settings for the baseline method results reported, which indeed is a concern here (see below).\n\nOne weakness with the experiments is that it is not clear that they were fair to RNN or LSTM, for example, in terms of giving them the same computation as the TT-RNNs. Section Hyper-parameter Analysis” on page 7 explains that they determined best TT rank and lags via grid search.  But presumably larger values for rank and lag require more computation, so to be fair to RNN and LSTM they should be given more computation as well, for example allowing them more hidden units than TT-RNNs get, so that overall computation cost is the same for all 3 methods.  As far as this reviewer can tell, the authors offer no experiments to show that a larger number of units for RNN or LSTM would not have helped them in improving long-term forecasting accuracies, so this seems like a very serious and plausible concern.\n\nAlso, on page 6 the authors say that they tried ARMA but that it performed about 5% worse than LSTM, and thus dismissing direct comparisons of ARMA against TT-RNN.  But they are unclear whether they gave ARMA as much hyper-parameter tuning (e.g. for number of lags) via grid search as their proposed TT-RNN benefited from.  Again, the concern here is that the experiments are plausibly not being fair to all methods equally.\n\nSo, due to the weaknesses in the experimental work, this work seems a bit premature.  It should more clearly establish that their proposed TT-RNN are indeed performing well compared to existing SOTA.\n\n\n']","[-60, -30, -50]","[20, 20, 20]","[""The sentiment score is -60 because the review is predominantly critical, pointing out numerous issues with the paper's presentation, methodology, and comparisons. The reviewer states the paper is 'not yet ready for publication' and expresses skepticism about the results. However, it's not entirely negative as the reviewer acknowledges some merits of the approach. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and offer constructive feedback. Phrases like 'I'm guessing', 'I'm curious', and 'It would be nice if' soften the critique. The reviewer also offers suggestions for improvement, which is a polite approach to criticism."", ""The sentiment score is -30 because the review is generally critical, pointing out several issues with the paper's claims, methods, and experiments. However, it's not entirely negative as it acknowledges the importance of the problem being tackled. The politeness score is 20 because the reviewer uses professional and constructive language, offering specific suggestions for improvement without being harsh. The reviewer maintains a respectful tone throughout, using phrases like 'I would doubt' instead of more direct criticisms. The review is structured and detailed, showing engagement with the paper, which contributes to its politeness."", ""The sentiment score is -50 because while the reviewer acknowledges the importance of the problem and the potential of the approach, they express significant concerns about the experimental work, describing 'numerous weaknesses' that 'limit the significance of the work'. The overall tone suggests the paper needs substantial improvements. The politeness score is 20 because the reviewer uses respectful language throughout, acknowledging positive aspects before critiquing, and uses phrases like 'it would be far more convincing' and 'the concern here is' rather than making blunt criticisms. However, the review is not overly polite, maintaining a professional, matter-of-fact tone focused on the paper's content.""]"
"['In this paper, authors discuss the use of block-diagonal hessian when computing the updates. The block-diagonal hessian makes it easier to solve the ""newton"" directions, as the CG can be run only on smaller blocks (and hence less CG iterations are needed).\n\nThe paper is nicely written and all was clear to me. In general, I agree that having larger batch-size is the way to go, for very large datasets and a pure SGD type of methods are having problems to efficiently utilize large clusters.\n\nThe only negative thing I find in the paper is the lack of more numerical results. Indeed, the paper is clearly not a theoretical paper, is proposing a new algorithm, hence there should be evidence that it works. For example, I would like to see how the choice of hyper-parameters influences the speed of the algorithm. Was ""CG"" cost included in the ""x""-axis? i.e. if we put ""passes"" over the data as x-axis, then 1 update \\approx 30 CG + some more == 32 batch evaluation.\nSo please try to make the ""x""-axis more fair.\n\n ', ""Summary: \nThe paper considers second-order optimization methods for training of neural networks.\nIn particular, the contribution of the paper is a Hessian-free method that works on blocks of parameters (this is a user defined splitting of the parameters in blocks, e.g., parameters of each layer is one block, or parameters in several layers could constitute a block). \nThis results into a block-diagonal approximation to the curvature matrix, in order to improve Hessian-free convergence properties: in the latter, a single step might require many CG steps, so the benefit from using second-order information is not apparent.\nThis is mainly an experimental work, where the authors show the merits of their approach on deep autoencoders, convolutional networks and LSTMs: results show favourable performance compared to the original Hessian-free approach and the Adam method.\n\nOriginality: \nThe paper is based on the works of Collobert (2004) and Le Roux et al. (2008), as well as the work of Martens: the twist is that each layer of the neural network is considered a parameter block, so that gradient interactions among weights in a single layer are more useful than those between weights in different layers. This increases the separability of the problem and reduces the complexity. \n\nImportance: \nUnderstanding the difference between first- and second-order methods for NN training is an important topic. Using second-order methods could be considered at its infancy, compared to the wide variety of first-order methods. Having new results on second-order methods with interesting results would definitely attract some attention at the conference. \n\nPresentation/Clarity: \nThe paper is well structured and well written. The authors clearly place their work w.r.t. state of the art and previous works, so that it is clear what is new and what is known.\n\nComments:\n1. It is not clear why the deficiency of first-order methods on training NNs with big batches motivates us to turn into second-order methods. Is there a reasoning for this statement? Or is it just because second-order methods are kind-of the only other alternative we have?\n\n2. Assuming we can perform a second-order method, like Newton's method, on a deep NN. Since originally Newton's method was designed to find solutions that have gradient equal to zero, and since NNs have saddle points (probably many more than local minima), even if we could perfectly perform second-order Newton motions, there is no guarantee whether we converge to a local minimum or a saddle point. However, since we perform Newton's method approximately in practice, this might help escaping saddle points. Any comment on this aspect (I'm not aware whether this is already commented in Schraudolph 2002, where the Gauss-Newton matrix was proposed instead of the Hessian)?\n"", 'The paper proposes a block-diagonal hessian-free method for training deep networks. \n\n- The block-diagonal approximation has been used in [1]. Although [1] is using Gauss-Newton matrix, the idea of ""block-diagonal"" approximation is similar. \n\n- Is the computational time (per iteration) of the proposed method similar to SGD/Adam? All the figures are showing the comparison in terms of number of updates, but it is not clear whether this speedup can be reflected in the training time. \n\n- Comparing block-diagonal approximation vs original HF method: \nIt is not clear to me what\'s the benefit using block-diagonal approximation. Is the time cost per iteration similar or faster? \nOr the main benefit is to reduce #CG iterations? (but it seems #CG iterations are fixed for both methods in the experiments). \nAlso, the paper mentioned that ""the HF method requires many hundreds of CG iterations for one update"". Is this true?\n Usually we can set a stopping condition for solving the Newton system.\n\n- It seems the benefit of block-diagonal approximation is marginal in CNN. \n\n[1] Practical Gauss-Newton Optimisation for Deep Learning. ICML 2017. ']","[50, 70, -20]","[80, 80, 50]","[""The sentiment score is 50 (moderately positive) because the reviewer expresses general agreement with the paper's approach and praises its clarity, but also points out a significant shortcoming in the lack of numerical results. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. The reviewer's suggestions are framed as requests ('please try to make...') rather than demands, maintaining a courteous tone even when pointing out areas for improvement."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper. They highlight its originality, importance, and clear presentation. The reviewer states that the paper is 'well structured and well written' and that it 'would definitely attract some attention at the conference.' However, it's not a perfect score as the reviewer does raise some questions and comments at the end. The politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout. They offer constructive feedback and frame their comments as questions rather than criticisms. The reviewer acknowledges the authors' work and contributions without using harsh or dismissive language. The tone is consistently professional and courteous, even when raising potential issues or seeking clarification."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's proposal, they raise several questions and concerns about the method's novelty, benefits, and performance. The reviewer points out similarities to existing work and asks for clarification on multiple aspects, suggesting some skepticism about the paper's contributions. However, the tone is not entirely negative, as the reviewer is engaging with the content and seeking more information.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns and frame their points as questions or requests for clarification rather than direct criticisms. The reviewer also acknowledges the paper's contributions and compares it to existing work in a fair manner. While not overly formal or deferential, the language is consistently polite and appropriate for academic discourse.""]"
"['This paper proposed a new optimization framework for semi-supervised learning based on derived inversion scheme for deep neural networks. The numerical experiments show a significant improvement in accuracy of the approach.', 'In summary, the paper is based on a recent work Balestriero & Baraniuk 2017 to do semi-supervised learning. In Balestriero & Baraniuk, it is shown that any DNN can be approximated via a linear spline and hence can be inverted to produce the ""reconstruction"" of the input, which can be naturally used to do unsupervised or semi-supervised learning. This paper proposes to use automatic differentiation to compute the inverse function efficiently. The idea seems interesting. However, I think there are several main drawbacks, detailed as follows:\n\n1. The paper lacks a coherent and complete review of the semi-supervised deep learning. Herewith some important missing papers, which are the previous or current state-of-the-art.\n\n[1] Laine S, Aila T. Temporal Ensembling for Semi-Supervised Learning[J]. arXiv preprint arXiv:1610.02242, ICLR 2016.\n[2] Li C, Xu K, Zhu J, et al. Triple Generative Adversarial Nets[J]. arXiv preprint arXiv:1703.02291, NIPS 2017.\n[3] Dai Z, Yang Z, Yang F, et al. Good Semi-supervised Learning that Requires a Bad GAN[J]. arXiv preprint arXiv:1705.09783, NIPS 2017.\n\nBesides, some papers should be mentioned in the related work such as Kingma et. al. 2014. I\'m not an expert of the network inversion and not sure whether the related work of this part is sufficient or not.\n\n2. The motivation is not sufficient and not well supported. \n\nAs stated in the introduction, the authors think there are several drawbacks of existing methods including ""training instability, lack of topology generalization and computational complexity."" Based on my knowledge, there are two main families of semi-supervised deep learning methods, classified by depending on deep generative models or not.  The generative approaches based on VAEs and GANs are time consuming, but according to my experience, the training of VAE-based methods are stable and the topology generalization ability of such methods are good. Besides, the feed-forward approaches including [1] mentioned above are efficient and not too sensitive with respect to the network architectures.  Overall, I think the drawbacks mentioned in the paper are not common in existing methods and I do not see clear benefits of the proposed method. Again, I strongly suggest the authors to provide a complete review of the literature.\n\nFurther, please explicitly support your claim via experiments. For instance, the proposed method should be compared  with the discriminative approaches including VAT and [1] in terms of the training efficiency. It\'s not fair to say GAN-based methods require more training time because these methods can do generation and style-class disentanglement while the proposed method cannot.\n\n3. The experimental results are not so convincing. \n\nFirst, please systematically compare your methods with existing methods on the widely adopted benchmarks including MNIST with 20, 100 labels and SVHN with 500, 1000 labels and CIFAR10 with 4000 labels. It is not safe to say the proposed method is the state-of-the-art by only showing the results in one setting.\n\nSecond, please report the results of the proposed method with comparable architectures used in previous methods and state clearly the number of parameters in each model. Resnet is powerful but previous methods did not use that.\n\nLast, show the sensitive results of the proposed method by tuning alpha and beta. For instance, please show what is the actual contribution of the proposed reconstruction loss to the classification accuracy with the other losses existing or not?\n\nI think the quality of the paper should be further improved by addressing these problems and currently it should be rejected.', 'After reading the revision:\n\nThe authors addressed my detailed questions on experiments. It appears sometimes the entropy loss (which is not the main contribution of the paper) is essential to improve performance; this obscures the main contribution.\n\nOn the other hand, the theoretical part of the paper is not really improved in my opinion, I still can not see how previous work by Balestriero and Baraniuk 2017 motivates and backups the proposed method.\n\nMy rating of this paper would remain the same. \n\n============================================================================================\n\nThis paper propose to use the reconstruction loss, defined in a somewhat unusual way, as a regularizar for semi-supervised learning.\n\nPros:\n\nThe intuition is that the ReLU network output is locally linear for each input, and one can use the conjugate mapping (which is also linear) for reconstructing the inputs, as in PCA. Realizing that the linear mapping is the derivative of network output w.r.t. the input (the Jacobian), the authors proposed to use the reconstruction loss defined in (8). Different from typical auto-encoders, this work does not require another reconstruction network, but instead uses the ""derivative"".  This observation is neat in my opinion, and does suggest a different use of the Jacobian in deep learning.  The related work include auto-encoders where the weights of symmetric layers are tied. \n\nCons:\n\nThe motivation (Section 2) needs to be improved. In particular, the introduction/review of the work of Balestriero and Baraniuk 2017 not very useful to the readers.  Notations in eqns (2) and (3) are not fully explained (e.g., boldface c). Intuition and implications of Theorem 1 is not sufficiently discussed: what do you mean by optimal DNN, what is the criteria for optimality? is there a generative assumption of the data underlying the theorem? and the assumption of all samples being norm 1 seems too strong and perhaps limits its application? As far as I see, section 2 is somewhat detached from the rest of the paper.\n\nThe main contribution of this paper is supposed to be the reconstruction mapping (6) and its effect in semi-supervised learning. The introduction of entropy regularization in sec 2.3 seems somewhat odd and obscures the contribution. It also bears the questions that how important is the entropy regularization vs. the reconstruction loss. In experiments, results with beta=1.0 need to be presented to assess the importance of network inversion and the reconstruction loss. Also, a comparison against typical auto-encoders (which uses another decoder networks, with weights possibly tied with the encoder networks) is missing.\n\n']","[80, -70, -30]","[0, 20, 20]","[""The sentiment score is 80 (positive) because the reviewer highlights the paper's proposal of a new optimization framework and mentions 'significant improvement in accuracy', which indicates a favorable view of the work. The language is factual and doesn't contain explicitly positive words, but the content implies approval. The politeness score is 0 (neutral) as the review uses straightforward, professional language without any particularly polite or impolite phrases. It's a concise, matter-of-fact statement about the paper's content and results, neither going out of its way to be courteous nor being rude."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several major drawbacks and concludes that the paper should be rejected. They criticize the lack of coherent literature review, insufficient motivation, and unconvincing experimental results. However, it's not entirely negative as they do mention that the idea seems interesting initially. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I think' and 'please' when making suggestions, which adds a degree of politeness. However, the overall critical nature and the recommendation for rejection prevent a higher politeness score."", ""The sentiment score is -30 because the reviewer expresses several concerns and states their rating would remain the same, implying a negative previous rating. However, they do acknowledge some positive aspects ('neat' idea, 'different use of the Jacobian'). The politeness score is 20 because the reviewer uses professional language and provides balanced feedback, listing both pros and cons. They avoid harsh criticism and use phrases like 'needs to be improved' rather than more negative wording. The reviewer also asks questions to prompt further explanation rather than making outright criticisms.""]"
"['Summary: The paper introduces ""Phase Conductor"", which consists of two phases, context-question attention phase and context-context (self) attention phase. Each phase has multiple layers of attention, for which the paper uses a novel way to fuse the layers, and context-question attention uses different question embedding for getting the attention weight and getting the attention vector. The paper shows that the model achieves state of the art on SQuAD among published papers, and also quantitatively and visually demonstrates that having multiple layers of attention is helpful for context-context attention, while it is not so helpful for context-question attention.\n\n\nNote: While I will mostly try to ignore recently archived, non-published papers when evaluating this paper, I would like to mention that the paper\'s ensemble model currently stands 11th on SQuAD leaderboard.\n\n\nPros:\n- The model achieves SOTA on SQuAD among published papers.\n- The sequential fusing (GRU-like) of the multiple layers of attention is interesting and novel. Visual analysis of the attention map is convincing.\n- The paper is overall well-written and clear.\n\nCons:\n- Using different embedding for computing attention weights and getting attended vector is not entirely novel but rather an expected practice for many memory-based models, and should cite relevant papers. For instance, Memory Networks [1] uses different embedding for key (computing attention weight) and value (computing attended vector).\n- While ablations for number of attention layers (1 or 2) were visually convincing, numerically there is a very small difference even for selfAtt. For instance, in Table 4, having two layers of selfAtt (with two layers of question-passage) only increases max F1 by 0.34, where the standard deviation is 0.31 for the one layer. While this may be statistically significant, it is a very small gain nonetheless.\n- Given the above two cons, the main contribution of the paper is 1.1% improvement over previous state of the art. I think this is a valuable engineering contribution, but I feel that it is not well-suited / sufficient for ICLR audience. \n\n\nQuestions:\n- page 7 first para: why have you not tried GloVe 300D, if you think it is a critical factor?\n\n\nErrors:\n- page 2 last para: ""gives an concrete"" -> ""gives a concrete""\n- page 2 last para: ""matching"" -> ""matched""\nFigure 1: I think ""passage embedding h"" and ""question embedding v"" boxes should be switched.\n- page 7 3.3 first para: ""evidence fully"" -> ""evidence to be fully""\n\n\n[1] Jason Weston, Sumit Chopra, and Antoine Bordes. Memory Networks. ICLR 2015.', 'This paper introduces a fairly elaborate model for reading comprehension evaluated on the SQuAD dataset.   The model is shown to improve on the published results but not as-of-submission leaderboard numbers.\n\nThe main weakness of the paper in my opinion is that the innovations seem to be incremental and not based on any overarching insight or general principle.  A less significant issue is that the English is often disfluent.\n\nSpecific comments: I would remove the significance daggers from table 2 as the standard deviations are already reported and the null hypothesis for which significance is measured seems unclear.  I am also concerned to see test performance significantly better than development performance in table 3.  Other systems seem to have development and test performance closer together.  Have the authors been evaluating many times on the test data?\n', 'This paper proposes a new machine comprehension model, which integrates several contributions like different embeddings for gate function and passage representation function, self-attention layers and highway network based fusion layers. The proposed method was evaluated on the SQuAD dataset only, and marginal improvement was observed compared to the baselines.\n\n(1) One concern I have for this paper is about the evaluation. The paper only evaluates the proposed method on the SQuAD data with systems submitted in July 2017, and the improvement is not very large. As a result, the results are not suggesting significance or generalizability of the proposed method.\n\n(2) The paper gives some ablation tests like reducing the number of layers and removing the gate-specific question embedding, which help a lot for understanding how the proposed methods contribute to the improvement. However, the results show that the deeper self-attention layers are indeed useful (but still not improving a lot, about 0.7-0.8%). The other proposed components contribute less significant. As a result, I suggest the authors add more ablation tests regarding (1) replacing the outer-fusion with simple concatenation (it should work for two attention layers); (2) removing the inner-fusion layer and only use the final layer\'s output, and using residual connections (like many NLP papers did) instead of the more complicated GRU stuff.\n\n(3) Regarding the ablation in Table 2, my first concern is that the improvement seems small (~0.5%). As a result, I am wondering whether this separated question embedding really brings new information, or the similar improvement can be achieved by increasing the size of LSTM layers. For example, if we use the single shared question embeddings, but increase the size from 128 to some larger number like 192, can we observe similar improvement. I suggest the authors try this experiment as well and I hope the answer is no, as separated input embeddings for gate functions was verified to be useful in some ""old"" works with syntactic features as gate values, like ""Semantic frame identification with distributed word representations"" and ""Learning composition models for phrase embeddings"" etc.\n\n(4) Please specify which version of the SQuAD leaderboard is used in Table 3. Is it a snapshot of the Jul 14 one? Because this paper is not comparing to the state-of-the-art, no specification of the leaderboard version may confuse the other reviewers and readers. By the way, it will be better to compare to the snapshot of Oct 2017 as well, indicating the position of this work during the submission deadline.\n\nMinor issues:\n\n(1) There are typos in Figure 1 regarding the notations of Question Features and Passage Features.\n\n(2) In Figure 1, I suggest adding an ""N \\times"" symbol to the left of the Q-P Attention Layer and remove the current list of such layers, in order to be consistent to the other parts of the figure.\n\n(3) What is the relation between the ""PhaseCond, QPAtt+""\x08 in Table 2 and the ""PhaseCond"" in Table 3? I was assuming that those are the same system but did not see the numbers match each other.']","[20, -30, -20]","[60, 20, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges some strengths of the paper, such as achieving state-of-the-art results and having interesting novel aspects. However, they also point out significant weaknesses and suggest the contribution may not be sufficient for the target audience. The politeness score is moderately high (60) as the reviewer uses professional language, provides balanced feedback with both pros and cons, and phrases criticisms constructively. They also offer helpful suggestions and point out minor errors politely. The tone remains respectful throughout, even when expressing doubts about the paper's suitability for the venue."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some improvements made by the paper, they also point out significant weaknesses. The reviewer states that the main weakness is that the innovations seem incremental and not based on any overarching insight. They also mention issues with the English used in the paper. The politeness score is slightly positive (20) as the reviewer uses fairly neutral language and offers specific, constructive feedback. They avoid harsh criticism and use phrases like 'in my opinion' to soften their critique. The reviewer also provides detailed suggestions for improvement, which is a polite way to offer criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'ablation tests... help a lot for understanding'), they express several concerns and suggest significant improvements. The overall tone indicates that the paper's contributions are not sufficiently significant or generalizable. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh criticism. They use phrases like 'I suggest' and 'Please specify' which maintain a polite tone while providing feedback. The reviewer also balances critique with positive observations, further contributing to the polite tone.""]"
"['Authors propose a greedy scheme to select a subset of (highly correlated) spectral features in a classification task. The selection criterion used is the average magnitude with which this feature contributes to the activation of a next-layer perceptron. Once validation accuracy drops too much, the pruned network is retrained, etc. \n\nPro: \n- Method works well on a single data set and solves the problem\n- Paper is clearly written \n- Good use of standard tricks \n\nCon: \n- Little novelty\n\nThis paper could be a good fit for an applied conference such as the International Symposium on Biomedical Imaging. \n', 'This paper explores the use of neural networks for classification and segmentation of hypersepctral imaging (HSI) of cells. The basic set-up of the method and results seem correct and will be useful to the specific application described. While the narrow scope might limit this work\'s significance, my main issue with the paper is that while the authors describe prior art in terms of HSI for biological preps, there is a very rich literature addressing HSI images in other domains: in particular for remote sensing. I think that this work can (1) be a lot clearer as to the novelty and (2) have a much bigger impact if this literature is addressed. In particular, there are a number of methods of supervised and unsupervised feature extraction used for classification purposes (e.g. endmember extraction or dictionary learning). It would be great to know how the features extracted from the neural network compare to these methods, as well as how the classification performance compares to typical methods, such as performing SVM classification in the feature space. The comparison with the random forests is nice, but that is not a standard method. Putting the presented work in context for these other methods would help make there results more general, and hopefully increase the applicability to more general HSI data (thus increasing significance).  \n\nAn additional place where this comparison to the larger HSI literature would be useful is in the section where the authors describe the use of the network weights to isolate sub-bands that are more informative than others. Given the high correlation in many spectra, typically something like random sampling might be sufficient (as in compressive sensing). This type of compression which can be applied at the sensor -- a benefit the authors mention of their band-wise sub-sampling. It would be good to acknowledge this prior work and to understand if the features from the network are superior to the random sampling scheme. \n\nFor these comments, I suggest the authors look at the following papers (and especially the references therein):\n[1] Li, Chengbo, et al. ""A compressive sensing and unmixing scheme for hyperspectral data processing."" IEEE Transactions on Image Processing 21.3 (2012): 1200-1210.\n[2] Bioucas-Dias, José M., et al. ""Hyperspectral unmixing overview: Geometrical, statistical, and sparse regression-based approaches."" IEEE journal of selected topics in applied earth observations and remote sensing 5.2 (2012): 354-379.\n[3] Charles, Adam S., Bruno A. Olshausen, and Christopher J. Rozell. ""Learning sparse codes for hyperspectral imagery."" IEEE Journal of Selected Topics in Signal Processing 5.5 (2011): 963-978.\n\n', 'In this paper, the authors proposed a framework to classify cells and implement cell segmentation based on the deep learning \ntechniques. Using the classification results to guide the feature selection method, the method can achieve comparable performance even 90% of the input features are reduced. \n\nIn general, the paper addresses an interesting problem, but the technical contribution is rather incremental. The authors seem to apply some well-define methods to realize a new task. The authors are expected to clarify their technical contributions or model improvement to address the specific problem. \n\nMoreover, there also exist some recent progress on image segmentation, such as FCN or mask R-CNN. The authors are expected to demonstrate the results by improving these advanced models. \n\nIn general, this is an interesting paper, but would be more fit to MICCAI or ISBI. \n\n\n\n']","[20, -20, -20]","[50, 60, 50]","['The sentiment score is slightly positive (20) because the reviewer mentions several pros (method works well, paper is clearly written, good use of standard tricks) and only one con (little novelty). The overall tone suggests the paper is decent but not groundbreaking. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language without any harsh criticism. They offer a balanced view of pros and cons and suggest a potential venue for publication, which is constructive. The language is neither overly formal nor particularly warm, maintaining a respectful, academic tone throughout.', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the basic set-up and results seem correct, they express concerns about the paper's limited scope and lack of comparison to existing literature in related fields. The reviewer suggests significant improvements, indicating that the current state of the paper is not entirely satisfactory. However, the score is not deeply negative as the reviewer sees potential in the work if the suggested changes are implemented. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'it would be great to know' and 'I suggest' rather than making demands. The reviewer also acknowledges positive aspects of the work, such as the comparison with random forests. The tone is professional and aimed at improving the paper rather than being critical for its own sake."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting', they also point out that the technical contribution is 'rather incremental' and suggest that the paper might be more suitable for different conferences. This indicates a mixed but slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, such as 'the authors are expected to' instead of more direct commands, and acknowledges the interesting aspects of the paper. The reviewer also provides constructive feedback and suggestions for improvement rather than harsh criticism.""]"
"[""The approach solves an important problem as getting labelled data is hard. The focus is on the key aspect, which is generalisation across heteregeneous data. The novel idea is the dataset embedding so that their RL policy can be trained to work across diverse datasets.\n\nPros: \n1. The approach performs well against all the baselines, and also achieves good cross-task generalisation in the tasks they evaluated on. \n2. In particular, they alsoevaluated on test datasets with fairly different statistics from the training datasets, which isnt very common in most meta-learning papers today, so it’s encouraging that the method works in that regime.\n\nCons: \n1. The embedding strategy, especially the representative and discriminative histograms, is complicated. It is unclear if the strategy is general enough to work on harder problems / larger datasets, or with higher dimensional data like images. More evidence in the paper for why it would work on harder problems would be great. \n2. The policy network would have to output a probability for each datapoint in the dataset U, which could be fairly large, thus the method is computationally much more expensive than random sampling. A section devoted to showing what practical problems could be potentially solved by this method would be useful.\n3. It is unclear to me if the results in table 3 and 4 are achieved by retraining from scratch with an RBF SVM, or by freezing the policy network trained on a linear SVM and directly evaluating it with a RBF SVM base learner.\n\nSignificance/Conclusion: The idea of meta-learning or learning to learn is fairly common now. While they do show good performance, it’s unclear if the specific embedding strategy suggested in this paper will generalise to harder tasks. \n\nComments: There’s lots of typos, please proof read to improve the paper.\n\nRevision: I thank the authors for the updates and addressing some of my concerns. I agree the computational budget makes sense for cross data transfer, however the embedding strategy and lack of larger experiments makes it unclear if it'll generalise to harder tasks. I update my review to 6. "", 'This reviewer has found the proposed approach quite compelling, but the empirical validation requires significant improvements:\n1) you should include in your comparison Query-by- Bagging & Boosting, which are two of the best out-of-the-box active learning strategies\n2) in your empirical validation you have (arbitrarily) split the 14 datasets in 7 training and testing ones, but many questions are still unanswered:\n -  would any 7-7 split work just as well (ie, cross-validate over the 14 domains)\n - do you what happens if you train on 1, 2, 3, 8, 10, or 13 domains? are the results significantly different? \n\nOTHER COMMENTS:\n- p3: both images in Figure 1 are labeled Figure 1.a\n- p3: typo ""theis"" --> ""this"" \n\nAbe & Mamitsuksa (ICML-1998). Query Learning Strategies Using Boosting and Bagging.', 'Overview\n\nThe authors propose a reinforcement learning approach to learn a general active query policy from multiple heterogeneous datasets. The reinforcement learning part is based on a policy network, which selects the data instance to be labeled next. They use meta-learning on feature histograms to embed heterogeneous datasets into a fixed dimensional representation. The authors argue that policy-based reinforcement learning allows learning the criteria of active learning non-myopically. The experiments show the proposed approach is effective on 14 UCI datasets.\n\nstrength\n\n* The paper is mostly clear and easy to follow.\n* The overall idea is interesting and has many potentials.\n* The experimental results are promising on multiple datasets.\n* There are thorough discussion with related works.\n\nweakness\n\n* The graph in p.3 don\'t show the architecture of the network clearly.\n* The motivation of using feature histograms as embedding is not clear.\n* The description of the 2-D histogram on p.4 is not clear. The term ""posterior value"" sounds ambiguous.\n* The experiment sets a fixed budget of only 20 instances, which seems to be rather few in some active learning scenarios, especially for non-linear learners. Also, the experiments takes a fixed 20K iterations for training, and the convergence status (e.g. whether the accumulated gradient has stabilized the policy) is not clear.\n* Are there particular reasons in using policy learning instead of other reinforcement learning approaches?\n* The term A(Z) in the objective function can be more clearly described.\n* While many loosely-related works were surveyed, it is not clear why literally none of them were compared. There is thus no evidence on whether a myopic bandit learner (say, Chu and Lin\'s work) is really worse than the RL policy. There is also no evidence on whether adaptive learning on the fly is needed or not.\n* In Equation 2, should there be a balancing parameter for the reconstruction loss?\n* Some typos\n    - page 4: some duplicate words in discriminative embedding session\n    - page 4: auxliary -> auxiliary\n    - page 7: tescting -> testing\n\n']","[40, 20, 20]","[60, 50, 50]","[""The sentiment score is 40 (slightly positive) because the reviewer acknowledges the importance of the problem and the novel approach, noting several pros such as good performance and cross-task generalization. However, they also point out significant cons and express uncertainty about the method's generalizability to harder tasks. The final score of 6 (out of 10) also indicates a moderately positive sentiment. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offers constructive criticism, and thanks the authors for their updates. The use of phrases like 'please proof read' and the acknowledgment of the authors' efforts to address concerns demonstrate politeness. However, the directness of some criticisms prevents a higher politeness score."", ""The sentiment score is 20 (slightly positive) because the reviewer finds the approach 'quite compelling', but has significant concerns about the empirical validation. This mix of positive and negative feedback results in a slightly positive overall sentiment. The politeness score is 50 (moderately polite) because the reviewer uses professional and constructive language, offering specific suggestions for improvement without harsh criticism. The use of phrases like 'you should include' and 'many questions are still unanswered' maintains a respectful tone while clearly communicating areas for improvement. The reviewer also helpfully points out minor errors, which contributes to the overall constructive and polite tone of the review."", ""The sentiment score is slightly positive (20) because the review begins by highlighting several strengths of the paper, including its clarity, interesting idea, promising results, and thorough discussion. However, it also lists a number of weaknesses, which tempers the overall positive sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout and frames criticisms as suggestions or questions rather than harsh judgments. They acknowledge the paper's merits before discussing areas for improvement. The review maintains a constructive tone, offering specific recommendations for enhancing the paper without using overly negative or confrontational language.""]"
"['This paper describes a method for computing representations for out-of-vocabulary words, e.g. based on their spelling or dictionary definitions. The main difference from previous approaches is that the model is that the embeddings are trained end-to-end for a specific task, rather than trying to produce generically useful embeddings. The method leads to better performance than using no external resources, but not as high performance as using Glove embeddings. The paper is clearly written, and has useful ablation experiments. However, I have a couple of questions/concerns:\n- Most of the gains seem to come from using the spelling of the word. As the authors note, this kind of character level modelling has been used in many previous works. \n- I would be slightly surprised if no previous work has used external resources for training word representations using an end-task loss, but I don’t know the area well enough to make specific suggestions \n- I’m a little skeptical about how often this method would really be useful in practice. It seems to assume that you don’t have much unlabelled text (or you’d use Glove), but you probably need a large labelled dataset to learn how to read dictionary definitions well. All the experiments use large tasks - it would be helpful to have an experiment showing an improvement over character-level modelling on a smaller task.\n- The results on SQUAD seem pretty weak - 52-64%, compared to the SOTA of 81. It seems like the proposed method is quite generic, so why not apply it to a stronger baseline?\n', '\nThis paper illustrates a method to compute produce word embeddings on the fly for rare words, using a pragmatic combination of existing ideas:\n\n* Backing off to a separate decoder for rare words a la Luong and Manning (https://arxiv.org/pdf/1604.00788.pdf, should be cited, though the idea might be older).\n\n* Using character-level models a la Ling et al.\n\n* Using dictionary embeddings a la Hill et al.\n\nNone of these ideas are new before but I haven’t seen them combined in this way before. This is a very practical idea, well-explained with a thorough set of experiments across three different tasks. The paper is not surprising but this seems like an effective technique for people who want to build effective systems with whatever data they’ve got. \n', 'This paper examines ways of producing word embeddings for rare words on demand. The key real-world use case is for domain specific terms, but here the techniques are demonstrated on rarer words in standard data sets. The strength of this paper is that it both gives a more systematic framework for and builds on existing ideas (character-based models, using dictionary definitions) to implement them as part of a model trained on the end task.\n\nThe contribution is clear but not huge. In general, for the scope of the paper, it seems like what is here could fairly easily have been made into a short paper for other conferences that have that category. The basic method easily fits within 3 pages, and while the presentation of the experiments would need to be much briefer, this seems quite possible. More things could have been considered. Some appear in the paper, and there are some fairly natural other ones such as mining some use contexts of a word (such as just from Google snippets) rather than only using textual definitions from wordnet. The contributions are showing that existing work using character-level models and definitions can be improved by optimizing representation learning in the context of the final task, and the idea of adding a learned linear transformation matrix inside the mean pooling model (p.3). However, it is not made very clear why this matrix is needed or what the qualitative effect of its addition is.\n\nThe paper is clearly written. \n\nA paper that should be referred to is the (short) paper of Dhingra et al. (2017): A Comparative Study of Word Embeddings\nfor Reading Comprehension https://arxiv.org/pdf/1703.00993.pdf . While it in no way covers the same ground as this paper it is relevant as follows: This paper assumes a baseline that is also described in that paper of using a fixed vocab and mapping other words to UNK. However, they point out that at least for matching tasks like QA and NLI that one can do better by assigning random vectors on the fly to unknown words. That method could also be considered as a possible approach to compare against here.\n\nOther comments:\n - The paper suggests a couple of times including at the end of the 2nd Intro paragraph that you can\'t really expect spelling models to perform well in representing the semantics of arbitrary words (which are not morphological derivations, etc.). While this argument has intuitive appeal, it seems to fly in the face of the fact that actually spelling models, including in this paper, seem to do surprisingly well at learning such arbitrary semantics.\n - p.2: You use pretrained GloVe vectors that you do not update. My impression is that people have had mixed results, sometimes better, sometimes worse with updating pretrained vectors or not. Did you try it both ways?\n - fn. 1: Perhaps slightly exaggerates the point being made, since people usually also get good results with the GloVe or word2vec model trained on ""only"" 6 billion words – 2 orders of magnitude less data.\n - p.4. When no definition is available, is making e_d(w) a zero vector worse than or about the same as using a trained UNK vector?\n - Table 1: The baseline seems reasonable (near enough to the quality of the original Salesforce model from 2016 (66 F1) but well below current best single models of around 76-78 F1. The difference between D1 and D3 does well illustrate that better definition learning is done with backprop from end objective. This model shows the rather strong performance of spelling models – at least on this task – which he again benefit from training in the context of the end objective. \n - Fig 2: It\'s weird that only the +dict (left) model learns to connect ""In"" and ""where"". The point made in the text between ""Where"" and ""overseas"" is perfectly reasonable, but it is a mystery why the base model on the right doesn\'t learn to associate the common words ""where"" and ""in"" both commonly expressing a location.\n - Table 2: These results are interestingly different. Dict is much more useful than spelling here. I guess that is because of the nature of NLI, but it isn\'t 100% clear why NLI benefits so much more than QA from definitional knowledge.\n - p.7: I was slightly surprised by how small vocabs (3k and 5k words) are said to be optimal for NLI (and similar remarks hold for SQuAD). My impression is that most papers on NLI use much larger vocabs, no?\n - Fig 3: This could really be drawn considerably better: make the dots bigger and their colors more distinct.\n - Table 3: The differences here are quite small and perhaps the least compelling, but the same trends hold.\n']","[-20, 70, 20]","[60, 80, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('clearly written', 'useful ablation experiments'), they express several concerns and skepticism about the method's novelty and practical utility. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or personal opinions ('I have a couple of questions/concerns', 'I'm a little skeptical'), and acknowledges their own potential lack of knowledge in some areas. The reviewer also balances criticism with positive comments, maintaining a professional and constructive tone."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as presenting a 'very practical idea' that is 'well-explained' with a 'thorough set of experiments'. They also mention that while the individual ideas aren't new, their combination is novel and potentially effective. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths and contributions without being overly critical. The tone is professional and objective, offering a balanced view of the work. The reviewer also suggests a citation that could improve the paper, which is a polite way of pointing out a potential oversight."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's clear contribution and strengths, but also points out limitations and suggests it could have been a short paper. The reviewer provides constructive feedback and suggestions for improvement, indicating a generally positive but measured stance. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms as suggestions or questions rather than direct attacks. The reviewer maintains a professional tone, balancing praise with constructive criticism, and uses phrases like 'The paper is clearly written' which contribute to the polite tone.""]"
"['(Last minute reviewer brought in as a replacement).\n\nThis paper proposed ""Bayesian Deep Q-Network"" as an approach for exploration via Thompson sampling in deep RL.\nThis algorithm maintains a Bayesian posterior over the last layer of the neural network and uses that as an approximate measure of uncertainty.\nThe agent then samples from this posterior for an approximate Thompson sampling.\nExperimental results show that this outperforms an epsilon-greedy baseline.\n\nThere are several things to like about this paper:\n- The problem of efficient exploration with deep RL is important and under-served by practical algorithms. This seems like a good algorithm in many ways.\n- The paper is mostly clear and well written.\n- The experimental results are impressive in their outperformance.\n\nHowever, there are also some issues, many of which have already been raised:\n- The poor performance of the DDQN baseline is concerning and does not seem to match the behavior of prior work (see Pong for example).\n- There are some loose and misleading descriptions of the algorithm computing ""the posterior"" when actually this is very much an approximation method... that\'s OK to have approximations but it shouldn\'t be hidden away.\n- The connection to RLSVI is definitely understated, since with a linear architecture this is precisely RLSVI. The sentiment that extending TS to larger spaces hasn\'t been fully explored is definitely valid... but this line of work should certainly be mentioned in the 4th paragraph. RLSVI is provably-efficient with a state-of-the-art regret bound for tabular learning - you would probably strengthen the case for this algorithm as an extension of RLSVI by building on this connection... otherwise it\'s a bit adhoc to justify this approximation method.\n- This paper spends a lot of time re-deriving Bayesian linear regression in a really standard way... and without much discussion of how/why this method is an approximation (it is) especially when used with deep nets.\n\nOverall, I like this paper and the approach of extending TS-style algorithms to Deep RL by just taking the final layer of the neural network.\nHowever, it also feels like there are some issues with the baselines + being a bit more clear about the approximations / position relative to other algorithms for approximate TS would be a better approach.\nFor example, in linear networks this is the same as RLSVI, bootstrapped DQN is one way to extend this idea to deep nets, but this is another one and it is much better because XYZ. (this discussion could perhaps replace the rather mundane discussion of BLR, for example).\n\nIn it\'s current state I\'d say marginally above, but wouldn\'t be surprised if these changes turned it into an even better paper quite quickly.\n\n\n===============================================================\n\nRevising my review following the rebuttal period and also the (ongoing) revisions to the paper.\n\nI\'ve been disappointed by the authors have incorporated the feedback/reviews - I expected something a little more clear / honest. Given the ongoing review decisions/issues I\'m putting my review slightly below accept.\n\n## Relation to literature on ""randomized value functions""\nIt\'s really wrong to present BDQN as is if it\'s the first attempt at large-scale approximations to Thompson sampling (and then slip in a citation to RLSVI as a BDQN-like algorithm). This algorithm is a form of RLSVI (2014) where you only consider uncertainty over the last (linear) layer - I think you should present it like this. Similarly *some* of the results for Bootstrapped DQN (2016) on Atari are presented without bootstrapping (pure ensemble) but this is very far from an essential part of the algorithm! If you say something like ""they did not estimate a true posterior"" then you should quantify this and (presumably) justify the implication that taking a gaussian approximation to the final layer is a *true* posterior. In a similar vein, you should be clear about the connections to Lipton et al 2016 as another method for approximate Bayesian posteriors in DQN.\n\n## Quality/science of experiments\nThe experimental results have been updated, and the performance of the baseline now seems much more reasonable. However, the procedure for ""selecting arbitrary number of frames"" to report performance seems really unnecessary... it would be clear that BDQN is outperforming DDQN... you should run them all for the same number of frames and then either compare (final score, cumulative score, #frames to human) or something else more fair/scientific. This type of stuff smells like overfitting!', '\nThe authors describe how to use Bayesian neural networks with Thompson sampling\nfor efficient exploration in q-learning. The Bayesian neural networks are only\nBayesian in the last layer. That is, the authors learn all the previous layers\nby finding point estimates. The Bayesian learning of the last layer is then\ntractable since it consists of a linear Gaussian model. The resulting method is\ncalled BDQL. The experiments performed show that the proposed approach, after\nhyper-parameter tuning, significantly outperforms the epsilon-greedy\nexploration approaches such as DDQN.\n\nQuality:\n\nI am very concern about the authors stating on page 1 ""we sample from the\nposterior on the set of Q-functions"". I believe this statement is not correct.\nThe Bayesian posterior distribution is obtained by combining an assumed\ngenerative model for the data, data sampled from that model and some prior\nassumptions. In this paper there is no generative model for the data and the\ndata obtained is not actually sampled from the model. The data are just targets\nobtained by the q-learning rule. This means that the authors are adapting\nQ-learning methods so that they look Bayesian, but in no way they are dealing\nwith a principled posterior distribution over Q-functions. At least this is my\nopinion, I would like to encourage the authors to be more precise and show in\nthe paper what is the exact posterior distribution over Q-functions and show\nhow they approximate that distribution, taking into account that a posterior\ndistribution is obtained as $p(theta|D) \\propto p(D|theta)p(\\theta)$. In the\ncase addressed in the paper, what is the likelihood $p(D|\\theta)$ and what are\nthe modeling assumptions that explain how $D$ is generated by sampling from a\nmodel parameterized by \\theta?\n\nI am also concerned about the hyper-parameter tuning for the baselines. In\nsection 5 (choice of hyper-parameters) the authors describe a quite exhaustive\nhyper-parameter tuning procedure for BDQL. However, they do not mention whether\nthey perform a similar hyper-parameter tuning for DDQN, in particular for the\nparameter epsilon which will determine the amount of exploration. This makes me\nwonder if the comparison in table 2 is fair. Especially, because the authors\ntune the amount of data from the replay-buffer that is used to update their\nposterior distribution. This will have the effect of tuning the width of their\nposterior approximation which is directly related to the amount of exploration\nperformed by Thompson sampling. You can, therefore, conclude that the authors are\ntuning the amount of exploration that they perform on each specific problem.\nIs that also being done for the baseline DDQN, for example, by tuning epsilon in\neach problem?\n\nThe authors also report in table 2 the scores obtained for DDQN by Osband et\nal. 2016. What is the purpose of including two rows in table 2 with the same\nmethod? It feels a bit that the authors want to hide the fact that they only\ncompare with a singe epsilon-greedy baseline (DDQN). Epsilon-greedy methods\nhave already been shown to be less efficient than Bayesian methods with\nThompson sampling for exploration in q learning (Lipton et al. 2016).\n\nThe authors do not compare with variational approaches to Bayesian learning\n(Lipton et al. 2016). They indicate that since Lipton et al. ""do not\ninvestigate the Atari games, we are not able to have their method as an\nadditional baseline"". This statement seems completely unjustified. The authors\nshould clearly include a description of why Lipton\'s approach cannot be applied\nto the Atari games or include it as a baseline. \n\nThe method proposed by the authors is very similar to Lipton\'s approach. The\nonly difference is that Lipton et al. use variational inference with a\nfactorized Gaussian distribution to approximate the posterior on all the\nnetwork weights. The authors by contrast, perform exact Bayesian inference, but\nonly on the last layer of their neural network. It would be very useful to know\nwhether the exact linear Gaussian model in the last layer proposed by the\nauthors has advantages with respect to a variational approximation on all the\nnetwork weights. If Lipton\'s method would be expensive to apply to large-scale\nsettings such as the Atari games, the authors could also compare with that\nmethod in smaller and simpler problems.\n\nThe plots in Figure 2 include performance in terms of episodes. However, it\nwould also be useful to know how much is the extra computational costs of\nthe proposed method. One could imagine that computing the posterior\napproximation in equation 6 has some additional cost. How do BDQN and DDQN\ncompare when one takes into account running time and not episode count into\naccount?\n\nClarity:\n\nThe paper is clearly written. However, I found a lack of motivation for the\nspecific design choices made to obtain equations 9 and 10. What is a_t in\nequation 9? The parameters \\theta are updated just after equation 10 by\nfollowing the gradient of the loss in which the weights of the last layer are\nfixed to a posterior sample, instead of the posterior mean. Is this update rule\nguaranteed to produce convergence of \\theta? I could imagine that at different\ntimes, different posterior samples of the weights will be used to compute the\ngradients. Does this create any instability in learning? \n\nI found the paragraph just above section 5 describing the maze-like\ndeterministic game confusing and not very useful. The authors should improve\nthis paragraph.\n\nOriginality:\n\nThe proposed approach in which the weights in the last layer of the neural\nnetwork are the only Bayesian ones is not new. The same method was proposed in\n\nSnoek, J., Rippel, O., Swersky, K., Kiros, R., Satish, N., Sundaram, N., ... &\nAdams, R. (2015, June). Scalable Bayesian optimization using deep neural\nnetworks. In International Conference on Machine Learning (pp. 2171-2180).\n\nwhich the authors fail to cite. The use of Thompson sampling for efficient\nexploration in deep Q learning is also not new since it has been proposed by\nLipton et al. 2016. The main contribution of the paper is to combine these two\nmethods (equations 6-10) and evaluate the results in the large-scale setting of\nATARI games, showing that it works in practice.\n\nSignificance:\n\nIt is hard to determine how significant the work is since the authors only\ncompare with a single baseline and leave aside previous work on efficient\nexploration with Thompson sampling based on variational approximations.\n\nAs far as the method is described, I believe it would be impossible to\nreproduce their results because of the complexity of the hyper-parameter tuning\nperformed by the authors. I would encourage the authors to release code that can\ndirectly generate Figure 2 and table 2.\n', 'The authors propose a new algorithm for exploration in Deep RL. They apply Bayesian linear regression, given the last layer of a DQN network as features, to estimate the Q function for each action. Posterior weights are sampled to select actions during execution (Thompson Sampling style). I generally liked the paper and the approach, here are some more detailed comments.\n\nUnlike traditional regression, here we are not observing noisy realisations of the true target, since the algorithm is bootstrapping on non-stationary targets. It’s not immediately clear what the semantics of this posterior are then. Take for example the case where a particular transition (s,a,r,s’) gets replayed multiple times in a row, the posterior about Q(s,a) might then become overly confident even though no new observation was introduced. \n\nPrevious applications of TS to MDPs (Strens, (A Bayesian framework for RL) 2000; Osband 2013) commit to a posterior sample for an episode. But the proposed algorithm samples every T_sample steps, did you find this beneficial to wait longer before resampling? It would be useful to comment on that aspect.\n\nThe method is evaluated on 6 Atari games (How were the games selected? Do they have exploration challenges?) against a single baseline (DDQN). DDQN wasn’t proposed as an exploration method so it would be good to justify why this is an appropriate baseline (versus other exploration methods). The authors argue they could not reproduce Osband’s bootstrapped DQN, which is also TS-based, but you could at least have reported their scores.  \n\nOn these games versus (their implementation of) DDQN, the results seem encouraging. But it would be good to know whether the approach works well across games and is competitive against other stronger baselines. Alternatively, some evidence that interesting exploratory behavior is obtained (in Atari or even smaller domain) would help convince the reader that the approach does what it claims in practice.\n\nIn addition, your reported score on Atlantis of ~2M seems too big. Did you cap the max episode time to 30mins? As is done in the baselines usually.\n\n\nMinor things:\n-“TS finds the true Q-function very fast” But that contradicts the previous statements, I think you mean something different. If TS does not select certain actions, the Q-function would not be updated for these actions. It might find the optimal policy quickly though, even though it doesn’t resolve the entire value function completely.\n-Which epsilon did you use for evaluation of DDQN in the experiments? It’s a bit suspicious that it doesn’t achieve 20+ in Pong.\n-The history of how to go from a Bellman equation to a sample-based update seems a bit distorted. Sample-based RL did not originate in 2008. Also, DQN does not optimize the Bellman residual, it’s a TD update. \n']","[-20, -50, 50]","[50, 50, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer initially expresses some positive aspects ('There are several things to like about this paper'), they ultimately conclude with concerns and disappointment ('I've been disappointed by the authors have incorporated the feedback/reviews'). The overall tone shifts from cautiously positive to negative by the end. The politeness score is moderately positive (50) as the reviewer uses polite and professional language throughout, even when expressing criticism. They use phrases like 'There are several things to like about this paper' and 'I like this paper' before offering constructive criticism. Even when expressing disappointment, the language remains professional rather than harsh or rude. The reviewer also offers specific suggestions for improvement, which is a polite way to provide criticism."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects (e.g., 'The paper is clearly written'), they express several significant concerns and criticisms throughout the review. These include questioning the correctness of key statements, fairness of comparisons, and lack of comparison with relevant baselines. The overall tone suggests more negative than positive sentiment, but not extremely negative.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'I would like to encourage the authors' and 'I would encourage the authors'. They also frame criticisms as concerns or questions rather than direct attacks. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral-to-slightly-positive level of politeness typical in academic discourse."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by saying they 'generally liked the paper and the approach', indicating a positive overall impression. However, they also raise several concerns and suggestions for improvement, which tempers the positivity. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'it would be good to know', 'it would be useful to comment'), and acknowledges positive aspects of the work. The reviewer also asks questions and makes suggestions rather than making blunt demands, which contributes to the polite tone. The language is professional and objective, avoiding any personal attacks or overly harsh criticism.""]"
"['The paper proposes a neural network architecture for centralized and decentralized settings in multi-agent reinforcement learning (MARL) which is trainable with policy gradients.\nAuthors experiment with the proposed architecture on a set of synthetic toy tasks and a few Starcraft combat levels, where they find their approach to perform better than baselines.\n\nOverall, I had a very confusing feeling when reading the paper.\u2028First, authors do not formulate what exactly is the problem statement for MARL. Is it an MDP or poMDP? How do different agents perceive their time, is it synchronized or not? Do they (partially) share the incentive or may have completely arbitrary rewards?\nWhat is exactly the communication protocol?\n\nI find this question especially important for MARL, because the assumption on synchronous and noise-free communication, including gradients is too strong to be useful in many practical tasks.\n\nSecond, even though the proposed architecture proved to perform empirically better that the considered baselines, the extent to which it advances RL research is unclear to me.\nCurrently, it looks \n\nBased on that, I can’t recommend acceptance of the paper.\n\nTo make the paper stronger and justify importance of the proposed architecture, I suggest authors to consider relaxing assumptions on the communication protocol to allow delayed and/or noisy communication (including gradients).\nIt would be also interesting to see if the network somehow learns an implicit global state representation used for planning and how is the developed plan changed when new information from one of the slave agents arrives.', 'This paper investigates multiagent reinforcement learning  making used of a ""master slave"" architecture (MSA). On the positive side, the paper is mostly well-written, seems technically correct, and there are some results that indicate that the MSA is working quite well on relatively complex tasks. On the negative side, there seems to be relatively limited novelty: we can think of MSA as one particular communication (i.e, star) configuration one could use is a multiagent system. One aspect does does strike me as novel is the ""gated composition module"", which allows differentiation of messages to other agents based on the receivers internal state. (So, the *interpretation* of the message is learned). I like this idea, however, the results are mixed, and the explanation given is plausible, but far from a clearly demonstrated answer.\n\nThere are some important issues that need clarification:\n\n* ""Sukhbaatar et al. (2016) proposed the “CommNet”, where broadcasting communication channel among all agents were set up to share a global information which is the summation of all individual agents. [...] however the summed global signal is hand crafted information and does not facilitate an independently reasoning master agent.""\n-Please explain what is meant here by \'hand crafted information\', my understanding is that the f^i in figure 1 of that paper are learned modules?\n-Please explain what would be the differences with CommNet with 1 extra agent that takes in the same information as your \'master\'.\n\n\n*This relates also to this: \n\n""Later we empirically verify that, even when the overall in-\nformation revealed does not increase per se, an independent master agent tend to absorb the same\ninformation within a big picture and effectively helps to make decision in a global manner. Therefore\ncompared with pure in-between-agent communications, MS-MARL is more efficient in reasoning\nand planning once trained. [...] \nSpecifically, we compare the performance among the CommNet model, our\nMS-MARL model without explicit master state (e.g. the occupancy map of controlled agents in this\ncase), and our full model with an explicit occupancy map as a state to the master agent. As shown in\nFigure 7 (a)(b), by only allowed an independently thinking master agent and communication among\nagents, our model already outperforms the plain CommNet model which only supports broadcast-\ning communication of the sum of the signals.""\n\n-Minor: I think that the statement ""which only supports broadcast-ing communication of the sum of the signals"" is not quite fair: surely they have used a 1-channel communication structure, but it would be easy to generalize that.\n\n-Major: When I look at figure 4D, I see that the proposed approach *also* only provides the master with the sum (or really mean) with of the individual messages...? So it is not quite clear to me what explains the difference.\n\n\n*In 4.4, it is not quite clear exactly how the figure of master and slave actions is created. This seems to suggest that the only thing that the master can communicate is action information? It this the case?\n\n* In table 2, it is not clear how significant these differences are. What are the standard errors?\n\n* The section 3.2 explains standard things (policy gradient), but the details are a bit unclear. In particular, I do not see how the Gaussian/softmax layers are integrated; they do not seem to appear in figure 4?\n\n* I cannot understand figure 7 without more explanation. (The background is all black - did something go wrong with the pdf?)\n\n\n\n\nDetails:\n* references are wrongly formatted throughout. \n\n* ""In this regard, we are among the first to combine both the centralized perspective and the decentralized perspective""\nThis is a weak statement (E.g., I suppose that in the greater scheme of things all of us will be amongst the first people that have walked this earth...)\n\n\n* ""Therefore they tend to work more like a commentator analyzing and criticizing the play, rather than\na coach coaching the game.""\n-This sounds somewhat vague. Can it be made crisper?\n\n* ""Note here that, although we explicitly input an occupancy map to the master agent, the actual infor-\nmation of the whole system remains the same.""\nThis is a somewhat peculiar statement. Clearly, the distribution of information over the agents is crucial. For more insights on this one could refer to the literature on decentralized POMDPs.\n\n\n\n\n', 'The paper presents results across a range of cooperative multi-agent tasks, including a simple traffic simulation and StarCraft micro-management. The architecture used is a fully centralized actor (Master) which observes the central state in combination with agents that receive local observation, MS-MARL. \nA gating mechanism is used in order to produce the contribution from the hidden state of the master to the logits of each agent.  This contribution is added to the logits coming from each agent. \n\nPros: \n-The results on StarCraft are encouraging and present state of the art performance if reproducible.\n\nCons:\n-The experimental evaluation is not very thorough:\nNo uncertainty of the mean is stated for any of the results. 100 evaluation runs is very low. It is furthermore not clear whether training was carried out on multiple seeds or whether these are individual runs. \n\n-BiCNet and CommNet are both aiming to learn communication protocols which allow decentralized execution. Thus they represent weak baselines for a fully centralized method such as MS-MARL. \nThe only fully centralized baseline in the paper is GMEZO, however results stated are much lower than what is reported in the original paper (eg. 63% vs 79% for M15v16). The paper is missing further centralized baselines. \n\n-It is unclear to what extends the novelty of the paper (specific architecture choices) are required. For example, the gating mechanism for producing the action logits is rather complex and seems to only help in a subset of settings (if at all).\n\nDetailed comments:\n""For all tasks, the number of batch per training epoch is set to 100.""\nWhat does this mean?\n\nFigure 1: \nThis figure is very helpful, however the colour for M->S is wrong in the legend. \n\nTable 2:\nGMEZO win rates are low compared to the original publication. \nWhat many independent seeds where used for training? What are the confidence intervals? How many runs for evaluation? \n\n\nFigure 4:\nB) What does it mean to feed two vectors into a Tanh? This figure currently very unclear. What was the rational for choosing a vanilla RNN for the slave modules?\n\nFigure 5:\na) What was the rational for stopping training of CommNet after 100 epochs? The plot looks like CommNet is still improving. \nc) This plot is disconcerting. Training in this plot is very unstable. The final performance of the method (\'ours\') does not match what is stated in \'Table 2\'. I wonder if this is due to the very small batch size used (""a small batch size of 4 "").\n\n\n']","[-50, -20, -40]","[20, 60, 50]","[""The sentiment score is -50 because the reviewer expresses confusion and uncertainty about the paper's problem statement and contributions. They state they 'can't recommend acceptance of the paper,' which is a negative sentiment. However, it's not entirely negative as they offer suggestions for improvement. The politeness score is 20 because the reviewer uses polite language throughout, avoiding harsh criticism and offering constructive feedback. They use phrases like 'I suggest' and 'It would be interesting,' which maintain a respectful tone. However, the overall critique is still direct, preventing a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well-written', 'technically correct', 'working quite well'), they express concerns about limited novelty and mixed results. The overall tone suggests more criticism than praise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positives, and phrases criticisms constructively as 'issues that need clarification' rather than outright flaws. They use polite phrases like 'Please explain' and avoid harsh language. The review maintains a professional and courteous tone while still providing substantive feedback."", ""The sentiment score is -40 because while the reviewer acknowledges some positive aspects ('The results on StarCraft are encouraging'), the majority of the review focuses on criticisms and limitations of the paper. The reviewer lists several 'Cons' and provides detailed comments on areas that need improvement or clarification. However, the tone isn't entirely negative, which is why the score isn't lower. The politeness score is 50 because the reviewer maintains a professional and objective tone throughout. They use neutral language to express criticisms ('It is unclear', 'The paper is missing') rather than harsh or accusatory statements. The reviewer also balances criticism with positive remarks ('This figure is very helpful'). While not overly warm, the language is respectful and constructive, which is appropriate for a peer review.""]"
"['This paper presents Bayesian Hypernetworks; variational Bayesian neural networks where the variational posterior over the weights is governed by a hyper network that implements a normalizing flow (NF) such as RealNVP and IAF. As directly outputting the weight matrix with a hyper network is computationally expensive the authors instead propose to utilize weight normalisation on the weights and then use the hyper network to output scalar scaling variables for each hidden unit, similarly to what was done at [1]. The main difference with this prior work is that [1] consider these NF scaling variables as auxiliary random variables to a mean field Gaussian distribution over the weights whereas this paper attempts to posit a distribution directly on the weights via the NF. This avoids the nested variational approximation and auxiliary models of [1], which can potentially yield a tighter bound. The proposed method is evaluated on extensive experiments.\n\nThis paper seems like a plausible idea with extensive experiments but the similarity with [1] make it an incremental contribution and, furthermore, it seems that it has a technical issue with what is explained at Section 3.3. More specifically, if you generate the parameters \\theta according to Eq. 7 and posit a prior over \\theta then you will have a problematic variational bound as there will be a KL divergence, KL(q(\\theta) || p(\\theta)), with distributions of different support (since q(\\theta) is defined only along the directions spanned by u), which is infinite. For the KL to be valid you will need to posit a prior distribution over `g`, p(g), and then consider KL(q(g) || p(g)), with q(g) being given by the NF. From the experiment paragraph at page 5 though I deduct that you instead employ “an isotropic standard normal prior over the weights”, i.e. \\theta, thus I believe that you indeed have a problematic bound. How do you actually compute logq(\\theta) when you employ the parametrisation discussed at 3.3? Did you use that parametrisation in every experiment?\n\nOther than that, I believe that it would be interesting to experiment with a `full` hyper network, i.e. generating directly the entire parameter vector \\theta, e.g. at the toy regression experiment where the dimensionality is small. This would then better illustrate the tradeoffs you make when you reduce the flexibility of the hyper-network to just outputting the row scaling variables and the effect this has at the posterior approximation.\n \nTypos:\n(1) Page 3, 3.1.1 log(\\theta) -> logp(\\theta).\n(2) Eq. 6, it needs to be |det \\frac{\\partial h(\\epsilon)}{\\partial \\epsilon}|^{-1} or |det \\frac{\\partial h^{-1}(\\theta)}{\\partial \\theta}| for a valid change of variables formula.\n\n[1] Louizos & Welling, Multiplicative Normalizing Flows for Variational Bayesian Neural Networks.', 'This paper proposes Bayesian hypernetworks to carry out Bayesian learning of deep networks. The idea is to construct a generative model capable of approximating the posterior distribution over the parameters of deep networks. I think that the paper is well written and easy to follow. \n\nI like the idea of constructing general approximation strategies for complex posterior distribution and the proposed approach inherits all the scalability properties of modern deep learning techniques. In this respect, I think that the paper tackles a timely topic and is interesting to read. \n\nIt is not entirely clear to me why the Authors name their proposal Bayesian hypernetworks. This seems to suggest that also the hypernetwork is infered using Bayesian inference, but if I understand correctly this is not the case. \n\nI have some comments on novelty and realization of the experiments. In the positioning of the work in the literature, the Authors point out that hypernetworks have been proposed before, so it is not clear what is the actual novelty in the proposal. Is it the use of Real NVPs and IAFs as hypernetworks? These methods have been already proposed and extensively studied in the literature, and even if they have been adapted to be hypernetworks here, I believe that the novelty is fairly limited. \n\nThe experimental part is interesting as it explores a number of learning scenarios. However, I think that it would have been useful to add comparisons with standard variational inference (e.g., Graves, 2011) for deep networks to substantiate the claims that this approach underestimates uncertainty. I believe that this would strengthen the comparative evaluation. \n\nI think the paper would have made a stronger case by including other approaches to approximate posteriors using generative models. For example, the variational Gaussian process paper sounds like an ideal method to include here. \n\n[1] D. Tran, R. Ranganath, and D. M. Blei. Variational Gaussian process. arXiv preprint arXiv:1511.06499, 2015.', '* Edit: I increased my rating to 6. The authors fixed the first error I pointed out below. Regarding the second point: I still think it is possible to take a limit of sigma -> 0 in MNF, which makes the methods very similar.\n\nThe authors propose a new method of defining approximate posteriors for use in Bayesian neural networks. The idea of using hypernetworks for Bayesian inference is compelling, and the authors show some promising first results. I see two issues, and would be willing to increase my rating if these were sufficiently addressed.\n\n- The paper says it uses an ""isotropic standard normal prior on the weights of the network"". However, the stochastic part of the generated weights (i.e. the scales) is of a lower dimension than the weights. It seems to me this means that the KL divergence between prior and posterior is undefined, or infinite, as the posterior is only defined on a sub-manifold. What exactly is the loss term that is added to the training objective? And how is this justified?\n\n- The instantiation of Bayesian hypernetworks that is used in experiments seems to be a special case of the method of multiplicative normalizing flows as proposed by Louizos and Welling and discussed in this paper. If the variances / sigmas are zero in the latter method, their approximation seems functionally equivalent to Bayesian hypernetworks (though with different parameterization). Is my understanding correct? If so, the novelty of the proposed method is limited.']","[-20, 20, -20]","[60, 60, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as a 'plausible idea with extensive experiments', they also point out that it's an 'incremental contribution' and highlight a potential 'technical issue'. The reviewer expresses concerns about the similarity to previous work and questions the validity of the variational bound. These criticisms outweigh the initial positive remarks, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions rather than direct attacks, and offers constructive feedback. The reviewer also points out typos politely and suggests additional experiments, which is helpful and courteous. The language is professional and objective, avoiding harsh or rude phrasing."", ""The sentiment score is slightly positive (20) because the reviewer expresses some positive aspects ('well written', 'easy to follow', 'interesting to read') but also raises several concerns and suggestions for improvement. The overall tone is constructive but not overwhelmingly positive. The politeness score is moderately high (60) as the reviewer uses polite language throughout, such as 'I think', 'I believe', and frames criticisms as suggestions or questions rather than direct negative statements. The reviewer maintains a professional and respectful tone while providing both positive feedback and areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('compelling idea', 'promising first results'), they raise two significant issues that need to be addressed. The reviewer's willingness to increase their rating if these issues are resolved indicates that the overall sentiment is not strongly negative. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and offers constructive criticism. They use phrases like 'I see two issues' and 'Is my understanding correct?', which maintain a polite and professional tone. The reviewer also shows flexibility by stating they would be 'willing to increase my rating if these were sufficiently addressed', which is a courteous approach to criticism.""]"
"[""The authors propose an extension of adversarial reinforcement learning to A3C. The proposed technique is of modest contribution and the experimental results do not provide sufficient validation of the approach.  \n\nThe authors propose extending A3C to produce more robust policies by training a zero-sum game with two agents: a protagonist and an antagonist. The protagonist is attempting to achieve the given task while the antagonist's goal is for the task to fail. \n\nThe contribution of this work, AR-A3C, is extending adversarial reinforcement learning, namely robust RL (RRL) and robust adversarial RL (RARL), to A3C. In the context of this prior work the novelty is extending the family of adversarial RL methods. However, the proposed method is still within the same family methods as demonstrated by RARL.\n\nThe authors state that AR-A3C requires half as many rollouts as compared to RARL. However, no empirical comparison between the two methods is performed. The paper only performs analysis against the A3C and no other adversarial baseline and on only one environment: cartpole.  While they show transfer to the real world cartpole with this technique, there is not sufficient analysis to satisfactorily demonstrate the benefits of the proposed technique. \n\nThe paper reads well. There are a few notational issues in the paper that should be addressed. The authors mislabel the value function V as the  action value, or Q function. The action value function is action dependent where the value function is not.  As a much more minor issue, the authors introduce y as the discount factor, which deviates from the standard notation of \\gamma without any obvious reason to do so.\n\nDouble blind was likely compromised with the youtube video, which was linked to a real name account instead of an anonymous account.\n\nOverall, the proposed technique is of modest contribution and the experimental results do not provide sufficient validation of the approach.    "", 'Clarity \nThe paper is clear in general. \n\nOriginality\nThe novelty of the method is limited. The proposed method is a simple extension of L. Pinto et al. by replacing TRPO with A3C. No evidence is provided to show the proposed method is competitive with the original TRPO version. \n\nSignificance\n- The empirical results on the hardware are valuable. \n- The simulated results are very limited. The neural networks used in the simulation have only one hidden layer. The method is tested on the Pendulum domain. \n\nPros:\n- Real hardware results are provided. \n\nCons:\n- Limited simulation results. \n- Lacking technical novelty. \n', 'Positive:\n- Interesting approach\n- Hardware validation (the RL field needs more of this!)\n\nNegative:\n- Figure 2: what is the reward here? The one from Section 5.1?\n- No comparisons to other methods: Single pendulum swing-up is a very easy task that has been solved with various methods (mostly in a cart-pole setup). Please compare to existing methods such as PILCO, basic Q-learning, classical methods... \n- I\'m not sure what\'s going on with the grammar in Section 5.3 (""like crazy"", ""super hot""...). This section also seems irrelevant (move to an appendix/supplementary or remove).\n- You should plot a typical control curve for the motors (requested torques). This might explain your heat problem (I\'m guessing the motor is effectively controlled by a bang-bang controller).\n- Why did you pick this task? It\'s fine to only validate on a single task in hardware, but why not include additional simulation results (e.g. double pendulum)?']","[-60, -20, -20]","[20, 50, 50]","[""The sentiment score is -60 because the review is generally negative, with phrases like 'modest contribution' and 'do not provide sufficient validation' indicating dissatisfaction with the paper. However, it's not entirely negative as it acknowledges some positive aspects like the paper reading well. The politeness score is 20 because while the reviewer maintains a professional tone and offers some constructive feedback, the overall critique is direct and somewhat harsh. The reviewer uses polite language but doesn't soften their criticisms much. The reasoning behind these scores comes from analyzing the language used throughout the review, the balance of positive and negative comments, and the overall tone of the feedback provided."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is clear in general', 'The empirical results on the hardware are valuable', 'Real hardware results are provided'), they also point out significant limitations ('The novelty of the method is limited', 'The simulated results are very limited', 'Lacking technical novelty'). The overall tone suggests more criticism than praise. The politeness score is moderately positive (50) because the reviewer uses neutral, professional language throughout. They present both pros and cons in a balanced manner without using harsh or judgmental language. The critique is delivered in a straightforward, matter-of-fact way without personal attacks or overly negative phrasing."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Interesting approach', 'Hardware validation'), the majority of the comments are critical and point out areas for improvement. The reviewer lists several negative points and requests for additional information or comparisons, which outweigh the positive remarks.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional tone throughout most of the review. They use neutral language for most criticisms and frame them as suggestions or questions rather than direct attacks. However, the score is not higher because of the slightly informal language used in critiquing Section 5.3 ('like crazy', 'super hot') and the direct nature of some comments ('No comparisons to other methods', 'Why did you pick this task?').\n\nOverall, the review is constructive but leans towards being critical, while maintaining a generally polite and professional tone.""]"
"[""This manuscript is fairly well-written, and discusses how the batch normalization step helps to stabilize the scale of the gradients.  Intriguingly, the analysis suggests that using a shallower but wider resnet should provide competitive performance, which is supported by empirical evidence.  This work should help elucidate the structure in the learning, and help to support efforts to improve both learning algorithms and the architecture.\n\nPros:\nClean, simple analysis\nEmpirical support suggests that theory captures reasonable effects behind learning\n\nCons:\nThe reasonableness of the assumptions used in the analysis needs a more careful analysis.  In particular, the assumption that all weights are independent is valid only at the first random iteration.  Therefore, the utility of this theory during initialization seems reasonable, but during learning the theory seems quite tenuous.  I would encourage the authors to discuss their assumptions, and talk about how the math would change as a result of relaxing the assumptions.\nThe empirical support does provide evidence that the theory is reasonable.  However, it is limited to a single dataset.  It would be nice to see that the effect happens more generally. Second, it is clear that shallow+wide networks may be better than deep+narrow networks, but it's not clear about how the width is evaluated and supported. I would encourage the authors to do more extensive experiments and evaluate the architecture further.\n\nRevision:\nUpon examining the comments of the other reviews, I have agreed with several of their points and it is necessary to increase the explanation of the mathematical points.  I encourage the authors to address these comments and revise their work."", 'This paper attempts to analyze the gradient flow through a batchNorm-ReLU ResNet and make suggestions for reducing gradient explosion.\n\nFirstly, the paper has a fatal mathematical flaw. Consider equation (10). There, you show the variance of y_{L,i} taken over BOTH random weights AND the batch. Now consider equation (32). In that equation, Var(y_{L,i}) appears in the denominator but this variance is taken over ONLY the batch and NOT the random weights. This Var(y_{L,i}) came from batch normalization, which divides its incoming activation values by their standard deviation. However, batch normalization only sees the variation in the activations given to it by a SPECIFIC set of weights. It does not know about the random variation of the weights because that randomness is in a sense a superstructure imposed on the network that the network operations themselves cannot see. Therefore, your substitution and therefore equation (13) is incorrect. If you replace the variance in equation (32) by the correct value, you will get a very different result from which very different (and very interesting!) conclusions can be drawn. \n\nSecondly, in section 4, your analysis depends on the specific type of ResNet you chose. Specifically, when transitioning from one ""scale"" to the next, you chose to insert not just a convolutional layer, but also a batch normalization and ReLU layer on the residual path. To achieve scale transitions, in general, people use a single convolutional layer with 1*1 receptive field on the residual path. It is not a problem in itself to use a nonstandard architecture, but you do not discuss how your results would generalize to other ResNet architectures. Therefore your results have very limited relevance. (Note that again, of course, your results are corrupted by the variance problem I described earlier.)\n\nFinally, with regards to section 5, let me be honest. (I hope that my area chair agrees with me that honesty is the best and kindest policy.) This section makes no sense. You do not understand the work by Veit et al. You do not know how to interpret gradient variances. While I won\'t be able to dicuss ""gradient variance"" as a concept in full detail in this review, here\'s a quick summary. (A) Veit et al. argued that a deep ResNet behaves as an ensemble of shallower networks as long as the gradient flowing through the residual paths is not larger than the gradient flowing through the skip paths. (B) The exploding gradient problem refers to the size of the gradient growing exponentially. The vanishing gradient problem refers to the size of the gradient shrinking exponentially. This can make it difficult to train the network. See ""DEEP INFORMATION PROPAGATION"" by Schoenholz et al. from ICLR 2017 to learn more about how gradient explosion can arise. (C) For a neural network to model a ground truth function exactly, the gradients of the network with respect to the input data have to match the gradients of the ground truth function with respect to the input. From observations (A) through (C), we can derive three guidelines for gradient conditioning: (A) have the gradient flowing through residual paths be not too small relative to the gradient flowing through skip paths, (B) have the gradient not grow or shrink exponentially with too large a rate, (C) have the data gradient match that of the ground truth function. However, you seem to be arguing that it is a problem if the gradient scale does increases too little from one residual block to the next. I am not aware of an established argument that this is indeed a problem. To be fair, one might make an argument as follows: ""the point of deep nets is to be expressive, expressiveness of a layer relates to the spetrum of the layer-Jacobian, a small increase in gradient scale implies the layer-Jacobian has many similar singular values, therefore a small increase in gradient scale implies low expressiveness of the layer, therefore the layer is pathological"". However, much more analysis, detail and care would be required to make this argument successfully. In any case, I also don\'t think that was the argument you were trying to make. Note that after I skimmed through the submissions to this conference, there seem to be interesting papers on the topic of gradients. Those papers plus the references provided in those papers should provide a good introduction to the topic of gradients in neural networks.\n\nOther comments:\n - your notation is quite sloppy and may have lead to errors. Example: in the beginning of section 4, you say that from one ""scale"" to the next, the filter number increases k times. But in appendix C you say ""Since the receptive field for the last scale is k times smaller"". So is k the change in the receptive field size or the filter number of both? I would strongly recommend using dedicated variables to denote the width of the receptive field in each convolutional layer, the height of the receptive field in each convolutional layer as well as the filter number and then express all assumptions made in equation form. \n- Equation (20) deals with the change of gradient variance within a scale. Where is the equation that shows the change of gradient variance between scales?\n- I would suggest making all derivations in appendices A through D much more detailed. \n\n\n', 'Summary:\nThis paper analyzed the effect of batch normalization (BN) on gradient backpropagation in residual networks (ResNets). The authors demonstrate that BN can confine the gradient variance to a certain range in each residual block. The analysis is extended to discuss the trade-off between the depth and width of residual networks. However, the effect of BN in ResNets is still not clear and some definitions in this paper are confusing.\n\nStrengths:\n1. This paper conducted mathematical analysis on the effect of batch normalization (BN) in residual networks during back-propagation. \n\n2. The authors demonstrated that BN confined the gradient variance to a certain range in each residual block. \n\n3. The authors discussed the tradeoff between the depth and width of residual networks based on the analysis of BN.\n\nWeak points:\n1. The motivation of the analysis on the effect of BN in residual network is not clear. Compared to the plain network with BN, the gradient vanishing/explosion problem has been largely addressed by the shortcut of identity mapping. After reading the paper, it is still not clear what kind of role the BN plays for addressing this issue, especially when compared to the effect of identity mapping.\n\n2. There seems a definition error in the first paragraph of Section 3.1. Should $\\delta x$ be the batch of input gradient and $\\delta \\tilde x$ be the batch of output gradient?\n\n3. In Section 3.1, what does “the standard normal variate of x is z” mean? \n\n4. The definition of x_i in Eqn. (4) is very confusing, which makes the paper hard to follow. Here, the subscript x_i should be the i-th channel of input feature map rather than the i-th example in a mini-batch. However, in the original BN paper, all the gradients are computed w.r.t. the i-th example in a mini-batch. So, how to transform the formulas in the original BN paper to the gradient w.r.t. a specific channel like Eqn. (4). More details should be provided.\n\n5. In Section 3.2, it is strange that the authors consider a basic block containing  BN and ReLU, followed by a convolution layer. However, in general deep learning setting,  the BN and ReLU is often put after a convolution layer. Please explain more on this point.\n\n6. In Section 3.3, the authors assume that the weights of convolution layer have zero-mean, because the mean of input/output gradient is zero. However, it does not mean that the gradient w.r.t. the weights has zero-mean and the gradient will introduce a distribution bias in the weights. \n\n7. In Section 5, the authors argued that the sharper gradient variance changes resulted in more discriminatory learning. However, this is not well justified. \n']","[50, -80, -30]","[75, -20, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer begins by praising the manuscript as 'fairly well-written' and acknowledges its potential to 'help elucidate the structure in the learning'. However, they also point out significant cons and areas for improvement, balancing the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'I would encourage the authors' and 'it would be nice to see', which maintain a polite and collaborative tone even when pointing out weaknesses in the work."", ""The sentiment score is -80 because the review is highly critical, pointing out a 'fatal mathematical flaw' and stating that a section 'makes no sense'. The reviewer also suggests that the authors don't understand key concepts. These are strong negative criticisms that indicate the paper has significant issues. The politeness score is -20 because while the reviewer attempts to be constructive in places (offering explanations and suggestions for improvement), the language is quite direct and at times harsh. Phrases like 'you do not understand' and 'This section makes no sense' are particularly blunt. The reviewer does attempt some politeness with phrases like 'let me be honest' and 'To be fair', but overall the tone is more critical than polite."", ""The sentiment score is -30 because while the review acknowledges some strengths of the paper, it primarily focuses on weak points and areas needing improvement. The reviewer points out several issues with definitions, clarity, and justification of claims. However, it's not entirely negative as it does recognize some positive aspects. The politeness score is 50 because the language used is professional and constructive. The reviewer uses phrases like 'please explain more on this point' and frames criticisms as observations or questions rather than direct attacks. The tone is academic and respectful, albeit critical.""]"
"[""The paper proposed a teacher-student framework and a modified objective function to adapt VAE training to streaming data setting. The qualitative experimental result shows that the learned model can generate reasonable-looking samples. I'm not sure about what conclusion to make from the numerical result, as the test negative ELBO actually increased after decreasing initially. Why did it increase?\n\nThe modified objective function is a little ad-hoc, and it's unclear how to relate the overall objective function to Bayesian posterior inference (what exactly is the posterior that the encoder tries to approximate?). There is a term in the objective function that is synthetic data specific. Does that imply that the objective function is different depending on if the data is synthetic or real? What is the motivation/justification of choosing KL(Q_student||Q_teacher) as regularisation instead of the other way around? Would that make a difference in the goodness of the learned model? If not, wouldn't KL(Q_teacher||Q_student) result reduction in the variance of gradients and therefore a better choice?\n\nDetails on the minimum number of real samples per interval for the model to be able to learn is also missing. Also, how many synthetic samples per real samples are needed? How is the update with respect to synthetic sample scheduled? Given infinite amount of streaming data with a fixed number of classes/underlying distributions and interval length, and sample the class of each interval (uniformly) randomly, will the model/algorithm converge? Is there a minimum number of real examples that the student learner needs to see before it can be turned into a teacher?\n\nOther question: How is the number of latent category J of the latent discrete distribution chosen?\n\nQuality: The numerical experiment doesn't really compare to any other streaming benchmark and is a little unsatisfying. Without a streaming benchmark or a realistic motivating example in which the proposed scheme makes a significant difference, it's difficult to judge the contribution of this work.\nClarity: The manuscript is reasonably well-written. (minor: Paragraph 2, section 5, 'in principle' instead of 'in principal')\nOriginality: Average. The student-teacher framework by itself isn't novel. The modifications to the objective function appears to be novel as far as I am aware, but it doesn't require much special insights.\nSignificance: Below average. I think it will be very helpful if the authors can include a realistic motivating example where lifelong unsupervised learning is critical, and demonstrate that the proposed scheme makes a difference in the example.\n\n\n"", 'We have seen numerous variants of variational autoencoders, most of them introducing delta changes to the original architecture to address the same sort of modeling problems. This paper attacks a different kind of problem, namely lifelong learning. This key aspect of the paper, besides the fact that it constitutes a very important problem, does also addes a strong element of freshness to the paper.\n\nThe construction of the generative model is correct, and commensurate with standard practice in the field of deep generative models. The derivations are correct, while the experimental evaluation is diverse and convincing. ', '- Second paragraph in Section 1: Nice motivation. I am not sure though whether the performed experiments are the most expressive for such motivation. For instance, is the experiment in Section 5.1 a common task in that sequential lifelong learning setting?\n\n- Section 4, which is the main technical section of the paper, is quite full of lengthy descriptions that are a bit equivocal. I reckon each claim really needs to be supported by a corresponding unequivocal mathermatical formulation.\n\n- An example of the last point can be found in Section 4.2: ""The synthetic samples need to be representative of all the previously observed distributions ..."": It will be much clearer how such samples are representative if a formulation follows, and that did not happen in Section 4.2.\n\n- ""1) Sampling the prior can select a point in the latent space that is in between two separate distributions ..."": I am not sure I got this drawback of using the standard form of VAEs. Could you please further elaborate on this?\n\n- ""we restrict the posterior representation of the student model to **be close to that of the teacher** for the previous distributions** accumulated by the teacher. This allows the model parameters to **vary as necessary** in order to best fit the data"": What if the previous distributions are not that close to the new one?\n\n- Distribution intervals: Will it be the case in reality that these intervals will be given? Otherwise, what are the solutions to that? Can they be estimated somehow (as a future work)?\n\n\nMinor:\n- ""we observe a sample X of K"": sample X of size K, I guess?\n- ""... form nor an efficient estimator Kingma (2017)"": citation style.\n- ""we illustrates ...""']","[-20, 90, -20]","[50, 50, 40]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('reasonable-looking samples', 'reasonably well-written'), they express several concerns and uncertainties about the paper's methods, results, and significance. The reviewer points out unclear aspects, questions the methodology, and suggests the contribution is 'below average'. However, it's not entirely negative as they provide constructive feedback and acknowledge some merits.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I'm not sure', 'it would be helpful if', and pose questions rather than making harsh statements. The reviewer also balances criticism with positive remarks and provides specific suggestions for improvement, which is considerate. The language is not overly formal or polite, but it avoids rudeness or harsh criticism, maintaining a neutral to slightly positive politeness level."", ""The sentiment score is 90 (highly positive) because the reviewer expresses strong approval of the paper's novelty, correctness, and experimental evaluation. They highlight the 'freshness' of the approach and describe the evaluation as 'diverse and convincing'. The politeness score is 50 (moderately polite) because while the language is professional and respectful, it doesn't contain overtly polite phrases. The reviewer uses neutral, objective language to convey their positive assessment without excessive formality or flattery."", ""The sentiment score is slightly negative (-20) because while the reviewer provides some positive feedback ('Nice motivation'), the majority of the comments are critical and point out areas for improvement. The reviewer questions the appropriateness of experiments, criticizes the clarity of explanations, and requests further elaboration on several points. However, the tone is not overly harsh, hence the score is only mildly negative. The politeness score is moderately positive (40) as the reviewer uses polite language throughout, such as 'Could you please further elaborate on this?' and frames criticisms as suggestions or questions rather than direct attacks. The reviewer also acknowledges positive aspects ('Nice motivation') before providing critiques. The language is professional and constructive, avoiding rudeness while still clearly communicating areas for improvement.""]"
"['In this paper the authors give a nice review of clustering methods with deep learning and a systematic taxonomy for existing methods. Finally, the authors propose a new method by using one unexplored combination of taxonomy features.\n\nThe paper is well-written and easy to follow. The proposed combination is straightforward, but lack of novelty. From table 1, it seems that the only differences between the proposed method and DEPICK is whether the method uses balanced assignment and pretraining. I am not convinced that these changes will lead to a significant difference. The performance of the proposed method and DEPICK are also similar in table 1. \n\nIn addition, the experiments section is not comprehensive enough as well. the author only tested on two datasets. More datasets should be tested for evaluation. In addition, It seems that nearly all the experiments results from comparison methods are borrowed from the original publications. The authors should finish the experiments on comparison methods and fill the entries in Table 1.\n\nIn summary, the proposed method is lack of novelty compare to existing methods. The survey part is nice, however extensive experiments should be conducted by running existing methods on different datasets and analyzing the pros and cons of the methods and their application scenarios. Therefore, I think the paper cannot be accepted at this stage.\n', 'This paper presents some reviews on clustering methods with deep learning. Based on the review taxonomy, the authors presents a mixed objective which aims for bretter clustering performance. The proposed method is then tested on two image data sets.\n\nThe claimed main contribution of the paper is the taxonomy. There are no new things in such kind of reviews. The taxonomy gives no scientific axioms. Therefore the impact or actual contribution to the ICLR community is very limited.\n\nThe proposed clustering method is problematic. It is hard to set the paramter alpha. The experimental results are also disappointing. For example, the COIL20 accuracy is only 0.762, much worse than the state of the art. Moreover, results on only two image data sets are not sufficient for convincing.', 'The paper is mostly a survey about clustering methods with neural networks. \n\nSection 2 presents a taxonomy for the different neural network clustering methods. A rich lists of the possible components of the neural network-based clustering methods are given, that include the different neural network architectures, feature to use for clustering, loss functions used and more. In Section 3, a few methods from the literature are classified according to the proposed taxonomy. Furthermore, in Section 4 a new method is proposed, that is to combine the best parts of the already existing models in the literature. Unfortunately, the experiments is Section 5 reveal that the proposed method yields results that are at most comparable with the existing methods. \n\nThe paper is written well and provides good insights (mostly taxonomy) on the existing methods for neural network-based clustering. However, the paper lacks novel content. The novel content of the paper sums up to the proposed method, that is composed of building blocks of existing models, and fails to impress in experimental results. It could be that this paper belongs to another venue that is more appropriate for survey papers.  Also, it overall rather appears short.\n']","[-50, -70, -20]","[50, -20, 50]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('nice review', 'well-written'), they ultimately recommend rejection due to lack of novelty and insufficient experiments. The overall tone is more negative than positive. The politeness score is 50 because the reviewer uses polite language ('nice', 'well-written') and provides constructive feedback, but doesn't go out of their way to be overly courteous. They maintain a professional tone throughout, balancing positive comments with critical feedback."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper's main contribution (the taxonomy) offers 'no new things' and has 'very limited' impact. They also describe the proposed clustering method as 'problematic' and the experimental results as 'disappointing'. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without much attempt to soften the criticism or offer positive feedback. Phrases like 'There are no new things', 'The impact or actual contribution... is very limited', and 'results... are not sufficient for convincing' are quite blunt and could be perceived as somewhat impolite in academic discourse."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('written well', 'provides good insights'), they also point out significant shortcomings. The paper is criticized for lacking novel content, having unimpressive experimental results, and possibly being more suitable for a different venue. The overall tone suggests disappointment with the paper's contributions.\n\nThe politeness score is moderately positive (50) as the reviewer uses respectful and professional language throughout. They begin with positive observations before moving to criticisms, which are presented in a constructive manner. The reviewer avoids harsh or personal criticism, instead focusing on the paper's content and suggesting potential improvements or alternative venues. The language is diplomatic, using phrases like 'It could be that' to soften critiques.""]"
"[""This paper generates adversarial examples using the fast gradient sign (FGS) and iterated fast gradient sign (IFGS) methods, but replacing the gradient computation with finite differences or another gradient approximation method. Since finite differences is expensive in high dimensions, the authors propose using directional derivatives based on random feature groupings or PCA. \n\nThis paper would be much stronger if it surveyed a wider variety of gradient-free optimization methods. Notably, there's two important black-box optimization baselines that were not included: simultaneous perturbation stochastic approximation ( https://en.wikipedia.org/wiki/Simultaneous_perturbation_stochastic_approximation), which avoids computing the gradient explicitly, and evolutionary strategies ( https://blog.openai.com/evolution-strategies/ ), a similar method that uses several random directions to estimate a better descent direction.\n\nThe gradient approximation methods proposed in this paper may or may not be better than SPSA or ES. Without a direct comparison, it's hard to know.  Thus, the main contribution of this paper is in demonstrating that gradient approximation methods are sufficient for generating good adversarial attacks and applying those attacks to Clarifai models. That's interesting and useful to know, but is still a relatively small contribution, making this paper borderline. I lean towards rejection, since the paper proposes new methods without comparing to or even mentioning well-known alternatives.\n\nREVISION: Thank you for your response! The additional material does strengthen the paper. There is now some discussion of how Chen et al. differs, and an explicit comparison to SPSA and PSO. I think there are some interesting results here, including attacks on Clarifai. However, the additional evaluations are not thorough. This is understandable (given the limited time frame), but unfortunate. SPSA is only evaluated on MNIST, and while the paper claims its distortion is greater, this is never shown explicitly (or was too difficult for me to find, even when searching through the revised paper). Chen et al. is only compared in terms of time, not on success rate, distortion, or number of queries. These timing results aren't necessarily comparable, since the experiments were done under different conditions. Overall, the new experiments and discussion are a step towards a thorough analysis of zero-order attacks, but they're not there yet. I've increased my rating from 4 to 5, but this is still below the bar for me."", '\nQuality: The paper studies an important problem given that public ML APIs are now becoming available. More specifically, the authors study black-box attacks based on gradient estimation. This means that adversaries have no access to the underlying model.\n\nClarity: The paper is clear and well-written. Some parts are a bit redundant, so more space of the main body of the paper could be devoted information provided in the appendix and would help with the flow (e.g., description of the models A, B, C; logit-based loss; etc.). This would also provide room for discussing the targeted attacks and the tranferability-based attacks.\n\nOriginality: While black-box attacks are of greater interest than withe-box attacks, I found the case considered here of modest interest. The assumption that the loss would be known, but not the gradient is relatively narrow. And why is not possible to compute the gradient exactly in this case? Also, it was not clear what how \\delta can be chosen in practice to increase the performance of the attack. Could the authors comment on that?\n\nSignificance: The results in the paper are encouraging, but it is not clear whether the setting is realistic. The main weakness of this paper is that it does not state the assumptions made and under which conditions these attacks are valid. Those have to be deduced from the main text and not all are clear and many questions remain, making it difficult to see when such an attack is a risk and what is the actual experimental set-up. For example, what does it mean that attackers have access to the training set and when does that occur? Is it assumed that the API uses the adversarial example for training as well or not? How are the surrogate models trained and what are they trying to optimize and/or what do they match? In which situations do attackers have access to the loss, but not the gradient? How sensitive are the results to a loss mismatch? Finally, I do not understand the performance metric proposed by the authors. It is always possible to get an arbitrarily high success rate unless one fixes the distortion. What would be the success rate if the distortion was equal to the distortion of white-box attacks?  And how sensitive are the results to \\epsilon (and how can it be chosen by an attacker in practice)?\n', 'The authors consider new attacks for generating adversarial samples against neural networks. In particular, they are interested in approximating gradient-based white-box attacks such as FGSM in a black-box setting by estimating gradients from queries to the classifier. They assume that the attacker is able to query, for any example x, the vector of probabilities p(x) corresponding to each class.\n\nGiven such query access it’s trivial to estimate the gradients of p using finite differences. As a consequence one can implement FGSM using these estimates assuming cross-entropy loss, as well as a logit-based loss. They consider both iterative and single-step FGSM attacks in the targeted (i.e. the adversary’s goal is to switch the example’s label to a specific alternative label) and un-targeted settings (any mislabelling is a success). They compare themselves to transfer black-box attacks, where the adversary trains a proxy model and generates the adversarial sample by running a white-box attack on that model.  For a number of target classifiers on both MNIST and CIFAR-10, they show that these attacks outperform the transfer-based attacks, and are comparable to white-box attacks, while maintaining low distortion on the attack samples. \n\nOne drawback of estimating gradients using finite differences is that the number of queries required scales with the dimensionality of the examples, which can be prohibitive in the case of images. They therefore describe two practical approaches for query reduction — one based on random feature grouping, and the other on PCA (which requires access to training data). They once again demonstrate the effectiveness of these methods across a number of models and datasets, including models deploying adversarially trained defenses. \n\nFinally, they demonstrate compelling real-world deployment against Clarifai classification models designed to flag “Not Safe for Work” content. \n\nOverall, the paper provides a very thorough experimental examination of a practical black-box attack that can be deployed against real-world systems. While there are some similarities with Chen et al. with respect to utilizing finite-differences to estimate gradients, I believe the work is still valuable for its very thorough experimental verification, as well as the practicality of their methods. The authors may want to be more explicit about their claim in the Related Work section that the running time of their attack is “40x” less than that of Chen et al. While this is believable, there is no running time comparison in the body of the paper. ']","[-50, -20, 80]","[50, 50, 70]","[""The sentiment score is -50 because the reviewer leans towards rejection and points out several shortcomings of the paper, such as lack of comparison with well-known alternatives and insufficient thoroughness in evaluations. However, they do acknowledge some improvements and interesting results, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses professional and respectful language throughout, acknowledging the authors' efforts and improvements while providing constructive criticism. They avoid harsh or dismissive language, instead offering specific suggestions for improvement and explaining their reasoning clearly."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem and the clarity of the paper, they express several concerns about the originality, significance, and assumptions of the work. The reviewer points out limitations in the experimental setup and questions the realism of the setting. However, it's not entirely negative as they do recognize some positive aspects.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'Could the authors comment on that?' and 'I do not understand' rather than making accusatory statements. The critique is presented as constructive feedback rather than harsh criticism. However, it doesn't reach the highest levels of politeness as it doesn't include overtly complimentary language or expressions of gratitude for the opportunity to review."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They describe the work as providing a 'very thorough experimental examination' and 'valuable for its very thorough experimental verification'. The reviewer also notes the 'practicality of their methods' and the 'compelling real-world deployment'. While there is a minor criticism about the lack of running time comparison, the overall tone is highly positive. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They acknowledge the authors' work positively without using overly effusive praise. The reviewer also offers a constructive suggestion ('The authors may want to be more explicit...') rather than a harsh criticism. The language is objective and focused on the content of the paper, maintaining a courteous and academic tone throughout.""]"
"['This paper introduces a neural network architecture for continual learning. The model is inspired by current knowledge about long term memory consolidation mechanisms in humans. As a consequence, it uses:\n-\tOne temporary memory storage (inspired by hippocampus) and a long term memory\n-\tA notion of memory replay, implemented by generative models (VAE), in order to simultaneously train the network on different tasks and avoid catastrophic forgetting of previously learnt tasks.\nOverall, although the result are not very surprising, the approach is well justified and extensively tested. It provides some insights on the challenges and benefits of replay based memory consolidation.\n\nComments:\n\t\n1-\tThe results are somewhat unsurprising: as we are able to learn generative models of each tasks, we can use them to train on all tasks at the same time, a beat algorithms that do not use this replay approach. \n2-\tIt is unclear whether the approach provides a benefit for a particular application: as the task information has to be available, training separate task-specific architectures or using classical multitask learning approaches would not suffer from catastrophic forgetting and perform better (I assume). \n3-\tSo the main benefit of the approach seems to point towards the direction of what possibly happens in real brains. It is interesting to see how authors address practical issues of training based on replay and it show two differences with real brains: 1/ what we know about episodic memory consolidation (the system modeled in this paper) is closer to unsupervised learning, as a consequence information such as task ID and dictionary for balancing samples would not be available, 2/ the cortex (long term memory) already learns during wakefulness, while in the proposed algorithm this procedure is restricted to replay-based learning during sleep.\n4-\tDue to these differences, I my view, this work avoids addressing directly the most critical and difficult issues of catastrophic forgetting, which relates more to finding optimal plasticity rules for the network in an unsupervised setting\n5-\tThe writing could have been more concise and the authors could make an effort to stay closer to the recommended number of pages.\n', 'This paper reports on a system for sequential learning of several supervised classification tasks in a challenging online regime. Known task segmentation is assumed and task specific input generators are learned in parallel with label prediction. The method is tested on standard sequential MNIST variants as long as a class incremental variant. Superior performance to recent baselines (e.g. EWC) is reported in several cases. Interesting parallels with human cortical and hippocampal learning and memory are discussed.\n\nUnfortunately, the paper does not go beyond the relatively simplistic setup of sequential MNIST, in contrast to some of the methods used as baselines. The proposed architecture implicitly reduces the continual learning problem to a classical multitask learning (MTL) setting for the LTM, where (in the best case scenario) i.i.d. data from all encountered tasks is available during training. This setting is not ideal, though. There are several example of successful multitask learning, but it does not follow that a random grouping of several tasks immediately leads to successful MTL. Indeed, there is good reason to doubt this in both supervised and reinforcement learning domains. In the latter case it is well known that MTL with arbitrary sets of task does not guarantee superior, or even comparable performance to plain single-task learning, due to ‘negative interference’ between tasks [1, 2]. I agree that problems can be constructed where these assumptions hold, but this core assumption is limiting. The requirement of task labels also rules out important use cases such as following a non-stationary objective function, which is important in several realistic domains, including deep RL.\n\n\n[1] Parisotto, Emilio; Lei Ba, Jimmy; Salakhutdinov, Ruslan: \t\nActor-Mimic: Deep Multitask and Transfer Reinforcement Learning. ICLR 2016.\n[2] Andrei A. Rusu, Sergio Gomez Colmenarejo, Çaglar Gülçehre, Guillaume Desjardins, James Kirkpatrick, Razvan Pascanu, Volodymyr Mnih, Koray Kavukcuoglu, Raia Hadsell: Policy Distillation. ICLR 2016.', ""This paper propose a variant of generative replay buffer/memory to overcome catastrophic forgetting. They use multiple copy of their model DGMN as short term memories and then consolidate their knowledge in a larger DGMN as a long term memory. \n\nThe main novelty of this work are 1-balancing mechanism for the replay memory. 2-Using multiple models for short and long term memory. The most interesting aspect of the paper is using a generate model as replay buffer which has been introduced before. As explained in more detail below, it is not clear if the novelties  introduced in this paper are important for the task or if they are they are tackling the core problem of catastrophic forgetting. \n\nThe paper claims using the task ID (either from Oracle or from a HMM) is an advantage of the model. It is not clear to me as why is the case, if anything it should be the opposite. Humans and animal are not given task ID and it's always clear distinction between task in real world.\n\nDeep Generative Replay section and description of DGDMN are written poorly and is very incomprehensible. It would have been more comprehensive if it was explained in more shorter sentences accompanied with proper definition of terms and an algorithm or diagram for the replay mechanism. \n\nUsing the STTM during testing means essentially (number of STTM) + 1 models are used which is not same as preventing one network from catastrophic forgetting.\n\nBaselines: why is Shin et al. (2017) not included as one of the baselines? As it is the closet method to this paper it is essential to be compared against.\n\nI disagree with the argument in section 4.2.  A good robust model against catastrophic forgetting would be a model that still can achieve close to SOTA.  Overfitting to the latest task is the central problem in catastrophic forgetting which this paper avoids it by limiting the model capacity.\n\n12 pages is very long, 8 pages was the suggested page limit. It’s understandable if the page limit is extend by one page, but 4 pages is over stretching. ""]","[50, -50, -50]","[60, 20, 0]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's well-justified approach and extensive testing, while also noting that the results are not very surprising. The reviewer provides balanced feedback, highlighting both strengths and limitations of the work. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or dismissive comments. The reviewer acknowledges the paper's contributions while suggesting areas for improvement, maintaining a professional and courteous tone. The use of phrases like 'It is interesting to see' and 'In my view' further contribute to the polite tone by presenting critiques as personal observations rather than absolute statements."", ""The sentiment score is -50 because the review starts positively by acknowledging the paper's contributions and interesting aspects, but then shifts to a more critical tone with phrases like 'Unfortunately, the paper does not go beyond...' and points out several limitations of the study. This indicates a moderately negative overall sentiment. The politeness score is 20 because the reviewer uses polite language throughout, even when criticizing. They start with positive comments and use phrases like 'I agree that...' when introducing critiques, which maintains a respectful tone. However, the criticism is direct and not overly softened, keeping the score only slightly positive rather than highly polite."", ""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper, such as poor explanations, questionable novelty, and disagreements with the authors' arguments. However, it's not entirely negative as it acknowledges some interesting aspects. The politeness score is 0 (neutral) because the reviewer uses direct language without being overtly polite or rude. They critique the work professionally, stating their concerns and disagreements without using harsh language or personal attacks, but also without using particularly polite phrasing.""]"
"[""The authors provide an improved implementation of the idea of dynamic evaluation, where the update of the parameters used in the last time step proposed in (Mikolov et al. 2010) is replaced with a back-propagation through the last few time steps, and uses  RMSprop rather than vanilla SGD. The method is applied to word level and character level language modeling where it yields some gains in perplexity. The algorithm also appears able to perform domain adaptation, in a setting where a character-level language model trained mostly on English manages to quickly adapt to a Spanish test set. \n\nWhile the general idea is not novel, the implementation choices matter, and the authors provide one which appears to work well with recently proposed models. The character level experiments on the multiplicative LSTM make the most convincing point, providing a significant improvement over already good results on medium size data sets. Figure 2 also makes a strong case for the method's suitability for applications where domain adaptation is important.\n\nThe paper's weakest part is the word level language modeling section. Given the small size of the data sets considered, the results provided are of limited use, especially since the development set is used to fit the RMSprop hyper-parameters. How sensitive are the final results to this choice? Comparing dynamic evaluation to neural cache models is a good idea, given how both depend en medium-term history: (Grave et al. 2017) provide results on the larger text8 and wiki103, it would be useful to see results for dynamic evaluation at least on the former.\n\nAn indication of the actual additional evaluation time for word-level, char-level and sparse char-level dynamic evaluation would also be welcome.\n\nPros:\n- Good new implementation of an existing idea\n- Significant perplexity gains on character level language modeling\n- Good at domain adaptation\n\nCons:\n- Memory requirements of the method\n- Word-level language modeling experiments need to be run on larger data sets\n\n(Edit: the authors did respond satisfactorily to the original concern about the size of the word-level data set)"", ""This paper takes AWD-LSTM, a recent, state of the art language model that was equipped with a Neural Cache, swaps the cache out for Dynamic Evaluation and improves the perplexities.\n\nDynamic Evaluation was the baseline that was most obviously missing from the original Neural Cache paper (Grave, 2016) and from the AWD-LSTM paper. In this sense, this work fills in a gap.\n\nLooking at the proposed update rule for Dynamic Evaluation though, the Global Prior seems to be an implementation of the Fast Weights idea. It would be great to explore that connection, or at least learn about how much the Global Prior helps.\n\nThe sparse update idea feels very much an afterthought and so do the experiments with Spanish.\n\nAll in all, this paper could be improved a lot but it is hard to argue with the strong results ...\n\nUpdate:  I'm happy with how the authors have addressed these and other comments in revision 2 of the paper and I've bumped the rating from 6 to 7.\n"", 'This paper proposes a dynamic evaluation of recurrent neural network language models by updating model parameters with certain segment lengths.\n\nPros.\n- Simple adaptation scheme seems to work, and the paper also shows (marginal) improvement from a conventional method (neural cache RNNLM) \nCons.\n- The paper is not well written due to undefined variables/indexes, confused explanations, not clear explanations of the proposed method in abstract and introduction (see the comments below)\n- Although the perplexity is an important measure, it’s better to show the effectiveness of the proposed method with more practical tasks including machine translation and speech recognition. \n\nComments:\n- Abstract: it is difficult to guess the characteristics of the proposed method only with a term “dynamic evaluation”. It’s better to explain it in more detail in the abstract.\n- Abstract: It’s better to provide relative performance (comparison) of the numbers (perplexity and bits/char) from conventional methods.\n- Section 2: Some variables are not explicitly introduced when they are appeared including i, n, g, and l\n- Section 3: same comment with the above for M. Also n is already used in Section 2 as a number of sequences.\n- Section 5. Why does the paper only provide examples for SGD and RMSprop? Can we apply it to other optimization methods including Adam and Adadelta?\n- Section 6, equation (9): is this new matrix introduced for every layer? Need some explanations.\n- Section 7.1: It’s better to provide the citation of Chainer.\n- Section 7.1 “AWD-LSTM”: The paper should provide the full name of AWD-LSTM when it is first appeared.\n\n']","[60, 50, -20]","[70, 70, 50]","[""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the paper's contributions and improvements, noting 'significant perplexity gains' and that it's 'good at domain adaptation'. However, they also point out some weaknesses, particularly in the word-level language modeling section. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, balancing praise with constructive criticism. They provide clear pros and cons, and their suggestions for improvement are framed as helpful recommendations rather than harsh criticisms. The tone remains professional and courteous throughout the review."", ""The sentiment score is 50 (slightly positive) because while the reviewer acknowledges the paper's strong results and its contribution to filling a gap in previous research, they also mention that 'this paper could be improved a lot.' The overall tone is constructive but with reservations. The update at the end indicates an improvement in the reviewer's opinion, bumping the rating from 6 to 7, which further supports a moderately positive sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. Phrases like 'it would be great to explore' and 'All in all' contribute to a polite tone. The reviewer also acknowledges the authors' efforts in addressing comments in the revision, which is a courteous gesture."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the paper, there are more cons listed and several critical comments. The reviewer points out that the paper is 'not well written' and suggests multiple areas for improvement, indicating an overall negative sentiment. However, it's not extremely negative as the reviewer does recognize some positive aspects.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use neutral language to express criticisms (e.g., 'It's better to...', 'The paper should...') rather than harsh or rude phrasing. The reviewer also balances criticism with positive observations ('Pros' section). However, the score is not extremely high as the review is direct and doesn't use overtly polite language or excessive praise.""]"
"['This paper proposes ResBinNet, with residual binarization, and temperature adjustment. It is a reconfigurable binarization method for neural networks. It improves the convergence rate during training. \n\nI appreciate a lot that the authors were able to validate their idea by building a prototype of an actual hardware accelerator.\n\nI am wondering what are the values of \\gamma’s in the residual binarization after learning? What is its advantage over having only one \\gamma, and then the rest are just 1/2*\\gamma, 1/4* \\gamma, … , etc.? The latter is an important baseline for residual binarization because that corresponds to the widely used fixed point format for real numbers. If you can show some results that residual encoding is better than having {\\gamma, 1/2*\\gamma, 1/4* \\gamma, …, } (which contains only one \\gamma), it would validate the need of using this relatively complex binarization scheme. Otherwise, we can just use the l-bit fixed point multiplications, which is off-the-shelf and already highly optimized in many hardwares. \n\nFor the temperature adjustment, modifying the tanh() scale has already had a long history, for example, http://yann.lecun.com/exdb/publis/pdf/lecun-89.pdf page 7, which is exactly the same form as in this paper. Adjusting the slope during training has also been explored in some straight-through estimator approaches, such as https://arxiv.org/pdf/1609.01704.pdf. In addition, having this residual binarization and adjustable tanh(), is already adding extra computations for training. Could you provide some data for comparing the computations before and after adding residual binarization and temperature adjustment? \n\nThe authors claimed that ResBinNet converges faster during training, and in table 2 it shows that ResBinNet just needs 1/10 of the training epochs needed by BinaryNet. However, I don’t find it very fair. Given that the accuracy RBN gets is much lower than Binary Net, the readers might suspect that maybe the other two models already reach ResBinNet’s accuracy at an earlier training epochs (like epoch 50), and just take all the remaining epochs to reach a higher accuracy. On the other hand, this comparison is not fair for ResBinNet as well. The model size was much larger in BinaryNet than in ResBinNet. So it makes sense to train a BinaryNet or FINN, in the same size, and then compare the training curves. Lastly, in CIFAR-10 1-level case, it didn’t outperform FINN, which has the same size. Given these experiments, I can’t draw any convincing conclusion.\n\nApart from that, There is an error in Figure 7 (b), where the baseline has an accuracy of 80.1% but its corresponding bar is lower than RBN1, which has an accuracy of 76%. ', '1. The idea of multi-level binarization is not new. The author may have a check at  Section ""Multiple binarizations"" in [a] and Section 3.1 in [b]. The author should also have a discussion on these works.\n\n2. For the second contribution, the authors claim ""Temperature Adjustment"" significantly improves the convergence speed. This argument is not well supported by the experiments.\n\nI prefer to see two plots: one for Binarynet and one for the proposed method. In these plot, testing accuracy v.s. the number of epoch (or time) should be shown. The total number of epochs in Table 2 does not tell anything.\n\n3. Confusing in Table 2. In ResBinNet, why 1-, 2- and 3- level have the same size? Should more bits required by using higher level?\n\n4. While the performance of the 1-bit system is not good, we can get very good results with 2 bits [a, c]. So, please also include [c] in the experimental comparison.\n\n5. The proposed method can be trained end-to-end. However, a comparison with [b], which is a post-processing method, is still needed (see Question 1). \n\n6. Could the authors also validate their proposed method on ImageNet? It is better to include GoogleNet and ResNet as well. \n\n7. Could the authors make tables and figures in the experiment section large? It is hard to read in current size.\n\nReference\n[a] How to Train a Compact Binary Neural Network with High Accuracy. AAAI 2017\n[b] Network Sketching: Exploiting Binary Structure in Deep CNNs. CVPR 2017\n[c] Trained Ternary Quantization. ICLR 2017', 'This paper proposes a method to quantize weights and activations in neural network during propagations.\n\nThe residual binarization idea is interesting. However, the experimental results are not sufficiently convincing that this method is meaningfully improving over previous methods. Specifically:\n\n1) In table 2, the 1-st level method is not performing better the FINN, while at the higher levels we pay with a much higher latency (about x2-x3 in figure 7) to get slightly better accuracy. \n\n2) Even at the highest level, the proposed method is not performing better than BinaryNet in terms of accuracy. The only gain in this comparison is the number of epochs needed for training. However, this is might be due to the size difference between the models, and not due to the proposed method. \n\n3) In a comment during the review period, the authors mention that ""For Imagenet, we can obtain a top-1 accuracy of 28.4%, 32.6%, and 33.6% for an Alexnet architecture with  1-3 levels of residual binarizations, while the Binarynet baseline achieves a top-1 accuracy of 27.9% with the same architecture."" However, this is not accurate, BinaryNet actually achieves 41.8% top-1 accuracy for Imagenet with Alexnet (e.g., see BNN on table 2 in Hubara et al.). \n\nMinor comment regarding novelty:\nThe temperature adjustment method sounds somewhat similar to previous method of increasing the slope described ""Adjustable Bounded Rectifiers: Towards Deep Binary Representations""']","[-20, -30, -50]","[60, 20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer appreciates some aspects of the paper (e.g., 'I appreciate a lot that the authors were able to validate their idea'), they raise several critical points and express skepticism about the paper's claims and methodology. The reviewer questions the advantages of the proposed method, points out potential issues with comparisons, and suggests that the conclusions are not convincing. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions (e.g., 'I am wondering...', 'Could you provide...'), and acknowledges positive aspects of the work. The reviewer maintains a professional tone even when pointing out errors or expressing doubts about the paper's claims."", ""The sentiment score is slightly negative (-30) because the reviewer points out several issues and requests significant additional work, such as including more comparisons, validating on ImageNet, and improving figures. However, it's not extremely negative as the reviewer provides constructive feedback and suggests ways to improve the paper. The politeness score is slightly positive (20) as the reviewer uses professional language and phrases requests politely (e.g., 'Could the authors...', 'I prefer to see...'). The reviewer also provides helpful references. The tone is generally constructive rather than harsh, though it lacks overtly polite language, keeping the score from being higher."", ""The sentiment score is -50 because the review is generally critical of the paper's results and contributions. The reviewer acknowledges the 'interesting' idea but expresses skepticism about the method's improvements over previous work. They point out several issues with the experimental results and accuracy claims. However, it's not entirely negative, as they do recognize some positive aspects, hence not a lower score. The politeness score is 20 because the language used is professional and constructive, avoiding harsh criticism. The reviewer uses phrases like 'not sufficiently convincing' and 'minor comment' which maintain a respectful tone. However, the review is direct in its criticisms without excessive softening language, so it's only slightly above neutral in politeness.""]"
"['This paper proposes a convnet-based neural network architecture for reading comprehension and demonstrates reasonably good performance on SQuAD and TriviaQA with a great speed-up.\n\nThe proposed architecture combines a few recent DL techniques: residual networks, dilated convolutions and gated linear units.\n\nI understand the motivation that ConvNet has a great advantage of easing parallelization and thus is worth exploring. However, I think the proposed architecture in this paper is less motivated. Why is GLU chosen? Why is dilation used? According to Table 4, dilation is really not worth that much and GLU seems to be significantly better than ReLU, but why?\n\nThe architecture search (Table 3 and Figure 4) seems to quite arbitrary. I  would like to see more careful architecture search and ablation studies. Also, why is Conv DrQA significantly worse than DrQA while Conv BiDAF can be comparable to BiDAF?\n\nI would like to see more explanations of Figure 4. How important is # of layers and residual connections?\n\nMinor:\n- It’d be helpful to add the formulation of gated linear units and residual layers. \n- It is necessary to put Table 5 in the main paper instead of Appendix. These are still the main results of the paper.', 'This paper borrows the idea from dilated CNN and proposes a dilated convolution based module for fast reading comprehension, in order to deal with the processing of very long documents in many reading comprehension tasks. The method part is clear and well-written. The results are fine when the idea is applied to the BiDAF model, but are not very well on the DrQA model.\n\n(1) My biggest concern is about the motivation of the paper: \n\nFirstly, another popular approach to speed up reading comprehension models is hierarchical (coarse-to-fine) processing of passages, where the first step processes sentences independently (which could be parallelized), then the second step makes predictions over the whole passage by taking the sentence processing results. Examples include , ""Attention-Based Convolutional Neural Network for Machine Comprehension"", ""A Parallel-Hierarchical Model for Machine Comprehension on Sparse Data"", and ""Coarse-to-fine question answering for long documents""\n\nThis paper does not compare to the above style of approach empirically, but the hierarchical approach seems to have more advantages and seems a more straightforward solution. \n\nSecondly, many existing works on multiple passage reading comprehension (or open-domain QA as often named in the papers) found that dealing with sentence-level passages could result in better (or on par) results compared with working on the whole documents. Examples include ""QUASAR: Datasets for question answering by search and reading"", ""SearchQA: A new q&a dataset augmented with context from a search engine"", and ""Reinforced Ranker-Reader for Open-Domain Question Answering"". If in many applications the sentence-level processing is already good enough, the motivation of doing speedup over LSTMs seems even waker.\n\nEven on the SQuAD data, the sentence-level processing seems sufficient: as discussed in this paper about Table 5, the author mentioned (at the end of Page 7) that ""the Conv DrQA model only encode every 33 tokens in the passage, which shows that such a small context is ENOUGH for most of the questions"".\n\nMoreover, the proposed method failed to give any performance boost, but resulted in a big performance drop on the better-performed DrQA system. Together with the above concerns, it makes me doubt the motivation of this work on reading comprehension.\n\nI would agree that the idea of using dilated CNN (w/ residual connections) instead of BiLSTM could be a good solution to many online NLP services like document-level classification tasks. Therefore, the motivation of the paper may make more sense if the proposed method is applied to a different NLP task.\n\n(2) A similar concern about the baselines: the paper did not compare with ANY previous work on speeding up RNNs, e.g. ""Training RNNs as Fast as CNNs"". The example work and its previous work also accelerated LSTM by several times without significant performance drop on some RC models (including DrQA).\n\n(3) About the speedup: it could be imaged that the speedup from the usage of dilated CNN largely depends on the model architecture. Considering that the DrQA is a better system on both SQuAD and TriviaQA, the speedup on DrQA is thus more important. However, the DrQA has less usage of LSTMs, and in order to cover a large reception field, the dilated CNN version of DrQA has a 2-4 times speedup, but still works much worse. This makes the speedup less impressive.\n\n(4) It seems that this paper was finished in a rush. The experimental results are not well explained and there is not enough analysis of the results.\n\n(5) I do not quite understand the reason for the big performance drop on DrQA. Could you please provide more explanations and intuitions?', 'The paper proposes a simple dilated convolutional network as drop-in replacements for recurrent networks in reading comprehension tasks. The first advantage of the proposed model is short response time due to parallelism of non-sequential output generation, proved by experiments on the SQuAD dataset. The second advantage is its potentially better representation, proved by better results compared to models using recurrent networks on the TriviaQA dataset.\n\nThe idea of using dilated convolutional networks as drop-in replacements for recurrent networks should have more value than just reading comprehension tasks. The paper should stress on this a bit more. The paper also lacks discussion with other models that use dilated convolution in different ways, such as WaveNet[1].\n\nIn general, the proposed model has novelty. The experimental results also sufficiently demonstrate the proposed advantages of the model. Therefore I recommend acceptance for it.\n\n[1] Oord, Aaron van den, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. ""Wavenet: A generative model for raw audio."" arXiv preprint arXiv:1609.03499 (2016).']","[-20, -60, 80]","[50, 20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('demonstrates reasonably good performance', 'great speed-up'), they express several concerns and criticisms about the paper's methodology and lack of explanations. The reviewer asks multiple questions indicating areas where they feel the paper is lacking, such as 'Why is GLU chosen?', 'Why is dilation used?', and requests more careful architecture search and ablation studies. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use polite language like 'I would like to see' and 'It'd be helpful to' when making suggestions, and frame their criticisms as questions or requests for more information rather than direct criticisms. The reviewer also acknowledges positive aspects of the work before diving into their concerns, which contributes to the overall polite tone."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's motivation, methodology, and results. They question the novelty and effectiveness of the approach compared to existing methods, and point out that the proposed method failed to improve performance on a key model. The politeness score is 20 because while the reviewer is critical, they use professional and respectful language throughout. They phrase concerns as questions or suggestions rather than harsh criticisms, and acknowledge potential merits of the work in other contexts. The reviewer also provides detailed explanations for their concerns, which is helpful and constructive."", ""The sentiment score is 80 (positive) because the reviewer recommends acceptance, praises the model's novelty, and acknowledges that the experimental results demonstrate the proposed advantages. The reviewer also offers constructive suggestions for improvement, indicating overall positive sentiment. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offers suggestions in a constructive manner, and maintains a professional tone. However, the review doesn't include overtly polite phrases or excessive praise, keeping it at a moderate level of politeness rather than extremely polite.""]"
"['This paper explores learning dynamic filters for CNNs. The filters are generated by using the features of an autoencoder on the input image, and linearly combining a set of base filters for each layer. This addresses an interesting problem which has been looked at a lot before, but with some small new parts. There is a lot of prior work in this area that should be cited in the area of dynamic filters and steerable filters. There are also parallels to ladder networks that should be highlighted. \n\nThe results indicate improvement over baselines, however baselines are not strong baselines. \nA key question is what happens when this method is combined with VGG11 which the authors train as a baseline? \nWhat is the effect of the reconstruction loss? Can it be removed? There should be some ablation study here.\nFigure 5 is unclear what is being displayed, there are no labels.\n\nOverall I would advise the authors to address these questions and suggest this as a paper suitable for a workshop submission.\n', 'The authors propose an approach to dynamically generating filters in a CNN based on the input image. The filters are generated as linear combinations of a basis set of filters, based on features extracted by an auto-encoder. The authors test the approach on recognition tasks on three datasets: MNIST, MTFL (facial landmarks) and CIFAR10, and show a small improvement over baselines without dynamic filters.\n\nPros:\n1) I have not seen this exact approach proposed before.\n2) There method is evaluated on three datasets and two tasks: classification and facial landmark detection.\n\nCons:\n1) The authors are not the first to propose dynamically generating filters, and they clearly mention that the work of De Brabandere et al. is closely related. Yet, there is no comparison to other methods for dynamic weight generation. \n2) Related to that, there is no ablation study, so it is unclear if the authors’ contributions are useful. I appreciate the analysis in Tables 1 and 2, but this is not sufficient. Why the need for the autoencoder - why can’t the whole network be trained end-to-end on the goal task? Why generate filters as linear combination - is this just for computational reasons, or also accuracy? This should be analyzed empirically.\n3) The experiments are somewhat substandard:\n- On MNIST the authors use a tiny poorly-performance network, and it is no surprise that one can beat it with a bigger dynamic filter network.\n- The MTFL experiments look most convincing (although this might be because I am not familiar with SoTA on the dataset), but still there is no control for the number of parameters, and the performance improvements are not huge\n- On CIFAR10 - there is a marginal improvement in performance, which, as the authors admit, can also be reached by using a deeper model. The baseline models are far from SoTA - the authors should look at more modern architecture such as AllCNN (not particularly new or good, but very simple), ResNet, wide ResNet, DenseNet, etc.\n\nAs a comment, I don’t think classification is a good task for showcasing such an architecture - classification is already working extremely well. Many other tasks - for instance, detection, tracking, few-shot learning - seem much more promising.\n\nTo conclude, the authors propose a new approach to learning convolutional networks with dynamic input-conditioned filters. Unfortunately, the authors fail to demonstrate the value of the proposed method. I therefore recommend rejection.', 'This paper proposes a two-pathway neural network architecture. One pathway is an autoencoder that extracts image features from different layers. The other pathway consists of convolutional layers to solve a supervised task. The kernels of these convolutional layers are generated dynamically based on the autoencoder features of the corresponding layers. Directly mapping the autoencoder features to the convolutional kernels requires a very large matrix multiplication. As a workaround, the proposed method learns a dictionary of base kernels and maps the features to the coefficients on the dictionary. \n\nThe proposed method is an interesting way of combining an unsupervised learning objective and a supervised one. \n\nWhile the idea is interesting, the experiments are a bit weak. \nFor MNIST (Table 1), only epoch 1 and epoch 20 results are reported. However, the results of a converged model (train for more epochs) are more meaningful. \nFor Cifar-10 (Figure 4b), the final accuracy is less than 90%, which is several percentages lower than the state-of-the-art method.\nFor MTFL, I am not sure how significant the final results are. It seems a more commonly used recent protocol is to train on MTFL and test on AFLW. \nIn general, the experiments are under controlled settings and are encouraging. However, promising results for comparing with the state-of-the-art methods are necessary for showing the practical importance of the proposed method. \n\nA minor point: it is a bit unnatural to call the proposed method “baseline” ...  \n\nIf the model is trained in an end-to-end manner. It will be helpful to perform ablative studies on how critical the reconstruction loss is (Note that the two pathway can be possibly trained using a single supervised objective function).  \n\nIt will be interesting to see if the proposed model is useful for semi-supervised learning. \n\nA paper that may be related regarding dynamic filters:\nImage Question Answering using Convolutional Neural Network with Dynamic Parameter Prediction\n\nSome paper that may be related regarding combine supervised and unsupervised learning:\nStacked What-Where Auto-encoders\nSemi-Supervised Learning with Ladder Networks\nAugmenting Supervised Neural Networks with Unsupervised Objectives for Large-Scale Image Classification\n\n']","[-20, -70, 20]","[50, 20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper addresses an interesting problem, they point out several shortcomings and suggest it's only suitable for a workshop submission. The reviewer notes weak baselines, missing comparisons, lack of ablation studies, and unclear figures. However, they do recognize some positive aspects, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses professional and constructive language throughout. They offer specific suggestions for improvement and frame criticisms as questions or areas for further exploration, rather than harsh judgments. The tone is generally respectful and aimed at helping the authors improve their work, though not overly effusive or deferential."", ""The sentiment score is -70 because the review is predominantly negative. While the reviewer acknowledges some pros, they list more cons and ultimately recommend rejection. The conclusion clearly states that the authors 'fail to demonstrate the value of the proposed method.' The politeness score is 20 because the reviewer uses professional language and acknowledges some positive aspects, but doesn't use overly polite phrasing. They provide constructive criticism and explain their reasoning, which maintains a level of respect, but the overall tone is direct and critical rather than overtly polite."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the proposed method as 'interesting' and the results as 'encouraging'. However, they also point out several weaknesses in the experiments, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and suggests improvements and related works. They avoid harsh criticism and frame their concerns as opportunities for improvement rather than outright flaws. The reviewer maintains a professional and helpful tone, which contributes to the politeness score.""]"
"['This paper proposes a label embedding network method that learns label embeddings during the training process of deep networks. \nPros: Good empirical results.\nCons:  There is not much technical contribution. The proposed approach is neither well motivated, nor well presented/justified.  The presentation of the paper needs to be improved. \n\n1. Part of the motivation on page 1 does not make sense. In particular, for paragraph 3, if the classification task is just to separate A from B, then (1,0) separation should be better than (0.8, 0.2). \n\n2. Label embedding learning has been investigated in many previous works. The authors however ignored all the existing works on this topic, but enforce label embedding vectors as similarities between labels in Section 2.1 without clear motivation and justification. This assumption is not very natural — though label embeddings can capture semantic information and label correlations, it is unnecessary that label embedding matrix should be m xm and each entry should represent the similarity between a pair of labels.  The paper needs to provide a clear rationale/justification for the assumptions made, while clarifying the difference (and reason) from the literature works. \n\n3. The proposed model is not well explained.  \n(1) By using the objective in eq.(14), how to learn the embeddings E? \n(2) The authors state “In back propagation, the gradient from z2 is kept from propagating to h”.  This makes the learning process quite arbitrary under the objective in eq.(14). \n(3) The label embeddings are not directly used for the classification (H(y, z’_1)), but rather as auxiliary part of the objective.  How to decide the test labels?\n', 'The paper proposes a method which jointly learns the label embedding (in the form of class similarity) and a classification model. While the motivation of the paper makes sense, the model is not properly justified, and I learned very little after reading the paper.\n\nThere are 5 terms in the proposed objective function. There are also several other parameters associated with them: for example, the label temperature of z_2’’ and and parameter alpha in the second last term etc.\n\nFor all the experiments, the same set of parameters are used, and it is claimed that “the method is robust in our experiment and simply works without fine tuning”. While I agree that a robust and fine-tuning-free model is ideal 1) this has to be justified by experiment. 2) showing the experiment with different parameters will help us understand the role each component plays. This is perhaps more important than improving the baseline method by a few point, especially given that the goal of this work is not to beat the state-of-the-art.', 'The paper proposes to add an embedding layer for labels that constrains normal classifiers in order to find label representations that are semantically consistent. The approach is then experimented on various image and text tasks.\n\nThe description of the model is laborious and hard to follow. Figure 1 helps but is only referred to at the end of the description (at the end of section 2.1), which instead explains each step without the big picture and loses the reader with confusing notation. For instance, it only became clear at the end of the section that E was learned.\n\nOne of the motivations behing the model is to force label representations to be in a semantic space (where two labels with similar meanings would be nearby). The assumption given in the introduction is that softmax would not yield such a representation, but nowhere in the paper this assumption is verified. I believe that using cross-entropy with softmax should also push semantically similar labels to be nearby in the weight space entering the softmax. This should at least be verified and compared appropriately.\n\nAnother motivation of the paper is that targets are given as 1s or 0s while soft targets should work better. I believe this is true, but there is a lot of prior work on these, such as adding a temperature to the softmax, or using distillation, etc. None of these are discussed appropriately in the paper.\n\nSection 2.2 describes a way to compress the label embedding representation, but it is not clear if this is actually used in the experiments. h is never discussed after section 2.2.\n\nExperiments on known datasets are interesting, but none of the results are competitive with current state-of-the-art results (SOTA), despite what is said in Appending D. For instance, one can find SOTA results for CIFAR100 around 16% and for CIFAR10 around 3%. Similarly, one can find SOTA results for IWSLT2015 around 28 BLEU. It can be fine to not be SOTA as long as it is acknowledged and discussed appropriately.\n']","[-60, -60, -50]","[-20, 20, 20]","[""The sentiment score is -60 because the review is predominantly negative. While it acknowledges 'good empirical results' as a pro, it lists several significant cons, including lack of technical contribution, poor motivation, and inadequate presentation. The reviewer also provides multiple critical points for improvement, indicating dissatisfaction with the current state of the paper. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without much attempt to soften the feedback. The reviewer uses phrases like 'does not make sense' and 'not well explained' which, while not impolite, lack the diplomatic phrasing often found in more polite reviews. The review also doesn't include any encouragement or positive reinforcement, which contributes to its slightly impolite tone."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper. They state that they 'learned very little after reading the paper' and that the model is 'not properly justified'. The reviewer also points out several issues with the methodology and lack of experimental justification. However, it's not entirely negative as they acknowledge that the motivation 'makes sense'. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and constructive manner. They use neutral language like 'While I agree...' and offer specific suggestions for improvement rather than harsh criticism. The tone is direct but not rude, maintaining a respectful academic discourse."", ""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper such as unclear descriptions, unverified assumptions, and lack of comparison with state-of-the-art results. However, it's not entirely negative as it acknowledges some interesting aspects of the experiments. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and offer constructive feedback. They use phrases like 'I believe' and 'it can be fine' which soften the critique. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism.""]"
"['The author present a language for expressing hyperparameters (HP) of a network. This language allows to define a tree structure search space to cover the case where some HP variable exists only if some previous HP variable took some specific value. Using this tool, they explore the depth of the network, when to apply batch-normalization, when to apply dropout and some optimization variables. They compare the search performance of random search, monte carlo tree search and a basic implementation of a Sequential Model Based Search. \n\nThe novelty in this paper is below what is expected for a publication at ICLR. I recommend rejection.', 'Monte-Carlo Tree Search is a reasonable and promising approach to hyperparameter optimization or algorithm configuration in search spaces that involve conditional structure.\n\nThis paper must acknowledge more explicitly that it is not the first to take a graph-search approach. The cited work related to SMAC and Hyperopt / TPE addresses this problem similarly. The technique of separating a description language from the optimization algorithm is also used in both of these projects / lines of research. The [mis-cited] paper titled “Making a science of model search …” is about using TPE to configure 1, 2, and 3 layer convnets for several datasets, including CIFAR-10. SMAC and Hyperopt have been used to search large search spaces involving pre-processing and classification algorithms (e.g. auto-sklearn, autoweka, hyperopt-sklearn). There have been near-annual workshops on AutoML and Bayesian optimization at NIPS and ICML (see e.g. automl.org).\n\nThere is a benchmark suite of hyperparameter optimization problems that would be a better way to evaluate MCTS as a hyperparameter optimization algorithm: http://www.ml4aad.org/automl/hpolib/', 'This paper introduces a DeepArchitect framework to build and train deep models automatically. Specifically, the authors proposes three components, i.e., model search specification language, model search algorithm, model evaluation algorithm. The paper is written well, and the proposed framework provides us with a systematical way to design deep models.\n\nHowever, my concern is mainly about its importance in practice. The experiments and computational modules are basic and small-scale, i.e., it may be restricted for large-scale computer vision problems. \n']","[-80, -20, 20]","[-20, 50, 60]","[""The sentiment score is -80 because the reviewer explicitly recommends rejection and states that the paper's novelty is 'below what is expected for a publication at ICLR'. This indicates a strongly negative sentiment towards the paper. The politeness score is -20 because while the reviewer provides a brief summary of the paper's content, the language used is direct and somewhat blunt, particularly in the final sentence. The reviewer doesn't use any softening language or positive remarks to balance the criticism, which makes the tone slightly impolite, though not overtly rude."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the approach is 'reasonable and promising', they also point out significant shortcomings in the paper, particularly regarding the lack of acknowledgment of prior work and the need for better evaluation methods. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'must acknowledge more explicitly' and suggest better evaluation methods, which is helpful and polite. The reviewer maintains a professional tone, focusing on the content rather than making personal criticisms."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's good writing and the systematic approach of the proposed framework. However, the reviewer expresses concerns about the practical importance and scale of the experiments, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language, acknowledges the paper's strengths, and expresses concerns in a constructive manner without harsh criticism. The reviewer uses phrases like 'The paper is written well' and 'provides us with a systematical way', which contribute to the polite tone. The concerns are presented as 'my concern' rather than direct criticism, maintaining a courteous approach.""]"
"['The main contributions in this paper are:\n1) New variants of a recent LSTM-based model (""ESIM"") are applied to the task of response-selection in dialogue modeling -- ESIM was originally introduced and evaluated for natural language inference. In this new setting, the ESIM model (vanilla and extended) outperform previous models when trained and evaluated on two distinct conversational datasets.\n\n2) A fairly trivial method is proposed to extend the coverage of pre-trained word embeddings to deal with the OOV problem that arises when applying them to these conversational datasets.\nThe method itself is to combine d1-dimensional word embeddings that were pretrained on a large unannotated corpus (vocabulary S) with distinct d2-dimensional word embeddings that are trained on the task-specific training data (vocabulary T). The enhanced (d1+d2)-dimensional representation for a word is constructed by concatenating its vectors from the two embeddings, setting either the d1- or d2-dimensional subvector to zeros when the word is absent from either S or T, respectively. This method is incorporated as an extension into ESIM and evaluated on the two conversation datasets.\n\nThe main results can be characterized as showing that this vocabulary extension method leads to performance gains on two datasets, on top of an ESIM-model extended with character-based word embeddings, which itself outperforms the vanilla ESIM model.\n\nThese empirical results are potentially meaningful and could justify reporting, but the paper\'s organization is very confusing, and too many details are too unclear, leading to low confidence in reproducibility. \n\nThere is basic novelty in applying the base model to a new task, and the analysis of the role of the special conversational boundary tokens is interesting and can help to inform future modeling choices. The embedding-enhancing method has low originality but is effective on this particular combination of model architecture, task and datasets. I am left wondering how well it might generalize to other models or tasks, since the problem it addresses shows up in many other places too...\n\nOverall, the presentation switches back and forth between the Douban corpus and the Ubuntu corpus, and between word2vec and Glove embeddings, and this makes it very challenging to understand the details fully.\n\nS3.1 - Word representation layer: This paragraph should probably mention that the character-composed embeddings are newly introduced here, and were not part of the original formulation of ESIM. That statement is currently hidden in the figure caption.\n\nAlgorithm 1:\n- What set does P denote, and what is the set-theoretic relation between P and T?\n- Under one possible interpretation, there may be items in P that are in neither T nor S, yet the algorithm does not define embeddings for those items even though its output is described as ""a dictionary with word embeddings ... for P"". This does not seem consistent? I think the sentence in S4.2 about initializing remaining OOV words as zeros is relevant and wonder if it should form part of the algorithm description?\n\nS4.1 - What do the authors mean by the statement that response candidates for the Douban corpus were ""collected by Lucene retrieval model""?\n\nS4.2 - Paragraph two is very unclear. In particular, I don\'t understand the role of the Glove vectors here when Algorithm 1 is used, since the authors refer to word2vec vectors later in this paragraph and also in the Algorithm description.\n\nS4.3 - It\'s insufficiently clear what the model definitions are for the Douban corpus. Is there still a character-based LSTM involved, or does FastText make it unnecessary?\n\nS4.3 - ""It can be seen from table 3 that the original ESIM did not perform well without character embedding."" This is a curious way to describe the result, when, in fact, the ESIM model in table 3 already outperforms all the previous models listed.\n\nS4.4 - gensim package -- for the benefit of readers unfamiliar with gensim, the text should ideally state explicitly that it is used to create the *word2vec* embeddings, instead of the ambiguous ""word embeddings"".\n\n', ""Summary:\nThis paper proposes an approach to improve the out-of-vocabulary embedding prediction for the task of modeling dialogue conversations. The proposed approach uses generic embeddings and combines them with the embeddings trained on the training dataset in a straightforward string-matching algorithm. In addition, the paper also makes a couple of improvements to Chen et. al's enhanced LSTM by adding character-level embeddings and replacing average pooling by LSTM last state summary vector. The results are shown on the standard Ubuntu dialogue dataset as well as a new Douban conversation dataset. The proposed approach gives sizable gains over the baselines.\n\n\nComments:\n\nThe paper is well written and puts itself nicely in context of previous work. Though, the proposed extension to handle out-of-vocabulary items is a simple and straightforward string matching algorithm, but nonetheless it gives noticeable increase in empirical performance on both the tasks. All in all, the methodological novelty of the paper is small but it has high practical relevance in terms of giving improved accuracy on an important task of dialogue conversation."", ""The paper considers a setting (Ubuntu Dialogue Corpus and Douban Conversation Corpus) where most word types in the data are not covered by pretrained representations. The proposed solution is to combine (1) external pretrained word embeddings and (2) pretrained word embeddings on the training data by keeping them as two views: use the view if it's available, otherwise use a zero vector. This scheme is shown to perform well compared to other methods, specifically combinations of pretraining vs not pretraining embeddings on the training data, updating vs not updating embeddings during training, and others. \n\nQuality: Low. The research is not very well modularized: the addressed problem has nothing specifically to do with ESIM and dialogue response classification, but it's all tangled up. The proposed solution is reasonable but rather minor. Given that the model will learn task-specific word representations on the training set anyway, it's not clear how important it is to follow this procedure, though minor improvement is reported (Table 5). \n\nClarity: The writing is clear. But the point of the paper is not immediately obvious because of its failure to modularize its contributions (see above).\n\nOriginality: Low to minor.\n\nSignificance: It's not convincing that an incremental improvement in the pretraining phase is so significant, for instance compared to developing a novel better architecture actually tailored to the dialogue task. ""]","[-20, 70, -60]","[50, 80, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some potential value in the paper's contributions, they express significant concerns about the paper's organization, clarity, and reproducibility. Phrases like 'very confusing', 'too many details are too unclear', and 'low confidence in reproducibility' indicate a negative sentiment. However, the reviewer also notes some positive aspects, such as 'potentially meaningful' results and 'basic novelty', which prevents the score from being more negative. The politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and explain their concerns in detail without using harsh or dismissive language. The reviewer also acknowledges the potential value of the work, which contributes to the polite tone. However, the critique is direct and doesn't use overtly polite language, which is why the score is not higher."", ""The sentiment score is 70 (positive) because the reviewer praises the paper as 'well written' and notes that it gives 'sizable gains over the baselines' and has 'high practical relevance'. However, it's not extremely positive as the reviewer mentions the 'methodological novelty of the paper is small'. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and contextualizing its contributions positively. The reviewer offers constructive feedback without harsh criticism, maintaining a professional and courteous tone."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer describes the quality as 'Low', originality as 'Low to minor', and significance as unconvincing. They criticize the paper for not being well modularized and for presenting a solution that is 'reasonable but rather minor'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone and provide clear explanations for their criticisms. They also acknowledge some positive aspects, such as the clarity of writing and the minor improvement reported. The language used is not rude, but rather matter-of-fact and constructive, albeit with a negative overall assessment.""]"
"['Summary: This work is a variant of previous work (Zaremba et al. 2016) that enables the use of (noisy) operators that invoke pre-trained neural networks and is trained with Actor-Critic. In this regard it lacks a bit of originality. The quality of the experimental evaluation is not great. The clarity of the paper could be improved upon but is otherwise fine. The existence of previous work (Zaremba et al. 2016) renders this work (including its contributions) not very significant. Relations to prior work are missing. But let\'s wait for the rebuttal phase. \n\nPros \n-It is confirmed that noisy operators (in the form of neural networks) can be used on the visual arithmetic task\n\nCons\n-Not very novel\n-Experimental evaluation is wanting\n\nThe focus of this paper is on integrating perception and reasoning in a single system. This is done by specifying an interface that consists of a set of discrete operations (some of which involve perception) and memory slots. A parameterized policy that can make use of these these operations is trained via Actor-Critic to solve some reasoning tasks (arithmetics in this case). \n\nThe proposed system is a variant of previous work (Zaremba et al. 2016) on the concept of interfaces, and similarly learns a policy that utilizes such an interface to perform reasoning tasks, such as arithmetics. In fact, the only innovation proposed in this paper is to incorporate some actions that invoke a pre-trained neural network to “read” the symbol from an image, as opposed to parsing the symbol directly. However, there is no reason to expect that this would not function in previous work (Zaremba et al. 2016), even when the network is suboptimal (in which case the operator becomes noisy and the policy should adapt accordingly). Another notable difference is that the proposed system is trained with Actor-Critic as opposed to Q-learning, but this is not further elaborated on by the authors. \n\nThe proposed system is evaluated on a visual arithmetics task. The input consists of a 2x2 grid of extended MNIST characters. Each location in the grid then corresponds to the 28 x 28 pixel representation of the digit. Actions include shifting the “fovea” to a different entry of the grid, invoking the digit NN or the operator NN which parse the current grid entry, and some symbolic operations that operate on the memory. The fact that the input is divided into a 2x2 grid severely limits the novelty of this approach compared to previous work (Zaremba et al. 2016). Instead it would have been interesting to randomly spawn digits and operators in a 56 x 56 image and maintain 4 coordinates that specify a variable-sized grid that glimpses a part of the image. This would make the task severely more difficult, given fixed pre-trained networks. The addition of the salience network is unclear to me in the context of MNIST digits, since any pixel that is greater than 0 is salient? I presume that the LSTM uses this operator to evaluate whether the current entry contains a digit or an operator. If so, wouldn’t simply returning the glimpse be enough?\n\nIn the experiments the proposed system is compared to three CNNs on two different visual arithmetic tasks, one that includes operators as part of the input and one that incorporates operators only in the tasks description. In all cases the proposed method requires fewer samples to achieve the final performance, although given enough samples all of the CNNs will solve the tasks. This is not surprising as this comparison is rather unfair. The proposed system incorporates pre-trained modules, whose training samples are not taken into account. On the other hand the CNNs are trained from scratch and do not start with the capability to recognize digits or operators. Combined with the observation that all CNNs are able to solve the task eventually, there is little insight in the method\'s performance that can be gained from this comparison. \n\nAlthough the visual arithmetics on a 2x2 grid is a toy task it would at least be nice to evaluate some of the policies that are learned by the LSTM (as done by Zaremba) to see if some intuition can be recovered from there. Proper evaluation on a more complex environment (or at least on that does not assume discrete grids) is much desired. When increasing the complexity (even if by just increasing the grid size) it would be good to compare to a recurrent method (Pyramid-LSTM, Pixel-RNN) as opposed to a standard CNN as it lacks memory capabilities and is clearly at a disadvantage compared to the LSTM.\n\nSome detailed comments are:\n\nThe introduction invokes evidence from neuroscience to argue that the brain is composed of (discrete) modules, without reviewing any of the counter evidence (there may be a lot, given how bold this claim is).\n\nFrom the introduction it is unclear why the visual arithmetic task is important.\n\nSeveral statements including the first sentence lack citations.\n\nThe contribution section is not giving any credit to Zaremba et al. (2016) whereas this work is at best a variant of that approach.\n\nIn the experiment section the role of the saliency detector is unclear.\n\nExperiment details are lacking and should be included.\n\nThe related work section could be more focused on the actual contribution being made.\n\nIt strikes me as odd that in the discussion the authors propose to make the entire system differentiable, since this goes against the motivation for this work.\n\n\nRelation to prior work:\n\np 1: The authors write: ""We also borrow the notion of an interface as proposed in Zaremba et al. (2016). An interface is a designed, task-specific machine that mediates the learning agent’s interaction with the external world, providing the agent with a representation (observation and action spaces) which is intended to be more conducive to learning than the raw representations. In this work we formalize an interface as a separate POMDP I with its own state, observation and action spaces."" \n\nThis interface terminology for POMDPs was actually introduced in:\n\nJ.  Schmidhuber. Reinforcement learning in Markovian and non-Markovian environments. In D. S. Lippman, J. E. Moody, and D. S. Touretzky, editors, Advances in Neural Information Processing Systems 3, NIPS\'3, pages 500-506. San Mateo, CA: Morgan Kaufmann, 1991.\n\np 4: authors write: ""For the policy πθ, we employ a Long Short-Term Memory (LSTM)"" \n\nDo the authors use the (cited) original LSTM of 1997, or do they also use the forget gates (recurrent units with gates) that most people are using now, often called the vanilla LSTM, by Gers et al (2000)?\n\np 4: authors write: ""One obvious point of comparison to the current work is recent research on deep neural networks designed to learn to carry out algorithms on sequences of discrete symbols. Some of these frameworks, including the Differen-tiable Forth Interpreter (Riedel and Rocktäschel, 2016) and TerpreT (Gaunt et al., 2016b), achieve this by explicitly generating code, while others, including the Neural Turing Machine (NTM; Graves et al., 2014), Neural Random-Access Machine (NRAM; Kurach et al., 2015), Neural Programmer (NP; Neelakan- tan et al., 2015), Neural Programmer-Interpreter (NPI; Reed and De Freitas, 2015) and work in Zaremba et al. (2016) on learning algorithms using reinforcement learning, avoid gen- erating code and generally consist of a controller network that learns to perform actions in a (sometimes differentiable) external computational medium in order to carry out an algorithm.""\n\nHere the original work should be mentioned, on differentiable neural stack machines: \n\nG.Z. Sun and H.H. Chen and  C.L. Giles and Y.C. Lee and D. Chen. Connectionist Pushdown Automata that Learn Context-Free Grammars. IJCNN-90, Lawrence Erlbaum, Hillsdale, N.J., p 577, 1990.\n\nMozer, Michael C and Das, Sreerupa. A connectionist symbol manipulator that discovers the structure of context-free languages. Advances in Neural Information Processing Systems (NIPS), p 863-863, 1993.\n\n\n', 'The paper presents an interesting model to reuse specialized models trained for perceptual tasks in order to solve more complex reasoning tasks. The proposed model is based on reinforcement learning with an agent that interacts with an environment C, which is the combination of E and I, the external world and the interface, respectively. This abstraction is nicely motivated and contextualized with respect to previous work.\n\nHowever, the paper evaluates the proposed model in artificial tasks with limited reasoning difficulty: the tasks can be solved with simpler baseline models. The paper argues that the advantage of the proposed approach is data efficiency, which seems to be a side effect of having pre-trained modules rather than a clear superior reasoning capability. The paper discusses other advantages of the model, but these are not tested or evaluated either. A more convincing experimental setup would include complex reasoning tasks, and the evaluation of all the aspects mentioned as benefits: computational time, flexibility of computation, better accuracy, etc.', 'Summary: The authors use RL to learn a visual arithmetic task, and are able to do this with a relatively small number of examples, presumably not including the number of examples that were used to pre-train the classifiers that pre-process the images. This appears to be a very straightforward application of existing techniques and networks.\n\nQuality: Given the task that the authors are trying to solve, the approach seems reasonable.\nClarity: The paper appears quite clearly written for the most part.\nOriginality & Significance: Unless I am missing something important, or misunderstanding something, I do not really understand what is significant about this work, and I don\'t see it as having originality.\n\nNitpick 1: top of Page 5, it says ""Figure ??"" \nNitpick 2: Section 2.3 says ""M means take the product, A means take the sum, etc"". Why choose exactly those terms that obscure the pattern, and then write ""etc""? In Figure 1, ""X"" could mean multiply, or take the maximum, but by elimination, it means take the maximum. It would have only added a few characters to the paper to specify the notation here, e.g. ""Addition(A), Max (X), Min (N), Multiply (M)"". If the authors insist on making the reader figure this out by deduction, I recommend they just write ""We leave the symbols-operation mapping as a small puzzle for the reader.""\n\nThe authors might find the paper ""Visual Learning of Arithmetic Operations” by  Yedid Goshen and Shmuel Peleg to also be somewhat relevant, although it\'s different from what they are doing.\n\nSection 3. The story from the figures seems to be that the authors\' system works beats a CNN when there are very few examples. But significance of this is not really discussed in any depth other than being mentioned in corresponding places in the text, i.e. it\'s not really the focal story of the text. \n\nPros: Seems to work OK. Seems like a reasonable application of pre-trained nets to allow solving a different visual problem for which less data might be available.\n\nCons: Unless I am missing an important point, the results are unsurprising, and I am not clear what is novel or significant about them.']","[-60, -20, -50]","[20, 60, 20]","[""The sentiment score is -60 because the review is generally negative, highlighting a lack of originality, poor experimental evaluation, and limited significance. The reviewer uses phrases like 'lacks a bit of originality', 'quality of the experimental evaluation is not great', and 'not very significant'. However, it's not entirely negative as it acknowledges some pros and suggests waiting for the rebuttal phase. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use neutral language like 'could be improved upon' and 'is wanting' rather than harsh criticism. The reviewer also balances negative points with positive ones and provides detailed, constructive feedback, which is a polite approach in academic reviewing."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting' and praises the model's abstraction as 'nicely motivated', they express significant concerns about the evaluation and experimental setup. The reviewer states that the tasks used are of 'limited reasoning difficulty' and can be solved with 'simpler baseline models', suggesting that the paper's claims are not sufficiently supported. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects before presenting criticisms, and offering constructive suggestions for improvement. The reviewer avoids harsh or dismissive language, instead using phrases like 'However' and 'A more convincing experimental setup would include' to soften their critiques."", ""The sentiment score is -50 because the reviewer expresses skepticism about the significance and originality of the work. They state 'I do not really understand what is significant about this work, and I don't see it as having originality.' and 'Unless I am missing an important point, the results are unsurprising, and I am not clear what is novel or significant about them.' However, they do acknowledge some positive aspects like 'Seems to work OK' and 'Seems like a reasonable application', which prevents the score from being more negative. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'Unless I am missing something important' and 'The authors might find...', which show consideration. They also offer constructive suggestions and acknowledge the paper's clarity. The slightly positive score reflects this professional courtesy despite the critical content.""]"
"['The paper claims that ""Deep Learning (DL) has not been able to explicitly represent and enforce grammatical structures"", which is false, see ""Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks"", ""Ask Me Anything: Dynamic Memory Networks for Natural Language Processing"", ""DRAGNN: A Transition-based Framework for Dynamically Connected Neural Networks"" or ""Deep Compositional Question Answering with Neural Module Networks"".\n\nThe Introduction triple challenge is confusing, not clear what are the challenges this paper tries to address.\n\n""The representation learned in a crucial layer of the TPGN can be interpreted as encoding grammatical roles"" Doesn\'t refer to any specific kind of layer, or what it make it special.\n\nThe idea of using outer product as a layer has already been explored in ""Multimodal compact bilinear pooling for visual question answering and visual grounding""\n\nThe following paragraph in page 2 is not clear, very confusing:\nThe work reported here .... their categories\n\n\nIn page 3 authors claim that the ""vectors are linearly independent"" but didn\'t specify how they enforce that.\n\nFigure 3 contradicts Figure 1, not clear what are the inputs for module S.\n\nThe experiments reported in Table1 are useless, there a tons of previous work with much better results, see \nhttps://competitions.codalab.org/competitions/3221#results\n\nEven the numbers reported for Vinyals et al. (2015) are much higher in the leaderboard. \n\nThere is no comparison with other models that use attention or analysis of the impact of the increased number of parameters of the method proposed. \n\nThe experiments about POS tagger and Phrase Classifier are reported on 5000 from the COCO test set, which is useful for comparisons. Should report numbers on PennTreeBank or other common POS dataset.\n\nThe text is missing a lot of references, for example:\n - page 2 GSC\n - page 2 The first approach takes the detected by a CNN ....\n - page 3 previous work where TPRs are hand-crafted', 'I have a huge amount of sympathy for this work, and was really hoping to read a well-presented paper setting out how to cleanly integrate Smolensky\'s theory with deep learning, ideally (but not necessarily) with some decent empirical results. If that had been the case, I would certainly have been recommending acceptance, since ICLR would benefit from the alternative perspective that Smolensky\'s work provides, compared to the majority of work in Deep Learning. The empirical results are decent, but the presentation requires too much work to warrant acceptance at ICLR for this year. There are also some questionable decisions made regarding the NLP evaluations.\n\nMore detailed comments.\n\no Just call the pos tagging task ""POS tagging"". Talking about classification of the part of speech of *a* word makes it sound like you\'re tagging a single word in isolation.\n\no The statement that language structures can\'t be integrated with DL is a hopeless misrepresentation of current practice in NLP, and misses a large body of existing work. There\'s obviously Richard Socher\'s work on integrating DL and the output of eg the Stanford parser, but also a current raft of work on trying to induce tree structures automatically via a DL framework and task-based objective. Two examples, by no means exhaustive:\n\nLearning to Compose Words into Sentences with Reinforcement Learning\nDani Yogatama, Phil Blunsom, Chris Dyer, Edward Grefenstette, Wang Ling.\nICLR 2017.\n\nJointly Learning Sentence Embeddings and Syntax with Unsupervised Tree-LSTMs\nJean Maillard, Stephen Clark, Dani Yogatama.\n\no It\'s not at all clear to me what the third task is - something like chunking. Identification of the phrase structure sounds like parsing, but you\'re not doing full parsing. This needs explaining fully. There are various standard NLP tasks related to identifying phrase structure - I would just do one of those, using one of the standard datasets, then there won\'t be any confusion.\n\no The description of tagging on p.2 mentions MEMMs too much - these were superseded by CRFs, which I think is what you mean to refer to.\n\no The reference to a maximum entropy language model is a little odd, since as far as I know these never became mainstream (assuming you mean Rosenfeld\'s whole sentence maxent language models).\n\no N is terrible name for a system!\n\no Not sure about the 5-role schema example on p.4, since presumably these would still be generated one word at a time? So in what sense is the model encoding a schema?\n\no Section 5 is the key section in the paper. Unfortunately I found it hard to follow. I guess the LSTM equations are needed for completeness, but what I really needed was a clear paragraph explaining how the LSTM is used to build the vectors and matrices used by the binding/unbinding network.\n\no There are various oddities in the POS tagging experiments. Why use the Stanford tagger? Are you using this to get the train/test data? Just use the Penn Treebank, or another standard pos tag dataset.\n\no Why precision and recall for tagging? Doesn\'t each word get assigned a single tag? In which case we just need accuracy.\n\no There are a number of minor comments I could have made re. the presentation, eg funny refs with both names (Chen and Laurence Zitnick). ', '**Strengths**\nThe approach to sentence generation makes a lot of sense -- and provides a potentially elegant manner to incorporate or provide the model with the inductive bias that language has syntax and semantics, by leveraging a classical idea called Tensor Product Representation and showing how to adapt it to modern deep learning architectures and “learn” syntax and semantics end to end. Results on image captioning models indicate that the proposed approach might be promising. As a by-product, the paper also evaluates the model on POS tagging and shows that one can do fairly well using the representations learned in the TPGN. \n\n**Weakness**\nMy main concerns are the lack of appropriate baselines to establish concretely the contribution of the TPGN. It would be good to address issues under “Baselines” below.\n\nApproach:\n1. It would be nice to explain clearly why the pretraining of the TPGN with the LSTM input is needed. Is the idea that one would want to feed the representation of the entire representation as input in order to infer what “S_n” should be? Why is it then justified to feed in the image input instead? Also, in the second stage, the image features need not correspond to the LSTM feature dimensions, which means that the pretraining seems unprincipled. A better solution would have been to learn a joint embedding of image captions and labels (say via. ranking), and then use the embedding for the caption as input to the TPGN. This would ensure that when we use images, the model sees input that is appropriately “aligned”. A discussion why this is not needed or implementing this seems important.\n\nMinor Points:\n1.  “There are mainly two approaches to natural language generation in image captioning. The first approach takes the words detected by a CNN as input, and uses a probabilistic model, such as a maximum entropy (ME) language model, to arrange the detected words into a sentence.” -- can cite Fang. et.al [A]\n\nBaselines:\n1. The arXiv version and the PAMI version of the Neural Image Captioning paper (Vinyals, 2015) does report numbers on METEOR and CIDEr metrics, so they should be used to populate Table. 1 for completeness. Also, it would be good to clarify which split of MSCOCO Table. 1 reports results on -- is it the 40K large validation split or the 5K validation/test split released by (Karpathy, 2015)? Clarifying this would be nice since the numbers seem a bit on the lower side.\n\n2. What are the relative number of parameters in the Vinyals et.al. baseline and the proposed TPGN model? Would having an LSTM with twice the number of layers (by stacking them) or twice the size of the hidden state do better?\n\n3. What if we used the hidden state of a regular LSTM decoder to do POS tagging? How well would that do? Does the TPN capture any more syntactic structure than an LSTM decoder (Table. 2). This seems to be an important result to report.\n\nClarity:\n1. Page 7.: “We also implemented the latest ResNet feature” -- would be good be explicit which resnet model is used.\n\nReferences:\n[A]: Fang, Hao, Saurabh Gupta, Forrest Iandola, Rupesh Srivastava, Li Deng, Piotr Dollár, Jianfeng Gao, et al. 2014. “From Captions to Visual Concepts and Back.” arXiv [cs.CV]. arXiv. http://arxiv.org/abs/1411.4952.']","[-70, -30, 20]","[-30, 50, 80]","[""The sentiment score is -70 because the review is predominantly negative, pointing out multiple flaws and inaccuracies in the paper without offering much positive feedback. The reviewer challenges the paper's claims, criticizes the experimental setup, and suggests the work is not novel. The politeness score is -30 because while the language is not overtly rude, it is quite direct and critical without softening the feedback. The reviewer uses phrases like 'which is false', 'useless', and 'contradicts' without hedging or polite framing. The review also lacks any positive reinforcement or encouragement, which contributes to its somewhat impolite tone."", ""The sentiment score is -30 because while the reviewer expresses initial sympathy and hope for the work, they ultimately recommend rejection due to presentation issues and questionable decisions in the NLP evaluations. The overall tone is more negative than positive, but not extremely so. The politeness score is 50 because the reviewer uses polite language throughout, such as 'I have a huge amount of sympathy for this work' and provides constructive feedback. However, they also directly point out flaws and use some strong language like 'hopeless misrepresentation', which prevents a higher politeness score. The reviewer balances criticism with positive remarks and maintains a professional tone throughout."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges strengths of the paper, such as the 'potentially elegant manner' of the approach and 'promising' results. However, they also express concerns about baselines and some aspects of the methodology, which tempers the overall positivity. The politeness score is high (80) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'It would be nice to explain' and 'It would be good to address', which maintain a polite and professional tone. The reviewer also balances positive comments with areas for improvement, demonstrating a fair and courteous approach to the review.""]"
"['1) this paper introduces a new cloze dataset, ""CLOTH"", which is designed by teachers. The authors claim that this cloze dataset is a more challenging dataset since CLOTH requires a deeper language understanding and wider attention span. I think this dataset is useful for demonstrating the robustness of current RC models. However, I still have the following questions which lead me to reject this paper.\n\n2) I have the questions as follows:\ni) The major flaw of this paper is about the baselines in experiments. I don\'t think the language model is a robust baseline for this paper.  When a wider span is used for selecting answers, the attention-based model should be a reasonable baseline instead of pure LM. \nii) the author also should provide the error rates for each kind of questions (grammar questions or long-term reasoning). \niii) the author claim that this CLOTH dataset requires wider span for getting the correct answer, however, there are only 22.4 of the entire data need long-term reasoning. More importantly, there are 26.5% questions are about grammar. These problems can be easily solved by LM. \niv) I would not consider 16% percent of accuracy is a ""significant margin"" between human and pure LM-based methods. LM-based methods should not be considered as RC model.\nv) what kind accuracy is improved if you use 1-billion corpus trained LM? Are these improvements mostly in grammar? I did not see why larger training corpus for LM could help a lot about reasoning since reasoning is only related to question document.\n', 'This paper presents a new dataset for cloze style question-answering. The paper starts with a very valid premise that many of the automatically generated cloze datasets for testing reading comprehension suffer from many shortcomings. The paper collects data from a novel source: reading comprehension data for English exams in China. The authors collect data for middle school and high school exams and clean it to obtain passages and corresponding questions and candidate answers for each question.\n\nThe rest of the paper is about analyzing this data and performance of various models on this dataset. \n\n1) The authors divide the questions into various types based on the type of reasoning needed to answer the question, noticeably short-term reasoning and long-term reasoning. \n2) The authors then show that human performance on this dataset is much higher than the performance of LSTM-based and language model-based baselines; this is in contrast to existing cloze style datasets where neural models achieve close to human performance. \n3) The authors hypothesize that this is partially explained by the fact that neural models do not make use of long-distance information. The authors verify their claim by running human eval where they show annotators only 1 sentence near the empty slot and find that the human performance is basically matched by a language model trained on 1 billion words. This part is very cool.\n4) The authors then hypothesize that human-generated data provides more information. They even train an informativeness prediction network to (re-)weight randomly generated examples which can then be used to train a reading comprehension model.\n\nPros of this work:\n1) This work contributes a nice dataset that addresses a real problem faced by automatically generated datasets.\n2) The breakdown of characteristics of questions is quite nice as well.\n3) The paper is clear, well-written, and is easy to read.\n\nCons:\n1) Overall, some of the claims made by the paper are not fully supported by the experiments. E.g., the paper claims that neural approaches are much worse than humans on CLOTH data -- however, they do not use state-of-the-art neural reading comprehension techniques but only a standard LSTM baseline. It might be the case that the best available neural techniques are still much worse than humans on CLOTH data, but that remains to be seen. \n2) Informativeness prediction: The authors claim that the human-generated data provides more information than automatically/randomly generated data by showing that the models trained on the former achieve better performance than the latter on test data generated by humans. The claim here is problematic for two reasons:\n   a) The notion of ""informativeness"" is not clearly defined. What does it mean here exactly?\n   b) The claim does not seem fully justified by the experiments -- the results could just as well be explained by distributional mismatch without appealing to the amount of information per se. The authors should show comparisons when evaluating on randomly generated data.\n\nOverall, this paper contributes a useful dataset; the analysis can be improved in some places.', 'This paper collects a cloze-style fill-in-the-missing-word dataset constructed manually by English teachers to test English proficiency.  Experiments are given which are claimed to show that  this dataset is difficult for machines relative to human performance.  The dataset seems interesting but I find the empirical evaluations unconvincing.  The models used to evaluate machine difficulty are basic language models.  The problems are multiple choice with at most four choices per question.  This allows multiple choice reading comprehension architectures to be used.   A window of words around the blank could be used as the ""question"".  A simple reading comprehension baseline is to encode the question (a window around the blank) and use the question vector to compute an attention over the passage.  One can then compute a question-specific representation of the passage and score each candidate answer by the inner product of the question-specific sentence representation and the vector representation of the candidate answer.  See ""A thorough examination of the CNN/Daily Mail reading comprehension task"" by Chen, Bolton and Manning.\n\n']","[-70, 60, -50]","[-20, 80, 0]","[""The sentiment score is -70 because the reviewer explicitly states they are rejecting the paper and lists several major criticisms. The overall tone is quite negative, with phrases like 'major flaw' and questioning the authors' claims. However, it's not entirely negative as the reviewer acknowledges some potential usefulness of the dataset. The politeness score is -20 because while the language isn't overtly rude, it's quite direct and critical without much attempt to soften the feedback. The reviewer uses phrases like 'I don't think' and 'I would not consider' which come across as somewhat dismissive. There's a lack of positive reinforcement or constructive framing that would be expected in a more polite review."", ""The sentiment score is 60 (positive) because the reviewer highlights several pros of the work, including its contribution of a useful dataset, nice breakdown of question characteristics, and clear writing. They also describe parts of the analysis as 'very cool'. However, the score is not higher due to the cons mentioned, such as unsupported claims and problematic aspects of the informativeness prediction. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'The paper is clear, well-written, and is easy to read' and offer specific suggestions for improvement rather than harsh criticism. The tone remains professional and courteous throughout the review."", ""The sentiment score is -50 because the reviewer expresses skepticism about the paper's empirical evaluations, calling them 'unconvincing'. They also suggest that the authors have not used appropriate models or techniques for evaluation. However, the reviewer does acknowledge that the dataset 'seems interesting', which prevents the score from being more negative. The politeness score is 0 (neutral) because the reviewer's language is neither particularly polite nor rude. They state their criticisms directly but professionally, without using overly harsh language or personal attacks. The reviewer provides constructive feedback by suggesting alternative approaches, which is a neutral way of offering criticism.""]"
"['The authors propose a probabilistic framework for semi-supervised learning and domain adaptation. By varying the prior distribution, the framework can incorporate both generative and discriminative modeling.  The authors emphasize on one particular form of constraint on the prior distribution, that is weight (parameter) sharing, and come up with a concrete model named Dauto for domain adaptation. A domain confusion loss is added to learn domain-invariant feature representations. The authors compared Dauto with several baseline methods on several datasets and showed improvement. \n\nThe paper is well-organized and easy to follow. The probabilistic framework itself is quite straight-forward. The paper will be more interesting if the authors are able to extend the discussion on different forms of prior instead of the simple parameter sharing scheme. \n\nThe proposed DAuto is essentially DANN+autoencoder.  The minimax loss employed in DANN and DAuto is known to be prone to degenerated gradient for the generator. It would be interesting to see if the additional auto-encoder part help address the issue. \n\nThe experiments miss some of the more recent baseline in domain adaptation, such as Adversarial Discriminative Domain Adaptation (Tzeng, Eric, et al. 2017). \n\nIt could be more meaningful to organize the pairs in table by target domain instead of source, for example, grouping 9->9, 8->9, 7->9 and 3->9 in the same block. DAuto does seem to offer more boost in domain pairs that are less similar. ', 'This paper proposed a probabilistic framework for domain adaptation that properly explains why maximizing both the marginal and the conditional log-likelihoods can achieve desirable performances.  \nHowever, I have the following concerns on novelty. \n\n1. Although the paper gives some justiification why auto-encoder can work for domain adaptation from perspective of probalistics model, it does not give new formulation or algorithm to handle domain adaptation.  At this point, the novelty is weaken.\n2. In the introduction, the authors mentioned “limitations of mSDA is that it needs to explicitly form the covariance matrix of input features and then solves a linear system, which can be computationally expensive in high dimensional settings.” However, mSDA cannot handle high dimension setting by performing the  reconstruction with a number of  random non-overlapping sub-sets of input features. It is not clear why mSDA cannot handle time-series data but DAuto can.  DAuto does not consider the sequence/ordering of data either. \n3. If my understanding is not wrong, the proposed DAuto is just a simple combination of three losses (i.e. prediction loss, reconstruction loss, domain difference loss). As far as I know, this kind of loss is commonly used in most existing methods. ', 'This is a very well-written paper that shows how to successfully use (generative) autoencoders together with the (discriminative) domain adversarial neural network (DANN) of Ganin et al.\nThe construction is simple but nicely backed by a probabilistic analysis of the domain adaptation problem.\n\nThe only criticism that I have towards this analysis is that the concept of shared parameter between the discriminative and predictive model (denoted by zeta in the paper) disappear when it comes to designing the learning model.  \n\nThe authors perform numerous empirical experiments on several types of problems. They successfully show that using autoencoder can help to learn a good representation for discriminative domain adaptation tasks. On the downside, all these experiments concern predictive (discriminative) problems. Given the paper title, I would have expected some experiments in a generative context. Also, a comparison with the Generative Adversarial Networks of Goodfellow et al. (2014) would be a plus.\nI would also like to see the results obtained using DANN stacked on mSDA representations, as it is done in Ganin et al. (2016).\n\nMinor comments:\n- Paragraph below Equation 6:  The meaning of $\\phi(\\psi)$ is unclear \n- Equation (7): phi and psi seems inverted \n- Section 4: The acronym MLP is used but never defined.\n\n=== update ===\nI lowered my score and confidence, see my new post below.']","[50, -50, 50]","[75, 20, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper is well-organized and easy to follow, and notes some improvements over baseline methods. However, they also point out several limitations and suggest areas for improvement, indicating a balanced but generally favorable view. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as opportunities for improvement rather than harsh criticisms. Phrases like 'The paper will be more interesting if...' and 'It would be interesting to see...' demonstrate a polite and encouraging tone while still providing feedback."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper in the first sentence, the majority of the review focuses on concerns and limitations, indicating a generally negative sentiment. The review uses phrases like 'I have the following concerns on novelty' and points out several weaknesses, which contribute to the negative score. The politeness score is 20 because the reviewer uses relatively neutral language and presents their concerns in a professional manner without using harsh or rude expressions. The reviewer starts with a positive comment and uses phrases like 'If my understanding is not wrong,' which shows a degree of politeness. However, the score is not higher as the review is quite direct in its criticism and doesn't use many explicitly polite phrases."", ""The sentiment score is 50 (moderately positive) because the reviewer starts by calling it a 'very well-written paper' and praises several aspects, but also provides some criticisms and suggestions for improvement. The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms constructively (e.g. 'The only criticism I have...'), and uses phrases like 'I would like to see' rather than making demands. The reviewer also acknowledges the paper's strengths before offering suggestions. The language is consistently professional and courteous.""]"
"['This paper aims to push the LSTM gates to be binary. To achieve this, the paper proposes to employ the recent Gumbel-Softmax trick to obtain end-to-end trainable categorical distribution (taking 0 or 1 value). The resulted G2-LSTM is applied for language model and machine translation in the experiments. \n\nThe novelty of this paper is limited. Just directly apply the Gumbel-Softmax trick. \n\nThe motivation is not explained clearly and convincingly. Why need to pursue binary gates? According to the paper, it may give better generalization performance. But there is no theoretical or experimental evidence provided by this paper to support this argument. \n\nThe results of the new G2-LSTM are not significantly better than baselines in the experiments.', 'The paper argues for pushing the input and forget gate’s output toward 0 or 1, i.e., the LSTM tends to reside in flat region of surface loss, which is likely to generalize well. To achieve that, the sigmoid function in the original LSTM is replaced by a function G that is continuous and differentiable with respect to the parameters (by applying the Gumbel-Softmax trick). As a result, the model is still differentiable while the output gate is approximately binarized.  \n\nPros:\n-\tThe paper is clearly written\n-\tThe method is new and somehow theoretically guaranteed by the proof of the Proposition 1\n-\tThe experiments are clearly explained with detailed configurations\n-\tThe performance of the method in the model compression task is promising \n\nCons:\n-\tThe “simple deduction” which states that pushing the gate values toward 0 or 1 correspond to the region of the overall loss surface may need more theoretical analysis\n-\tIt is confusing whether the output of the gate is sampled based on or computed directly by the function G  \n-\tThe experiments lack many recent baselines on the same dataset (Penn Treebank: Melis et al. (2017) – On the State of the Art of Evaluation in Neural Language Models; WMT: Ashish et.al. (2017) – Attention Is All You Need) \n-\tThe experiment’s result is only slightly better than the baseline’s\n-\tTo be more persuasive, the author should include in the baselines other method that can “binerize” the gate values such as the one sharpening the sigmoid function. \n\n\nIn short, this work is worth a read. Although the experimental results are not quite persuasive, the method is nice and promising. \n', 'This paper propose a new ""gate"" function for LSTM to enable the values of the gates towards 0 or 1. The motivation behind is a  flat region of the loss surface is likely to generalize well. It shows the experimental results are comparable or better than vanilla LSTM and much more robust to low-precision approximation and low-rank approximation.\n\nIn section 3.2, the paper claimed using a smaller temperature cannot guarantee the outputs to be close to the boundary. Is there any experimental evidence to show it\'s not working? It also claimed pushing output gate to 0/1 will drop the performance. It actually quite interesting because there are bunch of paper claimed output gate is not important for language modeling, e.g. https://openreview.net/pdf?id=HJOQ7MgAW . \n\nIn the sensitive analysis, what if apply rounding / low-rank for all the parameters? \n\nHow was this approach compare to binarynet https://arxiv.org/abs/1602.02830 ? Applying the same idea, but only for forget gate/ input gate. Also, can we apply this idea to the binarynet? \n\nOverall, I think it\'s an interesting paper but I feel it should compare with some simple baseline to binarized the gate function.  \n\nUpdates: Thanks a lot for all the clarification. It do improve the paper quality but I\'m still thinking it\'s higher than ""6"" but lower than ""7"". To me, improve ppl from ""52.8"" to ""52.1"" isn\'t very significant. For WMT, it improve on DE->EN but not for EN->DE (although it improve both for the author\'s own baseline). So I\'m not fully convinced this approach could improve the generalization. But I feel this work can have many other applications such as ""binarynet"". ']","[-60, 50, -20]","[0, 75, 60]","[""The sentiment score is -60 because the review is generally negative. The reviewer states that the paper has 'limited novelty', lacks clear motivation, and doesn't provide significant improvements over baselines. These are substantial criticisms that indicate the reviewer is not impressed with the work. However, it's not entirely negative as the reviewer does acknowledge the paper's aim and approach. The politeness score is 0 (neutral) because the language used is direct and matter-of-fact without being overtly polite or rude. The reviewer states their criticisms plainly without using harsh language or personal attacks, but also without softening their critique with polite phrases or positive reinforcement."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges both pros and cons of the paper, but ultimately concludes that 'this work is worth a read' and the method is 'nice and promising'. The review starts with a neutral summary and lists several positive aspects before addressing the limitations. The politeness score is 75 (quite polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths ('clearly written', 'new and somehow theoretically guaranteed') and frame criticisms as suggestions for improvement rather than harsh judgments. The use of phrases like 'To be more persuasive' and 'may need more theoretical analysis' indicates a considerate tone aimed at helping the authors improve their work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting', they express several concerns and suggest that the paper should compare with simple baselines. The reviewer is not fully convinced about the significance of the improvements and the generalization capabilities of the approach. However, the tone is not entirely negative, as they recognize potential applications.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful language throughout. They express their concerns as suggestions rather than harsh criticisms (e.g., 'I feel it should compare...', 'I'm still thinking...'). The reviewer also shows appreciation for the authors' clarifications ('Thanks a lot for all the clarification'). The language is constructive and professional, avoiding any rudeness or overly critical tone.""]"
"[""The paper proposes a method for adapting a pre-trained network, trained on a fixed number of\nclasses, to incorporate novel classes for doing classification, especially when the novel classes\nonly have a few training examples available. They propose to do a `hard' distillation, i.e. they\nintroduce new nodes and parameters to the network to add the new classes, but only fine-tune the new\nnetworks without modifying the original parameters. This ensures that, in the new expanded and\nfine-tuned network, the class confusions will only be between the old and new classes and not\nbetween the old classes, thus avoiding catastrophic forgetting. In addition they use GMMs trained on\nthe old classes during the fine-tuning process, thus avoiding saving all the original training data.\nThey show experiments on public benchmarks with three different scenarios, i.e.  base and novel\nclasses from different domains, base and novel classes from the same domain and novel classes have\nsimilarities among themselves, and base and novel classes from the same domain and each novel class\nhas similarities with at least one of the base class.                        \n                                                                             \n- The paper is generally well written and it is clear what is being done     \n- The idea is simple and novel; to the best of my knowledge it has not been tested before\n- The method is compared with Nearest Class Means (NCM) and Prototype-kNN with soft distillation\n  (iCARL; where all weights are fine-tuned). The proposed method performs better in low-shot\n  settings and comparably when large number of training examples of the novel classes are available\n- My main criticism will be the limited dataset size on which the method is validated. The ILSVRC12\n  subset contains 5 base and 5 novel classes and the UT-Zappos50K subset also has 10 classes. The\n  idea is simple and novel, which is good, but the validation is limited and far from any realistic\n  use. Having only O(10) classes is not convincing, especially when the datasets used do have large\n  number of classes. I agree that this will not allow or will takes some involved manual effort to\n  curate subsets for the settings proposed, but it is necessary for being convincing."", 'On few-shot learning problem, this paper presents a simple yet powerful distillation method where the base network is augmented with additional weights to classify the novel classes, while keeping the weights of the base network unchanged. Thus the so-called hard distillation is proposed. This paper is well-written and well organized. The good points are as follows,\n\n1. The paper proposes a well-performance method for the important low-shot learning problem based on the transform learning.\n2. The Gen-LSNE maintains a small memory footprint using a generative model for base examples and requires a few more parameters to avoid overfitting and take less time to train.\n3. This paper builds up a benchmark for low-shot network expansion.\n\nThere are some problems,\n1. There still is drop in accuracy on the base classes after adding new classes, and the accuracy may still drop as adding more classes due to the fixed parameters corresponding to the base classes. This is slightly undesired.\n2. Grammatical mistake: page 3, line 5(“a additional layers”)\n', 'The goal of this paper is to study generalisation to novel classes. This paper stipulates some interesting ideas, using an idea of expansion layers (using a form of hard distillation, where the weights of known classes are fixed), a GMM to model the already learned classes (to reduce storage), and a form of gradient dropout (updating just a subset of the weights using a dropout mask). All of these assume a fixed representation, trained on the base classifier, then only the final classification layer is adjusted for the novel examples. \n\nThe major drawback is that none of these ideas are fully explored. Given fixed representation, for example the influence of forgetting on base classes, the number of components used in the GMM, the influence of the low-shot, the dropout rate, etc etc.  The second major drawback is that the experimental setting seems very unrealistic: 5 base classes and 2 novel classes. \n\nTo conclude: the ideas in this paper are very interesting, but difficult to gather insights given the focus of the experiments.\n\nMinor remarks\n- Sect 4.1 ""The randomly ... 5 novel classes"" is not a correct sentence.\n- The extended version of NCM (4.2.1), here uses as prototype-kNN (Hastie 2001) has also been explored in the paper of NCM, using k-means per class to extract prototypes.\n- Given fixed representations, plenty of work has focused on few-shot (linear) learning, this work should be compared to these. ']","[50, 80, -20]","[75, 60, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novelty, clear writing, and good performance in low-shot settings. However, they also express criticism about the limited dataset size used for validation. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their criticism constructively. They use phrases like 'My main criticism will be...' and 'I agree that...' which maintain a polite tone while providing feedback."", ""The sentiment score is 80 (positive) because the review starts with a positive overview of the paper, describing it as 'well-written and well organized.' The reviewer lists three 'good points' about the paper, highlighting its strengths and contributions. While there are two problems mentioned, they are presented as minor issues rather than major flaws. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits before pointing out issues. The problems are presented as observations rather than harsh criticisms. The use of phrases like 'This paper is well-written' and 'The good points are as follows' contribute to the polite tone. However, the directness in pointing out the grammatical mistake slightly reduces the politeness score from being extremely high."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some 'interesting ideas' in the paper, they also point out major drawbacks such as ideas not being fully explored and an unrealistic experimental setting. The conclusion suggests that the paper's potential is not fully realized. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's merits before critiquing its shortcomings. They use phrases like 'interesting ideas' and provide constructive feedback rather than harsh criticism. The tone is professional and objective, offering specific suggestions for improvement without being overly critical or dismissive.""]"
"['The paper derived a way to compare nodes in graph based on wavelet analysis of graph laplacian. The method is correct but it is not clear whether the method can match the performance of state-of-the-art methods such as graph convolution neural network of Duvenaud  et al. and Structure2Vec of Dai et al. in large scale datasets.  \n1. Convolutional Networks on Graphs for Learning Molecular Fingerprints. D Duvenaud et al., NIPS 2015. \n2. Discriminative embeddings of latent variable models for structured data. Dai et al. ICML 2016.\n\n', 'The paper proposes a method for quantifying the similarity between the local neighborhoods of nodes in a graph/network.\n\nThere are many ways in which such a distance/similarity metric between nodes could be defined. For example, once could look at the induced subgraph G_i formed by the k-neighborhood of node i, and the induced subgraph G_j of the k-neighborhood of node j, and define the similarity as k(G_i,G_j) where k is any established graph kernel. Moreover, the task is unsupervised, which makes it hard to compare the performance of different methods. Most of the experiments in the paper seem a bit contrived.\n\nRegarding the algorithm, the question is: “sure, but why this way?”. The authors take the heat kernel matrix on the graph, treat each column as a probability distribution, compute its characteristic function, and define a distance between characteristics functions. This seems pretty arbitrary and heuristic. I also find it confusing that they refer to the heat kernel as wavelets. The spectral graph wavelets of Hammond et al is a beautiful construction, but, as far as I remember, it is explicitly emphasized that the wavelet generating function g must be continuous and satisfy g(0)=0. By setting g(\\lambda)=e^{-s \\lambda}, the authors just recover the diffusion/heat kernel of the graph. That’s not a wavelet. Why call this a “spectral graph wavelet” approach then? The heat kernel is much simpler. I find this misleading.\n\nI also feel that the mathematical results in the paper have little depth. Diffusion is an inherently local process. It is natural then that the diffusion matrix can be approximated by a polynomial in the Laplacian (in fact, it is sufficient to look at the power series of the matrix exponential). It is not surprising that the diffusion function captures some local properties of the graph (there are papers by Reid Andersen/ Fan Chung/ Kevin Lang, as well as by Mahoney, I believe on localized PCA in graphs following similar ideas). Again, there are many ways that this could be done. The particular way it is done in the paper is heuristic and not supported by either math or strong experiments.\n', 'The term ""structural equivalence"" is used incorrectly in the paper.  From sociology, two nodes with the same position are in an equivalence relation.  An equivalence, Q, is any relation that satisfies these three conditions:\n  - Transitivity: (a,b), (b,c) ∈ Q ⇒ (a,c) ∈Q\n  - Symmetry: (a, b) ∈ Q if and only if (b, a) ∈Q\n  - Reflexivity: (a, a) ∈Q\n\nThere are three deterministic equivalences: structural, automorphic, and regular.\n\nFrom Lorrain & White (1971), two nodes u and v are structurally equivalent if they have the same relationships to all other nodes.  Exact structural equivalence is rare in real-world networks.\n\nFrom Borgatti, et al. (1992) and Sparrow (1993), two nodes u and v are automorphically equivalent if all the nodes can be relabeled to form an isomorphic graph with the labels of u and v interchanged.\n\nFrom Everett & Borgatti (1992), two nodes u and v are regularly equivalent if they are equally related to equivalent others.\n\nParts of this statement are false: ""A notable example of such approaches is RolX (Henderson et al., 2012), which aims to recover a soft-clustering of nodes into a predetermined number of K distinct roles using recursive feature extraction (Henderson et al., 2011).""  RolX (as described in KDD 2012 paper) uses MDL to automatically determine the number of roles.\n\nAs indicated above, this statement is also false: ""We note that RolX requires the number of desired structural classes as input, ..."".\n\nThe paper does not discuss how the free parameter d (which represents the number of evenly spaced sample points)  is chosen. \n\nThis statement is misleading: ""In particular, a small perturbation of the graph yields small perturbations of the eigenvalues.""  What is considered a small perturbation?  One can delete an edge (seemingly a small perturbation) and change the eigenvalues of the Laplacian dramatically --  e.g., deleting an edge that increases the number of connected components.\n\nThe barbell graph experiment seemed contrived.  Why would one except such a graph to have 8 classes?  Why not 3?  One for cliques, one for the chain, and one for connectors of the clique to the chain.\n\nIn Section 4.2, how many roles were selected for RolX?\n\nThe paper states: ""Furthermore, nodes from different graphs can be embedded into the same space and their structural roles can be compared across different graphs.""  Experiments were not conducted to see how the competing approaches such as RolX compare with GraphWave on transfer learning tasks.\n\nGilpin et al (KDD 2013) extended RolX to incorporate sparsity and diversity constraints on the role space and showed that their approach is superior to RolX on measuring distances.  This is applicable to experiments in Figure 4.\n\nI strongly recommend running experiments that test the predictive power of the roles found by GraphWave.\n']","[-20, -70, -60]","[0, -20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the method is correct, they express doubt about its performance compared to state-of-the-art methods. The phrase 'it is not clear whether the method can match the performance' indicates a level of skepticism about the paper's contribution. The politeness score is neutral (0) as the language used is neither particularly polite nor rude. The reviewer states their concerns directly without using overly harsh or overly courteous language. The review is brief and to the point, focusing on the technical aspects without personal comments or strong emotional language."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer criticizes the paper's approach as 'arbitrary and heuristic', questions the novelty and depth of the mathematical results, and describes the experiments as 'contrived'. The reviewer also expresses confusion about terminology and suggests that there are better alternatives to the proposed method. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite critical and dismissive. Phrases like 'sure, but why this way?' and 'I find this misleading' come across as somewhat confrontational. The reviewer does not offer much positive feedback or constructive suggestions for improvement, which contributes to the overall negative and impolite tone."", ""The sentiment score is -60 because the review is predominantly critical, pointing out multiple errors and false statements in the paper. The reviewer suggests several improvements and expresses strong disagreement with some of the paper's claims. However, it's not entirely negative as the reviewer does provide constructive feedback. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and avoid personal attacks. They provide specific examples and references to support their points, which is a respectful approach. The tone is matter-of-fact rather than overtly polite, but it maintains a level of professional courtesy typical in academic reviews.""]"
"['The below review addresses the first revision of the paper. The revised version does address my concerns. The fact that the paper does not come with substantial theoretical contributions/justification still stands out.\n\n---\n\nThe authors present a variant of the adversarial feature learning (AFL) approach by Edwards & Storkey. AFL aims to find a data representation that allows to construct a predictive model for target variable Y, and at the same time prevents to build a predictor for sensitive variable S. The key idea is to solve a minimax problem where the log-likelihood of a model predicting Y is maximized, and the log-likelihood of an adversarial model predicting S is minimized. The authors suggest the use of multiple adversarial models, which can be interpreted as using an ensemble model instead of a single model.\n\nThe way the log-likelihoods of the multiple adversarial models are aggregated does not yield a probability distribution as stated in Eq. 2. While there is no requirement to have a distribution here - a simple loss term is sufficient - the scale of this term differs compared to calibrated log-likelihoods coming from a single adversary. Hence, lambda in Eq. 3 may need to be chosen differently depending on the adversarial model. Without tuning lambda for each method, the empirical experiments seem unfair. This may also explain why, for example, the baseline method with one adversary effectively fails for Opp-L. A better comparison would be to plot the performance of the predictor of S against the performance of Y for varying lambdas. The area under this curve allows much better to compare the various methods.\n\nThere are little theoretical contributions. Basically, instead of a single adversarial model - e.g., a single-layer NN or a multi-layer NN - the authors propose to train multiple adversarial models on different views of the data. An alternative interpretation is to use an ensemble learner where each learner is trained on a different (overlapping) feature set. Though, there is no theoretical justification why ensemble learning is expected to better trade-off model capacity and robustness against an adversary. Tuning the architecture of the single multi-layer NN adversary might be as good?\n\nIn short, in the current experiments, the trade-off of the predictive performance and the effectiveness of obtaining anonymized representations effectively differs between the compared methods. This renders the comparison unfair. Given that there is also no theoretical argument why an ensemble approach is expected to perform better, I recommend to reject the paper.', 'MARS is suggested to combine multiple adversaries with different roles.\nExperiments show that it is suited to create censoring representations for increased anonymisation of data in the context of wearables.\n\nExperiments a are satisfying and show good performance when compared to other methods.\n\nIt could be made clearer how significance is tested given the frequent usage of the term.\n\nThe idea is slightly novel, and the framework otherwise state-of-the-art.\n\nThe paper is well written, but can use some proof-reading.\n\nReferencing is okay.', '- The authors propose the use of multiple adversaries over random subspaces of features in adversarial feature learning to produce censoring representations. They show that their idea is effective in reducing private information leakage, but this idea alone might not be signifcant enough as a contribution. \n\n- The idea of training multiple adversaries over random subspaces is very similar to the idea of random forests which help with variance reduction. Indeed judging from the large variance in the accuracy of predicting S in Table 1a-c for single adversaries, I suspect one of the main advantage of the current MARS method comes from variance reduction. The author also mentioned using high capacity networks as adversaries does not work well in practice in the introduction, and this could also be due to the high model variance of such high capacity networks.  \n\n- The definition of S, the private information set, is not clear. There is no statement about it in the experiments section, and I assume S is the subject identity. But this makes the train-test split described in 4.1 rather odd, since there is no overlap of subjects in the train-test split. We need clarifications on these experimental details. \n\n- Judging from Figure 2 and Table 1, all the methods tested are not effective in hiding the private information S in the learned representation. Even though the proposed method works better, the prediction accuracies of S are still high.  \n']","[-70, 60, -30]","[20, 50, 50]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper lacks substantial theoretical contributions, points out flaws in the methodology, and ultimately recommends rejection. However, it's not entirely negative as the reviewer acknowledges that the revision addressed some previous concerns. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They provide detailed explanations for their criticisms and use phrases like 'I recommend' rather than making harsh demands. The language is formal and constructive, even when pointing out shortcomings."", ""The sentiment score is 60 (moderately positive) because the review generally expresses satisfaction with the paper's experiments and performance, noting that it shows 'good performance' and is 'satisfying'. The idea is described as 'slightly novel' and the framework as 'state-of-the-art', which are positive aspects. However, it's not overwhelmingly positive as it suggests some improvements like clearer significance testing and proof-reading. The politeness score is 50 (somewhat polite) because the language used is professional and constructive without being overly formal or effusive. The reviewer provides balanced feedback, acknowledging strengths while also pointing out areas for improvement in a respectful manner. There are no rude or harsh comments, but also no exceptionally polite phrases, resulting in a moderately polite tone overall."", ""The sentiment score is -30 because the review is somewhat negative overall. The reviewer acknowledges the effectiveness of the proposed method but suggests that the contribution might not be significant enough. They also point out similarities to existing methods and highlight that the approach is still not fully effective in hiding private information. The politeness score is 50 because the language used is professional and constructive. The reviewer provides specific feedback and suggestions without using harsh or dismissive language. They use phrases like 'I suspect' and 'We need clarifications' which maintain a respectful tone while expressing concerns.""]"
"['The authors present Auxiliary Guided Autoregressive Variational autoEncoders (AGAVE), a hybrid approach that combines the strengths of variational autoencoders (global statistics) and autorregressive models (local statistics) for improved image modeling. This is done by controlling the capacity of the autorregressive component within an auxiliary loss function.\n\nThe proposed approach is a straightforward combination of VAE and PixelCNN that although empirically better than PixelCNN, and presumably VAE, does not outperform PixelCNN++. Provided that the authors use PixelCNN++ in their approach, quantitively speaking, it is difficult to defend the value of adding a VAE component to the model. The authors do not describe how \\lambda was selected, which is critical for performance, provided the results in Figure 4. That being said, the contribution from the VAE is likely to be negligible given the performance of PixelCNN++ alone.\n\n- The KL divergence in (3) does more than simply preventing the approximation q() from becoming a point mass distribution.', 'Summary:\n\nThis paper attempts to solve the problem of meaningfully combining variational autoencoders (VAEs) and PixelCNNs. It proposes to do this by simultaneously optimizing a VAE with PixelCNN++ decoder, and a VAE with factorial decoder. The model is evaluated in terms of log-likelihood (with no improvement over a PixelCNN++) and the visual appearance of samples and reconstructions.\n\nReview:\n\nCombining density networks (like VAEs) and autoregressive models is an unsolved problem and potentially very useful. To me, the most interesting bit of information in this paper was the realization that you can weight the reconstruction and KL terms of a VAE and interpret it as variational inference in a generative model with multiple copies of pixels (below Equation 7). Unfortunately the authors were unable to make any good use of this insight, and I will explain below why I don’t see any evidence of an improved generative model in this paper.\n\nAs the paper is written now, it is not clear what the goal of the authors is. Is it density estimation? Then the addition of the VAE had no measurable effect on the PixelCNN++’s performance, i.e., it seems like a bad idea due to the added complexity and loss of tractability. Is it representation learning? Then the paper is missing experiments to support the idea that the learned representations are in any way an improvement. Is it image synthesis (not a real application by itself), then the paper should have demonstrated the usefulness of the model on a real task and probably involve human subjects in a quantitative evaluation.\n\nMuch of the authors’ analysis is based on a qualitative evaluation of samples. However, samples can be very misleading. A lookup table storing the training data generates samples containing objects and perfect details, but obviously has not learned anything about either objects or the low-level statistics of natural images. \n\nIn contrast to the authors, I fail to see a meaningful difference between the groups of samples in Figure 1.\n\nThe VAE samples in Figure 3b) look quite smooth. Was independent Gaussian noise added to the VAE samples or are those (as is sometimes done) sampled means? If the former, what was sigma and how was it chosen?\n\nOn page 7, the authors conclude that “the pixelCNN clearly takes into account the output of the VAE decoder” based on the samples. Being a mixture model, a PixelCNN++ could easily represent the following mixture:\n\np(x | z) = 0.01 \\prod_i p(x_i | x_{<i}) + 0.99 \\prod_i p(x_i | z)\n\nThe first term is just like a regular PixelCNN++, ignoring the latent variables. The second term is just like a variational autoencoder with factorial decoder. The samples in this case would be dominated by the VAE, which depends on the latent state. The log-likelihood would be dominated by the first term and would be minimally effected (see Theis et al., 2016). Note that I am not saying that this is exactly what the model has learned. I am merely providing a possible counter example to the notion that the PixelCNN++ has learned to use of the latent representation in a meaningful way.\n\nWhat happens if the KL term is simply downweighted but the factorial decoder is not included? This seems like it would be a useful control to include.\n\nThe paper is well written and clear.', 'The proposed approach is straight forward, experimental results are good, but don’t really push the state of the art. But the empirical analysis (e.g. decomposition of different cost terms) is detailed and very interesting.   ']","[-20, -50, 50]","[20, 50, 0]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the proposed approach as a 'straightforward combination' that is 'empirically better than PixelCNN', they also point out that it 'does not outperform PixelCNN++' and question the value of adding a VAE component. The reviewer also criticizes the lack of explanation for parameter selection and suggests the VAE contribution might be 'negligible'. However, the score is not deeply negative as the reviewer does recognize some merits of the work.\n\nThe politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout, using neutral language like 'The authors present...' and 'Provided that...'. They offer criticism in a constructive manner, pointing out specific areas for improvement rather than making personal attacks. The language is not overly formal or polite, but it avoids rudeness, maintaining a respectful academic tone."", ""The sentiment score is -50 because the reviewer expresses significant skepticism about the paper's contributions and methodology. They state that the authors were 'unable to make any good use' of their insight, question the paper's goals, and dispute the authors' interpretations of their results. However, it's not entirely negative as they acknowledge the potential usefulness of the problem being addressed. The politeness score is 50 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'To me' and 'I fail to see' to express disagreement without being confrontational. They also compliment the paper as being 'well written and clear' at the end, which is a polite gesture despite the overall critical review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges good experimental results and finds the empirical analysis 'detailed and very interesting'. However, they also note that the approach doesn't 'really push the state of the art', which tempers the positivity. The politeness score is 0 (neutral) as the language is direct and factual without being particularly polite or impolite. The reviewer states observations without using overtly courteous or rude language.""]"
"[""This paper presents a deep network architecture which processes data using multiple parallel branches and combines the posterior from these branches to compute the final scores; the network is trained in end-to-end, thus training the parallel branches jointly. Existing literature with branching architecture either employ a 2 stage training approach, training branches independently and then training the fusion network, or the branching is restricted to local regions (set of contiguous layers). In effect, this paper extends the existing literature suggesting end-to-end branching. While the technical novelty, as described in the paper, is relatively limited, the thorough experimentation together with detailed comparisons between intuitive ways to combine the output of the parallel branches is certainly valuable to the research community.\n\n+ Paper is well written and easy to follow.\n+ Proposed branching architecture clearly outperforms the baseline network (same number of parameters with a single branch) and thus offer yet another interesting choice while creating the network architecture for a problem\n+ Detailed experiments to study and analyze the effect of various parameters including the number of branches as well as various architectures to combine the output of the parallel branches.\n+ [Ease of implementation] Suggested architecture can be easily implemented using existing deep learning frameworks.\n\n- Although joint end-to-end training of branches certainly brings value compared to independent training, but the increased resource requirements may limits the applicability to large benchmarks such as ImageNet. While authors suggests a way to circumvent such limitations by training branches on separate GPUs but this would still impose limits on the number of branches as well as its ease of implementation.\n- Adding an overview figure of the architecture in the main paper (instead of supplementary) would be helpful.\n- Branched architecture serve as a regularization by distributing the gradients across different branches; however this also suggests that early layers on the network across branches would be independent. It would helpful if authors would consider an alternate archiecture where early layers may be shared across branches, suggesting a delayed branching, with fusion at the final layer.\n- One of the benefits of architectures such as DenseNet is their usefulness as a feature extractor (output of lower layers) which generalizes even to domain other that the dataset; the branched architecture could potentially diminish this benefit.\n\nMinor edits: Page 1. 'significantly match and improve' => 'either match or improve'\n\nAdditional notes:\n- It would interesting to compare this approach with a conditional training pipeline that sequentially adds branches, keeping the previous branches fixed. This may offer as a trade-off between benefits of joint training of branches vs being able to train deep models with several branches.\n"", 'This work proposed a reconfiguration of the existing state-of-the-art CNN model architectures including ResNet and DensNet. By introducing new branching architecture, coupled ensembles, they demonstrate that the model can achieve better performance in classification tasks compared with the single branch counterpart with same parameter budget. Additionally, they also show that the proposed ensemble method results in better performance than other ensemble methods (For example, ensemble over independently trained models)  not only in combined mode but also in individual branches.\n\nPaper Strengths:\n* The proposed coupled ensembles method truly show impressive results in classification benchmark (DenseNet-BC L = 118 k = 35 e = 3).\n* Detailed analysis on different ensemble fusion methods on both training time and testing time.\n* Simple but effective design to achieve a better result in testing time with same total parameter budget.\n\t\nPaper Weakness:\n* Some detail about different fusing method should be mentioned in the main paper instead of in the supplementary material.\n* In practice, how much more GPU memory is required to train the model with parallel branches (with same parameter budgets) because memory consumption is one of the main problems of networks with multiple branches.\n* At least one experiment should be carried out on a larger dataset such as ImageNet to further demonstrate the validity of the proposed method.\n* More analysis can be conducted on the training process of the model. Will it converge faster? What will be the total required training time to reach the same performance compared with single branch model with the same parameter budget?\n', 'Strengths:\n* Very simple approach, amounting to coupled training of ""e"" identical copies  of a chosen net architecture, whose predictions are fused during training. This forces the different model instances to become more complementary.\n* Perhaps counterintuitively, experiments also show that coupled ensembling leads to individual nets that perform better than those produced by separate training.\n* The practical advantages of the proposed approach are twofold:\n1. Given a fixed parameter budget, coupled ensembling leads to better accuracy than a single net or an ensemble of disjointly-trained nets.\n2. For the same accuracy, coupled ensembling yields significant parameter savings.\n\nWeaknesses:\n* Although results are very strong, the proposed models do not outperform the state-of-the-art, except for the models reported in Table 4, which however were obtained by *traditional* ensembling of coupled ensembles. \n* Coupled ensembling requires joint training of all nets in the ensemble and thus is limited by the size of the model that can be fit in memory. Conversely, traditional ensembling involves separate training of the different instances and this enables the learning of an arbitrary number of individual nets. \n* I am surprised by the results in Table 2, which suggest that the optimal number of nets in the ensemble is remarkably low (only 3!). It\'d be valuable to understand whether this kind of result holds for other network architectures or whether it is specific to this choice of net.\n* Strictly speaking it is correct to refer to the individual nets in the ensembles as ""branches"" and ""basic blocks."" Nevertheless, I find the use of these terms confusing in the context of the proposed approach, since they are commonly used to denote concepts different from those represented here.  I would recommend refraining from using these terms here.\n\nOverall, the paper provides limited technical novelty. Yet, it reveals some interesting empirical findings about the benefits of coordinated training of models in an ensemble.\n']","[60, 60, 50]","[80, 50, 75]","[""The sentiment score is 60 (positive) because the reviewer expresses overall positive sentiment towards the paper, highlighting its value to the research community, thorough experimentation, and clear writing. However, it's not extremely positive as the reviewer also points out some limitations and suggests improvements. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, balances positive and negative feedback, and offers constructive suggestions rather than harsh criticisms. The reviewer acknowledges the paper's strengths before discussing its weaknesses, and uses phrases like 'it would be helpful' when suggesting improvements, indicating a polite and considerate tone."", ""The sentiment score is 60 (positive) because the review starts by highlighting the strengths of the paper, noting its 'impressive results' and 'simple but effective design'. The reviewer acknowledges the paper's contributions and improvements over existing methods. However, it's not extremely positive as the reviewer also points out several weaknesses. The politeness score is 50 (somewhat polite) because the reviewer uses neutral, professional language throughout. They present both strengths and weaknesses in a balanced manner without using harsh or overly critical language. The reviewer offers constructive suggestions for improvement rather than outright criticism. The tone is respectful but not excessively formal or deferential."", ""The sentiment score is 50 (slightly positive) because the review begins by highlighting several strengths of the paper, including its simplicity, counterintuitive findings, and practical advantages. However, it also points out some weaknesses, creating a balanced view. The overall tone suggests the paper has merit despite limited technical novelty. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively. Phrases like 'I am surprised' and 'I would recommend' maintain a collegial tone. The reviewer also uses objective language to describe both strengths and weaknesses, avoiding harsh or dismissive statements.""]"
"['The paper tries to maintain the accuracy of 2bits network, while uses possibly less than 2bits weights.\n\n1.  The paper misses some more recent reference, e.g. [a,b]. The author should also have a discussion on them.\n\n2. Indeed, AlexNet is a good seedbed to test binary methods. However, it is more interesting and important to test on more advanced networks. So, I wish to see a section on testing with Resnet and GoogleNet.\n\nIndeed, the authors have commented: ""AlexNet with batch-normalization (AlexNet-BN) is the standard model ... acceptance that improvements made to accuracy transfer well to more modern architectures."" So, please show that.\n\n3. The paper wants to find a good trade-off on speed and accuracy. The authors have plotted such trade-off on space v.s. accuracy in Figure 3(b), then how about speed v.s. accuracy?\n\nMy concern is that one-bit system is already complicated to implement. Indeed, the authors have discussed their implementation in Section 3.3, so, how their method works in practice? One example is Section 4 in [Courbariaux et al. 2016].\n\n4. Is trade-off between 1 to 2 bits really important? \n\nCompared with 2bits or ternary network, the proposed method at most achieving (1.4/2) compression ratio and (2/1.4) speedup (based on their Table 1). Is such improvement really important?\n\nReference:\n[a]. Trained Ternary Quantization. ICLR 2017\n[b]. Extremely low bit neural network: Squeeze the last bit out with ADMM. arvix 2017', 'This paper suggests a method for varying the degree of quantization in a neural network during the forward propagation phase.\n\nThough this is an important direction to investigate, there are several issues:\n\n1. Comparison with previous results is misleading:\na.\t1-bit weights and floating point activations: Rastegari et al. got 56.8% accuracy on Alexnet, which is better than this paper 1.4bit result of 55.2%.\nb.\tHubara et al. got 51% results on 1-bit weights and 2-bit activations included also quantization first and last layer, in contrast to this paper. Therefore, it is not clear if there is a significant benefit in the proposed method which achieves 51.5% when decreasing the activation precision to 1.4bit. \n\nTherefore, it is not clear that the proposed methods improve over previous approaches.\n\n2. It is not clear to me: in which dimension of the tensors are we saving the scale factor? If it is per feature map, or neuron, this eliminates the main benefits of quantization: doing efficient binarized operations when doing Weight*activation during the forward pass?\n\n3. The review of the literature is inaccurate. For example, it is not true that Courbariaux et al. (2016) “further improved accuracy on small datasets”: the main novelty there was binarizing the activations (which typically decreased the accuracy). Also, it is not clear if the scale factors introduced by XNOR-Net indeed allowed ""a significant improvement over previous work"" in ImageNet (e.g., see DoReFA and Hubara et al. who got similar results using binarized weigths and activations on ImageNet without scale factors).  Lastly, the statement “Typical approaches include linearly placing the quantization points” is inaccurate: it was observed that logarithmic quantization works better in various cases. For example, see Miyashita, Lee and Murmann 2016, and Hubara et al.\n\n%%% After Author\'s Clarification %%%\nThis paper results seem more positive now, and I have therefore have increased my score, assuming the authors will revise the paper accordingly.\n\n', 'This paper presents an extension of binary networks, and the main idea is to use different bit rates for different layers so we can further reduce bitrate of the overall net, and achieve better performance (speed / memory). The paper addresses a real problem which is meaningful, and provides interesting insights, but it is more of an extension.\n\nThe description of the Heterogeneous Bitwidth Binarization algorithm is interesting and simple, and potentially can be practical, However it also adds more complication to real world implementations, and might not be an elegant enough approach for practical usages. \n\nExperiments wise, the paper has done solid experiments comparing with existing approaches and showed the gain. Results are promising.\n\nOverall, I am leaning towards a rejection mostly due to limited novelty. \n\n']","[-20, -50, -40]","[50, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's attempt to maintain accuracy with less than 2-bit weights, they express several concerns and suggest multiple improvements. The reviewer questions the importance of the trade-off between 1 to 2 bits and asks for more testing on advanced networks. However, the tone is not entirely negative, as they also provide constructive feedback. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, such as 'I wish to see' and 'please show that.' They also acknowledge the authors' comments and provide specific suggestions for improvement without using harsh or dismissive language. The review maintains a professional and constructive tone, even when expressing concerns or requesting additional work."", ""The sentiment score is -50 because the review starts with a positive note about the importance of the research direction, but then lists several significant issues with the paper. The reviewer points out misleading comparisons, unclear methodologies, and inaccuracies in the literature review. However, the final paragraph indicates a more positive view after the author's clarification, which slightly improves the overall sentiment. The politeness score is 20 because the reviewer uses professional and neutral language throughout, avoiding harsh criticism. They use phrases like 'it is not clear' and 'the review of the literature is inaccurate' rather than more confrontational language. The reviewer also acknowledges the importance of the research direction, which adds a polite tone to the critique."", ""The sentiment score is -40 because while the reviewer acknowledges some positive aspects of the paper (addressing a real problem, providing interesting insights, solid experiments), they ultimately lean towards rejection due to limited novelty. The overall tone is more negative than positive, but not extremely negative. The politeness score is 50 because the reviewer uses respectful and professional language throughout, acknowledging the paper's strengths before presenting criticisms. They avoid harsh or dismissive language, instead offering constructive feedback. The reviewer maintains a balanced and objective tone, which contributes to the politeness of the review.""]"
"['The paper makes a bold claim, that deep neural networks are robust to arbitrary level of noise. It also implies that this would be true for any type of noise, and support this later claim using experiments on CIFAR and MNIST with three noise types: (1) uniform label noise (2) non-uniform but image-independent label noise, which is named ""structured noise"", and (3) Samples from out-of-dataset classes. The experiments show robustness to these types of noise. \n\nReview: \nThe claim made by the paper is overly general, and in my own experience incorrect when considering real-world-noise. This is supported by the literature on ""data cleaning"" (partially by the authors), a procedure which is widely acknowledged as critical for good object recognition.  While it is true that some image-independent label noise can be alleviated in some datasets, incorrect labels in real world datasets can substantially harm classification accuracy.\n\nIt would be interesting to understand the source of the difference between the results in this paper and the more common results (where label noise damages recognition quality). The paper did not get a chance to test these differences, and I can only raise a few hypotheses. First, real-world noise depends on the image and classes in a more structured way. For instance, raters may confuse one bird species from a similar one, when the bird is photographed from a particular angle. This could be tested experimentally, for example by adding incorrect labels for close species using the CUB data for fine-grained bird species recognition.  Another possible reason is that classes in MNIST and CIFAR10 are already very distinctive, so are more robust to noise. Once again, it would be interesting for the paper to study why they achieve robustness to noise while the effect does not hold in general. \n\nWithout such an analysis, I feel the paper should not be accepted to ICLR because the way it states its claim may mislead readers. \n\nOther specific comments: \n-- Section 3.4 the experimental setup, should clearly state details of the optimization, architecture and hyper parameter search. For example, for Conv4, how many channels at each layer? how was the net initialized? which hyper parameters were tuned and with which values? were hyper parameters tuned on a separate validation set? How was the train/val/test split done, etc. These details are useful for judging technical correctness.\n-- Section 4, importance of large datasets. The recent paper by Chen et al (2017) would be relevant here.\n-- Figure 8 failed to show for me. \n-- Figure 9,10, need to specify which noise model was used.\n\n\n\n\n\n', 'The authors study the effect of label noise on classification tasks. They perform experiments of label noise in a uniform setting, structured setting as well provide some heuristics to mitigate the effect of label noise such as changing learning rate or batch size. \n\nAlthough, the observations are interesting, especially the one on MNIST where the network performs well even with correct labels slightly above chance, the overall contributions are incremental. Most of the observations of label noise such as training with structured noise, importance of larger datasets have already been archived in prior work such as in Sukhbataar et.al. (2014) and Van Horn et. al (2015). Agreed that the authors do a more detailed study on simple MNIST classification, but these insights are not transferable to more challenging domains. \n\nThe main limitation of the paper is proposing a principled way to mitigate noise as done in Sukhbataar et.al. (2014), or an actionable trade-off between data acquisition and training schedules. \n\nThe authors contend that the way they deal with noise (keeping number of training samples constant) is different from previous setting which use label flips. However, the previous settings can be reinterpreted in the authors setting. I found the formulation of the \\alpha to be non-intuitive and confusing at times. The graphs plot number of noisy labels per clean label so a alpha of 100 would imply 1 right label and 100 noisy labels for total 101 labels. In fact, this depends on the task at hand (for MNIST it is 11 clean labels for 101 labels). This can be improved to help readers understand better. \n\nThere are several unanswered questions as to how this observation transfers to a semi-supervised or unsupervised setting, and also devise architectures depending on the level of expected noise in the labels. \n\nOverall, I feel the paper is not up to mark and suggest the authors devote using these insights in a more actionable setting. \nMissing citation: ""Training Deep Neural Networks on Noisy Labels with Bootstrapping"", Reed et al.\n', 'The problem the authors are tackling is extremely relevant to the research community. The paper is well written with considerable number of experiments. While a few conclusions are made in the paper a few things are missing to make even broader conclusions. I think adding those experiments will make the paper stronger! \n\n1. Annotation noise is one of the biggest bottleneck while collecting fully supervised datasets. This noise is mainly driven by lack of clear definitions for each concept (fine-grained, large label dictionary etc.). It would be good to add such type of noise to the datasets and see how the networks perform.\n2. While it is interesting to see large capacity networks more resilient to noise I think the paper spends more effort and time on small datasets and smaller models even in the convolutional space. It would be great to add more experiments on the state of the art residual networks and large datasets like ImageNet.\n3. Because the analysis is very empirical and authors have a hypothesis that the batch size is effectively smaller when there are large batches with noisy examples it would be good to add some analysis on the gradients to throw more light and make it less empirical.  Batch size and learning rate analysis was very informative but should be done on ResNets and larger datasets to make the paper strong and provide value to the research community.\n\nOverall, with these key things missing the paper falls a bit short making it more suitable for a re submission with further experiments.']","[-60, -60, 20]","[20, 20, 60]","[""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's claims, stating they are 'overly general' and 'incorrect when considering real-world-noise'. The reviewer recommends against acceptance to ICLR, which strongly indicates a negative sentiment. However, the score is not at the extreme negative end because the reviewer does suggest ways to improve the paper and acknowledges some interesting aspects of the work. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and constructive manner. They use phrases like 'It would be interesting to understand' and 'I feel the paper should not be accepted' rather than using harsh or dismissive language. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism. However, the score is only slightly positive as the overall tone is more neutral than overtly polite."", ""The sentiment score is -60 because the reviewer expresses several criticisms and suggests the paper is not up to mark. They state the contributions are incremental, insights are not transferable, and there are unanswered questions. The overall tone is negative, but not extremely so, as they do acknowledge some interesting observations. The politeness score is 20 because while the reviewer is critical, they use professional and respectful language throughout. They use phrases like 'I feel' and 'suggest' rather than harsh commands, and acknowledge positive aspects before critiquing. The tone is direct but not rude, maintaining a level of politeness typical in academic reviews."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the relevance of the problem and the quality of the writing and experiments. However, they also point out several missing elements and suggest that the paper falls short, recommending resubmission with further experiments. This mix of positive and critical feedback results in a mildly positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They use phrases like 'it would be good to add' and 'it would be great to add' which are polite ways of suggesting improvements. The overall tone is professional and supportive, even while pointing out areas for improvement.""]"
"[""re. Introduction, page 2: Briefly explain here how SAB is different from regular Attention?\n\nGood paper. There's not that much discussion of the proposed SAB compared to regular Attention, perhaps that could be expanded. Also, I suggest summarizing the experimental findings in the Conclusion."", 'The paper proposes sparse attentive backtracking, essentially an attention mechanism that performs truncated BPTT around a subset of the selected states.\n\nThe early claims regarding biological plausibility seem stretched, at least when applying to this work. The ""waiting for life to end to learn"" and student study / test analogies were not helpful from an understanding point of view and indeed raised more questions than insight. The latter hippocampal discussion was at least more grounded.\n\nWhile a strong motivator for this work would be in allowing for higher efficiency on longer BPTT sequences, potentially capturing longer term dependencies, this aspect was not explored to this reviewer\'s understanding. To ensure clarity, in the character level PTB or Text8 examples, SAB\'s previous attention was limited to sequences of T = 100 or 180 respectively?\nLimiting the truncation to values below the sequence length for the LSTM baselines also appears strange given the standard within the literature is setting sequence length equal to BPTT length. I presume this was done to keep the number of optimizer updates equal?\nAnother broader question is whether longer term dependencies could be caught at all given the model doesn\'t feature ""exploration"" in the reinforcement learning sense, especially for non-trivial longer term dependencies.\n\nWhen noting the speed of generating a sparsely sourced summary vector (equation 3), it is worth pointing out that weighted summation over vectors in traditional attention is not a limiting factor as it\'s a very rapid element-wise only operation over already computed states.\n\nFor the experiments, I was looking for comparisons to attention over the ""LSTM (full BPTT)"" window. This experiment would provide an upper bound and an understanding of how much of SAB\'s improvement may be as a result of simply adding attention to the underlying LSTM models. Even a simpler and fast (cuDNN compatible) attention mechanism such as [a single cuDNN LSTM layer over the input, an attentional mechanism over the results of the first layer (masked to avoid observing timesteps from the future), summed, and then passed into a softmax] would be informative.\n\nFinally, whilst not a deal breaker for introducing new techniques, stronger LSTM baselines help to further underline the efficacy of the technique. For sequential MNIST, a relatively small dataset, previous papers have LSTM models that achieve 98.2% test accuracy (Arjovsky et al, https://arxiv.org/abs/1511.06464) and the IRNN example included as part of the Keras framework achieves 93% out of the box.\n\nNoting similarities to the Transformer architecture and other similar architectures would also be useful. Both are using attention to minimize the length of a gradient\'s path, though in Transformers it eliminates the RNN entirely. If a Transformer network performed a k=5 convolution or limited RNN run to produce the initial inputs to the Transformer, it would share many similarities to SAB, though without the sparsity.', 'This work proposes Sparse Attentive Backtracking, an attention-based approach to incorporating long-range dependencies into RNNs. Through time, a “macrostate” of previous hidden states is accumulated. An attention mechanism is used to select the states within the macro-state most relevant to the current timestep. A weighted combination of these previous states is then added to the hidden state as computed in the ordinary way. This construction allows gradients to flow backwards quickly across longer time scales via the macrostate. The proposed architecture is compared against LSTMs trained with both BPTT and truncated BPTT.\n\nPros:\n- Novel combination of recurrent skip connections with attention.\n- The paper is overall written clearly and structured well.\n  \n\nCons:\n- The proposed algorithm is compared against TBPTT but it is unclear the extent to which it is solving the same computational issues TBPTT is designed to solve.\n- Design decisions, particularly regarding the attention computation, are not fully explained.\n\nSAB, like TBPTT, allows for more frequent updates to the parameters. However, unlike TBPTT, activations for previous timesteps (even those far in the past) need to be maintained since gradients could flow backwards to them via the macrostate. Thus SAB seems to have higher memory requirements than TBPTT. The empirical results demonstrate that SAB performs slightly better than TBPTT for most tasks in terms of accuracy/CE, but there is no mention of comparing the memory requirements of each. Results demonstrating also whether SAB trains more quickly than the LSTM baselines would be helpful.\n\nThe proposed affine form of attention does not appear to actually represent the salience of a microstate and a given time. The second term of the RHS of equation 1 (w_2^T \\hat{h}^{(t)}) is canceled out in the subtraction in equation 2, since this term is constant for all i. Thus the attention weights for a given microstate are constant throughout time, which seems undesirable.\n\nThe related work discusses skip connections in the context of convolutional nets, but doesn’t mention previous works incorporating skip connections into RNN architectures, such as [1], [2], or [3].\n\nOverall, the combination of recurrent skip connections and attention appears to be novel, but experimental comparisons to other skip connection RNN architectures are missing and thus it is not clear how this work is positioned relative to previous related work. \n\n[1] Lin, Tsungnan, et al. ""Learning long-term dependencies in NARX recurrent neural networks."" IEEE Transactions on Neural Networks 7.6 (1996): 1329-1338.\n[2] Koutnik, Jan, et al. ""A clockwork rnn."" International Conference on Machine Learning. 2014.\n[3] Chang, Shiyu, et al. ""Dilated recurrent neural networks."" Advances in Neural Information Processing Systems. 2017.\n\nEDIT: I have read the updated paper and the author\'s rebuttal. I am satisfied with the update to the attention weight formulation. Overall, I still feel that the proposed SAB approach represents a change to the model structure via skip connections. Therefore SAB should also be compared against other approaches that use skip connections, and not just BPTT / TBPTT, which operate on the standard LSTM. Thus to me the experiments are still lacking. However, I think the approach is quite interesting and as such I am revising my rating from 4 to 5.']","[50, -30, 20]","[75, 20, 60]","[""The sentiment score is 50 (mildly positive) because the review starts with 'Good paper,' indicating overall approval, but also suggests areas for improvement. The politeness score is 75 (quite polite) as the reviewer uses respectful language, offers constructive feedback, and phrases suggestions politely ('I suggest'). The review is brief but maintains a professional and supportive tone throughout."", ""The sentiment score is -30 because the review is generally critical, pointing out several issues with the paper, such as stretched claims, unclear analogies, and limitations in the experiments. However, it's not entirely negative as it acknowledges some strengths and provides constructive feedback. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout, using phrases like 'to ensure clarity' and 'it is worth pointing out'. The reviewer also offers suggestions for improvement, which is a polite way to address shortcomings. The language is not overly formal or deferential, but it avoids rudeness or harsh criticism."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty of the approach and the clear writing, but also points out several cons and areas for improvement. The overall tone is constructive, with the reviewer increasing their rating from 4 to 5 after reading updates. The politeness score is moderately high (60) as the reviewer uses professional and respectful language throughout, offering balanced feedback and specific suggestions without harsh criticism. The reviewer acknowledges the authors' efforts in addressing previous concerns, which contributes to the polite tone.""]"
"['Recent work on incorporating prior knowledge about invariances into neural networks suggests that the feature dimension in a stack of feature maps has some kind of group or manifold structure, similar to how the spatial axes form a plane. This paper proposes a method to uncover this structure from the filters of a trained ConvNet. The method uses an InfoGAN to learn the distribution of filters. By varying the latent variables of the GAN, one can traverse the manifold of filters. The effect of moving over the manifold can be visualized by optimizing an input image to produce the same activation profile when using a perturbed synthesized filter as when using an unperturbed synthesized filter.\n\nThe idea of empirically studying the manifold / topological / group structure in the space of filters is interesting. A priori, using a GAN to model a relatively small number of filters seems problematic due to overfitting, but the authors show that their InfoGAN approach seems to work well.\n\nMy main concerns are:\n\nControls\nTo generate the visualizations, two coordinates in the latent space are varied, and for each variation, a figure is produced. To figure out if the GAN is adding anything, it would be nice to see what would happen if you varied individual coordinates in the filter space (""x-space"" of the GAN), or varied the magnitude of filters or filter planes. Since the visualizations are as much a function of the previous layers as they are a function of the filters in layer l which are modelled by the GAN, I would expect to see similar plots for these baselines.\n\nLack of new Insights\nThe visualizations produced in this paper are interesting to look at, but it is not clear what they tell us, other than ""something non-trivial is going on in these networks"". In fact, it is not even clear that the transformations being visualized are indeed non-linear in pixel space (note that even a 2D diffeomorphism, which is a non-linear map on R^2, is a linear operator on the space of *functions* on R^2, i.e. on the space of images). In any case, no attempt is made to analyze the results, or provide new insights into the computations performed by a trained ConvNet.\n\nInterpretation\nThis is a minor point, but I would not say (as the paper does) that the method captures the invariances learned by the model, but rather that it aims to show the variability captured by the model. A ReLU net is only invariant to changes that are mapped to zero by the ReLU, or that end up in the kernel of one of the linear layers. The presented method does not consider this and hence does not analyze invariances.\n\nMinor issues:\n- In the last equation on page 2, the right-hand side is missing a ""min max"".', ""This paper wants to probe the non-linear invariances learnt by CNNs. This is attempted by selecting a particular layer, and modelling the space of filters that result in activations that are indistinguishable from activations generated by the real filters (using a GAN). For a GAN noise vector a plausible filter set is created, and for a data sample a set of plausible activations are computed. If the noise vector is perturbed and a new plausible filter set is created, the input data can be optimised to find the input that produces the same set of activations. The claim is that the found input represents the non-linear transformations that the layer is invariant to.\n\nThis is a really interesting perspective on probing invariances and should be explored more. I am not convinced that this particular method is showing much information or highlighting anything particularly interesting, but could be refined in the future to do so.\n\nIt seems that the generated images are not actually plausible images at all and so not many conclusions can be drawn from this method. Instead of performing the optimisation to find x' have you tried visualising the real data sample that gives the closest activations?\n\nI think you may want to consider minimising ||a(x'|z) - a(x|z_k)|| instead to show that moving from x -> x' is the same as is invariant under the transformation z -> z_k  (and thus the corresponding movement in filter space). This (the space between x and x') I think is more interpretable as the invariance corresponding to the space between z and z_k. Have you tried that?\n\nThere is no notion of class invariance, so the GAN can find the space of filters that transform layer inputs into other classes, which may not be desirable. Have you tried conditioning the GAN on class?\n\nOverall I think this method is inventive and shows promise for probing invariances. I'm not convinced the current incarnation is showing anything insightful or useful. It also should be shown on more than a single dataset and for a single network, at the moment this is more of a workshop level paper in terms of breadth and depth of results."", 'The paper proposes an approach to learning a distribution over filters of a CNN. The method is based on a adversarial training: the generator produces filters, and the discriminator aims to distinguish the activation maps produced by real filters from those produced by the generated ones. \n\nPros:\n1) The general task of learning distributions over network weights is interesting\n2) To my knowledge, the proposed approach is new\n\nCons:\n1) Experimental evaluation is very substandard. The experiments on invariances seem to be the highlight of the paper, but they basically do not tell me anything. \n - Figures 3 and 4 take 2 pages, but what should one see there?\n - There are no quantitative results. Could there be a way to measure the invariances?\n - Can the results be applied to some practical task? Why are the results interesting and/or useful?\n2) The experiments are restricted to a single dataset - MNIST.  The authors mention that “the test accuracy obtained by following the above procedure is of 0.982, against a test accuracy of 0.971 for the real CNN” - these are very poor accuracies for MNIST. So even the MNIST results do not seem convincing.\n3) Presentation is suboptimal, and many details are missing. For instance, architectures of networks are not provided.\n \nTo conclude, while the general direction is interesting and the proposed method might work, the experimental evaluation is very poor, and the paper absolutely cannot be accepted for publication.']","[-20, -20, -70]","[60, 60, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting idea and that the approach seems to work well, they express several major concerns about the lack of controls, new insights, and interpretation. The overall tone suggests the reviewer is not fully convinced by the paper's contributions. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects before raising concerns, and framing criticisms as suggestions (e.g. 'it would be nice to see'). They also use phrases like 'My main concerns are' rather than more aggressive wording. The review maintains a professional and constructive tone even while pointing out significant issues."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting' and 'inventive', they express significant doubts about the effectiveness and insights of the current method. Phrases like 'I am not convinced' and 'not showing anything insightful or useful' indicate a generally critical stance. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their concerns as suggestions or questions rather than harsh criticisms. They also acknowledge the potential of the method, calling it 'inventive' and saying it 'shows promise'. The reviewer maintains a professional tone, avoiding personal attacks or overly negative language, which contributes to the politeness score."", ""The sentiment score is -70 because the review is predominantly negative. While the reviewer acknowledges some positive aspects ('general task is interesting', 'approach is new'), the majority of the review focuses on significant criticisms. The reviewer states that the experimental evaluation is 'very substandard', the results are poor, and concludes that the paper 'absolutely cannot be accepted for publication'. These strong negative statements outweigh the few positive comments. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use neutral language to describe the issues ('suboptimal', 'missing') rather than harsh or rude terms. The reviewer also acknowledges some positive aspects before diving into criticisms, which is a polite approach. However, the score is not higher due to the bluntness of some statements, particularly the concluding remark about the paper being unacceptable for publication.""]"
"['Stochastic Sign Descent (SSD) and Stochastic Variance Adapted Gradient (SVAG) are inspired by ADAM and studied in this paper, together with momentum terms. \n\nAnalysis showed that SSD should work better than usual SGD when the Hessian of training loss is highly diagonal dominant.  It is intrigued to observe that for MNIST and CIFAR10, SSD with momentum champions with better efficiency than ADAM, SGD and SVAG, while on the other hand, in CIFAR100, momentum-SVAG and SGD beat SSD and ADAM. Does it suggest the Hessians associated with MNIST and CIFAR10 training loss more diagonally dominant? \n\nThere are other adaptive step-sizes such as Barzilai-Borwein (BB) Step Sizes introduced to machine learning by Tan et al. NIPS 2016. Is there any connections between variance adaptation here and BB step size? ', 'Summary: \nThe paper is trying to improve Adam based on variance adaption with momentum. Two algorithms are proposed, M-SSD (Stochastic Sign Descent with Momentum) and M-SVAG (Stochastic Variance-Adapted Gradient with Momentum) to solve finite sum minimization problem. The convergence analysis is provided for SVAG for strongly convex case. Numerical experiments are provided for some standard neural network structures with three common datasets MNIST, CIFAR10 and CIFAR100 compared the performance of M-SSD and M-SVAG to two existing algorithms: SGD momentum and Adam. \n \nComments:\nPage 4, line 5: You should define \\nu clearly.\n\nTheorem 1: In the strongly convex case, assumption E ||g_t ||^2 \\leq G^2 (if G is a constant) is too strong. In this case, G could be equal to infinity. If G is not infinity, you already assume that your algorithm converges, that is the reason why this assumption is not so good for strongly convex. If G is infinity (this is really possible for strongly convex), your proof would get a trouble as eq. (40) is not valid anymore.\n\nAlso, to compute \\gamma_{t,i}, it requires to compute \\nabla f_{t,i}, which is full gradient. By doing this, the computational cost should add the dependence of M, which is very large as you mentioned in the introduction. According to your rate O(1/t), the complexity is worse than that of gradient descent and SGD as well. \n\nAs I understand, there is no theoretical results for M-SSG and M-SVAG, but only the result for SVAG with exact \\eta_i^2 in the strongly convex case. Also, theoretical results are not strong enough. Hence, the experiments need to make more convincingly, at least for some different complicated architecture of deep neural network. As I see, in some dataset, Adam performs better than M-SSD, some another dataset, Adam performs better than M-SVAG. Same situation for M-SGD. My question is that: When should we use M-SSD or M-SVAG? For a given dataset, why should we not use Adam or M-SGD (or other existing algorithms such as Adagrad, RMSprop), but your algorithms? \n\nYou should do more experiments to various dataset and architectures to be more convincing since theoretical results are not strong enough. Would you think to try to use VGG or ResNet to ImageNet?\n\nI like the idea of the paper but I would love if the author(s) could improve more theoretical results to convince people. Otherwise, the results in this paper could not be considered as good enough. At this moment, I think the paper is still not ready for the publication. \n\nMinor comments:\nPage 2, in eq. (6): You should mention that “1” is a vector.\nPage 4, line 4: Q in R^{d} => Q in R^{d x d}\nPage 6, Theorem 1: You should define the finite sum optimization problem with f since you have not used it before.\nPage 6, Theorem 1: You should use another notation for “\\mu”-strongly convex parameter since you have another “\\mu”-momentum parameter in section 3.4\nPage 4, Page 7: Be careful with the case when c = 0 (page 4) and mu = 1 (page 7-8) with dividing by 0. \n', ""The paper presents some analysis of the scale-invariance and the particular shape of the learning rate used in Adam. The paper argues that Adam's update is a combination of a sign-update and a variance-based learning rate. Some analysis is provided on these two aspects.\n\nAfter spending a sizeable amount of time with this paper, I am not sure what are its novel contributions and why it should be published in a scientific conference. The paper contains so many approximations, simplifications, and assumptions that make any presented result extremely weak.\n\nMore in details, the analysis of the sign is done in the case of quadratic functions of Gaussian variables. The result is mildly interesting, but I fail to see how this would give us a hint of what is happening during the minimization of the non-convex objectives for training deep networks.\nMoreover, the analysis of sign based updates has been already carried over using the Polyak-Łojasiewicz assumption in Karimi et al. ECML-PKDD 2016, that is strictly more general than any quadratic approximation.\n\nThe similarity between the ``optimal'' variance-based learning rate and the one of Adam hinges again on the fact that the noise is Gaussian. As the authors admit, Schaul et al. (2013) already derived similar updates. Also, Theorem 1 recover the usual rate of convergence for strongly convex function: How is this theorem supposed to support the fact that variance-adapted learning rates are a better idea than the usual updates?\nMoreover, the proof of Theorem 1 hinges on the fact that E[||g_t||^2]\\leq G^2. Clearly, this is not possible in general for a strongly convex function. The proof might still go through, but it needs to be fixed using the fact that the updates always decrease the function.\n\nOverall, if we are considering only the convex case, Adam is clearly sub-optimal from all the points of view and better algorithms with stronger guarantees can be used. Indeed, the fact that non-convexity is never discussed is particularly alarming. It is also indicative that none of the work for minimization of finite sums are cited or discussed, e.g. the variance reduced methods immediately come to mind.\n\nRegarding the experiments, the parameters are chosen to have the best test accuracy, mixing the machine learning problem with the optimization one: it is well-known and easy to prove that a worst optimizer can give rise to better test errors. Hence, the empirical results cannot be used to support any of the proposed interpretations nor the new optimization algorithms.\n\nTo summarize, I do not think the contributions of this paper are enough to be published in ICLR.""]","[50, -50, -80]","[75, 20, -20]","[""The sentiment score is 50 (slightly positive) because the reviewer shows interest in the paper's findings and asks thoughtful questions, indicating engagement with the material. They use phrases like 'It is intrigued to observe' and ask about potential implications of the results, suggesting a positive reception. However, the review doesn't contain overtly enthusiastic language, keeping it from scoring higher. The politeness score is 75 (quite polite) because the reviewer maintains a professional and respectful tone throughout. They ask questions in a non-confrontational manner and use polite phrasing like 'Is there any connections' instead of demanding answers. The language is consistently courteous without being overly formal or deferential."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's theoretical results and experimental validation. They state that the paper is 'not ready for publication' and that the results are 'not strong enough', indicating a generally negative view. However, they do mention liking the idea, which prevents the score from being even lower. The politeness score is 20 because the reviewer uses generally respectful language and offers constructive criticism. They use phrases like 'I like the idea' and 'I would love if the author(s) could improve', which are polite. However, the directness of some criticisms and the lack of more explicitly polite language keeps the score from being higher."", ""The sentiment score is -80 because the reviewer expresses strong negative opinions about the paper's contributions, novelty, and suitability for publication. They use phrases like 'I am not sure what are its novel contributions', 'any presented result extremely weak', and 'I do not think the contributions of this paper are enough to be published'. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism without much softening language. They use direct statements like 'Clearly, this is not possible in general' and 'it is well-known and easy to prove that a worst optimizer can give rise to better test errors', which come across as somewhat dismissive. However, they do not use overtly rude language, keeping the score from being extremely negative.""]"
"['The paper presents interesting algorithms for minimizing softmax with many classes. The objective function is a multi-class classification problem (using softmax loss) and with linear model. The main idea is to rewrite the obj as double-sum using the dual formulation and then apply SGD to solve it. At each iteration, SGD samples a subset of training samples and labels. The main contribution of this paper is: 1) proposing a U-max trick to improve the numerical stability and 2) proposing an implicit SGD approach. It seems the implicit SGD approach is better in the experimental comparisons. \n\nI found the paper quite interesting, but meanwhile I have the following comments and questions: \n\n- As pointed out by the authors, the idea of this formulation and doubly SGD is not new. (Raman et al, 2016) has used a similar trick to derive the double-sum formulation and solved it by doubly SGD. The authors claim that  the algorithm in (Raman et al) has an O(NKD) cost for updating u at the end of each epoch. However, since each epoch requires at least O(NKD) time anyway (sometimes larger, as in Proposition 2), is another O(NKD) a significant bottleneck? Also, since the formulation is similar to (Raman et al., 2016), a comparison is needed. \n\n- I\'m confused by Proposition 1 and 2. In appendix E.1, the formulation of the update is derived, but why we need Newton to get log(1/epsilon) time complexity? I think most first order methods instead of Newton will have linear converge (log(1/epsilon) time)? Also, I guess we are assuming the obj is strongly convex?\n\n- The step size is selected in one dataset and used for all others. This might lead to divergence of other algorithms, since usually step size depends on data. As we can see, OVE, NCE and IS diverges on Wiki-small, which may be fixed if the step size is chosen for each data (in practice we can choose using subsamples for each data). \n\n- All the comparisons are based on ""epochs"", but the competing algorithms are quite different and can have very different running time for each epoch. For example, implicit SGD has another iterative solver for each update. Therefore, the timing comparison is needed in this paper to justify that implicit SGD is faster. \n\n- The claim that ""implicit SGD never overshoots the optimum"" needs more supports. Is it proved in some previous papers? \n\n- The presentation can be improved. I think it will be helpful to state the algorithms explicitly in the main paper.', 'The problem of numerical instability in applying SGD to soft-max minimization is the motivation. It would have been helpful if the author(s) could have made a formal statement. \nSince the main contributions are two algorithms for stable SGD it is not clear how one can formally say that they are stable. For this a formal problem statement is necessary. The discussion around eq (7) is helpful but is intuitive and it is difficult to get a formal problem which we can use later to examine the proposed algorithms.\n\nThe proposed algorithms are variants of SGD but it is not clear why they should converge faster than existing strategies.\nSome parts of the text are badly written, see for example the following line(see paragraph before Sec 3)\n\n""Since the converge of SGD is\ninversely proportional to the magnitude of its gradients (Lacoste-Julien et al., 2012), we expect the\nformulation to converge faster.""\n \nwhich could have shed more light on the matter. \n\nThe title is also misleading in using the word ""exact"". I have understand it correct the proposed SGD method solves the optimization problem to an additive error.\n\nIn summary the algorithms are novel variants of SGD but the associated claims of numerical stability and speed of convergence vis-a-vis existing methods are missing. The choice of word exact is also not clear.\n', 'The paper develops an interesting approach for solving multi-class classification with softmax loss.\n\nThe key idea is to reformulate the problem as a convex minimization of a ""double-sum"" structure via a simple conjugation trick.  SGD is applied to the reformulation: in each step samples a subset of the training samples and labels, which appear both in the double sum.  The main contributions of this paper are: ""U-max"" idea (for numerical stability reasons) and an """"proposing an ""implicit SGD"" idea.\n\nUnlike the first review, I see what the term ""exact"" in the title is supposed to mean. I believe this was explained in the paper. I agree with the second reviewer that the approach is interesting. However, I also agree with the criticism (double sum formulations exist in the literature; comments about experiments); and will not repeat it here. I will stress though that the statement about Newton in the paper is not justified. Newton method does not converge globally with linear rate. Cubic regularisation is needed for global convergence. Local rate is quadratic.  \n\nI believe the paper could warrant acceptance if all criticism raised by reviewer 2 is addressed.\n\nI apologise for short and late review: I got access to the paper only after the original review deadline.']","[20, -50, 50]","[60, 0, 80]","[""The sentiment score is slightly positive (20) because the reviewer starts by calling the paper 'interesting' and acknowledges its contributions. However, they also raise several concerns and questions, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the paper's merits. They use phrases like 'I found the paper quite interesting' and 'I'm confused by' rather than making blunt criticisms. The reviewer also offers constructive feedback for improvement, which is a polite approach to peer review."", ""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper such as lack of formal problem statement, unclear convergence claims, and misleading title. However, it's not entirely negative as it acknowledges the algorithms as novel variants of SGD. The politeness score is 0 (neutral) because the reviewer uses direct language without being overtly polite or rude. They state criticisms plainly (e.g., 'Some parts of the text are badly written') but don't use harsh or insulting language. The review focuses on the content rather than personal comments about the authors."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting approach and potential for acceptance, while also pointing out some criticisms. The reviewer sees value in the work but suggests improvements are needed. The politeness score is 80 (quite polite) due to the respectful tone throughout, the use of phrases like 'I believe' and 'I apologise', and the constructive nature of the feedback. The reviewer also acknowledges other reviewers' points without being dismissive, showing collegiality. The language is professional and courteous throughout, even when providing critical feedback.""]"
"['The paper proposes an image segmentation method which iteratively refines the semantic segmentation mask obtained from a deep net. To this end the authors investigate a denoising auto-encoder (DAE). Its purpose is to provide a semantic segmentation which improves upon its input in terms of the log-likelihood.\n\nMore specifically, the authors `propose to condition the autoencoder with an additional input’ (page 1). To this end they use features obtained from the deep net. Instead of training the DAE with ground truth y, the authors found usage of the deep net prediction to yield better results.\n\nThe proposed approach is evaluated on the CamVid dataset.\n\nSummary:\n——\nI think the paper discusses a very interesting topic and presents an elegant approach. A few points are missing which would provide significantly more value to a reader. Specifically, an evaluation on the classical Pascal VOC dataset, details regarding the training protocol of the baseline (which are omitted right now), an assessment regarding stability of the proposed approach (not discussed right now), and a clear focus of the paper on segmentation or conditioning. See comments below for details and other points.\n\nComments:\n——\n1. When training the DAE, a combination of squared loss and categorical cross-entropy loss is used. What’s the effect of the squared error loss and would the categorical cross-entropy on its own be sufficient? This question remains open when reading the submission.\n\n2. The proposed approach is evaluated on the CamVid dataset which is used less compared to the standard and larger Pascal VOC dataset. I conjecture that the proposed approach wouldn’t work too well on Pascal VOC. On Pascal VOC, images are distinctly different from each other whereas subsequent frames are similar in CamVid, i.e., the road is always located at the bottom center of the image. The proposed architecture is able to take advantage of this dataset bias, but would fail to do so on Pascal VOC, which has a much more intricate bias. It would be great if the authors could check this hypothesis and report quantitative results similar to Tab. 1 and Fig. 4 for Pascal VOC.\n\n3. The authors mention a grid-search for the stepsize and the number of iterations. What values were selected in the end on the CamVid and hopefully the Pascal VOC dataset?\n\n4. Was the dense CRF applied out of the box, or were its parameters adjusted for good performance on the CamVid validation dataset? While parameters such as the number of iterations and epsilon are tuned for the proposed approach on the CamVid validation set, the submission doesn’t specify whether a similar procedure was performed for the CRF baseline.\n\n5. Fig. 4 seems to indicate that the proposed approach doesn’t converge. Hence an appropriate stepsize and a reasonable number of iterations need to be chosen on a validation set. Choosing those parameters guarantees that the method performs well on average, but individual results could potentially be entirely wrong, particularly if large step sizes are chosen. I suspect this effect to be more pronounced on the Pascal VOC dataset (hence my conjecture in point 2). To further investigate this property, as a reader, I’d be curious to get to know the standard deviation/variance of the accuracy in addition to the mean IoU. Again, it would be great if the authors could check this hypothesis and report those results.\n\n6. I find the experimental section to be slightly disconnected from the initial description. Specifically, the paper `proposes to condition the autoencoder with an additional input’ (page 1). No experiments are conducted to validate this proposal. Hence the main focus of the paper (image segmentation or DAE conditioning) remains vague. If the authors choose to focus on image segmentation, a comparison to state-of-the-art should be provided on classical datasets such as Pascal VOC, if DAE conditioning is the focus, some experiments in this direction should be included in addition to the Pascal VOC results.\n\nMinor comment:\n——\n- I find it surprising that the authors choose not to cite some related work on combining deep nets with structured prediction.', 'This paper proposes an iterative procedure on top of a standard image semantic segmentation networks. \n\nThe submission proposes a change to the training procedure of stacking a denoising auto-encoder for image segmentation. The technical contribution of this paper is small. The paper aims to answer a single question: When using a DAE network on top of a segmentation network output, should one condition on the predicted, or the ground truth segmentation? (why not on both?) The answer is conditioning on the predicted image for a second round of inference is a bit better. The method also performs a bit better (no statistical significance tests) than other post-processing methods (Dense-CRF, CRF-RNNs)\n\nExperimental results are available only on a small dataset and for two different networks. This may be sufficient for a first proof-of-concept but a comparison against standard benchmark methods and datasets for semantic segmentation is missing. It is unlikely that in the current state of this submission is a contribution to image segmentation, evidence is weak and several improvements are suggested.\n\n- The experimental evidence is insufficient. The improvements are small, statistical tests are not available. The CamVid dataset is the smallest of the image segmentation datasets used these days, more compelling would be MSCOCO or Cityscapes, better most of them. The question whether this network effect is tied to small-dataset and low-resolution is not answered. Will a similar effect be observed when compared to networks trained on way more data (e.g., CityScapes)? \n- The most important baseline is missing: auto-context [Tu08]. Training the same network the DAE uses in an auto-context way. That is, take the output of the first model, then train another network using both input and prediction again for semantic segmentation (and not Eq.3). This is easy to do, practically almost always achieves better performance and I would assume the resulting network is faster and performs similar to the method presented in this submission on (guessing, I have not tried). In any case, to me this is the most obvious baseline. \n- I am in favour of probabilistic methods, but the availability of an approximation of p(y) (or the nearest mode) is not used (as is most often the case).\n- Runtimes are absent. This is a practical consideration which is important especially if there is little technological improvement. The DAE model of this submission compares to simple filtering methods as Krähenbühl&Koltun DenseCRF which are fast and performance results are comparable. The question wether this is practically relevant is missing, judging from the construction I guess this does not fare well. Also training time is significantly more, please comment.\n- The related work is very well written, thanks. This proposal is conceptually very similar to auto-context [Tu08] and this reference missing (this is also the most important baseline)\n\n[Tu08] Tu, “Auto-context and its application to high-level vision tasks”, CVPR 2008\n\n\n', ""I am a returning reviewer for this paper, from a previous conference. Much of the paper remains unchanged from the time of my previous review. I have revised my review according to the updates in the paper:\n\nSummary of the paper:\nThis work proposes a neural network based alternative to standard CRF post-processing techniques that are generally used on top semantic segmentation CNNs. As an alternative to CRF, this work proposes to iteratively refine the predicted segmentation with a denoising auto encoder (DAE). Results on CamVid semantic segmentation dataset showed better improvements over base CNN predictions in comparison to popular DenseCRF technique.\n\n\nPaper Strengths:\n- A neat technique for incorporating CRF-like pixel label relations into semantic segmentation via neural networks (auto encoders).\n- Promising results on CamVid segmentation dataset with reliable improvements over baseline techniques and minor improvements when used in conjunction with recent models.\n\n\nMajor Weaknesses:\nI have two main concerns for this work:\n- One is related to the novelty as the existing work of Xie et al. ECCV'16 also proposed similar technique with very similar aim.  I think, conceptual or empirical comparisons are required to assess the importance of the proposed approach with respect to existing ones. Mere citation and short discussion is not enough. Moreover, Xie et al. seem to have demonstrated their technique on two different tasks and on three different datasets.\n- Another concern is related to experiments. Authors experimented with only one dataset and with one problem. But, I would either expect some demonstration of generality (more datasets or tasks) or strong empirical performance (state-of-the-art on CamVid) to assess the empirical usefulness with respect to existing techniques. Both of these aspects are missing in experiments. \n\n\nMinor Weaknesses:\n- Negligible improvements with respect to CRF techniques on modern deep architectures.\n- Runtime comparison is missing with respect to baseline techniques. Applying the proposed DAE 40-50 times seems very time consuming for each image.\n- By back-propagating through CRF-like techniques [Zheng et al. ICCV'15, Gadde et al. ECCV'16, Chandra et al. ECCV'16 etc.], one could refine the base segmentation CNN as well. It seems this is also possible with the proposed architecture. Is that correct? Or, are there any problems with the end-to-end fine-tuning as the input distribution to DAE constantly changes? Did authors try this?\n\n\nSuggestions:\n- Only Gaussian noise corruption is used for training DAE. Did authors experiment with any other noise types? Probably, more structured noise would help in learning better contextual relations across pixel labels?\n\nClarifications:\nWhat is the motivation to add Euclidean loss to the standard cross-entropy loss for segmentation in Eq-3?\n\nReview summary:\nThe use of denoising auto encoders (DAEs) for capturing pixel label relations and then using them to iteratively refine the segmentation predictions is interesting. But, incomplete comparisons with similar existing work and limited experiments makes this a weak paper.""]","[50, -50, -50]","[75, 20, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer states the paper discusses 'a very interesting topic and presents an elegant approach', but also notes several missing elements that would provide 'significantly more value'. The overall tone is constructive but with substantial critiques. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, framing critiques as suggestions (e.g. 'It would be great if the authors could...') and acknowledging positive aspects before providing criticism. The reviewer also uses phrases like 'I think' and 'I find' to soften opinions, and provides detailed, helpful feedback without harsh language."", ""The sentiment score is -50 because the review is generally critical of the paper, pointing out several limitations and missing elements. The reviewer states that the technical contribution is small, the experimental evidence is insufficient, and important baselines are missing. However, it's not entirely negative as the reviewer acknowledges some positive aspects like the well-written related work section. The politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They use phrases like 'I am in favour of' and 'thanks' which add a polite touch. The reviewer also provides specific suggestions for improvement rather than just criticizing, which is a polite approach to peer review. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -50 because while the reviewer acknowledges some strengths of the paper, they express major concerns about novelty and limited experiments. The review highlights 'major weaknesses' and calls it a 'weak paper' overall, indicating a negative sentiment. However, it's not extremely negative as they do note some positive aspects. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and suggestions. They avoid harsh or rude phrasing, instead using phrases like 'I would expect' or 'Did authors experiment with' which maintain a polite tone. The score is not higher as the review, while polite, doesn't go out of its way to be exceptionally courteous.""]"
"['The paper adresses a very interesting question about the handling of the dynamics of a recommender systems at scale (here for linking to some articles).\nThe defended idea is to use the context to fit a mixture of Gaussian with a NN and to assume that the noise could be additively split into two terms. One depend only on the number of observations of the given context and the average reward in this situation and the second term begin the noise. This is equivalent to separate a local estimation error from the noise. \n\nThe idea is interesting but maybe not pushed far enough in the paper:\n*At fixed context x, assuming that the error is a function of the average reward u and of the number of displays r of the context could be a constant could be a little bit more supported (this is a variance explanation that could be tested statistically, or the shape of this 2D function f(u,r) could be plot to exhibit its regularity). \n* None of the experiments is done on public data which lead to an impossible to reproduce paper\n* The proposed baselines are not really the state of the art (Factorization Machines, GBDT features,...) and the used loss is MSE which is strange in the context of CTR prediction (logistic loss would be a more natural choice)\n* I\'m not confident with the proposed surrogate metrics. In the paper, the work of Lihong Li &al on offline evaluation on contextual bandits is mentioned and considered as infeasible here because of the renewal of the set of recommendation. Actually this work can be adapted to handle theses situations (possibly requiring to bootstrap if the set is actually regenerating too fast). Also note that Yahoo Research R6a - R6b  datasets where used in ICML\'12 Exploration and Exploitation 3 challenge where about pushing some news in a given context and could be reused to support the proposed approach. An other option would be to use some counterfactual estimates (See Leon Bottou &all and Thorsten Joachims &all)\n* If the claim is about a better exploration,  I\'d like to have an idea of the influence of the tuning parameters and possibly a discussion/comparison over alternatives strategies (including an epsilon-n greedy algorithm)\n\nBesides theses core concerns, the papers suffers of some imprecisions on the notations which should be clarified. \n* As an example using O(1000) and O(1M) in the figure one. Everyone understands what is meant but O notation are made to eliminate constant terms and O(1) = O(1000).\n* For eqn (1) it would be better to refer to and ""optimistic strategy"" rather to UCB because the name is already taken by an algorithm which is not this one. Moreover the given strategy would achieve a linear regret if used as described in the paper which is not desirable for bandits algorithms (smallest counter example with two arms following a Bernouilli with different parameters if the best arms generates two zero in a row at the beginning, it is now stuck with a zero mean and zero variance estimate). This is why bandits bounds include a term which increase with the total number of plays. I agree that in practice this effect can be mitigated at that the strategy can be correct in the contextual case (but then I\'d like to the dependancies on x to be clear) \n* The papers never mentions whats is a scalar, a vector or a matrix. This creates confusion: as an example eqn (3) can have several different meaning depending if the values are scalars, scalars depending on x or having a diagonal \\sigma matrix\n* In the paragraph above (2) I unsure of what is a ""binomial noise error distribution"" for epsilon, but a few lines later epsilon becomes a gaussian why not just mention that you assume the presence of a gaussian noise on the parameters of a Bernouilli distribution ? \n\n ', ""This paper presents a methodology to allow us to be able to measure uncertainty of the deep neural network predictions, and then apply explore-exploit algorithms such as UCB to obtain better performance in online content recommendation systems. The method presented in this paper seems to be novel but lacks clarity unfortunately. My main doubt comes from Section 4.2.1, as I am not sure how exactly the two subnets fed into MDN to produce both mean and variance, through another gaussian mixture model. More specifically, I am not able to see how the output of the two subnets get used in the Gaussian mixture model, and also how the variance of the prediction is determined here. Some rewriting is needed there to make this paper better understandable in my opinion. \n\nMy other concerns of this paper include:\n1. It looks like the training data uses empirical CTR of (t,c) as ground truth. This doesn't look realistic at all, as most of the time (t,c) pair either has no data or very little data in the real world. Otherwise it is a very simple problem to solve, as you can just simply assume it's a independent binomial model for each (t,c).\n2. In Section 4.2.1, CTR is modeled as a Gaussian mixture, which doesn't look quite right, as CTR is between (0,1).\n3. A detailed explanation of the difference between MDN and DDN is needed.\n4. What is OOV in Section 5.3?"", 'In the paper ""DEEP DENSITY NETWORKS AND UNCERTAINTY IN RECOMMENDER SYSTEMS"", the authors propose a novel neural architecture for online recommendation. The proposed model deals with data and measurement uncertaintes to define exploitation/exploration startegies. \n\nMy main concern with the paper is that the contribution is unclear, as the authors failed from my point of view in establishing the novely w.r.t. the state of the art regarding uncertainty in neural networks. The state of the art section is very confusing, with works given in a random order, without any clear explanation about the limits of the existing works in the context of the task addressed in the paper. The only positioning argument that is given in that section is the final sentence ""In this paper we model measurement noise using a Gaussian model and combine it with a MDN"". It is clearly not sufficient to me, as it does not gives insights about why such proposal is done. \n\nIn the same spirit, I cannot understand why not any classical bandit baseline is given in the experiments. The experiments only concern two slightly different versions of the proposed algorithm in order to show the importance of the deconvolution of both considered noises, but nothing indicates that the model performs fairly well compared to existing approaches. Also, it would have been useful to compare ot to other neural models dealing with uncertainty (some of them having been applied to bandit problems- e.g., Blundell et al. (2015)).\n\nAt last, for me the uncertainty considered in the proposal is not sufficient to claim that the approach is an UCB-like one. The confidence bound considered should include the uncertainty on the parameters in the predictive posterior reward distribution (as done for instance in Blundell et al. (2015) in the context of neural networks), not only the distribution of the observed data with regards to the considered probabilistic families. Not enough discussion is given wrt the assumptions made by the model anyway. The section 4 is also particularly hard to follow.\n\nOther remarks:\n    - Equation (1) does not fit with mixtures considered in 4.2.1. So what is the selection score that is used\n    - ""Due to the fact that data noise is small given x"" => what does it mean since x is a couple ? Also I cannot understand the causal relation with the following of the sentence\n    - Figure 4 (and the associated paragraph) is very difficult to understand (I couldn\'t extract any information from this)\n    - Too many abreviations that complicate the reading\n    - The throughput measure is not clear\n    - Not enough justification about the architecture. For instance, nothing is said about the title subnet represented in the figure 3.\n    - What is the ""recommendation age"" ?\n    - ""We can rewrite eq. 2 using eq. 3 and 6"" => ""and 4"".\n\n']","[-20, -20, -70]","[50, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper addresses an interesting question and has some good ideas, they express several significant concerns and criticisms. The reviewer points out multiple areas where the paper falls short, including lack of public data, inadequate baselines, questionable metrics, and imprecise notations. However, the tone is not entirely negative, as they do recognize the potential of the work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'The idea is interesting' and 'I'd like to have an idea of' which show engagement with the work. Even when pointing out flaws, the language is constructive rather than harsh. For example, they suggest improvements or alternatives rather than simply criticizing. The reviewer also uses hedging language like 'maybe not pushed far enough' and 'I'm not confident with' which softens the criticism. However, the score is not higher because the review is quite direct in its criticisms and doesn't include many explicitly polite phrases or compliments."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty of the method, they express significant concerns about clarity and have several specific criticisms. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, framing criticisms as 'concerns' and suggestions rather than harsh judgments. They use phrases like 'in my opinion' and 'It looks like', which softens the critique. The reviewer also acknowledges positive aspects before presenting criticisms, which is a polite approach to peer review."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses several major concerns about the paper, including unclear contribution, insufficient comparison to existing approaches, and inadequate discussion of assumptions. Phrases like 'main concern', 'failed from my point of view', and 'not sufficient' indicate a negative sentiment. However, it's not entirely negative as the reviewer acknowledges the proposal of a novel architecture.\n\nThe politeness score is 20 because while the reviewer is critical, the language used is generally professional and constructive. The reviewer uses phrases like 'My main concern' and 'I cannot understand' rather than more aggressive or rude language. The review provides specific recommendations for improvement, which is a polite approach. However, the tone is more matter-of-fact than overtly polite, hence the relatively low positive score.""]"
"['In order to compress DNN intermediate feature maps the authors covert fixed-point activations into vectors over the smallest finite field, the Galois field of two elements (GF(2)) and use nonlinear dimentionality reduction layers.\n\nThe paper reads well and the methods and experiments are generally described in sufficient detail.\n\nMy main concern with this paper and approach is the performance achieved. According to Table 1 and Table 2 there is a small accuracy benefit from using the proposed approach over the ""quantized"" SqueezeNet baseline. If I am weighing in the need to alter the network for the proposed approach in comparison with the ""quantized"" setting then, from practical point of view, I would prefer the later ""quantized"" approach.\n', 'The method of this paper minimizes the memory usage of the activation maps of a CNN. It starts from a representation where activations are compressed with a uniform scalar quantizer and fused to reduce intermediate memory usage. This looses some accuracy, so the contribution of the paper is to add a pair of convolution layers in the binary domain (GF(2)) that are trained to restore the lost precision. \n\nOverall, this paper seems to be a nice addition to the body of works on network compression. \n\n+ : interesting approach and effective results. \n\n+ : well related to the state of the art and good comparison with other works. \n\n- : somewhat incremental. Most of the claimed 100x compression is due to previous work.\n\n- : impact on runtime is not reported. Since there is a caffe implementation it would be interesting to have an additional column with the comparative execution speeds, even if only on CPU. I would expect the FP32 timings to be hard to beat, despite the claims that it uses only binary operations.\n\n- : the paper is sometimes difficult to understand (see below)\n\ndetailed comments: \n\nEquations (3)-(4) are difficult to understand. If I understand correctly, b just decomposes a \\hat{x} in {0..2^B-1} into its B bits \\tilda{x} \\in {0,1}^B, which can be then considered as an additional dimension in the activation map where \\hat{x} comes from. \n\nIt is not stated clearly whether P^l and R^l have binary weights. My understanding is that P^l has but R^l not.\n\n4.1 --> a discussion of the large mini-batch size (1024) could be useful. My understanding is that large mini-batches are required to use averaged gradients and get smooth updates. \n\nend of 4.1 --> unclear what ""equivalent bits"" means\n\n', 'Strengths:\n- Unlike most previous approaches that suffer from significant accuracy drops for good feature map compression, the proposed method achieves reductions in feature map sizes of 1 order of magnitude at effectively no loss in accuracy.\n- Technical approach relates closely to some of the prior approaches (e.g., Iandola et al. 2016) but can be viewed as learning the quantization rather than relying on a predefined one.\n- Good results on both large-scale classification and object detection.\n- Technical approach is clearly presented.\n\nWeaknesses:\n- The primary downside is that the approach requires a specialized architecture to work well (all experiments are done with SqueezeNets). Thus, the approach is less general than prior work, which can be applied to arbitrary architectures.\n- From the experiments it is not fully clear what is the performance loss due to having to use the SqueezeNet architecture rather than state-of-the-art models. For example, for the image categorization experiment, the comparative baselines are for AlexNet and NIN, which are outdated and do not represent the state-of-the-art in this field. The object detection experiments are based on a variant of Faster R-CNN where the VGG16 feature extractor is replaced with a SqueezeNet model. However, the drop in accuracy caused by this modification is not discussed in the paper and, in any case, there are now much better models for object detection than Faster R-CNN.\n- In my view the strengths of the approach would be more convincingly conveyed visually with a plot reporting accuracy versus memory usage, rather than by the many numerical tables in the paper.\n\n']","[-20, 40, 50]","[60, 60, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper reads well and is sufficiently detailed, they express a 'main concern' about the performance achieved. The reviewer suggests that the proposed approach offers only a small benefit over the baseline, and they would prefer the simpler 'quantized' approach from a practical standpoint. This indicates a overall negative sentiment towards the paper's main contribution. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting their concerns. They phrase their criticism constructively, using phrases like 'My main concern' rather than direct attacks, maintaining a professional and courteous tone."", ""The sentiment score is 40 (slightly positive) because the reviewer starts by describing the paper as a 'nice addition' to the field and mentions 'interesting approach and effective results'. However, they also point out some negative aspects, such as it being 'somewhat incremental' and 'difficult to understand' in parts. The balance of positives and negatives, with a slight lean towards positive, justifies this score. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions (e.g., 'it would be interesting to have...') and balancing positive and negative points. They avoid harsh language, instead using phrases like 'somewhat incremental' for criticism. The reviewer also provides detailed comments to help improve the paper, which is a polite and constructive approach."", ""The sentiment score is 50 (moderately positive) because the review begins by highlighting several strengths of the paper, including its novel approach and good results. However, it also points out significant weaknesses, creating a balanced but overall positive tone. The politeness score is 75 (quite polite) because the reviewer uses respectful and professional language throughout, framing criticisms constructively (e.g., 'The primary downside is...', 'From the experiments it is not fully clear...'). The reviewer also acknowledges the paper's merits before discussing its limitations, which is a polite approach to peer review.""]"
"['This paper presents a few modifications on top of some earlier work (GRU4Rec, Hidasi et al. 2016) for session-based recommendation using RNN. The first one is to include additional negative samples based on popularity raised to some power between 0 and 1. The second one is to mitigate the vanishing gradient problem for pairwise ranking loss, especially with the increased number of negative samples from the first modification. The basic idea is to weight all the negative examples by their “relevance”, since for the irrelevant negatives the gradients are vanishingly small. Experimentally these modifications prove to be effective compared with the original GRU4Rec paper. \n\nThe writing could have been more clear, especially in terms of notations and definitions. I found myself sometimes having to infer the missing bits. For example, in Eq (4) and (5), and many that follow, the index i and j are not defined (I can infer it from the later part), as well as N_s (which I take it as the number of negative examples). This is just one example, but I hope the authors could carefully check the paper and make sure all the notations/terminologies are properly defined or referred with a citation when first introduced (e.g., pointwise, pairwise, and listwise loss functions). I consider myself very familiar with the RecSys literature, and yet sometimes I cannot follow the paper very well, not to mention the general ICLR audience. \n\nRegarding the two main modifications, I found the negative sampling rather trivial (and I am surprised in Hidasi et al. (2016) the negatives are only from the same batch, which seems a huge computational compromise) with many existing work on related topic: Steck (Item popularity and recommendation accuracy, 2011) used the same “popularity to the power between 0 and 1” strategy (they weighted the positive by the inverse popularity to the power). More closely, the negative sampling distribution in word2vec is in fact a unigram raised to the power of 0.75, which is the same as the proposed strategy here. As for the gradient vanishing problem for pairwise ranking loss, it has been previously observed in Rendle & Freudenthaler (Improving Pairwise Learning for Item Recommendation from Implicit Feedback, 2014) for BPR and they proposed an adaptive negative sampling strategy (trying to sample more relevant negatives while still keeping the computational cost low), which is closely related to the ranking-max loss function proposed in this paper. Overall, I don’t think this paper adds much on top of the previous work, and I think a more RecSys-oriented venue might benefit more from the insights presented in this paper.   \n\nI also have some high-level comments regarding using RNN for session-based recommendation (this was also my initial reaction after reading Hidasi et al. 2016). As mentioned in this paper, when applying RNN on RecSys datasets with longer time-span (which means there can be more temporal dynamics in users’ preference and item popularity), the results are not striking (e.g., Wu et al. 2017) with the proposed methods barely outperforming standard matrix factorization methods. It is puzzling that how RNN can work better for session-based case where a user’s preference can hardly change within such a short period of time. I wonder how a simple matrix factorization approach would work for session-based recommendation (which is an important baseline that is missing): regarding the claim that MF is not suited for session-based because of the absence of the concept of a user, each session can simply be considered as a pseudo-user and approaches like asymmetric matrix factorization (Paterek 2007, Improving regularized singular value decomposition for collaborative filtering) can even eliminate the need for learning user factors. ItemKNN is a pretty weak baseline and I wonder if a scalable version of the SLIM (Ning & Karypis 2011, SLIM: Sparse Linear Methods for Top-N Recommender Systems) would give better results. Finally, my general experience with BPR-type of pairwise ranking loss is that it is good at optimizing AUC, but not very well-suited for head-heavy metrics (MRR, Recall, etc.) I wonder how the propose loss would perform comparing with more competitive baselines. \n\nRegarding the page limit, given currently the paper is quite long (12 pages excluding references), I suggest the authors cutting down some space. For example, the part about fixing the cross entropy is not very relevant and can totally be put in the appendix. \n\nMinor comment:\n\n1. Section 3.3.1, “Part of the reasons lies in the rare occurrence…”, should r_j >> r_i be the other way around?\n', 'This is an interesting paper that analyzes existing loss functions for session-based recommendations. Based on the result of these analysis the authors propose two novel losses functions which add a weighting to existing ranking-based loss functions. These novelties are meant to improve issues related to vanishing gradients of current loss functions. The empirical results on two large-scale datasets are pretty impressive. \n\nI found this paper to be well-written and easy to read.  It also provides a nice introduction to some of the recent literature on RNNs for session-based recommendations. \n\nIn terms of impact, while it studies a fairly applied (and narrow) question, it seems like it would be of interest to researchers and practitioners in recommender systems.\n\n\nI have a few comments and questions: \n\n- The results in Figure 3 show that both a good loss function and sampling strategy are required to perform well. This is interesting in the sense that doing the ""right thing"" according to the model (optimizing using all samples) isn\'t optimal. This is a very empirical observation and it would be insightful to better understand exactly the objective that is being optimized.\n\n- While BPR-max seems to be the strongest performer (Table 2), cross-entropy (XE) with additional samples is close. This further outlines the importance of the sampling method over the exact form of the loss function. \n\n- In ranking-max losses, it seems like ""outliers"" could have a bigger impact. I don\'t know how useful it is to think about (and it is a bit unclear what an ""outlier"" means in this implicit feedback setting).\n\n\nMinor comments: \n\n- Around Eq. 4 it may be worth being more explicit about the meaning of i and j. \n', 'This paper discussed the issues for optimizing the loss functions in GRU4Rec and proposed tricks for optimize the loss functions, and also proposed enhanced version of the loss functions for GRU4Rec. Good performance improvements have been reported for the several datasets to show the effectiveness of the proposed methods.\n\nThe good point of this work is to show that the loss function is important to train a better classifier for the session-based recommendation. This work is of value to the session-based recommendations.\n\nSome minor points:\nI think it may be better if the authors could put the results of RSC15 from Tan (2016) and Chatzis ect. (2017) into table 2 as well.\nAs these work has already been published and should be compared with and reported in the formal table. ']","[-30, 80, 70]","[20, 70, 80]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'Experimentally these modifications prove to be effective'), they express several criticisms and doubts about the novelty and significance of the work. The reviewer suggests the paper doesn't add much to previous work and might be better suited for a different venue. They also point out missing baselines and unclear writing. However, the score is not extremely negative as the reviewer does provide constructive feedback and acknowledges some merits of the work. The politeness score is 20 because the reviewer maintains a professional and respectful tone throughout, offering suggestions for improvement and framing criticisms as personal opinions (e.g., 'I don't think', 'I wonder'). They also use polite phrases like 'I hope the authors could' and 'I suggest'. However, the score is not extremely high as the review is still quite critical and direct in its assessment."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'interesting' and 'well-written', with 'impressive' empirical results. They also mention its potential impact and interest to researchers and practitioners. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering constructive feedback and questions without harsh criticism. They use phrases like 'I found this paper to be...' and 'It would be insightful to...', which maintain a courteous tone. The reviewer also balances positive comments with areas for improvement, demonstrating a considerate approach to feedback."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its 'good performance improvements' and stating that 'this work is of value'. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's contributions and offering constructive suggestions. The reviewer refers to 'good points' and frames their recommendations as 'minor points', which maintains a courteous tone. The sentiment isn't 100 as there are some suggestions for improvement, and the politeness isn't 100 as it's professionally polite rather than excessively deferential.""]"
"['The paper introduces a method for learning graph representations (i.e., vector representations for graphs). An existing node embedding method is used to learn vector representations for the nodes. The node embeddings are then projected into a 2-dimensional space by PCA. The 2-dimensional space is binned using an imposed grid structure. The value for a bin is the (normalized) number of nodes falling into the corresponding region. \n\nThe idea is simple and easily explained in a few minutes. That is an advantage. Also, the experimental results look quite promising. It seems that the methods outperforms existing methods for learning graph representations. \n\nThe problem with the approach is that it is very ad-hoc. There are several (existing) ideas of how to combine node representations into a representation for the entire graph. For instance, averaging the node embeddings is something that has shown promising results in previous work. Since the methods is so ad-hoc (node2vec -> PCA -> discretized density map -> CNN architecure) and since a theoretical understanding of why the approach works is missing, it is especially important to compare your method more thoroughly to simpler methods. Again, pooling operations (average, max, etc.) on the learned node2vec embeddings are examples of simpler alternatives. \n\nThe experimental results are also not explained thoroughly enough. For instance, since two runs of node2vec will give you highly varying embeddings (depending on the initialization), you will have to run node2vec several times to reduce the variance of your resulting discretized density maps. How many times did you run node2vec on each graph? \n\n', 'The paper presents a novel representation of graphs as multi-channel image-like structures. These structures are extrapolated  by \n1) mapping the graph nodes into an embedding using an algorithm like node2vec\n2) compressing the embedding space using pca\n3) and extracting 2D slices from the compressed space and computing 2D histograms per slice.\nhe resulting multi-channel image-like structures are then feed into vanilla 2D CNN.\n  \nThe papers is well written and clear, and proposes an interesting idea of representing graphs as multi-channel image-like structures. Furthermore, the authors perform experiments with real graph datasets from the social science domain and a comparison with the SoA method both graph kernels and deep learning architectures. The proposed algorithm in 3 out of 5 datasets, two of theme with statistical significant.', 'The authors propose to use 2D CNNs for graph classification by transforming graphs to an image-like representation from its node embedding. The approach uses node2vec to obtain a node embedding, which is then compacted using PCA and turned into a stack of discretized histograms. Essentially the authors propose an approach to use a node embedding to achieve graph classification.\n\nIn my opinion there are several weak points:\n\n1) The approach to obtain the image-like representation is not well motivated. Other approaches how to  aggregate the set of node embeddings for graph classification are known, see, e.g., ""Representation Learning on Graphs: Methods and Applications"", William L. Hamilton, Rex Ying, Jure Leskovec, 2017. The authors should compare to such methods as a baseline.\n\n2) The experimental evaluation is not convincing:\n- the selection of competing methods is not sufficient. I would like to suggest to add an approach similar to Duvenaud et al., ""Convolutional networks on graphs for learning molecular fingerprints"", NIPS 2015.\n- the accuracy results are taken from other publications and it is not clear that this is an authoritative comparison; the accuracy results published for state-of-the-art graph kernels are superior to those obtained by the proposed method, cf., e.g., Kriege et al., ""On Valid Optimal Assignment Kernels and Applications to Graph Classification"", NIPS 2016.\n- it would be interesting to apply the approach to graphs with discrete and continuous labels.\n\n3) The authors argue that their method is preferable to graph kernels in terms of time complexity. This argument is questionable. Most graph kernels compute explicit feature maps and can therefore be used with efficient linear SVMs (unfortunately most publications use a kernelized SVM). Moreover, the running of computing the node embedding must be emphasized: On page 2 the authors claim a ""constant time complexity at the instance level"", which is not true when also considering the running time of node2vec. Moreover, I do not think that node2vec is more efficient than, e.g., Weisfeiler-Lehman refinement used by graph kernels.\n\nIn summary: Since the technical contribution is limited, the approach needs to be justified by an authoritative experimental comparison. This is not yet achieved with the results presented in the submitted paper. Therefore, it should not be accepted in its current form.']","[20, 80, -70]","[50, 70, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges some strengths of the paper, such as the simplicity of the idea and promising experimental results. However, they also point out significant concerns, particularly about the ad-hoc nature of the approach and lack of thorough comparisons. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, offering constructive criticism without using harsh language. They use phrases like 'The problem with the approach is...' and 'It is especially important to...' which convey concerns in a respectful manner. The reviewer also balances critique with positive observations, which contributes to the overall polite tone."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'well written and clear', and mentions that it 'proposes an interesting idea'. The reviewer also highlights the paper's experimental work and its favorable performance compared to state-of-the-art methods. The politeness score is 70 (polite) as the reviewer uses respectful and professional language throughout, acknowledging the paper's strengths without using overly effusive praise. The tone is constructive and objective, focusing on the paper's merits and contributions to the field."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several weak points and concludes that the paper should not be accepted in its current form. They criticize the approach, experimental evaluation, and time complexity claims. However, it's not entirely negative as they do suggest improvements, which prevents it from being at the extreme negative end. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'In my opinion' and 'I would like to suggest' which add a degree of politeness. They also provide constructive feedback and suggestions for improvement, which is considerate. However, the overall tone is still quite critical, preventing a higher politeness score.""]"
"['In this paper, the authors propose a new architecture for generative neural networks. Rather than the typical adversarial training procedure used to train a generator and a discriminator, the authors train a generator only. To ensure that noise vectors get mapped to images from the target distribution, the generator is trained to map noise vectors to the set of training images as closely as possible. Both the parameters of the generator and the noise vectors themselves are optimized during training. \n\nOverall, I think this paper is useful. The images generated by the model are not (qualitatively and in my opinion) as high quality as extremely recent work on GANs, but do appear to be better than those produced by DCGANs. More importantly than the images produced, however, is the novel training procedure. For all of their positive attributes, the adversarial training procedure for GANs is well known to be fairly difficult to deal with. As a result, the insight that if a mapping from noise vectors to training images is learned directly, other noise images still result in natural images is interesting.\n\nHowever, I do have a few questions for the authors, mostly centered around the choice of noise vectors.\n\nIn the paper, you mention that you ""initialize the z by either sampling them from a Gaussian distribution or by taking the whitened PCA of the raw image pixels."" What does this mean? Do you sample them from a Gaussian on some tasks, and use PCA on others? Is it fair to assume from this that the initialization of z during training matters? If so, why?\n\nAfter training, you mention that you fit a full Gaussian to the noise vectors learned during training and sample from this to generate new images. I would be interested in seeing some study of the noise vectors learned during training. Are they multimodal, or is a unimodal distribution indeed sufficient? Does a Gaussian do a good job (in terms of likelihood) of fitting the noise vectors, or would some other model (even something like kernel density estimation) allow for higher probability noise vectors (and therefore potentially higher quality images) to be drawn? Does the choice of distribution even matter, or do you think uniform random vectors from the space would produce acceptable images?', 'Summary: The authors observe that the success of GANs can be attributed to two factors; leveraging the inductive bias of deep CNNs and the adversarial training protocol. In order to disentangle the factors of success, and they propose to eliminate the adversarial training protocol while maintaining the first factor. The proposed Generative Latent Optimization (GLO) model maps a learnable noise vector to the real images of the dataset by minimizing a reconstruction loss. The experiments are conducted on CelebA and LSUN-Bedroom datasets. \n\nStrengths: \nThe paper is well written and the topic is relevant for the community.\nThe notations are clear, as far as I can tell, there are no technical errors.\nThe design choices are well motivated in Chapter 2 which makes the main idea easy to grasp. \nThe image reconstruction results are good. \nThe experiments are conducted on two challenging datasets, i.e. CelebA and LSUN-Bedroom.\n\nWeaknesses:\nA relevant model is Generative Moment Matching Network (GMMN) which can also be thought of as a “discriminator-less GAN”. However, the paper does not contrast GLO with GMMN either in the conceptual level or experimentally. \n\nAnother relevant model is Variational Autoencoders (VAE) which also learns the data distribution through a learnable latent representation by minimizing a reconstruction loss. The paper would be more convincing if it provided a comparison with VAE.\n\nIn general, having no comparisons with other models proposed in the literature as improvements over GAN such as ACGAN, InfoGAN, WGAN weakens the experimental section.\n\nThe evaluation protocol is quite weak: CelebA images are 128x128 while LSUN images are 64x64. Especially since it is a common practice nowadays to generate much higher dimensional images, i.e. 256x256, the results presented in this paper appear weak. \n\nAlthough the reconstruction examples (Figure 2 and 3) are good, the image generation results (Figure 4 and 5) are worse than GAN, i.e. the 3rd images in the 2nd row in Figure 4 for instance has unrealistic artifacts, the entire Figure 5 results are quite boxy and unrealistic. The authors mention in Section 3.3.2 that they leave the careful modeling of Z to future work, however the paper is quite incomplete without this.\n\nIn Section 3.3.4, the authors claim that the latent space that GLO learns is interpretable. For example, smiling seems correlated with the hair color in Figure 6. This is a strong claim based on one example, moreover the evidence of this claim is not as obvious (based on the figure) to the reader. Moreover, in Figure 8, the authors claim that the principal components of the GLO latent space is interpretable. However it is not clear from this figure what each eigenvector generates. The authors’ observations on Figure 8 and 9 are not clearly visible through manual inspection.  \n\nFinally, as a minor note, the paper has some vague statements such as\n“A linear interpolation in the noise space will generate a smooth interpolation of visually-appealing images”\n“Several works attempt at recovering the latent representation of an image with respect to a generator.”\nTherefore, a careful proofreading would improve the exposition. ', 'The paper is well written and easy to follow. I find the results very interesting. In particular the paper shows that many properties of GAN (or generative) models (e.g. interpolation, feature arithmetic) are a in great deal result of the inductive bias of deep CNN’s and can be obtained with simple reconstruction losses. \n\nThe results on CelebA seem quite remarkable for training examples (e.g. interpolation). Samples are quite good but inferior to GANs, but still impressive for the simplicity of the model. The results on SUN are a bit underwhelming, but still deliver the point reasonably well in my view. Naturally, the paper would make a much stronger claim showing good results on different datasets. \n\nThe authors mentioned that the current method can recover all the solutions that could be found by an autoencoder and reach some others. It would be very interesting to empirically explore this statement. Specifically, my intuition is that if we train a traditional autoencoder (with normalization of the latent space to match this setting) and compute the corresponding z vectors for each element in the dataset, the loss function (1) would be lower than that achieved with the proposed model. If that is true, the way of solving the problem is helping find a solution that prevents overfitting. \n\nFollowing with the previous point, the authors mention that different initializations were used for the z vectors in the case of CelebA and LSUN. Does this lead to significantly different results? What would happen if the z values were initialized say with the representations learned by a fully trained deterministic autoencoder (with the normalization as in this work)? It would be good to report and discuss these alternatives in terms of loss function and results (e.g. quality of the samples). \n\nIt seems natural to include VAE baselines (using both of the losses in this work). Also, recent works have used ‘perceptual losses’, for instance for building VAE’s capable of generating sharper images:\n\nLamb, A., et al (2016). Discriminative regularization for generative models. arXiv preprint arXiv:1602.03220.\n\nIt would be good to compare these results with those presented in this work. One could argue that VAE’s are also mainly trained via a regularized reconstruction loss. Conversely, the proposed method can be thought as a form of autoencoder. The encoder could be thought to be implicitly defined by the optimization procedure used to recover the latent vectors in GAN\'s. Using explicit variables for each image would be a way of solving the optimization problem.\n\nIt would be informative to also shows reconstruction and interpolation results for a set of ‘held out’ images. Where the z values would be found as with GANs. This would test the coverage of the method and might be a way of making the comparison with GANs more relevant. \n\nThe works:\n\nNguyen, Anh, et al. ""Synthesizing the preferred inputs for neurons in neural networks via deep generator networks."" Advances in Neural Information Processing Systems. 2016.\n\nHan, Tian, et al. ""Alternating Back-Propagation for Generator Network."" AAAI. 2017.\n\nSeems very related.\n']","[60, -20, 60]","[80, 60, 80]","[""The sentiment score is 60 (positive) because the reviewer states that the paper is 'useful' and highlights several positive aspects, such as the novel training procedure and the quality of generated images. However, it's not extremely positive as the reviewer also mentions that the image quality is not as high as some recent GAN work. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's contributions, and frames criticisms as questions or areas for further exploration rather than direct criticisms. The reviewer uses phrases like 'I think' and 'I would be interested in seeing' which maintain a polite and constructive tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper (well-written, relevant topic, clear notations), they also point out several significant weaknesses. These include lack of comparisons with relevant models, weak evaluation protocol, and some unconvincing claims. The overall tone suggests that the paper has potential but needs substantial improvements.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They begin by highlighting the paper's strengths before moving on to the weaknesses. The criticism is presented in a constructive manner, using phrases like 'The paper would be more convincing if...' and 'The authors' observations... are not clearly visible through manual inspection' rather than using harsh or dismissive language. The reviewer also offers suggestions for improvement, which is a polite way to provide criticism."", ""The sentiment score is 60 (positive) because the reviewer starts by praising the paper as 'well written and easy to follow' and finds the results 'very interesting'. They describe the CelebA results as 'quite remarkable' and the overall results as 'impressive'. However, they also note some limitations, like 'underwhelming' results on SUN and samples being 'inferior to GANs', which prevents a higher score. The politeness score is 80 (quite polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'It would be good to', 'It would be informative to', and 'It seems natural to', which suggest improvements politely rather than demanding them. They also acknowledge the paper's strengths before offering critiques. The lack of any harsh or dismissive language further supports the high politeness score.""]"
"['This paper proposed a method for automatic curriculum generation that allow an agent to learn to reach multiple goals in an environment with considerable sample efficiency. They use a generator network to propose tasks for the agent accomplish. The generator network is trained with GAN.  In addition, the proposed method is also shown to be able to solve tasks with sparse rewards without the need manually modify reward functions. They compare the Goal GAN method with four baselines, including Uniform sampling, Asymmetric Self-play, SAGG-RIAC, and Rejection sampling. The proposed method is tested on two environments: Free Ant and Maze Ant. The empirical study shows that the proposed method is able to improve policies’ training efficiency comparing to these baselines. The technical contributions seem sound, however I find it is slightly difficult to fully digest the whole paper without getting the insight from each individual piece and there are some important details missing, as I will elaborate more below.\n\n1. it is unclear to me why the proposed method is able to solve tasks with sparse rewards? Is it because of the horizons of the problems considered are not long enough? The author should provide more insight for this contribution.\n\n2. It is unclear to me how R_min and R_max as hyperparameters are obtained and how their settings affect the performance.\n\n3. Another concern I have is regarding the generalizability of the proposed method. One of the assumption is “A policy trained on a sufficient number of goals in some area of the goal-space will learn to interpolate to other goals within that area”. This seems to mean that the area is convex. It might be better if some quantitative analysis can be provided to illustrate geometry of goal space (given complex motor coordination) that is feasible for the proposed method.\n\n4. It is difficult to understand the plots in Figure 4 without more details. Do you assume for every episode, the agent starts from the same state? \n\n5. For the plots in Figure 2, is there any explanation for the large variance for Goal GAN? Given that the state space is continuous, 10 runs seems not enough.\n\n6. According to the experimental details, three rollouts are performed to estimate the empirical return. It there any justification why three rollouts are enough?\n\n7. Minor comments\nAchieve tasks -> achieve goals or accomplish/solve tasks\nA variation of to -> variation of \nAllows a policy to quickly learn to reach …-> allow an agent to be quickly learn a policy to reach…\n…the difficulty of the generated goals -> … the difficulty of reaching\n', 'Summary:\n\nThis paper proposes to use a GAN to generate goals to implement a form of curriculum learning. A goal is defined as a subset of the state space. The authors claim that this model can discover all ""goals"" in the environment and their \'difficulty\', which can be measured by the success rate / reward of the policy. Hence the goal network could learn a form of curriculum, where a goal is \'good\' if it is a state that the policy can reach after a (small) improvement of the current policy.\n\nTraining the goal GAN is done via labels, which are states together with the achieved reward by the policy that is being learned.\n\nThe benchmark problems are whether the GAN generates goals that allow the agent to reach the end of a U-maze, and a point-mass task.\n\nAuthors compare GAN goal generation vs uniformly choosing a goal and 2 other methods.\n\nMy overall impression is that this work addresses an interesting question, but the experimental setup / results are not clearly worked out. More broadly, the paper does not address how one can combine RL and training a goal GAN in a stable way.\n\nPro:\n- Developing hierarchical learning methods to improve the sample complexity of RL is an important problem.\n- The paper shows that the U-maze can be \'solved\' using a variety of methods that generate goals in a non-uniform way.\n\nCon:\n- It is not clear to me how the asymmetric self-play and SAGG-RIAC are implemented and why they are natural baselines.\n- It is not clear to me what the \'goals\' are in the point mass experiment. This entire experiment should be explained much more clearly (+image).\n- It is not clear how this method compares qualitatively vs baselines (differences in goals etc).\n- This method doesn\'t seem to always outperform the asymm-selfplay baseline. The text mentions that baseline is less efficient, but this doesn\'t make the graph very interpretable.\n- The curriculum in the maze-case consists of regions that just progress along the maze, and hence is a 1-dimensional space. Hence using a manually defined set of goals should work quite well. It would be better to include such a baseline as well.\n- The experimental maze-setting and point-mass have a simple state / goal structure. How can this method generalize to harder problems?\n-- The entire method is quite complicated (e.g. training GANs can be highly unstable). How do we stabilize / balance training the GAN vs the RL problem?\n-- I don\'t see how this method could generalize to problems where the goals / subregions of space do not have a simple distribution as in the maze problem, e.g. if there are multiple ways of navigating a maze towards some final goal state. In that case, to discover a good solution, the generated goals should focus on one alternative and hence the GAN should have a unimodal distribution. How do you force the GAN in a principled way to focus on one goal in this case? How could you combine RL and training the GAN stably in that case?\n\nDetailed:\n- (2) is a bit strange: shouldn\'t the indicator say: 1( \\exists t: s_t \\in S^g )? Surely not all states in the rollout (s_0 ... s_t) are in the goal subspace: the indicator does not factorize over the union. Same for other formulas that use \\union.\n- Are goals overlapping or non-overlapping subsets of the state space? \nDefinition around (1) basically says it\'s non-overlapping, yet the goal GAN seems to predict goals in a 2d space, hence the predicted goals are overlapping? \n- What are the goals that the non-uniform baselines predict? Does the GAN produce better goals?\n- Generating goal labels is\n- Paper should discuss literature on hierarchical methods that use goals learned from data and via variational methods:\n1. Strategic Attentive Writer (STRAW), V. Mnih et al, NIPS 2016\n2. Generating Long-term Trajectories Using Deep Hierarchical Networks. S.\nZheng et al, NIPS 2016', 'In general I find this to be a good paper and vote for acceptance. The paper is well-written and easy to follow.  The proposed approach is a useful addition to existing literature.\n\nBesides that I have not much to say except one point I would like to discuss:\n\nIn 4.2 I am not fully convinced of using an adversial model for goal generation. RL algorithms generally suffer from poor stability  and GANs themselves can have convergence issues. This imposes another layer of possible instability. \n \nBesides, generating useful reward function, while not trivial, can be seen as easier than solving the full RL problem. \nCan the authors argue why this model class was chosen over other, more simple, generative models?  \nFurthermore, did the authors do experiments with simpler models?\n\nRelated:\n""We found that the LSGAN works better than other forms of GAN for our problem."" \nWas this improvement minor, or major, or didn\'t even work with other GAN types? This question is important, because for me the big question is if this model is universal and stable in a lot of applications or requires careful fine-tuning and monitoring. \n\n---\nUpdate:\nThe authors addressed  the major point of criticism in my review.  I am now more convinced in the quality of the proposed work, and have updated my review score accordingly.']","[20, -20, 70]","[60, 50, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's technical contributions as 'sound' and recognizes the method's ability to improve training efficiency. However, they also express some concerns and difficulties in fully understanding the paper, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and uses polite expressions like 'it is unclear to me' instead of direct criticisms. The reviewer also provides specific, constructive feedback for improvement, which is a polite approach to peer review. The language is professional and objective, avoiding any harsh or rude expressions."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper addresses an interesting question and has some positive aspects ('Pro' section), there are more criticisms and concerns raised ('Con' section) than praise. The reviewer expresses doubts about the clarity of the experimental setup, the generalizability of the method, and the stability of the approach. However, the score is not deeply negative as the reviewer still sees value in the work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms (e.g., 'It is not clear to me...', 'This method doesn't seem to...') rather than harsh or dismissive statements. The reviewer also acknowledges the importance of the problem being addressed and some positive aspects of the work before delving into criticisms. However, the score is not extremely high as the review is primarily focused on critiquing the work rather than offering excessive praise or encouragement."", ""The sentiment score is 70 (positive) because the reviewer starts by stating it's a 'good paper' and votes for acceptance. They praise the writing and approach, indicating a generally positive view. However, it's not 100 as they do raise some concerns and questions. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the authors' efforts to address concerns in the update. The reviewer maintains a professional and constructive tone, even when expressing doubts or requesting clarifications.""]"
"['The authors propose to drop the recurrent state-to-gates connections from RNNs to speed up the model. The recurrent connections however are core to an RNN. Without them, the RNN defaults simply to a CNN with gated incremental pooling. This results in a somewhat unfortunate naming (simple *recurrent* unit), but most importantly makes a comparison with autoregressive sequence CNNs [ Bytenet (Kalchbrenner et al 2016), Conv Seq2Seq (Dauphin et al, 2017) ] crucial in order to show that gated incremental pooling is beneficial over a simple CNN architecture baseline. \n\nIn essence, the paper shows that autoregressive CNNs with gated incremental pooling perform comparably to RNNs on a number of tasks while being faster to compute. Since it is already extensively known that autoregressive CNNs and attentional models can achieve this, the *CNN* part of the paper cannot be counted as a novel contribution. What is left is the gated incremental pooling operation; but to show that this operation is beneficial when added to autoregressive CNNs, a thorough comparison with an autoregressive CNN baseline is necessary.\n\nPros:\n- Fairly well presented\n- Wide range of experiments, despite underwhelming absolute results\n\nCons:\n- Quasi-RNNs are almost identical and already have results on small-scale tasks.\n- Slightly unfortunate naming that does not account for autoregressive CNNs\n- Lack of comparison with autoregressive CNN baselines, which signals a major conceptual error in the paper.\n- I would suggest to focus on a small set of tasks and show that the model achieves very good or SOTA performance on them, instead of focussing on many tasks with just relative improvements over the RNN baseline.\n\nI recommend showing exhaustively and experimentally that gated incremental pooling can be helpful for autoregressive CNNs on sequence tasks (MT, LM and ASR). I will adjust my score accordingly if the experiments are presented.\n\n', ""The authors introduce SRU, the Simple Recurrent Unit that can be used as a substitute for LSTM or GRU cells in RNNs. SRU is much more parallel than the standard LSTM or GRU, so it trains much faster: almost as fast as a convolutional layer with properly optimized CUDA code. Authors perform experiments on numerous tasks showing that SRU performs on par with LSTMs, but the baselines for these tasks are a little problematic (see below).\n\nOn the positive side, the paper is very clear and well-written, the SRU is a superbly elegant architecture with a fair bit of originality in its structure, and the results show that it could be a significant contribution to the field as it can probably replace LSTMs in most cases but yield fast training. On the negative side, the authors present the results without fully referencing and acknowledging state-of-the-art. Some of this has been pointed out in the comments below already. As another example: Table 5 that presents results for English-German WMT translation only compares to OpenNMT setups with maximum BLEU about 21. But already a long time ago Wu et. al. presented LSTMs reaching 25 BLEU and current SOTA is above 28 with training time much faster than those early models (https://arxiv.org/abs/1706.03762). While the latest are non-RNN architectures, a table like Table 5 should include them too, for a fair presentation. In conclusion: the authors seem to avoid discussing the problem that current non-RNN architectures  could be both faster and yield better results on some of the studied problems. That's bad presentation of related work and should be improved in the next versions (at which point this reviewer is willing to revise the score). But in all cases, this is a significant contribution to deep learning and deserves acceptance.\n\nUpdate: the revised version of the paper addresses all my concerns and the comments show new evidence of potential applications, so I'm increasing my score."", 'This work presents the Simple Recurrent Unit architecture which allows more parallelism than the LSTM architecture while maintaining high performance.\n\nSignificance, Quality and clarity:\nThe idea is well motivated: Faster training is important for rapid experimentation, and altering the RNN cell so it can be paralleled makes sense. \nThe idea is well explained and the experiments convince that the new architecture is indeed much faster yet performs very well.\n\nA few constructive comments:\n- The experiment’s tables alternate between “time” and “speed”, It will be good to just have one of them.\n- Table 4 has time/epoch yet only time is stated']","[-50, 70, 80]","[20, 60, 70]","[""The sentiment score is -50 because the review is generally critical of the paper, pointing out several cons and suggesting major revisions. However, it's not entirely negative as it acknowledges some pros and offers constructive feedback. The politeness score is 20 because while the reviewer maintains a professional tone and offers suggestions for improvement, the language is direct and doesn't use many polite phrases. The reviewer uses phrases like 'fairly well presented' and 'I recommend', which add a degree of politeness, but also uses more critical language like 'major conceptual error' and 'underwhelming absolute results'."", ""The sentiment score is 70 (positive) because the reviewer expresses strong approval of the paper's clarity, the elegance of the SRU architecture, and its potential significance to the field. They recommend acceptance and increased their score after revisions. However, they also point out some shortcomings in the presentation of related work, which prevents a higher score. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging both strengths and weaknesses constructively. They offer specific suggestions for improvement and express willingness to revise their score, which demonstrates courtesy. The tone is professional and objective, avoiding harsh criticism while still pointing out areas for improvement."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the work, describing it as 'well motivated', 'well explained', and stating that the experiments 'convince that the new architecture is indeed much faster yet performs very well'. The politeness score is 70 (polite) due to the constructive and respectful tone throughout. The reviewer uses phrases like 'well motivated' and 'constructive comments', and offers specific, helpful suggestions for improvement without any harsh criticism. The overall tone is professional and supportive, though not excessively formal or deferential, hence the score of 70 rather than higher.""]"
"['This is a mostly experimental paper which evaluates the capabilities of neural networks with weight matrices that are block diagonal. The authors describe two methods to obtain this structure: (1) enforced during training, (2) enforced through regularization and pruning. As a second contribution, the authors show experimentally that the random matrix theory can provide a good model of the spectral behavior of the weight matrix when it is large. However, the authors only conjecture as to the potential of this method without describing clear ways of approaching this subject, which somewhat lessens the strength of their argument.\n\nQuality: this paper is of good quality\nClarity: this paper is clear, but would benefit from better figures and from tables to report the numerical results instead of inserting them into plain text.\nOriginality: this paper introduces block diagonal matrices to structure the weights of a neural network. The idea of structured matrices in this context is not new, but the diagonal block structure appears to be.  \nSignificance: This paper is somewhat significant.\n\nPROS \n- A new approach to analyzing the behavior of weight matrices during learning\n- A new structure for weight matrices that provides good performance while reducing matrix storage requirements and speeding up forward and backward passes.\n\nCONS\n- Some of the figures are hard to read (in particular Fig 1 & 2 left) and would benefit from a better layout.\n- It would be valuable to see experiments on bigger datasets than only MNIST and CIFAR-10. \n- I understand that the main advantage of this method is the speedup; however, providing the final accuracy as a function of the nonzero entries for slower methods (e.g. the sparse pruning showed in Fig 1. a) would provide a more complete picture.\n\nMain questions:\n- Could you briefly comment on the training time in section 4.1? \n- Could you elaborate on the last sentence of section 4.1?\n- You state: ""singular values of an IP layer behave according to the MP distribution even after 1000s of training iterations."" Is this a known fact, or something that you observed empirically? In practice, how large must the weight matrix be to observe this behavior?\n\nNitpicks:\n- I believe the term ""fully connected"" is more standard than ""inner product"" and would add clarity to the paper, but I may be mistaken. ', 'The paper proposes to make the inner layers in a neural network be block diagonal, mainly as an alternative to pruning. The implementation of this seems straightforward, and can be done either via initialization or via pruning on the off-diagonals. There are a few ideas the paper discusses:\n\n(1) compared to pruning weight matrices and making them sparse, block diagonal matrices are more efficient since they utilize level 3 BLAS rather than sparse operations which have significant overhead and are not ""worth it"" until the matrix is extremely sparse. I think this case is well supported via their experiments, and I largely agree.\n\n(2) that therefore, block diagonal layers lead to more efficient networks. This point is murkier, because the paper doesn\'t discuss possible increases in *training time* (due to increased number of iterations) in much detail. At if we only care about running the net, then reducing the time from 0.4s to 0.2s doesn\'t seem to be that useful (maybe it is for real-time predictions? Please cite some work in that case)\n\n(3) to summarize points (1) and (2), block diagonal architectures are a nice alternative to pruned architectures, with similar accuracy, and more benefit to speed (mainly speed at run-time, or speed of a single iteration, not necessarily speed to train)\n\n[as I am not primarly a neural net researcher, I had always thought pruning was done to decrease over-fitting, not to increase computation speed, so this was a surprise to me; also note that the sparse matrix format can increase runtime if implemented as a sparse object, as demonstrated in this paper, but one could always pretend it is sparse, so you never ought to be slower with a sparse matrix]\n\n(4) there is some vague connection to random matrices, with some limited experiments that are consistent with this observation but far from establish it, and without any theoretical analysis (Martingale or Markov chain theory)\n\nThis is an experimental/methods paper that proposes a new algorithm, explained only in general details, and backs up it up with two reasonable experiments (that do a good job of convincing me of point (1) above). The authors seem to restrict themselves to convolutional networks in the first paragraph (and experiments) but don\'t discuss the implications or reasons of this assumption. The authors seem to understand the literature well, and not being an expert myself, I have the impression they are doing a fair job.\n\n\nThe paper could have gone farther experimentally (or theoretically) in my opinion. For example, with sparse and block diagonal matrices, reducing the size of the matrix to fit into the cache on the GPU must obviously make a difference, but this did not seem to be investigated. I was also wondering about when 2 or more layers are block sparse, do these blocks overlap? i.e., are they randomly permuted between layers so that the blocks mix? And even with a single block, does it matter what permutation you use? (or perhaps does it not matter due to the convolutional structure?)\n\nThe section on the variance of the weights is rather unclear mathematically, starting with the abstract and even continuing into the paper. We are talking about sample variance? What does DeltaVar mean in eq (2)? The Marchenko-Pastur theorem seemed to even be imprecise, since if y>1, then a < 0, implying that there is a nonzero chance that the positive semi-definite matrix XX\' has a negative eigenvalue.\n\nI agree this relationship with random matrices could be interesting, but it seems too vague right now. Is there some central limit theorem explanation? Are you sure that you\'ve run enough iterations to fully converge? (Fig 4 was still trending up for b1=64). Was it due to the convolutional net structure (you could test this)? Or, perhaps train a network on two datasets, one which is not learnable (iid random labels), and one which is very easily learnable (e.g., linearly separable). Would this affect the distributions?\n\nFurthermore, I think I misunderstood parts, because the scaling in MNIST and CIFAR was different and I didn\'t see why (for MNIST, it was proportional to block size, and for CIFAR it was independent of block size almost).\n\nMinor comment: last paragraph of 4.1, comparing with Sindhwani et al., was confusing to me. Why was this mentioned? And it doesn\'t seem to be comparable. I have no idea what ""Toeplitz (3)"" is.', 'This paper proposes replacing fully connected layers with block-diagonal fully connected layers and proposes two methods for doing so.  It also make some connections to random matrix theory.\n\nThe parameter pruning angle in this paper is fairly weak.  The networks it is demonstrated on are not particularly large (largeness usually being the motivation for pruning) and the need for making them smaller is not well motivated.  Additionally MNIST is a uniquely bad dataset for evaluating pruning methods, since they tend to work uncharacteristically well on MNIST (This can be seen in some of the references the paper cites).\n\nThe random matrix theory part of this paper is intriguing, but left me wondering ""and then what?""  It is presented as a collection of observations with no synthesis or context for why they are important.  I\'m usually quite happy to see connections being made to other fields, but it is not clear at all how this particular connection is more than a curiosity.  This paper would be much stronger if it offered some way to exploit this connection.\n\nThere are two half-papers here, one on parameter pruning and one on applying insights from random matrix theory to neural networks, but I don\'t see a strong connection between them. Moreover, they are both missing their other half where the technique or insight they propose is exploited to achieve something. \n']","[50, 20, -50]","[75, 60, 0]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's good quality, clarity, and originality, while also pointing out some limitations. They mention both pros and cons, indicating a balanced view. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases their concerns as questions or suggestions rather than harsh criticisms. The reviewer also acknowledges the paper's strengths before discussing areas for improvement, which is a polite approach to feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and finds some aspects well-supported, particularly point (1). However, they also express several criticisms and areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges their own potential lack of expertise in some areas, and frames criticisms constructively. They use phrases like 'I think,' 'in my opinion,' and 'I agree,' which maintain a collegial tone. The reviewer also provides detailed feedback and suggestions for improvement, which is a polite and helpful approach in academic review."", ""The sentiment score is -50 because the review is generally critical of the paper, pointing out several weaknesses and limitations. The reviewer mentions that the parameter pruning angle is 'fairly weak', the need for making networks smaller is 'not well motivated', and the random matrix theory part is presented as 'a collection of observations with no synthesis or context'. However, the reviewer does acknowledge some positive aspects, such as the 'intriguing' random matrix theory part, which prevents the score from being more negative. The politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout, neither being particularly polite nor rude. The language is direct and critical but not personal or offensive. The reviewer uses phrases like 'This paper would be much stronger if...' which offers constructive criticism without being overly harsh or overly polite.""]"
"['This paper proposes to join temporal logic with hierarchical reinforcement learning to simplify skill composition.  The combination of temporal logic formulas with reinforcement learning was developed previously in the literature, and the main contribution of this paper is for fast skill composition.  The system uses logic formulas in truncated linear temporal logic (TLTL), which lacks an Always operator and where the LTL formula (A until B) also means that B must eventually hold true. The temporal truncation also requires the use of a specialized MDP formulation with an explicit and fixed time horizon T.  The exact relationship between the logical formulas and the stochastic trajectories of the MDP is not described in detail here, but relies on a robustness metric, rho.  The main contributions of the paper are to provide a method that converts a TLTL formula that specifies a task into a reward function for a new augmented MDP (that can be used by a conventional RL algorithm to yield a policy), and a method for quickly combining two such formulas (and their policies) into a new policy.  The proposed method is evaluated on a small Markov chain and a simulated Baxter robot.\n\nThe main problem with this paper is that the connections between the TLTL formulas and the conventional RL objectives are not made sufficiently clear.  The robustness term rho is essential, but it is not defined.  I was also confused by the notation $D_\\phi^q$, which was described but not defined.  The method for quickly combining known skills (the zero-shot skill composition in the title) is switching between the two policies based on rho.  The fact that there may be many policies which satisfy a particular reward function (or TLTL formula) is ignored.  This means that skill composition that is proposed in this paper might be quite far from the best policy that could be learned directly from a single conjunctive TLTL formula. It is unclear how this approach manages tradeoffs between objectives that are specified as a conjunction of TLTL goals. is it better to have a small probability of fulfilling all goals, or to prefer a high probability of fulfilling half the goals?  In short the learning objectives of the proposed composition algorithm are unclear after translation from TLTL formulas to rewards.\n', 'I very much appreciate the objectives of this paper:  learning compositional structures is critical for scaling and transfer.  \n\nThe first part of the paper offers a strategy for constructing a product MDP out of an original MDP and the automaton associated with an LTL formula, and reminds us that we can learn within that restricted MDP.  Some previous work is cited, but I would point the authors to much older work of Parr and Russell on HAMs (hierarchies of abstract machines) and later work by Andre and Russell, which did something very similar (though, indeed, not in hybrid domains).  The idea of extracting policies corresponding to individual automaton states and making them into options seems novel, but it would be important to argue that those options are likely to be useful again under some task distribution. \n\nThe second part offers an exciting result:  If we learn policy pi_1 to satisfy objective phi_1 and policy pi_2 to satisfy objective phi_2, then it will be possible to switch between pi_1 and pi_2 in a way that satisfies phi_1 ^ phi_2.   This just doesn\'t make sense to me.  What if phi_1 is o ((A v B) Until C) and phi_2 is o ((not A v B) Until C).   Let\'s assume that o(B Until C) is satisfiable, so the conjunction is satisfiable.  However, we may find policy pi_1 that makes A true and B false (in general, there is no single optimal policy) and find pi_2 that makes A false and B false, and it will not be possible to satisfy the phi_1 and phi_2 by switching between the policies.    But, perhaps I am misunderstanding something.\n\nSome other smaller points:\n- ""zero-shot skill composition"" sounds a lot like what used to be called ""planning"" or ""reasoning""\n- The function rho is originally defined on whole trajectories but in eq 7 it is only on a single s\':  I\'m not sure exactly what that means.\n- Section 4:  How is ""as soon as possible"" encoded in this objective?\n- How does the fixed horizon interact with conjoining goals?\n- There are many small errors in syntax;  it would be best to have this paper carefully proofread.', 'The paper argues for structured task representations (in TLTL) and shows how these representations can be used to reuse learned subtasks to decrease learning time.\n\nOverall, the paper is sloppily put together, so it\'s a little difficult to assess the completeness of the ideas. The problem being solved is not literally the problem of decreasing the amount of data needed to learn tasks, but a reformulation of the problem that makes it unnecessary to relearn subtasks. That\'s a good idea, but problem reformulation is always hard to justify without returning to a higher level of abstraction to justify that there\'s a deeper problem that remains unchanged. The paper doesn\'t do a great job of making that connection.\n\nThe idea of using task decomposition to create intrinsic rewards seems really interesting, but does not appear to be explored in any depth. Are there theorems to be had? Is there a connection to subtasks rewards in earlier HRL papers?\n\nThe lack of completeness (definitions of tasks and robustness) also makes the paper less impactful than it could be.\n\nDetailed comments:\n\n""learn hierarchical policies"" -> ""learns hierarchical policies""?\n\n""n games Mnih et al. (2015)Silver et al. (2016),"": The citations are a mess. Please proof read.\n\n""and is hardly reusable"" -> ""and are hardly reusable"".\n\n""Skill composition is the idea of constructing new skills with existing skills ("" -> ""Skill composition is the idea of constructing \nnew skills out of existing skills ("".\n\n""to synthesis"" -> ""to synthesize"".\n\n""set of skills are"" -> ""set of skills is"".\n\n""automatons"" -> ""automata"".\n\n""with low-level controllers can"" -> ""with low-level controllers that can"".\n\n""the options policy π o is followed until β(s) > threshold"": I don\'t think that\'s how options were originally defined... beta is generally defined as a termination probability.\n\n""The translation from TLTL formula FSA to"" -> ""The translation from TLTL formula to FSA""?\n\n""four automaton states Qφ = {q0, qf , trap}"": Is it three or four?\n\n""learn a policy that satisfy"" -> ""learn a policy that satisfies"".\n\n""HRL, We introduce the FSA augmented MDP"" -> ""HRL, we introduce the FSA augmented MDP."".\n\n"" multiple options policy separately"" -> "" multiple options policies separately""?\n\n""Given flat policies πφ1 and πφ2 that satisfies "" -> ""Given flat policies πφ1 and πφ2 that satisfy "".\n\n""s illustrated in Figure 3 ."" -> ""s illustrated in Figure 2 .""?\n\n"", we cam simply"" -> "", we can simply"".\n\n""Figure 4 <newline> ."" -> ""Figure 4."".\n\n"", disagreement emerge"" -> "", disagreements emerge""?\n\nThe paper needs to include SOME definition of robustness, even if it just informal. As it stands, it\'s not even clear if larger \nvalues are better or worse. (It would seem that *more* robustness is better than less, but the text says that lower values are \nchosen.)\n\n""with 2 hidden layers each of 64 relu"": Missing word? Or maybe a comma?\n\n""to aligns with"" -> ""to align with"".\n\n"" a set of quadratic distance function"" -> "" a set of quadratic distance functions"".\n\n""satisfies task the specification)"" -> ""satisfies the task specification)"".\n\nFigure 4: Tasks 6 and 7 should be defined in the text someplace.\n\n""current frame work i"" -> ""current framework i"".\n\n"" and choose to follow"" -> "" and chooses to follow"".\n\n"" this makes"" -> "" making"".\n\n""each subpolicies"" -> ""each subpolicy"".\n']","[-30, -20, -50]","[50, 60, 0]","[""The sentiment score is -30 because while the reviewer acknowledges the paper's contributions, they express significant concerns about the clarity of connections between TLTL formulas and RL objectives, undefined terms, and potential limitations of the proposed method. The review starts neutrally but becomes increasingly critical, indicating a slightly negative overall sentiment. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism while clearly stating their concerns. They use phrases like 'The main problem with this paper is...' and 'I was also confused by...' which maintain a polite tone while providing constructive feedback. The reviewer also acknowledges the paper's contributions before delving into criticisms, which is a polite approach in academic reviews."", ""The sentiment score is slightly negative (-20) because while the reviewer appreciates the objectives of the paper and finds some aspects 'exciting', they express significant concerns and confusion about key parts of the work. They point out potential misunderstandings and errors, which suggests a generally critical stance. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, starting with 'I very much appreciate' and using phrases like 'I would point the authors to' and 'perhaps I am misunderstanding something'. They offer constructive criticism and suggestions rather than harsh judgments. The reviewer maintains a professional and courteous tone even when expressing doubts or pointing out errors."", ""The sentiment score is -50 because the review starts with a negative tone, describing the paper as 'sloppily put together' and pointing out several shortcomings. However, it's not entirely negative as it acknowledges some good ideas and interesting concepts. The politeness score is 0 (neutral) because while the reviewer doesn't use overtly polite language, they also don't use rude or disrespectful language. The critique is direct and professional, focusing on the content rather than personal attacks. The reviewer provides specific, constructive feedback and suggestions for improvement, which is standard in academic peer reviews.""]"
"['In this paper, the authors propose a recurrent GAN architecture that generates continuous domain sequences. To accomplish this, they use a generator LSTM that takes in a sequence of random noise as well as a sequence of conditonal information and outputs a sequence. The discriminator LSTM takes a sequence (and conditional information) as input and classifies each element of the sequence as real or synthetic -- the entire sequence is then classified by vote. The authors evaluate on several synthetic tasks, as well as an ICU timeseries data task.\n\nOverall, I thought the paper was clearly written and extremely easy to follow. To the best of my knowledge, the method proposed by the authors is novel, and differs from traditional sentence generation (as an example) models because it is intended to produce continuous domain outputs. Furthermore, the story of generating medical training data for public release is an interesting use case for a model like this, particularly since training on synthetic data appears to achieve not competitive but quite reasonable accuracy, even when the model is trained in a differentially private fashion.\n\nMy most important piece of feedback is that I think it would be useful to include a few examples of the eICU time series data, both real and synthetic. This might give a better sense of: (1) how difficult the task is, (2) how much variation there is in the real data from patient to patient, and (3) how much variation we see in the synthetic time series. Are the synthetic time series clearly multimodal, or do they display some of the mode collapse behavior occasionally seen in GANs?\n\nI would additionally like to see a few examples of the time series data at both the 5 minute granularity and the 15 minute granularity. You claim that downsampling the data to 15 minute time steps still captures the relevant dynamics of the data -- is it obvious from the data that variations in the measured variables are not significant over a 5 minute interval? As it stands, this is somewhat an unknown, and should be easy enough to demonstrate.', 'The authors propose to use synthetic data generated by GANs as a replacement for personally identifiable data in training ML models for privacy-sensitive applications such as medicine. In particular it demonstrates adversarial training of a recurrent generator for an ICU monitoring multidimensional time series, proposes to evaluate such models by the performance (on real data) of supervised classifiers trained on the synthetic data (""TSTR""), and empirically analyzes the privacy implications of training and using such a model. \n\nThis paper touches on many interesting issues -- deep/recurrent models of time series, privacy-respecting ML, adaptation from simulated to real-world domains. But it is somewhat unfocused and does not seem make a clear contribution to any of these. \n\nThe recurrent GAN architecture does not appear particularly novel --- the authors note that similar architectures have been used for discrete tasks such language modeling (and fail to note work that uses convolutional or recurrent generators for video prediction, a more relevant continuous task, see e.g.  http://carlvondrick.com/tinyvideo/, or autoregressive approaches to deep models of time series, e.g. WaveNet https://arxiv.org/abs/1609.03499) and there is no obvious new architectural innovation. \n\nI also find it difficult to assess whether the proposed model is actually generating reasonable time series. It may be true that ""one plot showing synthetic ICU data would not provide enough information to evaluate its actual similarity to the real data"" because it could not rule out that case that the model has captured the marginal distribution in each dimension but not joint structure. However producing marginal distributions that look reasonable is at least a *necessary* condition and without seeing those plots it is hard to rule out that the model may be producing highly unrealistic samples. \n\nThe basic privacy paradigm proposed seems to be:\n1. train a GAN using private data\n2. generate new synthetic data, assume this data does not leak private information\n3. train a supervised classifier on the private data\nso that the GAN training-sampling loop basically functions as an anonymization procedure. For this to pan out, we\'d need to see that the GAN samples are a) useful for a range of supervised tasks, and b) do not leak private information. But the results  in Table 2 show that the TSTR results are quite a lot worse than real data in most cases, and it\'s not obvious that the small set of tasks evaluated are representative of all tasks people might care about. The attempts to demonstrate empirically that the GAN does not memorize training data aren\'t particularly convincing; this is an adversarial setting so the fact that a *particular* test doesn\'t reveal private data doesn\'t imply that a determined attacker wouldn\'t succeed. In this vein, the experiments with DP-\x0fSGD are more interesting, although a more direct comparison would be helpful (it is frustrating to flip back and forth between Tables 2 and 3 in an attempt to tease out relative performance) and and it is not clear how the settings (ε \x0f\x0f\x0f= 0.5 and δ ≤ 9.8 × 10−3) were selected or whether they provide a useful level of privacy. That said I agree this is an interesting avenue for future work.\n\nFinally it\'s worth noting that discarding patients with missing data is unlikely to be innocuous for ICU applications; data are quite often not missing at random (e.g., a patient going into a seizure may dislocate a sensor). It appears that the analysis in this paper threw out more than 90% of the patients in their original dataset, which would present serious concerns in using the resulting synthetic data to represent the population at large. One could imagine coding missing data in various ways (e.g. asking the generator to produce a missingness pattern as well as a time series and allowing the discriminator to access only the masked time series, or explicitly building a latent variable model) and some sort of principled approach to missing data seems crucial for meaningful results on this application. ', 'This paper proposes to use RGANs and RCGANS to generate synthetic sequences of actual data. They demonstrate the quality of the sequences on sine waves, MNIST, and ICU telemetry data.\n\nThe authors demonstrate novel approaches for generating real-valued sequences using adversarial training, a train on synthetic, test of real and vice versa method for evaluating GANS, generating synthetic medical time series data, and an empirical privacy analysis. \n\nMajor\n- the medical use case is not motivating. de-identifying the 4 telemetry measures is extremely easy and there is little evidence to show that it is even possible to reidentify individuals using these 4 measures. our institutional review board would certainly allow self-certification of the data (i.e. removing the patient identifiers and publishing the first 4 hours of sequences).\n- the labels selected by the authors for the icu example are to forecast the next 15 minutes and whether a critical value is reached. Please add information about how this critical value was generated. Also it would be very useful to say that a physician was consulted and that the critical values were ""clinically"" useful.\n- the changes in performance of TSTR are large enough that I would have difficulty trusting any experiments using the synthetic data. If I optimized a method using this synthetic data, I would still need to assess the result on real data.\n- In addition it is unclear whether this synthetic process would actually generate results that are clinically useful. The authors certainly make a convincing statement about the internal validity of the method. An externally valid measure would strengthen the results. I\'m not quite sure how the authors could externally validate the synthetic data as this would also require generating synthetic outcome measures. I think it would be possible for the synthetic sequence to also generate an outcome measure (i.e. death) based on the first 4 hours of stay.\n\nMinor\n- write in the description for table 1 what task the accuracies correspond.\n\nSummary\nThe authors present methods for generating synthetic sequences. The MNIST example is compelling. However the ICU example has some pitfalls which need to be addressed.']","[80, -50, -20]","[90, 20, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, describing it as 'clearly written and extremely easy to follow' and praising its novelty and interesting use case. The reviewer also finds the method and results reasonable. The score is not 100 as there are some suggestions for improvement. The politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They offer praise before giving feedback, and frame their suggestions as requests ('I would like to see') rather than demands. The reviewer also acknowledges the authors' claims and asks for clarification rather than dismissing them outright. The tone is consistently professional and courteous."", ""The sentiment score is -50 because the reviewer expresses several criticisms and concerns about the paper, including that it is 'unfocused', lacks clear contribution, and has unconvincing results. However, they do acknowledge some interesting aspects, preventing a more negative score. The politeness score is 20 because the reviewer uses generally professional language and offers constructive criticism. They use phrases like 'it is difficult to assess' and 'it's worth noting' rather than harsh or dismissive language. The reviewer also suggests areas for improvement and future work, which is a polite approach in academic reviews. However, the overall critical tone prevents a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some novel approaches and compelling examples, they raise several major concerns about the medical use case and the reliability of the synthetic data. The reviewer suggests that the ICU example has 'pitfalls which need to be addressed', indicating overall skepticism about a key part of the paper. The politeness score is moderately positive (50) as the reviewer uses professional and constructive language throughout. They acknowledge the paper's strengths before detailing concerns, use phrases like 'Please add' and 'it would be very useful', and offer suggestions for improvement rather than just criticism. The tone remains respectful even when pointing out significant issues.""]"
"[""This is an interesting paper focusing on building discrete reprentations of sequence by autoencoder. \nHowever, the experiments are too weak to demonstrate the effectiveness of using discrete representations.\nThe design of the experiments on language model is problematic.\nThere are a few interesting points about discretizing the represenations by saturating sigmoid and gumbel-softmax, but the lack of comparisons to benchmarks is a critical defect of this paper. \n\n\nGenerally, continuous vector representations are more powerful than discrete ones, but discreteness corresponds to some inductive biases that might help the learning of deep neural networks, which is the appealing part of discrete representations, especially the stochastic discrete representations. \nHowever, I didn't see the intuitions behind the model that would result in its superiority to the continuous counterpart. \nThe proposal of DSAE might help evaluate the usage of the 'autoencoding function' c(s), but it is certainly not enough to convince people. \nHow is the performance if c(s) is replaced with the representations achieved from autoencoder, variational autoencoder or simply the sentence vectors produced by language model?\nThe qualitative evaluation on 'Deciperhing the Latent Code' is not enough either. \nIn addition, the language model part doesn't sound correct, because the model cheated on seeing the further before predicting the words autoregressively.\nOne suggestion is to change the framework to variational auto-encoder, otherwise anything related to perplexity is not correct in this case.\n\nOverall, this paper is more suitable for the workshop track. It also needs a lot of more studies on related work."", 'The authors describe a method for encoding text into a discrete representation / latent space. On a measure that they propose, they should it outperforms an alternative Gumbel-Softmax method for both language modeling and NMT.\n\nThe proposed method seems effective, and the proposed DSAE metric is nice, though it’s surprising if previous papers have not used metrics similar to normalized reduction in log-ppl. The datasets considered in the experiments are also large, another plus. However, overall, the paper is difficult to read and parse, especially since low-level details are weaved together with higher-level points throughout, and are often not motivated.\n\nThe major critique would be the qualitative nature of results in the sections on “Decipering the latent code” and (to a lesser extent) “Mixed sample-beam decoding.” These two sections are simply too anecdotal, although it is nice being stepped through the reasoning for the single example considered in Section 3.3. Some quantitative or aggregate results are needed, and it should at least be straightforward to do so using human evaluation for a subset of examples for diverse decoding.\n', ""The topic is interesting however the description in the paper is lacking clarity. The paper is written in a procedural fashion - I first did that, then I did that and after that I did third. Having proper mathematical description and good diagrams of what you doing would have immensely helped. Another big issue is the lack of proper validation in Section 3.4. Even if you do not know what metric to use to objectively compare your approach versus baseline there are plenty of fields suffering from a similar problem yet  doing subjective evaluations, such as listening tests in speech synthesis. Given that I see only one example I can not objectively know if your model produces examples like that 'each' time so having just one example is as good as having none. ""]","[-50, 20, -50]","[20, 50, 0]","[""The sentiment score is -50 because while the reviewer acknowledges some interesting aspects of the paper, they express significant concerns about the experiments and methodology. The review starts positively but quickly shifts to highlighting major weaknesses, suggesting the paper is more suitable for a workshop track. The politeness score is 20 because the reviewer uses relatively neutral language and offers constructive criticism. They use phrases like 'interesting paper' and 'interesting points' which maintain a respectful tone. However, they also directly state problems without much softening language, keeping the score only slightly positive. The reviewer offers suggestions for improvement, which is a polite approach to criticism."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some strengths of the paper, such as the effectiveness of the proposed method, the nice DSAE metric, and the use of large datasets. However, they also point out significant weaknesses, particularly in the readability and the qualitative nature of some results. The overall tone suggests a balanced view with a slight positive lean.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful language throughout. They acknowledge the authors' work and provide constructive criticism without using harsh or dismissive language. Phrases like 'The proposed method seems effective' and 'it is nice being stepped through the reasoning' demonstrate a polite approach. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional tone."", ""The sentiment score is -50 because the review is generally critical, pointing out several significant issues with the paper, such as lack of clarity, poor mathematical description, and inadequate validation. However, it's not entirely negative as it acknowledges the topic is interesting. The politeness score is 0 (neutral) because the reviewer's language is direct and matter-of-fact without being overtly polite or rude. They state their criticisms plainly without using harsh language or personal attacks, but also without softening their critique with polite phrases or compliments beyond the initial acknowledgment of an interesting topic.""]"
"[""Quality: The paper proposes a direct improvement over SeqGAN by Yu. et. al. (2017). My assessment is partially determined by comparing this paper to Yu et. al (2017). In my opinion, this paper is lacking in quality in comparison to Yu et. al (2017). In particular, Yu et. al. (2017) provides detailed derivation of the policy gradient accompanied by a pseudo-code (algorithm) on how one can implement SeqGAN. On the contrary, this paper does not provide such details. Perhaps, all of the details of SeqGAN follows immediately, but the paper should not assume that all readers will be familiar with SeqGAN. \n\nClarity: \n\n1. The paper provides a review of related methods on conditional sequence generation in Section 3. However, it is very brief and as a non-expert in this field, I needed to refer to the original papers anyways. Perhaps, the review of the related methods can go to the Appendix and this space can be better utilized to expand on the original contributions made by the paper. \n2. MCMC (Markov chain Monte Carlo) is mentioned in 4.1 but it is not explained. \n3. Figure 1 is not sufficiently explained; neither in text nor in the figure caption. It would help greatly to describe the details of the network architecture shown in this figure.\n\nOriginality: The paper proposes a generalization of SeqGAN; however, in my opinion, the methodological contribution appears to be only incremental on SeqGAN. \n\nSignificance: The paper's significance may be evaluated in terms of its impact on applications as it proposes an improvement over the previous work of SeqGAN. However, the extent to which the evaluation is carried out is somewhat unsatisfactory with only one real application. Also, the applications considered in the experiments are primarily on dialogue generation. My initial impression is that the methodology lacks generality and may perhaps cater better to domain specific publication venues. \n"", 'UPDATE, 1/11/18:\nI read the revision. The writing has improved, and the new experiments are good. That said, it is my opinion that the paper is still not quite ready for publication, mostly because the story behind the model doesn\'t lead to the conclusions being made from the experiments in a clean and consistent way. It\'s a bit like patchwork at this point. The authors I think will need to put some time into a rewrite, but the content itself is worth pushing forward.\n\nSome notes:\n""StepGAN a general version of SeqGAN, and can simulate the process of Monte-Carlo search with low extra computational cost:"" This really is a strong claim that\'s not proven in any way in the paper.\n""In typical reinforcement learning, the agent obtains a reward..."": in typical RL settings, it\'s just as likely to find single or episodal rewards and this setting isn\'t limited to those where you have an extrinsic reward at each step.\nWhy do you still have WGAN-GP when there are no accompanying numbers?\n\n/begin old review\nThe approach is interesting, but as a contribution the paper has a long way to go. The ideas are there and everything seems correct, but there’s little motivation / insight on the model and why it might be better than competing methods for NLP tasks.\n\nIt would be good to see some sort of concrete analysis as far as what the model is doing (for instance how the discriminator scores change), and a comparison of how the reward signal given here might differ from other methods (SeqGAN, MaliGAN), and why this might be better. All we get is some scores, but it’s never clear why these scores indicate good (conditional) language generation. Can we not also look at BLEU scores for language generation or some other metric?\n\nFinally, the writing need to be improved: it starts out OK, but it progressively gets worse and worse.\n\nDetailed notes:\nP2\nIt might be good to mention beam search and scheduled sampling as other common methods to address the exposure bias.\n“objective function irrelevant to backpropagation”: what does this mean?\nMaliGAN actually also uses a “policy gradient”, which corresponds to an estimate of the likelihood ratio, to address the discrete problem.\nThough distinct from this work, Gulrajani used a CNN.\n\nP3\nUse \\log for logarithm\n“Moreover, the likelihood is only estimated at word-level”: is this true? It seems to me that likelihood of the sequence is estimated as well.\n\nP5\nWhy is this a generalized version of SeqGAN? The claim the discriminator value D(x_1..t | y) is the same as what you would get from a full-sequence generator using MCMC seems like a stretch.\nDid you not use a baseline?\nYou might want to build in a little more motivation for these different update rules. I think I understand that (10) is meant to accumulate credit across the rest of the sequence, while (11) does not, but it would be good to have this clearly stated. Why do you think one would work better than the other?\n\nP6\n“The generator G, in the mean time, struggle to maximize the likelihood of discriminator D” I don’t understand what this means.\nWhat was the motivation for using the same model here? Is the energy in this formulation related in any ways to EBGAN? Could you do something similar with separate parameters? Why would be or why would this not be a good idea?\nI do like these synthetic tasks. I think that more analyses would be helpful in understanding what the model (and what competing models) are doing.\n\nP7:\nWhat is VLGAN in the table?\nPerhaps it would be worth exploring changing alpha through optimization?\n\nP8:\nIt seems like many of the improvements in the table are marginal (with some exceptions): is it possible that ESGAN was optimized better?\n“auxiliary tricks” I would avoid this wording.\n\nOther comments on experiments:\nIt seems like the actual NLP part of this paper is quite sparse. Why was MaliGAN left out of the real experiments?', ""The authors present a new scheme for applying adversarial networks to dialog generation. The idea of why using adversarial networks is important in dialog generation is really well motivated in the paper and related works are discussed in details. \n\nIn the proposed approach, a more flexible discrimination score is obtained by treating independently each sub-sequence of the input. Technically speaking, the authors' contribution is to add a set of free parameters in the sub-sequence discriminator sum of equation 8. From a more general point of view, what is the key output of the paper, except to confirm that curriculum learning can help in dialog generation?  \n\nThe experiments do not seem to show that a net performance improvement can be associated with the introduced free weights and what is a good strategy to tune them in an optimal way. In general, as the authors report also in the abstract, the performance of the proposed algorithm is 'comparable' with the state of the art but never outperforms other existing methods in a consistent way. \n\nIn fact, the performance of the algorithms depends strongly on the specific grammar used to generate the dataset and on the specific evaluation score. The human evaluation experiment is interesting but the proposed method is only compared with one other algorithm (seqGAN) and only two examples of the output are given explicitly.\n\nThe increase in computational cost due to the weighted sub-sequence evaluation is also poorly discussed.   \n\nFew more questions:\n-through the experiments section, the authors focus on evaluating the set of possible good answers (softmax and coverage score) instead of the best answer (argmax). Why is this important for dialog generation? In the generation of a real conversation, shouldn t one always choose the argmax option? What would be a practical use of the second and third-best options?\n-why softmax is always lower than argmax in the synthetic experiment and always higher than argmax in the human evaluation experiment?\n-why MLE, which is used as initialization, does better than all optimized models in the first simulation? Why is the GAN approach expected to increase the coverage compared to MLE? And why, in general, this is not always the case?\n-would it be possible to compare the output of the proposed methods with the output of a non-GAN conditional sequence generator (if any) on human-scored dialog?  ""]","[-60, -20, -20]","[20, 50, 50]","[""The sentiment score is -60 because the reviewer expresses several criticisms and concerns about the paper's quality, clarity, originality, and significance. They state that the paper is 'lacking in quality' compared to a previous work, has insufficient explanations, and makes only 'incremental' contributions. The overall tone is predominantly negative, though not extremely harsh. The politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively respectful tone. They use phrases like 'in my opinion' and 'perhaps,' which soften the criticism. The reviewer also provides specific suggestions for improvement, which is constructive. However, the language is not overtly polite or complimentary, hence the modest positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges improvements and sees value in the content, they still express significant concerns about the paper's readiness for publication. The reviewer states that 'the paper is still not quite ready for publication' and points out several issues that need addressing. However, they also note positive aspects like improved writing and good new experiments, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and balance criticism with positive remarks. The language used is respectful and focuses on the work rather than personal attacks. Phrases like 'It would be good to see' and 'Perhaps it would be worth exploring' demonstrate a polite approach to giving feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (good motivation, detailed discussion of related works), they express several criticisms and concerns. These include the lack of consistent outperformance over existing methods, strong dependence on specific grammars and evaluation scores, limited human evaluation, and poor discussion of computational costs. The reviewer also raises several questions that suggest skepticism about some aspects of the work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They begin with positive comments and frame their criticisms as questions or observations rather than direct attacks. The language used is neutral and academic, avoiding harsh or personal criticism. However, the score is not higher because the review doesn't go out of its way to be exceptionally polite or encouraging, maintaining a fairly neutral, matter-of-fact tone in its criticisms.""]"
"['This paper addresses multiagent learning problems in which there is a social dilemma: settings where there are no \'cooperative polices\' that form an equilibrium. The paper proposes a way of dealing with these problems via amTFT, a variation of the well-known tit-for-that strategy, and presents some empirical results.\n\nMy main problem with this paper is clarity and I am afraid that not everything might be technically correct. Let me just list my main concerns in the below.\n\nThe definition of social dilemma, is unclear:\n""A social dilemma is a game where there are no cooperative policies which form equilibria. In other\nwords, if one player commits to play a cooperative policy at every state, there is a way for their\npartner to exploit them and earn higher rewards at their expense.""\ndoes this mean to say ""there are no cooperative *Markov* policies"" ? It seems to me that the paper precisely intents to show that by resorting to history-dependent policies (such as both using amTFT), there is a cooperative equilibrium. \n\nI don\'t understand:\n""Note that in a social dilemma there may be policies which achieve the payoffs of cooperative policies because they cooperate on the trajectory of play and prevent exploitation by threatening non-cooperation on states which are never reached by the trajectory. If such policies exist, we call the social dilemma solvable.""\nis this now talking about non-Markov policies? If not, there seems to be a contradiction?\n\nThe work focuses on TFT-like policies, motivated by \n""if one can commit to them, create incentives for a partner to behave cooperatively""\nhowever it seems that, as made clear below definition 4, we can only create such incentives for sufficiently powerful agents, that remember and learn from their failures to cooperate in the past?\n\nWhy is the method called ""approximate Markov""? As soon as one introduces history dependence, the Markov property stops to hold?\n\nOn page 4, I have problems following the text due to inconsistent use of notation: subscripts and superscripts seem random, it is not clear which symbols denote strategy profiles (rather than individual strategies), there seems mix-ups between \'i\' and \'1\' / \'2\', there is sudden use of \\hat{}, and other undefined symbols (Q_CC?).\n\nFor all practical purposes, it seems that the made assumptions imply uniqueness of the cooperative joint strategy. I fully appreciate that the coordination question is difficult and important, so if the proposed method is not compatible with dealing with that important question, that strikes me as a large drawback.\n\nI have problems understanding how it is possible to guarantee ""If they start in a D phase, they eventually return to a C phase."" without making more assumptions on the domain. The clear example being the typical \'heaven or hell\' type of problems: what if after one defect, we are trapped in the \'hell\' state where no cooperation is even possible? \n\n""If policies converge with this training then πˆ is a Markov equilibrium (up to function approximation)."" There are two problems here:\n1) A problem is that very typically things will not converge... E.g., \nWunder, Michael, Michael L. Littman, and Monica Babes. ""Classes of multiagent q-learning dynamics with epsilon-greedy exploration."" Proceedings of the 27th International Conference on Machine Learning (ICML-10). 2010.\n2) ""Up to function approximation"" could be arbitrary large?\n\n\nAnother significant problem seems to be with this statement:\n""while in the cooperative reward schedule the standard RL convergence guarantees apply. The latter is because cooperative training is equivalent to one super-agent controlling both players and trying to optimize for a single scalar reward."" The training of individual learners is quite different from ""joint action learners"" [Claus & Boutilier 98], and this in turn is different from a \'super-agent\' which would also control the exploration. In absence of the super-agent, I believe that the only guarantee is that one will, in the limit, converge to a Nash equilibrum, which might be arbitrary far from the optimal joint policy. And this only holds for the tabular case. See the discussion in \nA concise introduction to multiagent systems and distributed artificial intelligence. N Vlassis. Synthesis Lectures on Artificial Intelligence and Machine Learning 1 (1), 1-71\n\nAlso, the approach used in the experiments ""Cooperative (self play with both agents receiving sum of rewards) training for both games"", would be insufficient for many settings where a cooperative joint policy would be asymmetric.\n\nThe entire approach hinges on using rollouts (the commented lines in Algo. 1). However, it is completely not clear to me how this works. The one paragraph is insufficient to get across these crucial parts of the proposed approach.\n\nIt is not clear why the tables in Figure 1 are not symmetric; this strikes me as extremely problematic. It is not clear what the colors encode either.\n\nIt also seems that ""grim"" is better against all, except against amTFT, why should we not use that? In general, the explanation of this closely related paper by De Cote & Littman (which was published at UAI\'08), is insufficient. It is not quite clear to me what the proposed approach offers over the previous method.\n\n\n\n\n\n\n\n\n\n', 'About the first point, it does not present a clear problem definition. The paper continues stating what it should do (e.g.  ""our agents only live once at at test time and must maintain cooperation by behaving intelligently within the confines of a single game rather than threats across games."") without any support for these desiderata. It then continues explaining how to achieve these desiderata, but at this point it is impossible to follow a coherent argument without understanding why are the authors making these strong assumptions about the problem they are trying to solve, and why. Without this problem description and a good motivation, it is impossible to assess why such desiderata (which look awkward to me) are important. The paper continues defining some joint behavior (e.g. cooperative policies), but then construct arguments for individual policy deviations, including elements like \\pi_A and \\Pi_2^{A_k} that, as you see, A is used sometimes as subindex and sometimes as supperindex. Could not follow this part, as such elements lack definition. D_k is also not defined. \n\nExperiments are uninteresting and show same results as many other RL algorithms that have been proposed in the past. No comparison with such other approaches is presented, nor even recognized. The paper should include a related work section that explain such similar approaches and their difference with this approach. The paper should continue the experimental section making explicit comparisons with such related work.\n\n**Detailed suggestions**\n- On page 2 you say ""This methodology cannot be directly applied to our problem"" without first defining what the problem is.\n- When authors talk about the agent, it is unclear what agent they refer to\n- \\delta undefined\n- You say selfish reward schedule each agent i treats the other agent just as a part of their environment. However, you need to make some assumption about its behavior (e.g. adversarial, cooperative, etc.) and this disregarded. ', 'This paper studies learning to play two-player general-sum games with state (Markov games). The idea is to learn to cooperate (think prisoner\'s dilemma) but in more complex domains. Generally, in repeated prisoner\'s dilemma, one can punish one\'s opponent for noncooperation. In this paper, they design an apporach to learn to cooperate in a more complex game, like a hybrid pong meets prisoner\'s dilemma game. This is fun but I did not find it particularly surprising from a game-theoretic or from a deep learning point of view. \n\nFrom a game-theoretic point of view, the paper begins with somewhat sloppy definitions followed by a theorem that is not very surprising. It is basically a straightforward generalization of the idea of punishing, which is common in ""folk theorems"" from game theory, to give a particular equilibrium for cooperating in Markov games. Many Markov games do not have a cooperative equilibrium, so this paper restricts attention to those that do. Even in games where there is a cooperative solution that maximizes the total welfare, it is not clear why players would choose to do so. When the game is symmetric, this might be ""the natural"" solution but in general it is far from clear why all players would want to maximize the total payoff. \n\nThe paper follows with some fun experiments implementing these new game theory notions. Unfortunately, since the game theory was not particularly well-motivated, I did not find the overall story compelling. It is perhaps interesting that one can make deep learning learn to cooperate, but one could have illustrated the game theory equally well with other techniques.\n\nIn contrast, the paper ""Coco-Q: Learning in Stochastic Games with Side Payments"" by Sodomka et. al. is an example where they took a well-motivated game theoretic cooperative solution concept and explored how to implement that with reinforcement learning. I would think that generalizing such solution concepts to stochastic games and/or deep learning might be more interesting.\n\nIt should also be noted that I was asked to review another ICLR submission entitled ""CONSEQUENTIALIST CONDITIONAL COOPERATION IN\nSOCIAL DILEMMAS WITH IMPERFECT INFORMATION\n"" which amazingly introduced the same ""Pong Player’s Dilemma"" game as in this paper. \n\nNotice the following suspiciously similar paragraphs from the two papers:\n\nFrom ""MAINTAINING COOPERATION IN COMPLEX SOCIAL DILEMMAS USING DEEP REINFORCEMENT LEARNING"":\nWe also look at an environment where strategies must be learned from raw pixels. We use the method\nof Tampuu et al. (2017) to alter the reward structure of Atari Pong so that whenever an agent scores a\npoint they receive a reward of 1 and the other player receives −2. We refer to this game as the Pong\nPlayer’s Dilemma (PPD). In the PPD the only (jointly) winning move is not to play. However, a fully\ncooperative agent can be exploited by a defector.\n\nFrom ""CONSEQUENTIALIST CONDITIONAL COOPERATION IN SOCIAL DILEMMAS WITH IMPERFECT INFORMATION"":\nTo demonstrate this we follow the method of Tampuu et al. (2017) to construct a version of Atari Pong \nwhich makes the game into a social dilemma. In what we call the Pong Player’s Dilemma (PPD) when an agent \nscores they gain a reward of 1 but the partner receives a reward of −2. Thus, in the PPD the only (jointly) winning\nmove is not to play, but selfish agents are again tempted to defect and try to score points even though\nthis decreases total social reward. We see that CCC is a successful, robust, and simple strategy in this\ngame.']","[-60, -70, -30]","[20, -20, 20]","[""The sentiment score is -60 because the review is predominantly critical, pointing out numerous issues with clarity, technical correctness, and methodology. The reviewer expresses significant concerns about the paper's definitions, assumptions, and conclusions. However, it's not entirely negative as the reviewer acknowledges the importance of the topic. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and phrases like 'My main problem is...' and 'I am afraid that...', which soften the critique. The reviewer also uses 'Let me just list my main concerns' which is a polite way to introduce criticisms. However, the overall tone is more matter-of-fact than overtly polite, hence the relatively low positive score."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several major issues with the paper, including lack of clear problem definition, unsupported assumptions, confusing notation, uninteresting experiments, and lack of comparison with related work. There are no positive comments about the paper's content.\n\nThe politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite direct and critical. Phrases like 'impossible to follow a coherent argument', 'experiments are uninteresting', and 'Could not follow this part' come across as somewhat harsh. However, the reviewer does provide specific suggestions for improvement, which slightly mitigates the negative tone."", ""The sentiment score is -30 because the reviewer expresses several criticisms and doubts about the paper's contribution and motivation, using phrases like 'not particularly surprising', 'somewhat sloppy definitions', and 'not particularly well-motivated'. However, they do acknowledge some positive aspects ('fun experiments'), preventing the score from being more negative. The politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language and offering constructive criticism. They avoid harsh or personal attacks, instead focusing on the paper's content. The reviewer also provides suggestions for improvement and references to related work, which is helpful and courteous. However, the overall critical nature of the review prevents the politeness score from being higher.""]"
"['This paper proposes a model for generating long text strings given shorter text strings, and for inferring suitable short text strings given longer strings. Intuitively, the inference step acts as a sort of abstractive summarization. The general gist of this paper is to take the idea from ""Language as a Latent Variable"" by Miao et al., and then change it from a VAE to an adversarial autoencoder. The authors should cite ""Adversarial Autoencoders"" by Makzhani et al. (ICLR 2016).\n\nThe experiment details are a bit murky, and seem to involve many ad-hoc decisions regarding preprocessing and dataset management. The vocabulary is surprisingly small. The reconstruction cost is not precisely explained, though I assume it\'s a teacher-forced conditional log-likelihood (conditioned on the ""summary"" sequence). The description of baselines for REINFORCE is a bit strange -- e.g., annealing a constant in the baseline may affect variance of the gradient estimator, but the estimator is still unbiased and shouldn\'t significantly impact exploration. Similar issues are present in the ""Self-critical..."" paper by Rennie et al. though, so this point isn\'t a big deal.\n\nThe results look decent, but I would be more impressed if the authors could show some benefit relative to the supervised model, e.g. in a reasonable semisupervised setting. Overall, the paper covers an interesting topic but could use extra editing to clarify details of the model and training procedure, and could use some redesign of the experiments to minimize the number of arbitrary (or arbitrary-seeming) decisions.', 'TL;DR of paper: Generating summaries by using summaries as an intermediate representation for autoencoding the document. An encoder reads in the document to condition the generator which outputs a summary. The summary is then used to condition the decoder which is trained to output the original document. An additional GAN loss is used on the generator output to encourage the output to look like summaries -- this procedure only requires unpaired summaries. The results are that this procedure improves upon the trivial baseline  but still significantly underperforms supervised training.\n\nThis paper builds upon two recent trends:  a) cycle consistency, where f(g(x)) = x, which only requires unpaired data (i.e., CycleGAN), and (b) encoder-decoder models with a sequential latent representation (i.e., ""Language as a latent variable"" by Miao and Blunsom). A similar idea has also been explored by He et al. 2016 in ""Dual Learning for Machine Translation"". Both CycleGAN and He et al. 2016 are not cited. The key difference between this paper and He et al. 2016 is the use of GANs so only unpaired summaries are needed.\n\nThe idea is a simple but useful extension of these previous works. The problem set-up of unpaired summarization is not particularly compelling, since summaries are typically found paired with their original documents. It would be more interesting to see how well it can be used for other textual domains such as translation, where a lot of unpaired data exists (some other submissions to ICLR tackle this problem). Unsurprisingly, the proposed method requires a lot of twiddling to make it work since GANs, REINFORCE, and pretraining are necessary.\n\nA key baseline that is missing is pretraining the generator as a language model over summaries. The pretraining baseline in the paper is over predicting the next sentence / reordering, but this is an unfair comparison since the next sentence baseline never sees summaries over the course of training. Without this baseline, it is hard to tell whether GAN training is even useful. Another experiment missing is seeing whether joint supervised-GAN-reconstruction training can outperform purely supervised training. What is the performance of the joint training as the size of the supervised dataset is varied?\n\nThis paper has numerous grammatical and spelling errors throughout the paper (worse, the same errors are copy-pasted everywhere). Please spend more time editing the paper.\n\n', 'Summary: In this work, the authors propose a text reconstructing auto encoder which takes a sentence as the input sequence and an integrated text generator generates another version of the input text while a reconstructor determines how well this generated text reconstructs the original input sequence. The input to the discriminator (as real data) is a sentence that summarizes the ground truth sentences (rather than the ground truth sentences themselves). The experiments are conducted in two datasets of English and Chinese corpora.\n\nStrengths:\nThe proposed idea of generating text using summary sentences is new.\nThe model overview in Figure 1 is informative.\nThe experiments are conducted on English and Chinese corpora, comparison with competitive baselines are provided.\n\nWeaknesses:\nThe paper is poorly written which makes it difficult to understand. The second paragraph in the introduction is quite cryptic. Even after reading the entire paper a couple of times, it is not clear how the summary text is obtained, e.g. do the authors ask annotators to read sentences and summarize them? If so, based on which criteria do the annotators summarize text, how many annotators are there? Similarly, if so this would mean that the authors use additional supervision than the compared models. Please clarify how the summary text is obtained.\n\nIn footnote 1, the authors mention “seq2seq2seq2” term which they do not explain anywhere in the text.\n\nNo experiments that generate raw text (without using summaries) are provided. It would be interesting to see if GAN learns to memorize the ground truth sentences or generates sentences with enough variation. \n\nIn the English Gigaword dataset the results consistently drop compared to WGAN. This behavior is observed for both the unsupervised setting and two versions of transfer learning settings. There are too few qualitative results: One positive qualitative result is provided in Figure 3 and one negative qualitative result is provided in Figure 4. Therefore, it is not easy for the reader to judge the behavior of the model well. \n\nThe choice of the evaluation metric is not well motivated. The standard measures in the literature also include METEOR, CIDER and SPICE. It would be interesting to see how the proposed model performs in these additional criteria. Moreover, the results are not sufficiently discussed. \n\nAs a general remark, although the idea presented in this paper is interesting, both in terms of writing and evaluation, this paper has not yet reached the maturity expected from an ICLR paper. Regarding writing, the definite and indefinite articles are sometimes missing and sometimes overused, similarly most of the times there is a singular/plural mismatch. This makes the paper very difficult to read. Often the reader needs to guess what is actually meant. Regarding the experiments, presenting results with multiple evaluation criteria and showing more qualitative results would improve the exposition.\n\nMinor comments:\nPage 5: real or false —> real or fake (true or false)\n\t     the lower loss it get —> ?']","[-20, -20, -50]","[50, 20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper covers an interesting topic, they express several concerns about the clarity of experiment details, ad-hoc decisions, and the need for additional editing and experiment redesign. The reviewer also suggests the results are only 'decent' and could be more impressive. However, it's not entirely negative as they recognize the topic's interest and some positive aspects. The politeness score is moderately positive (50) as the reviewer uses professional language throughout, offers constructive criticism, and balances negative points with positive ones. They use phrases like 'could use extra editing' and 'could use some redesign' rather than more harsh critiques, maintaining a respectful tone while still clearly communicating areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's idea as 'simple but useful', they point out several significant issues. These include missing baselines, unconvincing problem set-up, and numerous grammatical errors. The reviewer also suggests that the method requires 'a lot of twiddling to make it work'. However, the score isn't deeply negative because the reviewer does recognize some value in the work.\n\nThe politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout. They offer constructive criticism and suggestions for improvement rather than harsh criticism. The language used is direct but not rude, with phrases like 'It would be more interesting to see...' and 'Please spend more time editing the paper.' However, the score isn't higher because the review doesn't include many explicitly polite phrases or compliments, and the final comment about grammatical errors could be seen as somewhat blunt."", ""The sentiment score is -50 because while the reviewer acknowledges some strengths of the paper (new idea, informative figure, experiments on multiple datasets), they highlight significant weaknesses that suggest the paper is not yet ready for publication. These include poor writing, unclear methodology, lack of comprehensive experiments, and insufficient discussion of results. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'Please clarify' and 'It would be interesting to see', while also providing constructive feedback. However, some direct criticisms like 'The paper is poorly written' and 'this paper has not yet reached the maturity expected' slightly lower the politeness score from being highly positive.""]"
"['Summary:\nThis paper presents very nice experiments comparing the complexity of various different neural networks using the notion of ""learnability"" --- the learnability of a model (N1) is defined as the ""expected agreement"" between the output of N1, and the output of another model N2 which has been trained to match N1 (on a dataset of size n).  The paper suggests that the learnability of a model is a good measure of how simple the function learned by that model is --- furthermore, it shows that this notion of learnability correlates well (across extensive experiments) with the test accuracy of the model.\n\nThe paper presents a number of interesting results:\n1) Larger networks are typically more learnable than smaller ones (typically we think of larger networks as being MORE complicated than smaller networks -- this result suggests that in an important sense, large networks are simpler).\n2) Networks trained with random data are significantly less learnable than networks trained on real data.\n3) Networks trained on small mini-batches (larger variance SGD updates) are more learnable than those trained on large minibatches.\n\nThese results are in line with several of the observations made by Zhang et al (2017), which showed that neural networks are able to both (a) fit random data, and (b) generalize well; these results at first seem to run counter to the ideas from statistical learning theory that models with high capacity (VC dimension, radamacher complexity, etc.) have much weaker generalization guarantees than lower capacity models.  These results suggest that models that have high capacity (by one definition) are also capable of being simple (by another definition).  These results nicely complement the work which studies the ""sharpness/curvature"" of the local minima found by neural networks, which argue that the minima which generalize better are those with lower curvature.\n\nReview:\nQuality:  I found this to be high quality work. The paper presents many results across a variety of network architectures.  One area for improvement is presenting results on larger datasets (currently all experiments are on CIFAR-10), and/or on non-convolutional architectures.  Additionally, a discussion of why learnabiblity might imply low generalization error would have been interesting (the more formal, the better), though it is unclear how difficult this would be.\n\nClarity:  The paper is written clearly.  A small point: Step 2 in section 3.1 should specify that argmax of N1(D2) is used to generate labels for the training of the second network.  Also, what dataset D_i is used for tables 3-6? Please specify.\n\nOriginality: The specific questions tackled in this paper are original (learnability on random vs. real data, large vs. small networks, and large vs. small mini-batch training).  But it is unclear to me exactly how original this use of ""learnability"" is in evaluating how simple a model is.  It seems to me that this particular use of ""learnability"" is original, even though PAC learnability was defined a while ago.\n\nSignificance:  I find the results in this paper to be quite significant, and to provide a new way of understanding why deep neural networks generalize.  I believe it is important to find new ways of formally defining the ""simplicity/capacity"" of a model, such that ""simpler"" models can be proven to have smaller generalization gap (between train and test error) relative to more ""complicated"" models. It is clear that VC dimension and radamacher complexity alone are not enough to explain the generalization performance of neural networks, and that neural networks with high capacity by these definitions are likely ""simple"" by other definitions (as we have seen in this paper).  This paper makes an important contribution to this conversation, and could perhaps provide a starting point for theoreticians to better explain why deep networks generalize well.\n\nPros\n- nice experiments, with very interesting results.\n- Helps explain one way in which large networks are in fact ""simple""\n\nCons\n- The paper does not attempt to relate the notion of learnability to that of generalization performance.  All it says is that these two metrics appear to be well correlated.', 'The proposed approach to figure out what do deep network learn is interesting -- the approach of learning a learned network. Some aspects needs more work to improve the work. The presentation of the results can be improved further. \n\nFirstly, confidence intervals on many experiments are missing (including Tables 3-9). Also, since we are looking at empirically validating the learnability criterion defined by the authors, all the results (the reported confusion tables) need to be tested statistically (to see whether one dominates the other). \n\nWhat is random label learning of N1 telling us? How different would that be in terms of simply learning random labels on real data directly. Further, the evaluations in Tables 3-6 need more attention since we are interested in the TLP=1 vs. PLP=0 case, and TLP=0 vs. PLP=1 case. \n\nThe influence of depth is not clear -- may be it is because of the way results are reported here. A simple figure with increasing layers vs. learnability values would do a better job at conveying the trends. \n\nThe evaluations in Section 3.5 are not conclusive? What is the question being tested for here? \n\nWhat about the influence of number of classes on learnability trends? Some experiments on large class datasets including cifar100 and/or imagenet need to be reported. \n\n--- Comments after response from authors --- \n\nThe authors have clarified and shown results for several of the issues I was concerned about. Although it is still unclear what the learnability model is capturing for deeper model or the trends in Section 3.5 (looks like the trends may relate to stability of SGD as well here) -- the proposed ideas are worth discussing. I have appropriately modified my rating. \n\n', 'Review Summary:\nThe primary claim that there is ""a strong correlation between small generalization errors and high learnability"" is correct and supported by evidence, but it doesn\'t provide much insight for the questions posed at the beginning of the paper or for a general better understanding of theoretical deep learning. In fact the relationship between test accuracy and learnability seems quite obvious, which unfortunately undermines the usefulness of the learnability metric which is used in many experiments in the paper.\n\nFor example, consider the results in Table 7. A small network (N1 = 16 neurons) with low test accuracy results in a low learnability, while a large network (N1 = 1024 neurons) gets a higher test accuracy and higher learnability. In this case, the small network can be thought of as applying higher label noise relative to the larger network. Thus it is expected that agreement between N1 and N2 (learnability) will be higher for the larger network, as the predictions of N1 are less noisy. More importantly, this relationship between test accuracy and learnability doesn\'t answer the original question Q2 posed: ""Do larger neural networks learn simpler patterns compared to neural networks when trained on real data"". It instead draws some obvious conclusions about noisy labeling of training data.\n\nOther results presented in the paper are puzzling and require further experimentation and discussion, such as the trend that the learnability of shallow networks on random data is much higher than 10%, as discussed at the bottom of page 4. The authors provide some possible reasoning, stating that this strange effect could be due to class imbalance, but it isn\'t convincing enough.\n\nOther comments:\n-Section 3.4 is unrelated to the primary arguments of the paper and seems like a filler.\n-Equations should have equation numbers\n-Learnability numbers reported in all tables should be between 0-1 per the definition on page 3\n-As suggested in the final sentence of the discussion, it would be nice if conclusions drawn from the learnability experiments done in this paper were applied to the design new networks which better generalize']","[80, 20, -50]","[90, 50, 20]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, describing it as 'high quality work' with 'very interesting results' and 'significant' findings. They use phrases like 'nice experiments' and state that the paper 'makes an important contribution'. The few criticisms are minor and constructive. The politeness score is 90 (very polite) due to the consistently respectful and professional tone. The reviewer uses phrases like 'I found this to be...', 'I believe...', and offers suggestions for improvement in a gentle manner, such as 'One area for improvement is...' and 'A small point:...'. The reviewer also balances critique with praise throughout, maintaining a courteous and constructive approach."", ""The sentiment score is slightly positive (20) because the reviewer finds the approach 'interesting' and acknowledges that the authors have clarified some issues, but still expresses concerns about certain aspects needing more work. The overall tone is constructive rather than overtly negative or positive. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers specific suggestions for improvement, and acknowledges the authors' responses. The reviewer avoids harsh criticism and frames concerns as areas for further development rather than outright flaws. The language is professional and objective, maintaining a courteous tone even when pointing out limitations."", ""The sentiment score is -50 because the reviewer expresses significant criticism of the paper's main claims and findings. They state that the primary claim is 'correct and supported by evidence, but it doesn't provide much insight' and describe some results as 'obvious' and 'puzzling'. However, it's not entirely negative as they acknowledge some correct aspects. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'it would be nice if' and provide constructive suggestions. The language is not overtly polite, but it avoids rudeness and harsh criticism, instead focusing on specific issues and potential improvements.""]"
"['I am highly sympathetic to the goals of this paper, and the authors do a good job of contrasting human learning with current deep learning systems, arguing that the lack of a mechanism for few-shot learning in such systems is a barrier to applying them in realistic scenarios. However, the main evaluation only considers four words - ""bonuses"", ""explained"", ""marketers"", ""strategist"" - with no explanation of how these words were chosen. Can I really draw any meaningful conclusions from such an experimental setup? Even the authors acknowledge, in footnote 1, that, for one of the tests, getting lower perplexity in three out of the four casess ""may just be chance variation, of course"". I wonder why we can\'t arrive at a similar conclusion for the other results in the paper. At the very least I need convincing that this is a reasonable experimental paradigm.\n\nI don\'t understand the first method for initializing the word embeddings. How can we use the ""current"" embedding for a word if it\'s never been seen before? What does ""current"" mean in this context?\n\nI also didn\'t understand the Latin square setup. Training on ten different permutations of the ten sentences suggests that all ten sentences are being used, so I don\'t see how this can lead to a few-shot or one-shot scenario.\n\n', 'Paper Summary\n\nFrom just seeing a word used in a sentence, humans can infer a lot about this word by leveraging the surrounding words. Based on this idea, this work tries to obtain a better understanding of words in the one-shot or few-shot setting by leveraging surrounding word. They do this by language modeling sentences which contain rarely seen or never seen words. They evaluated their model using percent change in perplexity on test sentences containing new word by varying the number of training sentences containing this word. 3 Proposed Methods to model few-shot words: (1) beginning with random embedding, (2) beginning with zero embedding (3) beginning with the centroid of other words in the sentence. They compare to 2 Baseline Methods: (1) centroid of other words in the sentence, and (2) full training including the sparse words. Their results show that learning from centroids of other words can outperform full training on the new words. \n\nExplanation\nThe paper is well written, and the experiments are well explained.  It is an interesting paper, and a research topic which is not well studied. The experiments are reasonable. The method seems to work well. \n\nHowever, the method provides a very marginal difference between the previous method in Lazaridou et al. (2017). They just use backdrop to learn from this starting position. The main contribution of this work is the evaluation section. \n\nWhy only use the PTB language modeling task. Why not use the task in Gauthier & Mordatch or Hermann et al. The one task of language modeling shows promising results, but it’s not totally convincing. \n\nOne of the biggest caveats is that the experiments are only done in a few words. I’m not sure why more couldn’t have been done. This is discussed in section 4.1, but I think some of these differences could have been alleviated if there were more experiments done. Regardless, the experiments on the 8 words that they did chose were well done. \n\nI don’t think that section 3.3 (embedding similarity) is particularly useful. \n', 'The paper proposes a technique for exploiting prior knowledge to learn embedding representations for new words with minimal data. The authors provide a good motivation for the task and it is also a nice step in the general direction of learning deep nets and other systems with minimal supervision. \n\nThe problem is useful and very relevant to natural language applications, especially considering the widespread use of word embeddings within NLP systems. However, the demonstrated experimental results do not match the claims which seems a little grand. Overall, the empirical results is unsatisfactory. The authors pick a few example words and provide a detailed analysis. This is useful to understand how the test perplexity varies with #training examples for these individual settings. However, it is hardly enough to draw conclusion about the general applicability of the technique or effectiveness of the results. Why were these specific words chosen? If the reason is due to some statistical property (e.g., frequency) observed in the corpus, then why not generalize this idea and demonstrate empirical results for a class of words exhibiting the property. Such an analysis would be useful to understand the effectiveness of the overall approach. Another idea would be to use the one/few-shot learning to learn embeddings and evaluate their quality on a semantic task (as suggested in Section 3.3), but on a larger scale.\n\nThe technical contributions are also not novel. Coupled with the narrow experimentation protocol, it does not make the paper’s contributions or proposed claims convincing.\n']","[-20, 20, -50]","[60, 60, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer expresses sympathy for the paper's goals and acknowledges some positive aspects, they raise significant concerns about the experimental setup and methodology. The reviewer questions the validity of conclusions drawn from such a limited dataset and expresses confusion about certain aspects of the methodology. These criticisms outweigh the initial positive remarks, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, starting with a positive acknowledgment and framing criticisms as questions or personal confusions rather than direct attacks. The use of phrases like 'I am highly sympathetic,' 'the authors do a good job,' and 'I need convincing' maintain a polite tone while still conveying critical feedback."", 'The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is well-written, interesting, and addresses an understudied topic. They also note that the experiments are reasonable and the method works well. However, the score is not higher due to several criticisms, such as the marginal improvement over previous methods, limited experimental scope, and some sections being deemed not particularly useful. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, balancing praise with constructive criticism. They avoid harsh or dismissive language, instead offering suggestions for improvement and acknowledging the strengths of the work alongside its limitations. The tone remains professional and courteous throughout the review.', ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects (good motivation, relevance to NLP), they express significant concerns about the experimental results and novelty of the technical contributions. The overall tone is more negative than positive, but not entirely dismissive. The politeness score is 20 because the reviewer uses respectful language and offers constructive criticism, suggesting improvements rather than outright rejecting the work. They acknowledge the paper's strengths before delving into criticisms, which is a polite approach. However, the language is not overly deferential or excessively polite, maintaining a professional tone throughout.""]"
"['This paper concerns open-world classification.  The open-world related tasks have been defined in many previous works. This paper had made a good survey. \nThe only special point of the open-word classification task defined in this paper is to employ the constraints from the similarity/difference expected for examples from the same class or from different classes.  Unfortunately, this paper is lack of novelty. \n\nFirstly, the problem context and setting is kinda synthesized. I cannot quite imagine in what kind of applications we can get “a set of pairs of intra-class (same class) examples, and the negative training data consists of a set of pairs of inter-class”.\n\nSecondly, this model is just a direct combination of the recent powerful algorithms such as DOC and other simple traditional models. I do not really see enough novelty here.\n\nThirdly, the experiments are only on the MNIST and EMNIST; still not quite sure any real-world problems/datasets can be used to validate this approach.\nI also cannot see the promising performance. The clustering results of rejected\nexamples are still far from the ground truth, and comparing the result with\na total unsupervised K-means is a kind of unreasonable.\n', 'This paper focuses on the sub-problem of discovering previously unseen classes for open-world classification. \nIt employs a previously proposed system, Open Classification Network, for classifying instances into known classes or rejecting as belonging to an unseen class, and applies hierarchical clustering to the rejected instances to identify unseen classes.\nThe key novel idea is to learn a pairwise similarity function using the examples from the known classes to apply to examples of unknown classes. The argument is that we tend to use the same notion of similarity and dissimilarity to define classes (known or unknown) and one can thus expect the similarity function learned from known classes to carry over to the unknown classes.  This concept is not new. Similar idea has been explored in early 2000 by Finley and Joachims in their ICML paper titled ""Supervised Clustering with Support Vector Machines"".  But to the best of my knowledge, this is the first paper that applies this concept to the open world classification task. \n\nOnce we learn the similarity function, the rest of the approach is straightforward, without any particular technical ingenuity.  It simply applies hierarchical clustering on the learned similarities and use cross-validation to pick a stopping condition for deciding the number of clusters.  \nI find the experiments to be limited, only on two hand-written digits/letters datasets.  Such datasets are too simplistic. For example, simply applying kmeans to PCA features of the images on the MNIST data can get you pretty good performance.  \nExperiments on more complex data is desired, for example on Imagenet classes. \n\nAlso the results do not clearly demonstrate the advantage of the proposed method, in particular the benefit of using PCN. The number of clusters found by the algorithm is not particularly accurate and the NMI values obtained by the proposed approach does not show any clear advantage over baseline methods that do not use PCN. \n\nSome minor comments:\nWhen applied to the rejected examples, wouldn\'t the ground truth # of clusters no longer be 4 or 10 because there are some known-class examples mixed in? \nFor the base line Encoder+HC, was the encoder trained independently? Or it\'s trained jointly with PCN and OCN?  It is interesting to see the impact of incorporating PCN into the training of OCN and encoder. Does that have any impact on accuracy of OCN? \nIt seems that one of the claimed benefit is that the proposed method is effective at identifying the k. If so, it would be necessary to compared the proposed method to some classic methods for identifying k with kmeans, such as the elbow method, BIC, G-means etc, especially since kmeans seem to give much better NMI values.\n\n\n', 'The main goal of this paper is to cluster images from classes unseen during training.\nThis is an interesting extension of the open-world paradigm, where at test time, the classifier has to identify images beloning to the C seen classes during training, but also identify (reject) images which were previously unseen. These rejected images could be clustered to identify the number of unseen classes; either for revealing the underlying structure of the unseen classes, or to reduce annotation costs.\n\nIn order to do so, an extensive framework is proposed, consisting of 3 ConvNet architectures, followed by a hierarchical clustering approach. The 3 ConvNets all have a different goal:\n1. an Open Classification Network (per class sigmoid, trained 1vsRest, with thresholds for rejection)\n2. Pairwise Classification Network, (binary sigmoid, trained on pairs of images of same/different classes)\n3. Auto encoder network\n\nThese network are jointly trained, and the joint-loss is simply the addition of a cross-entropy loss (from OCN), the binary cross-entropy loss (from PCN) and a pixel wise loss (from AE). \nRemarks:\n- it is unclear if the ConvNet weights of the first layers are shared). \n- it is unclear how joint training might help, given that the objectives do not influence each other\n- Eq 1: \n  *label ""y_i"" has two different semantics (L_ocn it is the class label, while in L_pcn it is the label of an image pair being from the same class or not)\n  * s_j is undefined\n  * relation between the p(y_i = 1) (in PCN) and g(x_p,x_q) in Eq 2 could be made more explicit, PCN depends on two images, according to Eq 1, it seems just a sum over single images.\n- It is unclear why the Auto Encoder network is added, and what its function is.\n- It is unclear wether OCN requires/uses unseen class examples during training.\n- Last paragraph of 3.1 ""The 1-vs-rest ... rejected"", I don\'t see why you need 1vsRest classifiers for this, a multi-class (softmax) output can also be thresholded to reject an test image from the known classes and to assign it to the unknown class.\n\n\nExperimental evaluation\nThe experimental evaluation uses 2 datasets, MNIST and EMNIST, both are very specific for character recognition. It is a pity that not also more general image classification has been considered (CIFAR100, ImageNet, Places365, etc), that would provide insights to the more general behaviour of the proposed ideas.\n\nMy major concern is that the clustering task is not extensively explored. Just a single setting (with a single random sampling of seen/unseen classes) has been evaluated. This is -in part- due to the nature of the chosen datasets, in a 10 class dataset it is difficult to show the influence of the number of unseen classes. So, I\'d really urge the authors to extend this evaluation. Will the method discover more classes when 100 unknown classes are used? What kind of clusters are discovered? Are the types of classes in the seen/unseen classes important, I\'d expect at least multiple runs of the current experiments on (E)MNIST. \n\nFurther, I miss some baselines and ablation study. Questions which I\'d like to seen answered: how good is the OCN representation when used for clustering compared to the PCN representation? What is the benefit of joint-training? How important is the AE in the loss?\n\nRemaining remarks\n- Just a very simple / non-standard ConvNet architecture is trained. Will a ResNet(32) show similar performance?\n- In Eq 4, |C_i || y_j| seems a strange notation for union.\n\nConclusion\nThis paper brings in an interesting idea, is it possible to cluster the unseen classes in an open-world classification scenario?  A solution using a pairwise convnet followed by hierarchical clustering is proposed. This is a plausible solution, yet in total I miss an exploration of the solution. \n\nBoth in terms of general visual classification (only MNIST is used, while it would be nice to see results on CIFAR and/or ImageNet as in Bendale&Boult 2016), as in exploration of different scenarios (different number of unseen classes, different samplings) and ablation of the method (independent training, using OCN for hierarchical clustering, influence of Auto Encoder). Therefore, I rate this paper as a (weak) reject: it is just not (yet) good enough for acceptance.']","[-70, -20, -60]","[-20, 50, 20]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states the paper 'lacks novelty', criticizes the problem context as 'synthesized', and expresses doubt about the real-world applicability and performance of the approach. The only positive aspect mentioned is the 'good survey' of previous work. The politeness score is -20 because while the language isn't overtly rude, it's quite direct and critical without much attempt to soften the feedback. Phrases like 'I cannot quite imagine', 'I do not really see enough novelty', and 'still not quite sure' come across as dismissive. The reviewer doesn't use any particularly polite language or acknowledge potential merits of the work beyond the initial survey."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some novel aspects of the paper, they express several criticisms and limitations. The reviewer points out that the key idea is not entirely new, the experiments are limited, and the results don't clearly demonstrate advantages over baseline methods. However, they do recognize the paper's contribution to applying a concept to open world classification.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'to the best of my knowledge' and 'I find', which soften their criticisms. The reviewer also provides constructive feedback and suggestions for improvement, such as recommending experiments on more complex data. The language is not overly formal or polite, but it avoids any rudeness or harsh criticism."", ""The sentiment score is -60 because the reviewer expresses several major concerns and ultimately recommends a 'weak reject' for the paper. They point out multiple issues with the methodology, lack of extensive exploration, and limited dataset choices. However, it's not entirely negative as they acknowledge the interesting idea behind the paper. The politeness score is 20 because the reviewer uses generally respectful language and offers constructive criticism. They use phrases like 'I'd really urge the authors' and 'I miss some baselines' which are polite ways of suggesting improvements. The reviewer also acknowledges positive aspects before critiquing, which is a polite approach. However, the overall tone remains professional rather than overtly polite, hence the moderate positive score.""]"
"['Summary: The paper proposes a multi-task feature learning framework with a focus on avoiding negative transfer. The objective has two kinds of terms to minimise: (1) The reweighed per-task loss, and (2) Regularisation. The new contribution is an asymmetric reconstruction error in the regularisation term, and one parameter matrix in the regulariser influences the reweighing of the pre-task loss. \n\nStrength: \nThe method has some contribution in dealing with negative transfer. The experimental results are positive.\nWeakness:\nSeveral issues in terms of concept, methodology, experiments and analysis.\n\nDetails:\n1. Overall conceptual issues.\n1.1. Unclear motivation re prior work. The proposed approach is motivated by the claim that GO-MTL style models assumes symmetric transfer where bad tasks can hurt good tasks. This assertion seems flawed. The point of grouping/overlap in “GO”-MTL is that a “noisy”, “hard”, or “unrelated"" task can just take its own latent predictor that is disjoint from the pool of predictors shared by the good/related tasks. \nCorrespondingly, Fig 2 seems over-contrived. A good GO-MTL solution would assign the noisy task $w_3$ its own latent basis, and let the two good tasks share the other two latent bases. \n\n1.2  Very unclear intuition of the algorithm. In the AMTFL, task asymmetry is driven by the per-task loss. The paper claims this is because transfer must go from easy=>hard to avoid negative transfer. But this logic relies on several questionable assumptions surrounding conflating the distinct issues of difficulty and relatedness: (i) There could be several easy tasks that are totally un-related. One could construct synthetic examples with data that are trivially separable (easy) but require unrelated or orthogonal classifiers. (ii) A task could appear to be “easy"" just by severe overfitting, and therefore still be detrimental to transfer despite low loss. (iii) A task could be very ""difficult"" in the sense of high loss, but it could still be perfectly learned in the sense of finding the ideal ""ground-truth” classifier, but for a dataset that is highly non-separable in the provided feature-space. Such a perfectly learned classifier may still be useful to transfer despite high loss. (iv) Analogous to point (i), there could be several “difficult” tasks that are indeed related and should share knowledge. (Since difficult/high loss != badly learned as mentioned before). Overall there are lots of holes in the intuitive justification of the algorithm.\n\n2. Somewhat incremental method. \n3.1 It’s a combination of AMTL (Lee 2016) and vanilla auto encoder. \n\n3. Methodology issues: \n3.1 Most of the explanation (Sec 3-3.1) is given re: Matrix B in Eq.(4) (AMTL method’s objective function). However the final proposed model uses matrix A in Eq.(6) for the same purpose of measuring the amount of outgoing transfers from task $t$ to all other tasks. However in the reconstruction loss, they work in very different ways: matrix B is for the reconstruction of model parameters, while matrix A is for the reconstruction of latent features. This is a big change of paradigm without adequate explanation. Why is it still a valid approach?\n3.2 Matrix B in the original paper of AMTL (Eq.(1) of Lee et al., 2016) has a constraint $B \\geq 0$, should matrix A have the same constraint? If not, why?\n3.3 Question Re: the |W-WB| type assumption for task relatedness. A bad task could learn an all-zero vector of outgoing related ness $b^0_t$ so it doesn’t directly influence other tasks in feed-forward sense. But hat about during training? Does training one task’s weights endup influencing other tasks’s weights via backprop? If a bad task is defined in terms of incoming relatedness from good tasks, then tuning the bad task with backprop will eventually also update the good tasks? (presumably detrimentally).\n\n4. Experimental Results not very strong.\n4.1 Tab 1: Neural Network NN and MT-NN beat the conventional shallow MTL approaches decisively for AWA and MNIST.  The difference between MT-NN and AMTFL is not significant. The performance boost is more likely due to using NNs rather than the proposed MTL module. For School, there is not significant difference between the methods. For ImageNet-Room AMTL and AMTFL have overlapping errors. Also, a variant of AMTL (AMTL-imbalance) was reported in Lee’2016, but not here where the number is $40\\pm1.71$. \n4.2 Tab 2: The “real” experiments are missing state of the art competitors. Besides a deep GO-MTL alternative, which should be a minimum,  there are lots of deep MTL state of the art: Misra CVPR’16 , Yang ICLR’17, Long arXiv/NIPS’17 Multilinear Relationship Nets,  Ruder arXiv’17 Sluice Nets, etc.\n\n5. Analysis\n5.1 The proposed method revolves around the notion of “noisy”/“unrelated”/“difficult” tasks. Although the paper conflates them, it may still be a useful algorithm in practice. But it in this case it should devise much better analysis to provide insight and convince us that this is not a fatal oversimplification: What is the discovered relatedness matrix in some benchmarks? Does the discovered relatedness reflect expert knowledge where this is available? Is there a statistically significant correlation between relatedness and task difficulty in practice? Or between relatedness and degree of benefit from transfer, etc? But this is hard to do cleanly as even if the results show a correlation between difficulty and relatedness, it may just be because that’s how relatedness is defined in the proposed algorithm.\n', 'This paper addresses multi-task feature learning, i.e. learning representations that are common across multiple related supervised learning tasks. The paper is not clearly written, so I outline my interpretation on what is the main idea of the manuscript. \n\nThe authors rely on two prior works in multi-task learning  that explore parameter sharing (Lee et al, 2016) and subspace learning (Kumar & Daume III 2012) for multi-task learning. \n1) The work of Lee et al 2016 is based on the idea of transferring information through weight vectors, where each task parameter can be represented as a sparse combination of other related task parameters. The interpretation is that negative transfer is avoided because only subset of relevant tasks is considered for transfer. The drawback is the scalability of this approach. \n2) The second prior work is Kumar & Daume III 2012 (and also an early work of Argyrio et al 2008) that is based on learning a common feature representation. Specifically, the main assumption is that tasks parameters lie in a low-dimensional subspace, and parameters of related tasks can be represented as linear combinations of a small number of common/shared latent basis vectors in such subspace.  Subspace learning could help to scale up to many tasks.\n\nThe authors try to combine together the ideas/principles in these previous works and propose a sparse auto encoder model for multi-task feature learning with (6) (and (7)) as the main learning objectives for training an autoencoder. \n\n- I couldn’t fully understand the objective in (6) and how exactly it is related to the previous works, i.e. how the relatedness and easyness/hardness of tasks is measured; where does f enter in the autoencoder network structure?\n- The empirical evaluations are not convincing. In the real experiments with image data, only decaf features were used as input to the autoencoder model. Why not using raw input image? Moreover all input features where projected to a lower dimensional space using PCA before inputing to the autoencoder. Why? In fact, linear PCA can be viewed as an autoencoder model with linear encoder and decoder (so that the squared error reconstruction loss between a given sample and the sample reconstructed by the autoencoder is minimal (Bishop, 2006)). Then doing PCA before training an autoencoder is not motivated.  \n\n-Writing can be improved. The introduction primarily criticizes  the approach of Lee et al, 2016 called Assymetric Multi-task Learning. It would be nicer if the introduction sets the background and covers different approaches/aspects/conditions of negative transfer in transfer learning/multi-task learning setting. The main learning objective (6) should be better explained. \n\n-Conceptual picture is a bit lacking. Striped hyena is used as an example of unreliable noisy data (source of negative transfer) when learning the attribute classifier ""stripes"". One might argue that visually, striped hyena is as informative as white tigers. Perhaps one could use a different (less striped) animal, e.g. raccoon. \n', ""This paper presents a deep asymmetric multi-task feature learning method (Deep-AMTFL).\n\nOne concern is that the high similarity between the proposed Deep-AMTFL and an existing AMTL method. Even though AMTL operates on task relations and Deep-AMTFL is on feature learning, the main ideas of both methods are very similar, that is, tasks with higher training losses will contribute less to other tasks' model or feature representations. Even though the regularizers seem a bit different, the large similarity with AMTL decreases the novelty of this work.\n\nIn real-world experiments, it is better to show the difference of learned features among the proposed Deep-AMTFL and other baselines.\n\nA minor problem: the last sentence in page 3 is incomplete.\n\n""]","[-60, -50, -30]","[20, 20, 20]","[""The sentiment score is -60 because the review is predominantly critical, pointing out several major issues with the paper's concept, methodology, experiments, and analysis. While the reviewer acknowledges some strengths ('The method has some contribution in dealing with negative transfer. The experimental results are positive.'), the bulk of the review focuses on weaknesses and areas for improvement. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use neutral language like 'unclear', 'issues', and 'questions' rather than harsh or dismissive terms. The reviewer also provides detailed explanations for their concerns, which is a constructive approach. However, the review doesn't go out of its way to be overtly polite or encouraging, hence the relatively low positive score."", ""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper such as unclear writing, unconvincing empirical evaluations, and conceptual problems. However, it's not entirely negative as it acknowledges the paper's attempt to combine ideas from previous works. The politeness score is 20 because while the reviewer is direct in their criticisms, they use relatively polite language such as 'can be improved' and 'it would be nicer if' rather than harsh or rude phrasing. The reviewer also offers constructive suggestions for improvement, which contributes to the slightly positive politeness score."", ""The sentiment score is -30 because the review expresses concerns about the novelty of the work due to its similarity with an existing method, which is a significant criticism. However, it's not entirely negative as it acknowledges the paper's contribution and offers constructive feedback. The politeness score is 20 because the reviewer uses neutral language and phrases criticisms as 'concerns' rather than direct attacks. They also offer suggestions for improvement, which is considerate. The tone is professional and not overly harsh, though it lacks overtly polite language.""]"
"['I think the idea of inferring programmatic descriptions of handwritten diagrams is really cool, and that the combination of SMC-based inference with constraint-based synthesis is nice. I also think the application is clearly useful – one could imagine that this type of technology would eventually become part of drawing / note-taking applications.\n\nThat said, based on the current state of the manuscript, I find it difficult to recommend acceptance. I understand that the ICLR does not strictly have a page limit, but I think submitting a manuscript of over 11 pages is taking things a bit too far. The manuscript would greatly benefit from a thorough editing pass and some judicious reconsideration of space allocated to figures. Moreover, despite its relative verbosity, or perhaps because of it, I found it surprisingly difficult to extract simple implementation details from the text (for example I had to dig up the size of the synthetic training corpus from the 44-page appendix). \n\nPresentation issues aside, I think this is great work. There is a lot here, and I am sympathetic to the challenges of explaining everything clearly in a single (short) paper. That said, I do think that the authors need to take another stab at this to get the manuscript to a point where it can be impactful. \n\nMinor Comments \n\n- I don\'t understand what the ""hypothesis"" is in the trace hypothesis. Breaking down the problem into an AIR-style sequential detection task and a program induction is certainly a reasonable thing to do. However, the word ""hypothesis"" is generally used to refer to a testable explanation of a phenomenon, which is not really applicable here. \n\n- How is the edit distance defined? In particular, are we treating the drawing commands as a set or a sequence when we calculate ""the number of drawing commands by which two trace sets differ""?\n\n- I took me a while to understand that the authors first consider the case of SMC for synthetic images with a pixel-based likelihood, and then move on to SMC with and edit-distance based surrogate likelihood for hand-drawn pictures. The text seems to suggest that only 100 of such hand drawn images were actually used, is that correct?\n \n- What does the (+) operator do in Figure 3?\n\n- I am not sure that ""correcting errors made by the neural network"" is the most accurate way to describe a reranking of the top-k samples returned by the SMC sweep.\n\n- Table 3 is very nice, but does not need to be a full page. \n\n- I would recommend that the authors consolidate wrap-around figures into full-width figures. \n', 'This paper proposes a method to infer lines of code that produces a given image. The method consists of two components. One is to generate traces, which are primitive commands of a graphic program, given an image. The other is to infer lines of code given traces. The first component uses a deep neural network for the conversion and a novel architecture is used for the network. The second component uses a learnt search polity to speed up the inference. Experimental results on a small dataset show that the proposed method can generate lines of code of a graphics program for the images reasonably well. It also discusses possible applications of the method.\n\nOverall, the paper is interesting and the proposed method seems reasonable. Also, it is well contrasted with related work. However, the paper contains too many contents and it is hard to understand the important details without reading supplement and the references. It might be even worth considering to split the paper into two ones and each paper proposes one idea (component) at a time with more details.\n\nThat said, I understood the basic ideas of the paper and I liked them. My concern is only around how to write.', 'Summary of paper:\n\nThis paper tackles the problem of inferring graphics programs from hand-drawn images by splitting it into two separate tasks:\n(1) inferring trace sets (functions to use in the program) and\n(2) program synthesis, using the results from (1).\nThe usefulness of this split is referred to as the trace hypothesis.\n\n(1) is done by training a neural network on data [input = rendered image; output = trace sets] which is generated synthetically. During test time, a trace set is generated using a population-based method which samples and assigns weights to the guesses made by the neural network based on a similarity metric. Generalization to hand-drawn images is ensured by by learning the similarity metric.\n\n(2) is done by feeding the trace set into a program synthesis tool of Solar Lezama. Since this is too slow, the authors design a search policy which proposes a restriction on the program search space, making it faster. The final loss for (2) in equation 3 takes into consideration the time taken to synthesize images in a search space. \n\n---\n\nQuality: The experiments are thorough and it seems to work. The potential limitation is generalization to non-synthetic data.\nClarity: The high level idea is clear however some of the details are not clear.\nOriginality: This work is one of the first that tackles the problem described.\nSignificance: There are many ad-hoc choices made in the paper, making it hard to extract an underlying insight that makes things work. Is it the trace hypothesis? Or is it just that trying enough things made this work?\n\n---\n\nSome questions/comments:\n- Regarding the trace set inference, the loss function during training and the subsequent use of SMC during test time is pretty unconventional. The use of the likelihood P_{\\theta}[T | I] as a proposal, as the paper also acknowledges, is also unconventional. One way to look at this which could make it less unconventional is to pose the training phase as learning the proposal distribution in an amortized way (instead of maximizing likelihood) as, for example, in [1, 2].\n- In section 2.1., the paper talks about learning the surrogate likelihood function L_{learned} in order to work well for actual hand drawings. This presumably stems from the problem of mismatch between the distribution of the synthetic data used for training and the actual hand drawings. But then L_{learned} is also learned from synthetic data. What makes this translate to non-synthetic data? Does this translate to non-synthetic data?\n- What does ""Intersection over Union"" in Figure 8 mean?\n- The details for 3.1 are not clear. In particular, what does t(\\sigma | T) in equation 3 refer to? Time to synthesize all images in \\sigma? Why is the concept of Bias-optimality important?\n- It seems from Table 4 that by design, the learned policy for the program search space already limits the search space to programs with maximum depth of the abstract syntax tree of 3. What is the usual depth of an AST when using Sketch?\n\n---\n\nMinor Comments:\n- In page 4, section 2.1: ""But pixel-wise distance fares poorly... match the model\'s renders."" and ""Pixel-wise distance metrics are sensitive... search space over traces."" seem to be saying the same thing\n- End of page 5: \\citep Polozov & Gulwani (2015)\n- Page 6: \\citep Solar Lezama (2008)\n\n---\n\nReferences\n\n[1] Paige, B., & Wood, F. (2016). Inference Networks for Sequential Monte Carlo in Graphical Models. In Proceedings of the 33rd International Conference on Machine Learning, JMLR W&CP 48: 3040-3049.\n[2] Le, T. A., Baydin, A. G., & Wood, F. (2017). Inference Compilation and Universal Probabilistic Programming. In Proceedings of the 20th International Conference on Artificial Intelligence and Statistics (Vol. 54, pp. 1338–1348). Fort Lauderdale, FL, USA: PMLR.']","[-20, 50, 50]","[60, 80, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer expresses interest in the idea and acknowledges it as 'great work', they also state they 'find it difficult to recommend acceptance' and point out several issues with the manuscript. The overall tone suggests the paper needs significant revisions. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the challenges of the work and offering constructive criticism. They use phrases like 'I think', 'I understand', and 'I would recommend', which maintain a polite tone even when giving critical feedback. The reviewer also balances negative comments with positive ones, showing consideration for the authors' efforts."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses interest in the paper and finds the proposed method reasonable, stating 'Overall, the paper is interesting and the proposed method seems reasonable.' They also mention liking the basic ideas. However, they have concerns about the paper's structure and readability, which prevents a higher positive score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. They use phrases like 'It might be worth considering' when suggesting improvements, which is a polite way to offer advice. The reviewer also balances critique with positive feedback, demonstrating courtesy in their evaluation."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the thoroughness of the experiments and the originality of the work, but also points out potential limitations and unclear details. The review is balanced, offering both praise and constructive criticism. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, poses questions and suggestions in a non-confrontational manner, and provides specific, constructive feedback. The reviewer also acknowledges the paper's contributions while offering areas for improvement. The use of phrases like 'Some questions/comments:' and the inclusion of references to support their points further contribute to the polite tone.""]"
"['The authors try to use continuous time generalizations of normalizing flows for improving upon VAE-like models or for standard density estimation problems.\n\nClarity: the text is mathematically very sloppy / hand-wavy.\n\n1. I do not understand proposition (1). I do not think that the proof is correct (e.g. the generator L needs to be applied to a function -- the notation L(x) does not make too much sense): indeed, in the case when the volatility is zero (or very small), this proposition would imply that any vector field induces a volume preserving transformation, which is indeed false.\n\n2. I do not really see how the sequence of minimization Eq(5) helps in practice. The Wasserstein term is difficult to hand.\n\n3. in Equation (6), I do not really understand what $\\log(\\bar{\\rho})$ is if $\\bar{\\rho}$ is an empirical distribution. One really needs $\\bar{\\rho}$ to be a probability density to make sense of that.', ""The authors propose the use of first order Langevin dynamics as a way to transition from one latent variable to the next in the VAE setting, as opposed to the deterministic transitions of normalizing flow. The extremely popular Fokker-Planck equation is used to analyze the steady state distributions in this setting. The authors also propose the use of CTF in density estimation, as a generator of samples from the ''true'' distribution, and show competitive performance w.r.t. inception score for some common datasets.\n\nThe use of Langevin diffusion for latent transitions is a good idea in my opinion; though quite simple, it has the benefit of being straightforward to analyze with existing machinery. Though the discretized Langevin transitions in \\S 3.1 are known and widely used, I liked the motivation afforded by Lemma 2. \n\nI am not convinced that taking \\rho to be the sample distribution with equal probabilities at the z samples is a good choice in \\S 3.1; it would be better to incorporate the proximity of the langevin chain to a stationary point in the atom weights instead of setting them to 1/K. However to their credit the authors do provide an estimate of the error in the distribution stemming from their choice.   \n\nTo the best of my knowledge the use of CTF in density estimation as described in \\S 4 is new, and should be of interest to the community; though again it is fairly straightforward. Regarding the experiments, the difference in ELBO between the macVAE and the vanilla ones with normalizing flows is only about 2%; I wish the authors included a discussion on how the parameters of the discretized Langevin chain affects this, if at all.\n\nOverall I think the theory is properly described and has a couple of interesting formulations, in spite of being not particularly novel. I think CTFs like the one described here will see increased usage in the VAE setting, and thus the paper will be of interest to the community."", '\nThe authors propose continuous-time flows as a flexible family of\ndistributions for posterior inference of latent variable models as\nwell as explicit density estimation. They build primarily on the work\nof normalizing flows from Rezende and Mohamed (2015). They derive an\ninteresting objective based on a sequence of sub-optimization\nproblems, following a variational formulation of the Fokker-Planck\nequations.\n\nI reviewed this paper for NIPS with a favorable decision toward weak\nacceptance; and the authors also addressed some of my questions in\nthis newer version (namely, some comparisons to related work; clearer\nwriting).\n\nThe experiments are only ""encouraging""; they do not illustrate clear\nimprovements over previous methods. However, I think the work\ndemonstrates useful ideas furthering the idea of continuous-time\ntransformations that warrants acceptance.']","[-70, 60, 60]","[-20, 70, 70]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer criticizes the paper for being 'mathematically very sloppy / hand-wavy', questions the correctness of a proposition, and expresses confusion about multiple aspects of the paper. There are no positive comments to balance these criticisms. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite blunt and dismissive. Phrases like 'I do not understand', 'I do not think that the proof is correct', and 'I do not really see how' are direct and could be perceived as somewhat impolite in academic discourse. However, the reviewer does attempt to explain their concerns, which prevents the score from being lower."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses overall approval of the paper, describing the main idea as 'good' and stating that it 'will be of interest to the community'. They also mention 'interesting formulations' and predict increased usage of the proposed method. However, they do note some limitations and areas for improvement, which prevents a higher score. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts ('to their credit') and offering constructive criticism. They use phrases like 'I think' and 'in my opinion' to soften their statements. The tone is professional and courteous, without being overly formal or effusive."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses a favorable decision towards weak acceptance, acknowledges that the authors addressed previous questions, and states that the work demonstrates useful ideas warranting acceptance. However, it's not extremely positive as the experiments are described as only 'encouraging' without clear improvements over previous methods. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts to address previous concerns, and provides balanced feedback. The tone is professional and constructive, avoiding harsh criticism while still pointing out areas for improvement.""]"
"['This paper misses the point of what VAEs (or GANs, in general) are used for. The idea of using VAEs is not to encode and decode images (or in general any input), but to recover the generating process that created those images so we have an unlimited source of samples. The use of these techniques for compressing is still unclear and their quality today is too low. So the attack that the authors are proposing does not make sense and my take is that we should see significant changes before they can make sense. \n\nBut let’s assume that at some point they can be used as the authors propose. In which one person encodes an image, send the latent variable to a friend, but a foe intercepts it on the way and tampers with it so the receiver recovers the wrong image without knowing. Now if the sender believes the sample can be tampered with, if the sender codes z with his private key would not make the attack useless? I think this will make the first attack useless. \n\nThe other two attacks require that the foe is inserted in the middle of the training of the VAE. This is even less doable, because the encoder and decoder are not train remotely. They are train of the same machine or cluster in a controlled manner by the person that would use the system. Once it is train it will give away the decoder and keep the encoder for sending information.\n\n', ""The idea is clearly stated (but lacks some details) and I enjoyed reading the paper. \n\nI understand the difference between [Kos+17] and the proposed scheme but I could not understand in which situation the proposed scheme works better. From the adversary's standpoint, it would be easier to manipulate inputs than latent variables. On the other hand, I agree that sample-independent perturbation is much more practical than sample-dependent perturbation.\n\nIn Section 3.1, the attack methods #2 and #3 should be detailed more. I could not imagine how VAE and T are trained simultaneously.\n\nIn Section 3.2, the authors listed a couple of loss functions. How were these loss functions are combined? The final optimization problem that is used for training of the propose VAE should be formally defined. Also, the detailed specification of the VAE should be detailed.\n\nFrom figures in Figure 4 and Figure 5, I could see that the proposed scheme performs successfully in a qualitative manner, however, it is difficult to evaluate the proposed scheme qualitatively without comparisons with baselines. For example, can the proposed scheme can be compared with [Kos+17] or some other sample-dependent attacks? Also, can you experimentally show that attacks on latent variables are more powerful than attacks on inputs?\n\n\n"", 'This paper is concerned with both security and machine learning. \nAssuming that data is encoded, transmited, and decoded using a VAE,\nthe paper proposes a man-in-middle attack that alters the VAE encoding of the input data so that the decoded output will be misclassified.\nThe objectives are to: 1) fool the autoencoder; the classification output of the autoencoder is different from the actual class of the input; 2) make minimal change in the middle so that the attack is not detectable. \n\nThis paper is concerned with both security and machine learning, but there is no clear contributions to either field. From the machine learning perspective, the proposed ""attacking"" method is standard without any technical novelty. From the security perspective, the scenarios are too simplistic. The encoding-decoding mechanism being attacked is too simple without any security enhancement. This is an unrealistic scenario. For applications with security concerns, there should have been methods to guard against man-in-the-middle attack, and the paper should have at least considered some of them. Without considering the state-of-the-art security defending mechanism, it is difficult to judge the contribution of the paper to the security community. \n\nI am not a security expert, but I doubt that the proposed method are formulated based on well founded security concepts and ideas. For example, what are the necessary and sufficient conditions for an attacking method to be undetectable? Are the criteria about the magnitude of epsilon given on Section 3.3. necessary and sufficient? Is there any reference for them? Why do we require the correspondence between the classification confidence of tranformed and original data? Would it be enough to match the DISTRIBUTION of the confidence? ']","[-70, 20, -60]","[-20, 60, 20]","[""The sentiment score is -70 because the reviewer strongly criticizes the paper's fundamental approach, stating it 'misses the point' and that the proposed attack 'does not make sense.' The reviewer suggests 'significant changes' are needed, indicating a highly negative view of the paper's current state. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite dismissive and blunt. Phrases like 'misses the point' and 'does not make sense' are direct criticisms without much softening language. The reviewer also doesn't offer many constructive suggestions or positive comments to balance the criticism, which contributes to the slightly impolite tone."", ""The sentiment score is 20 (slightly positive) because the reviewer starts with a positive statement about enjoying reading the paper and acknowledging that the idea is clearly stated. However, the rest of the review contains several critiques and requests for more information, which tempers the overall positivity. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions rather than direct attacks, and acknowledges positive aspects of the paper. The reviewer uses phrases like 'I understand,' 'I agree,' and 'can you' which maintain a collegial tone. The critique is presented constructively, asking for more details and comparisons rather than dismissing the work outright."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's contributions and novelty. They state that there are 'no clear contributions' to either security or machine learning fields, and describe the scenarios as 'too simplistic' and 'unrealistic'. The reviewer also questions the foundational concepts and ideas used in the paper. However, the score is not at the extreme negative end as the reviewer does acknowledge the paper's focus and objectives.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively neutral tone. They use phrases like 'I am not a security expert, but I doubt...' which shows a degree of humility and politeness. The reviewer also asks questions rather than making outright dismissive statements in some cases. However, the score is only slightly positive as the review doesn't include particularly polite language or compliments, focusing mainly on the paper's shortcomings.""]"
"['******\nPlease note the adjusted review score after revisions and clarifications of the authors. \nThe paper was improved significantly but still lacks novelty. For context, multi-layer VAEs also were not published unmodified as follow-up papers since the objective is identical. Also, I would suggest the authors study the modified prior with marginal statistics and other means to understand not just \'that\' their model performs better with the extra degree of freedom but also \'how\' exactly it does it. The only evaluation is sampling from z1 and z2 for reconstruction which shows that some structure is learned in z2 and the attribute classification task. However, more statistical understanding of the distributions of the extra layers/capacity of the model would be interesting.\n******\n\nThe authors propose a hierarchical GAN setup, called HALI, where they can learn multiple sets of latent variables.\nThey utilize this in a deep generative model for image generation and manage to generate good-looking images, faithful reconstructions and good inpainting results.\n\nAt the heart of the technique lies the stacking of GANS and the authors claim to be proposing a novel model here.\nFirst, Emily Denton et. al proposed a stacked version of GANs in ""Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks"", which goes uncited here and should be discussed as it was the first work stacking GANs, even if it did so with layer-wise pretraining.\nFurthermore, the differences to another very similar work to that of the authors (StackGan by Huan et al) are unclear and not well motivated.\nAnd third, the authors fail to cite \'Adversarial Message Passing\' by Karaletsos 2016, which has first introduced joint training of generative models with structure by hierarchical GANs and generalizes the theory to a particular form of inference for structured models with GANs in the loop. \nThis cannot be called concurrent work as it has been around for a year and has been seen and discussed at length in the community, but the authors fail to acknowledge that their basic idea of a joint generative model and inference procedure is subsumed there. In addition, the authors also do not offer any novel technical insights compared to that paper and actually fall short in positioning their paper in the broader context of approximate inference for generative models.\n\nGiven these failings, this paper has very little novelty and does not perform accurate attribution of credit to the community.\nAlso, the authors propose particular one-off models and do not generalize this technique to an inference principle that could be reusable.\n\nAs to its merits, the authors manage to get a particularly simple instance of a \'deep gan\' working for image generation and show the empirical benefits in terms of image generation tasks. \nIn addition, they test their method on a semi-supervised task and show good performance, but with a lack of details.\n\nIn conclusion, this paper needs to flesh out its contributions on the empirical side and position its exact contributions accordingly and improve the attribution.', '_________________________________________________________________________________________________________\n\nI raise my rating on the condition that the authors will also address the minor concerns in the final version, please see details below.\n_________________________________________________________________________________________________________\n\nThis paper proposes to perform Adversarially Learned Inference (ALI) in a layer-wise manner. The idea is interesting, and the authors did a good job to describe high-level idea, and demonstrate one advantage of hierarchy: providing different levels reconstructions. However, the advantage of better reconstruction could be better demonstrated.  Some major concerns should be clarified before publishing:\n\n(1) How did the authors implement p(x|z) and q(z|x), or p(z_l | z_{l+1}) and q(z_{l+1} | z_l )? Please provide the details, as this is key to the reconstruction issues of ALI.\n\n(2) Could the authors provide the pseudocode procedure of the proposed algorithm? In the current form of the writing, it is not clear what the HALI procedure is, whether (1) one discriminator is used to distinguish the concatenation of (x, z_1, ..., z_L), or (2) L discriminators are used to distinguish the concatenation of (z_l, z_{l+1}) at each layer, respectively?\n\nThe above two points are important. If not correctly constructed, it might reveal potential flaws of the proposed technique.\n\nSince one of the major claims for HALI is to provide better reconstruction with higher fidelity than ALI. Could the authors provide quantitative results on MNIST and CIFAR to demonstrate this? The reconstruction issues have first been highlighted and theoretically analyzed in ALICE [*], and some remedy has been proposed to alleviate the issue.  Quantitative comparison on MNIST and CIFAR are also conducted. Could the authors report numbers to compare with them (ALI and ALICE)? \n\nThe 3rd paragraph in Introduction should be adjusted to correctly clarify details of algorithms, and reflect up-to-date literature. ""One interesting feature highlighted in the original ALI work (Dumoulin et al., 2016) is that ... never explicitly trained to perform reconstruction, this can nevertheless be easily done..."". Note that ALI can only perform reconstruction when the deterministic mapping is used, while ALI itself adopted the stochastic mapping. Further, the deterministic mapping is the major difference of BiGAN from ALI. Therefore, more rigorous way to phrase is that ""the original ALI work with deterministic mappings"", or ""BiGAN"" never explicitly trained to perform reconstruction, this can nevertheless be easily done... This tiny difference between deterministic/stochastic mappings makes major difference for the quality of reconstruction, as theoretically analyzed and experimentally compared in ALICE. In ALICE, the authors confirmed further source of poor reconstructions of ALI in practice. It would be better to reflect the non-identifiability issues raised by ALICE in Introduction, rather than hiding it in Future Work as ""Although recent work designed to improve the stability of training in ALI does show some promise (Chunyuan Li, 2017), more work is needed on this front.""\n\nAlso, please fix the typo in reference as:\n[*] Chunyuan Li, Hao Liu, Changyou Chen, Yunchen Pu, Liqun Chen, Ricardo Henao and Lawrence Carin. ALICE: Towards understanding adversarial learning for joint distribution matching. In Advances in Neural Information Processing Systems (NIPS), 2017.\n\n\n ', 'The paper incorporated hierarchical representation of complex, reichly-structured data to extend the Adversarially Learned Inference (Dumoulin et al. 2016) to achieve hierarchical generative model. The hierarchical ALI (HALI) learns a hierarchy of latent variables with a simple Markovian structure in both the generator and inference. The work fits into the general trend of hybrid approaches to generative modeling that combine aspects of VAEs and GANs. \n\nThe authors showed that within a purely adversarial training paradigm, and by exploiting the model’s hierarchical structure, one can modulate the perceptual fidelity of the reconstructions. We provide theoretical arguments for why HALI’s adversarial game should be sufficient to minimize the reconstruction cost and show empirical evidence supporting this perspective.\n\nThe performance of HALI were evaluated on four datasets, CIFAR10, SVHN, ImageNet 128x128 and CelebA. The usefulness of the learned hierarchical representations were demonstrated on a semi-supervised task on MNIST and an attribution prediction task on the CelebA dataset. The authors also noted that the introduction of a hierarchy of latent variables can add to the difficulties in the training. \n\nSummary:\n——\nIn summary, the paper discusses a very interesting topic and presents an elegant approach for modeling complex, richly-structured data using hierarchical representation. The numerical experiments are thorough and HALI is shown to generate better results than ALI. Overall, the paper is well written. However, it would provide significantly more value to a reader if the authors could provide more details and clarify a few points. See comments below for details and other points.\n\nComments:\n——\n1.\tCould the authors comment on the training time for HALI? How does the training time scale with the levels of the hierarchical structure?\n\n2.\tHow is the number of hierarchical levels $L$ determined? Can it be learned from the data? Are the results sensitive to the choice of $L$?\n\n3.\tIt seems that in the experimental results, $L$ is at most 2. Is it because of the data or because of the lack of efficient training procedures for the hierarchical structure?\n\n\n']","[-60, 20, 70]","[-20, 60, 80]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several significant issues with the paper, including lack of novelty, failure to cite relevant prior work, and insufficient generalization. While the reviewer acknowledges some merits of the paper, these are outweighed by the criticisms. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical. Phrases like 'failings,' 'very little novelty,' and 'does not perform accurate attribution of credit' are quite harsh. The reviewer does not use softening language or positive reinforcement, which contributes to the slightly impolite tone. However, the reviewer does provide specific feedback and suggestions for improvement, which prevents the score from being even lower."", ""The sentiment score is slightly positive (20) because the reviewer starts by saying they raise their rating conditionally, and describes the paper's idea as 'interesting' with the authors doing 'a good job'. However, they also raise several major concerns and request clarifications, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing their critiques as requests for clarification or suggestions (e.g., 'Could the authors provide...', 'Please provide the details...'). They also acknowledge the positive aspects of the work before diving into concerns. The tone is professional and constructive, avoiding harsh or dismissive language."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as discussing 'a very interesting topic' and presenting 'an elegant approach'. They also mention that the numerical experiments are 'thorough' and that HALI generates 'better results than ALI'. The overall tone is appreciative of the work, although they do suggest some improvements. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, such as 'Could the authors comment on...' and 'It would provide significantly more value to a reader if...'. They balance positive feedback with constructive criticism, maintaining a professional and courteous tone. The reviewer also acknowledges the paper is 'well written' before suggesting improvements, which is a polite way to provide feedback.""]"
"['The authors propose to learn to pick up a block and put it on another block using DDPG. A few tricks are described, which I believe already appear in prior work. The discussion of results presented in prior work also has a number of issues. The claim of ""data efficient"" learning is not really accurate, since even with demonstrations, the method requires substantially more experience than prior methods. Overall, it\'s hard to discern a clear contribution, either experimentally or conceptually, and the excessive claims in the paper are very off-putting. This would perhaps make a reasonable robotics paper if it had a real-world evaluation and if the claims were scoped more realistically, but as-is, I don\'t think this work is ready for publication.\n\nMore detailed comments:\n\nThe two main contributions -- parallel training and asynchrony -- already appear in the Gu et al. paper. In fact, that paper demonstrates learning entirely in the real world, and substantially more efficiently than described in this paper. The authors don\'t discuss this at all, except a passing mention of Gu et al.\n\nThe title is not appropriate for this paper. The method is data-efficient compared to what? The results don\'t look very data efficient: the reported result is something on the order of 160 robot-hours, and 16 robot-hours with demonstration. That\'s actually dramatically less efficient than prior methods.\n\n""our results on data efficiency hint that it may soon be feasible to train successful stacking policies by collecting interactions on real robots"": Prior work already shows successful stacking policies on real robots, as well as successful pick-and-place policies and a variety of other skills. The funny thing is that many of these papers are actually cited by the authors, but they simply pretend that those works don\'t exist when discussing the results.\n\n""We assess the feasibility of performing analogous experiments on real robotics hardware"": I assume this is a typo, but the paper does not actually contain any real robotics hardware experiments.\n\n""To our knowledge our results provide the first demonstration of end-to-end learning for a complex manipulation problem involving multiple freely moving objects"": This was demonstrated by Finn et al. in ""Deep Spatial Autoencoders for Visuomotor Learning,"" with training times that are a tiny fraction of those reported in this paper, and using raw images and real hardware.\n\n""both rely on access to a well defined and fully observed state space"": This is not true of the Finn et al. paper mentioned above.', 'I already reviewed this paper for R:SS 2017. There were no significant updates in this version, see my largely identical detailed comment in ""Official Comment""\n\nQuality\n======\nThe proposed approaches make sense but it is unclear how task specific they are.\n\nClarity\n=====\nThe paper reads well. The authors cram 4 ideas into one paper which comes at the cost of clarity of each of them.\n\nOriginality\n=========\nThe ideas on their own are rather incremental.\n\nSignificance\n==========\nIt is unclear how widely applicable the ideas (and there combination) are an whether they would transfer to a real robot experiment. As pointed out above the ideas are not really groundbreaking on their own.\n\nPros and Cons (from the RSS AC which sums up my thoughts nicely)\n============\n+ The paper presents and evaluates a collection of approaches to speed learning of policies for manipulation tasks.\n+ Improving the data efficiency of learning algorithms and enabling learning across multiple robots is important for practical use in robot manipulation.\n+ The multi-stage structure of manipulation is nicely exploited in reward shaping and distribution of starting states for training.\n\n- The techniques of asynchronous update and multiple replay steps may have limited novelty, building closely on previous work and applying it to this new problem.\n- The contribution on reward shaping would benefit from a more detailed description and investigation.\n- There is concern that results may be specific to the chosen task.   \n- Experiments using real robots are needed for practical evaluation.\n', 'The title is too generic and even a bit misleading. Dexterous manipulation usually refers to more complex skills, like in-hand manipulation or using the fingers to turn an object, and not simple pick and place tasks. Reinforcement learning methods are generally aiming to be data-efficient, and the method does not seem designed specifically for dexterous manipulation (which is actually a positive point, as it is more general).\n\nThe paper presents two extensions for DDPG: multiple network updates per physical interactions, and asynchronous updates from multiple robots. As the authors themselves state, these contributions are fairly straightforward, and the contributions are largely based on prior works. The  authors do evaluate the methods with different parameter settings to see the effects on learning performance. \n\nThe simulation environment is fairly basic and seems unrealistic. The hand always starts close to the blocks, which are close together, so the inverse kinematics will be close to linear. The blocks are always oriented in the same direction and they can connect easily with no need to squeeze or wiggle them together. The task seems more difficult from the description in the paper, and the authors should describe the environment in more detail.\n\nDoes the robot learn to flip the blocks over such that they can be stacked? The videos show the \nblocks turning over accidentally, but then the robot seems to give up. Having the robot learn to turn the blocks  would make for a more challenging task and a better policy.\n\nThe paper’s third contribution is a recipe for constructing shaped reward functions for composite tasks. The method relies on a predefined task structure (reach-grasp-stack) and is very similar to reward shaping already used in many other reinforcement learning for manipulation papers. A comparison of different methods for defining the rewards and a more formal description of the reward generation procedure would improve the impact of this section.  The authors should also consider using tasks with longer sequences of actions, e.g., stacking four blocks. \n\nThe fourth and final listed contribution is learning from demonstrated states. Providing the robot with prior knowledge and easier partial tasks will result in faster learning. This result is not surprising. It is not clear though how applicable this approach is for a real robot system. It effectively assumes that the robot can grasp the block and pick it up, such that it can learn the stacking part, while simultaneously still learning how to grasp the block and pick it up. For testing the real robot applicability, the authors should try having the robot learn the task without simulation resets.  \n\nWhat are the actual benefits of using deep learning in this scenario? The authors mention skill representations, such as dynamic motor primitives, which employ significantly more prior knowledge than a deep network. However, as demonstrations of the task are provided, the task is divided into steps, the locations of the objects and finger tips are given, a suitable reward function is provided, and the generalization is only over the object positions, why not train a set of DMPs and optimize them with some additional reinforcement learning? The authors should consider adding a Cartesian DMP policy as a benchmark, as well as discussing the benefits of the proposed approach given the prior knowledge. ']","[-80, -30, -50]","[-20, 20, 20]","[""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer states that the paper has 'excessive claims,' lacks a 'clear contribution,' and is 'not ready for publication.' They also point out multiple inaccuracies and misrepresentations of prior work. The politeness score is -20 because while the reviewer provides detailed feedback, some language choices are quite harsh. Phrases like 'excessive claims' and 'very off-putting' are particularly blunt. The reviewer does attempt to offer constructive criticism, suggesting how the paper could be improved (e.g., 'This would perhaps make a reasonable robotics paper if...'), which prevents the score from being even lower. However, the overall tone is critical and at times dismissive, particularly when addressing the authors' claims about their work's novelty and efficiency."", 'The sentiment score is -30 because the review expresses several criticisms and concerns, such as lack of significant updates, unclear applicability, and limited novelty. However, it also acknowledges some positive aspects like the paper reading well and the importance of the topic. The overall tone leans negative but is not extremely critical. The politeness score is 20 because the reviewer uses professional and respectful language throughout, avoiding harsh or rude phrasing. They present criticisms in a constructive manner and balance negative points with positive ones. The tone is polite but not overly deferential or flattering.', ""The sentiment score is -50 because the review is generally critical of the paper, pointing out several limitations and areas for improvement. The reviewer questions the novelty of the contributions, the realism of the simulation environment, and the applicability of the approach to real robot systems. However, it's not entirely negative as the reviewer acknowledges some positive aspects and offers constructive suggestions for improvement. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'The authors should consider...' and 'It would improve the impact...' which are polite ways of suggesting improvements. The reviewer also acknowledges positive aspects, such as the evaluation of different parameter settings. The language is not overly formal or deferential, but it avoids rudeness or harsh criticism.""]"
"['The main aim of ICLR conference, at least as it is written on its website, is to provide new results on theories, methods and algorithms, supporting further breakthroughs in AI and DL.\n\nIn this respect the authors of the paper claim that their “systematic approach enables the discovery of new, improved regularization methods by combining the best properties of the existing ones.”\n\nHowever, the authors did not provide any discoveries concerning new approaches to regularisation supporting this claim. Thus, the main contribution of the paper is that the authors made a review and performed classification of available regularisation methods. So, the paper is in fact a survey paper, which is more appropriate for full-scale journals. The work, developed by the authors, is really big. However, I am not sure it will bring a lot of benefits for readers except those who need review for some reports, introductions in PhD thesis, etc.\n\nAlthough the authors mentioned some approaches to combine different regularisations, they did not performed any experiments supporting their ideas.\n\nThus, I think that\n- the paper is well written in general,\n- it can be improved (by taking into account several important comments from the Reviewer 2) and served as a review paper in some appropriate journal,\n- the paper is not suited for ICLR proceedings due to reasons, mentioned above.', 'This paper is unusual in that it is more of a review than contributing novel knowledge. It considers a taxonomy of all the ways that machine learning (mostly deep learning) methods can achieve a form of regularization. \n\nUnfortunately, it starts with a definition of regularization (\'making the model generalize better\') which I believe misses the point which was made in Goodfellow et al 2016 (\'intend to improve test error but not necessarily training error\'), i.e., that we would like to separate as much as possible the regularization effects from the optimization effect. Indeed, under the definition proposed here, any improvement in the optimizer could be considered like a regularizer, so long as we are not in the overfitting regime. That does not sound right to me.\n\nThere are several places where the authors make TOO STRONG STATEMENTS, taking for truth what are simply beliefs with no strong supporting evidence (at least published). This is not good for a review and when making recommendations.\n\nThe other weakness I estimate in this paper is that I did not get a sense that the taxonomy really helped us (me at least) to get insight into the different mentions being cited. Besides the obvious proposal to combine ideas to write new papers (but we did not need that paper to figure that out) I did not find much meat in the \'future directions\' section.\n\nHowever, I that except in a few places the understand of the field displayed by the authors is pretty good and, with correction, could serve as a useful reference for students of deep learning. The recommendations were reasonable although lacking empirical support (or pointers to the literature), so I would take them somewhat carefully, more as the current \'group think\' than ground truth.\n\nFinally, here a few minor points which could be fixed.\n\nEq. 1: in typical DL, minimization is approximate, not exact, so the proposed formalism does not reflect reality.\n\nEq. 4: in many cases, the noise is not added (e.g. dropout), so that should be clarified there.\n\npage 3, first bullet of \'Effect on the data representation\': not clear, may want to give translations as an example of such transformations,.\n\npage 8, activation functions: the ReLU is actually older than the cited papers, it was used by computational neuroscientists a long time ago. Jarrett 2009 did not use the ReLU but an absolute-value rectifier and it was Glorot 2011 who showed that the ReLU really kicked ass for deeper networks. Nair 2010 used the ReLU in a very different context (RBMs), not really feedforward multi-layer networks where it shines now.\nIn that same section (and probably elsewhere) there are TOO STRONG STATEMENTS, e.g., the ""facts"" mentioned are not facts but merely folk belief, as far as I know, and I would like to see well-done supporting evidence before treating those as facts. Note that approximating the sigmoid precisely would require many ReLUs!\n\npage 8: it is not clear how multi-task learning fits under the \'architecture\' formalism provided at the beginning of section 4.\n\nsection 7 (page 10): there is earlier work on the connection between early stopping and L2 regularization, at least dating back to Ronan Collobert\'s PhD thesis (with neural nets), probably earlier for linear systems.', 'The paper attempts to build a taxonomy for regularization techniques employed in deep learning. The authors categorize existing works related to regularization into five big categories, including data, model architecture, regularization term, error term and optimization. Subgroups are identified based on certain attributes. \n\nThe paper is written as a survey paper on literatures related to regularization in deep learning. The five top-level categories are quite obvious.  The authors organize works belonging to the first three categories into three big tables, and summarizing the key point of each one using one-liners to provide an overview for readers. While it is a worthy effort, I am not sure it offers much value to readers. Also there is a mix of trainability and regularization. Some of the works were proposed to address trainability issues instead of regularization, for example, densenet, and some of the initialization techniques. \n\nThe authors try to group items in each category into sub-groups according to certain attributes, however,  little explanation on how and why these attributes are identified was provided. For example, in table 1, what kind of information does the transformation space or phase provide in terms of helping readers choosing a particular data transformation / augmentation technique. At the end of section 3, the authors claim that dropout, BN are close to each other. Please elaborate on this point. \n\nThe authors offer some recommendation on how to choose or combine different regularization techniques at the end of the paper. However, it is not clear from reading the paper where these insights came from. ']","[-60, -30, -30]","[20, 20, 20]","[""The sentiment score is -60 because the reviewer expresses significant criticism of the paper's suitability for the ICLR conference. They state that the paper doesn't provide new discoveries as claimed, and is more of a survey paper which is not appropriate for the conference. The politeness score is 20 because while the reviewer is critical, they use professional and respectful language. They acknowledge the work done by the authors and suggest that the paper could be improved and published in a more appropriate journal. The reviewer also compliments the paper as 'well written in general'. The language used is not harsh or rude, but rather constructive and objective in its criticism."", ""The sentiment score is -30 because the review is generally critical, pointing out several weaknesses in the paper, such as 'too strong statements', lack of insight, and a problematic definition of regularization. However, it's not entirely negative, acknowledging the authors' good understanding of the field and the potential usefulness of the paper as a reference for students. The politeness score is 20 because while the reviewer is direct in their criticism, they use respectful language and offer constructive feedback. They use phrases like 'Unfortunately', 'I estimate', and 'could serve as a useful reference', which maintain a professional tone. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the paper's attempt to build a taxonomy and organize existing works, they express several concerns and doubts about the paper's value and clarity. The reviewer uses phrases like 'I am not sure it offers much value' and points out issues with the categorization and explanations. However, the score is not extremely negative as the reviewer does recognize some positive aspects, such as calling it a 'worthy effort'. The politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout, using phrases like 'please elaborate' and avoiding harsh language. They offer constructive criticism and suggestions for improvement rather than outright dismissal. The reviewer's language is generally neutral to mildly polite, balancing critique with acknowledgment of the authors' efforts.""]"
"['The authors describe a method for performing query completion with error correction using a neural network that can achieve real-time performance. The method described uses a character-level LSTM, and modifies the beam search procedure with a an edit distance-based probability to handle cases where the prefix may contain errors. Details are also given on how the authors are able to achieve realtime completion.\n\nOverall, it’s nice a nice study of the query completion application. The paper is well explained, and it’s also nice that the runtime is shown for each of the algorithm blocks. Could imagine this work giving nice guidelines for others who also want to run query completion using neural networks. The final dataset is also a good size (36M search queries).\n\nMy major concerns are perhaps the fit of the paper for ICLR as well as the thoroughness of the final experiments. Much of the paper provides background on LSTMs and edit distance, which granted, are helpful for explaining the ideas. But much of the realtime completion section is also standard practice, e.g. maintaining previous hidden states and grouping together the different gates. So the paper feels directed to an audience with less background in neural net LMs.\n\nSecondly, the experiments could have more thorough/stronger baselines. I don’t really see why we would try stochastic search. And expected to see more analysis of how performance was impacted as the number of errors increased, even if errors were introduced artificially, and expected analysis of how different systems scale with varying amounts of data. The fact that 256 hidden dimension worked best while 512 overfit was also surprising, as character language models on datasets such as Penn Treebank with only 1 million words use hidden states far larger than that for 2 layers. More regularization required?', 'This paper focuses on solving query completion problem with error correction which is a very practical and important problem. The idea is character based. And in order to achieve three important targets which are auto completion, auto error correction and real time, the authors first adopt the character-level RNN-based modeling which can be easily combined with error correction, and then carefully optimize the inference part to make it real time.\n\nPros:\n(1) the paper is very well organized and easy to read.\n(2) the proposed method is nicely designed to solve the specific real problem. For example, the edit distance is modified to be more consistent with the task.\n(3) detailed information are provided about the experiments, such as data, model and inference.\n\nCons:\n(1) No direct comparisons with other methods are provided. I am not familiar with the state-of-the-art methods in this field. If the performance (hit rate or coverage) of this paper is near stoa methods, then such experimental results will make this paper much more solid.', ""This paper presents methods for query completion that includes prefix correction, and some engineering details to meet particular latency requirements on a CPU.  Regarding the latter methods: what is described in the paper sounds like competent engineering details that those performing such a task for launch in a real service would figure out how to accomplish, and the specific reported details may or may not represent the 'right' way to go about this versus other choices that might be made.  The final threshold for 'successful' speedups feels somewhat arbitrary -- why 16ms in particular?  In any case, these methods are useful to document, but derive their value mainly from the fact that they allow the use of the completion/correction methods that are the primary contribution of the paper.  \n\nWhile the idea of integrating the spelling error probability into the search for completions is a sound one, the specific details of the model being pursued feel very ad hoc, which diminishes the ultimate impact of these results.  Specifically, estimating the log probability to be proportional to the number of edits in the Levenshtein distance is really not the right thing to do at all.  Under such an approach, the unedited string receives probability one, which doesn't leave much additional probability mass for the other candidates -- not to mention that the number of possible misspellings would require some aggressive normalization.  Even under the assumption that a normalized edit probability is not particularly critical (an issue that was not raised at all in the paper, let alone assessed), the fact is that the assumptions of independent errors and a single substitution cost are grossly invalid in natural language.  For example, the probability p_1 of 'pkoe' versus p_2 of 'zoze' as likely versions of 'poke' (as, say, the prefix of pokemon, as in your example) should be such that p_1 >>> p_2, not equal as they are in your model.  Probabilistic models of string distance have been common since Ristad and Yianlios in the late 90s, and there are proper probabilistic models that would work with your same dynamic programming algorithm, as well as improved models with some modest state splitting.  And even with very simple assumptions some unsupervised training could be used to yield at least a properly normalized model.  It may very well end up that your very simple model does as well as a well estimated model, but that is something to establish in your paper, not assume.  That such shortcomings are not noted in the paper is troublesome, particularly for a conference like ICLR that is focused on learned models, which this is not.  As the primary contribution of the paper is this method for combining correction with completion, this shortcoming in the paper is pretty serious.\n\nSome other comments:\n\nYour presentation of completion cost versus edit cost separation in section 3.3 is not particularly clear, partly since the methods are discussed prior to this point as extension of (possibly corrected) prefixes.  In fact, it seems that your completion model also includes extension of words with end point prior to the end of the prefix -- which doesn't match your prior notation, or, frankly, the way in which the experimental results are described.  \n\nThe notation that you use is a bit sloppy and not everything is introduced in a clear way.  For example, the s_0:m notation is introduced before indicating that s_i would be the symbol in the i_th position (which you use in section 3.3).  Also, you claim that s_0 is the empty string, but isn't it more correct to model this symbol as the beginning of string symbol?  If not, what is the difference between s_0:m and s_1:m?  If s_0 is start of string, the s_0:m is of length m+1 not length m.\n\nYou spend too much time on common, well-known information, such as the LSTM equations.  (you don't need them, but also why number if you never refer to them later?)  Also the dynamic programming for Levenshtein is foundational, not required to present that algorithm in detail, unless there is something specific that you need to point out there (which your section 3.3 modification really doesn't require to make that point).\n\nIs there a specific use scenario for the prefix splitting, other than for the evaluation of unseen prefixes?  This doesn't strike me as the most effective way to try to assess the seen/unseen distinction, since, as I understand the procedure, you will end up with very common prefixes alongside less common prefixes in your validation set, which doesn't really correspond to true 'unseen' scenarios.  I think another way of teasing apart such results would be recommended.\n\nYou never explicitly mention what your training loss is in section 5.1.\n\nOverall, while this is an interesting and important problem, and the engineering details are interesting and reasonably well-motivated, the main contribution of the paper is based on a pretty flawed approach to modeling correction probability, which would limit the ultimate applicability of the methods.""]","[20, 70, -60]","[60, 80, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges some positive aspects of the paper, such as it being 'nice' and 'well explained', with a 'good size' dataset. However, they also express 'major concerns' about the paper's fit for ICLR and the thoroughness of experiments, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses polite language throughout, such as 'nice study' and 'well explained', and frames criticisms constructively. They avoid harsh language and present concerns as suggestions for improvement rather than outright criticisms. The reviewer maintains a professional and respectful tone throughout, even when discussing limitations."", ""The sentiment score is 70 (positive) because the reviewer starts with a positive statement about the paper's focus being 'very practical and important'. They list several pros, including the paper being well-organized, the method being nicely designed, and detailed information being provided. The only con mentioned is the lack of direct comparisons, which slightly reduces the overall positive sentiment. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts and contributions. They provide constructive feedback and frame the single criticism as a suggestion for improvement rather than a harsh critique. The use of phrases like 'very well organized' and 'nicely designed' further contributes to the polite tone."", ""The sentiment score is -60 because the review is predominantly critical. While it acknowledges some positive aspects ('sound' idea, 'competent engineering'), it highlights significant flaws in the paper's approach, particularly in the modeling of correction probability. The reviewer describes this as a 'pretty serious' shortcoming that 'diminishes the ultimate impact' of the results. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'useful to document' and 'interesting and important problem'. However, some direct criticisms ('sloppy', 'troublesome') slightly lower the politeness score. The reviewer also provides constructive feedback and suggestions for improvement, which contributes to the slightly positive politeness score.""]"
"['This paper induces latent dependency syntax in the source side for NMT. Experiments are made in En-De and En-Ru.\n\nThe idea of imposing a non-projective dependency tree structure was proposed previously by Liu and Lapata (2017) and the structured attention model by Kim and Rush (2017). In light of this, I see very little novelty in this paper. The only novelty seems to be the gate that controls the amount of syntax needed for generating each target word. Seems thin for a ICLR paper.\n\nCaption of Fig 1: ""subject/object"" are syntactic functions, not semantic roles.\n\nI don\'t see how the German verb ""orders"" inflects with gender... Can you post the gold German sentence?\n\nSec 2 is poorly explained. What is z_t? Do you mean u_t instead? This is confusing.\n \nExpressions (12) to (15) are essentially the same as in Liu and Lapata (2017), not original contributions of this paper.\n\nWhy is hard attention (sec 3.3) necessary? It\'s not differentiable and requires sampling for training. This basically spoils the main advantage of structured attention mechanisms as proposed by Kim and Rush (2017).\n\nExperimentally, the gains are quite small compared to flat attention, which is disappiointing.\n\nIn table 3, it would be very helpful to display the English source.\n\nTable 4 is confusing. The DA numbers (rightmost three columns) are for the 2016 or 2017 dataset?\n\nComparison with predicted parses by Spacy are by no means ""gold"" parses...\n\nMinor comments:\n- Sec 1: ""... optimization techniques like Adam, Attention, ..."" -> Attention is not an optimization technique, but part of a model\n- Sec 1: ""abilities not its representation"" -> comma before ""not""\n', 'This paper describes a method to induce source-side dependency structures in service to neural machine translation. The idea of learning soft dependency arcs in tandem with an NMT objective is very similar to recent notions of self-attention (Vaswani et al., 2017, cited) or previous work on latent graph parsing for NMT (Hashimoto and Tsuruoka, 2017, cited). This paper introduces three innovations: (1) they pass the self-attention scores through a matrix-tree theorem transformation to produce marginals over tree-constrained head probabilities; (2) they explicitly specify how the dependencies are to be used, meaning that rather than simply attending over dependency representations with a separate attention, they select a soft word to attend to through the traditional method, and then attend to that word’s soft head (called Shared Attention in the paper); and (3) they gate when attention is used. I feel that the first two ideas are particularly interesting. Unfortunately, the results of the NMT experiments are not particularly compelling, with overall gains over baseline NMT being between 0.6 and 0.8 BLEU. However, they include a useful ablation study that shows fairly clearly that both ideas (1) and (2) contribute equally to their modest gains, and that without them (FA-NMT Shared=No in Table 2), there would be almost no gains at all. Interesting side-experiments investigate their accuracy as a dependency parser, with and without a hard constraint on the system’s latent dependency decisions.\n\nThis paper has some very good ideas, and asks questions that are very much worth asking. In particular, the question of whether a tree constraint is useful in self-attention is very worthwhile. Unfortunately, this is mostly a negative result, with gains over “flat attention” being relatively small. I also like the “Shared Attention” - it makes a lot of sense to say that if the “semantic” attention mechanism has picked a particular word, one should also attend to that word’s head; it is not something I would have thought of on my own. The paper is also marred by somewhat weak writing, with a number of disfluencies and awkward phrasings making it somewhat difficult to follow.\n\nIn terms of specific criticisms:\n\nI found the motivation section to be somewhat weak. We need a better reason than morphology to want to do source-side dependency parsing. All published error analyses of strong NMT systems (Bentivogli et al, EMNLP 2016; Toral and Sanchez-Cartagena, EACL 2017; Isabelle et al, EMNLP 2017) have shown that morphology is a strength, not a weakness of these systems, and the sorts of head selection problems shown in Figure 1 are, in my experience, handled capably by existing LSTM-based systems.\n\nThe paper mentions “significant improvements” in only two places: the introduction and the conclusion. With BLEU score differences being so low, the authors should specify how statistical significance is measured; ideally using a technique that accounts for the variance of random restarts (i.e.: Clark et al, ACL 2011).\nEquation (3): I couldn’t find the definition for H anywhere.\n\nSentence before Equation (5): I believe there is a typo here, “f takes z_i” should be “f takes u_t”.\n\nFirst section of Section 3: please cite the previous work you are talking about in this sentence.\n\nMy understanding was that the dependency marginals in p(z_{i,j}=1|x,\\phi) in Equation (11) are directly used as \\beta_{i,j}. If I’m correct, that’s probably worth spelling out explicitly in Equation (11): \\beta_{i,j} = p(z_{i,j}=1|x,\\phi) = …\n\nI don’t don’t feel like the clause between equations (17) and (18), “when sharing attention weights from the decoder with the encoder” is a good description of your clever “shared attention” idea. In general, I found this region of the paper, including these two equations and the text between them, very difficult to follow.\n\nSection 4.4: It’s very very good that you compared to “flat attention”, but it’s too bad for everyone cheering for linguistically-informed syntax that the results weren’t better.\n\nTable 5: I had a hard time understanding Table 5 and the corresponding discussion. What are “production percentages”?\n\nFinally, it would have been interesting to include the FA system in the dependency accuracy experiment (Table 4), to see if it made a big difference there.', 'This paper adds source side dependency syntax trees to an NMT model without explicit supervision. Exploring the use of syntax in neural translation is interesting but I am not convinced that this approach actually works based on the experimental results.\n\nThe paper distinguishes between syntactic and semantic objectives (4th paragraph in section 1), attention, and heads. Please define what semantic attention is. You just introduce this concept without any explanation. I believe you mean standard attention, if so, please explain why standard attention is semantic.\n\nClarity. What is shared attention exactly? Section 3.2 says that you share attention weights from the decoder with encoder. Please explain this a bit more. Also the example in Figure 3 is not very clear and did not help me in understanding this concept.\n\nResults. A good baseline would be to have two identical attention mechanisms to figure out if improvements come from more capacity or better model structure. Flat attention seems to add a self-attention model and is somewhat comparable to two mechanisms. The results show hardly any improvement over the flat attention baseline (at most 0.2 BLEU which is well within the variation of different random initializations). It looks as if the improvement comes from adding additional capacity to the model. \n\nEquation 3: please define H.']","[-60, 20, -50]","[-20, 60, 50]","[""The sentiment score is -60 because the reviewer expresses significant criticism and disappointment with the paper's novelty, methodology, and results. They state there is 'very little novelty', the gains are 'quite small', and the approach 'spoils the main advantage' of previous work. The politeness score is -20 as the language is direct and critical without much softening, using phrases like 'poorly explained', 'confusing', and 'disappointing'. However, it's not overtly rude, maintaining a professional tone while providing specific critiques and suggestions for improvement."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges 'very good ideas' and 'questions that are very much worth asking'. However, this is tempered by criticisms of 'modest gains' and 'weak writing'. The politeness score is moderately high (60) due to the reviewer's constructive tone, use of phrases like 'I feel that', and balanced presentation of positives and negatives. The reviewer offers specific, detailed feedback without harsh language, maintaining a professional and respectful tone throughout."", ""The sentiment score is -50 because the reviewer expresses skepticism about the effectiveness of the approach, stating 'I am not convinced that this approach actually works based on the experimental results.' They also point out that the results show 'hardly any improvement' over the baseline. However, the score is not extremely negative as the reviewer acknowledges that exploring syntax in neural translation is interesting. The politeness score is 50 because the reviewer uses polite and professional language throughout, offering constructive criticism and specific suggestions for improvement. They use phrases like 'Please define' and 'Please explain' rather than making demands. The tone is respectful but direct, maintaining a balance between politeness and critical feedback.""]"
"['The authors propose autoencoding text using a byte-level encoding and a convolutional network with shared filters such that the encoder and decoder should exhibit recursive structure. They show that the model can handle various languages and run various experiments testing the ability of the autoencoder to reconstruct the text with varying lengths, perturbations, depths, etc.\n\nThe writing is fairly clear, though many of the charts and tables are hard to decipher without labels (and in Figure 8, training errors are not visible -- maybe they overlap completely?).\n\nMain concern would be the lack of experiments showing that the network learns meaningful representations in the hidden layer. E.g. through semi-supervised learning experiments or experiments on learning semantic relatedness of sentences. Obvious citations such as https://arxiv.org/pdf/1511.06349.pdf and https://arxiv.org/pdf/1503.00075.pdf are missing, along with associated baselines. Although the experiment with randomly permuting the samples is nice, would hesitate to draw any conclusions without results on downstream tasks and a clearer survey of the literature.', 'The paper aims to illustrated the representation learning ability of the convolutional autoencoder with residual connections is  proposed by to encode text at the byte level.  The authors apply the proposed architecture to 3 languages and run comparisons with an LSTM.  Experimental results  with different perturbation of samples, pooling layers, and sample lengths are presented.\n\nThe writing is fairly clear, however the presentation of tables and figures could be done better, for example, Fig. 2 is referred  to in page 3,  Table 2 which contains results is referred to on page 5, Fig 4 is referred to in page 6 and appears in page 5, etc.\n\nWhat kind of minimal preprocessing is done on the text? Are punctuations removed? Is casing retained? How is the space character encoded?\n\nWhy was the encoded dimension always fixed at 1024?  What is the definition of a sample here?\n\nThe description of the various data sets could be moved to a table/Appendix, particularly since most of the results are presented on the enwiki dataset, which would lead to better readability of the paper.  Also results are presented only on a random 1M sample selected from these data sets, so the need for this whole page goes away.\n\nComparing Table 2 and Table 3, the LSTM is at 67% error on the test set while the proposed convolutional autoencoder is at 3.34%.  Are these numbers on the same test set?    While the argument that the LSTM does not generalize well due to the inherent memory learnt is reasonable, the differences in performance cannot be explained away with this. Can you please clarify this further?\n\nIt appears that the byte error shoot up for sequences of length 512+ (fig. 6 and fig. 7) and seems entirely correlated with the amount of data than recursion levels.\n\nHow do you expect these results to change for a different subset selection of training and test samples? Will Fig. 7 and Fig. 6 still hold?\n\nIn Fig, 8, unless the static train and test error are exactly on top of the  recursive errors, they are not visible.  What is the x-axis in Fig. 8?  Please also label axes on all figures. \n\nWhile the datasets are large and would take a lot of time to process for each case study, a final result on the complete data set, to illustrate if the model does learn well with lots of data would have been useful.  A table showing generated sample text would also clarify the power of the model.\n\nWith the results presented,  with a single parameter setting, its hard to determine what exactly the model learns and why.', '\nThis paper presents a convolutional auto-encoder architecture for text encoding and generation. It works on the character level and contains a recursive structure which scales with the length of the input text. Building on the recent state-of-the-art in terms of architectural components, the paper shows the feasibility of this architecture and compares it to LSTM, showing the cnn superiority for auto-encoding.\n\nThe authors have decided to encode the text into a length of 1024 - Why? Would different lengths result in a better performance?\n\nYou write ""Minimal pre-processing is applied to them since our model can be applied to all languages in the same fashion."" Please be more specific. Which pre-processing do you apply for each dataset?\n\nI wonder if the comparison to a simple LSTM network is fair. It would be better to use a 2- or 3-layer network. Also, BLSTM are used nowadays.\n\nA strong part of this paper is the large amount of investigation and extra experiments.\nMinor issues:\nPlease correct minor linguistic mistakes as well as spelling mistakes. In Fig. 3, for example, the t of Different is missing.\n\nAn issue making it hard to read the paper is that most of the figures appear on another page than where they are mentioned in the text.\n\nthe authors have chosen to cite a work from 1994 for the vanishing gradient problem. Note, that many (also earlier) works have reported this problem in different ways. A good analysis of all researches is performed in Hochreiter, S., Bengio, Y., Frasconi, P., and Schmidhuber, J. (2001) ""Gradient flow in recurrent nets: the difficulty of learning long-term dependencies"".']","[-20, -20, 50]","[50, 60, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The writing is fairly clear'), they express several concerns and criticisms. The main concern about the lack of experiments showing meaningful representations in the hidden layer, missing citations, and hesitation to draw conclusions without further results indicates a generally critical stance. The politeness score is moderately positive (50) as the reviewer uses polite and professional language throughout. They offer constructive criticism and suggestions rather than harsh judgments, using phrases like 'would hesitate to draw any conclusions' instead of more direct negative statements. The reviewer also acknowledges positive aspects of the work, which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The writing is fairly clear'), they raise several concerns and questions about the methodology, presentation, and results. The review points out multiple areas for improvement and clarification, which suggests a somewhat critical stance.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They use polite language such as 'please clarify' and phrase their criticisms as questions or suggestions rather than harsh statements. The reviewer also acknowledges positive aspects of the work before diving into critiques.\n\nThe reviewer provides specific, actionable feedback and asks for clarifications in a respectful manner, which contributes to both the slightly negative sentiment (due to the amount of critique) and the positive politeness score (due to the way the critique is presented)."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as the 'large amount of investigation and extra experiments,' and notes that it shows 'feasibility' and 'superiority' over LSTM. However, they also raise several questions and suggest improvements, indicating a balanced view. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, poses questions and suggestions constructively (e.g., 'I wonder if...', 'It would be better to...'), and refers to 'minor issues' rather than using harsh criticism. The reviewer also offers helpful suggestions for improvement, which is a polite way to provide feedback.""]"
"['The authors use a variant of deep RL to solve a  simplified 2d physical stacking task. To accommodate different goal stacking states the authors extend the state representation of DQN. The input to the network is the current state of the environment as represented by the 2d projection of the objects in the simulated grid world and a representation of the goal state in the same projection space. The reward function in its basic form rewards only the correctly finished model. A number of heuristics are used to augment this reward function so as to provide shaping rewards along the way and speed up learning. The learnt policy is evaluated on the successful assembly of the target stack and on a distance measure between the stack specified as goal and the actual stack. \n\nCurrently, I don’t understand from the manuscript, how DQN is actually trained. Are all different tasks used on a single network? If so, is it surprising that the network performs worse than when augmenting the state representation with the goal? Or are separate DQNs trained for multiple tasks?\n\nThe definition of value function at the bottom of page 4 uses the definition for continual tasks but in the current setting the tasks are naturally episodic. This should be reflected by the definition.\n\nIt would be good if the authors could comment on any classic research in RL augmenting the state representation with the goal state and any recent related developments, e.g. multi-task RL or the likes of Dosovitskiy & Koltun “Learning to act by predicting the future”.\n\nIt would be helpful do obtain more information about the navigation task, especially a plot of sorts would be helpful. Currently, it is particularly difficult to judge exactly what the authors did. \n\nHow physically “rich” is this environment compared to some of the cited work, e.g. Yildirim et al. or Battaglia et al:?\n\nOverall it feels as if this is an interesting project but that it is not yet ready for publication. ', 'The authors propose a model for learning physical interaction skills through trial and error. They use end-to-end deep reinforcement learning - the DQN model - including the task goal as an input in order to to improve generalization over several tasks, and shaping the reward depending on the visual differences between the goal state and the current state. They show that the task performance of their model is better than the DQN on two simulated tasks.\nThe paper is well-written, clarity is good, it could be slightly improved by updating the title ""Toy example with Goal integration"" to make it consistent with the naming ""navigation task"" used elsewhere.\n\nIf the proposed model is new given the reviewer\'s knowledge, the contribution is small. The biggest change compared to the DQN model is the addition of information in the input.\nThe authors initially claim that ""In this paper, [they] study how an artificial agent can autonomously acquire this intuition through interaction with the environment"", however the proposed tasks present little to no realistic physical interaction: the navigation task is a toy problem where no physics is simulated. In the stacking task, only part of the simulation actually use the physical simulation result. Given that machine learning methods are in general good at finding optimal policies that exploit simulation limitations, this problem seems a threat to the significance of this work.\n\nThe proposed GDQN model shows better performance than the DQN model. However, as the authors do not provide in-depth analysis of what the network learns (e.g. by testing policies in the absence of an explicit goal), it is difficult to judge if the network learnt a meaningful representation of the world\'s physics. This limitation along with potential other are not discussed in the paper.\n\nFinally, more than a third (10/26) references point to Arxiv papers. Despite Arxiv definitely being an important tool for paper availability, it is not peer-reviewed and there are also work that are non-finished or erroneous. It is thus a necessary condition that all Arxiv references are replaced by the peer-reviewed material when it exist (e.g. Lerer 2016 in ICML or Denil 2016 in ICLR 2017), once again to strengthen the author\'s claim.', 'Summary: This paper proposes to use deep Q-learning to learn how to reconstruct a given tower of blocks, where DQN is also parameterized by the desired goal state in addition to the current observed state.\n\nPros:\n- Impressive results on a difficult block-stacking task.\n\nCons:\n- The idea of parameterizing an RL algorithm by goals is not particularly novel.\n\nQuality and Clarity:\n\nThe paper is extremely well-written, easy to follow, and largely technically correct, though I am somewhat concerned about how the results were obtained as it does not seem like the vanilla DQN agent could do so well, even on the 2-block scenes. Even just including stable scenes, I estimated based on Figure 5 that there must be about 70 different configurations that are stable (and this is likely an underestimate). So, if each of these scenes occurs equally often and the vanilla DQN agent does not receive any information about the target goal and just acts based on an ""average"" policy, I would expect it to only achieve success about 1/70th of the time. Am I missing something here?\n\nAnother thing that was unclear to me is how the rotation of the blocks is chosen: is the agent given the next block with the correct rotation, or can it also choose to rotate the block? In the text it is implied that the only actions are {left, right, down}, which seems to simplify the task immensely. It would be interesting to include results where the agent additionally has to choose from actions of {rotate left by 90 degrees, rotate right by 90 degrees}.\n\nAlso: are the scenes used during testing separate from those used during training? If not, it\'s not obvious that the agent isn\'t just learning to memorize the solution (which somewhat defeats the idea behind parameterizing the Q-network with new goals every time).\n\nOriginality and Significance:\n\nThe block-stacking task is very cool and is more complex than many other physics-based RL tasks in the literature, which often involve just stacking square blocks in a single tower. I think it is a useful contribution to introduce this task and the GDQN agent as a baseline. However, the notion of parameterizing the policy by the goal state is not particularly novel. While it is true that many RL papers do train to optimize just a single reward function for a single goal, it is also very straightforward to modify the state space to include a goal and indeed [1-4] are just a few examples of recent papers that have done this. In general, any time there is a procedurally generated environment (e.g. Sokoban, as in [5]) the goal necessarily is included as part of the state space---so the idea of GDQN isn\'t really that new.\n\n[1] Oh, J., Singh, S., Lee, H., & Kohli, P. (2017). Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning. arXiv Preprint arXiv:1706.05064.\n[2] Dosovitskiy, A., & Koltun, V. (2017). Learning to act by predicting the future. Proceedings of the 5th International Conference on Learning Representations (ICLR 2017).\n[3] Hamrick, J. B., Ballard, A. J., Pascanu, R., Vinyals, O., Heess, N., & Battaglia, P. W. (2017). Metacontrol for adaptive imagination-based optimization. Proceedings of the 5th International Conference on Learning Representations (ICLR 2017).\n[4] Pascanu, R., Li, Y., Vinyals, O., Heess, N., Buesing, L., Racanière, S., … Battaglia, P. (2017). Learning model-based planning from scratch. arXiv Preprint arXiv: 1707.06170. Retrieved from https://arxiv.org/abs/1707.06170\n[5] Weber, T., Racanière, S., Reichert, D. P., Buesing, L., Guez, A., Rezende, D. J., … Wierstra, D. (2017). Imagination-Augmented Agents for Deep Reinforcement Learning. arXiv Preprint arXiv: 1707.06203. Retrieved from http://arxiv.org/abs/1707.06203']","[-20, -20, 20]","[50, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'interesting', they state that it is 'not yet ready for publication' and raise several questions and concerns about the methodology and clarity of the paper. The overall tone suggests that significant improvements are needed. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions (e.g., 'It would be good if...', 'It would be helpful...'), and acknowledges the potential of the project ('interesting project'). The reviewer maintains a professional and constructive tone, even when pointing out areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is well-written, clarity is good'), they also point out several limitations and concerns. The reviewer suggests the contribution is small, questions the significance of the work due to simulation limitations, and notes a lack of in-depth analysis. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, offering constructive criticism without harsh or rude phrasing. They acknowledge positive aspects before presenting criticisms and use phrases like 'could be slightly improved' rather than more negative alternatives."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some pros of the paper, such as 'impressive results' and being 'extremely well-written', while also pointing out some cons and areas of concern. The overall tone is constructive rather than overtly negative. The politeness score is high (80) as the reviewer uses respectful language throughout, phrases criticisms as questions or personal observations (e.g., 'Am I missing something here?'), and acknowledges the paper's strengths alongside its weaknesses. The reviewer also provides detailed feedback and suggestions for improvement, which is a polite and helpful approach in academic peer review.""]"
"['The paper proposes a new form of regularization that is an extension of ""Shake-Shake"" regularization (Gastaldi, 2017). The original ""shake-shake"" proposes using two residual paths adding to the same output (so x + F_1(x) + F_2(x)), and during training, considering different randomly selected convex combinations of the two paths (while using an equally weighted combination at test time). However, this paper contends that this requires additional memory, and attempt to achieve similar regularization with a single path. To do so, they train a network with a single residual path, where the residual is included without attenuation in some cases with some fixed probability, and  attenuated randomly (or even inverted) in others. The paper contends that this achieves superior performance than choosing simply a random attenuation for every sample (although, this can be seen as choosing an attenuation under a distribution with some fixed probability mass at 1). Experiments show improved generalization on CIFAR-10 and CIFAR-100.\n\nI don\'t think the paper contains sufficiently novel elements to be accepted as a conference track paper at ICLR. While it is interesting that this works well (especially the ""negative"" weight on the residual), the proposed method is fundamentally a combination of prior work: dropout and ""shake-shake"" regularization. Moreover, the evaluation is somewhat limited---essentially, I feel there isn\'t conclusive proof that ""shake-drop"" is a generically useful regularization technique. For one, the method is evaluated only on small toy-datasets: CIFAR-10 and CIFAR-100. I think at the very least, evaluation on Imagenet is necessary. The proposed regularization is applied only to the ""PyramidNet"" architecture---which begs the question of whether the proposed regularization is useful only for this specific network architecture. It would have been more useful to see results with and without ""shake-drop"" on different architectures (the point being to show a consistent improvement with this regularization, rather than achieving \'state of the art\' on CIFAR-10). Moreover, it would be interesting to see if the hyperparameter comparison shown in Tables 1 and 2 remained consistent across architectures.', 'The paper proposes ShakeDrop regularization, which is essentially a combination of the PyramidDrop and Shake-Shake regularization. The procedure consists of essentially weighting the residual branch with a random weight, in the style of Shake-Shake, where the weight is sampled from a mixture of uniform distribution in [-1, 1] and delta at 1, such that the mixture of those two distributions varies linearly with layer depth, in the style of PyramidDrop. In the style of Shake-Shake, a different random weight (in [0, 1]) is used for the backward pass. The most surprising part is that that the forward weight can be negative thus inverting the output of a convolution. Apparently the goal is to ""disturb"" the training, and the procedure yields state-of-the-art results on CIFAR-10/100.\n\nPositives:\n\n- Results: state-of-the-art on CIFAR-10/100\n\nNegatives:\n\n1. No real motivation on why should this work. I guess the motivation is the mixture of PyramidDrop and Shake-Shake motivations, but the main surprising part (forward weight can be negative) is not motivated at all. There is a tiny bit of discussion at the very end, section 4.4, where authors examine the training loss (showing it\'s non-zero so less overfitting) and mean/variance of gradients (increased). However, this doesn\'t really satisfy me - it is clear that more disturbance will cause this behaviour, but that doesn\'t mean any disturbance is good, e.g. if I always apply the negative weight and make my model weights go in the wrong direction, I\'m pretty sure training loss and gradients will be even larger, but it\'s a bad idea to do.\n\n2. I\'m concerned with the ""weird trick that happens to work on CIFAR"" line of work (not saying that this paper is the only offender) - are these methods actually useful and generalizable to other problems, or are we overfitting on CIFAR and creating MNIST v2.0 ? It would be nice to demonstrate that this regularization works in at least one more problem, maybe ImageNet, though maybe regularization is not needed there but just find one more dataset that needs regularization and test this on that.\n\n3. The paper doesn\'t explain well what is the problem with Shake-Shake and memory. I see that the author of Shake-Shake has made a comment on this and that makes a lot of sense, i.e. there is no memory issue, just because there are 2x branches doesn\'t mean shake-shake needs 2x memory as it can use less capacity=memory to achieve the same performance. So it seems the main premise of the paper - ""let\'s apply Shake-Shake to deeper models but we need to come up with a modified method because Shake-Shake cannot be applied due to memory problems"" - seems wrong.\n\n4. The writing quality is quite bad, it is very hard to understand what authors mean in parts of the text. E.g. at two places ""it has almost the same residual block as Eqn. (1)"" - how is it ""almost""? Below equation 5, it is never specified that alpha and beta are sampled uniformly(?) from those ranges, one could think that alpha and beta are fixed constants that take a specific value that is in that range. There are also various grammatical errors such as ""is expected to be powerful but slight memory overhead"" or ""which is introduced essence"", etc.\n\nSmaller comments:\n- Isn\'t it surprising that alpha in [-1, 1] and beta in [0, 1] works well, but alpha in [0, 1] and beta in [-1, 1] works much worse? The two important cases, (alpha negative, beta positive) and (alpha positive, beta negative), seem to me like they are conceptually very similar.\n- End of section 4.1, should it be b_l as p_L is a constant and b_l is what is sampled?\n- I don\'t like that exactly the same text is repeated 3 times (abstract, end of intro, end of 1.1) and in very short distance from each other - repeating the same words 3 times doesn\'t make the reader understand it better, slight rephrasing is much more beneficial.\n\nOverall:\nGood to know that this method sets the new state of the art on CIFAR-10/100, so as such it should be of interest to the community to be available online (arXiv). But with fairly little novelty (is a combination of 2 methods), very little insights of why this should work at all (especially the negative scaling coefficient which is the only extra thing that one learns from this paper, since the rest is a combination of PyramidDrop and Shake-Shake), no idea on whether the method would work outside of the CIFAR-world, and bad quality of the text - I don\'t think the manuscript is sufficiently good for ICLR.\n\n', 'This paper proposes a regularization technique for deep residual networks.  It is inspired by regularization techniques which disturb the training by applying multiplicative factors to the convolutional layer outputs e.g  Shake-Shake (Gastaldi \'17) and PyramidDrop (Yamada \'16).  The proposed approach samples a Bernoulli variable randomly to either follow the standard variant of Pyramid net, or applies a variant of shake-shake to pyramid net.\n\n+ Experimental results on CIFAR-10 and CIFAR-100 well-exceed exceed the existing ""vanilla"" techniques + regularizers.  \n- Clarity: some statements are not clear / not substantiated e.g. how does the proposed method overcome the memory problem that shake-shake has?  There are some minor issues wrt presentation, e.g. grammatical correctness of sentences, consistent usage of references, which can be fixed with more careful proofreading.\n- Quality: even though the experimental results are compelling, the paper lacks thorough analysis in understanding the effects of the regularizer.  The two experiments looks at (1) the training error, which the paper openly states does not explain why the proposed regularization works and (2) variance of the gradients throughout learning; the larger variance of gradients is speculated to be the cause, but this is almost expected, given that the method is designed to allow larger fluctuations and perturbations during training.']","[-50, -50, -20]","[50, 20, 50]","[""The sentiment score is -50 because the reviewer expresses a generally negative view of the paper, stating that it 'doesn't contain sufficiently novel elements to be accepted' and that the evaluation is 'somewhat limited.' However, they do acknowledge some positive aspects, such as the interesting results, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism and instead offering constructive feedback. They use phrases like 'I don't think' and 'I feel' to soften their criticisms, and provide specific suggestions for improvement, which is a polite approach to peer review."", ""The sentiment score is -50 because while the reviewer acknowledges some positives (state-of-the-art results), they list several significant negatives and ultimately recommend against publication at ICLR. The overall tone is critical, but not entirely dismissive. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I don't think' and 'I'm concerned' rather than harsh language. They also acknowledge positives before listing negatives. However, some direct criticisms (e.g., 'The writing quality is quite bad') prevent a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Experimental results... well-exceed existing techniques'), they also point out significant shortcomings in clarity and quality. The criticism outweighs the praise, but it's not overwhelmingly negative. The politeness score is moderately positive (50) as the reviewer uses neutral language and balances positive and negative feedback. They present criticisms constructively, using phrases like 'can be fixed' and 'lacks thorough analysis' rather than harsh or dismissive language. The review maintains a professional tone throughout, neither overly formal nor casual.""]"
"[""The authors study cases where interpretation of deep learning predictions is extremely fragile. They systematically characterize the fragility of several widely-used feature-importance interpretation methods. In general, questioning the reliability of the visualization techniques is interesting. Regarding the technical details, the reviewer has the following comments: \n\n- What's the limitation of this attack method?\n\n- How reliable are the interpretations? \n\n- The authors use spearman's rank order correlation and Top-k intersection as metrics for interpretation similarity. \n\n- Understanding whether influence functions provide meaningful explanations is very important and challenging problem in medical imaging applications. The authors showed that across the test images, they were able to perturb the ordering of the training image influences. I am wondering how this will be used and evaluated in medical imaging setting. \n"", 'The key observation is that it is possible to generate adversarial perturbations wherein the behavior of feature importance methods (e.g. simple gradient method (Simonyan et al, 2013), integrated gradient (Sundararajan et al, 2017), and DeepLIFT ( Shrikumar et al, 2016) ) have large variation while predicting same output.    Thus the authors claim that one has to be careful about using feature importance maps.\n\nPro:  The paper raises an interesting point about the stability of feature importance maps generated by gradient based schemes.\n\nCons:\nThe main problem I have with the paper is that there is no precise definition of what constitutes the stable feature importance map.  The examples in the paper seem to be cherry picked to illustrate dramatic effects.   The experimental protocol used does not provide enough information of the variability of the salience maps shown around small perturbations of adversarial inputs. The paper would benefit from more systematic experimentation and a better definition of what authors believe are important attributes of stability of human interpretability of neural net behavior.', 'The paper shows that interpretations for DNN decisions, e.g. computed by methods such as sensitivity analysis or DeepLift, are fragile: Visually (to a human) inperceptibly different image cause greatly different explanations (and also to an extent different classifier outputs). The authors perturb input images and create explanations using different methods. Even though the image is inperceptibly different to a human observer, the authors observe large changes in the heatmaps visualizing the explanation maps. This is true even for random perturbations. \n\nThe images have been modified wrt. to some noise, such that they deviate from the natural statistics for images of that kind. Since the explanation algorithms investigated in this papers merely react to the interactions of the model to the input and thus are unsupervised processes in nature, the explanation methods merely show the model\'s reaction to the change.\nFor one, the model itself reacts to the perturbation, which can be measured by the (considarbly) increased class probability. Since the prediction score is given in probabilty values, the reviewer assumes the final layer of the model is a SoftMax activation. In order to see change in the softmax output score, especially if the already dominant prediction score is further increased, a lot of change has to happen to the outputs of the layer serving as input to the SoftMax layer.\n\nIt can thus be expected, that the input- and class specific explanations change as well, to an also not so small extent. The explanation maps mirror for the considered methods the model\'s reaction to the input. They are thus not meaningless, but are a measure to model reaction instead of an independent process. The excellent Figure 2 supports this point. Not the interpretation itself is fragile, but the model.\nAdding a small delta to the sample x shifts its position in data space, completely altering the prediction rule applied by the model due to the change in proximity to another section of the decision hyperplane. The fragility of DNN models to marginally perturbed inputs themselves is well known. \nThis especially true for adversial perturbations, which have been used as test cases in this work. The explanation methods are expected to highlight highly important areas in an image, which have been targetet by these perturbation approaches.\n\nThe authors give an example of an adversary manipulating the input in order to draw the activation to specific features to draw confusing/malignant explanation maps. In a settig of model verification, the explanation via heatmaps is exactly what one wants to have: If tiny change to the image causes lots of change to the prediction (and explanation) we can visualize the instability of the model not the explanation method.\nFurther do targeted perturbations not show the fragility of explanation methods, but rather that the models actually find what is important to the model. It can be expected, that after a change to these parts of the input, the model will decide differently, albeit coming to the same conclusion (in terms of predicted class membership), which reflects in the explanation map computed for the perturbed input.\n\nFurther remarks:\nIt would be interesting to see the size and position of the center of mass attacks in the appendix. The reviewer closely follows and is experienced with various explanation methods, their application and the quality of the expected explanations. The reviewer is therefore surprised by the poor quality and lack of structure in the maps obtained from the DeepLift method. Can bugs and suboptimal configurations be ruled out during the experiments? The DeepLift explanations are almost as noisy as the ones obtained for Sensitivity Analysis (i.e. the gradient at the input point). However, recent work (e.g. Samek et al., IEEE TNNLS, 2017 or Montavon et al., Digital Signal Processing, 2017) showed that decomposition-based methods (such as DeepLift) provide less noisy explanations than Sensitivity Analysis.\n\nHave the authors considered training the net with small random perturbations added to the samples, to compare the ""vanilla"" model to the more robust one, which has seen noisy samples, and compared explanations? \nWhy not train (finetune) the considered models using softplus activations instead of exchanging activation nodes?\nAppendix B: Heatmaps through the different stages of perturbation should be normalized using a common factor, not individually, in order to better reflect the change in the explanation\n\nConclusion:\nThe paper follows an interesting approach, but ultimately takes the wrong view point:\nThe authors try to attribute fragility to explaining methods, which visualize/measure the reaction of the model to the perturbed inputs. A major rework should be considered.']","[20, -20, -50]","[50, 50, 50]","[""The sentiment score is slightly positive (20) because the reviewer begins by acknowledging the interesting nature of the study and its importance in questioning the reliability of visualization techniques. However, the review quickly moves to a list of questions and comments, which suggests some reservations or areas for improvement. The politeness score is moderately positive (50) as the reviewer uses neutral language and frames their comments as questions or observations rather than direct criticisms. The reviewer's tone is professional and constructive, avoiding harsh language or negative judgments. The use of phrases like 'I am wondering' indicates a respectful approach to offering feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges an 'interesting point' raised by the paper, they express several significant concerns ('main problem', 'cherry picked', 'not enough information', 'would benefit from more systematic experimentation'). These criticisms outweigh the initial positive comment, resulting in an overall negative sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, presenting their criticisms as observations ('The main problem I have...') rather than direct attacks. They also begin with a positive comment before moving to criticisms, which is a polite approach. The language is professional and constructive, suggesting improvements rather than simply pointing out flaws."", ""The sentiment score is -50 because while the reviewer acknowledges some interesting aspects of the paper, they ultimately conclude that the paper takes the wrong viewpoint and suggest a major rework. This indicates a predominantly negative sentiment, though not entirely dismissive. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and suggestions for improvement. They acknowledge the paper's strengths while pointing out areas of concern, maintaining a balanced and courteous tone. The reviewer also uses phrases like 'interesting approach' and 'excellent Figure 2', which contribute to the polite tone. However, the critique is direct and doesn't employ overly deferential language, hence the score is not higher.""]"
"['The authors propose a new loss function that is directed to take into account Boolean constraints involving the variables of a classification problem. This is a nice idea, and certainly relevant. The authors clearly describe their problem, and overall the paper is well presented. The contributions are a loss function derived from a set of axioms, and experiments indicating that this loss function captures some valuable elements of the input. This is a valid contribution, and the paper certainly has some significant strengths.\n\nConcerning the loss function, I find the whole derivation a bit distracting and unnecessary. Here we have some axioms, that are not simple when taken together, and that collectively imply a loss function that makes intuitive sense by itself. Well, why not just open the paper with Definition 1, and try to justify this definition on the basis of its properties. The discussion of axioms is just something that will create debate over questionable assumptions. Also it is frustrating to see some axioms in the main text, and some axioms in the appendix (why this division?). \n\nAfter presenting the loss function, the authors consider some applications. They are nicely presented; overall the gains are promising but not that great when compared to the state of the art --- they suggest that the proposed semantic loss makes sense. However I find that the proposal is still in search of a ""killer app"". Overall, I find that the whole proposal seems a bit premature and in need of more work on applications (the work on axiomatics is fine as long as it has something to add).\n\nConcerning the text, a few questions/suggestions:\n- Before Lemma 3, ""this allows..."" is the ""this including the other axioms in the appendix?\n- In Section 4, line 3: I suppose that the constraint is just creating a problem with a class containing several labels, not really a multi-label classification problem (?).\n- The beginning of Section 4.1 is not very clear. By reading it, I feel that the best way to handle the unlabeled data would be to add a direct penalty term forcing the unlabeled points to receive a label. Is this fair?\n- Page 6: ""a mor methodological""... should it be ""a more methodical""?\n- There are problems with capitalization in the references. Also some references miss page numbers and some do not even indicate what they are (journal papers, conference papers, arxiv, etc).\n', 'This paper suggest a method for including symbolic knowledge into the learning process. The symbolic knowledge is given as logical constraints which characterize the space of legal solutions.   This knowledge is ""injected"" into the learning process by augmenting the loss function with a symbolic-loss term that, in addition to the traditional loss, increases the probability of legal states (which also includes incorrect, yet legal, predictions). \n\nOverall the idea is interesting, but the paper does not seem ready for publication.  The  idea of semantic-loss function is appealing and is nicely motivated in the paper, however the practical aspects of how it can be applied are extremely vague and hard to understand.  Specifically, the authors define it over all assignments to the output variables that satisfy the constraints. For any non-trivial prediction problem, this would be at least computationally challenging. The author discuss it briefly mentioning a method by Darwiche-2003, but do not offer much intuition or analysis beyond that.  Their experiments focus on multiclass classification, which implicitly has a ""one-vs.-all"" constraint, although it\'s not clear why defining a formal loss function is needed (instead of just taking the argmax of the multiclass net), and even beyond that - why would it result in such significant improvements (when there are a few annotated data points)?   \n\nThe more interesting case is where the loss needs to decompose over the parts of a structural decision, where symbolic knowledge can help  constrain the output space. This has been addressed in the literature (e.g., [1], [2]) it\'s not clear why the authors don\'t compare to these models, or even attempt any meaningful evaluation.\n\n\n[1] Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, and Eric Xing. Harnessing deep neural\nnetworks with logic rules. ACL, 2016.\n\n[2]Posterior Regularization for Structured Latent Variable Models.  Ganchev et-al 2010.', 'SUMMARY \n\nThe paper proposes a new form of regularization utilizing logical constraints. The semantic loss function is built on the exploitation of symbolic knowledge extracted from data and connecting the logical constraints to the outputs of a neural network. The use of Boolean logic as a constraint provides a secondary regularization term to prevent over-fitting and improve predictions. The benefit of using the function is found primarily with semi-supervised tasks where data is partially unlabelled. The logical constraints provided by the semantic loss function allow for improved classification of unlabeled data.\nOutput constraints for the semantic loss function are represented with one-hot encoding, prefer- ence rankings, and paths in a grid. These three different output constraints are designed to explore different learning purposes. The semantic function was tested on both semi-supervised classifica- tion tasks as well as structure learning. The paper primarily focuses on the one-hot encoding constraint as it is viewed as a capable technique for multi-class classification.\n\nPOSITIVES \n\nIn terms of structure, the paper was written very well. Sufficient background information was con- veyed which helped in understanding the proposed semantic loss function. A thorough breakdown is also carried out on the semantic loss function itself by explaining its axioms which help explain how the outputs of a neural network match a given constraint.\nAs a scientific contribution, I would say results from the experiments were able to justify the proposal of the semantic loss function. The function was able to perform better than most other implementations for semi-supervised learning tasks, and the function was tested on multiple datasets. The paper also made use of testing the function against other notable machine learning approaches, and in most cases the function performed better, but this usually was confined to semi-supervised learning tasks. During supervised learning tasks the function did not perform markedly better than older implementations. Given that, the semantic loss function did prove to be a seemingly simple approach to improving semi-supervised classification tasks.\n• The background section covers the knowledge required in understanding the semantic loss function. The paper also clearly explains the meaning for some of the notation used in the definitions.\n• Experiments which clearly show the benefit of using the semantic loss function. Multiple experiment types were done as well which showed evidence of the broad applicability of the function.\n• In depth description of the definitions, axioms, and propositions of the semantic loss function.\n• A large number of experiments exploring the usefulness of the function for multiple learning tasks, and on multiple datasets.\n\nNEGATIVES \n\nI was not clear if the logical constraints are to be instantiated before learning, i.e. they are defined by hand prior to being implemented in the neural network. This is a pretty important question and drastically changes the nature of the learning process. Beyond that complaint, the paper did not suffer from any critical issues. There were some issues with spelling, and the section titled ’Algorithm’ fails to clearly define a complete algorithm using the semantic loss function. It would have helped to have two algorithms. One defining the pipeline for the semantic loss function, and another showing the implementation of the function in a machine learning framework. The semantic loss function found success only in cases were the learning task was semi-supervised, and not in cases of total supervised learning. This is not a true negative, but an observation on the effectiveness of the function.\n\n- A few typos in the paper.\n- The axioms for the semantic loss function where defined but there seemed to be a lack of a clear algorithm provided showing the pipeline implementation of the semantic loss function.\n- While the semantic loss function does improve learning performance in most cases, the im- provements are confined to semi-supervised learning tasks, and with the MNIST dataset another methodology, Ladder Nets, was able to outperform the semantic loss function.\n\nRELATED WORK\n\nThe paper proposed that logic constraints applied to the output of neural networks have the capacity to improve semi-supervised classification tasks as well as finding the shortest path. In the introduction, the paper lists Zhiting Hu et al. paper titled Harnessing Deep Neural Networks with Logic Rules as an example of a similar approach. Hu et al. paper utilized logic constraints in conjunction with neural nets as well. A key difference was that Hu et al. applied their network architecture to supervised classification tasks. Since the performance of the current papers semantic loss function with supervised tasks did not improve upon other methods, it may benefit to utilize the research by Hu et al. as a means of direct comparison for supervised learning tasks, and possibly incorporate their methods with the semantic loss function in order to improve upon supervised learning tasks.\n\nCONCLUSION\n\nGiven the success of the semantic loss function with semi-supervised tasks, I would accept this paper. The semantic loss was able to improve learning with respect to the tested datasets, and the paper clearly described the properties of the functions. The paper would benefit by including a more concrete algorithm describing the flow of data through a given neural net to the semantic loss function, as well as the process by which the semantic loss function constrains the data based on propositional logic, but in general this complaint is more nit picking. The semantic loss function and the experiments which tested the function showed clearly that there is a benefit to this research and there are areas for it to improve.']","[20, -50, 70]","[60, 20, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's strengths and relevance, calling it a 'nice idea' and 'well presented'. However, they also express concerns about the derivation process and the need for more work on applications, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They acknowledge the paper's merits before presenting their concerns, and use phrases like 'I find' to soften their critiques. The reviewer also provides specific, helpful suggestions for improvement, which is a polite way to offer feedback."", ""The sentiment score is -50 because while the reviewer acknowledges the idea as 'interesting' and 'nicely motivated', they state that the paper 'does not seem ready for publication' and point out several significant issues. The reviewer criticizes the practical aspects as 'extremely vague and hard to understand' and notes a lack of comparison to existing literature. These criticisms outweigh the initial positive remarks, resulting in a moderately negative sentiment. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'Overall the idea is interesting' and 'The idea of semantic-loss function is appealing'. However, they don't use overtly polite language or soften their criticisms extensively, keeping the tone more neutral than explicitly polite."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its well-written structure, thorough explanations, and successful experimental results. The reviewer states they would accept the paper and acknowledges its scientific contribution. However, it's not a perfect score due to some minor criticisms and areas for improvement mentioned. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They balance positive feedback with areas for improvement, and phrase criticisms in a considerate manner (e.g., 'This is not a true negative, but an observation...'). The reviewer also provides helpful suggestions for enhancement, demonstrating a supportive attitude towards the authors' work.""]"
"['The paper proposes a technique for differentially privately generating synthetic data using GAN, and experimentally showed that their method achieves both high utility and good privacy.\nThe idea of building a differentially private GAN and generating differentially private synthetic data is very interesting. However, my main concern is the privacy aspect of the technique, as it is not explained clearly enough in the paper. There is also room for improvement in the presentation and clarity of the paper.\n\nMore details:\n- About the differential privacy aspect:\n  The author didn\'t provide detailed privacy analysis of the Gaussian noise layer, and I don\'t find the values of the sensitivity (C = 1) provided in the answer to a public comment easy to see. Also, the paper mentioned that the batch size is 32 and the author mentioned in the comment that the std of the Gaussian noise is 0.7, and the number of epoch is 50 or 150. I think these values would lead to epsilon much larger than 8 (as in Table 1). However, in Section 5.2, it is said that ""Privacy bounds were evaluated using the moments accountant and the privacy amplification theorem (Abadi et al., 2016), and therefore, are data-dependent and are tighter than using normal composition theorems."" I don\'t see clearly why privacy amplification is needed here, and why using moments accountant and privacy amplification can lead to data-dependent privacy loss.\n  In general, I don\'t find the privacy analysis of this paper clear and detailed enough to convince me about the correctness of the privacy results. However, I am very happy to change my opinion if there are convincing details in the rebuttal.\n\n- About the presentation:\n  As a paper proposing a differentially private algorithm, detailed and formal analysis of the privacy guarantees is essential to convince the readers. For example, I think it would be much better if there is a formal theorem showing the sensitivity of the Gaussian noise layer. And it would be better to restate (in Appendix 7.4) not only the definition of moments accountant, but the composition and tail bound, as well as the moments accountant for the Gaussian mechanism, since they are all used in the privacy analysis of this paper.\n', ""Summary: The paper addresses the problem of non-interactive differentially private mechanism via adversarial networks. Non-interactive mechanisms have been one of the most sought-after approaches in differentially private algorithm design. The reason is that once a differentially private data set is released, it can be used in any way to answer queries / perform learning tasks without worrying about the privacy budget. However, designing effective non-interactive mechanisms are notoriously hard because of strong computational lower bounds. In that respect, the problem addressed in this paper is extremely important, and the approach of using an adversarial network for the task is very natural (yet novel).\n\nThe main idea in the paper is to set up a usual adversarial framework with the generator and the discriminator, where the discriminator has access to the raw data. The information (in the form of gradients) is passed from the discriminator on to the generator via a differentially private channel (using Gaussian mechanism).\n\nPositive aspects of the paper: One main positive aspect of the paper is that it comes up with a very simple yet effective approach for a non-interactive mechanism for differential privacy. Another positive aspect of the paper is that it is very well-written and is easy to follow.\n\nQuestions: I have a few questions about the paper.\n\n1. The technical novelty of the paper is not that high. Given the main idea of using a GAN, the algorithms and the experiments are fairly straightforward. I may be missing something. I believe the paper can be strengthened by placing more emphasis on the technical content.\n\n2. I am mildly concerned about the effectiveness of the algorithm in the high dimensional setting. The norm of i.i.d. Gaussian noise scales roughly as \\sqrt{dimensions}, which may be too much to tolerate in most settings.\n\n3. I was wondering if there is a way to incorporate assumptions about sparsity in the original data set, to handle curse of dimensionality.\n\n4. I am not sure about the novelty of Theorem 2. Isn't it just post-processing property of differential privacy?"", ""This paper considers the problem of generating differentially private datasets using GANs. To the best of my knowledge this is the first paper to study differential privacy for GANs.\n\nThe paper is fairly well-written but has several major weaknesses:\n-- Privacy parameter eps = 8 used in the experiments implies that the likelihood of any event can change by e^8 which is roughly 3000, which is an unacceptably high privacy loss. Moreover, even for this high privacy loss the accuracy on the SVHN dataset seems to drop a lot (92% down to 83%) when proposed mechanism is used.\n-- I didn't find a formal proof of the privacy guarantee in the paper. The authors say that the privacy guarantee is based on the moments accountant method, but I couldn't find the proof anywhere. The method itself is introduced in Section 7.4 but isn't used for the proof. Thus the paper seems to be incomplete.""]","[-30, 50, -50]","[50, 80, 20]","[""The sentiment score is -30 because while the reviewer acknowledges the interesting idea of the paper, they express significant concerns about the privacy analysis and presentation clarity. The overall tone is more critical than positive, but not entirely negative. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and expressing willingness to change their opinion if provided with more convincing details. They use phrases like 'I think' and 'I don't find' instead of making absolute statements, which contributes to a polite tone. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional and neutral stance overall."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance and novelty of the paper's approach, praising its simplicity and effectiveness. They also commend the paper for being well-written and easy to follow. However, the reviewer raises some questions and concerns, which temper the overall positive sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing their concerns as questions rather than criticisms. They begin with positive aspects before moving to questions, and use phrases like 'I may be missing something' and 'I was wondering,' which demonstrate a considerate tone. The reviewer also acknowledges the paper's strengths and importance of the topic, further contributing to the polite tone."", ""The sentiment score is -50 because the reviewer points out 'several major weaknesses' and criticizes key aspects of the paper, including the privacy parameter used and the lack of a formal proof. However, it's not entirely negative as the reviewer acknowledges it's the first paper to study this topic and is 'fairly well-written'. The politeness score is 20 because the language is generally professional and constructive, using phrases like 'to the best of my knowledge' and 'fairly well-written'. The reviewer provides specific critiques without using harsh or rude language, but also doesn't go out of their way to be overly polite or complimentary.""]"
"['The paper studies the global convergence for policy gradient methods for linear control problems. \n(1) The topic of this paper seems to have minimal connection with ICRL. It might be more appropriate for this paper to be reviewed at a control/optimization conference, so that all the technical analysis can be evaluated carefully. \n\n(2) I am not convinced if the main results are novel. The convergence of policy gradient does not rely on the convexity of the loss function, which is known in the community of control and dynamic programming. The convergence of policy gradient is related to the convergence of actor-critic, which is essentially a form of policy iteration. I am not sure if it is a good idea to examine the convergence purely from an optimization perspective.\n\n(3) The main results of this paper seem technical sound. However, the results seem a bit limited because it does not apply to neural-network function approximator. It does not apply to the more general control problem rather than quadratic cost function, which is quite restricted. I might have missed something here. I strongly suggest that these results be submitted to a more suitable venue.\n\n', 'I find this paper not suitable for ICLR. All the results are more or less direct applications of existing optimization techniques, and not provide fundamental new understandings of the learning REPRESENTATION.', 'The work investigates convergence guarantees of gradient-type policies for reinforcement learning and continuous control\nproblems, both in deterministic and randomized case, whiling coping with non-convexity of the objective. I found that the paper suffers many shortcomings that must be addressed:\n\n1) The writing and organization is quite cumbersome and should be improved.\n2) The authors state in the abstract (and elsewhere): ""... showing that (model free) policy gradient methods globally converge to the optimal solution ..."". This is misleading and NOT true. The authors show the convergence of the objective but not of the iterates sequence. This should be rephrased elsewhere.\n3) An important literature on convergence of descent-type methods for semialgebraic objectives is available but not discussed.']","[-50, -80, -60]","[20, -20, -20]","[""The sentiment score is -50 because the reviewer expresses significant doubts about the paper's suitability for the conference and its novelty. They suggest it might be more appropriate for a different venue and question if the main results are novel. However, they do acknowledge that the main results seem technically sound, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and constructive manner. They use phrases like 'I am not convinced' and 'I strongly suggest' rather than using harsh or dismissive language. The reviewer also acknowledges that they 'might have missed something,' showing a degree of openness and politeness. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -80 because the reviewer clearly states the paper is 'not suitable for ICLR' and criticizes it for not providing 'fundamental new understandings'. This indicates a strongly negative view of the paper's contribution. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and dismissive. The reviewer doesn't offer any positive feedback or soften their criticism, which comes across as somewhat impolite in academic discourse. The use of 'more or less' slightly softens the critique, preventing an even lower politeness score."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the paper 'suffers many shortcomings that must be addressed' and lists several critical points. There are no positive comments, indicating a negative sentiment. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without any softening language or positive reinforcement. Phrases like 'This is misleading and NOT true' and 'The writing and organization is quite cumbersome' are particularly blunt. The reviewer does not use polite phrases or acknowledge any strengths of the paper, which contributes to the slightly impolite tone.""]"
"[""The paper entitled 'Siamese Survival Analysis' reports an application of a deep learning to three cases of competing risk survival analysis. The author follow the reasoning that '... these ideas were not explored in the context of survival analysis', thereby disregarding the significant published literature based on the Concordance Index (CI). \n\nBesides this deficit, the paper does not present a proper statistical setup (e.g. 'Is censoring assumed to be at random? ...) , and numerical results are only referring to some standard implementations, thereby again neglecting the state-of-the-art solution. That being said, this particular use of deep learning in this context might be novel."", 'The authors tackle the problem of estimating risk in a survival analysis setting with competing risks. They propose directly optimizing the time-dependent discrimination index using a siamese survival network. Experiments on several real-world dataset reveal modest gains in comparison with the state of the art.\n\n- The authors should clearly highlight what is their main technical contribution. For example, Eqs. 1-6 appear to be background material since the time-dependent discrimination index is taken from the literature, as the authors point out earlier. However, this is unclear from the writing. \n\n- One of the main motivations of the authors is to propose a model that is specially design to avoid the nonidentifiability issue in an scenario with competing risks. It is unclear why the authors solution is able to solve such an issue, specially given the modest reported gains in comparison with several competitive baselines. In other words, the authors oversell their own work, specially in comparison with the state of the art.\n\n- The authors use off-the-shelf siamese networks for their settting and thus it is questionable there is any novelty there. The application/setting may be novel, but not the architecture of choice.\n\n- From Eq. 4 to Eq. 5, the authors argue that the denominator does not depend on the model parameters and can be ignored. However, afterwards the objective does combine time-dependent discrimination indices of several competing risks, with different denominator values. This could be problematic if the risks are unbalanced.\n\n- The competitive gain of the authors method in comparison with other competing methods is minor.\n\n- The authors introduce F(t, D | x) as cumulative incidence function (CDF) at the beginning of section 2, however, afterwards they use R^m(t, x), which they define as risk of the subject experiencing event m before t. Is the latter a proxy for the former? How are they related?', 'This paper introduces siamese neural networks to the competing risks framework of Fine and Gray. The authors optimize for the c-index by minimizing a loss function driven by the cumulative risk of competing risk m and correct ordering of comparable pairs. While the idea of optimizing directly for the c-index directly is a good one (with an approximation and with useful complementary loss function terms), the paper leaves something to be desired in quality and clarity.\n\nRelated works:\n- For your consideration: is multi-task survival analysis effectively a competing risks model, except that these models also estimate risk after the first competing event (i.e. in a competing risks model the rates for other events simply go to 0 or near-zero)? Please discuss. Also, if the claim is that there are not deep learning survival analyses, please see, e.g. Jing and Smola.\n- It would be helpful to define t_k explicitly to alleviate determining whether it is the interval time between ordered events or the absolute time since t_0 (it\'s the latter). Consider calling k a time index instead of t_k a time interval (""subject x experiences cause m occurs [sic] in a time interval t_k"")\n- Line after eq 8: do you mean accuracy term?\n- I would not call Reg a regularization term since it is not shrinking the coefficients. It is a term to minimize a risk not a parameter.\n- You claim to adjust for event imbalance and time interval imbalance but this is not mathematically shown nor documented in the experiments.\n- The results show only one form of comparison, and the results have confidence intervals that overlap with at least one competing method in all tasks.']","[-60, -40, -50]","[-20, 20, 20]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several deficits in the paper, including disregarding significant published literature, lack of proper statistical setup, and neglecting state-of-the-art solutions. The only positive aspect mentioned is that the particular use of deep learning might be novel, but this is overshadowed by the criticisms. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without much attempt to soften the criticism or provide encouragement. Phrases like 'disregarding the significant published literature' and 'neglecting the state-of-the-art solution' come across as somewhat harsh. The reviewer does not use any particularly polite language or offer any positive reinforcement, which contributes to the slightly negative politeness score."", ""The sentiment score is -40 because the review is generally critical, pointing out several issues with the paper such as lack of clarity in the main contribution, questionable novelty, and modest gains compared to the state of the art. However, it's not entirely negative as it acknowledges the authors' attempt to tackle a complex problem. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and provide specific, constructive feedback. The reviewer uses phrases like 'The authors should' and 'It is unclear' rather than more confrontational language. The tone is academic and objective, maintaining a level of politeness while still conveying critical feedback."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('the idea of optimizing directly for the c-index directly is a good one'), the overall tone is critical. The review states that 'the paper leaves something to be desired in quality and clarity' and lists several areas for improvement, indicating a generally negative sentiment. The politeness score is 20 because the reviewer uses relatively neutral language and offers constructive criticism. They avoid harsh or rude phrasing, instead using phrases like 'For your consideration' and 'It would be helpful to'. However, the review is not overly polite either, maintaining a professional and direct tone throughout.""]"
"[""This paper proposes what is essentially an off-policy method for learning options in complex continuous problems.  The idea is to use policy gradient style algorithms to update a suite of options using relatively \n\nOn the positive side, I like the core idea of this paper.  The idea of updating multiple options at once is a good one.  I think the authors should definitely continue to investigate this line of work.  I also appreciated that the authors took the time to try and visualize what was learned.  The paper is generally well-written and easy to read.\n\nOn the negative side: ultimately, the algorithm doesn't seem to work all that well.  Empirically, the method doesn't seem to perform substantially better than other algorithms, although there seems to be some slight advantage.  A clearly missing comparison would be something like TRPO or DDPG.\n\nFigure 1 was helpful in understanding marginalization and the forward algorithm.  Thanks.\n\nWas there really only 4 options that were learned?  How would this scale to more?\n"", 'This paper treats option discovery as being analogous to discovering useful latent variables.  The proposed formulation assumes there is a policy over options, which invokes an option’s policy to select actions at each timestep until the option’s termination function is activated.  A contribution of this paper is to learn all possible options that might have caused an observed trajectory, and to update parameters for all these pertinent option-policies with backprop.  The proposed method, IOPG, is compared to A3C and the option-critic (OC) on four continuous control tasks in Mujoco, and IOPG has the best performance on one of the four domains.\n\nThe primary weakness of this paper is the absence of performance or conceptual improvements in exchange for the additional complexity of using options.  The only domain where IOPG outperforms both A3C and OC is the Walker2D-v1 domain, and the reported performance on that domain (~800) is far below the performance of other methods (shown on OpenAI’s Gym site or in the PPO paper). Also, there is not much analysis on what kind of options are learned with this approach, beyond noting that the options seem clustered on tSNE plots.  Given the close match between the A3C agent and the IOPG agent on the other three domains, I expect that the system is mostly relying on the base A3C components with limited contributions from the extensions introduced in the network for options.  \n\nThe clarity of the paper’s contributions could be improved. The contribution of options might be made more clearly in smaller domains or in more detailed experiments. How is the termination beta provided from the network?  How frequently did the policy over options switch between them?  How was the number of options selected, and what happens when the number of possible options is varied from 1 to 4 or beyond 4?  To what extent was there overlap in the learned policies to realize the proposed algorithmic benefit of learning multiple option-policies from the same transitions?  The results in this paper do not provide strong support for using the proposed method.\n\n', 'The paper presents a new policy gradient technique for learning options. The option index is treated as latent variable and, in order to compute the policy gradient, the option distribution for the current sample is computed by using a forward pass. Hence, a single sample can be used to update all options and not just the option that has been used for this sample.\n \nThe idea of the paper is good but the novelty is limited. As noted by the authors, the idea of using inference for option discovery has already been presented in Daniel2016. Note that the option discovery process is Daniel2016 is not limited to linear sub-policies, only the policy update strategy is. So the main contribution is to use a new policy update strategy, i.e., policy gradients, for inference based option discovery. Thats fine but should be stated more clearly in the paper. The paper is also written very well and the topic is relevant for the ICLR conference. \n\nHowever, the paper has two main problems:\n- The results are not convincing. In most domains, the performance is similar to the A3C algorithm (which does not use inference based option discovery), so the impact of this paper seems limited. \n\n- One of the main assumptions of the algorithm is wrong. The assumption is that rewards from the past are not correlated with actions in the future conditioned on the state s_t (otherwise we would always have a correlation) ,which  is needed to use the policy gradient theorem. The assumption is only true for MDPs. However, using the option index as latent variable yields a PoMDP. There, this assumption does not hold any more. Example: Reward at time step t-1 depends on the action, which again depends on the option o_t-1. Action at time step t depends on o_t. Hence, there is a strong correlation between reward r_t-1 and action a_t+1 as o_t and o_t+1 are strongly correlated. o_t is not a conditional variable of the policy as it is not part of the state, thats why this assumption does not work any more.\n\nSummary: The paper is well written and presents a good extension of inference based option discovery. However, the results are not convincing and there is a crucial issue in the assumptions of the algorithm. \n']","[50, -50, -20]","[80, 20, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses appreciation for the core idea and encourages further investigation, while also noting some negative aspects like the algorithm's performance. The politeness score is 80 (quite polite) due to the reviewer's constructive tone, use of phrases like 'I like' and 'I appreciated', and the expression of gratitude for helpful elements. The reviewer balances criticism with positive feedback and offers specific suggestions for improvement, maintaining a respectful and encouraging tone throughout."", ""The sentiment score is -50 because the review is predominantly critical. While the first paragraph provides a neutral summary, the subsequent paragraphs highlight significant weaknesses in the paper, such as the lack of performance improvements and unclear contributions. The reviewer states that the results 'do not provide strong support for using the proposed method,' indicating a negative overall sentiment. However, it's not entirely negative as the reviewer acknowledges some positive aspects, like outperforming other methods in one domain. The politeness score is 20 because the language used is professional and constructive. The reviewer provides specific suggestions for improvement and frames criticisms as opportunities for clarification rather than direct attacks. The tone is respectful but direct, maintaining a balance between politeness and honest critique."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The idea of the paper is good', 'The paper is also written very well'), they highlight significant issues with the paper's novelty, results, and a crucial assumption. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positives before presenting criticisms, and uses phrases like 'However' to soften critiques. The reviewer also provides constructive feedback and explains their concerns in detail, which is considerate to the authors.""]"
"[""The paper proposes to use Adaptive Convolution (Niklaus 2017) in the context of GANs. A simple paper with: idea, motivation, experiments\n\nIdea:\nIt proposes a block called AdaConvBlock that replaces a regular Convolution with two steps:\nstep 1: regress convolution weights per pixel location conditioned on the input\nstep 2: do the convolution using these regressed weights\nSince local convolutions are generally expensive ops, it provides a few modifications to the size and shape of convolutions to make it efficient (like using depthwise)\n\nMotivation:\n- AdaConvBlock gives more local context per kernel weight, so that it can generate locally flexible objects / pixels in images\n\nMotivation is hand-wavy, the claim would need good experiments.\n\nExperiments:\n- Experiments are very limited, only overfit to inception score.\n- The experiments are not constructed to support the motivation / claim, but just to show that model performance improves.\n\nInception score experiments as the only experiments of a paper are woefully inadequate. The inception score is computed using a pre-trained imagenet model. It is not hard to overfit to.\nThe experiments need to support the motivation / claim better.\nIdeally the experiments need to show:\n- inception score improvements\n- actual samples showing that this local context helped produced better local regions / shapes\n- some kind of human evaluation supporting claims\n\nThe paper's novelty is also quite limited."", 'This manuscript proposes the use of ""adaptive convolutions"", previously proposed elsewhere, in GAN generators. The authors motivate this combination as allowing for better modeling of finer structure, conditioning the filter used for upsampling on the local neighbourhood beforehand.\n\nWhile Inception scores were the only proposed metric available for a time, other metrics have now been introduced in the literature (AIS log likelihood bounds, MS-SSIM, FID) and reporting Inception scores (with all of their problems) falls short for this reviewer. Because this is just the combination of two existing ideas, a more detailed analysis is warranted. Not only is the quantitative analysis lacking but also absent is any qualitative analysis of what exactly these adaptive convolutions are learning, whether this additional modeling power is well used, etc.', 'The paper operates under the hypothesis that the rigidity of the convolution operator is responsible in part for the poor performance of GANs on diverse visual datasets. The authors propose to replace convolutions in the generator with an Adaptive Convolution Block, which learns to generate the convolution weights and biases of the upsampling operation adaptively for each pixel location. State-of-the-art Inception scores are presented for the CIFAR-10 and STL-10 datasets.\n\nI think the idea of leveraging adaptive convolutions in decoder-based models is compelling, especially given its success in video frame interpolation, which makes me wonder why the authors chose to restrict themselves to GANs. Wouldn\'t the arguments used to justify replacing regular convolutions in the generator with adaptive convolution blocks apply equally well to any other decoder-based generative model, like a VAE, for instance?\n\nI find the paper lacking on the evaluation front. The evaluation of GANs is still very much an open research problem, which means that making a compelling case for the effectiveness of a proposed method requires nuance and contextualization. The authors claim a state-of-the-art Inception score but fail to explain what argument this claim supports. This is important, because the Inception score is not a universal measure of GAN performance: it provides a specific view on the ability of a generator to cover human-defined modes in the data distribution, but it does not inform on intra-class mode coverage and is blind to things like the generator collapsing on one or a few template samples per class.\n\nI am also surprised that the relationship with HyperNetworks [1] is not outlined, given that both papers leverage the idea of factoring network parameters through a second neural network.\n\nSome additional comments:\n\n- Figure 1 should be placed much earlier in the paper, preferably above Section 3. In its current state, the paper provides a lot of mathematical notation to digest without any visual support.\n- ""[...] a transposed convolution is equivalent to a convolution [...]"": This is inaccurate. A convolution\'s backward pass is a transposed convolution and vice versa, but they are not equivalent (especially when non-unit strides are involved).\n- ""The difficulties of training GANs is well known"": There is a grammatical error in this sentence.\n- ""If [the discriminator] is too strong, log(1 - D(G(z))) will be close to zero and there would be almost no gradient [...]"": This is only true for the minimax GAN objective, which is almost never used in practice. The non-saturating GAN objective does not exhibit this issue, as [2] re-iterated recently.\n- ""Several works have been done [...]"": There is a grammatical error here.\n- The WGAN-GP citation is wrong (Danihelka et al. rather than Gulrajani et al.).\n\nOverall, the paper\'s lack of sufficient convincing empirical support prevents me from recommending its acceptance.\n\nReferences:\n\n[1] Ha, D., Dai, A., and Le, Q. V. (2016). HyperNetworks. arXiv:1609.09106.\n[2] Fedus, W., Rosca, M., Lakshminarayanan, B., Dai, A. M., Mohamed, S., and Goodfellow, I. (2017). Many Paths to Equilibrium: GANs Do Not Need to Decrease a Divergence At Every Step. arXiv:1710.08446.']","[-50, -50, -50]","[0, 0, 50]","[""The sentiment score is -50 because the review is generally critical of the paper, pointing out significant limitations in the experiments and novelty. However, it's not entirely negative as it acknowledges the basic idea and structure of the paper. The politeness score is 0 (neutral) because the reviewer uses direct, matter-of-fact language without being overtly polite or rude. They state their criticisms plainly without using harsh language, but also without softening their critique with polite phrases. The reasoning for these scores is based on the reviewer's comments about 'limited' and 'woefully inadequate' experiments, 'hand-wavy' motivation, and 'limited' novelty, balanced against the neutral tone and straightforward presentation of the review."", ""The sentiment score is -50 because the reviewer expresses significant criticism and dissatisfaction with the manuscript. They point out several shortcomings, such as the use of outdated metrics and lack of detailed analysis. However, it's not entirely negative as they acknowledge the proposed idea and its potential motivation. The politeness score is 0 (neutral) because the reviewer maintains a professional tone without being overtly polite or rude. They present their criticisms directly but without using harsh language. The review focuses on the content and methodology rather than personal attacks, maintaining a neutral, academic tone throughout."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'compelling' idea), they ultimately do not recommend acceptance due to lack of sufficient empirical support. The review points out several shortcomings and areas for improvement, indicating a generally negative sentiment. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, offering constructive criticism and suggestions. They use phrases like 'I think,' 'I find,' and 'I am surprised,' which soften the critique. The reviewer also provides specific recommendations and references, showing engagement with the paper's content. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral-to-positive tone in its language use.""]"
"['In this paper, new layer architectures of neural networks using a low-rank representation of tensors are proposed. The main idea is assuming Tucker-type low-rank assumption for both a weight and an input. The performance is evaluated with toy data and Imagenet.\n\n[Clarity]\nThe paper is well written and easy to follow.\n\n[Originality]\nI mainly concern about the originality. Applying low-rank tensor decomposition in a network architecture has a lot of past studies and I feel this paper fails to clarify what is really distinguished from the other studies. For example, I found at least two papers [1,2] that are relevant. ([2] appears at the reference but it is not referred to.) How is the proposed method different from them?\n\nAlso, the ""end-to-end"" feature is repeatedly emphasized in the paper, but I don\'t understand its benefit. \n\n[1] Tai, Cheng, et al. ""Convolutional neural networks with low-rank regularization."" arXiv preprint arXiv:1511.06067 (2015).\n[2] Lebedev, Vadim, et al. ""Speeding-up convolutional neural networks using fine-tuned cp-decomposition."" arXiv preprint arXiv:1412.6553 (2014).\n\n[Significance]\nIn the experiments, the proposed method is compared with the vanilla model (i.e., the model having no low-rank structure) but with no other baseline using different compression techniques such as Novikov et al., 2015. So I cannot judge whether this method is better in terms of compression-accuracy tradeoff.\n\n\nPros:\n- The proposed model (layer architecture) is simple and easy to implement\n\nCons:\n- The novelty is low\n- No competitive baseline in experiments\n', 'This paper incorporates tensor decomposition and tensor regression into CNN by replacing its flattening operations and fully-connected layers with a new tensor regression layer. \n\nPros:\n\nThe low-rank representation of tensors is able to reduce the model complexity in the original CNN without sacrificing much prediction accuracy. This is promising as it enables the implementation of complex deep learning algorithms on mobile devices due to its huge space saving performance.  Overall, this paper is easy to follow. \n\nCons: \n\nQ1: Can the authors discuss the computational time of the proposed tensor regression layers and compare it to that of the baseline CNN? The tensor regression layer is computationally more expensive than the flattening operations in original CNN. Usually, it also involves expensive model selection procedure to choose the tuning parameters (N+1 ranks and a L2 norm sparsity parameter). In the experiments, the authors simply tried a few ranks without serious tuning. \n\nQ2: The authors reported the space saving in Table 1 but not in Table 2. Since spacing saving is a major contribution of the proposed method, can authors add the space saving percentage in Table 2?\n\nQ3: There are a few typos in the current paper. I would suggest the authors to take a careful proofreading. For example,\n\n(1) In the “Related work“ paragraph on page 2, “Lebedev et al. (2014) proposes…” should be “Lebedev et al. (2014) propose…”. Many other references have the same issue. \n\n(2) In Figure 1, the letter $X$ should be $\\tilde{\\cal X}$.\n\n(3) In expression (5) on page 3, the core tensor is denoted by $\\tilde{\\cal G}$. Is this the same as $\\tilde{\\cal X}^{‘}$ in Figure 1?\n\n(4) In expression (5) on page 3, the core tensor $\\tilde{\\cal G}$ is of dimension $(D_0, R_1, \\ldots, R_N)$. However, in expression (8) on page 5, $\\tilde{\\cal G}$ is of dimension $(R_0, R_1, \\ldots, R_N, R_{N+1})$.\n\n(5) Use \\cite{} and \\citep{} correctly. For example, in the “Related work“ paragraph on page 2,\n\n“Several prior papers address the power of tensor regression to preserve natural multi-modal structure and learn compact predictive models Guo et al. (2012); Rabusseau & Kadri (2016); Zhou et al. (2013); Yu & Liu (2016).”\n\nshould be\n\n“Several prior papers address the power of tensor regression to preserve natural multi-modal structure and learn compact predictive models (Guo et al., 2012; Rabusseau & Kadri, 2016; Zhou et al., 2013; Yu & Liu, 2016).”\n\n\n\n\n\n\n\n\n', 'This paper combines the tensor contraction method and the tensor regression method and applies them to CNN. This paper is well written and easy to read. \n\nHowever, I cannot find a strong or unique contribution from this paper. Both of the methods (tensor contraction and tensor decomposition) are well developed in the existing studies, and combining these ideas does not seem non-trivial.\n\n--Main question\n\nWhy authors focus on the combination of the methods? Both of the two methods can perform independently. Is there a special synergy effect?\n\n--Minor question\n\nThe performance of the tensor contraction method depends on a size of tensors. Is there any effective way to determine the size of tensors?']","[-30, 50, -20]","[50, 80, 60]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('well written and easy to follow', 'simple and easy to implement'), they express significant concerns about originality and lack of competitive baselines. The overall tone leans negative, but not extremely so. The politeness score is 50 because the reviewer uses respectful language throughout, framing criticisms as concerns rather than direct attacks, and acknowledges positive aspects. They use phrases like 'I mainly concern' and 'I feel' which soften the critique. However, the review doesn't go out of its way to be overly polite, maintaining a professional tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as reducing model complexity and enabling implementation on mobile devices, while also pointing out areas for improvement. The review starts with pros before moving to cons, indicating a balanced but generally favorable view. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as questions or suggestions rather than direct criticisms. Phrases like 'Can the authors discuss...' and 'I would suggest...' demonstrate a courteous tone. The reviewer also provides specific, constructive feedback, including detailed examples of typos to be corrected, which is helpful and considerate."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and easy to read, they express significant doubts about the paper's contribution. The reviewer states that they 'cannot find a strong or unique contribution' and questions the novelty of combining existing methods. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, starts with a positive comment, and frames criticisms as questions rather than direct statements. The reviewer also uses phrases like 'However' to soften criticism and 'Is there' to invite explanation rather than making accusatory statements.""]"
"['- The paper is fairly written and it is clear what is being done\n- There is not much novelty in the paper; it combines known techniques and is a systems paper, so I \n  would judge the contributions mainly in terms of the empirical results and messsage conveyed (see\n  third point)\n- The paper builds on a  previous paper (ICCV Workshops, https://arxiv.org/pdf/1707.06923.pdf),\n  however, there is non-trivial overlap between the two papers, e.g. Fig. 1 seems to be almost the\n  same figure from that paper, Sec 2.1 from the previous paper is largely copied     \n- The message from the empirical validation is also not novel, in the ICCVW paper it was shown that\n  the combination of different modalities etc. using a multiple kernel learning framework improved\n  results (73.3 on HMDB51), while in the current paper the same message comes across with another\n  kind of (known) method for combining different classifiers and modality (without iDT their best\n  results are 73.6 for CNN+GP-PoE) ', 'Summary: the paper considers an architecture combining neural networks and Gaussian processes to classify actions in a video stream for *one* dataset. The neural network part employs inception networks and residual networks. Upon pretraining these networks on RGB and optical flow data, the features at the final layer are used as inputs to a GP classifier. To sidestep the intractability, a model using a product of independent GP experts is used, each expert using a small subset of data and the Laplace approximation for inference and learning.\n\nAs it stands, I think the contributions of this paper is limited:\n\n* the paper considers a very specific architecture for a specific task (classifying actions in video streams) and a specific dataset (the HMDB-51 dataset). There is no new theoretical development.\n\n* the elements of the neural network architecture are not new/novel and, as cited in the paper, they have been used for action classification in Wang et al (2016), Ma et al (2017) and Sengupta and Qian (2017). I could not tell if there is any novelty on this part of the paper and it seems that the only difference between this paper and Sengupta and Qian (2017) is that Sengupta and Qian used SVM with multi-kernel learning and this paper uses GPs.\n\n* the paper considers a product of independent GP experts on the neural net features. It seems that combining predictions provided by the GPs helps. It is, however, not clear from the paper how the original dataset was divided into subsets.\n\n* it seems that the paper was written in a rush and many extensions and comparisons are only discussed briefly and left as future work, for example: using the Bayesian committee machine or modern sparse GP approximation techniques, end-to-end training and training with fewer training points.', 'This paper, although titled ""Distributed Non-Parametric Deep and Wide Networks"", is mostly about fusion of existing models for action recognition on the HMDB51 dataset. The fusion is performed with Gaussian Processes, where each of the i=1,..,4 inspected models (TSN-Inception RGB, TSN-Inception Flow, ResNet-LSTM RGB, ResNet-LSTM Flow) returns a (\\mu_i, \\sigma_i), which are then combined in a product of experts formulation, optimized w.r.t. maximum likelihood.\n\nAt its current form this paper is unfit for submission. First, the novelty of the paper is not clear. It is stated that a framework is introduced for independent deep neural networks. However, this framework, the Gaussian Processes, already exists. Also, it is stated that the method can classify video snippets that have heterogeneity regarding camera angle, video quality, pose, etc. This is something characterizes also all other methods that report similar results on the same dataset. The third claim is that deep networks are combined with non-parameteric Bayesian models. That is a good claim, which is also shared between papers at http://bayesiandeeplearning.org/. The last claim is that model averaging taking into account uncertainty is shown to be useful. That is not true, the only result are the final accuracies per GP model, there is no experiment that directly reports any results regarding uncertainty and its contribution to the final accuracy.\n\nSecond, it is not clear that the proposed method is the one responsible for the reported improvements in the experiments. Currently, the training set is split into 7 sets, and each set is used to train 4 models, totalling 28 GP experts. It is unclear what new is learned by the 7 GP expert models for the 7 splits. Why is this better than training a single model on the whole dataset? Also, why is difference bigger between ResNet Fusion-1 and Resnet SVM-SingleKernel?\n\nThird, the method reports results only on a single dataset, HMDB51, which is also rather small. Deriving conclusions from results on a single dataset is suboptimal. Other datasets that can be considered are (mini) Kinetics or Charades.\n\nForth,  the paper does not have the structure of a scientific publication. It rather looks like an unofficial technical report. There is no related work. The methodology section reads more like a tutorial of existing methods. And the discussion section is larger than any other section in the paper.\n\nAll in all, there might be some interesting ideas in the paper, specifically how to integrate GPs with deep nets. However, at the current stage the submission is not ready for publication.']","[-30, -60, -80]","[20, 20, 20]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges that the paper is 'fairly written' and 'clear', they also point out several significant issues: lack of novelty, overlap with a previous paper, and results that are not substantially better than prior work. The politeness score is slightly positive (20) as the reviewer uses neutral language and avoids harsh criticism, starting with a positive comment and presenting critiques in a factual manner. However, the review lacks overtly polite language or praise, keeping it closer to neutral than strongly polite."", ""The sentiment score is -60 because the reviewer expresses a largely negative view of the paper, stating that its contributions are 'limited' and pointing out several shortcomings. They mention a lack of novelty, specificity to one dataset, and rushed writing. However, it's not entirely negative as they acknowledge some positive aspects, like the combination of predictions helping. The politeness score is 20 because while the reviewer is critical, they maintain a professional and objective tone. They use phrases like 'I think' and 'it seems' to soften their criticisms, and they provide specific reasons for their assessment rather than making blanket negative statements. The language is not overtly polite, but it avoids rudeness and maintains a respectful academic tone."", ""The sentiment score is -80 because the review is predominantly negative. The reviewer states that the paper is 'unfit for submission' and lists several major issues, including lack of novelty, unclear methodology, limited dataset, and poor structure. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone and use phrases like 'there might be some interesting ideas' and 'at its current form' which soften the criticism slightly. The reviewer also provides specific suggestions for improvement, which is constructive. However, the overall tone is still quite critical, hence the relatively low positive score for politeness.""]"
"['The paper addresses the scenario when using a pretrained deep network as learnt feature representation for another (small) task where retraining is not an option or not desired. In this situation it proposes to use all layers of the network to extract feature from, instead of only one layer. \nThen it proposes to standardize different dimensions of the features based on their response on the original task. Finally, it discretize each dimension into {-1, 0, 1} to compress the final concatenated feature representation. \nDoing this, it shows improvements over using a single layer for 9 target image classification datasets including object, scene, texture, material, and animals.\n\nThe reviewer does not find the paper suitable for publication at ICLR due to the following reasons:\n- The paper is incremental with limited novelty.\n- the results are not encouraging\n- the pipeline of standardization, discretization is relatively costly, the final feature vector still large. \n- combining different layers, as the only contribution of the paper, has been done in the literature before,  for instance:\n“The Treasure beneath Convolutional Layers: Cross-convolutional-layer Pooling\nfor Image Classification” CVPR 2016\n', 'Paper claims to propose a deep transfer learning method. There are several reasons not to consider this paper for ICLR at this point.\n\nPaper is badly written and the problem it tries to solve is not clearly stated.\nProposed feature embedding is incremental (lack of novelty and technical contribution)\nObtained results are encouraging but not good enough.\nLack of experimental validation.\nI think paper can be improved significantly and is not ready for publication at this point.\n\n', ""This paper proposes an out-of-the-box embedding for image classification task. Instead of taking one single layer output from pre-trained network as the feature vector for new dataset, the method first extracts the activations from all the layers, then runs spatial average pooling on all convolutional layers, then normalizes the feature and uses two predefined thresholds to discretize the features to {-1, 0, 1}. Final prediction is learned through a SVM model using those embeddings. Experimental results on nine different datasets show that this embedding outperforms baseline of using one single layer. I think in general this paper lacks novelty and it shouldn't be surprising that activations from all layers should be more representative than one single layer representation. Moreover, in Table 4, it shows that discretization actually hurts the performance. It is also very heuristic to choose the two thresholds.  \n\n""]","[-70, -80, -50]","[20, -20, 0]","[""The sentiment score is -70 because the reviewer explicitly states that the paper is not suitable for publication and lists several critical reasons, including limited novelty, unencouraging results, and the main contribution already existing in literature. This indicates a strongly negative sentiment towards the paper. However, it's not at the extreme negative end as the reviewer does acknowledge the paper's approach and improvements in some areas. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone without using harsh or rude language. They present their points objectively, starting with a neutral summary of the paper's content before moving to their critique. The language is more neutral than overtly polite, but there's a slight lean towards politeness in the way the criticism is framed."", ""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer lists several major issues with the paper and concludes that it is not ready for publication. The only slightly positive note is that the results are 'encouraging,' but this is immediately followed by 'but not good enough.' The politeness score is -20 because while the language is not overtly rude, it is quite blunt and direct in its criticism. The reviewer does not use any softening language or offer much constructive feedback, instead listing the paper's shortcomings in a matter-of-fact manner. The phrase 'badly written' is particularly harsh. However, the reviewer does not use any explicitly insulting language, which prevents the score from being lower."", ""The sentiment score is -50 because the reviewer expresses skepticism about the paper's novelty and effectiveness. They state that the paper 'lacks novelty' and that the results 'shouldn't be surprising.' The reviewer also points out that discretization 'actually hurts the performance' and that the method is 'very heuristic.' These criticisms indicate a negative sentiment, though not extremely harsh. The politeness score is 0 (neutral) because the reviewer maintains a professional tone without using overtly polite or rude language. They present their criticisms directly but without personal attacks or overly harsh wording. The review focuses on the content of the paper rather than the authors themselves, which is appropriate for a peer review.""]"
"[""This paper investigates the complexity of neural networks with piecewise linear activations by studying the number of linear regions of the representable functions. It builds on previous works Montufar et al. (2014) and Raghu et al. (2017) and presents improved bounds on the maximum number of linear regions. It also evaluates the number of regions of small networks during training. \n\nThe improved upper bound given in Theorem 1 appeared in SampTA 2017 - Mathematics of deep learning ``Notes on the number of linear regions of deep neural networks'' by Montufar. \n\nThe improved lower bound given in Theorem 6 is very modest but neat. Theorem 5 follows easily from this. \n\nThe improved upper bound for maxout networks follows a similar intuition but appears to be novel. \n\nThe paper also discusses the exact computation of the number of linear regions in small trained networks. It presents experiments during training and with varying network sizes. These give an interesting picture, consistent with the theoretical bounds, and showing the behaviour during training. \n\nHere it would be interesting to run more experiments to see how the number of regions might relate to the quality of the trained hypotheses. \n\n\n\n"", ""Paper Summary:\n\nThis paper looks at providing better bounds for the number of linear regions in the function represented by a deep neural network. It first recaps some of the setting: if a neural network has a piecewise linear activation function (e.g. relu, maxout), the final function computed by the network (before softmax) is also piecewise linear and divides up the input into polyhedral regions which are all different linear functions. These regions also have a correspondence with Activation Patterns, the active/inactive pattern of neurons over the entire network. Previous work [1], [2], has derived lower and upper bounds for the number of linear regions that a particular neural network architecture can have. This paper improves on the upper bound given by [2] and the lower bound given by [1]. They also provide a tight bound for the one dimensional input case. Finally, for small networks, they formulate finding linear regions as solving a linear program, and use this method to compute the number of linear regions on small networks during training on MNIST\n\nMain Comments:\nThe paper is very well written and clearly states and explains the contributions. However, the new bounds proposed (Theorem 1, Theorem 6), seem like small improvements over the previously proposed bounds, with no other novel interpretations or insights into deep architectures. (The improvement on Zaslavsky's theorem is interesting.) The idea of counting the number of regions exactly by solving a linear program is interesting, but is not going to scale well, and as a result the experiments are on extremely small networks (width 8), which only achieve 90% accuracy on MNIST. It is therefore hard to be entirely convinced by the empirical conclusions that more linear regions is better. I would like to see the technique of counting linear regions used even approximately for larger networks, where even though the results are an approximation, the takeaways might be more insightful.\n\nOverall, while the paper is well written and makes some interesting points, it presently isn't a significant enough contribution to warrant acceptance.\n\n[1] On the number of linear regions of Deep Neural Networks, 2014, Montufar, Pascanu, Cho, Bengio\n[2] On the expressive power of deep neural networks, 2017, Raghu, Poole, Kleinberg, Ganguli, Sohl-Dickstein"", 'This is quite an interesting paper. Thank you. Here are a few comments:\n\nI think this style of writing theoretical papers is pretty good, where the main text aims of preserving a coherent story while the technicalities of the proofs are sent to the appendix. \nHowever I would have appreciated a little bit more details about the proofs in the main text (maybe more details about the construct that is involved). I can appreciate though that this a fine line to walk. Also in the appendix, please restate the lemma that is being proven. Otherwise one will have to scroll up and down all the time to understand the proof. \n\nI think the paper could also discuss a bit more in detail the results provided. For example a discussion of how practical is the algorithm proposed for exact counting of linear regions would be nice. Though regardless, I think the findings speak for themselves and this seems an important step forward in understanding neural nets. \n\n****************\nI had reduced my score based on the observation made by Reviewer 1 regarding the talk Montufar at SampTA. Could the authors prioritize clarification to that point ! \n - Thanks for the clarification and adding this citation. ']","[60, -50, 60]","[50, 50, 80]","[""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's contributions, describing the improved bounds as 'neat' and the experiments as 'interesting'. The reviewer also suggests areas for further research, indicating engagement with the work. However, it's not overwhelmingly positive, as the reviewer notes that some improvements are 'modest' and that one result appeared in previous work. The politeness score is 50 (slightly polite) because the language is professional and respectful throughout. The reviewer offers constructive feedback and suggestions without using harsh or critical language. The tone is neutral to mildly positive, avoiding overly effusive praise or sharp criticism, which is appropriate for a scientific peer review."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('The paper is very well written', 'makes some interesting points'), the overall sentiment is negative. The reviewer concludes that the paper 'isn't a significant enough contribution to warrant acceptance', indicating a negative recommendation. The politeness score is 50 because the reviewer uses polite and professional language throughout, offering constructive criticism and acknowledging positive aspects before presenting negative points. The reviewer avoids harsh or rude language, instead using phrases like 'it is hard to be entirely convinced' and 'I would like to see', which maintain a respectful tone while expressing concerns."", ""The sentiment score is 60 (positive) because the reviewer starts by calling the paper 'quite interesting' and mentions that the findings 'speak for themselves' and are 'an important step forward'. They also appreciate the writing style. However, they do suggest some improvements, which prevents a higher score. The politeness score is 80 (very polite) due to the use of phrases like 'Thank you', 'I would have appreciated', and 'please'. The reviewer offers constructive criticism in a respectful manner, acknowledging the challenges ('this is a fine line to walk') and using softening language ('I think', 'maybe'). The reviewer also shows flexibility by adjusting their score based on new information, which demonstrates respect for the authors' clarifications.""]"
"['This paper proposes a new reading comprehension model for multi-choice questions and the main motivation is that some options should be eliminated first to infer better passage/question representations.\n\nIt is a well-written paper, however, I am not very convinced by its motivation, the proposed model and the experimental results. \n\nFirst of all, the improvement is rather limited. It is only 0.4 improvement overall on the RACE dataset; although it outperforms GAR on 7 out of 13 categories; but why is it worse on the other 6 categories? I don’t see any convincing explanations here.\n\nSecondly, in terms of the development of reading comprehension models, I don’t see why we need to care about eliminating the irrelevant options. It is hard to generalize to any other RC/QA tasks. If the point is that the options can add useful information to induce better representations for passage/question, there should be some simple baselines in the middle that this paper should compare to. The two baselines SAR and GAR both only induce a representation from paragraph/question, and finally compare to the representation of each option. Maybe a simple baseline is to merge the question and all the options and see if a better document representation can be defined. \n\nSome visualizations/motivational examples could be also useful to understand how some options are eliminated and how the document representation has been changed based on that.\n', 'This paper gives an elaboration on the Gated Attention Reader (GAR) adding gates based on answer elimination in multiple choice reading comprehension.  I found the formal presentation of the model reasonably clear the the empirical evaluation reasonably compelling.\n\nIn my opinion the main weakness of the paper is the focus on the RACE dataset.  This dataset has not attracted much attention and most work in reading comprehension has now moved to the SQUAD dataset for which there is an active leader board.  I realize that SQUAD is not explicitly multiple choice and that this is a challenge for an answer elimination architecture.  However, it seems that answer elimination might be applied to each choice of the initial position of a possible answer span.  In any case, competing with an active leader board would be much more compelling.', 'In this paper, a model is built for reading comprehension with multiple choices. The model consists of three modules: encoder, interaction module and elimination module. The major contributions are two folds: firstly, proposing the interesting option elimination problem for multi-step reading comprehension;  and secondly, proposing the elimination module where a eliminate gate is used to select different orthogonal factors from the document representations. Intuitively, one answer option can be viewed as eliminated if the document representation vector has its factor along the option vector ignored.\n\nThe elimination module is interesting, but the usefulness of “elimination” is not well justified for two reasons. First, the improvement of the proposed model over the previous state of the art is limited. Second, the model is built upon GAR until the elimination module, then according to Table 1 it seems to indicate that the elimination module does not help significantly (0.4% improvement). \n\nIn order to show the usefulness of the elimination module, the model should be exactly built on the GAR with an additional elimination module (i.e. after removing the elimination module, the performance should be similar to GAR but not something significantly worse with a 42.58% accuracy). Then we can explicitly compare the performance between GAR and the GAR w/ elimination module to tell how much the new module helps.\n\nOther issues:\n\n1) Is there any difference to directly use $x$ and $h^z$ instead of $x^e$ and $x^r$ to compute $\\tilde{x}_i$? Even though the authors find the orthogonal vectors, they’re gated summed together very soon. It would be better to show how much “elimination” and “subtraction” effect the final performance, besides the effect of subtraction gate.\n\n2) A figure showing the model architecture and the corresponding QA process will better help the readers understand the proposed model.\n\n3) $c_i$ in page 5 is not defined. What’s the performance of only using $s_i$ for answer selection or replacing $x^L$ with $s_i$ in score function?\n\n4) It would be better to have the experiments trained with different $n$ to show how multi-hop effects the final performance, besides the case study in Figure 3.\n\nMinor issues:\n\n1) In Eqn. (4), it would be better to use a vector as the input of softmax.\n\n2) It would be easier for discussion if the authors could assign numbers to every equation.']","[-50, 20, -20]","[50, 50, 60]","[""The sentiment score is -50 because while the reviewer acknowledges the paper is well-written, they express significant doubts about the motivation, proposed model, and experimental results. The reviewer points out limited improvements and questions the generalizability of the approach. However, it's not entirely negative as they suggest potential improvements. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positive aspects ('well-written paper') and framing criticisms as personal opinions ('I am not very convinced') rather than harsh statements. They also offer constructive suggestions for improvement, which is a polite approach to criticism."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's clear presentation and compelling empirical evaluation. However, they also point out a significant weakness, which prevents a higher positive score. The politeness score is moderately positive (50) as the reviewer uses respectful language and phrases criticisms constructively, such as 'In my opinion' and 'it seems that'. They also balance positive and negative feedback. The reviewer doesn't use overly formal or particularly warm language, which is why the score isn't higher."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting aspects of the paper, they express significant concerns about the justification and effectiveness of the proposed method. The reviewer points out that the improvement over the state of the art is limited and that the elimination module doesn't seem to help significantly. They also suggest several areas for improvement and clarification.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They begin by acknowledging the paper's contributions and use phrases like 'it would be better' and 'it would be easier' when making suggestions. The reviewer also provides specific recommendations for improvement rather than just criticizing, which is a polite approach to peer review. However, the score is not extremely high as the review is direct in its critique and doesn't use overtly polite language or praise excessively.""]"
"['The authors introduce an approach for adding learning to search capability to Monte Carlo tree search. The proposed method incorporates simulation-based search inside a neural network by expanding, evaluating and backing-up a vector-embedding. The key is to represent the internal state of the search by a memory vector at each node. The computation of the network proceeds just like a simulation of MCTS, but using a simulation policy based on the memory vector to initialize the memory vector at the leaf. The proposed method allows each component of MCTS to be rich and learnable, and allows the joint training of the evaluation network, backup network, and simulation policy in optimizing the MCTS network. The paper is thorough and well-explained. My only complaint is the evaluation is only done on one domain, Sokoban. More evaluations on diverse domains are called for.  ', 'This paper proposes a framework for learning to search, MCTSNet. The paper proposes an idea to integrate simulation-based planning into a neural network. By this integration, solving planning problems can be end-to-end training. The idea is to represent all operators such as backup, action selection and node initialisation by neural networks. The authors propose to train this using policy gradient in which data of optimal state-action pairs is generated by a standard MCTS with a large number of simulations.\n\nIn overall, it is a nice idea to use DNN to represent all update operators in MCTS. However the paper writing has many unclear points. In my point of view, the efficiency of the proposed framework is also questionable.\n\n\nHere, I have many major concerns about the proposed idea.\n\n- It looks like after training MCTSnet with a massive amount of data from another MCTS, MTCSnet algorithm as in Algorithm 2 will not do very much more planning yet. More simulations (M increases) will not make the statistics in 4(a) improved. Is it the reason why in experiments M is always small and increasing it does not make a huge improvement?. This is different from standard planning when a backup is handled with more simulations, the Q value function will have better statistics, and then get smaller regrets (see 4(b) in Algorithm 1). This supervising step is similar to one previous work [1] and not mentioned in the paper.\n\n\n- MCTSnet has not dealt well with large/continuous state spaces. Each generated $s$ will amount to one tree node, with its own statistics. If M is large, the tree maintained is huge too. It might be not correct, then I am curious how this technical aspect is handled by MCTSnet.\n\n- Other questions:\n\n + how the value network used in the MCTS in section 3.5 is constructed?\n\n + what does p(a|s,{\\mathbf z}), p({\\mathbf s}|{\\mathbf z}) mean?\n\n + is R_1 similar to R^1\n\n + is z_m in section 3.5 and z^m in section 3.6 different?\n\n + is the action distribution from the root memory p_{\\theta}(a|s)? \n\n- Other related work: \n\n\n[1] Xiaoxiao Guo et. al. Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning, NIPS 2014\n\n[2] Guez et. al. Bayes-Adaptive Simulation-based Search with Value Function Approximation, NIPS 2014\n', ""This paper designs a deep learning architecture that mimics the structure of the well-known MCTS algorithm. From gold standard state-action pairs, it learns each component of this architecture in order to predict similar actions.\n\nI enjoyed reading this paper. The presentation is very clear, the design of the architecture is beautiful, and I was especially impressed with the related work discussion that went back to identify other game search and RL work that attempts to learn parts of the search algorithm. Nice job overall.\n\nThe main flaw of the paper is in its experiments. If I understand them correctly, the comparison is between a neural network that has been learned on 250,000 trajectories of 60 steps each where each step is decided by a ground truth close-to-optimal algorithm, say MCTS with 1000 rollouts (is this mentioned in the paper). That makes for a staggering 15 billion rollouts of prior data that goes into the MCTSNet model. This is compared to 25 rollouts of MCTS that make the decision for the baseline. I suspect that generating the training data and learning the model takes an enormous amount of CPU time, while 25 MCTS rollouts can probably be done in a second or two. I'm sure I'm misinterpreting some detail here, but how is this a fair comparison?\n\nWould it be fair to have a baseline that learns the MCTS coefficient on the training data? Or one that uses the value function that was learned with classic search? I find it difficult to understand the details of the experimental setup, and maybe some of these experiments are reported. Please clarify. Also: colors are not distinguishable in grey print.\n\nHow would the technique scale with more MCTS iterations? I suspect that the O(N^2) complexity is very prohibitive and will not allow this to scale up?\n\nI'm a bit worried about the idea of learning to trade off exploration and exploitation. In the end you'll just allow for the minimal amount of exploration to solve the games you've already seen. This seems risky, and I suspect that UCB and more statistically principled approaches would be more robust in this regard?\n\nAre these Sokoban puzzles easy for classical AI techniques? I know that many of them can be solved by A* search with a decent heuristic. It would be fair to discuss this.\n\nThe last sentence of conclusions is too far reaching; there is really no evidence for that claim.""]","[60, -30, 50]","[70, 20, 80]","[""The sentiment score is 60 (positive) because the reviewer generally praises the paper, calling it 'thorough and well-explained' and highlighting the novelty and potential of the proposed method. However, it's not a perfect score due to the criticism about limited evaluation. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the authors' work positively. The criticism is phrased as a 'complaint' rather than a harsh critique, and the suggestion for improvement is presented as a call for more evaluations rather than a demand. The overall tone is professional and constructive."", ""The sentiment score is -30 because while the reviewer acknowledges the paper's 'nice idea', they express 'many major concerns' and describe the paper writing as having 'many unclear points'. They also question the efficiency of the proposed framework. This indicates a generally negative sentiment, though not extremely so. The politeness score is 20 because the reviewer uses polite language such as 'In my point of view' and frames criticisms as questions or concerns rather than direct attacks. They also begin with a positive comment about the 'nice idea'. However, the overall tone is professional rather than overtly polite, hence the moderate positive score."", ""The sentiment score is 50 (moderately positive) because the reviewer starts with positive comments, praising the paper's clarity, design, and related work discussion. However, they also point out significant flaws in the experiments and raise several concerns, balancing the overall sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms as questions or suggestions rather than direct attacks. They use phrases like 'I enjoyed reading this paper,' 'Nice job overall,' and 'Please clarify,' which contribute to a polite tone. Even when pointing out flaws, the reviewer maintains a constructive approach, suggesting improvements and asking for clarification rather than being dismissive.""]"
"['Summary: \n\nThe authors consider the use of attention for sensor, or channel, selection. The idea is tested on several speech recognition datasets, including TIDIGITS and CHiME3, where the attention is over audio channels, and GRID, where the attention is over video channels. Results on TIDIGITS and GRID show a clear benefit of attention (called STAN here) over concatenation of features. The results on CHiME3 show gain over the CHiME3 baseline in channel-corrupted data.\n\nReview:\n\nThe paper reads well, but as a standard application of attention lacks novelty. The authors mention that related work is generalized but fail to differentiate their work relative to even the cited references (Kim & Lane, 2016; Hori et al., 2017). Furthermore, while their approach is sold as a general sensor fusion technique, most of their experimentation is on microphone arrays with attention directly over magnitude-based input features, which cannot utilize the most important feature for signal separation using microphone arrays---signal phase. Their results on CHiME3 are terrible: the baseline CHiME3 system is very weak, and their system is only slightly better! The winning system has a WER of only 5.8%(vs. 33.4% for the baseline system), while more than half of the submissions to the challenge were able to cut the WER of the baseline system in half or better! http://spandh.dcs.shef.ac.uk/chime_challenge/chime2015/results.html. Their results wrt channel corruption on CHiME3, on the other hand, are reasonable, because the model matches the problem being addressed…\n\nOverall Assessment: \n\nIn summary, the paper lacks novelty wrt technique, and as an “application-of-attention” paper fails to be even close to competitive with the state-of-the-art approaches on the problems being addressed. As such, I recommend that the paper be rejected.\n\n\nAdditional comments: \n\n-\tThe experiments in general lack sufficient detail: Were the attention masks trained supervised or unsupervised? Were the baselines with concatenated features optimized independently? Why is there no multi-channel baseline for the GRID results? \n-\tIssue with noise bursts plot (Input 1+2 attention does not sum to 1)\n-\tA concatenation based model can handle a variable #inputs: it just needs to be trained/normalized properly during test (i.e. like dropout)…\n', 'This paper proposes sensor transformation attention network (STAN), which dynamically select appropriate sequential sensor inputs based on an attention mechanism. \n\nPros:\nOne of the main focuses of this paper is to apply this method to a real task, multichannel speech recognition based on CHiME-3, by providing its reasonable sensor selection function in real data especially to avoid audio data corruptions. This analysis is quite intuitive, and also shows the effectiveness of the proposed method in this practical setup. \n\nCons:\nThe idea seems to be simple and does not have significant originality. Also, the paper does not clearly mention the attention mechanism part, and needs some improvement. \n\nComments:\n-\tThe paper mainly focuses on the soft sensor selection. However, in an array signal processing context (and its application to multichannel speech recognition), it would be better to mention beamforming techniques, where the compensation of the delays of sensors is quite important.\n-\tIn addition, there is a related study of using multichannel speech recognition based on sequence-to-sequence modeling and attention mechanism by Ochiai et al, ""A Unified Architecture for Multichannel End-to-End Speech Recognition with Neural Beamforming,"" IEEE Journal of Selected Topics in Signal Processing. This paper uses the same CHiME-3 database, and also showing a similar analysis of channel selection. It’s better to discuss about this paper as well as a reference.\n-\tSection 2: better to explain about how to obtain attention scores z in more details.\n-\tFigure 3, experiments of Double audio/video clean conditions: I cannot understand why they are improved from single audio/video clean conditions. Need some explanations.\n-\tSection 3.1: 39-dimensional Mel-frequency cepstral coefficients (MFCCs) -> 13 -dimensional Mel-frequency cepstral coefficients (MFCCs) with 1st and 2nd order delta features.\n-\tSection 3.2 Dataset “As for TIDIGIT”: “As for GRID”(?)\n-\tSection 4 Models “The parameters of the attention modules are either shared across sensors (STAN-shared) or not shared across sensors (STAN- default).”: It’s better to explain this part in more details, possibly with some equations. It is hard to understand the difference.\n\n', 'The manuscript introduces the sensor transformation attention networks, a generic neural architecture able to learn the attention that must be payed to different input channels (sensors) depending on the relative quality of each sensor with respect to the others. Speech recognition experiments on synthetic noise on audio and video, as well as real data are shown.\n\nFirst of all, I was surprised on the short length of the discussion on the state-of-the-art. Attention models are well known and methods to merge information from multiple sensors also (very easily, Multiple Kernel Learning, but many others).\n\nSecond, from a purely methodological point of view, STANs boil down to learn the optimal linear combination of the input sensors. There is nothing wrong about this, but perhaps other more complex (non-linear) models to combine data could lead to more robust learning.\n\nThird, the experiments with synthetic noise are significant to a reduced extend. Indeed, adding Gaussian noise to a replicated input is too artificial to be meaningful. The network is basically learning to discard the sensor when the local standard deviation is high. But this is not the kind of noise found in many applications, and this is clearly shown in the performances on real data (not always improving w.r.t state of the art). The interesting part of these experiments is that the noise is not stationary, and this is quite characteristic of real-world applications. Also, to be fair when discussion the results, the authors should say that simple concatenation outperforms the single sensor paradigm.\n\nI am also surprised about the baseline choice. The authors propose a way to merge/discard sensors, and there is no comparison with other ways of doing it (apart from the trivial sensor concatenation). It is difficult to understand the benefit of this technique if no other baseline is benchmarked. This mitigates the impact of the manuscript.\n\nI am not sure that the discussion in page corresponds to the actual number on Table 3, I did not understand what the authors wrote.']","[-80, -20, -40]","[-20, 60, 20]","[""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer states that the paper 'lacks novelty', fails to differentiate from existing work, and produces 'terrible' results on one dataset. The reviewer explicitly recommends rejection. The politeness score is -20 because while the language is not overtly rude, it is quite blunt and critical. Phrases like 'lacks novelty', 'terrible', and 'fails to be even close to competitive' are harsh criticisms delivered without much softening. However, the reviewer does acknowledge some positives ('The paper reads well') and provides specific feedback, which prevents the score from being lower."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the paper, they also point out significant cons and areas for improvement. The reviewer states that the idea 'seems to be simple and does not have significant originality' and that the paper 'needs some improvement', which contributes to the negative sentiment. However, the presence of positive comments about the paper's practical application balances this somewhat, preventing a more negative score. The politeness score is moderately positive (60) because the reviewer uses professional and respectful language throughout. They provide constructive criticism and suggestions for improvement without using harsh or dismissive language. The use of phrases like 'it would be better to' and 'it's better to' when making suggestions contributes to the polite tone. The reviewer also balances criticism with positive observations, which is a polite approach to peer review."", ""The sentiment score is -40 because the review is generally critical, pointing out several shortcomings of the manuscript. The reviewer expresses surprise at the short literature review, questions the methodological approach, criticizes the experimental design, and notes the lack of comparison with relevant baselines. However, it's not entirely negative as the reviewer acknowledges some interesting aspects of the work. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I was surprised' and 'I am not sure' rather than more confrontational language. The reviewer also acknowledges positive aspects, such as the non-stationary noise being characteristic of real-world applications. The language is direct but not rude, maintaining a balance between criticism and constructive feedback.""]"
"[""The author proposed:\n1. A data augmentation technique for asynchronous time series data.\n2. A convolutional 'Significance' weighting neural network that assigns normalised weights to the outputs of a fully-connected autoregressive 'Offset' neural network, such that the output is a weighted average of the 'Offset' neural net.\n3. An 'auxiliary' loss function.\n\nThe experiments showed that:\n1. The proposed method beat VAR/CNN/ResNet/LSTM 2 synthetic asynchronous data sets, 1 real electricity meter data set and 1 real financial bid/ask data set. It's not immediately clear how hyper-parameters for the benchmark models were chosen.\n2. The author observed from the experiments that the depth of the offset network has negligible effect, and concluded that the 'Significance' network has crucial impact. (I don't see how this conclusion can be made.)\n3. The proposed auxiliary loss is not useful.\n4. The proposed architecture is more robust to noise in the synthetic data set compared to the benchmarks, and together with LSTM, are least prone to overfitting.\n\nPros\n- Proposed a useful way of augmenting asynchronous multivariate time series for fitting autoregressive models\n- The convolutional Significance/weighting networks appears to reduce test errors (not entirely clear)\n\nCons\n- The novelties aren't very well-justified. The 'Significance' network was described as critical to the performance, but there is no experimental result to show the sensitivity of the model's performance with respect to the architecture of the 'Significance' network. At the very least, I'd like to see what happens if the weighting was forced to be uniform while keeping the 'Offset' network and loss unchanged.\n- It's entirely unclear how the train and test data was split. This may be quite important in the case of the financial data set.\n- It's also unclear if model training was done on a rolling basis, which is common for time series forecasting.\n- The auxiliary loss function does not appear to be very helpful, but was described as a key component in the paper.\n\nQuality: The quality of the paper was okay. More details of the experiments should be included in the main text to help interpret the significance of the experimental results. The experiment also did not really probe the significance of the 'Significance' network even though it's claimed to be important.\nClarity: Above average. \nOriginality: Mediocre. Nothing really shines. Weighted average-type architecture has been proposed many times in neural networks (e.g., attention mechanisms). \nSignificance: Low. It's unclear how useful the architecture really is."", 'To begin with, the authors seem to be missing some recent developments in the field of deep learning which are closely related to the proposed approach; e.g.:\n\nSotirios P. Chatzis, “Recurrent Latent Variable Conditional Heteroscedasticity,” Proc. 42nd IEEE International Conference on Acoustics, Speech and Signal Processing (IEEE ICASSP), pp. 2711-2715, March 2017.\n\nIn addition, the authors claim that Gaussian process-based models are not appropriate for handling asynchronous data, since the assumed Gaussianity is inappropriate for financial datasets, which often follow fat-tailed distributions. However, they seem to be unaware of several developments in the field, where mixtures of Gaussian processes are postulated, so as to allow for capturing long tails in the data distribution; for instance:\n\nEmmanouil A. Platanios and Sotirios P. Chatzis, “Gaussian Process-Mixture Conditional Heteroscedasticity,” IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 36, no. 5, pp. 888-900, May 2014.\n\nHence, the provided experimental comparisons are essentially performed against non-rivals of the method. It is more than easy to understand that a method not designed for modeling observations with the specific characteristics of financial data should definitely perform worse than a method designed to cope with such artifacts. That is why the sole purpose of a (convincing) experimental evaluation regime should be to compare between methods that are designed with the same data properties in mind. The paper does not satisfy this requirement.\n\nTurning to the method itself, the derivations are clear and straightforward; the method could have been motivated a somewhat better, though.', 'The authors propose an extension to CNN using an autoregressive weighting for asynchronous time series applications.  The method is applied to a proprietary dataset as well as a couple UCI problems and a synthetic dataset, showing improved performance over baselines in the asynchronous setting.\n\nThis paper is mostly an applications paper.  The method itself seems like a fairly simple extension for a particular application, although perhaps the authors have not clearly highlighted details of methodological innovation.  I liked that the method was motivated to solve a real problem, and that it does seem to do so well compared to reasonable baselines.  However, as an an applications paper, the bread of experiments are a little bit lacking -- with only that one potentially interesting dataset, which happens to proprietary.  Given the fairly empirical nature of the paper in general, it feels like a strong argument should be made, which includes experiments, that this work will be generally significant and impactful.  \n\nThe writing of the paper is a bit loose with comments like:\n“Besides these and claims of secretive hedge funds (it can be marketing surfing on the deep learning hype), no promising results or innovative architectures were publicly published so far, to the best of our knowledge.”\n\nParts of the also appear rush written, with some sentences half finished:\n“""ues of x might be heterogenous, hence On the other hand, significance network provides data-dependent weights for all regressors and sums them up in autoregressive manner.””\n\nAs a minor comment, the statement\n“however, due to assumed Gaussianity they are inappropriate for financial datasets, which often follow fat-tailed distributions (Cont, 2001).”\nIs a bit too broad.  It depends where the Gaussianity appears.  If the likelihood is non-Gaussian, then it often doesn’t matter if there are latent Gaussian variables.\n']","[-30, -60, -20]","[50, -20, 20]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('Pros'), there are more substantial criticisms ('Cons') and overall low ratings for originality and significance. The reviewer's tone is somewhat skeptical, particularly about the justification of novelties and the importance of certain components. The politeness score is 50 because the reviewer maintains a professional and objective tone throughout, offering balanced feedback with both pros and cons. They use neutral language and avoid harsh criticisms, instead framing issues as areas for improvement or clarification. The reviewer also acknowledges the positive aspects of the paper, which contributes to the polite tone."", ""The sentiment score is -60 because the reviewer points out several significant shortcomings in the paper, including missing recent developments, inappropriate comparisons, and inadequate experimental evaluation. The tone is generally critical, though not entirely negative. The politeness score is -20 because while the language is not overtly rude, it lacks warmth and contains some dismissive phrases like 'It is more than easy to understand' and 'The paper does not satisfy this requirement.' The reviewer provides constructive criticism by suggesting relevant literature, but the overall tone is somewhat stern and lacks positive reinforcement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('I liked that the method was motivated to solve a real problem'), they also point out several limitations and criticisms. The reviewer mentions that the paper is 'mostly an applications paper' with a 'fairly simple extension', and that the experiments are 'a little bit lacking'. They also note issues with the writing quality.\n\nThe politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout and uses some polite language ('I liked that...'), while also providing constructive criticism. They avoid harsh or rude language, instead using more neutral phrases like 'a bit loose' or 'appear rush written' when pointing out issues. The reviewer also offers a 'minor comment' at the end, which is a polite way to address a less significant concern.""]"
"[""This paper proposes a new convolutional network architecture, which is tested on three image classification tasks.\n\nPros:\nThe network is very clean and easy to implement, and the results are OK.\n\nCons:\nThe idea is rather incremental compared to FractalNet. The results seem to be worse than existing networks, e.g., DenseNet (Note that SVHN is no longer a good benchmark dataset for evaluating state-of-the-art CNNs). Not much insights were given.\n\nOne additional question: Skip connections have been shown to be very useful in ConvNets. Why not adopt it in CrescendoNet? What's the point of designing a network without skip connections?\n"", 'In this paper, the authors propose  a new network architecture, CrescendoNet, which is a simple stack of building blocks without residual connections. To reduce the memory required for training, the authors also propose a path-wise training procedure based on the independent convolution paths of CrescendoNet. The experimental results on CIFAR-10, CIFAR-100 and SVHN show that CrescendoNet outperforms most of the networks without residual connections.\n \nContributions:\n\n1 The authors proposed Crescendo block that consists of convolution paths with increasing depth. \n\n3 The authors conducted experiments on three benchmark datasets and show promising performance of CrescendoNet .\n\n3 The authors proposed a path-wise training procedure to reduce memory requirement in training.\n\nNegative points:\n\n1 The motivation of the paper is not clear. It is well known that the residual connections are important in training deep CNNs and have shown remarkable performance on many tasks. The authors propose the CrescendoNet which is without residual connections. However, the experiments show that CrescendoNet is worse than ResNet. \n\n2  The contribution of this paper is not clear. In fact, the performance of CrescendoNet is worse than most of the variants of residual networks, e.g., Wide ResNet, DenseNet, and ResNet with pre-activation. Besides, it seems that the proposed path-wise training procedure also leads to significant performance degradation.\n\n3 The novelty of this paper is insufficient. The CrescendoNet is like a variant of the FractalNet, and the only difference is that the number of convolutional layers in Crescendo blocks grows linearly.\n\n4 The experimental settings are unfair. The authors run 700 epochs and even 1400 epochs with path-wise training on CIFAR, while the baselines only have 160~400 epochs for training.\n\n5 The authors should provide the experimental results on large-scale data sets (e.g. ImageNet) to prove the effectiveness of the proposed method, as they only conduct experiments on small data sets, including CIFAR-10, CIFAR-100, and SVHN.\n\n\n6 The model size of CrescendoNet is larger than residual networks with similar performance.\n\n\nMinor issues:\n\n1In line 2, section 3.4, the period after “(128, 256, 512)” should be removed.\n', 'The paper presents a new CNN architecture: CrescendoNet. It does not have skip connections yet performs quite well.\n\nOverall, I think the contributions of this paper are too marginal for acceptance in a top tier conference.\n\nThe architecture is competitive on SVHN and CIFAR 10 but not on CIFAR 100. The performance is not strong enough to warrant acceptance by itself.\n\nFractalNets amd DiracNets (https://arxiv.org/pdf/1706.00388.pdf) have demonstrated that it is possible to train deep networks without skip connections and achieve high performance. While CrescendoNet seems to slightly outperform FractalNet in the experiments conducted, it is itself outperformed by DiracNet. Hence, CrescendoNet does not have the best performance among skip connection free networks.\n\nYou claim that FractalNet shows no ensemble behavior. This is clearly not true because FractalNet has ensembling directly built in, i.e. different paths in the network are explicitly averaged. If averaging paths leads to ensembling in CrescendoNet, it leads to ensembling in FractalNet. While the longest path in FractalNet is stronger than the other members of the ensemble, it is nevertheless an ensemble. Besides, as Veit showed, ResNet also shows ensemble behavior. Hence, using ensembling in deep networks is not a significant contribution.\n\nThe authors claim that ""Through our analysis and experiments, we note that the implicit ensemble behavior of CrescendoNet leads to high performance"". I don\'t think the experiments show that ensemble behavior leads to high performance. Just because a network performs averaging of different paths and individual paths perform worse than sets of paths doesn\'t imply that ensembling as a mechanism is in fact the cause of the performance of the entire architecture. Similary, you say ""On the other hand, the ensemble model can explain the performance improvement easily."" Veit et al only claimed that ensembling is a feature of ResNet, but they did not claim that this was the cause of the performance of ResNet.\n\nPath-wise training is not original enough or indeed different enough from drop-path to count as a major contribution.\n\nYou claim that the number of layers ""increase exponentially"" in FractalNet. This is misleading. The number of layers increases exponentially in the number of paths, but not in the depth of the network. In fact, the number of layers is linear in the depth of the network. Since depth is the meaningful quantity here, CrescendoNet does not have an advantage over FractalNet in terms of layer number. Also, it is always possible to simply add more paths to FractalNet if desired without increasing depth. Instead of using 1 long paths, one can simply use 2, 3, 4 etc. While this is not explicitly mentioned in the FractalNet paper, it clearly would not break the design principle of FractalNet which is to train a path of multiple layers by ensembling it with a path of fewer layers. CrescendoNets do not extend beyond this design principle.\n\nYou say that ""First, path-wise training procedure significantly reduces the memory requirements for convolutional layers, which constitutes the major memory cost for training CNNs. For example, the higher bound of the memory required can be reduced to about 40% for a Crescendo block with 4 paths where interval = 1."" This is misleading, as you need to store the weights of all convolutional layers to compute the forward pass and the majority of the weights of all convolutional layers to compute the backward pass, no matter how many weights you intend to update. In a response to a question I posed, you mentioned that we you meant was ""we use about 40% memory for the gradient computation and storage"". Fair enough, but ""gradient computation and storage"" is not mentioned in the paper. Also, the reduction to 40% does not apply e.g. to vanilla SGD because the computed gradient can be immediately added to the weights and does not need to be stored or combined with e.g. a stored momentum term.\n\nFinally, nowhere in the paper do you mention which nonlinearities you used or if you used any at all. In future revisions, this should be rectified.\n\nWhile I can definitely imagine that your network architecture is well-designed and a good choice for image classification tasks, there is a very saturated market of papers proposing various architectures for CIFAR-10 and related datasets. To be accepted to ICLR, either outstanding performance or truly novel design principles are required.']","[-30, -60, -70]","[20, 20, 20]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some pros ('The network is very clean and easy to implement, and the results are OK'), they also point out significant cons. The reviewer criticizes the paper for being incremental, having worse results than existing networks, and lacking insights. The additional question also implies skepticism about the design choices. The politeness score is slightly positive (20) because the reviewer uses neutral language and frames criticisms as observations rather than attacks. They also balance negative points with positive ones and pose a question for consideration rather than outright dismissing the approach."", ""The sentiment score is -60 because the review is predominantly negative. While it acknowledges some contributions, the majority of the review focuses on negative points, including unclear motivation, insufficient novelty, and unfair experimental settings. The reviewer also points out that the proposed method performs worse than existing methods. The politeness score is 20 because the language used is professional and objective, without personal attacks or harsh language. The reviewer presents criticisms in a matter-of-fact manner, using phrases like 'It is well known that...' and 'The authors should provide...'. However, the overall tone is more critical than overtly polite, hence the relatively low positive score."", ""The sentiment score is -70 because the reviewer clearly states the paper's contributions are 'too marginal for acceptance' and provides several critiques of the work's novelty and significance. They point out areas where the paper falls short or makes misleading claims. However, it's not entirely negative as they do acknowledge some positive aspects. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'I think' and 'I don't think' to soften some statements, and provide detailed explanations for their critiques rather than dismissive comments. The language is not overtly polite, but it avoids rudeness and maintains a respectful, constructive tone typical of academic peer reviews.""]"
"['The authors present confidence-based autodidactic returns, a Deep learning RL method to adjust the weights of an eligibility vector in TD(lambda)-like value estimation to favour more stable estimates of the state. The key to being able to learn these confidence values is to not allow the error of the confidence estimates propagate back though the deep learning architecture.\n\nHowever, the method by which these confidence estimates are refined could be better described. The authors describe these confidences variously as: ""some notion of confidence that the agent has in the value function estimate"" and ""weighing the returns based on a notion of confidence has been explored earlier (White & White, 2016; Thomas et al., 2015)"". But the exact method is difficult to piece together from what is written. I believe that the confidence estimates are considered to be part of the critic and the w vector to be part of the theta_c parameters. This would then be captured by the critic gradient for the CAR method that appears towards the end of page 5. If so, this should be stated explicitly.\n\nThere is another theoretical point that could be clearer. The variation in an autodidactic update of a value function (Equation (4)) depends on a few things, the in variation future value function estimates themselves being just one factor. Another two sources of variation are: the uncertainty over how likely each path is to be taken, and the uncertainty in immediate rewards accumulated as part of some n-step return. In my opinion, the quality of the paper would be much improved by a brief discussion of this, and some reflection on what aspects of these variation contribute to the confidence vectors and what isn\'t captured.\n\nNonetheless, I believe that the paper represents an interesting and worthy submission to the conference. I would strongly urge the authors to improve the method description in the camera read version though. A few additional comments are as follows:\n\n  • The plot in Figure 3 is the leading collection of results to demonstrate the dominance of the authors\' adaptive weight approach (CAR) over the A3C (TD(0) estimates) and LRA3C (truncated TD(lambda) estimates) approaches. However, the way the results are presented/plotted, namely the linear plot of the (shifted) relative performance of CAR (and LRA3C) versus A3C, visually inflates the importance of tasks on which CAR (and LRA3C) perform better than A3C, and diminishes the importance of those tasks on which A3C performs better. It would be better kept as a relative value and plotted on a log-scale so that positive and negative improvements can be viewed on an equal setting.\n  • On page 3, when Gt is first mentioned, Gt should really be described first, before the reader is told what it is often replaced with.\n  • On page 3, where delta_t is defined (the j step return TD error, I think the middle term should be $gamma^j V(S_{t+j})$\n  • On page 4 and 5, when describing the gradient for the actor and critic, it would be better if these were given their own terminology, but if not, then use of the word respectively in each case would help.', ""This paper revisits the idea of exponentially weighted lambda-returns at the heart of TD algorithms. The basic idea is that instead of geometrically weighting the n-step returns we should instead weight them according to the agent's own estimate of its confidence in it's learned value function. The paper empirically evaluates this idea on Atari games with deep non-linear state representations, compared to state-of-the-art baselines.\n\nThis paper is below the threshold because there are issues with the : 1) motivation, 2) the technical details, and (3) the empirical results.\n\nThe paper begins by stating that the exponential weighting of lambda returns is ad-hoc and unjustified. I would say the idea is well justified in several ways. First the lambda return definition lends itself to online approximations that achieve a fully incremental online form with linear computation and nearly as good performance of the off-line version. Second, decades of empirical results illustrating good performance of TD compared with MC methods. And an extensive literature of theoretical results. The paper claims that the exponential has been noted to be ad-hoc, please provide a reference for this.\n\nThere have been several works that have noted that lambda can and perhaps should be changed as a function of state (Sutton and Barto, White and White [1], TD-Gammon). In fact, such works even not that lambda should be related to confidence. The paper should work harder to motivate why adapting lambda as a function of state---which has been studied---is not sufficient.\n\nI don't completely understand the objective. Returns with higher confidence should be weighted higher, according to the confidence estimate around the value function estimate as a function of state? With longer returns, n>>1, the role of the value function in the target is down-weighted by gamma^n---meaning its accuracy is of little relevance to the target. How does your formalism take this into account? The basic idea of the lambda return assumes TD targets are better than MC targets due to variance, which place more weight on shorter returns.\n\nI addition I don't understand how learning confidence of the value function has a realizable target. We do not get supervised targets of the confidence of our value estimates. What is your network updating toward?\n\nThe work of Konidaris et al [1] is a more appropriate reference for this work (rather than the Thomas reference provided). Your paper does not very clearly different itself from Konidaris's work here. Please expand on this.\n\nThe experiments have some issues. One issue is that basic baselines could more clearly illustrate what is going on. There are two such baselines: random fixed weightings of the n-step returns, and persisting with the usual weighting but changing lambda on each time step (either randomly or according to some decay schedule). The first baseline is a sanity check to ensure that you are not observing some random effect. The second checks to see if your alternative weighting is simply approximating the benefits of changing lambda with time or state.\n\nI would say the current results indicate the conventional approach to TD is working well if not better than the new one. Looking at fig 3, its clear the kangaroo is skewing the results, and that overall the new method is performing worse. This is further conflated by fig7 which attempts to illustrate the quality of the learned value functions. In Kangaroo, the domain where your method does best, the l2 error is worse. On the other hand in sea quest and space invaders, where your method does worse, the l2 error is better. These results seem conflicting, or at least raise more questions than they answer.\n\n[1] A Greedy Approach to Adapting the Trace Parameter for Temporal Difference Learning . Adam White and Martha White. Autonomous Agents and Multi-agent Systems (AAMAS), 2016\n[2] G. D. Konidaris, S. Niekum, and P. S. Thomas. TDγ: Re-evaluating complex backups in temporal difference learning. In Advances in Neural Information Processing Systems 24, pages 2402–2410. 2011. "", 'SUMMARY\nThe major contribution of the paper is a generalization of lambda-returns called Confidence-based Autodidactic Returns (CAR), wherein the RL agent learns the weighting of the n-step returns in an end-to-end manner.   These CARs are used in the A3C algorithm.  The weights are based on the confidence of the value function of the n-step return.  Even though this idea in not new the authors propose a simple and robust approach for doing it by using the value function estimation network of A3C.\n\nDuring experiments, the autodidactic returns perform better only half of the time as compared to lambda returns.\n\n\nCOMMENTS\nThe j-step returns TD error is not written correctly\n\nIn Figure 1 it is not obvious how the confidence of the values is estimated.\nFigure 1 is unreadable.\n\n\nA lighter version of Algorithm 1 in Appendix F should be moved in the text, since this is the novelty of the paper.\n']","[50, -70, -20]","[80, 20, 0]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'an interesting and worthy submission' and provides constructive feedback, while also pointing out areas for improvement. The overall tone is balanced, recognizing both strengths and weaknesses. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout. They use phrases like 'I believe,' 'I would strongly urge,' and 'the quality of the paper would be much improved,' which suggest recommendations rather than demands. The reviewer also acknowledges the paper's merits before diving into criticisms, maintaining a courteous tone. The specific recommendations are presented as bullet points, which is a clear and professional way to provide feedback without being confrontational."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper is 'below the threshold' and lists several major issues with the motivation, technical details, and empirical results. They challenge the paper's fundamental premise and point out conflicts in the experimental results. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I don't completely understand' and 'Please expand on this' rather than using harsh language. They also provide constructive feedback and suggestions for improvement, which adds to the politeness. However, the overall critical nature of the review prevents a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution and novelty, they point out that the proposed method only performs better half the time compared to existing methods. The review also highlights several issues with the paper, such as incorrect equations and unreadable figures. The politeness score is neutral (0) as the reviewer's language is neither particularly polite nor rude. They state their observations and criticisms directly without using overly harsh or overly courteous language. The review is straightforward and focuses on the technical aspects of the paper without personal comments or excessive praise or criticism.""]"
"['The approach involves multiple steps.\nOn a high level the query is first used to retrieve k best matching response candidates. Then a concatenation of the query and the candidates are fed into a generative model to generate an additional artificial candidate.\nIn a final step, the k+1 candidates are re-ranked to report the final response.\nEach of these steps involves careful engineering and for each there are some minor novel components.\nYet, not all of the steps are presented in complete technical detail.\nAlso, training corpora and human labeling of the test data do not seem to be publicly available.\nConsequently, it would be hard to exactly reproduce the results of the paper.\nExperimental validation also is relatively thin.\nWhile the paper report both BLEU metrics and Fleiss kappa from a small-scale human test, the results are based on a single split of a single corpus into training, validation and test data.\nWhile the results for the ensemble are reported to be higher than for the various components for almost all metrics, measures of spread/variance would allow the reader to better judge the degree and significance of improvement.\n\nMinor:\nThe paper should be read by a native speaker, as it involves a number of minor grammar issues and typos.\n', ""The authors present a generation-based neural dialog response model that takes a list of retrieved responses from a search engine as input. This novel multi-seq2seq approach, which includes attention and a pointer network, increases reply diversity compared to purely retrieval or generation-based models. The authors also apply a reranking-based approach to ensembling based on a gradient-boosted decision tree classifier.\nBut their multi-seq2seq model is not particularly well-justified with evaluations and examples (as compared with the reranking/ensemble, which is essentially a standard approach) and it's unclear whether it helps more than other recent approaches to response diversity.\n\nSome additional points:\n1. For several of the GBDT features, the approach chosen is unusual or perhaps outdated. In particular, the choice of a word-level MT-based metric rather than an utterance-level one, and the choice of a bigram-based fluency metric rather than one based on a more complete language model are puzzling and should be justified.\n2. The authors report primarily comparisons to ablations of their own model, not to other recent work in dialog systems.\n3. The human evaluation performance of a simple reranking ensemble between the authors' generation-based model and their retrieval-based model is significantly higher than multi-seq2seq, suggesting that multi-seq2seq may not be an especially powerful way to combine information from the two models.\n4. The authors present only very limited examples (in Table 4) and one out of the two multi-seq2seq examples in that table is relatively nonsensical. When the original examples are non-English, papers should also include the original in addition to a translation."", 'Summary:\n\nThe paper proposes a new dialog model combining both retrieval-based and generation-based modules. Answers are produced in three phases: a retrieval-based model extracts candidate answers; a generator model, conditioned on retrieved answers, produces an additional candidate; a reranker outputs the best among all candidates.\n\nThe approach is interesting: the proposed ensemble can improve on both the retrieval module and the generation module, since it does not restrict modeling power (e.g. the generator is not forced to be consistent with the candidates). I am not aware of similar approaches for this task. One work that comes to mind regarding the blend of retrieval and generation is Memory Networks (e.g. https://arxiv.org/pdf/1606.03126.pdf and references): given a query, a set of relevant memories is extracted from a KB using an inverted index and the memories are fed into the generator. However, the extracted items in the current work are candidate answers which are used both to feed the generator and to participate in reranking.\n\nThe experimental section focuses on the task of building conversational systems. The performance measures used are 1) a human evaluation score with three volunteers and 2) BLUE scores. While these methods are not very satisfying, effective evaluation of such systems is a known difficulty. \n\nThe results show that the ensemble outperforms the individual modules, indicating that: the multi-seq2seq models have learned to use the new inputs as needed and that the ranker is correlated with the evaluation metrics.\n\nHowever, the results themselves do not look impressive to me: the subjective evaluation is close to the ""borderline"" score; in the examples provided, one is good, the other is borderline/bad, and the baseline always provides something very short. Does the LSTM work particularly poor on this dataset? Given that this is a novel dataset, I don\'t know what the state-of-the-art should be. Could you provide more insight? Have you considered adding a benchmark dataset (e.g. a QA dataset)?\n\nSpecific questions:\n\n1. The paper motivates conditioning on the candidates in two ways. First, that the candidates bring additional information which the decoder can use (e.g. read from the candidates locations, actions, etc.). Second, that the probability of universal replies must decrease due to the additional condition. I think the second argument depends on how the conditioning is performed: if the candidates are simply appended to the input, the model can learn to ignore them.\n2. The copy mechanism is a nice touch, encouraging the decoder to use the provided queries. Why not copy from the query too, e.g. with some answers reusing part of the query <""Where are you going?"", ""I\'m going to the park"">?\n3. How often does the model select the generated answer vs. the extracted answers? In both examples provided the selected answer is the one merging the candidate answers.\n\nMinor issues:\n- Section 3.2: using and the state\n- Section 3.2: more than one replies\n- last sentence on page 3: what are the ""following principles""?']","[-20, -30, 50]","[50, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's approach and some novel components, they also point out several limitations. These include incomplete technical details, lack of publicly available data, thin experimental validation, and the need for measures of spread/variance. The reviewer also mentions grammar issues and typos. However, the tone is not entirely negative, as they recognize the careful engineering and novel components in each step.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to describe the paper's approach and limitations, avoiding harsh criticism. The use of phrases like 'careful engineering' and 'minor novel components' shows a level of appreciation for the work. Even when pointing out weaknesses, the reviewer does so in a constructive manner, suggesting improvements rather than simply criticizing. The final comment about grammar is presented as a 'Minor' point, further demonstrating a polite approach to feedback."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the work (e.g., 'novel multi-seq2seq approach', 'increases reply diversity'), they express several significant criticisms and doubts about the effectiveness and justification of the proposed model. The overall tone is more critical than positive. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh or personal criticisms. They present their concerns as 'points' and use phrases like 'should be justified' rather than more confrontational language. However, the review is not overly deferential or complimentary, maintaining a neutral, professional tone."", 'The sentiment score is 50 (slightly positive) because the reviewer finds the approach interesting and novel, acknowledging its potential to improve on both retrieval and generation modules. However, they also express some concerns about the results not being particularly impressive and request more insight. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the difficulties in evaluating such systems. They offer constructive feedback and specific questions to improve the paper, maintaining a professional and courteous tone throughout the review.']"
"['Summary: \nThe paper considers the prediction problem where labels are given as multisets. The authors give a definition of a loss function for multisets and show experimental results. The results show that the proposed methods optimizing the loss function perform better than other alternatives.\n\nComments: \nThe problem of predicting multisets looks challenging and interesting. The experimental results look nice. On the other hand, I have several concerns about writing and technical discussions. \n\nFirst of all, the goal of the problem is not exactly stated. After I read the experimental section, I realized that the goal is to optimize the exact match score (EM) or F1 measure w.r.t. the ground truth multisets. This goal should be explicitly stated in the paper. Now then, the approach of the paper is to design surrogate loss functions to optimize these criteria. \n\nThe technical discussions for defining the proposed loss function seems not reliable for the reasons below. Therefore, I do not understand the rationale of the definition of the proposed loss function.:  \n- An exact definition of the term multiset is not given. If I understand it correctly, a multiset is a “set” of instances allowing duplicated ones. \n- There is no definition of Prec or Rec (which look like Precision and Recall) in Remark 1. The definitions appear in Appendix, which might not be well-defined. For example, let y, Y be mutisets , y=[a, a, a] and Y = [a, b]. Then, by definition, Prec(y,Y)=3/3 =1. Is this what you meant? (Maybe, the ill-definedness  comes from the lack of definition of inclusion in a mutiset.) \n- I cannot follow the proof of Remark 1 since it does not seem to take account of the randomness by the distribution \\pi^*. \n- I do not understand the definition of the oracle policy exactly. It seems to me that, the oracle policy knows the correct label (multi-set) \\calY for each instance x and use it to construct \\calY_t. But, this implicit assumption is not explicitly mentioned. \n- In (1), (2) and Definition 3, what defines \\calY_t? If \\calY_t is determined by some “optimal” oracle, you cannot define the loss function in Def. 3 since it is not known a priori. Or, if the learner determines \\calY_t, I don’t understand why the oracle policy is optimal since it depends on the learner’s choices. \n\nAlso, I expect an investigation of theoretical properties of the proposed loss function, e.g., relationship to EM or F1 or other loss functions. Without understanding the theoretical properties and the rationale, I cannot judge the goodness of the experimental results (look good though). In other words, I cannot judge the paper in a qualitative perspective, not in a quantitative view. \n\nAs a summary, I think the technical contribution of the paper is marginal because of the lack of reliable mathematical discussion or investigation.\n', 'This paper proposes a type of loss functions for the problem of multiset prediction. A detailed discussion on the intuition is provided and extensive experiments are conducted to show that this loss function indeed provides some performance gain in terms of Exact Matching and F1-score.\n\nThe idea of this paper is as follows: instead of viewing the multiset prediction task as a classification problem, this paper models it as a sequential decision problem (this idea is not new, see Welleck et al., 2017, as pointed out by the authors).  Define pi* to be the optimal policy that outputs the labels of input x in a certain way. We learn a parameterized policy pi(theta) which takes x and all previous predictions as input, and outputs a label as a new prediction. At each time step t, pi* and pi(theta) can be viewed as distributions over all remaining labels; the KL divergence is then used to calculate the difference between those two distributions. Finally, the loss function sums those KL divergences over all t. Computing this loss function directly can be intractable, so the author suggested that one can compute the entire trajectory of predictions and then do aggregation.\n\nAdmitted that such construction is quite intuitive, and can possibly be useful, the technical part of this paper seems to be rather straightforward. In particular, I think the solution to the issue of unknown T is very heuristic, making the proposed loss function less principled. \n\n\nOther Detailed Comments/Issues:\n\n-- It seems to me that models that can utilize this loss function must support varying-length inputs, e.g. LSTM. Any idea how to apply it to models with fixed-length inputs?\n\n-- The proposed loss function assumes that T (i.e. the size of the output set) is known, which is unrealistic. To handle this, the authors simply trained an extra binary classifier that takes x and all previous predictions as the input at each time step, and decides whether or not to terminate. I think this solution is rather hacky and I’d like to see a more elegant solution, e.g. incorporate the loss on T into the proposed loss function.\n\n-- Could you formally define “Exact Match”?\n\n-- In Section 4.4, maybe it is better to run the stochastic sampling multiple times to reduce the variance? I would expect that the result can be quite different in different runs.\n\n-- Any discussion on how will the classifier for T affect the experimental results? \n', 'This is an interesting paper, in the sense of looking at a problem such as multiset prediction in the context of sequential decision making (using a policy).  \n\nIn more detail, the authors construct an oracle policy, shown to be optimal (in terms of precision and recall).  A parametrized policy instead of the oracle policy is utilized in the proposed multiset loss function, while furthermore, a termination policy facilitates the application on variable-sized multiset targets.  The authors also study other loss functions, ordered sequence prediction as well as reinforcement learning.\n\nResults show that the proposed order-invariant loss outperforms other losses, along with a set if experiments evaluating choice of rank function for sequence prediction and selection strategies.  The experiments seem rather comprehensive, as well as the theoretical analysis.   The paper describes an interesting approach to the problem.\n\nWhile the paper is comprehensive it could be improved in terms of clarity & flow (e.g., by better preparing the reader on what is to follow)']","[-50, -20, 70]","[20, 60, 50]","[""The sentiment score is -50 because while the reviewer acknowledges the problem as 'challenging and interesting' and the experimental results as 'nice', they express several significant concerns about the paper's writing and technical discussions. They state that the technical contribution is 'marginal' due to a 'lack of reliable mathematical discussion or investigation'. This indicates a predominantly negative sentiment, though not entirely dismissive.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I have several concerns' and 'I cannot follow' rather than using harsh or dismissive language. The reviewer also acknowledges positive aspects before presenting criticisms. However, the score is not higher as the review is primarily focused on critiquing the paper rather than offering extensive praise or encouragement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('detailed discussion', 'extensive experiments', 'performance gain'), they also express significant criticisms. The reviewer states that the technical part is 'rather straightforward' and the solution to a key issue is 'very heuristic' and 'less principled'. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and phrases criticisms as suggestions or questions rather than direct attacks. For example, they use phrases like 'I think', 'I'd like to see', and 'Could you' when offering critiques or asking for clarifications. This maintains a constructive and polite tone even while expressing concerns about the paper."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'interesting' multiple times, praises the comprehensive experiments and theoretical analysis, and notes that the results show the proposed method outperforms others. The slight reduction from a perfect score is due to the final suggestion for improvement. The politeness score is 50 (somewhat polite) because the reviewer uses neutral, professional language throughout and offers constructive feedback. They avoid harsh criticism and use phrases like 'could be improved' rather than direct negative statements. However, the review doesn't go out of its way to be exceptionally polite either, maintaining a fairly neutral, academic tone.""]"
"[""The collaborative block that authors propose is a generalized module that can be inserted in deep architectures for better multi-task learning. The problem is relevant as we are pushing deep networks to learn representation for multiple tasks. The proposed method while simple is novel. The few places where the paper needs improvement are:\n\n1. The authors should test their collaborative block on multiple tasks where the tasks are less related. Ex: Scene and object classification. The current datasets where the model is evaluated is limited to Faces which is a constrained setting. It would be great if Authors provide more experiments beyond Faces to test the universality of the proposed approach.\n2. The Face datasets are rather small. I wonder if the accuracy improvements hold on larger datasets and if authors can comment on any large scale experiments they have done using the proposed architecture. \n\nIn it's current form I would say the experiment section and large scale experiments are two places where the paper falls short.  "", 'Pros:\n1. This paper proposed a new block which can aggregate features from different tasks. By doing this, it can take advantage of common information between related tasks and improve the generalization of target tasks.\n\n2. The achievement in this paper seems good, which is 24.31%.\n\nCons:\n1. The novelty of this submission seems a little limited.\n\n2. The target task utilized in this paper is too simple, which only detects 5 facial landmarks. It is hard to say this proposed work can still work when facing more challenging tasks, for example, 60+ facial landmarks prediction.\n\n3. "" Also, one drawback of HyperFace is that the proposed feature fusion is specific to AlexNet,"" In the original submission, HyperFace is based on AlexNet, but does this mean it can only work on AlexNet?', '\n\nThis paper proposes a multi-pathway neural network for facial landmark detection with multitask learning. In particular, each pathway corresponds to one task, and the intermediate features are fused at multiple layers. The fused features are added to the task-specific pathway using a residual connection (the input of the residual connection are the concatenation of the task-specific features and the fuse features). The residual connection allows each pathway to selectively use the information from other pathways and focus on its own task.\n\nThis paper is well written. The proposed neural network architectures are reasonable. \n\nThe residual connection can help each pathway to focus on its own task (suggested by Figure 8). This phenomenon is not guaranteed by the training objective but happens automatically due to the architecture, which is interesting. \n\nThe proposed model outperforms several baseline models. On MTFL, when using the AlexNet, the improvement is significant; when using the ResNet18, the improvement is encouraging but not so significant. On AFLW (trained on MTFL), the improvements are significant in both cases. \n\nWhat is missing is the comparison with other methods (besides the baseline). For examples, it will be helpful to compare with existing non-multitask learning methods, like TCDCN (Zhang et al., 2014) (it seems to achieve 25% failure rate on AFLW, which is lower than the numbers in Figure 5), and  multi-task learning method, like MTCNN (Zhang et al., 2016). It is important to show that proposed multitask learning method is useful in practice. \nIn addition, many papers take the average error as the performance metric. Providing results in the average error can make the experiments more comprehensive.\n\nThe proposed architecture is a bit huge. It scales linearly with the number of tasks, which is not quite preferable. It is also not straightforward to add new tasks to finetune a trained model. \n\nIn Figure 5 (left), it is a bit weird that the pretrained model underperforms the nonpretrained one. \n\nI am likely to change the rating based on the comparison with other methods.\n\n\n']","[20, 20, 50]","[60, 50, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the relevance and novelty of the proposed method, describing it as 'simple' yet 'novel'. However, they also point out areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'It would be great if' and 'I wonder if' which maintain a polite tone while expressing their concerns. The reviewer also balances positive comments with areas for improvement, showing a considerate approach to their feedback."", ""The sentiment score is slightly positive (20) because the review starts with pros, acknowledging the paper's contributions and achievements. However, it also lists several cons, which balance out the positivity. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents both pros and cons without harsh criticism. They use phrases like 'seems good' and 'a little limited' which soften potential negative feedback. The reviewer also asks a question at the end, which comes across as constructive rather than critical."", ""The sentiment score is 50 (slightly positive) because the reviewer notes the paper is 'well written' and the proposed methods are 'reasonable', with 'significant' improvements in some cases. However, they also point out missing comparisons and some concerns, indicating a balanced but generally favorable view. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging strengths while constructively suggesting improvements. They avoid harsh criticism and use phrases like 'it will be helpful' when making recommendations. The tone is professional and courteous overall.""]"
"['This paper claims to present a ""general deep reinforcement learning"" method that addresses the issues of real-world robotics: data constraints, safety, and lack of state information, and exploration by using demonstrations. However, this paper actually addresses these problems by training in a simulator, and only transferring 2 of the 6 tasks to the real world. The real world results are  lackluster. However, the simulated results are nice.\n\nThe method in the paper is as follows: the environment reward is augmented by a reward function learned from human demonstrations using GAIL on full state (except for the arm). Then, an actor-critic method is used where the critic gets full state information, while the actor needs to learn from an image. However, the actor\'s convolutional layers are additionally trained to detect the object positions. \n\nStrengths:\n+ The simulated tasks are novel and difficult (sorting, clearing a table)\n+ Resetting to demonstration states is a nice way to provide curriculum\n\nLimitations:\n+ The results make me worries that the simulation environments have been hyper-tailored to the method, as the real environments looks very similar, and should transfer. \n+ Each part of the method is not particularly novel. Combining IRL and RL has been done before (as the authors point out in the related work), side-training perception module to predict full state has been done before (""End-to-end visuomotor learning""), diversity of training conditions has been done before (Domain randomization).\n+ Requiring hand-specified clusters of states for both selecting starting states and defining a reward functions requires domain knowledge. Why can\'t they be clustered using a clustering method?\n+ Because the method needs simulation to learn a policy, it is limited to tasks that can be simulated somewhat accurately (e.g. ones with simple dynamics). As shown by the poor transfer of the stacking task, block stacking with foam blocks is not a such task.\n\n\nQuestions:\n+ How many demonstrations do you use per task?\n+ What are the ""relative"" positions included in the ""object-centric"" state input? \n\nMisleading parts of the paper:\n+ The introduction of the paper primes the reader to expect a method that can work on a real system. However, this method only gets 64% accuracy on a simple block lifting task, 35% on a stacking task.\n+ ""Appendix C. ""We define functions on the underlying physical state to determine the stage of a state…The definition of stages also gives rise to a convenient way of specifying the reward functions without hand-engineering a shaping reward. ""-> You are literally hand engineering a shaping reward. The main text misleadingly refers to ""sparse reward"", which usually refers to a single reward upon task completion.\n\nIn conclusion, I find that the work lacks significance because the results are dependent on a list of hacks that are only possible in simulation.', 'Paper summary: The authors propose a number of tricks to enable training policies for pick and place style tasks using a combination of GAIL-based imitation learning and hand-specified rewards, as well as use of unobserved state information during training and hand-designed curricula. The results demonstrate manipulation policies for stacking blocks and moving objects, as well as preliminary results for zero-shot transfer from simulation to a real robot for a picking task and an attempt at a stacking task.\n\nReview summary: The paper proposes a limited but interesting contribution that will be especially of interest to practitioners, but the scope of the contribution is somewhat incremental in light of recent work, and the results, while interesting, could certainly be better. In the balance, I think the paper should be accepted, because it will be of value to practitioners, and I appreciate the detail and real-world experiments. However, some of the claims should be revised to better reflect what the paper actually accomplishes: the contribution is a bit limited in places, but that\'s *OK* -- the authors should just be up-front about it.\n\nPros:\n- Interesting tasks that combine imitation and reinforcement in a logical (but somewhat heuristic) way\n- Good simulated results on a variety of pick-and-place style problems\n- Some initial attempt at real-world transfer that seems promising, but limited\n- Related work is very detailed and I think many will find it to be a very valuable overview\nCons:\n- Some of the claims (detailed below) are a bit excessive in my opinion\n- The paper would be better if it was scoped more narrowly\n- Contribution is a bit incremental and somewhat heuristic\n- The experimental results are difficult to interpret in simulation\n- The real-world experimental results are not great\n- There are a couple of missing citations (but overall related work is great)\n\nDetailed discussion of potential issues and constructive feedback:\n\n> ""Our approach leverages demonstration data to assist a reinforcement learning agent in learning to solve a wide range of tasks, mainly previously unsolved.""\n>> This claim is a bit peculiar. Picking up and placing objects is certainly not ""unsolved,"" there are many examples. If you want image-based pick and place with demonstrations for example, see Chebotar \'17 (not cited). If you want stacking blocks, see Nair \'17. While it\'s true that there is a particular combination of factors that doesn\'t exactly appear in prior work, the statement the authors make is way too strong. Chebotar \'17 shows picking and placing a real-world objective with a much higher success rate than reported here, without simulation. Nair \'17 shows a much harder stacking task, but without images -- would that method have worked just as well with image-based distillation? Very likely. Rajeswaran \'17 shows tasks that arguably are much harder. Maybe a more honest statement is that this paper proposes some tasks that prior methods don\'t show, and some prior methods show tasks that the proposed method can\'t solve. But as-is, this statement misrepresents prior work.\n\n> Previous RL-based robot manipulation policies (Nair et al., 2017; Popov et al., 2017) largely rely on low-level states as input, or use severely limited action spaces that ignore the arm and instead learn Cartesian control of a simple gripper. This limits the ability of these methods to represent and solve more complex tasks (e.g., manipulating arbitrary 3D objects) and to deploy in real environments where the privileged state information is unavailable.\n>> This is a funny statement. Some use images, some don\'t. There is a ton of prior work on RL-based robot manipulation that does use images. The current paper does use object state information during training, which some prior works manage to avoid. The comments about Cartesian control are a bit peculiar... the proposed method controls fingers, but the hand is simple. Some prior works have simpler grippers (e.g., Nair) and some have much more complex hands (e.g., Rajeswaran). So this one falls somewhere in the middle. That\'s fine, but again, this statement overclaims a bit.\n\n> To sidestep the constraints of training on real hardware we embrace the sim2real paradigm which\nhas recently shown promising results (James et al., 2017; Rusu et al., 2016a).\n>> Probably should cite Sadeghi et al. and Tobin et al. in regard to randomization, both of which precede James \'17.\n\n> we can, during training, exploit privileged information about the true system state\n>> This was done also in Pinto et al. and many of the cited GPS papers\n\n> our policies solve the tasks that the state-of-the-art reinforcement and imitation learning cannot solve\n>> I don\'t think this statement is justified without much wider comparisons -- the authors don\'t attempt any comparisons to prior work, such as Chebotar \'17 (which arguably is closest in terms of demonstrated behaviors), Nair \'17 (which is also close but doesn\'t use images, though it likely could).\n\n> An alternative strategy for dealing with the data demand is to train in simulation and transfer\n>> Aside from previously mentioned citations, should probably cite Devin ""Towards Adapting Deep Visuomotor Representations""\n\n> Sec 3.2.1\n>> This method seems a bit heuristic. It\'s logical, but can you say anything about what this will converge to? GAIL will try to match the demonstration distribution, and RL will try to maximize expected reward. What will this method do?\n\n> Experiments\n>> Would it be possible to indicate some measure of success rate for the simulated experiments? As-is, it\'s hard to tell how well either the proposed method or the baselines actually work.\n\n> Transfer\n>> My reading of the transfer experiments is that they are basically unsuccessful. Picking up a rectangular object with 80% success rate is not very good. The stacking success rate is too low to be useful. I do appreciate the authors trying out their method on a real robotic platform, but perhaps the more honest assessment of the outcome of these experiments is that the approach didn\'t work very well, and more research is needed. Again, it\'s *OK* to say this! Part of the purpose of publishing a paper is to stimulate future research directions. I think the transfer experiments should definitely be kept, but the authors should discuss the limitations to help future work address them, and present the transfer appropriately in the intro.\n\n> Diverse Visuomotor Skills\n>> I think this is a peculiar thing to put in the title. Is the implication that prior work is not diverse? Arguably several prior papers show substantially more diverse skills. It seems that all the skills here are essentially pick and place skills, which is fine (these are interesting skills), but the title seems like a peculiar jab at prior work not being ""diverse"" enough, which is simply misleading.', 'Given that imitation learning is often used to initialize reinforcement learning, the authors should consider using a more descriptive title for this paper. \n\nThe main contribution of the paper is to use a mixture of the reinforcement learning reward and the imitation learning signal from GAIL. This approach is generally fairly straightforward, but seems to be effective in simulation, and boils down to equation 2. It would be interesting to discuss and evaluate the effects of changing lambda overtime. \n\nThe second contribution can be seen as a list of four techniques for getting the most out of using the simulation environment and the state information that it provides. A list of these types of techniques could be useful for students training networks on simulations, although each point on the list is fairly straightforward. This part also leads to an ablation study to determine the effects of the proposed techniques. The results plot should include error bars.\n\nThe earlier parts of the experiment were evaluated on three additional tasks. Although these tasks are all variations of putting things into a box, they do add some variability to the experiments. It was also great seeing the robot learning multiple strategies for the table clearing task. \n\nThe third part is transferring the simulation policy to the real robot. This section and the additional supplementary material are fairly short and should be expanded upon. It seems as though the transfer mainly depends on learning from randomized domains to achieve more robust policies that can then be applied to the real domain. The transfer learning is a crucial step of the pipeline. Unfortunately the results are not great. A 64% success rate for lifting the block and 35% for stacking are both fairly low. The lifting success is somewhat higher for the stacking at 80% with repeated attempts. The authors need to discuss these results. What is the cause of these low success rates? Is it the transfer learning or due to an earlier step in the pipeline? How do these success rates change with the variance in the training scenarios?\n\nHow much of the shape variability is being accounted for by the natural adaptability of the hand? If you give the robot images with one set of objects, but the actual task is performed  using objects of different shapes and sizes, how much does the performance decrease?\n']","[-60, -20, 20]","[20, 60, 50]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several limitations and criticizes the paper for being misleading and lacking significance. While there are some positive points mentioned (e.g., 'simulated tasks are novel and difficult'), these are outweighed by the criticisms. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use neutral language like 'limitations' and 'questions' rather than harsh or rude phrasing. The reviewer also acknowledges some strengths of the paper, which contributes to a more polite tone. However, the overall critique is still quite strong, preventing a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer recommends acceptance, they express several significant criticisms and limitations of the paper. The review begins positively but then lists many 'cons' and detailed critiques of the authors' claims and results. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as suggestions for improvement rather than harsh judgments. They acknowledge the paper's value while pointing out areas for revision. The reviewer also uses phrases like 'I appreciate' and 'I think' to soften critiques."", ""The sentiment score is slightly positive (20) because while the reviewer offers some praise ('seems to be effective', 'great seeing the robot learning multiple strategies'), they also point out several areas for improvement and express concerns about the results. The overall tone is constructive but with significant critiques. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering suggestions rather than harsh criticisms ('should consider', 'It would be interesting to discuss'). They acknowledge positive aspects before providing critiques, which is a polite approach. However, the review doesn't go out of its way to be overly courteous, maintaining a professional, matter-of-fact tone.""]"
"[""- This paper proposes a framework where the agent has access to a set of user defined attributes parametrizing features of interest. The agent learns a policy for transitioning between similar sets of attributes and given a test task, it can repurpose its attributes to reactively plan a policy to achieve the task. A grid world and tele-kinetically operated block stacking task is used to demonstrate the idea\n\n- This framework is exactly the same as semi-MDPs (Precup, Sutton) and its several generalizations to function approximators as cited in the paper. The authors claim that the novelty is in using the framework for test generalization. \n\n- So the main burden lies on experiments. I do not believe that the experiments alone demonstrate anything substantially new about semi-MDPs even within the deep RL setup. There is a lot of new vocabulary (e.g. sets of attributes) that is introduced, but it dosen't really add a new dimension to the setup. But I do believe in the general setup and I think its an important research direction. However the demonstrations are not strong enough yet and need further development. For instance automatically discovering attributes is the next big open question and authors allude to it.\n\n- I want to encourage the authors to scale up their stacking setup in the most realistic way possible to develop this idea further. I am sure this will greatly improve the paper and open new directions of researchers. \n\n"", 'Summary: This paper proposes a method for planning which involves learning to detect high-level subgoals (called ""attributes""), learning a transition model between subgoals, and then learning a policy for the low-level transitions between subgoals. The high-level task plan is not learned, but is computed using Dijkstra\'s algorithm. The benefit of this method (called the ""Attribute Planner"", or AP) is that it is able to generalize to tasks requiring multi-step plans after only training on tasks requiring single-step plans. The AP is compared against standard A3C baselines across a series of experiments in three different domains, showing impressive performance and demonstrating its generalization capability.\n\nPros:\n- Impressive generalization results on multi-step planning problems.\n- Nice combination of model-based planning for the high-level task plan with model-free RL for the low-level actions.\n\nCons:\n- Attributes are handcrafted and pre-specified rather than being learned.\n- Rather than learning an actual parameterized high-level transition model, a graph is built up out of experience, which requires a large sample complexity.\n- No comparison to other hierarchical RL approaches.\n\nQuality and Clarity:\n\nThis is a great paper. It is extremely well written and clear, includes a very thorough literature review (though it should probably also discuss [1]), takes a sensible approach to combining high- and low-level planning, and demonstrates significant improvements over A3C baselines when generalizing to more complex task plans. The experiments and domains seem reasonable (though the block-stacking domain would be more interesting if the action and state spaces weren\'t discrete) and the analysis is thorough.\n\nWhile the paper in general is written very clearly, it would be helpful to the reader to include an algorithm for the AP.\n\nOriginality and Significance:\n\nI am not an expert in hierarchical RL, but my understanding is that typically hierarchical RL approaches use high-level goals to make the task easier to learn in the first place, such as in tasks with long planning horizons (e.g. Montezuma\'s Revenge). The present work differs from this in that, as they state, ""the goal of the model is to be able to generalize to testing on complex tasks from training on simpler tasks"" (pg. 5). Most work I have seen does not explicitly test for this generalization capability, but this paper points out that it is important and worthwhile to test for.\n\nIt is difficult to say how much of an improvement this paper is on top of other related hierarchical RL works as there are no comparisons made. I think it would be worthwhile to include a comparison to other hierarchical RL architectures (such as [1] or [2]), as I expect they would perform better than the A3C baselines. I suspect that the AP would still have better generalization capabilities, but it is hard to know without seeing the results. That said, I still think that the contribution of the present paper stands on its own.\n\n[1] Vezhnevets, A. S., Osindero, S., Schaul, T., Heess, N., Jaderberg, M., Silver, D., & Kavukcuoglu, K. (2017). FeUdal Networks for Hierarchical Reinforcement Learning. Retrieved from http://arxiv.org/abs/1703.01161\n[2] Kulkarni, T. D., Narasimhan, K. R., Saeedi, A., & Tenenbaum, J. B. (2016). Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation. Advances in Neural Information Processing Systems.', 'This paper proposed a method that enables hierarchical planning. Specifically, given human defined attributes, it learns a graph of attribute transitions. Given a test task and its target set of attributes and a current state, it infers the attribute of current state and search over paths through attribute spaces to get a high-level plan, and then use its low level policy to execute the plan.  Based on the relation (transition) of attributes, new and more complex tasks at test time can be solved compositionally. The proposed method is indeed technically sound and have some distinctions to other existing methods in literature, however, the novelty of this work does not seem to be significant as I will elaborate more.\n\n1.\tIn this work, the attributes are provided by human, which certainty can incur a significant amount of effort hence limit is generalizable of the proposed method.  It might be more appealing if automatic attributes discovery can be incorporated into current framework to remove such restriction as well as better justify the assumption underlying the proposed method is that “the cost of the supervision required to identify the important features of an environment, or to describe the space of possible tasks within it, is not too expensive” \n\n2.\tthe definition of ignorabilty a little confusing. “transition between \\rho_i and \\rho_j should only depend on the attributes \\rho, not exact state” should be written.\n\n3.\tWhen evaluating the model, the authors mentioned that “We recompute the path at intermediate steps in case we reach an attribute set we don’t expect”. What does “attribute set we don’t expect” mean? Do you mean the attribute never seen before?\n\n4.\tThe author should give better account of the relation between the proposed method to other frameworks. The authors mentioned that the proposed method can be placed into the framework of option. However, the option frame is mainly dealing with temporal abstraction, whereas this work seems have much more to do state abstraction. \n\n5.\tThe current work is limited to dealing with problems with two levels of hierarchy \n \n6. Minor comments \nwhich properties of the environment we consider important -> which properties of the environment are important\na model that learns -> a method \nfrom the set of goals rho_j -> from the set of goals, \nGVF is undefined\n']","[-20, 80, -20]","[50, 90, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the research direction, they express skepticism about the novelty of the framework and the strength of the experiments. The reviewer states that the framework is 'exactly the same as semi-MDPs' and that the experiments 'do not demonstrate anything substantially new.' However, they do encourage further development of the idea, which prevents the score from being more negative. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, offers constructive criticism, and encourages the authors to develop their idea further. They use phrases like 'I want to encourage the authors' and 'I am sure this will greatly improve the paper,' which demonstrate a supportive tone despite the critical feedback."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'a great paper' and praises its clarity, thoroughness, and significant improvements over baselines. They highlight several pros and express enthusiasm about the paper's contribution. The few cons mentioned are presented as constructive feedback rather than major criticisms. The politeness score is 90 (very polite) because the reviewer uses respectful and professional language throughout. They offer praise generously and frame criticisms diplomatically, using phrases like 'it would be helpful' and 'I think it would be worthwhile'. The reviewer also acknowledges their own potential limitations ('I am not an expert in hierarchical RL') which adds to the polite tone. The overall language is constructive and encouraging, maintaining a positive and respectful tone even when suggesting improvements."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the proposed method is 'technically sound', they also state that 'the novelty of this work does not seem to be significant'. The review then lists several limitations and areas for improvement, which contributes to the overall negative sentiment. However, the score is not deeply negative as the reviewer does recognize some merits of the work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'It might be more appealing if...' and 'The author should give better account of...' which suggest improvements without being harsh or confrontational. The reviewer also balances criticism with acknowledgment of the work's strengths. However, the score is not extremely high as the language, while polite, is not overly warm or encouraging.""]"
"[""The paper proposes graph-based neural network in which weights from neighboring nodes are adaptively determined. The paper shows importance of propagation layer while showing the non-linear layer does not have significant effect. Further the proposed method also provides class relation based on the edge-wise relevance.\n\nThe paper is easy to follow and the idea would be reasonable. \n\nImportance of the propagation layer than the non-linear layer is interesting, and I think it is worth showing.\n\nVariance of results of AGNN is comparable or even smaller than GLN. This is a bit surprising because AGNN would be more complicated computation than GLN. Is there any good explanation of this low variance of AGNN?\n\nInterpretation of Figure 2 is not clear. All colored nodes except for the thick circle are labeled node? I couldn't judge those predictions are appropriate or not."", ""SUMMARY.\n\nThe paper presents an extension of graph convolutional networks.\nGraph convolutional networks are able to model nodes in a graph taking into consideration the structure of the graph.\nThe authors propose two extensions of GCNs, they first remove intermediate non-linearities from the GCN computation, and then they add an attention mechanism in the aggregation layer, in order to weight the contribution of neighboring nodes in the creation of the new node representation.\nInterestingly, the proposed linear model obtains results that are on-par with the state-of-the-art model, and the linear model with attention outperforms the state-of-the-art models on several standard benchmarks.\n\n\n----------\n\nOVERALL JUDGMENT\nThe paper is, for the most part, clear, although some improvement on the presentation would be good (see below).\nAn important issue the authors should address is the notation consistency, the indexes i and j are used for defining nodes and labels, please use another index for labels.\nIt is very interesting that stripping standard GCN out of nonlinearities gives pretty much the same results, I would appreciate if the authors could give some insights of why this is the case.\nIt seems to me that an important experiment is missing here, have the authors tried to apply the attention model with the standard GCN?\nI like the idea of using a very minimal attention mechanism. The similarity function used for the attention (cosine) is symmetric, this means that if two nodes are connected in both directions, they will be equally important for each other. But intuitively this is not true in general. It would be interesting if the authors could elaborate a bit more on the choice of the similarity function.\n\n\n----------\n\nDETAILED COMMENTS\nPage 2. I do not understand the point of so many details on Graph Laplacian Regularization.\nPage 2. The use of the term 'skip-grams' is somewhat odd, it is not clear what the authors mean with that.\nPage 3. 'the natural random walk' ???\nBottom of page 4. When the authors introduce the attention based network also introduce the input/embedding layer, I believe there is a better place to do so instead of that together with the most important contribution of the paper.\n"", 'The paper proposes a semi supervised learning algorithm for graph node classification. The Algorithm is inspired from Graph Neural Networks and more precisely graph convolutional NNs recently proposed by ref (Kipf et al  2016)) in the paper.  These NNs alternate 2 types of layers:  non linear projection and diffusion, the latter incorporates the graph relational information by constraining neighbor nodes to have close representations according to some “graph metrics”. The authors propose a model with simplified projection layers and more sophisticated diffusion ones, incorporating a simple attention mechanism. Experiments are performed on citation textual datasets. Comparisons with published results on the same datasets are presented.\n\nThe paper is clear and develops interesting ideas relevant to semi-supervised graph node classification. One finding is that simple models perform as well as more complex ones in this setting where labeled data is scarce. Another one is the importance of integrating relational information for classifying nodes when it is available. The attention mechanism itself is extremely simple, and learns one parameter per diffusion layers. One parameter weights correlations between node embeddings in a diffusion layer. I understand that you tried more complex attention mechanisms, but the one finally selected is barely an attention mechanism and rather a simple “importance” weight. This is not a criticism, but this makes the title somewhat misleading. The experiments show that the proposed model is state of the art for graph node classification. The performance is on par with some other recent models according to table 2. The other tests are also interesting, but the comparison could have been extended to other models e.g. GCN.\nYou advocate the role of the diffusion layers, and in the experiments you stack 3 to 4 such layers. It would be interesting to have indications on the compromise performance/ number of diffusion layers and on the evolution of these performances when adding such layers.\nThe bibliography on semi-supervised learning in graphs for classification is light and should be enhanced.\nOverall this is an interesting paper with nice findings. The originality is however relatively limited in a field where many recent papers have been proposed, and the experiments need to be completed.\n']","[60, 50, 50]","[70, 70, 75]","[""The sentiment score is 60 (positive) because the reviewer expresses that the paper is 'easy to follow' and the idea is 'reasonable'. They also mention that the importance of the propagation layer is 'interesting' and 'worth showing'. However, it's not extremely positive as the reviewer raises some questions and points out areas that need clarification. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing critiques as questions or observations rather than direct criticisms. The tone is professional and constructive, without any harsh or rude language."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's clarity and interesting findings, particularly the effectiveness of the linear model and attention mechanism. However, they also point out areas for improvement and missing experiments, balancing the positive aspects. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They use phrases like 'I would appreciate' and 'It would be interesting' when making requests, maintaining a professional and courteous tone. The reviewer also acknowledges the paper's strengths before discussing areas for improvement, which is a polite approach to feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's clarity, interesting ideas, and state-of-the-art performance, but also points out limitations such as the simplicity of the attention mechanism and the need for more extensive comparisons. The reviewer balances positive aspects ('interesting paper with nice findings') with constructive criticism and suggestions for improvement. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as suggestions rather than harsh judgments. Phrases like 'This is not a criticism, but...' and 'It would be interesting to have...' demonstrate a considerate tone. The reviewer also acknowledges the authors' efforts and the paper's strengths before suggesting improvements.""]"
"['This article presents an approach for learning and inference in nonlinear state-space models (SSM) based on LSTMs. Learning is done using a stochastic EM where Particle PMCM is used to sample state trajectories.\n\nThe model is presented assuming that SSMs are linear. This is not necessarily the case since nonlinear SSMs have been used for a long time (see for example Ljung, 1999, ""System Identification, Theory for the User""). The presented model is a nonlinear SSM with a particular structure that uses LSTMs.\n\nThe model described in the paper is Markovian: if one defines the variable sz_t = {s_t, z_t} there exists a Markov chain for the latent state sz:\n\nsz_t -> sz_{t+1} -> sz_{t+2} -> ...\n\nMarginalizing the latent variables s_t leads to a structure that, in general, is not Markovian. The authors claim that this marginalization ""allows the SSL to have non-Markovian state transition"". The word ""allows"" may mislead the reader in thinking that the model has gained some appealing property whereas the model is still essentially Markovian as evidenced by the Markov chain in sz. Any general algorithm for inference in nonlinear Markovian models could be used for inference of sz.\n\nThe algorithm used for inference and learning is stochastic EM with PMCMC but the authors do not cite important prior work such as: Lindsten (2013) ""An efficient stochastic approximation EM algorithm using conditional particle filters""\n\n\nPros:\n\nThe model is sound.\n\nThe overall structure of the paper is good.\n\n\nCons:\n\nThe authors formulate the problem in such a way that they are forced to use an algorithm for non-Markovian models when they could have conserved the Markovian structure by choosing the appropriate parameterization.\n\nThe presentation of state-space models, filtering and smoothing shows some lack of familiarity with the literature. The control theory literature has dealt with nonlinear SSMs for decades and there is recent work in the machine learning community on nonlinear SSMs, e.g. Gaussian Process SSMs. \n\nI would advise against the use of non-English expressions unless they are used precisely:\n\n   - sine qua non: LSTMs are not literally an indispensable model for sequence modeling nowadays. If the use of Latin was unavoidable, ""de facto standard"" would have been slightly more accurate.\n\n   - bona fide: I am not sure what the authors wanted to say.\n\n   - naívely: the correct spelling would be naïvely or naively.', '[After author feedback]\nI would suggest that the authors revise the literature study and contributions to more accurately reflect prior work.\n\n[Original review]\nThe authors propose state space models where the transition probabilities are defined using an LSTM. For inference the authors propose to make use of Monte Carlo expectation maximization.\n\nThe model proposed seems to be a special case of previously proposed models that are mentioned in the 2nd paragraph of the related works section, and e.g. the Maddison et al. (2017) paper. The inference method has also been studied previously (but not to my knowledge applied to SSLs/SRNNs), see the following review papers and references therein:\nSchön, Lindsten, Dahlin, W˚agberg, Naesseth, Svensson, Dai, ""Sequential Monte Carlo Methods for System Identification"", 2015\nKantas, Doucet,  Singh, Maciejowski, Chopin, ""On Particle Methods for Parameter Estimation in State-Space Models"", 2015\n\nGiven this it is unclear to me what the novel contributions are. Perhaps the authors can elaborate on this?\n\nMinor comments:\n- Note that generally a state space model only has the Markov assumption, there is no restrictions on the transition and observation models.\n- EKF also requires Gaussian noise\n- It is a bit unclear what is meant by ""forward messages"" e.g. below eq. (6). For this model I believe the exact would generally be unavailable (at least for continuous models) because they would depend on previous messages.\n- Eq. (12) and (14) are exactly the same? The text seems to indicate they are not.\n- The optimal proposal is only locally optimal, minimizing the incremental weight variance\n- ""w"" should be ""x"" in eq. (20)\n', 'This paper introduces a novel extension of the LSTM which incorporates stochastic inputs at each timestep. These stochastic inputs are themselves dependent on the LSTM state at the previous timestep. Considering the stochastic dependencies, this then yields a highly flexible non-Markov state space model, where the latent variable transitions are partially parameterized by an LSTM update.\n\nNaturally, the challenges are then efficiently estimating parameters and performing inference over the latent states. Here, SMC (and conditional SMC / particle Gibbs) are used for inference over the latent states z. A particularly nice touch is that even when the LSTM model is used for the transitions in the latent space, so long as the conditional distributions p(z_t | z_{1:t-1}) are conjugate with the emission distribution then it is possible to compute the optimal forward filtering proposal distribution in closed form, as done for the conditionally Gaussian (with affine Gaussian observations) and conditionally multinomial models considered here. Note that this really is a special feature of the models under consideration, though: for example, if the emission distribution p(x_t | z_t) is instead a *nonlinear* Gaussian, then one would have to fall back to bootstrap proposals. This probably deserves some mention: equations (13) are not, generally, tractable to integrate or normalize.\n\nI think this paper is missing a few necessary details on how the overall optimization algorithm proceeds, which I would like to see in an update. I understand that particle Gibbs updates (or SMC) are used to approximate the posterior distribution in a Monte Carlo EM algorithm. However, this does leave some questions:\n\n1. For the M step, how are the \\omega parameters (of the LSTM) handled in equation (8)? I understand that due to the particular models considered, maximum likelihood estimates of \\phi can be found in closed form. However, that’s not the case for \\omega. Is a gradient descent algorithm run to convergence? Or is a single gradient step taken, interleaved with a single PG update? Or something else?\n\n2. How reliably does the algorithm as a whole converge? Monte Carlo EM does not in general have convergence guarantees of “standard” EM (i.e. each step is not guaranteed to monotonically improve the lower bound). This might be fine! But, I think requires a bit of discussion.\n\n3. Is it necessary to include a replenishing operation (or independent MCMC steps) in the particle Gibbs algorithm? A known issue when running an iterated conditional SMC algorithm like this is that path degeneracy can make it very difficult for the PG kernel to mix well over the early time steps in the LSTM. Does this issue appear here? How many particles P are needed to efficiently mix, when considering time series of length T?']","[-30, -50, 50]","[20, 20, 70]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('The model is sound' and 'The overall structure of the paper is good'), they also point out several significant issues and criticisms. These include the authors' misrepresentation of the model's Markovian nature, lack of familiarity with relevant literature, and inappropriate use of non-English expressions. The politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout, balancing criticisms with acknowledgments of the paper's strengths. They use phrases like 'I would advise against' rather than more harsh language, and provide constructive feedback. However, some critiques are quite direct, which prevents a higher politeness score."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the novelty of the work and its contributions, suggesting that the proposed model may be a special case of previously published work. This indicates a somewhat negative sentiment, though not entirely dismissive. The politeness score is 20 because while the reviewer is direct in their criticism, they use polite language such as 'I would suggest' and 'Perhaps the authors can elaborate on this?' The reviewer also provides constructive feedback and minor comments to improve the paper, which is a polite approach. However, the overall tone is more neutral than overtly polite, hence the moderate positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novel approach and praises certain aspects ('a particularly nice touch'), while also pointing out areas for improvement and requesting more details. This balanced view indicates a generally positive but not overly enthusiastic sentiment. The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively ('I think this paper is missing...', 'I would like to see...'), and acknowledges the strengths of the work. The reviewer also uses phrases like 'I understand that...' before raising questions, which adds to the polite tone. The review maintains a professional and courteous tone while providing specific, constructive feedback.""]"
"['I only got access to the paper after the review deadline; and did not have a chance to read it until now. Hence the lateness and brevity.\n\nThe paper tackles an important theoretical question; and it offers results that are complementary to existing results (e.g., Soudry et al). However, the paper does not properly relate their results, assumptions in the context of the existing literature. Much explanation is needed in the author reply in order to clear these questions.\n\nThe work should not be evaluated from a practical perspective as it is of a theoretical nature.\n\nI agree with most of the criticism raised by other reviewers. However, I also believe the authors managed to clear essentially of the criticism in they reply. The paper lacks in clarity as currently written. \n\nThe results are interesting, but more explanation is needed for the main message to be conveyed more clearly. I suggest 7, but the paper has a potential to become 8 in my eyes in a future resubmission.\n', 'This paper aims to study some of the theoretical properties of the global optima of single-hidden layer neural networks and also the convergence to such a solution. I think there are some interesting arguments made in the paper e.g. Lemmas 4.1, 5.1, 5.2, and 5.3. However, as I started reading beyond intro I increasingly got the sense that this paper is somewhat incomplete e.g. while certain claims are made (abstract/intro) the theoretical justification are rather far from these claims. Of course there is a chance that I might be misunderstanding some things and happy to adjust my score based on the discussions here.\n\nDetailed comments:\n1) My main concern is that the abstract and intro claims things that are never proven (or even stated) in the rest of the paper\nExample 1 from abstract: \n“We show that for a wide class of differentiable activation functions (this class involved “almost” all functions which are not piecewise linear), we have that first-order optimal solutions satisfy global optimality provided the hidden layer is non-singular.”\n\nThis is certainly not proven and in fact not formally stated anywhere in the paper. Closest result to this is Lemma 4.1 however, because the optimal solution is data dependent this lemma can not be used to conclude this. \n\nExample 2 from intro when comparing with other results on page 2:\nThe authors essentially state that they have less restrictive assumptions in the form of the network or assumptions on the data (e.g. do not require Gaussianity). However as explained above the final conclusions are also significantly weaker than this prior literature so it’s a bit of apples vs oranges comparison.\n\n2) Page 2 minor typos\nWe study training problem -->we study the training problem\nIn the regime training objective--> in the regime the training objective\n\n3) the basic idea argument and derivative calculations in section 3 is identical to section 4 of Soltan...et al\n\n4) Lemma 4.1 is nice, well done! That being said it does not seem easy to make it (1) quantifiable (2) apply to all W. It would also be nice to compare with Soudry et. al.\n\n5) Argument on top of page 6 is incorrect as the global optima is data dependent and hence lemma 4.1 (which is for a fixed matrix) does not apply\n\n6) Section 5 on page 6. Again the stated conclusion here that the iterates do not lead to singular W is much weaker than the claims made early on.\n \n7) I haven’t had time yet to verify correctness of Lemmas 5.1, 5.2, and Lemma 5.3 in detail but if this holds is a neat argument to side step invertibility w.r.t. W, Nicely done!\n\n8) What is the difference between Lemma 5.4 and Lemma 6.12 of Soltan...et al \n\n9) Theorem 5.9. Given that the arguments in this paper do not show asymptotic convergence to a point where gradient vanishes and W is invertible why is the proposed algorithm better than a simple approach in which gradient descent is applied but a small amount of independent Gaussian noise is injected in every iteration over W. By adjusting the noise variance across time one can ensure a result of the kind in Theorem 5.9 (Of course in the absence of a quantifiable version of Lemma 4.1 which can apply to all W that result will also suffer from the same issues).\n', 'The paper studies the theoretical properties of the two-layer neural networks. \n\nTo summarize the result, let\'s use the theta to denote the layer closer to the label, and W to denote the layer closer to the data. \n\nThe paper shows that \na) if W is fixed, then with respect to the randomness of the data, with prob. 1, the Jacobian matrix of the model is full rank\nb) suppose that we run an algorithm with fresh samples, then with respect to the randomness of the k-th sample, we have that with prob. 1, W_k is full rank, and the Jacobian of the model is full rank. \n\nIt\'s know (essentially from the proof of Carmon and Soudry) that if the Jacobian of the model is full rank for any matrix W w.r.t the randomness of the data, then all stationary points are global. But the paper cannot establish such a result. \n\nThe paper is not very clear, and after figuring out what it\'s doing, I don\'t feel it really provides many new things beyond C-S and Xie et al.\n\nThe paper argues that it works for activation beyond relu but result a) is much much weaker than the one with for all quantifier for W. result b) is very sensitive to the exactness of the events (such as W is exactly full rank) --- the events that the paper talks just naturally never happen as long as the density of the random variables doesn\'t degenerate.  \n\nAs the author admitted, the results don\'t provide any formal guarantees for the convergence to a global minimum. It\'s also a bit hard for me to find the techniques here provide new ideas that would potentially lead to resolving this question. \n\n--------------------\n\nadditional review after seeing the author\'s response: \n\nThe author\'s response pointed out some of the limitation of Soudry and Carmon, and Xie et al\'s which I agree. However, none of this limitation is addressed by this paper (or addressed in a misleading way to some extent.)  The key technical limitation is the dependency of the local minima on the weight parameters. Soudry and Carmon addresses this in a partial way by using the random dropout, which is a super cool idea. Xie et al couldn\'t address this globally but show that the Jacobian is well conditioned for a class of weights. The paper here doesn\'t have either and only shows that for a single fixed weight matrix, the Jacobian is well-conditioned. \n\nI don\'t also see the value of extension to other activation function. To some extent this is not consistent with the empirical observation that relu is very important for deep learning. \n\nRegarding the effect of randomness, since the paper only shows the convergence to a first-order optimal solution, I don\'t see why randomness is necessary. Gradient descent can converge to a first order optimal solution. (Indeed I have a typo in my previous review regarding ""w.r.t. k-th sample"", which should be ""w.r.t. k-th update"". ) Moreover, to justify the effect of the randomness, the paper should have empirical experiments. \n\nI think the writing of the paper is also misleading in several places. \n']","[20, -30, -60]","[50, 60, -20]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's importance and interesting results, they also point out several shortcomings and areas needing improvement. The reviewer suggests a score of 7 with potential for 8, indicating a generally positive but cautious view. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges the authors' efforts in addressing previous criticism, and offers constructive feedback. They also apologize for the late review, showing consideration. However, the tone remains professional rather than overtly polite, hence the moderate score."", ""The sentiment score is -30 because while the reviewer acknowledges some interesting arguments and positive aspects of the paper (e.g., 'Lemmas 4.1, 5.1, 5.2, and 5.3'), they express significant concerns about the paper being 'incomplete' and the claims in the abstract/intro not being fully justified in the rest of the paper. The overall tone suggests more criticism than praise, but it's not entirely negative.\n\nThe politeness score is 60 because the reviewer uses generally respectful language and offers constructive criticism. They acknowledge the possibility of misunderstanding ('Of course there is a chance that I might be misunderstanding some things') and offer praise where due ('Lemma 4.1 is nice, well done!'). The reviewer also uses phrases like 'happy to adjust my score' and 'Nicely done!', which contribute to a polite tone. However, the score is not higher because the criticism, while constructive, is quite direct and extensive."", ""The sentiment score is -60 because the reviewer expresses significant criticism and skepticism about the paper's contributions and clarity. They state that the paper 'is not very clear,' 'doesn't really provide many new things,' and that the results 'don't provide any formal guarantees.' The reviewer also questions the value and consistency of the paper's findings. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical without much attempt to soften the blow. Phrases like 'I don't feel it really provides many new things' and 'It's also a bit hard for me to find the techniques here provide new ideas' come across as somewhat dismissive. The reviewer doesn't use particularly polite language or acknowledge positive aspects, which contributes to the slightly negative politeness score.""]"
"['Summary: \nThe authors present a simple variation of vanilla recurrent neural networks, which use ReLU hiddens and a fixed identity matrix that is added to the hidden-to-hidden weight matrix. This identity connection acts as a “surrogate memory” component, preserving hidden activations over time steps. \nThe experiments demonstrate that this architecture reliably solves the addition task for up to 400 input frames. It also achieves a very good performance on sequential and permuted MNIST and achieves SOTA performance on bAbI.\nThe authors observe that the proposed recurrent identity network (RIN) is relatively robust to hyperparameter choices. After Le et al. (2015), the paper presents another convincing case for the application of ReLUs in RNNs.\n\nReview: \nI very much like the paper. The motivation and architecture is presented very clearly and I am happy to also see explorations of simpler recurrent architectures in parallel to research of gated architectures!\nI have a few comments and questions:\n1) Clarification: In Section 2.2, do you really mean bit-wise multiplication or element-wise? If bit-wise, can you elaborate why? I might have missed something.\n2) Why does the learning curve of the IRNN stop around epoch 270 in Figure 2c? Also some curves in the appendix stop abruptly without visible explosions. Were these experiments run until completion? If so, would it be possible to plot the complete curves?\n3) I think for a fair comparison with LSTMs and IRNNs a limited hyperparameter search should be performed separately on all three architectures at least for the addition task. Optimal hyperparameters are usually model-specific. Admittedly, the authors mention that they do not intend to make claims about superior performance to LSTMs, however the competitive performance of small RINs is mentioned a couple of times in the manuscript.\nLe et al. (2015) for instance perform a coarse grid search for each model.\n4) I wouldn\'t say that ResNets are Gated Neural Networks, as the branches are just summed up. There is no (multiplicative) gating as in Highway Networks.\n5) I think what enables the training of very deep networks or LSTMs on long sequences is the presence of a (close-to-)identity component in forward/backward propagation, not the gating. The use of ReLU activations in IRNNs (with identity initialization of the hidden-to-hidden weights) and RINs (effectively initialized with identity plus some noise) makes the recurrence more linear than with squashing activation functions.\n6) Regarding the absence of gating in RINs: What is your intuition on how the model would perform in tasks for which conditional forgetting is useful. Consider for example a task with long sequences, outputs at every time step and hidden activations not necessarily being encouraged to estimate last step hidden activations. Would RINs readily learn to reset parts of the hidden state?\n7) Henaff et al. (2016) might be related, as they are also looking into the addition task with long sequences.\n\nOverall, the presented idea is novel to the best of my knowledge and the manuscript is well-written. I would recommend it for acceptance, but would like to see the above points addressed (especially 1-3 and some comments on 4-6). After a revision I would consider to increase the score.\n\nReferences:\nHenaff, Mikael, Arthur Szlam, and Yann LeCun. ""Recurrent orthogonal networks and long-memory tasks."" In International Conference on Machine Learning, pp. 2034-2042. 2016.\nLe, Quoc V., Navdeep Jaitly, and Geoffrey E. Hinton. ""A simple way to initialize recurrent networks of rectified linear units."" arXiv preprint arXiv:1504.00941 (2015).', 'Here are my main critics of the papers:\n\n1. Equation (1), (2), (3) are those expectations w.r.t. the data distribution (otherwise I can\'t think of any other stochasticity)? If so your phrase ""is zero given a sequence of inputs X1, ...,T"" is misleading. \n2. Lack of motivation for IE or UIE. Where is your background material? I do not understand why we would like to assume (1), (2), (3). Why the same intuition of UIE can be applied to RNNs? \n3. The paper proposed the new architecture RIN, but it is not much different than a simple RNN with identity initialization. Not much novelty.\n4. The experimental results are not convincing. It\'s not compared against any previous published results. E.g. the addition tasks and sMNIST tasks are not as good as those reported in [1]. Also it only has been tested on very simple datasets.\n\n\n[1] Path-Normalized Optimization of Recurrent Neural Networks with ReLU Activations. Behnam Neyshabur, Yuhuai Wu, Ruslan Salakhutdinov, Nathan Srebro.', 'The paper investigates the iterative estimation view on gated recurrent networks (GNN). Authors observe that the average estimation error between a given hidden state and the last hidden state  gradually decreases toward zeros. This suggest that GNN are bias toward an identity mapping and learn to preserve the activation through time.\nGiven this observation, authors then propose RIN, a new RNN parametrization where the hidden to hidden matrix is decomposed as a learnable weight matrix plus the identity matrix.\nAuthors evaluate their RIN on the adding, sequential MNIST and the baby tasks and show that their IRNN outperforms the IRNN and LSTM models.\n\nQuestions:\n- Section 2 suggests that use of the gate  in GNNs encourages to learn an identity mapping. Does the average iteration error behaves differently in case of a tanh-RNN ?\n- It seems from Figure 4 (a) that the average estimation error is higher for RIN than IRNN and LSTM and only decrease toward zero at the very end. What could explain this phenomenon?\n- While the LSTM baseline matches the results of Le et al., later work such as Recurrent Batch Normalization or Unitary Evolution RNN have demonstrated much better performance with a vanilla LSTM on those tasks (outperforming both IRNN and RIN). What could explain this difference in the performances?\n- Unless I am mistaken, Gated Orthogonal Recurrent Units: On Learning to Forget from Jing et al. also reports better performances for the LSTM (and GRU) baselines that outperform RIN on the baby tasks with mean performances of 58.2 and 56.0 for GRU and LSTM respectively?\n\n- Quality/Clarity:\nThe paper is well written and pleasant to read\n\n- Originality:\nLooking at RNN from an iterative refinement point of view seems novel.\n\n- Significance:\nWhile looking at RNN from an iterative estimation is interesting, the experimental part does not really show what are the advantages of the propose RIN. In particular, the LSTM baseline seems to weak compared to other works.']","[70, -60, 20]","[80, -20, 80]","[""The sentiment score is 70 (positive) because the reviewer starts by saying 'I very much like the paper' and recommends it for acceptance. They provide constructive feedback and express enthusiasm for the research direction. However, it's not 100 as they do have some critiques and requests for clarification. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, phrases critiques as questions or suggestions, and acknowledges the authors' efforts. They use phrases like 'I think' and 'can you elaborate' which maintain a collegial tone. The score isn't 100 as the language, while polite, isn't excessively formal or deferential."", ""The sentiment score is -60 because the review is predominantly critical, listing several major issues with the paper without offering much positive feedback. The reviewer points out problems with equations, lack of motivation, limited novelty, and unconvincing experimental results. The tone suggests significant revisions are needed. The politeness score is -20 because while the language is not overtly rude, it is quite direct and lacks softening phrases or positive reinforcement. The reviewer uses phrases like 'Lack of motivation', 'Not much novelty', and 'not convincing' without cushioning the criticism. However, the reviewer does use some neutral language and frames criticisms as questions, which prevents the score from being lower."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is well-written and presents a novel perspective, but raises several questions and concerns about the experimental results and comparisons to other work. The politeness score is quite high (80) as the reviewer uses respectful language throughout, phrases criticisms as questions, and includes positive comments about the paper's quality and originality. The reviewer maintains a professional and constructive tone while still clearly communicating areas for improvement.""]"
"[""Originality\n--------------\nWhen the action space is N-dimensional, computing argmax could be problematic. The paper proposes to address the problem by creating N MDPs with 1-D actions. \n\nClarity\n---------\n1) Explicitly writing down DDPG will be helpful\n2) The number of actions in each of the domains will also be useful\n\nQuality\n----------\n1) The paper reports experimental results on order of actions as well as binning, and the results confirm with what one would expect from intuition. \n2) It will be important to talk about the case when the action dimension N is very large, what happens in that case? Does the proposed method would work in such a scenario? A discussion is needed.\n3) Given that the ordering of actions does not matter, what is the real take away of looking at them as 'sequence' (which has not temporal structure because action order could be arbitrary)?\n\n\nSignificance\n----------------\nWhile the proposed method seems a reasonable approach to handle the argmax problem, it still requires training multiple networks for Q^i (i=1,..N) for Q^L, which is a limitation. Further, since the actions could be arbitrary, it is unclear where 'sequence' approach helps. These limit the understand and hence significance.\n"", ""The paper presents Sequential Deep Q-Networks (SDQNs), which select actions from discretized high-dimensional action spaces.  This is done by introducing another, undiscounted MDP in which each action dimension is chosen sequentially by an agent.  By training a Q network to best choose these action dimensions, and loosely enforcing equality between the original and new MDPs at points where they are equivalent, the new MDP can be successfully navigated, resulting in good action selection for the original MDP.  This is experimentally compared against DDPG in several domains.  There are no theoretical results.\n\nThis work is correct and clearly written.  Experiments do demonstrate improved effectiveness in the chosen domains, and the authors do a nice job of illustrating the range of performance by their approach (which has low variance in some domains, but high variance in others).  Because of the clarity of the paper, the effectiveness of the approach, and the high quality experiments, I encourage acceptance.\n\nIt doesn't strike me as world-changing, however.  The MDP-within-an-MDP approach is quite similar to the Pazis and Lagoudakis MDP decomposition for the same problem (work which is appropriately cited, but maybe too briefly compared against).  In other words, it strikes me as merely being P&L plus networks, dampening my enthusiasm.\n\nMy one question for the authors is how much the order of action dimension selection matters.  This seems probably quite important practically, but is undiscussed."", ""The paper describes a new RL technique for high dimensional action spaces.  It discretizes each dimension of the action space, but to avoid an exponential blowup, it selects the action for each dimension in sequence.  This is an interesting approach.  The paper reformulates the MDP with a high dimensional action space into an equivalent MDP with more time steps (one per dimension) that each selects the action in one dimension.  This makes sense.\n\nWhile I do like very much the model, I am perplex about the training technique.  The lower MDP is precisely the new proposed model with unidimensional actions and therefore it should be sufficient.  However, the paper also describes an upper MDP that seems to be superfluous.  The two MDPs are mathematically equivalent, but their Q-values are obtained differently (TD-0 for the upper MDP and Q-learning for the lower MDP) and yet the paper tries to minimize the Euclidean distance between them.  This is really puzzling since the different training algorithms suggest that the Q-values should be different while minimizing the Euclidean distance between them tries to make them equal.  The paper suggests that divergence occurs without the upper MDP.  This is really suspicious. The approach feels like a band-aid solution to cover a problem that the authors could not identify.  While the empirical results are good, I don't think the paper should be published until the authors figure out a principled way of training.\n\nThe proposed approach reformulates the MDP with high dimensional actions into an equivalent one with uni dimensional actions.  There is a catch.  This approach effectively hides the exponential action space into the state space which becomes exponential.  Since u contains all the actions of the previous dimensions, we are effectively increasing the state space by an exponential factor.  The paper should discuss this and explain what are the consequences in practice.  In the end, the MDP does not become simpler.\n\nOverall, this is an interesting paper with a good idea, but the training technique is not mature enough for publication.""]","[-20, 60, -20]","[50, 80, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper, they also point out several limitations and areas for improvement. The review starts with neutral observations about the paper's approach, but then lists multiple concerns and suggestions, indicating that the reviewer is not fully satisfied with the current state of the work. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They offer constructive criticism and suggestions for improvement without using harsh or dismissive language. The reviewer's tone is academic and objective, focusing on the content rather than making personal comments."", ""The sentiment score is 60 (moderately positive) because the reviewer encourages acceptance of the paper, praising its clarity, effectiveness, and high-quality experiments. However, they also express that it's not 'world-changing' and dampens their enthusiasm somewhat, preventing a higher score. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and offering constructive criticism. They phrase their concerns gently (e.g., 'It doesn't strike me as world-changing') and end with a polite question for the authors, demonstrating engagement with the work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting approach and good empirical results, they express significant concerns about the training technique and believe the paper is not ready for publication. The reviewer uses phrases like 'really puzzling,' 'really suspicious,' and 'band-aid solution,' indicating skepticism about key aspects of the work. However, the reviewer also notes positive aspects, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'I do like very much the model' and 'This is an interesting approach.' They express their concerns clearly but without harsh language, and offer constructive feedback. The reviewer balances criticism with acknowledgment of the paper's strengths, which contributes to the polite tone.""]"
"[""In this paper, the authors propose a type of Normalizing Flows (Rezende and Mohamed, 2015) for Variational Autoencoders (Kingma and Welling, 2014; Rezende et al., 2014) they call Convolutional Normalizing Flows.\nMore particularly, it aims at extending on the Planar Flow scheme proposed in Rezende and Mohamed (2015). The authors notice an improvement through their method over Normalizing Flows, IWAE with diagonal gaussian approximation, and standard Variational Autoencoders. \nAs noted by AnonReviewer3, several baselines are missing. But the authors partly address that issue in the comment section for the MNIST dataset.\nThe requirement of h being bijective seems wrong. For example, if h was a rectifier nonlinearity in the zero-derivative regime, the Jacobian determinant of the ConvFlow would be 1. \nMore importantly, the main issue is that this paper might need to highlight the fundamental difference between their proposed method and Inverse Autoregressive Flow (Kingma et al., 2016). The proposed connectivity pattern proposed for the convolution in order to make the Jacobian determinant computation is exactly the same as Inverse Autoregressive Flow and the authors seems to be aware of the order dependence of their architecture which is every similar to autoregressive models. This presentation of the paper can be misleading concerning the true innovation in the model trained. Proposing ConvFlow as a type of Inverse Autoregressive Flow would be more accurate and would allow to highlight better the innovation of the work.\nSince this work does not offer additional significant insight over Inverse Autoregressive Flow, its value should be on demonstrating the efficiency of the proposed method. MNIST and Omniglot seems insufficient for that purpose given currently published work.\nIn the current state, I can't recommend the paper for acceptance. \n\n\nDanilo Jimenez Rezende, Shakir Mohamed: Variational Inference with Normalizing Flows. ICML 2015\nDanilo Jimenez Rezende, Shakir Mohamed, Daan Wierstra: Stochastic Back-propagation and Variational Inference in Deep Latent Gaussian Models. ICML 2014\nDiederik P. Kingma, Max Welling: Auto-Encoding Variational Bayes. ICLR 2014\nDiederik P. Kingma, Tim Salimans, Rafal Józefowicz, Xi Chen, Ilya Sutskever, Max Welling: Improving Variational Autoencoders with Inverse Autoregressive Flow. NIPS 2016"", 'The authors propose a new method for improving the flexibility of the encoder in VAEs, called ConvFlow. If I understand correctly (please correct me if not) the proposed method is a simplification of Inverse Autoregressive Flow as proposed by Kingma et al. Both of these methods use causal convolution to construct a normalizing flow with tractable Jacobian determinant. The difference is that Kingma et al. used 2d convolution (as well a fully connected architectures) where the authors of this paper propose to use 1d convolution. The novelty therefore seems limited.\n\nThe current version of the paper does not present convincing experimental results. The proposed method performs less well than previously proposed methods. If the authors were to update the experimental results to show equal or better performance to SOTA, with an analysis showing their method is indeed computationally less expensive, I would be willing to increase my rating.', 'The paper proposes to increase the expressivity of the variational approximation in VAEs using a new convolutional parameterization of normalizing flows. Starting from the planar flow proposed in Rezende & Mohammed 2015 using a vector inner product followed by a nonliniarity+element-wise scaling the authors suggests to replace inner product with a shifted 1-D convolution. This reduces the number of parameters used from 2*d to k + d and importantly still maintains the linear time computation of the determinant. This approach feels so straightforward that i’m surprised that it have not been tried before. The authors present results on a synthetic task as well as MNIST and OMNIGLOT. Please find some more detailed comments/questions below\n\n\nQ1) I feel that section 3 could be more detailed about how the convolution normalizing flow relate to normalizing flow, inverse autoregressive flow and the masked-convolution used in real NVP? Especifically a) is it correct that convolutional normalizing flow trades global connectivity for more expressivity locally? b) Can convolutional flow be seen as faster but ´more restricted version of the LSTM implemented inverse autoregressive flow (full lower triangular jacobian vs k off diagonal elements per row in convolutional normalizing flow) \n\nQ2) I miss some more baselines in the experimental section. Did the authors compare the convolutional normalizing flow with e.g. Inverse Autoregressive flow or Auxiliary latent variables? \n\n\nQ3) Albeit the MNIST results seems convincing - and to a lesser degree the OMNIGLOT ones - I miss results on larger natural image benchmark datasets like cifar10 and ImageNet or preferably other modalities like text? Would it be possible to include results on any of these datasets?\n\nOverall i think the idea is nice and potentially useful due to the ease of implementation and speed of convolutional operations. However I think the authors needs to 1) better describe how their method differs from prior work and 2) compare their method to more baselines for the experiments to fully convincing\n']","[-60, -50, 20]","[20, 50, 60]","[""The sentiment score is -60 because the reviewer expresses several critical points and ultimately does not recommend the paper for acceptance. They point out missing baselines, potential inaccuracies, and lack of significant insight over existing methods. However, it's not entirely negative as they acknowledge some improvements and partial addressing of issues. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'the authors notice an improvement' and 'the authors partly address that issue,' which show some level of politeness. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -50 because the reviewer expresses skepticism about the novelty of the proposed method and states that the experimental results are not convincing. However, they do offer a path for improvement, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses respectful language throughout, such as 'please correct me if not' and 'I would be willing to increase my rating.' They provide constructive criticism without being harsh or dismissive, maintaining a professional tone. The reviewer also acknowledges the potential for improvement, which adds to the politeness of the review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's novel approach and potential usefulness, stating it's 'nice and potentially useful'. However, they also express some reservations and request more comparisons and details. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'I miss some more baselines'), and offers specific suggestions for improvement. The reviewer maintains a professional tone, balancing positive feedback with areas for enhancement, without using harsh or dismissive language.""]"
"[""# Summary\nThis paper introduces a new prediction problem where the model should predict the hidden opponent's state as well as the agent's state. This paper presents a neural network architecture which takes the map information and several other features and reconstructs the unit occupancy and count information in the map. The result shows that the proposed method performs better than several hand-designed baselines on two downstream prediction tasks in Starcraft.\n\n[Pros]\n- Interesting problem\n\n[Cons]\n- The proposed method is not much novel.\n- The evaluation is a bit limited to two specific downstream prediction tasks.\n\n# Novelty and Significance\n- The problem considered in this paper is interesting.\n- The proposed method is not much novel. \n- Overall, this paper is too specific to Starcraft domain + particular downstream prediction tasks. It would be much stronger to show the benefit of defogging objective on the actual gameplay rather than prediction tasks. Alternatively, it could be also interesting to consider an RL problem where the agent should reveal the hidden state of the opponent as much/quickly as possible.\n\n# Quality\n- The experimental result is not much comprehensive. The proposed method is expected to perform better than hand-designed methods on downstream prediction tasks. It would be better to show an in-depth analysis of the learned model or show more results on different tasks (possibly RL tasks rather than prediction tasks).\n\n# Clarity\n- I did not fully understand the learning objective. Does the model try to reconstruct the state of the current time-step or the future? The learning objective is not clearly defined. In Section 4.1, the target x and y have time steps from t1 to t2. What is the range of t1 and t2? If the proposed model is doing future prediction, it would be important to show and discuss long-term prediction results."", 'The paper considers a problem of predicting hidden information in a poMDP with an application to Starcraft.\nAuthors propose a number of baseline models as well as metrics to assess the quality of “defogging”.\n\nI find the problem of defogging quite interesting, even though it is a bit too Starcraft-specific some findings could perhaps be translated to other partially observed environments.\nAuthors use the dataset provided for Starcraft: Brood war by Lin et al, 2017.\n\nMy impression about the paper is that even though it touches a very interesting problem, it neither is written well nor it contains much of a novelty in terms of algorithms, methods or network architectures.\n\nDetailed comments:\n* Authors should at very least cite (Vinyals et al, 2017) and explain why the environment and the dataset released for Starcraft 2 is less suited than the one provided by Lin et al.\n* Problem statement in section 3.1 should certainly be improved. Authors introduce rather heavy notation which is then used in a confusing way. For example, what is the top index in $s_t^{3-p}$ supposed to mean? The notation is not much used after sec. 3.1, for example, figure 1 does not use it. \n* A related issue, is that the definition of metrics is very informal and, again, does not use the already defined notation. Including explicit formulas would be very helpful, because, for example, it looks like when reported in table 1 the metrics are spatially averaged, yet I could not find an explicit notion of that.\n* Authors seem to only consider deterministic defogging models. However, to me it seems that even in 15 game steps the uncertainty over the hidden state is quite high and thus any deterministic model has a very limited potential in prediction it. At least the concept of stochastic predictions should be discussed\n* The rule-based baselines are not described in detail. What does “using game rules to infer the existence of unit types” mean?\n* Another detail which I found missing is whether authors use just a screen, a mini-map or both. In the game of Starcraft, only screen contains information about unit-types, but it’s field of view is limited. Hence, it’s unclear to me whether a model should infer hidden information based on just a single screen + minimap observation (or a history of them) or due to how the dataset is constructed, all units are observed without spatial limitations of the screen. \n', 'The authors introduce the task of ""defogging"", by which they mean attempting to infer the contents of areas in the game StarCraft hidden by ""the fog of war"".\n\nThe authors train a neural network to solve the defogging task, define several evaluation metrics, and argue that the neural network beats several naive baseline models. \n\nOn the positive side, the task is a nice example of reasoning about a complex hidden state space, which is an important problem moving forwards in deep learning.\n\nOn the negative side, from what I can tell, the authors don\'t seem to have introduced any fundamentally new architectural choices in their neural network, so the contribution seems fairly specific to mastering StarCraft, but at the same time, the authors don\'t evaluate how much their defogger actually contributes to being able to win StarCraft games.  All of their evaluation is based on the accuracy of defogging. \n\nGranted, being able to infer hidden states is of course an important problem, but the authors appear to mainly have applied existing techniques to a benchmark that has minimal practical significance outside of being able to win StarCraft competitions, meaning that, at least as the paper is currently framed, the critical evaluation metric would be showing that a defogger helps to win games. \n\nTwo ways I could image the contribution being improved are either highlighting and generalizing novel insights gleaned from the process of building the neural network that could help people build ""defoggers"" for other domains (and spelling out more explicitly what domains the authors expect their insights to generalize to), or doubling down on the StarCraft application specifically and showing that the defogger helps to win games.  A minimal version of the second modification would be having a bot that has access to a defogger play against a bot that does not have access to one.\n \nAll that said, as a paper on an application of deep learning, the paper appears to be solid, and if the area chairs are looking for that sort of contribution, then the work seems acceptable.\n\nMinor points:\n- Is there a benefit to having a model that jointly predicts unit presence and count, rather than having two separate models (e.g., one that feeds into the next)?  Could predicting presence or absence separately be a way to encourage sparsity, since absence of a unit is already representable as a count of zero?  The choice to have one model seems especially peculiar given the authors say they couldn\'t get one set of weights that works for both their classification and regression tasks\n- Notation: I believe the space U is never described in the main text. What components precisely does an element of U have?\n- The authors say they use gameplay from no later than 11 minutes in the game to avoid the difficulties of increasing variance. How long is a typical game?  Is this a substantial fraction of the time of the games studied?  If it is not, then perhaps the defogger would not help so much at winning.\n- The F1 performance increases are somewhat small. The L1 performance gains are bigger, but the authors only compare L1 on true positives. This means they might have very bad error on false positives. (The authors state they are favoring the baseline in this comparison, but it would be nice to have those numbers.)\n- I don\'t understand when the authors say the deep model has better memory than baselines (which includes a perfect memory baseline)']","[-20, -50, -20]","[50, 20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the problem as 'interesting', they also point out several cons and limitations. The reviewer states that the proposed method is 'not much novel', the evaluation is 'limited', and the paper is 'too specific'. These criticisms outweigh the positive aspects, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer uses neutral and professional language throughout. They present their criticisms constructively, using phrases like 'It would be better to' and 'It would be much stronger to', which suggest improvements rather than harshly criticizing. The reviewer also acknowledges the positive aspects before presenting the negatives, which is a polite approach in academic reviews."", ""The sentiment score is -50 because the reviewer expresses mixed feelings about the paper. While they find the problem interesting, they criticize the paper for not being well-written and lacking novelty. The phrase 'even though it touches a very interesting problem, it neither is written well nor it contains much of a novelty' indicates a predominantly negative sentiment. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I find' and 'My impression is' to soften criticisms. They also provide detailed comments for improvement, which is constructive. However, the directness of some criticisms (e.g., 'neither is written well') prevents a higher politeness score."", ""For the sentiment score, I assigned -20 because while the reviewer acknowledges some positive aspects ('nice example of reasoning about a complex hidden state space'), they express several significant criticisms. These include the lack of fundamentally new architectural choices, limited practical significance outside StarCraft, and the absence of evaluation on how the defogger contributes to winning games. The overall tone suggests the paper needs substantial improvements, but it's not entirely negative, hence a slightly negative score.\n\nFor the politeness score, I assigned 60 because the reviewer maintains a professional and respectful tone throughout. They offer constructive criticism and suggestions for improvement without using harsh language. Phrases like 'On the positive side' and 'All that said, as a paper on an application of deep learning, the paper appears to be solid' demonstrate a balanced and courteous approach. The reviewer also uses polite language when pointing out issues, such as 'from what I can tell' and 'the authors don't seem to have', which softens the criticism. However, it's not extremely polite, as it doesn't go out of its way to praise the authors, hence a moderately positive score.""]"
"['The authors argue that the spectral dimensionality reduction techniques are too slow, due to the complexity of computing the eigenvalue decomposition, and that they are not suitable for out-of-sample extension. They also note the limitation of neural networks, which require huge amounts of data to properly learn the data structure. The authors therefore propose to first sub-sample the data and afterwards to learn an MDS-like cost function directly with a neural network, resulting in a parametric framework.\n\nThe paper should be checked for grammatical errors, such as e.g. consistent use of (no) hyphen in low-dimensional (or low dimensional).\n\nThe abbreviations should be written out on the first use, e.g. MLP, MDS, LLE, etc.\n\nIn the introduction the authors claim that the complexity of parametric techniques does not depend on the number of data points, or that moving to parametric techniques would reduce memory and computational complexities. This is in general not true. Even if the number of parameters is small, learning them might require complex computations on the whole data set. On the other hand, even if the number of parameters is equal to the number of data points, the computations could be trivial, thus resulting in a complexity of O(N).\n\nIn section 2.1, the authors claim ""Spectral techniques are non-parametric in nature""; this is wrong again. E.g. PCA can be formulated as MDS (thus spectral), but can be seen as a parametric mapping which can be used to project new words.\n\nIn section 2.2, it says ""observation that the double centering..."". Can you provide a citation for this?\n\nIn section 3, the authors propose they technique, which should be faster and require less data than the previous methods, but to support their claim, they do not perform an analysis of computational complexity. It is not quite clear from the text what the resulting complexity would be. With N as number of data points and M as number of landmarks, from the description on page 4 it seems the complexity would be O(N + M^2), but the steps 1 and 2 on page 5 suggest it would be O(N^2 + M^2). Unfortunately, it is also not clear what the complexity of previous techniques, e.g DrLim, is.\n\nFigure 3, contrary to text, does not provide a visualisation to the sampling mechanism.\n\nIn the experiments section, can you provide a citation for ADAM and explain how the parameters were selected? Also, it is not meaningful to measure the quality of a visualisation via the MDS fit. There are more useful approaches to this task, such as the quality framework [*].\n\nIn figure 4a, x-axis should be ""number of landmarks"".\n\nIt is not clear why the equation 6 holds. Citation?\nIt is also not clear how exactly the equation 7 is evaluated. It says ""By varying the number of layers and the number of nodes..."", but the nodes and layer are not a part of the equation.\n\nThe notation for equation 8 is not explained.\n\nFigure 6a shows visualisations by different techniques and is evaluated ""by looking at it"". Again, use [*].\n\n[*] Lee, John Aldo ; Verleysen, Michel. Scale-independent quality criteria for dimensionality reduction. In: Pattern Recognition Letters, Vol. 31, no. 14, p. 2248-2257 (2010). doi:10.1016/j.patrec.2010.04.013.\n', ""The paper describes a manifold learning method that adapts the old ideas of multidimensional scaling, with geodesic distances in particular, to neural networks. The goal is to switch from a non-parametric to a parametric method and hence to have a straightforward out-of-sample extension.\n\nThe paper has several major shortcomings:\n* Any paper dealing with MDS and geodesic distances should test the proposed method on the Swiss roll, which has been the most emblematic benchmark since the Isomap paper in 2000. Not showing the Swiss roll would possibly let the reader think that the method does not perform well on that example. In particular, DR is one of the last fields where deep learning cannot outperform older methods like t-SNE. Please add the Swiss roll example.\n* Distance preservation appears more and more like a dated DR paradigm. Simple example from 3D to 2D are easily handled but beyond the curse of dimensionality makes things more complicated, in particular due to norm computation. Computation accuracy of the geodesic distances in high-dimensional spaces can be poor. This could be discussed and some experiments on very HD data should be reported.\n* Some key historical references are overlooked, like the SAMMANN. There is also an over-emphasis on spectral methods, with the necessity to compute large matrices and to factorize them, probably owing to the popularity of spectral DR metods a decade ago. Other methods might be computationally less expensive, like those relying on space-partitioning trees and fast multipole methods (subquadratic complexity). Finally, auto-encoders could be mentioned as well; they have the advantage of providing the parametric inverse of the mapping too.\n* As a tool for unsupervised learning or exploratory data visualization, DR can hardly benefit from a parametric approach. The motivation in the end of page 3 seems to be computational only.\n* Section 3 should be further detailed (step 2 in particular).\n* The experiments are rather limited, with only a few artifcial data sets and hardly any quantitative assessment except for some monitoring of the stress. The running times are not in favor of the proposed method. The data sets sizes are, however, quite limited, with N<10000 for point cloud data and N<2000 for the image manifold.\n* The conclusion sounds a bit vague and pompous ('by allowing a limited infusion of axiomatic computation...'). What is the take-home message of the paper?"", 'The key contribution of the paper is a new method for nonlinear dimensionality reduction. \n\nThe proposed method is (more or less) a modification of the DrLIM manifold learning algorithm (Hadsell, Chopra, LeCun 2006) with a slightly different loss function that is inspired by multidimensional scaling. While DrLIM only preserves local geometry, the modified loss function presents the opportunity to preserve both local and global geometry. The rest of the paper is devoted to an empirical validation of the proposed method on small-scale synthetic data (the familiar Swiss roll, as well as a couple of synthetic image datasets). \n\nThe paper revisits mostly familiar ideas. The importance of preserving both local and global information in manifold learning is well known, so unclear what the main conceptual novelty is. This reviewer does not believe that modifying the loss function of a well established previous method that is over 10 years old (DrLIM) constitutes a significant enough contribution.\n\nMoreover, in this reviewer\'s experience, the major challenge is to obtain proper estimates of the geodesic distances between far-away points on the manifold, and such an estimation is simply too difficult for any reasonable dataset encountered in practice. However, the authors do not address this, and instead simply use the Isomap approach for approximating geodesics by graph distances, which opens up a completely different set of challenges (how to construct the graph, how to deal with ""holes"" in the manifold, how to avoid short circuiting in the all-pairs shortest path computations etc etc). \n\nFinally, the experimental results are somewhat uninspiring. It seems that the proposed method does roughly as well as Landmark Isomap (with slightly better generalization properties) but is slower by a factor of 1000x. \n\nThe horizon articulation data, as well as the pose articulation data, are both far too synthetic to draw any practical conclusions. \n']","[-30, -60, -70]","[50, 20, 20]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the authors' proposed approach, they point out several issues and inaccuracies in the paper. The review begins with a neutral summary but then lists multiple criticisms and corrections needed. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'can you provide' and 'it is not clear' instead of more confrontational language. The reviewer also offers helpful suggestions and references. The overall tone is critical but respectful, aiming to improve the paper rather than dismiss it outright."", ""The sentiment score is -60 because the review is predominantly critical, pointing out several 'major shortcomings' of the paper. The reviewer lists multiple areas where the paper is lacking, such as missing key examples, overlooking important references, and having limited experiments. However, it's not entirely negative as it does acknowledge the paper's attempt to adapt old ideas to neural networks. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and provide constructive feedback. They use phrases like 'Please add' and 'This could be discussed' which maintain a respectful tone. The reviewer also offers specific suggestions for improvement, which is a polite way to provide criticism. However, the final comment about the conclusion sounding 'vague and pompous' is somewhat less polite, preventing a higher politeness score."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper 'revisits mostly familiar ideas,' questions the novelty of the contribution, and describes the experimental results as 'uninspiring.' They also mention that the method is significantly slower than existing approaches. However, it's not entirely negative as they acknowledge some potential benefits of the proposed method, hence not scoring at the extreme negative end.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and objective tone throughout. They use phrases like 'This reviewer does not believe' rather than making blunt statements, and they provide reasons for their criticisms. The language is not particularly warm or encouraging, but it avoids being rude or disrespectful. The slightly positive score reflects the reviewer's effort to maintain politeness while delivering criticism.""]"
"['This paper describes a setting in which a system learns collections of inverse-mapping functions that transform altered inputs to their unaltered ""canonical"" counterparts, while only needing unassociated and separate sets of examples of each at training time.  Each inverse map is an ""expert"" E akin to a MoE expert, but instead of using a feed-forward gating on the input, an expert is selected (for training or inference) based on the value of a distribution-modeling function c applied to the output of all experts:  The expert with maximum value c(E(x)) is selected.  When c is an adversarially trained discriminator network, the experts learn to model the different transformations that map altered images back to unaltered ones.  This is demonstrated using MNIST with a small set of synthetic translations and noise.\n\nThe fact that these different inverse maps arise under these conditions is interesting --- and Figure 5 is quite convincing in showing how each expert generalizes.  However, I think the experimental conditions are very limited:  Only one collection of transformations is studied, and on MNIST digits only.  In particular, I found the fact that only one of ten transformations can be applied at a time (as opposed to a series of multiple transforms) to be restrictive.  This is touched on in the conclusion, but to me it seems fundamental, as any real-world new example will undergo significantly more complex processes with many different variables all applied at once.\n\nAnother direction I think would be interesting, is how few examples are needed in the canonical distribution?  For example, in MNIST, could the canonical distribution P be limited to just one example per digit (or just one example per mode / style of digit, e.g. ""2"" with loop, and without loop)?  The different handwriters of the digits, and sampling and scanning process, may themselves constitute in-the-wild transformations that might be inverted to single (or few) canonical examples --- Is this possible with this mechanism?\n\nOverall, it is nice to see the different inverse maps arise naturally in this setting.  But I find the single setting limiting, and think the investigation could be pushed further into less restricted settings, a couple of which I mention above.\n\n\n\nOther comments:\n\n- c is first described to be any distribution model, e.g. the autoencoder described on p.5.  But it seems that using such a fixed, predefined c like the autoencoder may lead to collapse:  What is preventing an expert from learning a single constant mode that has high c value?  The adversarially trained c doesn\'t suffer from this, because presumably the discriminator will be able to learn the difference between a single constant mode output and the distribution P.  But if this is the case, it seems a critical part of the system, not a simple implementation choice as the text seems to say.\n\n- The single-net baseline is good, but I\'d like to get a clearer picture of its results.  p.8 says this didn\'t manage to ""learn more than one inverse mechanism"" --- Does that mean it learns to invert a single mechanism (that is always translates up, for example, when presented an image)?  Or that it learned some mix of transforms that didn\'t seem to generalize as well?  Or does it have some other behavior?  Also, I\'m not entirely clear on how it was trained wrt c --- is argmax(c(E(x)) always just the single expert?  Is c also trained adversarially?  And if so, is the approximate identity initialization used?\n', ""This paper presents a framework to recover a set of independent mechanisms. In order to do so it uses a set of experts each one made out of a GAN.\n\nMy main concern with this work is that I don't see any mechanism in the framework that prevents an expert  (or few of them) to win all examples except its own learning capacities. p7 authors have also noticed that several experts fail to specialize and I bet that is the reason why.\nThus, authors should analyze how well we can have all/most experts specialize in a pool vs expert capacity/architecture.\nIt would also be great to integrate a direct regularization mechanism in the cost  in order to do so. Like for example a penalty in how many examples a expert has catched.\n\nMoreover, the discrimator D  (which is trained to discriminate between real or fake examples) seems to be directly used to tell if an example is throw from the targeted distribution. It is not the same task. How D will handle an example far from fake or real ones ? Why will D answer negatively (or positively) on this example ? \n\n\n"", 'Summary:\nGiven data from a canonical distribution P and data from distributions that are\nindependent transformations (mechanisms) applied on P, this paper aims to learn\n1) those independent transformations; and 2) inverse transformations that map\ndata from transformed distributions to their corresponding canonical\ndistribution.\n\nThis is achieved by training a mixture of experts, where each expert is assumed to\nmodel a single inverse transformation. Each expert can be seen as the generator\nof a conditional GAN. The discriminator is trained to distinguish samples from\nthe canonical distribution P and those transformed distributions.\n\nExperiments on MNIST data shows that in the end of training, each expert wins\nalmost all samples from one transformation and no other, which confirms that\neach expert model a single inverse transformation.\n\nComments:\n1) Besides samples from distributions that are results of applying independent\nmechanisms, samples from the canonical distribution are also required to learn\nthe model. Are the samples from the canonical distribution always available in\npractice? Since the canonical samples are needed for training, this problem \nsetup seems not to be totally ""unsupervised"".\n\n2) The authors only run experiments on the MNIST data, where 1) the mechanisms are\nsimulated and relatively simple, and 2) samples from the canonical distribution\nare also available. Did the authors run experiments on other datasets?\n\n3) This work seems to be related to the work on 1) disentangling factors of\nvariation; and 2) non-linear independent component analysis. Could the authors\nadd discussions to illustrate the difference between the proposed work and\nthose topics?\n\n4) This work is motivated from the objective of causal inference, therefore it\nmight be helpful to add empirical results to show how the proposed method can\nbe used for causal inference.']","[-20, -30, 20]","[60, 20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer finds some aspects of the paper interesting and acknowledges its contributions, they express significant concerns about the limitations of the experimental conditions and suggest that the investigation could be pushed further. The reviewer points out that only one collection of transformations is studied on MNIST digits, which they find restrictive. They also raise questions about the methodology and suggest additional directions for research.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'it is nice to see' and 'I think' to soften criticisms, and they offer constructive suggestions for improvement. The reviewer also acknowledges the positive aspects of the work, such as the convincing Figure 5. However, the score is not extremely high as the review is still direct in its criticisms and doesn't use overly deferential language."", ""The sentiment score is -30 because the reviewer expresses significant concerns about the paper's methodology and results. The main concern is highlighted in the second paragraph, suggesting a fundamental issue with the framework. However, the score is not extremely negative as the reviewer also offers constructive suggestions for improvement. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'My main concern' and 'It would be great to' rather than harsh or dismissive language. The reviewer also acknowledges the authors' own observations, which shows respect. The suggestions are framed as recommendations rather than demands, contributing to the overall polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's achievements and provides constructive feedback. The review begins by summarizing the paper's objectives and methods, indicating engagement with the content. However, the reviewer also raises several questions and suggestions for improvement, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing their comments as questions or suggestions rather than criticisms. The reviewer's tone is professional and constructive, offering specific areas for the authors to consider without being overly critical or dismissive. The use of phrases like 'Could the authors add discussions...' and 'it might be helpful to add...' contribute to the polite tone.""]"
"['TL;DR of paper: they modify the Transformer architecture of Vaswani et al. (2017) to used branched attention with learned weights instead of concatenated attention, and achieve improved results on machine translation.\n\nUsing branches instead of a single path has become a hot architecture choice recently, and this paper applies the branching concept to multi-head attention. Weirdly, they propose using two different sets of weights for each branch: (a) kappa, which premultiplies the head before fully connected layers, and (b) alpha, which are the weights of the sum of the heads after the fully connected layers. Both weights have simplex constraints. A couple of questions about this:\n\n* What is the performance of only using kappa? Only alpha? Neither? What happens if I train only of them?\n* What happens if you remove the simplex constraints (i.e., don\'t have to sum to one, or can be negative)?\n* Why learn a global set of weights for the branch combiners? What happens if the weights are predicted for each input example? This is the MoE experiment, but where k = M (i.e., no discrete choices made).\n* Are the FFN layer parameters shared across the different heads?\n* At the top of page 4, it is said ""all bounds are respected during each training step by projection"". What does this mean? Is projected gradient descent used, or is a softmax used? If the former, why not use a softmax?\n* In Figure 3, it looks like the kappa and alpha values are still changing significantly before they are frozen. What happens if you let them train longer? On the same note, the claim is that Transformer takes longer to train. What is the performance of Transformer if using the same number of steps as the weighted Transformer?\n* What are the Transformer variants A, B, and C?\n\nWhile the results are an improvement over the baseline Transformer, my main concern with this paper is that the improved results are because of extensive hyperparameter tuning. Design choices like having a separate learning rate schedule for the alpha and kappa parameters, and needing to freeze them at the end of training stoke this concern. I\'m happy to change my score if the authors can provide empirical evidence for each design choice', 'This paper describes an extension to the recently introduced Transformer networks which shows better convergence properties and also improves results on standard machine translation benchmarks. \n\nThis is a great paper -- it introduces a relatively simple extension of Transformer networks which only adds very few parameters and speeds up convergence and achieves better results. It would have been good to also add a motivation for doing this (for example, this idea can be interpreted as having a variable number of attention heads which can be blended in and out with a single learned parameter, hence making it easier to use the parameters where they are needed). Also, it would be interesting to see how important the concatenation weight and the addition weight are relative to each other -- do you possibly get the same results even without the concatenation weight? \n\nA suggested improvement: Please check the references in the introduction and see if you can find earlier ones -- for example, language modeling with RNNs has been done for a very long time, not just since 2017 which are the ones you list; similar for speech recognition etc. (which probably has been done since 1993!).\n\nAddition to the original review: Your added additional results table clarifies a lot, thank you. As for general references for RNNs, I am not sure Hochreiter & Schmidhuber 1997 is a good reference as this only points to a particular type of RNN that is used today a lot. For speech recognition there are many better citations as well, check the conference proceedings from ICASSP for papers from Microsoft, Google, IBM, which are the leaders in speech recognition technology. However, I know citations can be difficult to get right for everybody, just try to do your best. ', ""The paper presentes a small extension to the Neural Transformer model of Vaswani et al 2017:\nthe multi-head attention computation (eq. 2,3):\nhead_i = Attention_i(Q,K,W)\nMultiHead = Concat_i(head_i) * W = \\sum_i head_i * W_i\n\nis replaced with the so-called BranchedAttention (eq. 5,6,7,4):\nhead_i = Attention_i(Q,K,W)       // same as in the base model\nBranchedAttention = \\sum_i \\alpha_i max(0, head_i * W_i * kappa_i * W^1 + b^1) W^2 + b^2\n\nThe main difference is that the results of application of each attention head is post-processed with a 2-layer ReLU network before being summed into the aggregated attention vector.\n\nMy main problem with the paper is understanding what really is implemented: the paper states that with alpha_i=1 and kappa_i=1 the two attention mechanism are equivalent. The equations, however, tell a different story: the original MultiHead attention quickly aggregates all attention heads, while the proposed BranchedAttention adds another processing step, effectively adding depth to the model.\n\nSince the BranchedAttention is the key novelty of the paper, I am confused by this contradiction and treat it as a fatal flaw of this paper (I am willing to revise my score if the authors explain the equations) - the proposed attention either adds a small amount of parameters (the alphas and kappas) that can be absorbed by the other weights of the network, and the added alphas and kappas are easier/faster to optimize, as the authors state in the text, or the BranchedAttention works as shown in the equations, and effectively adds depth to the network by processing each attention's result with a small MLP before combining multiple attention heads. This has to be clarified before the paper is published.\n\nThe experiment show that the proposed change speeds convergence and improves the results by about 1 BLEU point. However, this requires a different learning rate schedule for the introduced parameters and some non-standard tricks, such as freezing the alphas and kappas during the end of the training.\n\nI also have a questions about the presented results:\n1) The numbers for the original transformer match the ones in Vaswani et al 2017, am I correct to assume that the authors did not rerun the tensor2tensor code and simply copied them from the paper?\n2) Is all of the experimental setup the same as in Vaswani et al 2017? Are the results obtained using their tensor2tensor implementation, or are some hyperparameters different?\n\nDetailed review:\nQuality:\nThe equations and text in the paper contradict each other.\n\nClarity:\nThe language is clear, but the main contribution could be better explained.\n\nOriginality:\nThe proposed change is a small extension to the Neural Transformer model.\n\nSignificance:\nRather small, the proposed addition adds little modeling power to the network and its advantage may vanish with more data/different learning rate schedule.\n\nPros and cons:\n+ the proposed approach is a simple way to improve the performance of multihead attentional models.\n- it is not clear from the paper how the proposed extension works: does it regularize the model or dies it increase its capacity?""]","[-20, 80, -60]","[50, 70, 20]","['The sentiment score is slightly negative (-20) because while the reviewer acknowledges some improvements over the baseline Transformer, they express significant concerns about the methodology and results. The reviewer questions several design choices, asks for additional experiments, and expresses skepticism about whether the improvements are due to extensive hyperparameter tuning rather than the proposed architecture changes. However, the score is not deeply negative as the reviewer remains open to changing their opinion if the authors can provide more evidence.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns and frame their criticisms as questions or requests for clarification rather than direct attacks. The reviewer also offers the authors an opportunity to address the concerns, indicating a willingness to reconsider their assessment. While not overly effusive or deferential, the language is consistently polite and constructive.', ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'great' and praises its simple yet effective extension of Transformer networks. They highlight the improvements in convergence and results, which indicates a very positive view. The score is not 100 as there are some suggestions for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions. They acknowledge the authors' efforts with phrases like 'thank you' and 'just try to do your best'. The tone is encouraging and helpful, rather than critical. However, it's not 100 as it's a professional review rather than overly deferential."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper, particularly regarding a 'fatal flaw' in the explanation of the key novelty. The reviewer states they are 'confused by this contradiction' and that it 'has to be clarified before the paper is published.' However, the score is not at the extreme negative end because the reviewer acknowledges some positive aspects, such as improved results and faster convergence. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language throughout and offer to revise their score if the authors provide clarification. They also balance their critique with positive points. The language is not overly formal or polite, but it maintains a respectful tone typical of academic peer reviews.""]"
"['The paper proposes a modified approach to RL, where an additional ""episodic memory"" is kept by the agent. What this means is that the agent has a reservoir of n ""states"" in which states encountered in the past can be stored. There are then of course two main questions to address (i) which states should be stored and how (ii) how to make use of the episodic memory when deciding what action to take. \n\nFor the latter question, the authors propose using a ""query network"" that based on the current state, pulls out one state from the memory according to certain probability distribution. This network has many tunable parameters, but the main point is that the policy then can condition on this state drawn from the memory. Intuitively, one can see why this may be advantageous as one gets some information from the past. (As an aside, the authors of course acknowledge that recurrent neural networks have been used for this purpose with varying degrees of success.)\n\nThe first question, had a quite an interesting and cute answer. There is a (non-negative) importance weight associated with each state and a collection of states has weight that is simply the product of the weights. The authors claim (with some degree of mathematical backing) that sampling a memory of n states where the distribution over the subsets of past states of size n is proportional to the product of the weights is desired. And they give a cute online algorithm for this purpose. However, the weights themselves are given by a network and so weights may change (even for states that have been observed in the past). There is no easy way to fix this and for the purpose of sampling the paper simply treats the weights as immutable. \n\nThere is also a toy example created to show that this approach works well compared to the RNN based approaches.\n\nPositives:\n\n- An interesting new idea that has potential to be useful in RL\n- An elegant algorithm to solve at least part of the problem properly (the rest of course relies on standard SGD methods to train the various networks)\n\nNegatives:\n- The math is fudged around quite a bit with approximations that are not always justified\n- While overall the writing is clear, in some places I feel it could be improved. I had a very hard time understanding the set-up of the problem in Figure 2. [In general, I also recommend against using figure captions to describe the setup.]\n- The experiments only demonstrate the superiority of this method on an example chosen artificially to work well with this approach.', ""This paper considers a new way to incorporate episodic memory with shallow-neural-nets RL using reservoir sampling. The authors propose a reservoir sampling algorithm for drawing samples from the memory. Some theoretical guarantees for the efficiency of reservoir sampling are provided. The whole algorithm is tested on a toy problem with 3 repeats. The comparisons between this episodic approach and recurrent neural net with basic GRU memory show the advantage of proposed algorithm.\n\nThe paper is well written and easy to understand. Typos didn't influence reading. It is a novel setup to consider reservoir sampling for episodic memory. The theory part focuses on effectiveness of drawing samples from the reservoir. Physical meanings of Theorem 1 are not well represented. What are the theoretical advantages of using reservoir sampling? \n\nFour simple, shallow neural nets are built as query, write, value, and policy networks. The proposed architecture is only compared with a recurrent baseline with 10-unit GRU network. It is not clear the better performance comes from reservoir sampling or other differences. Moreover, the hyperparameters are not optimized on different architectures. It is hard to justify the empirically better performance without hyperparameter tuning. The authors mentioned that the experiments are done on a toy problem, only three repeats for each experiment. The technically soundness of this work is weakened by the experiments.\n"", 'This paper proposes one RL architecture using external memory for previous states, with the purpose of solving the non-markov tasks. The essential problems here are how to identify which states should be stored and how to retrieve memory during action prediction. The proposed architecture could identify the ‘key’ states through assigning higher weights for important states, and applied reservoir sampling to control write and read on memory. The weight assigning (write) network is optimized for maximize the expected rewards. This article focuses on the calculation of gradient for write network, and provides some mathematical clues for that.\n\nThis article compares their proposed architecture with RNN (GRU with 10 hidden unit) in few toy tasks. They demonstrate that proposed model could work better and rational of write network could be observed. However, it seems that hyper-parameters for RNN haven’t been tuned enough. It is because the toy task author demonstrates is actually quite similar to copy tasks, that previous state should be remembered. To my knowledge, copy task could be solved easily for super long sequence through RNN model. Therefore, empirically, it is really hard to justify whether this proposed method could work better. Also, intuitively, this episodic memory method should work better on long-term dependencies task, while this article only shows the task with 10 timesteps. \n\nAccording to that, the experiments they demonstrated in this article are not well designed so that the conclusion they made in this article is not robust enough. ']","[50, -20, -30]","[70, 50, 20]","[""The sentiment score is 50 (slightly positive) because the review acknowledges both positives and negatives of the paper. The reviewer praises the 'interesting new idea' and 'elegant algorithm', but also points out issues with the math and experiments. The overall tone is constructive rather than overly critical. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the authors' work and using phrases like 'interesting' and 'elegant'. The critique is presented in a professional manner without harsh or rude language. The reviewer also uses phrases like 'I feel' and 'I recommend' to soften suggestions, which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'easy to understand', 'novel setup'), they express significant concerns about the theoretical justification and experimental rigor. The reviewer points out weaknesses in the theoretical explanations and experimental design, which outweigh the positive comments.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They begin with positive observations and phrase criticisms as constructive suggestions or questions rather than harsh judgments. The tone remains objective and focused on the content of the paper rather than personal attacks.\n\nThe reviewer balances positive and negative feedback, maintaining a professional tone while clearly communicating areas for improvement. This approach is generally considered polite in academic peer review, even when providing critical feedback."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'demonstrate that proposed model could work better'), they express significant concerns about the experimental design and robustness of conclusions. The overall tone is more critical than positive. The politeness score is 20 because the reviewer uses neutral, professional language without harsh criticism. They offer constructive feedback and use phrases like 'it seems that' and 'to my knowledge' which soften their critiques. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a mostly neutral, professional tone.""]"
"['This paper proposes a particular form of variational RNN that uses a forward likelihood and a backwards posterior.  Additional regularization terms are also added to encourage the model to encode longer term dependencies in its latent distributions.\n\nMy first concern with this paper is that the derivation in Eq. 1 does not seem to be correct.  There is a p(z_1:T) term that should appear in the integrand.\n\nIt is not clear to me why h_t should depend on \\tilde{b}_t.  All paths from input to output through \\tilde{b}_t also pass through z_t so I don\'t see how this could be adding information.  It may add capacity to the decoder in the form of extra weights, but the same could be achieved by making z_t larger. Why not treat \\tilde{b}_t symmetrically to \\tilde{h}_t, and use it only as a regularizer?  \n\nIn the no reconstruction loss experiments do you still sample \\tilde{b}_t in the generative part?  Baselines where the \\tilde{b}_t -> h_t edge is removed would be very nice.\n\nIt seems the Blizzard results in Figure 2 are missing no reconstruction loss + full backprop.\n\nI don\'t understand the description of the ""Skip Gradient"" trick.  Exactly which gradients are you skipping at random?\n\nDo you have any intuition for why it is sometimes necessary to set beta=0?\n', ""This paper builds a sequential deep generative model with (1) an inference network parameterized by an RNN running from the future to the past and (2) an explicit representation of the hidden state of the backward RNN in the generative model. The model is validated on held-out likelihood via the ELBO on text, handwriting, speech and images. It presents good emprical results and works at par with or better than many other baselines considered.\n\nThe main source of novelty here the choice made in the transition function of z_t to also incorporate an explicit variable to models the hidden state of the backward RNN at inference time and use that random variable in the generative process. This is a choice of structural prior for the transition function of the generative model that I think lends it more expressivity realizing the empirical gains obtained.\n\nI found the presentation of both the model and learning objective to be confusing and had a hard time following it. The source of my confusion is is that \\tilde{b} (the following argument applies equivalently to \\tilde{h}) is argued to be a latent variable. Yet it is not inferred (via a variational distribution) during training.\n\nPlease correct me if I'm wrong but I believe that an easier to understand way to explain the model is as follows: both \\tilde{b} and \\tilde{h} should be presented as *observed* random variables during *training* and latent at inference time. Training then comprises maximizing the marginal likelihood of the data *and* maximizing the conditional likelihood of the two observed variables(via p_psi and p_eta; conditioned on z_t). Under this view, setting beta to 0 simply corresponds to not observing \\tilde{h_t}. alpha can be annealed but should never be set to anything less than 1 without breaking the semantics of the learned generative model.\n\nConsider Figure 1(b). It seems that the core difference between this work and [Chung et. al] is that this work parameterizes q(Z_t) using x_t....x_T (via a backward RNN). This choice of inference network can be motivated from the point of view of building a better approximation to the structure of the posterior distribution of Z_t under the generative model. Both [Fracarro et. al] and [Krishnan et. al] (https://arxiv.org/pdf/1609.09869.pdf) use RNNs from x_T to x_1 to train sequential state space models. [Gao et. al] (https://arxiv.org/pdf/1605.08454.pdf) derive an inference network with a block-diagonal structure motivated by correlations in the posterior distribution. Incorporating a discussion around this idea would provide useful context for where this work stands amongst the many sequential deep generative models in the\nliterature.\n\nQuestions for the authors:\n* How important is modeling \\tilde{h_t} in TIMIT, Blizzard and IMDB?\n* Did you try annealing the KL divergence in the PTB experiment. Based on the KL divergence you report it seems the latent variable is not necessary.\n\nOverall, I find the model to be interesting and it performs well empirically. However, the text of the paper lacks a bit of context and clarity that makes understanding it challenging to understand in its current form."", '*Quality*\n\nThe paper is easy to parse, with clear diagrams and derivations at the start. The problem context is clearly stated, as is the proposed model.\n\nThe improvements in terms of average log-likelihood are clear. The model does improve over state-of-the-art in some cases, but not all.\n\nBased on the presented findings, it is difficult to determine the quality of the learned models overall, since they are only evaluated in terms of average log likelihood. It is also difficult to determine whether the improvements are due to the model change, or some difference in how the models themselves were trained (particularly in the case of Z-Forcing, a closely related technique). I would like to see more exploration of this point, as the section titled “ablation studies” is short and does not sufficiently address the issue of what component of the model is contributing to the observed improvements in average log-likelihood.\n\nHence, I have assigned a score of ""4"" for the following reasons: the quality of the generated models is unclear; the paper does not clearly distinguish itself from the closely-related Z-Forcing concept (published at NIPS 2017); and the reasons for the improvements shown in average log-likelihood are not explored sufficiently, that is, the ablation studies don\'t eliminate key parts of the model that could provide this information.\n\nMore information on this decision is given in the remainder.\n\n*Clarity*\n\nA lack of generated samples in the Experimental Results section makes it difficult to evaluate the performance of the models; log-likelihood alone can be an inadequate measure of performance without some care in how it is calculated and interpreted (refer, e.g., to Theis et al. 2016, “A Note on the Evaluation of Generative Models”).\n\nThere are some typos and organizational issues. For example, VAEs are reintroduced in the Related Works section, only to provide an explanation for an unrelated optimization challenge with the use of RNNs as encoders and decoders.\n\nI also find the motivations for the proposed model itself a little unclear. It seems unnatural to introduce a side-channel-cum-regularizer between a sequence moving forward in time and the same sequence moving backwards, through a variational distribution. In the introduction, improved regularization for LSTM models is cited as a primary motivation for introducing and learning two approximate distributions for latent variables between the forward and backward paths of a bi-LSTM. Is there a serious need for new regularization in such models? The need for this particular regularization choice is not particularly clear based on this explanation, nor are the improvements state-of-the-art in all cases. This weakens a possible theoretical contribution of the paper.\n\n*Originality*\n\nThe proposed modification appears to amount to a regularizer for bi-LSTMs which bears close similarity to Z-Forcing (cited in the paper). I recommend a more careful comparison between the two methods. Without such a comparison, they are a little hard to distinguish, and the originality of this paper is hard to evaluate. Both appear to employ the same core idea of regularizing an LSTM using a learned variational distributions. The differences *seem* to be in the small details, and these details appear to provide better performance in terms of average log-likelihood on all tasks compared to Z-Forcing--but, crucially, not compared to other models in all cases.']","[-20, 20, -40]","[50, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's proposal, they express several concerns and questions about the methodology and results. The review points out potential errors in derivations, questions the model's design choices, and notes missing information in the results. However, the tone is not entirely negative, as the reviewer also suggests improvements and asks for clarifications, indicating engagement with the work. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout. They phrase their concerns as questions or suggestions rather than direct criticisms, using phrases like 'It is not clear to me why...' and 'Do you have any intuition for...'. This approach maintains a constructive tone while still addressing the paper's weaknesses."", ""The sentiment score is slightly positive (20) because while the reviewer finds the model interesting and acknowledges its good empirical results, they also express confusion about the presentation and suggest improvements. The overall tone is constructive but with reservations. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions, and acknowledges the paper's strengths. They use phrases like 'Please correct me if I'm wrong' and 'I found the presentation... confusing' rather than making blunt criticisms. The reviewer also offers detailed feedback and suggestions for improvement, which is a polite and constructive approach to peer review."", ""The sentiment score is -40 because the reviewer expresses several significant concerns about the paper, including unclear quality of the learned models, insufficient differentiation from related work, and inadequate exploration of reasons for improvements. However, they do note some positive aspects like clear diagrams and improvements in log-likelihood for some cases. The politeness score is 50 because the reviewer uses professional and constructive language throughout, offering specific suggestions for improvement without harsh criticism. They maintain a respectful tone while clearly communicating their concerns, balancing critique with acknowledgment of the paper's strengths.""]"
"['Summary:\n\nThis paper presents a derivation which links a DNN to recursive application of\nmaximum entropy model fitting. The mathematical notation is unclear, and in\none cases the lemmas are circular (i.e. two lemmas each assume the other is\ncorrect for their proof). Additionally the main theorem requires complete\nindependence, but the second theorem provides pairwise independence, and the\ntwo are not the same.\n\nMajor comments:\n\n- The second condition of the maximum entropy equivalence theorem requires\n  that all T are conditionally independent of Y. This statement is unclear, as\nit could mean pairwise independence, or it could mean jointly independent\n(i.e. for all pairs of non-overlapping subsets A & B of T I(T_A;T_B|Y) = 0).\nThis is the same as saying the mapping X->T is making each dimension of T\northogonal, as otherwise it would introduce correlations. The proof of the\ntheorem assumes that pairwise independence induces joint independence and this\nis not correct.\n\n- Section 4.1 makes an analogy to EM, but gradient descent is not like this\n  process as all the parameters are updated at once, and only optimised by a\nsingle (noisy) step. The optimisation with respect to a single layer is\nconditional on all the other layers remaining fixed, but the gradient\ninformation is stale (as it knows about the previous step of the parameters in\nthe layer above). This means that gradient descent does all 1..L steps in\nparallel, and this is different to the definition given.\n\n- The proofs in Appendix C which are used for the statement I(T_i;T_j) >=\n  I(T_i;T_j|Y) are incomplete, and in generate this statement is not true, so\nrequires proof.\n\n- Lemma 1 appears to assume Lemma 2, and Lemma 2 appears to assume Lemma 1.\n  Either these lemmas are circular or the derivations of both of them are\nunclear.\n\n- In Lemma 3 what is the minimum taken over for the left hand side? Elsewhere\n  the minimum is taken over T, but T does not appear on the left hand side.\nExplicit minimums help the reader to follow the logic, and implicit ones\nshould only be used when it is obvious what the minimum is over.\n\n- In Lemma 5, what does ""T is only related to X"" mean? The proof states that\n  Y -> T -> X forms a Markov chain, but this implies that T is a function of\nY, not X.\n\nMinor comments:\n\n- I assume that the E_{P(X,Y)} notation is the expectation of that probability\n  distribution, but this notation is uncommon, and should be replaced with a\nmore explicit one.\n\n- Markov is usually romanized with a ""k"" not a ""c"".\n\n- The paper is missing numerous prepositions and articles, and contains\n  multiple spelling mistakes & typos.', 'The paper aims to provide a view of deep learning from the perspective of maximum entropy principle.  I found the paper extremely hard to follow and seemingly incorrect in places.  Specifically:\na) In Section 2, the example given to illustrate underfitting and overfitting states that the 5-order polynomial obviously overfits the data.  However, without looking at the test data and ensuring the fact that it indeed was not generated by a 5-order polynomial, I don’t see how such a claim can be made.\nb) In Section 2 the authors state “Imposing extra data hypothesis actually violates the ME principle and degrades the model to non-ME model.” … Statements like this need to be made much clearer, since imposing feature expectation constraints (such as Eq. (3) in Berger et al. 1996) is a perfectly legitimate construct in ME principle.\nc) The opening paragraph of Section 3 is quite unclear; phrases like “how to identify the equivalent feature constraints and simple models” need to be made precise, it is not clear to me what authors mean by this.\nd) I’m not able to really follow Definition 1, perhaps due to unclear notation.  It seems to state that we need to have P(X,Y) = P(X,\\hat{Y}), and if that’s the case not clear what more can be accomplished by maximizing conditional entropy H(\\hat{Y}|X).  Also, there is a spurious w_i in Definition 1.\ne) Definition 2.  Not clear what is meant by notation E_{P(T,Y)}.\nf) Definition 3 uses t_i(x) without defining those, and I think those are different from t_i(x) defined in Definition 2.\n\nI think the paper needs to be substantially revised and clarified before it can be published at ICLR.', 'The presentation of the paper is crisp and clear. The problem formulation is explained clearly and it is well motivated by theorems. It is a theoretical papers and there is no experimental section. This is the only drawback for the paper as the claims is not supported by any experimental section. The author could add some experiments to support the idea presented in the paper.']","[-60, -80, 50]","[20, -20, 75]","[""The sentiment score is -60 because the review is predominantly critical, pointing out several major issues with the paper, including unclear mathematical notation, circular lemmas, and incomplete proofs. The reviewer uses phrases like 'unclear', 'not correct', and 'incomplete', indicating significant concerns. However, it's not entirely negative as the reviewer does provide constructive feedback and suggestions for improvement. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use neutral language like 'this statement is unclear' rather than more harsh phrasing. The reviewer also provides both major and minor comments, showing a thorough and considerate approach. The use of phrases like 'I assume that...' shows a degree of politeness by not being overly presumptive."", ""The sentiment score is -80 because the reviewer expresses strong negative opinions about the paper, stating it's 'extremely hard to follow and seemingly incorrect in places.' They list multiple specific issues and conclude that the paper needs 'substantial revision' before publication. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite critical and direct. They use phrases like 'seemingly incorrect' and 'not clear what more can be accomplished,' which come across as somewhat dismissive. The reviewer doesn't soften their criticisms or offer much positive feedback, which contributes to the slightly impolite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer starts with positive comments about the paper's presentation, clarity, and theoretical foundation. However, they also point out a drawback regarding the lack of experimental support, which balances out the overall sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before suggesting improvements. They phrase their criticism constructively, using phrases like 'The author could add' rather than making demands. The tone is professional and courteous throughout the review.""]"
"['This paper presents a new idea to use PACT to quantize networks, and showed improved compression and comparable accuracy to the original network. The idea is interesting and novel that PACT has not been applied to compressing networks in the past. The results from this paper is also promising that it showed convincing compression results. \n\nThe experiments in this paper is also solid and has done extensive experiments on state of the art datasets and networks. Results look promising too.\n\nOverall the paper is a descent one, but with limited novelty. I am a weak reject', 'The parameterized clipping activation (PACT) idea is very clear: extend clipping activation by learning the clipping parameter. Then,  PACT is combined with quantizing the activations. \n\nThe proposed technique sounds. The performance improvement is expected and validated by experiments. \n\nBut I am not sure if the novelty is strong enough for an ICLR paper. \n', 'The authors have addressed my concerns, and clarified a misunderstanding of the baseline that I had, which I appreciate. I do think that it is a solid contribution with thorough experiments. I still keep my original rating of the paper because the method presented is heavily based on previous works, which limits the novelty of the paper. It uses previously proposed clipping activation function for quantization of neural networks, adding a learnable parameter to this function. \n_______________\nORIGINAL REVIEW:\n\nThis paper proposes to use a clipping activation function as a replacement of ReLu to train a neural network with quantized weights and activations. It shows empirically that even though the clipping activation function obtains a larger training error for full-precision model, it maintains the same error when applying quantization, whereas training with quantized ReLu activation function does not work in practice because it is unbounded.\n\nThe experiments are thorough, and report results on many datasets, showing that PACT can reduce down to 4 bits of quantization of weights and activation with a slight loss in accuracy compared to the full-precision model. \nRelated to that, it seams a bit an over claim to state that the accuracy decrease of quantizing the DNN with PACT in comparison with previous quantization methods is much less because the decrease is smaller or equal than 1%, when competing methods accuracy decrease compared to the full-precision model is more than 1%. Also, it is unfair to compare to the full-precision model using clipping, because ReLu activation function in full-precision is the standard and gives much better results, and this should be the reference accuracy. Also, previous methods take as reference the model with ReLu activation function, so it could be that in absolute value the accuracy performance of competing methods is actually higher than when using PACT for quantizing DNN.\n\nOTHER COMMENTS:\n\n- the list of contributions is a bit strange. It seams that the true contribution is number 1 on the list, which is to introduce the parameter \\alpha in the activation function that is learned with back-propagation, which reduces the quantization error with respect to using ReLu as activation function. To provide an analysis of why it works and quantitative results, is part of the same contribution I would say.']","[-20, -20, 50]","[50, 50, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting idea, solid experiments, and promising results, they ultimately give a 'weak reject' recommendation. The positive aspects are outweighed by the 'limited novelty' critique and final rejection. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering criticism. They describe the paper as 'descent' (likely meant 'decent') and use phrases like 'interesting and novel' and 'promising'. The critique is delivered gently, avoiding harsh language. However, it's not extremely polite, as it doesn't go out of its way to soften the rejection or offer extensive encouragement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the clarity and soundness of the proposed technique, they express doubt about its novelty for an ICLR paper. This reservation outweighs the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the merits of the work before expressing concerns. They avoid harsh criticism and use phrases like 'I am not sure' to soften their doubts, maintaining a professional and courteous tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges that the authors have addressed their concerns and considers the paper a 'solid contribution with thorough experiments'. However, they maintain their original rating due to limited novelty. The politeness score is 70 (fairly polite) as the reviewer uses respectful language, appreciates the authors' clarifications, and provides constructive feedback. They use phrases like 'I appreciate' and 'I do think', which contribute to a polite tone. The reviewer also offers detailed explanations for their critiques, which is a courteous approach in academic discourse.""]"
"['This paper presents a lifelong learning method for learning word embeddings.  Given a new domain of interest, the method leverages previously seen domains in order to hopefully generate better embeddings compared to ones computed over just the new domain, or standard pre-trained embeddings.\n\nThe general problem space here -- how to leverage embeddings across several domains in order to improve performance in a given domain -- is important and relevant to ICLR.  However, this submission needs to be improved in terms of clarity and its experiments.\n\nIn terms of clarity, the paper has a large number of typos (I list a few at the end of this review) and more significantly, at several points in the paper is hard to tell what exactly was done and why.  When presenting algorithms, starting with an English description of the high-level goal and steps of the algorithm would be helpful.  What are the inputs and outputs of the meta-learner, and how will it be used to obtain embeddings for the new domain?  The paper states the purpose of the meta learning is ""to learn a general word context similarity from the first m domains"", but I was never sure what this meant.  Further, some of the paper\'s pseudocode includes unexplained steps like ""invert by domain index"" and ""scanco-occurrence"".  \n\nIn terms of the experiments, the paper is missing some important baselines that would help us understand how well the approach works.  First, besides the GloVe common crawl embeddings used here, there are several other embedding sets (including the other GloVe embeddings released along with the ones used here, and the Google News word2vec embeddings) that should be considered.  Also, the paper never considers concatenations of large pre-trained embedding sets with each other and/or with the new domain corpus -- such concatenations often give a big boost to accuracy, see :\n""Think Globally, Embed Locally—Locally Linear Meta-embedding of Words"", Bollegala et al., 2017\nhttps://arxiv.org/pdf/1709.06671.pdf\n\nThat paper is not peer reviewed to my knowledge so it is not necessary to compare against the new methods introduced there, but their baselines of concatenation of pre-trained embedding sets should be compared against in the submission.\n\nBeyond trying other embeddings, the paper should also compare against simpler combination approaches, including simpler variants of its own approach.  What if we just selected the one past domain that was most similar to the new domain, by some measure?  And how does the performance of the technique depend on the setting of m?  Investigating some of these questions would help us understand how well the approach works and in which settings.\n\nMinor:\n\nSecond paragraph, GloVec should be GloVe\n\n""given many domains with uncertain noise for the new domain"" -- not clear what ""uncertain noise"" means, perhaps ""uncertain relevance"" would be more clear\n\nThe text refers to a Figure 3 which does not exist, probably means Figure 2.  I didn\'t understand the need for both figures, Figure 1 is almost contained within Figure 2\n\nWhen m is introduced, it would help to say that m < n and justify why dividing the n domains into two chunks (of m and n-m domains) is necessary.\n\n""from the first m domain corpus"" -> ""from the first m domains""?\n\n""may not helpful"" -> ""may not be helpful""\n\n""vocabularie"" -> ""vocabulary""\n\n""system first retrieval"" -> ""system first retrieves""\n\nCOMMENTS ON REVISIONS: I appreciate the authors including the new experiments against concatenation baselines.  The concatenation does fairly comparably to LL in Tables 3&4.  LL wins by a bit more in Table 2.  Given these somewhat close/inconsistent wins, it would help the paper to include an explanation of why and under what conditions the LL approach will outperform concatenation.', 'In this paper, the authors proposed to learn word embedding for the target domain in the lifelong learning manner. The basic idea is to learn a so-call meter learner to measure similarities of the same words between the target domain and the source domains for help learning word embedding for the target domain with a small corpus. \n\nOverall, the descriptions of the proposed model (Section 3 - Section 5) are hard to follow. This is not because the proposed model is technically difficult to understand. On the contrary, the model is heuristic, and simple, but the descriptions are unclear. Section 3 is supposed to give an overview and high-level introduction of the whole model using the Figure 1, and Figure 2 (not Figure 3 mentioned in text). However, after reading Section 3, I do not catch any useful information about the proposed model expect for knowing that a so-called meta learner is used. Section 4 and  Section 5 are supposed to give details of different components of the proposed model and explain the motivations. However, descriptions in these two sections are very confusing, e.g, many symbols in Algorithm 1 are presented with any descriptions. Moreover, the motivations behind the proposed methods for different components are missing.  Also, a lot of types make the descriptions more difficult to follow, e.g., ""may not helpful or even harmful"", \'""Figure 3"", ""we show this Section 6"", ""large size a vocabulary"", etc.\n\nAnother major concern is that the technical contributions of the proposed model is quite limited. The only technical contributions are (4) and the way to construct the co-occurrence information A. However, such contributions are quite minor, and technically heuristic. Moreover, regarding the aggregation layer in the pairwise network, it is similar to feature engineering. In this case, why not just train a flat classifier, like logistic regression, with rich feature engineering, in stead of using a neural network.\n\nRegarding experiments, one straight-forward baseline is missing. As n domains are supposed to be given in advance before the n+1 domain (target domain) comes, one can use multi-domain learning approaches with ensemble learning techniques to learn word embedding for the target domain. For instance, one can learn n pairwise (1 out of n sources + the target) cross-domain word embedding, and combine them using the similarity between each source and the target as the weight.', 'Summary:\nThis paper proposes an approach to learn embeddings in new domains by leveraging the embeddings from other domains in an incremental fashion. The proposed approach will be useful when the new domain does not have enough data available. The baselines chosen are 1). no embeddings 2). generic embeddings from english wiki, common crawl and combining data from previous and new domains. Empirical performance is shown on 3 downstream tasks: Product-type classification, Sentiment Classification and Aspect Extraction. The proposed embeddings just barely beat the baseline on product classification and sentiment classification, but significantly beat them on aspect extraction task.\n\n\nComments:\n\nThe paper puts itself nicely in context of the previous work and the addressed problem of learning word embeddings for new domain in the absence of enough data is an important one that needs to be addressed. There is reasonable novelty in the proposed method compared to the existing literature. But, I was a little disappointed by the paper as several details of the model were unclear to me and the paper\'s writing could definitely be improved to make things clearer. \n\n1). In the ""Meta-learner"" section 4.1, the authors talk about word features (u{_w_{i,j,k}},u{_w_{i,j\',k}}). It is unclear what these word features are. Are they one-hot encodings or embeddings or something else? It would really help if the paper gave some expository examples.\n\n2). In Algorithm 1, how do you deal with vocabulary items in the new domain that do not exist in the previous domains i.e. when the intersection of V_i and V_{n+1} is the null set. This is very important because the main appeal of this work is its applicability to new domains with scarce data which have far fewer words and hence the above scenario is more likely to happen.\n\n3). The results in Table 3 are a little confusing. Why do the lifelong word embeddings relatively perform far worse on precision but significantly better on recall compared to the baselines? What is driving those difference in results?\n\n4). Typos: In Section 3, ""...is depicted in Figure 1 and Figure 3"". I think you mean ""Figure 1 and Figure 2"" as there is no Figure 3. \n']","[-20, -70, -20]","[60, -20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem space, they express several concerns about the paper's clarity and experiments. The reviewer states that the submission 'needs to be improved' and lists multiple issues, including typos, unclear explanations, and missing baselines. However, the score is not deeply negative as the reviewer sees potential in the work and offers constructive feedback. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers specific suggestions for improvement, and acknowledges the authors' efforts in the revision comments. The reviewer balances critique with positive remarks and uses phrases like 'it would help' and 'I appreciate' which contribute to a polite tone."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses major concerns about the paper's clarity, technical contributions, and experimental design. They state that the descriptions are 'hard to follow', 'unclear', and 'very confusing'. They also mention that the technical contributions are 'quite limited' and 'minor'. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical without much attempt to soften the blow. They use phrases like 'major concern' and directly state negative opinions without much hedging or politeness. However, they do use some neutral language and provide specific suggestions for improvement, which prevents the score from being lower."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem and some novelty in the approach, they express disappointment with the clarity of the paper and point out several issues. The reviewer states they were 'a little disappointed' and that 'several details of the model were unclear'. However, they do mention some positive aspects, which prevents the score from being more negative.\n\nThe politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They begin with positive comments about the paper's context and relevance, and phrase their criticisms as suggestions or questions rather than direct attacks. For example, they use phrases like 'It would really help if...' and 'Why do...?' The reviewer also points out a typo in a neutral manner. The language is consistently respectful and aimed at improving the paper rather than criticizing the authors.""]"
"['This paper extends the idea of forming an unsupervised representation of sentences used in the SkipThought approach by using a broader set of evidence for forming the representation of a sentence. Rather than simply encoding the preceding sentence and then generating the next sentence, the model suggests that a whole bunch of related ""sentences"" could be encoded, including document title, section title, footnotes, hyperlinked sentences. This is a valid good idea and indeed improves results. The other main new and potentially useful idea is a new idea for handling OOVs in this context where they are represented by positional placeholder variables. This also seems helpful. The paper is able to show markedly better results on paraphrase detection that skipthought and some interesting and perhaps good results on domain-specific coreference resolution.\n\nOn the negative side, the model of the paper isn\'t very excitingly different. It\'s a fairly straightforward extension of the earlier SkipThought model to a situation where you have multiple generators of related text. There isn\'t a clear evaluation that shows the utility of the added OOV Handler, since the results with and without that handling aren\'t comparable. The OOV Handler is also related to positional encoding ideas that have been used in NMT but aren\'t reference. And the coreference experiment isn\'t that clearly described nor necessarily that meaningful. Finally, the finding of dependencies between sentences for the multiple generators is done in a rule-based fashion, which is okay and works, but not super neural and exciting.\n\nOther comments:\n - p.3. Another related sentence you could possibly use is first sentence of paragraph related to all other sentences? (Works if people write paragraphs with a ""topic sentence"" at the beginning.\n - p.5. Notation seemed a bit non-standard. I thought most people use \\sigma for a sigmoid (makes sense, right?), whereas you use it for a softmax and use calligraphic S for a sigmoid....\n - p.5. Section 5 suggests the standard way to do OOVs is to average all word vectors. That\'s one well-know way, but hardly the only way. A trained UNK encoding and use of things like character-level encoders is also quite common.\n - p.6. The basic idea of the OOV encoder seems a good one. In domain specific contexts, you want to be able to refer to and re-use words that appear in related sentences, since they are likely to appear again and you want to be able to generate them. A weakness of this section however is that it makes no reference to related work whatsoever. It seems like there\'s quite a bit of related work. The idea of using a positional encoding so that you can generate rare words by position has previously been used in NMT, e.g. Luong et al. (Google brain) (ACL 2015). More generally, a now quite common way to handle this problem is to use ""pointing"" or ""copying"", which appears in a number of papers. (e.g., Vinyals et al. 2015) and might also have been used here and might be expected to work too. \n - p.7. Why such an old Wikipedia dump? Most people use a more recent one!\n - p.7. The paraphrase results seem good and prove the idea works. It\'s a shame they don\'t let you see the usefulness of the OOV model.\n - p.8. For various reasons, the coreference results seem less useful than they could have been, but they do show some value for the technique in the area of domain-specific coreference.\n\n', '1) This paper proposes a method for learning the sentence representations with sentences dependencies information. It is more like a dependency-based version skip-thought on the sentence level. The idea is interesting to me, but I think this paper still needs some improvements. The introduction and related work part are clear with strong motivations to me. But section 4 and 6 need a lot of details. \n\n2) My comments are as follows:\ni) this paper claims that this is a general sentence embedding method, however, from what has been described in section 3, I think this dependency is only defined in HTML format document. What if I only have pure text document without these HTML structure information? So I suggest the authors do not claim that this method is a ""general-purpose"" sentence embedding model.\n\nii) The authors do not have any descriptions for Figure 3.  Equation 1 is also very confusing.\n\niii) The experiments are insufficient in terms of details. How is the loss calculated? How is the detection accuracy calculated?\n', 'This paper presents simple but useful ideas for improving sentence embedding by drawing from more context. The authors build on the skip thought model where a sentence is predicted conditioned on the previous sentence; they posit that one can obtain more information about a sentence from other ""governing"" sentences in the document such as the title of the document, sentences based on HTML, sentences from table of contents, etc. The way I understand it, previous sentence like in SkipThought provides more local and discourse context for a sentence whereas other governing sentences provide more semantic and global context.\n\nHere are the pros of this paper:\n1) Useful contribution in terms of using broader context for embedding a sentence.\n2) Novel and simple ""trick"" for generating OOV words by mapping them to ""local"" variables and generating those variables.\n3) Outperforms SkipThought in evals.\n\nCons:\n1) Coreference eval: No details are provided for how the data was annotated for the coreference task. This is crucial to understanding the reliability of the evaluation as this is a new domain for coreference. Also, the authors should make this dataset available for replicability. Also, why have the authors not used this embedding for eval on standard coreference datasets like OntoNotes. Please clarify.\n2) It is not clear to me how the model learns to generate specific OOV variables. Can the authors clarify how does the decoder learns to generate these words.\n\nClarifications:\n1) In section 6.1, what is the performance of skip-thought with the same OOV trick as this paper?\n2) What is the exact heuristic in ""Text Styles"" in section 3.1? Should be stated for replicability.']","[20, -20, 60]","[50, 50, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's valid ideas and improvements over previous work, particularly in the first paragraph. However, the second paragraph introduces several criticisms, which balance out the positive aspects. The overall tone remains constructive rather than overtly negative. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'This is a valid good idea' and 'The paper is able to show markedly better results,' which are encouraging. Even when presenting criticisms, the language remains objective and constructive, avoiding harsh or rude expressions. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the idea interesting, they state that the paper 'needs some improvements' and point out several areas that require more details or clarification. This indicates a generally constructive but somewhat critical view. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, such as 'I think' and 'I suggest', and frames their criticisms as suggestions rather than harsh judgments. They also begin by acknowledging the interesting aspects of the paper before moving on to their concerns, which is a polite approach to reviewing."", ""The sentiment score is 60 (positive) because the reviewer starts by describing the paper as presenting 'simple but useful ideas' and lists several pros, including 'useful contribution' and 'novel and simple trick'. The reviewer also mentions that the paper 'outperforms SkipThought in evals'. While there are some cons and requests for clarification, these are presented as constructive feedback rather than major criticisms. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing criticisms as requests for clarification or additional information (e.g., 'Can the authors clarify...', 'Please clarify.'). The reviewer also acknowledges the positive aspects of the paper before presenting areas for improvement, which is a polite approach to peer review.""]"
"['This paper proposes  a natural extension of the CycleGAN approach. This is achieved by leveraging the feature and semantic losses to achieve a more realistic image reconstruction. The experiments show that including these additional losses is critical for improving the models performance.  The paper is very well written and technical details are well described and motivated. It would be good to identify the cases where the model fails and comment on those. For instance, what if the source data cannot be well reconstructed from adapted target data? What are the bounds of the domain discrepancy in this case? ', ""This paper essentially uses CycleGANs for Domain Adaptation. My biggest concern is that it doesn't adequately compare to similar papers that perform adaptation at the pixel level (eg. Shrivastava et al-'Learning from Simulated and Unsupervised Images through Adversarial Training' and Bousmalis et al - 'Unsupervised Pixel-level Domain Adaptation with GANs', two similar papers published in CVPR 2017 -the first one was even a best paper- and available on arXiv since December 2016-before CycleGANs). I believe the authors should have at least done an ablation study to see if the cycle-consistency loss truly makes a difference on top of these works-that would be the biggest selling point of this paper. The experimental section had many experiments, which is great. However I think for semantic segmentation it would be very interesting to see whether using the adapted synthetic GTA5 samples would improve the SOTA on Cityscapes. It wouldn't be unsupervised domain adaptation, but it would be very impactful. Finally I'm not sure the oracle (train on target) mIoU on Table 2 is SOTA, and I believe the proposed model's performance is really far from SOTA.\n\nPros:\n* CycleGANs for domain adaptation! Great idea!\n* I really like the work on semantic segmentation, I think this is a very important direction\n\nCons:\n* I don't think Domain separation networks is a pixel-level transformation-that's a feature-level transformation, you probably mean to use Bousmalis et al. 2017. Also Shrivastava et al is missing from the image-level papers.\n* the authors claim that Bousmalis et al, Liu & Tuzel and Shrivastava et al ahve only been shown to work for small image sizes. There's a recent work by Bousmalis et al. (Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping) that shows these methods working well (w/o cycle-consistency) for settings similar to semantic segmentation at a relatively high resolution. Also it was mentioned that these methods do not necessarily preserve content, when pixel-da explicitly accounts for that with a task loss (identical to the semantic loss used in this submission)\n* The authors talk about the content similarity loss on the foreground in Bousmalis et al. 2017, but they could compare to this method w/o using the content similarity or using a different content similarity tailored to the semantic segmentation tasks, which would be trivial.\n* Math seems wrong in (4) and (6). (4) should be probably have a minus instead of a plus. (6) has an argmin of a min, not sure what is being optimized here. In fact, I'm not sure if eg you use the gradients of f_T for training the generators?\n* The authors mention that the pixel-da approach cross validates with some labeled data. Although I agree that is not an ideal validation, I'm not sure if it's equivalent or not the authors' validation setting, as they don't describe what that is.\n* The authors present the semantic loss as novel, however this is the task loss proposed by the pixel-da paper.\n* I didn't understand what pixel-only and feat-only meant in tables 2, 3, 4. I couldn't find an explanation in captions or in text\n\n\n=====\nPost rebuttal comments:\nThanks for adding content in response to my comments. The cycle ablation is still a sticky point for me, and I'm still left not sure if cycle-consistency really offers an improvement. Although I applaud your offering examples of failures for when there's no cycle-consistency, these are circumstantial and not quantitative.  The reader is still left wondering why and when is the cycle-consistency loss is appropriate. As this is the main novelty, I believe this should be in the forefront of the experimental evaluation. "", 'This paper proposed a domain adaptation approach by extending the CycleGAN with 1) task specific loss functions and 2) loss imposed over both pixels and features. Experiments on digit recognition and semantic segmentation verify the effectiveness of the proposed method.\n\nStrengths:\n+ It is a natural and intuitive application of CycleGAN to domain adaptation. \n+ Some of the implementation techniques may be useful for the future use of CycleGAN or GAN in other applications, e.g., the regularization over both pixels and features, etc.\n+ The experimental results are superior over the past.\n+ The translated images in Figure 6 are amazing. Could the authors show more examples and include some failure cases (if any)?\n\nWeaknesses:\n- The presentation of the paper could be improved. I do not think I can reproduce the experimental results after reading the paper more than twice. Many details are missing and some parts are confusing or even misleading.  As below, I highlight a few points and the authors are referred to the comments by Cedric Nugteren for more suggestions.\n\n-- Equation (4) is incorrect.\n-- In the introduction and approach sections, it reads like a big deal to adapt on both the pixel and feature levels. However, the experiments fail to show that these two levels of adaptation are complementary to each other. Either the introduction is a little misleading or the experiments are insufficient. \n-- What does the “image-space adaptation” mean?\n-- There are three fairly sophisticated training stages in Section 4.2. However, the description of the three stages are extremely short and ambiguous. \n-- What are exactly the network architectures used in the experiments?\n\n- The technical contribution seems like only marginal innovative. \n- The experiments adapting from MNIST to SVHN would be really interesting, given that the MNIST source domain is not as visually rich as the SVHN target. Have the authors conducted the corresponding experiments? How are the results? \n\nSummary:\nThe proposed method is a natural application of CycleGAN to domain adaptation. The technical contribution is only marginal. The results on semantic segmentation are encouraging and may motivate more research along this direction. It is unfortunate that the paper writing leaves many parts of the paper unclear. \n\n=========================================\nPost rebuttal:\n\nThe rebuttal addresses my first set of questions. The revised paper describes more experiment details, corrects equation (4), and clarifies some points about the results. \n\nThis paper applies the cycle consistent GAN to domain adaptation. I still think the technical contribution is only marginally innovative. Nonetheless, I do not weigh this point too much given that the experiments are very extensive. \n\nThe rebuttal does not answer my last question. It would be interesting to see what happens to adapt from MNIST to SVHN, the latter of which contains more complicated background than the former. \n']","[80, -30, -20]","[70, 20, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They describe it as 'very well written' and state that the technical details are 'well described and motivated'. The reviewer also acknowledges the paper's contribution as a 'natural extension' of an existing approach and notes that the experiments show critical improvements. The score is not 100 because the reviewer does suggest some areas for improvement, such as identifying failure cases. The politeness score is 70 (polite) because the language used is professional and respectful throughout. The reviewer offers praise where due and frames their suggestion for improvement as a constructive comment ('It would be good to...'). The score is not higher because while polite, the language doesn't go beyond standard professional courtesy to be exceptionally warm or deferential."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('Great idea!', 'I really like the work'), the overall tone is critical. The reviewer expresses significant concerns about the paper's novelty, comparisons to existing work, and some technical details. The politeness score is 20 because the reviewer uses polite language ('I believe', 'I think') and balances criticism with praise, but doesn't go out of their way to be overly courteous. The reviewer provides constructive feedback and specific suggestions for improvement, which is professional but not excessively polite. The use of 'Pros' and 'Cons' sections helps organize the feedback in a neutral manner."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they also point out several weaknesses and areas for improvement. The reviewer states that the technical contribution is 'only marginal innovative' and that the paper writing leaves 'many parts of the paper unclear'. However, they do recognize some positive aspects like 'superior' experimental results and 'amazing' translated images.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use polite language such as 'Could the authors show more examples...' and 'Have the authors conducted...'. Even when pointing out weaknesses, the reviewer does so in a respectful manner, offering specific suggestions for improvement rather than harsh criticism. The use of phrases like 'It is unfortunate that...' instead of more direct criticism also contributes to the polite tone.""]"
"['The paper presents an extension of the Xception network of (Chollet et al. 2016) 2D grids to generic graphs. The Xception network decouples the spatial correlations from depth channels correlations by having separate weights for each depth channel. The weights within a depth channel is shared thus maintaining the stationary requirement. The proposed filter relaxes this requirement by forming the weights as the output of a two-layer perception. \n\nThe paper includes a detailed comparison of the existing formulations from the traditional label propagation scheme to more recent more graph convolutions (Kipf & Welling, 2016 ) and geometric convolutions  (Monti et al. 2016). \n\nThe paper provides quantitative evaluations under three different settings i) image classification, ii) Time series forcasting iii) Document classification. The proposed method out-performs all other graph convolutions on all the tasks (except image classification) though having comparable or less number of parameters. For image classification, the performance of proposed method is below its predecessor Xception network. \n\nPros:\ni) Detailed review of the existing work and comparison with the proposed work.\nii) The three experiments performed showed variety in terms of underlying graph structure hence provides a thorough evaluation of different methods under different settings.\niii) Superior performance with fewer number of parameters compared to other methods. \nCons:\ni) The architecture of the 2 layer MLP used to learn weights for a particular depth channel is not provided.\nii) The performance difference between Xception and proposed method for image classification experiments using CIFAR is incoherent with the intuitions provided Sec 3.1 as the proposed method have more parameters and is a generalized version of DSC.', ""Paper Summary:\nThis work proposes a new geometric CNN model to process spatially sparse data. Like several existing geometric CNNs, convolutions are performed on each point using nearest neighbors. Instead of using a fixed or Gaussian parametric filters, this work proposes to predict filter weights using a multi-layer perception. Experiments on 3 different tasks showcase the potential of the proposed method.\n\nPaper Strengths:\n- An incremental yet interesting advance in geometric CNNs.\n- Experiments on three different tasks indicating the potential of the proposed technique.\n\nMajor Weaknesses:\n- Some important technical details about the proposed technique and networks is missing in the paper. It is not clear whether a different MLP is used for different channels and for different layers, to predict the filter weights. Also, it is not clear how the graph nodes and connectivity changes after the max-pooling operation.\n- Since filter weight prediction forms the central contribution of this work, I would expect some ablation studies on the MLP (network architecture, placement, weight sharing etc.) that predicts filter weights. But, this is clearly missing in the paper.\n- If one needs to run an MLP for each edge in a graph, for each channel and for each layer, the computation complexity seems quite high for the proposed network. Also, finding nearest neighbors takes time on large graphs. How does the proposed technique compare to existing methods in terms of runtime?\n\nMinor Weaknesses:\n- Since this paper is closely related to Monti et al., it would be good if authors used one or two same benchmarks as in Monti et al. for the comparisons. Why authors choose different set of benchmarks? Because of different benchmarks, it is not clear whether the performance improvements are due to technical improvements or sub-optimal parameters/training for the baseline methods.\n- I am not an expert in this area. But, the chosen benchmarks and datasets seem to be not very standard for evaluating geometric CNNs.\n- The technical novelty seems incremental (but interesting) with respect to existing methods.\n\nClarifications:\n- See the above mentioned clarification issues in 'major weaknesses'. Those clarification issues are important to address.\n- 'Non-parametric filter' may not be right word as this work also uses a parametric neural network to estimate filter weights?\n\nSuggestions:\n- It would be great if authors can add more details of the multi-layer perceptron, used for predicting weights, in the paper. It seems some of the details are in Appendix-A. It would be better if authors move the important details of the technique and also some important experimental details to the main paper.\n\nReview Summary:\nThe proposed technique is interesting and the experiments indicate its superior performance over existing techniques. Some incomplete technical details and non-standard benchmarks makes this not completely ready for publication."", 'The paper presents a Depthwise Separable Graph Convolution network that aims\nat generalizing Depthwise convolutions, that exhibit a nice performance in image\nrelated tasks, to the graph domain. In particular it targets\nGraph Convolutional Networks.\n\nIn the abstract the authors mention that the Depthwise Separable Graph Convolution\nthat they propose is the key to understand the connections between geometric\nconvolution methods and traditional 2D ones. I am afraid I have to disagree as\nthe proposed approach is not giving any better understanding of what needs to be\ndone and why. It is an efficient way to mimic what has worked so far for the planar\ndomain but I would not consider it as fundamental in ""closing the gap"".\n\nI feel that the text is often redundant and that it could be simplified a lot.\nFor example the authors state in various parts that DSC does not work on\nnon-Euclidean data. Section 2 should be clearer and used to better explain\nrelated approaches to motivate the proposed one.\nIn fact, the entire motivation, at least for me, never went beyond the simple fact\nthat this happens to be a good way to improve performance. The intuition given\nis not sufficient to substantiate some of the claims on generality and understanding\nof graph based DL.\n\nIn 3.1, at point (2), the authors mention that DSC filters are learned from the\ndata whereas GC uses a constant matrix. This is not correct, as also reported in\nequation 2. The matrix U is learned from the data as well.\n\nEquation (4) shows that the proposed approach would weight Q different GC\nlayers. In practical terms this is a linear combination of these graph\nconvolutional layers.\nWhat is not clear is the \\Delta_{ij} definition. It is first introduced in 2.3\nand described as the relative position of pixel i and pixel j on the image, but\nthen used in the context of a graph in (4). What is the coordinate system used\nby the authors in this case? This is a very important point that should be made\nclearer.\n\nWhy is the Related Work section at the end? I would put it at the front.\n\nThe experiments compare with the recent relevant literature. I think that having\nless number of parameters is a good thing in this setting as the data is scarce,\nhowever I would like to see a more in-depth comparison with respect to the number\nof features produced by the model itself. For example GCN has a representation\nspace (latent) much smaller than DSCG.\nNo statistics over multiple runs are reported, and given the high variance of\nresults on these datasets I would like them to be reported.\n\nI think the separability of the filters in this case brings the right level of\nsimplification to the learning task, however as it also holds for the planar case\nit is not clear whether this is necessarily the best way forward.\nWhat are the underlying mathematical insights that lead towards selecting\nseparable convolutions?\n\nOverall I found the paper interesting but not ground-breaking. A nice application\nof the separable principle to GCN. Results are also interesting but should be\nfurther verified by multiple runs.\n']","[60, -20, -20]","[50, 60, 50]","[""The sentiment score is 60 (positive) because the review begins by neutrally describing the paper's content, then lists several pros and only two minor cons. The overall tone is appreciative of the work's contributions and thorough evaluation. The politeness score is 50 (somewhat polite) because the reviewer uses neutral, professional language throughout without any harsh criticisms. They objectively present both pros and cons without using overly emotional or judgmental language. The review maintains a respectful tone while providing constructive feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths and the potential of the proposed method, they also highlight several major weaknesses and clarification issues. The overall tone suggests that the paper is not yet ready for publication. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and offering constructive criticism. They use phrases like 'it would be great if' and 'it would be better if' when making suggestions, which contributes to a polite tone. The reviewer also admits to not being an expert in some areas, showing humility. However, the directness in pointing out weaknesses prevents the score from being higher."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper 'interesting', they also express several criticisms and disagreements. They state that the paper is 'not ground-breaking' and disagree with some of the authors' claims. The reviewer also points out areas that need clarification or improvement. However, the tone is not entirely negative, as they acknowledge some positive aspects like 'interesting' results and 'nice application' of principles. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, even when expressing criticisms. They use phrases like 'I am afraid I have to disagree' and 'I would like to see' rather than harsh or dismissive language. The reviewer also balances criticisms with positive comments and provides constructive feedback, which contributes to the polite tone.""]"
"[""The authors study compressing feed forward layers using low rank tensor decompositions. For instance a feed forward layer of 4096 x 4096 would first be reshaped into a rank-12 tensor with each index having dimension 2, and then a tensor decomposition would be applied to reduce the number of parameters. \n\nPrevious work used tensor trains which decompose the tensor as a chain. Here the authors explore a tree like decomposition. The authors only describe their model using pictures and do not provide any rigorous description of how their decomposition works.\n\nThe results are mediocre. While the author's approach does seem to reduce the feed forward net parameters by 30% compared to the tensor train decomposition for similar accuracy, the total number of parameters for both MERA (authors' approach) and Tensor Train is similar since in this regime the CNN parameters dominate (and the authors' approach does not work to compress those).\n\n"", 'In the paper the authors suggest to use MERA tensorization technique for compressing neural networks. MERA itseld in a known framework in QM but not in ML. Although the idea seems to be fruitful and interesting I find the paper quite unclear. The most important part is section 2 which presents the methodology used. However there no equations or formal descriptions of what is MERA and how it works. Only figures which are difficult to understand. It is almost impossible to reproduce the results based on such iformal description of tensorization method. The authors should be more careful and provide more details when describing the algorithm. There was enough room for making the algorithm more clear. This is my main point for critisism.\n\nAnother issue is related with practical usefulness. MERA allows to get better compression than TT keeping the same accuracy. But the authors do compress only one layer. In this case the total compression of DNN is almost tha same so why do we need yet another tensorization technique? I think the authors should try tenzorizing several layers and explore whether they can do any better than TT compression. Currently I would say the results are comparable but not definitely better.\n\nUPDATE: The revised version seems to be a bit more clear. Now the reader unfamiliar with MERA (with some efforts) can understand how the methods works. Although my second concern remains. Up to now it looks just yet another tensorization method with only slight advantages over TT framework. Tensorization of conv.layers could improve the paper a lot. I increased the score to 5 for making the presentation of MERA more readable.', 'The paper presents a new parameterization of linear maps for use in neural networks, based on the Multiscale Entanglement Renormalization Ansatz (MERA). The basic idea is to use a hierarchical factorization of the linear map, that greatly reduces the number of parameters while still allowing for relatively complex interactions between variables to be modelled. A limited number of experiments on CIFAR10 suggests that the method may work a bit better than related factorizations.\n\nThe paper contains interesting new ideas and is generally well written. However, a few things are not fully explained, and the experiments are too limited to be convincing.\n\n\nExposition\nOn a first reading, it is initially unclear why we are talking about higher order tensors at all. Usually, fully connected layers are written as matrix-vector multiplications. It is only on the bottom of page 3 that it is explained that we will reshape the input to a rank-k (k=12) tensor before applying the MERA factored map. It would be helpful to state this sooner. It would also be nice to state that (in the absense of any factorization of the weight tensor) a linear contraction of such a high-rank tensor is no less general than a matrix-vector multiplication.\n\nMost ML researchers will not know Haar measure. It would be more reader friendly to say something like ""uniform distribution over orthogonal matrices (i.e. Haar measure)"" or something like that. Explaining how to sample orthogonal matrices / tensors (e.g. by SVD) would be helpful as well.\n\nThe article does not explain what ""disentanglers"" are. It is very important to explain this, because it will not be generally known by the machine learning audience, and is the main thing that distinguishes this work form earlier tree-based factorizations.\n\nOn page 5 it is explained that the computational complexity of the proposed method is N^{log_2 D}. For D=2, this is better than a fully connected layer. Although this theoretical speedup may not currently have been realized, it perhaps could be achieved by a custom GPU kernel. It would be nice to highlight this potential benefit in the introduction.\n\n\nTheoretical motivation\nAlthough I find the theoretical motivation for the method somewhat compelling, some questions remain that the authors may want to address. For one thing, the paper talks about exploiting ""hierarchical / multiscale structure"", but this does not refer to the spatial multi-scale structure that is naturally present in images. Instead, the dimensions of a hidden activation vector are arbitrarily ordered, partitioned into pairs, and reshaped into a (2, 2, ..., 2) shape tensor. The pairing of dimensions determines the kinds of interactions the MERA layer can express. Although the earlier layers could learn to produce a representation that can be effectively analyzed by the MERA layer, one is left to wonder if the method could be made to exploit the spatial multi-scale structure that we know is actually present in image data.\n\nAnother point is that although from a classical statistics perspective it would seem that reducing the number of parameters should be generally beneficial, it has been observed many times that in deep learning, highly overparameterized models are easier to optimize and do not necessarily overfit. Thus at this point it is not clear whether starting with a highly constrained parameterization would allow us to obtain state of the art accuracy levels, or whether it is better to start with an overparameterized model and gradually constrain it or perform a post-training compression step.\n\n\nExperiments\nIn the introduction it is claimed that the method of Liu et al. cannot capture correlations on different length scales because it lacks disentanglers. Although this may be theoretically correct, the paper does not experimentally verify that the proposed factorization with disentanglers outperforms a similar approach without disentanglers. In my opinion this is a critical omission, because the addition of disentanglers seems to be the main or perhaps only difference to previous work.\n\nThe experiments show that MERA can drastically reduce the number of parameters of fully connected layers with only a modest drop in accuracy, for a particular ConvNet trained on CIFAR10. Unfortunately this ConvNet is far from state of the art, so it is not clear if the method would also work for better architectures. Furthermore, training deep nets can be tricky, and so the poor performance makes it impossible to tell if the baseline is (unintentionally) crippled.\n\nComparing MERA-2 to TT-3 or MERA-3 to TT-5 (which have an approximately equal number of parameters), the difference in accuracy appears to be less than 1 percentage point. Since only a handful of specific MERA / TT architectures were compared on a single dataset, it is not at all clear that we can expect MERA to outperform TT in many situations. In fact, it is not even clear that the small difference observed is stable under random retraining.\n\n\nSummary\nAn interesting paper with novel theoretical ideas, but insufficient experimental validation. Some expository issues need to be fixed.']","[-50, -20, -20]","[0, 50, 60]","[""The sentiment score is -50 because the review is generally negative, but not extremely so. The reviewer describes the results as 'mediocre' and points out that the authors' approach doesn't significantly outperform existing methods. However, they do acknowledge some minor improvements, which prevents the score from being lower. The politeness score is 0 (neutral) because the reviewer uses straightforward, factual language without being particularly polite or rude. They critique the work objectively without using harsh language or personal attacks, but also don't use any notably courteous phrases. The review focuses on the technical aspects and results without much attention to tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea as 'fruitful and interesting', they express significant concerns about the clarity of the paper and its practical usefulness. The reviewer mentions that the paper is 'quite unclear', 'difficult to understand', and 'almost impossible to reproduce'. However, they do note some improvement in the revised version, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'The authors should be more careful' instead of harsh criticism. They also acknowledge improvements in the revised version and increased their score, showing a fair approach. The language is constructive rather than confrontational, offering specific suggestions for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper contains 'interesting new ideas' and is 'generally well written', they also point out significant shortcomings such as 'insufficient experimental validation' and 'expository issues'. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They use phrases like 'it would be helpful', 'it would be nice', and 'the authors may want to address', which maintain a polite and professional tone even when pointing out flaws.""]"
"['The paper presents to combine self-learning and GAN. The basic idea is to first use GAN to generate data, and then infer the pseudo label, and finally use the pseudo labeled data to enhance the learning process. Experiments are conducted on one image data set. The paper contains several deficiencies.\n\n1.\tThe experiment is weak. Firstly, only one data set is employed for evaluation, which is hard to justify the applicability of the proposed approach. Secondly, the compared methods are too few and do not include many state-of-the-art SSL methods like graph-based approaches. Thirdly, in these cases, the results in table 1 contain evident redundancy. Fourthly, the performance improvement over compared method is not significant and the result is based on 3 splits of data set, which is obviously not convincing and involves large variance. \n2.\tThe paper claims that ‘when paired with deep, semi-supervised learning has had a few success’. I do not agree with such a claim. There are many success SSL deep learning studies on embedding. They are not included in the discussions. \n3.\tThe layout of the paper could be improved. For example, there are too many empty spaces in the paper. \n4.\tOverall technically the proposed approach is a bit straightforward and does not bring too much novelty.\n5.\tThe format of references is not consistent. For example, some conference has short name, while some does not have. ', 'This paper presents a self-training scheme for GANs and tests it on image (NIST) data.\n\nSelf-training is a well-known and usually effective way to learn models in a semi-supervised setting. It makes a lot of sense to try this with GANs, which have also been shown to help train Deep Learning methods.\n\nThe novelty seems quite limited, as both components (GANs and self-training) are well-known and their combination, given the context, is a fairly obvious baseline. The small changes described in Section 4 are not especially motivated and seem rather minor. [btw you have a repeated sentence at the end of that section]\n\nExperiments are also quite limited. An obvious baseline would be to try self-training on a non-GAN model, in order to determine the influence of both components on the performance. Results seem quite inconclusive: the variances are so large that all method perform essentially equivalently. On the other hand, starting with 10 labelled examples seems to work marginally better than 20. This is a bit weird and would justify at least a mention, and idealy some investigation.\n\nIn summary, both novelty and impact seem limited. The idea makes a lot of sense though, so it would be great to expand on these preliminary results and explore the use of GANs in semi-supervised learning in a more thorough manner.\n\n[Response read -- thanks]', 'This paper proposes to use self-training strategies for using unlabeled data in GAN. Experiments on only one data set, i.e., MNIST, are conducted \n\nPros:\n* Studying how to use unlabeled data to improve performance of GAN is of technical importance. The use of the self-training in GAN for exploiting unlabeled data is sound.\n\xa0\nCons:\n* The novelty and technical contribution is low. The unlabeled data are exploited by off-the-shelf self-training strategies, where the base learner is fixed to GAN. Using GAN does not make the self-training strategy special to the existing self-training approaches. Thus, the proposed approaches are actually a straight application of the existing techniques. In fact, It would be more interesting if the unlabeled data could be employed to the “G” and “A” in GAN.\n\n* In each self-training iteration, GAN needs to be retrained, whose computational cost is high..\n\n* Only one data set is used in the experiment. Some widely-used datasets, like SVHN or CIFAR-10, are not used in the experiment. \n\n* Important baseline methods are missing. The proposed methods should be evaluated with the state-of-the-art semi-supervised deep learning methods, such as those mentioned in related work section.\n']","[-70, -20, -30]","[20, 50, 50]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several 'deficiencies' in the paper, including weak experiments, disagreement with claims, layout issues, lack of novelty, and formatting inconsistencies. The only slightly positive aspect mentioned is the basic idea of the paper. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and avoid personal attacks. They use phrases like 'The paper contains several deficiencies' instead of more harsh language. However, the review lacks positive reinforcement or encouragement, which prevents it from being scored higher on politeness."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the idea 'makes a lot of sense' and is 'usually effective', they also point out significant limitations in novelty, experiments, and impact. The reviewer suggests that the results are 'inconclusive' and the changes described are 'not especially motivated and seem rather minor'. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges the potential of the idea, and offers constructive feedback for improvement. They use phrases like 'it would be great to expand' and 'ideally some investigation', which are encouraging and polite ways to suggest improvements. The reviewer also thanks the authors for their response at the end, which adds to the politeness."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('Pros'), the 'Cons' section is more extensive and points out significant limitations of the paper. The reviewer criticizes the novelty, technical contribution, computational cost, limited experimental data, and missing baseline methods. However, it's not entirely negative as they recognize the importance of the topic and the soundness of the approach. The politeness score is 50 because the reviewer uses professional and respectful language throughout, presenting both pros and cons objectively without harsh or personal criticism. They use phrases like 'It would be more interesting if...' which suggests improvements in a constructive manner. The review maintains a formal and academic tone, which is appropriate and polite for peer review.""]"
"['This paper proposed an X-shaped GAN for the so called semantic style transfer task, in which the goal is to transfer the style of an image from one domain to another without altering the semantic content of the image. Here, a domain is collectively defined by the images of the same style, e.g., cartoon faces. \n\nThe cost function used to train the network consists of five terms of which four are pretty standard: a reconstruction loss, two regular GAN-type losses, and an imitation loss. The fifth term, called the semantic consistency loss, is one of the main contributions of this paper. This loss ensures that the translated images should be encoded into about the same location as the embedding of the original image, albeit by different encoders. \n\nStrengths:\n1. The new CartoonSet dataset is carefully designed and compiled. It could facilitate the future research on style transfer. \n2. The paper is very well written. I enjoyed reading the paper. The text is concise and also clear enough and the figures are illustrative.\n3. The semantic consistency loss is reasonable, but I do not think this is significantly novel. \n\nWeaknesses:\n1. Although “the key aim of XGAN is to learn a joint meaningful and semantically consistent embedding”, the experiments are actually devoted to the qualitative style transfer only. A possible experiment design for evaluating “the key aim of XGAN” may be the facial attribute prediction. The CartoonSet contains attribute labels but the authors may need collect such labels for the VGG-face set.\n2. Only one baseline is considered in the style transfer experiments. Both CycleGAN and UNIT are very competitive methods and would be better be included in the comparison. \n3. The “many-to-many” is ambiguous. Style transfer in general is not a one-to-one or many-to-one mapping. It is not necessary to stress the many-to-many property of the proposed new task, i.e., semantic style transfer. \n\nThe CartoonSet dataset and the new task, which is called semantic style transfer between two domains, are nice contributions of this paper. In terms of technical contributions, it is not significant to have the X-shaped GAN or the straightforward semantic consistency loss. The experiments are somehow mismatched with the claimed aim of the paper. ', 'This paper proposes a new GAN-based model for unpaired image-to-image translation. The model is very similar to DTN [Taigman et al. 2016] except with trained encoders and a domain confusion loss to encourage the encoders to map source and target domains to a shared embedding. Additionally, an optional teacher network is introduced, but this feels rather tangential and problem-specific. The paper is clearly presented and I enjoyed the aesthetics of the figures. The method appears technically sound, albeit a bit complicated. The new cartoon dataset is also a nice contribution.\n\nMy main criticism of this paper is the experiments. At the end of reading, I don’t know clearly which aspects of the method are important, why they are important, and how the proposed system compares against past work. First, the baselines are insufficient. Only DTNs are compared against, yet there are many other recent methods for unpaired image-to-image translation, notably, cycle-consistency-based methods and UNIT. These methods should also be compared against, as there is little evidence that DTNs are actually SOTA on cartoons (rather, the cartoon dataset was not public so other papers did not compare on that dataset). Second, although I appreciated the ablation experiments, they are not comprehensive, as discussed more below. Third, there is no quantitative evaluation. The paper states that quantifying performance on style transfer is an unsolved problem, but this is no excuse for not at least trying. Indeed, there are many proposed metrics in the literature for quantifying style transfer / image generation, including the Inception score [Salimans et al. 2016], conditional variants like the FCN-score [Isola et al. 2017], and human judgments. These metrics could all be adapted to the present task (with appropriate modifications, e.g., switching from Inception to a face attribute classifier). Additionally, as the paper mentions at the end, the method could be applied to domain adaptation, where plenty of standard metrics and benchmarks exist.\n\nUltimately, the qualitative results in the paper are not convincing to me. It’s hard to see the advantages/disadvantages in each comparison. For example in Figure 8, it’s hard to even see any overall change in the outputs due to ablating the semantic consistency loss and the teacher loss (especially since I’m comparing these to Figure 6, which is referred to “Selected results” and therefore might not be a fair comparison). Perhaps the effect of the ablations would be clearer if the figures showed a single input followed by a series of outputs for that same input, each with a different term ablated. A careful reader might be able to examine the images for a long time and find some insights, but it would be much better if the paper distilled these insights into a more concise and convincing form. I feel sort of like I’m looking at raw data, and it still needs to be analyzed.\n\nI also think the ablations are not sufficiently comprehensive. In particular, there is no ablation of the domain adversarial loss. This seems like an important one to test since it’s one of the main differences from DTNs. I was a bit confused by the “finetuned DTN” in Section 7.2. Is this an ablation experiment where the domain adversarial loss and teacher loss are removed? If so, referring to it as so may be clearer than calling it a finetuned DTN. Interestingly, the results of this method look pretty decent, suggesting that the domain adversarial loss might not be having a big effect, in which case XGAN looks very close indeed to DTNs. It would be great here to actually quantify the mentioned sensitivity to hyperparameters.\n\nIn terms of presentation, at several points, the paper argues that previous, pixel-domain methods are more limited than the proposed feature-space method, but little evidence is given to support these claims. For example, “we argue that such a pixel-level constraint is not sufficient in our case” in the intro, and “our proposed semantic consistency loss acts at the feature level, allowing for more flexible transformations” in related work. I would like to see more motivation for these assertions, and ultimately, the limitations should be concretely demonstrated in experiments. In models like CycleGAN the pixel-level constraint is between inputs and reconstructed inputs, and I don’t see why this necessarily is overly restrictive on the kinds of transformations in the outputs. The phrasing in the current paper seems to suggest that the pixel-level constraints are between input and output, which, I agree, would be directly restrictive. The reasoning here should be clarified. Better yet would be to provide empirical evidence that pixel-domain methods are not successful (e.g., by comparing against CycleGAN).\n\nThe usage of the term “semantic” is also somewhat confusing. In what sense is the latent space semantic? The paper should clarify exactly what this term refers to, perhaps simply defining it to mean a “low-dimensional shared embedding.”\n\nI think the role of the GAN objective is somewhat underplayed. It is quite interesting that the current model achieves decent results even without the GAN. However, there is no experiment keeping the GAN but ablating other parts of the method. Other papers have shown that a GAN objective plus, e.g., cycle-consistency, can do quite well on this kind of problem. It could be that different terms in the current objective are somewhat redundant, so that you can choose any two or three, let’s say, and get good results. To check this, it would be great to see more comprehensive ablation experiments. \n\n\nMinor comments:\n1. Page 1: I wouldn’t call colorization one-to-one. Even though there is a single ground truth, I would say colorization is one-to-many in the sense that many outputs may be equally probable according to a Bayes optimal observer.\n2. Fig 1: It should be clarified that the left example is not a result of the method. At a glance this looks like an exciting new result and I think that could mislead casual readers.\n3. Fig 1 caption: “an other” —> “another”\n4. Page 2: “Recent work … fail for more general transformations” — DiscoGAN (Kim et al. 2017) showed some success beyond pixel-aligned transformations\n5. Page 5: “particular,the” —> “particular, the”; quotes around “short beard” are backwards\n6. Page 6: “founnd” —> “found”\n7. Page 11: what is \\mathcal{L}_r? I don’t see it defined above.', '\n\n- Lack of novelty\n\nThe paper has very limited novelty since the proposed method is a straightforward combination of two prior works on the same topic (unpair/unsupervised image translation or cross-domain image generation) where the two prior works are the DTN work [a] and the UNIT [b] work. To be more precise, the proposed method utilizes the weight-sharing design for enforcing the shared latent space constraint proposed in the UNIT work [b] and the feature consistency loss term for ensuring common embedding in the DTN work [a] for solving the ill-posed unpaired/unsupervised image-to-image translation problem. Since the ideas are already published in the prior work, the paper does not contribute additional knowledge to the problem. \n\nIn addition, the combination is done in a careless manner. First of all, the paper proposes jointly minimizing the common embedding loss [a] and the domain adversarial loss [b]. However, minimizing the common embedding loss [a] also results in minimizing the domain adversarial loss [c]. This can be easily seen as when the embeddings are the same, no discriminators can tell them apart. This suggests that the paper fails to see the connection and blindly put the two things together. Moreover, given the generators, minimizing the common embedding loss also results in minimizing the cycle-consistency loss [d]. As the UNIT work [b] utilize both the weight-sharing constraint and cycle-consistency loss, the proposed method becomes a close variant to the UNIT work [b].\n\n- Poor experimental verification\n\nThe paper only shows visualization results on translating frontal face images to cartoon images in the resolution of 64x64. This is apparently short as compared to the experimental validations done in several prior works [a,b,d]. In the CycleGAN work [d], the results are shown on several translation tasks (picture to painting, horse to zebra, map to image, and different scenarios) in a resolution of 256x256. In the UNIT work [b], the results are shown in various street scene (sunny to rainy, day to night, winter to summer, synthetic to real) and animal portraits (cat species and dog breeds) where the resolution is up to 640x480. In the DTN [a] and UNIT [b] work, promising domain adaptation results (SVHN to MNIST) are reported. Due to the shortage of results, the credibility of the paper is damaged. \n\n- Lack of clarity in presentation\n\nThe paper tends to introduces new key words for existing one. For example, the ""semantic style transfer"" is exactly the unpaired/unsupervised image-to-image translation or cross-domain image generation. It is not clear why the paper needs to introduce the new keyword. Also, the Coupled GAN work [e] is the first work that utilizes both weight-sharing (shared latent space assumption) and GAN for unpaired/unsupervised image-to-image translation. It is unfortunately that the paper fails to refer to this closely related prior work.\n\n[a] Yaniv Taigman, Adam Polyak, Lior Wolf ""Unsupervised Cross-Domain Image Generation"", ICLR 2017\n\n[b] Ming-Yu Liu, Thomas Breuel, Jan Kautz ""Unsupervised Image-to-Image Translation Networks"", NIPS 2017 \n\n[c] YaroslavGanin et al. ""Domain-adversarial Training of Neural Networks"" JMLR 2016\n\n[d] Jun-Yan Zhu, Taesung Park, Philip Isola, and Alexei A. Efros ""Unpaired Image-to-Image Translation Using Cycle-consistent Adversarial Networks"" ICCV 2017\n\n[e] Ming-Yu Liu, Oncel Tuzle ""Coupled Generative Adversarial Networks"", NIPS 2016']","[20, -30, -80]","[80, 60, -20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges some strengths of the paper, such as the well-designed dataset, clear writing, and reasonable semantic consistency loss. However, they also point out significant weaknesses, including limited experiments and comparisons, which balances out the positive aspects. The politeness score is high (80) as the reviewer uses respectful language throughout, acknowledging the paper's contributions and using phrases like 'I enjoyed reading the paper.' They provide constructive criticism without harsh language, maintaining a professional and courteous tone even when discussing weaknesses."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects (e.g., 'The paper is clearly presented and I enjoyed the aesthetics of the figures'), the overall tone is critical. The reviewer expresses significant concerns about the experiments, baselines, and lack of quantitative evaluation. Phrases like 'My main criticism' and 'the qualitative results in the paper are not convincing to me' indicate a generally negative sentiment, though not extremely so.\n\nThe politeness score is 60 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I appreciated' and 'I enjoyed', and frame criticisms constructively (e.g., 'It would be great to see...'). The reviewer also provides detailed feedback and suggestions for improvement, which is considerate. However, the score is not higher because some critiques are quite direct (e.g., 'Ultimately, the qualitative results in the paper are not convincing to me'), though still expressed professionally."", ""The sentiment score is -80 because the review is highly critical, pointing out major flaws in novelty, experimental verification, and clarity. The reviewer states the paper has 'very limited novelty', 'poor experimental verification', and 'lack of clarity'. There are no positive comments. The politeness score is -20 because while the language is not overtly rude, it is quite blunt and dismissive in places (e.g. 'careless manner', 'blindly put the two things together'). The reviewer does not use polite hedging language or acknowledge any positives, which contributes to the slightly impolite tone.""]"
"['The manuscript proposes to use the Cramer distance as a measure between distributions (acting as a loss) when optimizing\nan objective function using stochastic gradient descent (SGD). Cramer distance is a Bregman divergence and is a member of the Lp family of divergences.  Here a ""distance"" means a symmetric divergence measure that satisfies the relaxed triangle inequality. The motivation for using the Cramer distance is that it has unbiased sample gradients while still enjoying some other properties such as scale sensitivity and sum invariant. The authors also proof that for the Bernoulli distribution, there is a lower bound independent of the sample size for the deviation between the gradient of the Cramer distance, and the expectation of the estimated gradient of the Cramer distance. Then, the multivariate case of the Cramer distance, called the energy distance, is also briefly presented. The paper closes with some experiments on ordinal regression using neural networks and training GANs using the Cramer distance. \n\nIn general, the manuscript is well written and the ideas are smoothly presented. While the manuscript gives some interesting insights, I find that the contribution could have been explained in a more broader sense, with a stronger compelling message.\n\nSome remarks and questions:\n\n1.\tThe KL divergence considered here is sum invariant but not scale sensitive, and has unbiased sample gradients. The \n\tauthors are considering here the standard (asymmetric) KL divergence (sec. 2.1). Is it the case that losing scale\n\tsensitivity make the KL divergence insensitive to the geometry of the outcomes? or is it due to the fact the KL \n\tdivergence is not symmetric? or ?\n\n2.\tThe main argument for the paper is that the simple sample-based estimate for the gradient using the Wasserstein \n\tmetric is a biased estimate for the true gradient of the Wasserstein distance, and hence it is not favored with\n\tSGD-type algorithms. Are there any other estimators in the literature for the gradient of the Wasserstein distance?\n\tWas this issue overlooked in the literature?\n\n3.\tI am not sure if a biased estimate for the gradient will lead to a ``wrong minimum\'\' in an energy space that has \n\tinfinitely many local minima.  Of course one should use an unbiased estimate for the gradient whenever this is possible.\n\tHowever, even when this is possible, there is no guarantee that this will consistently lead to deeper and ``better\'\'\n\tminima, and there is no guarantee as well that these deep local minima reflect meaningful results.\n\n4.\tTo what extent can one generalize theorem 1 to other probability distributions (continuous and discrete) and to the \n\tmultivariate cases as well?\n\n5.\tI also don\'t think that the example given in sec. 4.2 and depicted in Fig. 1 is the best and simplest way to illustrate\n\tthe benefit of Cramer distance over Wasserstein. Similarly, the experiments for the multivariate case using GANs and\n\tNeural Networks do not really deliver tangible, concrete and conclusive results. Partly, these results are very  \n       qualitative, which can be understood within the context of GANs. However, the authors could have used other       \n       models/algorithms where they can obtain concrete quantitative results (for this type of contribution). In addition, \n\tsuch sophisticated models (with various hyper-parameters) can mask the true benefit for the Cramer distance, and can \n\talso mask the extent of how good/poor is the sample estimate for the Wasserstein gradient.', 'The contribution of the article is related to performance criteria, and in particular to the Wasserstein/Mallows metric, which has received a good deal of attention these last few years in the machine learning literature. The paper starts with a discussion about desirable properties of a loss function and points out the fact that (plug-in) empirical versions of the gradient of this quantity are biased, which limits its interest, insofar as many learning techniques are based on (stochastic) gradient descent. In its current state, this argument looks artificial. Indeed, zero bias can be a desirable properties for an estimate but being biased does not prevent it from being accurate. In contrast, in many situations like ridge regression, incorporating bias permits to drastically reduce variance.It quite depends on the structural assumptions made. For this reason, the worst case result (Theorem 1) is not that informative in my opinion. As they are mainly concerned by the L_1 version of the Wasserstein distance, rather than focussing on the bias, the authors could consider the formulation in terms of inverse cumulative distribution functions in the 1-d setup and the fact that the empirical cdf is never invertible: even if the theoretical cdf is invertible (which naturally guarantees uniqueness of the optimal transport) the underlying mass transportation problem is not as well-posed as that related to its statistical counterpart (however, smoothing the empirical distribution may remedy this issue).\nThe authors propose to use instead the Cramer distance, which is a very popular distance in Statistics and on which many statistical hypothesis testing procedures rely, and review its appealing properties. The comparisons between KL, Wasserstein and Cramer distances is vain in my opinion and willing to come to a general conclusion about the merits of one against the others is naive. In a nonparametric setup, it is always possible to find distributions such that certain of its properties are hidden by certain distances and highlighted by others. This is precisely why you are forced to specify the type of deviations between distributions in nonparametric hypothesis testing (a shift, a change in scale, etc.), there is no way of assessing universally that two distributions are close: optimality can only be assessed for sequences of contiguous hypotheses. The choice of the distance is part of the learning problem. ', 'The authors investigate how the properties of different discrepancies for distributions affect the training of parametric model with SGD. They argue that in order for SGD to be a useful training procedure, an ideal metric should be scale sensitive, sum invariant and also provide unbiased gradients. The KL-divergence is not is scale sensitive, and the Wasserstein metric does not provide unbiased gradients. The authors thus posit the Cramer distance as a foundation for the discriminator in the GAN, and then generalize this to an energy based discriminator. The authors then test their Cramer GAN on the CelebA dataset and show comparable results to the Wasserstein GAN, with less mode collapse.\n\nFrom what I can gather, the Cramer GAN is unlikely to be a huge improvement in the GAN literature, but the mathematical relationships investigated in the paper are illuminating. This brings some valuable understanding for improving upon previous GANs [e.g. WGAN]. As energy based GANs and MMD GANs have become more prominent, it would be nice to see how these ideas interplay with those GANs. However, overall I thought the paper did a nice job presenting some context for GAN training.\n\n']","[20, -30, 60]","[60, 20, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges that the manuscript is well-written and presents interesting ideas. However, they also express that the contribution could have been explained more broadly with a stronger message, indicating room for improvement. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and asking questions rather than making harsh judgments. They use phrases like 'In general, the manuscript is well written' and 'Some remarks and questions:' which maintain a professional and courteous tone. The reviewer also provides specific, detailed feedback which is helpful and considerate to the authors."", ""The sentiment score is slightly negative (-30) because the reviewer expresses several criticisms and doubts about the paper's arguments and approach. They describe some of the paper's arguments as 'artificial' and 'not that informative', and suggest that the comparisons made in the paper are 'vain' and 'naive'. However, the review is not entirely negative, as it acknowledges the paper's contribution and the attention the topic has received in recent literature. The politeness score is slightly positive (20) because while the reviewer is critical, they express their criticisms in a professional and academic manner. They use phrases like 'in my opinion' to soften their criticisms, and provide explanations for their viewpoints. The language is not overtly polite, but it maintains a respectful tone throughout, avoiding personal attacks or harsh language."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the paper's contributions, stating it brings 'valuable understanding' and does 'a nice job presenting some context for GAN training'. However, they also note it's 'unlikely to be a huge improvement', tempering the overall positivity. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the authors' work positively without harsh criticism. They offer constructive suggestions (e.g., 'it would be nice to see...') rather than demands, maintaining a professional and courteous tone.""]"
"['I find myself having a very hard time making a review of this paper,  because I mostly agree with the intro and discussion, and certainly agree that the ""typical"" versus ""worse case"" analysis is certainly an important point.  The authors are making a strong case for the use of these models to understand overfitting and generalization in deep leaning.\n\nThe problem is however that, except from advocating the use of these ""spin glass"" models studied back in the days by Seung, Sompolinksy, Opper and others, there are little new results presented in the paper. The arguments using the Very Simple Deep Learning (VSDL) are essentially a review of old known results --which I agree should maybe be revisited-- and the motivation to their application to deep learning stems from the reasoning  that, since this is the behavior observed in all these model, well then deep learning should behave just the same as well. This might very well be, but this is precisly the point: is it ? \n\nAfter reading the paper,  I agree with many points and enjoyed reading the discussion. I found interesting ideas discussed and many papers reviewed, and ended up discovering interesting papers on arxiv as a concequence.\n\nThis is all nice, interesting, and well written, but at the end of the day, the paper is not doing too much beyond being a nice review of all ideas. While this has indeed some values, and might trigger a renewal of interested for these approaches, I will let the comity decide if this is the material they want in ICLR.\n\nA minor comment: The generalization result of [9,11] obtained with heuristic tools (the replica method of statistical mechanics) and plotted in Fig.1 (a) has been proven recently with rigorous mathematical methods in arxiv:1708.03395 \n\nAnother remark:  if deep learning is indeed well described by these models, then again so are many other simpler problems, such as compressed sensing, matrix and tensor factorization, error corrections, etc etc... with similar phase diagram as in fig. 1.  For instance gaussian mixtures are discussed in http://iopscience.iop.org/article/10.1088/0305-4470/27/6/016/and  SVM (which the authors argue should behave quite differently) methods have been treated by statistical mechanics tools in https://arxiv.org/pdf/cond-mat/9811421.pdf with similar phase diagrams. I am a bit confused what would be so special about deep learning then?\n', '\nThis papers provides an interesting set of ideas related to theoretical understanding generalization properties of multilayer neural networks. It puts forward a qualitative analogy between some recently observed behaviours in deep learning and results stemming from previous quantitative statistical physics analysis of single and two-layer neural networks. The paper serves as a nice highlight into the not-so recent progress made in statistical physics for understanding of various models of neural networks. I agree with the authors that this line of work, that is not very well known in the current machine learning community, includes a number of ideas that should be able to shed light on some of the currently open theoretical questions. As such the paper would be a nice contribution to ICLR.\n\nOn the negative side, the paper is only qualitative. The Very Simple Deep Learning model that it introduces is not even a model in the physics or statistics sense, since it cannot be fit on data, it does not specify any macroscopic details. I only saw something like that to be called a *model* in experimental biology papers ... The models that are reviewed in the appendix, i.e. the continuous and Ising perceptron and the committee machine are more relevant. However, the present paper only reviews existing results about them. And even in that there are flaws, because it is not always clear from what previous works are the results taken nor is it clear how exactly they were obtained (e.g.  Fig. 2 (a) is for Ising or continuous weights? How was it computed? Why in Fig. 3(a) the training and generalization error is the same while in Fig. 3(c) they are different? What exact formulas were evaluated to obtain these figures?). \n\nConcerning the lack of mathematical rigour in the statistical physics literature on which the authors comment, they might want to relate to a very recent work https://arxiv.org/pdf/1708.03395.pdf work that sets all the past statistical physics results on optimal generalization in single layer neural networks on fully rigorous basis by proving that the corresponding formulas stemming from the replica method are indeed correct. \n', 'The authors suggest that ideas from statistical mechanics will help to understand the ""peculiar and counterintuitive generalization properties of deep neural networks."" The paper\'s key claim (from the abstract) is that their approach ""provides a strong qualitative description of recently-observed empirical results regarding the inability of deep neural networks not to overfit training data, discontinuous learning and sharp transitions in the generalization properties of learning algorithms, etc."" This claim is restated on p. 2, third full paragraph.\n\nI am sympathetic to the idea that ideas from statistical mechanics are relevant to modern learning theory. However, I do not find this paper at all convincing. I find the paper incoherent: I am unable to understand the argument for the central claims. On the one hand, the paper seems to be written as a ""response"" to Zhang et al.\'s ""Understanding Deep Learning Requires Rethinking Generalization"", (henceforth Z): the introduction mentions Z multiple times, and the title of this work refers to Z. On the other hand, none of the issues raised by Z are (as far as I can tell) addressed in any substantial way by this paper. In somewhat more detail, this work discusses two major observations:\n\n1. Neural nets can easily overtrain, even to random data.\n2. Popular ways to regularize may or may not help.\n\nZ certainly observes 1 and arguably observes 2. (I\'d argue against, see below, but it\'s at least arguable.) I do not see how this paper addresses either observation. Instead, what the statistical mechanics (SM) approach seems to do is explain (or predict) the existence of phase transitions, where we suddenly go from a regime of poor generalization to good generalization or vice versa. However, neither Z nor, as far as I can tell, any other reference given here, suggests that these phase transitions are frequently observed in modern deep learning. The most relevant bit from Z is Figure 1c, which suggests that as the noise level is increased (corresponding to alpha decreasing in this paper), the generalization error increases smoothly. This seems to be in direct contradiction to the predictions made by the theories presented here.\n\nIf the authors wish to hold to the claim that their work ""can provide a qualitative explanation of recently-observed empirical properties that are not easily-understandable from within PAC/VC theory of generalization, as it is commonly-used in ML"" (p. 2), it is absolutely critical that they be more specific about which specific observations from which papers they think they are explaining. As written, I simply do not see which actual observations they think they explain.\n\nIn observation 2, the authors suggest that many popular ways to implement regularization ""do not substantially improve the situation"". A careful reading of Z (and this was corroborated by discussion with the authors) is that Z observed that regularization with parameters commonly used in practice (or, put differently, regularization parameters that led to the highest holdout accuracy in other papers) still led to substantial overtraining on noisy data. I think it is almost certainly true (see below for more discussion) that much larger values of regularization can prevent overfitting, at the cost of underfitting. It\'s also worth noting that Z agrees with basically all practitioners that various regularization techniques can make an important difference to practitioners who want to minimize test error; what they don\'t do (at least at moderate values) is *qualitatively* destroy a network\'s ability to overfit to noise. It is unclear to me how this paper explains observation 2 (see below for extensive discussion).\n\nI don\'t actually understand the first full paragraph on p. 2 well. It is true that we can always avoid overtraining by tuning regularization parameters to get better generalization *error* (difference beween train and test) on the test data set (but possibly worse generalization accuracy); the rest of the paper seems to take the opposite side on this. A Gaussian kernel SVM with a small enough bandwidth and small enough regularization parameter can also overfit to noise. The argument needs to be sharpened here.\n\nI find the discussion of noise at the bottom of p. 2 confusing. The authors describe tau ""having to do with noise in the learning process"", but then suggest that ""adding noise decreases the effective load."" This is the first time noise is really talked about, and it seems like maybe noise in the data is about alpha, but noise in the ""learning process"" is about tau? This should be clarified.\n\nOn p. 3, the authors refer to ""the two parameters used by Z and many others."" I am honestly not sure what\'s being referred to here. I just reread Z and I don\'t get it.  What two parameters are used by Z?\n\np. 3, figure. The authors should be clear about what recent (ideally widely-discussed) experimental results look anything like this figure. I found nothing in Z et al. In Appendix A.4, there is a mention of Figure 3 of Chromanska et al. 2014; that figure also seems to be totally consistent with smooth transitions and does not (to me) present any obvious evidence of a sharp phase transition. (In any case, the main paper should not rely heavily on the appendix for its main empirical evidence.)\n\np. 3, figure 1a. What is essential in this figure? A single phase transition? That the error be very low on the r.h.s. of the phase transition (probably not that, judging from the related models in the\nAppendix).\n\np. 3, figure 1b/c. What does SG stand for? As far as I can tell it\'s never discussed.\n\np. 4. ""Thus, an important more general insight from our approach is that --- depending strongly on details of the model, the specific details of the learning algorithm, the detailed properties of the data and their noise etc. --- going beyond worst-case bounds can lead to a rich and complex array of manners in which generalization can depend on the control parameters of the ML process."" This is well-known to all practitioners. This paper does not seem to offer any specific testable explanations or predictions of any sort. I certainly agree that the study of SM models is ""interesting"", but what would\nmake this valuable would be a more direct analogy, a direct explanation of some empirical phenomenon.\n\nSection 2 in general. The authors discuss a couple different types of observations: (1) ""strong discontinuities in generalization performance as a function of control parameters"" aka phase transitions, and (2) generalization performance can depend sensitively on details of the model, details of algorithms, implicit regularization properties, detailed properties of data and noise, etc."" (1) shows up in the SM literature from the 90\'s discussed in Appendix A. I don\'t think it shows up in modern practice, and I don\'t think it shows up in Z. (2) is absolutely relevant to modern practitioners, but I don\'t see what this paper has to say about it beyond ""SM literature from the 90\'s exhibits similar phenomena."" The model introduced in Section 3 abstracts all such concerns away.\n\nSection 3. I am not super comfortable with the idea of ""Claims"", especially since the 3 Claims seem to be different sorts of things. I would normally think of a ""Claim"" as something that could be true or false, possibly with some argument for its truth.\n\nClaim 1 introduces a model (VSDL), but I wouldn\'t call this a claim, since nothing is actually ""claimed."" The subpoints of Claim 1 are arguably claims, but they\'re not introduced as such. I address these\nin turn:\n\n""Adding noise decreases an effective load alpha."" The paper states ""N is the effective capacity of the model trained on these data"", but ""effective capacity"" is never defined. Certainly, if we *define* alpha = m_eff / N and *define* m_eff = m - m_rand, the (sub)claim follows, but why are those definitions good?  I *think* what\'s going on here is hidden in the sentence ""empirical results indicate that for realistic DNNs it is close to 1. Thus, the model capacity N of realistic DNNs scales with m and not m_eff."", where ""it"" refers to the Rademacher complexity. Well, OK, but if we agree with that, then aren\'t we just *assuming* the main result of Z rather than explaining it? We\'re basically just stating that the models can memorize the data?\n\nI don\'t really understand the point the last part of the paragraph is trying to make (everything after what I quoted above).\n\n""Early stopping increases an effective temperature tau."" I find this plausible but don\'t understand the argument at all. To this reader, it\'s just ""stuff from SM I don\'t understand."" I think the typical ML reader of this paper won\'t necessarily be familiar with any of ""the weights evolve according to a relaxation Langevin equation"", ""from the fluctuation-dissipation theorem"", or the reference to annealing rate schedules. Consider either explaining this more or just appealing to SM and relegating this to an appendix.\n\nAfter the claim, the paper mentions that the VSDL model ignores other ""knobs"". This is fine for a model, but I think it\'s totally disingenuous to then suggest that this model explains anything about other popular ways to regularize (Observation 2 in the intro, see also my comment on Section 2). In the intro, the claim is ""Other regularizations sometimes help and sometimes don\'t and we don\'t understand why"" (the claim is about overfitting but it\'s also true for improving performance in general), which is basically true. But introducing a model which completely abstracts these things away cannot possibly explain anything about the behavior.\n\nClaim 2 is that we should consider a thermodynamic limit where model complexity grows with data (the paper says grows with the number of parameters, I assume this is a typo). I would probably call this one an ""Assumption"", with some arguments for the justification. I think this is one of the most interesting and important ideas in the paper, and I don\'t fully understand it, even after reading the appendix. I have questions. How should / could this apply to practitioners, who cannot in general hope to obtain arbitrary amounts of data? Are we assuming that any (or all) modern DNN experiments are in the asymptotic regime? Are we assuming the experiments in Z are in this regime? Is there any relevance to the fact that in an ML problem (unlike in say a spin glass, at least as far as I know) the ""complexity"" of the *task* is *not* increasing with the data size, so eventually one will have seen ""enough"" data to ""saturate"" the task?  I\'d love to know more.\n\nClaim 3 is more of an ""Informal Theorem"" that under the model of Claim 1 and the assumption of Claim 2, the phase diagrams of Figure 1 hold. The ""proof"" is a reference to SM papers. This should be clarified.\n\nYet again, I point out that I do not know any modern large-scale NN experiments that correspond to any of the pictures in Figure 1.\n\nThere\'s a mention of ""tau = 0 or t > 0."" What is the significance of tau = 0? How should an ML reader think about this?\n\nSection 3.2 suggests that Claim 3 (the existence of the 1 and 2d phase diagrams) ""explain"" Observations 1 and 2 from the Appendix. I simply do not see this. \n\nFor Observation 1, that NNs can easily overtrain, the ""argument"" seems to boil down to ""the system is in a phase where it cannot help but overtrain."" This is hardly an explanation at all. How do we know what phase these experiments were in? How do we know these experiments were in the thermodynamic limit?\n\nFor Observation 2, the authors point out that in VSDL, ""the only way to prevent overfitting is to decrease the number of iterations."" This seems true but vacuous: the authors introduced a model where regularization doesn\'t correspond to any knobs, so of course to the extent that that model explains reality, the knobs don\'t stop overfitting. But this feels like begging the question. If we accept the VSDL model, we\'d also accept that various regularizations can\'t improve generalization, which goes directly against basically all practice. I guess I technically have to concede that ""Given the three\nclaims"", Observation 2 follows, but Claim 1 by itself seems to be already assuming the conclusion.\n\nMinor writing issues:\n\nThe authors mention at least four times that reproducing others\' results is not easy (p. 1 observation 1, p. 4 first paragraph, p. 4 footnote 6, last sentence of the main text). While I think this statement is true, it is quite well-known, and I suggest that the authors may simply alienate readers by harping on it here.\n\np. 1. ""may always overtrain"" is unclear. I don\'t know what it means. Is the claim that SOTA DNNs wll always overtrain when presented with enough data? I don\'t think so from the rest of the paper, but I\'m not sure.\n\nI\'m a little unclear what the authors mean by ""generalization error"" (or ""generalization accuracy"", which seems to only be used on p. 2). Z use ""generalization error = training error - test error"". Check the appendix for consistency here too.\n\nReplace ""phenomenon"" with ""phenomena"", at least twice where appropriate.\n\np. 3, first paragraph. I think the reference to the Hopfield model should be relegated to a footnote. The text ""two or more such parameter holds more generally"" is confusing; is it two, or is it two or more? What will I understand differently if I use more than two parameters? The next paragraph, starting with ""Given these two identifications, which are novel to this work,"" seems odd, since we\'ve\njust seen 7+ references and a claim that they have similar parameterizations, so it\'s unclear what\'s novel.\n\nAppendix A.5. ""For non-linear dynamical systems... NNs from the 80s/90s or our VSDL model or realistic DNNs today .. there is simply no reason to expect this to be true."" where ""this"" refers to ""one can always choose a value of lambda to prevent overfitting, potentially at the expense of underfitting."" I don\'t understand, and I also think this disagrees with the first full paragraph on p. 2. Is there some thermodynamic limit argument required here? The very next bullet states that x = argmin_x f(x) + lambda g(x) can prevent overfitting with large lambda. What\'s different? I\'m overall not clear what\'s being implied here. Consider a modern DNN for classification. A network with all zero weights will have some empirical loss L(0). If I minimize, for the weights of a network w, L(w) + lambda ||w||^2, I have that L(w) + lambda ||w||^2 <= L(0) (assuming I can solve the optimization), and assuming L is non-negative, lambda ||w||^2 <= L(0), or ||w||^2 <= L(0) / lambda. So for very large lambda, I can drive ||w||^2 arbitrarily close to zero. How is this importantly different from the linear case?  What am I missing?\n\np. 3. ""inability not to overfit."" Avoid the double negative.\n\nIntro, last paragraph. Weird section order description, with ref to Section A coming before section 4.\n\nFootnote 2. ""but it can be quite limiting."" More detail needed. Limiting how?\n\nFootnotes 3 and 4. The text says there are ""technical"" and ""non-technical"" reasons, but 3 and 4 both seem technical to me.\n\nAppendix A.2. ""on a randomly chosen subset of X."" Is it really subset? Are we picking subsets uniformly at random?\n']","[-20, -20, -70]","[60, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer agrees with some aspects and found the paper interesting, they ultimately conclude there is little new research presented and question if it's suitable for the conference. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. They use phrases like 'I agree', 'I found interesting ideas', and 'This is all nice, interesting, and well written' before presenting concerns. The reviewer also leaves the final decision to the committee rather than outright rejecting the paper."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('interesting set of ideas', 'nice highlight', 'nice contribution'), they also point out significant shortcomings ('only qualitative', 'flaws', 'lack of mathematical rigour'). The criticism outweighs the praise, but not overwhelmingly so. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positives before presenting criticisms, and offering constructive suggestions. They avoid harsh or dismissive language, instead using phrases like 'On the negative side' to introduce criticisms. The reviewer also provides specific recommendations for improvement, which is a polite and constructive approach."", ""The sentiment score is -70 because the reviewer expresses significant criticism and skepticism throughout the review. They state they do not find the paper convincing, describe it as 'incoherent', and repeatedly point out that they don't see how the paper explains or addresses the issues it claims to. The reviewer does mention being 'sympathetic' to the general approach at the beginning, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is direct in their criticism, they generally use professional language and offer specific suggestions for improvement. They avoid personal attacks and use phrases like 'I don't understand' or 'It is unclear to me' rather than accusing the authors of being unclear. However, there are a few instances of more pointed language (e.g., 'I simply do not see this', 'This is hardly an explanation at all') that prevent a higher politeness score.""]"
"['(Summary)\nThis paper proposes weighted RBF distance based loss function where embeddings for cluster centroids and data are learned and used for class probabilities (eqn 3). The authors experiment on CUB200-2011, Cars106, Oxford 102 Flowers datasets.\n\n(Pros)\nThe citations and related works cover fairly comprehensive and up-to-date literatures on deep metric learning.\n\n(Cons)\nThe proposed method is unlikely to scale with respect to the number of classes. ""..our approach is also free to create multiple clusters for each class.."" This makes it unfair to deep metric learning baselines in figures 2 and 3 because DMP baselines has memory footprint constant in the number of classes. In contrast, the proposed method have linear memory footprint in the number of classes. Furthermore, the authors ommit how many centroids are used in each experiments.\n\n(Assessment)\nMarginally below acceptance threshold. The method is unlikely to scale and the important details on how many centroids the authors used in each experiments is omitted.', ""The authors propose a loss that is based on a RBF loss for metric learning and incorporates additional per exemplar weights in the index for classification. Significant improvements over softmax are shown on several datasets.\n\nIMHO, this could be a worthwhile paper, but the framing of the paper into existing literature is lacking and thus it appears as if the authors are re-inventing the wheel (NCA loss) under a different name (RBF solver).\n\nThe specific problems are:\n- The authors completely miss the connection to NCA loss (https://papers.nips.cc/paper/2566-neighbourhood-components-analysis.pdf) and thus appear to be re-inventing the wheel.\n  - The proposed metric learning scenario is exactly as proposed in the NCA loss works, while the classification approach adds an interesting twist by learning per exemplar weights. I haven't encountered this before and it could make an interesting proposal. Of course the benefit of this should be evaluated in ablation studies( Tab 3 shows one experiment with marginal improvements).\n- The authors' use of 'solver' seems uncommon and confusing. What is proposed is a loss in addition to building a weighted index in the case of classification.\n- In the metric learning comparison with softmax (end of page 9) the authors mentions that a Gaussian standard deviation for softmax is learned. It appears as if the authors use the softmax logits as embedding whereas the more common approach is to use the bottleneck layer. This is also indicated by the discussion at the end of page 10 where the authors mention that softmax is restricted to axis aligned embeddings. All softmax metric learning experiments should be carried out on appropriately sized bottleneck layers.\n- Some of the motivations of what the various methods learn seem flawed, e.g. triplet loss CAN learn multiple modes per class and there is nothing in the Softmax loss that encourages the classes to fill a large region of the space.\n- Why don't the authors compare on ImageNet?\n\nSome positive points:\n- The authors mention in Sec 3.3 that updating the RBF centres is not required. This is a crucial point that should be made a centerpiece of this work, as there are many metric learning works that struggle with this. Additional experiments that can investigate this point would greatly contribute to a well rounded paper.\n- The numbers reported in Tab 1 show very significant improvements\n\nIf the paper was re-framed and builds on top of the already existing NCA loss, there could be valuable contributions in this paper. The experimental comparisons are lacking in some respect, as the comparison with Softmax as a metric learning method seems uncommon, i.e. using the logits instead of the bottleneck layer. I encourage the authors to extend the paper and flesh out some of the experiments and then submit it again."", '- The paper proposes to use RBF kernel based neurons with each training data point as a center of\n  one of the RBF kernel neuron. (i) Kernel based neural networks have been explored before [A] and\n  (ii) ideas similar to the nearest neighbour based efficient but approximate learning for mixture\n  of Gaussians like settings have also been around, e.g. in traning GMMs [B]. Hence I would consider\n  the novelty to be very low \n- The paper says that the method can be applied to embedding learning and classification, which were\n  previously separate problems. This is largely incorrect as many methods for classification,\n  especially in zero- and few-shots settings (on some of the datasets used in the paper) are using\n  embedding learning [C], one of the cited and compared with paper (Sohn 2016) also does both\n  (mostly these methods use k-NN classifier with Euclidean distance between learned embeddings)\n- It seems that the method thus is adding a kernel neuron layer, with the number equal to the number\n  of training samples, centers initialized with the training samples, followed by a normalized\n  voting based on the distance of the test example with training examples of different classes\n  (approximately a weighted k-NN classifier)\n- The number of neurons in the last layer thus scales with the number of training examples, which\n  can be prohibitively large \n- It is difficult to understand what exactly is the embedding; if the number of neurons in the\n  RBF layer is equal to the number of training examples then it seems the embedding is the activation\n  of the layer before that (Fig1 also seems to suggest this). But the evaluation is done with\n  different embedding sizes, which suggests that another layer was inserted between the last FC\n  layer of the base network and the RBF layer. In that case the empirical validation is not fair as\n  the network was made deeper.\n- Also, it is a bit confusing that as training proceeds the centers change (Sec3.3 first few lines),\n  so the individual RBF neurons, eventually, do not necessarily correspond to the training examples\n  they were initialized with, but the final decision (Eq4) seems to be taken assuming that the\n  neurons do correspond to the training examples (and their classes). While the training might\n  ensure that the centers do not move so much, this should be explicitly discussed and clarified.\n  \nOverall, the novelty of the paper seems to be low and it is difficult to understand what exactly is\nbeing done.  \n\n[A] Xu et al., Kernel neuron and its training algorithm, ICONIP 2001\n[B] Verbeek et al., Efficient greedy learning of gaussian mixture models, Neural Computation 2003\n[C] Xian et al., Latent Embeddings for Zero-shot Classification, CVPR 2016']","[-30, -20, -80]","[20, 50, -20]","[""The sentiment score is -30 because the review is generally negative, with the final assessment stating the paper is 'Marginally below acceptance threshold.' The reviewer points out significant cons, such as scalability issues and omission of important details. However, it's not extremely negative as some pros are mentioned and the language isn't harsh. The politeness score is 20 because the reviewer uses professional and respectful language throughout, acknowledging both pros and cons objectively. They avoid personal attacks or overly critical language, maintaining a constructive tone even when pointing out weaknesses. The slightly positive politeness score reflects the reviewer's effort to provide balanced feedback in a courteous manner."", ""The sentiment score is slightly negative (-20) because while the reviewer sees potential in the paper ('this could be a worthwhile paper'), they express significant concerns about the framing and methodology. The reviewer points out several issues, such as missing connections to existing literature and potentially flawed motivations. However, they also note some positive aspects, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'IMHO' and 'I encourage the authors', and provides constructive feedback. They balance criticism with positive points and offer suggestions for improvement, which contributes to the polite tone. The reviewer avoids harsh language and frames their critique in a way that is helpful rather than dismissive."", ""The sentiment score is -80 because the review is highly critical of the paper, pointing out low novelty, incorrect claims, and difficulties in understanding the method. The reviewer states that 'Overall, the novelty of the paper seems to be low and it is difficult to understand what exactly is being done,' which is a strongly negative assessment. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite blunt and dismissive. The reviewer doesn't soften criticisms or offer encouragement, instead directly stating problems and using phrases like 'largely incorrect' and 'difficult to understand.' The lack of any positive comments or constructive suggestions also contributes to the slightly impolite tone.""]"
"['The authors of this manuscript proposed a model called PMN based on previous works for the classification of transcription factor binding. Overall, this manuscript is not well written. Clarification is needed in the method and data sections. The model itself is an incremental work, but the application is novel. My specific concerns are given below.\n\n1. It is unclear how the prototype of a TF is learned. Detailed explanation is necessary. \n\n2. Why did the authors only allow a TF to have only one prototype? A TF can have multiple distinct motifs.\n\n3. Why peaks with p-value>=1 were defined as positive? Were negative classes considered in the computational experiments?\n\n4. What\'s the relationship between the LSTM component in the proposed method and sparse coding?\n\n5. The manuscript contains lots of low-end issues, such as:\n5.1. Inconsistency in the format when referring to equations (eq. equation, Equation, attention LSTM, attentionLSTM, t and T etc);\n5.2. Some ""0""s are missing in Table 3;\n5.3. L2 should be L_2 norm; \n5.4. euclidean -> Euclidean; pvalue-> p-value;\n5.5. Some author name and year citations in the manuscript should be put in brackets;\n5.6. The ENCODE paper should be cited properly, (""Consortium et al., 2012"" is weird!) ;\n5.7. The references should be carefully reformatted, for example, some words in the references should be in uppercase (e.g. DNA, JASPER, CNN etc.), some items are duplicated, ...\n\nComments for the revised manuscript: I decide to keep my decision as it is. My major and minor concerns are not fully well addressed in the revised paper. ', 'This work proposes an approach for transcription factor binding site prediction using a multi-label classification formulation. It is a very interesting problem and application and the approach is interesting. \n\nNovelty:\nThe method is quite similar to matching networks (Vinyals, 2016) with a few changes in the matching approach. As such, in order to establish its broader applicability there should be additional evaluation on other benchmark datasets. The MNIST performance comparison is inadequate and there are other papers that do better on it. \nThey should clearly list what the contributions are w.r.t to the work by Vinyals et al 2016.\nThey should also cite works that learn embeddings in a multi-label setting such as StarSpace.\n\nImpact:\nIn its current form the paper seems to be most relevant to the computational biology / TFBS community. However, there is no comparison to the exact networks used in the prior works DeepBind/DeepSea/DanQ/Basset/DeepLift or bidirectional LSTMs. Further there is no comparison to existing one-shot learning techniques either. This greatly limits the impact of the work.\n\nFor biological impact, a comparison to any of the motif learning approaches that are popular in the biology/comp-bio community will help (for instance, HOMER, FIMO).\n\nCons:\nThe authors claim they can learn TF-TF interactions and it is one of the main biological contributions, but there is no evidence of why (beyond very preliminary evaluation using the Trrust database). Their examples are 200-bp long which does not mean that all TFs binding in that window are involved in cooperative binding. The prototype loss is too simplistic to capture co-binding tendencies and the combinationLSTM is not well motivated. One interesting source of information they could tap into for TF-TF interactions is CAP-SELEX (Jolma et al, Nature 2015).\n\nOne of the main drawbacks is the lack of interpretability of their model where approaches like DanQ/DeepLift etc benefit. The PWM-like filters in some of the prior works help understand what type of sequence properties contribute to binding events. Can their model lead to an understanding of this sort?\n\nEvaluation:\nThe empirical evaluation itself is not very strong as there are only modest improvements over simple baselines. Further there are no error-bars etc to indicate the variance in their performance numbers.\nIt will be useful to have a TF-level performance split-up to get an idea of which TFs benefit most.\n\nClarity:\nThe paper can benefit from more clarity in the technical aspects. It is hard to follow for anyone not already familiar with matching networks. The objective function, parameters need to be clearly introduced in one place. For instance, what is y_i in their multi-label framework?\nVarious choices are not well motivated; for instance cosine similarity, the value of hyperparameter epsilon.\nThe prototype vectors are not motif-like at all -- can the authors motivate this aspect better?\n\nUpdate: I have updated my rating based on the author rebuttal', 'Summary\nThis paper proposes a prototype matching network (PMN) to model transcription factor (TF) binding motifs and TF-TF interactions for large scale transcription factor binding site prediction task. They utilize the idea of having a support set of prototypes (motif-like features) and an LSTM from the few shot learning framework to develop this prototype matching network. The input is genomic sequences from 14% of the human genome, each sequence in the dataset is bound by at least one TF. First a Convolutional Neural Network with three convolutional layers is trained to predict single/multiple TF binding. The output of the last hidden layer before sigmoid transformation is used as the LSTM input. A weighted sum of similarity score (sigmoid of cosine similarity, similar to attention mechanism of LSTMs) along with prototype vectors are used to update the read vector. The final output is a sigmoid of the final hidden state concatenated with the read vector. The loss function used is difference of a cross-entropy loss function and a lambda weighted prototype loss function. The latter is the mean square error between the output label and the similarity score.  The authors compare the PMN with different lambda values with CNN with single/multi-label and see marginal improvement in auROC, auPR and Recall at 50% FDR with the PWM. To test that PWN finds biologically relevant TF interactions, the authors perform hierarchical clustering on the prototypes of 86 TFs and compare the clusters found to the known co-regulators from the TRRUST database and find 6 significant clusters. \n\n\nPros:\n1. The authors utilize the idea of prototypes and few shot learning to the task of TF-binding and cooperation. \n\n2. Attention LSTMs are used to model label interactions. \n\nJust like CNN can be related to discriminative training of PSSM or PWM, the above points demonstrate nicely how ideas/concepts from the recent developments in DL can be adopted/relate (and possibly improve on) to  similar generative modeling approaches used in the past  for learning cooperative TF binding.\n\nCons:\n\n1. Authors do not compare their model’s performance to the previously published TF binding prediction algorithms (DeepBind, DeepSEA). \n2. The authors miss important context and make some inaccurate statements: TF do not just “control if a gene is expressed or not” (p.1). It’s not true that previous DL works did not consider co-binding. Works such as DeepSea combined many filters which can capture cooperative binding to define which sequence is “regulated”. It is true this or DeepBind did not construct a structure a structure over those as learned by an LSTM. The authors do point out a model that does add LSTM (Quang and Xie) but then do not compare to it and make a vague claim about it modeling interactions between features but not labels (p. 6 top). Comparing to it and directly to DeepSee/Bind seems crucial to claim improvements on previous works. Furthermore, the authors acknowledge the existence of vast literature on this specific problem but completely discard it as “loose connection to our TFBS formulation”. In reality though, many works in that area are highly relevant and should be discussed in the context of what the authors are trying to achieve. For example, numerous works by Prof. Saurabh Sinha have focused specifically on joint TF modeling (e.g. Kazemian NAR 2011, He Plos One 2009, Ivan Gen Bio 2008, MORPH Plos Comp Bio 2007). In general, trying to lay claims about significant contributions to a problem, as stated here by the authors, while completely disregarding previous work simply because it’s not in a DL framework (which the authors are clearly more familiar with) can easily alienate reviewers and readers alike.  \n\n3. The learning setup seems problematic:\n3a. The model may overfit for the genomic sequences that contain TF binding sites as it has never seen genomic sequences without TF binding sites (the genomic sequences that don’t have CHIP peaks are discarded from the dataset). Performance for genome wide scans should definitely include those to assess accuracy.\n3b. The train/validation/test are defined by chromosome. There does not seem to be any screening for sequence similarity (e.g. repetitive sequences, paralogs). This may inflate performance, especially for more complicated models which may be able to “memorize” sequences better. \n4. The paper claims to have 4 major contributions. The details of second claim that the prototype matching loss learns motif like features is not explained anywhere in the paper. If we look at the actual loss function equation (12), it penalizes the difference between the label and the similarity score but the prototypes are not updated. The fourth claim about the biological relevance of the network is not sufficiently explored. The authors show that it learns co-bindings already known in the literature which is a good sanity check but does not offer any new biological insight.  The actual motifs or the structure of their relations is not shown or explored.\n5. PWN offers only marginal improvement over the CNN networks \n\n']","[-60, -20, -40]","[-20, 50, 20]","[""The sentiment score is -60 because the review starts with a negative overall assessment ('not well written'), lists several concerns, and concludes with a decision to 'keep my decision as it is', implying rejection or major revision. The politeness score is -20 because while the reviewer provides specific feedback, the tone is somewhat blunt and critical ('lots of low-end issues', 'weird!'), without much softening language or positive reinforcement. The reviewer does acknowledge the novel application, which prevents the scores from being even lower, but the overall tone remains critical and direct."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'very interesting', they raise several significant concerns about novelty, impact, evaluation, and clarity. They point out limitations in comparisons, lack of interpretability, and modest improvements over baselines. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positives and framing criticisms constructively as suggestions for improvement (e.g. 'The paper can benefit from...', 'It will be useful to...'). The reviewer maintains a professional tone without harsh or rude comments, even when pointing out shortcomings."", ""The sentiment score is -40 because while the review acknowledges some positive aspects ('Pros'), it lists more significant criticisms ('Cons') that outweigh the positives. The reviewer points out several major issues with the paper, including lack of comparison to previous work, problematic learning setup, and overstated claims of contribution. The politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language to describe both pros and cons. They avoid harsh or personal criticisms, instead focusing on specific scientific and methodological issues. The reviewer also acknowledges the positive aspects of the work before delving into criticisms, which is a polite approach. However, the score is not higher as the review is quite direct in its criticisms without much softening language.""]"
"['Quality and Clarity\nThe neural networks and neural codes are studied  in a concise way, most of the paper is clear. The section on data design, p3, could use some additional clarification wrt to how the data input is encoded (right now, it is hard to understand exactly what happens). \n\nOriginality\nI am not aware of other studies on this topic, the proposed approach seems original. \n\nSignificance\nThe biggest problem I have is with the significance: I don\'t see at all how finding somewhat localized responses in the hidden layer of an MLP with just one hidden layer has any bearing on deeper networks structured as CNNs: compared to MLPs, neurons in CNNs have much smaller receptive fields, and are known to be sensitive to selective and distinct  features.  \n\nOverall the results seem rather trivial without greater implications for modern deep neural networks: ie, of course adding dropout improves the degree of localist coding (sec 3.4). Similarly, for a larger network, you will find fewer localist codes (though this is hard to judge, as an exact definition of selectivity is missing). \n\nMinor issues: the ""selectivity"" p3 is not properly defined.  On p3, a figure is undefined. \nTypo: p2: ""could as be"". \nMany of the references are ugly : p3,  ""in kerasChollet (2015)"", this needs fixing. ', 'The authors ask when the hidden layer units of a multi-layer feed-forward neural network will display selectivity to object categories. They train 3-layer ANNs to categorize binary patterns, and find that typically at least some of the hidden layer units are category selective. The number of category selective (""localist"") units varies depending on the size of the hidden layer, the structure of the outputs the network is trained to return (i.e., one-hot vs distributed), the neurons\' activation functions, and the level of dropout-induced noise in the training procedure.\n\nOverall, I find the work to hint at an interesting phenomenon. However, the paper as presented uses an overly-simplistic task for the ANNs, and the work is sloppily presented. These factors detract from my enthusiasm. My specific criticisms are as follows:\n\n1) The binary pattern classification seems overly simplistic a task for this study. If you want to compare to the medial temporal lobe\'s Jennifer Aniston cells (i.e., the Quiroga result), then an object recognition task seems much more meaningful, as does a deeper network structure. Likewise, to inform the representations we see in deep object recognition networks, it is better to just study those networks, instead of simple shallow binary classification networks. Or, at least show that the findings apply to those richer settings, where the networks do ""real"" tasks.\n\n2) The paper is somewhat sloppy, and could use a thorough proofreading. For example, what are ""figures 3, ?? and 6""? And which is Figure 3.3.1?\n\n3) What formula is used to quantify the selectivity? And do the results depend on the cut-off used to label units as ""selective"" or not (i.e., using a higher or lower cutoff than 0.05)? Given that the 0.05 number is somewhat arbitrary, this seems worth checking.\n\n4) I don\'t think that very many people would argue that the presence of distributed representations strictly excludes the possibility of some of the units having some category selectivity. Consequently, I find the abstract and introduction to be a bit off-putting, coming off almost as a rant against PDP. This is a minor stylistic thing, but I\'d encourage the authors to tone it down a bit.\n\n5) The finding that more of the selective units arise in the hidden layer in the presence of higher levels of noise is interesting, and the authors provide some nice intuition for this phenomenon (i.e., getting redundant local representations makes the system robust to the dropout). This seems interesting in light of the Quiroga findings of Jennifer Aniston cells: the fact that the (small number of) units they happened to record from showed such selectivity suggests that many neurons in the brain would have this selectivity, so there must be a large number of category selective units. Does that finding, coupled with the result from Fig. 6, imply that those ""grandmother cell"" observations might reflect an adaptation to increase robustness to noise? \n', 'This paper studies the development of localist representations in the hidden layers\nof feed-forward neural networks.\n\nThe idea is interesting and the findings are intriguing.  Local codes\nincrease understandability and could be important for better\nunderstanding natural neural networks. Understanding how local codes\nform and the factors that increase their likelihood is critically\nimportant.  This is a good start in that direction, but still leaves\nopen many questions.  The issues raised in the Conclusions section are\nalso very interesting -- do the local codes increase with networks\nthat generalize better, or with overtrained networks?\n\nA  weakness in this paper (admitted by the authors in the\nConclusions section) is the dependence of the results on the form of input\nrepresentation.  If we consider the Jennifer Aniston cells, they do\nnot receive as input as well separated inputs as modeled in this\npaper.  In fact the input representation used in this study is already\na fairly localist representation as each 1 unit is fairly selectively\non for its own class and mostly off for the other classes.  It will be\nvery interesting to see the results of hidden layers in deep networks\noperating on natural images.\n\nPlease give your equation for selectivity.  On Page 2 it is stated ""We\nuse the word ‘selectivity’ as a quantitative measure of the difference\nbetween activations for the two categories, A and not-A, where A is\nthe class a neuron is selective for (and not-A being all other\nclasses).""  However you state that neurons were counted as a local\ncode if the selectivity was above .05.  A difference between\nactivations for the two categories of .05 does not seem very\nselective, so I\'m thinking you used something other than the\nmathematical difference.\n\nWhat is the selectivity of units in the input codewords?  With no\nperturbation, and S_x=.2, w_R=50, w_P=50, the units in the prototype\nblocks have a high selectivity responding with 1 for all patterns in\ntheir class and with 0 for 8/9 of the patterns in the other classes.\nCould this explain the much higher selectivity for this case in the\nhidden units?  I would like to see the selectivity of the input units\nfor each of the plots/curves.  This would be especially interesting\nfor Figure 5.\n\nIt is stated that LCs emerge with longer training and that ReLU\nneurons may produce more LCs because they train quicker and all\nexperiments were stopped at 45,000 epochs.  Why not investigate this\nby changing learning rates for one of ReLu or sigmoidal units to more\nclosely match their training speed?  It would be interesting to see if\nthe difference is simply due to learning rate, or something deeper\nabout the activation functions.\n\nYou found that very few local codes in the HLNs were found when a\n1-hot ouput encoding was used and suggest that this means that\nemergent local codes are highly unlikely to be found in the\npenultimate layer of deep networks.  If your inputs are a local code\n(e.g. for low w_R), you found local codes above the layer of local\ncodes but in this result not below the layer of local codes which\nmight also imply (as you say in the Conclusions) that more local\ncoding neurons may be found in the higher layers (though not the\npenultimate one as you argue).  Could you analyze how the selectivity\nof a hidden layer changes as a function of the selectivity in the\nlower and higher layers?\n\n\n\nMinor Note -- The Neural Network Design section looks like it still\nhas draft notes in it.\n\n\n']","[-20, -20, 50]","[50, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects (originality, clarity in parts), they express significant concerns about the paper's significance and implications. The reviewer states that the results seem 'rather trivial' and questions the relevance to modern deep neural networks. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, even when expressing criticisms. They offer specific suggestions for improvement and use phrases like 'could use some additional clarification' rather than harsh criticism. The reviewer also acknowledges positive aspects before diving into concerns, which is a polite approach to feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the work 'to hint at an interesting phenomenon', they express several criticisms and state that factors 'detract from my enthusiasm'. The overall tone suggests more criticism than praise. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, such as 'I find', 'I'd encourage', and provides constructive feedback. They also acknowledge interesting aspects of the work. However, they don't use overly deferential language, maintaining a professional tone. The reviewer balances criticism with positive remarks and suggestions for improvement, indicating a respectful but honest approach."", ""The sentiment score is 50 (moderately positive) because the reviewer expresses interest in the paper's ideas and findings, calling them 'intriguing' and 'critically important'. They also mention it's a 'good start' in the research direction. However, they point out some weaknesses and areas for improvement, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the authors' own admissions of limitations, and framing criticisms as suggestions or questions rather than direct attacks. They use phrases like 'It would be interesting to see' and 'Could you analyze' which maintain a collaborative tone. The reviewer also balances critique with praise, showing consideration for the authors' work.""]"
"['This paper is well written and easy to follow. The authors propose pixel deconvolutional layers for convolutional neural networks. The motivation of the proposed method, PixelDCL, is to remove the checkerboard effect of deconvolutoinal layers. \nThe method consists of adding direct dependencies among the intermediate feature maps generated by the deconv layer. PixelDCL is applied sequentially, therefore it is slower than the original deconvolutional layer. The authors evaluate the model in two different problems: semantic segmentation (on PASCAL VOC and MSCOCO datasets) and in image generation VAE (with the CelebA dataset). \n\nThe authors justify the proposed method as a way to alleviate the checkerboard effect (while introducing more complexity to the model and making it slower). In the experimental section, however, they do not compare with other approaches to do so For example, the upsampling+conv approach, which has been shown to remove the checkerboard effect while being more efficient than the proposed method (as it does not require any sequential computation). Moreover, the PixelDCL does not seem to bring substantial improvements on DeepLab (a state-of-the-art semantic segmentation algorithm). More comments and further exploration on this results should be done. Why no performance boost? Is it because of the residual connection? Or other component of DeepLab? Is the proposed layer really useful once a powerful model is used?\n\nI also think the experiments on VAE are not conclusive. The authors simply show set of generated images. First, it is difficult to see the different of the image generated using deconv and PixelDCL. Second, a set of 20 qualitative images does not (and cannot) validate any research idea.', 'This paper proposed the new approach for feature upsampling called pixel deconvolution, which aims to resolve checkboard artifact of conventional deconvolution. By sequentially applying a series of decomposed convolutions, the proposed method explicitly enforces the model to consider the relation between pixels thus effectively improve the deconvolution network with an increased computational cost to some extent.\n\nOverall, the paper is clearly written and easy to understand the main motivation and methods. However, the checkboard artifact is a well-known problem of deconvolution network, and has been addressed by several approaches which are simpler than the proposed pixel deconvolution. For example, it is well known that simple bilinear interpolation optionally followed by convolutions effectively removes checkboard artifact to some extent, and bilinear additive upsampling proposed in Wonja et al., 2017 also demonstrated its effectiveness as an alternative for deconvolution. Comparisons against these approaches would make the paper stronger. Besides, comparisons/discussions based on extensive analysis on various deconvolution architectures presented in Wonja et al., 2017 would also be interesting.\n\nWonja et al, The Devil is in the Decoder, In BMVC, 2017\n', 'Paper summary:\nThis paper proposes a technique to generalize deconvolution operations used in standard CNN architectures. Traditional deconvolution operation uses independent filter weights to compute output features at adjacent pixels. This work proposes to do sequential prediction of adjacent pixel features (via intermediate feature maps) resulting in more spatially smooth outputs for deconvolution layer. This new layer is referred to as ‘pixel deconvolution layer’ and it is demonstrated on two tasks of semantic segmentation and face generation.\n\n\nPaper Strengths:\n- Despite being simple technique, the proposed pixel deconvolution layer is novel and interesting.\n- Experimental results on two different tasks demonstrating the general use of the proposed deconvolution layer.\n\n\nMajor Weaknesses:\n- The main weakness of this paper lies in its weak experiments. Although authors say that several possibilities exist for the dependencies between intermediate feature maps, there are no systematic ablation studies on what type of connectivities work best for the proposed layer. Authors experimented with two randomly chosen connectivities which is not enough to understand what type of connectivities work best. This is important as this forms the main contribution of the paper.\n- Also, several quantitative results seem incomplete. Why is the DeepLab-ResNet performance so low? A quick look at PascalVOC results indicate that DeepLab-ResNet has IoU of over 79 on this dataset, but the reported numbers in this paper are only around 73 IoU. There is no mention of IoU for base DeepLab-ResNet model and the standard DeepLab+CRF technique. And, there are no quantitative results on image generation.\n\n\nMinor Weaknesses:\n- Although the paper is easy to understand, several parts of the paper are poorly written. Several sentences are repeated multiple times across the paper. Some statements need corrections/refinements such as “mean IoU is a more accuracy evaluation measure”. And, it is better to under-tone some statements such as changing “solving” to “tackling”.\n- The illustration of checkerboard artifacts from standard deconvolution technique is not clear. For example, the results presented in Figure-4 indicate segmentation mistakes of the network rather than checkerboard artifacts.\n\n\nClarifications:\n- Why authors choose to ‘resize’ the images for training semantic segmentation networks, instead of generally used ‘cropping’ to create batches?\n- I can not see the ‘red’ in Figure-5. I see the later feature map more as ‘pinkish’ color. It is probably due to my color vision. In any case, it is better to use different color scheme to distinguish.\n\n\nSuggestions:\n- I strongly advice authors to do some ablation studies on connectivities to make this a good paper. Also, it would be great if authors can revise the writing thoroughly to make this a more enjoyable read.\n\n\nReview Summary:\nThe proposed technique, despite being simple, is novel and interesting. But, the weak and incomplete experiments make this not yet ready for publication.']","[-20, 20, -50]","[50, 60, 50]","['The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and easy to follow, they express several criticisms and concerns about the method and experiments. The reviewer points out limitations in the experimental comparisons, questions the usefulness of the proposed method, and finds the VAE experiments inconclusive. These criticisms outweigh the initial positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They begin with positive comments and phrase their criticisms as suggestions or questions rather than harsh statements. The reviewer maintains a constructive tone, even when pointing out shortcomings, which contributes to the polite impression.', ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's clarity and ease of understanding, but also points out significant limitations and suggests comparisons with existing methods. The overall tone is constructive but not overwhelmingly positive. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering critiques, and phrases suggestions in a non-confrontational manner (e.g., 'would make the paper stronger', 'would also be interesting'). The reviewer maintains a professional and courteous tone while providing substantive feedback."", ""The sentiment score is -50 because while the reviewer acknowledges some strengths of the paper ('novel and interesting'), they also point out significant weaknesses ('weak experiments', 'incomplete' results) and conclude that the paper is 'not yet ready for publication'. This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'I strongly advise' and 'it would be great if', which are polite ways of giving feedback. However, the review is not overly effusive or deferential, maintaining a professional tone, hence the moderate positive score rather than a very high one.""]"
"[""This is an interesting paper.\n\nIt is well known that TBPTT is biased because of a fixed truncation length. The authors propose to make it  unbiased by sampling different truncation lengths and hence changing  the optimization procedure which corresponds to adding noise in the gradient estimates which leads to  unbiased gradients. \n\nPros:\n\n- Its a well written and easy to follow paper.\n- If I understand correctly, they are changing the optimization procedure so that the proposed approach is able to find a local minima, which was not possible by using truncated backpropagation through time.  \n- Its interesting to see in there PTB results that they get better validation score as compared to truncated BPTT.\n\nCons: \n\n- Though the approach is interesting, the results are quite preliminary. And given the fact there results are worse than the LSTM baseline (1.40 v/s 1.38). The authors note that it might be because of they are applying without sub-sequence shuffling. \n\n- I'm not convinced of the approach yet. The authors could do some large scale experiments on datasets like Text8 or speech modelling. \n\n\nFew points\n\n- If I'm correct that the proposed approach indeed changes the optimization procedure, than I'd like to know what the authors think about exposure bias issue. Its a well known[1, 2] that we can't sample from RNN's for more number of steps, than what we used for trained (difference b/w teacher forcing and free running RNN). I'd like to know how does there method perform in such a regime (where you sample for more number of steps than you have trained for)\n\n- Another thing, I'd like to see is the results of this model as compared to truncated backpropagation when you increase the sequence length. For example, Lets say you are doing language modelling on PTB, how the result varies when you change the length of the input sequence. I'd like to see a graph where on X axis is the length of the input sequence and on the Y axis is the bpc score (for PTB) and how does it compare to truncated backpropagation through time. \n\n-  PTB dataset has still not very long term dependencies, so I'm curious what the authors think about using there method for something like speech modelling or some large scale experiments.\n\n- I'd expect the proposed approach to be more computationally expensive as compared to Truncated Back-propagation through time. I dont think the authors mentioned this somewhere in the paper. How much time does a single update takes as compared to Truncated Back-propagation through time ?\n\n- Does the proposed approach help in flow of gradients?  \n\n- In practice for training RNN's people use gradient clipping which also makes the gradient biased. Can the proposed method be used for training longer sequences?  \n\n[1] Scheduled Sampling For Sequence Prediction with RNN's https://arxiv.org/abs/1506.03099\n[2] Professor Forcing  https://arxiv.org/abs/1610.09038\n\n\nOverall, Its an interesting paper which requires some more analysis to be published in this conference. I'd be very happy to increase my score if the authors can provide me results what I have asked for. "", 'This paper proposes stochastic determination methods for truncation points in backpropagation through time. The previous truncation methods naively determine truncation points with fixed intervals, however, these methods cannot ensure the unbiasedness of gradients. The proposed methods stochastically determine truncation points with importance sampling. This framework ensures the unbiasedness of gradients, which contribute to the reliable convergence. Moreover, this paper investigates how the proposed methods work effectively by carefully tuning the sampling probability. This paper shows two experimental results, in which one is a simple synthetic task and the other is a real-data task. These results validate the effectiveness of the proposed methods.\n\nOverall, I think the constitution and the novelty of this paper are above the bar. The proposed methods are simple extensions of the Truncated BPTT to ensure the unbiasedness. In particular, the investigation on the choice of the sampling probability is very helpful to consider how to enhance benefits of the proposed truncated BPTT methods. However, the written quality of this paper is not good at some points. I think the authors should re-check the manuscript and modify mistakes before the publication.', 'This paper introduces a new approximation to backpropagation through time (BPTT) to overcome the computational and memory load that arise when having to learn from long sequences. \nRather than chopping the sequence into subsequences of equal length as in truncated BPTT, the authors suggest to segment the sequence into subsequences of differing lengths according to an a priori specified distribution for the segment length. The gradient estimator is made unbiased through a weighting procedure.\n\nWhilst the proposed method is interesting and relevant, I find the analysis quite superficial and limited.\n\n1) The distribution for the segment length is fully specified a priori. Depending on the problem at hand, different specifications could give rise to very different results. It would be good to suggest an approach for more automatically determine the (parameters of the) distribution.\n\n2) Whilst unbiased, the proposed estimator could have high variance. This point is not investigated in the experimental section.\n\n3) For an experimental paper as this one, it would be good to have many more problems analysed and a deeper analysis than the one given for the language problem.  \n\n\n']","[20, 60, -20]","[60, 70, 50]","[""The sentiment score is slightly positive (20) because the reviewer describes the paper as 'interesting' and 'well written', and notes some pros. However, they also express significant concerns and request additional experiments, indicating they are not fully convinced. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms constructively, and expresses willingness to increase their score if the authors address their concerns. They also acknowledge the paper's strengths alongside areas for improvement."", ""The sentiment score is 60 (positive) because the reviewer states that the paper's constitution and novelty are 'above the bar' and validates the effectiveness of the proposed methods. They also mention that the investigation is 'very helpful'. However, it's not a perfect score due to the criticism of the written quality. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They acknowledge the paper's strengths before pointing out areas for improvement. The phrase 'I think the authors should re-check' is a polite way of suggesting revisions. The overall tone is professional and courteous, without being overly formal or effusive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the method as 'interesting and relevant', they also state that the analysis is 'quite superficial and limited'. This criticism outweighs the initial positive remarks. The review then lists several areas for improvement, further indicating a somewhat negative sentiment. The politeness score is moderately positive (50) as the reviewer uses polite language throughout. They start with positive acknowledgment and use phrases like 'it would be good' when suggesting improvements, rather than using harsh or demanding language. The critique is presented constructively without personal attacks or overly negative phrasing.""]"
"[""This paper demonstrate that by freezing all the penultimate layers at the end of regular training improves generalization. However, the results do not convince this reviewer to switch to using 'post-training'.\n\nLearning features and then use a classifier such as a softmax or SVM is not new and were actually widely used 10 years ago. However, freezing the layers and continue to train the last layer is of a minor novelty. The results of the paper show a generalization gain in terms of better test time performance, however, it seems like the gain could be due to the \\lambda term which is added for post-training but not added for the baseline. c.f. Eq 3 and Eq 4.\nTherefore, it's unclear whether the gain in generalization is due to an additional \\lambda term or from the post-training training itself.\n\nA way to improve the paper and be more convincing would be to obtain the state-of-the-art results with post-training that's not possible otherwise.\n\nOther notes, \n\nRemark 1: While it is true that dropout would change the feature function, to say that dropout 'should not be' applied, it would be good to support that statement with some experiments.\n\nFor table 1, please use decimal points instead of commas.\n"", ""This paper proposes to fine-tune the last layer while keeping the others fixed, after initial end-to-end training, viewing the last layer learning under the light of kernel theory (well actually it's just a linear model).\n\nSummary of evaluation\n\nThere is not much novelty in this idea (of optimizing carefully only the last layer as a post-training stage or treating the last layer as kernel machine in a post-processing step), which dates back at least a decade, so the only real contribution would be in the experiments. However the experimental setup is questionable as it does not look like the same care has been given to control overfitting with the 'regular training' method.\n\nMore details\n\nPrevious work on the same idea: at least a decade old, e.g., Huang and LeCun 2006. See a review of such work in 'Deep Learning using Linear Support Vector Machines' more recently.\n\nExperiments\n\nYou should also have a weight norm penalty in the end-to-end ('regular training') case and make sure it is appropriately and separately tuned (not necessarily the same value as for the post-training). Otherwise, the 'improvements' may simply be due to better regularization in one case vs the other, and the experimental curves suggest that interpretation is correct.\n"", 'Summary: \nBased on ideas within the context of kernel theory, the authors consider post-training of NNs as an extra training step, which only optimizes the last layer of the network.\nThis additional step makes sure that the embedding, or representation, of the data is used in the best possible way for the considered task (which is also reflected in the experiments).\n\nAccording to the authors, the contributions are the following:\n1. Post-training step: keeping the rest of the NN frozen (after training), the method trains the last layer in order to ""make sure"" that the representation learned is used in the most efficient way.\n2. Highlighting connections with kernel techniques and RKHS optimization (like kernel ridge regression).\n3. Experimental results.\n\nClarity:\nThe paper is well-written, the main ideas well-clarified. \n\nImportance:\nWhile the majority of papers nowadays focuses on the representation part (i.e., how we get to \\Phi_{L-1}(x)), this paper assumes this is given and proposes how to optimize the weights in the final step of the algorithm. This by itself is not enough to boost the performance universally (e.g., if \\Phi_{L-1} is not well-trained, the problem is deeper than training the last layer); however, it proposes an additional step that can be used in most NN architectures. From that front (i.e., proposing to do something different than simply training a NN), I find the paper interesting, that might attract some attention at the conference.\n\nOn the other hand, to my humble opinion, the experimental results do not show a significant gain in the performances of all networks (esp. Figure 3 and Table 1 are within the range of statistical error). In order to state something like this universally, either one needs to perform experiments with more than just MNIST/CIFAR datasets, or even more preferably, prove that the algorithm performs better.\n\nOriginality:\nIt would be great to have some more theory (if any) for the post-training step, or investigate more cases, rather than optimizing only the last layer.\n\nComments:\n1. I assume the authors focused in the last layer of the NN for simplicity, but is there a reason why one might want to focus only on the last layer? One reason is convexity in W of the problem (2). Any other? \n\n2. Have the authors considered (even in practice only) to include training of the last 2 layers of the NN? The authors state this question in the future direction, but it would make the paper more complete to consider it here.\n']","[-20, -50, 50]","[20, 0, 80]","[""The sentiment score is slightly negative (-20) because the reviewer expresses skepticism about the paper's main claim and points out potential flaws in the methodology. The reviewer states that the results 'do not convince' them and suggests that the observed improvements might be due to factors other than the proposed method. However, the score is not deeply negative as the reviewer acknowledges some novelty in the approach and offers constructive suggestions for improvement. The politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout, offers specific suggestions for improvement, and uses polite language such as 'please' when requesting changes. The reviewer also acknowledges the paper's contributions while expressing concerns, which contributes to a respectful tone. However, the score is not extremely high as the language is primarily neutral and matter-of-fact rather than overtly polite or deferential."", ""The sentiment score is -50 because the reviewer expresses significant criticism of the paper's novelty and experimental setup. They state that 'There is not much novelty in this idea' and that 'the experimental setup is questionable.' However, it's not entirely negative as they suggest improvements, indicating some potential value in the work. The politeness score is 0 (neutral) because the reviewer's language is direct and professional without being overtly polite or rude. They critique the work objectively, pointing out flaws and suggesting improvements without using inflammatory language or personal attacks, but also without using particularly courteous phrases."", ""The sentiment score is 50 (slightly positive) because the reviewer finds the paper interesting and well-written, acknowledging its potential to attract attention at the conference. However, they also express some reservations about the experimental results and suggest areas for improvement. The politeness score is 80 (quite polite) due to the reviewer's respectful tone throughout, using phrases like 'to my humble opinion' and offering constructive feedback. They acknowledge the paper's strengths while diplomatically suggesting improvements, maintaining a professional and courteous tone throughout the review.""]"
"['The article ""Contextual Explanation Networks"" introduces the class of models which learn the intermediate explanations in order to make final predictions. The contexts can be learned by, in principle, any model including neural networks, while the final predictions are supposed to be made by some simple models like linear ones. The probabilistic model allows for the simultaneous training of explanation and prediction parts as opposed to some recent post-hoc methods.\n\nThe experimental part of the paper considers variety of experiments, including classification on MNIST, CIFAR-10, IMDB and also some experiments on survival analysis. I should note, that the quality of the algorithm is in general similar to other methods considered (as expected). However, while in some cases the CEN algorithm is slightly better, in other cases it appears to sufficiently loose, see for example left part of Figure 3(b) for MNIST data set. It would be interesting to know the explanation. Also, it would be interesting to have more examples of qualitative analysis to see, that the learned explanations are really useful. I am a bit worried, that while we have interpretability with respect to intermediate features, these features theirselves might be very hard to interpret.\n\nTo sum up, I think that the general idea looks very natural and the results are quite supportive. However, I don\'t feel myself confident enough in this area of research to make strong conclusion on the quality of the paper.', 'the paper is clearly written; it works on a popular idea of combining graphical models and neural nets.\n\nthis work could benefit from differentiating more from previous literature.\n\none key component is interpretability, which comes from the use of graphical models.  the authors claim that the previous art directly integrate neural networks into the graphical models as components, which renders the models uninterpretable. however, it is unclear, following the same logic, why the proposed method has interpretability. after all, how to go from the context to the parameters of the graphical models is still uninterpretable. specifically, it is helpful to pinpoint what is special in this model that makes it interpretable, compared to works like Gao, Y., Archer, E. W., Paninski, L., & Cunningham, J. P. (2016). NIPS or Johnson, M., Duvenaud, D. K., Wiltschko, A., Adams, R. P., & Datta, S. R. (2016). NIPS. also, is there any methodological advancement essential to CENs? \n\nthe other idea is to go context specific. this idea has been present in language modeling, for example, amortized embedding models like M. Rudolph, F. Ruiz, S. Athey, and D. Blei (2017). NIPS and L. Liu, F. Ruiz, S. Athey, and D. Blei.  (2017). NIPS. application to medical data is interesting. but it could be helpful for the readers to understand if the idea in this work is fundamentally different from these previous ideas from amortized inference.\n\na final thing. a common challenge with composing graphical models and neural networks (in interpretable or uninterpretable ways) is that the neural networks will usually eat up all the representational power. the variance captured by graphical models becomes negligible. to this end, the power of graphical models for interpretability is limited. interpretability in this case is not much different from fitting only a neural network, taking the penultimate layer to the output as ""context specific features"" can claim that we are composing a linear model with a neural network, and the linear model is interpretable. it would be interesting to be clear about how the authors get around this issue.', 'The paper proposes an interesting combination of neural nets and graphical models by using a deep neural net to predict the parameters of a graphical model. When the nets are trained on contexts ""C"" (e.g. satellite images associated with a neighborhood) related to an input ""X"" (e.g. categorical features describing the neighborhood); and a graphical model relates ""X"" to targets ""Y"" (e.g. binary variable encoding poverty level of the neighborhood), then the proposed combination can produce interpretable explanations for its predictions.\nThis approach compares favorably with post-hoc explanation methods like LIME in experiments on conducted on images (CIFAR-10, MNIST), text (IMDB reviews) and time series (Satellite dataset). The paper is clearly written and might inspire follow-up work in other applications. The description of related work is sparse (beyond a derivation of an equivalence with LIME in some settings, explained in the appendix).\nThe experiments study interesting effects: what happens when the model relating X and Y is degraded (e.g. by introducing noise into X, or sub-selecting X). The paper can be substantially improved by studying the effect of dictionary size and sparsity regularization more thoroughly.\n']","[50, -20, 70]","[75, 50, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's natural idea and supportive results, but also expresses some concerns and uncertainties. The reviewer notes both strengths and weaknesses, maintaining a balanced view. The politeness score is 75 (quite polite) due to the reviewer's use of respectful language, constructive feedback, and acknowledgment of their own limitations in making a strong conclusion. The reviewer uses phrases like 'I should note,' 'It would be interesting,' and 'I think' which contribute to a polite and considerate tone throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is clearly written and works on a popular idea, they express several concerns and suggest areas for improvement. The reviewer points out that the work needs to differentiate more from previous literature, questions the claimed interpretability, and raises concerns about the power of graphical models in the proposed approach. These critiques outweigh the initial positive comment, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, framing their critiques as suggestions or areas for clarification rather than direct criticisms. They use phrases like 'could benefit from,' 'it is helpful to,' and 'it would be interesting,' which maintain a constructive tone. The reviewer also acknowledges the interesting application to medical data, further contributing to the polite tone."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'interesting' and 'clearly written', and mentions that it 'compares favorably' with other methods and 'might inspire follow-up work'. The reviewer also suggests ways to improve the paper, indicating a generally positive but not overwhelmingly enthusiastic sentiment. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and offers constructive suggestions for improvement without harsh criticism. The reviewer's tone is professional and courteous, using phrases like 'The paper can be substantially improved by...' rather than more direct or negative phrasing.""]"
"['This paper proposes to jointly learning a semantic objective and inducing a binary tree structure for word composition, which is similar to (Yogatama et al, 2017). Differently from (Yogatama et al, 2017), this paper doesn’t use reinforcement learning to induce a hard structure, but adopts a chart parser manner and basically learns all the possible binary parse trees in a soft way. \n\nOverall, I think it is really an interesting direction and the proposed method sounds reasonable. However, I am concerned about the following points:  \n\n- The improvements are really limited on both the SNLI and the Reverse Dictionary tasks. (Yogatama et al, 2017) demonstrate results on 5 tasks and I think it’d be helpful to present results on a diverse set of tasks and see if conclusions can generally hold. Also, it would be much better to have a direct comparison to (Yogatama et al, 2017), including the performance and also the induced tree structures.\n\n- The computational complexity of this model shouldn’t be neglected. If I understand it correctly, the model needs to compute O(N^3) LSTM compositions. This should be at least discussed in the paper. And I am not also sure how hard this model is being converged in all experiments (compared to LSTM or supervised tree-LSTM).\n\n- I am wondering about the effects of the temperature parameter t. Is that important for training?\n\nMinor:\n- What is the difference between LSTM and left-branching LSTM?\n- I am not sure if the attention overt chart is a highlight of the paper or not. If so, better move that part to the models section instead of mention it briefly in the experiments section. Also, if any visualization (over the chart) can be provided, that’d be helpful to understand what is going on. \n', 'Summary: The paper proposes to use the CYK chart-based mechanism to compute vector representations for sentences in a bottom-up manner as in recursive NNs. The key idea is to maintain a chart to take into account all possible spans. The paper also introduces an attention method over chart cells. The experimental results show that the propped model outperforms tree-lstm using external parsers.\n\nComment: I kinda like the idea of using chart, and the attention over chart cells. The paper is very well written.\n- My only concern about the novelty of the paper is that the idea of using CYK chart-based mechanism is already explored in Le and Zuidema (2015).\n- Le and Zudema use pooling and this paper uses weighted sum. Any differences in terms of theory and experiment?\n- I like the new attention over chart cells. But I was surprised that the authors didn’t use it in the second experiment (reverse dictionary).\n- In table 2, it is difficult for me to see if the difference between unsupervised tree-lstm and right-branching tree-lstm (0.3%) is “good enough”. In which cases the former did correctly but the latter didn’t?\n- In table 3, what if we use the right-branching tree-lstm with attention?\n- In table 4, why do Hill et al lstm and bow perform much better than the others?\n', 'The paper presents a model titled the ""unsupervised tree-LSTM,"" in which the authors mash up a dynamic-programming chart and a recurrent neural network. As far as I can glean, the topology of the neural network is constructed using the chart of a CKY parser. When combining different constituents, an energy function is computed (equation 6) and the resulting energies are passed through a softmax. The architecture achieves impressive results on two tasks: SNLI and the reverse dictionary of Hill et al. (2016).\n\nOverall, I found the paper deeply uninspired. The authors downplay the similarity of their paper to that of Le and Zuidema (2015), which  I did not appreciate. It\'s true that Le and Zuidema take a parse forest from an existing parser, but it still contains an exponential number of trees, as does the work in here. Note that exposition in Le and Zuidema (2015) discusses the pruned case as well, i.e., a compete parse forest. The authors of this paper simply write ""Le and Zuidema (2015) propose a model that takes as input a parse forest from an external parser, in order to deal with uncertainty."" I would encourage the authors to revisit Le and Zuidema (2015), especially section 3.2, and consider the technical innovations over the existing work. I believe the primary difference (other using an LSTM instead of a convnet) is to replace max-pooling with softmax-pooling. Do these two architectural changes matter? The experiments offer no empirical comparison. In short, the insight of having an end-to-end differentiable function based on a dynamic-programming chart is pretty common -- the idea is in the air. The authors provide yet another instantiation of such an approach, but this time with an LSTM. \n\nThe technical exposition is also relatively poor. The authors could have expressed their network using a clean recursion, following the parse chart, but opted not to, and, instead,  provided a round-about explanation in English. Thus, despite the strong results, I would not like to see this work in the proceedings, due to the lack of originality and poor technical discussion. If the paper were substantially cleaned-up, I would be willing to increase my rating. ']","[-20, 60, -80]","[60, 80, -30]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting' and the method as 'reasonable', they express several concerns and point out limitations in the improvements and results. The overall tone suggests more criticism than praise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, employing phrases like 'I think' and 'I am wondering' to soften criticisms. They also offer constructive suggestions for improvement rather than outright dismissals. The reviewer maintains a professional and courteous tone while still clearly communicating their concerns."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses liking the main ideas of the paper ('I kinda like the idea of using chart, and the attention over chart cells') and compliments the writing ('The paper is very well written'). However, they also raise some concerns and questions, which prevents a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as questions or mild concerns rather than harsh judgments, and begins with positive comments before addressing potential issues. The use of phrases like 'I like' and 'I was surprised' maintains a collegial tone. The reviewer also provides specific, constructive feedback without using dismissive or negative language."", ""The sentiment score is -80 because the reviewer expresses strong negative opinions about the paper, calling it 'deeply uninspired' and criticizing the lack of originality and poor technical discussion. They explicitly state they 'would not like to see this work in the proceedings.' The politeness score is -30 because while the reviewer doesn't use overtly rude language, their tone is quite harsh and dismissive. They accuse the authors of downplaying similarities to previous work and provide blunt criticism without much attempt to soften their language. However, they do offer a conditional possibility for improvement, which prevents the score from being even lower.""]"
"['The paper proposes a method to speed up the training of graph convolutional networks, which are quite slow for large graphs. The key insight is to improve the estimates of the average neighbor activations (via neighbor sampling) so that we can either sample less neighbors or have higher accuracy for the same number of sampled neighbors. The idea is quite simple: estimate the current average neighbor activations as a delta over the minibatch running average. I was hoping the method would also include importance sampling, but it doesn’t. The assumption that activations in a graph convolution are independent Gaussians is quite odd (and unproven). \n\nQuality: Statistically, the paper seems sound. There are some odd assumptions (independent Gaussian activations in a graph convolution embedding?!?) but otherwise the proposed methodology is rather straightforward. \n\nClarity: It is well written and the reader is able to follow most of the details. I wish the authors had spent more time discussing the independent Gaussian assumption, rather than just arguing that a graph convolution (where units are not interacting through a simple grid like in a CNN) is equivalent to the setting of Wang and Manning (I don’t see the equivalence). Wang and Manning are looking at MLPs, not even CNNs, which clearly have more independent activations than a CNN or a graph convolution. \n\nSignificance: Not very significant. The problem of computing better averages for a specific problem (neighbor embedding average) seems a bit too narrow. The solution is straightforward, while some of the approximations make some odd simplifying assumptions (independent activations in a convolution, infinitesimal learning rates). \n\nTheorem 2 is not too useful, unfortunately: Showing that the estimated gradient is asymptotically unbiased with learning rates approaching zero over Lipchitz functions does not seem like an useful statement. Learning rates will never be close enough to zero (specially for large batch sizes). And if the running activation average converges to the true value, the training is probably over. The method should show it helps when the values are oscillating in the early stages of the training, not when the training is done near the local optimum.\n\n\n', 'This paper proposes a new training method for graph convolutional networks. The experimental results look interesting. However, this paper has some issues.\n\nThis paper is hard to read. There are some undefined or multi-used notations. For instance, sigma is used for two different meanings: an activation function and variance. Some details that need to be explained are omitted. For example, what kind of dropout is used to obtain the table and figures in Section 5? Forward and backward propagation processes are not clearly explained\n\nIn section 4.2, it is not clear why we have to multiply sqrt{D}. Why should we make the variance from dropout sigma^2? \n\nProposition 1 is wrong. First, \\|A\\|_\\infty should be max_{ij} |A_ij| not A_{ij}. Second, there is no order between \\|AB\\|_\\infty and \\|A\\|_\\infty \\|B\\|_\\infty. When A=[1 1] and B is the transpose matrix of A, \\|AB\\|_\\infty =2 and \\|A\\|_\\infty \\|B\\|_\\infty = 1. When, A’=[1 -1] and B is the same matrix defined just before, \\|A’ B \\|_\\infty = 0 and \\|A’\\|_\\infty \\|B\\|_\\infty =1. So, both \\|AB\\|_\\infty \\le \\|A\\|_\\infty \\|B\\|_\\infty and \\|AB\\|_\\infty \\ge \\|A\\|_\\infty \\|B\\|_\\infty are not true. I cannot believe the proof of Theorem 2.\n', ""Existing training algorithms for graph convolutional nets are slow. This paper develops new novel methods, with a nice mix of theory, practicalities, and experiments.\n\nLet me caution that I am not familiar with convolutional nets applied to graph data.\n\nClearly, the existing best algorithm - neighborhood sampling is slow as well as not theoretically sound. This paper proposes two key ideas - preprocessing and better sampling based on historical activations. The value of these ideas is demonstrated very well via theoretical and experimental analysis. I have skimmed through the theoretical analysis. They seem fine, but I haven't carefully gone through the details in the appendices.\n\nAll the nets considered in the experiments have two layers. The role of preprocessing to add efficiency is important here. It would be useful to know how much the training speed will suffer if we use three or more layers, say, via one more experiment on a couple of key datasets. This will help see the limitations of the ideas proposed in this paper.\n\nIn subsection 4.3 the authors prove reduced variance under certain assumptions. While I can see that this is done to make the analysis simple, how well does this analysis correlate with what is seen in practice? For example, how well does the analysis results given in Table 2 correlate with the standard deviation numbers of Figure 5 especially when comparing NS+PP and CV+PP?""]","[-30, -60, 70]","[20, 20, 60]","[""The sentiment score is -30 because the review expresses several criticisms and doubts about the paper's significance, assumptions, and usefulness. The reviewer notes that the idea is 'quite simple,' the problem seems 'a bit too narrow,' and some assumptions are 'odd' and 'unproven.' They also state that the paper is 'Not very significant' and that Theorem 2 is 'not too useful.' However, the score is not extremely negative because the reviewer does acknowledge some positive aspects, such as the paper being 'well written' and 'statistically sound.'\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout, despite their criticisms. They use phrases like 'I wish the authors had spent more time discussing...' instead of more direct or harsh language. The reviewer also balances negative comments with positive ones, acknowledging the paper's clarity and statistical soundness. However, the score is not higher because the review doesn't go out of its way to be exceptionally polite or encouraging, maintaining a mostly neutral, academic tone."", ""The sentiment score is -60 because the review starts with a positive note about interesting experimental results, but quickly shifts to a critical tone, highlighting multiple issues with the paper. The reviewer points out problems with readability, undefined notations, omitted details, and a significant error in a proposition. The criticism outweighs the initial positive comment, resulting in a negative sentiment overall. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'This paper is hard to read' and 'it is not clear why' rather than using harsh or insulting language. The reviewer also provides specific examples and explanations for their criticisms, which is a constructive approach. However, the statement 'I cannot believe the proof of Theorem 2' is somewhat impolite, preventing a higher politeness score."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, praising its 'novel methods,' 'nice mix of theory, practicalities, and experiments,' and how well the ideas are demonstrated. The reviewer does suggest some improvements, but these are minor compared to the overall positive assessment. The politeness score is 60 (polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('I am not familiar with...'), and frames suggestions as constructive feedback rather than criticism. The reviewer also uses phrases like 'It would be useful to know' and 'This will help see,' which are polite ways of suggesting improvements. The score is not higher because the language, while polite, is not excessively formal or deferential.""]"
"[""The paper seems to claims that\n1) certain ConvNet architectures, particularly AlexNet and VGG, have too many parameters,\n2) the sensible solution is leave the trunk of the ConvNet unchanged, and to randomly sparsify the top-most weight matrices.\nI have two problems with these claims:\n1) Modern ConvNet architectures (Inception, ResNeXt, SqueezeNet, BottleNeck-DenseNets and ShuffleNets) don't have large fully connected layers.\n2) The authors reject the technique of 'Deep compression' as being impractical. I suspect it is actually much easier to use in practice as you don't have to a-priori know the correct level of sparsity for every level of the network.\n\np3. What does 'normalized' mean? Batch-norm?\np3. Are you using an L2 weight penalty? If not, your fully-connected baseline may be unnecessarily overfitting the training data.\np3. Table 1. Where do the choice of CL Junction densities come from? Did you do a grid search to find the optimal level of sparsity at each level?\np7-8. I had trouble following the left/right & front/back notation.\np8. Figure 7. How did you decide which data points to include in the plots?"", 'This paper examines sparse connection patterns in upper layers of convolutional image classification networks.  Networks with very few connections in the upper layers are experimentally determined to perform almost as well as those with full connection masks.  Heuristics for distributing connections among windows/groups and a measure called ""scatter"" are introduced to construct the connectivity masks, and evaluated experimentally on CIFAR-10 and -100, MNIST and Morse code symbols.\n\nWhile it seems clear in general that many of the connections are not needed and can be made sparse (Figures 1 and 2), I found many parts of this paper fairly confusing, both in how it achieves its objectives, as well as much of the notation and method descriptions.  I\'ve described many of the points I was confused by in more detailed comments below.\n\n\nDetailed comments and questions:\n\n\nThe distribution of connections in ""windows"" are first described to correspond to a sort of semi-random spatial downsampling, to get different views distributed over the full image.  But in the upper layers, the spatial extent can be very small compared to the image size, sometimes even 1x1 depending on the network downsampling structure.  So are do the ""windows"" correspond to spatial windows, and if so, how?  Or are they different (maybe arbitrary) groupings over the feature maps?\n\nAlso a bit confusing is the notation ""conv2"", ""conv3"", etc.  These names usually indicate the name of a single layer within the network (conv2 for the second convolutional layer or series of layers in the second spatial size after downsampling, for example).  But here it seems just to indicate the number of ""CL"" layers: 2.  And p.1 says that the ""CL"" layers are those often referred to as ""FC"" layers, not ""conv"" (though they may be convolutionally applied with spatial 1x1 kernels).\n\nThe heuristic for spacing connections in windows across the spatial extent of an image makes intuitive sense, but I\'m not convinced this will work well in all situations, and may even be sub-optimal for the examined datasets.  For example, to distinguish MNIST 1 vs 7 vs 9, it is most important to see the top-left:  whether it is empty, has a horizontal line, or a loop.  So some regions are more important than others, and the top half may be more important than an equally spaced global view.  So the description of how to space connections between windows makes some intuitive sense, but I\'m unclear on whether other more general connections might be even better, including some that might not be as easily analyzed with the ""scatter"" metric described.\n\nAnother broader question I have is in the distinction between lower and upper layers (those referred to as ""feature extracting"" and ""classification"" in this paper).  It\'s not clear to me that there is a crisply defined difference here (though some layers may tend to do more of one or the other function, such as we might interpret).  So it seems that expanding the investigation to include all layers, or at least more layers, would be good:  It might be that more of the ""classification"" function is pushed down to lower layers, as the upper layers are reduced in size.  How would they respond to similar reductions?\n\nI\'m also unsure why on p.6 MNIST uses 2d windows, while CIFAR uses 3d --- The paper mentions the extra dimension is for features, but MNIST would have a features dimension as well at this stage, I think?  I\'m also unsure whether the windows are over spatial extent only, or over features.', 'The authors propose reducing the number of parameters learned by a deep network by setting up sparse connection weights in classification layers. Numerical experiments show that such sparse networks can have similar performance to fully connected ones. They introduce a concept of “scatter” that correlates with network performance. Although  I found the results useful and potentially promising, I did not find much insight in this paper.\nIt was not clear to me why scatter (the way it is defined in the paper) would be a useful performance proxy anywhere but the first classification layer. Once the signals from different windows are intermixed, how do you even define the windows?  \nMinor\nSecond line of Section 2.1: “lesser” -> less or fewer\n']","[-50, -30, -20]","[0, 20, 50]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's claims and methodology. They point out two major problems with the paper's claims and list several specific questions and issues, indicating a generally negative view of the paper. However, it's not entirely negative as they engage with the content seriously. The politeness score is 0 because the language is neutral and professional. The reviewer doesn't use overtly polite language, but also doesn't use rude or harsh words. They present their criticisms and questions in a straightforward, matter-of-fact manner typical of academic peer reviews."", ""The sentiment score is -30 because while the reviewer acknowledges the paper's contribution ('Networks with very few connections in the upper layers are experimentally determined to perform almost as well as those with full connection masks'), they express significant confusion and criticism throughout the review. The reviewer states 'I found many parts of this paper fairly confusing' and raises several questions and concerns about the methodology and clarity of the paper. This indicates a generally negative sentiment, though not extremely so.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout, despite their criticisms. They use phrases like 'I'm not convinced' and 'I'm unclear on' rather than making blunt negative statements. The reviewer also offers constructive feedback and suggestions for improvement, which is a polite approach to criticism. However, the score is not higher because the review doesn't include many explicitly polite phrases or compliments, maintaining a mostly neutral tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the results as 'useful and potentially promising', they also state that they 'did not find much insight in this paper'. The reviewer also expresses confusion about a key concept ('scatter'), which further contributes to the negative sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral language and offers constructive criticism without harsh words. They also provide a minor correction suggestion politely. The review maintains a professional tone throughout, avoiding personal attacks or overly negative language.""]"
"['This paper uses CNNs to build document embeddings.  The main advantage over other methods is that CNNs are very fast.\n\nFirst and foremost I think this: ""The code with the full model architecture will be released … and we thus omit going into further details here.""  is not acceptable.  Releasing code is commendable, but it is not a substitute for actually explaining what you have done.  This is especially true when the main contribution of the work is a network architecture.  If you\'re going to propose a specific architecture I expect you to actually tell me what it is.\n\nI\'m a bit confused by section 3.1 on language modelling.  I think the claim that it is showing ""a direct connection to language modelling"" and that ""we explore this relationship in detail"" are both very much overstated.  I think it would be more accurate to say this paper takes some tricks that people have used for language modelling and applies them to learning document embeddings.\n\nThis paper proposed both a model and a training objective, and I would have liked to see some attempt to disentangle their effect.  If there is indeed a direct connection between embedding models and language models then I would have also expected to see some feedback effect from document embedding to language modeling.  Does the embedding objective proposed here also lead to better language models?\n\nOverall I do not see a substantial contribution from this paper. The main claims seem to be that CNNs are fast, and can be used for NLP, neither of which are new.\n', 'This paper proposes a new model for the general task of inducing document representations (embeddings). The approach uses a CNN architecture, distinguishing it from the majority of prior efforts on this problem, which have tended to use RNNs. This affords obvious computational advantages, as training may be parallelized. \n\nOverall, the model presented is relatively simple (a good thing, in my view) and it indeed seems fast. I can thus see potential practical uses of this CNN based approach to document embedding in future work on language tasks. The training strategy, which entails selecting documents and then indexes within them stochastically, is also neat. Furthermore, the work is presented relatively clearly. That said, my main concerns regarding this paper are that: (1) there\'s not much new here, and, (2) the experimental setup may be flawed, in that it would seem model hyperparams were tuned for the proposed approach but not for the baselines; I elaborate on these concerns below.\n\nSpecific comments:\n---\n- It\'s hard to tease out exactly what\'s new here: the various elements used are all well known. But perhaps there is merit in putting the specific pieces together. Essentially, the novelty is using a CNN rather than an RNN to induce document embeddings. \n\n- In Section 4.1, the authors write that they report results for their after running ""parameter sweeps ..."" -- I presume that these were performed on a validation set, but the authors should say so. In any case, a very potential weakness here: were analagous parameter sweeps for this dataset performed for the baseline models? It would seem not, as the authors write ""the IMDB training data using the default hyper-parameters"" for skip-thought. Surely it is unfair comparison if one model has been tuned to a given dataset while others use only the default hyper-parameters? \n\n- Many important questions were left unaddressed in the experiments. For example, does one really need to use the gating mechanism borrowed from the Dauphin et al. paper? What happens if not? How big of an effect does the stochastic sampling of document indices have on the learned embeddings? Does the specific underlying CNN architecture affect results, and how much? None of these questions are explored. \n\n- I was left a bit confused regarding how the v_{1:i-1} embedding is actually estimated; I think the details here are insufficient in the current presentation. The authors write that this is a ""function of all words up to w_{i-1}"". This would seem to imply that at test time, prediction is not in fact parallelizable, no? Yet this seems to be one of the main arguments the authors make in favor of the model (in contrast to RNN based methods). In fact, I think the authors are proposing using the (aggregated) filter activation vectors (h^l(x)) in eq. 5, but for some reason this is not made explicit. \n\nMinor comments:\n\n- In Eq. 4, should the product be element-wise to realize the desired gating (as per the Dauhpin paper)? This should be made explicit in the notation.\n\n- On the bottom of page 3, the authors claim ""Expanding the prediction to multiple words makes the problem more difficult since the only way to achieve that is by \'understanding\' the preceding sequence."" This claim should either by made more precise or removed. It is not clear exactly what is meant here, nor what evidence supports it.\n\n- Commas are missing in a few. For example on page 2, probably want a comma after ""in parallel"" (before ""significantly""); also after ""parallelize"" above ""Approach"".\n\n- Page 4: ""In contrast, our model addresses only requires"" --> drop the ""addresses"". ', ""This paper proposes using CNNs with a skip-gram like objective as a fast way to output document embeddings and much faster compared to skip-thought and RNN type models.\n\nWhile the problem is an important one, the paper only compares speed with the RNN-type model and doesn't make any inference speed comparison with paragraph vectors (the main competing baseline in the paper). Paragraph vectors are also parallelizable so it's not obvious that this method would be superior to it. The paper in the introduction also states that doc2vec is trained using localized contexts (5 to 10 words) and never sees the whole document. If this was the case then paragraph vectors wouldn't work when representing a whole document, which it already does as can be seen in table 2.\n\nThe paper also fails to compare with the significant amount of existing literature on state of the art document embeddings. Many of these are likely to be faster than the method described in the paper. For example:\n\n\nArora, S., Liang, Y., & Ma, T. A simple but tough-to-beat baseline for sentence embeddings. ICLR 2017.\nChen, M. Efficient vector representation for documents through corruption. ICLR 2017.\n""]","[-70, -20, -50]","[-20, 60, 0]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper's main claims are not novel, criticizes the lack of detailed explanation of the architecture, and expresses confusion and disagreement with some of the paper's statements. The phrase 'Overall I do not see a substantial contribution from this paper' clearly indicates a negative sentiment. The politeness score is -20 because while the reviewer maintains a professional tone, there are instances of direct criticism that could be perceived as slightly impolite. For example, the statement 'is not acceptable' and the use of phrases like 'I'm a bit confused' and 'I do not see a substantial contribution' are somewhat blunt. However, the reviewer does not use overtly rude language, keeping the score from being extremely negative."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'relatively simple', 'fast', 'potential practical uses'), they express significant concerns about the novelty and experimental setup. The reviewer states 'my main concerns' and lists two major issues, indicating an overall negative sentiment despite some positive points.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They acknowledge positive aspects before presenting criticisms, use phrases like 'I presume' and 'I think' to soften assertions, and offer constructive feedback. The tone is academic and objective, avoiding harsh or personal criticisms. However, it's not extremely polite, as it directly points out flaws and uses phrases like 'Surely it is unfair' which could be seen as slightly confrontational."", ""The sentiment score is -50 because the review is generally critical of the paper, pointing out several shortcomings and limitations. The reviewer acknowledges the importance of the problem but then proceeds to highlight multiple issues with the paper's approach and comparisons. The lack of positive comments and the focus on criticisms indicate a negative sentiment, though not extremely negative.\n\nThe politeness score is 0 (neutral) because the reviewer maintains a professional and objective tone throughout. They don't use overly polite language, but they also don't use rude or disrespectful language. The criticism is presented in a straightforward, matter-of-fact manner without personal attacks or overly harsh language.\n\nThe reviewer uses phrases like 'While the problem is an important one...' and 'The paper also fails to compare...' which are neutral in tone and typical of academic discourse. The language is direct but not impolite, focusing on the content of the paper rather than making judgments about the authors themselves.""]"
"['At the heart of the paper, there is a single idea: to decouple the weight decay from the number of steps taken by the optimization process (the paragraph at the end of page 2 is the key to the paper). This is an important and largely overlooked area of implementation and most off-the-shelf optimization algorithms, unfortunately, miss this point, too. I think that the proposed implementation should be taken seriously, especially in conjunction with the discussion that has been carried out with the work of Wilson et al., 2017 (https://arxiv.org/abs/1705.08292).\n\nThe introduction does a decent job explaining why it is necessary to pay attention to the norm of the weights as the training progresses within its scope. However, I would like to add a couple more points to the discussion: \n- ""Optimal weight decay is a function (among other things) of the total number of epochs / batch passes."" in principle, it is a function of weight updates. Clearly, it depends on the way the decay process is scheduled. However, there is a bad habit in DL where time is scaled by the number of epochs rather than the number of weight updates which sometimes lead to misleading plots (for instance, when comparing two algorithms with different batch sizes).\n- Another ICLR 2018 submission has an interesting take on the norm of the weights and the algorithm (https://openreview.net/forum?id=HkmaTz-0W&noteId=HkmaTz-0W). Figure 3 shows the histograms of SGD/ADAM with and without WD (the *un-fixed* version), and it clearly shows how the landscape appear misleadingly different when one doesn\'t pay attention to the weight distribution in visualizations. \n- In figure 2, it appears that the training process has three phases, an initial decay, a steady progress, and a final decay that is more pronounced in AdamW. This final decay also correlates with the better test error of the proposed method. This third part also seems to correspond to the difference between Adam and AdamW through the way they branch out after following similar curves. One wonders what causes this branching and whether the key the desired effects are observed at the bottom of the landscape.\n- The paper concludes with ""Advani & Saxe (2017) analytically showed that in the limited data regime of deep networks the presence of eigenvalues that are zero forms a frozen subspace in which no learning occurs and thus smaller (e.g., zero) initial weight norms should be used to achieve best generalization results."" Related to this there is another ICLR 2018 submission (https://openreview.net/forum?id=rJrTwxbCb), figure 1 shows that the eigenvalues of the Hessian of the loss have zero forms at the bottom of the landscape, not at the beginning. Back to the previous point, maybe that discussion should focus on the second and third phases of the training, not the beginning. \n- Finally, it would also be interesting to discuss the relation of the behavior of the weights at the last parts of the training and its connection to pruning. \n\nI\'m aware that one can easily go beyond the scope of the paper by adding more material. Therefore, it is not completely reasonable to expect all such possible discussions to take place at once. The paper as it stands is reasonably self-contained and to the point. Just a minor last point that is irrelevant to the content of the work: The slash punctuation mark that is used to indicate \'or\' should be used without spaces as in \'epochs/batch\'.\n\nEdit: Thanks very much for the updates and refinements. I stand by my original score and would like to indicate my support for this style of empirical work in scientific conferences.', 'This paper investigates weight decay issues lied in the SGD variants, especially Adam. Current implementations of adaptive gradient algorithms implicitly contain a crucial flaw, by which \x08weight decay in these methods does not correspond to L2 regularization. To fix this issue, this paper proposes the decoupling method between weight decay and the gradient-based update.\n\nOverall, this paper is well-written and contain sufficient references to note the overview of recent adaptive gradient-based methods for DNN. In addition, this paper investigates the crucial issue in the recent adaptive gradient methods and find the problem in weight decay. This is an interesting finding. And the proposed method to fix this issue is simple and reasonable. Their experimental results to validate the effectiveness of their proposed method are well-organized. In particular, the investigation on hyperparameter spaces shows the strong advantage of the proposed methods.', 'The paper presents an alternative way to implement weight decay in Adam. Empirical results are shown to support this idea.\n\nThe idea presented in the paper is interesting, but I have some concerns about it.\n\nFirst, the authors argue that the weight decay should be implemented in a way different from the minimization of a L2 regularization. This seems a very weird statement to me. In fact, it easy to see that what the authors propose is to minimize two different objective functions in SGDW and AdamW! I am not even sure how I should interpret what they propose. The fact is that SGD and Adam are optimization algorithms, so we cannot just change the update rule in the same way in both algorithms and expect them to behave in the same way just because the added terms have the same shape!\n\nSecond, the equation (5) that re-normalize the weight decay parameter as been obtained on one dataset, as the author admit, and tested only on another one. I am not sure this is enough to be considered as a scientific proof.\n\nAlso, the empirical experiments seem to use the cosine annealing of the learning rate. This means that the only thing the authors proved is that their proposed change yields better results when used with a particular setting of the cosine annealing. What happens in the other cases?\n\nTo summarize, I think the idea is interesting but the paper might not be ready to be presented in a scientific conference.']","[70, 80, -50]","[80, 70, 20]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, stating that it contains an 'important and largely overlooked' idea that 'should be taken seriously.' The reviewer provides constructive feedback and suggestions for improvement, indicating engagement with and interest in the work. The politeness score is 80 (polite) due to the respectful and professional tone throughout. The reviewer uses phrases like 'I would like to add,' 'it would be interesting to discuss,' and acknowledges that their suggestions might be beyond the scope of the paper. The reviewer also thanks the authors for updates and refinements, and expresses support for the work. The language is consistently courteous and constructive, avoiding any harsh criticism or dismissive remarks."", ""The sentiment score is 80 (positive) because the reviewer uses phrases like 'well-written,' 'interesting finding,' and 'strong advantage,' indicating a favorable view of the paper. They also mention that the paper contains 'sufficient references' and has 'well-organized' experimental results. The politeness score is 70 (polite) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'this paper investigates' and 'this paper proposes' rather than directly addressing the authors, which maintains a polite distance. The reviewer also balances positive comments with constructive observations, showing respect for the authors' work while maintaining objectivity."", ""The sentiment score is -50 because while the reviewer acknowledges the idea as 'interesting', they express several significant concerns and ultimately conclude that the paper 'might not be ready to be presented in a scientific conference'. This indicates a generally negative sentiment, though not entirely dismissive. The politeness score is 20 because the reviewer uses relatively polite language, such as 'I think the idea is interesting' and frames criticisms as personal concerns ('I have some concerns', 'I am not sure'). However, they also use some direct language that could be perceived as slightly confrontational, such as 'This seems a very weird statement to me'. Overall, the tone is professional but leans towards politeness while still clearly expressing criticisms.""]"
"['In this paper authors are summarizing their work on building a framework for automated neural network (NN) construction across multiple tasks simultaneously. \n\nThey present initial results on the performance of their framework called Multitask Neural Model Search (MNMS) controller. The idea behind building such a framework is motivated by the successes of recently proposed reinforcement based approaches for finding the best NN architecture across the space of all possible architectures. Authors cite the Neural Architecture Search (NAS) framework as an example of such a framework that yields better results compared to NN architectures configured by humans. \n\nOverall I think that the idea is interesting and the work presented in this paper is very promising. Given the depth of the empirical analysis presented the work still feels that it’s in its early stages. In its current state and format the major issue with this work is the lack of more in-depth performance analysis which would help the reader draw more solid conclusions about the generalization of the approach.\n\nAuthors use two text classification tasks from the NLP domain to showcase the benefits of their proposed architecture. It would be good if they could expand and analyze how well does their framework generalizes across other non-binary tasks, tasks in other domains and different NNs. This is especially the case for the transfer learning task. \n\nIn the NAS overview section, readers would benefit more if authors spend more time in outlining the RL detail used in the original NAS framework instead of Figure 1 which looks like a space filler. \n\nAcross the two NLP tasks authors show that MNMS models trained simultaneously give better performance than hand tuned architectures. In addition, on the transfer learning evaluation approach they showcase the benefit of using the proposed framework in terms of the initially retrieved architecture and the number of iterations required to obtain the best performing one. \nFor better clarity figures 3 and 5 should be made bigger. \nWhat is LSS in figure 4?', 'The paper proposes an extension of the Neural Architecture Search approach, in which a single RNN controller is trained with RL to select hyperparameters for child networks that must perform different tasks. The architecture includes the notion of a ""task embedding"", that helps the controller keeping track of similarity between tasks, to facilitate transfer across related tasks.\n\nThe paper is very well written, and based on a simple but interesting idea. It also deals with core issues in current machine learning.\n\nOn the negative side, there is just one experiment, and it is somewhat limited. In the experiment, the proposed model is trained on two very different tasks (English sentiment analysis and Spanish language detection), and then asked to generalize to another English sentiment analysis task and to a Spanish sentiment analysis task. The models converge faster to high accuracy in the proposed transfer learning setup than when trained one a single task with the same architecture search strategy. Moreover, the task embedding for the new English task is closer to that of the training English task, and the same for the training/test Spanish tasks.\n\nMy main concern with the experiment is that the approach is only tested in a setup in which there is a huge difference between two classes of tasks (English vs Spanish), so the model doesn\'t need to learn very sophisticated task embeddings to group the tasks correctly for transfer. It would be good to see other experiments where there is less of a trivial structure distinguishing tasks, to check if transfer helps.\n\nAlso, I find it surprising that the Corpus Cine sentiment task embedding is not correlated at all with the SST sentiment task. If the controller is really learning something interesting about the nature of the tasks, I would have expected a differential effect, such that IMDB is only correlated with SST, but Corpus Cine is correlated to both the Spanish language identification task and SST. Perhaps, this is worth some discussion.\n\nFinally, it\'s not clear to me why the multitask architecture was used in the experiment even when no multi-task pre-training was conducted: shouldn\'t the simple neural architecture search method be used in this case?\n\nMinor points:\n\n""diffferentiated"": different?\n\n""outputted actions"": output actions\n\n""the aim of increase the training stability"": the aim of increasing training stability\n\nInsert references for Polyak averaging and Savitzky-Golay filtering.\n\nFigure 3: specify that the Socher 2013 result is for SST\n\nFigure 4: does LSS stand for SST?\n\nI\'m confused by Fig. 6: why aren\'t the diagonal values 100%?\n\nMNMS is referred to as MNAS in Figure 5.\n\nFor architecture search, the neuroevolution literature should also be cited (https://www.oreilly.com/ideas/neuroevolution-a-different-kind-of-deep-learning).\n', 'Summary\nThis paper extends Neural Architecture Search (NAS) to the multi-task learning problem. A task conditioned model search controller is learned to handle multiple tasks simultaneously. The experiments are conducted on text data sets to evaluate the proposed method.\n\nPros\n1.\tThe problem of neural architecture design is important and interesting.\n2.\tThe motivation is strong. NAS (Zoph & Le, 2017) needs to train a model for a new task from scratch, which is inefficient. It is reasonable to introduce task embeddings into NAS to obtain a generalization model for multiple tasks.\n\nCons\n1.\tSome important technical details are missing, especially for the details regarding task embeddings.\n2.\tThe experiments are not sufficient.\n\nDetailed Comments\n1.\tThe paper does not provide the method of how to obtain task embeddings. In addition, if task embeddings are obtained by an auxiliary network, is it feasible to update task embeddings by updating the weights of this auxiliary network?\n2.\tThe discussion of off-policy training is questionable. There is no experiment to demonstrate the advantage of off-policy training compared to on-policy training.\n3.\tIn order to demonstrate the effectiveness of the idea of multi-task learning and task conditioning in MNMS, some architecture search methods for single-task should be conducted for comparison. For instance, NAS on SST or the Spanish language identification task should be compared.\n4.\tIn order to demonstrate the efficiency of MNMS, running time results of MNMS and NAS should be reported.\n5.\tIn my opinion, the title is not appropriate. The most important contribution of this paper is to search neural models for multiple tasks simultaneously using task conditioning. Only when this target is achieved, is it possible to transfer a pre-trained controller to new tasks with new task embeddings. Therefore, the title should highlight multitask neural model search rather than transfer learning.\n6.\tIn Figure 5, ""MNAS"" should be ""MNMS"".\n']","[50, 50, 20]","[75, 80, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer states that the idea is interesting and the work is promising, but also mentions that it feels like it's in early stages and lacks in-depth performance analysis. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions in a considerate manner (e.g., 'It would be good if...'). The reviewer balances positive comments with areas for improvement, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by praising the paper as 'very well written' and based on an 'interesting idea' that deals with 'core issues in current machine learning'. However, they also express concerns about the limited experimentation and some aspects of the results, balancing out the initial positive comments. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms constructively (e.g., 'It would be good to see...'), and offers specific suggestions for improvement. They also use phrases like 'My main concern' and 'I find it surprising' rather than more aggressive language. The reviewer also points out minor issues politely, such as typos and suggestions for additional references."", ""The sentiment score is slightly positive (20) because the review begins by acknowledging the importance and interest of the problem, and mentions some pros of the paper. However, it also lists several cons and areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses professional and respectful language throughout, presenting both positive and negative points in a constructive manner. The reviewer uses phrases like 'in my opinion' and frames criticisms as suggestions for improvement rather than harsh judgments. The tone remains objective and focused on the content of the paper rather than making personal comments about the authors.""]"
"[""1. This is an interesting paper - introduces useful concepts such as the formulation of the utility and privacy loss functions with respect to the learning paradigm\n2. From the initial part of the paper, it seems that the proposed PrivyNet is supposed to be a meta-learning framework to split a DNN in order to improve privacy while maintaining a certain accuracy level\n3. However, the main issue is that the meta-learning mechanism is a bit ad-hoc and empirical - therefore not sure how seamless and user-friendly it will be in general, it seems it needs empirical studies for every new application - this basically involves generation of a pareto front and then choose pareto-optimal points based on the user's requirements, but it is unclear how a privy net construction based on some data set considered from the internet has the ability to transfer and help in maintaining privacy in another type of data set, e.g., social media pictures"", 'Summary: The paper studies the problem of effectively training Deep NN under the constraint of privacy. The paper first argues that achieving privacy guarantees like differential privacy is hard, and then provides frameworks and algorithms that quantify the privacy loss via Signal-to-noise ratio.  In my opinion, one of the main features of this work is to split the NN computation to local computation and cloud computation, which ensures that unnecessary amount of data is never released to the cloud.\n\nComments: I have my concerns about the effectiveness of the notion of privacy introduced in this paper. The definition of privacy loss in Equation 5 is an average notion, where the averaging is performed over all the sensitive training data samples. This notion does not seem to protect the privacy of every individual training example, in contrast to notions like differential privacy. Average case notions of privacy are usually not appreciated in the privacy community because of their vulnerability to a suite of attacks.\n\nThe paper may have a valid point that differential privacy is hard to work with, in the case of Deep NN. However, the paper needs to make a much stronger argument to defend this claim.', ""1. Paper summary \n\nThis paper describes a technique using 3 neural networks to privatize data and make predictions: a feature extraction network, an image classification network, and an image reconstruction network. The idea is to learn a feature extraction network so that the image classification network performs well and the image reconstruction network performs poorly.\n\n\n2. High level paper - subjective\n\nI think the presentation of the paper is somewhat scattered: In section 2 the authors introduce their network and their metric for utility and privacy and then immediately do a sensitivity analysis. Section 3 continues with a sensitivity analysis now considering performance and storage of the method. Then 2.5 pages are spent on channel pruning.\nI would have liked if the authors spent more time justifying why we should trust their method as a privacy preserving technique (described in detail below). \nThe authors clearly performed an impressive amount of sensitivity experiments. Assuming the privacy claims are reasonable (which I have some doubts about below) then this paper is clearly useful to any company wanting to do privacy preserving classification. At the same time I think the paper does not have a significant amount of machine learning novelty in it. \n\n\n3. High level technical\n\nI have a few doubts about this method as a privacy-preserving technique:\n- Nearly every privacy-preserving technique gives a guarantee, e.g., differential privacy guarantees a statistical notion of privacy and cryptographic methods guarantee a computational notion of privacy. In this work the authors provide a way to measure privacy but there is no guarantee that if someone uses this method their data will be private, by some definition, even under certain assumptions.\n- Another nice thing about differential privacy and cryptography is that they are impervious to different algorithms because it is statistically hard or computationally hard to reveal sensitive information. Here there could be a better image reconstruction network that does a better job of reconstructing images than the ones used in the paper.\n- It's not clear to my why PSNR is a useful way to measure privacy loss. I understand that it is a metric to compare two images that is based on the mean-squared error so a very private image should have a low PSNR while a not private image should have a high PSNR, but I have no intuition about how small the PSNR should be to afford a useful amount of privacy. For instances, in nearly all of the images of Figures 21 and 22 I think it would be quite easy to guess the original images.\n\n\n4. 1/2 sentence summary\n\nWhile the authors did an extensive job evaluating different settings of their technique I have serious doubts about it as a privacy-preserving method.""]","[0, -20, -50]","[50, 50, 20]","[""The sentiment score is 0 (neutral) because the reviewer presents both positive and negative aspects of the paper. They acknowledge it as 'interesting' and introducing 'useful concepts', but also point out significant issues with the meta-learning mechanism. The politeness score is 50 (somewhat polite) because the reviewer uses respectful language and frames criticisms constructively, without harsh or dismissive language. They use phrases like 'it seems' and 'not sure' to soften their critiques. However, the review doesn't go out of its way to be exceptionally polite, maintaining a professional, matter-of-fact tone throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('one of the main features of this work is to split the NN computation'), they express significant concerns about the effectiveness of the privacy notion introduced and the paper's argumentation. The reviewer states 'I have my concerns' and points out potential vulnerabilities in the approach. However, the score is not deeply negative as the reviewer does recognize some merits of the work. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout. They present their concerns as personal opinions ('In my opinion', 'I have my concerns') rather than absolute statements, and they suggest improvements ('The paper needs to make a much stronger argument') rather than dismissing the work outright. The tone is constructive and avoids harsh or rude language."", ""The sentiment score is -50 because while the reviewer acknowledges the 'impressive amount of sensitivity experiments', they express 'serious doubts about it as a privacy-preserving method'. The review points out several perceived weaknesses and states the paper lacks 'significant machine learning novelty'. However, it's not entirely negative, recognizing some potential usefulness. The politeness score is 20 because the language is generally professional and constructive, offering specific critiques without being harsh. The reviewer uses phrases like 'I would have liked' and 'I think' to soften criticisms, and acknowledges positive aspects alongside negative ones. However, it doesn't go out of its way to be overly polite or complimentary either.""]"
"['The paper considers distribution to distribution regression with MLPs.  The authors use an energy function based approach.  They test on a few problems, showing similar performance to other distribution to distribution alternatives, but requiring fewer parameters.\n\nThis seems to be a nice treatment of distribution to distribution regression with neural networks. The approach is methodological similar to using expected likelihood kernels.  While similar performance is achieved with fewer parameters, it would be more enlightening to consider accuracy vs runtime instead of accuracy vs parameters.  That’s what we really care about.  In a sense, because this problem has been considered several times in slightly different model classes, there really ought to be a pretty strong empirical investigation.  In the discussion, it says \n“For future work, a possible study is to investigate what classes of problems DRN can solve.”  It feels like in the present work there should have been an investigation about what classes of problems the DRN can solve.  Its practical utility is questionable.  It’s not clear how much value there is adding yet another distribution to distribution regression approach, this time with neural networks, without some pretty strong motivation (which seems to be lacking), as well as experiments.  In the introduction, it would also improve the paper to outline clear points of methodological novelty.  \n', 'This is an intriguing paper on running regressions on probability distributions: i.e. a target distribution is expressed as a function of input distributions. A well-written manuscript, though the introduction could have motivated the problem a little better (i.e. why would we want to do this). The novelty in the paper is implementing such a regression in a layered network. The paper shows how the densities at each nodes are computed (and normalised). Optimisation by back propagation and discretization of the densities to carry out numerical integration are well explained and easy to follow. The paper uses three problems to illustrate the idea -- a synthetic dataset, a mean reverting stochastic process and a prediction problem on stock indices.  \nMy only two reservations of this paper is the illustration on the stock index data -- it seems to me, returns on individual constituent stocks of an index are used as samples of the return on the index itself.  But this cannot be true when the index is a weighted sum of the constituent assets.  Secondly, it is not clear to me why one would force a kernel density estimate on the asset returns and then bin the density into 100 bins for numerical reasons -- does the smoothing that results from this give any advantage over a histogram of the returns in 100 bins?\n ', ""Summary:\n\nThis paper presents a new network architecture for learning a regression of probability distributions.\n\nThe distribution output from a given node is defined in terms of a learned conditional probability function, and the output distributions of its input nodes. The conditional probability function is an unnormalized distribution with the same form as the Boltzman distribution, and distributions are approximated from point estimates by discretizing the finite support into predefined equal-sized bins. By letting the conditional distribution between nodes be unnormalized, and using an energy function that incorporates child nodes independently, the approach admits efficient computation that does not need to model the interaction between the distributions output by nodes at a given level.\n\nUnder these dynamics and discretization, the chain rule can be used to derive a matrix of gradients at each node that denotes the derivative of the discretized output distribution with respect to the current node's discretized distribution. These gradients are in turn used to calculate updates for the network parameters with respect to the Jensen Shannon divergence between the predicted distribution and a target distribution.\n\nThe approach is evaluated on three tasks, two synthetic and one real world. The baselines are the state of the art triple basis estimator (3BE) or a standard MLP that represents the output distribution using a softmax over quantiles. On both of the synthetic tasks --- which involve predicting gaussians --- the proposed approach can fit the data reasonably using far fewer parameters than the baselines, although 3BE does achieve better overall performance. On a real world task that involves predicting a distribution of future stock market prices from multiple input stock marked distributions, the proposed approach significantly outperforms both baselines. However, this experiment uses 3BE outside of its intended use case --- which is for a single input distribution --- so it's not entirely clear how well the very simple proposed model is doing.\n\nNotes to authors:\n\nI'm not familiar with 3BE but the fact that it is used outside of its intended use case for the stock data is worrying. How does 3BE perform at predicting the FTSE distribution at time t + k from the FTSE distribution at time t only? Do the multiple input distributions actually help?\n\nYou use a kernel density estimate with a Gaussian kernel function to estimate the stock market pdf, but then you apply your network directly to this estimate. What would happen if you built more complex networks using the kernel values themselves as inputs?\n\nCould you also run experiments on the real-world datasets used by the 3BE paper?\n\nWhat is the structure of the DRN that uses > 10^3 parameters (from Fig. 4)? The width of the network is bounded by the two input distributions, so is this network just incredibly deep? Also, is it reasonable to assume that both the DRN and MLP are overfitting the toy task when they have access to an order of magnitude more parameters than datapoints.\n\nIt would be nice if section 2.4 was expanded to actually define the cost gradients for the network parameters, either in line or in an appendix.""]","[-20, 50, 50]","[50, 80, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice treatment', 'similar performance'), they express several concerns and criticisms. They question the practical utility, suggest the need for stronger motivation and experiments, and indicate that the paper lacks a thorough investigation of what problems the proposed method can solve. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, such as 'seems to be', 'it would be more enlightening', and 'it feels like', which soften the criticisms. They also begin with a positive note before moving to constructive criticism. The reviewer maintains a professional tone without using harsh or rude language, even when pointing out limitations."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as 'intriguing' and 'well-written', and provides mostly positive feedback. However, they also express two reservations, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing their concerns as 'reservations' rather than criticisms. They use phrases like 'it is not clear to me' instead of more direct or harsh language when questioning aspects of the work. The overall tone is constructive and professional, maintaining a polite discourse even when pointing out potential issues."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and potential advantages, while also pointing out areas for improvement. The review begins with a neutral summary of the paper's content, followed by a mix of positive observations (e.g., 'the proposed approach significantly outperforms both baselines') and constructive criticism. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, frames criticisms as questions or suggestions (e.g., 'Could you also run experiments...?'), and provides specific, actionable feedback without using harsh or dismissive language. The reviewer maintains a professional tone and offers helpful suggestions for improving the paper, demonstrating courtesy towards the authors.""]"
"['This paper proposes for training a question answering model from answers only and a KB by learning latent trees that capture the syntax and learn the semantic of words, including referential terms like ""red"" and also compositional operators like ""not"".\n\nI think this model is elegant, beautiful and timely. The authors do a good job of explaining it clearly. I like the modules of composition that seem to make a very intuitive sense for the ""algebra"" that is required and the parsing algorithm is clean. \n\nHowever, I think that the evaluation is lacking, and in some sense the model exposes the weakness of the dataset that it uses for evaluation.\n\nI have 2.5 major issues with the paper and a few minor comments: \n\nParsing:\n\n* The authors don\'t really say what is the base case for \\Psi that scores tokens (unless I missed it and if indeed it is missing it really needs to be added) and only provide the recursive case. From that I understand that the only features that they use are whether a certain word makes sense in a certain position of the rule application in the context of the question. While these features are based on Durrett et al.\'s neural syntactic parser it seems like a pretty weak signal to learn from. This makes me wonder, how does the parser learn whether one parse is better than the other? Only based on this signal? It makes me suspicious that the distribution of language is not very ambiguous and that as long as you can construct a tree in some context you can do it in almost any other context. This is probably due to the fact that the CLEVR dataset was generated mostly using templates and is not really natural utterances produced by people. Of course many people have published on CLEVR although of its language limitations, but I was a bit surprised that only these features are enough to solve the problem completely, and this makes me curious as to how hard is it to reverse-engineer the way that the language was generated with a context-free mechanism that is similar to how the data was produced.\n\n* Related to that is that the decision for a score of a certain type t for a span (i,j) is the sum for all possible rule applications, rather than a max, which again means that there is no competition between different parse trees that result with the same type of a single span. Can the authors say something about what the parser learns? Does it learn to extract from the noise clear parse trees? What is the distribution of rules in those sums? is there some rule that is more preferred than others usually? It seems like there is loss of information in the sum and it is unclear what is the effect of that in the paper.\n\nEvaluation:\n\n* Related to that is indeed the fact that they use CLEVR only. There  is now the Cornell NLVR dataset that is more challenging from a language perspective and it would be great to have an evaluation there as well. Also the authors only compare to 3 baselines where 2 don\'t even see the entire KB, so the only ""real"" baseline is relation net. The authors indeed state that it is state-of-the-art on clevr. \n\n* It is worth noting that relation net is reported to get 95.5 accuracy while the authors have 89.4. They use a subset so this might be the reason, but I am not sure how they compared to relation net exactly. Did they re-tune parameters once you have the new dataset? This could make a difference in the final accuracy and cause an unfair advantage.\n\n* I would really appreciate more analysis on the trees that one gets. Are sub-trees interpretable? Can one trace the process of composition? This could have been really nice if one could do that. The authors have a figure of a purported tree, but where does this tree come from? From the mode? Form the authors?\n\nScalability:\n* How much of a problem would it be to scale this? Will this work in larger domains? It seems they compute an attention score over every entity and also over a matrix that is squared in the number of entities. So it seems if the number of entities is large that could be very problematic. Once one moves to larger KBs it might become hard to maintain full differentiability which is one of the main selling points of the paper. \n\nMinor comments:\n* I think the phrase ""attention"" is a bit confusing - I thought of a distribution over entities at first. \n* The feature function is not super clearly written I think - perhaps clarify in text a bit more what it does.\n* I did not get how the denotation that is based on a specific rule applycation t_1 + t_2 --> t works. Is it by looking at the grounding that is the result of that rule application?\n* Authors say that the neural enquirer and neural symbolic machines produce flat programs - that is not really true, the programs are just a linearized form of a tree, so there is nothing very flat about it in my opinion.\n\nOverall, I really enjoyed reading the paper, but I was left wondering whether the fact that it works so well mostly attests to the way the data was generated and am still wondering how easy it would be to make this work in for more natural language or when the KB is large.\n\n\n', 'The paper describes an end to end differentiable model to answer questions based on a knowledge base. They learn the composition modules which combine representations for parts of the question to generate a representation of the whole question.   \n\nMy major complaint is the evaluation on a synthetically generated data set. Given the method of generating the data, it was not a surprise that the method which leverages hierarchical structure can do better than other methods which do not leverage that. I will be convinced if evaluation can be done on a real data set.  \n\nMinor complaints: \n\nThe paper does not compare to NMN, or a standard semantic parser. I understand that all other methods will use a predefined set of predicates, but its still worthwhile to see how much we loose when trying to learn predicates from scratch.\n\nThe paper mentions that they enumerate all parses. That is true only if the groundings are not considered part of the parse. They actually enumerate all parses based on types, and then find the right groundings for the best parse. This two step inference is an approximation, which should be mentioned somewhere.\n\nResponse to rebuttal: \n\nI agree that current data sets have minimal compositionality,  and that ""if existing models cannot handle the synthetic data, they will not handle real data"". However, its not clear that your method will be better than the alternatives when you move to real data. Also, some work on CLEVR had some questions collected from humans, maybe you can try to evaluate on that. I am going to keep my rating the same.  ', 'This paper presents a model for visual question answering that can learn both\nparameters and structure predictors for a modular neural network, without\nsupervised structures or assistance from a syntactic parser. Previous approaches\nfor question answering with module networks can (at best) make a hard choice\namong a small number of structures. By contrast, this approach computes a\nbottom-up approximation to the softmax over all possible tree-shaped network\nlayouts using a CKY-style dynamic program. On a slightly modified set of\nstructured scene representations from the CLEVR dataset, this approach\noutperforms two LSTM baselines with incomplete information, as well as an\nimplementation of Relation Networks.\n\nI think the core technical idea here is really exciting! But the experimental\nvalidation of the approach is a bit thin, and I\'m not ready to accept the paper\nin its current form.\n\nRELATED WORK / POSITIONING\n\nThe title & first couple of paragraphs in the intro suggest that the\ndenotational interpretation of the representations computed by the modules is\none of the main contributions of this work. It\'s worht pointing out that the\nconnection between formal semantics and these kinds of locally-normalized\n""attentions"" to entities was already made in the cited NMN papers. Meanwhile,\nrecent work by Johnson et al. and Perez et al. has found that explicitly\nattentional / denotational models are not necessarily helpful for the CLEVR\ndataset.\n\nIf the current paper really wants to make denotational semantics part of the\ncore claim, I think it would help to talk about the representational\nimplications in more detail---what kinds of things can and can\'t you model\nonce you\'ve committed to set-like bottlenecks between modules? Are there things\nwe expect this approach to do better than something more free-form (a la\nJohnson)? Can you provide experimental evidence of this?\n\nAt the same time, one of these things that\'s really nice about the\nstructure-selection part of this model is that it doesn\'t care what kind of\nmessages the modules send to each other! It might be just as effective to focus\non the dynamic programming aspect and not worry so much about the semantics of\nindividual modules.\n\nMODELING\n\nFigure 2 is great. It would be nice to have a little bit of discussion about the\nmotivation for these particular modeling implementations---some are basically\nthe same as in Hu et al. (2017), but obviously the type system here is richer\nand it might be helpful to highlight some of the extra things it can do.\n\nThe phrase type semantic potential seems underpowered relative to the rest of\nthe model---is it really making decisions on the basis of 6 sparse features for\nevery (span, type) pair, with no score for the identity of the rule (t_1, t_2 ->\nt)? What happens if you use biRNN representations of each anchored token, rather\nthan the bare token alone? (This is standard in syntactic parsing these days.)\nIf you tried richer things and found that they didn\'t help, you should show\nablation experiments.\n\nEXPERIMENTS\n\nAs mentioned above, I think this is the only really disappointing piece of this\npaper. As far as I know, nobody else has actually worked with the structured KBs\nin CLEVR---the whole point of the dataset (and VQA, and the various other recent\nquestion answering datasets) is to get away from requiring structured knowledge\nbases. The present experiments involve both fake language data and fake,\nstructured world representations, so it\'s not clear how much we should trust the\nproposed approach to generalize to real tasks.\n\nWe know that more traditional semantic parsing approaches with real logical\nforms are capable of getting excellent accuracy on structured QA tasks with a\nlot more complexity and less data than this one. I think fairness really\nrequires a comparison to an approach for semantic parsing with denotations. \n\nBut more importantly, why not just run on images? Results on VQA, CLEVR, and\nNLVR (even if they\'re not all state of the art!) would make this paper much more\nconvincing.']","[20, -40, -20]","[60, 20, 60]","[""The sentiment score is slightly positive (20) because the reviewer expresses appreciation for the paper's elegance and clarity in the beginning, calling it 'beautiful and timely'. However, they also raise several major concerns about the evaluation and scalability, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as questions or suggestions rather than direct attacks. They use phrases like 'I think', 'I would appreciate', and 'Can the authors say something about...' which maintain a polite tone. The reviewer also ends on a positive note, saying they 'really enjoyed reading the paper', further contributing to the polite tone."", ""The sentiment score is -40 because the reviewer expresses major complaints about the evaluation on synthetic data and doubts about the method's effectiveness on real data. However, they do acknowledge some positive aspects like the model's differentiable nature. The politeness score is 20 because the reviewer uses professional language and offers constructive criticism, but also directly states complaints and maintains a skeptical tone. They use phrases like 'I will be convinced if...' which is polite but firm. The reviewer also responds to a rebuttal in a balanced way, acknowledging points but maintaining their position."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the core idea 'really exciting', they are 'not ready to accept the paper in its current form' due to thin experimental validation. They express disappointment with the experiments section. However, the overall tone is not entirely negative, as they see potential in the work. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges the strengths of the paper, and phrases criticisms constructively. They use phrases like 'I think' and 'It would be nice to' which soften their critiques. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism.""]"
"[""The authors proposed a new clustering algorithm named deep continuous clustering (DCC) that integrates autoencoder into continuous clustering. As a variant of  continuous clustering (RCC), DCC formed a global continuous objective for joint nonlinear dimensionality reduction and clustering. The objective can be directly optimized using SGD like method. Extensive experiments on image and document datasets show the effectiveness of DCC. However, part of experiments are not comprehensive enough. \n\nThe idea of integrating autoencoder with continuous clustering is novel, and the optimization part is quite different. The trick used in the paper (sampling edges but not samples) looks interesting and seems to be effective. \n\nIn the following, there are some detailed comments:\n1. The paper is well written and easy to follow, except the definition of Geman-McClure function is missing. It is difficult to follow Eq. (6) and (7).\n2. Compare DCC to RCC, the pros and cons are obvious. DCC does improve the performance of clustering with the cost of losing robustness. DCC is more sensitive to the hyper-parameters, especially embedding dimensionality d. With a wrong d DCC performs worse than RCC on MNIST and similar on Reuters. Since clustering is one unsupervised learning task. The author should consider heuristics to determine the hyper-parameters. This will increase the usability of the proposed method.\n3. However, the comparison to the DL based partners are not comprehensive enough, especially JULE and DEPICT on image clustering. Firstly, the authors only reported AMI and ACC, but not NMI that is reported in JULE. For a fair comparison, NMI results should be included. Secondly, the reported results do not agree with the one in original publication. For example, JULE reported ACC of 0.964 and 0.684 on MNIST and YTF. However, in the appendix the numbers are 0.800 and 0.342 respectively. Compared to the reported number in JULE paper, DCC is not significantly better.\n\nIn general, the paper is interesting and proposed method seems to be promising. I would vote for accept if my concerns can be addressed.\n\nThe author's respond address part of my concerns, so I have adjusted my rating."", 'As authors stated, the proposed DCC is very similar to RCC-DR (Shah & Koltun, 2007). The only difference in (3) from RCC-DR is the decoding part, which is replaced by autoencoder instead of linear transformation used in RCC-DR. Authors claimed that there are three major differences. However, due to the highly nonconvex properties of both formulations, the last two differences hardly support the advantages of the proposed DCC comparing with RCC-DR because the solutions obtained by both optimization approaches are local solutions, unless authors can claim that the gradient-based solver is better than alternating approach in RCC-DR. Hence, DCC is just a simple extension of RCC-DR.\n\nIn Section 3.2, how does the optimization algorithm handle the equality constraints in (5)? It is unclear why the existing autoencoder solver can be used to solve (3) or (5). It seems that the first term in (5) corresponds to the objective of autoencoder, but the last two terms added lead to different objective with respect to variables y. It is better to clarify the correctness of the optimization algorithm.\n\nAuthors claimed that the proposed method avoid discrete reconfiguration of the objective that characterize prior clustering algorithms, and it does not rely on a priori knowledge of the number of ground-truth clusters. However, it seems not true since the graph construction at every epoch depends on the initial parameter delta_2 and the graph is constructed such that f_{i,j}=1 if distance is less than delta_2. As a result, delta_2 is a fixed threshold for graph construction, so it is indirectly related to the number of clusters generated. In the experiments, authors set it as the mean of the bottom 1% of the pairwise distances in E at initialization, and clustering assignment is given by connected component in the last graph. This parameter might be sensitive to the final results.\n\nMany terms in the paper are not well explained. For example, in (1), theta are treated as parameters to optimize, but what is the theta used for? Does the Omega related to encoder and decoder of the parameters in autoencoder. What is the scaled Geman-McClure function? Any reference? Why should this estimator be used?\n\nFrom the visualization results in Figure 1, it is interesting to see that K-means++ can achieve much better results on the space learned by DCC than that by SDAE from Table 2. In Figure 1, the embedding by SDAE (Figure 1(b)) seems more suitable for kmeans-like algorithm than DCC (Figure 1(c)). That is the reason why connected component is used for cluster assignment in DCC, not kmeans. The results between Table 2 and Figure 1 might be interesting to investigate. \n', 'This paper presents a clustering method in latent space. The work extends a previous approach (Shah & Koltun 2017) which employs a continuous relaxation of the clustering assignments. The proposed method is tested on several image and text data sets.\n\nHowever, the work has a number of problems and unclear points.\n\n1) There is no theoretical guarantee that RCC or DCC can give good clusterings. The second term in Eq. 2 will pull z\'s closer but it can also wrongly place data points from different clusters nearby.\n\n2) The method uses an autoencoder with elementwise least square loss. This is not suitable for data sets such as images and time series.\n\n3) Please elaborate ""redesending M-estimator"" in Section 2. Also, please explicitly write out what are rho_1 and rho_2 in the experiments.\n\n4) The method requires many extra hyperparameters lambda, delta_1, delta_2. Users have to set them by ad hoc heuristics.\n\n5) In each epoch, the method has to construct the graph G (the last paragraph in Page 4) over all z pairs.  This is expensive. The author didn\'t give any running time estimation in theory or in experiments.\n\n6) The experimental results are not convincing. For MNIST its best accuracy is only 0.912. Existing methods for this data set have achieve 0.97 accuracy. See for example [Ref1,Ref2,Ref3]. For RCV1, [Ref2] gives 0.54, but here it is only 0.495.\n\n7) Figure 1 gives a weird result. There is no known evidence that MNIST clusters intrinsically distribute like snakes. They must be some wrong artefacts introduced by the proposed method. Actually t-SNE with MNIST pixels is not bad at all. See [Ref4].\n\n8) It is unknown how to set the number of clusters in proposed method.\n\n\n[Ref1] Zhirong Yang, Tele Hao, Onur Dikmen, Xi Chen, Erkki Oja. Clustering by Nonnegative Matrix Factorization Using Graph Random Walk. In NIPS 2012.\n[Ref2] Xavier Bresson, Thomas Laurent, David Uminsky, James von Brecht. Multiclass Total Variation Clustering. In NIPS 2013.\n[Ref3] Zhirong Yang, Jukka Corander and Erkki Oja. Low-Rank Doubly Stochastic Matrix Decomposition for Cluster Analysis. Journal of Machine Learning Research, 17(187): 1-25, 2016.\n[Ref4] https://sites.google.com/site/neighborembedding/mnist\n\nConfidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature']","[50, -50, -70]","[80, 20, -20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and potential of the proposed method, stating it's 'interesting and promising'. They also mention voting for acceptance if concerns are addressed. However, they point out some limitations and areas for improvement, which prevents a higher positive score. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and balances positive and negative feedback. They use phrases like 'The paper is well written' and 'The idea... is novel', while also politely expressing concerns. The reviewer's willingness to adjust their rating based on the authors' response also indicates a respectful and fair approach."", ""The sentiment score is -50 because the reviewer expresses significant skepticism about the novelty and advantages of the proposed method (DCC) compared to existing methods. They state it's 'just a simple extension' and question several of the authors' claims. However, it's not entirely negative as they do show interest in some results. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'It is better to clarify' and 'It is interesting to see', which are constructive rather than harsh. The reviewer also asks questions for clarification rather than making outright dismissals. However, some statements are quite direct, preventing a higher politeness score."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states there are 'a number of problems and unclear points' and proceeds to list 8 major issues with the paper, including lack of theoretical guarantees, unsuitable methods, unclear explanations, and unconvincing results. There are no positive comments about the paper's contributions or merits. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without any softening language or positive feedback. Phrases like 'There is no known evidence' and 'They must be some wrong artefacts' come across as somewhat harsh. The reviewer does not use polite phrases or acknowledge any strengths of the work, which contributes to the slightly negative politeness score.""]"
"['This paper describes the use of ensemble methods to improve the robustness of neural networks to adversarial examples. Adversarial examples are images that have been slightly modified (e.g. by adding some small perturbation) so that the neural network will predict a wrong class label.\n\nEnsemble methods have been used by the machine learning community since long time ago to provide more robust and accurate predictions.\n\nIn this paper the authors explore their use to increase the robustness of neural networks to adversarial examples.\n\nDifferent ensembles of 10 neural networks are considered. These include techniques such as bagging or injecting noise in the \ntraining data. \n\nThe results obtained show that ensemble methods can sometimes significantly improve the robustness against adversarial examples. However,\nthe performance of the ensemble is also highly deteriorated by these examples, although not as much as the one of a single neural network.\n\nThe paper is clearly written.\n\nI think that this is an interesting paper for the deep learning community showing the benefits of ensemble methods against adversarial\nexamples. My main concern with this paper is the lack of comparison with alternate techniques to increase the robustness against adversarial examples. The authors should have compared with the methods described in:\n\n(Goodfellow et al., 2014; Papernot et al., 2016c), \n(Papernot et al., 2016d) \n(Gu & Rigazio, 2014)\n\nFurthermore, the ensemble approach has the main disadvantage of increasing the prediction time by a lot. For example, with 10 elements in the ensemble, predictions are 10 times more expensive.\n------------------------------\nI have read the updated version of the paper. I think the authors have done a good job comparing with related techniques. Therefore, I have slightly increased my score.\n', ""Summary: This paper proposes to use ensembling as an adversarial defense mechanism. The defense is evaluated on MNIST and CIFAR10 ans shows reasonable performance against FGSM and BIM.\n\nClarity: The paper is clearly written and easy to follow. \n\nOriginality: Building an ensemble of models is a well-studied strategy that was shown long ago to improve generalization. As far as I know, this paper is however the first to empirically study the robustness of ensembles against adversarial examples. \n\nQuality: While this paper contributes to show that ensembling works reasonably well against adversarial examples, I find the contribution limited in general.\n- The method is not compared against other adversarial defenses. \n- The results illustrate that adding Gaussian noise on the training data clearly outperforms the other considered ensembling strategies. However, the authors do not go beyond this observation and do not appear to try to understand why it is the case. \n- Similarly, the Bagging strategy is shown to perform reasonably well (although it appears as a weaker strategy than Gaussian noise) but no further analysis is carried out. For instance, it is known that the reduction of variance is maximal in an ensemble when its constituents are maximally decorrelated. It would be worth studying more systematically if this correlation (or 'diversity') has an effect on the robustness against adversarial examples. \n- I didn't understand the motivation behind considering two distinct gradient estimators. Why deriving the exact gradient of an ensemble is more complicated?\n\nPros: \n- Simple and effective strategy.\n- Clearly written paper. \nCons:\n- Not compared against other defenses.\n- Limited analysis of the results. \n- Ensembling neural networks is very costly in terms of training. This should be considered.\n\nOverall, this paper presents an interesting and promising direction of research. However, I find the current analysis (empirically and/or theoretically) to be too limited to constitutes a solid enough piece of work. For this reason, I do not recommend this paper for acceptance. "", 'In this manuscript, the authors empirically investigated the robustness of some different deep neural networks ensembles to two types of attacks, namely FGSM and BIM, on two popular datasets, MNIST and CIFAR10. The authors concluded that the ensembles are more accurate on both clean and adversaries samples than a single deep neural network. Therefore, the ensembles are more robust in terms of the ability to correctly classify the adversary attacks.\n\nAs the authors stated, an attack that is designed to fool one network does not necessarily fool the other networks in the same way. This is likely why ensembles appear more robust than single deep learners. However, robustness of ensembles to the white-box attacks that are generated from the ensemble is still low for FGS. Generally speaking, although FGS attacks generated from one network can fool less the whole ensembles, generating FGS adversaries from a given ensemble is still able to effectively fool it. Therefore, if the attacker has access to the ensemble or even know the classification system based on that ensemble, then the ensemble-based system is still vulnerable to the attacks generated specifically from it. Simple ensemble methods are not likely to confer significant robustness gains against adversaries.\n\nIn contrast to FGS results, surprisingly BIM-Grad1 is able to fool more the ensemble than BIM-Grad2. Therefore, it seems that if the attacker makes BIM adversaries from only a single classifier, then she can simply and yet effectively mislead the whole ensemble. In comparison to BIM-Grad2, BIM-Grad1 results show that BIM attacks from one network (BIM-Grad1) can more successfully fool the other different networks in the ensembles in a similar way! BIM-Grad2 is not that much able to fool the ensemble-based system even this attack generated from the ensemble (white-box attacks). In order to confirm the robustness of the ensembles to BIM attacks, the authors can do more experiments by generating BIM-Grad2 attacks with higher number of iterations.\n\nIndeed, the low number of iterations might cause the lower rate of success for generating adversaries by BIM-Grad2. In fact, BIM adversaries from the ensembles might require more number of iterations to effectively fool the majority of the members in the ensembles. Therefore, increasing the number of iterations can increase the successful rate of generating BIM-Average Grad2 adversaries. Note that in this case, it is recommended to compare the amount of distortion (perturbation) with different number of iterations in order to indicate the effectiveness of the ensembles to white-box BIM attacks.\n\nDespite to averaging the output probabilities to compute the ensemble final prediction, the authors generated the adversaries from the ensemble by computing the sum of the gradients of the classifiers loss. A proper approach would have been to average of these gradients. The fact the sum is not divided by the number of members (i.e., sum of gradients instead of average of gradients) is increasing the step size of the adversarial method proportionally to the ensemble size, raising questions on the validity of the comparison with the single-model adversarial generation.\n\nOverall, I found the paper as having several methodological flaws in the experimental part, and rather light in terms of novel ideas. As noticed in the introduction, the idea of using ensemble for enhancing robustness as already been proposed. Making a paper only to restate it, is too light for acceptation. Moreover, experimental setup using a lot of space for comparing results on standard datasets (i.e., MNIST and CIFAR10), even with long presentation of these datasets. Several issues are raised in the current experiments and require adjustments. Experiments should also be more elaborated to make the case stronger, following at least some of indications provided. \n']","[60, -30, -50]","[80, 50, 20]","[""The sentiment score is 60 (moderately positive) because the reviewer describes the paper as 'interesting' and notes that it's 'clearly written'. They also mention that the authors have 'done a good job' in addressing previous concerns. However, they do point out some limitations, which prevents a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and acknowledges improvements in the updated version. They phrase their concerns as suggestions rather than harsh criticisms, using phrases like 'My main concern' and 'The authors should have', which maintains a polite tone."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('interesting and promising direction', 'clearly written', 'simple and effective strategy'), the overall recommendation is negative ('I do not recommend this paper for acceptance'). The reviewer lists several limitations and criticisms, which outweigh the positive comments. The politeness score is 50 because the reviewer uses respectful and professional language throughout, acknowledging positives before presenting criticisms, and uses phrases like 'I find' to soften negative feedback. However, it's not extremely polite, maintaining a neutral, objective tone typical of academic reviews."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the research (e.g., 'ensembles are more accurate'), they also point out several significant flaws and limitations. The review concludes that the paper has 'several methodological flaws' and is 'rather light in terms of novel ideas', suggesting an overall negative sentiment. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'the authors can do more experiments' and 'it is recommended to', which are polite suggestions. However, the criticism is direct and not overly softened, preventing a higher politeness score. The reviewer also uses some neutral academic language, balancing between politeness and directness in their critique.""]"
"['The paper proposes a nice idea of sparsification of skip connections in DenseNets. The authors decide to use a principle for sparsification that would minimize the distance among layers during the backpropagation. \n\nThe presentation of the paper could be improved. The paper presents an elegant and simple idea in a dense and complex way making the paper difficult to follow. E. g., Fig 1 d is discussed in Appendix and not in the main body of the paper, thus, it could be moved to Appendix section.\n\nTable 1 and 3 presents the results only for LogDenseNet V1, would it be possible to add results for V2 that have different MBD. Also, the budget for the skip connections is defined as log(i) in Table 1 and Table 2 has the budget of log(i/2), would it be possible to add the total number of skip connections to the tables? It would be interesting to compare the total number of skip connections in Jegou et. al. to LogDenseNet V1 in Table 3.\n\nOther issues:\n- Table 3, has an accuracy of nan. What does it mean? Not available or not a number? \n- L is used as the depth, however, in table 1 it appears as short for Log-DenseNetV1. Would it be possible to use another letter here?\n- “…, we make x_i also take the input from x_{i/4}, x_{i/8}, x_{i/16}…”. Shouldn’t x_{1/2} be used too?\n- I’m not sure I understand the reasons behind blurred image in Fig 2 at ½. It is mentioned that “it and its feature are at low resolution”. Could the authors comment on that?\n- Abstract: “… Log-DenseNets are easier than DenseNet to implement and to scale.” It is not clear why would LogDenseNets be easier to implement. ', ""This paper investigates how to impose layer-wise connections in DenseNets most efficiently. The authors propose a connection-pattern, which connects layer i to layer i-2^k, k=0,1,2... The authors also propose maximum backpropgation distance (MBD) for measuring the fluency of gradient flow in the network, and justify the Log-DenseNet's advantage in this framework. Empirically, the author demonstrates the effectiveness of Log-DenseNet by comparing it with two other intuitive connection patterns on CIFAR datasets. Log-DenseNet also improves on FC-DenseNet, where the connection budget is the bottleneck because the feature maps are of high resolutions.\n\n\nStrengths:\n1. Generally, DenseNet is memory-hungry if the connection is dense, and it is worth studying how to sparsify a DenseNet. By showing the improvements on FC-DenseNet, Log-DenseNet demonstrates good potential on tasks which require upsampling of feature maps. \n2. The ablation experiments are well-designed and the visualizations of connectivity pattern are clear.\n\nWeakness:\n1. Adding a comparison with Log-DenseNet and vanilla DenseNet in the Table 2 experiment would make the paper stronger. Also, the NearestHalfAndLog pattern is not used in any latter visual recognition experiments, so I think it's better to just compare LogDenseNet with the two baselines instead. Despite there are CIFAR experiments on Log-DenseNet in latter sections, including results here would be easier to follow.\n2. I would like to see the a comparison with the DenseNet-BC in the segmentation and CIFAR classification tasks, which uses 1x1 conv layers to reduce the number of channels. It should be interesting to study whether it is possible to further sparsify DenseNet-BC, as it has much higher efficiency.\n3. The improvement of efficiency on classifications task is not that significant.\n"", 'This paper introduces a new connectivity pattern for DenseNets, which encourages short distances among layers during backpropagation and gracefully scales to wider and deeper architectures. Experiments are performed to analyze the importance of the skip connections’ place in the context of image classification. Then, results are reported for both image classification and semantic segmentation tasks.\n\nThe clarity of the presentation could be improved. The main contribution of the paper is a network design that places skip connections to minimize the distances between layers, increasing the distance from 1 to 1 + log L when compared to traditional DenseNets. This design principle allows to mitigate the memory required to train DenseNets, which is critical for applications such as semantic segmentation where the input resolution has to be recovered.\n\nExperiments seem well executed; the authors consider several sparse connectivity patterns for DenseNets and provide empirical evidence highlighting the advantages of having a short maximum backpropagation distance (MBD). Moreover, they provide an analysis on the trade-off between the performance of a network and its computational cost.\n\nAlthough literature review is quite extensive, [a] might be relevant to discuss in the Network Compression section.\n[a] https://arxiv.org/pdf/1412.6550.pdf\n\nIt is not clear why Log-DenseNets would be easier to implement than DenseNets, as mentioned in the abstract. Could the authors clarify that?\n\nIn Tables 1-2-3, it would be good to add the results for Log-DenseNet V2. Adding the MBD of each model in the tables would also be beneficial.\n\nIn Table 3, what does “nan” accuracy mean? (DeepLab-LFOV)\n\nFinally, the authors might want to review the citep/cite use in the manuscript. ']","[20, 50, 50]","[60, 75, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper proposes a 'nice idea' and an 'elegant and simple idea'. However, they also point out several areas for improvement, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, often phrasing criticisms as suggestions or questions (e.g., 'would it be possible to...', 'Could the authors comment on that?'). The reviewer maintains a professional tone, avoiding harsh criticism while still providing constructive feedback. The balance of positive acknowledgment and constructive criticism, coupled with the polite phrasing of suggestions, results in these scores."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges strengths of the paper, such as the potential improvements on FC-DenseNet and well-designed experiments. However, they also point out weaknesses, including the lack of certain comparisons and the not-so-significant improvement in efficiency for classification tasks. This balanced view suggests a moderately positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, presenting both strengths and weaknesses in a constructive manner. They use phrases like 'would make the paper stronger' and 'I would like to see' when suggesting improvements, which is polite and considerate. The review maintains a professional tone without any harsh or rude comments."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and the well-executed experiments, but also points out areas for improvement in clarity and presentation. The review is not overwhelmingly positive, but it does recognize the value of the work. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as questions or gentle recommendations rather than demands. The reviewer also acknowledges the authors' efforts and provides specific, helpful feedback for improvement without using harsh or dismissive language.""]"
"['----------------- Summary -----------------\nThe paper tackles the problem of task-incremental learning using deep networks. It devises an architecture and a training procedure aiming for some desirable properties; a) it does not require retraining using previous tasks’ data, b) the number of network parameters grows only sublinearly c) it preserves the output of the previous tasks intact.\n\n----------------- Overall -----------------\nThe paper tackles an important problem, aims for important characteristics, and does extensive and various experiments. While the broadness of the experiments are encouraging, the main task which is to propose an effective task-incremental learning procedure is not conclusively tested, mainly due to the lack of thorough ablation studies (for instance when convolutional layers are fixed) and the architecture seems to change from one baseline (method) to another.\n\n----------------- Details -----------------\n- in the abstract it says: ""Existing approaches either learn sub-optimal solutions, require joint training, or incur a substantial increment in the number of parameters for each added task, typically as many as the original network.""\nThe linear-combination constraint in the proposed approach is a strong one and can learn a sub-optimal solution for the newly introduced tasks.\n\n- Page 3: R^C → R^{C_o}\n\n- The notation is (probably unnecessarily) too complicated, perhaps it’s better to formulate it without being faithful to the actual implementation but for higher clarity and ease of understanding. For instance, one could start from denoting feature maps and applying the controller/transform matrix W on that, circumventing the clutter of convolutional kernels.\n\n- What is the DAN architecture? \n\n- In table 1 a better comparison is when using same architecture (instead of VGG) to train it from scratch or fine-tune from ImageNet (the first two rows)\n\n- What is the architecture used for random-weights baseline?\n\n- An experiment is needed where no controller is attached but just the additional fully-connected layers to see the isolated improvements gained by the linear transform of convolutional layers.\n\n- Multiple Base Networks: The assumption in incremental learning is that one does not have access to all tasks/datasets at once, otherwise one would train them jointly which would save parameters, training time and performance. So, finding the best base network using the validation set is not relevant.\n\n- The same concern as above applies to the transferability and dataset decider experiments\n', 'This paper proposes to adapt convnet representations to new tasks while avoiding catastrophic forgetting by learning a per-task “controller” specifying weightings of the convolution-al filters throughout the network while keeping the filters themselves fixed.\n\n\nPros\n\nThe proposed approach is novel and broadly applicable.  By definition it maintains the exact performance on the original task, and enables the network to transfer to new tasks using a controller with a small number of parameters (asymptotically smaller than that of the base network).\n\nThe method is tested on a number of datasets (each used as source and target) and shows good transfer learning performance on each one.  A number of different fine-tuning regimes are explored.\n\nThe paper is mostly clear and well-written (though with a few typos that should be fixed).\n\n\nCons/Questions/Suggestions\n\nThe distinction between the convolutional and fully-connected layers (called “classifiers”) in the approach description (sec 3) is somewhat arbitrary -- after all, convolutional layers are a generalization of fully-connected layers. (This is hinted at by the mention of fully convolutional networks.)  The method could just as easily be applied to learn a task-specific rotation of the fully-connected layer weights.  A more systematic set of experiments could compare learning the proposed weightings on the first K layers of the network (for K={0, 1, …, N}) and learning independent weights for the latter N-K layers, but I understand this would be a rather large experimental burden.\n\nWhen discussing the controller initialization (sec 4.3), it’s stated that the diagonal init works the best, and that this means one only needs to learn the diagonals to get the best results.  Is this implying that the gradients wrt off-diagonal entries of the controller weight matrix are 0 under the diagonal initialization, hence the off-diagonal entries remain zero after learning?  It’s not immediately clear to me whether this is the case -- it could help to clarify this in the text.\n\nIf the off-diag gradients are indeed 0 under the diag init, it could also make sense to experiment with an “identity+noise” initialization of the controller matrix, which might give the best of both worlds in terms of flexibility and inductive bias to maintain the original representation. (Equivalently, one could treat the controller-weighted filters as a “residual” term on the original filters F with the controller weights W initialized to noise, with the final filters being F+(W\\crossF) rather than just W\\crossF.)\n\nThe dataset classifier (sec 4.3.4) could be learnt end-to-end by using a softmax output of the dataset classifier as the alpha weighting. It would be interesting to see how this compares with the hard thresholding method used here.  (As an intermediate step, the performance could also be measured with the dataset classifier trained in the same way but used as a soft weighting, rather than the hard version rounding alpha to 0 or 1.)\n\n\nOverall, the paper is clear and the proposed method is sensible, novel, and evaluated reasonably thoroughly.', ""This paper proposes new idea of using controller modules for increment learning. Instead of finetuning the whole network, only the added parameters of the controller modules are learned while the output of the old task stays the same. Experiments are conducted on multiple image classification datasets. \n\nI found the idea of using controller modules for increment learning interesting and have some practical use cases. However, this paper has the following weakness:\n1) Missing simple baselines. I m curious to see some other multitask learning approach, e.g. branch out on the last few layers for different tasks and finetune the last few layers. The number of parameters won't be affected so much and it will achieve better performance than 'feature' in table 3.\n2) Gain of margin is really small. The performance improvements in Table1 and Table3 are very small. I understand the point is to argue with fewer parameters the model can achieve comparable accuracies. However, there could be other ways to design the network architecture to reduce the size (sharing the lower level representations).\n3) Presentation of the paper is not quite good. Figures are blurry and too small. ""]","[-20, 70, -20]","[50, 80, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem and the extensive experiments, they express concerns about the effectiveness of the proposed method and the lack of thorough ablation studies. The reviewer points out several limitations and areas where the paper falls short, indicating a somewhat critical stance.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They begin by acknowledging the paper's strengths and importance of the topic. The criticisms are presented as constructive feedback rather than harsh judgments. The reviewer uses phrases like 'The paper tackles an important problem' and 'While the broadness of the experiments are encouraging,' which soften the critique. The specific recommendations are phrased as suggestions or questions rather than demands.\n\nOverall, the review balances critique with politeness, maintaining a professional tone while clearly communicating areas for improvement."", ""The sentiment score is 70 (positive) because the review begins by highlighting the novelty and broad applicability of the proposed approach as 'pros'. It also praises the thorough testing and clear writing. While there are some 'cons' and suggestions, they are presented constructively as areas for potential improvement rather than major flaws. The overall tone is supportive, concluding that the paper is 'clear' and the method 'sensible, novel, and evaluated reasonably thoroughly'. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering suggestions. Phrases like 'It could help to clarify' and 'It would be interesting to see' are used to frame critiques politely. The reviewer also shows understanding of the authors' constraints, noting that certain additional experiments would be 'a rather large experimental burden'."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the idea interesting, they point out several weaknesses in the paper. The reviewer acknowledges the potential practical use cases but expresses concerns about missing baselines, small performance gains, and poor presentation. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, starting with a positive note about the interesting idea, and frames criticisms as observations or curiosities rather than harsh judgments. The reviewer uses phrases like 'I found...interesting' and 'I'm curious to see' which maintain a polite tone while still conveying critical feedback.""]"
"['This paper presents an analysis of the properties of agents who learn grounded language through reinforcement learning in a simple environment that combines verbal instruction with visual information. The analyses are motivated by results from cognitive and developmental psychology, exploring questions such as whether agents develop biases for shape/color, the difficulty of learning negation, the impact of curriculum format, and how representations at different levels of abstraction are acquired. I think this is a nice example of a detailed analysis of the representations acquired by a reinforcement learning agent. The extent to which it provides us with insight into human cognition depends on the degree to which we believe the structure of the agent and the task have a correspondence to the human case, which is ultimately probably quite limited. Nonetheless the paper takes on an ambitious goal of relating questions in machine learning in cognitive science and does a reasonably good job of analyzing the results.\n\nComments:\n\n1. The results on word learning biases are not particularly surprising given previous work in this area, much of which has used similar neural network models. Linda Smith and Eliana Colunga have published a series of papers that explore these questions in detail:\n\nhttp://www.iub.edu/~cogdev/labwork/kinds.pdf\nhttp://www.iub.edu/~cogdev/labwork/Ontology2003.pdf\n\n2. In figure 2 and the associated analyses, why were 20 shape terms used rather than 8 to parallel the other cases? It seems like there is a strong basic color bias. This seems like one of the most novel findings in the paper and is worth highlighting.\n\nThis figure and the corresponding analysis could be made more systematic by mapping out the degree of shape versus color bias as a function of the number of shape and color terms in a 2D plot. The resulting plot would show the degree of bias towards color.\n\n3. The section on curriculum learning does not mention relevant work on “starting small”  and the “less is more"" hypothesis in language development by Jeff Elman and Elissa Newport:\n\nhttps://pdfs.semanticscholar.org/371b/240bebcaa68921aa87db4cd3a5d4e2a3a36b.pdf\nhttp://www.sciencedirect.com/science/article/pii/0388000188900101\n\n4. The section on learning speeds could include more information on the actual patterns that are found with human learners, for example the color words are typically acquired later. I found these human results hard to reconcile with the results from the models. I also found it hard to understand why colors were hard to learn given the bias towards colors shown earlier in the paper.\n\n5. The section on layerwise attention claims to give a “computational level” explanation, but this is a misleading term to use — it is not a computational level explanation in the sense introduced by David Marr which is the standard use of this term in cognitive science. The explanation of layerwise attention could be clearer.\n\nMinor:\n\n“analagous” -> “analogous”\n\nThe paper runs longer than eight pages, and it is not obvious that the extra space is warranted.\n', 'This paper presents an analysis of an agent trained to follow linguistic commands in a 3D environment.  The behaviour of the agent is analyzed by means of a set of ""psycholinguistic"" experiments probing what it learned, and by inspection of its visual component through an attentional mechanism.\n\nOn the positive side, it is nice to read a paper that focuses on understanding what an agent is learning. On the negative side, I did not get many new insights from the analyses presented in the study.\n\n3 A situated language learning agent\n\nI can\'t make up the chair from the refrigerator in the figure.\n\n4.1 Word learning biases\n\nThis experiment shows that, when an agent is trained on shapes only, it will exhibit a shape bias when tested on new shapes and colors. Conversely, when it is exposed to colors only, it will have a color bias. When the training set is balanced, the agent shows a mild bias for the simpler color property. How is this interesting or surprising? The crucial question, here, would be whether, when an agent is trained in a naturalistic environment (i.e., where distributions of colors, shapes and other properties reflect those encountered by biological agents), it would show a human-like shape bias. This, however, is not addressed in the paper.\n\nMinor comments about this section:\n\n- Was there noise also in shape generation, or were all object instances identical?\n\n- propensity to select o_2: rather o_1?\n\n- I did not follow the paragraph starting with ""This effect provides"".\n\n4.2 The problem of learning negation\n\nI found this experiment very interesting.\n\nPerhaps, the authors could be more explicit about the usage of negation here. The meaning of commands containing negation are, I think, conjunctions of the form ""pick something and do not pick X"" (as opposed to the more natural ""do not pick X"").\n\nmodifiation: modification\n\n4.3 Curriculum learning\n\nPerhaps the difference in curriculum effectiveness in language modeling vs grounded language learning simulations is due to the fact that the former operates on large amounts of natural data, where it\'s hard to define the curriculum, while the latter are typically grounded in toy worlds with a controlled language, where it\'s easier to construct the curriculum.\n\n4.4 Processing and representation differences\n\nThere is virtually no discussion of what makes the naturalistic setup naturalistic, and thus it\'s not clear which conclusions we should derive from the corresponding experiments. Also, I don\'t see what we should learn from Figure 5 (besides the fact that in the controlled condition shapes are easier than categories). For the naturalistic condition, the current figure is misleading, since different classes contain different numbers of instances. It would be better to report proportions.\n\nConcerning the attention analysis, it seems to me that all it\'s saying is that lower layers of a CNN detect lower-level properties such as colors, higher layers detect more complex properties, such as shapes characterizing objects. What is novel here?\n\nAlso, since introducing attention changes the architecture, shouldn\'t the paper report the learning behaviour of the attention-augmented network?\n\nThe explanation of the attention mechanism is dense, and perhaps could be aided by a diagram (in the supplementary materials?). I think the description uses ""length"" when ""dimensional(ity)"" is meant.\n\n6. Supplementary material\n\nIt would be good to have an explicit description of the architecture, including number of layers of the various components, structure of the CNN, non-linearities, dimensionality of the layers, etc. (some of this information is inconsistently provided in the paper).\n\nIt\'s interesting that the encoder is actually a BOW model. This should be discussed in the paper, as it raises concerns about the linguistic interest of the controlled language that was used.\n\nTable 3: indicates is: indicates if\n', 'In this manuscript, the authors connect psychological experimental methods to understand how the black box of the mind solves problems with current issues in understanding how the black box of deep learning methods solves problems. The authors used situated versions of human language learning tasks as simulation environments to test a CNN + LSTM deep learning network. They examined a few key phenomena: shape/color bias, learning negation concepts, incremental learning, and how learning affects the representation of objects via attention-like processes. They illustrated conditions in which their deep learning network acts similarly to people in simulations.\nDeveloping methods that enable humans to understand how deep learning models solve problems is an important problem for many reasons (e.g., usability of models for science, ethical concerns) that has captured the interest of a wide range of researchers. By adapting experimental methodology from psychology to test that have been used to understand and explain the internal workings of the mind, the authors approach the problem in a novel and innovative manner. I was impressed by the range of phenomena they tackled and their analyses were informative in understanding the behavior of deep learning models \nI found the analogy persuasive in theory, but I was not convinced that the current manuscript really demonstrates its value. In particular, I did not see the value of situating their model in a grounded environment. One analysis that would have helped convince me is a comparison to an equivalent non-grounded deep learning model (e.g., a CNN trained to make equivalent classifications), and show how this would not help us understand human behavior. However, the more I thought about the logic of this type of analysis, the more concerned I became about the logic of their approach. \nWhat would it mean if the equivalent non-situated model does not show the phenomena? If it does not, it could illustrate the efficacy of using situated environments. But, it also could mean that their technique acts differently for equivalent situated and non-situated models. In this case though, what would we learn about the more general non-situated case then? It does not seem like we would learn much, which would defeat the purpose of the technique. Alternatively, if the equivalent non-situated model does show the phenomena, then using the situated version would not be useful because the model acts equivalently in both cases. I am not fully convinced by the argument I just sketched, but leaves me very concerned about the usefulness of their approach. (note that the “controlled” vs. “naturalistic” analyses in the word learning section did not convince me. This argues for the importance of using naturalistic statistics – not necessarily cross-modal, situated environments as the authors argue for).\nAdditionally, I was unconvinced that simpler models could not be used to examine the phenomena that they analyzed. Although combining LSTM with CNN via a “mixing” module was interesting, it added another layer of complexity that made it more difficult to assess what the results meant. This left me less convinced of the usefulness of their paradigm. If we need to create a novel deep learning method to illustrate its efficacy, how will it be useful for solving the problem that motivated everything: understanding how pre-existing deep learning methods solve problems. \n']","[50, -20, -20]","[75, 50, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as 'a nice example' and praises its 'ambitious goal', while also noting limitations and areas for improvement. The tone is generally constructive rather than critical. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers specific suggestions for improvement rather than harsh criticisms, and acknowledges the paper's merits. The reviewer also uses phrases like 'I think' and 'I found' to soften critiques. The polite tone is maintained even when pointing out issues or suggesting changes."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice to read a paper that focuses on understanding what an agent is learning'), they express overall disappointment ('I did not get many new insights from the analyses presented in the study'). The review points out several limitations and questions the novelty and significance of some findings. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout, using phrases like 'it is nice to read' and 'I found this experiment very interesting'. They also provide constructive feedback and suggestions for improvement without using harsh language. The reviewer balances critique with positive comments and uses polite language to express concerns, demonstrating a courteous approach to academic review."", ""The sentiment score is slightly negative (-20) because while the reviewer initially expresses interest and appreciation for the authors' approach, they later raise significant concerns about the usefulness and logic of the methodology. The reviewer is 'not convinced' by several aspects of the work and expresses doubts about its overall value. However, the score is not deeply negative as the reviewer does acknowledge some positive aspects.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful language throughout, even when expressing criticisms. They use phrases like 'I was impressed,' 'I found the analogy persuasive in theory,' and 'I am not fully convinced' rather than harsh or dismissive language. The reviewer also acknowledges the potential value of the work before presenting their concerns, which is a polite approach to criticism.""]"
"[""This paper adapts the sequential halving algorithm that underpins Hyperband to run across multiple workers in a compute cluster. This represents a very practical scenario where a user of this algorithm would like to trade off computational efficiency for a reduction in wall time. The paper's empirical results confirm that indeed significant reductions in wall time come with modest increases in overall computation, it's a practical improvement.\n\nThe paper is crisply written, the extension is a natural one, the experiment protocols and choice of baselines are appropriate.\n\nThe left panel of figure 3 is blurry, compared with the right one."", 'This paper introduces a simple extension to parallelize Hyperband. \n\nPoints in favor of the paper:\n* Addresses an important problem\n\nPoints against:\n* Only 5-fold speedup by parallelization with 5 x 25 workers, and worse performance in the same budget than Google Vizier (even though that treats the problem as a black box)\n* Limited methodological contribution/novelty\n\n\nThe paper\'s methodological contribution is quite limited: it amounts to a straight-forward parallelization of successive halving (SHA). Specifically, whenever a worker frees up, do a new run on it, at the highest rung possible while making sure to not run too many runs for too high rungs. (I am pretty sure that is the idea, even though Algorithm 1, which is supposed to give the details, appears to have a bug in Procedure get_job -- it would always either pick the highest rung or the lowest!)\n\nEmpirically, the paper strangely does not actually evaluate a parallel version of Hyperband, but only evaluates the 5 parallel variants of SHA that Hyperband would run, each of them with all workers. The experiments in Section 4.2 show that, using 25 workers, the best of these 5 variants obtains a 5-fold speedup over sequential Hyperband on CIFAR and an 8-fold speedup on SVHN. I am confused: the *best* of 5 SHA variants only achieves a 5-fold speedup using 25 workers? I.e., parallel Hyperband, which would run the 5 SHA variants in parallel, would require 125 workers but only yield a 5-fold speedup? If I understand this correctly, I would clearly call this a negative result.\n\nLikewise, for the large-scale experiment, a single run of Vizier actually yields as good performance as the best of the 5 SHA variants, and it is unknown beforehand which SHA variant works best -- in this example, actually Bracket 0 (which is often the best) stagnates. Parallel Hyperband would run the 5 SHA variants in parallel, so its performance at a budget of 10R with a total of 500 workers can be evaluated by taking the minimum of the 5 SHA variants at a budget of 2R. This would obtain a perplexity of above 90, which is quite a bit worse than Vizier\'s result of about 82. In general, the performance of parallel Hyperband can be computed by taking the minimum of the SHA variants and multiplying the time taken by 5; this shows that at any time in the plot (Figure 3, left) Vizier dominates parallel Hyperband. Again, this is apparently a negative result. (For Figure 3, right, no results for Vizier are given yet.)\n\nIf I understand correctly, the experiment in Section 4.4 does not involve any run of Hyperband, but merely plots predictions of Qi et al.\'s Paelo framework of how many models could be evaluated with a growing number of GPUs.\n\nTherefore, all empirical results for parallel Hyperband reported in the paper appear to be negative. This confuses me, especially since the authors seem to take them as positive results. \nBecause the original Hyperband paper argued that Bayesian optimization does not parallelize as well as random search / Hyperband, and because Hyperband has been reported to work much better than Bayesian optimization on a single node, I would have expected clear improvements of parallel Hyperband over parallel Bayesian optimization (=Vizier in the authors\' setup). However, this is not what I see in the results. Am I mistaken somewhere? If not, based on these negative results the paper does not seem to quite clear the bar for ICLR.\n\n\nDetails, in order of appearance in the paper:\n\n- Vizier: why did the authors only use Vizier\'s default Bayesian optimization algorithm? The Vizier paper by Golovin et al (2017) states that for large budgets other optimizers often perform better, and the budget in the large scale experiments is as high as 5000 function evaluations. Also, isn\'t there an automatic choice built into Vizier to pick the optimizer expected to be best? I think using a suboptimal version of Vizier would be a problem for the experimental setup.\n- Algorithm 1: this needs some improvement; in particular fixing the bug I mentioned above.\n- Section 3.1: Li et al (2017) do not analyze any algorithm theoretically. They also do not discuss finite vs. infinite horizon. I believe the authors meant Li et al\'s arXiv paper (2016) in both of these cases.\n- Section 3.1, point 2: this is unclear to me, even though I know Hyperband very well. Can you please make this clearer?\n- ""A complete theoretical treatment of asynchronous SHA is out of the scope of this paper"" -> is some theoretical treatment in scope?\n- Section 4.1: It seems very useful to already recommend configurations in each rung of Hyperband, and I am surprised that the methods section does not mention this. From the text in this experiments section, it feels a little like that was always part of Hyperband; I didn\'t think it was, so I checked the original papers and blog posts, and both the ICLR 2017 and the arXiv 2016 paper state ""In fact, the first result returned by HYPERBAND after using a budget of 5R is often competitive with results returned by other searchers after using 50R."" and Kevin Jamieson\'s blog post on Hyperband (https://people.eecs.berkeley.edu/~kjamieson/hyperband.html) explicitly states: ""While random and the Bayesian Optimization algorithms output their first recommendation after max_iter iterations, Hyperband does not output anything until about max_iter(logeta(max_iter)+1) iterations [...]""\nTherefore, recommending after each rung seems to be a contribution of this paper, and I think it would be nice to read about this in the methods section. \n- Experiment 1 (SVM) used dataset size as a budget, which is what Fabolas (""Fast Bayesian optimization on large datasets"") is designed for according to Klein et al (2017). On the other hand, Experiments (2) and (3) used the number of epochs as a budget, and Fabolas is not designed for that (one would want to use a different kernel, for epochs, e.g., like Freeze-Thaw Bayesian optimization (FTBO) by Swersky et al (2014), instead of a kernel made for dataset sizes). Therefore, it is not surprising that Fabolas does not work as well in those cases. The case of number of epochs as a budget would be the domain of FTBO. I know that there is no reference implementation of FTBO, so I am not asking for a comparison, but the comparison against Fabolas is misleading for Experiments (2) and (3). This doesn\'t really change anything for the paper: the authors could still make the case that Fabolas hasn\'t been designed for this case and that (to the best of my knowledge) there simply isn\'t an implementation of a BO algorithm that is. Fabolas is arguably the closest thing, so the results could still be reported, just not as an apples-to-apples comparison; probably best as ""Fabolas-like, with dataset size kernel"" in the figure. The justification to not compare against Fabolas in the parallel regime is clearly valid.\n- A clarification question: Section 4.4 does not report on any runs of actual neural networks, does it? And not on any runs of Hyperband, correct? Do I understand the reasoning correctly as pointing out that standard parallelization across multiple GPUs is not great, and that thus, in combination with parallel Hyperband, runs should be done mostly on one GPU only? How does this relate to the results in the cited paper ""Accurate, Large-batch SGD: Training ImageNet in 1 Hour"" (https://arxiv.org/abs/1706.02677)? Quoting from its abstract: ""Using commodity hardware, our implementation achieves ∼ 90% scaling efficiency when moving from 8 to 256 GPUs."" That seems like a very good utilization of parallel computing power?\n- There is no conclusion / future work.\n\n----------\nEdit after author rebuttal:\nI thank the reviewers for their rebuttal. This cleared up some points, but some others are still open.\n(1) and (2) Unfortunately, I still do not agree that the need for 5*25 workers to get a 5-fold to 8-fold speedup is a positive result. Similarly, I would interpret the results in Figure 3 differently than the authors. For the comparison against Vizier the authors argue that they could just take the lowest 2 brackets of Hyperband; but running both of these two would still be 2x slower than Vizier. And we can\'t only run the best bracket because the information which one is the best is not available ahead of time. In fact, it is the entire point of Hyperband to hedge across multiple brackets including the one that is random search; one *could* just use the smallest bracket, but that is a heuristic and has no theoretical guarantees of being better (or at least not worse by more than a bounded factor) than random search. \nOrthogonally: the comparison to Vizier (or any other baseline) is still missing for the LSTM acoustic model.\n\n(3) Concerning SOTA results, I have to agree with AnonReviewer3: one way to demonstrate success is to show competitive performance on a dataset (e.g., CIFAR) on which other researchers can also evaluate their algorithms on. Getting 17% on CIFAR-10 does not fall into that category. Nevertheless, I agree with the authors that another way to demonstrate success is to show competitive performance on a *combination* of a dataset and a design space, but for that to be something that other researchers can compare to requires the authors making publicly available the implementations they have optimized; without that public availability, due to a host of possible confounding factors, it is impossible to judge whether state-of-the-art performance on such a combination of dataset and design space has been achieved.  I therefore recommend that the authors make the entire code they used for training CIFAR available; I don\'t expect this to have anything new in there, but it\'s a useful benchmark.\nLikewise, for the LSTM on PTB, DeepMind used Google Vizier (https://arxiv.org/abs/1707.05589) to achieve *perplexities below 60* (compared to the results above 80 reported by the authors). Just as above, I therefore recommend that the authors make their pipeline for LSTB on PTB available. Likewise for the LSTM acoustic model.\n\n(4) I\'m confused that Section 4.4 does relate to SHA/Hyperband. Of course, there are some diminishing returns of running an optimizer across multiple GPUs. But similarly, there are diminishing returns of parallelizing SHA (e.g., the 5-fold speedup on 125 workers above). So the natural question that would be nice to answer is which combination of the two will yield the best results. Relatedly, the paper by Goyal et al seems to show that the weak scaling regime leads to almost linear speedups; why do the authors then analyze the strong scaling regime that does not appear to work as well?\n\nOverall, the rebuttal did not change my evaluation and I kept my original score.', 'In this paper, the authors extend Hyperband--a recently proposed non model based hyperparameter tuning procedure--to better support parallel evaluation. Briefly, Hyperband builds on a ""successive halving"" algorithm. This algorithm allocates a budget of B total time to N configurations, trains for as long as possible until the budget is reached, and then recurses on the best N/2 configurations--called the next ""rung"" in the paper. Thus, as optimization proceeds, more promising configurations are allowed more time to train. This basic algorithm has the problem that different optimization tasks may require different amounts of time to become distinguishable; Hyperband solves this by running multiple rounds of succesive halving--called ""brackets""--varying the initial conditions. That is, should successive halving start with more initial configurations (but therefore less budget for each configuration), or a small number of configurations. The authors further extend Hyperband by allowing the successive halving algorithm to be run in parallel. To accomplish this, when a worker looks for a job it prefers to run jobs on the next available rung; if none are currently outstanding, a new job is started on the lowest rung.\n\nOverall, I think this is a natural scheme for parallelzing Hyperband. It is extremely simple (a good thing), and neatly circumvents the obvious problem with parallelizing Hyperband, which is that successive halving naturally limits the number of jobs that can be done. I think the non-model based approach to hyperparameter tuning is compelling and is of interest to the AutoML community, as it raises an obvious question of how approaches that exploit the fact that training can be stopped any time (like Hyperband) can be combined with model-based optimization that attempt to avoid evaluating configurations that are likely to be bad.\n\nHowever, I do have a few comments and concerns for the for the authors to address that I detail below. I will be more than happy to modify my evaluation if these concerns are addressed by the authors.\n\nFirst and most importantly, can the authors discuss the final results achieved by their hyperparameter optimization compared to state-of-the-art results in the field? I am not sure what SOTA is on the Penn Treebank  or acoustic modeling task, but obviously the small ConvNet getting 20% error on CIFAR10 is not state of the art. Do the authors think that their technique could improve SOTA on CIFAR10 or CIFAR100 if applied to a modern CNN architecture like a ResNet or DenseNet? \n\nObviously these models take a bit longer to train, but with the ability to train a large number of models in parallel, a week or two should be sufficient to finish a nontrivial number of iterations. The concern that I have is that we continue to see these hyperparameter tuning papers that discuss how important the task is, but--to the best of my knowledge--the last paper to actually improve SOTA using automated hyperparameter tuning was Snoek et al., 2012., and there they even achieved 9.5% error with data augmentation. Are hyperparameters just too well tuned on these tasks by humans, and the idea is that Hyperband will be better on new tasks where humans haven\'t been working on them for years? In BayesOpt papers, hyperparameter tuning has often been used simply as a task to compare optimization performance, but I don\'t think this argument applies to Hyperband because it isn\'t really applicable to blackbox functions outside of hyperparameter tuning because it explicitly relies on the fact that training can be cut short at any time.\n\nSecond (and this is more of a minor point), I am a little baffled by Figure 4. Not by the argument you are trying to make--it of course makes sense to me that additional GPUs would result in diminishing returns as you become unable to fully exploit the parallelism--but rather the plots themselves. To explain my confusion, consider the 8 days curve in the AlexNet figure. I read this as saying, with 1 GPU per model, in 8 days, I can consider 128 models (the first asterisk). With 2 GPUs per model, in 8 days, I can consider slightly less than 128 models (the second asterisk). By the time I am using 8 GPUs per model, in 8 days, I can only train a bit under 64 models (the fourth asterisk). The fact that these curves are monotonically decreasing suggests that I am just reading the plot wrong somehow -- surely going from 1 GPU per model to 2 should improve performance somewhere? Additionally, shouldn\'t the dashed lines be increasing, not horizontal (i.e., assuming perfect parallelism, if you increase the number of GPUs per model--the x axis--the number of models I can train in 8 days--the y axis--increases)?']","[80, -70, 50]","[60, 20, 75]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They describe it as a 'practical improvement' and praise its crisp writing, natural extension, and appropriate experimental protocols. The only minor criticism is about a blurry figure panel. The politeness score is 60 (moderately polite) because the reviewer uses respectful and professional language throughout, acknowledging the paper's strengths without being overly effusive. They offer constructive feedback on the figure quality in a neutral tone. The language is consistently positive and supportive, but maintains a professional distance typical of academic reviews."", ""The sentiment score is -70 because the reviewer expresses significant concerns about the paper's contributions and results, describing them as 'negative results' multiple times. They state the paper 'does not seem to quite clear the bar for ICLR' and point out several issues with methodology and interpretation of results. However, it's not entirely negative as they acknowledge some positive aspects like addressing an important problem. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'I am confused' and 'Can you please make this clearer?' rather than harsh language. They also thank the authors for their rebuttal and acknowledge when points were clarified. The reviewer provides detailed feedback and suggestions for improvement, which is constructive and polite, even if the overall assessment is negative."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses overall approval of the paper's approach, calling it 'natural' and 'compelling', but also raises significant concerns and requests for clarification. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions or questions rather than direct attacks. Phrases like 'I think this is a natural scheme', 'I will be more than happy to modify my evaluation', and 'can the authors discuss' contribute to the polite tone. The reviewer also balances critique with praise and expresses willingness to reconsider their evaluation based on the authors' response.""]"
"['The authors propose a new exploration algorithm for Deep RL. They maintain an ensemble of Q-values (based on different initialisations) to model uncertainty over Q. The ensemble is then used to derive a confidence interval at each step, which is used to select actions UCB-style.\n\nThere is some attempt at a Bayesian interpretation for the Bellman update. But to me it feels a bit like shoehorning the probabilistic interpretation into an already existing update - I’m not sure this is justified and necessary here. Moreover, the UCB strategy is generally not considered a Bayesian strategy, so I wasn’t convinced by the link to Bayesian RL in this paper.\n\nI liked the actual proposed method otherwise, and the experimental results on Atari seem good (but see also latest SOTA Atari results, for example the Rainbow paper). Some questions about the results:\n-How does it perform compared to epsilon-greedy added on top of Alg1, or is there evidence that this produces any meaningful exploration versus noise? \n-How does the distribution of Q values look like during different phases of learning?\n-Was epsilon-greedy used in addition to UCB exploration? Question for both Alg 1 and Alg 2.\n-What’s different between Alg 1 and bootstrapped DQN (other than the action selection)?\n\nMinor things:\n-Missing propto in Eq 7?\n-Maybe mention that the leftarrows are not hard updates. Maybe you already do somewhere…\n-it looks more a Bellman residual update as written in (11).\n', 'This paper introduces a number of different techniques for improving exploration in deep Q learning. The main technique is to use UCB (upper confidence bound) to speedup exploration. The authors also introduces ""Ensemble voting"" facilitate exploitation.\n\nThis paper shows improvement over baselines. But does not seem to offer significant insight or dramatic improvement. The techniques introduced are a small permutation of previous results. The baselines are not particularly strong either.\n\nThe paper appeared to have be rushed. The presentation is not always clear.\n\nI also have the following questions I hope the authors could help me with:\n\n1. I failed to understand how Eqn (5). Could you please clarify.\n\n2. What is the significance of the math introduced in section 3? All that was proposed was: (1) Majority voting, (2) UCB exploration.\n\n3. Why comparing to A3C+ which is not necessarily better than A3C in final performance?\n\n4. Why not comparing to Bootstrapped DQN since the proposed method is based on it?\n\n5. Why is the proposed method better than Bootstrapped DQN, since UCB does not necessarily outperform Thompson sampling in the case of bandits?\n\n6. If there is a section on INFOGAIN exploration, why not mention it in the main text?', 'This paper paper uses an ensemble of networks to represent the uncertainty in deep reinforcement learning.\nThe algorithm then chooses optimistically over the distribution induced by the ensemble.\nThis leads to improved learning / exploration, notably better than the similar approach bootstrapped DQN.\n\nThere are several things to like about this paper:\n- It is a clear paper, with a simple message and experiments that back up the claims.\n- The proposed algorithm is simple and could be practical in a lot of settings and even non-DQN variants.\n- It is interesting that Bootstrapped DQN gets such poor performance, this suggests that it is very important in the original paper https://arxiv.org/abs/1602.04621 that ""ensemble voting"" is applied to the test evaluation... (why do you think this is by the way, do you think it has something to do with the data being *more* off-policy / diverse under a TS vs UCB scheme?)\n\nOn the other hand:\n- The novelty/scope of this work is somewhat limited... this is more likely (valuable) incremental work than a game-changer.\n- Something feels wrong/hacky/incomplete about just doing ""ensemble"" for uncertainty without bootstrapping/randomization... if we had access to more powerful optimization techniques then this certainly wouldn\'t be sensible - I think that you should mention that you are heavily reliant on ""random initialization + SGD/Adam + specific network architecture"" to maintain this idea of uncertainty. For example, this wouldn\'t work for linear value functions!\n- I think the original bootstrapped DQN used ""ensemble voting"" at test time, so maybe you should change the labels or the way this is introduced/discussed. It\'s definitely very interesting that *essentially* the learning benefit is coming from ensembling (rather than ""raw"" bootstrapped DQN) and UCB still looks like it does better.\n- I\'m not convinced that page 4 and the ""Bayesian"" derivation really add too much value to this paper... alternatively, maybe you could introduce the actual algorithm first (train K models in parallel) and then say ""this is similar to particle filter"" and add the mathematical derivation after, rather than as if it was some complex formula derived. If you want to reference some justification/theory for ensemble-based uncertainty approximation you might consider https://arxiv.org/pdf/1705.07347.pdf instead.\n- I think this paper might miss the point of the ""bigger"" problem of efficient exploration in RL... or even how to get ""deep"" exploration with deep RL. Yes this algorithm sees improvements across Atari, but it\'s not clear why/if this is a step change versus simply increasing the amount of replay or tuning the learning rate.  (Actually I do believe this algorithm can demonstrate deep exploration... but it looks like we\'re not seeing the big improvements on the ""sub-human"" games you might hope.)\n\nOverall I do think this is a pretty good short paper/evaluation of UCB-ensembles on Atari.\nThe scope/insight of the paper isn\'t groundbreaking, but I think it delivers a clear short message on the Atari benchmark.\nPerhaps this will encourage people to dig deeper into some of these issues... I vote accept.\n']","[50, -40, 60]","[75, 20, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses some positive aspects ('I liked the actual proposed method', 'experimental results on Atari seem good') while also raising concerns and questions. The overall tone is balanced, leaning slightly positive. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, phrases criticisms constructively ('I wasn't convinced', 'Some questions about the results'), and offers specific suggestions for improvement. The reviewer maintains a professional and courteous tone, even when expressing doubts or requesting clarifications."", ""The sentiment score is -40 because the review is generally negative, pointing out that the paper doesn't offer significant insight or dramatic improvement, uses weak baselines, and appears rushed. However, it's not entirely negative as it acknowledges some improvement over baselines. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone and use phrases like 'I hope the authors could help me with' and 'Could you please clarify,' which are polite. The reviewer also frames their points as questions rather than outright criticisms in many cases, which is a more polite approach. However, some statements are quite blunt, preventing a higher politeness score."", ""The sentiment score is 60 (positive) because the reviewer expresses several positive aspects of the paper, such as its clarity, simplicity, and potential practical applications. They vote to accept the paper and describe it as 'pretty good'. However, they also point out limitations and areas for improvement, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, balancing praise with constructive criticism. They phrase their concerns as suggestions or questions rather than harsh criticisms. The use of phrases like 'There are several things to like about this paper' and 'I think' when offering critiques contributes to the polite tone.""]"
"['This paper presents an impressive set of results on predicting lung pathologies from chest x-ray images. \nAuthors present two architectures: one based on denseNet, and one based on denseNet + LSTM on output dimensions (i.e. similar to NADE model), and compare it to state of the art on the chest x-ray classification. Experiments are clearly described and results are significantly better compared to state of the art.\n\nThe only issue with this paper is, that their proposed method, in practice is not tractable for inference on estimating probability of a single output, a task which would be critical in medical domain. Considering that their paper is titled as a work to use ""dependencies"" among labels, not being able to evaluate their network\'s, and lack of interpretable evaluation results on this model in the experiment section is a major limitation. \n\nOn the other hand, there are many alternative models where one could simply use multi-task learning and shared parameter, to predict multiple outcomes extremely efficiently. To be able to claim that this paper improved the prediction by better modeling of \'dependencies\' among labels, I would need to see how the (much simpler) multi-task setting works as well. \n\nThat said, the paper has several positive aspects in all areas:\n\nOriginality - the paper presents first combination of DenseNets with LSTM-based output factorization,\nWriting clarity - the paper is very well written and clear.\nQuality - (apart from the missing multi-task baseline), the results are significantly better than state of the art, and experiments are well done,\nSignificance - Apart from the issue of intractable inference which is arguably a large limitation of this work, the application in medical field is significant. \n\n', ""The paper proposes to combine the recently proposed DenseNet architecture with LSTMs to tackle the problem of predicting different pathologic patterns from chest x-rays. In particular, the use of LSTMs helps take into account interdependencies between pattern labels. \n\nStrengths:\n- The paper is very well written. Contextualization with respect to previous work is adequate. Explanations are clear. Novelties are clearly identified by the authors.\n- Quantitative improvement with respect to the state the art. \n\nWeaknesses:\n- The paper does not introduce strong technical novelties -- mostly, it seems to apply previous techniques to the medical domain. It could have been interesting to know if there are more insights / lessons learned in this process. This could be of interest for a broader audience. For instance, what are the implications of using higher-resolution images as input to DenseNet / decreasing the number of layers? How do the features learned at different layers compare to the ones of the original network trained for image classification? How do features of networks pre-trained on ImageNet, and then fine-tuned for the medical domain, compare to features learned from medical images from scratch? \n- The impact of the proposed approach on medical diagnostics is unclear. The authors could better discuss how the approach could be adopted in practice. Also, it could be interesting also to discuss how the results in Table 2 and 3 compare to human classification capabilities, and if that performance would be already enough for building a computer-aided diagnosis system.\n\nFinally -- is it expected that the ordering of the factorization in Eq. 3 does not count much (results in Table 3)? As a non-expert in the field, I'd expect that ordering between pathologic patterns matters more."", 'Well written and appropriately structured. Well within the remit of the conference.\nNot much technical novelty to be found, but the original contributions are adequately identified and they are interesting on their own.\n\nMy main concern (and complaint) is not technical, but application-based. This study is (unfortunately) typical in that it focuses on and provides detail of the technical modeling issues, but ignores the medical applicability of the model and results. This is exemplified by the fact that the data set is hardly described at all and the 14 abnormalities/pathologies, the rationale behind their choice and the possible interrelations and dependencies are never described from a medical viewpoint. If I were a medical expert, I would not have a clue about how these results and models could be applied in practice, or about what medical insight I could achieve.\n\nThe bottom line seems to be: ""my model and approach works better than the other guys\' model and approach"", but one is left with the impression that these experiments could have been made with other data, other problems, other fields of application and they would not have not changed much ']","[50, 50, -20]","[75, 80, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges several positive aspects of the paper, including 'impressive results', 'clearly described experiments', and 'significantly better' performance compared to state of the art. However, they also point out a major limitation regarding the intractability of inference for single output probability estimation. The overall tone is balanced, recognizing both strengths and weaknesses.\n\nThe politeness score is 75 (quite polite) because the reviewer uses respectful and professional language throughout. They begin with positive comments, use phrases like 'the only issue' to soften criticism, and acknowledge multiple positive aspects in detail at the end. The critique is presented constructively without harsh or dismissive language. The reviewer maintains a collegial tone while providing both praise and suggestions for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges both strengths and weaknesses of the paper. They praise the writing quality and quantitative improvements, but also point out lack of strong technical novelties and unclear practical impact. The overall tone is constructive rather than overly critical or enthusiastic. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as suggestions for improvement rather than harsh judgments, and acknowledges the paper's positive aspects before discussing weaknesses. The reviewer also uses phrases like 'it could have been interesting' and 'it could be interesting' when suggesting additions, which is a polite way of offering constructive feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is well-written and structured, they express significant concerns about the lack of medical applicability and detail on the dataset. The phrase 'My main concern (and complaint)' indicates a negative sentiment, as does the criticism that the study 'ignores the medical applicability of the model and results.' The politeness score is moderately positive (50) as the reviewer uses professional language throughout and begins with positive comments. They express their concerns in a constructive manner, avoiding harsh or rude language. The use of phrases like 'Well written' and 'interesting on their own' contribute to the polite tone, even when expressing criticisms.""]"
"['The authors propose a procedure to generate an ensemble of sparse structured models. To do this, the authors propose to (1) sample models using SG-MCMC with group sparse prior, (2) prune hidden units with small weights, (3) and retrain weights by optimizing each pruned model. The ensemble is applied to MNIST classification and language modelling on PTB dataset. \n\nI have two major concerns on the paper. First, the proposed procedure is quite empirically designed. So, it is difficult to understand why it works well in some problems. Particularly. the justification on the retraining phase is weak. It seems more like to use SG-MCMC to *initialize* models which will then be *optimized* to find MAP with the sparse-model constraints. The second problem is about the baselines in the MNIST experiments. The FNN-300-100 model without dropout, batch-norm, etc. seems unreasonably weak baseline. So, the results on Table 1 on this small network is not much informative practically. Lastly, I also found a significant effort is also desired to improve the writing. \n\nThe following reference also needs to be discussed in the context of using SG-MCMC in RNN.\n- ""Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling"", Zhe Gan*, Chunyuan Li*, Changyou Chen, Yunchen Pu, Qinliang Su, Lawrence Carin', 'In this paper, the authors present a new framework for training ensemble of neural networks. The approach is based on the recent scalable MCMC methods, namely the stochastic gradient Langevin dynamics.\n\nThe paper is overall well-written and ideas are clear. The main contributions of the paper, namely using SG-MCMC methods within deep learning, and then increasing the computational efficiency by group sparsity+pruning are valuable and can have a significant impact in the domain. Besides, the proposed approach is more elegant the competing ones, while still not being theoretically justified completely. \n\nI have the following minor comments:\n\n1) The authors mention that retraining significantly improves the performance, even without pruning. What is the explanation for this? If there is no pruning, I would expect that all the samples would converge to the same minimum after retraining. Therefore, the reason why retraining improves the performance in all cases is not clear to me.\n\n2) The notation |\\theta_g| is confusing, the authors should use a different symbol.\n\n3) After section 4, the language becomes quite informal sometimes, the authors should check the sentences once again.\n\n4) The results with SGD (1 model) + GSP + PR should be added in order to have a better understanding of the improvements provided by the ensemble networks. \n\n5) Why does the performance get worse ""obviously"" when the pruning is 95% and why is it not obvious when the pruning is 90%?\n\n6) There are several typos\n\npg7: drew -> drawn\npg7: detail -> detailed\npg7: changing -> challenging\npg9: is strongly depend on -> depends on\npg9: two curve -> two curves', 'The authors note that several recent papers have shown that bayesian model averaging is an effective and universal way to improve hold-out performance, but unfortunately are limited by increased computational costs.   Towards that end, the authors of this manuscript propose several modifications to this procedure to make it computationally feasible and indeed improve performance.\n\nPros:\nThe authors demonstrate an effective procedure for FNN and LSTMs that makes model averaging improve performance.\nEmpirical evidence is convincing on the utility of the approach.\n\nCons:\nNot clear how this approach would be used with convolutional structures\nMuch of the benefit appears to come from the sparse prior, pruning, and retraining (Figure 3).  The model averaging seems to have a smaller contribution.  Due to that, it seems that the nature of the contribution needs to be clarified compared to the large literature on sparsifying neural networks, and the introductory comments of the paper should be rewritten to reflect that reality.']","[-50, 70, 50]","[20, 80, 75]","[""The sentiment score is -50 because the reviewer expresses 'two major concerns' about the paper, indicating a generally negative view. They criticize the procedure as 'empirically designed' and difficult to understand, and find the baselines 'unreasonably weak'. However, it's not entirely negative as they do acknowledge some positive aspects ('works well in some problems'). The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and constructive manner. They use phrases like 'I have two major concerns' and 'it is difficult to understand' rather than using harsh or rude language. They also provide specific suggestions for improvement, such as discussing an additional reference, which is helpful and polite. The language is generally neutral and academic in tone, avoiding personal attacks or overly negative phrasing."", ""The sentiment score is 70 (positive) because the reviewer states that the paper is 'overall well-written' and the ideas are 'clear'. They also mention that the main contributions are 'valuable' and can have a 'significant impact'. The approach is described as 'more elegant' than competing ones. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering 'minor comments' rather than criticisms. They provide constructive feedback and suggestions for improvement without using harsh or negative language. The reviewer also acknowledges the potential impact and value of the work. The presence of a few typos is mentioned politely at the end, without making it a major issue."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the effectiveness of the proposed procedure and the convincing empirical evidence, which are noted as 'Pros'. However, the 'Cons' section raises some concerns about the applicability to convolutional structures and the need for clarification on the paper's contribution. This balanced view suggests a moderately positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful and professional language throughout. They acknowledge the authors' work positively and frame criticisms constructively as areas for improvement rather than outright flaws. The use of phrases like 'The authors demonstrate' and 'Empirical evidence is convincing' shows respect for the authors' efforts, while suggestions for improvement are phrased diplomatically, such as 'it seems that the nature of the contribution needs to be clarified'.""]"
"['Thanks to the authors for their response.\n\nThough the paper presents an interesting approach, but it relies heavily on heuristics (such as those mentioned in the initial review) without a thorough investigation of scenarios in which this might not work. Also, it might be helpful to investigate if there ways to better group the variables for group  lasso regularization. The paper therefore needs further improvements towards following a more principled approach.\n\n=====================================\nThis paper presents methods for inducing sparsity in terms of blocks of weights in neural networks which aims to combine benefits of sparsity and faster access based on computing architectures. This is achieved by pruning blocks of weights and group lasso regularization. It is demonstrated empirically that model size can be reduced by upto 10 times with some loss in prediction accuracy.\n\nThough the paper presents some interesting evaluations on the impact of block based sparsity in RNNs, some of the shortcomings of the paper seem to be :\n\n- The approach taken consists of several heuristics rather than following a more principled approach such as taking the maximum of the weights in a block to represent that block and stop pruning till 40% training has been achieved. Also, the algorithm for computing the pruning threshold is based on a new set of hyper-parameters. It is not clear under what conditions the above settings will (not) work.\n\n - For the group lasso method, since there are many ways to group the variable, it is not clear how the variables are grouped. Is there a reasoning behind a particular grouping of the variables. Individually, group lasso does not seem to work, and gives much worse results. The reasons for worse performance could be investigated. It is possible that important weights are in different groups, and group sparsity is forcing some of them to be zero, and hence leading to worse results. It would be insightful to explain the kind of solver used for group lasso regularization, and if that works for large-scale problems.\n\n - The results for various kinds of sparsity are unclear in the sense that it is not clear how to set the block size a-priori for having minimum reduction in accuracy and still significant sparsity without having to repeat the process for various choices.\n\nOverall, the paper does not seem to present novel ideas, and is mainly focused on evaluating the impact of block-based sparsity instead of weight pruning by Han etal. As mentioned in Section 2, regularization has been used earlier to achieve sparsity in deep networks. In this view the significance over existing work is relatively narrow, and no explicit comparison with existing methods is provided. It is possible that an existing method leads to pruning method such as by Han etal. leads to 8x decrease in model size while retaining the accuracy, while the proposed method leads to 10x decrease while also decreasing the accuracy by 10%. Scenarios like these need to be evaluated to understand the impact of the method proposed in this paper.', 'Compressing/pruning of neural networks is required to enable running on devices with limited compute resources. While previous works have proposed to 0 out weights, especially for the case of RNNs, in an unstructured way, the current paper proposes to 0 out weights blocks at a time via thresholding. The process is further aided by utilizing group lasso regularization. The resulting networks are sparse, memory efficient and can be run more efficiently while resulting in minimal loss in accuracy when compared to networks learned with full density. The proposed techniques are evaluated on RNNs for speech recognition and benefits clearly spelled out. Further experiments thresh out how much benefit is provided by thresholding (block sparsity) and regularizing via group lasso.\n\nThe paper quality seems high, presentation clarity sufficient, the ideas presented (especially the use of group lasso) well thought out and original, and the work seems significant. If I were to nitpick then I would suggest trying out these techniques on RNNs meant for something other than speech recognition (machine translation perhaps?).', 'The authors propose a block sparsity pruning approach to compress RNNs. There are several ways. One is using  group LASSO to promote sparsity. The other is to prune, but with a very specialized schedule as to the pruning and pruning weight, motivated by the work of Narang et al 2017 for non-group sparsity.  The block sizes used in experiments are about 4x4, 8x8, up to 32 x 32. The relative performance degradation ranges between 10% to 96%, depending on the method, severity of compression, and task. The speedup for a matrix multiply is between 1.5x to 4x, and varies according to batch size.\n\nThis is certainly a well-motivated problem, and the procedure is simple but makes sense. Also, the paper contains a good overview of related work in compression, and is not hiding anything.  One paper that is missing is\n\nScardapane, S., Comminiello, D., Hussain, A., & Uncini, A. (2017). Group sparse regularization for deep neural networks. Neurocomputing, 241, 81-89.\n\nA major complaint is the lack of comparison of results against other compression techniques. Since it is a block sparsity approach, and the caching / fetching overhead is reduced, one does not need to have competitively superior results to basic pruning approaches, but one should come close on the same types of problems. This is not well presented. Additionally, the speedup should be superior to the sparse methods, which is also not shown (against previously published results, not personally run experiments.) \n\nAnother issue I find is the general writing, especially for the results section, is not entirely clear. For example, when showing a relative performance degradation of 96%, why is that happening? Is that significant? What should an implementer be aware of in order to avoid that? \n\nFinally, a meta issue to address is, if the block size is small (realistically, less than 64 x 64) usually I doubt there will be significant speedup. (4x is not considered terribly significant.) What we need to see is what happens when, say, block size is 256 x 256? What is the performance degradation? If you can give 10x speedup in the feedforward part (testing only) then if you have a 10% degradation in performance that might be acceptable in certain applications. \n\nOverall, I believe this is a very promising and well-motivated work, but needs to be ""marinated"" further to be publishable. Actually, with the inclusion of 2-3 tables against known, previously published results, and clearly stated benefits, I would change my review to accept. \n\nMinor complaints:\n\nThe axis labels/numbers in figure 2 are too small. \n\nAlso, please reread for some grammar / writing issues (last paragraph of 1st page, caption of figure 2, for example)\n\nI think also figure 2 should be rerun with more trials. The noise in the curves are not showing a highly interpretable trend. (Though, actually, batch size = 8 being super low might have a significance; can this be explained?)\n\n']","[-50, 90, -20]","[20, 70, 50]","[""The sentiment score is -50 because the review expresses several criticisms and shortcomings of the paper, suggesting that 'further improvements' are needed and that the paper 'does not seem to present novel ideas'. However, it's not entirely negative as it acknowledges the paper presents 'an interesting approach' and 'some interesting evaluations'. The politeness score is 20 because the reviewer uses polite language such as 'Thanks to the authors for their response' and phrases criticisms constructively, like 'it might be helpful to investigate'. The tone is professional and not overtly rude, but also not excessively polite, maintaining a neutral to slightly positive politeness level throughout."", ""The sentiment score is 90 (highly positive) because the reviewer expresses a very favorable opinion of the paper. They describe the paper quality as 'high', the presentation as 'sufficient', the ideas as 'well thought out and original', and the work as 'significant'. The only minor criticism is presented as a 'nitpick', suggesting overall strong approval. The politeness score is 70 (quite polite) because the reviewer uses respectful and professional language throughout. They offer praise without being overly effusive, and present their suggestion for improvement in a gentle way ('If I were to nitpick...'). The tone is constructive and supportive, maintaining a polite and collegial atmosphere typical of academic peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'well-motivated' and 'promising', they also express several major concerns and state that the paper needs to be 'marinated further to be publishable'. The reviewer points out significant issues such as lack of comparison with other techniques, unclear writing in the results section, and the need for more comprehensive experiments with larger block sizes. However, the reviewer also suggests that with some additions, they would change their review to accept, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They balance criticism with positive remarks, use phrases like 'please reread' for minor issues, and offer specific suggestions for improvement. The language is not overly formal or deferential, but it remains respectful and helpful, avoiding any harsh or rude expressions.""]"
"['The authors propose a new CNN approach to graph classification that generalizes previous work. Instead of considering the direct neighborhood of a vertex in the convolution step, a filter based on outgoing walks of increasing length is proposed. This incorporates information from more distant vertices in one propagation step.\n\nThe proposed idea is not exceptional original, but the paper has several strong points:\n\n* The relation to previous work is made explicit and it is show that several previous approaches are generalized by the proposed one.\n* The paper is clearly written and well illustrated by figures and examples. The paper is easy to follow although it is on an adequate technical level.\n* The relation between the vertex and spectrum domain is well elaborated and nice (although neither important for understanding nor implementing the approach).\n* The experimental evaluation appears to be sound. A moderate improvement compared to other approaches is observed for all data sets.\n\nIn summary, I think the paper can be accepted for ICLR.\n----------- EDIT -----------\nAfter reading the publications mentioned by the other reviewers as well as the following related contributions\n\n* Network of Graph Convolutional Networks Trained on Random Walks (under review for ICLR 2018)\n* Graph Convolution: A High-Order and Adaptive Approach, Zhenpeng Zhou, Xiaocheng Li (arXiv:1706.09916)\n\nI agree that the relation to previous work is not adequately outlined. Therefore I have modified my rating accordingly.', 'The paper introduces Topology Adaptive GCN (TAGCN) to generalize convolutional\nnetworks to graph-structured data.\nI find the paper interesting but not very clearly written in some sections,\nfor instance I would better explain what is the main contribution and devote\nsome more text to the motivation. Why is the proposed approach better than the\npreviously published ones, and when is that there is an advantage in using it?\n\nThe main contribution seems to be the use of the ""graph shift"" operator from\nSandryhaila and Moura (2013), which closely resembles the one from\nShuman et al. (2013). It is actually not very well explained what is the main\ndifference.\n\nEquation (2) shows that the learnable filters g are operating on the k-th power\nof the normalized adjacency matrix A, so when K=1 this equals classical GCN\nfrom T. Kipf et al.\nBy using K > 1 the method is able to leverage information at a farther distance\nfrom the reference node.\n\nSection 2.2 requires some polishing as I found hard to follow the main story\nthe authors wanted to tell. The definition of the weight of a path seems\ndisconnected from the main text, ins\'t A^k kind of a a diffusion operator or\nrandom walk?\nThis makes me wonder what would be the performance of GCN when the k-th power\nof the adjacency is used.\n\nI liked Section 3, however while it is true that all methods differ in the way they\ndo the filtering, they also differ in the way the input graph is represented\n(use of the adjacency or not).\n\nExperiments are performed on the usual reference benchmarks for the task and show\nsensible improvements with respect to the state-of-the-art. TAGCN with K=2 has\ntwice the number of parameters of GCN, which makes the comparison not entirely\nfair. Did the author experiment with a comparable architecture?\nAlso, how about using A^2 in GCN or making two GCN and concatenate them in\nfeature space to make the representational power comparable?\n\nIt is also known that these benchmarks, while being widely used, are small and\nresult in high variance results. The authors should report statistics over\nmultiple runs.\nGiven the systematic parameter search, with reference to the actual validation\n(or test?) set I am afraid there could be some overfitting. It is quite easy\nto probe the test set to get best performance on these benchmarks.\n\nAs a minor remark, please make figures readable also in BW.\n\nOverall I found the paper interesting but also not very clear at pointing out\nthe major contribution and the motivation behind it. At risk of being too reductionist:\nit looks as learning a set of filters on different coordinate systems given\nby the various powers of A. GCN looks at the nearest neighbors and the paper\nshows that using also the 2-ring improves performance.\n', 'In this paper a new neural network architecture for semi-supervised graph classification is proposed. The new construction builds upon graph polynomial filters and utilizes them on each successive layer of the neural network with ReLU activation functions.\n\nIn my opinion writing of this paper requires major revision. The first 8 pages mostly constitute a literature review and experimental section provides no insights about the performance of the TAGCN besides the slight improvement of the Cora, Pubmed and Citeseer benchmarks.\n\nThe one layer analysis in sections 2.1, 2.2 and 2.3 is simply an explanation of graph polynomial filters, which were previously proposed and analyzed in cited work of Sandryhaila and Moura (2013). Together with the summary of other methods and introduction, it composes the first 8 pages of the paper. I think that the graph polynomial filters can be summarized in much more succinct way and details deferred to the appendix for interested reader. I also recommend stating which ideas came from the Sandryhaila and Moura (2013) work in a more pronounced manner.\n\nNext, I disagree with the statement that ""it is not clear how to keep the vertex local property when filtering in the spectrum domain"". Graph Laplacian preserves the information about connectivity of the vertices and filtering in the vertex domain can be done via polynomial filters in the Fourier domain. See Eq. 18 and 19 in [1].\n\nFinally, I should say that TAGCN idea is interesting. I think it can be viewed as an extension of the GCN (Kipf and Welling, 2017), where instead of an adjacency matrix with self connections (i.e. first degree polynomial), a higher degree graph polynomial filter is used on every layer (please correct me if this comparison is not accurate). With more experiments and interpretation of the model, including some sort of multilayer analysis, this can be a good acceptance candidate.\n\n\n[1] David I Shuman, Sunil K Narang, Pascal Frossard, Antonio Ortega, and Pierre Vandergheynst.\nThe emerging field of signal processing on graphs: Extending high-dimensional data analysis to\nnetworks and other irregular domains. IEEE Signal Processing Magazine, 30(3):83–98, 2013.']","[50, -20, -50]","[80, 50, 20]","[""The sentiment score is 50 (moderately positive) because the reviewer initially expresses a positive view, highlighting several strong points of the paper and recommending acceptance. However, the score is not higher due to the edit at the end, where the reviewer modifies their rating based on inadequate outlining of relations to previous work. The politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout, acknowledging the paper's strengths and providing constructive feedback. The reviewer also shows willingness to reconsider their initial assessment based on new information, which demonstrates respect for the peer review process."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper 'interesting', they also point out several areas for improvement and clarity. They mention that some sections are 'not very clearly written' and require 'polishing'. The reviewer also raises concerns about the fairness of comparisons and potential overfitting. However, the overall tone is not entirely negative, as they acknowledge 'sensible improvements' and find certain sections likeable. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism rather than harsh judgments. They use phrases like 'I find', 'I would better explain', and 'please make figures readable', which maintain a polite tone while providing feedback. The reviewer also balances critique with positive comments, showing consideration for the authors' work."", ""The sentiment score is -50 because the reviewer states that the paper 'requires major revision' and provides several criticisms, including that the first 8 pages are mostly literature review, the experimental section lacks insights, and the reviewer disagrees with a key statement. However, the score is not lower because the reviewer does acknowledge that the TAGCN idea is interesting and could be a good acceptance candidate with more work. The politeness score is 20 because while the reviewer is critical, they use professional and respectful language throughout. They offer constructive feedback and suggestions for improvement, such as summarizing certain sections more succinctly and adding more experiments and interpretations. The reviewer also uses phrases like 'In my opinion' and 'I think,' which soften the criticism. However, the score is not higher due to the overall critical nature of the review.""]"
"['The paper extended the Adam optimization algorithm to preserve the update direction. Instead of using the un-centered variance of individual weights, the proposed method adapts the learning rate for the incoming weights to a hidden unit jointly using the L2 norm of the gradient vector. The authors empirically demonstrated the method works well on CIFAR-10/100 tasks.\n\nComments:\n\n- I found the paper very hard to follow. The authors could improve the clarity of the paper greatly by listing their contribution clearly for readers to digest. The authors also combined the proposed method with a few existing deep learning tricks in the paper. All those tricks that, ie. section 3.3 and 4, should go into the background section.\n\n- Overall, the only contribution of the paper seems to be the ad-hoc modification to Adam in Eq. (9). Why is this a reasonable modification? Do we expect this modification to fail in any circumstances? The experiments on CIFAR dataset and one CNN architecture do not provide enough evidence to show the proposed method work well in general.\n\n', 'Method:\n\nThe paper is missing analysis of some important related works such as\n\n""Beyond convexity: Stochastic quasi-convex optimization"" by E. Hazan et al. (2015) \n\nwhere Stochastic Normalized Gradient Descent (SNGD) was proposed. \n\nThen, normalized gradient versions of AdaGrad and Adam were proposed in \n\n""Normalized Gradient with Adaptive Stepsize Method for Deep\nNeural Network Training"" by A. W. Yu et al. (2017).\n\nAnother work which I find to be relevant is \n\n""Follow the Signs for Robust Stochastic Optimization"" by L. Balles and P. Hennig (2017).\n\nFrom my personal experiments, restricting w_i to have L2 norm of 1, i.e., to be +-1 \nleads to worse generalization. One reason for this is that weight decay is not \nreally functioning since it cannot move w_i to 0 or make its amplitude any smaller. \nPlease correct me if I misunderstand something here. \n\nThe presence of +-1 weights moves us to the area of low-precision NNs, \nor more specifically, NNs with binary / binarized weights as in \n\n""BinaryConnect: Training Deep Neural Networks with\nbinary weights during propagations"" by M. Courbariaux et al. (2015)\n\nand \n\n""Binarized neural networks: Training deep neural networks with weights and activations constrained to+ 1 or-1"" by M. Courbariaux et al. (2016). \n\nRegarding\n""Moreover, the magnitude of each update does not depend on themagnitude of the gradient. Thus, ND-Adam is more robust to improper initialization, and vanishing or exploding gradients.""\n\nIf the magnitude of each update does not depend on the magnitude of the gradient, then the algorithm heavily depends on the learning rate. Otherwise, it does not have any means to approach the optimum in a reasonable number of steps *when* it is initialized very / unreasonably far from it. The claim of your second sentence is not supported by the paper. \n\nEvaluation:\n\nI am not confident that the presented experimental validation is fair. First, the original WRN paper and many other papers with ResNets used weight decay of 0.0005 and not 0.001 or 0.002 as used for SGD in this paper. It is unclear why this setting was changed. One could just use \\alpha_0 = 0.05 and \\lambda = 0.0005.\n\nThen, I don\'t see why the authors use WRN-22-7.5 which is different from WRN-28-10 which was suggested in the original study and used in several follow-up works. The difference between WRN-22-7.5 and WRN-28-10 is unlikely to be significant, \nthe former might have about only 2 times less parameters which should barely change the final validation errors. However, the use of WRN-22-7.5 makes it impossible to easily compare the presented results to the results of Zagoruyko who had 3.8\\% with WRN-28-10. I believe that the use of the setup of Zagoruyko for WRN-22-7.5 would allow to get much better results than 4.5\\% and 4.49\\% shown for SGD and likely better 4.14\\% shown for ND-Adam. I note that the use of WRN-22-7.5 is unlikely to be due to the used hardware because later in paper the authors refer to WRN-34-7.5.\n\nMy intuition is that the proposed ND-Adam moves the algorithm back to SGD but with potentially harmful constraints of w_i=+-1. Even the values of \\alpha^v_0 found for ND-Adam (e.g., \\alpha^v_0=0.05 in Figure 1B) are in line of what would be optimal values of \\alpha_0 for SGD. \n\nI find it uncomfortable that BN-Softmax is introduced here to support the use of an optimization algorithm, moreover, that the values of \\gamma_c are different for CIFAR-10 and CIFAR-100. I wonder if the proposed values are optimal (and therefore selected) for all three tested algorithms  or only for Adam-ND. I expect that hyperparameters of SGD and Adam would also need to be revised to account for BN-Softmax.', 'This paper proposes a variant of ADAM optimization algorithm that normalizes the weights of each hidden unit. They further suggest using batch normalization on the output of the network before softmax to improve the generalization. The main ideas are new to me and the paper is well-written. The arguments and derivations are very clear. However, the experimental results suggest that the proposed method is not superior to SGD and ADAM.\n\nPros: \n\n- The idea of optimizing the direction while ignoring the magnitude is interesting and make sense.\n- Using batch normalization before softmax is interesting.\n\nCons:\n\n- In the abstract, authors claim that the proposed method has good optimization performance of ADAM and good generalization performance of SGD. Such a method could be helpful if one can get to the same level of generalization faster (less number of epochs). However, the experiments suggest that optimization advantages of the proposed method do not translate to faster generalization. Figures 2,3 and Table 1 indicate that the generalization performance of this method is very similar to SGD.\n\n- The paper is not coherent. In particular, direction-preserving ADAM and batch-normalized softmax trick are completely orthogonal ideas. \n\n- In the introduction and Section 2.2, authors claim that weight decay has a significant effect on the generalization performance of DNNs. I wonder if authors can refer to any work on this. My own experience and several empirical works have suggested that weight decay does not improve generalization significantly.\n\n']","[-50, -60, -20]","[0, 20, 60]","[""The sentiment score is -50 because the review is generally critical, pointing out significant issues with the paper's clarity and contribution. The reviewer states the paper is 'very hard to follow' and questions the significance and generalizability of the proposed method. However, it's not entirely negative as the reviewer acknowledges that the authors 'empirically demonstrated the method works well on CIFAR-10/100 tasks'. The politeness score is 0 (neutral) because the language used is neither particularly polite nor rude. The reviewer presents criticisms directly but professionally, without using overly harsh language or personal attacks. They use phrases like 'I found' and 'The authors could improve' which are neutral in tone."", ""The sentiment score is -60 because the review is predominantly critical, pointing out several issues with the paper such as missing related works, questionable methodological choices, and concerns about the experimental validation. The reviewer expresses skepticism about the paper's claims and results. However, it's not entirely negative as the reviewer does provide constructive feedback and suggestions for improvement. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'Please correct me if I misunderstand' and 'I find it uncomfortable' rather than using harsh or rude language. The reviewer also provides detailed explanations for their concerns, which is a courteous way to give feedback. However, the overall tone is more matter-of-fact than overtly polite, hence the relatively low positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('main ideas are new', 'paper is well-written', 'arguments and derivations are very clear'), they ultimately conclude that 'the experimental results suggest that the proposed method is not superior to SGD and ADAM'. The cons outweigh the pros in the review. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively (e.g., 'I wonder if authors can refer to any work on this'). The reviewer maintains a professional tone without using harsh or dismissive language.""]"
"['This paper proves a new separation results from 3-layer neural networks to 2-layer neural networks. The core of the analysis is a proof that any 2-layer neural networks can be well approximated by a polynomial function with reasonably low degrees. Then the authors constructs a highly non-smooth function can be represented by a 3-layer network, but impossible to approximate by any polynomial-degree polynomial function.\n\nSimilar results about polynomial approximation can be found in [1] (Theorem 4). To me, the result proved in [1] is spiritually very similar to propositions 3-4. The authors need to justify the difference.\n\nThe main strength of the new separation result is that it holds for a larger class of input distributions. Comparing to Daniely (2017) which requires the input distribution to be spherically uniform, the new result only needs the distribution to be lower bounded by 1/poly(d) in a small ball of radius 1/poly(d). Conceptually I don\'t think this is a much weaker condition. For a ""truly"" non-uniform distribution, one should allow its density function to be very close to zero at certain regions of the ball. Nevertheless, the result is a step forward from Daniely (2017) and the paper is well written.\n\nI am still in doubt of the practical value of such kind of separation results. The paper proves the separation by constructing a very specific function that cannot be approximated by 2-layer networks. This function has a super large Lipschitz constant, which we don\'t expect to see in practice. Consider the function f(x)=cos(Nx). When N is chosen large enough, the function f can not be well approximated by any 2-layer network with polynomial size. Does it imply that the family of cosine functions is rich enough so that it is a better family to learn than 2-layer neural networks? I guess the answer would be negative. In addition, the paper doesn\'t show that any 2-layer network can be well approximated by a 3-layer network, which is a missing piece in justifying the richness of 3-layer nets.\n\nFinally, the constructed ""hard"" function has order d^5 Lipschitz constant, but Theorem 7 assumes that the 2-layer networks\' weight must be bounded by O(d^2). This assumption is crucial to the proof but not well justified (especially considering the d^5 factor in the function definition).\n\n[1] On the Computational Efficiency of Training Neural Networks, Livni et al., NIPS\'14', 'This paper contributes to the growing literature on depth separations in neural network, showing cases where depth is provably needed to express certain functions. Specifically, the paper shows that there are functions on R^d that can be approximated well by a depth-3 sigmoidal network with poly(d) weights, that cannot be approximated by a depth-2 sigmoidal network with poly(d) weights, and with respect to any input distributions with sufficiently large density in some part of the domain. The proof builds on ideas in Daniely (2017) and Shalev-Shwartz et al. (2011). \n\nCompared to previous works, the main novelty of the result is that it applies to a very large family of input distributions, as opposed to some specific distributions. On the flip side, it applies only to networks with sigmoids as activation functions, and the weights need to be polynomially bounded. Moreover, although the result is robust to the choice of input distribution, the function used to get the lower bound is still rather artificial ( x -> sin(N||x||^2) for some large N). In a sense, this is complementary to the separation result in Safran and Shamir (2017), mentioned by the authors, where the function is arguably ""natural"", but the distribution is not. Finally, the proof ideas appear to be not too different than those of Daniely (2017).\n\nOverall, I think this is a decent contribution to this topic, and would recommend accepting it given enough room. It\'s a bit incremental in light of existing work, but does contribute to the important question of whether we can prove depth separations which are also robust.', 'The paper shows that there are functions that can be represented by depth 3 sigmoidal neural networks (with polynomial weights and polynomially many units), but sigmoidal networks of depth 2 with polynomially bounded weights require exponentially many units. There is nothing new technically in the paper and I find the results uninteresting given the spate of results of this kind. I don\'t share the authors enthusiasm about much more general distributions etc. The approximations the authors are shooting for are much stronger the kind that has been used by Eldan and Shamir (2016) or other such papers. The approximation used here is $\\ell_\\infty$ rather than $\\ell_2$. So a negative result for depth 2 is weaker; the earlier work (and almost trivially by using the work of Cybenko, Hornik, etc.) already shows that the depth -3 approximations are uniform approximators. \n\nThe fact that sigmoidal neural networks with bounded weights can be expressed as ""low"" degree polynomials is not new. Much stronger results including bounds on the weights of the polynomial (sum of squares of coefficients) appear implicitly in Zhang et al. (2014) and Goel et al. (2017). In fact, these last two papers go further and show that this has implications for learnability not just for representation as the current paper shows. \n\nAdditionally, I think the paper is a bit sloppy in the maths. For example, Theorem 7 does not specifiy what delta is. I\'m sure they mean that there is a ""small enough \\delta"" (with possible dependence on d, B, etc.). But surely this statement is not true for all values of $\\delta$. For e.g. when $\\delta = 1$, sin(\\pi d^5 \\Vert x \\Vert^2) can rather trivially be expressed as a sigmoidal neural network of depth 2. \n\nOverall, I think this paper has a collection of results that are well-known to experts in the field and add little novelty. It\'s unlikely that having yet another paper separating depth 2 from depth 3 with some other set of conditions will move us towards further progress in the very important question of depth separation. ']","[20, 50, -80]","[60, 75, -20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contribution as a 'step forward' and mentions that it is 'well written'. However, they also express doubts about the practical value and point out some limitations, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'I am still in doubt' and 'The authors need to justify' instead of more confrontational language. The review maintains a professional tone, balancing praise with areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as a 'decent contribution' and recommends accepting it, while also noting some limitations. The review begins by highlighting the paper's contributions and novelty, but also points out areas where it is incremental or limited. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits and offering constructive criticism without harsh or dismissive language. Phrases like 'I think this is a decent contribution' and 'would recommend accepting it given enough room' indicate a polite and considerate tone."", ""The sentiment score is -80 because the reviewer expresses strong negative opinions about the paper, stating that there is 'nothing new technically' and finding the results 'uninteresting'. They also criticize the paper for being 'sloppy in the maths' and assert that the results are 'well-known to experts'. The overall tone is dismissive and critical throughout. The politeness score is -20 because while the reviewer doesn't use overtly rude language, their criticism is direct and somewhat harsh. They don't soften their negative feedback with any positive comments or constructive suggestions, which comes across as slightly impolite in academic discourse. The use of phrases like 'I don't share the authors enthusiasm' and 'It's unlikely that...' contribute to a somewhat dismissive tone.""]"
"['This paper propose to evaluate the distributions learned by GAN using classification-based methods. As two examples, the authors evaluates the mode collapse effect and measure the diversity for GAN distributions. The proposed approaches are experimental but does not require human inspection. The main idea is to fit a classifier on the training data and also learn a GAN model using the training data. Then generate simulated data using GAN and use the classifier to predict the labels of the simulated data. The distribution of predicted labels  and the labels of the true data can be easily compared.\n\nDetailed comments:\n\n1. The proposed method is purely experimental. It  would be better to gain some theoretical insights of this methodology. Moreover, in terms of experiments, it would be nice to consider more examples except for mode collapse and diversity, since these problems are well-known for GAN.\n\n2. Since mode collapse is a well-known phenomenon, the novelty of this paper is not sufficient.\n\n3. There are other measures for the quality of GAN. For example, the inception scores and mode scores (Salimans et al. 2016, Che et al. 2017). It would be nice to compare the method here with other related work.\n\nReferences:\n1. Improved Techniques for Training GANs https://arxiv.org/abs/1606.03498\n\n2. Mode Regularized Generative Adversarial Networks https://arxiv.org/abs/1612.02136\n\n', ""The paper proposes a new evaluation measure for evaluating GANs. Specifically, the paper proposes generating synthetic images using GAN, training a classifier (for an auxiliary task, not the real vs fake discriminator) and measuring the performance of this classifier on held out real data. \n\nWhile the idea of using a downstream classification task to evaluate the quality of generative models has been explored before  (e.g. semi-supervised learning), I think that this is the first paper to evaluate GANs using such an evaluation metric.\n\nI'm not super convinced that this is an useful evaluation metric as the absolute number is somewhat to interpret and dependent on the details of the classifier used. The results in Table 1 change quite a bit depending on the classifier. \n\nIt would be useful to add a discussion of the failure modes of the proposed metric. It seems like a generator which generates samples close to the classification boundary (but drops examples far away from the boundary) could still achieve a high score under this metric. \n\nIn the experiments, were different architectures used for different GAN variants?\n\nI think the mode-collapse evaluation metrics in MR-GAN are worth discussing in Section 2.1\nMode Regularized Generative Adversarial Networks\nhttps://arxiv.org/abs/1612.02136"", 'Overall comments: Trying to shed light at comparison between different GAN variants, but the metrics introduced are not very novel, results are not comparable with prior work and older version of certain models are used (WGAN instead of Improved WGAN)\n\nSection 2.1: quantifying mode collapse\n* This section should mention Inception scores. A model which collapses on only one class will have a low inception score, and this metric also uses a conv net classifier, as the approach is very similar (the method is only mentioned briefly in section 2.3)\n* The authors might not be aware of concurrent work published before the ICLR deadline, which introduces a very similar metric: https://arxiv.org/abs/1706.08500\n\nSection 2.2: measuring diversity:\n* There is an inherent flaw in this metric, namely it trains one GAN per class. One cannot generalize from this metric on how different GAN models will perform when trained on the entire dataset. One model might be able to capture more diverse distributions, but lose a bit of quality, while another model might be able to create good samples when train on low diversity data. We already know that when looking at other generative models, we can find such examples. VAEs can obtain very good samples on celebA, a dataset with relative low diversity, but not so good samples on cifar. \n* The authors compare their experiment with Radford et al. (2015), but that needs to be done with caution. In Radford et al. (2015), the authors use a conditional generative model trained on the entire dataset. In that setting, this test is more suitable since one can test how good well the model has learned the conditioning. For example, for a conditional model trained on cats and dogs, a failure mode is that the model generates only cats. This failure mode can then be captured by this metric. However, when training two models, one on cats and one on dogs, this failure mode is not present since the data is already split into classes. \n* The proposed metric is not necessarily a diversity metric, it is also a quality metric:  in a situation where all the models diverge and generate random noise, with high diversity, but without any structure. This metric would capture this issue, because a classifier will not be able to learn the classes, because there is no correlation between the classes and the generated images. \n\nExperimental results:\n* Positive insights regarding labels and celeba. Looks like subtle labels on faces are not being captured by GAN models. \nFigure 1 is hard to read. \n* ALI having higher diversity on celeba is explicitly mentioned in a paper the authors cite, namely “Do GANs actually learn the distribution? An empirical study”. Would be nice to mention that in the paper.\n\nWould like to see:\n* A comparison with the Improved Wasserstein GAN model. This model is now the one used by the community, as opposed to the original Wasserstein GAN.\n* Models trained on cifar, with the reported inception scores of the models on cifar. That makes the paper comparable with previous work and is a test against bugs in model implementations or other parts of the code. This would also allow to test for claims such as the fact that the Improved GAN has more mode collapse than DCGAN, while the Improved GAN paper says the opposite. \nThe reason why the authors chose the models they did for comparison. In the BiGAN (same model as ALI) paper the authors report a low inception score, which suggests that their model is not able to capture the subtleties of the Cifar dataset, and this seems to be correlated with the results obtained in this work. \n\n\n']","[-20, 20, -50]","[50, 60, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's proposal and experimental approach, they express concerns about the lack of theoretical insights, insufficient novelty, and the need for more examples and comparisons. The overall tone suggests that the paper has potential but requires significant improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism with phrases like 'It would be better' and 'It would be nice,' which soften the critique. The reviewer also provides specific suggestions and references, demonstrating a helpful and professional approach to the feedback."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the novelty of the approach ('I think that this is the first paper to evaluate GANs using such an evaluation metric'), they express some skepticism about its usefulness ('I'm not super convinced that this is an useful evaluation metric'). The reviewer also provides constructive feedback and suggestions for improvement, indicating a generally positive but cautious stance. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers suggestions rather than demands ('It would be useful to add...'), and phrases criticisms as personal opinions ('I'm not super convinced...') rather than absolute statements. The reviewer also acknowledges the paper's contributions and asks questions in a polite manner."", ""The sentiment score is -50 because the review is generally critical, pointing out several flaws and limitations in the paper, though it does acknowledge some positive insights. The reviewer suggests many improvements and expresses skepticism about the novelty and comparability of the results. However, it's not entirely negative, as the reviewer offers constructive feedback and recognizes some valuable contributions. The politeness score is 20 because while the language is professional and not overtly rude, it's also quite direct in its criticisms. The reviewer uses phrases like 'The authors might not be aware of...' and 'There is an inherent flaw in this metric,' which are polite ways of pointing out shortcomings. The reviewer also offers suggestions for improvement and acknowledges positive aspects, which contributes to a slightly positive politeness score.""]"
"['SUMMARY \n========\nThis paper proposes to measure the ""influence"" of single neurons w.r.t. to a quantity of interest represented by another neuron, typically w.r.t. to an output neuron for a class of interest, by simply taking the gradient of the corresponding output neuron w.r.t to the considered neuron. This gradient is used as is, given a single input instance, or else, gradients are averaged over several input instances. \nIn the latter case the averaging is described by an ad-hoc distribution of interest P which is introduced in the definition of the influence measure, however in the present work only two types of averages are practically used: either the average is performed over all instances belonging to one class, or over all input instances.\n\nIn other words, standard gradient backpropagation values (or average of them) are used as a proxy to quantify the importance of neurons (these neurons being within hidden layers or at the input layer), and are intended to better explain the classification, or sometimes even misclassification, performed by the network.\n\nThe proposed importance measure is theoretically justified by stating a few properties (called axioms) an importance measure should generally verify, and then showing the proposed measure fullfills these requirements.\n\nEmpirically the proposed measure is used to inspect the classification of a few input instances, to extract ""class-expert"" neurons, and to find a preprocessing bug in one model. The only comparison to a related work method is done qualitatively on one image visualization, where the proposed method is compared to Integrated Gradients [Sundararajan et al. 2017].\n\nWEAKNESSES\n==========\nThe similarity and differences between the proposed method and related work is not made clear. For example, in the case of a single input instance, and when the quantity of interest is one output neuron corresponding to one class, the proposed measure is identical to the image-specific class saliency of [Simonyan et al. 2014].\nThe difference to Integrated Gradients [Sundararajan et al. 2017] at the end of Section 1.1 is also not clearly formulated: why is the constraint on distribution marginality weaker here ?\nAn important class of explanation methods, namely decomposition-based methods (e.g. LRP, Excitation Backprop, Deep Taylor Decomposition), are not mentioned. Recent work (Montavon et al., Digital Signal Processing, 2017), discusses the advantages of decomposition-based methods over gradient-based approaches. Thus, the authors should clearly state the advantages/disadvantes of the proposed gradient-based method over decomposition-based techniques.\n\nConcerning the theoretical justification:\nIt is not clear how Axiom 2 ensures that the proposed measure only depends on points within the input data manifold. This is indeed an important issue, since otherwise the gradients in equation (1) might be averaged completely outside the data manifold and thus the influence measure be unrelated to the data and problem the neural network was trained on. Also the notation used in Axiom 5 is very confusing. Moreover it seems this axiom is even not used in the proof of Theorem 2.\n\nConcerning the experiments:\nThe experimental setup, especially in Section 3.3.1, is not well defined: on which layer of the network is the mask applied? What is the ""quantity of interest"": shouldn\'t it be an output neuron value rather than h|i (as stated at the begin of the fourth paragraph of Section 3.3.1)?\nThe proposed method should to be quantitatively compared with other explanation techniques (e.g. by iteratively perturbing most relevant pixels and tracking the performance drop, see Samek et al., IEEE TNNLS, 2017).\nThe last example of explaining the bug is not very convincing, since the observation that class 2 distinctive features are very small in the image space, and thus might have been erased through gaussian blur, is not directly related to the influence measure and could have been made aso independently from it.\n\nCONCLUSION\n==========\nOverall this work does not introduce any new importance measure for neurons, it merely formalizes the use of standard backpropagation gradients as influence measure.\nUsing gradients as importance measure was already done in previous work (e.g. [Simonyan et al. 2014]). Though taking the average of gradients over several input instances is new, this information might not be of great help for practical applications.\nRecent work also showed that raw gradients are less informative than decomposition-based quantities to explain the classification decisions made by a neural network.', 'Notions of ""influence"" have become popular recently, and these notions try to understand how the output of a classifier or a learning algorithm is influenced by its training set. In this paper, the authors propose a way to measure influence that satisfies certain axioms. This notion of influence may be used to identify what part of the input is most influential for the output of a particular neuron in a deep neural network. Using a number of examples, the authors show that this notion of influence seems useful and may yield non-trivial results.\n\nMy main criticism of this paper is the definition of influence. It is easy to see that sometimes, influence of $x_i$ in a function $f(x_1, \\dots, x_n)$ will turn out to be 0, simply because the integral in equation (1) is 0. However, this does not mean that $x_i$ is irrelevant to the the output f. This is not a desirable property for any notion of influence. A better definition would have been taking the absolute value of the partial derivative of f wrt x_i, or square of the same. This will ensure that equation (1) will always lead to a positive number as the influence, and 0 influence will indeed imply x_i is completely irrelevant to the output of f. These alternate notions do not satisfy Axiom 1, and possibly Axiom 5. But it is likely that tweaking the axioms will fix the issue. The authors should have at least mentioned why they preferred to use df/dx instead of |df/dx| or (df/dx)^2, since the latter clearly make more intuitive sense.\n\nThe examples in section 3 are quite thorough, but I feel the basic idea of measuring influence by equation (1) is not on solid footing. ', ""The authors extend traditional approach of examining the gradient in order to understand which features/units are the most relevant to given class.\n\nTheir extension proposes to measure the influence over a set of images by adding up influences over individual images. They also propose measuring influence for the classification decision restricted to two classes, by taking the difference of two class activations as the objective.\n\nThey provide an axiomatic treatment which shows that this gradient-based approach has desirable qualities.\n\nOverall it's not clear what this paper adds to existing body of work:\n1. axiomatic treatment takes a bulk of the paper, but does not motivate any significantly new method\n2. from experimental evaluation it's not clear the results are better than existing work, ie Yosinsky http://yosinski.com/deepvis""]","[-60, -20, -30]","[20, 50, 20]","[""The sentiment score is -60 because the review is predominantly critical. The reviewer points out several weaknesses, including lack of clarity in comparing to related work, issues with theoretical justification, and unconvincing experimental results. The conclusion states that the work doesn't introduce any new measure and that recent work shows raw gradients are less informative than other methods. However, it's not entirely negative as it acknowledges some novel aspects, hence not the lowest possible score.\n\nThe politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use neutral language like 'not clear', 'should be', and 'is not very convincing' rather than harsh or rude phrasing. The reviewer also acknowledges some positive aspects, such as the novelty of averaging gradients over several input instances. The tone is more matter-of-fact than overtly polite, hence a slightly positive but not high score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions and thoroughness in examples, they express a 'main criticism' about the definition of influence. They suggest alternative approaches and point out perceived flaws in the current method, indicating some dissatisfaction with a core aspect of the paper. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'The authors should have at least mentioned' rather than more aggressive language, and offer constructive suggestions for improvement. The review maintains a professional tone without personal attacks or overly harsh language."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the authors' work in extending traditional approaches and providing an axiomatic treatment, they ultimately express skepticism about the paper's contribution. The reviewer states that 'it's not clear what this paper adds to existing body of work' and points out two specific concerns. This indicates a generally negative sentiment, though not extremely so. The politeness score is slightly positive (20) because the reviewer uses neutral, professional language throughout and begins by objectively describing the authors' work. They avoid harsh or personal criticism, instead focusing on the content. However, the critique is direct and doesn't include many polite phrases or compliments, keeping the score from being higher.""]"
"['This paper proposes several client-server neural network gradient update strategies aimed at reducing uplink usage while maintaining prediction performance.  The main approaches fall into two categories: structured, where low-rank/sparse updates are learned, and sketched, where full updates are either sub-sampled or compressed before being sent to the central server.  Experiments are based on the federated averaging algorithm.  The work is valuable, but has room for improvement.\n\nThe paper is mainly an empirical comparison of several approaches, rather than from theoretically motivated algorithms.  This is not a criticism, however, it is difficult to see the reason for including the structured low-rank experiments in the paper (itAs a reader, I found it difficult to understand the actual procedures used.  For example, what is the difference between the random mask update and the subsampling update (why are there no random mask experiments after figure 1, even though they performed very well)?  How is the structured update ""learned""?  It would be very helpful to include algorithms.\n\nIt seems like a good strategy is to subsample, perform Hadamard rotation, then quantise.    For quantization, it appears that the HD rotation is essential for CIFAR, but less important for the reddit data.  It would be interesting to understand when HD works and why,  and perhaps make the paper more focused on this winning strategy, rather than including the low-rank algo.  \n\nIf convenient, could the authors comment on a similarly motivated paper under review at iclr 2018:\nVARIANCE-BASED GRADIENT COMPRESSION FOR EFFICIENT DISTRIBUTED DEEP LEARNING\n\npros:\n\n- good use of intuition to guide algorithm choices\n- good compression with little loss of accuracy on best strategy\n- good problem for FA algorithm / well motivated\n- \n\ncons:\n\n- some experiment choices do not appear well motivated / inclusion is not best choice\n- explanations of algos / lack of \'algorithms\' adds to confusion\n\na useful reference:\n\nStrom, Nikko. ""Scalable distributed dnn training using commodity gpu cloud computing."" Sixteenth Annual Conference of the International Speech Communication Association. 2015.\n\n', 'This paper proposes a new learning method, called federated learning, to train a centralized model while training data remains distributed over a large number of clients each with unreliable and relatively slow network connections. Experiments on both convolutional and recurrent networks are used for evaluation. \n\nThe studied problem in this paper seems to be interesting, and with potential application in real settings like mobile phone-based learning. Furthermore, the paper is easy to read with good organization. \n\nHowever, there exist several major issues which are listed as follows:\n\nFirstly, in federated learning, each client independently computes an update to the current model based on its local data, and then communicates this update to a central server where the client-side updates are aggregated to compute a new global model. This learning procedure is heuristic, and there is no theoretical guarantee about the correctness (convergence) of this learning procedure. The authors do not provide any analysis about what can be learned from this learning procedure. \n\nSecondly, both structured update and sketched update methods adopted by this paper are some standard techniques which have been widely used in existing works. Hence, the novelty of this paper is limited. \n\nThirdly, experiments on larger datasets, such as ImageNet, will improve the convincingness. \n', '\nThe authors examine several techniques that lead to low communication updates during distributed training in the context of Federated learning (FL). Under the setup of FL, it is assumed that training takes place over edge-device like compute nodes that have access to subsets of data (potentially of different size), and each node can potentially be of different computational power. Most importantly, in the FL setup, communication is the bottleneck. Eg a global model is to be trained by local updates that occur on mobile phones, and communication cost is high due to slow up-link.\n\nThe authors present techniques that are of similar flavor to quantized+sparsified updates. They distinguish theirs approaches into 1) structured updates and 2) sketched updates. For 1) they examine a low-rank version of distributed SGD where instead of communicating full-rank model updates, the updates are factored into two low rank components, and only one of them is optimized at each iteration, while the other can be randomly sampled.\nThey also examine random masking, eg a sparsification of the updates, that retains a random subset of the entries of the gradient update (eg by zero-ing out a random subset of elements). This latter technique is similar to randomized coordinate descent.\n\nUnder the theme of sketched updates, they examine quantized and sparsified updates with the property that in expectation they are identical to the true updates. The authors specifically examine random subsampling (which is the same as random masking, with different weights) and probabilistic quantization, where each element of a gradient update is randomly quantized to b bits. \n\nThe major contribution of this paper is their experimental section, where the authors show the effects of training with structured, or sketched updates, in terms of reduced communication cost, and the effect on the training accuracy. They present experiments on several data sets, and observe that among all the techniques, random quantization can have a significant reduction of up to 32x in communication with minimal loss in accuracy.\n\nMy main concern about this paper is that although the presented techniques work well in practice, some of the algorithms tested are similar algorithms that have already been proven to work well in practice. For example, it is unclear how the performance of the presented quantization algorithms compares to say  QSGD [1] and Terngrad [2]. Although the authors cite QSGD, they do not directly compare against it in experiments.\n\nAs a matter of fact, one of the issues of the presented quantized techniques (the fact that random rotations might be needed when the dynamic range of elements is large, or when the updates are nearly sparse) is easily resolved by algorithms like QSGD and Terngrad that respect (and promote) sparsity in the updates. \n\nA more minor comment is that it is unclear that averaging is the right way to combine locally trained models for nonconvex problems. Recently, it has been shown that averaging can be suboptimal for nonconvex problems, eg a better averaging scheme can be used in place [3]. However, I would not worry too much about that issue, as the same techniques presented in this paper apply to any weighted linear averaging algorithm.\n\nAnother minor comment: The legends in the figures are tiny, and really hard to read.\n\nOverall this paper examines interesting structured and randomized low communication updates for distributed FL, but lacks some important experimental comparisons.\n\n\n[1] QSGD: Communication-Optimal Stochastic Gradient Descent, with Applications to Training Neural Networks https://arxiv.org/abs/1610.02132\n[2] TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep Learning\nhttps://arxiv.org/abs/1705.07878\n[3] Parallel SGD: When does averaging help? \nhttps://arxiv.org/abs/1606.07365\n\n']","[-20, -20, -20]","[50, 60, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'valuable', they also state it 'has room for improvement' and list several criticisms. The reviewer points out issues with experiment choices, lack of clear explanations, and confusion in the presentation. However, they do mention some positive aspects ('good use of intuition', 'good compression'), which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive criticism, and balances negative points with positive ones. They use phrases like 'It would be helpful' and 'If convenient, could the authors comment' which are polite ways of suggesting improvements. The reviewer also lists both pros and cons, showing a balanced approach. While not overly effusive, the tone remains professional and courteous throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting topic and good organization, they also point out several major issues. The reviewer uses phrases like 'However, there exist several major issues' and 'the novelty of this paper is limited,' which indicate a generally critical stance. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, starting with positive comments before moving to criticisms. They use phrases like 'seems to be interesting' and 'will improve the convincingness' rather than harsh or dismissive language. The reviewer also presents their criticisms as objective observations rather than personal attacks, maintaining a professional tone throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, particularly in the experimental section, they express significant concerns about the novelty of the techniques and lack of comparisons to existing methods. The reviewer states 'My main concern about this paper is that although the presented techniques work well in practice, some of the algorithms tested are similar algorithms that have already been proven to work well in practice.' This indicates a notable criticism, but not a complete rejection of the paper's value. The politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'The authors examine...', 'The major contribution of this paper is...', and 'Overall this paper examines interesting...', which show respect for the authors' work. Even when expressing concerns, the language remains constructive and not personally critical, such as 'My main concern about this paper is...' rather than using more harsh or dismissive language.""]"
"['This paper presents a simple image retrieval method. Paper claims it is a deep learning method, however it is not an end-to-end network. The main issue of the paper is lack of technical contributions.\n\nPaper assumes that image retrieval task can be reformulated at a supervised similarity learning task. That is fine, however image retrieval is traditionally an unsupervised task. \n\nEven after using supervised method and deep learning technique, still this method is not able to obtain better results than hand crafted methods. Why is that? See - paper from CVPR2012 -  Arandjelović, Relja, and Andrew Zisserman. ""Three things everyone should know to improve object retrieval."" Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. IEEE, 2012.\n\nPaper make use of external signal to obtain y_{i,j}. It is not clear to me how does this generalize to large datasets?\n\nIf features are L2 normalized, why you need to normalize the features again in equation 5?\n\nIn equation 5, why not simply use a max margin deep similarity metric learning method with slack variables to generalizability?\n\nThe performance of entire network really rely on the accuracy of y_{i,j} and it is not clear the obtained performance is simply due to this supervision.\n\nPaper does not argue well why we need this supervision.\n\nTechnically, there is nothing new here.\n', 'The authors of this work propose learning a similarity measure for visual similarity and obtain, by doing that, an improvement in the very well-known datasets of Oxford and Paris for image retrieval. The work takes high-level image representations generated with an existing architecture (R-MAC), and train on top a neural network of two fully connected layers. \n\nThe training of such network is performed in three stages: firstly approximating the cosine similarity with a large amount of random feature vectors, secondly using image pairs from the same class, and finally using the hard examples.\n\n\nPROS\n\nP1. Results indicate the benefit of this approach in terms of similarity estimation and, overall, the paper present results that extend the state of the art in well-known datasets. \n\nP2. The authors make a very nice effort in motivation the paper, relating it with the state of the art and funding their proposal on studies regarding human visual perception. The whole text is very well written and clear to follow.\n\nCONS\n\nC1. As already observed by the authors, training a similarity function without considering images from the target dataset is actually harmful. In this sense, the simple cosine similarity does not present this drawback in terms of lack of generalization. This observation is not new, but relevant in the field of image retrieval, where in many applications the object of interest for a query is actually not present in the training dataset.\n\nC2. The main drawback of this approach is in terms of computation. Feed-forwarding the two samples through the trained neural network is far more expensive that computing the simple cosine similarity, which is computed very quickly with a GPU as a matrix multiplication. The authors already point at this in Section 4.3.\n\nC3. I am somehow surprised that the authors did not explore also training the network that would extract the high-level representations, that is, a complete end-to-end approach. While I would expect to have the weights frozen in the first phase of training to miimic the cosine similarity, why not freeing the rest of layers when dealing with pairs of images ?\n\nC4. There are a couple of recent papers that include results of the state of the art which are closer and sometimes better than the ones presented in this work. I do not think they reduce at all the contribution of this work, but they should be cited and maybe included in the tables:\n\nA. Gordo, J. Almazan, J. Revaud, and D. Larlus. End-to-end learning of deep visual representations for image retrieval.\nInternational Journal of Computer Vision, 124(2):237–254, 2017.\n\nAlbert Jimenez, Jose M. Alvarez, and Xavier Giro-i-Nieto. “Class-Weighted Convolutional Features for Visual Instance Search.” In Proceedings of the 28th British Machine Vision Conference (BMVC). 2017.\n', '(1) The motivation\nThe paper argues that it is more suitable to use non-metric distances instead of metric distances. However, the distance function used in this work is cosine similarity between two l2 normalized features. It is known that in such a situation, cosine similarity is equivalent to Euclidean distance. The motivation should be further explained.\n\n(2) In Eq. (5), I am not sure why not directly set y_ij = 1 if two images come from the same category, and set to 0 otherwise. It is weird to see the annotation is related to the input features considering that we already have the groundtruth labels.\n\n(3) The whole pipeline is not trained in an end-to-end manner. It requires some other features as the input (RMAC used in this work), and three-stage training. It is interesting to see some more experiments where image pixels are the input.\n\n(4) The algorithm is not comparable to the state-of-the-art. Some representative papers have reported much better performances on the datasets used in this paper. It is suggested to refer to some recent papers in top conferences.']","[-70, 60, -50]","[-20, 80, 20]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several issues with the paper, including lack of technical contributions, inability to outperform hand-crafted methods, and unclear generalization. The phrase 'Technically, there is nothing new here' is particularly damning. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite critical and direct. The reviewer doesn't soften criticisms or offer much positive feedback, which comes across as somewhat impolite in academic discourse. The use of questions to point out flaws ('Why is that?', 'why you need to normalize...?') adds a slightly confrontational tone."", ""The sentiment score is 60 (positive) because the reviewer begins by highlighting the novelty and effectiveness of the proposed approach, noting its improvement on well-known datasets. They also praise the authors' effort in motivation and clear writing (P1, P2). However, the score is not higher due to the cons mentioned, such as potential lack of generalization and computational expense (C1, C2). The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms constructively. They use phrases like 'very nice effort' and 'I am somehow surprised' rather than harsh language. Even when pointing out drawbacks, the reviewer acknowledges that the authors themselves have noted some of these issues, showing a fair and considerate approach."", ""The sentiment score is -50 because the review primarily focuses on criticisms and areas for improvement, without much positive feedback. The reviewer questions the motivation, methodology, and comparability of the work, indicating a generally negative sentiment. However, it's not extremely negative as the reviewer does offer constructive suggestions. The politeness score is 20 because while the language is not overtly rude, it's also not particularly warm or polite. The reviewer uses neutral, professional language like 'It is suggested' and 'I am not sure why,' which avoids rudeness but doesn't go out of its way to be polite. The slight positive score is due to the constructive nature of the feedback and the use of phrases like 'It is interesting to see' which show some engagement with the work.""]"
"['In the paper, the authors proposed using GAN for anomaly detection.\nIn the method, we first train generator g_\\theta from a dataset consisting of only healthy data points.\nFor evaluating whether the data point x is anomalous or not, we search for a latent representation z such that x \\approx g_\\theta(z).\nIf such a representation z could be found, x is deemed to be healthy, and anomalous otherwise.\nFor searching z, the authors proposed a gradient-descent based method that iteratively update z.\nMoreover, the authors proposed updating the parameter \\theta of the generator g_\\theta.\nThe authors claimed that this parameter update is one of the novelty of their method, making it different from the method of Schlegl et al. (2017).\nIn the experiments, the authors showed that the proposed method attained the best AUC on MNIST and CIFAR-10.\n\nIn my first reading of the paper, I felt that the baselines in the experiments are too primitive.\nSpecifically, for KDE and OC-SVM, a naive PCA is used to reduce the data dimension.\nNowadays, there are several publicly available CNNs that are trained on large image datasets such as ImageNet.\nThen, one can use such CNNs as feature extractor, that will give better low dimensional expression of the data than the naive PCA.\nI believe that the performances of KDE and OC-SVM can be improved by using such feature extractors.\n\nAdditionally, I found that some well-known anomaly detection methods are excluded from the comparison.\nIn Emmott et al. (2013), which the authors referred as a related work, it was reported that Isolation Forest and Ensemble of GMMs performed well on several datasets (better than KDE and OC-SVM).\nIt would be essential to add these methods as baselines to be compared with the proposed method.\n\nOverall, I think the experimental results are far from satisfactory.\n\n\n### Response to Revision ###\nIt is interesting to see that the features extracted from AlexNet are not helpful for anomaly detection.\nIt would be interesting to see whether features extracted from middle layers are helpful or they are still useless.\nI greatly appreciate the authors for their extensive experiments as a response to my comments.\nHowever, I have decided to keep my score unchanged, as the additional experiments have shown that the performance of the proposed method is not significantly better than the other methods.\nIn particular, in MNIST, GMM performed better.', 'The paper is about doing anomaly detection for image data. The authors use a GAN based approach where it is trained in a standard way. After training is completed, the generator\'s latent space is explored to find a representation for a test image. Both the noise variable and generator model is updated using back propagation to achieve this. The paper is original, well written, easy to follow and presented ideas are interesting. \n\nStrengths:\n- anomaly detection for images is a difficult problem and the paper uses current state of the art in generative modeling (GAN) to perform anomaly detection.\n- experiments section includes non-parametric methods such as OC-SVM as well as deep learning methods including a recent GAN based approach and the results are promising. \n\nWeaknesses:\n - It is not clear why updating the generator during the anomaly detection helps. On evaluating on a large set of anomalies, the generator may run a risk of losing its ability to generate the original data if it is adjusted too much to the anomalies. The latent space of the generator no longer is the same that was achieved by training on the original data. I don\'t see how this is not a problem in the presented approach.\n- The experimental results on data with ground truth needs statistical significance tests to convince that the benefits are indeed significant. \n- It is not clear how the value of ""k"" (number of updates to the noise variable) was chosen and how sensitive it is to the performance. By having a large value of k, the reconstruction loss for an anomalous image may reduce to fall into the nominal category. How is this avoided?', 'Authors propose an anomaly detection scheme using GANs. It relies on a realistic assumption: points that are badly represented in the latent space of the generator are likely to be anomalous. Experiments are given in a classification and unsupervised context.\nIn the introduction, authors state that traditional algorithms ""often fail when applied to high dimensional objects"". Such claim should be supported by strong references as oc-svm or k-pca based anomaly detection algorithms (see Hoffman 2007) perform well in this context.\nOC-SVM is a well-known technique that gives similar performances: authors fail at convincing that there are advantages of using the proposed framework, which do not strongly differs from previously published AnoGAN.\nThe underlying assumption of the algorithm (points badly represented by GANs are likely to be anomalous) justifies the fact that anomalies should be detected by the algorithm (type-I error). What is the rationale behind the type-II error? Is it expected to be small as well? What happens with adversarial examples for instance?\n']","[-50, 50, -20]","[50, 75, 50]","[""The sentiment score is -50 because the reviewer expresses several criticisms and states that the 'experimental results are far from satisfactory.' However, they do acknowledge some positive aspects, such as the authors' extensive experiments in response to comments. The politeness score is 50 because the reviewer uses professional and respectful language throughout, even when expressing criticisms. They use phrases like 'I believe' and 'I think' to soften their critiques, and express appreciation for the authors' efforts. The reviewer maintains a constructive tone, offering specific suggestions for improvement rather than harsh criticism."", ""The sentiment score is 50 (moderately positive) because the reviewer starts with positive comments about the paper being original, well-written, and interesting. They also highlight strengths of the approach. However, they also point out significant weaknesses, which balances out the overall sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms as questions or suggestions rather than harsh statements. They use phrases like 'It is not clear' instead of more confrontational language, maintaining a professional and courteous tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the proposed method and its realistic assumption, they express several criticisms and doubts about the work. They question unsupported claims, point out similarities to existing methods without clear advantages, and raise concerns about the rationale behind certain aspects of the algorithm. The politeness score is moderately positive (50) as the reviewer maintains a professional and neutral tone throughout, avoiding harsh language or personal attacks. They use phrases like 'authors propose' and 'authors state' which are neutral, and frame their criticisms as suggestions or questions rather than direct attacks. The review is constructive in nature, pointing out areas for improvement without being overly negative or confrontational.""]"
"['This paper presents a new method for estimation of mutual information (MI) based on the Donsker-Varhan (DV) representation of KL-divergence. This representation requires the calculation of a supremum over a set of functions and a lower bound is achieved when a neural network is used for the maximisation of it. Computing the DV representation also requires evaluating expectations wrt to the distributions of interest, the proposed method uses Monte-Carlo estimates based on the empirical distributions.\n\nThe experiments evaluating the quality of the OMIE estimator for mutual information should be more thorough to make a point that OMIE beats competing estimators. The bivariate Gaussian case presented in Figure 1 is not a very relevant test case as estimating MI is especially difficult in higher dimensions. It would also be interesting to know the number of samples used as the ratio nbr dimensions/samples matters for estimation quality. The caption for Figure 2 mentions “bivariate Gaussians of dimension 50”, do the author mean two Gaussians of dimension 50 each?\n\nThe results of the proposed method on the swiss-roll dataset look good, however the authors only provide a comparison to a classic GAN where it seems more natural to compare with the other works on mode-dropping for GAN cited in the related works section. A comparison with InfoGAN and Dai et al. would be especially relevant to evaluate the effectiveness of OMIE. \n\nOn the application of OMIE to the Information Bottleneck (IB) problem:\nHow was the optimization of the objective exactly performed? How are gradients calculated? Is the reparametrisation trick used? More details should be provided on the results presented in table 3. Are the results obtained on the test set? What was the value of beta and to which values of I(X,Z) and I(Z,Y) does it correspond? Was the misclassification rate averaged over multiple runs?\n\nThe generalization to f-divergences is interesting but seems rather straightforward. \n\nThe second line of equation (20) does not make sense to me, it is not equivalent to the first line.\n\nThe methods proposed in Alemi et al. and Chalk et al. differ also in the way the bounds are estimated, not only in the choice of the marginal distribution.\n\nThe authors mention that strong consistency and convergence properties (page 3) are proven in the appendix, however I could not find them.', ""Summary\n======================================================================\nThe authors propose an estimator for the Shannon Mutual Information that is based on\nthe Donsker Varadhan lower bound. The idea is to choose an expressive class of functions\n(in this case, parametrized by a NN) and maximise a statistic. The authors present\nsome applications for the proposed estimator.\n\nWhile the idea of using the Donsker-Varadhan lower bound is interesting and potentially\nworkable, the theory is not strong and the experiments are far from compelling to warrant\nacceptance.\n\nDetailed Review\n======================================================================\n\nWhy is this called an online MI estimator? Nothing about the formalism or the estimator\nuses an online learning approach.\n\nDespite the authors' claims, the estimator does not come with any theoretical guarantees.\n- What is your definition of strongly consistent? Since the MI is a scalar quantity,\n  strong consistency is the same as (weak) consistency.\n- The proof is not given, and I don't think the proposed estimator would be consistent if\n  you use a fixed class of networks T. There is a necessarily a bias between the class of\n  functions the network can approximate and all bounded functions.\n\nMissing citations: There is a ton of recent work on estimating mutual information\nthat the authors have missed. These are a few but you should also look at papers that\ncite these and are cited by these.\n- Kandasamy et al 2015. Nonparametric von Mises estimators for entropies, divergences and\n  mutual informations.\n- Singh & Poczos 2016. Finite-sample analysis of fixed kNN density functional estimators.\n- Moon et al 2017. Ensemble estimation of Mutual Information. \n\nIn Algorithm 1, why do the samples have to be inside the loop? What is wrong with\napplying the last two lines on the same dataset? On the same note, do you really need\n\\bar{z}^(i) to be different from z^(i)?\n\nThe authors claims in the introduction that the non-parametric methods make critical\nassumptions while GANs do not is misleading. Many of the methods make assumptions for the\ntheoretical analysis - in practice, some, if not most of them work well even when the\nassumptions do not hold. Similarly, if you want to prove something about GANs you\nprobably have to make assumptions too.\n\nExperiments:\nThe authors present 4 use cases. All of them are toy settings and none of them make a\ncompelling case for the proposed estimator.\n- In the GAN setting, I am failing to see why one would use a MI regularizer over an\n  entropic regularizer. It seems like what you need is entropy, and it is not clear what\n  happens to the conditional entropy term when you maximize MI.\n- Section 4.3: The bound on the reconstruction error is dropping a KL(p(z)||q(z)) term\n  and the authors don't really discuss how lose this is.\n- The authors make claims about scalability with n and d but none of the experiments\n  show the evaluation times compared to simpler estimators.\n\nMinor\n- I thought there were several unnecessary tangential discussions that didn't really add\n  much to the paper. For instance, Section 3.3 was unnecessary given that all the\n  experiments solely focused on the Shannon case. The para after theorem 1 on the\n  compression lemma doesn't add much. Even the definitions of the Shannon MI and Theorem\n  1 could have been stated without appealing to measure theory constructs.\n- Figure 1: This is perhaps not the cleanest way to present this graph. Perhaps consider\n  plotting the error in a log-scale might work better.\n\n"", 'The authors present an estimator for the mutual information (MI) based on the Donsker-Varadhan representation for the KL divergence and its generalization to arbitrary f-divergences by Ruderman et al. While that last work introduced an estimator based on optimization over the unit ball in an RKHS, the current work propose to use a parametric function class given by a neural network (I\'d suggest that the authors make this point more explicit, as currently it\'s not totally clear what their actual contribution is and how their work compares to the prior art they cite). The authors show that such an estimator can be used to train models with less mode-dropping in adversarial models. \n\nThe work is quite straightforward, but improves over similar work in the GAN space by Nowozin et al. by using Ruderman\'s tighter variational representation instead of Nguyen\'s one.\n\nThe paper contains many typos and grammatical errors and the authors should do an exhaustive proof-reading. More problematic is that, right after eq. 10, the authors mention ""We show in the Appendix that OMIE has the desirable strong consistency and convergence properties"". However, the appendix doesn\'t contain such a proof. Is it missing from the submitted version? I don\'t think that such a consistency proof is strictly necessary for a paper like this, but for the review to be accurate I need to see the proof. Since I can\'t find it, I assume it does not exist. In that case, the authors should give less emphasis to the MI estimator itself and more to the empirical properties and applications.\n\nThe authors present some experiments comparing different estimators of MI applied to synthetic data. Figure 1 is hard to read, I suggest the authors try to come up with a more legible plot. Figure 2 is also a bit surprising, why show error for 50 dimensions but estimates for 2 dimensions? Since these experiments are quick to run, it would be helpful to get more information on how the gap between the methods change as the dimensionality increases (e.g. a surface plot with d and # of iterations on the x and y axes). Also it would be highly beneficial to compare with the method in Ruderman at al., so that people interested in MI estimation but who don\'t plan on using the estimator as part of a neural net architecture can get some idea on how the inductive bias of NNs compare to RKHS.\n\nIn the caption to Fig. 3 the authors state ""The OMIEGAN generator learns a distribution with a high amount of structured noise"", which I find hard to understand. Probably the authors can be a bit more precise than saying ""structured noise"".\n\nI would recommend dropping the Information Bottleneck section to focus on showing more convincingly the impact of OMIE in GANs. The experiments section currently looks rushed and lacking in depth.\n\nIn summary, this work provides value by introducing a (previously known) superior f-divergence variational representation to the GAN community. The mode-collapse prevention via MI maximisation is also interesting and deserves more experimental attention to make the paper stronger.']","[-20, -60, -20]","[60, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The results of the proposed method on the swiss-roll dataset look good'), they primarily focus on areas for improvement and missing information. They request more thorough experiments, additional comparisons, and clarification on several points, indicating that the paper needs significant work.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'It would be interesting to know' and 'More details should be provided', which are polite ways of requesting additional information. The reviewer also acknowledges positive aspects of the work before suggesting improvements, which is a courteous approach to criticism. However, the score is not higher because the review is primarily focused on critiquing the paper rather than offering praise, and some statements are quite direct (e.g., 'The second line of equation (20) does not make sense to me')."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that 'the theory is not strong and the experiments are far from compelling to warrant acceptance.' They also point out several significant issues with the paper, including missing citations, misleading claims, and unconvincing experiments. However, the score is not at the extreme negative end because the reviewer does acknowledge some positive aspects, such as the 'interesting and potentially workable' idea of using the Donsker-Varadhan lower bound. The politeness score is 20 because while the reviewer maintains a professional tone throughout, they are quite direct in their criticisms. They use phrases like 'I don't think,' 'I am failing to see why,' and 'The authors make claims about... but none of the experiments show,' which are polite but firm ways of expressing disagreement. The reviewer also offers constructive suggestions for improvement, such as considering alternative ways to present data and including missing citations, which adds to the politeness of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some value in the work, they point out several issues and areas for improvement. The review starts with a neutral tone but becomes more critical as it progresses, mentioning typos, missing proofs, hard-to-read figures, and suggesting dropping a section. However, it ends on a somewhat positive note, recognizing the work's value and potential.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I'd suggest,' 'it would be helpful,' and 'I would recommend,' which are polite ways of offering criticism. The reviewer also acknowledges the work's strengths and potential value, which contributes to the overall politeness. However, the directness of some criticisms prevents the score from being higher.""]"
"['This paper proposes to jointly model computed tomography reconstruction and lesion detection in the lung, training the mapping from raw sinogram to detection outputs in an end-to-end manner. In practice, such a mapping is computed separately, without regard to the task for wich the data is to be used. Because such a mapping loses information, optimizing such a mapping jointly with the task should preserve more information that is relevant to the task. Thus, using raw medical image data should be useful for lesion detection in CT as well as most other medical image analysis tasks.\n\n\nStyle considerations:\n\nThe work is adequately motivated and the writing is generally clear. However, some phrases are awkward and unclear and there are occasional minor grammar errors. It would be useful to ask a native English speaker to polish these up, if possible. Also, there are numerous typos that could nonetheless be easily remedied with some final proofreading. Generally, the work is well articulated with sound structure but needs polish.\n\nA few other minor style points to address:\n- ""g"" is used throughout the paper for two different networks and also to define gradients - if would be more clear if you would choose other letters.\n- S3.3, p. 7 : reusing term ""iteration""; clarify\n- fig 10: label the columns in the figure, not in the description\n- fig 11: label the columns in the figure with iterations\n- fig 8 not referenced in text\n\n\nQuestions:\n\n1. Before fine-tuning, were the reconstruction and detection networks trained end-to-end (with both L2 loss and cross-entropy loss) or were they trained separately and then joined during fine-tuning?\n(If it is the former and not the latter, please make that more clear in the text. I expect that it was indeed the former; in case that it was not, I would expect fully end-to-end training in the revision.)\n\n2. Please confirm: during the fine-tuning phase of training, did you use only the cross-entropy loss and not the L2 loss?\n\n3a. From equation 3 to equation 4 (on an iteration of reconstruction), the network g() was dropped. It appears to replace the diagonal of a Hessian (of R) which is probably a conditioning term. Have you tried training a g() network? Please discuss the ramifications of removing this term.\n\n3b. Have you tracked the condition number of the Jacobian of f() across iterations? This should be like tracking the condition number of the Hessian of R(x).\n\n4. Please discuss: is it better to replace operations on R() with neural networks rather than to replace R()? Why?\n\n5. On page 5, you write ""masks for lung regions were pre-calculated"". Were these masks manual segmentations or created with an automated method?\n\n6. Why was detection only targetted on ""non-small nodules""? Have you tried detecting small nodules?\n\n7. On page 11, you state: ""The tissues in lung had much better contrast in the end-to-end network compared to that in the two-step network"". I don\'t see evidence to support that claim. Could you demonstrate that?\n\n8. On page 12, relating to figure 11, you state:\n\n""Whereas both methods kept similar structural component, the end-to-end method had more focus on the edges and tissues inside lung compared to the two-step method. As observed in figure 11(b), the structures of the lung tissue were much more clearer in the end-to-end networks. This observation indicated that sharper edge and structures were of more importance for the detection network than the noise level in the reconstructed images, which is in accordance with human perceptions when radiologists perform the same task.""\n\nHowever, while these claims appear intuitive and such results may be expected, they are not backed up by figure 11. Looking at the feature map samples in this figure, I could not identify whether they came from different populations. I do not see the evidence for ""more focus on the edges and tissues inside lung"" for the end-to-end method in fig 11. It is also not obvious whether indeed ""the structures of the lung tissue were much more clearer"" for the end-to-end method, in fig 11. Can you clarify the evidence in support of these claims? \n\n\nOther points to address:\n\n1. Please report statistical significance for your results (eg. in fig 5b, in the text, etc.). Also, please include confidence intervals in table 2.\n\n2. Although cross-entropy values, detection metrics were not (except for the ROC curve with false positives and false negatives). Please compute: accuracy, precision, and recall to more clearly evaluate detection performance.\n\n3a. ""Abnormality detection"" implies the detection of anything that is unusual in the data. The method you present targets a very specific abnormality (lesions). I would suggest changing ""abnormality detection"" to ""lesion detection"".\n\n3b. The title should also be updated accordingly. Considering also that the presented work is on a single task (lesion detection) and a single medical imaging modality (CT), the current title appears overly broad. I would suggest changing it from ""End-to-End Abnormality Detection in Medical Imaging"" -- possibly to something like ""End-to-End Computed Tomography for Lesion Detection"".\n\n\nConclusion:\n\nThe motivation of this work is valid and deserves attention. The implementation details for modeling reconstruction are also valuable. It is interesting to see improvement in lesion detection when training end-to-end from raw sinogram data.  However, while lung lesion detection is the only task on which the utility of this method is evaluated, detection improvement appears modest. This work would benefit from additional experimental results or improved analysis and discussion.', 'The authors present an end to end training of a CNN architecture that combines CT image signal processing and image analysis. This is an interesting paper. Time will tell whether a disease specific signal processing will be the future of medical image analysis, but - to the best of my knowledge - this is one of the first attempts to do this in CT image analysis, a field that is of significance both to researchers dealing with image reconstruction (denoising, etc.) and image analysis (lesion detection).  As such I would be positive about the topic of the paper and the overall innovation it promises both in image acquisition and image processing, although I would share the technical concerns pointed out by Reviewer2, and the authors would need good answers to them before this study would be ready to be presented. ', 'The paper proposes a DNN for patch-based lung nodule detection, directly from the CT projection data. The two-component network, comprising of the reconstruction network and the nodule detection network, is trained end-to-end. The trained network was validated on a simulated dataset of 1018\tlow-dose chest CT images. It is shown that end-to-end training produces better results compared to a two-step approach, where the reconstruction DNN was trained first and the detection DNN was trained on the reconstructed images. \n\nPros\n\nIt is a well written paper on a very important problem. It shows the promise of DNNs for solving difficult inverse problems of great importance. It shows encouraging results as well. \n\nCons\n\nThe contributions seem incremental, not properly enunciated, or appropriately validated.\n\nThe putative contributions of the paper can be \n(a) Directly solving the target problem from raw sensory data without first solving an inversion problem\n(b) (Directly) solving the lung nodule detection problem using a DNN. \n(c) A novel reconstruction DNN as a component of the above pipeline.\n(d) A novel detection network as a component of the above pipeline.\n\nLet\'s take them one by one:\n\n(a) As pointed out by authors, this is in the line of work being done in speech recognition, self-driving cars, OCR etc. and is a good motivation for the work but not a contribution. It\'s application to this problem can require significant innovation which is not the case as components have been explored before and there is no particular innovation involved in using them together in a pipeline either.\n\n(c) As also pointed by the authors, there are many previous approaches - Adler & Oktem (2017), Hammernik et al (2017) etc. among others. Another notable reference (not cited) is Jin et al. ""Deep Convolutional Neural Network for Inverse Problems in Imaging."" arXiv preprint arXiv:1611.03679 (2016). These last two (and perhaps others) train DNNs to learn unrolled iterative methods to reconstruct the CT image. The approach proposed in the paper is not compared by them (and perhaps others), neither at a conceptual level nor experimentally. So, this clearly is not the main contribution of the paper.\n\n(d) Similarly, there is nothing particularly novel about the detection network nor the way it is used. \n\nThis brings us to (b). The proposed approach to solve this problem may indeed by novel (I am not an expert in this application area.), but considering that there is a considerable body of work on this problem, the paper provides not comparative evaluation of the proposed approach to published ones in the literature. It just provides an internal comparison of end-to-end training vis-a-vis two step training. \n\nTo summarize, the contributions seem incremental, not properly enunciated, or appropriately validated.']","[20, 50, -50]","[60, 75, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's valid motivation, valuable implementation details, and interesting results. However, they also point out several areas for improvement, including modest detection improvement and the need for additional experimental results or improved analysis. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases their comments as suggestions or questions rather than demands. They also acknowledge the paper's strengths before diving into areas for improvement. The reviewer maintains a professional tone, avoiding harsh criticism while still providing thorough feedback."", ""The sentiment score is 50 (moderately positive) because the reviewer describes the paper as 'interesting' and expresses positivity about the topic and innovation. However, they also mention technical concerns that need to be addressed, tempering the overall positivity. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the potential significance of the work and framing criticisms constructively. They use phrases like 'to the best of my knowledge' and 'I would be positive about', which demonstrate courtesy and consideration for the authors' work."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('well written paper', 'shows promise', 'encouraging results'), the overall tone is critical. The reviewer spends more time detailing the cons, stating that the contributions seem 'incremental, not properly enunciated, or appropriately validated'. This indicates a predominantly negative sentiment, though not extremely so due to the recognition of some positive aspects. The politeness score is 50 because the reviewer uses professional and respectful language throughout. They acknowledge the paper's strengths before presenting criticisms, and phrase their concerns as observations rather than attacks (e.g., 'The contributions seem incremental' rather than 'The authors failed to make significant contributions'). However, the politeness doesn't reach the highest levels as the critique is still quite direct and doesn't include many softening phrases or expressions of appreciation for the authors' efforts.""]"
"[""This paper offers an extension to density estimation networks that makes them better able to learn dependencies between covariates of a distribution.\n\nThis work does not seem particularly original as applying transformations to input is done in most AR estimators.\n\nUnfortunately, it's not clear if the work is better than the state-of-the-art. Most results in the paper are comparisons of toy conditional models. The paper does not compare to work for example from Papamakarios et al. on the same datasets. The one Table that lists other work showed LAM and RAM to be comparable. Many of the experiments are on synthetic results, and the paper would have benefited from concentrating on more real-world datasets."", 'The authors propose to combine nonlinear bijective transformations and flexible density models for density estimation. In terms of bijective change of variables transformations, they propose linear triangular transformations and recurrent transformations. They also propose to use as base transformation an autoregressive distribution with mixture of gaussians emissions.\nComparing with the Masked Autoregressive Flows (Papamakarios et al., 2017) paper, it seems that the true difference is using the linear autoregressive transformation (LAM) and recurrent autoregressive transformation (RAM), already present in the Inverse Autoregressive Flow (Kingma et al., 2016) paper they cite, instead of the masked feedforward architecture used Papamakarios et al. (2017).\nGiven that, the most important part of the paper would be to demonstrate how it performs compared to Masked Autoregressive Flows. A comparison with MAF/MADE is lacking in Table 1 and 2. Nonetheless, the comparison between models in flexible density models, change of variables transformations and combinations of both remain relevant.\n\nDiederik P. Kingma, Tim Salimans, Rafal Józefowicz, Xi Chen, Ilya Sutskever, Max Welling: Improving Variational Autoencoders with Inverse Autoregressive Flow. NIPS 2016\nGeorge Papamakarios, Theo Pavlakou, Iain Murray: Masked Autoregressive Flow for Density Estimation. NIPS 2017\n', 'This paper is well constructed and written. It consists of a number of broad ideas regarding density estimation using transformations of autoregressive networks. Specifically, the authors examine models involving linear maps from past states (LAM) and recurrence relationships (RAM). \n\nThe critical insight is that the hidden states in the LAM are not coupled allowing considerable flexibility between consecutive conditional distributions. This is at the expense of an increased number of parameters and a lack of information sharing. In contrast, the RAM transfers information between conditional densities via the coupled hidden states allowing for more constrained smooth transitions.\n\nThe authors then explored a variety of transformations designed to increase the expressiveness of LAM and RAM. The authors importantly note that one important restriction on the class of transformations is the ability to evaluate the Jacobian of the transformation efficiently. A composite of transformations coupled with the LAM/RAM networks provides a highly expressive model for modelling arbitrary joint densities but retaining interpretable conditional structure.\n\nThere is a rich variety of synthetic and real data studies which demonstrate that LAM and RAM consistently rank amongst the top models demonstrating potential utility for this class of models.\n\nWhilst the paper provides no definitive solutions, this is not the point of the work which seeks to provide a description of a general class of potentially useful models.\n\n\n']","[-50, 20, 80]","[-20, 50, 50]","[""The sentiment score is -50 because the review starts with a neutral statement about the paper's contribution, but then becomes increasingly critical. The reviewer states that the work 'does not seem particularly original' and expresses doubt about its superiority to state-of-the-art methods. The criticism of the paper's experimental focus and lack of comparison to relevant work indicates a generally negative sentiment. The politeness score is -20 because while the language is not overtly rude, it is quite direct and lacks softening phrases or positive reinforcement. The use of words like 'unfortunately' and the blunt criticism without much constructive feedback or acknowledgment of the paper's strengths contribute to a somewhat impolite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the relevance of the paper's comparisons and the proposed methods. However, they also point out a significant limitation in the lack of comparison with Masked Autoregressive Flows, which prevents a higher positive score. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language without harsh criticism. They objectively state the paper's contributions and limitations, and provide constructive feedback by suggesting a comparison with MAF/MADE. The tone is respectful and focused on the scientific content rather than personal judgments."", ""The sentiment score is 80 (positive) because the review begins with praise, stating the paper is 'well constructed and written'. It highlights the 'critical insight' of the authors and notes the 'rich variety' of studies demonstrating the utility of the models. The reviewer acknowledges the paper's contribution to providing 'a general class of potentially useful models'. The politeness score is 50 (somewhat polite) as the language is professional and respectful throughout, without being overly formal or effusive. The reviewer offers constructive observations and avoids harsh criticism, maintaining a neutral to positive tone. The use of phrases like 'importantly note' and 'potential utility' indicate a considerate approach to feedback.""]"
"[""The paper presents a method for predicting future video frames. The method is based on Villegas et al. (2017), with the main difference being that no ground truth pose is needed to train the network.\n\nThe novelty of the method is limited. It seems that there is very little innovation in terms of network architecture compared to Villegas et al. The difference is mainly on how the network is trained. But it is straightforward to train the architecture of Villegas et al. without pose -- just use any standard choice of loss that compares the predicted frame versus the ground truth frame. I don't see what is non-trivial or difficult about not using pose ground truth in training.\n\nOverall I think the contribution is not significant enough. \n"", 'The paper treats the interesting problem of long term video prediction in complex video streams. I think the approach of adding more structure to their representation before making longer term prediction is also a reasonable one. Their approach combines an RNN that predicts an encoding of scene and then generating an image prediction using a VAN (Reed et al.). They show some results on the Human3.6M and the Robot Push dataset. \n\nI find the submission lacking clarity in many places. The main lack of clarity source I think is about what the contribution is. There are sparse mentions in the introduction but I think it would be much more forceful and clear if they would present VAN or Villegas et al method separately and then put the pieces together for their method in a separate section. This would allow the author to clearly delineate their contribution and maybe why those choices were made. Also the use of hierarchical is non-standard and leads to confusion I recommend maybe ""semantical"" or better ""latent structured"" instead. Smaller ambiguities in wording are also in the paper : e.g. related work -> long term prediction ""in this work"" refers to the work mentioned but could as well be the work that they are presenting.  \n\nI find some of the claims not clearly backed by a thorough evaluation and analysis. Claiming to be able to produce encodings of scenes that work well at predicting many steps into the future is a very strong claim. I find the few images provided very little evidence for that fact. I think a toy example where this is clearly the case because we know exactly the factors of variations and they are inferred by the algorithm automatically or some better ones are discovered by the algorithm, that would make it a very strong submission. Reed et al. have a few examples that could be adapted to this setting and the resulting representation, analyzed appropriately, would shed some light into whether this is the right approach for long term video prediction and what are the nobs that should be tweaked in this system. \n\nIn the current format, I think that the authors are on a good path and I hope my suggestions will help them improve their submission, but as it stands I recommend rejection from this conference.', 'The paper presents a method for hierarchical future frame prediction in monocular videos. It builds upon the recent method of Villegas et al. 2017, which generates future RGB frames in two stages: in the first stage, it predicts a human body pose sequence, then it conditions on the pose sequence to predict RGB content, using an image analogy network. This current paper, does not constrain the first stage (high level) prediction to be human poses, but instead it can be any high level representation. Thus, the method does not require human annotations.\n\nThe method has the following two sub-networks:\n1) An image encoder, that given an RGB image, predicts a deep feature encoding. \n2) An LSTM predictor, that conditioned on the last observed frame\'s encoding,  predicts future high level structure p_t. Once enough frames are generated though, it conditions on its own predictions. \n3) A visual analogy network (VAN), that given predicted high level structure p_t, it predicts the pixel image I_t, by applying the transformation from the first to tth frame, as computed by the vector subtraction of the corresponding high level encodings (2nd equation of the paper). VAN is trained to preserve parallelogram relationships in the joint RGB image and high level structure embedding.\n\nThe authors experiment with  many different neural network connectivities, e.g., not constraining the predicted high level structure to match the encoder\'s outputs, constraining the predicted high level structure to match the encoder\'s output (EPEV), and training together the VAN  and predictor so that VAN can tolerate mistakes of the predictor. Results are shown in H3.6m and the pushobject datasets, and are compared against the method of Villegas et all (INDIVIDUAL). The conclusion seems to be that not constraining the predicted high level structure to match the encoder’s output, but biasing the encoder’s output in the observed frames to represent ground-truth pose information, gives the best results. \n\nPros\n1) Interesting alternative training schemes are tested\n\nCons:\n1)Numerous English mistakes, e.g.,  \'\'an intelligent agents"", \'\'we explore ways generate"" etc.\n\n2) Equations are not numbered (and thus is hard to refer to them.) E.g., i do not understand the first equation, shouldn’t it be that e_{t-1} is always fixed and equal to the encoding of the last observed (not predicted) frame? Then the subscript cannot be t-1.\n\n3) In H3.6M, the results are only qualitative. The conclusions from the paper are uncertain, partly  due to the difficulty of evaluating the video prediction results.\n\n\nGiven the difficulty of assessing the experimental results quantitatively (one possibility to do so is asking a set of people of which one they think is the most plausible video completion), and given the limited novelty of the paper, though interesting alternative architectures are tried out, it may not be suitable to be part of  ICLR proceedings as a conference paper.  \n']","[-70, -50, -50]","[0, 50, 50]","[""The sentiment score is -70 because the reviewer expresses significant criticism and doubts about the paper's novelty and contribution. They state that 'the novelty of the method is limited' and 'the contribution is not significant enough.' The overall tone is negative, though not entirely dismissive. The politeness score is 0 (neutral) because the reviewer's language is direct and professional without being overtly polite or rude. They present their criticisms in a matter-of-fact manner without using harsh language or personal attacks, but also without softening their critique with polite phrases or positive reinforcement."", ""The sentiment score is -50 because while the reviewer acknowledges the interesting problem and reasonable approach, they ultimately recommend rejection. The review points out several shortcomings in clarity and lack of thorough evaluation, indicating a generally negative sentiment. However, it's not extremely negative as the reviewer sees potential and offers constructive feedback. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positive aspects and offering suggestions for improvement. They use phrases like 'I think' and 'I hope my suggestions will help,' which are polite ways to express criticism. The reviewer maintains a professional tone without being overly formal or informal."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('Interesting alternative training schemes are tested'), they ultimately recommend against accepting the paper for the conference proceedings. The review lists several cons and expresses uncertainty about the results, indicating a generally negative sentiment. However, it's not extremely negative, as the reviewer does recognize some merits of the work. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, offering constructive criticism without using harsh language. They present their concerns objectively and provide specific suggestions for improvement. The reviewer also acknowledges the positive aspects of the work before discussing the limitations, which is a polite approach to giving feedback.""]"
"['This paper introduces a new design of kernels in convolutional neural networks. The idea is to have sparse but complementary kernels with predefined patterns, which altogether cover the same receptive field as dense kernels. Because of the sparsity of such kernels, deeper or wider networks can be designed at the same computational cost as networks with dense kernels.\n\nStrengths:\n- The complementary kernels come at no loss compare to standard ones\n- The resulting wider networks can achieve better accuracies than the original ones\n\nWeaknesses:\n- The proposed patterns are clear for 3x3 kernels, but no solution is proposed for other dimensions\n- The improvement over the baseline is not very impressive\n- There is no comparison against other strategies, such as 1xk and kx1 kernels (e.g., Ioannou et al. 2016)\n\nDetailed comments:\n- The separation into + and x patterns is quite clear for 3x3 kernels. However, two such patterns would not be sufficient for 5x5 or 7x7 kernels. This idea would have more impact if it generalized to arbitrary kernel dimensions.\n\n- The improvement over the original models are of the order of less than 1 percent. I understand that such improvements are not easy to achieve, but one could wonder if they are not due to the randomness of initialization/mini-batches. It would be more meaningful to report average accuracies and standard deviations over several runs of each experiment.\n\n- Section 4.4 briefly discusses the comparison with using 3x1 and 1x3 kernels, mentioning that an empirical comparison is beyond the scope of this paper. To me, this comparison is a must. In fact, the discussion in this section is not very clear to me, as it mentions additional experiments that I could not find (maybe I misunderstood the authors). What I would like to see is the results of a model based on the method of Ioannou et al, 2016 with the same number of FLOPS.\n\n- In Section 2, the authors review ideas of so-called random kernel sparsity. Note that the work of Wen et al., 2016, and that of Alvarez & Salzmann, NIPS 2016, do not really impose random sparsity, but rather aim to cancel out entire kernels, thus reducing the size of the model and not requiring implementation overhead. They also do not require pre-training and re-training, but just a single training procedure. Note also that these methods often tend not to decrease accuracy, but rather even increase it (by a similar magnitude to that in this paper), for a more compact model.\n\n- In the context of random sparsity, it would be worth citing the work of Collins & Kohli, 2014, Memory Bounded Deep Convolutional Networks.\n\n- I am not entirely convinced by the discussion of the grouped sparsity method in Section 3.1. In fact, the order of the channels is arbitrary, since the kernels are learnt. Therefore, it seems to me that they could achieve the same result. Maybe the authors can clarify this?\n\n- Is there a particular reason why the central points appears in both complementary kernels (+ and x)?\n\n- Why did the authors change the training procedure of ResNets slightly compared to the original paper, i.e., 50k training images instead of 45k training + 5k validation? Did the baseline (original model) reported here also use 50k? What would the results be with 45k?\n\n- Fig. 5 is not entirely clear to me. What was the width of each layer? The original one or the modified one?\n\n- It would be interesting to report the accuracy of a standard ResNet with 1.325*width as a comparison, as well as the runtime of such a model.\n\n- In Table 4, I find it surprising that there is an actual speedup for the model with larger width. I would have expected the same runtime. How do the authors explain this? \n', '\n\nThis paper presented interesting ideas to reduce the redundancy in convolution kernels. They are very close to existing algorithms.\n\n(1)\tThe SW-SC kernel (Figure 2 (a)) is an extension of the existing shaped kernel (Figure 1 (c)).\n(2)\tThe CW-SC kernel (Figure 2 (c)) is very similar to interleaved group convolutions. The CW-SC kernel can be regarded as a redundant version of interleaved group convolutions [1]. \n\nI would like to see more discussions on the relation to these methods and more strong arguments for convincing reviewers to accept this paper. \n\n[1] Interleaved Group Convolutions. Ting Zhang, Guo-Jun Qi, Bin Xiao, and Jingdong Wang. ICCV 2017. http://openaccess.thecvf.com/content_ICCV_2017/papers/Zhang_Interleaved_Group_Convolutions_ICCV_2017_paper.pdf', 'Summary:\nThis paper proposed a sparse-complementary convolution as an alternative to the convolution operation in deep networks. In this method, two new types of kernels are developed, namely the spatial-wise and channel-wise sparse-complementary kernels. The authors argue that the proposed kernels are able to cover the same receptive field as the regular convolution with almost half the parameters. By adding more filters or layers in the model while keeping the same FLOPs and parameters, the models with the proposed method outperform the regular convolution models. The paper is easy to follow and the idea is interesting. However, the novelty of the paper is limited and the experiments are not sufficient.\n\nStrengths:\n1. The authors proposed the sparse-complementary convolution to cover the same receptive field as the regular convolution. \n\n2. The authors implement the proposed sparse-complementary convolution on NVIDIA GPU and achieved competitive speed under the same computational load to regular convolution.\n\n3. The authors demonstrated that, given the same resource budget, the wider networks with the proposed method are more efficient than the deeper networks due to the nature of GPU parallel mechanism.\n\nWeak points:\n\n1. The novelty of this paper is limited. The main idea is to design complementary kernels that cover the same receptive field as the regular convolution. However, the performance improvement is marginal and may come from the benefit of wide networks rather than the proposed complementary kernels. Moreover, the experiments are not sufficient to support the arguments. For example, how is the performance of a model containing SW-SC or CW-SC without deepening or widening the networks? Without such experiment, it is unclear whether the improved performance comes from the sparse-complementary kernels or the increased number of kernels.\n\n2. The relationship between the proposed spatial-wise kernels and the channel-wise kernels is not very clear. Which kernel is better and how to choose between them in a deep network? There is no experimental proof in the paper.\n\n3. The proposed two kernels introduce sparsity in the spatial and channel dimension, respectively. The two methods are used separately. Is it possible to combine them together?\n\n4. The proposed method only considers the “+-shape” and “x-shape” sparse pattern. Given the same receptive field with multiple complementary kernels, is the kernel shape important for the training? There is no experimental result to verify this.\n\n5. As mentioned in the paper, there are many methods which introduce sparsity in the convolution layer, such as “random kernels”, “low-rank approximated kernels” and “mixed-shape kernels”. However, there is no experimental comparison with these methods.\n\n6. In the paper, the author mentioned another sparse-complementary baseline (sc-seq), which applies sparse kernels sequentially. It yields smaller receptive field than the proposed method when the model depth is very small. Indeed, when the model goes deeper, the receptive field becomes very close to that of the proposed method. In the experiments, it is strange that this method can also achieve comparable or better results. So, what is the advantage of the proposed “sc” method compared to the “sc-seq” method?\n\n\n8. Figure 5 is hard to understand. This figure only shows that training shallower networks is more effective than training the deeper networks on GPU. However, it does not mean training the wider networks is more efficient than training the deeper ones.\n']","[-20, -20, -30]","[60, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they also point out several weaknesses and areas for improvement. The review is more critical than positive, with phrases like 'The improvement over the baseline is not very impressive' and 'To me, this comparison is a must.' However, it's not entirely negative, as the reviewer does mention some strengths. The politeness score is moderately positive (60) because the reviewer uses professional and respectful language throughout. They phrase criticisms as suggestions or questions rather than direct attacks, using phrases like 'It would be more meaningful to...' and 'I am not entirely convinced by...'. The reviewer also provides detailed feedback and explanations for their comments, which is a polite and constructive approach to peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper presents 'interesting ideas', they also point out that these ideas are 'very close to existing algorithms' and request 'more strong arguments' to accept the paper. This suggests some reservations about the novelty and convincingness of the work. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the interesting aspects of the work and framing their criticisms as requests for more information rather than outright dismissals. They use phrases like 'I would like to see' which maintains a constructive tone. The review avoids harsh or rude language, maintaining a professional and courteous tone throughout."", ""The sentiment score is -30 because while the reviewer acknowledges some strengths of the paper (e.g., 'The paper is easy to follow and the idea is interesting'), they also point out significant weaknesses and limitations. The overall tone suggests that the reviewer is not fully convinced by the paper's contributions. The politeness score is 60 because the reviewer uses respectful language throughout, acknowledging positive aspects before presenting criticisms, and frames weaknesses as suggestions for improvement rather than harsh criticisms. The reviewer maintains a professional tone, using phrases like 'The authors...' and 'It is unclear whether...' instead of more direct or confrontational language.""]"
"['This paper introduces a comparison between several approaches for evaluating GANs. The authors consider the setting of a pre-trained image models as generic representations of generated and real images to be compared. They compare the evaluation methods based on five criteria termed disciminability, mode collapsing and mode dropping, sample efficiency,computation efficiency, and robustness to transformation. This paper has some interesting insights and a few ideas of how to validate an evaluation method. The topic is an important one and a very difficult one. However, the work has some problems in rigor and justification and the conclusions are overstated in my view.\n\nPros\n-Several interesting ideas for evaluating evaluation metrics are proposed\n-The authors tackle a very challenging subject\n\nCons\n-It is not clear why GANs are the only generative model considered\n-Unprecedented visual quality as compared to other generative models has brought the GAN to prominence and yet this is not really a big factor in this paper.\n-The evaluations rely on using a pre-trained imagenet model as a representation. The authors point out that different architectures yield similar results for their analysis, however it is not clear how the biases of the learned representations affect the results. The use of learned representations needs more rigorous justification\n-The evaluation for discriminative metric, increased score when mix of real and unreal increases, is interesting but it is not convincing as the sole evaluation for “discriminativeness” and seems like something that can be gamed. \n- The authors implicitly contradict the argument of Theis et al against monolithic evaluation metrics for generative models, but this is not strongly supported.\n\nSeveral references I suggest:\nhttps://arxiv.org/abs/1706.08500 (FID score)\nhttps://arxiv.org/abs/1511.04581 (MMD as evaluation)\n', 'The paper describes an empirical evaluation of some of the most common metrics to evaluate GANs (inception score, mode score, kernel MMD, Wasserstein distance and LOO accuracy). \n\nThe paper is well written, clear, organized and easy to follow.\n\nGiven that the underlying application is image generation, the authors move from a pixel representation of images to using the feature representation given by a pre-trained ResNet, which is key in their results and further comparisons. They analyzed discriminability, mode collapsing and dropping, robustness to transformations, efficiency and overfitting. \n\nAlthough this work and its results are very useful for practitioners, it lacks in two aspects. First, it only considers a single task for which GANs are very popular. Second, it could benefit from a deeper (maybe theoretical analysis) of some of the questions. Some of the conclusions could be further clarified with additional experiments (e.g., Sec 3.6 ‘while the reason that RMS also fails to detect overfitting may again be its lack of generalization to datasets with classes not contained in the ImageNet dataset’).\n', 'Thanks for an interesting paper. \n\nThe paper evaluates popular GAN evaluation metrics to better understand their properties. The ""novelty"" of this paper is a bit hard to assess. However, I found their empirical evaluation and experimental observations to be very interesting. If the authors release their code as promised, the off-the-shelf tool would be a very valuable contribution to the GAN community. \n\nIn addition to existing metrics, it would be useful to add Frechet Inception Distance (FID) and Multi-scale structural similarity (MS-SSIM). \n\nHave you considered approximations to Wasserstein distance? E.g. Danihelka et al proposed using an independent Wasserstein critic to evaluate GANs: \nComparison of Maximum Likelihood and GAN-based training of Real NVPs\nhttps://arxiv.org/pdf/1705.05263.pdf\n\nHow sensitive are the results to hyperparameters? It would be interesting to see some sensitivity analysis as well as understand the correlations between different metrics for different hyperparameters (cf. Appendix G in https://arxiv.org/pdf/1706.04987.pdf)\n\nDo you think it would be useful to compare other generative models (e.g. VAEs) using these evaluation metrics? Some of the metrics don\'t capture perceptual similarity, but I\'m curious to hear what you think. \n', 'In the paper, the authors discuss several GAN evaluation metrics.\nSpecifically, the authors pointed out some desirable properties that GANS evaluation metrics should satisfy.\nFor those properties raised, the authors experimentally evaluated whether existing metrics satisfy those properties or not.\nSection 4 summarizes the results, which concluded that the Kernel MMD and 1-NN classifier in the feature space are so far recommended metrics to be used.\n\nI think this paper tackles an interesting and important problem, what metrics are preferred for evaluating GANs.\nIn particular, the authors showed that Inception Score, which is one of the most popular metric, is actually not preferred for several reasons.\nThe result, comparing data distributions and the distribution of the generator would be the preferred choice (that can be attained by Kernel MMD and 1-NN classifier), seems to be reasonable.\nThis would not be a surprising result as the ultimate goal of GAN is mimicking the data distribution.\nHowever, the result is supported by exhaustive experiments making the result highly convincing.\n\nOverall, I think this paper is worthy for acceptance as several GAN methods are proposed and good evaluation metrics are needed for further improvements of the research field.\n']","[-20, 60, 70, 80]","[50, 80, 80, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting insights', 'important topic'), they also highlight several significant concerns and state that 'the conclusions are overstated'. The overall tone suggests more criticism than praise. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the difficulty of the topic and the interesting ideas presented. They frame criticisms as 'problems' rather than using harsh language, and offer constructive suggestions like additional references. The review maintains a professional tone without resorting to personal attacks or overly negative language."", ""The sentiment score is 60 (positive) because the reviewer starts by praising the paper as 'well written, clear, organized and easy to follow.' They also mention that the work and results are 'very useful for practitioners.' However, the score is not higher because the reviewer points out two lacking aspects and suggests areas for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. They use phrases like 'could benefit from' and 'could be further clarified' when suggesting improvements, which maintains a polite and professional tone."", ""The sentiment score is 70 (positive) because the reviewer starts by thanking the authors for an 'interesting paper' and expresses that they found the empirical evaluation and observations 'very interesting'. They also mention that the potential code release would be a 'very valuable contribution'. The overall tone is encouraging and appreciative of the work. The politeness score is 80 (polite) due to the reviewer's use of courteous language throughout. They begin with a thank you, use phrases like 'it would be useful' and 'I'm curious to hear what you think', which show respect and invite dialogue. The reviewer also frames suggestions as questions or considerations rather than demands, maintaining a polite and constructive tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable opinion of the paper, stating it tackles an 'interesting and important problem' and is 'worthy for acceptance'. They praise the 'exhaustive experiments' and describe the results as 'highly convincing'. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the authors' work and findings without harsh criticism. They use phrases like 'I think' to soften their statements and maintain a professional tone. The review focuses on the paper's strengths and contributions to the field, avoiding negative or confrontational language.""]"
"['\nThe authors deal with the problem of implicit ordering in a dataset and the challenge of recovering it, i.e. when given a random dataset with no explicit ordering in the samples, the model is able to recover an ordering. They propose to learn a distance-metric-free model that assumes a Markov chain as the generative mechanism of the data and learns not only the transition matrix but also the optimal ordering of the observations.\n\n\n> Abstract\n“Aiming to find such orders, we introduce a novel Generative Markov Network (GMN) which we use to extract the order of data instances automatically. ”\nI am not sure what automatically refers here to. Do the authors mean that the GMN model does not explicitly assume any ordering in the observed dataset? This needs to be better stated here. \n“Aiming to find such orders, we introduce a novel Generative Markov Network (GMN) which we use to extract the order of data instances automatically; given an unordered dataset, it outputs the best -most possible- ordering.”\n\nMost of the models assume an explicit ordering in the dataset and use it as an integral modelling assumption. Contrary to that they propose a model where no ordering assumption is made explicitly, but the model itself will recover it if any.\n\n> Introduction\nThe introduction is fairly well structured and the example of the joint locations in different days helps the reader.  \n\nIn the last paragraph of page 1, “we argue that … a temporal model can generate it.”, the authors present very good examples where ordered observations (ballerina poses, video frames) can be shuffled and then the proposed model can recover a temporal ordering out of them. What I would like to think also here is about an example where the recovered ordering will also be useful as such. An example where the recovered ordering will increase the importance of the inferred solution would be more interesting..\n\n\n\n2. Related work\nThis whole section is not clear how it relates to the proposed model GMN. Rewriting is strongly suggested. \nThe authors mention Deep Generative models and One-shot learning methods as related work but the way this section is constructed makes it hard for the reader to see the relation. It is important that first the authors discuss the characteristics of GMN that makes it similar to Deep generative models and the one-shot learning models. They should briefly explain the characteristics of DGN and one-shot learning so that the readers see the relationship. \nAlso, the authors never mention that the architecture they propose is deep.\n \nRegarding the last paragraph of page 2, “Our approach can be categorised … can be computed efficiently.”:\nNot sure why the authors assume that the samples can be sampled from an unmixed chain. An unmixed chain can also result in observing data that do not exhibit the real underlying relationships. Also the authors mention couple of characteristics of the GMN but without really explaining them.  What are the explicit and implicit models [1] … this needs more details. \n\n[1] P. J. Diggle and R. J. Gratton. Monte Carlo methods of inference for implicit statistical models. Journal of the Royal Statistical Society. Series B (Methodological), pages 193–227, 1984. \n\n“Second, prior approaches were proposed based on the notion of denoising models. In other words, their goal was generating high-quality images; on the other hand, we aim at discovering orders in datasets.” —>this bit is confusing. Do the authors mean that prior approaches were considering the observed ordering as part of the model assumptions and were just focusing on the denoising? \n\n3. Generative Markov models\nFirst, I would like to draw the attention of the authors on the terminology they use. The states here are not the latent states usually referred in the literature of Markov chains. The states here are observed and should not be confused with the emissions also usually stated in the corresponding literature. There are as many states as the number of observations and not differentiation is made for ties. All these are based on my understanding of the model.\n\nIn  the Equation just before equation (1),  on the left hand side, shouldn’t \\pi be after the `;’. It’s an average over the possible \\pi.  We cannot  consider the average over \\pi when we also want to find the optimal \\pi.  The sum doesn’t need to be there. Shouldn’t it just be  max_{\\theta, \\pi} log P({s_i}^{n}_{i=1}; \\pi, \\theta) ?\nEquation (1), same. The summation over the possible \\pi is confusing. It’s an optimisation problem…\n\npage 4, section 3.1: The discussion about the use of Neural Net for the construction of the transition matrix needs expansion. It is unclear how the matrix is constructed. Please add more details. E.g. use of soft-max non-linear transformation so that the output of the Neural Net can be interpreted as the probabilities of jumping to one of the possible states. In this fashion, we map the input (current state) and transform it to the probability gf occupying states at the next time step.\n\nWhy this needs expansion: The construction of the transition matrix is the one that actually plays the role of the distance metric in the related models. More specifically, the choice of the non-linear function that outputs the transition probability is crucial; e.g. a smooth function will output comparable transition probabilities to similar inputs (i.e. similar states). \n\nsection 3.2: \nMy concern about averaging over \\pi applies on the equations here too. \n\n“However, without further assumption on the structure of the transitional operator..”—> I think the choice of the nonlinear function in the output node of the NN is actually related to the transition matrix and defines the probabilities. It is a confusing statement to make and authors need to discuss more about it. After all, what is the driving force of the inference? This is a problem/task where the observations are considered in a number of different permutations. As such, the ordering is not fixed and the main driving force regarding the best choice of ordering should come from the architecture of the transition matrix; what kind of transitions does the Neural Net architecture favour? Distance free metric but still assumptions are made that favour specific transitions over others. \n\n“At first, Alg. 1 enumerates all the possible states appearing in the first time step. For each of the following steps, it finds the next state by maximizing the transition probability at the current step, i.e., a local search to find the next state. ” —>  local search in the sense that the algorithm chooses as the next state the state with the biggest transition probability (to it) as defined in the Neural Net (transition operator) output? This is a deterministic step, right? \n\n4.1 DISCOVERING ORDERS IN DATASETS \nNice description of the datasets. In the <MSR_SenseCam> the choice of one of the classes needs to be supported.  Why? What do the authors expect to happen if a number of instances from different classes are chosen? \n\n4.1.1 IMPLICIT ORDERS IN DATASETS \nThe explanation of the inferred orderings for the GMN and Nearest Neighbour model is not clear. In figure 2, what forces the GMN to make distinguishable transitions as opposed to the Nearest neighbour approach that prefers to get stuck to similar states? Is it the transition matrix architecture as defined by the neural network? \n\n>> Figure 10: why use of X here? Why not keep being consistent by using s?\n\n*** DO the authors test the model performance on a ordered dataset (after shuffling it…) ?  Is the model able of recovering the order? **\n', ""The paper is about learning the order of an unordered data sample via learning a Markov chain. The paper is well written, and experiments are carefully performed. The math appears correct and the algorithms are clearly stated. However, it really is unclear how impactful are the results.\n\nGiven that finding order is important, A high level question is that given a markov chain's markov property, why is it needed to estimate the entire sequence \\pi star at all? Given that the RHS of the first equation in section 3.2 factorizes, why not simply estimate the best next state for every data s_i?\n\nIn the related works section, there are past generative models which deserve mentions: Deep Boltzmann Machines, Deep Belief Nets, Restricted Boltzmann Machines,  and Neural Autoregressive Density Estimators.\n\nEquation 1, why is P(\\pi) being multiplied with the probability of the sequence p({s_i}) ? are there other loss formulations here?\n\nAlg 1, line 7, are there typos with the subscripts?\n\nSection 3.1 make sure to note that f(s,s') sums to 1.0, else it is not a proper transition operator.\n\nSection 3.4, the Bernoulli transition operators very much similar to RBMs, where z is the hidden layer, and there are a lot of literature related to MCMC with RBM models.\n\nDue the complexity of the full problem, a lot of simplification are made and coordinate descent is used. However there are no guarantees to finding the optimal order and a local minimum is probably always reached. Imagining a situation where there are two distinct clusters of s_i, the initial transition operator just happen to jump to the other cluster. This would produce a very different learned order \\pi compared to a transition operator which happen to be very local. Therefore, initialization of the transition operator is very important, and without any regularization, it's not clear what is the point of learning a locally optimal ordering.\n\nMost of the ordering results are qualitative, it would be nice if a dataset with a ground truth ordering can be obtained and we have some quantitative measure. (such as the human pose joint tracking example given by the authors)\n\nIn summary, there are some serious concerns on the impact of this paper. However, this paper is well written and interesting.\n\n\n\n"", '[After rebuttal]: \nI appreciate the effort the authors have put into the rebuttal, but I do not see a paper revision or new results, so I keep my rating.\n\n---\n\nThe paper proposes “Generative Markov Networks” - a deep-learning-based approach to modeling sequences and discovering order in datasets. The key ingredient of the model is a deep network playing the role of a transition operator in Markov chain, trained via Variational Bayes, similar to a variational autoencoder (but with non-identical input and output images). Given an unordered dataset, the authors maximize its likelihood under the model by alternating gradient ascent steps on the parameters of the network and greedy reordering of the dataset. The model learns to find reasonable order in unordered datasets, and achieves non-trivial performance on one-shot learning. \n\nPros:\n1) The one-shot learning results are promising. The method is conceptually more attractive than many competitors, because it does not involve specialized training on the one-shot classification task. The ability to perform unsupervised fine-tuning on the target test set is also appealing.\n2) The idea of explicitly representing the neighborhood structure within a dataset is generally interesting and seems related to the concept of low-dimensional image manifold. It’s unclear why does this manifold have to be 1-dimensional, though.\n\nCons:\n1) The motivation of the paper is not convincing. Why does one need to find order in unordered datasets? The authors do not really discuss this at all, even though this seems to be the key task in the paper, as reflected in the title. What does one do with this order? How does one even evaluate if a discovered order is good or not?\n2) The one-shot classification results are to me the strongest part of the paper. However, they are rushed and not analyzed in detail. It is unclear which components of the system contribute to the performance. As I understand the method, the authors effectively select several neighbors of the labeled samples and then classify the remaining samples based on the average similarity to these. What if the same procedure is performed with a different similarity measure, not the one learned by GMN? I am not convinced that the proposed method is well tuned for the task. Why is it useful to discover one-dimensional structure, rather than learning a clustering or a metric? Could it be that with a different similarity measure (like the distance in the feature space of a network trained on classification) this procedure would work even better? Or is GMN especially good for this task? If so. why?\n3) The experiments on dataset ordering are not convincing. What should one learn from those? There are no quantitative results, just a few examples (and more in the supplement). The authors even admit that “Comparing to the strong ordering baseline Nearest Neighbor sorting, one could hardly tell which one is better”. Nearest neighbor with Euclidean metric is not a strong baseline at all, and not being able to tell if the proposed method is better than that is not a good sign.\n4) The authors call their method distance-metric-free. This is strange to me. The loss function used during training of the network is a measure of similarity between two samples (may or may not be a proper distance metric). So the authors do assume having some similarity measure between the data points. The distance-metric-free claim is similar to saying that negative log-likelihood of a Gaussian has nothing to do with Euclidean distance. \n5) The experiments on using the proposed model as a generative model are confusing. First, the authors do not generate the samples directly, but instead select them from the dataset - this is quite unconventional. Then, the NN baseline is obviously doomed to jump between two samples - the authors could come up with a better baseline, for instance linearly extrapolating based on two most recent samples, or learning the transition operator with a simple linear model. \n6) I am puzzled by the hyperparameter choices. It seems there was a lot of tuning behind the scenes, and it should be commented on. The parameters are very different between the datasets (top of page 7), why is that? Why do they have to differ so much - is the method very unstable w.r.t. the parameters? How can it be that b_{overlap} = b ? Also, in the one-shot classification results, the number of sampled neighbors is 1 without fine-tuning and 5 with fine-tuning - this is strange and not explained.\n7) This work seems related to simultaneous clustering and representation learning, in that it combines discrete reordering and continuous deep network training. The authors should perhaps mention this line of work. See e.g. Yang et al. “Joint Unsupervised Learning of Deep Representations and Image Clusters”, CVPR 2016.\n\nTo conclude, the paper has some interesting ideas, but the presentation is not convincing, and the experiments are substandard. Therefore at this point I cannot recommend the paper for publication.']","[-20, 20, -70]","[50, 60, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper, they raise several concerns and suggest significant revisions. The review begins with a neutral summary but then lists multiple issues and areas needing clarification or improvement throughout the paper. The politeness score is moderately positive (50) as the reviewer uses respectful language, offers constructive feedback, and phrases criticisms as suggestions rather than harsh judgments. They use polite phrases like 'I would like to draw the attention of the authors' and 'Please add more details.' The tone remains professional and helpful throughout, even when pointing out flaws."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges that the paper is well-written, experiments are carefully performed, and the math appears correct. However, they express concerns about the impact of the results and raise several questions, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and balances positive comments with areas of concern. They use phrases like 'well written,' 'carefully performed,' and 'interesting,' while also clearly stating their concerns without being harsh or dismissive. The review concludes with a balanced summary, acknowledging both the paper's strengths and weaknesses in a professional manner."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer lists several cons and concludes that they 'cannot recommend the paper for publication'. While there are some positive points mentioned ('promising' one-shot learning results), these are outweighed by the criticisms. The politeness score is 20 because the reviewer uses professional language and acknowledges the authors' efforts ('I appreciate the effort the authors have put into the rebuttal'). However, the criticism is direct and unvarnished, which prevents a higher politeness score. The reviewer also uses phrases like 'I am puzzled' and 'This is strange to me' which, while not impolite, do not contribute to a highly polite tone.""]"
"[""Summary:\nThis paper proposes an extension to the RWA model by introducing the discount gates to computed discounted averages instead of the undiscounted attention. The problem with the RWA is that the averaging mechanism can be numerically unstable due to the accumulation operations when computing d_t.\n\nPros:\n- Addresses an issue of RWAs.\n\nCons:\n-The paper addresses a problem with an issue with RWAs. But it is not clear to me why would that be an important contribution.\n-The writing needs more work.\n-The experiments are lacking and the results are not good enough.\n\nGeneral Comments:\n\nThis paper addresses an issue regarding to RWA which is not really widely adopted and well-known architecture, because it seems to have some have some issues that this paper is trying to address. I would still like to have a better justification on why should we care about RWA and fixing that model. \n\nThe writing of this paper seriously needs more work.  The Lemma 1 doesn't make sense to me, I think it has a typo in it, it should have been (-1)^t c instead of -1^t c.\n\nThe experiments are only on toyish and small scale tasks. According to the results the model doesn't really do better than a simple LSTM or GRU."", 'The authors present RDA, the Recurrent Discounted Attention unit, that improves upon RWA, the earlier introduced Recurrent Weighted Average unit, by adding a discount factor. While the RWA was an interesting idea with bad results (far worse than the standard GRU or LSTM with standard attention except for hand-picked tasks), the RDA brings it more on-par with the standard methods.\n\nOn the positive side, the paper is clearly written and adding discount to RWA, while a small change, is original. On the negative side, in almost all tasks the RDA is on par or worse than the standard GRU - except for MultiCopy where it trains faster, but not to better results and it looks like the difference is between few and very-few training steps anyway. The most interesting result is language modeling on Hutter Prize Wikipedia, where RDA very significantly improves upon RWA - but again, only matches a standard GRU or LSTM. So the results are not strongly convincing, and the paper lacks any mention of newer work on attention. This year strong improvements over state-of-the-art have been achieved using attention for translation (""Attention is All You Need"") and image classification (e.g., Non-local Neural Networks, but also others in ImageNet competition). To make the evaluation convincing enough for acceptance, RDA should be combined with those models and evaluated more competitively on multiple widely-studied tasks.', 'This paper extends the recurrent weight average (RWA, Ostmeyer and Cowell, 2017) in order to overcome the limitation of the original method while maintaining its advantage. The motivation of the paper and the approach taken by the authors are sensible, such as adding discounting was applied to introduce forget mechanism to the RWA and manipulating the attention and squash functions.\n\nThe proposed method is using Elman nets as the base RNN. I think the same method can be applied to GRUs or LSTMs. Some parameters might be redundant, however, assuming that this kind of attention mechanism is helpful for learning long-term dependencies and can be computed efficiently, it would be nice to see the outcomes of this combination.\n\nIs there any explanation why LSTMs perform so badly compared to GRUs, the RWA and the RDA?\nOverall, the proposed method seems to be very useful for the RWA.']","[-60, -20, 70]","[-20, 50, 80]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several cons and expresses skepticism about the paper's contribution and importance. The only pro mentioned is brief and not elaborated upon. The general comments further emphasize the paper's shortcomings in writing, justification, and experimental results. The politeness score is -20 because while the reviewer isn't overtly rude, the language is quite direct and critical without much attempt to soften the feedback. Phrases like 'The writing of this paper seriously needs more work' and 'The experiments are only on toyish and small scale tasks' come across as somewhat harsh. However, the reviewer does use some neutral language and doesn't resort to personal attacks, preventing the score from being extremely negative."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('clearly written', 'original'), they express more concerns about the paper's results and lack of comparison to newer work. The overall tone suggests the paper's contributions are not strongly convincing. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, balancing criticism with acknowledgment of positive aspects. They provide constructive feedback without using harsh or dismissive language, maintaining a professional tone."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, describing the motivation and approach as 'sensible' and the proposed method as 'very useful'. They also suggest potential extensions, indicating interest in the work. The politeness score is 80 (polite) due to the constructive and respectful tone throughout. The reviewer uses phrases like 'it would be nice to see' and poses a question rather than making a criticism. The language is professional and supportive, without any harsh or rude comments.""]"
"['The paper adds few operations after the pipeline for obtaining visual concepts from CNN as proposed by Wang et al. (2015). This latter paper showed how to extract from a CNN some clustered representations of the features of the internal layers of the network, working on a large training dataset. The clustered representations are the visual concepts. This paper shows that these representations can be used as exemplars by test images, in the same vein as bag of words used word exemplars to create the bag of words of unseen images.\n\n A simple nearest neighborhood and a likelihood model is built to assign a picture to an object class.\n\nThe results a are convincing, even if they are not state of the art in all the trials. \nThe paper is very easy to follows, and the results are explained in a very simple way.\n\n\nFew comments:\nThe authors in the abstract should revise their claims, too strong with respect to a literature field which has done many advancements on the cnn interpretation (see all the literature of Andrea Vedaldi) and the literature on zero shot learning, transfer learning, domain adaptation and fine tuning in general.', 'My main concern for this paper is that the description of the Visual Concepts is completely unclear for me. At some point I thought I did understand it, but then the next equation didnt make sense anymore... If I understand correctly, f_p is a representation of *all images* of a specific layer *k* at/around pixel ""p"", (According to last line of page 3). That would make sense, given that then the dimensions of the vector f_p is a scalar (activation value) per image for that image, in layer k, around pixel p. Then f_v is one of the centroids (named VCs). However, this doesnt seem to be the case, given that it is impossible to construct VC activations for specific images from this definition. So, it should be something else, but it does not become clear, what this f_p is. This is crucial in order to follow / judge the rest of the paper. Still I give it a try.\n\nSection 4.1 is the second most important section of the paper, where properties of VCs are discussed. It has a few shortcomings. First, iIt is unclear why coverage should be >=0.8 and firerate ~ 1, according to the motivation firerate should equal to coverage: that is each pixel f_p is assigned to a single VC centroid. Second, ""VCs tent to occur for a specific class"", that seems rather a bold statement from a 6 class, 3 VCs experiment, where the class sensitivity is in the order 40-77%. Also the second experiment, which shows the spatial clustering for the ""car wheel"" VC, is unclear, how is the name ""car wheel"" assigned to the VC? That has have to be named after the EM process, given that EM is unsupervised. Finally the cost effectiveness training (3c), how come that the same ""car wheel"" (as in 3b) is discovered by the EM clustering? Is that coincidence? Or is there some form of supervision involved? \n\n\nMinor remarks\n- Table 1: the reported results of the Matching Network are different from the results in the paper of Vinyals (2016).\n- It is unclear what the influence of the smoothing is, and how the smoothing parameter is estimated / set.\n- The VCs are introduced for few-shot classification, unclear how this is different from ""previous few-shot methods"" (sect 5). \n- 36x36 patches have a plausible size within a 84x84 image, this is rather large, do semantic parts really cover 20% of the image?\n- How are the networks trained, with what objective, how validated, which training images? What is the influence of the layer on the performance? \n- Influence of the clustering method on VCs, eg k-means, gaussian, von-mises (the last one is proposed)?\n\nOn a personal note, I\'ve difficulties with part of the writing. For example, the introduction is written rather ""arrogant"" (not completely the right word, sorry for that), with a sentence, like ""we have only limited insights into why CNNs are effective"" seems overkill for the main research body. The used Visual Concepts (VCs) were already introduced by other works (Wangt\'15), and is not a novelty. Also the authors refer to another paper (about using VCs for detection) which is also under submission (somewhere). Finally, the introduction paragraph of Section 5 is rather bold, ""resembles the learning process of human beings""? Not so sure that is true, and it is not supported by a reference (or an experiment). \n\nIn conclusion:\nThis paper presents a method for creating features from a (pre-trained) ConvNet. \nIt clusters features from a specific pooling layer, and then creates a binary assignment between per image extracted feature vectors and the cluster centroids. These are used in a 1-NN classifier and a (smoothed) Naive Bayes classifier. The results show promising results, yet lack exploration of the model, at least to draw conclusions like ""we address the challenge of understanding the internal visual cues of CNNs"". I believe this paper needs to focus on the working of the VCs for few-shot experiments, showing the influences of some of the choices (layer, network layout, smoothing, clustering, etc). Moreover, the introduction should be rewritten, and the the background section of VCs (Sect 3) should be clarified. Therefore, I rate the current manuscript as a reject. \n\nAfter rebuttal:\nThe writing of the paper greatly improved, still missing insights (see comments below). Therefore I\'ve upgraded my rating, and due to better understanding now, als my confidence. ', 'The paper proposes a method for few-shot learning using a new image representation called visual concept embedding. Visual concepts were introduced in Wang et al. 2015, which are clustering centers of feature vectors in a lattice of a CNN. For a given image, its visual concept embedding is computed by thresholding the distances between feature vectors in the lattice of the image to the visual concepts. Using the visual concept embedding, two simple methods are used for few-shot learning: a nearest neighbor method and a probabilistic model with Bernoulli distributions. Experiments are conducted on the Mini-ImageNet dataset and the PASCAL3D+ dataset for few-shot learning.\n\nPositives:\n- The three properties of visual concepts described in the paper are interesting.\n\nNegatives:\n- The novelty of the paper is limited. The idea of visual concept has been proposed in Wang et al. 2015. Using a embedding representation based on visual concepts is straightforward. The two baseline methods for few-shot learning provide limited insights in solving the few-shot learning problem.\n\n- The paper uses a hard thresholding  in the visual concept embedding. It would be interesting to see the performance of other strategies in computing the embedding, such as directly using the distances without thresholding.']","[50, -60, -20]","[75, 20, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and finds the results convincing, even if not state-of-the-art. They also praise the paper's clarity. However, the reviewer suggests revising claims in the abstract, indicating room for improvement. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offering constructive feedback and balancing positive comments with areas for improvement. The phrase 'Few comments' before critiques softens the criticism. The reviewer's tone is professional and courteous, avoiding harsh or dismissive language."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the clarity of the paper's key concepts and methodology, points out several shortcomings, and ultimately recommends rejection. However, they do note some promising results and potential for improvement, preventing an extremely negative score. The politeness score is 20 because while the reviewer maintains a professional tone overall and offers constructive criticism, there are instances of more direct language (e.g., calling parts of the writing 'arrogant'). The reviewer also apologizes for potentially harsh wording, indicating an effort to remain polite despite critical feedback. The use of phrases like 'I believe' and 'I've difficulties' softens the critique, contributing to a slightly positive politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positives ('The three properties of visual concepts described in the paper are interesting'), they express more significant concerns about the paper's novelty and methodology. The reviewer states that 'The novelty of the paper is limited' and that the methods 'provide limited insights'. However, the criticism is not extremely harsh, hence the score is only mildly negative. The politeness score is moderately positive (50) because the reviewer maintains a professional and objective tone throughout. They present both positives and negatives in a balanced manner, using neutral language like 'It would be interesting to see' rather than more critical phrasing. The reviewer also avoids personal attacks or overly harsh language, maintaining a respectful tone while still providing constructive criticism.""]"
"['*Summary*\n\nThe paper proposes to use hyper-networks [Ha et al. 2016] for the tuning of hyper-parameters, along the lines of [Brock et al. 2017]. The core idea is to have a side neural network sufficiently expressive to learn the (large-scale, matrix-valued) mapping from a given configuration of hyper-parameters to the weights of the model we wish to tune.\nThe paper gives a theoretical justification of its approach, and then describes several variants of its core algorithm which mix the training of the hyper-networks together with the optimization of the hyper-parameters themselves. Finally, experiments based on MNIST illustrate the properties of the proposed approach.\n\nWhile the core idea may appear as appealing, the paper suffers from several flaws (as further detailed afterwards):\n-Insufficient related work\n-Correctness/rigor of Theorem 2.1\n-Clarity of the paper (e.g., Sec. 2.4)\n-Experiments look somewhat artificial\n-How scalable is the proposed approach in the perspective of tuning models way larger/more complex than those treated in the experiments?\n\n*Detailed comments*\n\n-""...and training the model to completion."" and ""This is wasteful, since it trains the model from scratch each time..."" (and similar statement in Sec. 2.1): Those statements are quite debatable. There are lines of work, e.g., in Bayesian optimization, to model early stopping/learning curves (e.g., Domhan2014, Klein2017 and references therein) and where training procedures are explicitly resumed (e.g., Swersky2014, Li2016). The paper should reformulate its statements in the light of this literature.\n\n-""Uncertainty could conceivably be incorporated into the hypernet..."". This seems indeed an important point, but it does not appear as clear how to proceed (e.g., uncertainty on w_phi(lambda) which later needs to propagated to L_val); could the authors perhaps further elaborate?\n\n-I am concerned about the rigor/correctness of Theorem 2.1; for instance, how is the continuity of the best-response exploited? Also, throughout the paper, the argmin is defined as if it was a singleton while in practice it is rather a set-valued mapping (except if there is a unique minimizer for L_train(., lambda), which is unlikely to be the case given the nature of the considered neural-net model). In the same vein, Jensen\'s inequality states that Expectation[g(X)] >= g(Expectation[X]) for some convex function g and random variable X; how does it precisely translate into the paper\'s setting (convexity, which function g, etc.)? \n\n-Specify in Alg. 1 that ""hyperopt"" refers to a generic hyper-parameter procedure.\n\n-More details should be provided to better understand Sec. 2.4. At the moment, it is difficult to figure out (and potentially reproduce) the model which is proposed.\n\n-The training procedure in Sec. 4.2 seems quite ad hoc; how sensitive was the overall performance with respect to the optimization strategy? For instance, in 4.2 and 4.3, different optimization parameters are chosen.\n\n-typo: ""weight decay is applied the..."" --> ""weight decay is applied to the...""\n\n-""a standard Bayesian optimization implementation from sklearn"": Could more details be provided? (there does not seem to be implementation there http://scikit-learn.org/stable/model_selection.html to the best of my knowledge)\n\n-The experimental set up looks a bit far-fetched and unrealistic: first scalar, than diagonal and finally matrix-weighted regularization schemes. While the first two may be used in practice, the third scheme is not used in practice to the best of my knowledge.\n\n-typo: ""fit a hypernet same dataset."" --> ""fit a hypernet on the same dataset.""\n\n-(Franceschi2017) could be added to the related work section.\n\n*References*\n\n(Domhan2014) Domhan, T.; Springenberg, T. & Hutter, F. Extrapolating learning curves of deep neural networks ICML 2014 AutoML Workshop, 2014\n\n(Franceschi2017) Franceschi, L.; Donini, M.; Frasconi, P. & Pontil, M. Forward and Reverse Gradient-Based Hyperparameter Optimization preprint arXiv:1703.01785, 2017\n\n(Klein2017) Klein, A.; Falkner, S.; Springenberg, J. T. & Hutter, F. Learning curve prediction with Bayesian neural networks International Conference on Learning Representations (ICLR), 2017, 17\n\n(Li2016) Li, L.; Jamieson, K.; DeSalvo, G.; Rostamizadeh, A. & Talwalkar, A. Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization preprint arXiv:1603.06560, 2016\n\n(Swersky2014) Swersky, K.; Snoek, J. & Adams, R. P. Freeze-Thaw Bayesian Optimization preprint arXiv:1406.3896, 2014\n\n*********\nUpdate post rebuttal\n*********\n\nI acknowledge the fact that I read the rebuttal of the authors, whom I thank for their detailed answers.\n\nMy minor concerns have been clarified. Regarding the correctness of the proof, I am still unsure about the applicability of Jensen inequality; provided it is true, then it is important to see that the results seem to hold only for particular hyperparameters, namely regularization parameters (as explained in the new updated proof). This limitation should be exposed transparently upfront in the paper/abstract. \nTogether with the new experiments and comparisons, I have therefore updated my rating from 5 to 6.\n', '[Apologies for short review, I got called in late. Marking my review as ""educated guess"" since I didn\'t have time for a detailed review]\n\nThe authors model the function mapping hyperparameters to parameter values using a neural network. This is similar to the Bayesian optimization setting but with some advantages such as the ability to evaluate the function stochastically.\n\nI find the approach to be interesting and the paper to be well written. However, i found theoretical results have unrealistic assumptions on the size of the network (i.e., rely on networks being universal approximator, whose number of parameters scale exponentially with the dimension) and as such are not more than a curiosity. Also, the authors compare their approach (Fig. 6) vs Bayesian optimization and random search, which are approaches that are know to perform extremely poorly on high dimensional datasets. Comparison with other gradient-based approaches (Maclaurin 2015, Pedregosa 2016, Franceschi 2017) is lacking.\n', 'This paper introduces the use of hyper-networks for hyper-parameter optimization in the context of neural networks. A hyper-network is a network that has been trained to find optimal weights for another neural network on a particular learning task. This hyper-network can also be trained using gradient descent, and then can be optimized with respect to its inputs (hyper-parameters) to find optimal hyper-parameters. Of course, for this to be feasible training the hyper-network has to be efficient. For this, the authors suggest to use a linear hyper-network. The use of this approach for hyper-parameter optimization is illustrated in several experiments considering a linear model on the MNIST dataset.\n\nThe paper is clearly written with only a few typing errors.\n\nAs far as I know this work is original. This is the first time that hyper-networks are used for hyper-parameter optimization.\n\nThe significance of the work can, however, be questioned. To begin with, the models considered by the authors are rather small. They are simply linear models in which the number of weights is not very big. In particular, only 7,850 weights. The corresponding hyper-net has around 15,000, which is twice as big. Furthermore, the authors say that they train the hyper-network 10 times more than standard gradient descent on the hyper-parameter. This accounts for training the original model 20 times more. \n\nIf the original model is a deep neural network with several hidden layers and several hidden units in each layer, it is not clear if the proposed approach will be feasible. That is my main concern with this paper. The lack of representative models such as the ones used in practical applications.\n\nAnother limitation is that the proposed approach seems to be limited to neural network models. The other techniques the authors compare with are more general and can optimize the hyper-parameters of other models.\n\nSomething strange is that the authors claim in Figure 6 that the proposed method is able to optimize 7,850 hyper-parameters. However, it is not clear to what extent this is true. To begin with, it seems that the performance obtained is worse than with 10 hyper-parameters (shown on the right). Since the left case is a general case of the right case (having only 10 hyper-parameters different) it is strange that worse results are obtained in the left case. It seems that the optimization process is reaching sub-optimal solutions.\n\nThe experiments shown in Figure 7 are strange. I have not fully understood their importance or what conclusions can the authors extract from them.\n\nI have also missed comparing with related techniques such as Dougal Maclaurin et al., 2015.\n\nSumming up, this seems to be an interesting paper proposing an interesting idea. However, it seems the practical utility of the method described is limited to small models only, which questions the overall significance.\n\n']","[-40, -20, -20]","[20, 50, 60]","['The sentiment score is -40 because the review starts with some positive comments about the core idea being appealing, but then lists several significant flaws and concerns with the paper. The reviewer points out issues with related work, theoretical correctness, clarity, and experimental design. The updated score after rebuttal shows some improvement but still indicates reservations. The politeness score is 20 because the reviewer uses professional and constructive language throughout, acknowledging positive aspects and providing detailed feedback for improvement. However, the critique is direct and does not use overly polite phrasing. The reviewer also thanks the authors for their detailed rebuttal, which adds to the politeness.', ""The sentiment score is slightly negative (-20) because while the reviewer finds the approach interesting and the paper well-written, they express significant criticisms about the theoretical results and comparisons made. The reviewer points out unrealistic assumptions and lack of comparison with relevant approaches, which outweigh the initial positive comments. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'I find the approach to be interesting' and 'the paper to be well written', which contribute to a respectful tone. The criticisms are presented factually without harsh language, maintaining a professional and courteous demeanor."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the originality and interesting nature of the work, they express significant concerns about its practical utility and limitations. The reviewer questions the significance of the work due to the small models used and the lack of applicability to larger, more practical neural networks. They also point out some strange results and missed comparisons.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They begin by acknowledging the paper's clarity and originality. Even when expressing concerns, the language is constructive rather than harsh. Phrases like 'The significance of the work can, however, be questioned' and 'Something strange is...' are used instead of more direct criticisms. The reviewer also uses 'I have missed' instead of directly accusing the authors of omissions. The conclusion summarizes both positive and negative aspects, maintaining a balanced tone.""]"
"['The paper is clearly written, with a good coverage of previous relevant literature. \nThe contribution itself is slightly incremental, as several different parameterization of orthogonal or almost-orthogonal weight matrices for RNN have been introduced.\nTherefore, the paper must show that this new method performs better in some way compared with previous methods. They show that the proposed method is competitive on several datasets and a clear winner on one task: MSE on TIMIT.\n\nPros:\n1. New, relatively simple method for learning orthogonal weight matrices for RNN\n\n2. Clearly written\n\n3. Quite good results on several relevant tasks.\n\nCons:\n1. Technical novelty is somewhat limited\n\n2. Experiments do not evaluate run time, memory use, computational complexity, or stability. Therefore it is more difficult to make comparisons: perhaps restricted-capacity uRNN is 10 times faster than the proposed method?', 'This paper suggests an RNN reparametrization of the recurrent weights with a skew-symmetric matrix using Cayley transform to keep the recurrent weight matrix orthogonal. They suggest that they reparametrization leads to superior performance compare to other forms of Unitary Recurrent Networks.\n\nI think the paper is well-written.  Authors have discussed previous works adequately and provided enough insight and motivation about the proposed method.\n\nI have two questions from authors:\n\n1- What are the hyperparameters that you optimized in experiments?\n\n2- How sensitive is the results to the number of -1 in the diagonal matrix?\n\n3- ince the paper is not about compression, it might be unfair to limit the number of hidden units in LSTMs just to match the number of parameters to RNNs. In MNIST experiment, for example, better numbers are reported for larger LSTMs. I think matching the number of hidden units could be helpful. Also, one might want to know if the scoRNN is still superior in the regime where the number of hidden units is about 1000. I appreciate if authors can provide more results in these settings.\n\n', ""This manuscript introduce a scheme for learning the recurrent parameter matrix in a neural network that uses the Cayley transform and a scaling weight matrix. This scheme leads to good performance on sequential data tasks and requires fewer parameters than other techniques\n\nComments:\n-- It’s not clear to me how D is determined for each test. Given the definition in Theorem 3.1 it seems like you would have to have some knowledge of how many eigenvalues in W you expect to be close to -1. \n-- For the copying and adding problem test cases, it might be useful to clarify or cite something clarifying that the failure mode RNNs run into with temporal ordering problems is an exploding gradient, rather than any other pathological training condition, just to make it clear why these experiments are relevant.\n-- The ylabel in Figure 1 is “Test Loss” which I didn’t see defined. Is this test loss the cross entropy? If so, I think it would be more effective to label the plot with that.\n-- The plots in figure 1 and 2 have different colors to represent the same set of techniques. I would suggest keeping a  consistent color scheme\n-- It looks like in Figure 1 the scoRNN is outperformed by the uRNN in the long run in spite of the scoRNN convergence being smoother, which should be clarified.\n-- It looks like in Figure 2 the scoRNN is outperformed by the LSTM across the board, which should be clarified.\n-- How is test set accuracy defined in section 5.3? Classifying digits? Recreating digits? \n-- When discussing table 1, the manuscript mentions scoRNN and Restricted-capacity uRNN have similar performance for 16k parameters and then state that scoRNN has the best test accuracy at 96.2%. However, there is no example for restricted-capacity uRNN with 69k parameters to show that the performance of restricted-capacity uRNN doesn't also increase similarly with more parameters.\n-- Overall it’s unclear to me how to completely determine the benefit of this technique over the others because, for each of the tests, different techniques may have superior performance. For instance, LSTM performs best in 5.2 and in 5.3 for the MNIST test accuracy. scoRNN and Restricted-capacity uRNN perform similarly for permuted MNIST Test Accuracy in 5.3. Finally, scoRNN seems to far outperform the other techniques in table 2 on the TIMIT speech dataset. I don’t understand the significance of each test and why the relative performance of the techniques vary from one to the other.\n-- For example, the manuscript seems to be making the case that the scoRNN gradients are more stable than those of a uRNN, but all of the results are presented in terms of network accuracy and not gradient stability. You can sort of see that generally the convergence is more gradual for the scoRNN than the uRNN from the training graphs but it'd be nice if there was an actual comparison of the stability of the gradients during training (as in Figure 4 of the Arjovsky 2016 paper being compared to for instance) just to make it really clear.""]","[50, 70, 20]","[75, 80, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges both pros and cons of the paper. They praise the clear writing, good literature coverage, and competitive results, but also note the limited technical novelty and incomplete experimental evaluation. The overall tone is constructive rather than overtly critical or enthusiastic. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before discussing its limitations. They offer specific, constructive feedback without using harsh or dismissive language. The use of phrases like 'clearly written' and 'quite good results' contributes to the polite tone."", ""The sentiment score is 70 (positive) because the reviewer states that the paper is 'well-written' and that the authors have 'discussed previous works adequately and provided enough insight and motivation'. There are no negative comments, only questions for clarification and suggestions for additional experiments. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, such as 'I think' and 'I appreciate if authors can provide'. The questions are phrased politely and constructively, without any harsh criticism. The reviewer also acknowledges the authors' work positively before asking questions, which is a polite approach in academic reviews."", ""The sentiment score is slightly positive (20) because the review begins with a neutral summary of the manuscript's contribution, followed by a list of constructive criticisms and suggestions for improvement. While there are many points of critique, they are presented as areas to clarify or improve rather than fundamental flaws. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, phrasing criticisms as questions or suggestions (e.g. 'It's not clear to me...', 'I would suggest...', 'It might be useful to...') rather than direct criticisms. The reviewer also acknowledges positive aspects, such as the smooth convergence of scoRNN. However, the tone remains professional rather than overly deferential, hence the score is not higher.""]"
"['This paper presents a reparametrization of the perturbation applied to features in adversarial examples based attacks. It tests this attack variation on against Inception-family classifiers on ImageNet. It shows some experimental robustness to JPEG encoding defense.\n\nSpecifically about the method: Instead of perturbating a feature x_i by delta_i, as in other attacks, with delta_i in range [-Delta_i, Delta_i], they propose to perturbate x_i^*, which is recentered in the domain of x_i through a heuristic ((x_i ± Delta_i + domain boundary that would be clipped)/2), and have a similar heuristic for computing a Delta_i^*. Instead of perturbating x_i^* directly by delta_i, they compute the perturbed x by x_i^* + Delta_i^* * g(r_i), so they follow the gradient of loss to misclassify w.r.t. r (instead of delta). \n\n+/-:\n+ The presentation of the method is clear.\n+ ImageNet is a good dataset to benchmark on.\n- (!) The (ensemble) white-box attack is effective but the results are not compared to anything else, e.g. it could be compared to (vanilla) FGSM nor C&W.\n- The other attack demonstrated is actually a grey-box attack, as 4 out of the 5 classifiers are known, they are attacking the 5th, but in particular all the 5 classifiers are Inception-family models.\n- The experimental section is a bit sloppy at times (e.g. enumerating more than what is actually done, starting at 3.1.1.).\n- The results on their JPEG approximation scheme seem too explorative (early in their development) to be properly compared.\n\nI think that the paper need some more work, in particular to make more convincing experiments that the benefit lies in CIA (baselines comparison), and that it really is robust across these defenses shown in the paper.', 'In this paper the authors present a new method for generating adversarial examples by constraining the perturbations to fall in a bounded region.  Further, experimentally, they demonstrate that learning the perturbations to balance errors against multiple classifiers can overcome many common defenses used against adversarial examples.\n\nPros:\n- Simple, easy to apply technique\n- Positive results in a wide variety of settings.\n\nCons:\n- Writing is a bit awkward at points.\n- Approach seems fairly incremental.\n\nOverall, the results are interesting but the technique seems relatively incremental.\n\nDetails:\n\n""To find the center of domain definition..."" paragraph should probably go after the cases are described.  Confusing as to what is being referred to where it currently is written.\n\nTable 1: please use periods not commas (as in Table 2), e.g. 96.1 not 96,1\n\ninexistent --> non-existent\n', 'The paper is not anonymized. In page 2, the first line, the authors revealed [15] is a self-citation and [15] is not anonumized in the reference list.\n\n']","[-20, 20, -50]","[50, 50, 0]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The presentation of the method is clear', 'ImageNet is a good dataset to benchmark on'), there are more criticisms than praises. The reviewer points out several limitations and areas for improvement, concluding that 'the paper need some more work'. This suggests an overall negative sentiment, though not severely so. The politeness score is moderately positive (50) because the reviewer uses neutral, professional language throughout. They present criticisms constructively, using phrases like 'need some more work' rather than harsh or dismissive language. The reviewer also balances negative points with positive ones, which contributes to a polite tone. However, the review doesn't go out of its way to be exceptionally polite or encouraging, hence the moderate rather than high score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting results and positive aspects ('Pros'), but also notes that the technique seems 'relatively incremental' and lists some 'Cons'. The overall tone is cautiously positive. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, offering constructive criticism without harsh words. They balance positive and negative feedback, and provide specific suggestions for improvement in a polite manner."", ""The sentiment score is -50 because the reviewer points out a significant issue with the paper's anonymization, which is a critical aspect of the peer review process. This indicates a negative sentiment towards the paper's preparation, though not extremely negative as it's a specific, fixable issue. The politeness score is 0 (neutral) because the reviewer's language is direct and factual, without any particularly polite or impolite phrasing. The reviewer simply states the problem without using any softening language or harsh criticism, maintaining a professional, neutral tone.""]"
"['\nThe paper proposes a GAN for novelty detection (predicting novel versus nominal data), using a mixture generator with feature matching loss.  The key difference between this paper and previous is the different definition of mixture generator.  Here the authors enforce p_other to have some significant mass in the tails of p_data (Def 1), forcing the \'other\' data to be on or around the true data, creating a tight boundary around the nominal data.\n\nThe paper is well written, derives cleanly from previous work, and has solid experiments.  The experiments are weak 1) in the sense that they are not compared against simple baselines like p(x) (from, say, just thresholding a vae, or using a more powerful p(x) model -- there are lots out there), 2) other than KNNs, only compared with class-prediction based novelty detection (entropy, thresholds), and 3) in my view perform consistently, but not significantly better, than simply using the entropy of the class predictions.  How would entropy improve if it was a small ensemble instead of a single classifier?\n\nThe authors may be interested in [1], a principled approach for learning a well-calibrated uncertainty estimate on predictions.    Considering how well entropy works, I would be surprised in the model in [1] does not perform even better.\n\npros:\n- good application of GAN models\n- good writing and clarity\n- solid experiments and explanations\n\ncons:\n - results weak relative to naive baseline (entropy)\n - weak comparisons\n - lack of comparison to density models \n\n\n[1] Louizos, Christos, and Max Welling. ""Multiplicative Normalizing Flows for Variational Bayesian Neural Networks."" arXiv preprint arXiv:1703.01961 (2017).', 'This paper proposed a GAN to unify classification and novelty detection. The technical difficulty is acceptable, but there are several issues. First of all, the motivation is clearly given in the 1st paragraph of the introduction: ""In fact for such novel input the algorithm will produce erroneous output and classify it as one of the classes that were available to it during training. Ideally, we would like that the classifier, in addition to its generalization ability, be able to detect novel inputs, or in other words, we would like the classifier to say, \'I don\'t know.\'"" There is a logical gap between the ability of saying \'I don\'t know\' and the necessity of novelty detection. Moreover, there are many papers known as ""learning with abstention"" and/or ""learning with rejection"" from NIPS, ICML, COLT, etc. (some are coauthored by Dr. Peter Bartlett or Dr. Corinna Cortes), but the current paper didn\'t cite those that are particularly designed to let the classifier be able to say \'I don\'t know\'. All those abstention/rejection papers have solid theoretical guarantees.\n\nThe 3rd issue is that the novelty for the novelty detection part in the proposed GAN seems quite incremental. As mentioned in the paper, there are already a few GANs, such that ""If the \'real\' data consists of K classes, then the output of the discriminator is K+1 class probabilities where K probabilities corresponds to K known classes, and the K+1 probability correspond to the \'fake\' class."" On the other hand, the idea in this paper is that ""At test time, when the discriminator classifies a real example to the K+1th class, i.e., class which represented \'fake examples\' during training, this the example is most likely a novel example and not from one of the K nominal classes."" This is just a replacement of concepts, where the original one is the fake class in training and the new one is the novel class in test. Furthermore, the 4th issue also comes from this replacement. The proposed method assumes a very strong distributional assumption, that is, the class-conditional density of the union of all novel classes at test time is very similar to the class-conditional density of the fake class at training time, where the choice of similarity depends on the divergence measure for training GAN. This assumption is too strong for the application of novelty detection, since novel data can be whatsoever unseen during training.\n\nThis inconsistency leads to the last issue. Again mentioned in the 1st paragraph, ""there are no requirements whatsoever on how the\nclassifier should behave for new types of input that differ substantially from the data that are available during training"". This evidences that novel data can be whatsoever unseen during training (per my words). However, the ultimate goal of the generator is to fool the discriminator by generating fake data as similar to the real data as possible in all types of GANs. Therefore, it is conceptually and theoretically strange to apply GAN to novelty detection, which is the major contribution of this paper.\n\nLast but not least, there is an issue not quite directly related to this paper. Novelty detection sounds very data mining rather than machine learning. It is fully unsupervised without a clearly-defined goal which makes it sounds like an art rather than a science. The experimental performance is promising indeed, but a lot of domain knowledge is involved in the experiment design. I am not sure they are really novelty detection tasks because the real novelty detection tasks should be fully exploratory. \n\nBTW, there is a paper in IPMI 2017 entitled ""Unsupervised Anomaly Detection with Generative Adversarial Networks to Guide Marker Discovery"", which is very closely related to the current paper but the authors seem not aware of it.', 'The paper presents a method for novelty detection based on a multi-class GAN which is trained to output images generated from a mixture of the nominal and novel distributions. The trained discriminator is used to classify images as belonging to the nominal or novel distributions. To deal with the missing data from the novel distributions the authors propose to use a proxy mixture distribution resulting from training the GAN using the Feature matching loss. \n\nI liked the paper and the idea of using the discriminator of the GAN to detect novelty. But I do feel the paper lakes some details to better justify/explain the design choices:\n\n1. A multi-class GAN  is used but in the formal background presentation of GANs, section 2.2 only the binary version of the discriminator is presented. I think it would be helpful if the paper is more self contained and add the discriminator objective function to complete the presentation of the GAN design actually used.\nAlso would be nice if the authors can comment on whether the multi-class design necessary? can\'t the approach presented in the paper be naively extended to a regular GAN as long as it is trained to output a mixture distribution? \n\n2.  It is not clear to me why the Feature Matching loss results in a mixture distribution or more specifically why it results in a mixture distribution which is helpful for novelty detection? The paragraph before eq (7) and the two after hint to why this loss results in a good mixture distribution. I think this explanation would benefit from a more formal attempt of defining what is a ""good"" mixture distribution.  \n\n3. In addition to the above remark, generally I feel there is a gap between the definition of mixture distribution and proposition 1 to the actual implementation choice where it cannot be assumed the p_novel is known. I feel the paper would be clearer if the authors can draw a more direct connection.\n\n4. I am missing a baseline approach comparing to a \'regular\' multi-class GAN with a reject option. i.e. a GAN which was not trained to output a mixture distribution. Comparing ROC curves for the output of a discriminator from such a regular GAN to that of the ND-GAN would help to asses the importance of the discussion of the mixture distribution.\n\n5. Is the method proposed sensitive to noise, i.e will poor quality images of known classes have a higher chance to be classified as novel classes? \n\nSome typos such as :\n\n\'able to generates\'\n\'loss function i able to generate\'\n\'this the example\'']","[50, -70, 50]","[75, 20, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths ('well written', 'solid experiments') while also pointing out significant weaknesses ('results weak relative to naive baseline', 'weak comparisons'). The overall tone is balanced but leans positive due to the 'pros' outweighing the 'cons'. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and even suggests a potentially helpful reference. The reviewer maintains a professional tone, avoiding harsh language or personal attacks, and presents both positive and negative aspects in a balanced manner."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several issues with the paper, including logical gaps, lack of citation of relevant work, incremental novelty, strong distributional assumptions, and conceptual inconsistencies. The reviewer also questions the applicability of GANs to novelty detection and the nature of novelty detection itself. While the reviewer acknowledges some positive aspects (e.g., 'The technical difficulty is acceptable' and 'The experimental performance is promising'), these are outweighed by the numerous criticisms.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and academic tone throughout. They use phrases like 'there are several issues' and 'I am not sure' rather than more confrontational language. The reviewer also provides detailed explanations for their criticisms, which is a courteous approach in academic discourse. However, the overall tone is more matter-of-fact than overtly polite, hence the relatively low positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by saying they 'liked the paper and the idea,' indicating a generally positive view. However, they also mention that the paper 'lakes some details,' suggesting room for improvement. The overall tone is constructive rather than overly critical. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, such as 'I liked the paper,' 'would be nice if the authors can comment,' and 'I think it would be helpful.' They frame their criticisms as suggestions or questions rather than direct criticisms. The reviewer also acknowledges positive aspects before providing constructive feedback. The presence of detailed, specific recommendations also indicates a thorough and respectful review process.""]"
"['The authors explore how different methods of visualizing network decisions (saliency methods) react to mean shifts of the input data by comparing them on two networks that are build to compensate for this mean shift. With the emergence of more and more saliency methods, the authors contribute an interesting idea to a very important and relevant discussion.\n\nHowever, I\'m missing a more general and principled discussion. The question that the authors address is how different saliency methods react to transformations of the input data. Since the authors make sure that their two models compensate for these transformation, the difference in saliency can be only due to underlying assumptions about the input data made by the saliency methods and therefore the discussion boils down to which invariance properties are justified for which kind of input -- it is not by chance that the attribution methods that work are exactly those that extract statistics from the input data and therefore compensate for the input transformation: IG with black reference point and Pattern Attribution.\nThe mean shift explored by the authors assumes that there is no special point in the input space (especially that zero is not a special point).\nHowever, since images usally are considered bounded by 0 and 1 (or 255), there are in fact two special points (as a side note, in Figure 2 left column, the two inputs look very different which might be due to the fact that it is not at all obvious how to visualize ""image"" input that does not adhere to the common image input structure).\nWould the authors argue that scaling the input with a positive factor should also lead to invariant saliency methods?\nWhat about scaling with a negative factor?\nI would argue that if the input has a certain structure, then it should be allowed for the saliency method to make use of this structure.\n\nMinor points:\n\nUnderstanding the two models in section 3 is a bit hard since the main point (both networks share the weights and biases except for the bias of the first layer) is only said in 2.1\n', 'Saliency methods are effective tools for interpreting the computation performed by DNNs, but evaluating the quality of interpretations given by saliency methods are often largely heuristic. Previous work has tried to address this shortcoming by proposing that saliency methods should satisfy ""implementation invariance"", which says that models that compute the same function should be assigned the same interpretation. This paper builds on this work by proposing and studying ""input invariance"", a specific kind of implementation invariance between two DNNs that compute identical functions but where the input is preprocessed in different ways. Then, they examine whether a number of existing saliency methods satisfy this property.\n\nThe property of ""implementation invariance"" proposed in prior work seems poorly motivated, since the entire point of interpretations is that they should explain the computation performed by a specific network. Even if two DNNs compute the same function, they may do so using very different computations, in which case it seems natural that their interpretations should be different. Nevertheless, I can believe that the narrower property of input invariance should hold for saliency methods.\n\nA much more important concern I have is that the proposed input invariance property is not well motivated. A standard preprocessing step for DNNs is to normalize the training data, for example, by subtracting the mean and dividing by the standard deviation. Similarly, for image data, pixel values are typically normalized to [0,1]. Assuming inputs are transformed in this way, the input invariance property (for mean shift) is always trivially satisfied. The paper does not justify why we should consider networks where the training data is not normalized is such a way.\n\nEven if the input is not normalized, the failures they find in existing saliency methods are typically rather trivial. For example, for the gradient times input method, they are simply noting that the interpretation is translated by the gradient times the mean shift. The paper does not discuss why this shift matters. It is not at all clear to me that the quality of the interpretation is adversely affected by these shifts.\n\nI believe the notion that saliency methods should be invariant to input transformations may be promising, but more interesting transformations must be considered -- as far as I can tell, the property of invariance to linear transformations to the input does not provide any interesting insight into the correctness of saliency methods.\n', 'The scope of the paper is interesting i.e. taking a closer look at saliency methods in view of explaining deep learning neural networks. The authors state that saliency methods that do not satisfy an input invariance property can be misleading.\n\nOn the other hand the paper can be improved in my opinion in different aspects:\n- it would be good to be more precise on the type of invariance (e.g. translation invariance, rotation invariance etc.) or is the paper only about invariance to mean shifts? I suggest to explain in the introduction which type of invariances have been considered in the area of deep learning and then position the paper relative to it.\n- in the introduction the authors talk about an ""invariance axiom"": it was difficult to see where in the paper this axiom is precisely stated.\n- While in section 2.1 specifies a 3-layer MLP as the considered deep learning network. It is not clear why CNN haven\'t been used here (especially because the examples are on MNIST images), while in section 3.1 this is mentioned. \n- I think that the conclusion with respect to invariances could also depend on the choice of the activation function. Therefore the authors should from the beginning make more clear to which class of deep learning networks the study and conclusions apply.\n- From section 3.1 it becomes rather unclear which parts of the paper relate to the literature and which parts relate to section 2.1. Also the new findings or recommendations are not clear.\n\n\n\n\n\n']","[20, -50, -20]","[60, 20, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the importance and relevance of the authors' work in the first paragraph. However, the review then shifts to pointing out missing elements and suggesting improvements, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing criticisms as suggestions or questions rather than direct criticisms. For example, phrases like 'I'm missing' and 'Would the authors argue' maintain a polite tone while expressing concerns. The reviewer also acknowledges the authors' contribution before offering critiques, which is a polite approach in academic discourse."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's approach and motivation, particularly regarding the input invariance property and its relevance. The reviewer states that the property is 'not well motivated' and that the failures found in existing saliency methods are 'rather trivial'. However, the score is not lower because the reviewer does acknowledge some potential in the idea, stating that 'the notion that saliency methods should be invariant to input transformations may be promising'.\n\nThe politeness score is 20 because the reviewer maintains a professional and academic tone throughout, avoiding personal attacks or overly harsh language. They use phrases like 'I believe' and 'It is not at all clear to me' to express their opinions, which adds a level of politeness. However, the score is not higher because the criticism, while professionally expressed, is quite direct and does not include many softening phrases or positive reinforcement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting scope of the paper, they provide a list of aspects that need improvement, indicating that the paper has significant shortcomings. The overall tone suggests that substantial revisions are needed. The politeness score is moderately positive (60) as the reviewer uses polite language throughout, such as 'in my opinion' and 'I suggest,' which softens the criticism. They also start with a positive comment about the paper's scope before moving on to the improvements needed. The reviewer maintains a professional and constructive tone, offering specific suggestions for improvement rather than harsh criticism.""]"
"['The paper investigates how the learning rate and mini-batch size in SGD impacts the optima that the SGD algorithm finds.\nEmpirically, the authors argue that it was observed that larger learning rates converge to minima which are more wide,\nand that smaller learning rates more often lead to convergence to minima which are narrower, i.e. where the Hessian has large Eigenvalues. In this paper, the authors derive an analytical theory that aims at explaining this phenomenon.\n\nPoint of departure is an analytical theory proposed by Mandt et al., where SGD is analyzed in a continuous-time stochastic\nformalism. In more detail, a stochastic differential equation is derived which mimicks the behavior of SGD. The advantage of\nthis theory is that under specific assumptions, analytic stationary distributions can be derived. While Mandt et al. focused\non the vicinity of a local optima, the authors of the present paper assumed white diagonal gradient noise, which allows to\nderive an analytic, *global* stationary distribution (this is similar as in Langevin dynamics).\n\nThen, the authors focus again on individual local optima and ""integrate out"" the stationary distribution around a local optimum, using again a Gaussian assumption. As a result, the authors obtain un-normalized probabilities of getting trapped in a given local optimum. This un-normalized probability depends on the strength of the value of the loss function in the vicinity of the optimum, the gradient noise, and the width of the optima. In the end, these un-normalized probabilities are taken as\nprobabilities that the SGD algorithm will be trapped around the given optimum in finite time.\n\n\nOverall assessment:\nI find the analytical results of the paper very original and interesting. The experimental part has some weaknesses. The paper could be drastically improved when focusing on the experimental part.\n\nDetailed comments:\n\nRegarding the analytical part, I think this is all very nice and original. However, I have some comments/requests:\n\n1. Since the authors focus around Gaussian regions around the local minima, perhaps the diagonal white noise assumption could be weakened. This is again the multivariate Ornstein-Uhlenbeck setup examined in Mandt et al., and probably possesses an analytical solution for the un-normalized probabilities (even if the noise is multivariate Gaussian). Would the authors to consider generalizing the proof for the camera-ready version perhaps?\n\n2. It would be nice to sketch the proof of theorem 2 in the main paper, rather than to just refer to the appendix. In my opinion, the theorem results from a beautiful and instructive calculation that should provide the reader with some intuition.\n\n3. Would the authors comment on the underlying theoretical assumptions a bit more? In particular, the stationary distribution predicted by the Ornstein-Uhlenbeck formalism is never reached in practice. When using SGD in practice, one is in the initial mode-seeking phase. So, why is it a reasonable assumption to still use results obtained from the stationary (equilibrated) distribution which is never reached?\n\n\nRegarding the experiments: here I see a few problems. First, the writing style drops in quality. Second, figures 2 and 3 are cryptic. Why do the authors focus on two manually selected optima? In which sense is this statistically significant? How often were the experiments repeated? The figures are furthermore hard to read. I would recommend overhauling the entire experiments section.\n\nDetails:\n\n- Typo in Figure 2: ”with different with different”.\n- “the endpoint of SGD with a learning rate schedule η → η/a, for some a > 0, and a constant batch size S, should be the same\n  as the endpoint of SGD with a constant learning rate and a batch size schedule S → aS.” This is clearly wrong as there are many local minima, and running teh algorithm twice results in different local optima.  Maybe add something that this only true on average, like “the characteristics of these minima ... should be the same”.', ""The authors study SGD as a stochastic differential equation and use the Fokker planck equation from statistical physics to derive the stationary distribution under standard assumptions. Under a (somewhat strong) local convexity assumption, they derive the probability of arriving at a local minimum, in terms of the batchsize, learning rate and determinant of the hessian.\n\nThe theory in section 3 is described clearly, although it is largely known. The use of the Fokker Planck equation for stationary distributions of stochastic SDEs has seen wide use in the machine learning literature over the last few years, and this paper does not add any novel insights to that. For example, the proof of Theorem 1 in Appendix C is boilerplate. Also, though it may be relatively new to the deep learning/ML community, I don't see the need to derive the F-P equation in Appendix A.\n\nTheorem 2 uses a fairly strong locally convex assumption, and uses a straightforward taylor expansion at a local minimum. It should be noted that the proof in Appendix D assumes that the covariance of the noise is constant in some interval around the minimum; I think this is again a strong assumption and should be included in the statement of Theorem 2.\n\nThere are some detailed experiments showing the effect of the learning rate and batchsize on the noise and therefore performance of SGD, but the only real insight that the authors provide is that the ratio of learning rate to batchsize controls the noise, as opposed to the that of l.r. to sqrt(batchsize). I wish this were analyzed in more detail.\n\nOverall I think the paper is borderline; the lack of real novelty makes it marginally below threshold in my view."", 'In this paper, the authors present an analysis of SGD within an SDE framework. The ideas and the presented results are interesting and are clearly of interest to the deep learning community. The paper is well-written overall.\n\nHowever, the paper has important problems. \n\n1) The analysis is widely based on the recent paper by Mandt et al. While being an interesting work on its own, the assumptions made in that paper are very strict and not very realistic. For instance, the assumption that the stochastic gradient noise being Gaussian is very restrictive and trying to justify it just by the usual CLT is not convincing especially when the parameter space is extremely large, the setting that is considered in the paper.\n\n2) There is a mistake in the proof Theorem 1. Even with the assumption that the gradient of sigma is bounded, eq 20 cannot be justified and the equality can only be ""approximately equal to"". The result will only hold if sigma does not depend on theta. However, letting sigma depend on theta is the only difference from Mandt et al. On the other hand, with constant sigma the result is very trivial and can be found in any text book on SDEs (showing the Gibbs distribution). Therefore, presenting it as a new result is misleading.  \n\n3) Even if the sigma is taken constant and theorem 1 is corrected, I don\'t think theorem 2 is conclusive. Theorem 2 basically assumes that the distribution is locally a proper Gaussian (it is stated as locally convex, however it is taken as quadratic) and the result just boils down to computing some probability under a Gaussian distribution, which is still quite trivial. Apart from this assumption not being very realistic, the result does not justify the claims on ""the probability of ending in a certain minimum"" -- which is on the other hand a vague statement. First of all ""ending in"" a certain area depends on many different factors, such as the structure of the distribution, the initial point, the distance between the modes etc. Also it is not very surprising that the inverse image of a wider Gaussian density is larger than of a pointy one. This again does not justify the claims. For instance consider a GMM with two components, where the means of the individual components are close to each other, but one component having a very large variance and a smaller weight, and the other one having a lower variance and higher weight. With authors\' claim, the algorithm should spend more time on the wider one, however it is evident that this will not be the case. \n\n4) There is a conceptual mistake that the authors assume that SGD will attain the exact stationary distribution even when the SDE is simulated by the fixed step-size Euler integrator. As soon as one uses eta>0 the algorithm will never attain the stationary distribution of the continuous-time process, but will attain a stationary distribution that is close to the ideal one (of course with several smoothness, growth assumptions). The error between the ideal distribution and the empirical distribution will be usually O(eta) depending on the assumption and therefore changing eta will result in a different distribution than the ideal one. With this in mind the stationary distributions for (eta/S) and (2eta/2S) will be clearly different. \n\n\nThe experiments are very interesting and I do not underestimate their value. However, the current analysis unfortunately does not properly explain the rather strong claims of the authors, which is supposed to be the main contribution of this paper. \n']","[50, -40, -50]","[70, 20, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer finds the analytical results 'very original and interesting', but also points out weaknesses in the experimental part. The overall tone is constructive, suggesting improvements rather than outright criticism. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering suggestions and asking questions rather than making demands. Phrases like 'Would the authors consider...', 'It would be nice to...', and 'I would recommend...' contribute to the polite tone. The reviewer also balances criticism with praise, acknowledging the paper's strengths before discussing areas for improvement."", ""The sentiment score is -40 because the reviewer expresses a generally negative view of the paper, stating it lacks novelty and is 'borderline' and 'marginally below threshold'. However, they do acknowledge some positive aspects, such as clear description of theory and detailed experiments, which prevents the score from being more negative. The politeness score is 20 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They offer constructive feedback and acknowledge the paper's strengths alongside its weaknesses. The tone is polite but not overly deferential, maintaining a neutral professional stance while delivering criticism."", ""The sentiment score is -50 because while the reviewer acknowledges the paper's interesting ideas and good writing in the first paragraph, the bulk of the review is critical. The reviewer points out 'important problems', including mistakes in proofs, unrealistic assumptions, and conceptual errors. These criticisms outweigh the initial positive comments, resulting in a negative overall sentiment. The politeness score is 20 because the reviewer uses polite language throughout, such as 'interesting work' and 'I do not underestimate their value'. However, the criticisms are direct and unambiguous, which prevents a higher politeness score. The reviewer maintains a professional tone without resorting to personal attacks or overly harsh language, balancing critique with respect.""]"
"['This paper suggests a reparametrization of the transition matrix. The proposed reparametrization which is based on Singular Value Decomposition can be used for both recurrent and feedforward networks.\n\nThe paper is well-written and authors explain related work adequately. The paper is a follow up on Unitary RNNs which suggest a reparametrization that forces the transition matrix to be unitary. The problem of vanishing and exploding gradient in deep network is very challenging and any work that shed lights on this problem can have a significant impact. \n\nI have two comments on the experiment section:\n\n- Choice of experiments. Authors have chosen UCR datasets and MNIST for the experiments while other experiments are more common. For example, the adding problem, the copying problem and the permuted MNIST problem and language modeling are the common experiments in the context of RNNs. For feedforward settings, classification on CIFAR10 and CIFAR100 is often reported.\n\n- Stopping condition. The plots suggest that the optimization has stopped earlier for some models. Is this because of some stopping condition or because of gradient explosion? Is there a way to avoid this?\n\n- Quality of figures. Figures are very hard to read because of small font. Also, the captions need to describe more details about the figures.', ""The paper introduces SVD parameterization and uses it mostly for controlling the spectral norm of the RNN. \n\nMy concerns with the paper include: \n\na) the paper says that the same method works for convolutional neural networks but I couldn't find anything about convolution. \n\nb) the theoretical analysis might be misleading --- clearly section 6.2 shouldn't have title ALL CRITICAL POINTS ARE GLOBAL MINIMUM because 0 is a critical point but it's not a global minimum. Theorem 5 should be phrased as \n\nall critical points of the population risk that is non-singular are global minima.\n\nc) the paper should run some experiments on language applications where RNN is widely used\n\nd) I might be wrong on this point, but it seems that the GPU utilization of the method would be very poor so that it's kind of impossible to scale to large datasets? \n"", ""This paper proposed a new parametrization scheme for weight matrices in neural network based on the Householder  reflectors to solve the gradient vanishing and exploding problems in training. The proposed method improved two previous papers:\n1) stronger expressive power than Mahammedi et al. (2017),\n2) faster gradient update than Vorontsov et al. (2017).\nThe proposed parametrization scheme is natrual from numerical linear algebra point of view and authors did a good job in Section 3 in explaining the corresponding expressive power. The experimental results also look promising. \n\nIt would be nice if the authors can analyze the spectral properties of the saddle points in linear RNN (nonlinear is better but it's too difficult I believe). If the authors can show the strict saddle properties then as a corollary, (stochastic) gradient descent finds a global minimum. \n\nOverall this is a strong paper and I recommend to accept.""]","[60, -40, 80]","[80, 20, 70]","[""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'well-written' and noting that the work could have 'significant impact'. The reviewer also acknowledges the importance of the problem being addressed. However, it's not extremely positive as the reviewer does have some comments and suggestions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively, and framing their comments as suggestions rather than criticisms. The reviewer uses phrases like 'I have two comments' and asks questions rather than making demands, which contributes to the polite tone. The comments are constructive and aimed at improving the paper rather than dismissing it."", ""The sentiment score is -40 because the review primarily focuses on concerns and criticisms of the paper, indicating a generally negative sentiment. However, it's not extremely negative as the reviewer acknowledges the paper's introduction of SVD parameterization and its use for controlling the spectral norm of RNN. The politeness score is 20 because the language used is professional and constructive, without any harsh or rude expressions. The reviewer uses phrases like 'My concerns include' and 'I might be wrong on this point,' which show a level of politeness and openness to dialogue. However, the score is not higher as the review doesn't include any explicitly positive or encouraging comments, which would be considered more polite in academic discourse."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, highlighting its strengths and improvements over previous work. The reviewer states it's a 'strong paper' and recommends acceptance. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the authors' good work and offering a suggestion for improvement in a constructive manner. The phrase 'It would be nice if...' is particularly polite. The scores are not 100 in either case as there is room for even more enthusiastic praise or more overtly polite language, but the overall tone is decidedly positive and courteous.""]"
"['The paper proposes a modified GAN objective, summarized in Eq.(3). It consists of two parts:\n(A) Classic GAN term: \\E_{x ~ P_{data} } \\log D\'(x) + \\E_{z ~ P_{Z}, z\' ~ P_{Z\'}  } \\log D\'( G(z\',E(x))   )\n(B) Invariant Encoding term: \\E_{x ~ P_{data} }  [ \\log D(T(x),x) + \\E_{z\' ~ P_{Z\'}  } \\log D( G(z\',E(x)), x   ) ]\n\nTerm (A) is standard, except the latent space of original GAN is decomposed into (1) the feature, which should be invariant between x and T(x), and (2) the noise, which is for the diversity of generated x.\n\nTerm (B) is the proposed invariant-encoding scheme. It is essentially a conditional GAN, where the the generated sample G(z\',E(x)) is conditioned on input sample x, which guarantees that the generated sample is T(x) of x. \nIn fact, this could be theoretically justified. Suggestion: the authors might want to follow the proofs of Proposition 1 or 2 in [*] to show similar conclusion, making the paper stronger.\n\n[*] ALICE: Towards Understanding Adversarial Learning for Joint Distribution Matching, NIPS 2017\n\nThe definition of feature-invariant is E(T(x))=E(x)=E(G(z\',E(x))), while the objective of the paper achieves T(x)=G(z\',E(x)). Applying E() to both side yields the invariant features.  It might be better to make this point clear.\n\nOverall Comments:\n\nOriginality: the proposed IVE-GAN algorithm is quite novel.\nQuality: The paper could be stronger, if the theoretical justification has been provided. \nClarity: Overall clear, while important details are missing. Please see some points in Detailed Comments.\nSignificance: The idea is interesting, it would be better if the quantitative evidence has been provided to demonstrate the use of the learned invariant feature. For example, some classification task to demonstrate the learned rotation-invariant feature shows higher accuracy.\n\nDetailed Comments:\n\n-- In Figure 1, please explains that ""||"" is the concatenation operator for better illustration.\n\n-- When summarizing the contributions of the paper, it is mentioned that ""our GANs ... without mode collapsing issues"". This is a strong point to claim. While precisely identifying the ""mode collapsing issue"" itself is difficult, the authors only show that samples in all modes are generated on the toy datasets. Please consider to rephrase. \n\n-- In Section 2, y is first used to indicate true/false of x in Eq.(1), then y is used to indicate the associated information (e.g., class label) of x in Eq.(2). Please consider to avoid overloading notations.\n\n-- In Eq.(3), the expectation \\E_{z ~ P_Z} in the 3rd term is NOT clear, as z is not involved in the evaluation. I guess it may be implemented as z=E(x), where x ~ P_{data}. From the supplement tables, It seems that the novel sample G(z\', E(x)) is implemented as G evaluated on the concatenation of noise sample z\' ~ P_{Z\'} and encoded feature z=E(x). \nI am wondering how to generate novel samples? Related to this,  Please clarify how to implement: ""To generate novel samples, we can draw samples z ~ P_Z as latent space"".\n\n-- Section 5, ""include a encoding unit"" ---> ""an""\n\n-- In Supplement, please revise G(z\'E(x)) to G(z\', E(x)) in every table.\n', 'This paper proposes a GAN-based approach to learning factored latent representations of images. The latent space is factored into a set of variables encoding image identity and another set of variables encoding deformations of the image. Variations on this theme have been presented previously (see, e.g. ""Learning to Generate Chairs with Convolutional Neural Networks"" by Dosvitskiy et al., CVPR 2015). There\'s also some resemblance to methods for learning unsupervised embeddings based on discrimination between ""invariance classes"" of images (see, e.g. ""Discriminative Unsupervised Feature Learning with Convolutional Neural Networks"" by Dosovitskiy et al., NIPS 2014). The submitted paper is the first GAN-based paper on this precise topic I\'ve seen, but it\'s hard to keep up these days.\n\nThe method described in the paper applies existing ideas about learning factored image representations which split features into subsets describing image type and variation. The use of GANs is a somewhat novel extension of existing conditional GAN methods. The paper is reasonably written, though many parentheses are missing. The qualitative results seem alright, and generally comparable to concurrent work on GANs. No concrete tasks or quantitative metrics are provided. Perhaps the authors could design a simple classification-based metric using a k-NN type classifier on top of the learned representations for the MNIST or CelebA tasks. The t-SNE plots suggest a comparison with the raw data will be favourable (though stronger baselines would also be needed). \n\nI\'m curious why no regularization (e.g., some sort of GAN cost) was placed on the marginal distribution of the ""image type"" encodings E(x). It seems like it would be useful to constrain these encodings to be distributionally similar to the prior from which free samples will be drawn.', 'This paper presents the IVE-GAN, a model that introduces en encoder to the Generative Adversarial Network (GAN) framework. The model is evaluated qualitatively through samples and reconstructions on a synthetic dataset, MNIST and CelebA.\n\nSummary: \nThe evaluation is superficial, no quantitative evaluation is presented and key aspects of the model are not explored. Overall, there just is not enough innovation or substance to warrant publication at this point.\n\nImpact:\nThe motivation given throughout the introduction -- to add an encoder (inference) network to GANs -- is a bit odd in the light of the existing literature. In addition to the BiGAN/ALI models that were cited, there are a number of (not cited) papers with various ways of combining GANs with VAE encoders to accomplish exactly this. If your goal was to improve reconstructions in ALI, one could simply add an reconstruction (or cycle) penalty to the ALI objective as advocated in the (not cited) ALICE paper (Li et al., 2017 -- ""ALICE: Towards Understanding Adversarial Learning for Joint Distribution Matching""). \n\nThe training architecture presented here is novel as far as I know, though I am unconvinced that it represents an optimum in model design space. The model presented in the ALICE paper would seem to be a more elegant solution to the motivation given in this paper.\n\nModel Feature:\nThe authors should discuss in detail the interaction between the regular GAN pipeline and the introduced variant (with the transformations). Why is the standard GAN objective thrown in? I assume it is to allow you to sample directly from the noise in z (as opposed to z\' which is used for reconstruction), but this is not discussed in much detail. The GAN objective and the added IVE objective seem like they will interact in not all together beneficial ways, with the IVE component pushing to make the distribution in z complicated. This would result in a decrease in sample quality. Does it? Exploration of this aspect of the model should be included in the empirical evaluation.\n\nAlso the addition of the transformations added to the proposed IVE pipeline seem to cause the latent variations z\' to encode these variations rather than the natural variations that exist in the dataset. They would seem to make it difficult to encode someone face and make some natural manipulates (such as adjusting the smile) that are not included in this transformations.\n\nEmpirical Evaluation:\nComparison to BiGAN/ALI: The authors motivate their work by drawing comparisons to BiGAN/ALI, showing CelebA reconstructions from the ALI paper in the appendix. The comparison is not fair for two reasons, (1) authors should state that their reconstructions are made at a higher resolution (seems like 128x128, which is now standard but was not so when the BiGAN/ALI papers came out, they were sampled at 64x64), also, unlike the ALI results, they authors cut the background away from the CelebA faces. This alone could account for the difference between the two models, as ICE-GAN only has to encode the variability extant in faces and hair, ALI had to additionally encode the much greater variability in the background. The failure to control the experimental conditions makes this comparison inappropriate. \n\nThere is no quantitative evaluations at all. While many GAN papers do not place an emphasis on quantitative evaluations, at this point, I consider the complete lack of such an evaluation as a weakness of the paper. \n\nFinally, based on just the samples offered in the paper, which is admittedly a fairly weak standard, the model does not seem to be among the state-of-the-art on CelebA that have been reported in the literature. Given the rapid progress that is being made, I do not feel this should be could against this particular paper, but the quality of samples cannot be considered a compelling reason to accept the paper.\n\nMinor comment:\nThe authors appear to be abusing the ICLR style file by not leaving a blank line  between paragraphs. This is annoying and not at all necessary since ICLR does not have a strict page limit. \n\nFigure 1 is not consistent with the model equations (in Eqns. 3). In particular, Figure 1 is missing the standard GAN component of the model.\n\nI assume that the last term in Eqns 3 should have G(z) as opposed to G(z\',E(x)). Is that right?']","[50, -20, -70]","[80, 50, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty of the proposed IVE-GAN algorithm and finds the idea interesting. However, they also point out areas for improvement, such as providing theoretical justification and quantitative evidence. The overall tone is constructive rather than overtly critical or enthusiastic. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering suggestions rather than demands (e.g., 'Please consider to rephrase', 'It might be better to make this point clear'). They also balance critique with positive comments and provide detailed, helpful feedback without using harsh or dismissive language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'reasonably written', 'qualitative results seem alright'), they also point out several limitations and areas for improvement. The reviewer suggests that the approach is not entirely novel and lacks quantitative metrics, which contributes to the negative sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I'm curious' and offer suggestions for improvement rather than harsh criticism. The language is respectful and focuses on the content rather than personal attacks, which contributes to the polite tone."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the evaluation is 'superficial', there's 'not enough innovation or substance to warrant publication', and points out several weaknesses in the paper's approach and comparisons. However, it's not entirely negative as the reviewer acknowledges some novel aspects. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I assume', 'I consider', and 'I am unconvinced' rather than making blunt statements. They also offer constructive feedback and suggestions for improvement. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score.""]"
"['Summary:\n\nThis paper optimizes the beta-VAE objective and analyzes the resulting models in terms of the two components of the VAE loss: the reconstruction error (which the authors refer to as distortion, “D”) and the KL divergence term (which the authors refer to as rate, “R”). Various VAEs using either PixelCNN++ or a simpler model for the encoder, decoder, or marginal distribution of a VAE are trained on MNIST (with some additional results on OMNIGLOT) and analyzed in terms of samples, reconstructions, and their rate-distortion trade-off.\n\nReview:\n\nI find it difficult to point my finger to novel conceptual or theoretical insights in this paper. The idea of maximizing information for unsupervised learning of representations has of course been explored a lot (e.g., Bell & Sejnowski, 1995). Deeper connections between variational inference and rate-distortion have been made before (e.g., Balle et al., 2017; Theis et al., 2017), while this paper merely seems to rename the reconstruction and KL terms of the ELBO. Variational lower and upper bounds on mutual information have been used before as well (e.g., Barber & Agakov, 2003; Alemi et al., 2017), although they are introduced like new results in this paper. The derived “sandwich equation” only seems to be used to show that H - D - R <= 0, which also follows directly from Gibbs’ inequality (since the left-hand side is a negative KL divergence). The main contributions therefore seem to be the proposed analysis of models in the R-D plane, and the empirical contribution of analyzing beta-VAEs.\n\nBased on the R-D plots, the authors identify a potential problem of generative models, namely that none of the trained models appear to get close to the “auto-encoding limit” where the distortion is close zero. Wouldn’t this gap easily be closed by a model with identity encoder, identity decoder, and PixelCNN++ for the marginal distribution? Given that autoregressive models generally perform better than VAEs in terms of log-likelihood, the model’s performance would probably be closer to the true entropy than the ELBO plotted in Figure 3a). What about increasing the capacity of the used in this paper? This makes me wonder what exactly the R-D plot can teach us about building better generative models.\n\nThe toy example in Figure 2 is interesting. What does it tell us about how to build our generative models? Should we be using powerful decoders but a lower beta?\n\nThe authors write: “we are able to learn many models that can achieve similar generative performance but make vastly different trade-offs in terms of the usage of the latent variable”. Yet in Figure 3b) it appears that changing the rate of a model can influence the generative performance (ELBO) quite a bit?', 'EDIT:  I have reviewed the authors revisions and still recommend acceptance. \n\n\nSummary\n\nThis paper proposes assessing VAEs via two quantities: rate R (E[ KLD[q(z|x) || p(z)] ]) and distortion D (E[ log p(x|z) ]), which can be used to bound the mutual information (MI) I(x,z) from above and below respectively (i.e. H[x] - D <= I(x,z) <= R).  This fact then implies the inequality H[x] <= R + D, where H[x] is the entropy of the true data distribution, and allows for the construction of a phase diagram (Figure 1) with R and D on the x and y axis respectively.  Models can be plotted on the diagram to show the degree to which they favor reconstruction (D) or sampling diversity (R).  The paper then reports several experiments, the first being a simulation to show that a VAE trained with vanilla ELBO cannot recover the true rate in even a 1D example.  For the second experiment, 12 models are trained by varying the encoder/decoder strength (CNN vs autoregressive) and prior (fact. Gauss vs autoregressive vs VampPrior).  Plots of the D vs R and ELBO vs R are shown for the models, revealing that the same ELBO value can be decomposed into drastically different R and D values.  The point is further made through qualitative results in Figure 4.   \n\n\nEvaluation\n\nPros:  While no one facet of the paper is particularly novel (as similar observations and discussion has been made by [1-4]), the paper, as far as I’m aware, is the first to formally decompose the ELBO into the R vs D tradeoff, which is natural.  As someone who works with VAEs, I didn’t find the conclusions surprising, but I imagine the paper would be valuable to someone learning about VAEs.  Moreover, it’s nice to have a clear reference for the unutilized-latent-space-behavior mentioned in various other VAE papers.  The most impressive aspect of the paper is the number of models trained for the empirical investigation.  Placing such varied models (CNN vs autoregressive vs VampPrior etc) onto the same plot from comparison (Figure 3) is a valuable contribution.       \n\nCons:  As mentioned above, I didn’t find the paper conceptually novel, but this isn’t a significant detraction as its value (at least for VAE researchers) is primarily in the experiments (Figure 3).  I do think the paper---as the ‘Discussion and Further Work’ section is only two sentences long---could be improved by providing a better summary of the findings and recommendations moving forward.  Should generative modeling papers be reporting final R and D values in addition to marginal likelihood?  How should an author demonstrate that their method isn’t doing auto-decoding?  The conclusion claims that “[The rate-distortion tradeoff] provides new methods for training VAE-type models which can hopefully advance the state of the art in unsupervised representation learning.”  Is this referring to the constrained optimization problem given in Equation #4?  It seems to me that the optimal R-vs-D tradeoff is application dependant; is this not always true?      \n\nMiscellaneous / minor comments:  Figure 3 would be easier to read if the dots better reflected their corresponding tuple (although I realize representing all tuple combinations in terms of color, shape, etc is hard).  I had to keep referring to the legend, losing my place in the scatter plot.  I found sections 1 and 2 rather verbose; I think some text could be cut to make room for more final discussion / recommendations.  For example, I think the first two whole paragraphs could be cut or at least condensed and moved to the related works section, as they are just summarizing research history/trends.  The paper’s purpose clearly starts at the 3rd paragraph (“We are interested in understanding…”).  The references need cleaned-up.  There are several conference publications that are cited via ArXiv instead of the conference (IWAE should be ICLR, Bowman et al. should be CoNLL, Lossy VAE should be ICLR, Stick-Breaking VAE should be ICLR, ADAM should be ICLR, Inv Autoregressive flow should be NIPS, Normalizing Flows should be ICML, etc.), and two different versions of the VAE paper are cited (ArXiv and ICLR).  \n\n\nConclusions\n\nI found this paper to present valuable analysis of the ELBO objective and how it relates to representation learning in VAEs.  I recommend the paper be accepted, although it could be substantially improved by including more discussion at the end.  \n\n\n\n1.  S. Zhao, J. Song, and S. Ermon.  “InfoVAE: Information Maximizing Variational Autoencoders.”  ArXiv 2017.\n\n2.  X. Chen, D. Kingma, T. Salimans, Y. Duan, P. Dhariwal, J. Shulman, I. Sutskever, and P. Abbeel.  “Variational Lossy Autoencoder.”  ICLR 2017.\n\n3.  I. Higgins, L. Matthey, A. Pal, C. Burgess, X. Glorot, M. Botvinick, S. Mohamed, and A. Lerchner. “Beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework.”  ICLR 2017\n\n4.  S. Bowman, L. Vilnis, O. Vinyas,  A. Dai, R. Jozefowicz, and S. Bengio.  “Generating Sentences from a Continuous Space.”  CoNLL 2016.', '\n- I think that VAEs are rather forced to be interpreted from an information theoretic point of view for the sake of it, rather than for the sake of a clear and unequivocal contribution from the perspective of VAEs and latent-variable models themselves. How is that useful for a VAE? \n\n- ""The left vertical line corresponds to the zero rate setting. ..."": All these limits are again from an information theoretic point of view and no formulation nor demonstration is provided on how this can actually be as useful. As mentioned earlier in the paper, there are well-known problems with taking this information theory perspective, e.g. difficulties in estimating MI values, etc.\n\n- Breaking (some of) the long sentences and paragraphs in page 3 with an unequivocal mathematical formulation would smooth the flow a bit.\n\n- ""(2) an upper bound that measures the rate, or how costly it is to transmit information about the latent variable."": I am not entirely sure about this one and why it is massively important to be compromised against the obviously big first term.\n\n- Toy Model experiment: I do not see any indication of how this is not just a lucky catch and that VAEs consistently suffer from a problem leading to such effect.\n\n- Section 5: ""can shed light on many different models and objectives that have been proposed in the literature... "": Again the contribution aspect is not so clear through the word ""shed light"".\n\n\nMinor\n- Although apparently VAEs represent the main and most influential latent-variable model example, I think switching too much between citing them as VAEs and then as latent-variable models in general was a bit confusing. I propose mentioning in the beginning (as happened) that VAEs are the seminal example of latent-variable models and then going on from this point onwards with VAEs without too much alternation between latent-variable models and VAEs.\n\n- page 8: ""as show""']","[-40, 70, -50]","[20, 80, 20]","[""The sentiment score is -40 because the reviewer expresses significant skepticism about the paper's novelty and contributions. They state it's 'difficult to point my finger to novel conceptual or theoretical insights' and question the usefulness of the main analysis method. However, it's not entirely negative as they do find some aspects 'interesting'. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and constructive manner. They use phrases like 'I find it difficult' rather than making blunt negative statements, and they pose their criticisms as questions for the authors to consider, which is a polite way of pointing out potential issues."", ""The sentiment score is 70 (positive) because the reviewer recommends acceptance and provides several positive comments about the paper's value and contributions. They mention that while not conceptually novel, the paper offers valuable analysis and experiments. The politeness score is 80 (polite) due to the reviewer's constructive and respectful tone throughout. They balance praise with suggestions for improvement, using phrases like 'I found this paper to present valuable analysis' and 'it could be substantially improved by'. The reviewer also acknowledges the paper's strengths and the effort put into the experiments. The language is professional and courteous throughout, avoiding any harsh criticism or dismissive remarks."", ""The sentiment score is -50 because the review is generally critical and skeptical of the paper's approach and contributions. The reviewer questions the usefulness of the information theoretic perspective, expresses doubt about the importance of certain aspects, and suggests that the paper's contributions are not clear. However, it's not entirely negative as the reviewer does provide constructive feedback and suggestions for improvement. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I think' and 'I propose' which soften the criticism. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback. However, the language is not overtly polite or deferential, hence the relatively low positive score.""]"
"['\nSUMMARY\n\nThis paper addresses the cybersecurity problem of domain generation algorithm (DGA)  detection. A class of malware uses algorithms to automatically generate artificial domain names for various purposes, e.g. to generate large numbers of rendezvous points. DGA detection concerns the (automatic) distinction of actual and artificially generated domain names. In this paper, a basic problem formulation and general solution approach is investigated, namely that of treating the detection as a text classification task and to let domain names arrive to the classifier as strings of characters. A set of five deep learning architectures (both CNNs and RNNs) are compared empirical on the text classification task. A domain name data set with two million instances is used for the experiments. The main conclusion is that the different architectures are almost equally accurate and that this prompts a preference of simpler architectures over more complex architectures, since training time and the likelihood for overfitting can potentially be reduced.\n\nCOMMENTS\n\nThe introduction is well-written, clear, and concise. It describes the studied real-world problem and clarifies the relevance and challenge involved in solving the problem. The introduction provides a clear overview of deep learning architectures that have already been proposed for solving the problem as well as some architectures that could potentially be used. One suggestion for the introduction is that the authors take some of the description of the domain problem and put it into a separate background section to reduce the text the reader has to consume before arriving at the research problem and proposed solution.\n\nThe methods section (Section 2) provides a clear description of each of the five architectures along with brief code listings and details about whether any changes or parameter choices were made for the experiment. In the beginning of the section, it is not clarified why, if a 75 character string is encoded as a 128 byte ASCII sequence, the content has to be stored in a 75 x 128 matrix instead of a vector of size 128. This is clarified later but should perhaps be discussed earlier to allow readers from outside the subarea to grasp the approach.\n\nSection 3 describes the experiment settings, the results, and discusses the learned representations and the possible implications of using either the deep architectures or the “baseline” Random Forest classifier. Perhaps, the authors could elaborate a little bit more on why Random Forests were trained on a completely different set of features than the deep architectures? The data is stated to be randomly divided into training (80%), validation (10%), and testing (10%). How many times is this procedure repeated? (That is, how many experimental runs were averaged or was the experiment run once?).\n\nIn summary, this is an interesting and well-written paper on a timely topic. The main conclusion is intuitive. Perhaps the conclusion is even regarded as obvious by some but, in my opinion, the result is important since it was obtained from new, rather extensive experiments on a large data set and through the comparison of several existing (earlier proposed) architectures. Since the main conclusion is that simple models should be prioritised over complex ones (due to that their accuracy is very similar), it would have been interesting to get some brief comments on a simplicity comparison of the candidates at the conclusion.\n\nMINOR COMMENTS\n\nAbstract: “Little studies” -> “Few studies”\n\nTable 1: “approach” -> “approaches”\n\nFigure 1: Use the same y-axis scale for all subplots (if possible) to simplify comparison. Also, try to move Figure 1 so that it appears closer to its inline reference in the text.\n\nSection 3: “based their on popularity” -> “based on their popularity”\n\n', 'This paper applies several NN architectures to classify url’s between benign and malware related URLs.\nThe baseline is random forests and feature engineering.\n\nThis is clearly an application paper. \nNo new method is being proposed, only existing methods are applied directly to the task.\n\nI am not familiar with the task at hand so I cannot properly judge the quality/accuracy of the results obtained but it seems ok.\nFor evaluation data was split randomly in 80% train, 10% test and 10% validation. Given the amount of data 2*10**6 samples, this seems sufficient.\nI think the evaluation could be improved by using malware URLs that were obtained during a larger time window.\nSpecifically, it would be nice if train, test and validation URLs would be operated chronologically. I.e. all train url precede the validation and test urls.\nIdeally, the train and test urls would also be different in time. This would enable a better test of the generalization capabilities in what is essentially a continuously changing environment. \n\nThis paper is a very difficult for me to assign a final rating.\nThere is no obvious technical mistake  and the paper is written reasonably well.\nThere is however a lack of technical novelty or insight in the models themselves. \nI think that the paper should be submitted to a journal or conference in the application domain where it would be a better fit.\n\nFor this reason, I will give the score marginally below the acceptance threshold now.\nBut if the other reviewers argue that the paper should be accepted I will change my score.\n\n', 'This paper proposes to automatically recognize domain names as malicious or benign by deep networks (convnets and RNNs) trained to directly classify the character sequence as such.\n\n\nPros\n\nThe paper addresses an important application of deep networks, comparing the performance of a variety of different types of model architectures.\n\nThe tested networks seem to perform reasonably well on the task.\n\n\nCons\n\nThere is little novelty in the proposed method/models -- the paper is primarily focused on comparing existing models on a new task.\n\nThe descriptions of the different architectures compared are overly verbose -- they are all simple standard convnet / RNN architectures.  The code specifying the models is also excessive for the main text -- it should be moved to an appendix or even left for a code release.\n\nThe comparisons between various architectures are not very enlightening as they aren’t done in a controlled way -- there are a large number of differences between any pair of models so it’s hard to tell where the performance differences come from. It’s also difficult to compare the learning curves among the different models (Fig 1) as they are in separate plots with differently scaled axes.\n\nThe proposed problem is an explicitly adversarial setting and adversarial examples are a well-known issue with deep networks and other models, but this issue is not addressed or analyzed in the paper. (In fact, the intro claims this is an advantage of not using hand-engineered features for malicious domain detection, seemingly ignoring the literature on adversarial examples for deep nets.) For example, in this case an attacker could start with a legitimate domain name and use black box adversarial attacks (or white box attacks, given access to the model weights) to derive a similar domain name that the models proposed here would classify as benign.\n\n\nWhile this paper addresses an important problem, in its current form the novelty and analysis are limited and the paper has some presentation issues.']","[70, -20, -40]","[80, 50, 20]","[""The sentiment score is 70 (positive) because the reviewer describes the paper as 'interesting and well-written' and praises various aspects such as the clear introduction, well-described methods, and the importance of the results. The reviewer also provides constructive suggestions for improvement, indicating a generally positive but not overly effusive sentiment. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offers suggestions in a constructive manner (e.g., 'Perhaps the authors could elaborate...'), and balances criticism with praise. The reviewer also uses phrases like 'in my opinion' to soften critiques. The language is consistently professional and courteous, without any harsh or rude comments."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that there are no obvious technical mistakes and the paper is reasonably well-written, they express concerns about the lack of technical novelty and suggest that the paper would be a better fit for a different journal or conference. The reviewer also states that they will give a score 'marginally below the acceptance threshold'. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges their own limitations in judging certain aspects, and shows willingness to change their score if other reviewers disagree. They also provide constructive feedback for improvement without using harsh or dismissive language."", ""The sentiment score is -40 because while the reviewer acknowledges some positive aspects ('Pros' section), the overall tone is critical. The 'Cons' section is longer and more detailed, highlighting significant issues with novelty, presentation, and lack of addressing important concerns like adversarial attacks. The politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language to express criticisms. They acknowledge the importance of the problem and some strengths of the paper before detailing the weaknesses. The reviewer avoids harsh or personal criticisms, instead focusing on specific aspects of the paper that could be improved.""]"
"['Update:\n\nI\'m going to change my review to a 6 to acknowledge the substantial improvements you\'ve made—I no longer fear that there are major errors in the paper, but this paper is still solidly borderline, and I\'m not completely convinced that any new claim is true. The evidence presented for the main claim—that you can get by without an autoregressive decoder when pretraining encoders—is somewhat persuasive, but isn\'t as unequivocal as I\'d hope, and even if the claim is true, it is arguably too limited a claim for an ICLR main conference paper. As R1 says, a *ACL short paper would be more appropriate.  The writing is also still unclear in places.\n\n----\n\nThis paper presents a new RNN encoder–CNN decoder hybrid design for use in pretraining reusable sentence encoders on Kiros\'s SkipThought objective. The task is interesting and important, and the results are generally good: The new model outperforms SkipThought, and all other prior models for training sentence encoders on unlabeled data. However, some of the design choices seem a bit odd, and I have a large number of minor concerns about the paper. I\'d like to see the authors\' replies and the other reviews before I can confidently endorse this paper as correct.\n\n\nNon-autoregressive decoding with a CNN strikes me as a somewhat ill-posed problem, even for in this case where you don\'t actually use the decoder in the final application of your model. At each position, you\'re training your model to predict a distribution over all words that could appear at the beginning/tenth position/twentieth position in sentences on some topic. I\'d appreciate some more discussion of why this should or shouldn\'t hurt performance. I\'d be less concerned about this if the results supporting the use of the CNN decoder were a bit more conclusive: while they are better on average across your smaller experiments, your largest experiment (2400D) shows them roughly tied.\n\nYour paper opens with the line ""Context information plays an important role in human language understanding."" This sounds like it\'s making an empirical claim that your paper doesn\'t support, but it\'s so vague that it\'s hard to tell exactly what that claim is. Please clarify this or remove it.\n\nThis sentence is quite inaccurate: ""The idea of learning from the context information was first successfully applied to vector representation learning for words in Mikolov et al. (2013b) and learning from the occurrence of words also succeeded in Pennington et al. (2014)."" Turney and Pantel 2010 ( https://www.jair.org/media/2934/live-2934-4846-jair.pdf ) offer a survey of the substantial prior work that existed at that time.\n\nThe ""Neighborhood Hypothesis"" is given quite a lot of importance, given that it\'s a fairly small empirical effect without any corresponding theory. The fact that it\'s emphasized so heavily makes me suspect that I can guess the author of the paper. I\'d tone down that part of your framing.\n\nI would appreciate some more analysis of which of the non-central tricks that you describe in section 3 help. For example, max pooling seems reasonable, but you report yourself that mean pooling generally works much better in prior work. Without an explicit experiment, it\'s not clear why you\'d add a mean pooling component.\n\nIt seems misleading to claim that your CNN is modeled after AdaSent, as that model uses a number of layers that varies with the length of the sentence (and differs from yours in a few other less-important ways). Please correct or clarify.\n\nThe use of “†” in table to denote models that predict the next sentence in a sequence doesn\'t make sense. It should apply to all of your models if I understand correctly. Please clarify.\n\nYou could do a better job at table placement and formatting. Table 3 is in the wrong section, for example.\n\nYou write that: ""Our proposed RNN-CNN model gets similar result on SNLI as Skip-thought, but with much less training time."" This seems to be based on a comparison between your model run on your hardware and their model run on their (presumably older) hardware, and possibly also with their older version of CuDNN. If that\'s right, you should tone down this claim or offer some more evidence.', '\n-- updates to review: --\n\nThanks for trying to respond to my comments. I find the new results very interesting and fill in some empirical gaps that I think were worth investigating. I\'m now more confident that this paper is worth publishing and I increased my rating from 6 to 7. \n\nI admit that this is a pretty NLP-specific paper, but to the extent that ICLR has core NLP papers (I think it does have some), I think the paper is a reasonable fit for ICLR. It might feel more at home at a *ACL conference though. \n\n-- original review is below: --\n\nThis paper is about modifications to the skip-thought framework for learning sentence embeddings. The results show performance comparable to or better than skip-thought while decreasing training time. \n\nI think the overall approach makes sense: use an RNN encoder because we know it works well, but improve training efficiency by changing the decoder to a combination of feed-forward and convolutional layers. \n\nI think it may be the case that this works well because the decoder is not auto-regressive but merely predicts each word independently. This is possible because the decoder will not be used after training. So all the words can be predicted all at once with a fixed maximum sentence length. In typical encoder-decoder applications, the decoder is used at test time to get predictions, so it is natural to make it auto-regressive. But in this case, the decoder is thrown away after training, so it makes more sense to make the decoder non-auto-regressive.  I think this point should be made in the paper. \n\nAlso, I think it\'s worth noting that an RNN decoder could be used in a non-auto-regressive architecture as well. That is, the sentence encoding could be mapped to a sequence of length 30 as is done with the CNN decoder currently; then a (multi-layer) BiLSTM could be run over that sequence, and then a softmax classifier can be attached to each hidden vector to predict the word at that position. It would be interesting to compare that BiLSTM decoder with the proposed CNN decoder and also to compare it to a skip-thought-style auto-regressive RNN decoder. This would let us understand whether the benefit is coming more from the non-auto-regressive nature of the decoder or from the CNN vs RNN differences. \n\nThat is, it would make sense to factor the decision of decoder design along multiple axes. One axis could be auto-regressive vs predict-all-words. Another axis could be using a CNN over the sequence of word positions or an RNN over the sequence of word positions.  For auto-regressive models, another axis could be train using previous ground-truth word vs train using previous predicted word.  Skip-thought corresponds to an auto-regressive RNN (using the previous ground-truth word IIRC).  The proposed decoder is a predict-all-words CNN.  It would be natural to also experiment with an auto-regressive CNN and a predict-all-words RNN (like what I described in the paragraph above). The paper is choosing a single point in the space and referring to it as a ""CNN decoder"" whereas there are many possible architectures that can be described this way and I think it would strengthen the paper to increase the precision in discussing the architecture and possible alternatives. \n\nOverall, I think the architectural choices and results are strong enough to merit publication. Adding any of the above empirical comparisons would further strengthen the paper. \n\nHowever, I did have quibbles with some of the exposition and some of the claims made throughout the paper. They are detailed below:\n\nSec. 2:\n\nIn the ""Decoder"" paragraph: please add more details about how the words are predicted. Are there final softmax layers that provide distributions over output words? I couldn\'t find this detail in the paper. What loss is minimized during training? Is it the sum of log losses over all words being predicted?\n\nSec. 3:\n\nSection 3 does not add much to the paper. The motivations there are mostly suggestive rather than evidence-based. Section 3 could be condensed by about 80% or so without losing much information. Overall, the paper has more than 10 pages of content, and the use of 2 extra pages beyond the desired submission length of 8 should be better justified. I would recommend adding a few more details to Section 2 and removing most of Section 3. I\'ll mention below some problematic passages in Section 3 that should be removed.\n\nSec. 3.2:\n""...this same constraint (if using RNN as the decoder) could be an inappropriate constraint in the decoding process.""  What is the justification or evidence for this claim?  I think the claim should be supported by an argument or some evidence or else should be removed. If the authors intend the subsequent paragraphs to justify the claim, then see my next comments. \n\nSec. 3.2:\n""The existence of the ground-truth current word embedding potentially decreases the tendency for the decoder to exploit other information from the sentence representation.""\nBut this is not necessarily an inherent limitation of RNN decoders since it could be addressed by using the embedding of the previously-predicted word rather than the ground-truth word. This is a standard technique in sequence-to-sequence learning; cf. scheduled sampling (Bengio et al., 2015). \n\nSec. 3.2: \n""Although the word order information is implicitly encoded in the CNN decoder, it is not emphasized as it is explicitly in the RNN decoder. The CNN decoder cares about the quality of generated sequences globally instead of the quality of the next generated word. Relaxing the emphasis on the next word, may help the CNN decoder model to explore the contribution of context in a larger space.""\nAgain, I don\'t see any evidence or justification for these arguments. Also see my discussion above about decoder variations; these are not properties of RNNs vs CNNs but rather properties of auto-regressive vs predict-all-words decoders. \n\nSec. 5.2-5.3:\nThere are a few high-level decisions being tuned on the test sets for some of the tasks, e.g., the length of target sequences in Section 5.2 and the number of layers and channel size in Section 5.3. \n\nSec. 5.4:\nWhen trying to explain why an RNN encoder works better than a CNN encoder, the paper includes the following: ""We stated above that, in our belief, explicit usage of the word order information will augment the transferability of the encoder, and constrain the search space of the parameters in the encoder. The results match our belief.""\nI don\'t think these beliefs are concrete enough to be upheld or contradicted. Both encoders explicitly use word order information. Can you provide some formal or theoretical statement about how the two encoders treat word order differently? I fear that it\'s only impressions and suppositions that lead to this difference, rather than necessarily something formal. \n\nSec. 5.4:\nIn Table 1, it is unclear why the ""future predictor"" model is the one selected to be reported from Gan et al (2017). Gan et al has many settings and the ""future predictor"" setting is the worst. An explanation is needed for this choice. \n\nSec. 6.1: \n\nIn the ""BYTE m-LSTM"" paragraph:\n\n""Our large RNN-CNN model trained on Amazon Book Review (the largest subset of Amazon Review) performs on par with BYTE m-LSTM model, and ours works better than theirs on semantic relatedness and entailment tasks.""  I\'m not sure this ""on par"" assessment is warranted by the results in Table 2.  BYTE m-LSTM is better on MR by 1.6 points and better on CR by 4.7 points. The authors\' method is better on SUBJ by 0.7 and better on MPQA by 0.5.  So on sentiment tasks, BYTE m-LSTM is clearly better, and on the other tasks the RNN-CNN is typically better, especially on SICK-r.  \n\n\nMore minor things are below:\n\nSec. 1:\nThe paper contains this: ""The idea of learning from the context information was first successfully applied to vector representation learning for words in Mikolov et al. (2013b)""\n\nI don\'t think this is accurate. When restricting attention to neural network methods, it would be more correct to give credit to Collobert et al. (2011). But moving beyond neural methods, there were decades of previous work in using context information (counts of context words) to produce vector representations of words. \n\ntypo: ""which d reduces"" --> ""which reduces""\n\nSec. 2:\nThe notation in the text doesn\'t match that in Figure 1: w_i^1 vs. w_1 and h_i^1 vs h_1. \n\nInstead of writing ""non-parametric composition function"", describe it as ""parameter-free"". ""Non-parametric"" means that the number of parameters grows with the data, not that there are no parameters. \n\nIn the ""Representation"" paragraph: how do you compute a max over vectors? Is it a separate max for each dimension? This is not clear from the notation used.\n\nSec. 3.1:\ninappropriate word choice: the use of ""great"" in ""a great and efficient encoding model""\n\nSec. 3.2:\ninappropriate word choice: the use of ""unveiled"" in ""is still to be unveiled""\n\nSec. 3.4:\nTying input and output embeddings can be justified with a single sentence and the relevant citations (which are present here). There is no need for speculation about what may be going on, e.g.: ""the model learns to explore the non-linear compositionality of the input words and the uncertain contribution of the target words in the same space"".\n\nSec. 4:\nI think STS14 should be defined and cited where the other tasks are described. \n\nSec. 5.3:\ntypo in Figure 2 caption: ""and and""\n\n\nSec. 6.1: \n\nIn the ""Skip-thought"" paragraph:\n\ninappropriate word choice: ""kindly""\n\nThe description that says ""we cut off a branch for decoding"" is not clear to me. What is a ""branch for decoding"" in this context? Please modify it to make it more clear. \n\n\nReferences:\n\nBengio S, Vinyals O, Jaitly N, Shazeer N. Scheduled sampling for sequence prediction with recurrent neural networks. NIPS 2015.\n\nCollobert R, Weston J, Bottou L, Karlen M, Kavukcuoglu K, Kuksa P. Natural language processing (almost) from scratch. Journal of Machine Learning Research 2011.\n', 'The authors build on the work of Tang et al. (2017), who made a minor change to the skip-thought model by decoding only the next sentence, rather than the previous one also. The additional minor change in this paper is to use a CNN, rather than RNN, decoder.\n\nI am sympathetic to the goals of the work, and believe this sort of work should be carried out, but I see the contribution as too minor to constitute a paper at the conference track of a leading international conference such as ICLR. Given the incremental nature of the work, I think this would be a good fit for something like a short paper at *ACL.\n\nI found the more theoretical motivation of the CNN decoder not terribly convincing, and somewhat post-hoc. I feel as though analogous arguments could just as easily be made for an RNN decoder. Ultimately I see these questions - such as CNN vs. RNN for the decoder - as empirical ones.\n\nFinally, the authors have admirably attempted a thorough comparison with existing work, in the related work section, but this section takes up a large chunk of the paper at the end, and again I would have preferred this section to be much shorter and more concise.\n\nSummary: worthwhile empirical goal, but the paper could have been easily written using half as much space.\n']","[-20, 50, -30]","[50, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some improvements and positive aspects of the paper, there are still significant concerns and criticisms. The reviewer states the paper is 'solidly borderline' and they're 'not completely convinced that any new claim is true'. They also mention several areas needing clarification or improvement. However, it's not extremely negative as they do recognize substantial improvements and some persuasive evidence. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, offers constructive criticism, and acknowledges the authors' efforts. They use phrases like 'I'd appreciate', 'Please clarify', and 'I would appreciate', which are polite ways of requesting changes. The reviewer also balances criticisms with positive remarks, showing a considerate approach."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses overall approval of the paper, stating it 'merits publication' and that the 'results are strong enough'. They increased their rating from 6 to 7, indicating improved sentiment. However, they also have several critiques and suggestions for improvement, balancing out the positive aspects. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, such as 'I think', 'please add', and 'I would recommend'. They offer constructive criticism and suggestions rather than harsh judgments. However, they do directly point out flaws and use some strong language like 'quibbles' and 'problematic', which prevents the score from being higher."", ""The sentiment score is -30 because while the reviewer is 'sympathetic to the goals of the work', they ultimately view the contribution as 'too minor' and 'incremental', suggesting it's not suitable for a major conference. They also criticize the theoretical motivation and structure of the paper. However, it's not entirely negative as they do see some value in the work. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the authors' efforts ('admirably attempted') and offering constructive criticism. They also provide a balanced view, mentioning both positive and negative aspects. The tone is professional and not personally critical, but it's not overly polite either, maintaining a neutral academic tone.""]"
"['The paper addresses the problem of learning the form of the activation functions in neural networks.  The authors propose to place Gaussian process (GP) priors on the functional form of each activation function (each associated with a hidden layer and unit) in the neural net. This  somehow allows to non-parametrically infer from the data the ""shape"" of the activation functions needed for a specific problem.  The paper then proposes an inference framework (to approximately marginalize out all GP functions)  based on sparse GP methods that use inducing points and variational inference.  The inducing point approximation used here is very efficient since all GP functions depend on a scalar input (as any activation function!) and therefore by just placing the inducing points in a dense grid gives a fast and accurate representation/compression of all GPs in terms of the inducing function values (denoted by U in the paper).  Of course then inference involves approximating the finite posterior over inducing function values U and the paper make use of the standard Gaussian approximations.   \n       \nIn general I like the idea and I believe that it can lead to a very useful model. However, I have found the current paper quite preliminary and incomplete.  The authors need to address the following:  \n\nFirst (very important): You need to show experimentally how your method compares against regular neural nets (with specific fixed forms for their activation functions such relus etc). At the moment in the last section you mention ""We have validated networks of Gaussian Process Neurons in a set of experiments, the details of which we submit in a subsequent publication. In those experiments, our model shows to be significantly less prone to overfitting than a traditional feed-forward network of same size, despite having more parameters."" ===>  Well all this needs to be included in the same paper.  \n\nSecondly: Discuss the connection with Deep GPs (Damianou and Lawrence 2013). Your method seems to be connected with Deep GPs although there appear to be important differences as well. E.g. you place GPs on the scalar activation functions in an otherwise  heavily parametrized neural network (having interconnection weights between layers) while deep GPs model the full hidden layer mapping as a single GP (which does not require interconnection weights).  \n\nThirdly:  You need to better explain the propagation of uncertainly in section 3.2.2  and the central limit of distribution in section 3.2.1. This is the technical part of your paper which is a non-standard approximation. I will suggest to give a better intuition of the whole idea and move a lot of mathematical details to the appendix.  \n', 'In Bayesian neural networks, a deterministic or parametric activation is typically used. In this work, activation functions are considered random functions with a GP prior and are inferred from data.\n\n\n- Unnecessary complexity\n\nThe presentation of the paper is unnecessarily complex. It seems that authors spend extra space creating problems and then solving them. Although some of the derivations in Section 3.2.2 are a bit involved, most of the derivations up to that point (which is already in page 6) follow preexisting literature.\n\nFor instance, eq. (3) proposes one model for p(F|X). Eq. (8) proposes a different model for p(F|X), which is an approximation to the previous one. Instead, the second model could have been proposed directly, with the appropriate citation from the literature, since it isn\'t new. Eq. (13) is introduced as a ""solution"" to a non-existent problem, because the virtual observations are drawn from the same prior as the real ones, so it is not that we are ""coming up"" with a convenient GP prior that turns out to produce a computationally tractable solution, we are just using the prior on the observations consistently.\n\nIn general, the authors seem to use ""approximately equal"" and ""equal"" interchangeably, which is incorrect. There should be a single definition for p(F|X). And there should be a single definition for L_pred. The expression for L_pred given in eq. (20) (exact) and eq. (41) (approximate) do not match and yet both are connected with an equality (or proportionality), which they shouldn\'t.\n\nQ(A) is sometimes taken to mean the true posterior (i.e., eq. (31)), sometimes a Gaussian approximation (i.e., eq (32) inside the integral), and both are used interchangeably.\n\n\n- Incorrect references to the literature\n\nPage 3: ""using virtual observations (originally proposed by Quiñonero-Candela & Rasmussen (2005) for sparse approximations of GPs)""\n\nThe authors are citing as the origin of virtual observations a survey paper on the topic. Of course, that survey paper correctly attributes the origin to [1].\n\nPage 4: ""we apply the technique of variational inference Wainwright et al. (2008)"".\n\nHow can variational inference be attributed to (again) a survey paper on the topic from 2008, when for instance [2] appeared in 2003?\n\n\n- Correctness of the approach\n\nCan the authors guarantee that the variational bound that they are introducing (as defined in eqs. (19) and (41)) is actually a variational bound? It seems to me that the approximations made to Q(A) to propagate the uncertainty are breaking the bounding guarantee. If it is no longer a lower bound, what is the rationale behind maximizing it?\n\nThe mathematical basis for this paper is actually introduced in [3] and a single-layer version of the current model is developed in [4]. However, in [4] the authors manage to avoid the additional Q(A) approximation that breaks the variational bound. The authors should contrast their approach with [4] and discuss if and why that additional central limit theorem application is necessary.\n\n\n- No experiments\n\nThe use of a non-parametric definition for the activation function should be contrasted with the use of a parametric one. With enough data, both might produce similar results. And the parameter sharing in the parametric one might actually be beneficial. With no experiments at all showing the benefit of this proposal, this paper cannot be considered complete.\n\n\n- Minor errors:\n\nEq. (4), for consistency, should use the identity matrix for the covariance matrix definition.\nEq. (10) uses subscript d where it should be using subscript n\nEq. (17) includes p(X^L|F^L) in the definition of Q(...), but it shouldn\'t. That was particularly misleading, since if we take eq. (17) to be correct (which I did at first), then p(X^L|F^L) cancels out and should not appear in eq. (20).\nEq. (23) uses Q(F|A) to mean the same as P(F|A) as far as I understand. Then why use Q?\n\n\n- References\n\n[1] Edward Snelson and Zoubin Ghahramani. Sparse Gaussian processes using pseudo-inputs.\n[2] Beal, M.J. Variational Algorithms for Approximate Bayesian Inference.\n[3] M.K. Titsias and N.D. Lawrence. Bayesian Gaussian process latent variable model. \n[4] M. Lázaro-Gredilla. Bayesian warped Gaussian processes.\n', 'This paper investigates probabilistic activation functions that can be structured in a manner similar to traditional neural networks whilst deriving an efficient implementation and training regime that allows them to scale to arbitrarily sized datasets.\n\nThe extension of Gaussian Processes to Gaussian Process Neurons is reasonably straight forward, with the crux of the paper being the path taken to extend GPNs from intractable to tractable.\nThe first step, virtual observations, are used to provide stand ins for inputs and outputs of the GPN.\nThese are temporary and are later made redundant.\nTo avoid the intractable marginalization over latent variables, the paper applies variational inference to approximate the posterior within the context of given training data.\nOverall the process by which GPNs are made tractable to train leverages many recent and not so recent techniques.\n\nThe resulting model is theoretically scalable to arbitrary datasets as the total model parameters are independent of the number of training samples.\nIt is unfortunate but understandable that the GPN model experiments are confined to another paper.']","[-20, -70, 50]","[50, -20, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer initially expresses liking the idea, they then state that the paper is 'quite preliminary and incomplete' and list several major improvements needed. This indicates a generally critical stance, though not entirely negative. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, such as 'I like the idea' and 'I believe that it can lead to a very useful model'. They also frame their criticisms as suggestions ('You need to show', 'Discuss the connection', 'You need to better explain') rather than harsh demands. The tone is professional and constructive, avoiding rudeness while still clearly communicating the need for significant improvements."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several issues such as 'unnecessary complexity', 'incorrect references', lack of experiments, and questions about the correctness of the approach. There are no positive comments about the paper's contributions or merits. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite critical and direct. Phrases like 'unnecessarily complex', 'non-existent problem', and 'cannot be considered complete' are quite harsh. The reviewer does not soften criticisms or offer encouragement, which contributes to the slightly impolite tone. However, the language remains professional and focused on the paper's content rather than personal attacks, preventing a lower politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contribution in extending Gaussian Processes to Gaussian Process Neurons and making them tractable for large datasets. The reviewer describes the approach as 'reasonably straight forward' and notes that it leverages various techniques effectively. However, the sentiment is not overwhelmingly positive as the reviewer expresses disappointment that the experimental results are in another paper. The politeness score is 75 (quite polite) because the reviewer uses neutral, professional language throughout. They acknowledge the paper's strengths without excessive praise and mention the limitation (lack of experimental results) in a respectful manner ('It is unfortunate but understandable'). The reviewer maintains an objective tone, focusing on the technical aspects of the paper without personal comments or harsh criticisms.""]"
"['This paper proposes an alternative to the relation network architecture whose computational complexity is linear in the number of objects present in the input. The model achieves good results on bAbI compared to memory networks and the relation network model. From what I understood, it works by computing a weighted average of sentence representations in the input story where the attention weights are the output of an MLP whose input is just a sentence and question (not two sentences and a question). This average is then fed to a softmax layer for answer prediction. I found it difficult to understand how the model is related to relation networks, since it no longer scores every combination of objects (or, in the case of bAbI, sentences), which is the fundamental idea behind relation networks. Why is the approach not evaluated on CLEVR, in which the interaction between two objects is perhaps more critical (and was the main result of the original relation networks paper)? The fact that the model works well on bAbI despite its simplicity is interesting, but it feels like the paper is framed to suggest that object-object interactions are not necessary to explicitly model, which I can\'t agree with based solely on bAbI experiments. I\'d encourage the authors to do a more detailed experimental study with more tasks, but I can\'t recommend this paper\'s acceptance in its current form.\n\nother questions / comments:\n- ""we use MLP to produce the attention weight without any extrinsic computation between the input sentence and the question."" isn\'t this statement false because the attention computation takes as input the concatenation of the question and sentence representation?\n- writing could be cleaned up for spelling / grammar (e.g., ""last 70 stories"" instead of ""last 70 sentences""), currently the paper is very hard to read and it took me a while to understand the model', ""The paper proposes to address the quadratic memory/time requirement of Relation Network (RN) by sequentially attending (via multiple layers) on objects and gating the object vectors with the attention weights of each layer. The proposed model obtains state of the art in bAbI story-based QA and bAbI dialog task.\n\nPros:\n- The model achieves the state of the art in bAbI QA and dialog. I think this is a significant achievement given the simplicity of the model.\n- The paper is clearly written.\n\nCons:\n- I am not sure what is novel in the proposed model. While the authors use notations used in Relation Network (e.g. 'g'), I don't see any relevance to Relation Network. Rather, this exactly resembles End-to-end memory network (MemN2N) and GMemN2N. Please tell me if I am missing something, but I am not sure of the contribution of the paper. Of course, I notice that there are small architectural differences, but if these are responsible for the improvements, I believe the authors should have conducted ablation study or qualitative analysis that show that the small tweaks are meaningful.\n \nQuestion:\n- What is the exact contribution of the paper with respect to MemN2N and GMemN2N?"", 'This paper introduces Related Memory Network (RMN), an improvement over Relationship Networks (RN). RMN avoids growing the relationship time complexity as suffered by RN (Santoro et. Al 2017). RMN reduces the complexity to linear time for the bAbi dataset. RN constructs pair-wise interactions between objects in RN to solve complex tasks such as transitive reasoning. RMN instead uses a multi-hop attention over objects followed by an MLP to learn relationships in linear time.\n\nComments for the author:\n\nThe paper addresses an important problem since understanding object interactions are crucial for reasoning. However, how widespread is this problem across other models or are you simply addressing a point problem for RN? For example, Entnet is able to reason as the input is fed in and the decoding costs are low. Likewise, other graph-based networks (which although may require strong supervision) are able to decode quite cheaply. \n\nThe relationship network considers all pair-wise interactions that are replaced by a two-hop attention mechanism (and an MLP). It would not be fair to claim superiority over RN since you only evaluate on bABi while RN also demonstrated results on other tasks. For more complex tasks (even over just text), it is necessary to show that you outperform RN w/o considering all objects in a pairwise fashion. More specifically, RN uses an MLP over pair-wise interactions, does that allow it to model more complex interactions than just selecting two hops to generate attention weights. Showing results with multiple hops (1,2,..) would be useful here.\n\nMore details are needed about Figure 3. Is this on bAbi as well? How did you generate these stories with so many sentences? Another clarification is the bAbi performance over Entnet which claims to solve all tasks. Your results show 4 failed tasks, is this your reproduction of Entnet?\n\nFinally, what are the savings from reducing this time complexity? Some wall clock time results or FLOPs of train/test time should be provided since you use multiple hops.\n\nOverall, this paper feels like a small improvement over RN. Without experiments over other datasets and wall clock time results, it is hard to appreciate the significance of this improvement. One direction to strengthen this paper is to examine if RMN can do better than pair-wise interactions (and other baselines) for more complex reasoning tasks.\n\n']","[-50, 20, -20]","[20, 70, 60]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's approach and states they 'can't recommend this paper's acceptance in its current form.' However, they do acknowledge some positive aspects like the model achieving good results on bAbI and the interesting simplicity of the approach. The politeness score is 20 because the reviewer uses generally polite language, offering constructive criticism and suggestions for improvement. They use phrases like 'I'd encourage the authors' and frame their concerns as questions rather than direct criticisms. However, the overall tone is professional rather than overtly polite, hence the moderate positive score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some pros like the model achieving state-of-the-art results and the paper being clearly written. However, the reviewer also expresses significant concerns about the novelty of the proposed model and its contribution relative to existing work. This mixed feedback leans slightly positive overall. The politeness score is relatively high (70) because the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms as questions or requests for clarification rather than direct accusations. Phrases like 'Please tell me if I am missing something' and 'I believe the authors should have' contribute to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper addresses an important problem, they express several concerns and limitations of the work. The reviewer suggests the paper feels like a 'small improvement' and questions its significance without additional experiments and results. However, it's not entirely negative as they do recognize the importance of the problem and offer constructive feedback. The politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'it would not be fair to claim' and offer suggestions for improvement rather than harsh criticisms. The reviewer also asks clarifying questions and provides specific recommendations, which is a polite way of addressing concerns.""]"
"['This paper shows that an LSTM language model trained on a large corpus of Amazon product reviews can learn representations that are useful for sentiment analysis. \nGiven representations from the language model, a logistic regression classifier is trained with supervised data from the task of interest to produce the final model.\nThe authors evaluated their approach on six sentiment analysis datasets (MR, CR, SUBJ, MPQA, SST, and IMDB), and found that the proposed method is competitive with existing supervised methods. \nThe results are mixed, and they understandably are better for test datasets from similar domains to the Amazon product reviews dataset used to train the language model.\nAn interesting finding is that one of the neurons captures sentiment property and can be used to predict sentiment as a single unit.\n\nI think the main result of the paper is not surprising and does not show much beyond we can do pretraining on unlabeled datasets from a similar domain to the domain of interest. \nThis semi-supervised approach has been known to improve in the low data regime, and pretraining an expressive neural network model with a lot of unlabeled data has also been shown to help in the past.\nThere are a few unanswered questions in the paper:\n- What are the performance of the sentiment unit on other datasets (e.g., SST, MR, CR)? Is it also competitive with the full model?\n- How does this method compare to an approach that first pretrains a language model on the training set of each corpus without using the labels, and then trains a logistic regression while fixing the language model? Is the large amount of unlabeled data important to obtain good performance here? Or is similarity to the corpus of interest more important?\n- I assume that the reason to use byte LSTM is because it is cheaper than a word level LSTM. Is this correct or was there any performance issue with using the word directly?\n- More analysis on why the proposed method does well on the binary classification task of SST, but performs poorly on the fine-grained classification would be useful. If the model is capturing sentiment as is claimed by the authors, why does it only capture binary sentiment instead of a spectrum of sentiment level?\n\nThe paper is also poorly written. There are many typos (e.g., ""This advantage is also its difficulty"", ""Much previous work on language modeling has evaluated "", ""We focus in on the task"", and others) so the writing needs to be significantly improved for it to be a conference paper, preferably with some help from a native English speaker.', ""First of all, I don't think I fully understand this paper, because it is difficult for me to find answers from this paper to the following questions:\n1) what is the hypothesis in this paper? Section 1 talks about lots of things, which I don't think is relevant to the central topic of this paper. But it misses the most important thing: what is THIS paper (not some other deep learning/representation problems)\n2) about section 2, regardless whether this is right place to talk about datasets, I don't understand why these two datasets. Since this paper is about generating reviews and discovering sentiment (as indicated in the paper)\n3) I got completely confused about the content in section 3 and lost my courage to read the following sections. "", 'The authors propose to use a byte level RNN to classify reviews. In the meantime, they learn to generate reviews. The authors rely on the multiplicative LSTM proposed by Krause et al. 2016, a generative model predicting the next byte. They apply this architecture on the same task as the original article: document classification; they use a logistic regression on the extracted representation. The authors propose an evaluation on classical datasets and compare themselves to the state of the art.\nThe authors obtain interesting results on several datasets. They also explore the core of the unsupervised architecture and discover a neuron which activation matches the sentiment target very accurately. A deeper analyze shows that this neuron is more efficient on small datasets than on larger.\nExploiting the generative capacity of the network, they play with the ""sentiment neuron"" to deform a review. Qualitative results are interesting.\n\n\n\n\nThe authors do not propose an original model and they do not describe the used model inside this publication.\n\nNor the model neither the optimized criterion is detailled: the authors present some curve mentioning ""bits per character"" but we do not know what is measured. In fact, we do not know what is given as input and what is expected at the output -some clues are given in the experimental setup, but not in the model description-.\n\nFigure 2 is very interesting: it is a very relevant way to compare authors model with the literature.\n\nUnfortunately, the unsupervised abilities of the network are not really explained: we are a little bit frustrated by section 5.\n\n==\n\nThis article is very interesting and well documented. However, according to me, the fact that it provides no model description, no model analysis, no modification of the model to improve the sentiment discovery, prevents this article from being publicized at ICLR.\n']","[-20, -80, -20]","[20, -20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'competitive with existing supervised methods', 'interesting finding'), they also express significant criticisms. The reviewer states that the main result is 'not surprising' and 'does not show much beyond' existing techniques. They also point out several unanswered questions and criticize the paper's writing quality. The politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout, using phrases like 'I think' and 'I assume' to soften criticisms. They also acknowledge positive aspects before presenting criticisms. However, the direct statement about the paper being 'poorly written' and the suggestion to seek help from a native English speaker slightly reduces the politeness score."", ""The sentiment score is -80 because the reviewer expresses significant confusion and dissatisfaction with the paper. They state that they don't fully understand the paper, can't find answers to basic questions, and got 'completely confused' about a major section. There are no positive comments to balance this out. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite blunt and critical without any softening phrases or constructive suggestions. Phrases like 'I don't think I fully understand' and 'I got completely confused' are direct criticisms without much attempt to be tactful. However, the reviewer doesn't use explicitly rude language, which prevents the score from being lower."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the work, they ultimately recommend against publication due to lack of model description and analysis. The review starts positively but ends with criticism and rejection. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the interesting aspects of the work and providing constructive feedback. They use phrases like 'interesting results', 'well documented', and frame criticisms politely (e.g., 'Unfortunately, the unsupervised abilities...'). The rejection is stated professionally without harsh language.""]"
"['The paper is well-written which makes it easy to understand its main\nthrust - choosing loss functions so that at test time one can\naccurately (and speedily) determine whether an example is in a given\nclass, ie loss functions which are aligned with the ""Principle of Logit\nSeparation (PoLS)"". \n\nWhen the ""Principle of logit separation"" was first given (second page)\nI found it confusing and difficult to parse (too many ""any""s, I could\nnot work out how the quantification worked). However, the formal\ndefinition (Definition 2.1) was fine. Why not just use this - and drop\nthe vague, wordy definition?\n\nThe paper is fairly \'gentle\'. For example, we are taken through\nexamples of loss functions which satisfy ""PoLS"" and those which don\'t.\nNo \'deep\' mathematical reasoning is required - but I don\'t see this as\na deficiency.\n\nThe experiments are reasonably chosen and, as expected, show the\nbenefits of using PoLS-aligned loss functions.\n\nMy criticism of the paper is that I don\'t think there is enough\nmotivation. We have that normal classification is linear in the number\nof classes. This modest computational burden (ie just linear),\napparently, is too slow for certain applications.  I would like more\nevidence for this, including some examples of this problem including\nin the paper. This is lacking from the current version.\n\n\ntypos, etc\n\nmax-maring -> max-margin\nthe seconds term -> the second term\n\n', 'This paper explores a neat, simple idea intended to learn models suitable for fast membership queries about single classes (""is this data point a member of this class [or set of classes]?""). In the common case when the class prediction is made with a softmax function minimizing 1-of-K multiclass cross-entropy loss, this cannot in general be determined without essentially evaluating all K logits (inputs to the softmax). This paper describes how other losses (such as the natural multilabel cross-entropy) do not suffer this problem because all true labels\' logits rank above all false labels\' (so that any membership query can be answered by choosing a threshold), and models trained to minimize these losses perform better on class membership metrics. One of the new losses suggested, the batch cross-entropy, is particularly interesting in keeping with the recent work on using batch statistics; I would like to see this explored further (see below). The paper is well-written.\n\nI am not sure of the relevance of this work as written. The authors discuss how related work (e.g. Grave et al.) scales computationally with K, which is undesirable; however, training the entire network with a non-CE objective function is an end-to-end model change, and practical uptake may suffer without further justification. The problem (and the proposed solution by changing training objective) is of interest because standard approaches ostensibly suffer unfavorable runtime-to-performance tradeoffs, so this should be demonstrated. I would be more comfortable if the authors actually evaluated runtime, preferably against one or two of the other heuristic baselines they cite. \nThe notation is a little uneven. The main idea is stated given the premise of Fig. 1, that there exist logits which are computed and passed through a softmax neuron, but this is never formally stated. (There are a few other very minor quibbles, e.g. top of pg. 6: sum should be over 1...k). ', 'The paper addresses the problem of a mismatch between training classification loss and a loss at test time. This is motivated by use cases in which multiclass classification problems are learned during training, but where binary or reduced multi-class classifications is performed at test time. The question for me is the following: if at test time, we have to solve ""some"" binary classification task, possibly drawn at random from a set of binary problems (this is not made precise in the paper), then why not optimize the same classification error or a surrogate loss at training time? Instead, the authors start with a multiclass problem, which may introduce a computational burden. when the number of classes is large as one needs to compute a properly normalized softmax. The authors now seem to ask, what if one were to use a multi-classification loss at training time, but then decides at test time that a binary classification of one-vs-all is asked for. \n\nIf one buys into the relevance of the setting, then of course, one is faced with the problem that the multiclass logits (aka raw scores) may not be calibrated to be used for binary classification by applying a fixed threshold. The authors call this sententiously ""Principle of logit separation"". Not too surprisingly, the standard multiclass losses do not have the desired property, however approaches that reduce multi-class to binary classification at training time do, namely unnormalized models with penalized log Z (self-normalization), the NCE approach, as well as (the natural in the proposed setting) binary classification loss. I find this almost a bit circular in the line of argumentation, but ok. It remains odd that while usually one has tried to reduce multiclass to binary, the authors go the opposite direction.\n\nThe main technical contribution of the paper is the batch-nornalization that makes sure that multiclass logits across mini-batches of data are better calibrated. One can almost think of that as an additional regularization. This seems interesting and does not create much overhead, if one applies mini-batched SGD optimization anyway. However, I feel this technique would need to be investigated with regard to general improvements in a multiclass setting and as such also benchmarked relative to other methods that could be applied. \n']","[50, -20, -20]","[60, 60, 50]","['The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper is well-written and easy to understand, praises the gentle approach and reasonable experiments, but also expresses some criticism about motivation and a confusing definition. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, offers constructive criticism, and even points out typos helpfully. However, the review maintains a professional tone without being overly deferential or excessively polite.', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'neat, simple idea', 'well-written'), they express significant doubts about its relevance and practical applicability. The reviewer also points out some shortcomings and suggests additional work needed. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'I would like to see' and 'I would be more comfortable if' to suggest improvements, which maintains a polite tone while still conveying concerns."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, they express skepticism about the relevance of the setting and the circularity of the argumentation. Phrases like 'Not too surprisingly' and 'I find this almost a bit circular' indicate a critical stance. However, the reviewer does recognize some interesting aspects, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'If one buys into the relevance of the setting' and 'This seems interesting' to soften criticism. They also provide detailed feedback without using harsh language. The reviewer's questioning approach ('The question for me is the following:') is polite and constructive, contributing to the positive politeness score.""]"
"['The paper studies a regularization method to promote sparsity and reduce the overlap among the supports of the weight vectors in the learned representations. The motivation of using this regularization is to enhance the interpretability of the learned representation and avoid overfitting of complex models. \n\nTo reduce the overlap among the supports of the weight vectors, an existing method (Xie et al, 2017b) encouraging orthogonality is adopted to let the Gram matrix of the weight vectors to be close to the identity matrix (so that each weight vector is with unit norm and any pair of vectors are approximately orthogonal).\n\nNeural network and sparse coding are considered as two case studies. The alternating algorithm for solving the regularized sparse coding formulation is common and less attracted. I think the major point is to see how much benefit that the regularization can afford for learning deep neural networks. To avoid overfitting, some off-the-shelf methods, e.g., dropout which can be viewed as a kind of regularization, are commonly used for deep neural networks. Are there any connections between the adopted regularization terms and the existing methods? Will these less overlapped parameters control the activation of different neurons? I think these are some straightforward questions while there are not much explanations on those aspects.\n\nFor training neural networks, a simple sub-gradient method is used because of the non-smoothness of the regularization terms. When training with large neural networks, will the sub-gradient method affect the efficiency a lot compared without using the regularizer? For example, in the image classification problem with ResNet.\n\nIt is better not to use dropout in the experiments (language modeling and image classification), because one of the motivation of using the proposed regularizer is to avoid overfitting while dropout does the same work and may affect the evaluation of effectiveness of the regularization.\n', 'The paper proposed a new regularization approach that simultaneously encourages the weight vectors (W) to be sparse and orthogonal to each other. The argument is that the sparsity helps to eliminate the irrelevant feature vectors by making the corresponding weights zero. Nearly orthogonal sparse vectors will have zeros at different indexes and hence, encourages the weight vectors to have small overlap in terms of indices of nonzero entries (called support). Small overlap in support of weight vectors, aids interpretability as each weight vector is associated with a unique subset of feature vectors. For example, in the topic model, small overlap encourages, each topic to have unique set of representation words. \n\nThe proposed approach used L1 regularizer for enforcing sparsity in W. For enforcing orthogonality between different weight vectors (wi, wj), the log-determinant divergence (LDD) regularization term encourages the Gram Matrix G (Gij = wiTwj) to be close to an identity matrix I. The authors applied and tested the performance of proposed approach on Neural Network and Sparse Coding (SC) machine learning models. The authors validated the need for their proposed regularizer through experiments on 4 datasets (3 text and 1 images).\n\nMajor\n* The novelty of the paper is not clear. Neither L1 no logdet() are novel regularizers (see the literature of Determinatal Point Process). With the presence of the auto-differentiator, one cannot claim the making derivative a novelty.\n\n* L1 is also encourages diversity although as explicit as logdet. This is also obvious from Fig 2.  Perhaps the advantage of diversity is in interpretability but that is hard to quantify and the authors did not put enough effort to do that; we only have small anecdotal results in section 4.3. \n\n* The Table 1 is not convincing because one can argue, for example, gun (vec 1) and weapon (vec 4) are colinear.  \n\n* In section 4.2, the authors experimented with SC on text dataset.  The overlap score decreases as the strength of regularization increases. The authors didn’t show the effect of increasing the regularization strength on the model accuracy and convergence time. This analysis is important to make sure, the decrease in overlap score is not coming at the expense of model accuracy and performance. \n\n* In section 4.4, increase in test set accuracy and difference between test and train set accuracy is used to validate the claim, that the proposed regularizer helps reducing over fitting. In Table-2, , the test accuracy increases between SC and LDD-L1 SC while the train accuracy remains almost the same. Also, the authors didn’t do any cross validation to support their claim. The difference is numbers is too small to support the claim.\n\n* In section on LSTM for Language Modeling, the perplexity score of LDD-L1 regularization on PytorchLM received perplexity score of 1.2 lower than without regularization. Although, the author mentions it as a significant reduction, the lowest perplexity score in Table 3 is significantly lower than this result. It’s not clear how 1.2 reduction in perplexity is significant and why the method should be preferred while much better models already exists.\n\n* Results of the best perplexity model, Neural Architecture Search + WT V2, with proposed regularization would also help, validating the generalizability claims of the new approach.\n\n* In CNN for Image Classification section, details of increase interpretability of the model, in terms of classification decision, is missing.\n\n* In Table-4, the proposed LDD-L1 WideResNet is not the best results. Results of adding the proposed regularization, to the best know method (Pyramid Sep Drop) would be interesting. \n\n* The proposed regularization claims to provide more interpretable representation and less overfit model. The given experiments are inadequate to validate the claims.\n\n* A more extensive experimentation is required to validate the applicability of the method.\n\n* In SC, aj are the linear coefficients or the coefficient vector of the j-th sample. If A ∈ Rm×n then aj ∈ Rm×1 and j ranges between [1,n] as in equation 6. The notation in section 2.2, Sparse Coding section is misleading as j ranges between [1,m].\n\n* In Related works, the authors mention previous work done on interpreting the results of the machine learning models. Related works on enhancing interpretability and reducing overfitting by using regularization is missing.\n\n\n', '*Summary*\nThe paper introduces a matrix regularizer to simultaneously induce both sparsity and (approximate) orthogonality. The definition of the regularizer mostly relies on the previous proposal from Xie et al. 2017b, to which a weighted L1 term is added.\nThe regularizer aims at reducing overlap among the learned matrices, and it is applied to various neural networks and sparse coding (SC) settings.\nMost of the challenges of the paper concentrate on the optimization side.\nThe evaluation of the paper is based on 3 experiments: SC (to illustrate the gain in interpretability and the reduction in overfitting), LTSM (for a NLP task over PTB) and CNN (for a computer vision task over CIFAR-10). \n\nThe paper is overall clear and fairly well structured, but it suffers from several flaws, as next discussed.\n\n*Detailed comments*\n(mostly in linear order)\n\n-The proposed regularization scheme seems closely related to the approach taken in [Zass2007]; a detailed discussion and potential comparison should be provided. In particular, the approach of [Zass2007] would lead to an easier optimization. \n\n-The sparse coding formulation has an extremely heavy parametrization (4 regularization parameters + the optimization parameter for ADMM + the number of columns of W). It seems to me that the resulting approach may not be very practical.\n\n-Sparse coding: More references to previous work are needed, such as references related to alternating schemes and proximal optimization for SC (in Sec. 3); e.g., see [Mairal2010,Jenatton2011] and numerous references therein.\n\n-I would suggest to move the derivations of Sec. 3.1 into an appendix not to break the flow of the readers. The derivations look sound.\n\n-Due to the use of ADMM, I think that only W_tilde is sparse (due to the prox update (10)), but W may not be. This point should be discussed. Is a ""manual"" thresholding applied thereafter?\n\n-For equation (25), I would precise that the columns of U have to be properly ordered to make sure we can only look at those from s=m...d.\n\n-More details about the optimization in the case of the neural networks should be discussed.\n\n-Could another splitting for ADMM, based on the logdet to reuse ideas from [Banerjee2008,Friedman2008], be possible?\n\n-In table 2., are those 3-decimal statistics significant? Any idea of the variability of those numbers?\n\n-Interpretability: The paper focuses on the gain in interpretability thanks to the regularizer (e.g., Table 1 and 3). But all the proposed settings (SC or neural networks) are such that the parameters are themselves subject to sources of variations, e.g., the initial conditions. How can we make strong conclusions while inspecting the parameters?\n\n-In Figure 2., it seems to be that the final performance metric should also be overlaid. What appears as interesting to me is the the trade-off between overlap score and final performance metric.\n\n*References*\n\n[Banerjee2008] Banerjee, O.; El Ghaoui, L. & d\'Aspremont null, A. Model selection through sparse maximum likelihood estimation for multivariate Gaussian or binary data Journal of Machine Learning Research, MIT Press, 2008, 9, 485-516\n\n[Friedman2008] Friedman, J.; Hastie, T. & Tibshirani, R. Sparse inverse covariance estimation with the graphical lasso Biostatistics, 2008, 9, 432\n\n[Jenatton2011] Jenatton, R.; Mairal, J.; Obozinski, G. & Bach, F. Proximal Methods for Hierarchical Sparse Coding Journal of Machine Learning Research, 2011, 12, 2297-2334\n\n[Mairal2010] Mairal, J.; Bach, F.; Ponce, J. & Sapiro, G. Online learning for matrix factorization and sparse coding Journal of Machine Learning Research, 2010, 11, 19-60\n\n[Zass2007] Zass, R. & Shashua, A. Nonnegative sparse PCA Advances in Neural Information Processing Systems, 2007']","[-20, -60, -20]","[50, 20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, they raise several concerns and questions about the methodology and its effectiveness. The reviewer suggests improvements and points out potential issues, indicating a somewhat critical stance. However, it's not overwhelmingly negative, as the reviewer also recognizes the paper's efforts and potential benefits.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They phrase their criticisms as suggestions or questions rather than direct attacks. For example, they use phrases like 'I think' and 'It is better' instead of more forceful language. The reviewer also acknowledges the paper's contributions before diving into critiques, which is a polite approach in academic reviews."", ""The sentiment score is -60 because the review is predominantly critical, pointing out several major issues with the paper. The reviewer questions the novelty of the approach, the convincingness of the results, and the adequacy of the experiments to support the claims. However, it's not entirely negative as the reviewer acknowledges some positive aspects of the work, hence not reaching the lowest end of the scale. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use neutral language like 'The novelty of the paper is not clear' rather than more confrontational phrases. The reviewer also provides specific suggestions for improvement, which is a constructive approach. However, the overall tone is more matter-of-fact than overtly polite, hence the relatively low positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is 'overall clear and fairly well structured', they also state that it 'suffers from several flaws'. The review lists multiple criticisms and suggestions for improvement, indicating a generally critical stance. However, the tone is not entirely negative, as the reviewer does point out some positive aspects.\n\nThe politeness score is moderately positive (60) because the reviewer uses professional and respectful language throughout. They begin with a neutral summary and use phrases like 'I would suggest' and 'More details... should be discussed' rather than making demands. The criticisms are presented as constructive feedback rather than harsh judgments. The reviewer also acknowledges the paper's strengths alongside its weaknesses, which contributes to a polite tone.""]"
"['The paper proposes training an autoencoder such that the middle layer representation consists of the class label of the input and a hidden vector representation called ""style memory"", which would presumably capture non-class information. The idea of learning representations that decompose into class-specific and class-agnostic parts, and more generally ""style"" and ""content"", is an interesting and long-standing problem. The results in the paper are mostly qualitative and only on MNIST. They do not show convincingly that the network managed to learn interesting class-specific and class-agnostic representations. It\'s not clear whether the examples shown in figures 7 to 11 are representative of the network\'s general behavior. The tSNE visualization in figure 6 seems to indicate that the style memory representation does not capture class information as well as the raw pixels, but doesn\'t indicate whether that representation is sensible.\n\nThe use of fully connected networks on images may affect the quality of the learned representations, and it may be necessary to use convolutional networks to get interesting results. It may also be interesting to consider class-specific representations that are more general than just the class label. For example, see ""Learning a Nonlinear Embedding by Preserving Class Neighbourhood Structure"" by Salakhutdinov and Hinton, 2007, which learns hidden vector representations for both class-specific and class-agnostic parts. (This paper should be cited.)', 'This paper proposes to train a classifier neural network not just to classifier, but also to reconstruct a representation of its input, in order to factorize the class information from the appearance (or ""style"" as used in this paper). This is done by first using unsupervised pretraining and then fine-tuning using a weighted combination of the regular multinomial NLL loss and a reconstruction loss at the last hidden layer. Experiments on MNIST are provided to analyse what this approach learns.\n\nUnfortunately, I fail to see a significantly valuable contribution from this work. First, the paper could do a better job at motivating the problem being addressed. Why is it important to separate class from style? Should it allow better classification performance? If so, it\'s never measured in this work. If that\'s not the motivation, then what is it?\n\nSecond, all experiments were conducted on the MNIST dataset. In 2017, most would expect experiments on at least one other, more complex dataset, to trust any claims on a method.\n\nFinally, the results are not particularly impressive. I don\'t find the reconstructions demonstrated particularly compelling (they are generally pretty different from the original input). Also, that the ""style"" representation contain less (and I\'d say slightly less, in Figure 7 b and d, we still see a lot of same class nearest neighbors) is not exactly a surprising result. And the results of figure 9, showing poor reconstructions when changing the class representation essentially demonstrates that the method isn\'t able to factorize class and style successfully. The interpolation results of Figure 11 are also underwhelming, though possibly mostly because the reconstructions are in general not great. But most importantly, none of these results are measured in a quantitative way: they are all qualitative, and thus subjective.\n\nFor all these reasons, I\'m afraid I must recommend this paper be rejected.', 'The paper proposes combining classification-specific neural networks with auto-encoders. This is done in a straightforward manner by designating a few nodes in the output layer for classification and few for reconstruction. The training objective is then changed to minimize the sum of the classification loss (as measured by cross-entropy for instance) and the reconstruction error (as measured by ell-2 error as is done in training auto-encoders). \n\nThe authors minimize the loss function by greedy layer-wise training as is done in several prior works. The authors then perform other experiments on the learned representations in the output layer (those corresponding to classification + those corresponding to reconstruction). For example, the authors plot the nearest-neighbors for classification-features and for reconstruction-features and observe that the two are very different. The authors also observe that interpolating between two reconstruction-feature vectors (by convex combinations) seems to interpolate well between the two corresponding images.\n\nWhile the experimental results are interesting they are not striking especially when viewed in the context of the tremendous amount of work on auto-encoders. Training the classification-features along with reconstruction-features does not seem to give any significantly new insights. ']","[-30, -80, -20]","[50, 20, 50]","[""The sentiment score is -30 because the review is generally critical, pointing out several limitations of the paper, such as the lack of convincing results and the use of only MNIST dataset. However, it's not entirely negative as it acknowledges the interesting nature of the problem. The politeness score is 50 because the reviewer uses neutral and professional language, offering constructive criticism and suggestions for improvement without being harsh or dismissive. The reviewer acknowledges the interesting aspects of the work and provides specific recommendations, which is a polite approach in academic reviews."", ""The sentiment score is -80 because the reviewer expresses significant criticism and recommends rejection. They state they 'fail to see a significantly valuable contribution' and list several major shortcomings of the paper. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone and use phrases like 'I'm afraid I must recommend' rather than harsh language. The reviewer also acknowledges some positive aspects, like the interpolation results, even if they find them underwhelming. The reasoning behind these scores is based on the overall negative assessment of the paper's contribution, methodology, and results, balanced against the reviewer's effort to maintain a respectful and constructive tone despite their strong recommendation for rejection."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the experimental results are 'interesting', they also state that they are 'not striking' and don't provide 'significantly new insights'. This suggests a somewhat underwhelmed response to the paper's contributions. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They provide a factual summary of the paper's content without using harsh criticism or overly praising language. The reviewer offers their perspective in a respectful manner, even when pointing out limitations, which maintains a polite tone.""]"
"['This paper proposes an approximate method to construct Bayesian uncertainty estimates in networks trained with batch normalization.\n\nThere is a lot going on in this paper. Although the overall presentation is clean, there are few key shortfalls (see below). Overall, the reported functionality is nice, although the experimental results are difficult to intepret (despite laudable effort by the authors to make them intuitive).\n\nSome open questions that I find crucial:\n\n* How exactly is the “stochastic forward-pass” performed that gives rise to the moment estimates? This step is the real meat of the paper, yet I struggle to find a concrete definition in the text. Is this really just an average over a few recent weights during optimization? If so, how is this method specific to batch normalization? Maybe I’m showing my own lack of understanding here, but it’s worrying that the actual sampling technique is not explained anywhere. This relates to a larger point about the paper\'s main point: What, exactly, is the Bayesian interpretation of batch normalization proposed here? In Bayesian Dropout, there is an explicit variational objective. Here, this is replaced by an implicit regularizer. The argument in Section 3.3 seems rather weak to me. To paraphrase it: If the prior vanishes, so does the regularizer. Fine. But what\'s the regularizer that\'s vanishing? The sentence that ""the influence of the prior diminishes as the size of the training data increases"" is debatable for something as over-parametrized as a DNN. I wouldn\'t be surprised that there are many directions in the weight-space of a trained DNN along which the posterior is dominated by the prior.\n\n* I’m confused about the statements made about the “constant uncertainty” baseline. First off, how is this (constant) width of the predictive region chosen? Did I miss this, or is it not explained anywhere? Unless I misunderstand the definition of CRPS and PLL, that width should matter, no? Then, the paragraph at the end of page 8 is worrying: The authors essentially say that the constant baseline is quite close to the estimate constructed in their work because constant uncertainty is “quite a reasonable baseline”. That can hardly be true (if it is, then it puts the entire paper into question! If trivial uncertainty is almost as good as this method, isn\'t the method trivial, too?). \nOn a related point: What would Figure 2 look like for the constand uncertainty setting? Just a horizontal line in blue and red? But at which level?\n\nI like this paper. It is presented well (modulo the above problems), and it makes some strong points. But I’m worried about the empirical evaluation, and the omission of crucial algorithmic details. They may hide serious problems.', 'The authors show how the regularization procedure called batch normalization,\ncurrently being used by most deep learning systems, can be understood as\nperforming approximate Bayesian inference. The authors compare this approach to\nMonte Carlo dropout (another regularization technique which can also be\nconsidered to perform approximate Bayesian inference). The experiments\nperformed show that the Bayesian view of batch normalization performs similarly\nas MC dropout in terms of the estimates of uncertainty that it produces.\n\nQuality:\n\nI found the quality to be low in some aspects. First, the description of what\nis the prior used by batch normalization in section 3.3 is unsatisfactory. The\nauthors basically refer to Appendix 6.4 for the case in which the weight decay\npenalty is not zero. The details in that Appendix are almost none, they just\nsay ""it is thus possible to derive the prior..."".\n\nThe results in Table 2 are a bit confusing. The authors should highlight in\nbold face the results of the best performing method.\n\nThe authors indicate that they do not need to compare to variational methods\nbecause Gal and Ghahramani 2015 compare already to those methods. However, Gal\nand Ghahramani\'s code used Bayesian optimization methods to tune\nhyper-parameters and this code contains a bug that optimizes hyper-parameters\nby maximizing performance on the test data. In particular for hyperparameter\nselection, they average performance across (subsets of) 5 of the training sets\nfrom the 20x train/test split, and then using the tau which got the best\naverage performance for all of 20x train/test splits to evaluate performance:\n\nhttps://github.com/yaringal/DropoutUncertaintyExps/blob/master/bostonHousing/net/experiment_BO.py#L54\n\nTherefore, the claim that \n\n""Since we have established that MCBN performs on par with MCDO, by proxy we\nmight conclude that MCBN outperforms those VI methods as well.""\n\nis not valid.\n\nAt the beginning of section 4.3 the authors indicate that they follow in their\nexperiments the setup of Gal and Ghahramani (2015). However, Gal and Ghahramani\n(2015) actually follow Hernández-Lobato and Adams, 2015 so the correct\nreference should be the latter one.\n\nClarity:\n\nThe paper is clearly written and easy to follow and understand.\n\nI found confusing how to use the proposed method to obtain estimates of\nuncertainty for a particular test data point x_star. The paragraph just above\nsection 4 says that the authors sample a batch of training data for this, but\nassume that the test point x_star has to be included in this batch.\nHow is this actually done in practice?\n\nOriginality:\n\nThe proposed contribution is original. This is the first time that a Bayesian\ninterpretation has been given to the batch normalization regularization\nproposal.\n\nSignificance:\n\nThe paper\'s contributions are significant. Batch normalization is a very\npopular regularization technique and showing that it can be used to obtain\nestimates of uncertainty is relevant and significant. Many existing deep\nlearning systems can use this to produce estimates of uncertainty in their\npredictions.\n', ""*Summary*\n\nThe paper proposes using batch normalisation at test time to get the predictive uncertainty. The stochasticity of the prediction comes from different minibatches of training data that were used to normalise the activity/pre-activation values at each layer. This is justified by an argument that using batch norm is doing variational inference, so one should use the approximate posterior provided by batch norm at prediction time. Several experiments show Monte Carlo prediction at test time using batch norm is better than dropout.\n\n*Originality and significance*\n\nAs far as I understand, almost learning algorithms similar to equation 2 can be recast as variational inference under equation 1. However, the critical questions are what is the corresponding prior, what is the approximating density, what are the additional approximations to obtain 2, and whether the approximation is a good approximation for getting closer to the posterior/obtain better prediction. \n\nIt is not clear to me from the presentation what the q(w) density is -- whether this is explicit (as in vanilla Gaussian VI or MC dropout), or implicit (the stochasticity on the activity h due to batch norm induces an equivalence q on w).\n\nFrom a Bayesian perspective, it is also not satisfying to ignore the regularisation term by an empirical heuristic provided in the batch norm paper [small \\lambda] -- what is the rationale of this? Can this be explained by comparing the variational free-energy. \n\nThe experiments also do not compare to modern variational inference methods using the reparameterisation trick with Gaussian variational approximations (see Blundell et al 2016) or richer variational families (see e.g. Louizos and Welling, 2016, 2017). The VI method included in the PBP paper (Hernandez-Lobato and Adams, 2015) does not use the reparameterisation trick, which has been found to reduce variance and improve over Graves' VI method.\n\n*Clarity*\nThe paper is in general well written and easy to understand. \n\n*Additional comments*\n\nPage 2: Monte Carlo Droput --> Dropout\nPage 3 related work: (Adams, 2015) should be (Hernandez-Lobato and Adams, 2015)""]","[-20, 50, -20]","[60, 75, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer says they 'like this paper' and it 'makes some strong points', they express significant concerns about crucial missing details, potential problems with the empirical evaluation, and weaknesses in the Bayesian interpretation. The overall tone suggests more criticism than praise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the authors' efforts ('laudable effort'), and frames criticisms as questions or personal confusion rather than direct attacks. They also start and end with some positive comments, softening the critique."", ""The sentiment score is 50 (slightly positive) because while the reviewer acknowledges the originality and significance of the paper, they also point out several issues with the quality and clarity. The review begins with positive comments about the paper's contribution and ends on a positive note about its significance, but the middle section contains multiple criticisms. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, even when pointing out flaws. They use phrases like 'I found' and 'The authors should' rather than making blunt criticisms. The reviewer also balances negative feedback with positive comments, which contributes to the overall polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is in general well written and easy to understand'), they raise several critical points and concerns about the methodology and comparisons. The reviewer questions the clarity of the approach, the justification for certain choices, and points out missing comparisons to modern methods. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'As far as I understand' and 'It is not clear to me', which soften their criticisms. The reviewer also provides constructive feedback and specific suggestions for improvement, which is a polite way to offer criticism. The language is formal and academic, avoiding any harsh or rude expressions.""]"
"['[Apologies for short review, I got called in late. Marking my review as ""educated guess"" since i didn\'t have time for a detailed review]\n\nThe paper proposes an algorithm to tune the momentum and learning rate for SGD. While the algorithm does not have a theory for general non-quadratic functions, experimental validation is extensive, making it a worthy contribution in my opinion. I have personally tried the algorithm when the paper came out and can vouch for the empirical results presented here.', ""This paper proposes a method to automatically tuning the momentum parameter in momentum SGD methods, which achieves better results and fast convergence speed than state-of-the-art Adam algorithm.\n\nAlthough the results are promising, I found the presentation of this paper almost inaccessible to me.\n\nFirst, though a minor point, but where does the name *YellowFin* come from?\n\nFor the presentation, the motivation in introduction is fine, but the following section about momentum operator is hard to follow. There are a lot of undefined notation. For example, what does the *convergence rate* mean (what is the measurement for convergence)? And is the *optimal accelerated rate* the same as *convergence rate* mentioned above? Also, what do you mean by *all directions* in the sentence below eq.2?\n\nThen the paper talks about robustness properties of the momentum operator. But: first, I am not sure why the derivative of f(x) is defined as in eq.3, how is that related to the original definition of derivative?\n\nIn the following paragraph, what is *contraction*? Does it have anything to do with the paper as I didn't see it in the remaining text?\n\nLemma 2 seems to use the spectral radius of the momentum operator as the *robustness*. But how can it describe the robustness? More details are needed to understand this.\n\nWhat it comes to Section 3, it seems to me that the authors try to use a local quadratic approximation for the original function f(x), and use the results in last section to find the optimal momentum parameter. I got confused in this section because eq.9 defines f(x) as a quadratic function. Is this f(x) the original function (non quadratic) or just the local quadratic approximation? If it is the local quadratic approximation, how is it correlated to the original function? It seems to me that the authors try to say if h and C are calculated from the original function, then this f(x) is a local quadratic approximation? If what I think is correct, I think it would be important to show this.\n\nAlso, the objective function in SingleStep algorithm seems to come from eq.13, but I failed to get the exact reasoning.\n\nOverall, I think this is an interesting paper, but the presentation is too fuzzy to get it evaluated."", 'The paper explores momentum SGD and an adaptive version of momentum SGD which the authors name YF (Yellow Fin). They compare YF to hand tuned momentumSGD and to Adam in several deep learning applications.\n\n\nI found the first part which discusses the theoretical motivation behind YF to be very confusing and misleading:\nBased on the analysis of 1-dimensional problems, the authors design a framework and an algorithm that  supposedly ensures accelerated convergence. There are two major problems with this approach:\n\n-First: Exploring 1-dim functions is indeed a nice way to get some intuition. Yet,  algorithms that work in the 1-dim case do not trivially generalize to high dimensions, and such reasoning might lead to very bad solutions.\n\n-Second: Accelerated GD does not benefit over GD in the 1-dim case. And therefore, this is not an appropriate setting to explore acceleration.\nConcretely, the definition of the generalized condition number $\\nu$, and relating it to the standard definition of the condition number $\\kappa$, is very misleading. This is since $\\kappa =1$ for 1-dim problems, and therefore accelerated GD does not have any benefits over non accelerated GD in this case.\nHowever, $\\nu$ might be much larger than 1 even in the 1-dim case.\n\n\nRegarding the algorithm itself: there are too many hyper-parameters (which depend on each other) that are tuned (per-dimension).\nAnd as I have mentioned, the design of the algorithm is inspired by the analysis of 1-dim quadratic functions.\nThus, it is very hard for me to believe that this algorithm works in practice unless very careful fine tuning is employed.\nThe authors mention that their experiments were done without tuning or with very little tuning, which is very mysterious for me.\n\nIn contrast to the theoretical part, the experiments seems very encouraging. Showing YF to perform very well on several deep learning tasks without (or with very little) tuning. Again, this seems a bit magical or even too good to be truth. I suggest the authors to perform a experiment with say a qaudratic high dimensional function, which is not aligned with the axes in order to illustrate how their method behaves and try to give intuition.\n']","[70, -50, -30]","[50, 20, 20]","[""The sentiment score is 70 (positive) because the reviewer expresses a favorable opinion of the paper, calling it a 'worthy contribution' and personally vouching for the empirical results. They acknowledge the lack of theoretical backing but emphasize the extensive experimental validation. The politeness score is 50 (slightly polite) as the reviewer uses respectful language and even apologizes for the short review. They also show consideration by explaining why the review is brief. The tone is professional and constructive without being overly formal or effusive."", ""The sentiment score is -50 because while the reviewer acknowledges that the results are promising, they express significant difficulty in understanding the paper's presentation, describing it as 'almost inaccessible'. They raise numerous questions and points of confusion throughout the review, indicating a generally negative sentiment towards the paper's clarity and organization. However, it's not entirely negative as they do recognize the potential of the work.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They phrase their criticisms as questions or observations rather than direct attacks. For example, they use phrases like 'I found', 'I am not sure', and 'I got confused', which softens the critique. The reviewer also ends on a somewhat positive note, calling it an 'interesting paper'. However, the score is not higher because the review is quite direct in its criticisms and doesn't use many explicitly polite phrases or compliments."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects (encouraging experiments), they express significant concerns about the theoretical foundations and methodology. The reviewer uses phrases like 'very confusing and misleading', 'major problems', and 'very hard for me to believe', indicating a generally negative sentiment. However, the score is not extremely negative due to the positive comments about the experiments.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I found', 'I suggest', and 'it is very hard for me to believe' rather than making blunt or rude statements. They also acknowledge positive aspects of the work. However, the score is not higher because the criticism, while politely phrased, is quite direct and doesn't use many softening phrases or compliments.""]"
"['The paper proposed a subgraph image representation and validate it in image classification and transfer learning problems. The image presentation is a minor extension based on a method of producing permutation-invariant adjacency matrix. The experimental results supports the claim.\n\nIt is very positive that the figures are very helpful for delivering the information.\n\nThe work seems to be a little bit incremental. The proposed image representation is mainly based on a previous work of permutation-invariant adjacency matrix. A novelty of this work seems to be transforming a graph into an image. By the proposed representation, the authors are able to apply image classification methods (supervised or unsupervised) to subgraph classification. \n\nIt will be better if the authors could provide more details in the methodology or framework section.\n\nThe experiments on 9 networks support the claims that the image embedding approaches with their image representation of the subgraph outperform the graph kernel and classical features based methods. It seem to be promising when using transfer learning.\n\nThe last two process figures in 1.1 can be improved. No caption or figure number is provided.\n\nIt will be better to make the notations easy to understand and avoid any notation in a sentence without explanation nearby.\nFor example:\n""the test example is correctly classified if and only if its ground truth matches C.""(P5)\n""We carry out this exercise 4 times and set n to 8, 16, 32 and 64 respectively.""(P6)\n\nSome minor issues:\n""Zhu et al.(2011) discuss heterogeneous transfer learning where in they use...""(P3)\n""Each label vector (a tuple of label, label-probability pairs)."" (incomplete sentence?P5)', 'This paper views graph classification as image classification, and shows that the CNN model adapted from image net can be effectively adapted to the graph classification. The idea is interesting and the result looks promising, but I do not understand the intuition behind the success of analogizing graph with images.\n\nFundamentally, a convolutional filter stands for a operation within a small neighborhood on the image. However, it is unclear how it means for the graph representation. Is the neighborhood predefined? Are the graph nodes pre-ordered? \n\nI am also curious with the effect of pre-trained model from ImageNet. Since the graph presentation does not use color channels,  pre-trained model is used different from what it was designed to. I would imagine the benefit of using ImageNet is just to bring a random, high-dimensional embedding.  In addition, I wonder whether it will help to fine-tune the model on the graph classification data. Could this submission show some fine-tune experiments?', ""The paper proposes to use 2-d image representation techniques as a means of learning representations of graphs via their adjacency matrices. The adjacency matrix (or a subgraph of it) is first re-ordered to produce some canonical ordering which can then be fed into an image representation method. This can then be fed into a classifier.\n\nThis is a little too unprincipled for my taste. In particular the paper uses a Caffe reference model on top of the adjacency matrix, rather than learning a method specifically for graphs. Perhaps this is due to a lack of available graph training data, but it doesn't seem to make a lot of sense.\n\nMaybe I missed or overlooked some detail, but I didn't spot exactly what the classification task was. I think the goal is to identify which of the graphs a subgraph belongs to? I'm not sure how relevant this graph classification task is. \n\nThe method does prove that the Caffe reference model maintains some information that can be used for classification, but this doesn't really suggest a generalizable method that we could confidently use for a variety of tasks. It's surprising that it works at all, but ultimately doesn't reveal a big scientific finding that could be re-used.""]","[50, -20, -60]","[60, 50, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and experimental support for its claims, while also noting areas for improvement. The review begins with positive remarks about the figures and experimental results, but also mentions that the work is 'a little bit incremental' and suggests areas for improvement. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive criticism with phrases like 'It will be better if...' and 'It seem to be promising...'. The reviewer also balances positive and negative feedback, which contributes to a polite tone. However, the score is not higher as the review is direct in its criticism without excessive softening language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea as interesting and the results as promising, they express significant confusion and skepticism about the fundamental approach and its intuition. They raise several critical questions and concerns about the methodology. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, framing their concerns as questions and curiosities rather than direct criticisms. They acknowledge positive aspects before delving into their concerns, and use phrases like 'I am curious' and 'I wonder' which maintain a collegial tone."", ""The sentiment score is -60 because the reviewer expresses several criticisms and doubts about the paper. They describe the approach as 'too unprincipled', question the relevance of the classification task, and state that the method doesn't reveal a 'big scientific finding'. However, they do acknowledge that the method works to some extent, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional manner. They use phrases like 'Maybe I missed or overlooked some detail' and 'This is a little too unprincipled for my taste', which soften the criticism. The reviewer also acknowledges positive aspects, such as the surprising effectiveness of the method. The language is not overtly polite, but it maintains a respectful tone throughout, hence a slightly positive score.""]"
"[""This paper proposes a new way of sampling data for updates in deep-Q networks. The basic principle is to update Q values starting from the end of the episode in order to facility quick propagation of rewards back along the episode.\n\nThe paper is interesting, but it lacks the proper comparisons to previously published techniques.\n\nThe results presented by this paper shows improvement over the baseline. But the Atari results is still significantly worse than the current SOTA.\n\nIn the non-tabular case, the authors have actually moved away from Q learning and defined an objective that is both on and off-policy. Some (theoretical) analysis would be nice. It is hard to judge whether the objective defined in the non-tabular defines a contraction operator at all in the tabular case.\n\nThere has been a number of highly relevant papers. Prioritized replay, for example, could have a very similar effect to proposed approach in the tabular case.\n\nIn the non-tabular case, the Retrace algorithm, tree backup, Watkin's Q learning all bear significant resemblance to the proposed method. Although the proposed algorithm is different from all 3, the authors should still have compared to at least one of them as a baseline. The Retrace algorithm specifically has also been shown to help significantly in the Atari case, and it defines a convergent update rule."", 'The authors propose a simple modification to the DQN algorithm they call Episodic Backward Update. The algorithm selects transitions in a backward order fashion from end of episode to be more effective in propagating learning of new rewards. This issue of fast propagation of updates is a common theme in RL (cf eligibility traces, prioritised sweeping, and more recently DQN with prioritised replay etc.). Here the proposed update applies the max Bellman operator recursively on a trajectory (unsure whether this is novel), with some decay to prevent accumulating errors with the nested max.\n\nThe paper is written in a clear way. The proposed approach seems reasonable, but I would have guessed that prioritized replay would also naturally sample transitions in roughly that order - given that TD-errors would at first be higher towards the end of an episode and progress backwards from there. I think this should have been one of the baselines to compare to for that reason.\n\nThe experimental results seem promising in the illustrative MNIST domain. Atari results seem decent, especially given that experiments are limited to 10M frames, though the advantage compared to the related approach of optimality tightening is not obvious. \n', 'This paper proposes a new variant of DQN where the DQN targets are computed on a full episode by a « backward » update (i.e. from end to start of episode). The targets’ update rule is similar to a regular tabular Q-learning update with high learning rate beta: this allows faster propagation of rewards obtained at the end of the episode (while beta=0 corresponds to regular DQN with no such reward propagation). This mechanism is shown to improve on Q-learning in a toy 2D maze environment (with MNIST-based pixel states providing cell coordinates) with beta=1, and on DQN and its optimality tightening variant on Atari games with beta=0.5.\n\nThe intuition behind the algorithm (that one should try to speed up the propagation of rewards across multiple steps) is not new, in fact it has inspired other approaches like n-step Q-learning, eligibility traces or more recently Retrace(lambda) in deep RL. Actually the idea of replaying experiences in backward order can be traced back to the origins of experience replay («  Programming Robots Using Reinforcement Learning and Teaching », Lin, 1991), something that is not mentioned here. That being said, to the best of my knowledge the specific algorithm proposed in this submission (Alg. 2) is novel, even if Alg. 1 is not (Alg. 1 can be seen as a specific instance of Lin’s algorithm with a very high learning rate, and clearly only makes sense in toy deterministic environments).\n\nIn the absence of any theoretical analysis of the proposed approach, I would have expected an in-depth empirical validation. Unfortunately this is not the case here. In the toy environment (4.1) I am surprised by the really poor quality of the results (paths 5-10 times longer than the shortest path on average): have algorithms been run for a long enough time? Or maybe the average is a bad performance measure due to outliers? I would have also appreciated a comparison to Retrace(lambda), which is a more principled way to use multi-step rewards than n-step Q-learning (which is technically an on-policy method). Similar remarks can be made on the Atari experiments (4.2), where 10M frames is really low (the original DQN paper had results on 50M frames, and Rainbow reports 200M frames in only ~2x the training time reported here). The comparison also should have included prioritized experience replay, which has been shown to provide a significant boost in DQN, but may be tricky to combine with the proposed algorithm. Overall comparing only to vanilla DQN and its optimality tightening variant is too limited when there have been so many other meaningful improvements over DQN. This makes it really hard to tell whether the proposed algorithm would actually help when combined with a state-of-the-art method like Rainbow for instance.\n\nA few additional small remarks and questions:\n- « Second, there is no point in updating a one-step transition unless the future transitions have not been updated yet. »: should « unless » be replaced by « if »?\n- In 4.1 is there a maximum number of steps per episode and can you please confirm that training is done independently for each maze?\n- Typo in eq. 3: the - in the max should be a comma\n- There is a good amount of typos and grammar errors, though they do not harm the readability of the paper\n- Citations for « Deep Reinforcement Learning with Double Q-learning » and « Dueling Network Architectures for Deep Reinforcement Learning » could refer to their conference versions\n- « epsilon starts from 1 and is annealed to 0 at 200,000 steps in a quadratic manner »: please specify the exact formula\n- Fig. 7 is really confusing, there seem to be typos and it is not clear why the beta updates appear in these specific cells, please revise it if you want to keep it']","[-20, 50, -30]","[50, 75, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting', they express several criticisms and concerns. They mention the lack of proper comparisons, results being worse than SOTA, and the need for theoretical analysis. The reviewer also points out that similar approaches exist which haven't been compared to.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They begin with a positive note calling the paper 'interesting', and their criticisms are presented as suggestions for improvement rather than harsh judgments. The language used is respectful and focuses on the content of the paper rather than making personal comments about the authors."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's clarity and the promising results, especially in the MNIST domain. However, they also express some reservations, such as questioning the novelty of the approach and suggesting additional comparisons. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledging the authors' work positively while offering constructive criticism. They use phrases like 'The paper is written in a clear way' and 'The experimental results seem promising,' which contribute to a polite tone. The reviewer also frames their suggestions as considerations rather than demands, maintaining a courteous approach to feedback."", ""The sentiment score is -30 because while the reviewer acknowledges the novelty of the proposed algorithm, they express significant concerns about the lack of theoretical analysis and in-depth empirical validation. They point out several limitations in the experiments and comparisons, suggesting the work is not yet comprehensive enough. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement and asking clarifying questions. They use phrases like 'I would have expected,' 'I would have appreciated,' and 'please specify,' which are polite ways to express concerns and request additional information. The reviewer also acknowledges the paper's contributions and provides detailed feedback, which is a courteous approach in academic review.""]"
"['This paper proposes a simplified LSTM variants by removing the non-linearity of content item and output gate. It shows comparable results with standard LSTM.\n\nI believe this is a updated version of https://arxiv.org/abs/1705.07393 (Recurrent Additive Networks) with stronger experimental results. \n\nHowever, the formulation is very similar to ""[1] Semi-supervised Question Retrieval with Gated Convolutions"" 2016 by Lei, and ""Deriving Neural Architectures from Sequence and Graph Kernels"" which give theoretical view from string kernel about why this type of networks works. Both of the two paper don\'t have output gate and non-linearity of ""Wx_t"" and results on PTB also stronger than this paper. It also have some visualization about how the model decay the weights. Other AnonReviewer also point out some similar work. I won\'t repeat it here. In the paper, the author argued ""we propose and evaluate the minimal changes..."" but I think the these type of analysis also been covered by [1], Figure 5. \n\nOn the experimental side, to draw the conclusion, ""weighted sum"" is enough for LSTM. I think at least Machine Translation and other classification results should be added. I\'m not very familiar with SQuAD dataset, but the results seems worse than ""Reading Wikipedia to answer open-domain questions"" Table 4 which seems use a vanilla LSTM setup. \n\nUpdate: the revised version of the paper addresses all my concerns about experiments. So I increased my score. \n', 'Summary: the paper proposes a new insight to LSTM in which the core is an element-wise weighted sum. The paper then argues that LSTM is redundant by keeping only input and forget gates to compute the weights. Experimental results show that the simplified versions work as well as the full LSTM. \n\n\nComment: I kinda like the idea and welcome this line of research. The paper is very well written and has nice visualisation of demonstrating weights. I have only one question:\n\nin the simplified versions, content(x_t) = Wx_t , which works very well (outperforming full LSTM). I was wondering if the problem is from the tanh activation function (eq 2). What if content(x_t) = W_1 . h_{t-1} + W_2 . x_t? ', 'This paper presents an analysis of LSTMS showing that they have a from where the memory cell contents at each step is a weighted combination of the “content update” values computed at each time step. The weightings are defined in terms of an exponential decay on each dimension at each time step (given by the forget gate), which lets the cell be computed sequentially in linear time rather than in the exhaustive quadratic time that would apparently be necessary for this definition. Second, the paper offers a simplification of LSTMs that compute the value by which the memory cell at each time step in terms of a deterministic function of the input rather than a function of the input and the current context. This reduced form of the LSTM is shown to perform comparably to “full” LSTMs.\n\nThe decomposition of the LSTM in terms of these weights is useful, and suggests new strategies for comparing existing quadratic time attention-based extensions to RNNs. The proposed model variations (which replaces the “content update” that has a recurrent network in terms of context-independent update) and their evaluations seem rather more arbitrary. First, there are two RNNs present in the LSTM- one controls the gates, one controls the content update. You get rid of one, not the other. You can make an argument for why the one that was ablated was “more interesting”, but really this is an obvious empirical question that should be addressed. The second problem of what tasks to evaluate on is a general problem with comparing RNNs. One non-language task (e.g., some RL agent with an LSTM, or learning to execute or something) and one synthetic task (copying or something) might be sensible. Although I don’t think this is the responsibility of this paper (although something that should be considered).\n\nFinally, there are many further simplifications of LSTMs that could have been explored in the literature: coupled input-forget gates (Greff et al, 2015), diagonal matrices for gates, GRUs. When proposing yet another simplification, some sense for how these different reductions is useful, so I would recommend comparison to those.\n\nNotes on clarity:\nBefore Eq 1 it’s hard to know what the antecedent of “which” is without reading ahead.\n\nFor componentwise multiplication, you have been using \\circ, but then for the iterated component wise product, \\prod is used. To be consistent, notation like \\odot and \\bigodot might be a bit clearer.\n\nThe discussion of dynamic programming: the dynamic program is also only available because the attention pattern is limited in a way that self attention is not. This might be worth mentioning.\n\nWhen presenting Eq 11, the definition of w_j^t elides a lot of complexity. Indeed, w_j^t is only ever implicitly defined in Eq 8, whereas things like the input and forget gates are defined multiple times in the text. Since w_j^t can be defined iteratively and recursively (as a dynamic program), it’s probably worth writing both out, for expository clarity.\n\nEq 11 might be clearer if you show that Eq 8 can also be rewritten in the same wheat, provided, you make h_{t-1} an argument to output and content.\n\nTable 4 is unclear. In a language model, the figure looks like it is attending to the word that is being generated, which is clearly not what you want to convey since language models don’t condition on the word they are predicting. Presumably the strong diagonal attention is attending to the previous word when computing the representation to generate the subsequent word? In any case, this figure should be corrected to reflect this. This objection also concerns the right hand figure, and the semantics of the meaning of the upper vs lower triangles should be clarified in the caption (rather than just in the text).']","[20, 80, 20]","[50, 90, 60]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's contributions and improved experimental results, they also raise concerns about similarity to previous work and the need for additional experiments. The initial criticism is balanced by the update noting that the revised version addressed their concerns, leading to an increased score. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges the paper's merits, and provides constructive feedback without harsh criticism. They use phrases like 'I believe' and 'I think' to soften their suggestions, and the tone remains professional and courteous even when pointing out limitations."", ""The sentiment score is 80 (positive) because the reviewer expresses liking the idea, welcomes the research direction, and praises the paper as 'very well written' with 'nice visualisation'. The only slight reservation is a question about a potential alternative approach, which doesn't significantly detract from the overall positive sentiment. The politeness score is 90 (very polite) due to the use of respectful and encouraging language throughout. The reviewer uses phrases like 'I kinda like the idea' and 'I was wondering', which are gentle and considerate ways of expressing opinions and asking questions. The overall tone is supportive and constructive, without any harsh criticism or demanding language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the usefulness of the paper's decomposition of LSTM and its potential for new strategies. However, they also point out several limitations and areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'might be sensible' and 'I would recommend' which maintain a polite tone. The reviewer also provides detailed feedback on clarity issues, which is helpful and courteous. The overall tone is professional and constructive, even when pointing out areas for improvement.""]"
"['The authors proposed an algorithm named Deep Temporal Clustering (DTC) that integrates autoencoder with time-series data clustering. Compared to existing methods, DTC used a network structure (CNN + BiLSTM) that suits time-series data. In addition, a new clustering loss with different similarity measures are adopted to DTC. Experiments on different time-series data show the effectiveness of DTC compared to complete link. \n\nAlthough the idea of applying deep learning for temporal clustering is novel and interesting, the optimization problem is not clearly stated and experiments section is not comprehensive enough.\n\nHere are the detailed comments.\nThe methods are described in a higher level language. The formula of overall loss function and its optimization should be written down to avoid unclearness.\nThe framework adopt the K-medoid clustering idea. But complete-link is used for initialization and comparison. Is that a difference? In addition, how to generate K centroids from complete-link clustering is not described at all.\nThe author Dynamic Time Warping is too expensive to integrate into DTC. However, most of the evaluated dataset are with small time points. Even for the longer ones, DTC does dimensionality reduction to make the time-series shorter. I do not see why quadratic computation is a problem here. DTW is most effective similarity measure for time-series data clustering. There is no excuse to skip it.\nIs DTC robust to hyperparameters? If not, are there any guidelines to tune the hyperparameters, which is very important for unsupervised clustering. \n\nIn summary, the method need to be described clearer, state-of-the-arts need to be compared and the usability of the method needs to be discussed. Therefore, at the current stage the paper cannot be accepted in my opinion. \n', 'This paper proposes an algorithm for jointly performing dimensionality reduction and temporal clustering in a deep learning context.  An autoencoder is utilized for dimensionality reduction alongside a clustering objective - that is the autoencoder optimizes the mse (using LSTM layers are utilized in the autoencoder for modelling temporal information), while the latent space  is fed into the temporal clustering layer.  The clustering/autoencoder objectives are optimized in an alternating optimization fashion.\n\nThe main con lies in this work being very closely related to t-sne, i.e. compare the the temporal clustering loss based on kl-div (eq 6) to t-sne.  If we consider e.g., a linear 1-layer autoencoder to be equivalent to PCA (without the rnn layers), in essence this formulation is closely related to applying pca to reduce the initial dimensionality and then t-sne. \n\nAlso, do the cluster centroids appear to be roughly stable over many runs of the algorithm? As the authors mention, the method is sensitive to intitialization.  As the averaged results over 5 runs are shown, the standard deviation would be helpful towards showing this empirically.\n\nOn the positive side, it is likely that richer representations can be obtained via this architecture, and results appear to be good with comparison to other metrics \n\nThe section of the paper that discusses heat-maps should be written more clearly.  Figure 3 is commented with respect to detecting an event - non-event but the process itself is not clearly described as far as I can see.\n\nminor note: the dynamic time warping is formally not a metric', '\nSummary:\nThe authors proposed an unsupervised time series clustering methods built with deep neural networks. The proposed model is equipped with an encoder-decoder and a clustering model. First, the encoder employs CNN to shorten the time series and extract local temporal features, and the CNN is followed by bidirectional LSTMs to get the encoded representations. A temporal clustering model and a DCNN decoder are applied on the encoded representations and jointly trained. An additional heatmap generator component can be further included in the clustering model. The authors compared the proposed method with hierarchical clustering with 4 different temporal similarity methods on several univariate time series datasets.\n\nDetailed comments:\nThe problem of unsupervised time series clustering is important and challenging. The idea of utilizing deep learning models to learn encoded representations for clustering is interesting and could be a promising solution.\n\nOne potential limitation of the proposed method is that it is only designed for univariate time series of the same temporal length, which limits the usage of this model in practice. In addition, given that the input has fixed length, clustering baselines for static data can be easily applied and should be compared to demonstrate the necessity of temporal clustering.\n\nSome important details are missing or lack of explanations. For example, what is the size of each layer and the dimension of the encoded space? How much does the model shorten the input time series and how is this be determined?\n\nHow does the model combine the heatmap output (which is a sequence of the same length as the time series) and the clustering output (which is a vector of size K) in Figure 1? The heatmap shown in Figure 3 looks like the negation of the decoded output (i.e., lower value in time series -> higher value in heatmap). How do we interpret the generated heatmap? \n\nFrom the experimental results, it is difficult to judge which method/metric is the best. For example, in Figure 4, all 4 DTC-methods achieved the best performance on one or two datasets. Though several datasets are evaluated in experiments, they are relatively small. Even the largest dataset (Phalanges OutlinesCorrect) has only 2 thousand samples, and the best performance is achieved by one of the baseline, with AUC score only 0.586 for binary classification.\n\nMinor suggestion: \nIn Figure 3, instead of showing the decoded output (reconstruction), it may be more helpful to visualize the encoded time series since the clustering method is applied directly on those encoded representations.\n\n']","[-50, 20, 20]","[50, 50, 60]","[""The sentiment score is -50 because while the reviewer acknowledges the novelty and interesting nature of the idea, they ultimately conclude that the paper cannot be accepted in its current state. They point out several significant issues with the methodology and experiments, indicating a generally negative sentiment. However, it's not entirely negative as they do recognize some positive aspects. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and specific suggestions for improvement. They avoid harsh or personal criticisms, instead focusing on the content of the paper. The tone is firm but not rude, maintaining a level of politeness typical in academic peer reviews."", ""The sentiment score is slightly positive (20) because while the reviewer points out some concerns and areas for improvement, they also acknowledge positive aspects of the paper. The review begins by neutrally describing the paper's approach, then lists some cons, but also mentions positive aspects like 'results appear to be good'. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, avoiding harsh criticism and instead offering constructive feedback. They use phrases like 'The main con lies in...' and 'Also, do the cluster centroids...' which are polite ways of raising concerns. The reviewer also balances critique with positive comments, which contributes to the overall polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the importance of the problem and the potential of the proposed method, calling it 'interesting' and 'promising'. However, they also point out several limitations and areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions without harsh or dismissive comments. They use phrases like 'potential limitation', 'it may be more helpful', and 'Minor suggestion', which maintain a polite and professional tone. The review is balanced, offering both positive feedback and areas for improvement in a courteous manner.""]"
"['This work proposes a multi task learning framework for the modeling of clinical data in neurodegenerative diseases. \nDifferently from previous applications of machine learning in neurodegeneration modeling, the proposed approach models the clinical data accounting for the bounded nature of cognitive tests scores. The framework is represented by a feed-forward deep architecture analogous to a residual network. At each layer a low-rank constraint is enforced on the linear transformation, while the cost function is specified in order to differentially account for the bounds of the predicted variables.\n\nThe idea of explicitly accounting for the boundedness of clinical scores is interesting, although the assumption of the proposed model is still incorrect: clinical scores are defined on discrete scales. For this reason the Gaussian assumption for the cost function used in the method is still not appropriate for the proposed application. \nFurthermore, while being the main methodological drive of this work, the paper does not show evidence about improved predictive performance and generalisation when accounting for the boundedness of the regression targets. \nThe proposed algorithm is also generally compared with respect to linear methods, and the authors could have provided a more rigorous benchmark including standard non-linear prediction approaches (e.g. random forests, NN, GP, …). \n\nOverall, the proposed methods seems to provide little added value to the large amount of predictive methods proposed so far for prediction in neurodegenerative disorders. Moreover, the proposed experimental paradigm appears flawed. What is the interest of predicting baseline (or 6 months at best) cognitive scores (relatively low-cost and part of any routine clinical assessment) from brain imaging data (high-cost and not routine)?\n\nOther remarks. \n\n- In section 2.2 and 4 there is some confusion between iteration indices and samples indices “i”. \n\n- Contrarily to what is stated in the introduction, the loss functions proposed in page 3 (first two formulas) only accounts for the lower bound of the predicted variables.  \n\n-  Figure 2, synthetic data. The scale of the improvement of the subspace difference is quite tiny, in the order of 1e-2 when compared to U, and of 1e-5 across iterations. The loss function of Figure 2.b also does not show a strong improvement across iterations, while indicating a rather large instability of the optimisation procedure. These aspects may be a sign of convergence issues. \n\n- The dimensionality of the subspace representation importantly depends on the choice of the rank R of U and V. This is a crucial parameters that is however not discussed nor analysed in the paper. \n\n- The synthetic example of page 7 is quite misleading and potentially biased towards the proposed model. The authors are generating the synthetic data according to the model, and it is thus not surprising that they managed to obtain the best performance.  In particular, due to the nonlinear nature of (1), all the competing linear models are expected to perform poorly in this kind of setting.\n\n- The computation time for the linear model shown in Table 3 is quite surprising (~20 minutes for linear regression of 5k observations). Is there anything that I am missing?\n', 'This paper presents a new multi-task network architecture within which low-rank parameter spaces were found using matrix factorization. As carefully proved and tested, only one pass of the training data would help recover the parametric subspace, thus network could be easily trained layer-wise and expanded.\n\nSome novel contributions:\n1. Layer by layer feedforward training process, no back-prop.\n2. On-line settings to train parameters ( guaranteed convergence in a single pass of the data)\n\nWeakness :\n1. The assumption that a low-rank parameter space exists among tasks rather than original feature spaces is not new and widely used in literature.\n2. The proof part(Section 2.2) can be extended with more details in Appendix.\n3. In synthetic data experiments (Table1), only small margins could be observed between SN, f-MLP and rf-MLP, and only Layer 1 of SN performs better above all others. \n4. Typo: In Table2,3,5, Multi-l_{2,1} (denotes the L2,1 norm) were written wrong.\n5. In the synthetic data experiments on comparison with single-task and multi-task models, counter-intuitive results (with larger training data split, ANMSE raises instead of decreases) of multi-task models may need further explanation. \n6. Extra models like Deep Networks with/without matrix factorization could be added. ( As proposed model is a deep model, the lack of comparison with deep methods is dubious)\n7. In Section 4.2, the real dataset is rather small thus the results on this small dataset were not convincing enough. SN model outperforms the state-of-the-art with only small margin. Extensive experiments could be added.\n8. The performance on One-Layer Subspace Network (with only the input features) could be added. \n\nConclusion:\nThough with a quite novel idea on solving multi-task censored regression problem, the experiments conducted on synthetic data and real data are not convincing enough to ensure the contribution of the Subspace Network. \n', 'The authors propose a DNN, called subspace network, for nonlinear multi-task censored regression problem. The topic is important. Experiments on real data show improvements compared to several traditional approaches.\n\nMy major concerns are as follows.\n\n1. The paper is not self-contained. The authors claim that they establish both asymptotic and non-asymptotic convergence properties for Algorithm 1. However, for some key steps in the proof, they refer to other references. If this is due to space limitation in the main text, they may want to provide a complete proof in the appendix.\n\n2. The experiments are unconvincing. They compare the proposed SN with other traditional approaches on a very small data  set with 670 samples and 138 features. A major merit of DNN is that it can automatically extract useful features. However, in this experiment, the features are handcrafted before they are fed into the models. Thus, I would like to see a comparison between SN with vanilla DNN. ']","[-60, -20, -20]","[20, 50, 50]","[""The sentiment score is -60 because the review is predominantly critical. While it acknowledges the interesting idea of accounting for boundedness of clinical scores, it points out several significant flaws in the methodology, experimental design, and overall contribution. The reviewer states that the method provides 'little added value' and that the experimental paradigm is 'flawed'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'The idea... is interesting' and 'Other remarks' to soften their criticisms. The language is not overtly rude, but rather matter-of-fact in presenting the issues. However, the overall critical nature of the comments prevents a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some novel contributions, they also list several weaknesses and conclude that the experiments are not convincing enough to ensure the contribution of the Subspace Network. The overall tone suggests that the paper has potential but needs significant improvements. The politeness score is moderately positive (50) as the reviewer uses neutral language, acknowledges positive aspects, and frames criticisms as suggestions or areas for improvement rather than direct attacks. They use phrases like 'could be added' and 'may need further explanation' which maintain a respectful tone while providing constructive feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and notes improvements shown in experiments, they express 'major concerns' about the paper's self-containment and the convincingness of the experiments. These concerns outweigh the initial positive remarks. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, framing their concerns as suggestions ('they may want to provide...') and requests ('I would like to see...') rather than demands. The reviewer also begins with positive observations before moving to criticisms, which is a polite approach. However, the directness of the criticisms prevents a higher politeness score.""]"
"['This submission proposes a new seq2sel solution by adopting two new techniques, a sequence-to-set model and column attention mechanism. They show performance improve over existing studies on WikiSQL dataset.\n\nWhile the paper is written clearly, the contributions of the work heavily depends on the WikiSQL dataset. It is not sure if the approach is generally applicable to other sequence-to-sql workloads. Detailed comments are listed below:\n\n1. WikiSQL dataset contains only a small class of SQL queries, with aggregation over single table and various filtering conditions. It does not involve any complex operator in relational database system, e.g., join and groupby. Due to its simple structure, the problem of sequence-to-sql translation over WikiSQL is actually simplified as a parameter selection problem for a fixed template. This greatly limits the generalization of approaches only applicable to WikiSQL. The authors are encouraged to explore other datasets available in the literature.\n\n2. The ""order-matters"" motivation is not very convincing. It is straightforward to employ a global ordering approach to rank the columns and filtering conditions based on certain rules, e.g., alphabetical order. That could ensure the orders in the SQL results are always consistent.\n\n3. The experiments do not fully verify how the approaches bring performance improvements. In the current version, the authors only report superficial accuracy results on final outcomes, without any deep investigation into why and how their approach works. For instance, they could verify how much accuracy improvement is due to the insensitivity to order in filtering expressions.\n\n4. They do not compare against state-of-the-art solution on column and expression selection. While their attention mechanism over the columns could bring performance improvement, they should have included experiments over existing solutions designed for similar purpose. In (Yin, et al., IJCAI 2016), for example, representations over the columns are learned to generate better column selection.\n\nAs a conclusion, I find the submission contains certain interesting ideas but lacks serious research investigations. The quality of the paper could be much enhanced, if the authors deepen their studies on this direction.', 'The authors present a neural architecture for the WikiSQL task. The approach can be largely seen as graphical model tailored towards the constrained definition of SQL queries in WikiSQL. The model makes strong independence-assumptions, and only includes interactions between structures where necessary, which reduces the model complexity while alleviating the ""order matters"" problem. An attention mechanism over the columns is used to model the interaction between columns and the op or value in a soft differentiable manner. The results show impressive gains over the baseline, despite using a much simpler model. I appreciated the breakdown of accuracy over the various subtasks, which provides insights into where the challenges lie.', 'This paper proposes a neural network-based approach to converting natural language questions to SQL queries. The idea is to use a small grammar to facilitate the process, together making some independence assumptions. It is evaluated on a recently introduced dataset for natural language to SQL.\n\nPros:\n- good problem, NL2SQL is an important task given how dominant SQL is\n- incorporating a grammar (""sketch"") is a sensible improvement.\n\nCons:\n- The dataset used makes very strong simplification assumptions. Not  problem per se, but it is not the most challenging SQL dataset. The ATIS corpus is NL2SQL and much more challenging and realistic:\nDeborah A. Dahl, Madeleine Bates, Michael Brown, William Fisher, Kate Hunicke-Smith, David Pallett, Christine Pao, Alexander Rudnicky, and Elizabeth Shriberg. 1994. Expanding the scope of the ATIS task: the ATIS-3 corpus. In Proceedings of the workshop on Human Language Technology (HLT \'94). Association for Computational Linguistics, Stroudsburg, PA, USA, 43-48. DOI: https://doi.org/10.3115/1075812.1075823\n\n- In particular, the assumption that every token in the SQL statement is either an SQL keyword or appears in the natural language statement is rather atypical and unrealistic.\n\n- The use of a grammar in the context of semantic parsing is not novel; see this tutorial for many pointers:\nhttp://yoavartzi.com/tutorial/\n\n- As far as I can tell, the set prediction is essentially predicted each element independently, without taking into account any dependencies. Nothing wrong, but also nothing novel, that is what most semantic parsing/semantic role labeling baseline approaches do. The lack of ordering among the edges, doesn\'t mean they are independent.\n\n- Given the rather constrained type of questions and SQL statements, it would make sense to compare it against approaches for question answering over knowledge-bases:\nhttps://github.com/scottyih/Slides/blob/master/QA%20Tutorial.pdf\nWhile SQL can express much more complex queries, the ones supported by the grammar here are not very different.\n\n- Pasupat and Liang (2015) also split the data to make sure different tables appear only in training, dev, test and they developed their dataset using crowd sourcing.\n\n- The comparison against Dong and Lapata (2016) is not fair because their model is agnostic and thus applicable to 4 datasets while the one presented here is tailored to the dataset due the grammar/sketch used. Also, suggesting that previous methods might not generalize well sounds odd given that the method proposed seems to use much larger datasets.\n\n- Not sure I agree that mixing the same tables across training/dev/test is more realistic. If anything, it assumes more training data and manual annotation every time a new table is added.']","[-30, 80, -30]","[50, 50, 20]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('paper is written clearly', 'contains certain interesting ideas'), they express significant concerns about the work's limitations and lack of depth. The overall tone suggests the paper needs substantial improvements. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions ('authors are encouraged to', 'could verify') rather than harsh criticism. They also acknowledge positive aspects before diving into concerns, which is a polite approach. However, it's not extremely polite, as it maintains a professional, somewhat detached tone rather than being overtly courteous."", ""The sentiment score is 80 (positive) because the reviewer expresses appreciation for the authors' work, noting 'impressive gains' and praising the breakdown of accuracy. The review highlights the strengths of the approach without any significant criticisms. The politeness score is 50 (somewhat polite) as the reviewer uses respectful language and acknowledges the authors' contributions, but doesn't use overtly polite phrases. The tone is professional and constructive, focusing on the merits of the work rather than personal comments or excessive praise."", ""The sentiment score is -30 because while the reviewer acknowledges some pros ('good problem', 'sensible improvement'), the majority of the review focuses on cons and criticisms. The reviewer points out several limitations, suggests comparisons that weren't made, and questions some of the authors' claims. However, the tone isn't entirely negative, hence a score above -50. The politeness score is 20 because the reviewer uses professional and neutral language throughout, avoiding harsh criticism. They present their points objectively, using phrases like 'Not sure I agree' instead of more confrontational language. The reviewer also acknowledges positive aspects before diving into criticisms, which is a polite approach. However, the score isn't higher because the review doesn't go out of its way to be exceptionally polite or encouraging.""]"
"['\n# Summary of paper\nThe paper proposes an algorithm for hyperparameter optimization that can be seen as an extension of Franceschi 2017 were some estimates are warm restarted to increase the stability of the method. \n\n# Summary of review\nI find the contribution to be incremental, and the validation weak. Furthermore, the paper discusses the algorithm using hand-waiving arguments and lacks the rigor that I would consider necessary on an optimization-based contribution. None of my comments are fatal, but together with the incremental contribution I\'m inclined as of this revision towards marginal reject. \n\n# Detailed comments\n\n1. The distinction between parameters and hyperparameters (section 3) should be revised. First, the definition of parameters should not include the word parameters. Second, it is not clear what ""parameters of the regularization"" means. Typically, the regularization depends on both hyperparameters and parameters. The real distinction between parameters and parameters is how they are estimated: hyperparameters cannot be estimated from the same dataset as the parameters as this would lead to overfitting and so need to be estimated using a different criterion, but both are ""begin learnt"", just from different datasets.\n\n2. In Section 3.1, credit for the approach of computing the hypergradient by backpropagating through the training procedure is attributed to Maclaurin 2015. This is not correct. This approach was first proposed in Domke 2012 and refined by Maclaurin 2015 (as correctly mentioned in Maclaurin 2015).\n\n3. Some quantities are not correctly specified. I should not need to guess from the context or related literature what the quantities refer to. theta_K for example is undefined (although I could understand its meaning from the context) and sometimes used with arguments, sometimes without (i.e., both theta_K(lambda, theta_0) and theta_K are used).\n\n4. The hypothesis are not correctly specified. Many of the results used require smoothness of the second derivative (e.g., the implicit function theorem) but these are nowhere stated.\n\n5. The algorithm introduces too many hyper-hyperparameters, although the authors do acknowledge this. While I do believe that projecting into a compact domain is necessary (see Pedregosa 2016 assumption A3), the other parameters should ideally be relaxed or estimated from the evolution of the algorithm.\n\n# Minor\n\nmissing . after ""hypergradient exactly"".\n\n""we could optimization the hyperparam-"" (typo)\n\nReferences:\n Justin  Domke.    Generic  methods  for  optimization-based modeling.  In\nInternational Conference on Artificial Intelligence and Statistics, 2012.\n', 'Summary of paper:\n\nThis work proposes an extension to an existing method (Franceschi 2017) to optimize regularization hyperparameters. Their method claims increased stability in contrast to the existing one.\n\nSummary of review:\n\nThis is an incremental change of an existing method. This is acceptable as long as the incremental change significantly improves results or the paper presents some convincing theoretical arguments. I did not find either to be the case. The theoretical arguments are interesting but lacking in rigor. The proposed method introduces hyper-hyperparameters which may be hard to tune. The experiments are small scale and it is unclear how much the method improves random grid search. For these reasons, I cannot recommend this paper for acceptance.\n\nComments:\n1. Paper should cite Domke 2012 in related work section.\n2. Should state and verify conditions for application of implicit function theorem on page 2.\n3. Fix notation on page 3. Dot is used on the right hand side to indicate an argument but not left hand side for equation after ""with respect to \\lambda"".\n4. I would like to see more explanation for the figure in Appendix A. What specific optimization is being depicted? This figure could be moved into the paper\'s main body with some additional clarification.\n5. I did not understand the paragraph beginning with ""This poor estimation"". Is this just a restatement of the previous paragraph, which concluded convergence will be slow if \\eta is too small?\n6. I do understand the notation used in equation (8) on page 4. Are <, > meant to denote less than/greater than or something else?\n7. Discussion of weight decay on page 5 seems tangential to main point of the paper. Could be reduced to a sentence or two.\n8. I would like to see some experimental verification that the proposed method significantly reduces the dropout gradient variance (page 6), if the authors claim that tuning dropout probabilities is an area they succeed where others don\'t.\n9. Experiments are unconvincing. First, only one hyperparameter is being optimized and random search/grid search are sufficient for this. Second, it is unclear how close the proposed method is to finding the optimal regularization parameter \\lambda. All one can conclude is that it performs slightly better than grid search with a small number of runs. I would have preferred to see an extensive grid search done to find the best possible \\lambda, then seen how well the proposed method does compared to this.\n10. I would have liked to see a plot of how the value of lambda changes throughout optimization. If one can initialize lambda arbitrarily and have this method find the optimal lambda, that is more impressive than a method that works simply because of a fortunate initialization.\n\n\nTypos:\n1. Optimization -> optimize (bottom of page 2)\n2. Should be a period after sentence starting ""Several algorithms"" on page 2.\n3. In algorithm box on page 5, enable_projection is never used. Seems like warmup_time should also be an input to the algorithm. \n', 'Summary of the paper\n---------------------------\nThe paper addresses the issue of online optimization of hyper-parameters customary involved in deep architectures learning.  The covered framework is limited to regularization parameters. These hyper-parameters, noted $\\lambda$, are updated along the training of model parameters $\\theta$ by relying on the generalization performance (validation error). The paper proposes a dynamical system including the dynamical update of $\\theta$ and the update of the gradient $y$, derivative of $\\theta$ w.r.t. to the hyper-parameters. The main contribution of the paper is to propose a way to re-initialize $y$ at each update of $\\lambda$ and a clipping procedure of $y$ in order to maintain the stability of the dynamical system. Experimental evaluations on synthetic or real datasets are conducted to show the effectiveness of the approach.\n\nComments\n-------------\n- The materials of the paper sometimes may be quite not easy to follow. Nevertheless the paper is quite well written.\n- The main contributions of the paper can be seen as an incremental version of (Franceschi et al, 2017) based on the proposal in (Luketina et al., 2016). As such the impact of the contributions appears rather limited even though the experimental results show a better stability of the method compared to competitors.\n- One motivation of the approach is to fix the slow convergence of the method in (Franceschi et al, 2017). The paper will gain in quality if a theoretical analysis of the speed-up brought by the proposed approach is discussed.\n- The goal of the paper is to address automatically the learning of regularization parameters. Unfortunately, Algorithm 1 involves several other hyper-parameters (namely clipping factor $r$, constant $c$ or $\\eta$) which choices are not clearly discussed. It turns that the paper trades a set of hyper-parameters for another one which tuning may be tedious. This fact weakens the scope of the online hyper-parameter optimization approach.\n- It may be helpful to indicate the standard deviations of the experimental results.']","[-60, -70, -20]","[20, 20, 50]","[""The sentiment score is -60 because the reviewer states the contribution is 'incremental' and the validation 'weak', and is 'inclined towards marginal reject'. However, they do note that 'None of my comments are fatal', which prevents the score from being even lower. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and provide specific, constructive feedback. They acknowledge the authors' work ('the authors do acknowledge this') and use phrases like 'I find' and 'I'm inclined' rather than stating opinions as facts. The reviewer also provides detailed comments to help improve the paper, which is a polite and helpful approach."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states they 'cannot recommend this paper for acceptance' and lists several major criticisms, including that the theoretical arguments lack rigor, the experiments are small scale, and the improvements over existing methods are unclear. However, it's not entirely negative as the reviewer acknowledges some interesting aspects, hence not the lowest possible score. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'I would like to see' and 'I did not understand' rather than more confrontational language. They also provide specific, constructive feedback and suggestions for improvement, which is polite and helpful. However, the overall tone is more neutral than overtly polite, hence a slightly positive but not high score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('quite well written', 'experimental results show a better stability'), they also point out several limitations and weaknesses of the paper. The overall tone suggests that the paper's contributions are incremental and limited in impact. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'The paper will gain in quality if...' and 'It may be helpful to...' which suggest improvements in a polite manner. The reviewer also balances critique with positive observations, maintaining a professional and courteous tone.""]"
"['This paper discusses the phenomenon of a fast convergence rate for training resnet with cyclical learning rates under a few particular setting. It tries to provide an explanation for the phenomenon and a procedure to test when it happens. However, I don\'t find the paper of high significance or the proposed method solid for publication at ICLR.\n\nThe paper is based on the cyclical learning rates proposed by Smith (2015, 2017). I don\'t understand what is offered beyond the original papers. The ""super-convergence"" occurs under special settings of hyper-parameters for resnet only and therefore I am concerned if it is of general interest for deep learning models. Also, the authors do not give a conclusive analysis under what condition it may happen.\n\nThe explanation of the cause of ""super-convergence"" from the perspective of  transversing the loss function topology in section 3 is rather illustrative at the best without convincing support of arguments. I feel most content of this paper (section 3, 4, 5) is observational results, and there is lack of solid analysis or discussion behind these observations.', 'The paper discusses a phenomenon where neural network training in very specific settings can profit much from a schedule including large learning rates. Unfortunately, this paper feels to be hastily written and can only be read when accompanied with several references as key parts (CLR) are not described and thus the work can not be reproduced from the paper.\n\nThe main claim of the author hinges of the fact that in some learning problems the surface of the objective function can be very flat near the optimum. In this setting, a typical schedule with a decreasing learning rate would be a bad choice as the change of curvature must be corrected as well. However, this is not a general problem in neural network training and might not be generalizable to other datasets or architectures as the authors acknowledge.\n\nIn the end, the actual gain of this paper is only in the form of a hypothesis but there is only very little enlightenment, especially as the only slightly theoretical contribution in section 5 does not predict the observed behavior. \n\nPersonally i would not use the term ""convergence"" in this setting at all as the runs are very short and thus we might not be close to any region of convergence. Most of the plots shown are actually not converged and convergence in test accuracy is not the same as convergence in training loss, which is not shown at all. The results of smaller test error with larger learning rates on small training sets might therefore just be the inability of the optimizer to get closer to the optimum as steps are too long to decrease the expected loss, thus having a similar effect as early stopping.\n\nPros:\n- Many experiments which try to study the effect\nCons:\n-The described phenomenon seems to depend strongly on the problem surface and might never \nbe encountered on any problem aside of Cifar-10\n- Only single runs are shown, considering the noise on those the results might not be reproducible.\n-Experiments are not described in detail\n-Experiment design feels ""ad-hoc"" and unstructured\n-The role and value of the many LR-plots remains unclear to me.\n\nForm:\n- The paper does not maker clear how the exact schedules work. The terms are introduced but the paper misses the most basic formulas\n- Figures are not properly described, e.g. axes in Figures 3 a) and b)\n- Explicit references to code are made which require familiarity with the used framework(if at all published).  ', 'In this paper, the authors analyze training of residual networks using large cyclic learning rates (CLR). The authors demonstrate (a) fast convergence with cyclic learning rates and (b) evidence of large learning rates acting as regularization which improves performance on test sets – this is called “super-convergence”. However, both these effects are only shown on a specific dataset, architecture, learning algorithm and hyper parameter setting. \n\n\nSome specific comments by sections:\n\n2. Related Work: This section loosely mentions other related works on SGD, topology of loss function and adaptive learning rates. The authors mention Loshchilov & Hutter in next section but do not compare it to their work. The authors do not discuss a somewhat contradictory claim from NIPS 2017 (as pointed out in the public comment): http://papers.nips.cc/paper/6770-train-longer-generalize-better-closing-the-generalization-gap-in-large-batch-training-of-neural-networks.pdf\n\n3. Super-convergence: This is a well explained section where the authors describe the LR range test and how it can be used to understand potential for super-convergence for any architecture. The authors also provide sufficient intuition for super-convergence. Since CLRs were already proposed by Smith (2015), the originality of this work would be specifically tied to their application to residual units. It would be interesting to see a qualitative analysis on how the residual error is impacting super-convergence.\n\n4. Regularization: While Fig 4 demonstrates the regularization property, the reference to Fig 1a with better test error compared to typical training methods could simply be a result of slower convergence of typical training methods. \n5. Optimal LRs: Fig.5b shows results for 1000 iterations whereas the text says 10000 (seems like a typo in scaling the plot). Figs 1 and 5 illustrate only one cycle (one increase and one decrease) of CLR. It would be interesting to see cases where more than one cycle is required and to see what happens when the LR increases the second time.\n\n6. Experiments: This is a strong section where the authors show extensive reproducible experimentation to identify settings under which super-convergence works or does not work. However, the fact that the results only applies to CIFAR-10 dataset and could not be observed for ImageNet or other architectures is disappointing and heavily takes away from the significance of this work. \n\nOverall, the work is presented as a positive result in very specific conditions but it seems more like a negative result. It would be more appealing if the paper is presented as a negative result and strengthened by additional experimentation and theoretical backing.']","[-60, -60, -20]","[20, 20, 50]","[""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's significance, novelty, and analytical depth. They state that they 'don't find the paper of high significance' and that there's a 'lack of solid analysis or discussion'. The tone is generally critical, though not entirely dismissive. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone. They use phrases like 'I don't understand' and 'I am concerned' rather than more aggressive language. The reviewer also acknowledges some positive aspects, such as the paper's attempt to explain a phenomenon, which contributes to a more polite overall tone."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several issues with the paper, including that it's 'hastily written', lacks key descriptions, has limited generalizability, and provides 'very little enlightenment'. The few positive aspects mentioned ('Many experiments') are outweighed by the numerous criticisms. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'Personally i would not use' and 'remains unclear to me' instead of more confrontational language. The reviewer also acknowledges some positive aspects ('Pros:') before listing the negatives. However, the overall tone is more matter-of-fact than overtly polite, hence the relatively low positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'well explained section', 'strong section'), they also point out significant limitations. The reviewer notes that the results are limited to specific conditions and suggests the work might be better presented as a negative result. The phrase 'disappointing and heavily takes away from the significance of this work' indicates a notably negative sentiment.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They offer constructive criticism and specific suggestions for improvement without using harsh or dismissive language. The reviewer acknowledges the authors' efforts and provides detailed feedback, which is a polite approach in academic peer review. However, the score is not higher because the review doesn't include overtly polite phrases or compliments beyond what is typical in a professional review.""]"
"['The paper is clear and well written.\nIt is an incremental modification of prior work (ResNeXt) that performs better on several experiments selected by the author; comparisons are only included relative to ResNeXt.\n\nThis paper is not about gating (c.f., gates in LSTMs, mixture of experts, etc) but rather about masking or perhaps a kind of block sparsity, as the ""gates"" of the paper do not depend upon the input: they are just fixed masking matrices (see eq (2)).\n\nThe main contribution appears to be the optimisation procedure for the binary masking tensor g. But this procedure is not justified: does each step minimise the loss? This seems unlikely due to the sampling. Can the authors show that the procedure will always converge? It would be good to contrast this with other attempts to learn discrete random variables (for example, The Concrete Distribution: Continuous Relaxation of Continuous Random Variables, Maddison et al, ICLR 2017).\n', 'The paper proposes replacing each layer in a standard (residual) convnet with a set of convolutional modules which are run in parallel.  The input to each model is a sparse sum of the outputs of modules in the previous set.  The paper shows marginal improvements on image classification datasets (2% on CIFAR, .2% on ImageNet) over the ResNeXt architecture that they build on.  \n\nPros:\n- The connectivity is constrained to be sparse between modules, and it is somewhat interesting that this connectivity can be learned with algorithms similar to those previously proposed to learn binary weights.  Furthermore, this learning extends to large-scale image datasets.\n- There is indeed a boost in classification performance, and the approach shows promise for automatically reducing the number of parameters in the network.\n\nCons:\n- Overall, the approach seems to be an incremental improvement over the previous work ResNeXt.\n- The datasets used are not very interesting: Cifar is too small, and ImageNet is essentially solved.  From the standpoint of the computer vision community, increasing performance on these datasets is no longer a meaningful objective.\n- The modifications add complexity.\n\nThe paper is well written and conceptually simple.  However, I feel the paper demonstrates neither enough novelty nor enough of a performance gain for me to advocate acceptance.   ', 'The authors extend the ResNeXt architecture. They substitute the simple add operation with a selection operation for each input in the residual module. The selection of the inputs happens through gate weights, which are sampled at train time. At test time, the gates with the highest values are kept on, while the other ones are shut. The authors fix the number of the allowed gates to K out of C possible inputs (C is the multi-branch factor in the ResNeXt modules). They show results on CIFAR-100 and ImageNet (as well as mini ImageNet). They ablate the choice of K, the binary nature of the gate weights.\n\nPros:\n(+) The paper is well written and the method is well explained\n(+) The authors ablate and experiment on large scale datasets\n\nCons:\n(-) The proposed method is a simple extension of ResNeXt \n(-) The gains are reasonable, yet not SOTA, and come at a price of more complex training protocols (see below)\n(-) Generalization to other tasks not shown\n\nThe authors do a great job walking us through the formulation and intutition of their proposed approach. They describe their training procedure and their sampling approach for the gate weights. However, the training protocol gets complicated with the introduction of gate weights. In order to train the gate weights along with the network parameters, the authors need to train the parameters jointly followed by the training of only the network parameters while keeping the gates frozen. This makes training of such networks cumbersome.\n\nIn addition, the authors report a loss in performance when the gates are not discretized to {0,1}. This means that a liner combination with the real-valued learned gate parameters is suboptimal. Could this be a result of suboptimal, possibly compromised training? \n\nWhile the CIFAR-100 results look promising, the ImageNet-1k results are less impressive. The gains from introducing gate weights in the input of the residual modules vanish when increasing the network size. \n\nLast, the impact of ResNeXt/ResNet lies in their ability to generalize to other tasks. Have the authors experimented with other tasks, e.g. object detection, to verify that their approach leads to better performance in a more diverse set of problems?\n']","[20, -50, -20]","[50, 50, 60]","[""The sentiment score is slightly positive (20) because the reviewer starts by saying the paper is 'clear and well written' and acknowledges that it performs better on several experiments. However, the reviewer also points out limitations and areas for improvement, which tempers the positive sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout and phrases criticisms as suggestions or questions rather than direct attacks. The reviewer maintains a respectful tone while providing constructive feedback, such as 'It would be good to contrast this with...' and 'Can the authors show that...', which contributes to the polite tone."", 'The sentiment score is -50 because while the reviewer acknowledges some pros of the paper, they ultimately do not recommend acceptance due to lack of novelty and significant performance gains. The cons outweigh the pros in their assessment. The politeness score is 50 because the reviewer uses professional and respectful language throughout, acknowledging both strengths and weaknesses of the paper without using harsh or dismissive language. They provide a balanced critique, stating both pros and cons, and explain their reasoning for not recommending acceptance in a constructive manner.', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'well explained', 'great job walking us through'), there are more significant criticisms. The cons outweigh the pros, with concerns about the method being a 'simple extension', gains not being SOTA, complex training protocols, and lack of generalization to other tasks. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the authors' efforts ('great job', 'well written') and framing criticisms as questions or observations rather than direct attacks. The reviewer maintains a professional tone, balancing praise with constructive criticism.""]"
"['The paper proposes data augmentation as an alternative to commonly used regularisation techniques like weight decay and dropout, and shows for a few reference models / tasks that the same generalization performance can be achieved using only data augmentation.\n\nI think it\'s a great idea to investigate the effects of data augmentation more thoroughly. While it is a technique that is often used in literature, there hasn\'t really been any work that provides rigorous comparisons with alternative approaches and insights into its inner workings. Unfortunately I feel that this paper falls short of achieving this.\n\nExperiments are conducted on two fairly similar tasks (image classification on CIFAR-10 and CIFAR-100), with two different network architectures. This is a bit meager to be able to draw general conclusions about the properties of data augmentation. Given that this work tries to provide insight into an existing common practice, I think it is fair to expect a much stronger experimental section. In section 2.1.1 it is stated that this was a conscious choice because simplicity would lead to clearer conclusions, but I think the conclusions would be much more valuable if variety was the objective instead of simplicity, and if larger-scale tasks were also considered.\n\nAnother concern is that the narrative of the paper pits augmentation against all other regularisation techniques, whereas more typically these will be used in conjunction. It is however very interesting that some of the results show that augmentation alone can sometimes be enough.\n\nI think extending the analysis to larger datasets such as ImageNet, as is suggested at the end of section 3, and probably also to different problems than image classification, is going to be essential to ensure that the conclusions drawn hold weight.\n\n\n\nComments:\n\n- The distinction between ""explicit"" and ""implicit"" regularisation is never clearly enunciated. A bunch of examples are given for both, but I found it tricky to understand the difference from those. Initially I thought it reflected the intention behind the use of a given technique; i.e. weight decay is explicit because clearly regularisation is its primary purpose -- whereas batch normalisation is implicit because its regularisation properties are actually a side effect. However, the paper then goes on to treat data augmentation as distinct from other explicit regularisation techniques, so I guess this is not the intended meaning. Please clarify this, as the terms crop up quite often throughout the paper. I suspect that the distinction is somewhat arbitrary and not that meaningful.\n\n- In the abstract, it is already implied that data augmentation is superior to certain other regularisation techniques because it doesn\'t actually reduce the capacity of the model. But this ignores the fact that some of the model\'s excess capacity will be used to model out-of-distribution data (w.r.t. the original training distribution) instead. Data augmentation always modifies the distribution of the training data. I don\'t think it makes sense to imply that this is always preferable over reducing model capacity explicitly. This claim is referred to a few times throughout the work.\n\n- It could be more clearly stated that the reason for the regularising effect of batch normalisation is the noise in the batch estimates for mean and variance.\n\n- Some parts of the introduction could be removed because they are obvious, at least to an ICLR audience (like ""the model would not be regularised if alpha (the regularisation parameter) equals 0"").\n\n- The experiments with smaller dataset sizes would be more interesting if smaller percentages were used. 50% / 80% / 100% are all on the same order of magnitude and this setting is not very realistic. In practice, when a dataset is ""too small"" to be able to train a network that solves a problem reliably, it will generally be one or more orders of magnitude too small, not 2x too small.\n\n- The choices of hyperparameters for ""light"" and ""heavy"" motivation seem somewhat arbitrary and are not well motivated. Some parameters which are sampled uniformly at random should be probably be sampled log-uniformly instead, because they represent scale factors. It should also be noted that much more extreme augmentation strategies have been used for this particular task in literature, in combination with padding (for example by Graham). It would be interesting to include this setting in the experiments as well.\n\n- On page 7 it is stated that ""when combined with explicit regularization, the results are much worse than without it"", but these results are omitted from the table. This is unfortunate because it is a very interesting observation, that runs counter to the common practice of combining all these regularisation techniques together (e.g. L2 + dropout + data augmentation is a common combination). Delving deeper into this could make the paper a lot stronger.\n\n- It is not entirely true that augmentation parameters depend only on the training data and not the architecture (last paragraph of section 2.4). Clearly more elaborate architectures benefit more from data augmentation, and might need heavier augmentation to perform optimally because they are more prone to overfitting (this is in fact stated earlier on in the paper as well). It is of course true that these hyperparameters tend to be much more robust to architecture changes than those of other regularisation techniques such as dropout and weight decay. This increased robustness is definitely useful and I think this is also adequately demonstrated in the experiments.\n\n- Phrases like ""implicit regularization operates more effectively at capturing reality"" are too vague to be meaningful.\n\n- Note that weight decay has also been found to have side effects related to optimization (e.g. in ""Imagenet classification with deep convolutional neural networks"", Krizhevsky et al.)\n\nREVISION: I applaud the effort the authors have put in to address many of my and the other reviewers\' comments. I think they have done so adequately for the most part, so I\'ve decided to raise the rating from 3 to 5, for what it\'s worth.\n\nThe reason I have decided not to raise it beyond that, is that I still feel that for a paper like this, which studies an existing technique in detail, the experimental side needs to be significantly stronger. While ImageNet experiments may be a lot of work, some other (smaller) additional datasets would also have provided more interesting evidence. CIFAR-10 and CIFAR-100 are so similar that they may as well be considered variants of the same dataset, at least in the setting where they are used here.\n\nI do really appreciate the variety in the experiments in terms of network architectures, regularisation techniques, etc. but I think for real-world relevance, variety in problem settings (i.e. datasets) is simply much more important. I think it would be fine if additional experiments on other datasets were not varied along all these other axes, to cut down on the amount of work this would involve. But not including them at all unfortunately makes the results much less impactful.', 'This paper presents an empirical study of whether data augmentation can be a substitute for explicit regularization of weight decay and dropout.  It is a well written and well organized paper.  However, overall I do not find the authors’ premises and conclusions to be well supported by the results and would suggest further investigations.  In particular:\n\na) Data augmentation is a very domain specific process and limits of augmentation are often not clear.  For example, in financial data or medical imaging data it is often not clear how data augmentation should be carried out and how much is too much.  On the other hand model regularization is domain agnostic (has to be tuned for each task, but the methodology is consistent and well known).  Thus advocating that data augmentation can universally replace explicit regularization does not seem correct.\n\nb) I find the results to be somewhat inconsistent.  For example, on CIFAR-10, for 100% data regularization+augmentation is better than augmentation alone for both models, whereas for 80% data augmentation alone seems to be better.  Similarly on CIFAR-100 the WRN model shows mixed trends, and this model is significantly better than the All-CNN model in performance.  These results also seem inconsistent with authors statement “…and conclude that data augmentation alone - without any other explicit regularization techniques - can achieve the same performance to higher as regularized models…”\n', ""This paper provides a systematic study of data augmentation in image classification problems with deep neural networks and argues that data augmentation could replace some common explicit regularizers like the weight decay and dropout. The data augmentation techniques are also shown to be insensitive to hyper parameters, so easier to use than explicit regularizers when changing architectures.\n\nIt is good to have a systematic study of data augmentations, however, the materials in this paper in the current state might not be a strong ICLR publication. The paper could potentially be made more interesting or solid if some of the followings could be investigated:\n\n- considering a wider range of different problems apart from image classification, and investigate the effectiveness of domain specific data augmentation and general data augmentation\n- systematically study each of the data augmentation techniques separately to see which is more important (as oppose to only having 'light' and 'heavy' scheme); potentially also study other less-traditional augmentation schemes such as adversarial examples, etc.\n- propose novel data augmentation schemes\n- more analysis of the interplay with Batch Normalization, why the results for BN vs no-BN is not presented for WRN?\n- carefully designed synthetic (or real) data / task to verify the statements. For example, the explicit regularizers are thought to unnecessarily constraint the model too much. Can you measure the norm (or other complexity measures) of the models learned with explicit regularizers vs models learned with data augmentation?\n\n""]","[-20, -50, -20]","[60, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting idea and some positive aspects, they express several significant concerns and criticisms. The reviewer states that the paper 'falls short' of its goals, has a 'meager' experimental section, and needs essential extensions to 'ensure that the conclusions drawn hold weight.' However, it's not extremely negative as the reviewer also notes some positive aspects and provides constructive feedback. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms constructively. They use phrases like 'I think,' 'I feel,' and 'Please clarify' which maintain a polite tone. The reviewer also ends on a positive note in the revision section, appreciating the authors' efforts to address previous comments."", ""The sentiment score is -50 because while the reviewer acknowledges that the paper is 'well written and well organized', they express significant concerns about the premises and conclusions, stating they are not 'well supported by the results'. The reviewer suggests 'further investigations' and provides specific critiques, indicating an overall negative sentiment towards the paper's content and conclusions. However, it's not entirely negative as they do recognize some positive aspects.\n\nThe politeness score is 50 because the reviewer uses respectful and professional language throughout. They begin with a positive comment about the writing and organization, which is a polite way to start a critique. The criticisms are presented as suggestions ('would suggest further investigations') rather than harsh demands. The reviewer also uses phrases like 'I find' and 'does not seem correct' instead of more confrontational language. While not overly effusive, the tone maintains a level of courtesy expected in academic discourse."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's systematic study of data augmentation, they state that 'the materials in this paper in the current state might not be a strong ICLR publication.' This indicates that the reviewer sees significant room for improvement. The reviewer then provides a list of suggestions for enhancing the paper, which further supports the slightly negative sentiment.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and constructive language throughout. They begin by acknowledging the positive aspects of the paper ('It is good to have a systematic study of data augmentations'). The suggestions for improvement are phrased as possibilities ('The paper could potentially be made more interesting or solid if...') rather than demands. The reviewer also uses polite phrases like 'considering,' 'investigate,' and 'carefully designed' when making recommendations, which maintains a courteous tone.""]"
"[""\nSummary:\n- The paper proposes a new activation function that looks similar to ELU but much cheaper by using the inverse square root function.\n\nContributions:\n- The paper proposes a cheaper activation and validates it with an MNIST experiment. The paper also shows major speedup compared to ELU and TANH (unit-wise speedup).\n\nPros:\n- The proposed function has similar behavior as ELU but 4x cheaper.\n- The authors also refer us to faster ways to compute square root functions numerically, which can be of general interests to the community for efficient network designs in the future.\n- The paper is clearly written and key contributions are well present.\n\nCons:\n- Clearly, the proposed function is not faster than ReLU. In the introduction, the authors explain the motivation that ReLU needs centered activation (such as BN). But the authors also need to justify that ISRLU (or ELU) doesn’t need BN. In fact, in a recent study of ELU-ResNet (Shah et al., 2016) finds that ELU without BN leads to gradient explosion. To my knowledge, BN (at least in training time) is much more expensive than the activation function itself, so the speedup get from ISRLU may be killed by using BN in deeper networks on larger benchmarks. At inference time, all of ReLU, ELU, and ISRLU can fuse BN weights into convolution weights, so again ISRLU will not be faster than ReLU. The core question here is, whether the smoothness and centered zero property of ELU can buy us any win, compared to ReLU? I couldn’t find it based on the results presented here.\n- The authors need to validate on larger datasets (e.g. CIFAR, if not ImageNet) so that their proposed methods can be widely adopted.\n- The speedup is only measured on CPU. For practical usage, especially in computer vision, GPU speedup is needed to show an impact.\n\nConclusion:\n- Based on the comments above, I recommend weak reject.\n\nReferences:\n- Shah, A., Shinde, S., Kadam, E., Shah, H., Shingade, S.. Deep Residual Networks with Exponential Linear Unit. In Proceedings of the Third International Symposium on Computer Vision and the Internet (VisionNet'16)."", 'This paper introduces a new nonlinear activation function for  neural networks, i.e., Inverse Square Root Linear Units (ISRLU). Experiments show that ISRLU is promising compared to competitors like ReLU and ELU.\n\nPros:\n(1) The paper is clearly written.\n\n(2) The proposed ISRLU function has similar curves with ELU and has a learnable parameter \\alpha (although only fixed value is used in the experiments) to control the negative saturation zone. \n\nCons:\n(1) Authors claim that ISRLU is faster than ELU, while still achieves ELU’s performance. However, they only show the reduction of computation complexity for convolution, and speed comparison between ReLU, ISRLU and ELU on high-end CPU. As far as I know, even though modern CNNs have reduced convolution’s computation complexity, the computation cost of activation function is still only a very small part (less than 1%) in the overall running time of training/inference. \n\n(2) Authors only experimented with two very simple CNN architectures and with three different nonlinear activation functions, i.e., ISRLU/ELU/ReLU and showed their accuracies on MNIST. They did not provide the comparison of running time which I believe is important here as the efficiency is emphasized a lot throughout the paper.\n\n(3) For ISRLU of CNN, experiments on larger scale dataset such as CIFAR or ImageNet would be more convincing. Moreover, authors also propose ISRU which is similar to tanh for RNN, but do not provide any experimental results.\n\nOverall, I think the current version of the paper is not ready for ICLR conference. As I suggested above, authors need more experiments to show the effectiveness of their approach.\n', 'Summary:\nThe contribution of this paper is an alternative activation function which is faster to compute than the Exponential Linear Unit, yet has similar characteristics.\nThe paper first presents the mathematical form of the proposed activation function (ISRLU), and then shows the similarities to ELU graphically. It then argues that speeding up the activation function may be important since the convolution operations in CNNs are becoming heavily optimized and may form a lesser fraction of the overall computation. The ISRLU is then reported to be 2.6x faster compared to ELU using AVX2 instructions. The possibility of computing a faster approximation of ISRLU is also mentioned.\nPreliminary experimental results are reported which demonstrate that ISRLU can perform similar to ELU.\n\nQuality and significance:\nThe paper proposes an interesting direction for optimizing the computational cost of training and inference using neural networks. However, on one hand the contribution is rather narrow, and on the other the results presented do not clearly show that the contribution is of significance in practice.\nThe paper does not present clear benchmarks showing a) what is the fraction of CPU cycles spent in evaluating the activation function in any reasonably practical neural network, b) and what is the percentage of cycles saved by employing the ISRLU.\nThe presented results using small networks on the MNIST dataset only show that networks with ISRLU can perform similar to those with other activation functions, but not the speed advantages of ISRLU.\nThe effect of using the faster approximation on performance also remains to be investigated.\n\nClarity:\nThe content of the paper is unclear in certain areas.\n- It is not clear what Table 2 is showing. What is ""performance"" measured in? In general the Table captions need to be clearer and more descriptive. The acronym pkeep in later Tables should be clarified.\n- Why is the final Cross-Entropy Loss so high even though the accuracy is >99% for the MNIST experiments? It looks like the loss at initialization was reported instead?']","[-60, -50, -20]","[50, 50, 50]","[""The sentiment score is -60 because the review concludes with a 'weak reject' recommendation and lists several significant cons, outweighing the pros. The reviewer expresses skepticism about the method's advantages over existing techniques and points out the need for more comprehensive validation. However, it's not entirely negative as the reviewer acknowledges some positive aspects of the paper. The politeness score is 50 because the reviewer uses professional and respectful language throughout, acknowledging the paper's strengths before presenting criticisms. The reviewer offers constructive feedback and suggestions for improvement rather than harsh criticism. The tone is objective and focused on the scientific merits of the work, maintaining a polite and professional demeanor even while recommending rejection."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('Pros'), the overall tone is critical. The reviewer lists more 'Cons' than 'Pros' and concludes that the paper is 'not ready for ICLR conference', suggesting significant improvements are needed. This indicates a negative sentiment, but not extremely so, hence the moderate negative score. The politeness score is 50 because the reviewer uses professional and respectful language throughout. They provide constructive criticism and suggestions for improvement without using harsh or rude language. The reviewer maintains a balanced tone, acknowledging both strengths and weaknesses of the paper, which contributes to the polite impression."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's 'interesting direction,' they express several concerns about the significance and clarity of the work. They point out that the contribution is 'rather narrow' and that the results don't clearly demonstrate practical significance. The reviewer also notes unclear areas in the paper's content. However, the tone isn't entirely negative, as they recognize the potential of the approach.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'interesting direction' and 'proposes an interesting direction,' which show appreciation for the authors' work. The criticisms are presented as constructive feedback rather than harsh judgments. The reviewer asks questions and suggests improvements rather than making blunt statements, which contributes to the polite tone.""]"
"['The paper addresses an important problem in multitask learning. But its current form has several serious issues. \n\nAlthough I get the high-level goal of the paper, I find Sec. 3.1, which describes the technical approach, nearly incomprehensible. There are many things unclear. For example:\n\n-  it starts with talking about multiple tasks, and then immediately talks about a ""filter F"", without defining what the kind of network is being addressed. \n\n- Also it is not clear what L_grad is. It looks like a loss, but Equation 2 seems to define it to be the difference between the gradient norm of a task and the average over all tasks. It is not clear how it is used. In particular, it is not clear how it is used to ""update the task weights""\n\n- Equation 2 seems sloppy. “j” appears as a free index on the right side, but it doesn’t appear on the left side. \n\nAs a result, I am unable to understand how the method works exactly, and unable to judge its quality and originality.\n\nThe toy experiment is not convincing. \n\n- the evaluation metric is the sum of the relative losses, that is, the sum of the original losses weighted by the inverse of the initial loss of each task. This is different from the sum of the original losses, which seems to be the one used to train the “equal weight” baseline. A more fair baseline is to directly use the evaluation metric as the training loss. \n- the curves seem to have not converged.\n\nThe experiments on NYUv2 involves non-standard settings, without a good justification. So it is not clear if the proposed method can make a real difference on state of the art systems. \n\nAnd the reason that the proposed method outperforms the equal weight baseline seems to be that the method prevents overfitting on some tasks (e.g. depth). However, the method works by normalizing the norms of the gradients, which does not necessarily prevent overfitting — it can in fact magnify gradients of certain tasks and cause over-training and over-fitting. So the performance gain is likely dataset dependent, and what happens on NYU depth can be a fluke and does not necessarily generalize to other datasets. ', ""Paper summary:\nExisting works on multi-task neural networks typically use hand-tuned weights for weighing losses across different tasks. This work proposes a dynamic weight update scheme that updates weights for different task losses during training time by making use of the loss ratios of different tasks. Experiments on two different network indicate that the proposed scheme is better than using hand-tuned weights for multi-task neural networks.\n\n\nPaper Strengths:\n- The proposed technique seems simple yet effective for multi-task learning.\n- Experiments on two different network architectures showcasing the generality of the proposed method.\n\n\nMajor Weaknesses:\n- The main weakness of this work is the unclear exposition of the proposed technique. Entire technique is explained in a short section-3.1 with many important details missing. There is no clear basis for the main equations 1 and 2. How does equation-2 follow from equation-1? Where is the expectation coming from? What exactly does ‘F’ refer to? There is dependency of ‘F’ on only one of sides in equations 1 and 2? More importantly, how does the gradient normalization relate to loss weight update? It is very difficult to decipher these details from the short descriptions given in the paper.\n- Also, several details are missing in toy experiments. What is the task here? What are input and output distributions and what is the relation between input and output? Are they just random noises? If so, is the network learning to overfit to the data as there is no relationship between input and output? \n\n\nMinor Weaknesses:\n- There are no training time comparisons between the proposed technique and the standard fixed loss learning.\n- Authors claim that they operate directly on the gradients inside the network. But, as far as I understood, the authors only update loss weights in this paper. Did authors also experiment with gradient normalization in the intermediate CNN layers?\n- No comparison with state-of-the-art techniques on the experimented tasks and datasets.\n\n\nClarifications:\n- See the above mentioned issues with the exposition of the technique.\n- In the experiments, why are the input images downsampled to 320x320?\n- What does it mean by ‘unofficial dataset’ (page-4). Any references here?\n- Why is 'task normalized' test-time loss as good measure for comparison between models in the toy example (Section 4)? The loss ratios depend on initial loss, which is not important for the final performance of the system.\n\n\nSuggestions:\n- I strongly suggest the authors to clearly explain the proposed technique to get this into a publishable state. \n- The term ’GradNorm’ seem to be not defined anywhere in the paper.\n\n\nReview Summary:\nDespite promising results, the proposed technique is quite unclear from the paper. With its poor exposition of the technique, it is difficult to recommend this paper for publication."", 'The paper proposes a method to train deep multi-task networks using gradient normalization. The key idea is to enforce the gradients from multi tasks balanced so that no tasks are ignored in the training. The authors also demonstrated that the technique can improve test errors over single task learning and uncertainty weighting on a large real-world dataset.\n\nIt is an interesting paper with a novel approach to multi-task learning. To improve the paper, it would be helpful to evaluate the method under various settings. My detailed comments are below.\n\n1. Multi-task learning can have various settings. For example, we may have multiple groups of tasks, where tasks are correlated within groups but tasks in different groups are not much correlated. Also, tasks may have hierarchical correlation structures. These patterns often appear in biological datasets. I am wondering how a variety of multi-task settings can be handled by the proposed approach. It would be helpful to discuss the conditions where we can benefit from the proposed method.\n\n2. One intuitive approach to task balancing would be to weight each task objective based on the variance of each task.  It would be helpful to add a few simple and intuitive baselines in the experiments. \n\n3. In Section 4, it would be great to have more in-depth simulations (e.g., multi-task learning in various settings). Also, in the bottom right panel in Figure 2, GrandNorm and equal weighting decrease test errors effectively even after 15000 steps but uncertainty weighting seems to reach a plateau. Discussions on this would be useful.\n\n4. It would be useful to discuss the implementation of the method as well. \n\n\n\n\n\n\n\n\n\n']","[-70, -60, 60]","[20, 20, 80]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper has 'several serious issues' and finds a key section 'nearly incomprehensible'. They also express skepticism about the experiments and results. However, it's not entirely negative as they acknowledge the paper addresses an important problem. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone. They use phrases like 'I find' and 'It is not clear' rather than making blunt accusations. They also provide specific examples to support their criticisms, which is a constructive approach. However, some phrases like 'seems sloppy' slightly reduce the politeness score."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several major weaknesses, including unclear exposition of the proposed technique and missing details in experiments. The review summary explicitly states that it's 'difficult to recommend this paper for publication.' However, it's not entirely negative as the reviewer acknowledges some strengths and the 'promising results.'\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They use phrases like 'I strongly suggest' and offer specific recommendations for improvement. The language is not overly harsh or rude, but rather focuses on the paper's content in a respectful manner. However, it's not extremely polite either, as the criticism is direct and unvarnished."", ""The sentiment score is 60 (positive) because the reviewer starts by describing the paper as 'interesting' with a 'novel approach', indicating a generally positive view. However, they also provide several suggestions for improvement, which tempers the positivity somewhat. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, such as 'it would be helpful' and 'I am wondering', rather than making demands. They also acknowledge the paper's strengths before offering constructive criticism. The reviewer maintains a professional and courteous tone while providing detailed feedback.""]"
"['Summary:\nThis paper proposes an approach to generate images which are more aesthetically pleasing, considering the feedback of users via user interaction. However, instead of user interaction, it models it by a simulated measure of the quality of user interaction and then feeds it to a Gan architecture. \n\nPros:\n+ The paper is well-written and has just a few typos: 2.1: “an Gan”.\n+ The idea is very interesting. \n\nCons:\n\n- Page 2- section 2- The reasoning that a deep-RL could not be more successful is not supported by any references and it is not convincing.\n\n- Page 3- para 3 - mathematically the statement does not sound since the 2 expressions are exactly equivalent. The slight improvement may be achieved only by chance and be due to computational inefficiency, or changing a seed.  \n\n- Page 3- 2.2. Using a crowd-sourcing technique, developing a similarly small dataset (1000 images with 100 annotations) would normally cost less than 1k$.\n\n- Page 3- 2.2.It is highly motivating to use users feedback in the loop but it is poorly explained how actually the user\'s\' feedback is involved if it is involved at all. \n\n- Page 4- sec 3 "".. it should be seen as a success""; the claim is not supported well.\n\n- Page 4- sec 3.2- last paragraph.\nThis claim lacks scientific support, otherwise please cite proper references. The claim seems like a subjective understanding of conscious perception and unconscious perception of affective stimuli is totally disregarded.\nThe experimental setup is not convincing.\n\n- Page 4. 3.3) ""Note that.. outdoor images"" this is implicitly adding the designers\' bias to the results. The statement lacks scientific support.\n\n- Page 4. 3.3) the importance of texture and shape is disregarded. “In the Eye of the Beholder: Employing Statistical Analysis and Eye Tracking for Analyzing Abstract Paintings, Yanulevskaya et al”\nThe architecture may lead in overfitting to users\' feedback (being over-fit on the data with PIR measures)\n\n- Page 6-Sec 4.2) "" It had more difficulty optimizing for the three-color result"" why? please discuss it.\n\n- The expectation which is set in the abstract and the introduction of the paper is higher than the experiments shown in the Experimental setup.\n', 'This paper proposes a technique to improve the output of GANs by maximising a separate score that aims to mimic human interactions. \n\nSummary:\nThe goal of the technique to involve human interaction in generative processes is interesting. The proposed addition of a new loss function for this purpose is an obvious choice, not particularly involved. It is unclear to me whether the paper has value in its current form, that is without experimental results for the task it achieves. It feels to premature for publication. \n\n\nMore comments:\nThe main problem with this paper is that the proposed systems is designed for a human interaction setting but no such experiment is done or presented. The title is misleading, this may be the direction where the authors of the submission want to go, but the title  “.. with human interactions” is clearly misleading. “Model of human interactions” may be more appropriate. \n\nThe technical idea of this paper is to introduce a separate score in the GAN training process. This modifies the generator objective.  Besides “fooling” the discriminator, the generator objective is to maximise user interaction with the generated batch of images. This is an interesting objective but since no interactive experiments presented in this paper, the rest of the experiments hinges on the definition of “PIR” (positive interaction rate)using a model of human interaction. Instead of real interactions, the submission proposes to maximise the activations of hidden units in a separate neural network. By choosing the hierarchy level and type of filter the results of the GAN differ. \n\nI could not appreciate the results in Figure 2 since I was missing the definition of PIR, how it is drawn in the training setup. Further I found it not surprising that the PIR changes when a highly parameterised model is trained for this task. The PIR value comes from a separate network not directly accessible during training time, nonetheless I would have been surprised to not see an increase. Please comment in the rebuttal and I would appreciate if the details of the synthetic PIR values on the training set could be explained.\n\n- Technically it was a bit unclear to me how the objective is defined. There is a PIR per level and filter (as defined in C4) but in the setup the L_{PIR} was mentioned to be a scalar function, how are the values then summarized? There is a PIR per level and feature defined in C4. \n- What does the PIR with the model in Section 3 stand for? Shouldn’t be something like “uniqueness”, that is how unique is an image in a batch of images be a better indicator? Besides, the intent of what possibly interesting PIR examples will be was unclear. \nE.g., the statement at the end of 2.1 is unclear at that point in the document. How is the PIR drawn exactly? What does it represent? Is there a PIR per image? It becomes clear later, but I suggest to revisit this description in a new version.\n- Also I suggest to move more details from Section C4 into the main text in Section 3. The high level description in Section 3. \n', ""+ Quality:\nThe paper discusses an interesting direction of incorporating humans in the training of a generative adversarial networks in the hope of improving generated samples. I personally find this exciting/refreshing and will be useful in the future of machine learning.\n\nHowever, the paper shows only preliminary results in which the generator trained to maximize the PIR score (computed based on VGG features to simulate human aesthetics evaluation) indeed is able to do so. However, the paper lacks discussion / evidence of how hard it is to optimize for this VGG-based PIR score. In addition, if this was challenging to optimize, it'd be useful to include lessons for how the authors manage to train their model successfully.\nIn my opinion, this result is not too surprising given the existing power of deep learning to fit large datasets and generalize well to test sets. \n\nAlso, it is not clear whether the GAN samples indeed are improved qualitatively (with the incorporation of the PIR objective score maximization objective) vs. when there is no PIR objective. The paper also did not report sample quantitative measures e.g. Inception scores / MS-SSIM.\n\nI'd be interested in how their proposed VGG-based PIR actually correlates with human evaluation.\n\n+ Clarity: \n- Yosinski et al. 2014 citation should be Nguyen et al. 2015 instead (wrong author order / year).\n- In the abstract, the authors should emphasize that the PIR model used in this paper is based on VGG features.\n\n+ Originality: \n- The main direction of incorporating human feedback in the loop is original.\n\n+ Significance: \n- I think the paper contribution is lighter vs. ICLR standard. Results are preliminary.\n\nOverall, I find this direction exciting and hope the authors would keep pushing in this direction! However, the current manuscript is not ready for publication.""]","[-50, -50, -20]","[20, 20, 60]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('well-written', 'interesting idea'), the majority of the review consists of criticisms and concerns. The cons significantly outweigh the pros, indicating a generally negative sentiment. However, it's not extremely negative as the reviewer does point out some strengths.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns, avoiding harsh or personal criticisms. The reviewer acknowledges positive aspects before diving into the negatives, which is a polite approach. However, the score is not higher because the review is primarily focused on criticisms without much softening language or suggestions for improvement, which could be seen as more polite."", ""The sentiment score is -50 because the reviewer expresses significant doubts about the paper's value and readiness for publication. They state it feels 'premature for publication' and that the main problem is the lack of human interaction experiments despite the paper's focus on this aspect. The title is called 'misleading'. However, the score is not lower because the reviewer acknowledges the interesting goal and concept of the paper.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They use phrases like 'I could not appreciate' and 'I suggest' rather than harsh language. They also invite the authors to comment in the rebuttal, showing openness to further explanation. The reviewer provides specific recommendations for improvement, which is helpful and courteous. However, the score is not higher due to the direct criticism and questioning of the paper's value in its current form."", 'The sentiment score is slightly negative (-20) because while the reviewer finds the direction of the research interesting and exciting, they point out several significant shortcomings and state that the paper is not ready for publication. The overall tone suggests more work is needed, but there is potential. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the interesting aspects of the work, and offers constructive criticism. They even end on an encouraging note, expressing hope that the authors will continue their work in this direction. The reviewer maintains a professional and courteous tone while providing honest feedback.']"
"[""Thanks to the authors for their feedback.\n==============================\nThe paper presents a method for classification scheme for problems involving large number of classes in multi-class setting. This is related to the theme of extreme classification but the setting is restricted to that of multi-class classification instead of multi-label classification. The training process involves data transformation using R hash functions, and then learning R classifiers. During prediction the probability of a test instance belonging to a class is given by the sum of the probabilities assigned by the R meta-classifiers to the meta-class in the which the given class label falls. The paper demonstrates better results on ODP and Imagenet-21K datasets compared to LOMTree, RecallTree and OAA.\n\nThere are following concerns regarding the paper which don't seem to be adequately addressed :\n \n - The paper seems to propose a method in which two-step trees are being constructed based on random binning of labels, such that the first level has B nodes. It is not intuitively clear why such a method could be better in terms of prediction accuracy than OAA. The authors mention algorithms for training and prediction, and go on to mention that the method performs better than OAA. Also, please refer to point 2 below.\n\n - The paper repeatedly mentions that OAA has O(Kd) storage and prediction complexity. This is however not entirely true due to sparsity of training data, and the model. These statements seem quite misleading especially in the context of text datasets such as ODP. The authors are requested to check the papers [1] and [2], in which it is shown that OAA can perform surprisingly well. Also, exploiting the sparsity in the data/models, actual model sizes for WikiLSHTC-325K from [3] can be reduced from around 900GB to less than 10GB with weight pruning, and sparsity inducing regularizers. It is not clear if the 160GB model size reported for ODP took the above suggestions into considerations, and which kind of regularization was used. Was the solver used from vowpal wabbit or packages such as Liblinear were used for reporting OAA results.\n\n - Lack of empirical comparison - The paper lacks empirical comparisons especially on large-scale multi-class LSHTC-1/2/3 datasets [4] on which many approaches have been proposed. For a fair comparison, the proposed method must be compared against these datasets. It would be important to clarify if the method can be used on multi-label datasets or not, if so, it needs to be evaluated on the XML datasets [3].\n\n[1] PPDSparse - http://www.kdd.org/kdd2017/papers/view/a-parallel-and-primal-dual-sparse-method-for-extreme-classification\n[2] DiSMEC - https://arxiv.org/abs/1609.02521\n[3] http://manikvarma.org/downloads/XC/XMLRepository.html\n[4] http://lshtc.iit.demokritos.gr/LSHTC2_CFP"", 'The paper presents a hashing based scheme (MACH) for reducing memory and computation time for K-way classification when K is large. The main idea is to use R hash functions to generate R different datasets/classifiers where the K classes are mapped into a small number of buckets (B). During inference the probabilities from the R classifiers are summed up to obtain the best scoring class. The authors provide theoretical guarantees showing that both memory and computation time become functions of log(K) and thus providing significant speed-up for large scale classification problems. Results are provided on the Imagenet and ODP datasets with comparisons to regular one-vs-all classifiers and tree-based methods for speeding up classification.\n\nPositives\n- The idea of using R hash functions to remap K-way classification into R B-way classification problems is fairly novel and the authors provide sound theoretical arguments showing how the K probabilities can be approximated using the R different problems.\n- The theoritical savings in memory and computation time is fairly significant and results suggest the proposed approach provides a good trade-off between accuracy and resource costs.\n\nNegatives\n- Hierarchical softmax is one of more standard techniques that has been very effective at large-scale classification. The paper does not provide comparisons with this baseline which also reduces computation time to log(K).\n- The provided baselines LOMTree, Recall Tree are missing descriptions/citations. Without this it is hard to judge if these are good baselines to compare with.\n- Figure 1 only shows how accuracy varies as the model parameters are varied. A better graph to include would be a time vs accuracy trade-off for all methods. \n- On the Imagenet dataset the best result using the proposed approach is only 85% of the OAA baseline.  Is there any setting where the proposed approach reaches 95% of the baseline accuracy?', 'The manuscript proposes an efficient hashing method, namely MACH, for softmax approximation in the context of large output space, which saves both memory and computation. In particular, the proposed MACH uses 2-universal hashing to randomly group classes, and trains a classifier to predict the group membership. It does this procedure multiple times to reduce the collision and trains a classifier for each run. The final prediction is the average of all classifiers up to some constant bias and multiplier as shown in Eq (2).\n\nThe manuscript is well written and easy to follow. The idea is novel as far as I know. And it saves both training time and prediction time. One unique advantage of the proposed method is that, during inference, the likelihood of a given class can be computed very efficiently without computing the expensive partition function as in traditional softmax and many other softmax variants. Another impressive advantage is that the training and prediction is embarrassingly parallel, and thus can be linearly sped up, which is very practical and rarely seen in other softmax approximation.\n\nThough the results on ODP dataset is very strong, the experiments still leave something to be desired.\n(1) More baselines should be compared. There are lots of softmax variants for dealing with large output space, such as NCE, hierarchical softmax, adaptive softmax (""Efficient softmax approximation for GPUs"" by Grave et. al), LSH hashing (as cited in the manuscript) and matrix factorization (adding one more hidden layer). The results of MACH would be more significant if comparison to these or some of these baselines can be available.\n(2) More datasets should be evaluated. In this manuscript, only ODP and imagenet are evaluated. However, there are also lots of other datasets available, especially in the area of language modeling, such as one billion word dataset (""One billion\nword benchmark for measuring progress in statistical language modeling"" by Chelba et. al) and many others.\n(3) Why the experiments only focus on simple logistic regression? With neural network, it could actually save computation and memory. For example, if one more hidden layer with M hidden units is added, then the memory consumption would be M(d+K) rather than Kd. And M could be a much smaller number, such as 512. I guess the accuracy might possibly be improved, though the memory is still linear in K.\n\nMinor issues:\n(1) In Eq (3), it should be P^j_b rather than P^b_j?\n(2) The proof of theorem 1 seems unfinished']","[-50, 50, 70]","[20, 75, 80]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper (e.g. 'demonstrates better results'), they express several significant concerns and criticisms. The review points out multiple issues that 'don't seem to be adequately addressed' and requests clarifications and additional comparisons, indicating an overall negative sentiment. The politeness score is 20 because the reviewer uses polite language like 'Thanks to the authors for their feedback' and 'The authors are requested to', but maintains a professional and critical tone throughout. The reviewer provides constructive feedback and suggestions for improvement rather than harsh criticism, which contributes to the slightly positive politeness score."", ""The sentiment score is 50 (slightly positive) because the review begins with a neutral summary of the paper's content, followed by a balanced presentation of positives and negatives. The reviewer acknowledges the novelty and theoretical soundness of the approach, but also points out several limitations and areas for improvement. The politeness score is 75 (fairly polite) because the reviewer uses professional and respectful language throughout. They present criticisms constructively, using phrases like 'A better graph to include would be...' and asking questions rather than making harsh statements. The review maintains a formal and objective tone, avoiding personal attacks or overly negative language."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the manuscript, describing it as 'well written and easy to follow' with a 'novel' idea that has unique advantages. They praise the method's efficiency and practical applications. However, it's not 100 as the reviewer also points out areas for improvement in the experiments. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, acknowledging the strengths of the work and framing suggestions for improvement constructively. They use phrases like 'would be more significant if' and 'I guess' which soften their critiques. The tone is professional and courteous, without any harsh or rude language.""]"
"['The paper lists 5 previous very recent papers that combine IRL, adversarial learning, and stochastic policies. The goal of this paper is to do the same thing but with deterministic policies as a way of decreasing the sample complexity. The approach is related to that used in the deterministic policy gradient work. Imitation learning results on the standard control problems appear very encouraging.\n\nDetailed comments:\n\n""s with environment"" -> ""s with the environment""?\n\n""that IL algorithm"" -> ""that IL algorithms"".\n\n""e to the real-world environments"" -> ""e to real-world environments"".\n\n"" two folds"" -> "" two fold"".\n\n""adopting deterministic policy"" -> ""adopting a deterministic policy"".\n\n""those appeared on the expert’s demonstrations"" -> ""those appearing in the expert’s demonstrations"".\n\n""t tens of times less interactions"" -> ""t tens of times fewer interactions"".\n\nOk, I can\'t flag all of the examples of disfluency. The examples above come from just the abstract. The text of the paper seems even less well edited. I\'d highly recommend getting some help proof reading the work.\n\n""Thus, the noisy policy updates could frequently be performed in IL and make the learner’s policy poor. From this observation, we assume that preventing the noisy policy updates with states that are not typical of those appeared on the expert’s demonstrations benefits to the imitation."": The justification for filtering is pretty weak. What is the statistical basis for doing so? Is it a form of a standard variance reduction approach? Is it a novel variance reduction approach? If so, is it more generally applicable?\n\nUnfortunately, the text in Figure 1 is too small. The smallest font size you should use is that of a footnote in the text. As such, it is very difficult to assess the results.\n\nAs best I can tell, the empirical results seem impressive and interesting.\n', ""This paper considers the problem of model-free imitation learning. The problem is formulated in the framework of generative adversarial imitation learning (GAIL), wherein we alternate between optimizing reward parameters and learner policy's parameters. The reward parameters are optimized so that the margin between the cost of the learner's policy and the expert's policy is maximized. The learner's policy is optimized (using any model-free RL method) so that the same cost margin is minimized. Previous formulation of GAIL uses a stochastic behavior policy and the RIENFORCE-like algorithms. The authors of this paper propose to use a deterministic policy instead, and apply the deterministic policy gradient DPG (Silver et al., 2014) for optimizing the behavior policy. \nThe authors also briefly discuss the problem of the little overlap between the teacher's covered state space and the learner's. A state screening function (SSF) method is proposed to drive the learner to remain in areas of the state space that have been covered by the teacher. Although, a more detailed discussion and a clearer explanation is needed to clarify what SSF is actually doing, based on the provided formulation.\nExcept from a few typos here and there, the paper is overall well-written. The proposed idea seems new. However, the reviewer finds the main contribution rather incremental in its nature. Replacing a stochastic policy with a deterministic one does not change much the original GAIL algorithm, since the adoption of stochastic policies is often used just to have differentiable parameterized policies, and if the action space is continuous, then there is not much need for it (except for exploration, which is done here through re-initializations anyway). My guess is that if someone would use the GAIL algorithm for real problems (e.g, robotic task), they would significantly reduce the stochasticity of the behavior policy, which would make it virtually similar in term of data efficiency to the proposed method.\nPros:\n- A new GAIL formulation for saving on interaction data. \nCons:\n- Incremental improvement over GAIL\n- Experiments only on simulated toy problems \n- No theoretical guarantees for the state screening function (SSF) method"", ""This paper proposes to extend the determinist policy gradient algorithm to learn from demonstrations. The method is combined with a type of density estimation of the expert to avoid noisy policy updates. It is tested on Mujoco tasks with expert demonstrations generated with a pre-trained network. \n\nI found the paper a bit hard to read. My interpretation is that the main original contribution of the paper (besides changing a stochastic policy for a deterministic one) is to integrate an automatic estimate of the density of the expert (probability of a state to be visited by the expert policy) so that the policy is not updated by gradient coming from transitions that are unlikely to be generated by the expert policy. \n\nI do think that this part is interesting and I would have liked this trick to be used with other imitation methods. Indeed, the deterministic policy is certainly helpful but it is tested in a deterministic continuous control task. So I'm not sure about how it generalizes to other tasks. Also, the expert demonstration are generated by the pre-trained network so the distribution of the expert is indeed the distribution of the optimal policy. So I'm not sure the experiments tell a lot. But if the density estimation could be combined with other methods and tested on other tasks, I think this could be a good paper.  ""]","[20, -20, -20]","[50, 60, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's encouraging results and interesting empirical findings, despite pointing out several issues. The initial paragraph suggests the paper's goal is valid and results are promising. However, the score is not higher due to the numerous criticisms about writing quality and weak justification for some methods. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'I'd highly recommend' and 'Unfortunately' to soften criticisms. They also balance negative feedback with positive comments about the results. The reviewer doesn't use harsh language, but rather offers constructive criticism, which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well-written', 'new idea'), they also express significant criticisms. The reviewer describes the main contribution as 'rather incremental' and points out several cons, including the lack of experiments on real problems and no theoretical guarantees. The overall tone suggests that the reviewer is not fully convinced of the paper's value.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They begin by summarizing the paper objectively and use phrases like 'the authors propose' and 'the reviewer finds' rather than making blunt criticisms. Even when expressing concerns, the language is measured and constructive, such as suggesting 'a more detailed discussion and a clearer explanation is needed'. The reviewer also balances criticism with positive comments, noting the paper is 'overall well-written' and the idea 'seems new'."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the paper, they express several concerns and limitations. The reviewer finds the paper 'a bit hard to read' and questions the generalizability and significance of the experiments. However, they do see potential in the density estimation technique if applied more broadly.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I found,' 'My interpretation is,' and 'I do think' to soften criticism and present their views as personal opinions rather than absolute statements. The reviewer also offers suggestions for improvement, which is a polite way to address weaknesses in the paper.""]"
"[""The idea of this work is fairly simple. Two main problems exist in end devices for deep learning: power and memory. There have been a series of works showing how to discretisize neural networks. This work, discretisize a NN incrementally. It does so in the following way: First, we train the network with the memory we have. Once we train and achieve a network with best performance under this constraint, we take the sign of each weight (and leave them intact), and use the remaining n-1 bits of each weight in order to add some new connections to the network. Now, we do not change the sign weights, only the new n-1 bits. We continue with this process (recursively) until we don't get any improvement in performance. \n\nBased on experiments done by the authors, on MNIST, having this procedure gives the same performance with 3-4 times less memory or increase in performance of 1% for the same memory as regular network. \n\nI like the idea, and I think it is indeed a good idea for IoT and end devices. The main problem with this method that there is undiscussed payment with current hardware architectures. I think there is a problem with optimizing the memory after each stage was trained. Also, current architectures do not support a single bit manipulations, but is much more efficient on large bits registers. So, in theory this might be a good idea, but I think this idea is not out-of-the-box method for implementation.\n\nAlso, as the authors say, more experiments are needed in order to understand the regime in which this method is efficient. To summarize, I like this idea, but more experiments are needed in order to understand this method merits. "", 'There could be an interesting idea here, but the limitations and applicability of the proposed approach are not clear yet. More analysis should be done to clarify its potential. Besides, the paper seriously needs to be reworked. The text in general, but also the notation, should be improved.\n\nIn my opinion, the authors should explain how to apply their algorithm to more general network architectures, and test it, in particular to convnets. An experiment on a modern dataset beyond MNIST would also be a welcome addition.\n\nSome comments:\n- The method is present as a fully-connected network training procedure. But the resulting network is not really fully-connected, but modular. This is clear in Fig. 1 and in the explanation in Sect. 3.1. The newly added hidden neurons at every iteration do not project to the previous pool of hidden neurons. It should be stressed that the networks end up with this non-conventional “tiled” architecture. Are there studies where the capacity of such networks is investigated, when all the weights are trained concurrently.\n\n- It wasn’t clear to me whether the memory reallocation could be easily implemented in hardware. A few references or remarks on this issue would be welcome.\n\n- The work “Efficient supervised learning in networks with binary synapses” by Baldassi et al. (PNAS 2007) should be cited. Although usually ignored by the deep learning community, it actually was a pioneering study on the use of low resolution weights during inference while allowing for auxiliary variables during learning.\n\n- Coming back my main point above, I didn’t really get the discussion on Sect. 5.3. Why didn’t the authors test their algorithm on a convnet? Are there any obstacles in doing so? It seems quite important to understand this point, as the paper appeals to technical applications and convolution seems hard to sidestep currently.\n\n- Fig. 3: xx-axis: define storage efficiency and storage requirement.\n\n- Fig. 4: What’s an RSBL? Acronyms should be defined.\n\n- Overall, language and notation should really be refined. I had a hard time reading Algorithm 1, as the notation is not even defined anywhere. And this problem extends throughout the paper.\nFor example, just looking at Sect. 4.1, “training and testing data x is normalized…”, if x is not properly defined, it’s best to omit it;  “… 2-dimentonal…”, at least major typos should be scanned and corrected.', 'Summary: The paper addresses the issue of training feed-forward neural networks with memory constraints. The idea is to start by training a very small network, binarise this network, then reuse the non-signed bits of the binarised weights to add/store new weights, and recursively repeat these steps. The cost of reducing the memory storage is the extra computation. An experiment on MNIST shows the efficacy of the proposed recursive scheme.\n\nQuality and significance: The proposed method is a combination of the binarised neural network (BNN) architecture of Courbariaux et al. (2015; 2016) with a network growing scheme to reduce the number of bits per weight. However, the computation complexity is significantly larger. The pitch of the paper is to reduce the ""high overhead of data access"" when training NNs on small devices and indeed this seems to be the case as shown in the experiment. However, if the computation is that large compared to the standard BNNs, I wonder if training is viable on small devices after all. Perhaps all aspects (training cost [computation + time], accuracy and storage) should be plotted together to see what methods form the frontier. This is probably out of scope for ICLR but to really test these methods, they should be trained/stored on a real small device and trained/fine-tuned using user data to see what would work best.\n\nThe experiment is also limited to MNIST and fully connected neural networks.']","[50, -30, -20]","[75, 20, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses liking the idea and acknowledging its potential for IoT and end devices. However, they also point out some concerns and limitations, balancing the positive aspects. The politeness score is 75 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the merits of the work while offering constructive criticism. They use phrases like 'I like the idea' and 'I think it is indeed a good idea,' which contribute to a polite tone. The reviewer also provides suggestions for improvement without being harsh or dismissive, maintaining a professional and courteous approach."", ""The sentiment score is slightly negative (-30) because the reviewer expresses several concerns and criticisms about the paper, stating that it 'seriously needs to be reworked' and that 'limitations and applicability of the proposed approach are not clear yet'. However, they also mention that there 'could be an interesting idea here', which prevents the score from being more negative. The politeness score is slightly positive (20) as the reviewer uses generally polite language, offering constructive criticism and suggestions for improvement rather than harsh criticism. They use phrases like 'In my opinion' and 'would be welcome' which contribute to a polite tone. However, some direct statements about the paper's shortcomings prevent the score from being higher."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution to addressing memory constraints in neural network training, they express significant concerns about the method's computational complexity and limited experimental scope. The reviewer questions the viability of the approach on small devices and suggests that more comprehensive testing is needed. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They offer suggestions for improvement and acknowledge the potential of the method, even while pointing out its limitations. The language used is respectful and avoids harsh criticism, instead framing concerns as areas for potential further investigation.""]"
"['Update after rebuttal\n==========\nThanks for your response on my questions. The stated usefulness of the method unfortunately do not answer my worry about the significance. It remains unclear to me how much ""real"" difference the presented results would make to advance the existing work on generative models. Also, the authors did not promised any major changes in the final version in this direction, which is why I have reduced my score.\n\nI do believe that this work could be useful and should be resubmitted. There are two main things to improve. First, the paper need more work on improving the clarity. Second, more work needs to be added to show that the paper will make a real difference to advance/improve existing methods.\n\n==========\nBefore rebuttal\n==========\nThis paper proposes an optimization problem whose Lagrangian duals contain many existing objective functions for generative models. Using this framework, the paper tries to generalize the optimization problems by defining computationally-tractable family which can be expressed in terms of existing objective functions. \n\nThe paper has interesting elements and the results are original. The main issue is that the significance is unclear. The writing in Section 3 is unclear for me, which further made it challenging to understand the consequences of the theorems presented in that section. \n\nHere is a big-picture question that I would like to know answer for. Do the results of sec 3 help us identify a more useful/computationally tractable model than exiting approaches? Clarification on this will help me evaluate the significance of the paper.\n\nI have three main clarification points. First, what is the importance of T1, T2, and T3 classes defined in Def. 7, i.e., why are these classes useful in solving some problems? Second, is the opposite relationship in Theorem 1, 2, and 3 true as well, e.g., is every linear combination of beta-ELBO and VMI is equivalent to a likelihood-based computable-objective of KL info-encoding family? Is the same true for other theorems?\n\nThird, the objective of section 3 is to show that ""only some choices of lambda lead to a dual with a tractable equivalent form"". Could you rewrite the theorems so that they truly reflect this, rather than stating something which only indirectly imply the main claim of the paper.\n\nSome small comments:\n- Eq. 4. It might help to define MI to remind readers.\n- After Eq. 7, please add a proof (may be in the Appendix). It is not that straightforward to see this. Also, I suppose you are saying Eq. 3 but with f from Eq. 4.\n- Line after Eq. 8, D_i is ""one"" of the following... Is it always the same D_i for all i or it could be different? Make this more clear to avoid confusion.\n- Last line in Para after Eq. 15, ""This neutrality corresponds to the observations made in.."" It might be useful to add a line explaining that particular ""observation""\n- Def. 7, the names did not make much sense to me. You can add a line explaining why this name is chosen.\n- Def. 8, the last equation is unclear. Does the first equivalence impy the next one? \n- Writing in Sec. 3.3 can be improved. e.g., ""all linear operations on log prob."" is very unclear, ""stated computational constraints"" which constraints?\n', 'EDIT: I have read the authors\' rebuttals and other reviews. My opinion has not been changed. I recommend the authors significantly revise their work, streamlining the narrative and making clear what problems and solutions they solve. While I enjoy the perspective of unifying various paths, it\'s unclear what insights come from a simple reorganization. For example, what new objectives come out? Or given this abstraction, what new perspectives or analysis is offered?\n\n---\n\nThe authors propose an objective whose Lagrangian dual admits a variety of modern objectives from variational auto-encoders and generative adversarial networks. They describe tradeoffs between flexibility and computation in this objective leading to different approaches. Unfortunately, I\'m not sure what specific contributions come out, and the paper seems to meander in derivations and remarks that I didn\'t understand what the point was.\n\nFirst, it\'s not clear what this proposed generalization offers. It\'s a very nuanced and not insightful construction (eq. 3) and with a specific choice of a weighted sum of mutual informations subject to a combinatorial number of divergence measure constraints, each possibly held in expectation (eq. 5) to satisfy the chosen subclass of VAEs and GANs; and with or without likelihoods (eq. 7). What specific insights come from this that isn\'t possible without the proposed generalization?\n\nIt\'s also not clear with many GAN algorithms that reasoning with their divergence measure in the limit of infinite capacity discriminators is even meaningful (e.g., Arora et al., 2017; Fedus et al., 2017). It\'s only true for consistent objectives such as MMD-GANs.\n\nSection 4 seems most pointed in explaining potential insights.  However, it only introduces hyperparameters and possible combinatorial choices with no particular guidance in mind. For example, there are no experiments demonstrating the usefulness of this approach except for a toy mixture of Gaussians and binarized MNIST, explaining what is already known with the beta-VAE and infoGAN. It would be useful if the authors could make the paper overall more coherent and targeted to answer specific problems in the literature rather than try to encompass all of them.\n\nMisc\n+ The ""feature marginal"" is also known as the aggregate posterior (Makhzani et al., 2015) and average encoding distribution (Hoffman and Johnson, 2016); also see Tomczak and Welling (2017).', 'Thank you for the feedback, I have read it.\n\nI do think that developing unifying frameworks is important. But not all unifying perspective is interesting; rather, a good unifying perspective should identify the behaviour of existing algorithms and inspire new algorithms.\n\nIn this perspective, the proposed framework might be useful, but as noted in the original review, the presentation is not clear, and it\'s not convincing to me that the MI framework is indeed useful in the sense I described above.\n\nI think probably the issue is the lack of good evaluation methods for generative models. Test-LL has no causal relationship to the quality of the generated data. So does MI. So I don\'t think the argument of preferring MI over MLE is convincing.\n\nSo in summary, I will still keep my original score. I think the paper will be accepted by other venues if the presentation is improved and the advantage of the MI perspective is more explicitly demonstrated.\n\n==== original review ====\n\nThank you for an interesting read.\n\nThe paper presented a unifying framework for many existing generative modelling techniques, by first considering constrained optimisation problem of mutual information, then addressing the problem using Lagrange multipliers.\n\nI see the technical contribution to be the three theorems, in the sense that it gives a closure of all possible objective functions (if using the KL divergences). This can be useful: I\'m tired of reading papers which just add some extra ""regularisation terms"" and claim they work. I did not check every equation of the proof, but it seems correct to me.\n\nHowever, an imperfection is, the paper did not provide a convincing explanation on why their view should be preferred compared to the original papers\' intuition.  For example in VAE case, why this mutual information view is better than the traditional view of approximate MLE, where q is known to be the approximate posterior? A better explanation on this (and similarly for say infoGAN/infoVAE) will significantly improve the paper.\n\nContinuing on the above point, why in section 4 you turn to discuss relationship between mutual information and test-LL?  How does that relate to the main point you want to present in the paper, which is to prefer MI interpretation if I understand it correctly?\n\nTerm usage: we usually *maximize* the ELBO and *minimise* the variational free-energy (VFE). ']","[-30, -60, -20]","[50, 20, 60]","[""The sentiment score is -30 because the reviewer expresses some concerns about the paper's significance and clarity, and mentions reducing their score after the rebuttal. However, they also acknowledge interesting elements and original results, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses respectful language throughout, offers constructive feedback, and expresses belief in the work's potential usefulness. They phrase criticisms as questions or suggestions rather than harsh statements. The reviewer maintains a professional tone, balancing critique with positive comments, which contributes to the polite impression."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's clarity, contributions, and insights. They recommend 'significant revision' and state that their opinion 'has not been changed' after reading rebuttals. The reviewer questions the usefulness of the proposed generalization and the lack of specific insights or solutions to problems in the literature. However, it's not entirely negative as they acknowledge some positive aspects like the 'perspective of unifying various paths'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I recommend' and 'It would be useful if' which are constructive rather than harsh. The reviewer also acknowledges some positive aspects of the work, showing a balanced approach. However, the criticism is direct and doesn't employ overly polite language, hence the relatively low positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting read', 'can be useful'), they express several concerns and criticisms about the paper's clarity, convincingness, and overall contribution. The reviewer maintains their original score, suggesting they are not fully satisfied with the work.\n\nThe politeness score is moderately positive (60) because the reviewer uses polite language throughout, starting with 'Thank you for the feedback' and 'Thank you for an interesting read'. They also use phrases like 'I think' and 'I see' to soften their criticisms, and offer constructive suggestions for improvement. However, the tone is professional rather than overly deferential, hence not a higher score.""]"
"['The method proposes a new architecture for solving image super-resolution task. They provide an analysis that connects aims to establish a connection between how CNNs for solving super resolution and solving sparse regularized inverse problems.\n\nThe writing of the paper needs improvement. I was not able to understand the proposed connection, as notation is inconsistent and it is difficult to figure out what the authors are stating. I am willing to reconsider my evaluation if the authors provide clarifications.\n\nThe paper does not refer to recent advances in the problem, which are (as far as I know), the state of the art in the problem in terms of quality of the solutions. This references should be added and the authors should put their work into context.\n\n1) Arguably, the state of the art in super resolution are techniques that go beyond L2 fitting. Specifically, methods using perceptual losses such as:\n\nJohnson, J. et al ""Perceptual losses for real-time style transfer and super-resolution."" European Conference on Computer Vision. Springer International Publishing, 2016.\n\nLedig, Christian, et al. ""Photo-realistic single image super-resolution using a generative adversarial network."" arXiv preprint arXiv:1609.04802 (2016).\n\nPSNR is known to not be directly related to image quality, as it favors blurred solutions. This should be discussed.\n\n2) The overall notation of the paper should be improved. For instance, in (1), g represents the observation (the LR image), whereas later in the text, g is the HR image. \n\n3) The description of Section 2.1 is quite confusing in my view. In equation (1), y is the signal to be recovered and K is just the downsampling plus blurring. So assuming an L1 regularization in this equation assumes that the signal itself is sparse. Equation (2) changes notation referring y as f. \n\n4) Equation (2) seems wrong. The term multiplying K^T is not the norm (should be parenthesis).\n\n5) The first statement of Section 2.2. seems wrong. DL methods do state the super resolution problem as an inverse problem. Instead of using a pre-defined basis function they learn an over-complete dictionary from the data, assuming that natural images can be sparsely represented. Also, this section does not explain how DL is used for super resolution. The cited work by Yang et al learns a two coupled dictionaries (one for LR and HL), such that for a given patch, the same sparse coefficients can reconstruct both HR and LR patches. The authors just state the sparse coding problem.\n\n6) Equation (10) should not contain the \\leq \\epsilon.\n\n7) In the second paragraph of Section 3, the authors mention that the LR image has to be larger than the HR image to prevent border effects. This makes sense. However, with the size of the network (20 layers), the change in size seems to be quite large. Could you please provide the sizes? When measuring PSNR, is this taken into account? \n\n8) It would be very helpful to include an image explaining the procedure described in the second paragraph of Section 3.\n\n9) I find the description in Section 3 quite confusing. The authors relate the training of a single filter (or neuron) to equation (7), but they define D, that is not used in all of Section 2.1. And K does not show in any of the analysis given in the last paragraph of page 4. However, D and K seem two different things (it is not just one for the other), see bellow.\n\n10) I cannot understand the derivation that the authors do in the last paragraph of page 4 (and beginning of page 5). What is phi_l here? K in equation (7) seems to match to D here, but D here is a collection of patches and in (7) is a blurring and downsampling operator. I cannot review this section. I will wait for the author\'s response clarifications.\n\n11) The authors describe a change in roles between the representations and atoms in the training and testing phase respectively. I do not understand this. If I understand correctly, the final algorithm, the authors train a CNN mapping LR to HR images. The network is used in the same way at training and testing.\n\n12) It would be useful to provide more details about the training of the network. Please describe the training set used by Kim et al. Are the two networks trained independently? One could think of fine-tuning them jointly (including the aggregation).\n\n13) The authors show the advantage of separating networks on a single image, Barbara. It would be good to quantify this better (maybe in terms of PSNR?). This observation might be true only because the training loss, say than the works cited above. Please comment on this.\n\n14) In figures 3 and 4, the learned filters are those on the top (above the yellow arrow). It is not obvious to me that the reflect the predominant structure in the data. (maybe due to the low resolution).\n\n15) This work is related to (though clearly different)  that of LISTA (Learned ISTA) type of networks, proposed in:\n\nGregor, K., & LeCun, Y. (2010). Learning fast approximations of sparse coding. In Proceedings of the 27th International Conference on Machine Learning (ICML) \n\nWhich connect the network architecture with the optimization algorithm used for solving the sparse coding problem. Follow up works have used these ideas for solving inverse problems as well.\n', 'This paper discusses using neural networks for super-resolution. The positive aspects of this work is that the use of two neural networks in tandem for this task may be interesting, and the authors attempt to discuss the network\'s behavior by drawing relations to successful sparsity-based super-resolution. Unfortunately I cannot see any novelty in the relationship the authors draw to LASSO style super-resolution and dictionary learning beyond what is already in the literature (see references below), including in one reference that the authors cite. In addition, there are a number of sloppy mistakes (e.g. Equation 10 as a clear copy-paste error) in the manuscript. Given that much of the main result seems to already be known, I feel that this work is not novel enough at this time. \n\nSome other minor points for the authors to consider for future iterations of this work:\n\n- The authors mention the computational burden of solving L1-regularized optimizations. A lat of work has been done to create fast, efficient solvers in many settings (e.g. homotopy, message passing etc.). Are these methods still insufficient in some applications? If so, which applications of interest are the authors considering?\n\n- In figure 1, it seems that under ""superresolution problem"": \'f\' should be \'High res data\' and \'g\' should be \'Low res data\' instead of what is there. I\'m also not sure how this figure adds to the information already in the text.\n\n- In the results, the authors mention how some network features represented by certain neurons resemble the training data. This seems like over-training and not a good quality for generalization. The authors should clarify if, and why, this might be a good thing for their application. \n\n- Overall a heavy editing pass is needed to fix a number of typos throughout.\n\nReferences:\n\n[1] K. Gregor and Y. LeCun , “Learning fast approximations of sparse coding,” in Proc. Int. Conf. Mach. Learn., 2010, pp. 399–406.\n[2] P. Sprechmann, P. Bronstein, and G. Sapiro, “Learning efficient structured sparse models,” in Proc. Int. Conf. Mach. Learn., 2012, pp. 615–622.\n[3] M. Borgerding, P. Schniter, and S. Rangan, ``AMP-Inspired Deep Networks for Sparse Linear Inverse Problems [pdf] [arxiv],"" IEEE Transactions on Signal Processing, vol. 65, no. 16, pp. 4293-4308, Aug. 2017.\n[4] V. Papyan*, Y. Romano* and M. Elad, Convolutional Neural Networks Analyzed via Convolutional Sparse Coding, accepted to Journal of Machine Learning Research, 2016. ', ""The paper proposes an understanding of the relation between inverse problems, CNNs and sparse representations. Using the ground work for each proposes a new competitive super resolution technique using CNNs. Overall I liked authors' endeavors bringing together different fields of research addressing similar issues. However, I have significant concerns regarding how the paper is written and final section of the proposed algorithm/experiments etc.  \n\nIntroduction/literature review-> I think paper significantly lacks literature review and locating itself where the proposed approach at the end stands in the given recent SR literature (particularly deep learning based methods) --similarities to other techniques, differences from other techniques etc. There have been several different ways of using CNNs for super resolution, how does this paper’s architecture differs from those? Recent GAN based methods are very promising and how does the proposed technique compares to them? \n\nNotation/readability -> I do respect the author’s mentioning different research field’s notations and understand the complication of building a single framework. However I still think that notations could be a lot more simplified—to make them look in the same page. It is very confusing for readers even if you know the mentioned sub-fields and their notations. Figure 1 was very useful to alleviate this problem. More visuals like figure 1 could be used for this problem. For example different network architecture figures (training/testing for CNNs) could be used to explain in a compact way instead of plain text. \n\nSection 3-> I liked the way authors try to use the more generalized Daubechies et. al. However I do not understand lots of pieces still. For example using the low resolution image patches as a basis—more below. In the original solution Daubechies et. al. maps data to the orthonormal Hilbert space, but authors map to the D (formed by LR patches). How does this affect the provability? \n\nRepresentation-dictionary duality concept -> I think this is a very fundamental piece for the paper and don’t understand why it is in the appendix. Using images as D in training and using filters as D in scoring/testing, is very unintuitive to me. Even after reading second time. This requires better discussion and examples. Comparison/discussion to other CNN/deep learning usage for super-resolution methods is required exactly right here.\n\nFinal proposed algorithm -> Splitting the data for high and low coherence makes sense however coherence is a continues variable. Why to keep the quantization at binary? Why not 4,8 or more? Could this be modeled in the network?\n\nResults -> I understand the numerical results and comparisons to the Kim et. Al—and don’t mind at all if they are on-par or slightly better or worse. However in super-resolution paper I do expect a lot more visual comparisons. There has been only Figure 5. Authors could use appendix for this purpose. Also I would love to understand why the proposed solution is significantly faster. This is particularly critical in super-resolution as to apply the algorithms to videos and reconstruction time is vital.\n""]","[-50, -50, -20]","[20, 20, 60]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's clarity, methodology, and lack of reference to recent advances. They state they 'was not able to understand the proposed connection' and list numerous issues, indicating a generally negative view. However, they do mention willingness to reconsider, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I am willing to reconsider' and 'Please describe' which show respect. The reviewer also provides detailed, constructive feedback, which is a polite way to critique. However, some direct statements like 'The writing of the paper needs improvement' and 'Equation (2) seems wrong' prevent the score from being higher."", ""The sentiment score is -50 because the review starts with some positive aspects but quickly shifts to a predominantly negative tone. The reviewer states that they 'cannot see any novelty' in the work, mentions 'sloppy mistakes', and concludes that the work is 'not novel enough'. However, it's not entirely negative as they do acknowledge some positive aspects initially. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'Unfortunately I cannot see' and 'Some other minor points for the authors to consider' which soften the criticism. They also provide constructive feedback and references for improvement, which is helpful and polite. However, the use of words like 'sloppy' slightly reduces the overall politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer mentions liking some aspects of the paper ('Overall I liked authors' endeavors'), they express 'significant concerns' about how the paper is written and the final section. They point out several areas needing improvement, such as lacking literature review and confusing notation. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the authors' efforts ('I do respect the author's mentioning...') and providing constructive criticism. They use phrases like 'I think' and 'I would love to understand' which soften their critiques. The reviewer also balances negative points with positive ones, showing a fair and considerate approach.""]"
"['- This paper discusses an agent architecture which uses a shared representation to train multiple tasks with different sprite level visual statistics. The key idea is that the agent learns a shared representations for tasks with different visual statistics\n\n- A lot of important references  touching on very similar ideas are missing. For e.g. ""Unsupervised Pixel-level Domain Adaptation with Generative Adversarial Networks"", ""Using Simulation and Domain Adaptation to Improve Efficiency of Deep Robotic Grasping"", ""Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics"". \n\n- This paper has a lot of orthogonal details. For instance sec 2.1 reviews the history of games and AI, which is besides the key point and does not provide any literary context. \n\n- Only single runs for the results are shown in plots. How statistically valid are the results?\n\n- In the last section authors mention the intent to do future work on atari and other env. Given that this general idea has been discussed in the literature several times, it seems imperative to at least scale up the experiments before the paper is ready for publication', ""This paper introduces a method to learn a policy on visually different but otherwise identical games. While the idea would be interesting in general, unfortunately the experiment section is very much toy example so that it is hard to know the applicability of the proposed approach to any more reasonable scenario. Any sort of remotely convincing experiment is left to 'future work'.\n\nThe experimental setup is 4x4 grid world with different basic shape or grey level rendering. I am quite convinced that any somewhat correctly setup vanilla deep RL algorithm would solve these sort of tasks/ ensemble of tasks almost instantly out of the box.\n\nFigure 5: Looks to me like the baseline is actually doing much better than the proposed methods?\n\nFigure 6: Looking at those 2D PCAs, I am not sure any of those method really abstracts the rendering away. Anyway, it would be good to have a quantified metric on this, which is not just eyeballing PCA scatter plots."", 'In this paper, the authors propose a new approach for learning underlying structure of visually distinct games.\n\nThe proposed approach combines convolutional layers for processing input images, Asynchronous Advantage Actor Critic for deep reinforcement learning task and adversarial approach to force the embedding representation to be independent of the visual representation of games. \n\nThe network architecture is suitably described and seems reasonable to learn simultaneously similar games, which are visually distinct. However, the authors do not explain how this architecture can be used to do the domain adaptation. \nIndeed, if some games have been learnt by the proposed algorithm, the authors do not precise what modules have to be retrained to learn a new game. This is a critical issue, because the experiments show that there is no gain in terms of performance to learn a shared embedding manifold (see DA-DRL versus baseline in figure 5).\nIf there is a gain to learn a shared embedding manifold, which is plausible, this gain should be evaluated between a baseline, that learns separately the games, and an algorithm, that learns incrementally the games. \nMoreover, in the experimental setting, the games are not similar but simply the same.\n\nMy opinion is that this paper is not ready for publication. The interesting issues are referred to future works.\n']","[-50, -70, -60]","[0, -20, 20]","[""The sentiment score is -50 because the review is generally critical, pointing out several shortcomings of the paper. The reviewer mentions missing references, unnecessary details, lack of statistical validity, and the need for more extensive experiments. However, it's not entirely negative as it acknowledges the key idea of the paper at the beginning. The politeness score is 0 (neutral) because the language used is direct and matter-of-fact, without being overtly polite or rude. The reviewer states their criticisms plainly without using harsh language or personal attacks, but also without softening their critique with polite phrases or compliments."", ""The sentiment score is -70 because the reviewer expresses significant disappointment with the paper, particularly criticizing the experimental section as being too simplistic and unconvincing. They use phrases like 'unfortunately', 'very much toy example', and 'hard to know the applicability', indicating a strongly negative view. The politeness score is -20 because while the reviewer doesn't use overtly rude language, their tone is quite dismissive and critical. They use phrases like 'I am quite convinced that any somewhat correctly setup vanilla deep RL algorithm would solve these sort of tasks... almost instantly', which comes across as condescending. The reviewer also directly questions the effectiveness of the proposed method without much tact, saying 'Looks to me like the baseline is actually doing much better than the proposed methods?'. While not explicitly impolite, the overall tone lacks the courtesy typically expected in peer reviews."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper, stating it's 'not ready for publication' and that 'interesting issues are referred to future works.' They point out critical issues with the approach and experimental design. However, it's not entirely negative as they acknowledge some positive aspects like the 'suitably described' network architecture. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and avoid personal attacks. They offer constructive feedback and explain their reasoning, which is polite in academic contexts. The use of phrases like 'My opinion is...' also adds a degree of politeness by framing the criticism as a personal view rather than an absolute judgment.""]"
"[""The main strengths of the paper are the supporting experimental results in comparison to plain feed-forward networks (FNNs).  The proposed method is focused on discovering sparse neural networks.  The experiments show that sparsity is achieved and still the discovered sparse networks have comparable or better performance compared to dense networks.\n\nThe main weakness of the paper is lack of cohesion in contributions and difficulty in delineating the scope of their proposed approach.\n\nBelow are some suggestions for improving the paper:\n\nCan you enumerate the paper’s contributions and specify the scope of this work?  Where is this method most applicable and where is it not applicable?\n\nWhy is the paper focused on these specific contributions?  What problem does this particular set of contributions solve that is not solvable by the baselines?  There needs to be a cohesive story that puts the elements together.  For example, you explain how the algorithm for creating the backbone can use unsupervised data.  On the other hand, to distinguish this work from the baselines you mention that this work is the first to apply the method to supervised learning problems.\n\nThe motivation section in the beginning of the paper motivates using the backbone structure to get a sparse network.  However, it does not adequately motivate the skip-path connections or applications of the method to supervised tasks.\n\nIs this work extending the applicability of baselines to new types of problems?  Or is this work focused on improving the performance of existing methods?  Answers to these questions can automatically determine suitable experiments to run as well.  It's not clear if Pruned FNNs are the most suitable baseline for evaluating the results.  Can your work be compared experimentally with any of the constructive methods from the related work section?  If not, why?\n\nWhen contrasting this work with existing approaches, can you explain how existing work builds toward the same solution that you are focusing on?  It would be more informative to explain how the baselines contribute to the solution instead of just citing them and highlighting their differences.\n\nRegarding the experimental results, is there any insight on why the dense networks are falling short?  For example, if it is due to overfitting, is there a correlation between performance and size of FNNs?  Do you observe a similar performance vs FNNs in existing methods?  Whether this good performance is due to your contributions or due to effectiveness of the baseline algorithm, proper analysis and discussion is required and counts as useful research contribution.\n"", 'There is a vast literature on structure learning for constructing neural networks (topologies, layers, learning rates, etc.) in an automatic fashion. Your work falls under a similar category. I am a bit surprised that you have not discussed it in the paper not to mention provided a baseline to compare your method to. Also, without knowing intricate details about each of 17 tasks you mentioned it is really hard to make any judgement as to how significant is improvement coming from your approach. There has been some work done on constructing interpretable neural networks, such as stimulated training in speech recognition, unfortunately these are not discussed in the paper despite interpretability being considered important in this paper. ', ""This paper introduces a skip-connection based design of fully connected networks, which is loosely based on learning latent variable tree structure learning via mutual information criteria. The goal is to learn sparse structures across layers of fully connected networks.  Compared to prior work (hierarchical latent tree model), this work introduces skip-paths. \nAuthors refer to prior work for methods to learn this backbone model. Liu et.al (http://www.cse.ust.hk/~lzhang/ltm/index.htm) and Chen et.al. (https://arxiv.org/abs/1508.00973) and (https://arxiv.org/pdf/1605.06650.pdf). \n\nAs far as I understand, the methods for learning backbone structure and the skip-path are performed independently, i.e. there is no end-to-end training of the structure and parameters of the layers. This will limit the applicability of the approach in most applications where fully connected networks are currently used. \n\nOriginality - The paper heavily builds upon prior work on hierarchical latent tree analysis and adds 'skip path' formulation to the architecture, however the structure learning is not performed end-to-end and in conjunction with the parameters. \n\nClarity - The paper is not self-contained in terms of methodology.\n\nQuality and Significance - There is a disconnect between premise of the paper (improving efficiency of fully connected layers by learning sparser structures) and applicability of the approach (slow EM based method to learn structure first, then learn the parameters).  As is, the applicability of the method is limited. \nAlso in terms of experiments, there is not enough exploration of simpler sparse learning methods such as heavy regularization of the weights. ""]","[20, -50, -60]","[60, 0, 20]","[""The sentiment score is slightly positive (20) because the review starts by highlighting the main strengths of the paper, particularly the supporting experimental results. However, it also points out a significant weakness, which balances out some of the positivity. The overall tone suggests room for improvement rather than outright criticism. The politeness score is moderately high (60) as the reviewer uses constructive language throughout, framing suggestions as questions or polite requests (e.g., 'Can you enumerate...', 'Why is the paper focused on...') rather than direct criticisms. The reviewer also acknowledges the paper's strengths and provides detailed, actionable feedback without using harsh or dismissive language."", ""The sentiment score is -50 because the review is generally critical, pointing out several significant omissions in the paper, such as lack of discussion on relevant literature and baselines. However, it's not entirely negative as it acknowledges the work's category and potential importance. The politeness score is 0 (neutral) because the language is direct and professional without being overtly polite or rude. The reviewer uses phrases like 'I am a bit surprised' and 'it is really hard to make any judgement,' which are neutral in tone. The critique is presented factually without personal attacks or overly harsh language, but also without particularly polite or softening phrases."", ""The sentiment score is -60 because the review is generally critical of the paper. The reviewer points out several limitations, such as the lack of end-to-end training, limited applicability, and insufficient exploration of simpler methods. The reviewer also mentions that the paper is not self-contained and heavily builds upon prior work without significant originality. However, it's not entirely negative as the reviewer acknowledges the paper's attempt to improve on prior work.\n\nThe politeness score is 20 because while the reviewer is critical, the language used is professional and objective. The reviewer uses phrases like 'As far as I understand' and 'There is a disconnect' rather than using harsh or rude language. The criticism is presented in a constructive manner, focusing on the paper's content rather than making personal remarks. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score.""]"
"[""Summary:\n\nThis paper studies learning forward models on latent representations of the environment, and use these for model-based planning (e.g. via MCTS) in partial-information real-time-strategy games. The testbed used is MiniRTS, a simulation environemnt for 1v1 RTS.\n\nForecasting the future suffers from buildup / propagation of prediction errors, hence the paper uses multi-step errors to stabilize learning.\n\nThe paper:\n1. describes how to train strong agents that might have learned an informative latent representation of the observed state-space.\n2. Evaluates how informative the latent states are via state reconstruction.\n3. trains variatns of a forward model f on the hidden states of the various learned agents.\n4. evaluates different f within MCTS for MiniRTS.\n\nPro:\n- This is a neat idea and addresses the important question of how to learn accurate models of the environment from data, and how to integrate them with model-free methods.\n- The experimental setting is very non-trivial and novel.\n\nCon:\n- The manuscript is unclear in many parts -- this should be greatly improved.\n1. The different forward models are not explained well (what is MatchPi, MatchA, PredN?). Which forward model is trained from which model-free agent?\n2. How is the forward model / value function used in MCTS? I assume it's similar to what AlphaGo does, but right now it's not clear at all how everything is put together.\n\n- The paper devotes a lot of space (sect 4.1) on details of learning and behavior of the model-free agents X. Yet it is unclear how this informs us about the quality of the learned forward models f. It would be more informative to focus in the main text on the aspects that inform us about f, and put the training details in an appendix.\n\n- As there are many details on how the model-free agents are trained and the system has many moving parts, it is not clear what is important and what is not wrt to the eventual winrate comparisons of the MCTS models. Right now, it is not clear to me why MatchA / PredN differ so much in Fig 8.\n\n- The conclusion seems quite negative: the model-based methods fare *much* worse than the model-free agent. Is this because of the MCTS approach? Because f is not good? Because the latent h is not informative enough? This requires a much more thorough evaluation. \n\nOverall:\nI think this is an interesting direction of research, but the current manuscript does provide a complete and clear analysis.\n\nDetailed:\n- What are the right prediction tasks that ensure the latent space captures enough of the forward model?\n- What is the error of the raw h-predictions? Only the state-reconstruction error is shown now.\n- Figure 6 / sect 4.2: which model-free agent is used? Also fig 6 misses captions.\n- Figure 8: scrambled caption.\n- Does scheduled sampling / Dagger (Ross et al.) improve the long-term stability in this case?\n"", 'The paper proposes to use a pretrained model-free RL agent to extract the developed state representation and further re-use it for learning forward model of the environment and planning.\nThe idea of re-using a pretrained agent has both pros and cons. On one hand, it can be simpler than learning a model from scratch because that would also require a decent exploration policy to sample representative trajectories from the environment. On the other hand, the usefulness of the learned representation for planning is unclear. A model-free agent can (especially if trained with certain regularization) exclude a lot of information which is potentially useful for planning, but is it necessary for reactively taking actions.\nA reasonable experiment/baseline thus would be to train a model-free agent with a small reconstruction loss on top of the learned representation.\u2028In addition to that, one could fine-tune the representation during forward model training. \nIt would be interesting to see if this can improve the results.\n\nI personally miss a more technical and detailed exposition of the ideas. For example, it is not described anywhere what loss is used for learning the model. MCTS is not described and a reader has to follow references and infer how exactly is it used in this particular application which makes the paper not self-contained. \nAgain, due to lack of equations, I don’t completely understand the last paragraph of 3.2, I suggest re-writing it (as well as some other parts) in a more explicit way.\nI also could find the details on how figure 1 was produced. As I understand, MCTS was not used in this experiment. If so, how would one play with just a forward model?\n\nIt is a bit disappointing that authors seem to consider only deterministic models which clearly have very limited applicability. Is mini-RTS a deterministic environment? \nWould it be possible to include a non-deterministic baseline in the experimental comparison?\n\nExperimentally, the results are rather weak compared to pure model-free agents. Somewhat unsatisfying, longer-term prediction results into weaker game play. Doesn’t this support the argument about need in stochastic prediction? \n\nTo me, the paper in it’s current form is not written well and does not contain strong enough empirical results, so that I can’t recommend acceptance. \n\nMinor comments:\n* MatchA and PredictPi models are not introduced under such names\n* Figure 1 that introduces them contains typos. \n* Formatting of figure 8 needs to be fixed. This figure does not seem to be referred to anywhere in the text and the broken caption makes it hard to understand what is happening there.\n', ""Summary: This paper proposes to use the latent representations learned by a model-free RL agent to learn a transition model for use in model-based RL (specifically MCTS). The paper introduces a strong model-free baseline (win rate ~80% in the MiniRTS environment) and shows that the latent space learned by this baseline does include relevant game information. They use the latent state representation to learn a model for planning, which performs slightly better than a random baseline (win rate ~25%).\n\nPros:\n- Improvement of the model-free method from previous work by incorporating information about previously observed states, demonstrating the importance of memory.\n- Interesting evaluation of which input features are important for the model-free algorithm, such as base HP ratio and the amount of resources available.\n\nCons:\n- The model-based approach is disappointing compared to the model-free approach.\n\nQuality and Clarity:\n\nThe paper in general is well-written and easy to follow and seems technically correct, though I found some of the figures and definitions confusing, specifically:\n\n- The terms for different forward models are not defined (e.g. MatchPi, MatchA, etc.). I can infer what they mean based on Figure 1 but it would be helpful to readers to define them explicitly.\n- In Figure 3b, it is not clear to me what the difference between the red and blue curves is.\n- In Figure 4, it would be helpful to label which color corresponds to the agent and which to the rule-based AI.\n- The caption in Figure 8 is malformatted.\n- In Figure 7, the baseline of \\hat{h_t}=h_{t-2} seems strange---I would find it more useful for Figure 7 to compare to the performance if the model were not used (i.e. if \\hat{h_t}=h_t) to see how much performance suffers as a result of model error.\n\nOriginality:\n\nI am unfamiliar with the MiniRTS environment, but given that it is only published in this year's NIPS (and that I couldn't find any other papers about it on Google Scholar) it seems that this is the first paper to compare model-free and model-based approaches in this domain. However, the model-free approach does not seem particularly novel in that it is just an extension of that from Tian et al. (2017) plus some additional features. The idea of learning a model based on the features from a model-free agent seems novel but lacks significance in that the results are not very compelling (see below).\n\nSignificance:\n\nI feel the paper overstates the results in saying that the learned forward model is usable in MCTS. The implication in the abstract and introduction (at least as I interpreted it) is that the learned model would outperform a model-free method, but upon reading the rest of the paper I was disappointed to learn that in reality it drastically underperforms. The baseline used in the paper is a random baseline, which seems a bit unfair---a good baseline is usually an algorithm that is an obvious first choice, such as the model-free approach.""]","[-20, -60, -20]","[50, 20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting direction and neat idea, they express several significant concerns about clarity, analysis, and results. The reviewer states that the manuscript is unclear in many parts and doesn't provide a complete and clear analysis. They also note that the conclusion seems quite negative, with model-based methods performing much worse than model-free agents. However, the score isn't deeply negative because the reviewer still sees value in the research direction.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They balance criticism with positive remarks, using phrases like 'This is a neat idea' and 'I think this is an interesting direction of research'. The reviewer also provides specific suggestions for improvement and asks clarifying questions, which is helpful and respectful. While direct in their critique, they avoid harsh or rude language, instead using more neutral phrases like 'should be greatly improved' or 'it is not clear'."", ""The sentiment score is -60 because the reviewer expresses several criticisms and disappointments with the paper. They mention weak results, lack of technical details, and unclear usefulness of the proposed method. The reviewer concludes by not recommending acceptance, which is a strong negative sentiment. However, they do acknowledge some potential pros of the approach, preventing the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I personally miss' and 'It would be interesting to see' which soften the criticism. They also offer constructive suggestions for improvement. However, some direct statements like 'the paper in its current form is not written well' prevent the score from being higher on the politeness scale."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they express disappointment with the model-based approach and feel the paper overstates its results. The cons and criticisms outweigh the pros in the review. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'well-written and easy to follow' and 'it would be helpful to readers', which contribute to a polite tone. The reviewer also provides specific suggestions for improvement, which is considerate. However, the score is not extremely high as the review does contain direct criticisms without excessive softening language.""]"
"['This paper proposes a deep learning architecture for joint learning of feature representation, a target-task mapping function, and a sample re-weighting function. Specifically, the method tries to discover feature representations, which are invariance in different domains, by minimizing the re-weighted empirical risk and distributional shift between designs.\nOverall, the paper is well written and organized with good description on the related work, research background, and theoretic proofs. \n\nThe main contribution can be the idea of learning a sample re-weighting function, which is highly important in domain shift. However, as stated in the paper, since the causal effect of an intervention T on Y conditioned on X is one of main interests, it is expected to add the related analysis in the experiment section.', 'The paper proposes a novel way of causal inference in situations where in causal SEM notation the outcome Y = f(T,X) is a function of a treatment T and covariates X. The goal is to infer the treatment effect E(Y|T=1,X=x) - E(Y|T=0,X=x) for binary treatments at every location x. If the treatment effect can be learned, then forecasts of Y under new policies that assign treatment conditional on X will still ""work"" and the distribution of X can also change without affecting the accuracy of the predictions. \n\nWhat is proposed seems to be twofold:\n- instead of using a standard inverse probability weighting, the authors construct a bound for the prediction performance under new distributions of X and new policies and learn the weights by optimizing this bound. The goal is to avoid issues that arise if the ratio between source and target densities become very large or small and the weights in a standard approach would become very sparse, thus leading to a small effective sample size.\n- as an additional ingredient the authors also propose ""representation learning"" by mapping x to some representation Phi(x). \nThe goal is to learn the mapping Phi (and its inverse) and the weighting function simultaneously by optimizing the derived bound on the prediction performance. \n\nPros: \n- The problem is relevant and also appears in similar form in domain adaptation and transfer learning. \n- The derived bounds and procedures are interesting and nontrivial, even if there is some overlap with earlier work of Shalit et al. \n\nCons:\n- I am not sure if ICLR is the optimal venue for this manuscript but will leave this decision to others. \n- The manuscript is written in a very compact style and I wish some passages would have been explained in more depth and detail. Especially the second half of page 5 is at times very hard to understand as it is so dense. \n- The implications of the assumptions in Theorem 1 are not easy to understand, especially relating to the quantities B_\\Phi, C^\\mathcal{F}_{n,\\delta} and D^{\\Phi,\\mathcal{H}}_\\delta. Why would we expect these quantities to be small or bounded? How does that compare to the assumptions needed for standard inverse probability weighting? \n- I appreciate that it is difficult to find good test datasets for evaluating causal estimator.  The experiment on the semi-synthetic IHDP dataset is ok, even though there is very little information about its structure in the manuscript (even basic information like number of instances or dimensions seems missing?). The example does not provide much insight into the main ideas and when we would expect the procedure to work more generally.\n\n\n\n\n\n\n\n\n\n', 'Summary:\nThis paper proposes a new approach to tackle the problem of prediction under\nthe shift in design, which consists of the shift in policy (conditional\ndistribution of treatment given features) and the shift in domain (marginal \ndistribution of features).\n\nGiven labeled samples from a source domain and unlabeled samples from a target\ndomain, this paper proposes to minimize the risk on the target domain by \njointly learning the shift-invariant representation and the re-weighting \nfunction for the induced representations. According to Lemma 1 and its finite\nsample version in Theorem 1, the risk on the target domain can be upper bounded\nby the combination of 1) the re-weighted empirical risk on the source domain; \nand 2) the distributional discrepancy between the re-weighted source domain and\nthe target domain. These theoretical results justify the objective function\nshown in Equation 8. \n\nExperiments on the IHDP dataset demonstrates the advantage of the proposed\napproach compared to its competing alternatives.\n\nComments:\n1) This paper is well motivated. For the task of prediction under the shift in\ndesign, shift-invariant representation learning (Shalit 2017) is biased even in\nthe inifite data limit. On the other hand, although re-weighting methods are\nunbiased, they suffer from the drawbacks of high variance and unknown optimal\nweights. The proposed approach aims to overcome these drawbacks.\n\n2) The theoretical results justify the optimization procedures presented in\nsection 5. Experimental results on the IHDP dataset confirm the advantage of\nthe proposed approach.\n\n3) I have some questions on the details. In order to make sure the second \nequality in Equation 2 holds, p_mu (y|x,t) = p_pi (y|x,t) should hold as well.\nIs this a standard assumption in the literature?\n\n4) Two drawbacks of previous methods motivate this work, including the bias of\nrepresentation learning and the high variance of re-weighting. According to\nLemma 1, the proposed method is unbiased for the optimal weights in the large\ndata limit. However, is there any theoretical guarantee or empirical evidence\nto show the proposed method does not suffer from the drawback of high variance?\n\n5) Experiments on synthetic datasets, where both the shift in policy and the\nshift in domain are simulated and therefore can be controlled, would better \ndemonstrate how the performance of the proposed approach (and thsoe baseline \nmethods) changes as the degree of design shift varies. \n\n6) Besides IHDP, did the authors run experiments on other real-world datasets, \nsuch as Jobs, Twins, etc?']","[70, 20, 70]","[80, 60, 80]","[""The sentiment score is 70 (positive) because the reviewer states that the paper is 'well written and organized' and acknowledges the main contribution as 'highly important'. The overall tone is positive, with only a minor suggestion for improvement. The politeness score is 80 (polite) due to the use of respectful language throughout, such as 'Overall, the paper is well written' and 'it is expected to add', which suggests improvements in a non-confrontational manner. The reviewer maintains a professional and courteous tone while providing constructive feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the relevance and interesting aspects of the paper, mentioning 'pros' such as the problem being relevant and the derived bounds being interesting. However, there are also several 'cons' listed, which temper the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the difficulty of finding good test datasets and using phrases like 'I appreciate' and 'I wish'. The reviewer also frames criticisms constructively, such as suggesting more detailed explanations. The tone remains professional and objective throughout, without any harsh or rude language."", ""The sentiment score is 70 (positive) because the reviewer expresses that the paper is well-motivated, provides theoretical justification for its approach, and demonstrates advantages over competing methods. The reviewer acknowledges the paper's contributions while also raising some questions and suggestions for improvement, indicating a generally positive but not overwhelmingly enthusiastic sentiment. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They frame their comments as questions or suggestions rather than criticisms, and they acknowledge the paper's strengths before discussing potential improvements. The reviewer maintains a professional and courteous tone, avoiding any harsh or dismissive language.""]"
"[""By generating multiple samples at once with the LSTM, the model is introducing some independence assumptions between samples that are from neighbouring windows and are not conditionally independent given the context produced by Wavenet. This reduces significantly the generality of the proposed technique.\n\nPros:\n- Attempting to solve the important problem of speeding up autoregressive generation.\n- Clarity of the write-up is OK, although it could use some polishing in some parts.\n- The work is in the right direction, but the paucity of results and lack of thoroughness reduces somewhat the work's overall significance.\n\nCons:\n- The proposed technique is not particularly novel and it is not clear whether the technique can be used to get speed-ups beyond 2x - something that is important for real-world deployment of Wavenet.\n- The amount of innovation is on the low side, as it involves mostly just fairly minor architectural changes.\n- The absolute results are not that great (MOS ~3.8 is not close to the SOTA of 4.4 - 4.5)\n\n\n"", ""TL;DR of paper: for sequential prediction, in order to scale up the model size without increasing inference time, use a model that predicts multiple timesteps at once. In this case, use an LSTM on top of a Wavenet for audio synthesis, where the LSTM predicts N steps for every Wavenet forward pass. The main result is being able to train bigger models, by increasing Wavenet depth, without increasing inference time.\n\nThe idea is simple and intuitive. I'm interested in seeing how well this approach can generalize to other sequential prediction domains. I suspect that it's easier in the waveform case because neighboring samples are highly correlated. I am surprised by how much an improvement \n\nHowever, there are a number of important design decisions that are glossed over in the paper. Here are a few that I am wondering about:\n* How well do other multi-step decoders do? For example, another natural choice is using transposed convolutions to upsample multiple timesteps. Fully connected layers? How does changing the number of LSTM layers affect performance?\n* Why does the Wavenet output a single timestep? Why not just have the multi-step decoder output all the timesteps?\n* How much of a boost does the separate training give over joint training? If you used the idea suggested in the previous point, you wouldn't need this separate training scheme.\n* How does performance vary over changing the number of steps the multi-step decoder outputs?\n\nThe paper also reads like it was hastily written, so please go back and fix the rough edges.\n\nRight now, the paper feels too coupled to the existing Deep Voice 2 system. As a research paper, it is lacking important ablations. I'll be happy to increase my score if more experiments and results are provided."", ""This paper presents HybridNet, a neural speech (and other audio) synthesis system (vocoder) that combines the popular and effective WaveNet model with an LSTM with the goal of offering a model with faster inference-time audio generation.\n\nSummary: The proposed model, HybridNet is a fairly straightforward variation of WaveNet and thus the paper offers a relatively low novelty. There is also a lack of detail regarding the human judgement experiments that make the significance of the results difficult to interpret. \n\nLow novelty of approach / impact assessment:\nThe proposed model is based closely on WaveNet, an existing state-of-the-art vocoder model. The proposal here is to extend WaveNet to include an LSTM that will generate samples between WaveNet samples -- thus allowing WaveNet to sample at a lower sample frequency. WaveNet is known for being relatively slow at test-time generation time, thus allowing it to run at a lower sample frequency should decrease generation time. The introduction of a local LSTM is perhaps not a sufficiently significant innovation. \n\nAnother issue that lowers the assessment of the likely impact of this paper is that there are already a number of alternative mechanism to deal with the sampling speed of WaveNet. In particular, the cited method of Ramachandran et al (2017) uses caching and other tricks to achieve a speed up of 21 times over WaveNet (compared to the 2-4 times speed up of the proposed method). The authors suggest that these are orthogonal strategies that can be combined, but the combination is not attempted in this paper. There are also other methods such as sampleRNN (Mehri et al. 2017) that are faster than WaveNet at inference time. The authors do not compare to this model.\n\nInappropriate evaluation:\nWhile the model is motivated by the need to reduce the generation of WaveNet sampling, the evaluation is largely based on the quality of the sampling rather than the speed of sampling. The results are roughly calibrated to demonstrate that HybridNet produces higher quality samples when (roughly) adjusted for sampling time. The more appropriate basis of comparison is to compare sample time as a function of sample quality. \n\nExperiments:\nFew details are provided regarding the human judgment experiments with Mechanical Turkers. As a result it is difficulty to assess the appropriateness of the evaluation and therefore the significance of the findings. I would also be much more comfortable with this quality assessment if I was able to hear the samples for myself and compare the quality of the WaveNet samples with HybridNet samples. I will also like to compare the WaveNet samples generated by the authors' implementation with the WaveNet samples posted by van den Oord et al (2017).  \n\n\nMinor comments / questions:\n\nHow, specifically, is validation error defined in the experiments? \n\nThere are a few language glitches distributed throughout the paper.  \n""]","[-30, -20, -50]","[20, 50, 20]","[""The sentiment score is -30 because the review is generally critical, pointing out several cons and limitations of the work. However, it does acknowledge some positive aspects ('Pros'), which prevents it from being extremely negative. The politeness score is 20 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They present both pros and cons in a balanced manner, and use phrases like 'could use some polishing' instead of more direct criticism. The reviewer also acknowledges the work is 'in the right direction', showing a degree of encouragement despite the overall critical tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea as 'simple and intuitive' and expresses interest in its potential, they also point out several important design decisions that are 'glossed over' and state that the paper 'feels too coupled to the existing Deep Voice 2 system' and is 'lacking important ablations'. The reviewer also mentions that the paper 'reads like it was hastily written'. However, they do offer to increase their score if more experiments and results are provided, which prevents the score from being more negative.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I'm interested in seeing' and 'I am wondering about', which are polite ways of expressing curiosity and requesting more information. The reviewer also offers specific suggestions for improvement and expresses willingness to reconsider their evaluation if additional work is done. However, some direct criticisms (e.g., 'reads like it was hastily written') prevent the score from being higher."", ""The sentiment score is -50 because the review is generally critical of the paper, pointing out low novelty, lack of detail in experiments, and inappropriate evaluation methods. However, it's not entirely negative as it acknowledges some potential benefits of the proposed model. The politeness score is 20 because while the reviewer maintains a professional tone and offers constructive criticism, there's a lack of positive reinforcement or encouraging language. The reviewer uses phrases like 'fairly straightforward variation', 'low novelty', and 'lack of detail' which are direct but not overtly rude. The review also offers specific suggestions for improvement, which is a polite way to provide criticism.""]"
"['Collaborative learning has been proposed as a way to learn over federated data while preserving privacy. However collaborative learning has been shown to be suscepti\nble to active attacks in which one of the participants uses a GAN to reveal information about another participant.\n\nThis paper proposes a collaborative learning framework (CLF) that mitigates the GAN attack. The framework involves using the neural net to learn a mapping of the inp\nut to a high-dimensional vector and computing the inner product of this vector to a random class-specific key (the final class prediction is the argmax of this inner product). The class-specific key can be chosen randomly by each participant. By choosing sufficiently long random keys, the probability of an attacker guessing the key can be reduced. Experiments on two datasets show that this scheme successfully avoids the GAN attack.\n \n1. Some of the details of key sharing are not clear and would appear to be important for the scheme to work. For example, if participants have instances associated with the same class, then they would need to share the key. This would require a central key distribution scheme which would then allow the attacker to also get access to the key.\n\n2. I would have  liked to see how the method works with an increasing fraction of adversarial participants (I could only see experiments with one adversary). Similarly, I would have liked to see experiments with and without the fixed dense layer to see its contribution to effective learning. ', ""This paper is a follow-up work to the CCS'2017 paper on the GAN-based attack on collaborative learning system where multiple users contribute their private and sensitive data to joint learning tasks. In order to avoid the potential risk of adversary's mimic based on information flow among distributed users, the authors propose to embed the class label into a multi-dimensional space, such that the joint learning is conducted over the embedding space without knowing the accurate representation of the classes. Under the assumption that the adversary can only generate fake and random class representations, they show their scheme is capable of hiding information from individual samples, especially over image data.\n\nThe paper is clearly written and easy to understand. The experiments show interesting results, which are particularly impressive with the face data. However, the reviewer feels the assumption on the adversary is generally too weak, such that slightly smarter adversary could circumvent the protection scheme and remain effective on sample recovery.\n\nBasically, instead of randomly guessing the representations of the classes from other innocent users, the adversary could apply GAN to learn the representation based on the feedback from these users. This can be easily done by including the representations in the embedding space in the parameters in GAN for learning.\n\nThis paper could be an interesting work, if the authors address such enhanced attacks from the adversary and present protection results over their existing experimental settings."", 'In this paper, the authors proposed a counter measure to protect collaborative training of DNN against the GAN attack in (Hitaj et al. 2017). The motivation of the paper is clear and so is the literature review. But for me the algorithm is not clearly defined and it is difficult to evaluate how the proposed procedure works. I am not saying that this is not the solution. I am just saying that the paper is not clear enough to say that it is (or it is not). From, my perspective this will make the paper a clear reject. \n\nI think the authors should explain a few things more clearly in order to make the paper foolproof. The first one seems to me the most clear problem with the approach proposed in the paper:\n\n1 $\\psi(c)$ defines the mapping from each class to a high dimensional vector that allows protection against the GAN attack. $\\psi(c)$ is suppose to be private for each class (or user if each class belong only to one user). This is the key aspect in the paper. But if more than one user have the same class they will need to share this key. Furthermore, at test time, these keys need to be known by everyone, because the output of the neural network needs to be correlated against all keys to see which is the true label. Of course the keys can only be released after the training is completed. But the adversary can also claim to have examples from the class it is trying to attack and hence the legitimate user that generated the key will have to give the attacker the key from the training phase. For example, let assume the legitimate user only has ones from MNIST and declares that it only has one class. The attacker says it has two classes the same one that the legitimate user and some other label. In this case the legitimate user needs to share $\\psi(c)$ with the attacker. Of course this sounds “fishy” and might be a way of finding who the attacker is, but there might be many cases in which it makes sense that two or more users shares the same labels and in a big system might be complicated to decide who has access to which key.\n\n2 I do not understand the definition of $\\phi(x)$. Is this embedding fixed for each user? Is this embedding the DNN? In Eq. 4 I would assume that $\\phi(x)$ is the DNN and that it should be $\\phi_\\theta(x)$, because otherwise the equation does not make sense. But this is not clearly explained in the paper and Eq 4 makes no sense at all. In a way the solution to the maximization in Eq 4 is Theta=\\infty. Also the term $\\phi(x)$ is not mentioned in the paper after page 5. My take is that the authors want to maximize the inner product, but then the regularizer should go the other way around. \n\n3 In the paper in page 5 we can read: “Here, we emphasize the first reason why it is important to use l2-normalized class keys and embedding outputs: in this manner, the resulting classification score is by definition restricted to the range [-1; +1],” If I understand correctly the authors are dividing the inner product by ||$\\psi(c)|| ||$\\phi(x)||. I can see that we can easily divide by ||$\\psi(c)||, but I cannot see how we can do dive by ||$\\phi(x)||, if this term depends on \\theta. If this term does not depend on \\theta, then Eq 4 does not make sense.\n\nTo summarize, I have the impression that there are many elements in the paper that does not makes sense in the way that they are explained and that the authors need to tell the paper in a way that can be easily understood and replicated. I recommend the authors to run the paper by someone in their circle that could help them rewrite the paper in a way that is more accessible. \n']","[20, -20, -70]","[60, 60, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contribution to mitigating GAN attacks in collaborative learning and notes successful experimental results. However, they also point out some limitations and areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or dismissive comments. They use phrases like 'I would have liked to see' instead of demanding changes, which contributes to the polite tone. The review maintains a professional and objective stance, focusing on the content rather than making personal remarks."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is clearly written and shows interesting results, they express significant concerns about the weakness of the adversary assumption and suggest that a smarter adversary could circumvent the protection scheme. The reviewer states that the paper 'could be an interesting work' if these issues are addressed, implying it's not quite there yet. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and offers constructive criticism. They use phrases like 'The paper is clearly written' and 'The experiments show interesting results' before presenting their concerns. The suggestion for improvement is framed politely as an opportunity to make the work more interesting rather than as a harsh criticism."", ""The sentiment score is -70 because the reviewer expresses significant concerns about the clarity and validity of the paper's methodology. They state that the algorithm is not clearly defined, making it difficult to evaluate. The reviewer explicitly mentions that from their perspective, this would make the paper 'a clear reject'. However, it's not entirely negative as they suggest ways for improvement.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They use phrases like 'I think the authors should explain', and 'I am not saying that this is not the solution', which soften the criticism. The reviewer also offers specific suggestions for improvement and encourages the authors to seek help in rewriting the paper, showing a supportive attitude despite the negative evaluation.\n\nThe language used is generally respectful and aimed at helping the authors improve their work, even though the overall assessment is negative. This balance of criticism with constructive feedback and polite language results in a slightly positive politeness score.""]"
"['In this paper, the authors present an open-source toolbox to explore layerwise-parallel deep neural networks. They offer an interesting and detailed comparison of the temporal progression of layerwise-parallel and layerwise-sequential networks, and differences that can emerge in the results of these two computation strategies.\n\nWhile the open-source toolbox introduced in this paper can be an excellent resource for the community interested in exploring these networks, the present submission offers relatively few results actually using these networks in practice. In order to make a more compelling case for these networks, the present submission could include more detailed investigations, perhaps demonstrating that they learn differently or better than other implementations on standard training sets.', 'Quality and clarity\n\nThe paper goes to some length to explain that update order in a neural network matters in the sense that different update orders give different results. While standard CNN like architectures are fine with the layer parallel updating process typically used in standard tools, for recurrent networks and also for networks with connections that skip layers, different update orders may be more natural, but no GPU-accelerated toolboxes exist that support this. The authors provide such a toolbox, statestream, written Theano.\n\nThe paper\'s structure is reasonably clear, though the text has very poor ""flow"": the english could use a native speaker straightening out the text. For example, a number of times there are phrases like ""previously mentioned"", which is ugly. \n\nMy main issue is with the significance of the work. There are no results in the paper that demonstrate a case where it is useful to apply fully parallel updates. As such, it is hard to see the value of the contribution, also since the toolbox is written in Theano for which support has been discontinued. ', ""This paper introduces a new toolbox for deep neural networks learning and evaluation. The central idea is to include time in the processing of all the units in the network. For this, the authors propose a paradigm switch: form layerwise-sequential networks, where at every time frame the network is evaluated by updating each layer – from bottom to top – sequentially; to layerwise-parallel networks, where all the neurons are updated in parallel. The new paradigm implies that the layer update is achieved by using the stored previous state and the corresponding previous state of the previous layer. This has three consequences. First, every layer now use memory, a condition that already applies for RNNs in layerwise-sequential networks. Second, in order to have a consistent output, the information has to flow in the network for a number of time frames equal to the number of layers. In Neuroscience, this concept is known as reaction time. Third, since the network is not synchronized in terms of the information that is processed in a specific time frame, there are discrepancies w.r.t. the layerwise-sequential networks computation: all the techniques used to train deep NNs have to be reconsidered. \n\nOverall, the concept is interesting and timely especially for the rising field of spiking neural networks or for large and distributed architectures. The paper, however, should probably provide more examples and results in terms of architectures that can been implemented with the toolbox in comparison with other toolboxes. The paper presents a single example in which either the accuracy and the training time are not reported. While I understand that the main result of this work is the toolbox itself, more examples and results would improve the clarity and the implications for such paradigm switch. Another concern comes from the choice to use Theano as back-end, since it's known that it is going to be discontinued. Finally I suggest to improve the clarity and description of Figure 2, which is messy and confusing especially if printed in B&W. \n""]","[20, -50, 20]","[60, 20, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the potential value of the open-source toolbox and describes the comparison as 'interesting and detailed'. However, they also express that the paper lacks sufficient practical results, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, such as 'the authors present' and 'can be an excellent resource'. They offer constructive criticism in a polite manner, suggesting improvements rather than harshly criticizing. The reviewer maintains a professional tone while providing balanced feedback, which contributes to the politeness of the review."", 'The sentiment score is -50 because while the reviewer acknowledges some positive aspects (e.g., \'reasonably clear\' structure), they express significant concerns about the paper\'s significance and value. The criticism about the lack of results demonstrating usefulness and the outdated toolbox choice outweighs the positive elements. The politeness score is 20 because the reviewer maintains a professional tone throughout, offering constructive criticism without harsh language. However, some phrases like \'very poor ""flow""\' and \'ugly\' slightly reduce the overall politeness. The reviewer balances critique with acknowledgment of the paper\'s efforts, maintaining a relatively polite but honest assessment.', ""The sentiment score is slightly positive (20) because the reviewer describes the concept as 'interesting and timely' and acknowledges the main contribution of the work. However, they also express several concerns and suggestions for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the work's potential while offering constructive criticism. They use phrases like 'I understand that' and 'I suggest' which maintain a polite tone. The reviewer balances positive comments with areas for improvement without using harsh or dismissive language.""]"
"['Approach is interesting however my main reservation is with the data set used for experiments and making general (!) conclusions. MNIST, CIFAR-10 are too simple tasks perhaps suitable for debugging but not for a comprehensive validation of quantization/compression techniques. Looking at the results, I see a horrific degradation of 25-43% relative to DC baseline despite being told about only a minimal loss in accuracy. A number of general statements is made based on MNIST data, such as on page 3 when comparing GMM and k-means priors, on page 7 and 8 when claiming that parameter tying and sparsity do not act strongly to improve generalization. In addition, by making a list of all hyper parameters you tuned I am not confident that your claim that this approach requires less tuning. \n\nAdditional comments:\n\n(a) you did not mention student-teacher training\n(b) reference to previously not introduced K-means prior at the end of section 1\n(c) what is that special version of 1-D K-means?\n(d) Beginning of section 4.1 is hard to follow as you are referring to some experiments not shown in the paper.\n(e) Where is 8th cluster hiding in Figure 1b?\n(f) Any comparison to a classic compression technique would be beneficial.\n(g) You are referring to a sparsity at the end of page 8 without formally defining it. \n(h) Can you label each subfigure in Figure 3 so I do not need to refer to the caption? Can you discuss this diagram in the main text, otherwise what is the point of dumping it in the appendix?\n(i) I do not understand Figure 4 without explanation. ', 'As the authors mentioned, weight-sharing and pruning are not new to neural network compression. The proposed method resembles a lot with the deep compression work (Han et. al. 2016), with the distinction of clustering across different layers and a Lasso regularizer to encourage sparsity of the weights. Even though the change seems minimal, the authors has demonstrated the effectiveness on the benchmark.\n\nBut the description of the optimization strategy in Section 3 needs some refinement. In the soft-tying stage, why only the regularizer (1) is considered, not the sparsity one? In the hard-tying stage, would the clustering change in each iteration? If not, this has reduced to the constrained problem as in the Hashed Compression work (Chen et. al. 2015) where the regularizer (1) has no effect since the clustering is fixed and all the weights in the same cluster are equal. Even though it is claimed that the proposed method does not require a pre-trained model to initialize, the soft-tying stage seems to take the responsibility to ""pre-train"" the model.\n\nThe experiment section is a weak point. It is much less convincing with no comparison result of compression on large neural networks and large datasets. The only compression result on large neural network (VGG-11) comes with no baseline comparisons. But it already tells something: 1) what is the classification result for reference network without compression? 2) the compression ratio has significantly reduced comparing with those for MNIST. It is hard to say if the compression performance could generalize to large networks.\n\nAlso, it would be good to have an ablation test on different parts of the objective function and the two optimization stages to show the importance of each part, especially the removal of the soft-tying stage and the L1 regularizer versus a simple pruning technique after each iteration. This maybe a minor issue, but would be interesting to know: what would the compression performance be if the classification accuracy maintains the same level as that of the deep compression. As discussed in the paper, it is a trade-off between accuracy and compression. The network could be compressed to very small size but with significant accuracy loss.\n\nSome minor issues:\n- In Section 1, the authors discussed a bunch of pitfalls of existing compression techniques, such as large number of parameters, local minimum issues and layer-wise approaches. It would be clearer if the authors could explicitly and succinctly discuss which pitfalls are resolved and how by the proposed method towards the end of the Introduction section. \n- In Section 4.2, the authors discussed the insensitivity of the proposed method to switching frequency. But there is no quantitative results shown to support the claims.\n- What is the threshold for pruning zero weight used in Table 2?\n- There are many references and comparisons missing: Soft-to-Hard Vector Quantization for End-to-End Learning Compressible Representations in NIPS 17 for instance. This paper also considers quantization for compression which is related to this work.', 'This is yet another paper on parameter tying and compression of DNNs/CNNs.  The key idea here is a soft parameter tying under the K-means regularization on top of which an L1 regularization is further imposed for promoting sparsity. This strategy seems to help the hard tying in a later stage while keeping decent performance.  The idea is sort of interesting and the reported experimental results appear to be supportive.  However, I have following concerns/comments. \n\n1.  The roles played by K-means and L1 regularization are a little confusing from the paper.  In Eq.3, it appears that the L1 regularization is always used in optimization. However, in Eq.4,  the L1 norm is not included.  So the question is,  in the soft-tying step, is L1 regularization always used?  Or a more general question,  how important is it to regularize the cross-entropy with both K-means and L1? \n\n2. A follow-up question on K-means and L1.   If no L1 regularization, does the K-means soft-tying followed by a hard-tying work as well as using the L1 regularization throughout? \n\n3. It would be helpful to say a few words on the storage of the model parameters. \n\n4. It would be helpful to show if the proposed technique work well on sequential models like LSTMs.']","[-60, -20, 20]","[-20, 50, 60]","[""The sentiment score is -60 because the reviewer expresses significant reservations about the paper's methodology and conclusions. They describe the data sets as 'too simple' and the results as showing 'horrific degradation'. The reviewer also questions several claims made in the paper. However, it's not entirely negative as they do mention the approach is 'interesting'. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical. They use strong negative words like 'horrific' and express doubt about the authors' claims without much softening language. The list of additional comments is presented bluntly without any positive reinforcement. However, the reviewer does maintain a professional tone overall, avoiding personal attacks or overly harsh language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the work ('demonstrated effectiveness on the benchmark'), they also point out several weaknesses and areas for improvement. The review highlights issues with the optimization strategy, experiment section, and lack of comparisons with large neural networks and datasets. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement without using harsh or dismissive language. They use phrases like 'it would be good to have' and 'would be interesting to know' which maintain a polite tone while providing feedback."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting idea and supportive experimental results. However, they express several concerns and questions, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing their concerns as questions or suggestions rather than criticisms. They use phrases like 'it would be helpful' and 'the question is,' which maintain a constructive tone. The reviewer also acknowledges the paper's merits before presenting their concerns, which is a polite approach to peer review.""]"
"[""Summary:\n\nThis paper proposes an adversarial learning framework for machine comprehension task. Specifically, authors consider a reader network which learns to answer the question by reading the passage and a narrator network which learns to obfuscate the passage so that the reader can fail in its task. Authors report results in 3 different reading comprehension datasets and the proposed learning framework results in improving the performance of GMemN2N.\n\n\nMy Comments:\n\nThis paper is a direct application of adversarial learning to the task of reading comprehension. It is a reasonable idea and authors indeed show that it works.\n\n1. The paper needs a lot of editing. Please check the minor comments.\n\n2. Why is the adversary called narrator network? It is bit confusing because the job of that network is to obfuscate the passage.\n\n3. Why do you motivate the learning method using self-play? This is just using the idea of adversarial learning (like GAN) and it is not related to self-play.\n\n4. In section 2, first paragraph, authors mention that the narrator prevents catastrophic forgetting. How is this happening? Can you elaborate more?\n\n5. The learning framework is not explained in a precise way. What do you mean by re-initializing and retraining the narrator? Isn’t it costly to reinitialize the network and retrain it for every turn? How many such epochs are done? You say that test set also contains obfuscated documents. Is it only for the validation set? Can you please explain if you use obfuscation when you report the final test performance too? It would be more clear if you can provide a complete pseudo-code of the learning procedure.\n\n6. How does the narrator choose which word to obfuscate? Do you run the narrator model with all possible obfuscations and pick the best choice?\n\n7. Why don’t you treat number of hops as a hyper-parameter and choose it based on validation set? I would like to see the results in Table 1 where you choose number of hops for each of the three models based on validation set.\n\n8. In figure 2, how are rounds constructed? Does the model sees the same document again and again for 100 times or each time it sees a random document and you sample documents with replacement? This will be clear if you provide the pseudo-code for learning.\n\n9. I do not understand author's’ justification for figure-3. Is it the case that the model learns to attend to last sentences for all the questions? Or where it attends varies across examples?\n\n10. Are you willing to release the code for reproducing the results?\n\nMinor comments:\n\nPage 1, “exploit his own decision” should be “exploit its own decision”\nIn page 2, section 2.1, sentence starting with “Indeed, a too low percentage …” needs to be fixed.\nPage 3, “forgetting is compensate” should be “forgetting is compensated”.\nPage 4, “for one sentences” needs to be fixed.\nPage 4, “unknow” should be “unknown”.\nPage 4, “??” needs to be fixed.\nPage 5, “for the two first datasets” needs to be fixed.\nTable 1, “GMenN2N” should be “GMemN2N”. In caption, is it mean accuracy or maximum accuracy?\nPage 6, “dataset was achieves” needs to be fixed.\nPage 7, “document by obfuscated this word” needs to be fixed.\nPage 7, “overall aspect of the two first readers” needs to be fixed.\nPage 8, last para, references needs to be fixed.\nPage 9, first sentence, please check grammar.\nSection 6.2, last sentence is irrelevant.\n"", 'The paper aims to improve the accuracy of reading model on question answering dataset by playing against an adversarial agent (which is called narrator by the authors) that ""obfuscates"" the document, i.e. changing words in the document. The authors mention that word dropout can be considered as its special case which randomly drops words without any prior. Then the authors claim that smartly choosing the words to drop can make a stronger adversarial agent, which in turn would improve the performance of the reader as well. Hence the adversarial agent is trained and is architecturally similar to the reader but just has a different last layer, which predicts the word that would make the reader fail if the word is obfuscated.\n\nI think the idea is interesting and novel. While there have been numerous GAN-like approaches for language understanding, very few, if any, have shown worthy results. So if this works, it could be an impactful achievement. \n\nHowever, I am concerned with the experimental results.\n\nFirst, CBT: NE and CN numbers are too low. Even a pure LSTM achieves (no attention, no memory) 44% and 45%, respectively (Yu et al., 2017). These are 9% and 6% higher than the reported numbers for adversarial GMemN2N. So it is very difficult to determine if the model is appropriate for the dataset in the first place, and whether the gain from the non-adversarial setting is due to the adversarial setup or not.\n\nSecond, Cambridge dialogs: the dataset\'s metric is not accuracy-based (while the paper reports accuracy), so I assume some preprocessing and altering have been done on the dataset. So there is no baseline to compare. Though I understand that the point of the paper is the improvement via the adversarial setting, it is hard to gauge how good the numbers are.\n\nThird, TripAdvisor: the dataset paper by Wang et al. (2010) is not evaluated on accuracy (rather on ranking, etc.). Did you also make changes to the dataset? Again, this makes the paper less strong because there is no baseline to compare.\n\nIn short, the only comparable dataset is CBT, which has too low accuracy compared to a very simple baseline.\nIn order to improve the paper, I recommend the authors to evaluate on more common datasets and/or use more appropriate reading models.\n\n---\n\nTypos:\npage 1 first para: ""One the first hand"" -> ""On the first hand""\npage 1 first para: ""minimize to probability"" -> ""minimize the probability""\npage 3 first para: ""compensate"" -> ""compensated""\npage 3 last para: ""softmaxis"" -> ""softmax is""\npage 4 sec 2.4: ""similar to the reader"" -> ""similarly to the reader""\npage 4 sec 2.4: ""unknow"" -> ""unknown""\npage 4 sec 3 first para: missing reference at ""a given dialog""\npage 5 first para: ""Concretly"" -> ""Concretely""\nTable 1: ""GMenN2N"" -> ""GMemN2N""\nTable 1: what is difference between ""mean"" and ""average""?\npage 8 last para: missing reference at ""Iterative Attentive Reader""\npage 9 sec 6.2 last para: several citations missing, e.g. which paper is by ""Tesauro""?\n\n\n[Yu et al. 2017] Adams Wei Yu, Hongrae Kim, and Quoc V. Le. Learning to Skim Text. ACL 2017\n\n', 'The main idea of this paper is to automate the construction of adversarial reading comprehension problems in the spirit of Jia and Liang, EMNLP 2017.  In that work a ""distractor sentence"" is manually added to a passage to superficially, but not logically, support an incorrect answer.  It was shown that these distractor sentences largely fool existing reading comprehension systems although they do not fool human readers.\n\nThis paper replaces the manual addition of a distractor sentence with a single word replacement where a ""narrator"" is trained adversarially to select a replacement to fool the question answering system.  This idea seems interesting but very difficult to evaluate.  An adversarial word replacement my in fact destroy the factual information needed to answer the question and there is no control for this.  The performance of the question answering system in the presence of this adversarial narrator is of unclear significance and the empirical results in the paper are very difficult to interpret.  No comparisons with previous work are given (and perhaps cannot be given).\n\nA better model would be the addition of a distractor sentence as this preserves the information in the original passage.  A language model could probably be used to generate a compelling distractor.  But we want that the corrupted passage has the same correct answer as the uncorrupted passage and this difficult to guarantee.  A trained ""narrator"" could learn to actually change the correct answer.']","[-20, -20, -50]","[50, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper presents a 'reasonable idea' and shows that it works, they also point out numerous issues and areas for improvement. The review lists 10 major points of criticism or requests for clarification, as well as several minor comments on writing and grammar issues. This suggests the reviewer sees significant room for improvement, though they are not entirely dismissive of the work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'Can you please explain' and 'I would like to see', which are polite ways of requesting more information or suggesting improvements. The reviewer also offers specific, actionable feedback rather than vague criticisms. However, the score is not higher because the review is quite direct in pointing out flaws and doesn't include many explicitly positive statements or praise for the authors' work."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the idea 'interesting and novel', they express significant concerns about the experimental results and recommend major changes. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges potential impact, and provides constructive feedback. They use phrases like 'I think', 'I recommend', and offer specific suggestions for improvement. The reviewer also helpfully points out typos, which adds to the constructive tone. However, the critique is direct and doesn't use overly deferential language, keeping it from scoring higher on politeness."", ""The sentiment score is -50 because while the reviewer acknowledges the interesting idea of the paper, they express significant concerns about the evaluation method and the interpretability of the results. The reviewer points out that the approach may destroy factual information needed to answer questions and that the empirical results are difficult to interpret. They also note the lack of comparisons with previous work. However, the score is not extremely negative as the reviewer does recognize the potential of the idea.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They present their criticisms constructively, using phrases like 'seems interesting but very difficult to evaluate' and 'A better model would be...'. The reviewer also offers suggestions for improvement, which is a polite way to provide criticism. While not overly warm or complimentary, the language is consistently courteous and appropriate for academic discourse.""]"
"['1. Summary\n\nThis paper introduced a method to learn a compressed version of a neural network such that the loss of the compressed network doesn\'t dramatically change.\n\n\n2. High level paper\n\n- I believe the writing is a bit sloppy. For instance equation 3 takes the minimum over all m in C but C is defined to be a set of c_1, ..., c_k, and other examples (see section 4 below). This is unfortunate because I believe this method, which takes as input a large complex network and compresses it so the loss in accuracy is small, would be really appealing to companies who are resource constrained but want to use neural network models.\n\n\n3. High level technical\n\n- I\'m confused at the first and second lines of equation (19). In the first line, shouldn\'t the first term not contain \\Delta W ? In the second line, shouldn\'t the first term be \\tilde{\\mathcal{L}}(W_0 + \\Delta W) ?\n- For CIFAR-10 and SVHN you\'re using Binarized Neural Networks and the two nice things about this method are (a) that the memory usage of the network is very small, and (b) network operations can be specialized to be fast on binary data. My worry is if you\'re compressing these networks with your method are the weights not treated as binary anymore? Now I know in Binarized Neural Networks they keep a copy of real-valued weights so if you\'re just compressing these then maybe all is alright. But if you\'re compressing the weights _after_ binarization then this would be very inefficient because the weights won\'t likely be binary anymore and (a) and (b) above no longer apply.\n- Your compression ratio is much higher for MNIST but your accuracy loss is somewhat dramatic, especially for MNIST (an increase of 0.53 in error nearly doubles your error and makes the network worse than many other competing methods: http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354). What is your compression ratio for 0 accuracy loss? I think this is a key experiment that should be run as this result would be much easier to compare with the other methods.\n- Previous compression work uses a lot of tricks to compress convolutional weights. Does your method work for convolutional layers?\n- The first paper to propose weight sharing was not Han et al., 2015, it was actually:\nChen W., Wilson, J. T., Tyree, S., Weinberger K. Q., Chen, Y. ""Compressing Neural Networks with the Hashing Trick"" ICML 2015\nAlthough they did not learn the weight sharing function, but use random hash functions.\n\n\n4. Low level technical\n\n- The end of Section 2 has an extra \'p\' character\n- Section 3.1: ""Here, X and y define a set of samples and ideal output distributions we use for training"" this sentence is a bit confusing. Here y isn\'t a distribution, but also samples drawn from some distribution. Actually I don\'t think it makes sense to talk about distributions at all in Section 3.\n- Section 3.1: ""W is the learnt model...\\hat{W} is the final, trained model"" This is unclear: W and \\hat{W} seem to describe the same thing. I would just remove ""is the learnt model and""\n\n\n5. Review summary\n\nWhile the trust-region-like optimization of the method is nice and I believe this method could be useful for practitioners, I found the paper somewhat confusing to read. This combined with some key experimental questions I have make me think this paper still needs work before being accepted to ICLR.', 'The paper addresses an interesting problem of DNN model compression. The main idea is to combine the approaches in (Han et al., 2015) and (Ullrich et al., 2017) to get a loss value constrained k-means encoding method for network compression. An iterative algorithm is developed for model optimization. Experimental results on MNIST, CIFAR-10 and SVHN are reported to show the compression performance. \n\nThe reviewer would expect papers submitted for review to be of publishable quality. However, this manuscript is not polished enough for publication: it has too many language errors and imprecisions which make the paper hard to follow. In particular, there is no clear definition of problem formulation, and the algorithms are poorly presented and elaborated in the context. \n\nPros: \n\n- The network compression problem is of general interest to ICLR audience. \n\nCons:\n\n- The proposed approach follows largely the existing work and thus its technical novelty is weak. \n\n- Paper presentation quality is clearly below the standard. \n\n- Empirical results do not clearly show the advantage of the proposed method over state-of-the-arts. \n\n\n\n', '1. This paper proposes a deep neural network compression method by maintaining the accuracy of deep models using a hyper-parameter. However, all compression methods such as pruning and quantization also have this concern. For example, the basic assumption of pruning is to discard subtle parameters has little impact on feature maps thus the accuracy of the original network can be preserved. Therefore, the novelty of the proposed method is somewhat weak.\n\n2. There are a lot of new algorithms on compressing deep neural networks such as [r1][r2][r3]. However, the paper only did a very simple investigation on related works.\n[r1] CNNpack: packing convolutional neural networks in the frequency domain.\n[r2] LCNN: Lookup-based Convolutional Neural Network.\n[r3] Xnor-net: Imagenet classification using binary convolutional neural networks.\n\n3. Experiments in the paper were only conducted on several small datasets such as MNIST and CIFAR-10. It is necessary to employ the proposed method on benchmark datasets to verify its effectiveness, e.g., ImageNet.\n']","[-50, -50, -50]","[20, 20, 0]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper ('trust-region-like optimization of the method is nice', 'this method could be useful for practitioners'), the overall tone is critical. The reviewer points out several issues with the paper, including 'sloppy' writing, confusing equations, and experimental concerns. The conclusion that 'this paper still needs work before being accepted' indicates a generally negative sentiment. The politeness score is 20 because the reviewer uses relatively polite language throughout, avoiding harsh criticism and using phrases like 'I believe' and 'I'm confused' rather than making blunt statements. However, the politeness is not overly effusive, maintaining a professional tone. The reviewer also provides specific, constructive feedback, which is a polite way to offer criticism."", ""The sentiment score is -50 because while the reviewer acknowledges the interesting problem and some pros, they express significant concerns about the paper's quality, novelty, and presentation. The overall tone is more negative than positive, but not entirely dismissive. The politeness score is 20 because the reviewer uses professional language and provides both pros and cons, but doesn't use overtly polite phrases. They are direct in their criticism while maintaining a respectful tone. The reviewer begins with positive aspects before moving to criticisms, which is a polite approach. However, phrases like 'clearly below the standard' are quite direct, preventing a higher politeness score."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the novelty and scope of the research. They state that the paper's main claim is not particularly novel and that the literature review is insufficient. The experiments are also criticized for being limited to small datasets. However, the score is not extremely negative as the reviewer does acknowledge the paper's attempt to address an important concern in neural network compression.\n\nThe politeness score is 0 (neutral) because the reviewer's language is neither particularly polite nor rude. They present their criticisms in a direct, matter-of-fact manner without using overly harsh language or personal attacks, but also without any notably courteous phrasing. The tone is professional and objective, focusing on the content of the paper rather than on pleasantries or unnecessarily negative comments.""]"
"['\n\nThis paper proposes to use deep reinforcement learning to solve a multiagent coordination task. In particular, the paper introduces a benchmark domain to model fleet coordination problems as might be encountered in taxi companies. \n\nThe paper does not really introduce new methods, and as such, this paper should be seen more as an application paper. I think that such a paper could have merits if it would really push the boundary of the feasible, but I do not think that is really the case with this paper: the task still seems quite simplistic, and the empirical evaluation is not convincing (limited analysis, weak baselines). As such, I do not really see any real grounds for acceptance.\n\nFinally, there are also many other weaknesses. The paper is quite poorly written in places, has poor formatting (citations are incorrect and half a bibtex entry is inlined), and is highly inadequate in its treatment of related work. For instance, there are many related papers on:\n\n-taxi fleet management (e.g., work by Pradeep Varakantham)\n \n-coordination in multi-robot systems for spatially distributed tasks (e.g., Gerkey and much work since)\n\n-scaling up multiagent reinforcement learning and multiagent MDPs (Guestrin et al 2002, Kok & Vlassis 2006, etc.)\n\n-dealing with partial observability (work on decentralized POMDPs by Peshkin et al, 2000, Bernstein, Amato, etc.)\n\n-multiagent deep RL has been very active last 1-2 years. E.g., see other papers by Foerster, Sukhbataar, Omidshafiei\n\n\nOverall, I see this as a paper which with improvements could make a nice workshop contribution, but not as a paper to be published at a top-tier venue.\n\n', 'The main contribution of the paper seems to be the application to this problem, plus minor algorithmic/problem-setting contributions that consist in considering partial observability and to balance multiple objectives. On one hand, fleet management is an interesting and important problem. On the other hand, although the experiments are well designed and illustrative, the approach is only tested in a small 7x7 grid and 2 agents and in a 10x10 grid with 4 agents. In spirit, these simulations are similar to those in the original paper by M. Egorov. Since the main contribution is to use an existing algorithm to tackle a practical application, it would be more interesting to tweak the approach until it is able to tackle a more realistic scenario (mainly larger scale, but also more realistic dynamics with traffic models, real data, etc.).\n\nSimulation results compare MADQN with Dijkstra\'s algorithm as a baseline, which offers a myopic solution where each agent picks up the closest customer. Again, since the main contribution is to solve a specific problem, it would be worthy to compare with a more extensive benchmark, including state of the art algorithms used for this problem (e.g., heuristics and metaheuristics). \n\nThe paper is clear and well written. There are several minor typos and formatting errors (e.g., at the end of Sec. 3.3, the authors mention Figure 3, which seems to be missing, also references [Egorov, Maxim] and [Palmer, Gregory] are bad formatted). \n\n\n-- Comments and questions to the authors:\n\n1. In the introduction, please, could you add references to what is called ""traditional solutions""?\n\n2. Regarding the partial observability, each agent knows the location of all agents, including itself, and the location of all obstacles and charging locations; but it only knows the location of customers that are in its vision range. This assumption seems reasonable if a central station broadcasts all agents\' positions and customers are only allowed to stop vehicles in the street, without ever contacting the central station; otherwise if agents order vehicles in advance (e.g., by calling or using an app) the central station should be able to communicate customers locations too. On the other hand, if no communication with the central station is allowed, then positions of other agents may be also partial observable. In other words, the proposed partial observability assumption requires some further motivation. Moreover, in Sec. 4.3, it is said that agents can see around them +10 spaces away; however, experiments are run in 7x7 and 10x10 grid worlds, meaning that the agents are able to observe the grid completely.\n\n3. The fact that partial observability helped to alleviate the credit-assignment noise caused by the missing customer penalty might be an artefact of the setting. For instance, since the reward has been designed arbitrarily, it could have been defined as giving a penalty for those missing customers that are at some distance of an agent.\n\n4. Please, could you explain the last sentence of Sec. 4.3 that says ""The drawback here is that the agents will not be able to generalize to other unseen maps that may have very different geographies."" In particular, how is this sentence related to partial observability?', 'In this paper, the authors define a simulated, multi-agent “taxi pickup” task in a GridWorld environment. In the task, there are multiple taxi agents that a model must learn to control. “Customers” randomly appear throughout the task and the taxi agents receive reward for moving to the same square as a customer. Since there are multiple customer and taxi agents, there is a multi-agent coordination problem. Further, the taxi agents have “batteries”, which starts at a positive number, ticks down by one on each time step and a large negative reward is given if this number reaches zero. The battery can be “recharged” by moving to a “charge” tile.\n\nCooperative multi-agent problem solving is an important problem in machine learning, artificial intelligence, and cognitive science. This paper defines and examines an interesting cooperative problem: Assignment and control of agents to move to certain squares under “physical” constraints. The authors propose a centralized solution to the problem by adapting the Deep Q-learning Network model. I do not know whether using a centralized network where each agent has a window of observations is a novel algorithm. The manuscript itself makes it difficult to assess (more on this later). If it were novel, it would be an incremental development. They assess their solution quantitatively, demonstrating their model performs better than first, a simple heuristic model (I believe de-centralized Dijkstra’s for each agent, but there is not enough description in the manuscript to know for sure), and then, two other baselines that I could not figure out from the manuscript (I believe it was Dijkstra’s with two added rules for when to recharge).\n\nAlthough the manuscript has many positive aspects to it, I do not believe it should be accepted for the following reasons. First, the manuscript is poorly written, to the point where it has inhibited my ability to assess it. Second, given its contribution, the manuscript is better suited for a conference specific to multi-agent decision-making. There are a few reasons for this. 1) I was not convinced that deep Q-learning was necessary to solve this problem. The manuscript would be much stronger if the authors compared their method to a more sophisticated baseline, for example having each agent be a simple Q-learner with no centralization or “deepness”. This would solve another issue, which is the weakness of their baseline measure. There are many multi-agent techniques that can be applied to the problem that would have served as a better baseline. 2) Although the problem itself is interesting, it is a bit too applied and specific to the particular task they studied than is appropriate for a conference with as broad interests as ICLR. It also is a bit simplistic (I had expected the agents to at least need to learn to move the customer to some square rather than get reward and move to the next job from just getting to the customer’s square). Can you apply this method to other multi-agent problems? How would it compare to other methods on those problems? \n\nI encourage the authors to develop the problem and method further, as well as the analysis and evaluation. \n']","[-70, -20, -50]","[-20, 60, 50]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states there are 'no real grounds for acceptance', calls the paper 'poorly written' with 'many weaknesses', and suggests it's only suitable as a 'workshop contribution'. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and dismissive. Phrases like 'does not really introduce new methods', 'task still seems quite simplistic', and 'empirical evaluation is not convincing' are direct criticisms without much softening. The reviewer does attempt some politeness by acknowledging potential merits ('could have merits if...') and suggesting possible improvements, which prevents the score from being lower."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects (e.g., 'fleet management is an interesting and important problem', 'experiments are well designed and illustrative'), they express several criticisms and suggest significant improvements. The reviewer points out limitations in the scale of experiments, lack of comparison with state-of-the-art algorithms, and questions some assumptions. However, it's not entirely negative as they also recognize the paper's clarity and potential importance.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'please, could you...' when asking questions, and frame criticisms constructively (e.g., 'it would be more interesting to...', 'it would be worthy to...'). The reviewer also balances critiques with positive comments about the paper's clarity and writing. While direct in their assessment, they avoid harsh or dismissive language, maintaining a collegial tone appropriate for academic discourse."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper ('interesting cooperative problem', 'performs better than... baselines'), they ultimately recommend rejection due to significant issues. The overall tone is critical, stating the paper 'should not be accepted' and needs further development. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and encouragement for future work. They avoid harsh or rude phrasing, instead using phrases like 'I do not believe' and 'I encourage the authors to develop'. The reviewer also balances criticism with positive observations about the paper's strengths.""]"
"[""This paper proposes a hybrid Homomorphic encryption system that is well suited for privacy-sensitive data inference applications with the deep learning paradigm. \nThe paper presents a well laid research methodology that shows a good decomposition of the problem at hand and the approach foreseen to solve it. It is well reflected in the paper and most importantly the rationale for the implementation decisions taken is always clear.\n\nThe results obtained (as compared to FHEW) seem to indicate well thought off decisions taken to optimize the different gates' operations as clearly explained in the paper. For example, reducing bootstrapping operations by two-complementing both the plaintext and the ciphertext, whenever the number of 1s in the plain bit-string is greater than the number of 0s (3.4/Page 6).\n\nResult interpretation is coherent with the approach and data used and shows a good understanding of the implications of the implementation  decisions made in the system and the data sets used.\nOverall, fine work, well organized, decomposed, and its rationale clearly explained. The good results obtained support the design decisions made.\nOur main concern is regarding thorough comparison to similar work and provision of comparative work assessment to support novelty claims.\n\nNota: \n     - In Figure 4/Page 4: AND Table A(1)/B(0), shouldn't  A And B be 0?\n     - Unlike Figure 3/Page 3, in Figure 2/page 2, shouldn't  operations' precedence prevail (No brackets), therefore 1+2*2=5?"", 'Summary:\nThis paper proposes a framework for private deep learning model inference using FHE schemes that support fast bootstrapping.\nThe main idea of this paper is that in the two-party computation setting, in which the client\'s input is encrypted while the server\'s deep learning model is plain.\nThis ""hybrid"" argument enables to reduce the number of necessary bootstrapping, and thus can reduce the computation time.\nThis paper gives an implementation of adder and multiplier circuits and uses them to implement private model inference.\n\nComments:\n1. I recommend the authors to tone down their claims. For example, the authors mentioned that ""there has been no complete implementation of established deep learning approaches"" in the abstract, however, the authors did not define what is ""complete"". Actually, the SecureML paper in S&P\'17 should be able to privately evaluate any neural networks, although at the cost of multi-round information exchanges between the client and server.\n\nAlso, the claim that ""we show efficient designs"" is very thin to me since there are no experimental comparisons between the proposed method and existing works. Actually, the level FHE can be very efficient with a proper use of message packing technique such as [A] and [C]. For a relatively shallow model (as this paper has used), level FHE might be faster than the binary FHE.\n\n2. I recommend the author to compare existing adder and multiplier circuits with your circuits to see in what perspective your design is better. I think the hybrid argument (i.e., when one input wire is plain) is a very common trick that used in the circuit design field, such as garbled circuit [B], to reduce the depth of the circuit. \n\n3. I appreciate that optimizations such as low-precision and point-wise convolution are discussed in this paper. Such optimizations are very common in deep learning field while less known in the field of security.\n\n[A]: Dowlin et al. Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy.\n[B]: V. Kolesnikov et al. Improved garbled circuit: free xor gates and applications. \n[C]: Liu et al. Oblivious Neural Network Predictions via MiniONN transformations.', 'The paper presents a means of evaluating a neural network securely using homomorphic encryption. A neural network is already trained, and its weights are public. The network is to be evaluated over a private input, so that only the final outcome of the computation-and nothing but that-is finally learned.\n\nThe authors take a binary-circuit approach: they represent numbers via a fixed point binary representation, and construct circuits of secure adders and multipliers, based on homomorphic encryption as a building block for secure gates. This allows them to perform the vector products needed per layer; two\'s complement representation also allows for an ""easy"" implementation of the ReLU activation function, by ""checking"" (multiplying by) the complement of the sign bit. The fact that multiplication often involves public weights is used to speed up computations, wherever appropriate. A rudimentary  experimental evaluation with small networks is provided.\n\nAll of this is somewhat straightforward; a penalty is paid by representing numbers via fixed point arithmetic, which is used to deal with ReLU mostly. This is somewhat odd: it is not clear why, e.g., garbled circuits where not used for something like this, as it would have been considerably faster than FHE.\n\nThere is also a work in this area that the authors do not cite or contrast to, bringing the novelty into question; please see the following papers and references therein:\n\nGILAD-BACHRACH, R., DOWLIN, N., LAINE, K., LAUTER, K., NAEHRIG, M., AND WERNSING, J. Cryptonets: Applying neural networks to encrypted data with high throughput and accuracy. In Proceedings of The 33rd International Conference on Machine Learning (2016), pp. 201–210.\n\nSecureML: A System for Scalable Privacy-Preserving Machine Learning\nPayman Mohassel and Yupeng Zhang\n\nSHOKRI, R., AND SHMATIKOV, V. Privacy-preserving deep learning. In\nProceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security (2015), ACM, pp. 1310–1321.\n\nThe first paper is the most related, also using homomorphic encryption, and seems to cover a superset of the functionalities presented here (more activation functions, a more extensive analysis, and faster decryption times). The second paper uses arithmetic circuits rather than HE, but actually implements training an entire neural network securely.\n\n Minor details:\n\nThe problem scenario states that the model/weights is private, but later on it ceases to be so (weights are not encrypted).\n\n""Both deep learning and FHE are relatively recent paradigms"". Deep learning is certainly not recent, while Gentry\'s paper is now 7 years old.\n\n""In theory, this system alone could be used to compute anything securely."" This is informal and incorrect. Can it solve the halting problem?\n\n""However in practice the operations were incredibly slow, taking up to 30 minutes in some cases."" It is unclear what operations are referred to here.\n\n\n\n\n\n\n\n\n']","[80, -20, -50]","[70, 60, 20]","[""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, using phrases like 'well laid research methodology', 'well thought off decisions', and 'fine work'. The overall tone is very positive, with only one minor concern mentioned at the end. The politeness score is 70 (polite) as the reviewer uses respectful and professional language throughout, offering praise and constructive feedback. They use phrases like 'well organized' and 'clearly explained', which are polite ways to commend the authors. The reviewer also tactfully presents their concern and notes minor corrections, maintaining a courteous tone. The scores are not 100 in either case due to the slight criticism and the professional, rather than overly effusive, nature of the praise."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., appreciating the discussion of optimizations), they also express several criticisms and recommendations for improvement. The reviewer suggests toning down claims, comparing with existing work, and providing more experimental comparisons. These critiques indicate that the reviewer sees significant room for improvement in the paper.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and constructive language throughout. They use phrases like 'I recommend' and 'I appreciate' which are polite ways to offer suggestions and praise. The criticisms are presented as recommendations rather than harsh judgments. The reviewer also provides specific references to support their points, which is a courteous way to offer critique in academic discourse."", ""The sentiment score is -50 because the review is generally critical of the paper. The reviewer points out several limitations and questions the novelty of the work, citing other papers that cover similar or more extensive ground. They also highlight some inaccuracies in the paper's statements. However, it's not entirely negative as they do acknowledge some aspects of the work, hence not a lower score. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'somewhat straightforward' and 'somewhat odd' rather than more harsh language. They also provide constructive feedback by suggesting alternative approaches and pointing out relevant literature. The reviewer's language is not overtly polite, but it's not rude either, maintaining a neutral to slightly polite tone typical of academic reviews.""]"
"['This paper presents an algorithm for clustering using DNNs. The algorithm essentially alternates over two steps: a step that trains the DNN to predict random targets, and another step that reassigns the targets based on the overall matching with the DNN outputs. The second step also shrinks the number of targets over time to achieve clustering. Intuitively, the randomness in target may achieve certain regularization effect.\n\nMy concerns:\n1. There is no analysis on what the regularization effect is. What advantage does the proposed algorithm offer to an user that a more deterministic algorithm cannot?\n2. The delete-and-copy step also introduces randomness, and since the algorithm removes targets over time, it is not clear if the algorithm consistently optimizes one objective throughout. Without a consistent objective function, the algorithm seems somewhat heuristic.\n3. Due to the randomness from multiple operations, the experiments need to be run multiple times, and see if the output clustering is sensitive to it. If it turns out the algorithm is quite robust to the randomness, it is then an interesting question why this is the case.\n4. Does the  Hungarian algorithm used for matching scales to much larger datasets?\n5. While the algorithm empirically improve over k-means, I believe at this point combinations of DNN with classical clustering algorithms already exist and comparisons with such stronger baselines are missing. The authors have listed a few related algorithms in the last paragraph on page 1. I think the following one is also relevant:\n-- Law et al. Deep spectral clustering learning. ICML 2015.\n\n', 'This ms presents a new clustering method which combines deep autoencoder and a recent unsupervised representation learning approach (NAT; Bojanowski and Joujin 2017). The proposed method can jointly learn latent features and the cluster assignments. Then the method is tested in several image and text data sets.\n\nI have the following concerns:\n\n1) The paper is not self-contained. The review of NAT is too brief and makes it too hard to understand the remaining of the paper. Because NAT is a fundamental starting point of the work, it will be nice to elaborate the NAT method to be more understandable.\n\n2) Predicting the noise has no guarantee that the data items are better clustered in the latent space. Especially, projecting the data points to a uniform sphere can badly blur the cluster boundaries.\n\n3) How should we set the parameter lambda? Is it data dependent?\n\n4) The experimental results are a bit less satisfactory:\na) It is known that unsupervised clustering methods can achieve 0.97 accuracy for MNIST. See for example [Ref1, Ref2, Ref3].\nb) Figure 3 is not satisfactory. Actually t-SNE on raw MNIST pixels is not bad at all. See https://sites.google.com/site/neighborembedding/mnist\nc) For 20 Newsgroups dataset, NATAC achieves 0.384 NMI. By contrast, the DCD method in [Ref3] can achieve 0.54.\n\n5) It is not clear how to set the number of clusters. More explanations are appreciated.\n\n[Ref1] Zhirong Yang, Tele Hao, Onur Dikmen, Xi Chen, Erkki Oja. Clustering by Nonnegative Matrix Factorization Using Graph Random Walk. In NIPS 2012.\n[Ref2] Xavier Bresson, Thomas Laurent, David Uminsky, James von Brecht. Multiclass Total Variation Clustering. In NIPS 2013.\n[Ref3] Zhirong Yang, Jukka Corander and Erkki Oja. Low-Rank Doubly Stochastic Matrix Decomposition for Cluster Analysis. Journal of Machine Learning Research, 17(187): 1-25, 2016.', 'This paper proposes a neural clustering model following the ""Noise as Target"" technique. Combining with an reconstruction objective and ""delete-and-copy"" trick, it is able to cluster the data points into different groups and is shown to give competitive results on different benchmarks.\n\nIt is nice that the authors tried to extend the ""noise as target"" to the clustering problem, and proposed the simple ""delete-and-copy"" technique to group different data points into clusters. Even tough a little bit ad-hoc, it seems promising based on the experiment results. However, it is unclear to me why it is necessary to have the optimal matching here and why the simple nearest target would not work. After all, the cluster membership is found based on the nearest target in the test stage. \n\nAlso, the authors should provide more detailed description regarding the scheduling of the alpha and lambda values during training, and how sensitive it is to the final clustering performance. The authors cited the no requirement of ""a predefined number of clusters"" as one of the contributions, but the tuning of alpha seems more concerning.\n\nI like the authors experimented with different benchmarks, but lack of comparisons with existing deep clustering techniques is definitely a weakness. The only baseline comparison provided is the k-means clustering, but the comparisons were somewhat unfair. For all the text datasets, there were no comparisons with k-means on the features learned from the auto-encoders or clusterings learned from similar number of clusters. The comparisons for the Twitter dataset were even based on character-level with word-level. It is more convincing to show the superiority of the proposed method than existing ones on the same ground.\n\nSome other issues regarding quantitative results:\n- In Table 1, there are 152 clusters for 10-d latent space after convergence, but there are 61 clusters for 10-d latent space in Table 2 for the same MNIST dataset. Are they based on different alpha and lambda values? \n- Why does NATAC perform much better than NATAC-k? Would NATAC-k need a different number of clusters than the one from NATAC? The number of centroids learned from NATAC may not be good for k-means clustering.\n- It seems like the performance of AE-k is increasing with increase of dimensionality of latent space for Fashion-MNIST. Would AE-k beat NATAC with a different dimensionality of latent space and k?']","[-20, -30, -20]","[50, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution, they express several concerns and point out missing elements in the analysis and experiments. The review starts with a neutral summary but then lists five specific concerns, indicating a somewhat critical stance. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They present their concerns as questions or suggestions rather than harsh criticisms, and use phrases like 'My concerns' and 'I believe' which maintain a polite tone. The reviewer also offers constructive feedback by suggesting additional comparisons and relevant literature, which contributes to the politeness of the review."", ""The sentiment score is -30 because while the reviewer acknowledges the novelty of the method, they express several significant concerns about the paper's content and results. The review starts neutrally but quickly moves to a list of issues, indicating a generally negative sentiment. However, it's not extremely negative as the reviewer offers constructive feedback. The politeness score is 50 because the reviewer uses professional and respectful language throughout. They frame their concerns as 'I have the following concerns' rather than using harsh or dismissive language. The reviewer also offers suggestions for improvement and cites relevant literature, which is helpful and courteous. While not overly warm, the tone remains consistently polite and constructive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice that the authors tried', 'seems promising'), there are several criticisms and concerns raised. The reviewer points out unclear aspects, lack of comparisons with existing techniques, and questions about the results. The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (60) as the reviewer uses polite language throughout, such as 'It is nice that', 'I like', and frames criticisms as questions or suggestions rather than direct attacks. The reviewer maintains a professional and constructive tone, even when pointing out weaknesses in the paper.""]"
"['In the medical context, this paper describes the classic problem of ""knowledge base completion"" from structured data only (no text).  The authors argue for the advantages of a generative VAE approach (but without being convincing).  They do not cite the extensive literature on KB completion.  They present experimental results on their own data set, evaluating only against simpler baselines of their own VAE approach, not the pre-existing KB methods.\n\nThe authors seem unaware of a large literature on ""knowledge base completion.""  E.g. [Bordes, Weston, Collobert, Bengio, AAAI, 2011],  [Socher et al 2013 NIPS], [Wang, Wang, Guo 2015 IJCAI], [Gardner, Mitchell 2015 EMNLP], [Lin, Liu, Sun, Liu, Zhu AAAI 2015], [Neelakantan, Roth, McCallum 2015], \n\nThe paper claims that operating on pre-structured data only (without using text) is an advantage.  I don\'t find the argument convincing.  There are many methods that can operate on pre-structured data only, but also have the ability to incorporate text data when available, e.g. ""universal schema"" [Riedel et al, 2014].\n\nThe paper claims that ""discriminative approaches"" need to iterate over all possible entity pairs to make predictions.  In their generative approach they say they find outputs by ""nearest neighbor search.""  But the same efficient search is possible in many of the classic ""discriminatively-trained"" KB completion models also.\n\nIt is admirable that the authors use an interesting (and to my knowledge novel) data set.  But the method should also be evaluated on multiple now-standard data sets, such as FB15K-237 or NELL-995.  The method is evaluated only against their own VAE-based alternatives.  It should be evaluated against multiple other standard KB completion methods from the literature, such as Jason Weston\'s Trans-E, Richard Socher\'s Tensor Neural Nets, and Neelakantan\'s RNNs.\n', 'SUMMARY.\n\nThe paper presents a variational autoencoder for generating entity pairs given a relation in a medical setting.\nThe model strictly follows the standard VAE architecture with an encoder that takes as input an entity pair and a relation between the entities.\nThe encoder maps the input to a probabilistic latent space.\nThe latent variables plus a one-hot-encoding representation of the relation is used to reconstruct the input entities.\nFinally, a generator is used to generate entity pairs give a relation.\n\n----------\n\nOVERALL JUDGMENT\nThe paper presents a clever use of VAEs for generating entity pairs conditioning on relations.\nMy main concern about the paper is that it seems that the authors have tuned the hyperparameters and tested on the same validation set.\nIf this is the case, all the analysis and results obtained are almost meaningless.\nI suggest the authors make clear if they used the split training, validation, test.\nUntil then it is not possible to draw any conclusion from this work.\n\nAssuming the experimental setting is correct, it is not clear to me the reason of having the representation of r (one-hot-vector of the relation) also in the decoding/generation part.\nThe hidden representation obtained by the encoder should already capture information about the relation.\nIs there a specific reason for doing so?\n\n', 'The authors suggest using a variational autoencoder to infer binary relationships between medical entities. The model is quite simple and intuitive and the authors demonstrate that it can generate meaningful relationships between pairs of entities that were not observed before.  \nWhile the paper is very well-written I have certain concerns regarding the motivation, model, and evaluation methodology followed:\n\n1) A stronger motivation for this model is required. Having a generative model for causal relationships between symptoms and diseases is ""intriguing"" yet I am really struggling with the motivation of getting such a model from word co-occurences in a medical corpus. I can totally buy the use of the proposed model as means to generate additional training data for a discriminative model used for information extraction but the authors need to do a better job at explaining the downstream applications of their model. \n\n2) The word embeddings used seem to be sufficient to capture the ""knowledge"" included in the corpus. An ablation study of the impact of word embeddings on this model is required. \n\n3) The authors do not describe how the data from xywy.com were annotated. Were they annotated by experts in the medical domain or random users?\n\n4) The metric of quality is particularly ad-hoc. Meaningful relationships in a medical domain and evaluation using random amazon mechanical turk workers do not seem to go well together. \n\n5) How does the proposed methods compare against a simple trained extractor? For instance one can automatically extract several linguistic features of the sentences two known related entities appeared with and learn how to extract data. The authors need to compare against such baselines or justify why they cannot be used.\n']","[-60, -20, -20]","[-20, 50, 60]","[""The sentiment score is -60 because the reviewer expresses significant criticisms of the paper, including lack of awareness of existing literature, unconvincing arguments, and limited evaluation. The tone is generally negative, though not entirely dismissive. The politeness score is -20 as the language is direct and critical without using overtly polite phrasing, but also avoids rudeness. The reviewer uses phrases like 'The authors seem unaware' and 'I don't find the argument convincing' which are somewhat blunt. However, there is one positive note about the 'admirable' use of a novel dataset, slightly softening the overall tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'clever', they express significant concerns about the experimental methodology, stating that if hyperparameters were tuned on the validation set, 'all the analysis and results obtained are almost meaningless'. This major criticism outweighs the initial positive comment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh judgments. They use phrases like 'I suggest' and ask questions for clarification, maintaining a professional and courteous tone even while expressing concerns."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and the model is 'simple and intuitive', they express several concerns about the motivation, model, and evaluation methodology. The reviewer uses phrases like 'I have certain concerns' and 'I am really struggling with the motivation', indicating a generally critical stance. However, the criticism is balanced with some positive remarks, preventing a more negative score. The politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout. They use polite language such as 'The authors suggest' and 'The authors need to do a better job', offering constructive criticism rather than harsh judgments. The reviewer also acknowledges positive aspects before presenting concerns, which is a polite approach to feedback.""]"
"[""The paper investigates a method of data augmentation for image classification, where two images from the training set are averaged together\xa0as input, but the label from only one image is used as a target.  Since this scheme is asymmetric and uses quite unrealistic input images, a training scheme is used where the technique is only enabled in the middle of training (not very beginning or end), and in an alternating on-off fashion.  This improves classification performance nicely on a variety of datasets.\n\nThis is a simple technique, and the paper is concise and to the point.  However, I would have liked to see a few additional comparisons.\n\nFirst, this augmentation technique seems to have two components:  One is the mixing of inputs, but another is the effective dropping of labels from one of the two images in the pair.  Which of these are more important, and can they be separated?  What if some of the images' labels are changed at random, for half the images in a minibatch, for example?  This would have the effect of random label changes, but without the input mixing.  Likewise, what if both labels in the pair are used as targets (with 0.5 assigned to each in the softmax target)?  This would mix the images, but keep targets intact.\n\nSecond, the bottom of p.3 says that multiple training procedures were evaluated, but I'd be interested to see the results of some of these.  In particular, is it important to alternate enabling and disabling SamplePairing, or does it also work to mix samples with and without it in each minibatch (e.g. 3/4 of the minibatch with pairing augmentation, and 1/4 without it)?\n\nI liked the experiment mixing images from within a restricted training set composed of a subset of the CIFAR images, compared to mixing these images with CIFAR training set images outside the restricted sample (p.5 and Fig 5).  This suggests to me, however, that it's possible the label manipulations may play an important role.  Or, is an explanation why this performs not as well that the network will train these mixing images to random targets (that of the training image in the pair), and never see this example again, whereas by using the training set alone, the mixing image is likely to be repeated with its correct label?  Some more discussion on this would be nice.\n\nOverall, I think this is an interesting technique that appears to achieve nice results.  It could be investigated deeper at some key points.\n"", 'The paper reports that averaging pairs of training images improves image classification generalization in many datasets. \nThis is quite interesting. The paper is also straightforward to read and clear, which is positive. Overall i think the finding is of sufficient interest for acceptance.\n\nThe paper would benefit from adding some speculation on reasons why this phenomenon occurs.\nThere are a couple of choices that would benefit from more explanation / analysis:  a) averaging, then forcing the classifier to pick one of the two classes present; why not pick both? b) the choice of hard-switching between sample pairing and regular training - it would be interesting if sample-pairing as an augmentation meshed better with other augmentations implementation-wise, so that it could be easier to integrate in other frameworks.', 'The paper proposes a new data augmentation technique based on picking random image pairs and producing \na new average image which is associated with the label of one of the two original samples. The experiments show\nthat this strategy allows to reduce the risk of overfitting especially in the case of a limited amount of training \nsamples or in experimental settings with a small number of categories.\n\n+ The paper is easy to read: the method and the experiments are explained clearly.\n\n- the method is presented as a heuristic technique. \n1) The training process has some specific steps with the Sample Pairing intermittently disabled. \nThe number of epochs with enabled or disabled Sample Pairing changes depending on the dataset.\nHow much si the method robust/sensitive to variations on these choices?\n2) There is no specific analysis on the results besides showing the validation and training errors: would it\nbe possible to see the results per class? Would the confusion matrices reveal something more about the\neffect of the method?  Does Sample Pairing help to differentiate similar categories even if they are mixed\nat trainign time?\n3)  Would it be possible to better control the importance of each sample label rather\nthan always choosing one of the two as ground truth? \n\nThe paper misses an in-depth analysis of the proposed practical strategy.\n\n']","[60, 70, 20]","[70, 60, 60]","[""The sentiment score is 60 (positive) because the reviewer expresses overall positive sentiment towards the paper, describing it as 'interesting' with 'nice results'. They appreciate the conciseness and the experiments conducted. However, it's not extremely positive as they suggest additional comparisons and deeper investigation. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They use phrases like 'I would have liked to see' and 'I think this is an interesting technique' which are polite ways of providing feedback. The reviewer also acknowledges the positive aspects of the paper before suggesting improvements, which is a polite approach to reviewing."", ""The sentiment score is 70 (positive) because the reviewer expresses interest in the paper's findings, calling them 'quite interesting' and stating that the paper is 'straightforward to read and clear'. The reviewer also recommends acceptance, indicating a positive overall sentiment. However, it's not 100 as there are suggestions for improvement. The politeness score is 60 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than criticisms. Phrases like 'The paper would benefit from' and 'it would be interesting if' indicate a polite tone. The score isn't higher as the language, while polite, is not excessively formal or deferential."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some positive aspects of the paper, such as its readability and clear explanations. However, they also point out several limitations and areas for improvement, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing their criticisms as questions or suggestions rather than direct criticisms. They begin with positive comments before moving on to areas of concern, which is a polite approach. The reviewer's tone is professional and constructive, offering specific recommendations for improvement without being harsh or dismissive.""]"
"[""In this paper, the authors consider the problem of generating a training data set for the neural programmer-interpreter from an executable oracle. In particular, they aim at generating a complete set that fully specifies the behavior of the oracle. The authors propose a technique that achieves this aim by borrowing ideas from programming language and abstract interpretation. The technique systematically interacts with the oracle using observations, which are abstractions of environment states, and it is guaranteed to produce a data set that completely specifies the oracle. The authors later describes how to improve this technique by further equating certain observations and exploring only one in each equivalence class. Their experiments show that this improve technique can produce complete training sets for three programs.\n\nIt is nice to see the application of ideas from different areas for learning-related questions. However, there is one thing that bothers me again and again. Why do we need a data-generation technique in the paper at all? Typically, we are given a set of data, not an oracle that can generate such data, and our task is to learn something from the data. If we have an executable oracle, it is now clear to me why we want to replicate this oracle by an instance of the neural programmer-interpreter. One thing that I can see is that the technique in the paper can be used when we do research on the neural programmer-interpreter. During research, we have multiple executable oracles and need to produce good training data from them. The authors' technique may let us do this data-generation easily. But this benefit to the researchers does not seem to be strong enough for the acceptance at ICLR'18.\n\n "", 'Quality\nThe paper is well-written and clear, and includes relevant comparisons to previous work (NPI and recursive NPI).\n\nClarity\nThe paper is clearly written.\n\nOriginality\nTo my knowledge the method proposed in this work is novel. It is the first to study constructing minimal training sets for NPI given a black-box oracle. However, as pointed out by the authors, there is a lot of similar prior work in software testing.\n\nSignificance\nThe work could be potentially significant, but there are some very strong assumptions made in the paper that could limit the impact. If the NPI has access to a black-box oracle, it is not clear what is the use of training an NPI in the first place. It would be very helpful to describe a potential scenario where the proposed approach could be useful. Also, it is assumed that the number of possible inputs is finite (also true for the recursive NPI paper), and it is not clear what techniques or lessons of this paper might transfer to tasks with perceptual inputs. The main technical contribution is the search procedure to find minimal training sets and pare down the observation size, and the empirical validation of the idea on several algorithmic tasks.\n\nPros\n- Greatly improves the data efficiency of recursive NPI.\n- Training and verification sets are automatically generated by the proposed method.\n\nCons\n- Requires access to a black-box oracle to construct the dataset.\n- Not clear that the idea will be useful in more complex domains with unbounded inputs.\n', ""Previous work by Cai et al. (2017) shows how to use Neural Programmer-Interpreter (NPI) framework to prove correctness of a learned neural network program by introducing recursion. It requires generation of a diverse training set consisting of execution traces which describe in detail the role of each function in solving a given input problem. Moreover, the traces need to be recursive: each function only takes a finite, bounded number of actions. In this paper, the authors show how training set can be generated automatically satisfying the conditions of Cai et al.'s paper. They iteratively explore all\npossible behaviors of the oracle in a breadth-first manner, and the bounded nature of the recursive\noracle ensures that the procedure converges. As a running example, they show how this can be be done for bubblesort. The training set generated in this process may have a lot of duplicates, and the authors show how these duplicates can possibly be removed. It indeeds shows a dramatic reduction in the number of training samples for the three experiments that have been shown in the paper. \n\nI am not an expert in this area, so it is difficult for me to judge the technical merit of the work. My feeling from reading the paper is that it is rather incremental over Cai et al. I am impressed by the results of the three experiments that have been shown here, specifically, the reduction in the training samples once they have been generated is significant. But these are also the same set of experiments performed by Cai et al. \n\nGiven the original number of traces generated is huge, I do not understand, why this method is at all practical. This also explains why the authors have just tested the performance on extremely small sized data. It will not scale. So, I am hesitant accepting the paper. I would have been more enthusiastic if the authors had proposed a way to combine the training space exploration as well as removing redundant traces together to make the whole process more scalable and done experiments on reasonably sized data. ""]","[-20, 50, -30]","[50, 75, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('It is nice to see...'), they express significant doubts about the necessity and impact of the work ('Why do we need a data-generation technique in the paper at all?', 'this benefit to the researchers does not seem to be strong enough for the acceptance'). The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms as personal observations ('However, there is one thing that bothers me...', 'It is now clear to me why...'). The reviewer maintains a professional tone without using harsh or dismissive language, even when expressing concerns."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths (well-written, clear, novel method, potential significance) while also pointing out limitations and areas for improvement. The review begins with positive comments and lists pros, but also includes cons and suggestions for enhancement, indicating a balanced but generally favorable view. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' contributions, and frames criticisms constructively. The reviewer uses phrases like 'well-written,' 'clearly written,' and 'could be potentially significant,' which contribute to a polite tone. Even when discussing limitations, the reviewer maintains a professional and courteous approach, suggesting improvements rather than harshly criticizing."", ""The sentiment score is -30 because the reviewer expresses hesitation in accepting the paper, citing concerns about its practicality and scalability. They acknowledge some positive aspects (e.g., impressive results in reducing training samples) but overall seem unimpressed, calling the work 'rather incremental.' The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging their own limitations ('I am not an expert in this area') and offering constructive feedback. They avoid harsh criticism and use phrases like 'I would have been more enthusiastic if...' to suggest improvements politely. The tone is professional and considerate, even while expressing reservations about the paper.""]"
"[""The focus of the paper is independent component analysis (ICA) and its nonlinear variants such as the post non-linear (PNL) ICA model. Motivated by the fact that estimating mutual information and similar dependency measures require density estimates and hard to optimize, the authors propose a Wasserstein GAN (generative adversarial network) based solution to tackle the problem, with illustrations on 6 (synthetic) and 3-dimemensional (audio) examples. The primary idea of the paper is to use the Wasserstein distance as an independence measure of the estimated source coordinates, and optimize it in a neural network (NN) framework.\n\nAlthough finding novel GAN applications is an exciting topic, I am not really convinced that ICA with the proposed Wasserstein GAN based technique fulfills this goal.\n \nBelow I detail my reasons:\n\n1)The ICA problem can be formulated as the minimization of pairwise mutual information [1] or one-dimensional entropy [2]. In other words, estimating the joint dependence of the source coordinates is not necessary; it is worthwhile to avoid it.\n\n2)The PNL ICA task can be efficiently tackled by first 'removing' the nonlinearity followed by classical linear ICA; see for example [3].\n\n3)Estimating information theoretic (IT) measures (mutual information, divergence) is a quite mature field with off-the-self techniques, see for example [4,5,6,8]. These methods do not estimate the underlying densities; it would be superfluous (and hard).\n\n4)Optimizing non-differentiable IT measures can computationally quite efficiently carried out in the ICA context by e.g., Givens rotations [7]; differentiable ICA cost functions can be robustly handled by Stiefel manifold methods; see for example [8,9].\n\n5)Section 3.1: This section is devoted to generating samples from the product of the marginals, even using separate generator networks. I do not see the necessity of these solutions; the subtask can be solved by independently shuffling all the coordinates of the sample.\n\n6)Experiments (Section 6): \ni) It seems to me that the proposed NN-based technique has some quite serious divergence issues: 'After discarding diverged models, ...' or 'Unfortunately, the model selection procedure also didn't identify good settings for the Anica-g model...'.\nii) The proposed method gives pretty comparable results to the chosen baselines (fastICA, PNLMISEP) on the selected small-dimensional tasks. In fact, [7,8,9] are likely to provide more accurate (fastICA is a simple kurtosis based method, which is \na somewhat crude 'estimate' of entropy) and faster estimates; see also 2).\n\nReferences:\n[1] Pierre Comon. Independent component analysis, a new concept? Signal Processing, 36:287-314, 1994.\n[2] Aapo Hyvarinen and Erkki Oja. Independent Component Analysis: Algorithms and Applications. Neural Networks, 13(4-5):411-30, 2000. \n[3] Andreas Ziehe, Motoaki Kawanabe, Stefan Harmeling, and Klaus-Robert Muller. Blind separation of postnonlinear mixtures using linearizing transformations and temporal decorrelation. Journal of Machine Learning Research, 4:1319-1338, 2003.\n[4] Barnabas Poczos, Liang Xiong, and Jeff Schneider. Nonparametric divergence: Estimation with applications to machine learning on distributions. In Conference on Uncertainty in Artificial Intelligence, pages 599-608, 2011.\n[5] Arthur Gretton, Karsten M. Borgwardt, Malte J. Rasch, Bernhard Scholkopf, Alexander Smola. A Kernel Two-Sample Test. Journal of Machine Learning Research, 13:723-773, 2012.\n[6] Alan Wisler, Visar Berisha, Andreas Spanias, Alfred O. Hero. A data-driven basis for direct estimation of functionals of distributions. TR, 2017. (https://arxiv.org/abs/1702.06516) \n[7] Erik G. Learned-Miller, John W. Fisher III. ICA using spacings estimates of entropy. Journal of Machine Learning Research, 4:1271-1295, 2003.\n[8] Francis R. Bach. Michael I. Jordan. Kernel Independent Component Analysis. Journal of Machine Learning Research 3: 1-48, 2002.\n[9] Hao Shen, Stefanie Jegelka and Arthur Gretton. Fast Kernel-Based Independent Component Analysis, IEEE Transactions on Signal Processing, 57:3498-3511, 2009.\n"", 'The paper proposes a GAN variant for solving the nonlinear independent component analysis (ICA) problem. The method seems interesting, but the presentation has a severe lack of focus.\n\nFirst, the authors should focus their discussion instead of trying to address a broad range of ICA problems from linear to post-nonlinear (PNL) to nonlinear. I would highly recommend the authors to study the review ""Advances in Nonlinear Blind Source Separation"" by Jutten and Karhunen (2003/2004) to understand the problems they are trying to solve.\n\nLinear ICA is a solved problem and the authors do not seem to be able to add anything there, so I would recommend dropping that to save space for the more interesting material.\n\nPNL ICA is solvable and there are a number of algorithms proposed for it, some cited already in the above review, but also more recent ones. From this perspective, the presented comparison seems quite inadequate.\n\nFully general nonlinear ICA is ill-posed, as shown already by Darmois (1953, doi:10.2307/1401511). Given this, the authors should indicate more clearly what is their method expected to do. There are an infinite number of nonlinear ICA solutions - which one is the proposed method going to return and why is that relevant? There are fewer relevant comparisons here, but at least Lappalainen and Honkela (2000) seem to target the same problem as the proposed method.\n\nThe use of 6 dimensional example in the experiments is a very good start, as higher dimensions are quite different and much more interesting than very commonly used 2D examples.\n\nOne idea for evaluation: comparison with ground truth makes sense for PNL, but not so much for general nonlinear because of unidentifiability. For general nonlinear ICA you could consider evaluating the quality of the estimated low-dimensional data manifold or evaluating the mutual information of separated sources on new test data.\n\nUpdate after author feedback: thanks for the response and the revision. The revision seems more cosmetic and does not address the most significant issues so I do not see a need to change my evaluation.', ""\nThe idea of ICA is constructing a mapping from dependent inputs to outputs (=the derived features) such that the outputs are as independent as possible. As the input/output densities are often not known and/or are intractable, natural independence measures such as mutual information are hard to estimate. In practice, the independence is characterized by certain functions of higher order moments -- leading to several alternatives in a zoo of independence objectives.  \n\nThe current paper makes the iteresting observation that independent features can also be computed via adversarial objectives. The key idea of adversarial training is adapted in this context as comparing samples from the joint distribution and the product of the marginals. \n\nTwo methods are proposed for drawing samples from the products of marginals. \nOne method is generating samples but permuting randomly the sample indices for individual marginals - this resampling mechanism generates approximately independent samples from the product distribution. The second method is essentially samples each marginal separately. \n\nThe approach is demonstrated in the solution of both linear and non-linear ICA problems.\n\nPositive:\nThe paper is well written and easy to follow on a higher level. GAN's provide a fresh look at nonlinear ICA and the paper is certainly thought provoking. \n\n\nNegative:\nMost of the space is devoted for reviewing related work and motivations, while the specifics of the method are described relatively short in section 4. There is no analysis and the paper is \nsomewhat anecdotal. The simulation results section is limited in scope. The sampling from product distribution method is somewhat obvious.\n\n\nQuestions:\n\n- The overcomplete audio source separation case is well known for audio and I could not understand why a convincing baseline can not be found. Is this due to nonlinear mixing?\nAs 26 channels and 6 channels are given, a simple regularization based method can be easily developed to provide a baseline performance, \n\n\n- The need for normalization in section 4 is surprising, as it obviously renders the outputs dependent. \n\n- Figure 1 may be misleading as h are not defined \n""]","[-60, -50, 20]","[20, 20, 60]","[""The sentiment score is -60 because the reviewer expresses significant skepticism about the paper's approach and contributions. They state they are 'not really convinced' by the proposed method and provide a detailed list of criticisms. However, they do acknowledge that 'finding novel GAN applications is an exciting topic', which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I am not really convinced' and 'It seems to me' rather than making blunt negative statements. They also provide detailed explanations and references to support their critiques, which is a respectful approach. However, the overall critical nature of the review prevents the politeness score from being higher."", ""The sentiment score is -50 because the review is generally critical, pointing out several shortcomings in the paper's focus and methodology. However, it's not entirely negative as it acknowledges the method as 'interesting' and praises the use of 6-dimensional examples. The politeness score is 20 because while the reviewer is direct in their criticism, they use polite language such as 'I would highly recommend' and 'thanks for the response'. They also offer constructive suggestions for improvement rather than just criticism. The reviewer maintains a professional tone throughout, even when pointing out significant issues."", ""The sentiment score is slightly positive (20) because the review begins with a positive tone, describing the paper as 'interesting' and 'thought provoking'. However, it also includes significant criticisms, such as the limited scope of simulation results and lack of analysis. The overall sentiment is therefore mildly positive. The politeness score is moderately high (60) because the reviewer uses respectful language throughout, even when offering criticisms. They describe the paper as 'well written' and 'easy to follow', and frame their criticisms as observations rather than harsh judgments. The questions at the end are posed in a neutral, inquisitive manner rather than confrontationally.""]"
"[""Summary: \nThe paper extends the the recently proposed Boundary Equilibrium Generative Adversarial Networks (BEGANs), with the hope of generating images which are more realistic. In particular, the authors propose to change the energy function associated with the auto-encoder, from an L2 norm (a single number) to an energy function with multiple components. Their energy function is inspired by the structured similarity index (SSIM), and the three components they use are the L1 score, the gradient magnitude similarity score, and the chromium score. Using this energy function, the authors hypothesize, that it will force the generator to generate realistic images. They test their hypothesis on a single dataset, namely, the CelebA dataset. \n\nReview: \nWhile the idea proposed in the paper is somewhat novel and there is nothing obviously wrong about the proposed approach, I thought the paper is somewhat incremental. As a result I kind of question the impact of this result. My suspicion is reinforced by the fact that the experimental section is extremely weak. In particular the authors test their model on a single relatively straightforward dataset. Any reason why the authors did not try on other datasets involving natural images? As a result I feel that the title and the claims in the paper are somewhat misleading and premature: that the proposed techniques improves the training and evaluation of energy based gans. \n\nOver all the paper is clearly written and easy to understand. \n\nBased on its incremental nature and weak experiments, I'm on the margin with regards to its acceptance. Happy to change my opinion if other reviewers strongly think otherwise with good reason and are convinced about its impact. "", 'This paper proposed some new energy function in the BEGAN (boundary equilibrium GAN framework), including l_1 score, Gradient magnitude similarity score, and chrominance score, which are motivated and borrowed from the image quality assessment techniques. These energy component in the objective function allows learning of different set of features and determination on whether the features are adequately represented. experiments on the using different hyper-parameters of the energy function, as well as visual inspections on the quality of the learned images, are presented. \n\nIt appears to me that the novelty of the paper is limited, in that the main approach is built on the existing BEGAN framework with certain modifications. For example, the new energy function in equation (4) larges achieves similar goal as the original energy (1) proposed by Zhao et. al (2016), except that the margin loss in (1) is changed to a re-weighted linear loss, where the dynamic weighting scheme of k_t is borrowed  from the work of Berthelot et. al (2017). It is not very clear why making such changes in the energy would supposedly make the results better, and no further discussions are provided.  On the other hand, the several energy component introduced are simply choices of the similarity measures as motivated from the image quality assessment, and there are probably a lot more in the literature whose application can not be deemed as a significant contribution to either theories or algorithm designs in GAN.\n\nMany results from the experimental section rely on visual evaluations, such as in Figure~4 or 5; from these figures, it is difficult to clearly pick out the winning images. In Figure~5, for a fair  evaluation on the performance of model interploations, the same human model should be used for competing methods, instead of applying different human models and different interpolation tasks in different methods. \n ', 'Quick summary:\nThis paper proposes an energy based formulation to the BEGAN model and modifies it to include an image quality assessment based term. The model is then trained with CelebA under different parameters settings and results are analyzed.\n\nQuality and significance:\nThis is quite a technical paper, written in a very compressed form and is a bit hard to follow. Mostly it is hard to estimate what is the contribution of the model and how the results differ from baseline models.\n\nClarity:\nI would say this is one of the weak points of the paper - the paper is not well motivated and the results are not clearly presented. \n\nOriginality:\nSeems original.\n\nPros:\n* Interesting energy formulation and variation over BEGAN\n\nCons:\n* Not a clear paper\n* results are only partially motivated and analyzed']","[-30, -30, -20]","[50, 20, 20]","[""The sentiment score is -30 because the reviewer expresses several concerns about the paper, calling it 'somewhat incremental' and questioning its impact. They also mention the 'extremely weak' experimental section and suggest the title and claims are 'misleading and premature'. However, they do acknowledge some positive aspects, such as the novelty of the idea and clear writing, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses generally respectful language, acknowledging positive aspects and expressing willingness to change their opinion. They avoid harsh criticism, instead using softer phrases like 'somewhat incremental' and 'I kind of question'. The reviewer also offers constructive feedback and expresses their opinion as a personal view rather than an absolute judgment."", ""The sentiment score is -30 because the reviewer expresses concerns about the paper's limited novelty and the lack of clear improvements over existing methods. They state that 'the novelty of the paper is limited' and question why the proposed changes would make the results better. However, the score is not extremely negative as the reviewer acknowledges some positive aspects, such as the introduction of new energy functions.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'It appears to me' and 'It is not very clear' instead of making blunt criticisms. The reviewer also provides constructive feedback and suggestions for improvement, such as recommending the use of the same human model for fair evaluation. However, the score is not extremely high as the language, while polite, is not overly deferential or complimentary."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Interesting energy formulation', 'Seems original'), they highlight more negative points. The review mentions that the paper is 'hard to follow', 'not well motivated', and 'results are not clearly presented'. The cons outweigh the pros in the reviewer's summary. The politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout. They use neutral language like 'I would say' and 'Seems original' rather than harsh criticisms. The reviewer also balances negative feedback with positive observations, which is a polite approach. However, the politeness doesn't reach a high positive score because the review is quite direct in its criticisms without much softening language.""]"
"['The paper ""CONTEXTUAL MEMORY BANDIT FOR PRO-ACTIVE DIALOG ENGAGEMENT"" proposes to address the problem of pro-active dialog engagement by the mean of a bandit framework that selects dialog situations w.r.t. to the context of the system. Authors define a neural archiecture managing memory with the mean of a contextual attention mechanism.\n\nMy main concern about this paper is that the proposal is not enough well described. A very large amount of technical details are missing for allowing the reader to understand the model (and reproduce the experiments). The most important ones are about the exploration policies which are not described at all, while it is a very central point of the paper. The only discussion given w.r.t. the exploration policy is a very general overview about Thompson Sampling. But nothing is said about how it is implemented in the case of the proposed model. How is estimated p(\\Theta|D) ? Ok  authors give p(\\Theta|D) as a product between prior and likelihood. But it is not sufficient to get p(\\Theta|D), the evidence should also been considered (for instance by using variational inference). Also, what is the prior of the parameters ? How is distributed r given a,x and \\Theta ? \n\nAlso, not enough justification is given about the general idea of the model. Authors should give more intuitions about the mechanism they propose. Figure 2 should be able to help, but no reference to this figure is given in the text, so it is very difficult to extract any information from it. Authors only (roughly) describe  the architecture without justifying their choices.\n\nAt last, the experiments really fail at demonstrating the relevance of the approach, as only questionable artificial data is used. On the first hand it appears mandatory to me to consider some (even minimal) experiments on real data for such proposal. On the other one, the simulated data used there cannot correspond to cues to validate the approach since they appear very far from real scenarios: the trajectories do not depend on what is recommended. Ok only the recommended places reveal some reward but it appears not as a sufficiently realistic scenario to me. Also, very too few baselines are considered: only different versions of the proposal and a random baseline are considered. A classical contextual bandit instance (such as LinUCB) would have been a minimum.\n\nOther remarks:\n      - the definition of q is not given\n      - user is part of the context x  in the bandit section but not after where it is denoted as u.\n      - the notion of time window should be more formally described\n      - How is built the context is not clear in the experiments section\n\n', 'This paper attempts to use contextual bandits for a dialog system. The paper is not clear about how exactly the problem is being mapped to the contextual bandit framework. Similarly, the Thompson sampling algorithm is used, but there is no mention of a posterior or how to sample. Furthermore, the lack of systematic experiments and ablation studies casts doubts on the entire framework. Below is a detailed review and questions for the authors:\n1. Please motivate clearly the need for having a bandit framework. One would imagine that dialog systems have a huge amount of data that can be leveraged for a pro-active service. \n2. In the sentence ""the agent needs to leverage on the already gathered feedback to choose propositions that maximize the current expected reward"". The expected reward or the agent is undefined at this point in the paper. \n3. After introducing the contextual bandit problem, please give the explicit mapping of your system to this framework. What do the arms correspond to, how are they related, how is the expected reward computed at each round? Another thing which is not clear is what is the environment? It seems that a recommendation by the dialog system will cause the environment to change, in which case it\'s not a bandit problem? Isn\'t it more natural to model this problem as a reinforcement learing problem?\n4. In the sentence, ""a record of the last K successful engagements of the agent"". It is not clear what constitutes a successful engagement. Also, please justify why you are not keeping negative examples in order to learn. \n5. Section 5 describes the Thompson sampling algorithm. Again, there is no mapping between the problem at hand and the TS framework. For instance, what is the posterior in this case. How are you sampling it? Are we being Bayesian, if so what is the prior?\n6. In the sentence ""longer patterns from series of events occurred through time can motive a suggestion"", it seems that the problem you are trying to solve involves delayed feedback. Can you use the strategies in [1] over here?\n7. For equation 8, please give some intuition. Why is it necessary?\n8. In the sentence, ""Regarding the learning algorithms, hyper-parameters have been determined by cross-validation."". Isn\'t the data is being collected on the fly in a bandit framework? What is the cross-validation being done on?\n9.One experiment on one dataset does not imply that the method is effective. Similarly, the lack of ablation studies for the various components of the system is worrying. \n[1] Guha, Sudipto, Kamesh Munagala, and Martin Pal. ""Multiarmed bandit problems with delayed feedback."" arXiv preprint arXiv:1011.1161 (2010).', 'This article propose to combine a form of contextual Thompson sampling policy with memory networks to handle dialog engagement in mobility interfaces.\n\nThe idea of using contextual bandits (especially Thompson sampling) instead of state of the art approximate RL algorithms (like DQN, AC3, or fittedQ) is surprising given the intrinsic Markovian nature of dialog. Another key difficulty of dialogs is delayed feedback. Contextual bandits are not designed to handle this delay. I saw no attempt to elaborate on that ground.\nOne possible justification, however, could be the recent theoretical works on Contextual Decision Processes (See for instance the OLIVE algorithm in ""Contextual Decision Processes with Low Bellman rank are PAC learnable"" by Jiang et al. @ NIPS 2016). A mix of OLIVE, memory networks and Thompson sampling could be worth studying.\n\nThe article is however poorly written and it reflects a severe lack of  scientific methodology : the problem statement is too vague and the experimental protocol is dubious.\n\nThe dialog engagement problem considered is a special case of reinforcement learning problem where the agent is given the option of ""doing nothing"". The authors did not explain clearly the specificity of this dialog-engagement setting with regard to other RL settings. For instance why not evaluate their algorithm on video-games where doing nothing is an option?\n\nThe authors introduce the notion of regret on page 3 but it is never used after.\nIt is unclear whether the problem considered here is purely online (cold start) or off-line (repeated training on a simulator).\n\nIn order to obtain a decent experimental protocol for their future submissions I suggest that the authors provide:\n- both offline (repeated training on simulator) and online (cold-start) experiments;\n- at least more than one dialog simulation scenario (in order to convince you reader that your experimental result is more than a side-effect of your simulator bias);\n- at least a few baselines with state of the art deep and shallow RL algorithms to justify the use of a new method.\n']","[-60, -70, -70]","[20, 20, -20]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer expresses several major concerns about the paper, including insufficient description of the model, lack of justification for the approach, and inadequate experiments. Phrases like 'My main concern,' 'not enough justification,' and 'experiments really fail at demonstrating the relevance' indicate a negative sentiment. However, it's not entirely negative as the reviewer acknowledges some aspects of the paper and provides constructive feedback, hence not reaching the lowest possible score. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'My main concern' and 'it appears mandatory to me' rather than using harsh or rude language. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism. However, the score is only slightly positive as the review doesn't include explicitly polite language or praise, focusing mainly on the paper's shortcomings."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses significant doubts about the paper's clarity, methodology, and experimental rigor. Phrases like 'not clear', 'casts doubts', and 'lack of systematic experiments' indicate strong criticism. However, it's not entirely negative as the reviewer provides constructive feedback and suggestions for improvement. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use polite phrases like 'Please motivate clearly' and 'Can you use the strategies', and frame their criticisms as questions or suggestions rather than direct attacks. The reviewer also provides specific, detailed feedback which is helpful to the authors, showing a level of engagement that can be seen as respectful. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses surprise at the chosen approach, points out several perceived flaws in the methodology, and describes the article as 'poorly written' with a 'severe lack of scientific methodology'. The few positive elements (like suggesting a possible justification) are outweighed by the criticisms. The politeness score is -20 because while the reviewer isn't overtly rude, the language is quite direct and critical. Phrases like 'poorly written' and 'severe lack of scientific methodology' are particularly harsh. However, the reviewer does offer constructive suggestions for improvement, which prevents the score from being lower.""]"
"[""The authors present two autoregressive models for sampling action probabilities from a factorized discrete action space. On a multi-agent gridworld task and a multi-agent multi-armed bandit task, the proposed method seems to benefit from their lower-variance entropy estimator for exploration bonus. A few key citations were missing - notably the LSTM model they propose is a clear instance of an autoregressive density estimator, as in PixelCNN, WaveNet and other recently popular deep architectures. In that context, this work can be viewed as applying deep autoregressive density estimators to policy gradient methods. At least one of those papers ought to be cited. It also seems like a simple, obvious baseline is missing from their experiments - simply independently outputting D independent softmaxes from the policy network. Without that baseline it's not clear that any actual benefit is gained by modeling the joint distribution between actions, especially since the optimal policy for an MDP is provably deterministic anyway. The method could even be made to capture dependencies between different actions by adding a latent probabilistic layer in the middle of the policy network, inducing marginal dependencies between different actions. A direct comparison against one of the related methods in the discussion section would help better contextualize the paper as well. A final point on clarity of presentation - in keeping with the convention in the field, the readability of the tables could be improved by putting the top-performing models in bold, and Table 2 should almost certainly be replaced by a boxplot."", 'In this paper, the authors suggest introducing dependencies between actions in RL settings with multi-dimensional action spaces by way of two mechanisms (using an RNN and making partial action specification as part of the state); they then introduce entropy pseudo-rewards whose maximization corresponding to joint entropy maximization.\n\nIn general, the multidimensional action methods either seem incremental or non novel to me. The combined use of the chain rule and RNNs (LSTM or not) to induce correlations in multi-dimensional outputs is well know (sequence-to-sequence networks, pixelRNN, etc.) and the extension to RL presents no difficulties, if it is not already known. Note very related work in https://arxiv.org/pdf/1607.07086.pdf and https://www.media.mit.edu/projects/improving-rnn-sequence-generation-with-rl/overview/ .\n\nAs for the MMDP technique, I believe it is folklore (it can for instance be found as a problem in a problem set - http://stellar.mit.edu/S/course/2/sp04/2.997/courseMaterial/topics/topic2/readings/problemset4/problemset4.pdf). Note that both approaches could be combined; the first idea is essentially a policy method, the second, a value method. The second method could be used to provide stronger, partial action-conditional baselines (or even critics) to the first method.\n\nThe entropy derivation are more interesting - and the smoothed entropy technique is as far as I know, novel. The experiments are well done, though on simple toy environments.\n\nMinor:\n- In section 3.2, one should in principle tweak the discount factor of the modified MDP to recover behavior identical to the original one with large action space. This should be noted (alternatively, the discount between non-environment transitions should be set to 1).\n\n- From the description at the end of 3.2, and figure 1.b, it seems actions fed to the MMDP feed-forward network are not one-\nhot; I thought this was pretty surprising as it would almost certainly affect performance? Note also that the collection of feed-forward network which collectively output the joint vector can be thought of as an RNN with non-learned state transition.\n\n- Since the function optimized can be written as an expectation of reward+pseudo-reward, the proof of theorem 4 can be simplified by using generic score-function optimization arguments (see Stochastic Computation Graphs, Schulman et al).\n', 'Clarity and quality:\n\nThe paper is well written and the ideas are motivated clearly both in writing and with block diagram panels.  Also the fact  that the paper considers different  variants of  the idea  adds to the quality of the paper. May main concern is with the quality of results which is limited to some toy/synthetic problems. Also the comparison with the previous work is missing.The paper would benefit from  a more in depth numerical analysis of this approach both by applying it to more challenging/standard domains such as Mujoco and also by comparing the results with prior approaches such as A3C, DDPG and TRPO.\n\nOriginality, novelty and Significance:\n\nThe paper claims that the approach is novel in the context of policy gradient and Deep RL. I am not sure this is entirely the case since there is a recent work from Google Brain (https://arxiv.org/pdf/1705.05035.pdf ) which consider almost the identical idea with the same variation in the context of DQN and policy gradient (they call their policy gradient approach  Prob SDQN).  The Brain paper also  makes a much more convincing case with their numerical analysis, applied to more challenging domains such as control suite. The paper under review  should acknowledge this prior work and discuss the similarities and the differences. Also since the main idea and the algorithms are quiet similar to the Brain paper I believe the novelty of this work is at best marginal.']","[-20, -20, -50]","[50, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the work, they also point out several significant shortcomings and missing elements. The reviewer notes that the proposed method 'seems to benefit' from their approach, but then lists multiple criticisms, including missing citations, lack of important baselines, and suggestions for improvement. This indicates a generally critical stance, albeit not overwhelmingly negative. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'it seems like' and 'could be improved' rather than making blunt criticisms. The reviewer also offers specific suggestions for improvement, which is a polite way of addressing shortcomings. The language is neither overly formal nor informal, striking a balance that is appropriate for peer review."", ""The sentiment score is slightly negative (-20) because the reviewer expresses skepticism about the novelty of some aspects of the paper, using phrases like 'seem incremental or non novel to me' and 'I believe it is folklore'. However, they do acknowledge some positive aspects, such as the 'more interesting' entropy derivations and 'well done' experiments. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using neutral language and providing constructive feedback. They offer specific suggestions and references, which is helpful, and avoid harsh or personal criticisms. The use of phrases like 'I believe' and 'as far as I know' also softens potential negative comments."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('well written', 'ideas are motivated clearly', 'adds to the quality'), they express significant concerns about the quality of results, lack of comparison with previous work, and limited novelty. The overall tone suggests more criticism than praise. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism without harsh or rude phrasing. They acknowledge positive aspects before presenting concerns, and use phrases like 'The paper would benefit from' to suggest improvements politely. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional tone.""]"
"['This paper proposes a new method for reverse curriculum generation by gradually reseting the environment in phases and classifying states that tend to lead to success. It additionally proposes a mechanism for learning from human-provided ""key states"".\n\nThe ideas in this paper are quite nice, but the paper has significant issues with regard to clarity and applicability to real-world problems:\nFirst, it is unclear is the proposed method requires access only high-dimensional observations (e.g. images) during training or if it additionally requires low-dimensional states (e.g. sufficient information to reset the environment). In most compelling problems settings where a low-dimensional representation that sufficiently explains the current state of the world is available during training, then it is also likely that one can write down a nicely shaped reward function using that state information during training, in which case, it makes sense to use such a reward function. This paper seems to require access to low-dimensional states, and specifically considers the sparse-reward setting, which seems contrived.\nSecond, the paper states that the assumption ""when resetting, the agent can be reset to any state"" can be satisfied in problems such as real-world robotic manipulation. This is not correct. If the robot could autonomously reset to any state, then we would have largely solved robotic manipulation. Further, it is not always realistic to assume access to low-dimensional state information during training on a real robotic system (e.g. knowing the poses of all of the objects in the world).\nThird, the experiments section lacks crucial information needed to understand the experiments. What is the state, observation, and action space for each problem setting? What is the reward function for each problem setting? What reinforcement learning algorithm is used in combination with the curriculum and tendency rewards? Are the states and actions continuous or discrete? Without this information, it is difficult to judge the merit of the experimental setting.\nFourth, the proposed method seems to lack motivation, making the proposed scheme seem a bit ad hoc. Could each of the components be motivated further through more discussion and/or ablative studies?\nFinally, the main text of the paper is substantially longer than the recommended page limit. It should be shortened by making the writing more concise.\n\nBeyond my feedback on clarity and significance, here are further pieces of feedback with regard to the technical content, experiments, and related work:\nI\'m wondering -- can the reward shaping in Equation 2 be made to satisfy the property of not affecting the final policy? (see Ng et al. \'09) If so, such a reward shaping would make the method even more appealing.\nHow do the experiments in section 5.4 compare to prior methods and ablations? Without such a comparison, it is impossible to judge the performance of the proposed method and the level of difficulty of these tasks. At the very least, the paper should compare the performance of the proposed method to the performance a random policy.\n\nThe paper is missing some highly relevant references. First, how does the proposed method compare to hindsight experience replay? [1] Second, learning from keyframes (rather than demonstrations) has been explored in the past [1]. It would be preferable to use the standard terminology of ""keyframe"".\n\n[1] Andrychowicz et al. Hindsight Experience Replay. 2017\n[2] Akgun et al. Keyframe-based Learning from Demonstration. 2012\n\nIn summary, I think this paper has a number of promising ideas and experimental results, but given the significant issues in clarity and significance to real world problems, I don\'t think that the current version of this paper is suitable for publication in ICLR.\n\nMore minor feedback on clarity and correctness:\n- Abstract: ""Deep RL algorithms have proven successful in a vast variety of domains"" -- This is an overstatement.\n- The introduction should be more clear with regard to the assumptions. In particular, it would be helpful to see discussion of requiring human-provided keyframes. As is, it is unclear what is meant by ""checkpoint scheme"", which is not commonly used terminology.\n- ""This kind of spare reward, goal-oriented tasks are considered the most difficult challenges"" -- This is also an overstatement. Long-horizon tasks and high-dimensional observations are also very difficult. Also, the sentence is not grammatically correct.\n- ""That is, environment"" -> ""That is, the environment""\n- In the last paragraph of the intro, it would be helpful to more clearly state what the experiments can accomplish. Can they handle raw pixel inputs?\n- ""diverse domains"" -> ""diverse simulated domains""\n- ""a robotic grasping task"" -> ""a simulated robotic grasping task""\n- There are a number of issues and errors in citations, e.g. missing the year, including the first name, incorrect reference\n- Assumption 1: \\mathcal{P} has not yet been defined.\n- The last two paragraphs of section 3.2 are very difficult to understand without reading the method yet\n- ""conventional RL solver tend"" -> ""conventional RL tend"", also should mention sparse reward in this sentence.\n- Algorithm 1 and Figure 1 are not referenced in the text anywhere, and should be\n- The text in Figure 1 and Figure 3 is extremely small\n- The text in Figure 3 is extremely small\n\n\n', 'The authors extend the approach proposed in the  ""Reverse Curriculum Learning for Reinforcement Learning"" paper by adding a discriminator that gives a bonus reward to a state based on how likely it thinks the current policy is to reach the goal from said state. The discriminator is a potentially interesting mechanism to approximate multi-step backups in sparse-reward environments. \n\nThe approach of this paper seems severely severely limited by the assumptions made by the authors, mainly assuming a deterministic environment, known goal states and the ability to sample anywhere in the state space. Some of these assumptions may be reasonable in domains such as robotics, but they seem very restrictive in the domains like the games considered in the paper.\n\n\nAdditional Comments:\n\n-The authors demonstrate some benefits of using Tendency rewards, but made little attempt to explain why it leads to accelerated learning. Results are pure performance results.\n\n-The authors should probably structure the tendency reward as potential based instead of using the Gaussian kernel hack they introduce in section 4.2\n\n- Presentation: There are several mistakes and formatting issues in References\n\n- Assumption 2 transformations -> transitions?\n\n-Need to add assumption 3: advance knowledge of goal state\n\n- the use of gamma as  a scale factor in equation 2 is confusion, it was already introduced as the discount factor ( which is default notation in RL). It also isn\'t clear what the notation r_f denotes (is it the same as r^f in appendix?).\n\n-It is nice to see that the authors compare their method with alternative approaches. Unfortunately, the proposed method does not seem to offer many benefits. \n', 'The authors present a new method for doing reverse curriculum training for reinforcement learning tasks with deterministic dynamics, a desired goal state at which reward is received, and the ability to teleport to any state. This covers a number of important cases of interest, including all simulated domains, and a number of robotics applications. The training proceeds in phases, where in each phase the initial starting set of states is expanded. The initial set of states used is close to the desired state goal. Each phase is initiated when 80% of the states in the current phase can reach the goal. Once the initial set of start states overlaps with the desired initial set of states for the task, training can terminate. During the training in a single phase, the algorithm uses a shaping reward (the tendency) which is based on a binary classifier that predicts if it will be possible to reach the goal from this state. This reward is combined in a hybrid reward signal. The authors suggest the use of a small number of checkpoints to guide the backwards state expansion to improve the search efficiency. Results are presented on several domains: maze, Super Mario, and Mujoco domains. \n\nThe topic of doing more sample efficient training is important and interesting, and the subset of settings the authors consider is still a good set. \n\nThe paper was clearly written though some details were relegated to the appendix which would’ve been useful to see in the main text.\n\nI’m not yet convinced about this method for the desired setting in terms of significance and quality.\n\nAn alternative to using tendency shaping reward would be (during phase expansion) make the new “goal” states any of the states in the previous phase of initial states P_{i} that did reach the goal. This should greatly reduce the decision making horizon needed in each  phase. Since the domain is deterministic, as soon as one can reach one of those states, we have a path to the goal. If we care about the number of steps to reach the goal (vs finding any path), then each of the states in P_{i} for which a successful path can be achieved to the goal can also be labeled by the cost / number of time steps to reach the goal. This should decompose the problem into a series of smaller problems. Perhaps I’m missing something-- could the authors please address this suggestion and/or explain why this wouldn’t be beneficial?\n\nThe authors currently use checkpoints to help guide the search towards the true task desired set of initial states. If those are lacking, it seems like the generation of the new P_{i+1} could be biased towards that desired set of states. One approach could be to randomly roll out from the start state and then bias P_{i+1} towards any states close to states along such trajectories. In general one could imagine a situation in which one both does forward learning/planning from the task start state and backwards learning from the goal state to obtain a significant benefit, similar to ideas that have been used in robot motion planning.\n\nWhy learn from pixels for the robot domains considered? Here it would be nice to compare to some robotics approaches. With the action space of the robot and motion planning, it seems like this problem could be tackled using existing techniques. It is interesting to have a method that can be used with pixels, but in cases where there are other approaches, it would be useful to compare to them.\n\nSmall point\nD.2 Why not compare to GAIL instead? \n']","[-60, -30, -20]","[20, 20, 60]","[""The sentiment score is -60 because the review is predominantly critical, highlighting significant issues with clarity and applicability. The reviewer states that the paper is not suitable for publication in its current form, which indicates a negative sentiment. However, they do acknowledge some 'promising ideas and experimental results', preventing the score from being even lower. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'I think' and 'I'm wondering' which soften the critique. The reviewer also provides constructive feedback and suggestions for improvement, which is a polite approach to criticism. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -30 because while the reviewer acknowledges some potential in the approach ('potentially interesting mechanism'), they express significant concerns about the limitations and assumptions of the paper. The review points out several issues and suggests that the method doesn't offer many benefits over alternatives. However, it's not entirely negative, as it does recognize some positive aspects. The politeness score is 20 because the reviewer maintains a professional tone throughout, offering constructive criticism and specific suggestions for improvement. They use phrases like 'The authors should probably' and 'It is nice to see' which add a polite tone. However, the criticism is direct and doesn't use overly softening language, keeping the score only moderately positive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and the clear writing, they express skepticism about the method's significance and quality. The phrase 'I'm not yet convinced' indicates a lack of full support for the work. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive suggestions, and phrases criticisms as questions or suggestions rather than direct attacks. They use phrases like 'Perhaps I'm missing something' and 'could the authors please address' which maintain a polite tone while raising concerns.""]"
"['Summary:\nThis paper proposes parallel GANs (PGANs). This is a new architecture which composes the generator based on a mixture of weak generators with the main intended purpose that each unique generator may suffer mode collapse, but as long as each generator collapses to a distinct mode, the combination of generators will cover the whole image distribution. The paper proposes a number of technical details to 1) ensure that each sub generator offers distinct information (adjustment component, C) and 2) to efficiently train the generators in parallel while accumulating information to update both the discriminator and the adjustment component. \nResults are shown on a synthetic dataset of gaussian mixtures, demonstrating that the model does indeed find all modes within the data, and on two small real image datasets: MNIST and CIFAR-10. Overall the parallel generator model results in ~x2 speedup in training time compared with a single complex generator model.\n\nStrengths:\nMode collapse in GANs is a timely and unsolved problem. While most work aims to construct auxiliary loss function to prevent this collapse, this paper instead chooses to accept the collapse and instead encourage multiple models which collapse to unique modes. Though this does present a new problem in chooses the number of modes to estimate within a data source, the paper also presents a solution to systematically combine redundant modes over time, making the model more robust to the choice of number of generators overall. \n\nWeaknesses:\nOrganization - The paper is quite difficult to read. Some concepts are presented out of order. For example, the notion of an adjustment component is very natural but not introduced until after it is mentioned a few times. Similarly, G_{-k} is mentioned many times but not clearly defined.  I would suggest to the authors to reorder the subsections in the method part to first outline the main idea: (parallel generators to capture different parts of overall distribution), mention the need to prevent redundancy between the generators (C), and mention some technical overhead in determining how to process all generated images by D. All of this may be discussed within the context of Fig 1. Also Fig 1a-b may be combined and may aid in explanation. \n\nExperiments - Comparison is limited to single generator models. Many other generator approaches exist beyond a single generator/discriminator GAN. In particular, different loss functions for training the generator (LS-GAN etc). Missing some relevant details like why use HogWild or what it is. \n\nMinimal understanding - I would like to know what exactly each generator contributes in the real world datasets. Can you show some generations from each mode? Is there a human perceivable difference?\n\nFigure 4: why does the inception score for the single generator models vary with the #generators?\n\nLast paragraph before 4.2.1: Please clarify this sentence - “we designed a relatively strong discriminator with a high learning rate, since the gradient vanish problem is not observed in reverse KL GAN.” \n\nTypo: last line page 7: “we the use” → “we use the”', 'The paper proposes to use multiple generators to fix mode collapse issue. The multiple generators are trained to be diverse. Each generator uses the reverse KL loss so that it models a single mode. One disadvantage is that it increases the number of networks (and hence the number of parameters). \n\nThe paper needs some additional experiments to convincingly demonstrate the usefulness of the proposed method. Experiments on a challenging dataset with large number of classes (e.g.  ImageNet as done by AC-GAN paper) would better illustrate the power of the method.\n\nAC-GAN paper:\nConditional Image Synthesis with Auxiliary Classifier GANs\nhttps://arxiv.org/pdf/1610.09585.pdf\n\nThe paper lacks clarity in some places and could use another round of editing/polishing.', 'Overall, the writing is very confusing at points and needs some attention to make the paper clearer. I’m not entirely sure the authors understand the material particularly well, as I found some of the arguments and narrative confusing or just incorrect. I don’t really see any significant contribution here except “we had this idea for this model, and it works”. There’s no interesting questions being asked about missing modes (and no answers through good experimentation), no insight that might contribute to our understanding of the problem, and no comparison to other models. My guess is this submission was rushed (and perhaps they were just looking for feedback). I like the idea, don’t get me wrong: a model that is trainable across multiple GPUs and that distributes generative work is pretty cool, and I want to see this work succeed (after a *lot* more work). But the paper really lacks what I’d consider good science, and I don’t see it publishable without significant improvement.\n\nPersonally I think you should change the angle from missing modes to parallel training. I don’t see any strong guarantees that the model will do what you say it will, especially as beta goes to zero.\n\nDetailed comments\n\nP1\n“, that explicitly approximate data distribution, the approximation of GAN is implicit”\nThe wording of this is pretty strange: by “implicit”, we mean that we only have *samples* from the distribution(s) of interest, but what does it mean for an approximation to be “implicit”?\n\nFrom the intro, it doesn’t sound like the approach is meant for the “mode collapse” problem, but for dealing with missing modes. These are different types of failures for GANs, and while there are many theories for why these happen, to my knowledge there’s no such consensus that these issues are the same.\nFor instance, what is keeping each of the generators from collapsing onto a single value? We often see the model collapse on several different values: why couldn’t each of your generators do this?\n\nP2: No, it is incorrect that the KL is what is causing mode collapse, and I think actually you mean “missing modes”. Arjovsky et al addresses the mode collapse problem, which is just another word for a type of instability in GANs. But this isn’t because of “vanishing gradients”, as the “proxy loss” (which you call “heuristic loss”, this isn’t a common term, fyi), which is what GANs are trained on in practice don’t vanish, but show some other sorts of instabilities (Arjovsky 2016). That said, other GAN variants without regularization also show collapse *and* missing modes, such as LSGAN and all the f-GAN variants (even the auto encoder variants).\n\nYou should also probably cite Che et al 2016 as another model that addressed missing modes. Also, what about ALI, BiGAN, and ALiCE? These also address missing modes (at least they claim to).\n\nI don’t understand why you’re comparing f-GAN and WGAN convergences: they are addressing different things with GANs: one shows insight into what exactly traditional GANs are doing (solving a dual problem of minimizing an f-divergence) versus addressing stability through using an IPM (though also a dual formulation of the wasserstein). f-GANs ensure neither stability nor non-vanishing gradients.\n\nP3: I like the breakdown of how the memory is organized.\nThis is for multi-GPU, correct? This needs to be explicitly stated.\n\nP6:\nThere’s a sign error in proof 1 (both in the definition of the reverse KL and when the loss is written out).\nAlso, the gradient w.r.t. theta magically appears in the second half.\nThis is a pretty round-about way to arrive at that you’re minimizing the reverse KL: I’m pretty sure this can be shown by formulating the second term in f-gan (the one where you sample from the generator), that is f*(T), where f* is the convex conjugate of f = -log\n\nMixture of Gaussians: common *missing modes* experiment.\n\nSo my general comments about the experiments\nYou need to compare to other models that address missing modes. Overall, many people have shown success with experiments similar to your simple mixture of Gaussians experiments, so in order to show something significant here, you will need to have a more challenging experiments and show a comparison to other models.\nThe real-world experiments are fairly unconvincing, as you only show MNIST and CIFAR-10 (and MNIST doesn’t look very good). Overall, the good inception scores aren’t too surprising given the model has several generators for each mode, but I think we need to see a demonstration on better datasets.']","[50, -20, -60]","[80, 50, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges both strengths and weaknesses of the paper. They praise the paper's approach to the mode collapse problem and its novel solution, but also point out organizational issues and limitations in the experiments. The overall tone is constructive rather than overly critical or enthusiastic. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering suggestions rather than demands (e.g., 'I would suggest to the authors...'), and frames criticisms as areas for improvement rather than outright flaws. The reviewer also uses phrases like 'Please clarify' and asks questions, which maintains a courteous tone. The high level of detail in the feedback also indicates respect for the authors' work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's proposal to address mode collapse, they also point out disadvantages and suggest that additional experiments are needed to demonstrate the method's usefulness. The reviewer also mentions that the paper lacks clarity in some places. These critiques outweigh the initial positive acknowledgment, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer uses neutral, professional language throughout. They offer constructive criticism and suggestions for improvement without using harsh or dismissive language. The reviewer also provides a helpful reference to support their suggestion for additional experiments, which is a courteous gesture."", ""The sentiment score is -60 because the review is largely critical of the paper, pointing out numerous issues with the writing, understanding of the material, and lack of significant contribution. The reviewer states that the paper 'lacks what I'd consider good science' and is not publishable without significant improvement. However, the score is not at the extreme negative end because the reviewer does express some positive sentiment about the idea itself, calling it 'pretty cool' and expressing a desire to see the work succeed. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout and offer constructive feedback. They use phrases like 'I like the idea' and 'I want to see this work succeed' which soften the criticism. The reviewer also provides detailed comments and suggestions for improvement, which is a polite and helpful approach in academic review.""]"
"['This paper presents mutual autoencoders (MAE). MAE aims to address the limitation of regular variational autoencoders (VAE) for latent representation learning — VAE sometimes simply ignores the latent code z, especially with a powerful decoding distribution. The idea of MAE is to optimize the VAE objective subject to a constraint on the mutual information between the data x and latent code z: setting the mutual information constraints larger will force the latent code z to learn a meaningful representation of the data. An approximation strategy is employed to approximate the intractable mutual information. Experimental results on both synthetic data and movie review data demonstrate the effectiveness of the MAEs.  \n\nOverall, the paper is well-written. The problem that VAEs fail to learn a meaningful representation is a well-known issue. This paper presents a simple, yet principled modification to the VAE objective to address this problem. I do, however, have two major concerns about the paper:\n\n1. The proposed idea to add a mutual information constraint between the data x and latent code z is a very natural fix to the failure of regular VAEs. However, mutual information itself is not a quantity that is easy to comprehend and specify. This is not like, e.g., l2 regularization parameter, for which there exists a relatively clear way to specify and tune. For mutual information, at least it is not clear to me, how much mutual information is “enough” and I am pretty sure it is model/data-dependent. To make it worse, there exist no metrics in representation learning for us to easily tune this mutual information constraint. It seems the only way to select the mutual information constraint is to qualitative inspect the model fits. This makes the method less practical. \n\n2. The approximation to the mutual information seems rather loose. If I understand correctly, the optimization of MAE is similar to that of a regular VAE, with an additional parametric model r_w(z|x) which is used to approximate the infomax bound. (And this also adds an additional term to the gradient wrt \\theta). r_w(z|x) is updated at the same time as \\theta, which means r_w(z|x) is quite far from being an optimal r* as it is intended, especially early during the optimization. Further more, all the derivation following Eq (12-13) are based on r* being optimal, while in reality, it is probably not even close. This makes the whole approximation quite hand-waving. \n\nRelated to 2, the discussion in Section 6 deserves more elaboration. It seems that having a flexible encoder is quite important, yet the authors only mention lightly that they use the approximate posterior from Cremer et al. (2017). Will MAE not work without this? How will VAE (without the mutual information constraint) work with this? A lot of the details seem to be glossed over. \n\nFurthermore, this work is also related to the deep variational information bottleneck of Alemi et al. 2017 (especially in the appendix they derived the VAE objective using information bottleneck principle). My intuition is that using a larger mutual information constraint in MAE is somewhat similar to setting the regularization \\beta to be smaller than 1 — both are making the approximating posterior more concentrated. I wonder if the authors have explored this idea. \n \n\nMinor comments:\n\n1. It would be more informative to include the running time in the presented results. \n\n2. Since the goal of r_w(z | x) is to approximate the posterior p(z | x), what about directly using q(z | x) to approximate it? \n\n3. In Algorithm 1, should line 14 and 15 be swapped? It seems samples are required in line 14 as well. \n\n4. Nitpicking: technically the model in Eq (1) is not a hierarchical model. \n\n', '\nSummary\n\nThis paper proposes a penalized VAE training objection for the purpose of increasing the information between the data x and latent code z.  Ideally, optimization would consist of maximizing log p(x) - | I(x,z) - M |, where M is the user-specified target mutual information (MI) and I(x,z) is the model’s current MI value, but I(x,z) is intractable, necessitating the use of an auxiliary model r(z|x).  Optimization, then, consists of alternating gradient ascent on the VAE parameters and r’s parameters.  Experiments on simulations and text data are reported, showing that increasing M has the desired effect of allowing more deviation from the prior.  Specifically, this is shown through text generation where the sampled sentences become more varied as M is decreased and better reconstructed as M is increased.  \n\n\nEvaluation\n\nPros:  I like how this paper formalizes failure in representation learning as information loss in z---although the formulation is not particularly novel, i.e. [Zhao et al., ArXiv 2017]), and constructs an explicit, penalized objective to allow the user to specify the amount of information retained in z.  In my opinion, the proposed objective is more transparent than the objectives proposed by related work.  For instance, Chen et al.’s (2017) Lossy VAE, while aiming to solve essentially the same problem, does so by parameterizing the prior and using a windowed decoder, but there is no explicit control mechanism as far as I’m aware (except for how many parameters / window size).  Perhaps the Beta-VAE’s [Higgins et al., ICLR 2017] KLD weight is similarly interpretable (as beta increases, less information is retained), but I like that M has the clear meaning of mutual information---whereas the beta in the Beta-VAE is just a Lagrangian.  In terms of experiments, I like the first simulation; it’s a convincing sanity check.  As for the second, I like the spirit of it, but I have some criticisms, as I’ll explain below.\n\nCons:  The method requires training an auxiliary model r(z|x) to estimate I(x,z).  While I don’t find the introduction of r(z|x) problematic, I do wish there was more discussion and analysis of how well the mutual information is being approximated during training, especially given some of the simplifying assumptions, such as r(z|x)=p(z|x).  If the MI estimate is way off, that detracts from the method and makes an alternative like the Beta-VAE---which doesn’t require an auxiliary model---more appealing, since what makes the MAE superior---its principled targeting of MI---does not hold in practice.\n\nAs for the movie review experiment, I find the sentence samples a bit anecdotal.  Was the seed sentence (“there are many great scenes of course”) randomly chosen or hand picked?  Was this interpolation behavior typical?  I ask these questions because I find the plot in Figure 3 all but meaningless.  It’s good that we see reconstruction quality go up as M increases, as expected, but the baseline VAE model is a strawman.  How does reconstruction percentage look for the Bowman et al. (2015) VAE?  What about the Beta-VAE?  Or Lossy VAE?  Figure 3 would be okay if there were more experiments, but as it is the only quantitative result, more work should have gone in to it.  For instance, a compelling result would be if we see one or more of the models above plateau in reconstruction percentage and the MAE surpass that plateau.\n\n\nConclusions\n\nWhile I found aspects of this paper interesting, I recommend rejection primarily for two reasons.  The first is that I would like to see how well the mutual information is being estimated during training.  If the estimate is way off, this makes the method less appealing as what I like about it---the interpretable MI target---is not really a ‘target’, in practice, and rather, is a rough hyperparameter similar to the Beta-VAE’s beta term (which has the added benefit of no auxiliary model).  The second reason is the paper’s weak experimental section.  The only quantitative result is Figure 3, and while it shows reconstruction percentage increases with M, there is no way to contextualize the number as the only comparison model is a weak VAE, which gives ~ 0%.  Questions I would like to see answered: How good is the MI estimate?  How close is the converged VAE to the target?  How does the model compare to the Bowman et al. VAE or the Beta-VAE?  (It would be quite compelling to show similar or improved performance without the training tricks used by Bowman et al.)  Can we somehow estimate the appropriate M directly from data (such as based on the entropy of training or validation set) in order to set the target rigorously?         \n\n\n1.  S. Zhao, J. Song, and S. Ermon.  “InfoVAE: Information Maximizing Variational Autoencoders.”  ArXiv 2017.\n2.  X. Chen, D. Kingma, T. Salimans, Y. Duan, P. Dhariwal, J. Shulman, I. Sutskever, and P. Abbeel.  “Variational Lossy Autoencoder.”  ICLR 2017.\n3.  I. Higgins, L. Matthey, A. Pal, C. Burgess, X. Glorot, M. Botvinick, S. Mohamed, and A. Lerchner. “Beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework.”  ICLR 2017\n4.  S. Bowman, L. Vilnis, O. Vinyas,  A. Dai, R. Jozefowicz, and S. Bengio.  “Generating Sentences from a Continuous Space.”  CoNLL 2016.', 'The authors propose a variational autoencoder constrained in such a way that the mutual information between the observed variables and their latent representation is constant and user specified. To do so, they leverage the penalty function method as a relaxation of the original problem, and a variational bound (infomax) to approximate the mutual information term in their objective.\n\nI really enjoyed reading the paper, the proposed approach is well motivated and clearly described. However, the experiments section is very weak. Although I like the illustrative toy problem, in that it clearly highlights how the method works, the experiment on real data is not very convincing. Further, the authors do not consider a more rigorous benchmark including additional datasets and state-of-the-art modelling approaches for text. \n\n- {\\cal Z} in (1) not defined, same for \\Theta.']","[-20, -30, 20]","[60, 60, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and presents a 'simple, yet principled modification' to address a known issue, they express 'two major concerns' about the paper. These concerns relate to the practicality of the method and the looseness of the approximation used. The reviewer also points out several areas where more elaboration or exploration is needed. However, the overall tone is not entirely negative, as the reviewer recognizes the paper's contributions and provides constructive feedback.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They begin with positive comments about the paper being 'well-written' and the idea being 'simple, yet principled'. Even when expressing concerns, the reviewer uses phrases like 'I do, however, have two major concerns' and 'It seems' rather than making blunt criticisms. The reviewer also offers suggestions and asks questions, indicating a collaborative approach rather than a dismissive one. The use of phrases like 'I wonder if the authors have explored this idea' further contributes to the polite tone."", ""The sentiment score is -30 because while the reviewer finds some aspects of the paper interesting and praises certain elements (e.g., 'I like how this paper formalizes...', 'I like the spirit of it'), they ultimately recommend rejection and express significant concerns about the methodology and experimental results. The overall tone is more negative than positive, but not extremely negative. The politeness score is 60 because the reviewer uses polite and constructive language throughout, acknowledging positives before presenting criticisms, and framing concerns as suggestions for improvement (e.g., 'I would like to see...'). The reviewer maintains a professional and respectful tone, even when recommending rejection."", ""The sentiment score is slightly positive (20) because the reviewer expresses enjoyment reading the paper and praises aspects like clear motivation and description. However, they also point out significant weaknesses in the experiments section, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering both praise and criticism in a constructive manner. They use phrases like 'I really enjoyed reading the paper' and provide specific, actionable feedback without harsh or rude phrasing. The tone remains professional and courteous even when pointing out shortcomings.""]"
"['Learning adjacency matrix of a graph with sparsely connected undirected graph with nonnegative edge weights is the goal of this paper. A projected sub-gradient descent algorithm is used. The UPS optimizer by itself is not new.\n\nGraph Polynomial Signal (GPS) neural network is proposed to address two shortcomings of GSP using linear polynomial graph filter. First, a nonlinear function sigma in (8) is used, and second, weights are shared among neighbors of every data points. There are some concerns about this network that need to be clarified:\n1. sigma is never clarified in the main context or experiments\n2. the shared weights should be relevant to the ordering of neighbors, instead of the set of neighbors without ordering, in which case, the sharing looks random.\n3. another explanation about the weights as the rescaling to matrix A needs to further clarified. As authors mentioned that the magnitude of |A| from L1 norm might be detrimental for the prediction. What is the disagreement between L1 penalty and prediction quality? Why not apply these weights to L1 norm as a weighted L1 norm to control the scaling of A?\n4. Authors stated that the last step is to build a mapping from the GPS features into the response Y. They mentioned that linear fully connected layer or a more complex neural network can be build on top of the GPS features. However, no detailed information is given in the paper. In the experiments, authors only stated that “we fit the GPS architecture using UPS optimizer for varying degree of the neighborhood of the graph”, and then the graph is used to train existing models as the input of the graph. Which architecture is used for building the mapping ?\n\nIn the experimental results, detailed definition or explanation of the compared methods and different settings should be clarified. For example, what is GPS 8, GCN_2 Eq. 9 in Table 1, and GCN_3 9 and GPS_1, GPS_2, GPS_3 and so on. More explanations of Figure 2 and the visualization method can be great helpful to understand the advantages of the proposed algorithm. \n', ""The authors develop a novel scheme for backpropagating on the adjacency matrix of a neural network graph.  Using this scheme, they are able to provide a little bit of evidence that their scheme allows for higher test accuracy when learning a new graph structure on a couple different example problems.\n\nPros: \n-Authors provide some empirical evidence for the benefits of using their technique.\n-Authors are fairly upfront about how, overall, it seems their technique isn't doing *too* much--null results are still results, and it would be interesting to better understand *why* learning a better graph for these networks doesn't help very much.\n\nCons: \n-The grammar in the paper is pretty bad.  It could use a couple more passes with an editor.\n-For a, more or less, entirely empirical paper, the choices of experiments are...somewhat befuddling.  Considerably more details on implementation, training time/test time, and even just *more* experiment domains would do this paper a tremendous amount of good.\n-While I mentioned it as a pro, it also seems to be that this technique simply doesn't buy you very much as a practitioner.  If this is true--that learning better graph representations really doesn't help very much, that would be good to know, and publishable, but actually *establishing* that requires considerably more experiments.\n\nUltimately, I will have to suggest rejection, unless the authors considerably beef up their manuscript with more experiments, more details, and improve the grammar considerably.\n"", 'There are many language issues rendering the text hard to understand, e.g.,\n-- in the abstract: ""several convolution on graphs architectures""\n-- in the definitions: ""Let data with N observation"" (no verb, no plural, etc).\n-- in the computational section: ""Training size is 9924 and testing is 6695. ""\nso part of my negative impression may be pure mis-understanding of what\nthe authors had to say. \n\nStill, the authors clearly utilise basic concepts (c.f. ""utilize eigenvector \nbasis of the graph Laplacian to do filtering in the Fourier domain"") in ways\nthat do not seem to have any sensible interpretation whatsoever, even allowing\nfor the mis-understanding due to grammar. There are no clear insight, \nno theorems, and an empirical evaluation on an ill-defined problem in \ntime-series forecasting. (How does it relate to graphs? What is the graph \nin the time series or among the multiple time series? How do the authors\nimplement the other graph-related approaches in this problem featuring\ntime series?) My impression is hence that the only possible outcome is\n\nrejection.']","[-20, -50, -80]","[50, 20, -20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's goals and proposed methods, they express several concerns and request multiple clarifications. This indicates that the reviewer sees potential in the work but finds significant areas for improvement. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'need to be clarified' and 'can be great helpful' rather than harsh criticism. They also offer constructive suggestions for improvement. The language is not overly formal or deferential, but it remains respectful and focused on the content rather than personal critiques."", ""The sentiment score is -50 because while the reviewer acknowledges some pros of the paper, they ultimately suggest rejection and point out several significant cons. The overall tone is more negative than positive, but not entirely dismissive. The politeness score is 20 because the reviewer uses relatively polite language and acknowledges positive aspects, but also provides direct criticism. They use phrases like 'could use' and 'would do this paper a tremendous amount of good' which are constructive rather than harsh. However, some statements like 'grammar is pretty bad' are more blunt, preventing a higher politeness score."", ""The sentiment score is -80 because the reviewer expresses strong negative opinions about the paper. They mention numerous language issues, lack of clear insights, and an ill-defined problem. The review concludes with a recommendation for rejection, indicating a highly negative sentiment. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite critical and dismissive. They use phrases like 'do not seem to have any sensible interpretation whatsoever' and 'the only possible outcome is rejection,' which come across as harsh and somewhat impolite. However, they do acknowledge that some of their negative impression may be due to misunderstanding, which slightly softens the overall tone.""]"
"['The paper proposed a new framework called `Learning to select’, in which a best candidate needs to be identified in the decision making process such as job dispatching. A CNN architecture is designed, called `Variable-Length CNN’, to solve this problem.\n\nMy major concern is on the definition of the proposed concept of `learning-to-select’. Essentially, I’ve not seen its key difference from the classification problem. While `even in the case of completely identical candidates, the label can be 1 in some situations, and in some other situations the label can be 0’, why not including such `situations’ into your feature vector (i.e., x)? Once you do it, the gap between learning to select and classification will vanish. If this is not doable, you should better make more discussions, especially on what the so-called `situations’ are.  Furthermore, the application scope of the proposed framework is not very well discussed. If it is restricted to job dispatching scenarios, why do we need a new concept “learning to select”?\n\nThe proposed model looks quite straightforward. Standard CNN is able to capture the variable length input as is done in many NLP tasks. Dynamic computational graph is not new either. In this sense, the technical novelty of this work is somehow limited.\n\nThe experiments are weak in that the data are simulated and the baselines are not strong. I’ve not gained enough insights on why the proposed model could outperform the alternative approaches. More discussions and case studies are sorely needed.\n', 'The authors state\n""This problem is simply a matter of choosing the best candidate among the given candidates in a specific situation."" -> It would be nice to have examples of what constitutes a ""candidate"" or ""situation""?\n\nThe problem definition and proposed approach needs to be made more precise. For e.g. statements like ""\nFor the problem of classifying data into several classes, neural networks have dominated with high performance. However, the neural networks are not an adequate answer for every problem."" are not backed with enough evidence. \n\nA detailed section on related work would be beneficial.\n', 'This paper proposes a ""Learning to Select"" problem which essentially is to select the best among a flexible size of candidates, which is in fact Learning to Rank with number of items to select as 1. To be able to efficiently train the model without wasting time on the items that are not candidates, the authors applied an existing work in literature named Dynamic Computation Graph and added convolutional layer, and showed that this model outperforms baseline methods such as CNN, fully-connected, Rank-SVM etc. \n\nAs this paper looks to me as an simple application of an existing approach in literature to a real-world problem, novelty is the main concern here. Other concerns include:\n1. Section 2. It would be good to include more details of DCG to make the papers more complete and easier to read.\n2. It looks to me that the data used in experimental section is simulated data, rather than real data. \n3. It looks to me that baselines such as CNN did not perform well, mainly because in test stage, some candidates that CNN picked as the best do not actually qualify. However, this should be able to be fixed easily by picking the best candidate that qualify. Otherwise I feel it is an unfair comparison to the proposed method. ']","[-50, -30, -30]","[20, 20, 50]","[""The sentiment score is -50 because the review expresses several major concerns and criticisms about the paper, including the lack of clear distinction from classification problems, limited technical novelty, and weak experiments. However, it's not entirely negative as it acknowledges the proposed framework and model. The politeness score is 20 because the reviewer uses professional and neutral language, avoiding harsh criticism. They use phrases like 'My major concern is...' and 'More discussions and case studies are sorely needed' which maintain a respectful tone while still conveying critical feedback. The reviewer also acknowledges some positive aspects of the work, which contributes to the slightly positive politeness score."", ""The sentiment score is slightly negative (-30) because the reviewer points out several areas for improvement and lacks positive comments. The review suggests that the paper needs more precision, examples, evidence, and a detailed related work section, indicating that significant revisions are required. However, the score is not deeply negative as the criticisms are constructive and presented as suggestions rather than harsh criticisms. The politeness score is slightly positive (20) because the reviewer uses polite language such as 'It would be nice to have' and 'would be beneficial.' The reviewer also frames their comments as suggestions rather than direct criticisms. However, the politeness is not extremely high as the review is quite direct and doesn't include any explicitly positive remarks or encouragement."", ""The sentiment score is slightly negative (-30) because the reviewer expresses concerns about the paper's novelty and points out several issues. The reviewer states that the paper seems to be 'a simple application of an existing approach' and lists multiple concerns, which indicates a somewhat critical view. However, the tone is not entirely negative as the reviewer acknowledges the paper's contributions and performance improvements.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They phrase their criticisms as 'concerns' rather than outright flaws, and use polite language such as 'It would be good to' when making suggestions. The reviewer also acknowledges the paper's strengths, showing a balanced approach. While not overly effusive, the language is consistently courteous and constructive.""]"
"['The authors investigate a modified input layer that results in color invariant networks. The proposed methods are evaluated on two car datasets. It is shown that certain color invariant ""input"" layers can improve accuracy for test-images from a different color distribution than the training images.\n\n\nThe proposed assumptions are not well motivated and seem arbitrary. Why is using a permutation of each pixels\' color a good idea?\n\nThe paper is very hard to read. The message is unclear and the experiments to prove it are of very limited scope, i.e. one small dataset with the only experiment purportedly showing generalization to red cars.\n\nSome examples of specific issues:\n- the abstract is almost incomprehensible and it is not clear what the contributions are\n- Some references to Figures are missing the figure number, eg. 3.2 first paragraph, \n- It is not clear how many input channels the color invariant functions use, eg. p1 does it use only one channel and hence has fewer parameters?\n- are the training and testing sets all disjoint (sec 4.3)?\n- at random points figures are put in the appendix, even though they are described in the paper and seem to show key results (eg ""tested on nored-test"")\n- Sec 4.6: The explanation for why the accuracy drops for all models is not clear. Is it because the total number of training images drops? If that\'s the case the whole experimental setup seems flawed.\n- Sec 4.6: the authors refer to the ""order net"" beating the baseline, however, from Fig 8 (right most) it appears as if all models beat the baseline. In the conclusion they say that weighted order net beats the baseline on all three test sets w/o red cars in the training set. Is that Fig 8 @0%? The baseline seems to be best performing on ""all cars"" and ""non-red cars""\n\nIn order to be at an appropriate level for any publication the experiments need to be much more general in scope.\n', 'The paper proposes and evaluates a method to make neural networks for image recognition color invariant.\n\nThe contribution of the paper is: \n - some proposed methods to extract a color-invariant representation\n - an experimental evaluation of the methods on the cifar 10 dataset\n - a new dataset ""crashed cars""\n - evaluation of the best method from the cifar10 experiments on the new dataset\n\nPros: \n - the crashed cars dataset is interesting. The authors have definitely found an interesting untapped source of interesting images.\n\n\nCons: \n- The authors name their method order network but the method they propose is not really parts of the network but simple preprocessing steps to the input of the network. \n- The paper is incomplete without the appendices. In fact the paper is referring to specific figures in the appendix in the main text.\n - the authors define color invariance as a being invariant to which specific color an object in an image does have, e.g. whether a car is red or green, but they don\'t think about color invariance in the broader context - color changes because of lighting, shades, ..... Also, the proposed methods aim to preserve the ""colorfullness"" of a color. This is also problematic, because while the proposed method works for a car that is green or a car that is red, it will fail for a car that is black (or white) - because in both cases the ""colorfulness"" is not relevant. Note that this is specifically interesting in the context of the task at hand (cars) and many cars being, white, grey (silver), or black. \n- the difference in the results in table 1 could well come from the fact that in all of the invariant methods except for ""ord"" the input is a WxHx1 matrix, but for ""ord"" and ""cifar"" the input is a ""WxHx3"" matrix. This probably leads to more parameters in the convolutions. \n- the results in the  figure 4: it\'s very unlikely that the differences reported are actually significant. It appears that all methods perform approximately the same - and the authors pick a specific line (25k steps) as the relevant one in which the RGB-input space performs best. The proposed method does not lead to any relevant improvement.\nFigure 6/7: are very hard to read. I am still not sure what exactly they are trying to say.\n\nMinor comments: \n - section 1: ""called for is network"" -> called for is a network\n - section 1.1: And and -> And\n - section 1.1: Appendix -> Appendix C\n - section 2: Their exists many -> There exist many\n - section 2: these transformation -> these transformations\n - section 2: what does ""the wallpaper groups"" refer to? \n - section 2: are a groups -> are groups\n - section 3.2: reference to a non-existing figure\n - section 3.2/Training: 2499999 iterations = steps? \n - section 3.2/Training: longer as suggested -> longer than suggested\n\n', 'The authors test a CNN on images with color channels modified (such that the values of the three channels, after modification, are invariant to permutations).\n\nThe main positive point is that the performance does not degrade too much. However, there are several important negative points which should prevent this work, as it is, from being published.\n\n1. Why is this type of color channel modification relevant for real life vision? The invariance introduced here does not seem to be related to any real world phenomenon. The nets, in principle, could learn to recognize objects based on shape only, and the shape remains stable when the color channels are changed.\n\n2. Why is the crash car dataset used in this scenario? It is not clear to me why this types of theoretical invariance is tested on such as specific dataset. Is there a real reason for that?\n\n3. The writing could be significantly improved, both at the grammatical level and the level of high level organization and presentation. I think the authors should spend time on better motivating the choice of invariance used, as well as on testing with different (potentially new) architectures, color change cases, and datasets.\n\n4. There is no theoretical novelty and the empirical one seems to be very limited, with less convincing results.']","[-70, -60, -60]","[-20, 20, 20]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer criticizes the paper's motivation, readability, and experimental scope. They point out numerous issues and state that the paper needs significant improvement to be publishable. The politeness score is -20 because while the reviewer doesn't use overtly rude language, their tone is quite critical and direct. They use phrases like 'very hard to read', 'almost incomprehensible', and 'flawed', which come across as somewhat harsh. The reviewer does not soften their criticisms with polite language or positive comments, leading to a slightly negative politeness score."", ""The sentiment score is -60 because the review is predominantly negative. While it acknowledges one positive aspect (the crashed cars dataset), the majority of the review focuses on significant cons and criticisms of the paper. The reviewer points out multiple issues with the methodology, results interpretation, and presentation. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'The authors have definitely found an interesting untapped source of interesting images' which shows some appreciation. However, they don't use overly polite language or soften their criticisms, maintaining a neutral to slightly polite tone overall. The reviewer also provides constructive feedback and specific suggestions for improvement, which contributes to the slightly positive politeness score."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states there are 'several important negative points which should prevent this work, as it is, from being published.' They list multiple criticisms about the relevance, dataset choice, writing quality, and lack of novelty. The only positive point mentioned is that 'performance does not degrade too much.' The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'It is not clear to me' and 'I think the authors should' which soften the critique. The reviewer also provides specific recommendations for improvement, which is constructive and polite. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score.""]"
"['The paper makes a mathematical analogy between deep neural networks and quantum field theory, and claims that this explains a large number of empirically observed phenomena.\n\nI have a solid grasp of the relevant mathematics, and a superficial understanding of QFT, but I could not really make sense of this paper. The paper uses mathematics in a very loose manner. This is not always bad (an overly formal treatment can make a paper hard to read), but in this case it is not clear to me that the results are even ""correct modulo technicalities"" or have much to do with the reality of what goes on in deep nets.\n\nThe first thing I\'m confused about is the nature and significance of the symmetries considered in this paper. At a very high level, there are two kinds of symmetries one could consider in DL: transformations of the input space that leave invariant the desired output, and transformations of the weight space that leave invariant the input/output mapping. These are not necessarily related. For instance, a translation or rotation of an image is an example of the former, whereas an arbitrary permutation of hidden units (and corresponding rows/columns of weight matrices) is an example of the latter. This paper is apparently dealing with groups that act on the input as well as the weight space, seemingly conflating the two.\n\nSection 2.2 defines the action of symmetries on the input and weight space. For each layer t, we have a matrix Q_t in G, where G is an unspecified Lie group. Since all Q_t are elements of the same group, they have the same dimension, so all layers must have the same dimension as well. This is somewhat unrealistic. Furthermore, from the definitions in 2.2 it seems that in order to get covariance, the Q_t would have to be the same for all t, which is probably not what the authors had in mind.\n\nFor symmetries like rotation/translation of images, a better setup would probably involve a single group with different group actions or linear group representations for each layer. In that case, covariance of the weight layers is not automatic, but only holds for certain subspaces of weight space. For permutation or scale symmetries in weight space, a more sensible setup would be to say that each layer has a different group of symmetries, and the symmetry group of the whole network is the direct product of these groups.\n\nIt is stated that transformations in the affine group may not commute with nonlinearities, but rotations of feature maps do. This is correct (at least up to discretization errors), but the paper continues to talk about affine and orthogonal group symmetries. Later on an attempt is made to deal with this issue, by splitting the feature vectors into a part that is put to zero by a ReLU, and a part that is not, and the group is split accordingly. However, this does not make any sense because the pattern of zeros/non-zeros is different for each input, so one cannot speak of a ""remnant symmetry"" for a layer in general.\n\nThe connection between DL and QFT described in 2.3 is based on some kind of ""continuous limit"" of units and layers, i.e. having an uncountably infinite number of them. Even setting aside the enormous amount of technical difficulty involved in doing this math properly, I\'m a bit skeptical that this has anything to do with real networks.\n\nAs an example of how loose the math is, ""theorem 1"" is only stated in natural language: ""Deep feedforward networks learn by breaking symmetries"". The proof involves assuming that the network is a sequence of affine transformations (no nonlinearities). Then it says that if we include a nonlinearity, it breaks the symmetry. Thus, since neural nets use nonlinearities, they break symmetries, and therefore learning works by breaking symmetries and the layers can learn a ""more generalized representation"" than an affine network could. The theorem is so vaguely stated that I don\'t know what it means, and the proof is inscrutable to me.\n\nTheorem 2 states ""Let x^T x be an invariant under Aff(D)"". Clearly x^T x is not invariant under Aff(D).\n\nThe paper claims to explain many empirical facts, but it is not exactly clear which are the conspicuous and fundamental facts that need explaining. For instance, the IB phase transition claimed to happen in deep learning was recently called into question [1]. It appears that this phenomenon does not occur in ReLU nets but only in sigmoid nets, but the current paper purports to explain the phenomenon while assuming ReLUs. I would further note that the paper claims to explain a suspiciously large number of previously observed phenomena (Appendix A), but as far as I can tell does not make novel testable predictions.\n\nThe paper makes several strong claims, like ""we [...] illustrate that spontaneous symmetry breaking of affine symmetries is the sufficient and necessary condition for a deep network to attain its unprecedented power"", ""This phenomenon has profound implications"", ""we have solved one of the most puzzling mysteries of deep learning"", etc. In my opinion, unless it is completely obvious that this is indeed a breakthrough, one should refrain from making such statements.\n\n[1] On the information bottleneck theory of deep learning. Anonymous ICLR2018 submission.', 'In this paper, an number of very strong (even extraordinary) claims are made:\n\n* The abstract promises ""a framework to understand the unprecedented performance and robustness of deep neural networks using field theory.""\n* Page 8 states that this is ""This is a first attempt to describe a neural network with a scalar quantum field theory.""\n* Page 2 promises the use of the ""Goldstone theorem"" (no less) to understand phase transition in deep learning\n* It also claim that many ""seemingly different experimental results can be explained by the presence of these zero eigenvalue weights.""\n* Three important results are stated as ""theorem"", with a statement like ""Deep feedforward networks learn by breaking symmetries"" proven in 5 lines, with no formal mathematics.\n\nThese are extraordinary claims, but  when reaching page 5, one sees that the basis of these claims seems to be the Lagrangian of a simple phi-4 theory, and Fig. 1 shows the standard behaviour of the so-called mexican hat in physics, the basis of the second-order transition. Given physicists have been working on neural network for more than three or four decades, I am surprise that this would enough to solve all these problems!\n\nI tried to understand these many results, but I am afraid I cannot really understand or see them. In many case, the explanation seems to be a vague analogy. These are not without interest, and maybe there is indeed something deep in this paper, but it is so far hidden by the hype. Still, I fail to see how the fact that phase transitions and negative direction in the landscape is a new phenomena, and how it explains all the stated phenomenology. Beside, there are quite a lot of things known about the landscape of these problems \n\nMaybe I am indeed missing something, but i clearly suspect the authors are simply overselling physics results.\n\nI have been wrong many times, but I beleive that the authors should probably precise their claim, and clarify the relation between their results and both the physics AND statistics litterature, or better, with the theoretical physics litterature applied to learning, which is ---astonishing-- absent in the paper.\n\nAbout the content:\n\nThe main problem for me is that the whole construction using field theory seems to be used to advocate for the appearence of a phase transition in neural nets and in learning. This rises three comments:\n\n(1) So we really need to use quantum field theory for this? I do not see what should be quantum here (despite the very vague remarks page 12 ""WHY QUANTUM FIELD THEORY?"")\n\n\n(2) This is not new. Phase transitions in learning in neural nets are being discussed since aboutn 40 years, see for instance all the pionnering work of Sompolinky et al. one can see for instance the nice review in https://arxiv.org/abs/1710.09553 In non aprticular order, phase transition and symmetry breaking are discussed in\n* ""Statistical mechanics of learning from examples"", Phys. Rev. A 45, 6056 – Published 1 April 1992\n* ""The statistical mechanics of learning a rule"", Rev. Mod. Phys. 65, 499 – Published 1 April 1993\n* Phase transitions in the generalization behaviour of multilayer neural networks\nhttp://iopscience.iop.org/article/10.1088/0305-4470/28/16/010/meta\n* Note that some of these results are now rigourous, as shown in ""Phase Transitions, Optimal Errors and Optimality of Message-Passing in Generalized Linear Models"", https://arxiv.org/abs/1708.03395\n* The landscape of these problems has been studied quite extensivly, see for instance ""Identifying and attacking the saddle point problem in high-dimensional non-convex optimization"", https://arxiv.org/abs/1406.2572\n\n\n(3) There is nothing particular about deep neural net and neural nets about this. Negative direction in the Hessian in learning problems appears in matrix and tensor factorizaion, where phase transition are well understood (even rigorously, see for instance, https://arxiv.org/abs/1711.05424 ) or in problems such as unsupervised learning, as e.g.:\nhttps://journals.aps.org/prl/abstract/10.1103/PhysRevLett.86.2174\nhttps://journals.aps.org/pre/pdf/10.1103/PhysRevE.50.1766\n\nHere are additional comments:\n\nPAGE 1:\n\n* ""It has been discovered that the training process ceases when it goes through an information bottleneck (ShwartzZiv & Tishby, 2017)"".\n\nWhile this paper indeed make a nice suggestion, I would not call it a discovery yet as this has never been shown on a large network. Beside, another paper in the conference is claiming exacly the opposite, see : ""On the Information Bottleneck Theory of Deep Learning"". This is still subject of discussion.\n\n* ""In statistical terms, a quantum theory describes errors from the mean of random variables. ""\n\nLast time I studied quantum theory, it was a theory that aim to explain the physical behaviours at the molecular, atomic and sub-atomic levels, usinge either on the wave function (Schrodinger) or the Matrix operatir formalism (Hesienbger) (or if you want, the path integral formalism of Feynman).\n\nIt is certainly NOT a theory that describes errors from the mean of random variables. This is, i beleive, the field of ""statistics"" or ""probability"" for correlated variables. It is certianly used in physics, and heavily both in statistical physics and in quantum thoery, but this is not what the theory is about in the first place.\n\nBeside, there is little quantum in this paper, I think most of what the authors say apply to a statistical field theory ( https://en.wikipedia.org/wiki/Statistical_field_theory )\n\n* ""In the limit of a continuous sample space, the quantum theory becomes a quantum field theory.""\n\nAgain, what is quantum about all this? This true for a field theory, as well for continous theories of, say, mechanics, fracture, etc...\n\nPAGE 2:\n\n* ""Using a scalar field theory we show that a phase transition must exist towards the end of training based on empirical results.""\n\nSo it is a scalar classical field theory after all. This sounds a little bit less impressive that a quantum field theory. Note that the fact that phase transition arises in learning, and in a statistical theory applied to any learning process, is an old topic, with a classical litterature. The authors might be interested by the review ""The statistical mechanics of learning a rule"", Rev. Mod. Phys. 65, 499 – Published 1 April 1993\n\nPAGE 8:\n\n\n* ""In this work we solved one of the most puzzling mysteries of deep learning by showing that deep neural networks undergo spontaneous symmetry breaking.""\n\nI am afraid I fail to see what is so mysterious about this nor what the authors showed about it. In any case, gradient descent break symmetry spontaneously in many systems, including phi-4, the Ising model or (in learning problems) the community detection problem (see eg https://journals.aps.org/prx/abstract/10.1103/PhysRevX.4.011047). I am afraid I miss what is new there...\n\n* ""This is a first attempt to describe a neural network with a scalar quantum field theory.""\n\nGiven there seems to be little quantum in the paper, I fail to see the relevance of the statement. Secondly, I beleive that field theory has been used, many times and in greater lenght, both for statistical and dynamical problems in neural nets, see eg.\n* http://iopscience.iop.org/article/10.1088/0305-4470/27/6/016/meta\n* https://arxiv.org/pdf/q-bio/0701042.pdf\n* http://www.lps.ens.fr/~derrida/PAPIERS/1987/gardner-zippelius-87.pdf\n* http://iopscience.iop.org/article/10.1088/0305-4470/21/1/030/meta\n* https://arxiv.org/pdf/cond-mat/9805073.pdf\n', 'The paper promises quite a few intriguing connections between information bottleneck, phase transitions and deep learning. While we think that this is a worthwhile bridge to build between machine learning and statistical field theory, the exposition of the paper leaves much to be desired. Had it been a clean straightforward application of QFT, as well-trained theoretical physicists, we would have been able to evaluate the paper.\nGenerally, it would help the reader to have an overall map and indication of the steps that would be taken formally. \nSpecifically, starting from Section 2.3, especially around the transition to continuous layers, very little information is provided how one is dealing with the cost function and the results are derived. Section 2.3 would benefit from expanded discussion with examples and detailed explanations.\nMinor:\nThe following sentence in third paragraph of the Introduction is incomplete:\nBecause the ResNet does\nnot contain such symmetry breaking layers in the architecture.']","[-80, -70, -50]","[20, 20, 50]","[""The sentiment score is -80 because the reviewer expresses significant confusion and skepticism throughout the review. They state they 'could not really make sense of this paper' and criticize the loose use of mathematics, unclear theorems, and strong claims without sufficient evidence. The reviewer questions the paper's fundamental assumptions and methodology, indicating a highly negative sentiment. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone and use phrases like 'I'm a bit skeptical' and 'In my opinion' rather than using harsh language. They also acknowledge their own limitations in understanding certain aspects. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -70 because the reviewer expresses significant skepticism about the paper's claims, pointing out numerous issues and suggesting that the authors are 'overselling physics results'. The reviewer questions the novelty and validity of many of the paper's assertions, citing existing literature that contradicts or precedes the authors' claims. However, the score is not at the extreme negative end because the reviewer does acknowledge that there might be 'something deep in this paper' and admits they could be 'missing something'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I am afraid I cannot really understand' and 'Maybe I am indeed missing something', which soften the criticism. The reviewer also offers constructive feedback and suggestions for improvement, which is a polite approach to peer review. However, the score is not higher because there are moments of direct criticism, such as suggesting the authors are 'overselling' their results."", ""The sentiment score is -50 because the review expresses significant concerns about the paper's exposition and clarity, stating that it 'leaves much to be desired.' However, it's not entirely negative as it acknowledges the paper's 'intriguing connections' and considers it a 'worthwhile bridge.' The politeness score is 50 because the reviewer uses respectful language and constructive criticism. They offer specific suggestions for improvement and use phrases like 'it would help the reader' and 'would benefit from,' which are polite ways to provide feedback. The reviewer also acknowledges their own potential limitations in evaluating the paper, which shows humility. However, the review isn't overly effusive or extremely polite, maintaining a professional tone throughout.""]"
"['Summary:\n\nThis paper proposes an encoder-decoder framework for learning latent representations of sets of elements. The model utilizes the neural attention mechanism for set inputs proposed in (Vinyals et al., ICLR 2016) to encode a set into a fixed-length latent representation, and then employs an LSTM decoder to reconstruct the original set of elements, in which a stable matching algorithm is used to match decoder outputs to input elements. Experimental results on synthetic datasets show that the model learns meaningful representations and effectively handles permutation invariance.\n\nMajor Concerns:\n\n1. Although the employed Gale-Shapely algorithm facilitates permutation-invariant set reconstruction, it has O(n^2) computational complexity during each back-propagation iteration, which might prevent it from scaling to sets of fairly big sizes. \n\n2. The experiments are only evaluated on synthetic datasets, and applications of the set autoencoder to real-world applications or scientific problems will make this work more interesting and significant.\n\n3. The main contribution of this work is the adoption of the stable matching algorithm in the decoder. A strong set autoencoder baseline will be, the encoder employs the neural attention mechanism proposed in (Vinyals et al., ICLR 2016), but the decoder just uses a standard LSTM as in a seq2seq framework. Comparisons to this baseline will reveal the contribution of the stable matching procedure in the whole  framework of  the set autoencoder for learning representations. \n\nMinor issues:\n\nOn page 5, above Section 4, d_j -> o_j ?\n\nthe footnote on page 5: we not consider -> we do not consider?\n\non page 6 and 7,   6.000, 1.000 and 10.000 training examples ->  6000, 1000 and 10,000 training examples', 'This paper mostly extends Vinyals et al, 2015 paper (""Order Matters"") on how to represent sets as input and/or output of a deep architecture.\n\nAs far as I understood, the set encoder is the same as the one in ""Order Matters"". If not, it would be useful to underline the differences.\n\nThe decoder, on the other hand, is different and relies on a loss that is based on an heuristic to find the current best order (based on an ordering, or mapping W, found using the Gale-Shapely algorithm). Does this mean that Algorithm 1 needs to be run for every training (and test) example? if so, it is important to note what is the effective complexity of running it?\n\nThe experimental section is interesting, but in the end a bit disappointing: although a new artificial dataset is proposed to evaluate sets, it is unclear how different are the findings from those in the ""Order Matters"" paper:\n- the first set of results (in Section 4.1) confirms that the set encoder is important (which was also in the other paper I believe)\n- the second set of results (Section 4.2) shows that in some cases, an auto-encoder is also useful: this is mostly the case when the supervised data is small compared to the availability of a much larger unsupervised data (of sets). This is interesting (and novel compared to the ""Order Matters"" paper) but corresponds to known findings from most previous work on semi-supervised learning: pre-training is only useful when only a very small supervised data exists, and quickly becomes irrelevant. This is not specific to sets.\n\nFinally, It would have been very interesting to see experiments on real data concerned with sets.\n\n------------------\nI have read the respond to the reviewers but haven\'t seen any reason to\nchange my score. In particular, the authors have not answered my questions\nabout differences with the prior art, and have not provided results on\nreal data.\n\n', 'Summary\nThis paper proposes an autoencoder for sets. An input set is encoded into a\nfixed-length representation using an attention mechanism (previously proposed by\n[1]). The decoder generates the output sequentially and the generated sequence\nis matched to the best-matching ordering of the target output set.\nExperiments are done on synthetic datasets to demonstrate properties of the\nlearned representation.\n\nPros\n- Experiments show that the autoencoder helps improve classification accuracy\n  for small training set sizes on the shape classification task.\n- The analysis of how the decoder generates data is insightful.\n\nCons\n- The experiments are on toy datasets only. Given the availability of point\n  cloud data sets, for example, KITTI which has a widely used benchmark for\npoint cloud based object detection, it would make the paper stronger if this\nmodel was benchmarked against published baselines.\n\n- The autoencoder does not seem to help much on the regression tasks where even\n  for the smaller training set size setting, directly using the encoder to solve\nthe task often works best. Even finetuning is unable to recover from the\npretrained weights. Therefore, it seems that the decoder (which is the novel\naspect of this work) is perhaps not working well, or is not well suited to the\nregression tasks being considered.\n\n- The classification task, for which the learned representations work well\n  empirically, seems to be geared towards representing object shape. It doesn\'t\nreally require remembering each point. On the other hand, the regression tasks\nthat could require remembering the points don\'t seem to be benefit much from the\nautoencoder pretraining. This suggests that while the model is able to represent\noverall shape, it has a hard time remembering individual elements of the set.\nThis seems like a drawback, since a general ""set auto-encoder"" should be able\nto perform a wide variety of tasks on the input set which could require remembering\nthe set\'s elements.\n\nQuality\nThis paper describes the proposed model quite well and provides encouraging\npreliminary results.\n\nClarity\nThe paper is easy to understand.\n\nOriginality\nThe novelty in the model is using a matching algorithm to find the best ordering\nof the target output set to match with the sequentially generated decoder\noutput. However, the paper makes a choice of one ranking based matching scheme\nand does not compare to other alternatives.\n\nSignificance\nThis paper proposes a way of learning representations of sets which will be of\nbroad interest across the machine learning community. These models are likely to\nbecome more relevant with increasing prevelance of point cloud data.\n\nReferences\n[1] Oriol Vinyals, Samy Bengio, and Manjunath Kudlur. Order matters: Sequence to\nsequence for sets. arXiv preprint arXiv:1511.06391.']","[20, -30, 20]","[60, 20, 60]","[""The sentiment score is slightly positive (20) because the review acknowledges the paper's contributions and potential, while also providing constructive criticism. The reviewer notes the model's ability to learn meaningful representations and handle permutation invariance, which are positive aspects. However, the 'Major Concerns' section indicates significant areas for improvement, balancing out the positive elements.\n\nThe politeness score is moderately high (60) due to the reviewer's professional and respectful tone throughout. They use neutral language to present their concerns and suggestions, avoiding harsh criticism. The reviewer also acknowledges the paper's strengths before diving into the concerns, which is a polite approach. The use of phrases like 'will make this work more interesting and significant' suggests a constructive intent rather than purely critical.\n\nThe review maintains a balanced and objective tone, offering both positive feedback and areas for improvement without using overly negative or positive language, which contributes to both the slightly positive sentiment and the polite tone."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some interesting aspects of the paper, they express disappointment with the experimental section and results. They note that the findings are not significantly different from previous work and that the paper lacks experiments on real data. The politeness score is mildly positive (20) as the reviewer uses professional and respectful language throughout, asking questions for clarification rather than making harsh criticisms. They use phrases like 'as far as I understood' and 'it would be useful to' which maintain a polite tone. However, the review is not overly complimentary, keeping the politeness score from being higher."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some pros of the paper, such as improved classification accuracy and insightful analysis. However, they also point out significant cons, including limited experiments on toy datasets and the autoencoder's poor performance on regression tasks. The overall tone suggests cautious approval with substantial room for improvement. The politeness score is moderately high (60) as the reviewer maintains a professional and respectful tone throughout. They use neutral language to present both pros and cons, and their criticisms are constructive rather than harsh. Phrases like 'it would make the paper stronger if' and 'This paper describes the proposed model quite well' contribute to the polite tone. The reviewer also acknowledges the potential significance of the work, which adds to the overall politeness.""]"
"['The paper addresses an important problem of how ML systems can learn episodic memory.\nAuthors, first, criticize the existing approaches and benchmarks for episodic memory, arguing that the latter do not necessarily test episodic memory to the full extent of human-level intelligence.\nThen, a new external memory augmented network (MEM) is proposed which is similar in the spirit to content-based retrieval architectures such as DNC and memory networks, but allows to explicitly exclude certain dimensions of memory vectors from matching. \nAuthors evaluate the proposed MEM together with DNC and simple LSTM baselines on the game of Concentration where they find MEM to outperform concurrent approaches.\n\nUnfortunately, I did not find enough of novelty, clarity or at least rigorous and interesting experiments in the paper to recommend acceptance.\n\nDetailed comments:\n1) When a new architecture is proposed, it is good to describe in detail, at least in the appendix. Currently, it is introduced only implicitly and a reader should infer the details from fig. 2.\n2) It looks like the main difference between DNC and MEM is the way of addressing memories that allow explicit masking. If so, then to me this is a rather minor novelty and to justify it\'s importance authors should run a control experiment with the exact same architecture as in DNC, but with a masked similarity kernel. Besides that, an analysis of that is learned to be masked should be provided, how ""hard"" (i.e. strictly 0 and 1) are the masks, what influences them etc.\n3) While the game of concentration clearly requires episodic memory to some extent, this only task is not enough for testing EM approaches, because there is always a risk that one of the evaluated systems somehow overfitted to this task by design. Especially to reason about human-level intelligence we need a variety of tasks.\n4) To continue the previous point, humans would not perform well in the proposed task with random card labels, because it is very likely that familiar objects on cards help building associations and remembering them. Thus it is impossible to make a human baseline for this task and decide on how far are we below the human level. ', '# Summary\nThis paper proposes an external memory architecture for dealing with partial observability. The proposed method is similar to Memory Q-Network [Oh et al.], but the paper proposes a masked Euclidean distance as a similarity measure for content-based memory retrieval. The results on ""Concentration"" task show that the proposed method outperforms DNC and LSTM.\n\n[Pros]\n- Presents a new memory-related task.\n\n[Cons]\n- No comparison to proper baselines and existing methods.\n- Demonstrated in a single artificial task.\n\n# Novelty and Significance\nThe proposed external memory architecture is very similar to MQN [Oh et al.]. The proposed masked Euclidean distance for similarity measure is quite straightforward. More crucially, there is no proper comparison between the proposed masked Euclidean distance and cosine similarity (MQN). \n \n# Quality\n- The paper does not compare their method against proper baselines (e.g., MQN or the same memory architecture with cosine similarity). DNC is quite a different architecture that has flexible writing/erasing with complex addressing mechanisms. Comparison to DNC does not show the effect of the proposed idea (masked Euclidean distance). \n- The paper shows empirical results only on ""Concentration"" task, which is a bit artificial. In addition, the paper only shows a learning curve without any analysis of the learned model or qualitative results.  \n\n# Clarity\n- Is the masked weight (w) a parameter or an activation of the network? \n- The description of concentration task is a bit lengthy. It would be better to move some details to the appendix.\n- I did not understand the paper\'s claim that ""no existing RL benchmark task could unambiguously evaluate episodic memory in RL agents"" and ""In contrast, an episodic memory task like Concentration presents many previously unseen observations which must be handled correctly without prior exposure"". In the Pattern Matching task from [Oh et al.], the agent is also required to compare two unseen visual patterns during evaluation. ', ""There are a number of attempts to add episodic memory to RL agents. A common approach is to use some sort of recurrent model with a model-free agent. This work follows this approach using what could be considered a memory network with a identity embedding function and tests on 'Concentration', a game which requires matching pairs of cards. They find their model outperforms a DNC and LSTM baselines.\n\nThe primary novelty is the use of an explicitly masked similarity function (with learned mask) and the concentration task, which requires more memory than, for example, common tasks adapted from the psychology literature such as the Morris watermaze or T-maze (although in the supervised setting tasks such as Omniglot are quite similar).\n\nThis work is well-communicated and cites relevant prior work. The author's should also be commended for agreeing to release their code on publication.\n\nThe primary weakness of this work its lack of novelty and lack of evidence of generalization of the approach, which limits its significance. The model introduced is a slight variant of memory networks. Additionally, the single task the model is tested on appears custom-designed to favor the model (see next paragraph). While the analysis of the weakness of cosine similarity is interesting, memory networks which compute separate embeddings for the 'label' (content-based label for retrieval) and memory content don't appear to suffer from the same issue as the DNC. They can store only retrieval-relevant content in the label and thus avoid issues with normalization.\n\nThe observation vector is stored directly in memory without passing through an embedding function, which in general seems quite limiting. However, in the constructed task the labels are low-dimensional, random vectors and there is no noise in the labels (i.e. two cards with the same label are labelled identically, rather the similarly). The author's mention avoiding naturalistic labels such as omniglot characters (closer to the real version of concentration) due to the possibility the agent might memorise the finite set of labels, however by choosing a large dataset and using a non-overlapping set of examples for the test set this probably could be avoided and would provide a more naturalistic test set.\n\nThe comparison with the DNC also seems designed to favor their model. DNC has write-gates, which might be relevant in a task with many irrelevant observations, but in this task are clearly going to impair learning. A memory network seems the more appropriate comparison. Its not clear why the DNC model used two different DNCs for computing the policy and value.\n\nTo demonstrate their model is of more general interest it would be necessary to try on a wider range of more naturalistic tasks and a comparison with model-free agents augmented with memory networks. Simply showing that a customized model can outperform on a single custom, synthetic task is insufficient to demonstrate that these changes are of wider interest.\n\nMinor issues:\n- colorblind seems an odd description for agents which cannot perceive the card face. Why not just 'blind'? colorblind would seem to imply partial perception of the card face.\n\n- the observations of the environment are defined explicitly, but not the action space.""]","[-50, -50, -20]","[20, 20, 60]","[""The sentiment score is -50 because the reviewer states they 'did not find enough of novelty, clarity or at least rigorous and interesting experiments in the paper to recommend acceptance.' This indicates a negative overall sentiment, but not extremely negative as they do acknowledge the paper addresses an important problem. The politeness score is 20 because the reviewer uses polite language throughout, such as 'Unfortunately' to soften criticism, and provides detailed, constructive feedback. However, the criticism is direct, preventing a higher politeness score. The reviewer maintains a professional tone without using overly formal or deferential language."", ""The sentiment score is -50 because the review is generally critical, with more cons than pros listed. The reviewer points out several limitations of the paper, such as lack of comparison to proper baselines, demonstration on only a single artificial task, and similarity to existing methods. However, it's not entirely negative as it acknowledges a new memory-related task as a positive point. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use neutral language like 'The paper does not compare...' rather than more accusatory phrasing. The reviewer also asks clarifying questions and suggests improvements, which is a polite way of addressing issues. The language is not overly formal or deferential, but it avoids rudeness or harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects (well-communicated, relevant citations, code release), they primarily focus on the weaknesses of the work, such as lack of novelty, limited significance, and concerns about the task design favoring the model. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. They use phrases like 'The author's should be commended' and provide specific suggestions for improvement, which contributes to a polite tone. However, the critique is direct and doesn't use overly deferential language, keeping it from scoring higher on politeness.""]"
"['The authors propose a penalization term that enforces decorrelation between the dimensions of the representation \nThey show that it can be included as additional term in cost functions to train generic models.\nThe idea is simple and it seems to work for the presented examples.\n\nHowever, they talk about gradient descent using this extra term, but I\'d like to see the derivatives of the \nproposed term depending on the parameters of the model (and this depends on the model!). On the other hand, \ngiven the expression of the proposed regulatization,\nit seems to lead to non-convex optimization problems which are hard to solve. Any comment on that?.\n\nMoreover, its results are not quantitatively compared to other Non-Linear generalizations of PCA/ICA designed for similar goals (e.g. those cited in the ""related work"" section or others which have been proved to be consistent non-linear generalizations of PCA such as: Principal Polynomial Analysis, Dimensionality Reduction via Regression that follow the family introduced in the book of Jolliffe, Principal Component Analysis).\n\nMinor points: Fig.1 conveys not that much information.', '\nI think the first intuition is interesting. However I think the benefits are not clear enough. Maybe finding better examples where the benefits of the proposed regularization are stressed could help. \n\nThere is a huge amount of literature about ICA, unmixing, PCA, infomax... based on this principle that go beyond of the proposal. I do not see a clear novelty in the proposal.  \n\nFor instance the proposed regularization can be achieved by just adding a linear combination at the layer which based on PCA. As shown in [Szegedy et al 2014, ""Intriguing properties of neural networks""] adding an extra linear transformation does not change the expressive power of the representation.    \n\n\n- ""Inspired by this, we consider a simpler objective: a representation disentangles the data well when its components do not correlate...""\n\nThe first paragraph is confusing since jumps from total correlation to correlation without making clear the differences.\nAlthough correlation is a second oder approach to total correlation are not the same. This is extremely important since the whole proposal is based on that.\n\n- Sec 2.1. What prevents the regularization to enforce the weights in the linear layers to be very small and thus minimize the covariance. I think the definition needs to enforce the out-diagonal terms in C to be small with respect to the terms in the diagonal.   \n\n- All the evaluation measures are based on linear relations, some of them should take into account non-linear relations (i.e. total correlation, mutual information...) in order to show that the method gets something interesting.\n\n- The first experiment (dim red) is not clear to me. The original dimensionality of the data is 4, and only a linear relation is introduced. I do not understand the dimensionality reduction if the dimensionality of the transformed space is 10. Also the data problem is extremely simple, and it is not clear the didactic benefit of using it. I think a much more complicated data would be more interesting. Besides L_1 is not well defined. If it is L_1 norm on the output coefficients the comparison is misleading. \n\n- Sec 3.3. As in general the model needs to be compared with other regularization techniques to stress its benefits.\n\n- Sec 3.4. Here the comparison makes clear that not a real benefit is obtained with the proposal. The idea behind regularization is to help the model to avoid overfitting and thus improving the quality of the prediction in future samples. However the MSE obtained when not using regularization is the same (or even smaller) than when using it.   \n', ""This paper presents a regularization mechanism which penalizes covariance between all dimensions in the latent representation of a neural network. This penalty is meant to disentangle the latent representation by removing shared covariance between each dimension. \n\nWhile the proposed penalty is described as a novel contribution, there are multiple instances of previous work which use the same type of penalty (Cheung et. al. 2014, Cogswell et. al. 2016). Like this work, Cheung et. al. 2014 propose the XCov penalty which penalizes cross-covariance to disentangle subsets of dimensions in the latent representation of autoencoder models. Cogswell et. al. 2016 also proposes a similar penalty (DeCov) to this work for reducing overfitting in supervised learning.\n\nThe novel contribution of the regularizer proposed in this work is that it also penalizes the variance of individual dimensions along with the cross-covariance. Intuitively, this should lead to dimensionality reduction as the model will discard variance in dimensions which are unnecessary for reconstruction. But given the similarity to previous work, the authors need to quantitatively evaluate the value in additionally penalizing variance of each dimension as compared with earlier work. Cogswell et. al. 2016 explicitly remove these terms from their regularizer to prevent the dynamic range of the activations from being unnecessarily rescaled.  It would be helpful to understand how this approach avoids this issues - i.e.,  if you penalize all the variance terms then you could just be arbitrarily rescaling the activities, so what prevents this trivial solution?\n\nThere doesn't appear to be a definition of the L1 penalty this paper compares against and it's unclear why this is a reasonable baseline. The evaluation metrics this work uses (MAPC, CVR, TdV, UD) need to be justified more in the absence of their use in previous work. While they evaluate their method on non-toy dataset such as CIFAR, they do not show what the actual utility of their proposed regularizer serves for such a dataset beyond having no-regularization at all. Again, the utility of the evaluation metrics proposed in this work is unclear.\n\nThe toy examples are kind of interesting but it would be more compelling if the dimensionality reduction aspect extended to real datasets.\n\n> Our method has no penalty on the performance on tasks evaluated in the experiments, while it does disentangle the data\n\nThis needs to be expanded in the results as all the results presented appear to show Mean Squared Error increasing when increasing the weight of the regularization penalty.\n""]","[20, -50, -30]","[50, 20, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and effectiveness of the proposed method in the first paragraph, stating 'The idea is simple and it seems to work for the presented examples.' However, the reviewer also raises several concerns and requests for additional information, which tempers the overall positive sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I'd like to see' and 'Any comment on that?' which are polite ways of requesting more information. The reviewer also provides constructive feedback and suggestions for improvement without using harsh or dismissive language. The balance between positive acknowledgment and constructive criticism contributes to both the slightly positive sentiment and the moderately polite tone."", ""The sentiment score is -50 because the reviewer expresses several criticisms and doubts about the paper's novelty, clarity, and effectiveness. They mention that the benefits are not clear, there's a lack of novelty, and comparisons show no real benefit. However, they do acknowledge an 'interesting first intuition', preventing a more negative score. The politeness score is 20 because the reviewer uses generally neutral language and offers constructive feedback. They suggest improvements ('Maybe finding better examples...') and explain their concerns without using harsh or rude language. The tone is professional and academic, slightly leaning towards politeness without being overly deferential."", ""The sentiment score is -30 because the review is generally critical, pointing out several issues with the paper's novelty and evaluation methods. However, it's not entirely negative as it acknowledges some interesting aspects and suggests improvements. The politeness score is 20 because the reviewer uses professional and respectful language throughout, offering constructive criticism without being harsh. They use phrases like 'it would be helpful' and 'it would be more compelling,' which are polite ways to suggest improvements. The reviewer also acknowledges positive aspects, such as the 'kind of interesting' toy examples, which contributes to the overall polite tone.""]"
"['Pros:\nThe paper is a nice read, clearly written, and its originality is well stated by the authors, “addressing the lifetime clustering problem without end-of-life signals for the first time”. I do not feel experienced enough in the field to evaluate the significance of this work.\n\nThe approach proposed in the manuscript is mainly based on a newly-designed nonparametric loss function using the Kuiper statistic and uses a feed-forward neural network to optimize the loss function. This approach does challenge some traditional assumptions, such as the presence of end-of-life signals or the artificial defined timeouts. Instead of giving a clear end-of-life signal, the authors specify a probability of end-of-life that permits us to take into account the associated uncertainty. By analyzing a large-scale social network dataset, it is shown that the proposed method performs better on average than the other two traditional models.\n\nCons:       \nI think that the main drawback of the paper is that the structure of the neural network and the deep learning techniques used for optimizing the loss function are not explained in sufficient detail. ', 'Authors provide an interesting loss function approach for clustering using a deep neural network. They optimize Kuiper-based nonparametric loss and apply the approach on a large social network data-set.  However, the details of the deep learning approach are not well described. Some specific comments are given below.\n\n1.Further details on use of 10-fold cross validation need to be discussed including over-fitting aspect.\n2. Details on deep learning, number of hidden layers, number of hidden units, activation functions, weight adjustment details on each learning methods should be included.\n\n3. Conclusion section is very brief and can be expanded by including a discussion on results comparison and  over fitting aspects in cross validation. Use of Kuiper-based nonparametric loss should also be justified as there are other loss functions can be used under these settings.\n', ""This paper discusses an application of survival analysis  in social networks.\n\nWhile the application area seems to be pertinent, the statistics as presented in this paper are suboptimal at best. There is no useful statistical setup described (what is random? etc etc), the interplay between censoring and end-of-life is left rather fuzzy, and mentioned clustering approaches are extensively studied in the statistical literature in so-called frailty analysis. The setting is also covered in statistics in the extensive literature on repeated measurements  and even time-series analysis. It's up to the authors discuss similarities and differences of results of the present approach and those areas.\n\nThe numerical result is not assessing the different design decisions of the approach (why use a Kuyper loss?) in this empirical paper.\n\n""]","[60, 20, -60]","[80, 60, -20]","[""The sentiment score is 60 (positive) because the reviewer starts with positive comments, praising the paper as 'a nice read, clearly written' and acknowledging its originality. They also highlight the paper's strengths and innovative approach. However, it's not a perfect score due to the mentioned drawback in the 'Cons' section. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, even when expressing criticism. They use phrases like 'I do not feel experienced enough' and 'I think that' which show humility and present criticism as personal opinion rather than harsh judgment. The reviewer also balances positive and negative feedback, which is a polite approach in academic reviews."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the work as 'interesting' and recognizes the authors' efforts in optimizing a new loss function and applying it to a large dataset. However, the reviewer also points out significant areas for improvement, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, starting with positive aspects before moving to constructive criticism. They use phrases like 'need to be discussed' and 'should be included' rather than more demanding language. The review maintains a professional tone without any harsh or rude comments, focusing on specific recommendations for improvement rather than criticizing the authors directly."", ""The sentiment score is -60 because the reviewer expresses significant criticism of the paper's statistical approach, describing it as 'suboptimal at best' and pointing out several shortcomings. They also suggest that the authors have not adequately addressed existing literature in the field. The lack of positive comments and the focus on criticisms indicate a negative sentiment. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite direct and critical without much attempt to soften the feedback. Phrases like 'suboptimal at best' and the imperative 'It's up to the authors to discuss...' come across as somewhat brusque. However, the reviewer does not resort to personal attacks or extremely harsh language, which prevents the score from being lower.""]"
"['The paper falls far short of the standard expected of an ICLR submission. \n\nThe paper has little to no content. There are large sections of blank page throughout. The algorithm, iterative temporal differencing, is introduced in a figure -- there is no formal description. The experiments are only performed on MNIST. The subfigures are not labeled. The paper over-uses acronyms; sentences like “In this figure, VBP, VBP with FBA, and ITD using FBA for VBP…” are painful to read. \n\n\n', '- This paper is not well written and incomplete. There is no clear explanation of what exactly the authors want to achieve in the paper, what exactly is their approach/contribution, experimental setup, and analysis of their results. \n\n- The paper is hard to read due to many abbreviations, e.g., the last paragraph in page 2. \n\n- The format is inconsistent. Section 1 is numbered, but not the other sections. \n\n- in page 2, what do the numbers mean at the end of each sentence? Probably the figures? \n\n- in page 2, ""in this figure"": which figure is this referring to?\n\n\nComments on prior work:\n\np 1: authors write: ""vanilla backpropagation (VBP)"" ""was proposed around 1987 Rumelhart et al. (1985)."" \n\nNot true. A main problem with the 1985 paper is that it does not cite the inventors of backpropagation. The VBP that everybody is using now is the one published by  Linnainmaa in 1970, extending Kelley\'s work of 1960. The first to publish the application of VBP to NNs was Werbos in 1982. Please correct. \n\np 1: authors write: ""Almost at the same time, biologically inspired convolutional networks was also introduced as well using VBP LeCun et al. (1989).""\n\nHere one must cite the person who really invented this biologically inspired convolutional architecture (but did not apply backprop to it): Fukushima (1979). He is cited later, but in a misleading way. Please correct.\n\np 1: authors write: ""Deep learning (DL) was introduced as an approach to learn deep neural network architecture using VBP LeCun et al. (1989; 2015); Krizhevsky et al. (2012)."" \n\nNot true. Deep Learning was introduced by Ivakhnenko and Lapa in 1965: the first working method for learning in multilayer perceptrons of arbitrary depth. Please correct. (The term ""deep learning"" was introduced to ML in 1986 by Dechter for something else.)\n\np1: authors write: ""Extremely deep networks learning reached 152 layers of representation with residual and highway networks He et al. (2016); Srivastava et al. (2015)."" \n\nHighway networks were published half a year earlier than resnets, and reached many hundreds of layers before resnets. Please correct.\n\n\nGeneral recommendation: Clear rejection for now. But perhaps the author want to resubmit this to another conference, taking into account the reviewer comments.\n\n', 'The paper is incomplete and nowhere near finished, it should have been withdrawn. \n\nThe theoretical results are presented in a bitmap figure and only referred to in the text (not explained), and  the results on datasets are not explained either (and pretty bad). A waste of my time.']","[-90, -80, -100]","[-30, -20, -50]","[""The sentiment score is -90 because the review is overwhelmingly negative. The first sentence states that the paper 'falls far short of the standard expected,' and the rest of the review lists multiple serious shortcomings without any positive aspects. The politeness score is -30 because while the reviewer doesn't use explicitly rude language, the tone is quite harsh and dismissive. Phrases like 'little to no content' and 'painful to read' are particularly blunt. The reviewer doesn't attempt to soften criticism or offer constructive suggestions, which contributes to the negative politeness score. However, it's not at the extreme end of rudeness as it doesn't contain personal attacks or offensive language."", ""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer states that the paper is 'not well written and incomplete,' 'hard to read,' and has inconsistent formatting. They also point out multiple factual errors and misattributions in the paper's discussion of prior work. The review concludes with a 'Clear rejection for now' recommendation. The politeness score is -20 because while the reviewer provides specific feedback, the tone is quite direct and critical without much attempt to soften the criticism. Phrases like 'Not true' and the blunt rejection recommendation come across as somewhat impolite. However, the reviewer does offer the possibility of resubmission and provides detailed feedback for improvement, which prevents the score from being even lower."", ""The sentiment score is -100 (extremely negative) because the reviewer expresses strong disapproval of the paper, calling it 'incomplete and nowhere near finished' and 'a waste of my time.' There are no positive comments whatsoever. The politeness score is -50 (moderately rude) because while the reviewer doesn't use explicitly offensive language, the tone is dismissive and harsh. Phrases like 'should have been withdrawn' and 'a waste of my time' are particularly impolite. The reviewer makes no attempt to soften their criticism or offer constructive feedback, which contributes to the negative politeness score.""]"
"['This paper presents a model-based approach to variance reduction in policy gradient methods.  The basic idea is to use a multi-step dynamics model as a ""baseline"" (more properly a control variate, as the terminology in the paper uses, but I think baselines are more familiar to the RL community) to reduce the variance of a policy gradient estimator, while remaining unbiased.  The authors also discuss how to best learn the type of multi-step dynamics that are well-suited to this problem (essentially, using off-policy data via importance weighting), and they demonstrate the effectiveness of the approach on four continuous control tasks.\n\nThis paper presents a nice idea, and I\'m sure that with some polish it will become a very nice conference submission. But right now (at least as of the version I\'m reviewing), the paper reads as being half-finished.  Several terms are introduced without being properly defined, and one of the key formalisms presented in the paper (the idea of ""embedding"" an ""imaginary trajectory"" remains completely opaque to me.  Further, the paper seems to simply leave out some portions: the introduction claims that one of the contributions is ""we show that techniques such as latent space trajectory embedding and dynamic unfolding can significantly boost the performance of the model based control variates,"" but I see literally no section that hints at anything like this (no mention of ""dynamic unfolding"" or ""latent space trajectory embedding"" ever occurs later in the paper).\n\nIn a bit more detail, the key idea of the paper, at least to the extent that I understood it, was that the authors are able to introduce a model-based variance-reduction baseline into the policy gradient term.  But because (unlike traditional baselines) introducing it alone would affect the actual estimate, they actually just add and subtract this term, and separate out the two terms in the policy gradient: the new policy gradient like term will be much smaller, and the other term can be computed with less variance using model-based methods and the reparameterization trick.  But beyond this, and despite fairly reasonable familiarity with the subject, I simply don\'t understand other elements that the paper is talking about.\n\nThe paper frequently refers to ""embedding"" ""imaginary trajectories"" into the dynamics model, and I still have no idea what this is actually referring to (the definition at the start of section 4 is completely opaque to me).  I also don\'t really understand why something like this would be needed given the understanding above, but it\'s likely I\'m just missing something here.  But I also feel that in this case, it borders on being an issue with the paper itself, as I think this idea needs to be described much more clearly if it is central to the underlying paper.\n\nFinally, although I do think the extent of the algorithm that I could follow is interesting, the second issue with the paper is that the results are fairly weak as they stand currently.  The improvement over TRPO is quite minor in most of the evaluated domains (other than possibly in the swimmer task), even with substantial added complexity to the approach.  And the experiments are described with very little detail or discussion about the experimental setup.\n\nNor are either of these issues simply due to space constraints: the paper is 2 pages under the soft ICLR limit, with no appendix.  Not that there is anything wrong with short papers, but in this case both the clarity of presentation and details are lacking.  My honest impression is simply that this is still work in progress and that the write up was done rather hastily.  I think it will eventually become a good paper, but it is not ready yet.', 'The main idea of the paper is to improve off-policy policy gradient estimates using control variates based on multi-step rollouts, and reduce the variance of those control variates using the reparameterization trick. This is laid out primarily in Equations 1-5, and seems like a nice idea, although I must admit I had some trouble following the maths in Equation 5. They include results showing that their method has better sample efficiency than TRPO (which their method also uses under the hood to update value function parameters).\n\nMy main issue with this paper is that the empirical section is a bit weak, for instance only one run seems to be shown for both methods, there is no mention of hyper-parameter selection, and the measure used for generating Table 1 seems pretty arbitrary to me (how were those thresholds chosen?). In addition, one thing I would have liked to get out of this paper is a better understanding of how much each component helps. This could have been done via empirical work, for instance:\n- Explore the effect of the planning horizon, and implicitly compare to SVG(1), which as the authors point out is the same as their method with a horizon of 1.\n- Show the effect of the reparameterization trick on estimator variance.\n- Compare the bias and variance of TRPO estimates vs the proposed method.', 'The paper studies a combination of model-based and model-free RL. The idea is to train a forward predictive model which provides multi-step estimates to facilitate model-free policy learning.  Some parts of the paper lack clarity and the empirical results need improvement to support the claims (see details below).   \n\nClarity \n- The main idea of the proposed method is clear. \n- Some notations and equations are broken. For example: \n(1) The definition of \\bar{A} in Section 4 is broken. \n(2) The overall objective in Section 5 is broken. \n(3) The computation of w in Algorithm 2 is problematic. \n- Some details of the experiments/methods are confusing. For example: \n(1) The step number k is dynamically determined by a short line search as in Section 4 ``Dynamic Rollout’’, but later in the experiments (Section 6) the value of k is set to be 2 uniformly. \n(2) Only the policy and value networks specified. The forward models are not specified.  \n(3) In algorithm 1, what exact method is used in determining if \\mu is converged or not? \n\nOriginality\nThe proposed method can be viewed as a multi-step version of the stochastic value gradient algorithm. An empirical comparison could be helpful but not provided. \n\nThe idea of the proposed method is related to the classic Dyna methods from Sutton. A discussion on the difference would be helpful. \n\nSignificance\n- The paper could compare against other relevant baselines that combine model-based and model-free RL methods, such as SVG (stochastic value gradient). \n- To make a fair comparison, the results in Table 1 should consider the amount of data used in pre-training the forward models. Current results in Table 1 only compare the amount of data in policy learning.  \n- Figure 3 is plotted for just one random starting state. The Figure could have been more informative if it was averaged over different starting states.  The same issue is found in Figure 2.  It would be helpful if the plots of other domains are provided. \n- In Figure 2, even though the diff norm fluctuates, the cosine similarity remains almost constant. Does it suggest the cosine similarity is not effective in measuring the state similarity? \n- Figure 1, 4 and 5 need confidence intervals or standard errors. \n\nPros:\n- The research direction in combining model-based and model-free RL is interesting.\n- The main idea of the proposed method is clear. \n\nCons:\n- Parts of the paper are unclear and some details are missing. \n- The paper needs more discussion and comparison to relevant baseline methods.  \n- The empirical results need improvement to support the paper’s claims. \n']","[-50, 20, -30]","[20, 60, 50]","[""The sentiment score is -50 because while the reviewer acknowledges that the paper presents 'a nice idea' with potential, they also express significant concerns about the paper being 'half-finished', lacking clarity, and having weak results. The reviewer states that the paper 'is not ready yet', indicating a generally negative sentiment despite seeing some potential. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I'm sure that with some polish it will become a very nice conference submission' and 'My honest impression is...'. They critique the paper without using harsh language, but also don't go out of their way to be overly polite or complimentary."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's 'nice idea' and potential improvements to policy gradient estimates. However, they express some concerns about the empirical section and mathematical clarity, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's merits while offering constructive criticism. They use phrases like 'I must admit' and 'I would have liked' which maintain a polite tone while expressing their thoughts. The reviewer also provides specific suggestions for improvement without using harsh or dismissive language."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('The research direction is interesting', 'The main idea is clear'), there are significant criticisms and areas for improvement mentioned. The review points out several issues with clarity, lack of comparisons, and the need for improved empirical results. The overall tone suggests the paper needs substantial work before it can be considered acceptable.\n\nThe politeness score is 50 because the reviewer maintains a professional and constructive tone throughout. They provide specific examples of issues and suggestions for improvement without using harsh language. The review is structured with 'Pros' and 'Cons' sections, which is a balanced approach. The reviewer uses phrases like 'could be helpful' and 'would be helpful' when making suggestions, which is polite. However, the score is not higher because the review is direct in its criticisms without excessive softening language.""]"
"['\nAs one can see by the title, the originality (application of DCNN) and significance (limited to ATM domain) is very limited. If this is still enough for ICLR, the paper could be okay. However, even so one can clearly see that the architecture, the depth, the regularization techniques, and the evaluation are clearly behind the state of the art. Especially for this problem domain, drop-out and data augmentation should be investigated.\n\nOnly one dataset is used for the evaluation and it seems to be very limited and small. Moreover, it seems that the same subjects (even if it is other pictures) may appear in the training set and test set as they were randomly selected. Looking into the referece (to get the details of the dataset -  from a workshop of the IEEE International Conference on Computer Vision Workshops (ICCVW) 2017) reveals, that it has only 25 subjects and 10 disguises. This makes it even likely that the same subject with the same disguise appears in the training and test set.\n\nA very bad manner, which unfortunately is often performed by deep learning researchers with limited pattern recognition background, is that the accuracy on the test set is measured for every timestamp and finally the highest accuracy is reported. As such you perform an optimization of the paramerter #iterations on the test set, making it a validation set and not an independent test set. \n\nMinor issues:\nmake sure that the capitalization in the references is correct (ATM should be capital, e.g., by putting {ATM} - and many more things).', 'The paper is relatively clear to follow, and implement. \n\nThe main concern is that this looks like a class project rather than a scientific paper. For a class project this could get an A in a ML class!\n\nIn particular, the authors take an already existing dataset, design a trivial convolutional neural network, and report results on it. There is absolutely nothing of interest to ICLR except for the fact that now we know that a trivial network is capable of obtaining 90% accuracy on this dataset.', ""This paper is an application paper on detecting when a face is disguised, however it is poorly written and do not contribute much in terms of novelty of the approach. The application domain is interesting, however it is simply a classification problem\n\nThe paper is written clearly (with mistakes in an equation), however, it does not contribute much in terms of novelty or new ideas.\n\nTo make the paper better, more empirical results are needed. In addition, it would be useful to investigate how this particular problem is different than a binary classification problem using CNNs.\n\nNotes:\nEquation 2 has a typo, '*'""]","[-70, -50, -50]","[-20, -20, 0]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer criticizes the paper's originality, significance, methodology, and evaluation. They point out several limitations and issues with the research, such as limited dataset, potential data leakage, and outdated techniques. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite critical and dismissive. Phrases like 'very bad manner' and 'limited pattern recognition background' come across as somewhat condescending. The reviewer does not offer many positive comments or constructive suggestions, which contributes to the overall negative tone."", ""The sentiment score is -50 because while the reviewer acknowledges that the paper is clear and implementable, they express significant concerns about its scientific value, stating it looks more like a class project than a scientific paper. The politeness score is -20 because the language, while not overtly rude, is quite blunt and dismissive. The reviewer uses phrases like 'absolutely nothing of interest' and 'trivial network', which come across as somewhat harsh. The reviewer does offer a small positive note about the paper potentially getting an 'A' in a ML class, but this is framed in a way that further emphasizes its lack of suitability for a scientific conference. The overall tone is critical and somewhat condescending, lacking the constructive feedback and politeness typically expected in peer reviews."", ""The sentiment score is -50 because the review is generally negative, stating that the paper is 'poorly written' and 'does not contribute much in terms of novelty'. However, it's not entirely negative as it acknowledges that the application domain is interesting. The politeness score is 0 (neutral) because the reviewer uses direct language without being overtly polite or rude. They state their criticisms plainly ('poorly written', 'do not contribute much') but also offer constructive suggestions for improvement. The language is professional and matter-of-fact, neither particularly courteous nor disrespectful.""]"
"['Summary: The paper proposes a self-play model for goal oriented dialog generation, aiming to enforce a stronger coupling between the task reward and the language model.\n\nContributions:\n\nWhile there are architectural changes (e.g. the customer agent and client agent have different roles and parameters; the parameters of both agents are updated via self-play training), the information isolation claim is not clear. Both the previous work (Lewis et al., 2017) and the proposed approach pitch two agents against each other and the agents communicate via language utterances alone (e.g. rather than exchanging hidden states). In the previous work, the two agents share a set of initial conditions (the set of objects to be divided; this is required by the nature of the task: negotiation), but the goals of each agent are hidden and the negotiation process and outcome are only revealed through natural language. Could you expand on your claim regarding information isolation? Could you design an experiment which highlights the contribution and provide a comparison with the previous approach?\n\nFurthermore, divergence from natural language when optimizing the task reward remains an issue. As a result, both methods require alternate training between the supervised loss and the reinforcement loss.\n\nExperiments:\n\n1. Minor question: During self-play ""we conduct 1 supervised training using the training data every time we make a reinforcement update"". One iteration or one epoch of supervised training?\n\n2. The method is only evaluated on a toy dataset where both the structure of the dialog is limited (see figure 2) and the sentences themselves (the number of language templates is not provided). The referenced negotiation paper uses data collected from mechanical turk ensuring more diversity and the dataset is publicly available. Couldn\'t your method be applied to that setting for comparison?\n\n3. The qualitative evaluation shows compelling examples from the model. Are the results hand-picked to highlight the two outcomes? I wish more examples and some statistics regarding the diversity of produced dialogs were provided (e.g. how many times to they result in a booked flight vs. unfulfilled request and compare that with the training data).\n\n4. What is the difference between evaluation reward reported in Table 4 and self-play evaluation reward reported in Table 5? (Is the former obtained by conditioning on target utterances?). Is there a reason to not report the itemized rewards in Table 5 as well (Eval flight, Eval action) etc?\n\n5. The use of the value network vs. the policy network is not clarified in the model description nor in the experiments. Is the value network used to reduce the variance in the reward?\n\nFinally, there are several typos or grammatical errors, including:\n- Page 4, t and i should be the same.\n- Page 4. Use p(u_t |  t_{<t-1}; \\theta) instead of p(u_t |  t_{<t-1} | \\theta).\n- Page 2, second paragraph: ""which correctness"" -> ""whose correctness"".\n- Page 2, second-to-last paragraph: ""access to a pieces"" -> ""access to pieces"", ""to the best of it can"" -> ""as good as it can"".\n- Page 4. ""feeded"" -> fed\n- Page 5, second-to-last paragraph: ""dataset is consists of"" -> ""dataset consists of"".\n- Page 7/8: Both examples are labeled ""Sample dialog 1""\n- Dataset & experiments: Table 3 and Table 3\n- Experiments: ""to see how our model performs qualitative"" -> ""to see how our model performs qualitatively""\n- Related work: ""... of studying dialog system is to ..."" -> ""dialog systems""\n- Conclusion: ""In those scenario"" -> ""In those scenarios""', 'This paper describes a method for improving a goal oriented dialogue system using selfplay. Using similar techniques to previous work, they pretrain the model using supervised learning, and then update it with selfplay reinforcement learning. The model is evaluated on a synthetic flight booking task, and selfplay training improves the results.\n\nI found it very difficult to work out what the contribution of this paper is over previous work, particularly the Lewis et al. (2017) paper that they cite. The approach to using selfplay RL seems almost identical in each case, so there doesn’t appear to be a technical contribution. The authors say that in contrast to Lewis et al. their “setting enforces the isolation of information between the models of the two agents” - I’m not sure what this means, but the agents in Lewis et al. each have information that the other does not. They also claim that Lewis et al.’s task “can easily degenerate into classification problems without the need to interact through dialogue”, but offer no justification for this claim.\n\nThe use of a synthetic dataset also weakens the paper, and means it is unclear if the results will generalize to real language. For example, Lewis et al. note challengings in avoiding divergence from human language during selfplay, which are likely to be less pronounced on a synthetic dataset. \n\nOverall, the paper needs to be much clearer about what its contributions are over previous work before it can be accepted.\n', 'I like the idea of coupling the language and the conversation model. This is in line with the latest trends of constructing end-to-end NN models that deal with the conversation in a holistic manner. The idea of enforcing information isolation is brilliant. Creating hidden information and allowing the two-party model to learn through self-play is a very interesting approach and the results seem promising. \n\nHaving said that, I feel important references are missing and specific statements of the paper, like that ""Their success is however limited to conversations with very few turns and without goals"" can be argued. There are papers that are goal oriented and have many turns. I will just provide one example, to avoid being overwhelming, although more can be found in the literature. That would be the paper of T.-H. Wen, D. Vandyke, N. Mrksic, M. Gasic, L. Rojas-Barahona, P.-H. Su, S. Ultes and S. Young (2017). ""A Network-based End-to-End Trainable Task-oriented Dialogue System."" EACL 2017, Valencia, Spain. In fact in this paper even more dialogue modules are coupled. So, the ""fresh challenge"" of the paper can be argued. \n\nIt is not clear to me how you did the supervised part of the training. To my experience, although supervised learning can be used, reinforcement learning seems to be the most popular choice. Also, I had to read most of the paper to understand that the system is based on a simulator. Additionally, it is not clear how you got the ground-truth for the training. How are the action and the dialogue generated by the simulator guaranteed to follow the optimal policy?\n \nI also disagree with the statement that ""based on those... to estimate rewards"". If ruled-based systems were sufficient, there would not be a need for statistical dialogue managers. However, the latter is a very active research area. \n\nFigure 1 is missing information (for my likings), like not defined symbols. In addition, it\'s not self-contained. Also, I would prefer a longer, descriptive and informative label to make the figure as self-explained as possible. I believe it would add to the clarity of the paper. \n\nAlso, fundamental information, according to my opinion is missing. For example, what are the restrictions R and how is the database K formed? What is the size of the database? How many actions do you define? Some of them are defined in the action state decoder, but it is not clear if it is all of them.\n\n\nGRU -> abbreviation not defined\n\nI would really appreciate a figure to better explain the subsection ""Encoding External Knowledge"". In the current form I am struggling to understand what the authors mean. \n\nHow is the embedding matrix E created?\n\nHave you tried different unit sizes d? Have you tried different unit sizes for the customer and the service? \n\n""we use 2 transformation matrixes"" -> if you could please provide more details\n\nHow is equation 2 related to figure 1? \n\nTypo: ""name of he person""\n\n""During the supervised learning... and the action states"". I am not sure I get what you mean. May you make this statement more clearly by adding an equation for example?\n\nWhat happens if you use random rather than supervised learning weight initialisation? \n\nEquation 7: What does T stand for?\n\nI cannot find Table 1, 2 and 5 referred to in-text. Moreover I am not sure about quite some items. For example, what is number db? What is the inference set? \n\n500k of data is quite some. A figure on convergence would be nice.\n\nSetting generator: You mention the percentage of book and flight not found. What about the rest of the cases? \n\n\nTypo: “table 3 and table 3”\n\nThe set of the final states of the dialogue is not the same as the ones presented at Fig. 2.\n\nSub section reward generation is poorly described. After all, reward seems to play a very important role for the proposed system. Statements like  “things such as” (instead the exhaustive list of rules for example) or “the error against the optimal distance” with no note what should be considered the optimal distance make the paper clarity decreased and the results not possible to be reproduced. Personally I would prefer to see some equations or a flow chart. By the way, have you tried and alternative reward function? \n\n\nTable 4 is not easy for me to understand. For example, what do you mean when you say eval reward?\n\nImplementation details. I fail to understand how the supervised learning is used (as said already). Also you make a note for the value network, but not for the policy network. \n\nThere are some minor issues with the references such as pomdp or lstm not being capitalised\n\n\nIn general, I believe that the paper has a great potential and is a noticeable work. However, \nthe paper could be better organised. Personally, I struggled with the clarity of some text portions.\nFor me, the main drawback of the paper is that it was\'t tested with human users. The actual success of the system when evaluated by humans can be surprisingly different from the one that comes from simulation. ']","[-20, -50, 50]","[60, 0, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('compelling examples'), they raise several critical points and questions about the methodology, experiments, and clarity of contributions. The review is not overwhelmingly negative, but it does highlight significant areas for improvement. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and provides detailed, constructive feedback. They also acknowledge positive aspects and use polite phrases like 'Could you expand on...'. The reviewer maintains a professional tone while clearly communicating areas of concern."", ""The sentiment score is -50 because the review is generally critical and points out several weaknesses in the paper, such as lack of clear contribution over previous work and use of a synthetic dataset. However, it's not entirely negative as it acknowledges some aspects of the work. The politeness score is 0 (neutral) because the reviewer uses professional language without being overly polite or rude. They express criticisms directly but without harsh language, maintaining a neutral, academic tone throughout the review."", ""The sentiment score is 50 (slightly positive) because the reviewer starts with positive comments about the paper's ideas and approach, calling them 'brilliant' and 'very interesting'. However, they also raise several concerns and criticisms throughout the review, balancing out the initial positivity. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, often prefacing criticisms with phrases like 'I feel', 'It is not clear to me', and 'I would really appreciate'. They also offer constructive feedback and suggestions for improvement. The reviewer maintains a professional tone, even when disagreeing with the authors' statements. The combination of positive acknowledgment of the work's potential and the courteous phrasing of criticisms contributes to the overall polite tone.""]"
"['The authors studied the behavior that a strong regularization parameter may lead to poor performance in training of deep neural networks. Experimental results on CIFAR-10 and CIFAR-100 were reported using AlexNet and VGG-16. The results seem to show that a delayed application of the regularization parameter leads to improved classification performance.\n\nThe proposed scheme, which delays the application of regularization parameter, seems to be in contrast of the continuation approach used in sparse learning. In the latter case, a stronger parameter is applied, followed by reduced regularization parameter. One may argue that the continuation approach is applied in the convex optimization case, while the one proposed in this paper is for non-convex optimization. It would be interesting to see whether deep networks can benefit from the continuation approach, and the strong regularization parameter may not be an issue because the regularization parameter decreases as the optimization progress goes on.\n\nOne limitation of the work, as pointed by the authors, is that experimental results on big data sets such as ImageNet is not reported. \n', ""The paper is well motivated and written. However, there are several issues.\n1. As the regularization constant increases, the performance first increases and then falls down -- this specific aspect is well known for constrained optimization problems. Further, the sudden drop in performance also follows from vanishing gradients problem in deep networks. The description for ReLUs in section 2.2 follows from these two arguments directly, hence not novel. Several of the key aspects here not addressed are: \n1a. Is the time-delayed regularization equivalent to reducing the value (and there by bringing it back to the 'good' regime before the cliff in the example plots)? \n1b. Why should we keep increasing the regularization constant beyond a limit? Is this for compressing the networks (for which there are alternate procedures), or anything else. In other words, for a non-convex problem (about whose landscape we know barely anything), if there are regimes of regularizers that work well (see point 2) -- why should we ask for more stronger regularizers? Is there any optimization-related motivation here (beyond the single argument that networks are overparameterized)? \n2. The proposed experiments are not very conclusive. Firstly, the authors need to test with modern state-of-the-art architectures including inception and residual networks. Secondly, more datasets including imagenet needs to be tested. Unless these two are done, we cannot assertively say that the proposal seems to do interesting things. Thirdly, it is not clear what Figure 5 means in terms of goodness of learning. And lastly, although confidence intervals are reported for Figures 3,4 and Table 2, statistical tests needs to be performed to report p-values (so as to check if one model significantly beats the other)."", 'The work was prompted by  an interesting observation: a phase transition can be observed in deep learning with stochastic gradient descent and Tikhonov regularization. When the regularization parameter exceeds a (data-dependent) threshold, the parameters of the model are driven to zero, thereby preventing any learning. The authors then propose to moderate this problem by letting the regularization parameter to be zero for 5 to 10 epochs, and then applying the ""strong"" penalty parameter. In their experimental results, the phase transition is not observed anymore with their protocol. This leads to better performances, by using penalty parameters that would have prevent learning with the usual protocol.\n\nThe problem targeted is important, in the sense that it reveals that some of the difficulties related to non-convexity and the use of SGD that are often overlooked. The proposed protocol is reported to work well, but since it is really ad hoc, it fails to convince the reader that it provides the right solution to the problem. I would have found much more satisfactory to either address the initialization issue by a proper warm-start strategy, or to explore standard optimization tools such as constrained optimization (i.e. Ivanov regularization) , that could be for example implemented by stochastic projected gradient or barrier functions. I think that the problem would be better handled that way than with the proposed strategy, which seems to rely only on a rather limited amount of experiments, and which may prove to be inefficient when dealing with big databases.\n\nTo summarize, I believe that the paper addresses an important point, but that the tools advocated are really rudimentary compared with what has been already proposed elsewhere.\n\nDetails :\n- there is a typo in the definition of the proximal operator in Eq. (9) \n- there are many unsubstantiated speculations in the comments of the experimental section that do not add value to the paper \n- the figure showing the evolution of the magnitude of parameters arrives too late and could be completed by the evolution of the data-fitting term of the training criterion']","[20, -30, -20]","[50, 50, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the authors' work and findings, and suggests that the results 'seem to show' improved performance. However, the reviewer also points out limitations and suggests alternative approaches, indicating a balanced view rather than strong enthusiasm. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, avoiding harsh criticism and instead offering constructive suggestions. Phrases like 'It would be interesting to see' and acknowledging the authors' own recognition of limitations ('as pointed by the authors') contribute to the polite tone. The review maintains a professional and objective stance without being overly formal or deferential."", ""The sentiment score is -30 because while the review starts positively ('The paper is well motivated and written'), it quickly transitions to a critical tone with 'However, there are several issues.' The reviewer then lists multiple concerns and criticisms, suggesting that the paper's contributions may not be novel or conclusive. This indicates a generally negative sentiment, though not extremely so due to the initial positive comment. The politeness score is 50 because the reviewer uses professional and respectful language throughout. They begin with a positive comment and phrase criticisms as observations or suggestions rather than direct attacks. The use of phrases like 'The authors need to' and 'it is not clear' maintain a polite tone while still conveying critical feedback. The reviewer also provides specific, constructive suggestions for improvement, which is a polite approach to criticism in academic contexts."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem and the interesting observation, they express significant reservations about the proposed solution. The reviewer states that the proposed protocol is 'ad hoc' and 'fails to convince', suggesting that more robust methods should have been explored. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'I would have found much more satisfactory' and 'I believe that' to express their opinions. They also acknowledge the importance of the work and provide constructive feedback, including specific suggestions for improvement and details on typos and areas that could be enhanced. The language is not overly formal or deferential, but it remains respectful and constructive throughout.""]"
"['I have read comments and rebuttal - i do not have the luxury of time to read in depth the revision.\nIt seems that the authors have made an effort to accommodate reviewers\' comments. I upgraded the rating.\n\n-----------------------------------------------------------------------------------------------------------------------\n\nSummary: The paper considers the use of natural gradients for learning. The added twist is the substitution of the KL divergence with the Wasserstein distance, as proposed in GAN training. The authors suggest that Wasserstein regularization improves generalization over SGD with a little extra cost.\n\nThe paper is structured as follows:\n1. KL divergence is used as a similarity measure between two distributions.\n2. Regularizing the objective with KL div. seems promising, but expensive.\n3. We usually approximate the KL div. with its 2nd order approximation - this introduces the Hessian of the KL divergence, known as Fisher information matrix.\n4. However, computing and inverting the Fisher information matrix is computationally expensive.\n5. One solution is to approximate the solution F^{-1} J using gradient descent. However, still we need to calculate F. There are options where F could be formed as the outer product of a collection gradients of individual examples (\'empirical Fisher\').\n6. This paper does not move towards Fisher information, but towards Wasserstein distance: after a ""good"" initialization via SGD is obtained, the inner loop continues updating that point using the Wasserstein regularized objective. \n7. No large matrices need to be formed or inverted, however more passes needed per outer step.\n\nImportance:\nSomewhat lack of originality and poor experiments lead to low importance.\n\nClarity:\nThe paper needs major revision w.r.t. presenting and highlighting the new main points. E.g., one needs to get to page 5 to understand that the paper is just based on the WGAN ideas in Arjovsky et al., but with a different application (not GANS).\n\nOriginality/Novelty:\nThe paper, based on WGAN motivation, proposes Wasserstein distance regularization over KL div. regularization for training of simple models, such as neural networks. Beyond this, the paper does not provide any futher original idea. So, slight to no novelty.\n\nMain comments:\n1. Would the approximation of C_0 by its second-order Taylor expansion (that also introduces a Hessian) help? This would require the combination of two Hessian matrices.\n\n2. Experiments are really demotivating: it is not clear whether using plain SGD or the proposed method leads to better results. \n\nOverall:\nRejection.\n', 'The paper presents an additive regularization scheme to encourage parameter updates that lead to small changes in prediction (i.e. adjusting updates based on their size in the output space instead of the input space). This goal is to achieve a similar effect to that of natural gradient, but with lighter computation. The authors claim that their regularization is related to Wasserstein metric (but the connection is not clear to me, read below). Experiments on MNIST with show improved generalization (but the baseline is chosen poorly, read below).\n\nThe paper is easy to read and organized very well, and has adequate literature review. However, the contribution of the paper itself needs to be strengthened in both the theory and empirical sides.\n\nOn the theory side, the authors claim that their regularization is based on Wasserstein metric (in the title of the paper as well as section 2.2). However, this connection is not very clear to me [if there is a rigorous connection, please elaborate]. From what I understand, the authors argue that their proposed loss+regularization is equivalent to the Kantorovich-Rubinstein form. However, in the latter, the optimization objective is the f itself (sup E[f_1]-E[f_2]) but in your scheme you propose adding the regularization term (which can be added to any objective function, and then the whole form loses its connection to Wasserstrin metric).\n\nOn the practical side, the chosen baseline is very poor. The authors only experiment with MNIST dataset. The baseline model lacks both ""batch normalization"" and ""dropout"", which I guess is because otherwise the proposed method would under-perform against the baseline. It is hard to tell if the proposed regularization scheme is something significant under such poorly chosen baseline.\n', '\nGENERAL IMPRESSION:\n\nOverall, the revised version of the paper is greatly improved. The new derivation of the method yields a much simpler interpretation, although the relation to the natural gradient remains weak (see below). The experimental evaluation is now far more solid. Multiple data sets and network architectures are tested, and equally important, the effect of parameter settings is investigated. I enjoyed the investigation of the effect of L_2 regularization on qualitative optimization behavior.\n\n\nCRITICISM:\n\nMy central criticism is that the introduction of the L_2 norm as a replacement of KL divergence is completely ad-hoc; how it is related to KL divergence remains unclear. It seems that other choices are equally well justified, including the L_2 norm in parameter space, which then defeats the central argument of the paper. I do believe that L_2 distance is more natural in function space than in parameter space, but I am missing a strict argument for this in the paper.\n\nAlthough related work is discussed in detail in section 1, it remains unclear how exactly the proposed algorithm overlaps with existing approaches. I am confident that it is easy to identify many precursors in the optimization literature, but I am not an expert on this. It would be of particular interest to highlight connections to algorithm regularly applied to neural network training. Adadelta, RMSprop, and ADAM are mentioned explicitly, but what exactly are differences and similarities?\n\nThe interpretation of figure 2 is off. It is deduced that HCGD generalizes better, however, this is the case only at the very end of training, while SGD with momentum and ADAM work far better initially. With the same plot one could sell SGD as the superior algorithm. Overall, also in the light of figure 4, the interpretation that the new algorithm results in better generalization seems to stand on shaky ground, since differences are small.\n\nI like the experiment presented in figure 5 in particular. It adds insights that are of value even if the method should turn out to have significant overlap with existing work (see above), and perform ""only"" on par with these: it adds an interesting perspective to the discussion of how network optimization ""works"", how it handles local optima and which role they play, and how the objective function landscape is ""perceived"" by different optimizers. This is where I learned something new.\n\n\nMINOR POINTS:\n\npage 5: ""the any"" (typo)\n\npage 5: ""ture"" -> ""true"" (typo)\n']","[-60, -40, 50]","[-20, 50, 70]","[""The sentiment score is -60 because the review is overall negative, recommending rejection and citing 'lack of originality and poor experiments'. However, it's not entirely negative as it acknowledges some effort made by the authors. The politeness score is -20 because while the reviewer uses professional language, there are several blunt criticisms without much softening language. The reviewer states opinions quite directly, such as 'Experiments are really demotivating' and 'Somewhat lack of originality and poor experiments lead to low importance', which comes across as somewhat impolite. However, the reviewer does provide detailed feedback and explanations for their criticisms, which prevents the score from being lower."", ""The sentiment score is -40 because while the reviewer acknowledges some positive aspects (e.g., 'The paper is easy to read and organized very well'), they express significant concerns about both the theoretical and practical contributions of the paper. The reviewer points out unclear connections to the Wasserstein metric and criticizes the choice of baseline in experiments, suggesting the paper's contribution 'needs to be strengthened'. These criticisms outweigh the positive comments, resulting in a moderately negative sentiment.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'please elaborate' and 'from what I understand', which show consideration. The criticism is presented constructively, focusing on the content rather than attacking the authors. However, the review doesn't go out of its way to be overly polite or complimentary, keeping it from scoring higher on the politeness scale."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by stating that the revised version is 'greatly improved' and mentions enjoying parts of the investigation. However, they also provide significant criticisms, which balances out the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges improvements, and frames criticisms constructively. They use phrases like 'I enjoyed' and 'I like', showing appreciation. Even when pointing out issues, the tone remains professional and not personal. The reviewer also offers specific suggestions for improvement, which is a polite way to provide criticism.""]"
"['The paper proposes a generalization of an algorithm by Yin et al. (2017), which performs SGD with adaptive batch sizes. The present paper generalizes the algorithm to SGD with momentum. Since the original algorithm was already formulated with a general utility function, the proposed algorithm is similar in structure but replaces the utility function so that it takes momentum into account. Experiments on an image classification task show improvements in the training loss. However, no test accuracies are reported and the learning curves have suspicious artifacts, see below. Experiments on a relation extraction task show little improvement over SGD with momentum and constant batch size.\n\n\nCOMMENTS:\n\nThe paper discusses a relevant issue. While adaptive learning algorithms are popular in deep learning, most algorithms adapt the learning rate or the momentum coefficient, but not the batch size. It appears to me that the main idea and the overall structure of the proposed algorithm is the same as in the one published by Yin et al. (2017), and that only few changes were necessary to include momentum. Given the incremental process, I find the presentation unnecessarily involved, and experiments not convincing enough.\n\nConcerning the presentation, the paper dedicates two full pages on a review of the algorithm by Yin et al. (2017). The first page of this review states that, for large enough batch sizes, the change of the objective function in SGD is normal distributed with a variance that is inversely proportional the batch size. It seems to me that this is a direct consequence of the central limit theorem. The derivation, however, is quite technical and introduces some quantities that are never used (e.g., $\\vec{\\xi}_j$ is never used individually, only the combined term $\\epsilon_t$ defined below Eq. 12 is). The second page of the review seems to discuss the main part of the algorithm, but I could not follow it. First, a ""state"" $s_t$ (also written as $S$) is introduced, which, according to the text, is ""the objective value"", which was earlier denoted by $F$. Nevertheless, the change of $s_t$, Eq. 5, appears to obey a different probability distribution than the change of $F$. The paper provides a verbal explanation for this discrepancy, saying that it is possible that $S$ is first reduced to the minimum $S^*$ of the objective and then increased again. However, in my understanding, the minimum of the objective is only realized at a singular point in parameter space. Crossing this point in an update step should have zero probability as long as the model has more than one parameter. The explanation also does not make it clear why the argument should apply to $S$ (or $s$) but not to $F$.\n\nPage 5 provides pseudocode for the proposed algorithm. However, I couldn\'t find an explanation of the code. The code suggests that, for each update step, one gradually increases the batch size until it becomes larger or equal than a running estimate of the optimal batch size. While this may be a plausible strategy in practice, it seems to have a bias that is not addressed in the paper: the algorithm recalculates a noisy estimate of the optimal batch size after each increase of the batch size, and it terminates as soon as the noisy estimate happens to be small enough, resulting in a bias towards a smaller than optimal batch size. A probably more important issue is that the algorithm is sequential and hard to parallelize, where parallelization is usually the main motivation to use larger batch sizes. As the gradient noise scales inversely proportional to the batch size, I don\'t see why increasing the batch size should be preferred over decreasing the learning rate unless optimizations with a larger batch size can be parallelized. The experiments don\'t compare the two alternatives.\n\nConcerning the experiments, it seems peculiar that the learning curves in Figure 1 remain at a constant value for a long time at the beginning of the optimization before they begin to drop. Do the authors understand this behavior? It could indicate that the magnitude of the random initialization was chosen too small. I.e., the parameters might have been initialized too close to zero, where the loss is stationary due to symmetries. Also, absolute values of the training loss can be deceptive since there is often no natural scale. A better indicator of convergence would be the test accuracy. The identification of the ""batch size boom"" is interesting.', 'The authors propose extending the recently-proposed adaptive batch-size approach of Yin et al. to an update that includes momentum, and perform more comprehensive experiments than in the Yin et al. paper validating their approach.\n\nThe basic idea makes a great deal of intuitive sense: inaccurate gradient estimates are fine in early iterations, when we\'re far from convergence, and accurate estimates are more valuable in later iterations, when we\'re close. Finding the optimal trade-off between computational cost and expected decrease seems like the most natural way to accomplish this, and this is precisely what they propose. That said, I\'m not totally convinced by the derivation of sections 2 and 3: the Gaussian assumption is fine as a heuristic (and they don\'t really claim that it\'s anything else), but I don\'t feel that the proposed algorithm really rests on a solid theoretical foundation.\n\nThe extension to the momentum case (section 3) seems to be more-or-less straightforward, but I do have a question about equation 15: am I misreading this, or is it saying that the variance of the momentum update \\mathcal{P} is the same as the variance of the most recent minibatch? Shouldn\'t it depend on the previous terms which are included in \\mathcal{P}?\n\nI\'m also not convinced by the dependence on the ""optimal"" objective function value S^* in equation 6. In their algorithm, they take S^* to be zero, which is a good conservative choice for a nonnegative loss, but the fact that this quantity is present in the first place, as a user-specified parameter, makes me nervous, since even for a nonnegative loss, the optimum might be quite far from zero, and on a non-convex problem, the eventual local optimum at which we eventually settle down may be further still.\n\nAlso, the ""Robbins 2007"" reference should, I believe, be ""Robbins and Monro, 1951"".\n\nThese are all relatively minor issues, however. My main criticism is that the experiments only report results in terms of *training* loss. The use of adaptive batch sizes does indeed appear to result in faster convergence in terms of training loss, but the plots are in log scale (which I do think is the right way to present it), so the difference is smaller in reality than it appears visually. To determine whether this improvement in training performance is a *real* improvement, I think we need to see the performance (in terms of accuracy, not loss) on held-out data.\n\nFinally, as the authors mention in the final paragraph of their conclusion, some recent work has indicated that large-batch methods may generalize worse than small-batch methods. They claim that, by using small batches early and large batches late, they may avoid this issue, and I don\'t necessarily disagree, but I think an argument could be made in the opposite direction: that since the proposed approach becomes a large-batch method in the later iterations, it may suffer from this problem. I think that this is worth exploring further, and, again, without results on testing data being presented, a reader can\'t make any determination about how well the proposed method generalizes, compared to fixed-size minibatches.\n', 'Overall, the manuscript is well organized and written with solid background knowledge and results to support the claim of the paper. \xa0The authors borrow the idea from a previously published work and claim that their contributions are twofold: (1) extend batch adaptive SGD to adaptive momentum, and (2) adopt the algorithms to complex neural networks problems (while the previous paper only demonstrates with simple neural networks). \xa0In this regard, it does not show much novelty. \xa0Several issues should be addressed to improve the quality of the paper: \xa0\n\u20281) The paper has demonstrated that the proposed method exhibits fast convergence and lower training loss. \xa0However, the test accuracy is not shown.\xa0 This makes it hard to justify the\xa0effectiveness of the proposed method. \xa0\n\u20282) From Fig. 4(b), it shows that the batch size is updated in every iteration.\xa0 The reviewer wonders whether\xa0it is too frequent.\xa0 Moreover, the paper does not explicitly show the computation cost of computing the batch size.\xa0\n3) The comparison of other methodologies seems not fair.\xa0 All the compared methods adopt a fixed batch size, but the proposed method uses an adaptive batch size.\xa0 The paper can compare the proposed method with adaptive batch size in intuitive settings, e.g., small batch size in the beginning of training and larger batch size later.\n4) The font size is too small in some figures, e.g., Figure 7(a).\n']","[-50, 20, -20]","[20, 80, 50]","[""The sentiment score is -50 because the review is generally critical of the paper, pointing out several issues with the presentation, methodology, and experiments. The reviewer finds the paper's contribution incremental, the presentation unnecessarily involved, and the experiments not convincing. However, it's not entirely negative as the reviewer acknowledges that the paper discusses a relevant issue and finds some aspects interesting.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'It appears to me' and 'I find' to soften their criticisms, and they provide detailed explanations for their concerns rather than making blunt dismissals. The reviewer also acknowledges positive aspects, such as the relevance of the topic and the interesting identification of the 'batch size boom'. However, the score is not higher because the review is predominantly critical and doesn't use overtly polite language or praise."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the intuitive sense of the basic idea and the potential value of the approach. However, they express several concerns and criticisms, which temper the overall positive sentiment. The politeness score is high (80) as the reviewer uses respectful language throughout, acknowledging the potential of the work while offering constructive criticism. They use phrases like 'I'm not totally convinced' and 'I think we need to see' rather than making blunt or harsh statements. The reviewer also balances criticism with positive remarks and presents their concerns as suggestions for improvement rather than outright dismissals."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the manuscript is well-organized and written with solid background knowledge, they also point out several issues and state that the paper 'does not show much novelty.' The overall tone suggests that significant improvements are needed. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'Several issues should be addressed to improve the quality of the paper' and 'The reviewer wonders,' which maintain a polite and professional tone while providing feedback.""]"
"['This paper presents a multi-task neural network for classification on MNIST-like datasets.\n\nThe main concern is that the technical innovation is limited. It is well known that multi-task learning can lead to performance improvement on similar tasks/datasets. This does not need to be verified in MNIST-like datasets. The proposed multi-task model is to fine tune a pretrained model, which is already a standard approach for multi-task and transfer learning. So the novelty of this paper is very limited.\n\nThe experiments do not bring too much insights.', 'The manuscript mainly utilizing the data from all three MNIST-like datasets to pre-train the parameters of joint classification networks, and the pre-trained parameters are utilized to initialize the disjoint classification networks (of the three datasets).\n\nThe presented idea is quite simple and the authors only re-affirm that multi-task learning can lead to performance improvement by simultaneously leverage the information of multiple tasks. There is no technique contribution.\n\nPros:\n1.\tThe main idea is clearly presented.\n2.\tIt is interesting to visualize the results obtained with/without multi-task learning in Figure 6.\n\nCons:\n1.\tThe contribution is quite limited since the authors only apply multi-task learning to the three MNIST-like datasets and there is no technique contribution.\n2.\tThere is no difference between the architecture of the single-task learning network and multi-task learning network.\n3.\tMany unclear points, e.g., there is no description for “zero-padding” and why it can enhance target label. What is the “two-stage learning rate decay scheme” and why it is implemented? It is also unclear what can we observed from Figure 4.\n', 'The paper applies multi-task learning to MNIST (M), FashionNIST (F), and NotMNIST (N) datasets. That is, the authors first train a neural network (with a specific architecture; in this case, it is an all-convolutional network) on a combination of the datasets (M+F; F+N; N+M; M+F+N) and then use the learned weights (in all but the output layer) to initialize the weights for task-specific training on each of the datasets. The authors observe that for each of the combinations, the above approach does better than training on a dataset individually. Further, in all but one case, initializing weights based on training on M+F+N gives the best performance. The improvements are not striking but are noticeable. ']","[-70, -50, 50]","[0, 20, 0]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses significant concerns about the paper's lack of technical innovation and limited novelty. They state that the main approach is 'already a standard' and that the experiments 'do not bring too much insights.' These criticisms suggest a strong negative sentiment towards the paper's contribution. However, it's not entirely negative (-100) as the reviewer acknowledges that the paper does present a multi-task neural network, which is why the score isn't at the extreme end. The politeness score is 0 (neutral) because the language used is neither particularly polite nor rude. The reviewer states their concerns directly and professionally without using overly harsh language or personal attacks, but also without any notably courteous phrasing."", ""The sentiment score is -50 because the review is generally critical, stating that the contribution is 'quite limited' and there is 'no technique contribution'. However, it's not entirely negative as it does mention some pros and interesting aspects. The politeness score is 20 because while the language is not overtly polite, it maintains a professional tone and offers both pros and cons. The reviewer uses phrases like 'it is interesting' and 'clearly presented', which add a slight positive tone. The criticism is presented factually without harsh language, though it's direct in pointing out limitations."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper's approach and results in a neutral, factual manner, but notes that the improvements are 'noticeable,' which implies a positive outcome. The review doesn't express strong enthusiasm or criticism, maintaining a balanced tone. The politeness score is 0 (neutral) because the language used is purely professional and descriptive, without any particularly polite phrases or rude comments. The reviewer simply states the facts about the paper's content and findings without personal opinions or courtesies.""]"
"['""topic modeling of text documents one of most important tasks""\nDoes this claim have any backing?\n\n""inference of HDP is more complicated and not easy to be applied to new models""  Really an artifact of the misguided nature of earlier work. The posterior for the $\\vec\\pi$ of a elements of DP or HDP can be made a Dirichlet, made finite by keeping a ""remainder"" term and appropriate augmentation.  Hughes, Kim and Sudderth (2015) have avoided stick-breaking and CRPs altogether, as have others in earlier work. Extensive models building on simple HDP doing all sorts of things have been developed.\n\nVariational stick-breaking methods never seemed to have worked well.  I suspect you could achieve better results by replacing them as well, but you would have to replace the tree of betas and extend your Kumaraswamy distribution, so it may not work.  Anyway, perhaps an avenue for future work.\n\n""infinite topic models"" I\'ve always taken the view that the use of the word ""infinite"" in machine learning is a kind of NIPSian machismo. In HDP-LDA at least, the major benefit in model performance comes from fitting what you call $\\vec\\pi$, which is uniform in vanilla LDA, and note that the number of topics ""found"" by a HDP-LDA sampler can be made to vary quite widely by varying what you call $\\alpha$, so any statement about the ""right"" number of topics is questionable.  So the claim in 3rd paragraph of Section 2, ""superior"" and ""self-determined topic number"" I\'d say are misguided.  Plenty of experimental work to support this.\n\nIn Related Work, you seem to only mention HDP for non-parametric topic models.  More work exists, for instance using Pitman-Yor distributions for modelling words and using Gibbs samplers that are efficient and don\'t rely on the memory hungry HCRP.\n\nGood to see a prior is placed on the concentration parameter.  Very important and not well done in the community, usually.  \nADDED:  Originally done by Teh et al for HDP-LDA, and subsequently done\nby several, including Kim et al 2016.   Others stress the importance of this.  You need to\ncite at least Teh et al. in 5.4 to show this isn\'t new and the importance is well known.\n\nThe Prod version is a very nice idea.  Great results.  This looks original, but I\'m not expert enough in the huge masses of new deep neural network research popping up.\n\nYou\'ve upped the standard a bit by doing good experimental work.  Oftentimes this is done poorly and one is left wondering.  A lot of effort went into this.\nADDED:   usually like to see more data sets experimented with\n\nWhat code is used for HDP-LDA?  Teh\'s original Matlab HCRP sampler does pretty well because at least he samples hyperparameters and can scale to 100k documents (yes, I tried). The comparison with LDA makes me suspicious. For instance, on 20News, a good non-parametric LDA will find well over 400 topics and roundly beat LDA on just 50 or 200.  If reporting LDA, or HDP-LDA, it should be standard to do hyperparameter fitting and you need to mention what you did as this makes a big difference.\nADDED:   20News results still poor for HPD, but its probably the implementation used ... their\n        online variational algorithm only has advantages for large data sets \n\nPros:   \n* interesting new prod model with good results\n* alternative ""deep"" approach to a HDL-LDA model\n* good(-ish) experimental work\nCons:\n* could do with a competitive non-parametric LDA implementation\n\nADDED:   good review responses generally\n', 'The paper constructs infinite Topic Model with Variational Auto-Encoders (iTM-VAE) by combining stick-breaking variational auto-encoder (SB-VAE) of Nalisnick & Smyth (2017) with latent Dirichlet allocation (LDA) and several inference techniques used in Miao et al. (2016 & 2017). A main difference from Autoencoded Variational Inference For Topic Model (AVITM) of Srivastava & Sutton (2017), which had already applied VAE to LDA, is that the Dirichlet-distributed topic distribution vector for each document is now imposed with a stick-breaking prior. To address the challenge of reparameterizing the beta distributions used in stick-breaking, the paper follows SB-VAE to use the Kumaraswamy distributions to approximate the beta distributions.\n\nThe novelty of the paper does not appear to be significant, considering that most of the key techniques used in the paper had already appeared in several related papers, such as Nalisnick & Smyth (2017), Srivastava & Sutton (2017), and Miao et al. (2016 & 2017). \n\nWhile experiments show the proposed models outperform the others quantitatively (perplexity and coherence), the paper does not provide sufficient justifications on why ITM-VAE is better. In particular, it provides little information about how the two baselines, LDA and HDP, are implemented (e.g., via mean-field variational inference, VAE, or MCMC?) and how their perplexities and topic coherences are computed. In addition, achieving the best performance with about 20 topics seem quite surprising for 20news and RCV-v2. It is hard to imagine 20 news, which consists of articles in 20 different newsgroups, can be well characterized by about 20 different topics. Is there a tuning parameter that significantly impacts the number of topics inferred by iTM-VAE?\n\nAnother clear problem of the paper is that the “Bayesian nonparametric” generative procedure specified in Section 4.1 is not correct in theory. More specifically, independently drawing the document-specific pi vectors from the stick-breaking processes will lead to zero sharing between the atoms of different stick-breaking process draws. To make the paper theoretically sound as a Bayesian nonparametric topic model that uses the stick-breaking construction, please refer to Teh et al. (2006, 2008) and Wang et al. (2011) for the correct construction that ties the document-specific pi vectors with a globally shared stick-breaking process. ', 'The paper proposes a VAE inference network for a non-parametric topic model.\n\nThe model on page 4 is confusing to me since this is a topic model, so document-specific topic distributions are required, but what is shown is only stick-breaking for a mixture model.\n\nFrom what I can tell, the model itself is not new, only the fact that a VAE is used to approximate the posterior. In this case, if the model is nonparametric, then comparing with Wang, et al (2011) seems the most relevant non-deep approach. Given the factorization used in that paper, the q distributions are provably optimal by the standard method. Therefore, something must be gained by the VAE due to a non-factorized q. This would be best shown by comparing with the corresponding non-deep version of the model rather than LDA and other deep models.']","[30, -50, -20]","[20, 0, 50]","[""The sentiment score is slightly positive (30) because while the reviewer offers some criticisms and points out areas for improvement, they also highlight several positive aspects of the work, such as the 'very nice idea' of the Prod version, 'great results', and praise for the experimental work. The overall tone suggests the reviewer sees value in the research despite some concerns. The politeness score is mildly positive (20) as the reviewer maintains a professional tone throughout, using phrases like 'Good to see' and acknowledging the effort put into experiments. However, some critiques are quite direct without much softening language, which prevents a higher politeness score. The reviewer balances constructive criticism with recognition of the paper's strengths, maintaining a generally respectful but frank approach."", ""The sentiment score is -50 because the review is generally critical, pointing out lack of significant novelty and issues with the paper's theoretical soundness. However, it's not entirely negative as it acknowledges some improvements in performance. The politeness score is 0 (neutral) because the reviewer uses professional language without being overly polite or rude. They directly state criticisms but in a matter-of-fact way, using phrases like 'The novelty of the paper does not appear to be significant' and 'Another clear problem of the paper is...', which are direct but not impolite."", ""The sentiment score is slightly negative (-20) because the reviewer expresses confusion about the model and suggests that the proposed approach may not be entirely novel. They also point out that comparisons with certain existing methods are missing, which implies some criticism. However, the tone is not overwhelmingly negative, as the reviewer provides constructive feedback and suggestions for improvement. The politeness score is moderately positive (50) because the reviewer uses neutral language and phrases their concerns as personal observations ('is confusing to me', 'From what I can tell') rather than making accusatory statements. They also offer specific suggestions for improvement in a professional manner, without using harsh or impolite language.""]"
"['The paper presents a Network of Graph Convolutional Networks (NGCNs) that uses\nrandom walk statistics to extract information from near and distant neighbors\nin the graph.\n\nThe authors show that a 2-layer Graph Convolutional Network, with linear\nactivation and W0 as identity matrix, reduces to a one-step random walk.\nThey build on this notion to  introduce the idea to make the GCN directly operate\non random walk statistics to better model information across distant nodes.\n\nGiven that it is not clear how many steps of random walk to use a-priori it is\nproposed to make a mixture of models whose outputs are combined by a\nsoftmax classifier, or by an attention based mixing (learning the mixing coefficients).\n\nI find that the comparison can be considered slightly unfair as NGCN has k-times\nthe number of GCN models in it. Did the authors compare with a deeper GCN, or\nsimply with a mixture of plain GCN using one-step random walk?\nThe datasets used for comparison are extremely simple, and I am glad that the\nauthors point out that this is a significant issue for benchmark driven research.\nHowever, doing calibration on a subset of the validation nodes via gradient\ndescent is not very clean as by doing it one implicitly uses those nodes for training.\nThe improvement of the calibrated model on 5 nodes per class (Table 3) seems\nto hint that this peeking into the validation is indeed happening.\n\nThe authors mention that feeding explicitly the information on distant nodes\nmakes learning easier and that otherwise such information it would be hard to\nextract from stacking several GCN layers. While this is true for the small datasets\nusually considered it is not clear at all whether this still holds when we will\nhave large scale graph benchmarks.\n\nExperiments are well conducted but lack a comparison with GraphSAGE and MoNet,\nwhich are the reference models for the selected benchmarks. A comparison would have made the contribution stronger in my opinion. Improvements in performance are minor\nexcept for decimated inputs setting reported in Table 3. In this last case though\nno statistics over multiple runs are shown.\n\nOverall I like the interpretation, even if a bit forced, of GCN as using one-step\nrandom walk statistics. The paper is clearly written.\nThe main issue I have with the approach is that it does not bring a very novel\nway to perform deep learning on graphs, but rather improves marginally upon\na well established one.\n', 'The paper proposes a novel graph convolutional network in which a variety of random walk steps are involved with multiple GCNs.\n\nThe basic idea, introducing long rage dependecy, would be interesting. Robustness for the feature remove is also interesting.\n\nThe validation set would be important for the proposed method, but for creating larger validation set, labeled training set would become small. How the good balance of training-and-validation can be determined?\n\nDiscussing choice of the degree would be informative. In introducing many degrees (GCNs) for small labeled nodes semi-supervised setting seems to cause over-fitting.', 'In this work a new network of GCNs is proposed. Different GCNs utilize different powers of the transition matrix to capture varying neighborhoods in a graph. As an aggregation mechanism of the GCN modules two approaches are considered: a fully connected layer on top of stacked features and attention mechanism that uses a scalar weight per GCN. The later allows for better interpretability of the effects of varying degree of neighborhoods in a graph.\n\nProposed approach, as authors noted themselves, is quite similar to DCNN (Atwood and Towsley, 2016) and becomes equivalent if the combined GCNs have one layer each. While comparison to vanilla GCN is quite extensive, there is no comparison to DCNN at all. I would be curious to see at least portion of the experiments of the DCNN paper with the proposed approach, where the importance of number of GCN layers is addressed. DCNN did well on Cora and Pubmed when more training samples were used. It also was tested on graph classification datasets, but the results were not as good for some of the datasets. I think that comparison to DCNN is important to justify the importance of using multilayer GCN modules.\n\nSome questions and concerns:\n- I could not quite figure out how many layers did each GCN have in the experiments and how impactful is this parameter \n- Why is it necessary to replicate GCNs for each of the transition matrix powers? In section 4.3 it is mentioned that replication factors r = 1 and r = 4 were used, but it is not clear from Table 2 what are the results for respective r.\n- Early stopping implementation seems a bit too intense. ""We invoke many runs over all datasets"" - how many? Mean and standard deviation are reported for top 3 performers, which is not enough to get a sense of standard deviation and mean. Kipf and Welling (2017) report results over 100 runs without selecting top performers if I understood correctly their setup. Could you please report mean and standard deviation of all the runs? Given relatively small performance improvement (comparatively to GCN), more than 3 (selected) runs are needed for comparison.\n- I liked the attention idea and its interpretation in Fig. 2. Could you please add the error bars for the attention weights. It is interesting to see them shifting towards higher powers of the transition matrix, but also it is important to know if this phenomena is statistically significant.\n- Following up on the previous item - did you try not including self connections when computing transition matrix powers? This way the effect of different degrees of neighborhoods in a graph could be understood better. When self-connections are present, each subsequent transition matrix power contains neighborhoods of lower degrees and interpretation becomes not as apparent.\n\nMinor comments:\n- Understanding of this paper quite heavily relies on the reader knowing Kipf and Welling (2017) paper. Particularly, the comment about approximations derived by Kipf and Welling (2017) in Section 3.3 and how directed graph was converted to undirected (Section 4.1) require a bit more details.\n- I am not quite sure why Section 2.3 is needed. Connection to graph embeddings is not given much attention in the paper later on (except t-SNE picture).\n- Typo in Fig. 1 caption - right and left are mixed up.\n- Typo in footnote on page 3.']","[-20, 50, -20]","[50, 75, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Overall I like the interpretation', 'The paper is clearly written'), they express several concerns and criticisms. These include potential unfairness in comparisons, issues with the datasets used, and the lack of significant novelty in the approach. The improvements are described as 'minor' and the reviewer suggests that the contribution could have been stronger with additional comparisons.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I find that', 'I am glad that', and 'I like' to express personal opinions without being harsh. The criticisms are presented as constructive feedback rather than blunt negativity. The reviewer also acknowledges positive aspects of the paper, which contributes to the overall polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the interesting aspects of the paper, such as the 'novel graph convolutional network' and the 'interesting' idea of introducing long-range dependency. However, they also raise some concerns and questions, which prevents the sentiment from being more strongly positive. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, framing their concerns as questions or suggestions rather than criticisms. They use phrases like 'would be interesting' and 'would be informative,' which maintain a constructive tone. The reviewer also doesn't use any harsh or negative language, even when pointing out potential issues."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the work (e.g., 'I liked the attention idea'), they raise several concerns and questions that suggest the paper needs significant improvements. The reviewer points out similarities to existing work, requests additional comparisons, and questions some methodological choices. However, the tone is not entirely negative, as the reviewer also offers constructive feedback and suggestions for improvement. The politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout. They use polite language such as 'Could you please...', 'I would be curious to see...', and 'I liked...'. The reviewer also frames their criticisms as questions or suggestions rather than direct attacks, which contributes to the overall politeness of the review.""]"
"['In this paper an alternating optimization approach is explored for training Auto Encoders (AEs).\nThe authors treat each layer as a generalized linear model, and suggest to use the stochastic normalized GD of [Hazan et al., 2015] as the minimization algorithm in each (alternating) phase.\nThen they apply the suggested method to several single layer and multi layer AEs, comparing its performance to standard SGD. The paper suggests an interesting approach and provides experimental evidence for its usefulness, especially for multi-layer AEs.\n\n\nSome comments on the theoretical part:\n-The theoretical part is partly misleading. While it is true that every layer can be treated a generalized linear model, the SLQC property only applies for the last layer.\nRegarding the intermediate layers, we may indeed treat them as generalized linear models, but with non-monotone activations, and therefore the SLQC property does not apply.\nThe authors should mention this point.\n\n-Showing that generalized ReLU is SLQC with a polynomial dependence on the domain is interesting. \n\n-It will be interesting if the authors can provide an analysis/relate to some theory related to alternating minimization of bi-quasi-convex objectives. Concretely: Is there any known theory for such objectives? What guarantees can we hope to achieve?\n\n\nThe extension to muti-layer AEs makes sense and seems to works quite well in practice.\n\nThe experimental part is satisfactory, and seems to be done in a decent manner. \nIt will be useful if the authors could relate to the issue of parameter tuning for their algorithm.\nConcretely: How sensitive/robust is their approach compared to SGD with respect to hyperparameter misspecification.\n', 'After reading the rebuttal:\n\nThe authors addressed some of my theoretical questions. I think the paper is borderline, leaning towards accept.\n\nI do want to note my other concerns:\n\nI suspect the theoretical results obtained here are somewhat restricted to the least-squares, autoencoder loss.  \n\nAnd note that the authors show that the proposed algorithm performs comparably to SGD, but not significantly better. The classification result (Table 1) was obtained on the autoencoder features instead of training a classifier on the original inputs. So it is not clear if the proposed algorithm is better for training the classifier, which may be of more interest.\n\n=============================================================\n\nThis paper presents an algorithm for training deep neural networks. Instead of computing gradient of all layers and perform updates of all weight parameters at the same time, the authors propose to perform alternating optimization on weights of individual layers. \n\nThe theoretical justification is obtained for single-hidden-layer auto-encoders. Motivated by recent work by Hazan et al 2015, the authors developed the local-quasi-convexity of the objective w.r.t. the hidden layer weights for the generalized RELU activation. As a result, the optimization problem over the single hidden layer can be optimized efficiently using the algorithm of Hazan et al 2015. This itself can be a small, nice contribution.\n\nWhat concerns me is the extension to multiple layers. Some questions are not clear from section 3.4:\n1. Do we still have local-quasi-convexity for the weights of each layer, when there are multiple nonlinear layers above it? A negative answer to this question will somewhat undermine the significance of the single-hidden-layer result.\n\n2. Practically, even if the authors can perform efficient optimization of weights in individual layers, when there are many layers, the alternating optimization nature of the algorithm can possibly result in overall slower convergence. Also, since the proposed algorithm still uses gradient based optimizers for each layer, computing the gradient w.r.t. lower layers (closer to the inputs) are still done by backdrop, which has pretty much the same computational cost of the regular backdrop algorithm for updating all layers at the same time. As a result, I am not sure if the proposed algorithm is on par with / faster than the regular SGD algorithm in actual runtime. In the experiments, the authors plotted the training progress w.r.t. the minibatch iterations, I do not know if the minibatch iteration is a proxy for actual runtime (or number of floating point operations).\n\n3. In the experiments, the authors found the network optimized by the proposed algorithm generalize better than regular SGD. Is this result consistent (across dataset, random initializations, etc), and can the authors elaborate the intuition behind?\n', 'The authors propose an alternating minimization framework for training autoencoders and encoder-decoder networks. The central idea is that a single encoder-decoder network can be cast as an alternating minimization problem. Each minimization problem is not convex but is quasi-convex and hence one can use stochastic normalized gradient descent to minimize w.r.t. each variable. This leads to the proposed algorithm called DANTE which simply minimizes w.r.t. each variable using stochastic normalized gradient algorithm to minimize w.r.t. each variable The authors start with this idea and introduce a generalized ReLU which is specified via a subgradient function only whose local quasi-convexity properties are established. They then extend these idea to multi-layer encoder-decoder networks by performing greedy layer-wise training and using the proposed algorithms for training each layer. The ideas are interesting, but I have some concerns regarding this work.\n\nMajor comments:\n\n1. When dealing with a 2 layer network where there are 2 matrices W_1, W_2 to optimize over. It is not clear to me why optimizing over W_1 is a quasi-convex optimization problem? The authors seem to use the idea that solving a GLM problem is a quasi-convex optimization problem. However, optimizing w.r.t. W_1 is definitely not a GLM problem, since W_1 undergoes two non-linear transformations one via \\phi_1 and another via \\phi_2. Could the authors justify why minimizing w.r.t. W_1 is still a quasi-convex optimization problem?\n\n2. Theorem 3.4, 3.5 establish  SLQC properties with generalized RELU activations. This is an interesting result, and useful in its own right. However, it is not clear to me why this result is even relevant here. The main application of this paper is autoencoders, which are functions from R^d -> R^d. However, GLMs are functions from R^d ---> R. So, it is not at all clear to me how Theorem 3.4, 3.5 and eventually 3.6 are useful for the autoencoder problem that the authors care about. Yes they are useful if one was doing 2-layer neural networks for binary classification, but it is not clear to me how they are useful for autoencoder problems.\n\n3. Experimental results for classification are not convincing enough. If, one looks at Table 1. SGD outperforms DANTE on ionosphere dataset and is competent with DANTE on MNIST and USPS. \n\n4. The results on reconstruction do not show any benefits for DANTE over SGD (Figure 3). I would recommend the authors to rerun these experiments but truncate the iterations early enough. If DANTE has better reconstruction performance than SGD with fewer iterations then that would be a positive result.']","[60, 20, -30]","[70, 60, 50]","[""The sentiment score is 60 (moderately positive) because the reviewer describes the paper as 'interesting' and providing 'experimental evidence for its usefulness'. They also mention that the experimental part is 'satisfactory' and 'done in a decent manner'. However, they do point out some theoretical issues and suggest improvements, which prevents the score from being higher. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'It will be interesting if...' and 'It will be useful if...' which are polite ways of suggesting improvements. The reviewer also acknowledges the positive aspects of the paper before offering critiques, which is a polite approach to reviewing."", ""The sentiment score is slightly positive (20) because the reviewer states the paper is 'borderline, leaning towards accept' and acknowledges that the authors addressed some theoretical questions. However, they also express several concerns, which prevents a higher positive score. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout, asking questions and expressing concerns without harsh criticism. They use phrases like 'I suspect,' 'I do want to note,' and 'What concerns me is,' which maintain a polite tone while still conveying their points. The reviewer also acknowledges positive aspects, such as calling a contribution 'nice,' which adds to the politeness."", ""The sentiment score is -30 because while the reviewer acknowledges that the ideas are interesting, they express several major concerns about the work. The review starts positively but quickly moves to a list of significant issues, indicating a generally negative sentiment. However, it's not extremely negative as the reviewer still sees some value in the work. The politeness score is 50 because the reviewer uses respectful language throughout, framing their concerns as questions or suggestions rather than direct criticisms. They use phrases like 'Could the authors justify...' and 'I would recommend...', which are polite ways of pointing out issues. The reviewer also acknowledges the potential value of some aspects of the work, even while critiquing others, which contributes to the overall polite tone.""]"
"['* Summary *\nThe paper addresses the instability of GAN training. More precisely, the authors aim at improving the stability of the semi-supervised version of GANs presented in [1] (IGAN for short) . The paper presents a novel architecture for training adversarial networks in a semi-supervised settings (Algorithm 1). It further presents two theoretical results --- one (Theorem 2.1) showing that the generator\'s gradient vanish for IGAN, and the second (Theorem 3.1) showing that the proposed algorithm does not suffer this behaviour. Finally, experiments are provided (for MNIST and CIFAR10), which are meant to support empirically the claimed improved stability of the proposed method compared to the previous GAN implementations (including IGAN).\n\nI need to say the paper is poorly written and not properly polished. Among many other things:\n\n(1) It refers to non-existent results in other papers. Eq 2 is said to follow [1], meanwhile the objectives are totally different: the current paper seems to use the l2 loss, while Salimans et al. use the cross-entropy;\n\n(2) Does not introduce notations in statements of theorems ($J_\\theta$ in Theorem 2.1?) and provides unreadable proofs in appendix (proof of Theorem 2.1 is a sequence of inequalities involving the undefined notations with no explanations). In short, it is very hard to asses whether the proposed theoretical results are valid;\n\n(3) Does not motivate, discuss, or comment the architecture of the proposed method at all (see Section 3).\n\nFinally, in the experimental section it is unclear how exactly the authors measure the stability of training. The authors write ""unexpectedly high error rates and poor generate image quality"" (page 5), however, these things sounds very subjective and the authors never introduce a concrete metric. The authors only report ""0 fails"", ""one or two out of 10 runs fail"" etc. Moreover, for CIFAR10 it seems the authors make conclusions based only on 3 independent runs (page 6).\n\n[1] Salimans et al, Improved Techniques for Training GANs, 2016', 'In the paper, the author tried to address the training issue of SSL-GANs. Arguing that the main problem is the gradients vanishing, it proposed a co-training framework which combining the Wasserstein GAN training. The experiments were executed on MNIST and CIFAR-10. \n\nI think the paper made two strong claims, which are not reasonable for me: firstly, it argued that this is the first work to address training issue of SSL-GANs. Actually, the Fisher GAN paper [Youssef et al., 2017] proposed the ""New Parametrization of the Critic"" for SSL and showed it was very stable. In [Abhishek at al., 2017], the author also addressed how to make the SSL-GANs stable, following the improved GANs paper idea. Secondly, it made an impression that the author thought the main issue of SSL-GANs is the gradient vanishing. Following the paper [Zihang et al., 2017], it is hard to make claim like this. \n\nThe co-training framework is not so novel for me, which combined the Wasserstein loss and general GAN loss. Meanwhile, the experimental results are not solid. The baselines listed are not the state-of-the-art. I suggested that the author should compare with some very recent ones, such as [Youssef et al., 2017], [Zihang et al., 2017], [Abhishek et al., 2017], [Jeff et al., 2016].', ""Summary of paper and review:\n\nThe paper presents the instability issue of training GANs for semi-supervised learning. Then, they propose to essentially utilize a wgan for semi-supervised learning. \n\nThe novelty of the paper is minor, since similar approaches have been done before. The analysis is poor, the text seems to contain mistakes, and the results don't seem to indicate any advantage or promise of the proposed algorithm.\n\nDetailed comments:\n\n- Unless I'm grossly mistaken the loss function (2) is clearly wrong. There is a cross-entropy term used by Salimans et al. clearly missing.\n\n- As well, if equation (4) is referring to feature matching, the expectation should be inside the norm and not outside (this amounts to matching random specific random fake examples to specific random real examples, an imbalanced form of MMD).\n\n- Theorem 2.1 is an almost literal rewrite of Theorem 2.4 of [1], without proper attribution. Furthermore, Theorem 2.1 is not sufficient to demonstrate existence of this issues. This is why [1] provides an extensive batch of targeted experiments to verify this assumptions. Analogous experiments are clearly missing. A detailed analysis of these assumptions and its implications are missing.\n\n- In section 3, the authors propose a minor variation of the Improved GAN approach by using a wgan on the unsupervised part of the loss. Remarkably similar algorithms (where the two discriminators are two separate heads) to this have been done before (see for example, [2], but other approaches exist after that, see for examples papers citing [2]).\n\n- Theorem 3.1 is a trivial consequence of Theorem 3 from WGAN.\n\n- The experiments leave much to be desired. It is widely known that MNIST is a bad benchmark at this point, and that no signal can be established from a minor success in this dataset. Furthermore, the results in CIFAR don't seem to bring any advantage, considering the .1% difference in accuracy is 1/100 of chance in this dataset.\n\n[1]: Arjovsky & Bottou, Towards Principled Methods for Training Generative Adversarial Networks, ICLR 2017\n[2]: Mroueh & Sercu, Goel, McGan: Mean and Covariance Feature Matching GAN, ICML 2017""]","[-70, -60, -70]","[-20, 20, -20]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper is 'poorly written and not properly polished,' and lists several significant issues with the paper, including incorrect references, unclear notations, and inadequate experimental methodology. The lack of positive comments and the emphasis on problems indicate a strongly negative sentiment. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite critical and direct. Phrases like 'I need to say the paper is poorly written' and the lack of any softening language or positive reinforcement make the review come across as somewhat impolite. However, the reviewer does maintain a professional tone overall, which prevents the score from being lower."", ""The sentiment score is -60 because the reviewer expresses significant criticism of the paper's claims and novelty. They dispute two main claims of the paper, stating they are 'not reasonable' and pointing out existing work that contradicts these claims. The reviewer also finds the co-training framework 'not so novel' and the experimental results 'not solid'. However, it's not entirely negative as the reviewer acknowledges the author's efforts and provides constructive feedback, hence not reaching the lowest possible score. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I think' and 'I suggested' which soften the criticism. The language is not overtly polite, but it avoids rudeness, striking a neutral to slightly polite tone typical of academic discourse."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper's novelty is minor, the analysis is poor, and the results don't show any advantage. They also point out several mistakes and missing elements in the paper. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite critical and dismissive. Phrases like 'Unless I'm grossly mistaken' and 'Remarkably similar algorithms' have a somewhat condescending tone. The reviewer also uses strong negative language like 'clearly wrong' and 'The experiments leave much to be desired' without softening their criticisms.""]"
"['This paper studies the impact of angle bias on learning deep neural networks, where angle bias is defined to be the expected value of the inner product of a random vectors (e.g., an activation vector) and a given vector (e.g., a weight vector).  The angle bias is non-zero as long as the random vector is non-zero in expectation and the given vector is non-zero.  This suggests that the some of the units in a deep neural network have large values (either positive or negative) regardless of the input, which in turn suggests vanishing gradient.  The proposed solution to angle bias is to place a linear constraint such that the sum of the weight becomes zero.  Although this does not rule out angle bias in general, it does so for the very special case where the expected value of the random vector is a vector consisting of a common value.  Nevertheless, numerical experiments suggest that the proposed approach can effectively reduce angle bias and improves the accuracy for training data in the CIFAR-10 task.  Test accuracy is not improved, however.\n\nOverall, this paper introduces an interesting phenomenon that is worth studying to gain insights into how to train deep neural networks, but the results are rather preliminary both on theory and experiments.\n\nOn the theoretical side, the linearly constrained weights are only shown to work for a very special case.  There can be many other approaches to mitigate the impact of angle bias.  For example, how about scaling each variable in a way that the mean becomes zero, instead of scaling it into [-1,+1] as is done in the experiments?  When the mean of input is zero, there is no angle bias in the first layer.  Also, what about if we include the bias term so that b + w a is the preactivation value?\n\nOn the experimental side, it has been shown that linearly constrained weights can mitigate the impact of angle bias on vanishing gradient and can reduce the training error, but the test error is unfortunately increased for the particular task with the particular dataset in the experiments.  It would be desirable to identify specific tasks and datasets for which the proposed approach outperforms baselines.  It is intuitively expected that the proposed approach has some merit in some domains, but it is unclear exactly when and where it is.\n\nMinor comments:\n\nIn Section 2.2, is Layer 1 the input layer or the next?', 'The authors introduce the concept of angle bias (angle between a weight vector w and input vector x)  by which the resultant pre-activation (wx) is biased if ||x|| is non-zero or ||w|| is non-zero (theorm 2 from the article). The angle bias results in almost constant activation independent of input sample resulting in no weight updates for error reduction.   Authors chose to add an additional optimization constraint LCW (|w|=0) to achieve zero-mean pre-activation while, as mentioned in the article, other methods like batch normalization BN tend to push for |x|=0 and unit std to do the same. \n\nClearly, because of lack of scaling factor incase of LCW, like that in BN, it doesnot perform well when used with ReLU. When using with sigmoid the activation being bouded (0,1) seems to compensate for the lack of scaling in input. While BN explicitly makes the activation zero-mean LCW seems to achieve it through constraint on the weight features. Though it is shown to be computationally less expensive LCW seems to work in only specific cases unlike BN.', 'Pros:\nThe paper is easy to read. Logic flows naturally within the paper.\n\nCons:\n\n1. Experimental results are neither enough nor convincing. \n\nOnly one set of data is used throughout the paper: the Cifar10 dataset, and the architecture used is only a 100 layered MLP. Even though LCW performs better than others in this circumstance, it does not prove its effectiveness in general or its elimination of the gradient vanishing problem. For the 100 layer MLP, it\'s very hard to train a simple MLP and the training/testing accuracy is very low for all the methods. More experiments with different number of layers and different architecture like ResNet should be tried to show better results. \n\nIn Figure (7), LCW seems to avoid gradient vanishing but introduces gradient exploding problem.\n\nThe proposed concept is only analyzed in MLP with Sigmoid activation function. In the experimental parts, the authors claim they use both ReLU and Sigmoid function, but no comparisons are reflected in the figures. \n\n2. The whole standpoint of the paper is quite vague and not very convincing.\nIn section 2, the authors introduce angle bias and suggest its effect in MLPs that with random weights, showing that different samples may result in similar output in the second and deeper layers. However, the connection between angle bias and the issue of gradient vanishing lacks a clear analytical connection. The whole analysis of the connection is built solely on this one sentence ""At the same time, the output does not change if we adjust the weight vectors in Layer 1"", which is nowhere verified. \n\nFurther, the phenomenon is only tested on random initialization. When the network is trained for several iterations and becomes more settled, it is not clear how ""angle affect"" affects gradient vanishing problem.\n\n\nMinors:\n1. Theorem 1,2,3 are direct conclusions from the definitions and are mis-stated as Theorems.\n\n2. \'patters\' -> \'patterns\'\n\n3. In section 2.3, reasons 1 and 2 state the similar thing that output of MLP has relatively small change with different input data when angle bias occurs. Only reason 1 mentions the gradient vanishing problem, even though the title of this section is ""Relation to Vanishing Gradient Problem"". \n']","[-20, -20, -70]","[60, 0, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper introduces 'an interesting phenomenon that is worth studying', they also state that 'the results are rather preliminary both on theory and experiments'. The reviewer points out several limitations and areas for improvement, suggesting the paper needs more work. However, the tone is not entirely negative, as they recognize the potential value of the research.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and constructive language throughout. They begin by summarizing the paper's content objectively, use phrases like 'it would be desirable' when suggesting improvements, and offer specific recommendations for enhancing the work. The reviewer maintains a professional tone, avoiding harsh criticism while still clearly communicating areas for improvement. The use of phrases like 'interesting phenomenon' and 'worth studying' also contribute to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the authors' introduction of the concept of angle bias and their proposed solution (LCW), they also point out limitations of the approach. The reviewer notes that LCW doesn't perform well with ReLU and only works in specific cases, unlike batch normalization (BN). This suggests a somewhat critical view of the paper's contributions. The politeness score is neutral (0) as the language used is neither particularly polite nor rude. The reviewer maintains a professional and objective tone throughout, stating observations and comparisons without using overtly positive or negative language. The review focuses on technical aspects and comparisons without personal comments or strong praise or criticism."", ""The sentiment score is -70 because the review is predominantly negative. While it acknowledges that the paper is easy to read, the majority of the content focuses on significant criticisms. The reviewer points out major issues with the experimental results, questioning their sufficiency and convincingness. They also criticize the paper's standpoint as vague and unconvincing, and highlight several minor issues. These criticisms outweigh the single positive comment, resulting in a strongly negative sentiment.\n\nThe politeness score is 20 because while the reviewer doesn't use overtly polite language, they maintain a professional and objective tone throughout. They present their criticisms in a straightforward manner without using harsh or rude language. The use of phrases like 'The paper is easy to read' and the organization of feedback into 'Pros' and 'Cons' sections shows a level of consideration. However, the lack of more explicitly polite language or positive reinforcement keeps the score from being higher.""]"
"[""The paper proposes an unsupervised structure learning method for deep neural networks. It first constructs a fully visible DAG by learning from data, and decomposes variables into autonomous sets. Then latent variables are introduced and stochastic inverse is generated. Later a deep neural network structure is constructed based on the discriminative graph. Both the problem considered in the paper and the proposed method look interesting. The resulting structure seems nice.\n\nHowever, the reviewer indeed finds a major technical flaw in the paper. The foundation of the proposed method is on preserving the conditional dependencies in graph G. And each step mentioned in the paper, as it claims, can preserve all the conditional dependencies. However, in section 2.2, it seems that the stochastic inverse cannot. In Fig. 3(b), A and B are no longer dependent conditioned on {C,D,E} due to the v-structure induced in node H_A and H_B. Also in Fig. 3(c), if the reviewer understands correctly, the bidirectional edge between H_A and H_B is equivalent to H_A <- h -> H_B, which also induces a v-structure, blocking the dependency between A and B. Therefore, the very foundation of the proposed method is shattered. And the reviewer requests an explicit explanation of this issue.\n\nBesides that, the reviewer also finds unfair comparisons in the experiments.\n\n1. In section 5.1, although the authors show that the learned structure achieves 99.04%-99.07% compared with 98.4%-98.75% for fully connected layers, the comparisons are made by keeping the number of parameters similar in both cases. The comparisons are reasonable but not very convincing. Observing that the learned structures would be much sparser than the fully connected ones, it means that the number of neurons in the fully connected network is significantly smaller. Did the authors compare with fully connected network with similar number of neurons? In such case, which one is better? (Having fewer parameters is a plus, but in terms of accuracy the number of neurons really matters for fair comparison. In practice, we definitely would not use that small number of neurons in fully connected layers.)\n\n2. In section 5.2, it is interesting to observe that using features from conv10 is better than that from last dense layer. But it is not a fair comparison with vanilla network. In vanilla VGG-16-D, there are 3 more conv layers and 3 more fully connected layers. If you find that taking features from conv10 is good for the learned structure, then maybe it will also be good by taking features from conv10 and then apply 2-3 fully-connected layers directly (The proposed structure learning is not comparable to convolutional layers, and what it should really compare to is fully-connected layers.) In such case, which one is better? \nSecondly, VGG-16 is a large network designed for ImageNet data. For small dataset such as CIFAR10 and CIFAR100, it is really overkilled. That's maybe the reason why taking the output of shallow layers could achieve pretty good results.\n\n3. In Fig. 6, again, comparing the learned structure with fully-connected network by keeping parameters to be similar and resulting in large difference of the number of neurons is unfair from my point of view.\n\nFurthermore, all the comparisons are made with respect to fully-connected network or vanilla CNNs. No other structure learning methods are compared with. Reasonable baseline methods should be included.\n\nIn conclusion, due to the above issues both in method and experiments, the reviewer thinks that this paper is not ready for publication.\n"", 'This paper tackles the important problem of structure learning by introducing an unsupervised algorithm, which encodes a hierarchy of independencies in the input distribution and allows introducing skip connections among neurons in different layers. The quality of the learnt structure is evaluated in the context of image classification, analyzing the impact of the number of parameters and layers on the performance.\n\nThe presentation of the paper could be improved. Moreover, the paper largely exceeds the recommended page limit (11 pages without references).\n\nMy main comments are related to the experimental section:\n\n- Section 5 highlights that experiments were repeated 5 times; however, the standard deviation of the results is only reported for some cases. It would be beneficial to include the standard deviations of all experiments in the tables summarizing the obtained results.\n\n- Are the differences among results presented in table 1 (MNIST) and table 2 (CIFAR10) statistically significant?\n\n- It is not clear how the numbers of table 4 were computed (size replaced, size total, t-size, replaced-size). Would it be possible to provide the number of parameters of the vanilla model, the pre-trained feature extractor and the learned structure separately?\n\n- In section 5.2., there is only one sentence mentioning comparisons to alternative approaches. It might be worth expanding this and including numerical comparisons.\n\n- It seems that the main focus of the experiments is to highlight the parameter reduction achieved by the proposed algorithm. There is a vast literature on model compression, which might be worth reviewing, especially given that all the experiments are performed on standard image classification tasks.\n\n\n\n', 'Authors propose a deep architecture learning algorithm in an unsupervised fashion. By finding conditional in-dependencies in input as a Bayesian network and using a stochastic inverse mechanism that preserves the conditional dependencies, they suggest an optimal structure of fully connected hidden layers (depth, number of groups and connectivity). Their algorithm can be applied recursively, resulting in multiple layers of connectivity. The width of each layer (determined by number of neurons in each group) is still tuned as a hyper-parameter.\n\nPros:\n- Sound derivation for the method.\n- Unsupervised and fast algorithm. \nCons:\n- Poor writing, close to a first draft. \n- Vague claims of the gain in replacing FC with these structures, lack of comparison with methods targeting that claim.\n - If the boldest claim is to have a smaller network, compare results with other compression methods.\n - If it is the gain in accuracy compare with other learn to learn methods and show that you achieve same or higher accuracy. The NAS algorithm achieves 3.65% test error. With a smaller network than the proposed learned structure (4.2M vs 6M) here they achieve slightly worse (5.5% vs 4.58%) but with a slightly larger (7.1M vs 6M) they achieve slightly better results (4.47% vs 4.58%). The winner will not be clear unless the experiments fixes one of variables or wins at both of them simultaneously.\n\nDetailed comments:\n\n- Results in Table 4 mainly shows that replacing fully connected layer with the learned structures leads to a much sparser connectivity (smaller number of parameters) without any loss of accuracy. Fewer number of parameters usually is appealing either because of better generalizability or less computation cost. In terms of generalizability, on most of the datasets the accuracy gain from the replacement is not statistically significant. Specially without reporting the standard deviation. Also the generalizability impact of this method on the state-of-the-art is not clear due to the fact that the vanilla networks used in the experiments are generally not the state-of-the-art networks. Therefore, it would be beneficial if the authors could show the speed impact of replacing FC layers with the learned structures. Are they faster to compute or slower?\n- The purpose of section 5.1 is written as number of layers and number of parameters. But it compares with an FC network which has same number of neurons-per-layer. The rest of the paper is also about number of parameters. Therefore, the experiments in this section should be in terms of number of parameters as well. Also most of the numbers in table 1 are not significantly different. \n\nSuggestions for increasing the impact:\n\nThis method is easily adaptable for convolutional layers as well. Each convolutional kernel is a fully connected layer on top of a patch of an image. Therefore, the input data rather than being the whole image would be all patches of all images. This method could be used to learn a new structure to replace the KxK fully connected transformation in the convolutional layer. \n\nThe fact that this is an unsupervised algorithm and it is suitable for replacing FC layers suggests experimentation on semi-supervised tasks or tasks that current state-of-the-art relies more on FC layers than image classification. However, the experiments in this paper are on fully-labeled image classification datasets which is possibly not a good candidate to verify the full potential of this algorithm.']","[-70, -20, -20]","[20, 50, 50]","[""The sentiment score is -70 because the review identifies a 'major technical flaw' in the paper's foundation and concludes that the paper is 'not ready for publication'. The reviewer also points out several issues with the experimental comparisons, describing them as 'unfair'. However, the score is not at the extreme negative end because the reviewer does acknowledge some positive aspects, such as the interesting problem and method, and the 'nice' resulting structure. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional and respectful language throughout. They use phrases like 'the reviewer finds' and 'the reviewer requests' rather than making personal attacks. They also acknowledge positive aspects before diving into criticisms. However, the score is not higher due to the overall critical tone and direct statement that the paper is not ready for publication."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem and the novel approach, they also point out several areas for improvement, particularly in the experimental section. The review begins positively but quickly moves to critiques and suggestions for enhancement, indicating a somewhat critical stance overall. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, framing their comments as suggestions ('It would be beneficial...', 'Would it be possible...') rather than direct criticisms. They also acknowledge the paper's strengths before moving on to areas of improvement. The reviewer maintains a professional tone, avoiding harsh language or personal comments, which contributes to the politeness of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros ('Sound derivation', 'Unsupervised and fast algorithm'), they also list several significant cons and areas for improvement. The review points out 'Poor writing', 'Vague claims', and lack of proper comparisons, which outweigh the positive aspects. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, offering constructive criticism and suggestions for improvement. They use neutral language like 'It would be beneficial if...' and 'Suggestions for increasing the impact:', which contributes to the polite tone. However, some direct criticisms like 'Poor writing, close to a first draft' prevent the score from being higher.""]"

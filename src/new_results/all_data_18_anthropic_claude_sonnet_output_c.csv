reviews,sentiment_scores,politeness_scores,reasonings
"['*Summary*\n\nThe paper applies variational inference (VI) with the \'reparameterisation\' trick for Bayesian recurrent neural networks (BRNNs). The paper first considers the ""Bayes by Backprop"" approach of Blundell et al. (2015) and then modifies the BRNN model with a hierarchical prior over the network parameters, which then requires a hierarchical variational approximation with a simple linear recognition model. Several experiments demonstrate the quality of the prediction and the uncertainty over dropout.  \n\n*Originality + significance*\n\nTo my knowledge, there is no other previous work on VI with the reparameterisation trick for BRNNs. However, one could say that this paper is, on careful examination, an application of reparameterisation gradient VI for a specific application. \n\nNevertheless, the parameterisation of the conditional variational distribution q(\\theta | \\phi, (x, y)) using recognition model is interesting and could be useful in other models. However, this has not been tested or concretely shown in this paper. The idea of modifying the model by introducing variables to obtain a looser bound which can accommodate a richer variational family is also not new, see: hierarchical variational model (Ranganath et al., 2016) for example. \n\n*Clarity*\n\nThe paper is, in general, well-written. However, the presentation in 4 is hard to follow. I would prefer if appendix A3 was moved up front -- in this case, it would make it clear that the model is modified to contain \\phi, a variational approximation over both \\theta and \\phi is needed, and a q that couples \\theta, \\phi and and the gradient of the log likelihood term wrt \\phi is chosen. \n\nAdditional comments:\n\nWhy is the variational approximation called ""sharpened""?\n\nAt test time, normal VI just uses the fixed q(\\theta) after training. It\'s not clear to me how prediction is done when using \'posterior sharpening\' -- how is q(\\theta | \\phi, x) in eqs. 19-20 parameterised? The first paragraph of page 5 uses q(\\theta | \\phi, (x, y)), but y is not known at test time.\n\nWhat is C in eq. 9?\n\nThis comment ""variational typically underestimate the uncertainty in the posterior...whereas expectation propagation methods are mode averaging and so tend to overestimate uncertainty..."" is not precise. EP can do mode averaging as well as mode seeking, depending on the underlying and approximate factor graphs. In the Bayesian neural network setting when the likelihood is factorised point-wise and there is one factor for each likelihood, EP is just as mode-seeking as variational. On the other hand, variational methods can avoid modes too, see the mixture of Gaussians example in the ""Two problems with variational EM... "" paper by Turner and Sahani (2010).\n\nThere are also many hyperparameters that need to be chosen -- what would happen if these are optimised using the free-energy? Was there any KL reweighting scheduling as done in the original BBB paper? \n\nWhat is the significance of the difference between BBB and BBB with sharpening in the language modelling task? Was sharpening used in the image caption generation task?\n\nWhat is the computational complexity of BBB with posterior sharpening? Twice that BBB? If this is the case, would BBB get to the same performance if we optimise it for longer? Would be interesting to see the time/accuracy frontier.', 'This paper proposes an interesting variational posterior approximation for the weights of an RNN. The paper also proposes a scheme for assessing the uncertainty of the predictions of an RNN. \n\npros:\n--I liked the posterior sharpening idea. It was well motivated from a computational cost perspective hence the use of a hierarchical prior. \n--I liked the uncertainty analysis. There are many works on Bayesian neural networks but they never present an analysis of the uncertainty introduced in the weights. These works can benefit from the uncertainty analysis scheme introduced in this paper.\n--The experiments were well carried through.\n\ncons:\n--Change the title! the title is too vague. ""Bayesian recurrent neural networks"" already exist and is rather vague for what is being described in this paper.\n--There were a lot of unanswered questions:\n (1) how does sharpening lead to lower variance? This was a claim in the paper and there was no theoretical justification or an empirical comparison of the gradient variance in the experiment section\n(2) how is the level of uncertainty related to performance? It would have been insightful to see effect of \\sigma_0 on the performance rather than report the best result. \n(3) what was the actual computational cost for the BBB RNN and the baselines?\n--There were very minor typos and some unclear connotations. For example there is no such thing as a ""variational Bayes model"".\n\nI am willing to adjust my rating when the questions and remarks above get addressed.', 'The manuscript proposes a new framework for inference in RNN based upon the Bayes by Backprop (BBB) algorithm.  In particular, the authors propose a new framework to ""sharpen"" the posterior.\n\nIn particular, the hierarchical prior in (6) and (7) frame an interesting modification to directly learning a multivariate normal variational approximation.  In the experimental results, it seems clear that this approach is beneficial, but it\'s not clear as to why.  In particular, how does the variational posterior change as a result of the hierarchical prior?  It seems that (7) would push the center of the variational structure back towards the MAP point and reduces the variance of the output of the hierarchical prior; however, with the two layers in the prior it\'s unclear what actually is happening.  Carefully explaining *what* the authors believe is happening and exploring how it changes the variational approximation in a classic modeling framework would be beneficial to understanding the proposed change and evaluating it.  As a final point, the authors state, ""as long as the improvement along the gradient is great than the KL loss incurred...this method is guaranteed to make progress towards optimizing L.""  Do the authors mean that the negative log-likelihood will be improved in this case?  Or the actual optimization?  Improving the negative log-likelihood seems straightforward, but I am confused by what the authors mean by optimization.\n\nThe new evaluation metric proposed in Section 6.1.1 is confusing, and I do not understand what the metric is trying to capture.  This needs significantly more detail and explanation.  Also, it is unclear to me what would happen when you input data examples that are opposite to the original input sequence; in particular, for many neural networks the predictions are unstable outside of the input domain and inputting infeasible data leads to unusable outputs.  It\'s completely feasible that these outputs would just be highly uncertain, and I\'m not sure how you can ascribe meaning to them.  The authors should not compare to the uniform prior as a baseline for entropy.  It\'s much more revealing to compare it to the empirical likelihoods of the words.\n']","[-20, 50, -20]","[60, 75, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's originality in applying VI with the reparameterisation trick for BRNNs, they also point out several limitations and areas for improvement. The reviewer suggests that the paper is largely an application of existing techniques to a specific case, and raises questions about the significance of the results and the clarity of certain sections. However, the tone is not overwhelmingly negative, as the reviewer does highlight some positive aspects.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'To my knowledge' and 'I would prefer' which soften their criticisms. The reviewer also balances negative points with positive ones, acknowledging the paper's contributions while suggesting improvements. The language is constructive rather than harsh, focusing on specific areas for improvement rather than blanket criticisms. However, it's not extremely polite, as the reviewer doesn't use overtly complimentary language or go out of their way to soften every criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by describing the paper as 'interesting' and lists several pros, indicating a generally positive view. However, they also list significant cons and unanswered questions, which tempers the positivity. The willingness to adjust the rating suggests the review is not overwhelmingly positive or negative. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. The use of phrases like 'I liked' and the offer to adjust the rating based on addressing concerns demonstrates a collegial tone. While direct in pointing out issues, the reviewer maintains a professional and courteous approach."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting modification', 'clear that this approach is beneficial'), they express several concerns and request significant clarifications. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language, frames criticisms constructively ('would be beneficial', 'needs significantly more detail'), and acknowledges positive aspects. They avoid harsh or dismissive language, maintaining a professional tone throughout.""]"
"[""This paper studies hyperparameter-optimization by Bayesian optimization, using the Knowledge Gradient framework and allowing the Bayesian optimizer to tune fideltiy against cost.\n\nThere’s nothing majorly wrong with this paper, but there’s also not much that is exciting about it. As the authors point out very clearly in Table 1, this setting has been addressed by several previous groups of authors. This paper does tick a previously unoccupied box in the problem-type-vs-algorithm matrix, but all the necessary steps are relatively straightforward.\n\nThe empirical results look good in comparison to the competing methods, but I suspsect an author of those competitors could find a way to make their own method look better in those plots, too.\n\nIn short: This is a neat paper, but it’s novelty is low. I don't think it would be a problem if this paper were accepted, but there are probably other, more groundbreaking papers in the batch.\n\nMinor question: Why are there no results for 8-cfKG and Hyperband in Figure 2 for SVHN?"", '\nMany black-box optimization problems are ""multi-fidelity"", in which it\nis possible to acquire data with different levels of cost and\nassociated uncertainty.  The training of machine learning models is a\ncommon example, in which more data and/or more training may lead to\nmore precise measurements of the quality of a hyperparameter\nconfiguration.  This has previously been referred to as a special case\nof ""multi-task"" Bayesian optimization, in which the tasks can be\nconstructed to reflect different fidelities.  The present paper\nexamines this construction with three twists: using the knowledge\ngradient acquisition function, using batched function evaluations, and\nincorporating derivative observations.  Broadly speaking, the idea is\nto allow fidelity to be represented as a point in a hypercube and then\ninclude this hypercube as a covariate in the Gaussian process.  The\nknowledge gradient acquisition function then becomes ""knowledge\ngradient per unit cost"" the KG equivalent to the ""expected improvement\nper unit cost"" discussed in Snoek et al (2012), although that paper\ndid not consider treating fidelity separately.\n\nI don\'t understand the claim that this is ""the first multi-fidelity\nalgorithm that can leverage gradients"".  Can\'t any Gaussian process\nmodel use gradient observations trivially, as discussed in the\nRasmussen and Williams book?  Why can\'t any EI or entropy search\nmethod also use gradient observations?  This doesn\'t usually come up\nin hyperparameter optimization, but it seems like a grandiose claim.\nSimilarly, although I don\'t know of a paper that explicitly does ""A +\nB"" for multi-fidelity BO and parallel BO, it is an incremental\ncontribution to combine them, not least because no other parallel BO\nmethods get evaluated as baselines.\n\nFigure 1 does not make sense to me.  How can the batched algorithm\noutperform the sequential algorithm on total cost?  The sequential\ncfKG algorithm should always be able to make better decisions with its\nremaining budget than 8-cfKG.  Is the answer that ""cost"" here means\n""wall-clock time when parallelism is available""?  If that\'s the case,\nthen it is necessary to include plots of parallelized EI, entropy\nsearch, and KG.  The same is true for Figure 2; other parallel BO\nalgorithms need to appear.', 'Minor comments:\n- page 7. “Then, observe that the same reasoning we used to develop the cfKG acquistion function\nin (3.2) can be used when when we observe gradients to motivate the acquisition function…” - some misprints, e.g. double “when”\n- The paper lacks theoretical analysis of convergence of the proposed modification of the knowledge gradient criterion.\n\nMajor comments:\n\nCurrent approaches to optimisation of expensive functions are mainly based on Gaussian process model. Such approaches are important for Auto ML algorithms.\n\nThere are a lot of cases, when for an expensive function we can obtain measurements of its values with continuous fidelity by leveraging costs for evaluation vs. fidelity of the obtained values. E.g. as fidelity we can consider a size of the training set used to train a deep neural network.\n\nThe paper contains a some new algorithm to perform Bayesian optimisation of a function with continuous fidelity. Using modification of the knowledge gradient acquisition function the authors obtained black box optimisation method taking into account continuous fidelity. \n\nDue to some reason the authors forgot to take the cost function into account when formulating the algorithm 1 in 3.3.2 and corresponding formula (3.7).\n\nSo, the logic of the definition of q-cfKG is understandable, but the issue with the missing denominator, containing cost function, remains.\n\nThe approach, proposed in section 3.3.2, looks as follows:\n- the authors used formulas from [Wu t al (2017) - https://arxiv.org/abs/1703.04389] \n- and include additional argument in the mean function of the Gaussian process.\nHowever, in Wu t al (2017) they consider usual knowledge gradient, but in this paper they divide by the value of max(cost(z)), which is not differentiable.\n\nOther sections of the paper are sufficiently well written, except \n- the section 3.3.2, \n- section with results of experiments: I was not able to understand how the authors defined cost function in sections 4.2 and 4.3 for their neural network and large scale kernel learning.\n\nIn principle, the paper contains some new results, but it should be improved before publishing.']","[-20, -20, -20]","[50, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that there's 'nothing majorly wrong' with the paper, they also state that it's not very exciting and has low novelty. The reviewer suggests that other papers might be more groundbreaking, indicating a lukewarm reception. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's merits ('neat paper', 'empirical results look good') while offering constructive criticism. They avoid harsh language and present their concerns in a professional manner, even when pointing out the paper's limitations."", 'The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper\'s contributions, they express significant doubts and criticisms. They question the novelty claim (\'I don\'t understand the claim that this is ""the first multi-fidelity algorithm that can leverage gradients""\'), point out perceived weaknesses (\'it is an incremental contribution\'), and express confusion about the results (\'Figure 1 does not make sense to me\'). However, the review isn\'t entirely negative, as it does recognize some merits of the paper. The politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout, using phrases like \'I don\'t understand\' instead of more confrontational language. They also provide constructive feedback and suggestions for improvement. The language is not overly formal or polite, but it avoids rudeness, resulting in a slightly positive score.', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some new results and the importance of the topic, they point out several issues with the paper, including missing elements in the algorithm, lack of theoretical analysis, and unclear explanations in some sections. The overall tone suggests the paper needs significant improvements before publication. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's contributions and providing constructive feedback. They use phrases like 'the paper contains some new results' and 'should be improved before publishing' rather than harsh criticisms. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback.""]"
"['This paper attempts to improve the beta-VAE (Higgins et al, 2017) by removing the trade-off between the quality of disentanglement in the latent representation and the quality of the reconstruction. The authors suggest doing so by explicitly modelling the noise of the reconstructed image Gaussian p(x|z). The authors assume that VAEs typically model the data using a Guassian distribution with a fixed noise. This, however, is not the case. Since the authors are trying to address a problem that does not actually exist, I am not sure what the contributions of the paper are. \n\nApart from the major issue outlined above, the paper also makes other errors. For example, it suggests using D_KL(q(z)||p(z)) as a measure of disentanglement, with lower values being indicative of better disentanglement. This, however, is incorrect, since one can have tiny D_KL by encoding all the information into a single latent z_i. Such a representation would be highly entangled while still satisfying all of the conditions the authors propose for a disentangled representation. \n\nGiven the points outlined above and the fact that the paper is hard to read and is excessively long, I do not believe it should be accepted.', 'This paper studies the importance of the noise modelling in Gaussian VAE. The original Gaussian VAE proposes to use the inference network for the noise that takes latent variables as inputs and outputs the variances, but most of the existing works on Gaussian VAE just use fixed noise probably because the inference network is hard to train. In this paper, instead of using the fixed noise or inference network for the noise, the authors proposed to train the noise using Empirical-Bayes like fashion. The algorithm to train noise level for the single Gaussian decoder and mixture of Gaussian decoder is presented, and the experiments show that fitting the noise actually improves the ELBO and enhances the ability to disentangle latent factors.\n \nI appreciate the importance of noise modeling, but not sure if the presented algorithm is a right way to do it. The proposed algorithm assumes the Gaussian likelihood with homoscedastic noise, but this is not the case for many real-world data (MNIST and Color images are usually modelled with Bernoulli likelihood). The update equations for noises rely on the simple model structure, and this may not hold for the arbitrary complex likelihood (or implicit likelihood case). In my personal opinion, making the inference network for the noise to be trainable would be more principled way of solving the problem.\n \nThe paper is too long (30 pages) and dense, so it is very hard to read and understand the whole stuff. Remember that the ‘recommended’ page limit is 8 pages. The proposed algorithm was not compared to the generative models other than the basic VAE or beta-VAE.', 'This paper proposes to modify how noise factors are treated when developing VAE models.  For example, the original VAE work from (Kingma and Welling, 2013) applies a deep network to learn a diagonal approximation to the covariance on the decoder side.  Subsequent follow-up papers have often simplified this covariance to sigma^2*I, where sigma^2 is assumed to be known or manually tuned.  In contrast, this submission suggests either treating sigma^2 as a trainable parameter, or else introducing a more flexible zero-mean mixture-of-Gaussians (MoG) model for the decoder noise.  These modeling adaptations are then analyzed using various performance indicators and empirical studies.\n\nThe primary issues I have with this work are threefold:  (i) The paper is not suitably organized/condensed for an ICLR submission, (ii) the presentation quality is quite low, to the extent that clarity and proper understanding are jeopardized, and (iii) the novelty is limited.  Consequently my overall impression is that this work is not yet ready for acceptance to ICLR.\n\nFirst, regarding the organization, this submission is 19 pages long (*excluding* references and appendices), despite the clear suggestion in the call for papers to limit the length to 8 pages: ""There is no strict limit on paper length. However, we strongly recommend keeping the paper at 8 pages, plus 1 page for the references and as many pages as needed in an appendix section (all in a single pdf). The appropriateness of using additional pages over the recommended length will be judged by reviewers.""  In the present submission, the first 8+ pages contain minimal new material, just various background topics and modified VAE update rules to account for learning noise parameters via basic EM algorithm techniques.  There is almost no novelty here.  In my mind, this type of well-known content is in no way appropriate justification for such a long paper submission, and it is unreasonable to expect reviewers to wade through it all during a short review cycle.\n\nSecondly, the presentation quality is simply too low for acceptance at a top-tier international conference (e.g., it is full of strange sentences like ""Such amelioration facilitates the VAE capable of always reducing the artificial intervention due to more proper guiding of noise learning.""  While I am sympathetic to the difficulties of technical writing, and realize that at times sufficiently good ideas can transcend local grammatical hiccups, my feeling is that, at least for now, another serious pass of editing is seriously needed.  This is especially true given that it can be challenging to digest so many pages of text if the presentation is not relatively smooth.\n\nThird and finally, I do not feel that there is sufficient novelty to overcome the issues already raised above.  Simply adapting the VAE decoder noise factors via either a trainable noise parameter or an MoG model represents an incremental contribution as similar techniques are exceedingly common.  Of course, the paper also invents some new evaluation metrics and then applies them on benchmark datasets, but this content only appears much later in the paper (well after the soft 8 page limit) and I admittedly did not read it all carefully.  But on a superficial level, I do not believe these contributions are sufficient to salvage the paper (although I remain open to hearing arguments to the contrary).']","[-90, -20, -80]","[-20, 50, -20]","[""The sentiment score is -90 because the reviewer strongly criticizes the paper, stating that it addresses a non-existent problem, makes errors, and should not be accepted. The reviewer uses phrases like 'I am not sure what the contributions of the paper are' and 'I do not believe it should be accepted,' indicating a very negative sentiment. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite dismissive and critical. The reviewer directly states that the paper is 'hard to read and is excessively long' without offering constructive feedback, which comes across as somewhat impolite. The lack of any positive comments or suggestions for improvement also contributes to the slightly negative politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and some positive aspects ('I appreciate the importance of noise modeling'), they express significant doubts about the approach ('not sure if the presented algorithm is a right way to do it') and criticize the paper's length and readability. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's contributions and offering constructive criticism. They use phrases like 'I appreciate' and 'In my personal opinion' which maintain a polite tone even when expressing concerns."", ""The sentiment score is -80 because the reviewer expresses significant concerns about the paper, stating it is 'not yet ready for acceptance' and highlighting three major issues. The reviewer criticizes the paper's organization, presentation quality, and lack of novelty. The language used is largely negative, with phrases like 'primary issues,' 'jeopardized,' and 'simply too low for acceptance.' The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism and somewhat dismissive language. For example, phrases like 'it is unreasonable to expect reviewers to wade through it all' and 'I admittedly did not read it all carefully' come across as slightly rude. However, the reviewer does offer some balanced statements and expresses openness to counterarguments, which prevents the score from being lower.""]"
"[""The paper investigates the potential of hierarchical latent variable models for generating images and image sequences. The paper relies on the ALI model from [Dumoulin et al, ICLR'16] as the main building block. The main innovation in the paper is to propose to train several ALI models stacked on top of each other to create a hierarchical representation of the data. The proposed hierarchical model is trained in stages. First stage is an original ALI model as in [Dumoulin et al]. Each subsequent stage is constructed by using the Z variables from the previous stage as the target data to be generated.\n\nThe paper constructs models for generatation of images and image sequences. The model for images is a 2-level ALI. The first level is similar to PatchGAN from [1] but is trained as an ALI model. The second layer is another ALI that is trained to generate latent variables from the first layer. \n\n[1] Isola et al. Image-to-Image Translation with Conditional Adversarial Networks, CVPR'17 \n\nIn the the model for image sequences the hierarchy is somewhat different. The top layer is directly generating images and not patches as in the image-generating model.\n\nSummary: I think this paper presents a direct and somewhat straightforward extension of ALI. Therefore the novelty is limited. I think the paper would be stronger if it (1) demonstrated improvements when compared to ALI and (2) showed advantages of hierarchical training on other datasets, not just the somewhat simple datasets like CIFAR and Pacman. \n\nOther comments / questions: \n\n- baseline should probably be 1-level ALI from [Dumoulin et al.]. I believe in the moment the baseline is a standard GAN.\n\n- I think the paper would be stronger if it directly reproduced the experiments from [Dumoulin et al.] and showed how hierarchy compares to standard ALI without hierarchy. \n\n- the reference Isola et al. [1] should ideally be cited since the model for image genration is similar to PatchGAN in [1]\n\n- Why is the video model in this paper not directly extending the image model? Is it due to limitation of the implementation or direclty extending the iamge model didn't work? \n"", 'Training GAN in a hierarchical optimization schedule shows promising performance recently (e.g. Zhao et al., 2016). However, these works utilize the prior knowledge of the data (e.g. image) and it\'s hard to generalize it to other data types (e.g. text). The paper aims to learn these hierarchies directly instead of designing by human. However, several parts are missing and not well-explained. Also, many claims in paper are not proved properly by theory results or empirical results. \n\n(1) It is not clear to me how to train the proposed algorithm. My understanding is train a simple ALI, then using the learned latent as the input and train the new layer. Do the authors use a separate training ? or a joint training algorithms. The authors should provide a more clear and rigorous objective function. It would be even better to have a pseudo code. \n\n(2) In abstract, the authors claim the theoretical results are provided. I am not sure whether it is sec 3.2 The claims is not clear and limited. For example, what\'s the theory statement of [Johnsone 200; Baik 2005]. What is the error measure used in the paper? For different error, the matrix concentration bound might be different. Also, the union bound discussed in sec 3.2 is also problematic. Lats, for using simple standard GAN to learn mixture of Gaussian, the rigorous theory result doesn\'t seem easy (e.g. [1])  The author should strive for this results if they want to claim any theory guarantee. \n\n(3) The experiments part is not complete. The experiment settings are not described clearly. Therefore, it is hard to justify whether the proposed algorithm is really useful based on Fig 3. Also, the authors claims it is applicable to text data in Section 1, this part is missing in the experiment. Also, the idea of ""local"" disentangled LV is not well justified to be useful.\n\n[1] On the limitations of first order approximation in GAN dynamics, ICLR 2018 under review\n', 'This paper proposed a method called Locally Disentangled Factors for hierarchical latent variable generative model, which can be seen as a hierarchical variant of Adversarially Learned Inference (Dumoulin el atl. 2017). The idea seems to be a valid variant, however, the quality of the paper is not good. The introduction and related works sections read well, but the rest of the paper has not been written well. More specifically, the content in section 3 and experiment section is messy. Also the experiments have not been conducted thoroughly, and the results and the interpretation of the results are not complete.\n\nIntroduction:\nAlthough in introduction the author discussed a lot of works on hierarchical latent variable model and some motivating examples, after reading it the reviewer has absolutely no idea what the paper is about (except hierarchical latent variable model), what is the motivation, what is the general idea, what is the contribution of the paper. Only after carefully reading the detailed implementation in section 3.1 and section 5, did I realize that what the authors are actually doing is to use N variables to model N different parts of the observation, and one higher level variable to model the N variables. The paper should really more precisly state what the idea is throughout the paper, instead of causing confusion and ambiguity.\n\nSection 3:\n1. The concepts of ""disentanglment"" and ""local connectivity"" are really unnecessary and confusing. First, the whole paper and experiments has nothing to do with ""local connectivity"". Even though you might have the intention to propose the idea, you didn\'t show any support for the idea. Second, what you actually did is to use top level variable to generate N latent variables. That could hardly called ""disentanglement"". The mean field factorization in (Kingma & Welling 2013) is on the inference side (Q not P), and as found out in literature, it could not achieve disentanglement.\n\n2. In section 3.2, I understand that you want to say the hierarchical model may require less data sample. But, here you are really off-topic. It would be much better if you can relate to the proposed method, and state how it may require less data.\n\n3. Section 3.1 is more important, and is really major part of your method. Therefore, it need more extensive discussion and emphasis.\n\nExperiment:\nThis section is really bad.\n1. Since in the introduction and related works, there are already so many hierarchical latent variable model listed, the baseline methods should really not just vanilla GAN, but hierarchical latent variable models, such as the Hierachical VAE, Variational Ladder Autoencoder in (Zhao et al. 2017), ALI (not hierarchical, but should be a baseline) in (Dumoulin et al. 2017), etc.\n\n2. Since currently there is still no standard way to evaluate the quality of image generation, by giving only inception score, we can really not judge whether it is good or not. You need to give more metrics, or generation examples, recontruction examples, and so on. And equally importantly, compare and discuss about the results. Not just leave it there.\n\n3. For section 5.2, similar problems as above exist. Baseline methods might be insufficient. The paper only shows several examples, and the reviewer cannot draw any conclusion about it. Nor does the paper discuss any of the results.\n\n4. Section 5.3, second to the last line, typo: ""This is shown in 7"". Also this result is not available. \n\n5. More importantly, some experiments should be conducted to explicitly show the validity of the proposed hierarchical latent model idea. Show that it exists and works by some experiment explicitly.\n\nAnother suggestion the review would like to make is that, instead of proposing the general framework in section 2, it would be better to propose the hierarchical model in the context of section 3.1. That is, instead of saying z_0 -> z_1 ->... ->x, what the paper and experiment is really about is z_0 -> z_{1,1}, z_{1,2} ... z_{1,N} -> x_{1}, x_{2},...,x_{N}, where z_{1,1...N} are distinct variables. How section 2 is related to the learning of this might be concatenating these N distinct variables into one (if that\'s what you mean). Talking about the joint distribution and inference process in this way might more align with your idea. Also, the paper actually only deals with 2 level. It seems to me that it\'s meaningless to generalize to n levels in section 2, since you do not have any support of it.\n\nIn conclusion, the reviewer thinks that this work is incomplete and does not worth publishing with its current quality.\n==============================================================\nThe reviewer read the response from the authors. However, I do not think the authors resolved the issues I mentioned. And I am still not convinced by the quality of the paper. I would say the idea is not bad, but the paper is still not well-prepared. So I do not change my decision.\n']","[-20, -50, -80]","[50, 20, -20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution, they express concerns about limited novelty and suggest improvements. The reviewer states 'I think this paper presents a direct and somewhat straightforward extension of ALI. Therefore the novelty is limited.' They also suggest ways to strengthen the paper, indicating it's not entirely satisfactory in its current form. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh criticism. They use phrases like 'I think the paper would be stronger if...' and pose questions politely, showing consideration for the authors' work while providing feedback."", ""The sentiment score is -50 because the review expresses significant concerns and criticisms about the paper, stating that 'several parts are missing and not well-explained' and 'many claims in paper are not proved properly'. However, it's not entirely negative as it acknowledges the paper's aim as 'promising'. The politeness score is 20 because the reviewer uses relatively neutral language and frames criticisms as suggestions or questions (e.g., 'It is not clear to me...', 'The authors should provide...'), rather than making blunt negative statements. The reviewer also offers constructive feedback and suggestions for improvement, which contributes to a more polite tone. However, the overall critique is still quite direct, preventing a higher politeness score."", ""The sentiment score is -80 because the reviewer expresses strong negative opinions about the paper's quality, stating it is 'not good', 'messy', 'incomplete', and 'does not worth publishing'. They criticize multiple aspects including the writing, experiments, and results interpretation. The conclusion explicitly recommends against publication. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are several instances of blunt criticism without much softening language. Phrases like 'This section is really bad' and 'the quality of the paper is not good' come across as somewhat rude. However, the reviewer does provide detailed feedback and suggestions for improvement, which prevents the score from being lower.""]"
"['== Preamble ==\n\nAs promised, I have read the updated paper from scratch and this is my revised review. My original review is kept below for reference. My original review had rating ""4: Ok but not good enough - rejection"".\n\n== Updated review ==\n\nThe revised improves upon the original submission in several ways and, in particular, does a much better job at positioning itself within the existing body of literature. The new experiments also indicate that the proposed model offer some improvement over Nickel & Douwe, NIPS 2017).\n\nI do have remaining concerns that unfortunately still prevent me from recommending acceptance:\n\n- Throughout the paper it is argued that we should embed into a hyperbolic space. Such a space is characterized by its metric, but the proposed model do not use a hyperbolic metric. Rather it relies on a heuristic similarity measure that is inspired by the hyperbolic metric. I understand that this may be a practical choice, but then I find it misleading that the paper repeatedly states that points are embedded into a hyperbolic space (which is incorrect). This concern was also raised on this forum prior to the revision.\n\n- The resulting optimization is one of the key selling points of the proposed method as it is unconstrained while Nickel & Douwe resort to a constrained optimization. Clearly unconstrained optimization is to be preferred. However, it is not entirely correct (from what I understand), that the resulting optimization is indeed unconstrained. Nickel & Douwe work under the constraint that |x| < 1, while the proposed model use polar coordinates (r, theta): r in (0, infinity) and theta in (0, 2 pi]. Note that theta parametrize a circle, and therefore wrapping may occur (this should really be mentioned in the paper). The constraints on theta are quite easy to cope with, so I agree with the authors that they have a more simple optimization problem. However, this is only true since points are embedded on the unit disk (2D). Should you want to embed into higher dimensional spaces, then theta need to be confined to live on the unit sphere, i.e. |theta| = 1 (the current setting is just a special-case of the unit sphere). While optimizing over the unit sphere is manageable it is most definitely a constrained optimization problem, and it is far from clear that it is much easier than working under the Nickel & Douwe constraint, |x| < 1.\n\nOther comments:\n- The sentence ""even infinite trees have nearly isometric embeddings in hyperbolic space (Gromov, 2007)"" sounds cool (I mean, we all want to cite Gromov), but what does it really mean? An isometric embedding is merely one that preserves a metric, so this statement only makes sense if the space of infinite trees had a single meaningful metric in the first place (it doesn\'t; that\'s a design choice).\n\n- In the ""Contribution"" and ""Conclusion"" sections it is claimed that the paper ""introduce the new concept of neural embeddings in hyperbolic space"". I thought that was what Nickel & Douwe did... I understand that the authors are frustrated by this parallel work, but at this stage, I don\'t think the present paper can make this ""introducing"" claim.\n\n- The caption in Figure 2 miss some indication that ""a"" and ""b"" refer to subfigures. I recommend ""a"" --> ""a)"" and ""b"" --> ""b)"".\n\n- On page 4 it is mentioned that under the heuristic similarity measure some properties of hyperbolic spaces are lost while other are retained. From what I can read, it is only claimed that key properties are kept; a more formal argument (even if trivial) would have been helpful.\n\n\n== Original Review ==\n\nThe paper considers embeddings of graph-structured data onto the hyperbolic Poincare ball. Focus is on word2vec style models but with hyperbolic embeddings. I am unable to determine how suitable an embedding space the Poincare ball really is, since I am not familiar enough with the type of data studied in the paper. I have a few minor comments/questions to the work, but my main concern is a seeming lack of novelty:\nThe paper argues that the main contribution is that this is the first neural embedding onto a hyperbolic space. From what I can see, the paper\n\n  Poincaré Embeddings for Learning Hierarchical Representations\n  https://arxiv.org/abs/1705.08039\n\nconsider an almost identical model to the one proposed here with an almost identical motivation and application set. Some technicalities appear different, but (to me) it seems like the main claimed novelties of the present paper has already been out for a while. If this analysis is incorrect, then I encourage the authors to provide very explicit arguments for this in the rebuttal phase.\n\nOther comments:\n*) It seems to me that, by construction, most data will be pushed towards the boundary of the Poincare ball during the embedding. Is that a property you want?\n*) I found it rather surprising that the log-likelihood under consideration was pushed to an appendix of the paper, while its various derivatives are part of the main text. Given the not-so-tight page limits of ICLR, I\'d recommend to provide the log-likelihood as part of the main text (it\'s rather difficult to evaluate the correctness of a derivative when its base function is not stated).\n*) In the introduction must energy is used on the importance of large data sets, but it appears that only fairly small-scale experiments are considered. I\'d recommend a better synchronization.\n*) I find visual comparisons difficult on the Poincare ball as I am so trained at assuming Euclidean distances when making visual comparisons (I suspect most readers are as well). I think one needs to be very careful when making visual comparisons under non-trivial metrics.\n*) In the final experiment, a logistic regressor is fitted post hoc to the embedded points. Why not directly optimize a hyperbolic classifier?\n\nPros:\n+ well-written and (fairly) well-motivated.\n\nCons:\n- It appears that novelty is very limited as highly similar work (see above) has been out for a while.\n\n', 'The authors present a method to embed graphs in hyperbolic space, and show that this approach yields stronger attribute predictions on a set of graph datasets. I am concerned by the strong similarity between this work and Poincaré Embeddings for Learning Hierarchical Representations (https://arxiv.org/abs/1705.08039). The latter has been public since May of this year, which leads me to doubt the novelty of this work.\n\nI also find the organization of the paper to be poor.\n- There is a surprisingly high number of digressions.\n- For some reason, Eq 17 is not included in the main paper. I would argue that this equation is one of the most important equations in the paper, given that it is the one you are optimizing.\n- The font size in the main result figure is so small that one cannot hope to parse what the plots are illustrating.\n- I am not sure what insights the readers are supposed to gain from the visual comparisons between the Euclidean and Poincare embeddings. \n\nDue to the poor presentation, I actually have difficulty making sense of the evaluation in this paper (it would help if the text was legible). I think this paper requires significant work and it not suitable for publication in its current state.\n\nAs a kind of unrelated note. It occurs to me that papers on hyperbolic embeddings tend to evaluate evaluate on attribute or link prediction. It would be great if authors would also evaluate these pretrained embeddings on downstream applications such as relation extraction, knowledge base population etc.', 'The authors present a neural embedding technique using a hyperbolic space.\nThe idea of embedding data into a space that is not Euclidean is not new.\nThere have been attempts to project onto (hyper)spheres.\nAlso, the proposal bears some resemblance with what is done in t-SNE, where an (exponential) distortion of distances is induced. Discussing this potential similarity would certainly broaden the readership of the paper.\n\nThe organisation of the paper might be improved, with a clearer red line and fewer digressions.\nThe call to the very small appendix via eq. 17 is an example.\nThe position of Table in the paper is odd as well.\nThe order of examples in Fig.5 differs from the order in the list.\n\nThe experiments are well illustrative but rather small sized.\nThe qualitative assessment is always interesting and it is completed with some label prediction task.\nDue the geometrical consideretations developed in the paper, other quality criteria like e.g. how well neighbourhoods are preserved in the embeddings would give some more insights.\n\nAll in all the idea developed in the paper sounds interesting but the paper organisation seems a bit loose and additional aspects should be investigated. ', 'This paper proposes tree vertex embeddings over hyperbolic space. The conditional predictive distribution is the softmax of <v1, v2>_H = ||v1|| ||v2|| cos(theta1-theta2), and v1, v2 are points  defined via polar coordinates (r1,theta1), and (r2,theta2).\nTo evaluate, the authors show some qualitative embeddings of graph and 2-d projections, as well as F1 scores in identifying the biggest cluster associated with a class. \n\nThe paper is well motivated, with an explanation of the technique as well as its applications in tree embedding in general. I also like the evaluations, and shows a clear benefit of this poincare embedding vs euclidean embedding.\n\nHowever, graph embeddings are now a very well explored space, and this paper does not seem to mention or compare against other hyperbolic (or any noneuclidean) embedding techniques. From a 2 second google search, I found several sources with very similar sounding concepts:\n\nMaximilian Nickel, Douwe Kiela, Poincaré Embeddings for Learning Hierarchical Representations\n\nA Cvetkovski, M Crovella, Hyperbolic Embedding and Routing for Dynamic Graphs\n\nYuval Shavitt, Tomar Tankel, Hyperbolic Embedding of Internet Graph for Distance Estimation and Overlay Construction\n\nThomas Bläsius, Tobias Friedrich, Anton Krohmer, andSören Laue. Efficient Embedding of Scale-Free Graphs in the Hyperbolic Plane\n\nI think this paper does have some novelty in applying it to the skip-gram model and using deep walk, but it should make more clear that using hyperbolic space embeddings for graphs is a popular and by now, intuitive construct. Along the same lines, the benefit of using the skip-gram and deep-walk techniques should be compared against some of the other graph embedding techniques out there, of which none are listed in the experiment section. \n\nOverall, a detailed comparison against 1 or 2 other hyperbolic graph embedding techniques would be sufficient for me to change my vote to accept. \n\n\n']","[-50, -70, -20, -20]","[50, -20, 50, 60]","[""The sentiment score is -50 because while the reviewer acknowledges some improvements in the revised paper, they still have significant concerns that prevent them from recommending acceptance. The reviewer states 'I do have remaining concerns that unfortunately still prevent me from recommending acceptance' which indicates a negative overall sentiment. However, the reviewer does note some positive aspects, preventing the score from being more negative. The politeness score is 50 because the reviewer uses respectful and professional language throughout, acknowledging improvements and providing constructive feedback. They use phrases like 'I understand that...' and 'I encourage the authors to...' which demonstrate politeness. However, the criticism is still direct, preventing a higher politeness score. The reviewer maintains a balanced and objective tone, offering both positive and negative feedback in a professional manner."", ""The sentiment score is -70 because the reviewer expresses significant concerns about the novelty of the work and the poor organization of the paper. They state that the paper is 'not suitable for publication in its current state' and requires 'significant work'. The politeness score is -20 because while the reviewer doesn't use overtly rude language, their criticism is direct and somewhat harsh. They use phrases like 'I am concerned', 'I find the organization of the paper to be poor', and 'I actually have difficulty making sense of the evaluation'. The reviewer does offer some constructive feedback and suggestions, which prevents the politeness score from being lower."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea as 'interesting', they point out several areas for improvement and suggest that the paper organization is 'loose'. They also mention that the experiments are 'rather small sized' and that 'additional aspects should be investigated'. These criticisms outweigh the positive aspects, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral language and offers constructive criticism. They avoid harsh or rude phrasing, instead using phrases like 'might be improved' and 'would give some more insights'. The reviewer also acknowledges positive aspects, such as calling the qualitative assessment 'interesting'. This balanced and professional tone contributes to the politeness of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (well-motivated, clear benefits shown), they ultimately recommend major revisions and comparisons with existing work before acceptance. The overall tone suggests the paper has potential but falls short in its current state. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and provides constructive feedback. They use phrases like 'I like the evaluations' and offer specific suggestions for improvement rather than harsh criticism. The reviewer maintains a professional and courteous tone while still clearly communicating the paper's shortcomings.""]"
"[""The paper presents a model-based imitation learning framework which learns the state transition distribution of the expert. A model-based policy is learned that should matches the expert transition dynamics. The approach can be used for imitation learning when the actions of the expert are not observed, but only the state transitions (which is an important special case).  \n\nPros:\n- The paper concentrates on an interesting special case of imitation learning\n\nCons:\n- The paper is written very confusingly and hard to understand. The algorithm needs to be better motivated and explained and the paper needs proof reading.\n- The algorithm is based on many heuristics that are not well motivated. \n- The algorithm is only optimizing the one step error function for imitation learning but not the long term behavior. It heavily relies on the learned transition dynamics of the expert p(s_t+1|s_t). This transition model will be wrong if we go away from the expert's trajectories. Hence, I do not see why we should use p(s_t+1|s_t) to define the reward function. It does not prevent the single step \nerrors of the policy to accumulate (which is the main goal of inverse reinforcement learning)\n- The results are not convincing\n- Other algorithms (such as GAIL) could be used in the same setup (no action observations). Comparisons to other imitation learning approaches are needed.\n\nIn summary, this is a poorly written paper that seems to rely on a lot of heuristics that are not well motivated. Also the results are not convincing. Clear reject.\n\n\nMore detailed comments\n- It is unclear why a model-based and model-free policy need to be used. Is the model-based policy used at any time in the algorithm? If it is just used as final result, why train it iteratively? Why can we not just also use the model-based policy for data collection?\n- It is unclear why the heuristic reward function makes sense. First of all, the defined reward is stochastic as \\hat{s}_t+1 is a sample from the next state from the expert's transition model. Why do not we use the mean of the transition model here, then it would not be stochastic any more. Second, a much simpler reward could be used that essentially does the same thing. Instead of requiring a learned dynamics model f_E for predicting the next state, we can just use the experienced next state s_t+1. Note that the reward function for time step t can depend on s_t+1 in an MDP.  \n- The objective that is optimized (Eq. 4) is not well defined. A function is not an objective function if we can only optimize part of it for theta while keeping theta fixed for the other part. It is unclear which objective the real algorithm optimizes\n- There are quite a few confusions in terms of notation. Sometimes, a stochastic transition model p(s_t+1|s_t, a_t) is used and sometimes a deterministic model f_E(s,a). It is unclear how they relate. \n- Many other imitation learning techniques could be used in this setup including max-entropy inverse RL [1], IRL by distribution matching [2] and the approach given in [3] and GAIL. A comparison to at least a subset of these methods is needed\n\n[1] B. Ziebart et al, Maximum Entropy Inverse Reinforcement Learning, AAAI 2008\n[2] Arenz, O.; Abdulsamad, H.; Neumann, G. (2016). Optimal Control and Inverse Optimal Control by Distribution Matching, Proceedings of the International Conference on Intelligent Robots and Systems (IROS)\n[3] P Englert, A Paraschos, J Peters, MP Deisenroth, Model-based Imitation Learning by Probabilistic Trajectory Matching, IEEE International Conference on Robotics and Automation"", 'The problem addressed here is imitation learning when no action information is available, which is an important problem in robotics for instance. The main idea of the proposed method is to produce a policy that matches the states observed in the expert trajectories, and this is achieved via a somewhat complex mix of model-free and model-based learning.\n\nMy main issues with the paper are:\n- It does not cite or discuss a very important piece of related work: ""Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation"" (Liu et al., 2017)\n- The empirical results are unconvincing - it seems like in all problems they use there is a straightforward mapping from state feature differences to actions, as pointed out in an anonymous comment.\n\nAdditionally, it would have been nice to show empirically how helpful the model-based component of their approach is.\n', 'Model-Based Imitation Learning from State Trajectories\n\nSIGNIFICANCE AND ORIGINALITY:\n\nThe authors propose a model-based method for accelerating the learning of a policy\nby observing only the state transitions of an expert trace.\nThis is an important problem in many fields such as robotics where\nfinding a feasible policy is hard using pure RL methods.\n\nThe authors propose a unique two step method to find a high-quality model-based policy.\n\nFirst: To create the environment model for the model-based learner, \n they need a source of state transitions with actions ( St, At,xa St+1 ).\nTo generate these samples, they first employ a model-free algorithm.\nThe model-free algorithm is trained to try to duplicate the expert state at each trajectory.\nIn continuous domains, the state is not unique … so they build a soft next state predictor\nthat gives a probability over next states favoring those demonstrated by the expert.\nSince the transitions were generated by the agent acting in the environment,\nthese transitions have both states and actions ( St, At, St+1 ).\nThese are added to a pool.\n\nThe authors argue that the policy found by this model-free learner is\nnot highly accurate or guaranteed to converge, but presumably is good at\ngenerating transitions relevant to the expert’s policy.\n(Perhaps slowly reducing the \\sigma in the reward would improve accuracy?)\nI guess if expert trace data is sparse, the model-free learner can generate a lot \nof transitions which enable it to create accurate dynamics models which in turn\nallow it to extract more information out of sparse expert traces?\n\nSecond: They then train a model based agent using the collected transitions ( St, At, St+1 ).\nThey formulate the problem as a maximum likelihood problem with two terms: \nan action dynamics model which is learned from local exploration using the learner’s own actions and outcomes\nand expert policy model in terms of the actions learned above \nthat maximizes the probability of the observed expert’s trajectory.\nThis is a nice clean formulation that integrates the two processes.\nI thought the comparison to an encoder - decoder network was interesting.\n\nThe authors do a good job of positioning the work in the context of recent work in IML.\n\nIt looks like the authors extract position information from flappy bird frames, \nso the algorithm is only using images for obstacle reasoning?\n\n\nQUALITY\n\nThe propose model is described fairly completely and evaluated on \na “reaching"" problem and the ""flappy bird” game domain.\nThe evaluation framework is described in enough detail to replicate the results.\n\nInterestingly, the assisted method starts off much higher in the “reacher” task.\nPresumably this task is easy to observe the correct actions.\n\nThe flappy bird test shows off the difference between unassisted learning (DQN),\nmodel free learning with the heuristic reward (DQN+reward prediction) \nand model based learning. \n\nInterestingly, DQN + heuristic reward approaches expert performance\nwhile behavioral cloning never achieves expert performance level even though it has actions.\n\nWhy does the model-based method only run to 600 steps and stopped before convergence??\nDoes it not converge to expert level?? If so, this would be useful to know.\n\nThere are minor grammatical mistakes that can be corrected.\n\nAfter equation 5, the authors suggest categorical loss for discrete problems, \nbut cross-entropy loss might work better. Maybe this is what they meant.\n\n\nCLARITY\n\nThe overall approach and algorithms are described fairly clearly. Some minor typos here and there.\n\nAlgorithm 1 does not make clear the relationship between the model learned in step 2 and the algorithms in steps 4 to 6.\n\nI would reverse the order of a few things to align with a right to left ordering principle. \nIn Figure 1, put the model free transition generator on the left and the model-based sample consumer on the right.\nIn Figure 3, put the “reacher” test on the left and the “flappy bird” on the right.\n\n\nPROS AND CONS\n\nInteresting idea for learning quickly from small numbers of samples of expert state trajectories. \n\nNot clear that method converges on all problems. \n\nNot clear that the method is able to extract the state from video — authors had to extract position manually\n(this point is more about their deep architecture than the imitation framework they describe -\nthough perhaps a key argument for the authors is the ability to work with small numbers of \nexpert samples and still be able to train deep methods ) ??\n\n\nPOST REVIEW SUBMISSION:\n\nThe authors make a number of clarifying comments to improve the text and add the reference suggested by another reviewer. ']","[-80, -50, 70]","[-20, 20, 80]","[""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer lists many cons and very few pros, concluding with 'Clear reject.' The language used is strongly critical, with phrases like 'poorly written paper' and 'not convincing.' The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite harsh and direct. The reviewer doesn't soften their criticisms or offer many constructive suggestions. Phrases like 'The paper is written very confusingly' and 'Clear reject' are particularly blunt. However, the reviewer does maintain some level of professional language, preventing the score from being even lower."", ""The sentiment score is -50 because the reviewer expresses several significant concerns about the paper, including missing important related work and unconvincing empirical results. However, it's not entirely negative as they acknowledge the importance of the problem and suggest additional experiments. The politeness score is 20 because the language is professional and constructive, using phrases like 'it would have been nice' rather than harsh criticism. The reviewer presents their concerns objectively without using inflammatory language, but also doesn't go out of their way to be overly polite or complimentary."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its significance, originality, and quality. They describe the proposed method as 'unique' and 'important', and praise the authors for positioning their work well in the context of recent research. The reviewer also offers constructive criticism and suggestions for improvement, which indicates a balanced but overall positive sentiment. The politeness score is 80 (polite) because the reviewer uses respectful and professional language throughout. They acknowledge the authors' efforts and contributions, use phrases like 'The authors do a good job' and 'Interesting idea', and frame their criticisms as suggestions or questions rather than direct attacks. The reviewer also offers specific, constructive feedback to improve the paper, which is a polite way to address shortcomings.""]"
"['Summary\n\nThis paper presents differentiable Neural Computational Machines (∂NCM), an abstraction of existing neural abstract machines such as Neural Turing Machines (NTMs) and Neural Random Access Machines (NRAMs). Using this abstraction, the paper proposes loss terms for incorporating supervision on execution traces. Adding supervision on execution traces in ∂NCM improves performance over NTM and NRAM which are trained end-to-end from input/output examples only. The observation that adding additional forms of supervision through execution traces improves generalization may be unsurprising, but from what I understand the main contribution of this paper lies in the abstraction of existing neural abstract machines to ∂NCM. However, this abstraction does not seem to be particularly useful for defining additional losses based on trace information. Despite the generic subtrace loss (Eq 8), there is no shared interface between ∂NCM versions of NTM and NRAM that would allow one to reuse the same subtrace loss in both cases. The different subtrace losses used for NTM and NRAM (Eq 9-11) require detailed knowledge of the underlying components of NTM and NRAM (write vector, tape, register etc.), which questions the value of ∂NCM as an abstraction.\n\nWeaknesses\n\nAs explained in the summary, it is not clear to me why the abstraction to NCM is useful if one still needs to define specific subtrace losses for different neural abstract machines.\nThe approach seems to be very susceptible to the weight of the subtrace loss λ, at least when training NTMs. In my understanding each of the trace supervision information (hints, e.g. the ones listed in Appendix F) provides a sensible inductive bias we would the NTM to incorporate. Are there instances where these biases are noisy, and if not, could we incorporate all of them at the same time despite the susceptibility w.r.t λ?\nNTMs and other recent neural abstract machines are often tested on rather toyish algorithmic tasks. I have the impression providing extra supervision in form of execution traces makes these tasks even more toyish. For instance, when providing input-output examples as well as the auxiliary loss in Eq6, what exactly is left to learn? What I like about Neural-Programmer Interpreters and Neural Programmer [1] is that they are tested on less toyish tasks (a computer vision and a question answering task respectively), and I believe the presented method would be more convincing for a more realistic downstream task where hints are noisy (as mentioned on page 5).\n\nMinor Comments\n\np1: Why is Grefenstette et al. (2015) an extension of NTMs or NRAMs? While they took inspiration from NTMs, their Neural Stack has not much resemblance with this architecture.\np2: What is B exactly? It would be good to give a concrete example at this point. I have the feeling it might even be better to explain NCMs in terms of the communication between κ, π and M first, so starting with what I, O, C, B, Q are before explaining what κ and π are (this is done well for NTM as ∂NCM in the table on page 4). In addition, I think it might be better to explain the Controller before the Processor. Furthermore, Figure 2a should be referenced in the text here.\np4 Eq3: There are two things confusing in these equations. First, w is used as the write vector here, whereas on page 3 this is a weight of the neural network. Secondly, π and κ are defined on page 2 as having an element from W as first argument, which are suddenly omitted on page 4.\np4: The table for NRAM as ∂NCM needs a bit more explanation. Where does {1}=I come from? This is not obvious from Appendix B either.\np3 Fig2/p4 Eq4: Related to the concern regarding the usefulness of the ∂NCM abstraction: While I see how NTMs fit into the NCM abstraction, this is not obvious at all for NRAMs, particularly since in Fig 2c modules are introduced that do not follow the color scheme of κ and π in Fig 2a (ct, at, bt and the registers).\np5: There is related work for incorporating trace supervision into a neural abstract machine that is otherwise trained end-to-end from input-output examples [2].\np5: ""loss on example of difficulties"" -> ""loss on examples of the same difficulty""\np5: Do you have an example for a task and hints from a noisy source?\nCitation style: sometimes citation should be in brackets, for example ""(Graves et al. 2016)"" instead of ""Graves et al. (2016)"" in the first paragraph of the introduction.\n\n[1] Neelakantan et al. Neural programmer: Inducing latent programs with gradient descent. ICLR. 2015. \n[2] Bosnjak et al. Programming with a Differentiable Forth Interpreter. ICML. 2017.', 'The authors introduce the general concept of a differential neural computational machine, dNCM. It can apply to any fully differentiable neural programming machine, such as the Neural Turing Machine (NTM) or NRAM or the Neural GPU, but not to non-fully-differentiable architecture such as NPI. The author show how partial traces can be used to improve training of any dNCM with results on instantiations of dNCM for NTM and NRAM.\n\nOn the positive side, the paper is well-written (though too many results require looking into the Appendix) and dNCM is elegant. Also, while it\'s hard to call the idea of using partial traces original, it\'s not been studied in this extent and setting before. On the negative side, the authors have chosen weak baselines and too few and easy tasks to be sure if their results will actually hold in general. For example, for NTM the authors consider only 5 tasks, such as Copy, RepeatCopyTwice, Flip3rd and so on (Appendix E) and define  ""a model to generalize if relative to the training size limit n, it achieves perfect accuracy on all of tests of size ≤ 1.5n and perfect accuracy on 90% of the tests of size ≤ 2n"". While the use of subtraces here shows improvements, it is not convincing since other architectures, e.g., the Improved Neural GPU (https://arxiv.org/abs/1702.08727), would achieve 100% on this score without any need for subtraces or hints. The tasks for the NRAM are more demanding, but the results are also more mixed. For one, it is worrysome that the baseline has >90% error on each task (Appendix J, Figure 12) and that Merge even with full traces has still almost 80% errors. Neural programmers are notoriously hard to tune, so it is hard to be sure if this difference could be eliminated with more tuning effort. In conclusion, while we find this paper valuable, to be good enough for acceptance it should be improved with more experimentation, adding baselines like the (Improved) Neural GPU and more tasks and runs.', ""Much of the work on neural computation has focused on learning from input/output samples.  This paper is a study of the effect of adding additional supervision to this process through the use of loss terms which encourage the interpretable parts of the architecture to follow certain expected patterns.\n\nThe paper focuses on two topics:\n1.  Developing a general formalism for neural computers which includes both the Neural Turing Machine (NTM) and the Neural Random Access Machine (NRAM), as well as a model for providing partial supervision to this general architecture.\n\n2.  An experimental study of providing various types of additional supervision to both the NTM and the NRAM architecture.\n\nI found quite compelling the idea of exploring the use of additional supervision in neural architectures since oftentimes a user will know more about the problem at hand than just input-output examples.  However, the paper is focused on very low-level forms of additional supervision, which requires the user to deeply understand the neural architecture as well as the way in which a given algorithm might be implemented on this architecture.  So practically speaking I don't think it's reasonable to assume that users would actually provide additional supervision in this form.\n\nThis would have been fine, if the experimental results provided some insights into how to extend and/or improve existing architectures.  Unfortunately,  the results were simply a very straight-forward presentation of a lot of numbers, and so I was unable to draw any useful insights.  I would have liked the paper to have been more clear about the insights provided by each of the tables/graphs.  In general we can see that providing additional supervision improves the results, but this is not so surprising.\n\nFinally, much of the body of the paper is focused on topic (1) from above, but I did not feel as though this part of the paper was well motivated, and it was not made clear what insights arose from this generalization.  I would have liked the paper to make clear up front the insights created by the generalization, along with an intuitive explanation.  Instead much of the paper is dedicated to introduction of extensive notation, with little clear benefit.  The notation did help make clear the later discussion of the experiments, but it was not clear to me that it was required in order to explain the experimental results.\n\nSo in summary I think the general premise of the paper is interesting, but in it's current state I feel like the paper does not have enough sufficiently clear insights for acceptance.\n""]","[-20, -20, -30]","[60, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper, they express significant concerns about the usefulness of the proposed abstraction and the applicability of the method to real-world tasks. The review begins with a neutral summary but then lists several weaknesses and questions the main contribution's value. The politeness score is moderately positive (60) because the reviewer uses professional and respectful language throughout. They phrase criticisms as questions or observations rather than direct attacks, and use phrases like 'from what I understand' and 'I have the impression' to soften their critiques. The reviewer also offers constructive suggestions and acknowledges positive aspects of the work, which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well-written', 'elegant'), they express significant concerns about the paper's methodology and results. The reviewer points out weak baselines, too few and easy tasks, and unconvincing results compared to other architectures. They conclude that the paper needs improvement to be acceptable.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They balance criticism with positive remarks and use phrases like 'On the positive side' and 'On the negative side' to structure their feedback. The reviewer also uses polite language when suggesting improvements, such as 'to be good enough for acceptance it should be improved with...'\n\nOverall, while the sentiment is slightly negative due to the critical content, the reviewer expresses their concerns in a polite and constructive manner."", ""The sentiment score is -30 because while the reviewer finds the general premise interesting, they express several criticisms and ultimately conclude that the paper doesn't have enough clear insights for acceptance. This indicates a slightly negative overall sentiment. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positive aspects ('I found quite compelling...') and framing criticisms constructively ('I would have liked...'). They maintain a professional tone without using harsh or rude language, even when expressing disagreement or disappointment with aspects of the paper.""]"
"['In this manuscript, the authors propose an interesting deep reinforcement learning approach via CNNs to learn the rationales associated to target chemical properties. The paper has merit, but in its current form does not match the acceptance criteria for ICLR.\n\nIn particular, the main issue lies in the poor performance reached by the systems, both overall and in comparison with baseline methods, which at the moment hardly justifies the effort required in setting up the DL framework. Moreover, the fact that test performances are sometimes (much) better than training results are quite suspicious in methodological terms.\nFinally, the experimental part is quite limited (two small datasets), making it hard to evaluate the scalability (in all sense) of the proposed solution to much larger data. ', ""This paper presents an interesting approach to identify substructural features of molecular graphs contributing to the target task (e.g. predicting toxicity). The algorithm first builds two conv nets for molecular graphs, one is for searching relevant substructures (policy improvement), and another for evaluating the contribution of selected substructures to the target task (policy evaluation). These two phases are iterated in a reinforcement learning manner as policy iterations. Both parts are based on conv nets for molecular graphs, and this framework is a kind of 'self-supervised' scheme compared to the standard situations that the environment provides rewards. The experimental validations demonstrate that this model can learn a competitive-performed conv nets only dependent on the highlighted substructures, as well as reporting some case study on the inhibition assay for hERG proteins.\n\nTechnically speaking, the proposed self-supervised scheme with two conv nets is very interesting. This demonstrates how we can perform progressive substructure selections over molecular graphs to highlight relevant substructures as well as maximizing the prediction performance. Given that conv nets for molecular graphs are not trivially interpretable, this would provides a useful approach to use conv nets for more explicit interpretations of how the task can be performed by neural nets. \n\nHowever, at the same time, I had one big question about the purpose and usage of this approach. As the paper states in Introduction, the target problem is 'hard selection' of substructures, rather than 'soft selection' that neural nets (with attention, for example) or neural-net fingerprints usually provide. Then, the problem would become a combinatorial search problem, which has been long studied in the data mining and machine learning community. There would exist many exact methods such as LEAP, CORK, and graphSig under the name of 'contrast/emerging/discriminative' pattern mining exactly developed for this task. Also, it is widely known that we can even perform a wrapper approach for supervised learning from graphs simultaneously with searching all relevant subgraphs as seen in Kudo+ NIPS 2004, Tsuda ICML 2007, Saigo+ Machine Learning 2009, etc. It would be unconvincing that the proposed neural nets approach fits to this hard combinatorial task rather than these existing (mostly exact) methods.\n\nIn addition to the above point, several technical points below would also be unclear.\n\n- A simple heuristic by adding 'selected or not' variables to the atom features works as intended? Because this is fed to the conv net, it seems we can ignore this elements of features by tweaking the weight parameters accordingly. If the conv net performs the best when we use the entire structure, then learning might be forced to ignore the selection. Can we guarantee in some sense this would not happen? \n\n- Zeroing out the atom features also sounds quite simple and a bit groundless. Confusingly, the P network also has an attention mechanism, and it is a bit unclear to me what was actually worked.\n\n- In the experiments, the baseline is based on LR, but this would not be fair because usually we cannot expect any linear relationship for molecular fingerprints. It's highly correlated due to the inclusion relationships between subgraphs. At least, any nonlinear baseline (e.g. Random forest or something?) should be presented for discussing the results.\n\nPros:\n- interesting self-supervised framework provided for highlighting relevant substructures for a given prediction task\n- the hard selection setting is encoded in input graph featurization\n\nCons:\n- it would be a bit unconvincing that identifying 'hard selection' is better suited for neural nets, rather than many existing exact methods (without using neural networks). At least one of the typical ones should be compared or discussed.\n- I'm still not quite sure whether or not some heuristic parts work as intended. "", ""\nThe paper proposes a feature learning technique for molecular prediction using reinforcement learning. The predictive model is an interesting two-step approach where important atoms of the molecule are added one-by-one with a reward given by a second Q-network that learns how well we can solve the prediction problem with the given set of atoms. The overall scheme is intuitive, but \n\nThe model is experimented on two small datasets of few thousand of molecules, and compared to a state-of-the-art DeepTox, and also to some basic baselines (RF/SVM/logreg). In the Tox21 dataset the proposed sparse RL-CNN method is less accurate than DeepTox or full CNN. In the hERG dataset RL-CNN is again weaker than the full CNN, but also seems to be beaten by several baseline methods. Overall the results are surprisingly weak, since e.g. with LASSO one often improves by using less features in complex problems. Both datasets should be compared to LASSO as well. \n\nIt's somewhat odd that the test performance in table 2 is often better than CV performance. This feels suspicious, especially with 79.0 vs 84.3. The table 2 does not seem reliable result, and should use more folds and more randomizations, etc.\n\nThe key problem of the method is its seeming inabability to find the correct number of atoms to use. In both datasets the number of atoms were globally fixed, which is counter-intuitive. The authors should at least provide learning curves where different number of atoms are used; but ideally the method should learn the number of atoms to use for each molecule.\n\nThe proposed Q+P network is interesting, but its unclear how well it works in general. There should be experiments that compare the the Q+P model with incresing number of atoms against a full CNN, to see whether the Q+P can converge to maximal performance.\n\nOverall the method is interesting and has a clear impact for molecular prediction, however the paper has limited appeal to the broader audience. Its difficult to assess how useful the Q/P-network is in general. The inability to choose the optimal number of atoms is a major drawback of the method, and the experimental section could be improved. This paper also would probably be more suitable for a chemoinformatics journal, where the rationale learning would be highly appreciated.\n""]","[-50, -20, -30]","[20, 60, 20]","[""The sentiment score is -50 because while the reviewer acknowledges the paper has 'merit' and the approach is 'interesting', they express significant concerns about the performance, methodology, and limited experimental scope. The overall tone is critical, suggesting the paper doesn't meet acceptance criteria. The politeness score is 20 because the reviewer uses polite language like 'interesting' and 'has merit', and frames criticisms professionally without harsh language. However, the critique is direct and doesn't use overly deferential language, keeping the score only moderately positive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting approach and potential usefulness, they express significant concerns about the purpose and usage of the approach, as well as several technical points. The reviewer questions whether the proposed method is better suited than existing exact methods and expresses doubts about some of the technical aspects. However, the review is not entirely negative, as it does highlight some positive aspects of the paper.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'interesting approach' and 'would provide a useful approach' when discussing positive aspects. Even when expressing concerns, the language remains polite and constructive, using phrases like 'I had one big question' and 'it would be unconvincing' rather than using harsh or dismissive language. The reviewer also provides a balanced view by listing both pros and cons at the end of the review."", ""The sentiment score is -30 because while the reviewer acknowledges the method as 'interesting' and having 'clear impact', they express several significant concerns about the paper's results, methodology, and overall appeal. The reviewer points out that the proposed method performs worse than existing approaches, questions the reliability of some results, and highlights major drawbacks like the inability to choose the optimal number of atoms. The overall tone suggests the paper needs substantial improvements.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'It's somewhat odd' and 'The key problem' rather than harsh or dismissive language. The reviewer also acknowledges positive aspects of the work, such as calling the approach 'interesting' and 'intuitive'. However, the score is not higher because the review is primarily focused on criticisms and doesn't go out of its way to be exceptionally polite or encouraging.""]"
"['This paper addresses the problem of sample selection bias in MMD-GANs. Instead of having access to an i.i.d. sample from the  distribution of interest, it is assumed that the dataset is subject to sample selection bias or the data has been gathered via a biased sample selection mechanism. Specifically, the observed data are drawn from the modified distribution T(x)P(x) where P(x) is the true distribution we aim to estimate and T(x) is an appropriately scaled ""thinning function"". Then, the authors proposed an estimate of the MMD between two distributions using weighted maximum mean discrepancy (MMD). The idea is in fact similar to an inverse probability weighting (IPW). They considered both when T(x) is known and when T(x) is unknown and must be estimated from the data. The proposed method was evaluated using both synthetic and real MNIST dataset. \n\nIn brief, sample selection bias is generally a challenging problem in science, statistics, and machine learning, so the topic of this paper is interesting. Nevertheless, the motivation for investigating this problem specifically in MMD-GANs is not clear. What motivated you to study this problem specifically for GAN in the first place? How does solving this problem help us understand or solve the sample selection bias in general? Will it shed light on how to improve the stability of GAN? Also, the experiment results are too weak to make any justified conclusion.\n\nSome comments and questions:\n\n- How is sample selection bias related to the stability issue of training GAN? Does it worsen the stability?\n- Have estimators in Eq. (2) and Eq. (3) been studied before? Are there any theoretical guarantees that this estimate will convergence to the true MMD? \n- On page 5, why T(men) = 1 and T(women) equals to the sample ratio of men to women in labeled subset?\n- Can we use clustering to estimate the thinning function?', ""This paper presents a modification of the objective used to train generative networks with an MMD adversary (i.e. as in Dziugaite et al or Li et al 2015), where importance weighting is used to evaluate the MMD against a target distribution which differs from the data distribution. The goal is that this could be used to correct for known bias in the training data — the example considered here is for class imbalance for known, fixed classes.\n\nUsing importance sampling to estimate the MMD is straightforward only if the relationship between the data-generating distribution and the desired target distribution is somehow known and computable. Unfortunately the treatment of how this can be learned in general in section 4 is rather thin, and the only actual example here is on class imbalance. It would be good to see a comparison with other approaches for handling class imbalance. A straightforward one would be to use a stratified sampling scheme in selecting minibatches — i.e. rather than drawing minibatches uniformly from labeled data, select each minibatch by sampling an equal number of representatives from each class from the data. (Fundamentally, this requires explicit labels for whatever sort of bias we wish to correct for, for every entry in the dataset.) I don't think the demonstration of how to compute the MMD with an importance sampling estimate is a sufficient contribution on its own.\n\nAlso, I am afraid I do not understand the description of subfigures a through c in figure 1. The target distribution p(x) is given in 1(a), a thinning function in 1(b), and an observed distribution in 1(c). As described, the observed data distribution in 1(c) should be found by multiplying the density in 1(a) by the function in 1(b) and then normalizing. However, the function \\tilde T(x) in 1(b) takes values near zero when x < 0, meaning the product \\tilde T(x)p(x) should also be near zero. But in figure 1(c), the mode of p(x) near x=0 actually has higher probability than the mode near x=2, despite the fact that there \\tilde T(x) \\approx 0.5. I think this might simply be a mistake in the definition of \\tilde T(x), and that rather it should be 1.0 - \\tilde T(x), but in any case this is quite confusing.\n\nI also am confused by the results in figure 2. I would have thought that the right column, where the thinning function is used to correct for the class imbalance, would then have approximately equal numbers of zeros and ones in the generative samples. But, there are still more zeros by a factor of around 2.\n\nMinor note: please double-check references, there seem to be some issues; for example, Sutherland et al is cited twice, once as appearing at ICML 2016 and once as appearing at ICML 2017.\n\n"", 'This paper proposes an importance-weighted estimator of the MMD, in order to estimate the MMD between distributions based on samples biased according to a known scheme. It then discusses how to estimate the scheme when it is unknown, and further proposes using it in either the MMD-based generative models of Y. Li et al. (2015) / Dziugaite et al. (2015), or in the MMD GAN of C.-L. Li et al. (2017).\n\nThe estimator itself is natural (and relatively obvious), though it has some drawbacks that aren\'t fully discussed (below).\n\nThe application to GAN-type learning is reasonable, and topical. The first, univariate, experiment shows that the scheme is at least plausible. But the second experiment, involving a simple T ratio based on whether an MNIST digit is a 0 or a 1, doesn\'t even really work! (The best model only gets the underrepresented class from 20% up to less than 40%, rather than the desired 50%, and the ""more realistic"" setting only to 33%.)\n\nIt would be helpful to debug whether this is due to the classifier being incorrect, estimator inaccuracies, or what. In particular, I would try using T based on a pretrained convnet independent of the autoencoder representation in the MMD GAN, to help diagnose where the failure mode comes from.\n\nWithout at least a working should-be-easy example like this, and with the rest of the paper\'s technical contribution so small, I just don\'t think this paper is ready for ICLR.\n\nIt\'s also worth noting that the equivalent algorithm for either vanilla GANs or Wasserstein GANs would be equally obvious.\n\nEstimator:\n\nIn the discussion about (2): where does the 1/m bias come from? This doesn\'t seem to be in Robert and Casella section 3.3.2, which is the part of the book that I assume you\'re referring to (incidentally, you should specify that rather than just citing a 600-page textbook).\n\nMoreover, it is worth noting that Robert and Cassela emphasize that if E[1 / \\tilde T] is infinite, the importance sampling estimator can be quite bad (for example, the estimator may have infinite variance). This happens when \\tilde T puts mass in a neighborhood around 0, i.e. when the thinned distribution doesn\'t have support at any place that P does. In the biased-observations case, this is in some sense unsurprising: if we don\'t see *any* data in a particular class of inputs, then our estimates can be quite bad (since we know nothing about a group of inputs that might strongly affect the results). In the modulating case, the equivalent situation is when F(x) lacks a mean, which seems less likely. Thus although this is probably not a huge problem for your case, it\'s worth at least mentioning. (See also the following relevant blog posts:  https://radfordneal.wordpress.com/2008/08/17/the-harmonic-mean-of-the-likelihood-worst-monte-carlo-method-ever/ and https://xianblog.wordpress.com/2012/03/12/is-vs-self-normalised-is/ .)\n\nThe paper might be improved by stating (and proving) a theorem with expressions for the rate of convergence of the estimator, and how they depend on T.\n\n\nMinor:\n\nAnother piece of somewhat-related work is Xiong and Schneider, Learning from Point Sets with Observational Bias, UAI 2014.\n\nSutherland et al. 2016 and 2017, often referenced in the same block of citations, are the same paper.\n\nOn page 3, above (1): ""Since we have projected the distributons into an infinite-dimensional space, the distance between the two distributions is zero if and only if all their moments are the same."" An infinite-dimensional space isn\'t enough; the kernel must further be characteristic, as you mention. See e.g. Sriperumbuder et al. (AISTATS 2010) for more details.\n\nFigure 1(b) seems to be plotting only the first term of \\tilde T, without the + 0.5.']","[-20, -20, -60]","[60, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting topic, they express concerns about the motivation, clarity, and experimental results. The reviewer states that 'the experiment results are too weak to make any justified conclusion,' which is a significant criticism. However, they also note positive aspects like the challenging nature of the problem, which prevents the score from being more negative. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, poses questions rather than making harsh statements, and offers constructive feedback. The use of phrases like 'In brief' and 'Some comments and questions' contributes to a polite tone. The reviewer also acknowledges the interesting aspects of the work before presenting criticisms, which is a polite approach to peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution, they express several concerns and confusions about the methodology and results. The reviewer points out thin treatment of certain aspects, lack of comparison with other approaches, and confusion about figures and results. These criticisms outweigh the initial positive acknowledgment of the paper's concept. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, phrases criticisms as suggestions or personal confusions (e.g., 'I am afraid I do not understand', 'I think this might simply be a mistake'), and offers constructive feedback. The reviewer also uses polite phrases like 'It would be good to see' and 'please double-check'. The tone is professional and constructive, even when pointing out potential issues."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's readiness for publication, stating 'I just don't think this paper is ready for ICLR.' They point out that the main experiment 'doesn't even really work' and that the paper's technical contribution is 'so small.' However, it's not entirely negative as they acknowledge some positive aspects like the estimator being 'natural' and the application being 'reasonable and topical.' The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They offer constructive suggestions for improvement and use phrases like 'It would be helpful to...' and 'The paper might be improved by...' which are polite ways of offering criticism. The reviewer also provides detailed feedback and references, showing respect for the authors' work despite the overall negative assessment.""]"
"[""The authors propose to speed up RL techniques, such as DQN, by utilizing expert demonstrations. The  expert demonstrations are sequences of consecutive states that do not include actions, which is closer to a real setting of imitation learning. The goal of this process is to extract a function that maps any given state to a subgoal. Subgoals are then used to learn different Q-value functions, one per subgoal. \nTo learn the function that maps states into subgoals, the authors propose a surrogate reward model that corresponds to the angle between: the difference between two consecutive states (which captures velocity or direction) and a given subgoal. A von Mises- Fisher distribution policy is then assumed to be used by the expert to generate actions that guide the agent toward the subgoal. Finally, the mapping function state->subgoal is learned by performing a gradient descent on the expected total cost (based on the surrogate reward function, which also has free parameters that need to be learned).\nFinally, the authors use the DQN platform to learn a Q-value function using the learned  surrogate reward function that guides the agent to specific subgoals, depending on the situation.\nThe paper is overall well-written, and the proposed idea seems interesting. However, there are rather little explanations provided to argue for the different modeling choices made, and the intuition behind them. From my understanding, the idea of subgoal learning boils down to a non-parametric (or kernel) regression where each state is mapped to a subgoal based on its closeness to different states in the expert's demonstration. It is not clear how this method would generalize to new situations. There is also the issue of keeping tracking of a large number of demonstration states in memory. This technique reminds me of some common methods in learning from demonstrations, such as those using GPs or GMMs, but the novelty of this technique is the fact that the subgoal mapping function is learned in an IRL fashion, by tacking into account the sum of surrogate rewards in the expert's demonstration. \nThe architecture of the action value estimator does not seem novel, it's basically just an extension of DQN with an extra parameter (subgoal g).\nThe empirical evaluation seems rather mixed. Figure 3 shows that the proposed method learns faster than DQN, but Table I shows that the improvement is not statistically significant, except in two games, DefendCenter and PredictPosition. Are these the results after all agents had converged? \nOverall, this is a good paper, but focusing on only a single game (Doom) is a weakness that needs to be addressed because one cannot tell if the choices were tailored to make the method work well for this game. Since the paper does not provide significant theoretical or algorithmic contribution, at least more realistic and diverse experiments should be performed. "", ""The paper presents a method that leverages demonstrations from experts provided in the shape of sequences of states (actually, state transitions are enough, they don't need to come in sequences) to faster learn reinforcement learning tasks. The authors propose to learn subgoals (actually local rewards) to encourage the agent to go towards the same direction as the expert when encountering similar states. The main claimed advantage is that it doesn't require the knowledge of the actions taken by the expert, only observations of states. \n\nTo me, there is a major flaw in the approach. Ho and Ermon 2016 extensively study the fact that imitation is not possible in stochastic environment without the knowledge of the actions. As the author say, learning the actions from state transitions in a standard stochastic MDP would require to learn the model. Yet, the authors demonstrate their approach in environments where the controlable dynamics is mainly deterministic (if one decides to turn right, the agents indeed turns right). So by subtracting features from successive states, the method mainly encodes the action as it almost encodes the one step dynamics in one shot. \n\nAlso the main assumption is that there is an easy way to compute similarity between states. This assumption is not met in the HealthGathering environment as several different states may generate very similar vision features. This causes the method not to work. This brings us back to the fact that features encoding the actual dynamics, potentially on many consecutive states (e.g. feature expectations used in IRL or occupancy probability used in Ho and Ermon 2016), are mandatory. \n\nThe method is also very close to the simplest IRL method possible which consists in placing positive rewards on every state the expert visited. So I would have liked a comparison to that simple method (using similar regression technique to generalize over states with similar features). \n\nFinally, I also think that using expert data generated by a pre-trained network makes the experimental section very weak. Indeed, it is unlikely that this kind of data can be obtained and training on this type of data is just a kind of distillation of the optimal network making the weights of the network close to the right optimum. With real data, acquired from humans, the training is likely to end up in a very different minima. \n\nConcerning the related work, the authors didn't mention the Universal Value Function Approximation (Schaul et al, @ICML 2015) which precisely extends V and Q functions to generalize over goals. This very much relates to the method used to generalize over subgoals in the paper. Also, the state if the art in IRL and learning from demonstration is lacking a lot of references. For instance, learning via RL + demonstrations was already studied into papers by Farahmand et al (APID, @NIPS 2013), Piot et al (RLED, @ ECML 2014) or Chemali & Lazaric (DPID, @IJCAI 2015) before Hester et al (DQfD @AAAI 2018). Some work is cited in the wrong context. For instance, Borsa et al 2017 doesn't do inverse RL (as said in the related work section) but learn to perform a task only from the extrinsic reward provided by the environment (as said in the introduction). BTW, I would suggest to refer to published papers if they exist instead of their Arxiv version (e.g. Hester et al, DQfD). "", 'SIGNIFICANCE AND ORIGINALITY:\n\nThe authors propose to accelerate the learning of complex tasks by exploiting traces of experts.\nUnlike the most common form of imitation learning or behavioral cloning, the authors \nformulate their solution in the case where the expert’s state trajectory is observable, \nbut the expert’s actions are not. This is an important and useful problem in robotics and other\napplications. Within this specific setting the authors differentiate their approach from others \nby developing a solution that does NOT estimate an explicit dynamics model ( e.g.,  P( S’ | S, A ) ).\nThe benefits of not estimating an explicit action model are not really demonstrated in a clear way.\n\nThe author’s articulate a specific solution that provides heuristic guidance rewards that cause the \nlearner to favor actions that achieve subgoals calculated from expert behavior\nand refactors the representation of the Q function so that it \nhas a component that is a function of the subgoal extracted from the expert.\nThese subgoals are linear functions of the expert’s change in state (or change in state features).\nThe resultant policy is a function of the expert traces on which it depends.\nThe authors show they can retrain a new policy that does not require the expert traces.\nAs far as I am aware, this is a novel approach to the problem. \nThe authors claim that this factorization is important and useful but the paper doesn’t\nreally illustrate this well.\n\nThey demonstrate the usefulness of the algorithm against a DQN baseline on Doom game problems.\nThe algorithm learns faster than unassisted DQN as shown by learning curve plots. \nThey also evaluate the algorithms on the quality of the final policies for their approach, DQN, \nand  a supervised learning from demonstration approach ( LfD ) that requires expert actions.\nThe proposed approach does as well or better than competing approaches.\n\n\nQUALITY\n\nAblation studies show that the guidance rewards are important to achieving the improved performance of the proposed method which is important confirmation that the architecture is working in the intended way. However, it would also be useful to do an ablation study of the “factorization” of action values.  Is this important to achieving better results as well or is the guidance reward enough? This seems like a key claim to establish.\n\n\nCLARITY\n\nThe details of the memory based kernel density estimation and neural gradient training seemed\ncomplicated by the way that the process was implemented. Is it possible to communicate\nthe intuitions behind what is going on?\n \nI was able to work out the intuitions behind the heuristic rewards, but I still don’t clearly get \nwhat the Q-value factorization is providing:\n\nTo keep my text readable, I assume we are working in feature space\ninstead of state space and use different letters for learner and expert:\n\n   Learner: S = \\phi(s) \n   Expert’s i^th state visit:  Ei = \\phi( \\hat{s}_i }  where Ei’ is the successor state to Ei\n\nThe paper builds upon approximate n-step discrete-action Q-learning \nwhere the Q value for an action is a linear function of the state features:\n\n    Qp(S,a) = Wa S + Ba\n\nwhere parameters p = ( Wa, Ba ).\n\nAfter observing an experience ( S,A,R,S’ ) we use Bellman Error as a loss function to optimize Qp for parameter p.\nI ignore the complexities of n-step learning and discount factors for clarity.\n\n    Loss = E[    R + MAXa’ Qp(S’,a’)    -   Qp(S,a)   ]  \n\nThe authors suggest we can augment the environment reward R \nwith a heuristic reward Rh proportional to the similarity between \nthe learner “subgoal"" and the expert “subgoal"" in similar states. \n\nThe authors propose to use cosine distance between representations \nof what they call the “subgoals” of learner and expert. \nA subgoal is defined as a linear transformation of the distance traveled by an agent during a transition.\nThe heuristic reward is proportional to the cosine distance between the learner and expert “subgoals""\n\n   Rh = B  <   Wv LearnerDirectionInStateS,   \n                     Wv ExpectedExpertDirectionInStatesSimilarToS   >\n\nThe learner’s direction in state S is just (S-S’) in feature space.\n\nThe authors model the behavior of the expert as a kernel density type approximator\ngiving the expected direction of the expert starting from a states similar to the one the learner is in. \nLet < Wk S, Wk Ej > be a weighted similarity between learner state features S and expert state features Ej\nand Ej’ be the successor state features encountered by the expert.\nThen the expected expert direction for learner state S is:\n\n     SUMj  < Wk S, Wk Ej > ( Ej - Ej’ ) \n\nPresumably the linear Wk transform helps us pick out the important dimensions of similarity between S and Ej.\n\nMapping the learner and expert directions into subgoal space using Wv, the heuristic reward is\n\n   Rh = B <   Wv (S-S’),  \n                    Wv SUMj  < Wk S, Wk Ej > ( Ej - Ej’ ) >\n\nI ignore the ReLU here, but I assume that is operates element-wise and just clips negative values?\nThere is only one layer here so we don’t have complex non-linear things going on?\n\nIn addition to introducing a heuristic reward term, the authors propose to alter the Q-function\nto be specific to the subgoal.\n\n   Q( s,a,g ) = g(S) Wa S + Ba\n\nThe subgoal is the same as the first part, namely a linear transform of the expected expert direction in \nstates similar to state S.\n\n    g(S) =  Wv   SUMj  < Wk S, Wk Ej >  ( Ej - Ej’ ) \n\nSo in some sense, the Q function is really just a function of S, as g is calculated from S.\n\n    Q( S,a ) = g(S) Wa S + Ba \n\nSo this allows the Q-function more flexibility to capture each subgoal in a different linear space?\nI don’t really get the intuition behind this formulation. It allows the subgoal to adjust the value \nof the underlying model? Essentially the expert defines a new Q-value problem at every state \nfor the learner? In some sense are we are defining a model for the action taken by the expert?\n\n\nADDITIONAL THOUGHTS\n\nWhile the authors compare to an unassisted baseline, they don’t compare to methods that use an action model\nwhich is not a fatal flaw but would have been nice. \n\nOne can imagine there might be scenarios where the local guidance rewards of this \nform could be problematic, particularly in scenarios where the expert and learner are not identical\nand it is possible to return to previous states, such as the grid worlds the authors discuss:\nIf the expert’s first few transitions were easily approximable,\nthe learner would get local rewards that cause it to mimic expert behavior.\nHowever, if the next step in the expert’s path was difficult to approximate, \nthen the reward for imitating the expert would be lower.\nWould the learner then just prefer to go back towards those states that it can approximate and endlessly loop?\nIn this case, perhaps expressing heuristic rewards as potentials as described in Ng’s shaping paper might solve the problem.\n\n\nPROS AND CONS\n\nImportant problem generally. Avoiding the estimation of a dynamics model was stated as a given, but perhaps more could be put into motivating this goal. Hopefully it is possible to streamline the methodology section to communicate the intuitions more easily.\n']","[20, -70, 50]","[60, 20, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges that the paper is 'overall well-written' and the idea 'seems interesting'. However, they also point out several limitations and mixed results, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They balance positive comments with areas for improvement, maintaining a professional tone. The reviewer uses phrases like 'The paper is overall well-written' and 'Overall, this is a good paper', which contribute to the polite tone, while also providing specific, constructive feedback for improvement."", ""The sentiment score is -70 because the reviewer identifies several major flaws and weaknesses in the paper, including a 'major flaw in the approach', issues with assumptions not being met, lack of comparisons to simpler methods, and a 'very weak' experimental section. The reviewer also points out missing or incorrectly cited related work. However, it's not entirely negative as the reviewer acknowledges some aspects of the paper's contribution.\n\nThe politeness score is 20 because while the reviewer is direct and critical, they maintain a professional tone throughout. They use phrases like 'To me' and 'I would have liked' which soften the criticism slightly. The reviewer also provides specific suggestions for improvement and additional references, which is constructive. However, the language is not overtly polite or complimentary, maintaining a mostly neutral, academic tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance and novelty of the work, praising its usefulness in robotics and other applications. They note that the proposed approach performs well compared to baselines. However, they also point out areas for improvement and request additional clarifications, balancing the positive aspects with constructive criticism. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the authors' contributions and framing criticisms as suggestions or questions rather than direct attacks. They use phrases like 'it would be useful' and 'I was able to work out' which maintain a collegial tone. The reviewer also provides detailed feedback and shows engagement with the paper, which is a form of respect in academic discourse.""]"
"[""This paper proposes to improve time complexity of factorization machine. Unfortunately, the paper's claim that FM's time complexity is quadratic to feature size is wrong. Specifically, the dot product can be computed as (which is linear to feature size)\n\n(\\sum x_i \\beta_i)^T (\\sum x_i \\beta_i) - \\sum_i x_i^2 beta_i^T beta_i\n\nThe projection of feature group into one embedded space proposed in the paper can be viewed as another form of representing the same model when group equals one. When the number of feature groups do not equal one, they correspond to field aware factorization machine(FFM)"", 'The authors introduce a novel novel for collaborative filtering. The proposed model combines some of the strengths of factorization machines and of polynomial regression. Another way to understand this model is that it\'s a feed forward neural network with a specific connection structure (i.e., not fully connected).\n\nThe paper is well written overall and relatively easy to understand. The study seems fairly thorough (both vanilla and cold-start experiments are reported).\n\nOverall the paper feels a little bit incomplete . This is particularly apparent in the empirical study. Given the somewhat limited novelty of the model the potential impact of this work relies on more convincing experimental results. Here are some suggestions about how to achieve that: \n\n1) Methodically report results for MF, FM, CTR (when meaningful), other strong baselines (maybe SLIM?) and all your methods for all datasets.\n\n2) Report results on well-known CF datasets. Movielens comes to mind.\n\n3) Shed some light on some of the poor CTR results (last paragraph of Section 4.2.2)\n\n4) Explore the models and shed some lights on where the gains are coming from.\n\n\nMinor: \n\n- How do you deal with unobserved preferences in the implicit case?\n\n- I found the idea of Figure 1 very good but in its current form I didn\'t find it particularly insightful (these ""clouds"" are hard to interpret).\n\n- It may also be worth adding this reference when discussing neural factorization:\nhttp://www.cs.toronto.edu/~mvolkovs/nips2017_deepcf.pdf\n', 'This paper presents a method for matrix factorization using DNNs. The suggestion is to make the factorization machine (eqn 1) deep, by grouping the features meaningfully (eqn 5), extracting nonlinear features from original inputs (deep-in, eqn 8), and adding additional nonlinearity after computing pairwise interactions (deep-out, eqn 7). From the methodology point of view, such extensions are relatively straightforward. As an example, from the experimental results, it seems the grouping of features is done mostly with domain knowledge (e.g., months of year) and not learned automatically. The authors claim the proposed method can circumvent the cold-start problem, and presented some experimental results on recommendation systems with text features.\n\nWhile the application problems look quite interesting, in my opinion, the paper needs to make the context and contribution clearer. In particular, there is a huge literature in collaborative filtering, and I believe there is by now sufficient work on collaborative filtering with input features (and possibly dealing with the cold-start problem). I think this paper does not connect very well with that literature. When reading it, at times I felt the main purpose of this paper is to solve the application problems presented in experimental results, instead of proposing a general framework. I suggest the authors to demonstrate their method on some well-known datasets (e.g., MovieLens, Netflix), to give the readers an idea if the proposed method is indeed advantageous over more classical methods, or if the success of this paper is mostly due to clever processing of text features using DNNs.\n\nSome detailed comments:\n1. eqn 4 does not indicate any rank-r factors. \n2. some statements do not seem straightforward/justified to me:  \n    -- the paper uses the word ""inference"" several times without definition\n    -- ""if we were interested in interpreting the parameters, we could constrain w to be non-negative ... "". Is this easy to do, and can the authors demonstrate this in their experiments and show interpretable examples?\n    -- ""Note that if the dot product is replaced with a neural function, fast inference for cold-start ..."". \n3. the experimental setup seems quite unusual to me: ""since we only observe positive labels, for such tasks in the test set we sample a labels according to the label frequency"". This seems very problematic if most of the entries are not observed. Why cannot you use the typical evaluation procedure for collaborative filtering, where you hide some known entries during model training, and evaluate on these entries during test? ']","[-70, 20, -30]","[-20, 60, 60]","[""The sentiment score is -70 because the review starts with 'Unfortunately' and directly states that the paper's main claim is wrong, which is a strong negative critique. The reviewer also points out that the proposed method is essentially equivalent to existing methods, further diminishing the paper's contribution. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and doesn't soften the criticism or offer encouragement. The reviewer states the paper's flaw directly without any mitigating language or positive aspects, which comes across as somewhat impolite in academic discourse. The use of technical language and formulas, while appropriate for the context, also contributes to a more impersonal and less polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper is well-written and the study is fairly thorough. However, they also mention that the paper feels 'incomplete' and suggests several improvements, indicating room for enhancement. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'well written overall' and 'fairly thorough' to soften their criticisms, and frame their suggestions as ways to improve the paper rather than pointing out flaws."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some interesting aspects of the paper, they express several concerns and suggest significant improvements. The reviewer states that the paper needs to make its context and contribution clearer, doesn't connect well with existing literature, and suggests demonstrating the method on well-known datasets. These criticisms outweigh the initial positive remarks about the interesting application problems.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and constructive language throughout. They use phrases like 'I suggest,' 'in my opinion,' and 'I believe,' which soften their criticisms. The reviewer also acknowledges positive aspects before presenting concerns. However, the score is not higher because the review is still quite critical and direct in its feedback.\n\nThe language is professional and academic throughout, avoiding any rudeness or overly harsh statements, while still clearly communicating the areas where the paper needs improvement.""]"
"['The manuscript proposes to estimate the number of components in SVD by comparing the eigenvalues to those obtained on bootstrapped version of the input.\n\nThe paper has numerous flaws and is clearly below acceptance threshold for any scientific forum. Some of the more obvious issues, each alone sufficient for rejection, include:\n\n1. Discrepancy between motivation and actual work. The method is specifically about determining the rank of a matrix, but the authors motivate it with way too general and vague relationships, such as ""determining the number of nodes in neural networks"". Somewhat oddly, the problem is highlighted to be of interest in supervised problems even though one would expect it to be much more important in unsupervised ones.\n\n2. Complete lack of details for related work. Methods such as PA and MAP are described with vague one-sentences summaries that tell nothing about how they actually work. There would have been ample space to provide the mathematical formulations.\n\n3. No technical contribution. The proposed method is trivial variant of randomised testing, described with single sentence ""Bootstrapped samples R_B are simply generated through random sampling with replacement of the values of R."" with literally no attempt of providing any sort of justification why this kind of random sampling would be good for the proposed task or what kind of assumptions it builds on.\n\n4. Poor experiments using really tiny artificial data sets, reported in unprofessional manner (visual style in plots changes from figure to figure, tables report irrelevant numbers in hard-to-read format etc). No real improvement over the somewhat random choice of comparison methods that do not even represent the techniques people would typically use for this problem.', 'The authors propose the use of bootstrapping the data (random sampling entries with replacement) to form surrogate data for which they can evaluate the singular value spectrum of the SVD of the matrix to the singular values of the bootstrapped data, thereby determining the number of latent dimensions in PCA by the point in which the singular values are no greater than the bootstrapped sampled values.  The procedure is contrasted to some existing methods for determining the number of latent components and found to perform similarly to another procedure based on bootstrapping correlation matrices, the PA procedure.\n\nPros:\nDetermining the number of components is an important problem that the authors here address.\n\nCons:\nI find the paper poorly written and the methodology not sufficiently rooted in the existing literature. There are many approaches to determining the number of latent components in PCA that needs to be discussed and constrasted including:\nCross-validation:\nhttp://scholar.google.dk/scholar_url?url=http%3A%2F%2Fwww.academia.edu%2Fdownload%2F43416804%2FGeneralizable_Patterns_in_Neuroimaging_H20160306-9605-1xf9c9h.pdf&hl=da&sa=T&oi=gga&ct=gga&cd=0&ei=rjkXWrzKKImMmAH-xo7gBw&scisig=AAGBfm2iRQhmI2EHEO7Cl6UZoRbfAxDRng&nossl=1&ws=1728x1023\nVariational Bayesian PCA:\nhttps://www.microsoft.com/en-us/research/publication/variational-principal-components/\nFurthermore, the idea of bootstrapping for the SVD has been discussed in prior publications and the present work need to be related to these prior works. This includes:\n\nMilan, Luis, and Joe Whittaker. “Application of the Parametric Bootstrap to Models That Incorporate a Singular Value Decomposition.” Journal of the Royal Statistical Society. Series C (Applied Statistics), vol. 44, no. 1, 1995, pp. 31–49. JSTOR, JSTOR, www.jstor.org/stable/2986193.\n\nFisher A, Caffo B, Schwartz B, Zipunnikov V. Fast, Exact Bootstrap Principal Component Analysis for p > 1 million. Journal of the American Statistical Association. 2016;111(514):846-860. doi:10.1080/01621459.2015.1062383.\n\nIncluding the following package in R for performing bootstrapped SVD: https://cran.r-project.org/web/packages/bootSVD/bootSVD.pdf\n\nThe novelty of the present approach is therefore unclear given prior works on bootstrapping SVD/PCA.\n\nFurthermore, for sparse data with missing entries there are specialized algorithms handling sparsity either using imputation or marginalization, which would be more principled to estimate the PCA parameters. \n\nFinaly, the performance appears almost identical with the PA procedure. In fact, it seems bootstrapping the correlation matrix has a very similar effect as the proposed bootstrapping procedure. Thus, it seems the proposed procedure which is very similar in spirit to PA does not have much benefit over this procedure.\n\nMinor comments:\nExplain what SW abbreviates when introduced first.\nWe will see that it PA a close relationship with BSVD-> We will see that PA is closely related to BSVD\n\nmore effective than SVD under certain conditions (?). – please provide reference instead of ?\n\nBut table 4 that shows -> But table 4 shows that\n\nWe can sum up with that the result seems ->To summarize, the result seems\n', ""The authors propose a bootstrap-based test for determining the number of latent dimensions to retain for linear dimensionality reduction (SVD/PCA). The idea is to retain eigenvectors which are larger than a bootstrap average. The resulting approach is evaluated on two simulated datasets (dense and sparse)as compared to common baselines and evaluated. The results suggest improved performance.\n\nThe paper addresses an important problem, but does not seem ready for publication:\n - The evaluation only uses simulated data. Ideally, the authors can evaluate the approach on real data -- perhaps using out of sample variance explained as a criterion?\n - There is limited technical novelty. The bootstrap is well known already. The authors do not provide additional insight, or provide any theory justifying the technique.\n - It's not clear if the results are new:\nPaper with related discussion: http://jackson.eeb.utoronto.ca/files/2012/10/Jackson1995.pdf\nand a blog post:\nhttps://stats.stackexchange.com/questions/33917/how-to-determine-significant-principal-components-using-bootstrapping-or-monte-c""]","[-90, -50, -50]","[-50, 0, 50]","[""The sentiment score is -90 because the review is overwhelmingly negative. The reviewer states that the paper has 'numerous flaws' and is 'clearly below acceptance threshold for any scientific forum.' They list multiple issues, each described as 'sufficient for rejection.' The language used is strongly critical throughout, with no positive aspects mentioned. The politeness score is -50 because while the reviewer doesn't use explicitly rude language, the tone is quite harsh and dismissive. Phrases like 'Complete lack of details,' 'No technical contribution,' and 'Poor experiments' are blunt and could be considered impolite in academic discourse. The reviewer also describes the authors' work as 'trivial' and their reporting as 'unprofessional,' which are particularly negative characterizations. While the reviewer provides specific critiques, which is expected in a peer review, the overall tone lacks the diplomacy and constructive approach often found in more polite academic communications."", ""The sentiment score is -50 because while the reviewer acknowledges the importance of the topic, they express significant concerns about the paper's methodology, novelty, and writing quality. The review lists more cons than pros and suggests the work is not sufficiently grounded in existing literature. The politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout, neither being particularly polite nor rude. They directly state their criticisms without softening language, but also without using harsh or insulting terms. The review provides constructive feedback and specific recommendations for improvement, which is standard in academic peer reviews."", ""The sentiment score is -50 because while the reviewer acknowledges the importance of the problem, they state that the paper 'does not seem ready for publication' and list several significant criticisms. This indicates a generally negative sentiment, though not extremely negative. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh or rude phrasing. They begin with a neutral summary and use phrases like 'Ideally, the authors can...' which suggest constructive criticism rather than blunt negativity. However, the review is not overly polite or effusive, maintaining a professional tone.""]"
"['Summary of the paper:\nThe paper derives a lower bound on the expected  squared KL-divergence between a true distribution and the sample based maximum likelihood estimate (MLE) of that distribution modelled by an Boltzmann machine (BM) based on methods from information geometry. This  KL-divergence is first split into the squared KL-divergence between the true distribution and MLE of that distribution,  and the expected squared KL-divergence between the MLE of the true distribution and the sample based MLE (in a similar spirit to splitting the excess error into approximation and estimation error in statistical learning theory). The letter is than lower bounded (leading to a lower bound on the overall KL-divergence) by a term  which does not necessarily increase if the number of model parameters is increased. \n\n\nPros:\n- Using insights from information geometry  opens up a very interesting and (to my knowledge) new approach for analysing the generalisation ability of ML models.\n- I am not an expert on information geometry and I did not find the time to follow all the steps of the proof in detail, but the analysis seems to be correct.\n\nCons:\n- The fact that the lower bound does not necessary increase with a growing number of parameters does not guarantee that the same holds true for the KL-divergence (in this sense an upper bound would be more informative). Therefore, it is not clear how much of insights the theoretical analysis gives for practitioners (it could be nice to analyse the tightness of the bound for toy models).\n- Another drawback reading the practical impact is, that the theorem bounds the expected  squared KL-divergence between a true distribution and the sample based MLE, while training minimises the divergence between the empirical distribution and the model distribution ( i.e. the sample based MLE in the optimal case),  and the theorem does not show the dependency on the letter. \n\nI found some parts difficulty to understand and clarity could be improved  e.g. by\n- explaining why minimising KL(\\hat P, P_B) is equivalent to minimising the KL-divergence between the empirical distribution and the Gibbs distribution \\Phi.\n- explaining in which sense the formula on page 4 is equivalent to “the learning equation of Boltzmann machines”.\n- explaining what is the MLE of the true distribution (I assume the closest distribution in the set of distributions that can be modelled by the BM).\n\nMinor comments:\n- page 1: and DBMs….(Hinton et al., 2006) : The paper describes deep belief networks (DBNs) not DBMs \n- \\theta is used to describe the function in eq. (2) as well as the BM parameters in Section 2.2 \n- page 5: “nodes H is” -> “nodes H are” \n\n\n\nREVISION:\nThanks to the reviewers for replying to my comments and making the changes. I think they improved the paper. On the other hand the other reviewers raised valid questions, that led to my decision to not change the overall rating of the paper.', 'Summary: The goal of this paper is to analyze the effectiveness and generalizability of deep learning. This authors present a theoretical analysis of bias-variance decomposition for hierarchical graphical models, specifically Boltzmann Machines (BM).  The analysis follows a geometric formulation of hierarchical probability distributions. The authors describe a general log-linear model and other variations of it such as the standard BM, arbitrary-order BM and Restricted BM to motivate their approach. \n\nThe authors first define the bias-variance decomposition of KL divergence using Pythagorean theorem followed by applying Cramer-Rao bound and show that the variance decreases when adding more parameters in the model. \n\nPositives:\n-The paper is clearly written and the analysis is helpful to show the effect of adding more parameters on the variance and bias in a general architecture (the Boltzmann Machines)\n-The authors did a good job covering general probabilistic models and progression of models starting with the log-linear model.\n-The authors provided an example to illustrate the theory, by showing that the variance decreases with the increase of model parameters.\n\nQuestions:\n-How does this analysis apply to other deep learning architectures such as Convolutional Neural Networks?\n-How does this analysis apply to other frameworks such as variational auto-encoders and generative adversarial networks?', ""This paper uses an information geometric view on hierarchical models to discuss a bias - variance decomposition in Boltzmann machines, presenting interesting conclusions, whereby some more care appears to be needed for making these claims. \n\nThe paper arrives at the main conclusion that it is possible to reduce both the bias and the variance in a hierarchical model. The discussion is not specific to deep learning nor to Boltzmann machines, but actually addresses hierarchical exponential family models. The methods pertaining hierarchical models are interesting and presented in a clear way. My concern are the following points: \n\nThe main theorem presents only a lower bound, meaning that it provides no guarantee that the variance can indeed be reduced. \n\nThe paper seems to ignore that a model with hidden variables may be singular, in which case the Fisher metric is not positive definite and the Cramer Rao bound has no meaning. This interferes with the claims and derivations made in the paper in the case of models with hidden variables. The problem seems to lie in the fact that the presented derivations assume that an optimal distribution in the data manifold is given (see Theorem 1 and proof), effectively making this a discussion about a fully observed hierarchical model. In particular, it is not further specified how to obtain θˆB(s) in page 6 before (13). \n\nAlso, in page 5 the paper states that ``it is known that the EM-algorithm can obtain the global optimum of Equation (12) (Amari, 2016, Section 8.1.3)''. However, what is shown in that reference is only that:  (Theorem 8.2., Amari, 2016) ``The KL-divergence decreases monotonically by repeating the E-step and the M-step. Hence, the algorithm converges to an equilibrium.'' A model with hidden variables can have several global and local optimisers (see, e.g. https://arxiv.org/abs/1709.05276). The critical points of the EM algorithm can have a non trivial structure, as has been observed in the case of non negative rank matrix varieties (see, e.g., https://arxiv.org/pdf/1312.5634.pdf). \n\nOTHER\n\nIn page 3, ``S_\\beta is e-flat and S_\\alpha ... '', should this not be the other way around? (See also page 5 last paragraph of Section 2.) Please also indicate the precise location in the provided reference.  \n\nAll pages up to page 5 are introduction. Section 2.3. as presented is very vague and does not add much to the discussion. \n\nIn page 7, please explain E ψ(θˆ )^2 −ψ(θ∗ )^2=0 \n""]","[20, 70, -20]","[60, 80, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges some pros of the paper, such as the interesting approach using information geometry, and believes the analysis seems correct. However, they also point out significant cons and areas for improvement, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges their own limitations ('I am not an expert'), and frames criticisms as suggestions for improvement rather than harsh judgments. The reviewer also thanks the authors for their revisions in the final paragraph, which adds to the politeness. The language is professional and constructive throughout, without any rudeness or overly negative phrasing."", ""The sentiment score is 70 (positive) because the review begins with a neutral summary of the paper's content, followed by a list of positives that highlight the paper's strengths. The reviewer praises the clear writing, helpful analysis, and good coverage of the topic. There are no explicit criticisms, only questions for further exploration, which suggests a generally positive view of the paper. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts with phrases like 'The authors did a good job' and 'The authors provided an example'. The questions at the end are phrased neutrally and constructively, showing interest in the work rather than criticism. The overall tone is professional and courteous, maintaining a positive and encouraging atmosphere."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting conclusions', 'methods... are interesting and presented in a clear way'), they express several significant concerns about the paper's claims and methodologies. The reviewer points out potential flaws in the main theorem, issues with assumptions about hidden variables, and questionable statements about the EM algorithm. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'My concern are the following points' and 'Please explain' rather than using harsh or dismissive language. The reviewer also balances criticism with positive feedback, which contributes to the polite tone. However, the score is not extremely high as the review is primarily focused on technical critiques rather than overt politeness.""]"
"['The paper presents a method for evaluating the sensitivity and robustness of deep RL policies, and proposes a dynamic game approach for learning robust policies.\n\nThe paper oversells the approach in many ways. The authors claim that ""experiments confirm that state-of-the-art reinforcement learning algorithms fail in the presence of additive disturbances, making them brittle when used in situations that call for robustness"". However, their methods and experiments are only applied to Guided Policy Search (GPS), which seems like a specialized RL algorithm. Conclusions drawn from empirically running GPS on a problem cannot be generalized to all ""state-of-the-art RL algorithms"".\n\nIn Fig 3, the authors conclude that ""our algorithm uses lesser number for the GMMs and requires fewer samples to generalize to the real-world"". I\'m not sure how this can be concluded from Fig 3 [LEFT]. The two line graphs for different values of gamma almost overlay each other, and the cost seems to go up and down, even with number of samples on a log scale. If this shows the variance in the procedure, then the authors should run enough repeats of the experient to smooth out the variance and show the true signal (with error bars if possible). All related conclusions with regards to the dynamic game achieving higher sample efficiency for GMM dynamics fitting need to be backed up with better experimental data (or perhaps clearer presentation, if such data already exists).\n\nFigures 2 and 3 talk about optimal adversarial costs. The precise mathematical definition of this term should be clarified somewhere, since there are several cost functions described in the paper, and it\'s unclear which terms are actually being plotted here.\n\nThe structure of the global policies used in the experiments should be mentioned somewhere.\n\nNote about anonymity: Citation [21] breaks anonymity, since it\'s referred to in the text as ""our abstract"". The link to the YouTube video breaks author anonymity. Further, the link to a shared dropbox folder breaks reviewer anonymity, hence I have not watched those videos.', ""The authors propose to incorporate elements of robust control into guided policy search, in order to devise a method that is resilient to perturbations and (presumably) model mismatch.\n\nThe idea behind the method and the discussion in the introduction and related work is interesting and worthwhile, and I think that combining elements from robust control and reinforcement learning is a very promising direction to explore. However, in its present state, the paper is very hard to evaluate, perhaps because the submission was a bit rushed. It may be that the authors can clarify some of these issues in the response period.\n\nFirst, the authors repeatedly state that perturbations are applied to the policy parameters. This seems very strange to me, as typically robust control considers perturbations to the state or control. And reading the actual method, I can't actually figure out how perturbations are applied to the parameters -- as near as I can tell, the perturbations are indeed applied to the controls. So which is it?\n\nThere is quite a lot of math in the derivation, and it's unclear which parts relate to the standard guided policy search algorithm, and which parts are new. After reading the technical sections several times, my best guess is that the method corresponds to using an adversarial trajectory optimization setup to generate supervision for training a policy. So only the trajectory optimization phase is actually different. Is that true? Or are there other modifications? Some sort of summary of the overall method would have been appreciated, or else a clearer separation of new and old components.\n\nThe evaluation also leaves a lot to be desired. What kind of perturbations are actually being considered? Are they all adversarial perturbations? Do the authors actually test model mismatch or other more natural conditions where robustness would be beneficial? In the end, I was unable to really interpret what the experiments are trying to get across, which makes it hard for me to tell if the method actually works or improves on anything.\n\nIn its present state, the paper is very hard to parse, and the evaluation appears too rushed for me to be able to deduce how well the method works. Hopefully the authors can clarify some of these issues in the response period."", 'There are two anonymity violations in the paper. The first is in the sentence ""The 7-DoF robot result presented shortly previously appeared in our abstract that introduced robust GPS [21]"". The second is in the first linked video, which links to a non-anonymized youtube video. The second linked video, a dropbox link, does not have the correct permissions set, and thus cannot be viewed. Also, the citation style does not seem to follow the ICLR style guidelines.\n\nDisregarding the anonymity and style violations, I will review the paper.  I do not have background in H_inf control theory, but I will review the paper to the best of my ability.\n\nThis paper proposes a guided policy search method for training deep neural network policies that are robust to worst-case additive disturbances. To my knowledge, the approach presented in the paper is novel, though some relevant references are missing. The experimental results demonstrate the method on two simulated experimental domains, demonstrating robustness to adversarial perturbations. The paper is generally well-written, but has some bugs and typos. The paper is substantially longer than the strongly suggested page limit. There are parts of the paper that should be moved to an appendix to accommodate the page limit.\n\nRegarding the experiments:\nMy main concerns are with regard to the completeness of the experiments. First, the experimental results report performance in terms of cost/reward, which is extremely difficult to interpret. It would be helpful to also provide success rate for all experiments, where the authors can define success as, e.g. getting the peg in the hole or being within a certain threshold of the goal.\nSecond, the paper should provide a comparison of policy robustness between the proposed approach and (1) a policy trained with standard GPS, (2) a policy trained with GPS and random perturbations, and ideally, (3) prior approaches to robustness, e.g. Pinto et al., Madelkar et al. [1], or Rajeswaran et al. [2].\n\nRegarding related work and clarity:\nThere are a few papers that consider the problem of building deep neural network policies that are robust [1,2] that should be discussed and ideally compared to.\nRecent deep reinforcement learning work has studied the problem of robustness to adversarial perturbations in the observation space, e.g. [3,4,5,6]. As such, it would be helpful to clarify in the introduction that this paper is considering additive perturbations in the action space.\nThe paper switches between using rewards and costs. It would be helpful to pick one term and stick with it for the entire paper, rather than switching. Further, it seems like there are errors due to the switching. e.g. on page 3, \\ell is defined as the expected reward and in equation 3, it seems like the protaganist policy is trying to minimize \\ell, contradicting the earlier definition.\nLastly, section 5.1 is currently rather difficult to follow. It would help to see more top-down direction in the derivation and more details in section 5.1, 5.2, and 5.3 to be moved to an appendix.\n\nRegarding correctness:\nThere seem to be some issues in the math and/or notation:\nThe most major issue is in Algorithm 2, which is probably the most important part of the paper to be correct, given that it provides a complete picture of the algorithm. I believe that steps 3 and 4 are incorrect and/or incomplete. Step 4 should be referring to the local policy p rather than the global policy pi (assuming the notation in sections 5.1 and 5.3). Also, the local policy p(v|x) appears nowhere in the algorithm, and probably should appear in step 4. In step 5, how is this regression different from step 7?\nIn equation 1 and elsewhere in section 4, there is a mix of notation, using u and z inter-changably. (e.g. in equation 1 and the following equation, I believe the u should be switched to z or the z should be switched to u).\n\nMinor feedback:\n> ""requires fewer samples to generalize to the real world""\nNone of these experiments are in the real world, so the term ""real world"" should not be used.\n> ""algoruithm"" -> ""algorithm""\n> ""when unexpected such as when there exists"" - bad grammar / typo\n> ""ertwhile sensy-sensitivity parameter"" - typo\n- reference 1 is missing authors\n\nIn summary, I think the paper would be significantly improved with further experimental comparisons, further discussion of related work, and clarifications/corrections on the notation, equations, and algorithms.  In its current form, I don\'t think the paper is fit for publication. My rating is between a 4 and a 5.\n\n[1] http://vision.stanford.edu/pdf/mandlekar2017iros.pdf\n[2] https://arxiv.org/abs/1610.01283\n[2] https://arxiv.org/abs/1701.04143\n[3] https://arxiv.org/abs/1702.02284\n[4] https://www.ijcai.org/proceedings/2017/0525.pdf\n[5] https://arxiv.org/abs/1705.06452']","[-50, -30, -40]","[20, 50, 50]","[""The sentiment score is -50 because the review is generally critical of the paper, pointing out several issues with the methodology, conclusions, and presentation. The reviewer states that the paper 'oversells the approach in many ways' and questions the validity of some of the claims and conclusions. However, it's not entirely negative as the reviewer acknowledges the paper's contribution of a method for evaluating sensitivity and robustness of deep RL policies. The politeness score is 20 because while the reviewer is critical, the language used is professional and constructive. The reviewer offers specific suggestions for improvement and clarification, which is a polite way to provide criticism. The tone is direct but not rude, maintaining a respectful academic discourse."", ""The sentiment score is -30 because while the reviewer acknowledges the interesting idea and potential of the paper, they express significant concerns about the clarity, methodology, and evaluation of the work. The review starts positively but quickly shifts to highlighting numerous issues, indicating an overall negative sentiment. However, it's not extremely negative as the reviewer suggests the authors may clarify these issues. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the potential of the work and framing criticisms as areas for clarification rather than outright flaws. They use phrases like 'Hopefully the authors can clarify' and 'It may be that the authors can clarify', which maintain a constructive tone. The reviewer also balances critique with positive comments about the paper's potential, further contributing to the polite tone."", ""The sentiment score is -40 because the review is generally critical, pointing out several issues with the paper including anonymity violations, exceeding page limits, and concerns about the completeness of experiments. The reviewer states that the paper is 'not fit for publication' in its current form, indicating a negative sentiment. However, some positive aspects are noted, such as the novelty of the approach and the paper being 'generally well-written', which prevents the score from being even lower. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement and acknowledging their own limitations ('I do not have background in H_inf control theory, but I will review the paper to the best of my ability'). The language used is respectful and focuses on the content rather than making personal criticisms. However, it doesn't reach the highest levels of politeness as it maintains a direct, matter-of-fact tone rather than using overtly courteous language.""]"
"['This paper proposes a feature augmentation method for one-shot learning.  The proposed approach is very interesting. However, the method needs to be further clarified and the experiments need to be improved. \n\nDetails:\n1. The citation format used in the paper is not appropriate, which makes the paper, especially the related work section, very inconvenient to read. \n\n2. The approach:\n(1) Based on the discussion in the related work section and the approach section, it seems the proposed approach proposes to augment each instance in the visual feature space by adding more features, as shown by [x_i; x_i^A] in 2.3.  However, under one-shot learning, won’t this  make each class still have only one instance for training? \n\n(2) Moreover, the augmenting features x_i^A (regardless A=F, G, or H), are in the same space as the original features x_i. Hence x_i^A is rather an augmenting instance than additional features. What makes feature augmentation better than instance augmentation? \n\n(3) It is not clear how will the vocabulary-information be exploited? In particular, how to ensure the semantic space u to be same as the vocabulary semantic space? How to generate the neighborhood in Neigh(\\hat{u}_i) on page 5? \n\n3.  In the experiments: \n(1) The authors didn’t compare the proposed method with existing state-of-the-art one-shot learning approaches, which makes the results not very convincing. \n\n(2) The results are reported for different numbers of augmented instances. Clarification is needed. \n', 'This paper proposes a (new) semantic way for data augmentation problem, specifically targeted for one-shot learning setting, i.e. synthesizing training samples based on semantic similarity with a given sample . Specifically, the authors propose to learn an autoencoder model, where the encoder translates image data into the lower dimensional subspace of semantic representation (word-to-vec representation of image classes), and the decoder translates semantic representation back to the original input space. For one-shot learning, in addition to a given input image, the following data augmentation is proposed: a) perturbed input image (Gaussian noise added to input image features); b) perturbed decoded image; c) perturbed decoded neighbour image, where neighbourhood is searched in the semantic space.   \nThe idea is nice and simple, however the current framework has several weaknesses:\n1. The whole pipeline has three (neural network) components: a) input image features are extracted from VGG net pre-trained on auxiliary data; 2) auto-encoder that is trained on data for one-shot learning; 3) final classifier for one-shot learning is learned on augmented image space with two (if I am not mistaken) fully connected layers. This three networks need to be clearly described; ideally combined into one end-to-end training pipeline.\n2. The empirical performance is very poor. If you look into literature for zero shot learning, work by Z. Akata in CVPR 2015, CVPR2016, the performance on AwA and on CUB-bird goes way above 50%, where in the current paper it is 30.57% and 8.21% at most (for the most recent survey on zero shot learning papers using attribute embeddings, please, refer to Zero-Shot Learning - The Good, the Bad and the Ugly by Xian et al, CVPR 2017). It is important to understand, why there is such a big drop in performance in one-shot learning comparing to zero-shot learning? One possible explanation is as follows: in the zero-shot learning, one has access to large training data to learn the semantic embedding (training classes). In contrary, in the proposed approach, the auto-encoder model (with 10 hidden layers) is learned using 50 training samples in AwA, and 200 images of birds (or am I missing something?). I am not sure, how can the auto-encoder model not overfit completely to the training data instances. Perhaps, one could try to explore the zero-shot learning setting, where there is a split between train and test classes: training the autoencoder model using large training dataset, and adapting the weights using single data points from test classes in one-shot learning setting. \nOverall, I like the idea, so I am leaning towards accepting the paper, but the empirical evaluations are not convincing. \n\n \n\n \n\n ', 'Summary:\nThis paper proposes a data augmentation method for one-shot learning of image classes. This is the problem where given just one labeled image of a class, the aim is to correctly identify other images as belonging to that class as well. \nThe idea presented in this paper is that instead of performing data augmentation in the image space, it may be useful to perform data augmentation in a latent space whose features are more discriminative for classification. One candidate for this is the image feature space learned by a deep network. However they advocate that a better candidate is what they refer to as ""semantic space"" formed by embedding the (word) labels of the images according to pre-trained language models like word2vec. The reasoning here is that the image feature space may not be semantically organized so that we are not guaranteed that a small perturbation of an image vector will yield image vectors that correspond to semantically similar images (belonging to the same class). On the other hand, in this semantic space, by construction, we are guaranteed that similar concepts lie near by each other. Thus this space may constitute a better candidate for performing data augmentation by small perturbations or by nearest neighbour search around the given vector since 1) the augmented data is more likely to correspond to features of similar images as the original provided image and 2) it is more likely to thoroughly capture the intra-class variability in the augmented data.\nThe authors propose to first embed each image into a feature space, and then feed this learned representation into a auto-encoder that handles the projection to and from the semantic space with its encoder and decoder, respectively. Specifically, they propose to perform the augmentation on the semantic space representation, obtained from the encoder of this autoencoder. This involves producing some additional data points, either by adding noise to the projected semantic vector, or by choosing a number of that vector\'s nearest neighbours. The decoder then maps these new data points into feature space, obtaining in this way the image feature representations that, along with the feature representation of the original (real) image will form the batch that will be used to train the one-shot classifier.\nThey conduct experiments in 3 datasets where they experiment with augmentation in the image feature space by random noise, as well as the two aforementioned types of augmentation in the semantic space. They claim that these augmentation types provide orthogonal benefits and can be combined to yield superior results.\n\nOverall I think this paper addresses an important problem in an interesting way, but there is a number of ways in which it can be improved, detailed in the comments below. \n\nComments:\n-- Since the authors are using a pre-trained VGG for to embed each image, I\'m wondering to what extent they are actually doing one-shot learning here. In other words, the test set of a dataset that is used for evaluation might contain some classes that were also present in the training set that VGG was originally trained on. It would be useful to clarify whether this is happening. Can the VGG be instead trained from scratch in an end-to-end way in this model?\n\n-- A number of things were unclear to me with respect to the details of the training process: the feature extractor (VGG) is pre-trained. Is this finetuned during training?  If so, is this done jointly with the training of the auto-encoder? Further, is the auto-encoder trained separately or jointly with the training of the one-shot learning classifier? \n\n-- While the authors have convinced me that data augmentation indeed significantly improves the performance in the domains considered (based on the results in Table 1 and Figure 5a), I am not convinced that augmentation in the proposed manner leads to a greater improvement than just augmenting in the image feature domain. In particular, in Table 2, where the different types of augmentation are compared against each other, we observe similar results between augmenting only in the image feature space versus augmenting only in the semantic feature space (ie we observe that ""FeatG"" performs similarly as ""SemG"" and as ""SemN""). When combining multiple types of augmentation the results are better, but I\'m wondering if this is because more augmented data is used overall. Specifically, the authors say that for each image they produce 5 additional ""virtual"" data points, but when multiple methods are combined, does this mean 5 from each method? Or 5 overall? If it\'s the former, the increased performance may merely be attributed to using more data. It is important to clarify this point.\n\n-- Comparison with existing work: There has been a lot of work recently on one-shot and few-shot learning that would be interesting to compare against. In particular, mini-ImageNet is a commonly-used benchmark for this task that this approach can be applied to for comparison with recent methods that do not use data augmentation. Some examples are:\n- Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks. (Finn et al.)\n- Prototypical Networks for Few-shot Learning (Snell et al.)\n- Matching Networks for One-shot Learning (Vinyals et al.)\n- Few-Shot Learning Through an Information Retrieval Lens (Triantafillou et al.)\n\n-- A suggestion: As future work I would be very interested to see if this method can be incorporated into common few-shot learning models to on-the-fly generate additional training examples from the ""support set"" of each episode that these approaches use for training.']","[-20, -20, 50]","[50, 60, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer finds the approach 'very interesting', they express several concerns and state that the method needs further clarification and improved experiments. The overall tone suggests the paper needs significant work before being acceptable. The politeness score is moderately positive (50) as the reviewer uses polite language like 'very interesting' and frames criticisms as suggestions for improvement rather than harsh criticisms. They maintain a professional tone throughout, avoiding rudeness while still clearly communicating areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer states they 'like the idea' and are 'leaning towards accepting the paper', they also point out several significant weaknesses and state that 'the empirical evaluations are not convincing'. The overall tone suggests more concerns than praise. The politeness score is moderately positive (60) as the reviewer uses polite and constructive language throughout, offering specific suggestions for improvement rather than harsh criticism. They acknowledge the positive aspects ('The idea is nice and simple') before delving into the weaknesses, and use phrases like 'I am not sure' and 'Perhaps, one could try' when offering critiques and suggestions, maintaining a respectful tone."", ""The sentiment score is 50 (slightly positive) because the reviewer states 'Overall I think this paper addresses an important problem in an interesting way,' indicating a generally positive view. However, they also mention 'there is a number of ways in which it can be improved,' which tempers the positivity. The politeness score is 80 (quite polite) due to the use of respectful language throughout, such as 'I think,' 'I'm wondering,' and 'It would be useful to clarify.' The reviewer offers constructive criticism and suggestions in a professional manner, avoiding harsh or dismissive language. They also acknowledge the paper's strengths before discussing areas for improvement, which is a polite approach to reviewing.""]"
"['Summary: This paper introduces a model that combines the rotation matrices with the LSTMs. They apply the rotations before the final tanh activation of the LSTM and before applying the output gate. The rotation matrix is a block-diagonal one where each block is a 2x2 rotations and those rotations are parametrized by another neural network that predicts the angle of the rotations. The paper only provides results on the bAbI task. \n\nQuestions:\nHave you compared against to the other parametrizations of the LSTMs and rotation matrices? (ablation study)\nHave you tried on other tasks?\nWhy did you just apply the rotations only on d_{t}.\n\nPros:\nUses a simple parametrization of the rotation matrices.\n\nCons:\nNot clear justification and motivations\nThe experiments are really lacking:\nNo ablation study\nThe results are only limited to single toy task.\n\n\nGeneral Comments:\n\nThis paper proposes to use the rotation matrices with LSTMs. However there is no clear justification why is this particular parametrization of rotation matrix is being used over others and why is it only applied before the output gate. The experiments are seriously lacking, an ablation study should have been made and the results are not good enough. The experiments are only limited to bAbI task which doesn’t tell you much. This paper is not ready for publication, and really feels like it is rushed.\n\nMinor Comment:\nThis paper needs more proper proof-reading. There are some typos in it, e.g.:\n1st page, senstence --> sentence\n4th page, the the ... --> the\n\n', 'The paper proposes an additional transform in the recurrent neural network units. The transform allows for explicit rotations and swaps of the hidden cell dimensions. The idea is illustrated for LSTM units, where the transform is applied after the cell values are computed via the typical LSTM updates.\n\nMy first concern is the motivation. I think the paper needs a more compelling example where swaps and rotations are needed and cannot otherwise be handled via gates. In the proposed example, it\'s not clear to me why the gate is expected to be saturated at every time step such that it would require the memory swaps. Alternatively, experimentally showing that the network makes use of swaps in an interpretable way (e.g. at certain sentence positions) could strengthen the motivation.\n\nSecondly, the experimental analysis is not very extensive. The method is only evaluated on the bAbI QA dataset, which is a synthetic dataset. I think a language modeling benchmark and/or a larger scale question answering dataset should be considered.\n\nRegarding the experimental setup, how are the hyper-parameters for the baseline tuned? Have you considered training jointly (across the tasks) as well?\n\nAlso, is the setting the same as in Weston et al (2015)? While for many tasks the numbers reported by Weston et al (2015) and the ones reported here for the LSTM baseline are aligned in the order of magnitude, suggesting that some tasks are easier or more difficult for LSTMs, there are large differences in other cases, for task #5 (here 33.6, Weston 70), for task #16 (here 48, Weston 23), and so on.\n\nFinally, do you have an intuition (w.r.t. to swaps and rotations) regarding the accuracy improvements on tasks #5 and #18?\n\nSome minor issues:\n- The references are somewhat inconsistent in style: some have urls, others do not; some have missing authors, ending with ""et al"".\n- Section 1, second paragraph: senstence\n- Section 3.1, first paragraph: thorugh\n- Section 5: architetures', 'The paper proposes to add a rotation operation in long short-term memory (LSTM) cells. It performs experiments on bAbI tasks and showed that the results are better than the simple baselines with original LSTM cells. There are a few problems with the paper.\n\nFirstly, the title and abstract discuss ""modifying memories"", but the content is only about a rotation operation. Perhaps the title should be ""Rotation Operation in Long Short-Term Memory""?\n\nSecondly, the motivation of adding the rotation operation is not properly justified. What does it do that a usual LSTM cell could not learn? Does it reduce the excess representational power compared to the LSTM cell that could result in better models? Or does it increase its representational capacity so that some pattern is modeled in the new cell structure that was not possible before? This is not clear at all after reading the paper. Besides, the idea of using a rotation operation in recurrent networks has been explored before [3].\n\nFinally, the task (bAbI) and baseline models (LSTM from a Keras tutorial) are too weak. There have been recent works that nearly solved the bAbI tasks to perfection (e.g., [1][2][4][5], and many others). The paper presented a solution that is weak compared to these recent results.\n\nIn a summary, the main idea of adding rotation to LSTM cells is not properly justified in the paper, and the results presented are quite weak for publication in ICLR 2018.\n\n[1] Sainbayar Sukhbaatar, Jason Weston, Rob Fergus. End-to-end memory networks, NIPS 2015\n[2] Caiming Xiong, Stephen Merity, Richard Socher. Dynamic Memory Networks for Visual and Textual Question Answering, ICML 2016\n[3] Mikael Henaff, Arthur Szlam, Yann LeCun, Recurrent Orthogonal Networks and Long-Memory Tasks, ICML 2016 \n[4] Caglar Gulcehre, Sarath Chandar, Kyunghyun Cho, Yoshua Bengio, Dynamic Neural Turing Machine with Soft and Hard Addressing Schemes, ICLR 2017\n[5] Mikael Henaff, Jason Weston, Arthur Szlam, Antoine Bordes, Yann LeCun, Tracking the World State with Recurrent Entity Networks, ICLR 2017\n']","[-70, -20, -60]","[-20, 60, 20]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper lacks clear justification, has limited experiments, and is 'not ready for publication'. They use phrases like 'seriously lacking' and 'rushed', indicating strong disapproval. There are only brief positive comments about the 'simple parametrization'. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and critical. The reviewer doesn't use many polite phrases or softeners, and directly states negative opinions. The mention of typos and need for proofreading adds to the somewhat impolite tone. However, it's not extremely rude, maintaining some professional distance, hence not a lower score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's proposal, they express several concerns and criticisms. They question the motivation, call for more extensive experimental analysis, and point out inconsistencies in the results. However, the tone is not entirely negative as they also offer constructive suggestions for improvement. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions rather than direct attacks, and offers specific recommendations for improvement. They use phrases like 'My first concern is...' and 'I think...' which maintain a polite tone while expressing critiques. The minor issues are presented neutrally at the end, further contributing to the overall polite tone."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several problems with the paper, including a misleading title, lack of proper justification for the proposed method, and weak results compared to recent work. The phrase 'There are a few problems with the paper' sets a negative tone early on. However, it's not entirely negative as the reviewer acknowledges that the proposed method showed better results than simple baselines.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'Perhaps the title should be...' and 'This is not clear at all after reading the paper' which are polite ways of pointing out issues. The reviewer also provides constructive feedback and references to relevant literature, which is helpful to the authors. However, the overall tone is more matter-of-fact than overtly polite, hence the relatively low positive score.""]"
"['SUMMARY\n\nTraditional convolutional neural networks consist of a sequence of information processing layers. However, one can relax this sequential design constraint so that higher layers receive inputs from one, some, or all preceding layers. This modification allows information to travel more freely throughout the network and has been shown to improve performance, e.g., in image recognition tasks. However, it is not clear whether this change in architecture truly increases representational capacity or it merely facilitates network training. \n\nIn this paper, the authors present a theoretical analysis of the gain in representational capacity induced by additional inter-layer connections. The authors restrict their analysis to convolutional arithmetic circuits (ConvACs), a class of networks whose representational capacity has been studied previously. An important property of ConvACs is that the network mapping can be recast as a homogeneous polynomial over the input, with coefficients stored in a ""grid tensor"" $\\mathcal{A}^y$. The grid tensor itself is a function of the hidden weight vectors $\\mathbf{a}^{z,i}$. The authors first extend ConvACs to accommodate ""dense"" inter-layer connections and describe how adding dense connections affects the grid tensor. This analysis gives a potentially useful perspective for understanding the mappings that densely connected ConvACs compute.\n\nThe authors\' main results (Theorems 5.1-5.3) analyze the ""dense gain"" of a densely connected ConvAC. This quantity roughly captures how much wider a standard ConvAC would need to be in order to represent the network mapping of a generic densely connected ConvAC. This is in a way a measure of the added representational power obtained from dense connections. The authors give upper bounds on this quantity, but also produce a case in which the upper bound is achieved. Importantly, the upper bounds are inversely proportional to a parameter $\\lambda \\leq 1$ controlling the rate at which hidden layer widths decay with increasing depth. The implication is that indeed densely connected ConvACs can have greater representational capacity, however the gain is limited to the case where hidden layers shrink exponentially with increasing depth.\n\nThese results are partly unsurprising, since densely connected ConvACs contain more trainable parameters than standard ConvACs. In Proposition 3, the authors give some criteria for evaluating when it is nonetheless worthwhile to add dense connections to a ConvAC.\n\nCOMMENTS\n\n(1.) The authors address an interesting and important problem: explaining the empirical success of densely connected CNNs such as ResNets & DenseNets, relative to standard CNNs. The tensor algebra machinery built around ConvACs is impressive and seems to generate sound insights. However, I feel the current presentation fails to provide adequate intuition and interpretation of the results. Moreover, there is no overarching narrative linking the formal results together. This makes it difficult for the reader to grasp the main ideas and significance of the work without diving into all the details. For example:\n\n- In Proposition 1, the authors comment that including a dense connection increases the rank of the grid tensor for a shallow densely connected convAC. However, the significance of grid tensor rank is not discussed.\n\n- In Proposition 2, the authors do not explain why it is important that the added term $g(\\mathbf{X})$ contains only polynomial terms of strictly smaller degree. It is not clear how Propositions 1 & 2 relate to the main Theorems 5.1-5.3. Is the characterization of the grid tensor in Proposition 1 used to obtain the bounds in the later Theorems?\n\n- In Section 5, the authors introduce a parameter $\\lambda \\leq 1$ controlling how the widths of the hidden layers decay with increasing depth. This parameter seems central to the following bounds on dense gain, yet the authors do not motivate it, and there is no discussion of decaying hidden layer widths in previous sections.\n\n- The practical significance of Proposition 3 is not sufficiently well explained. First, it is not clear how to use this result if all we have is an upper bound for $G_w$, as given by Theorems 5.1-5.2. It seems we would need a lower bound to be able to conclude that the ratio $\\Delta P_{stand}/ \\Delta P_{dense}$ is large. Second, it would be helpful if the authors commented on the implication for the special case $k=1$ and $r \\leq (1/1+\\lambda) \\sqrt{M}$, where the dense gain is known.\n\n(2.) Moreover, because the authors choose not to sketch the main proof ideas, it is difficult to identify the key novel insights, and how the special structure of densely connected ConvACs factors into the analysis. After studying the proofs in some detail, I have some specific concerns outlined below, which diminish the significance of the results and raise some doubts about soundness.\n\n- In Theorem 5.1, the authors upper bound the dense gain by showing that arbitrary $(L, r, \\lambda, k)$ dense ConvACs can be represented as standard $(L, r^\\prime, \\lambda, 0)$ ConvACs of sufficient width $r^\\prime \\geq G_w r$. The mechanism of the proof is to relate the grid tensor ranks of dense and standard ConvACs. However, a worst case bound on the grid tensor rank of a dense ConvAC is used, which does not seem to rely on the formulation of dense ConvACs. Thus, this result does not tell us anything in particular about dense ConvACs, but rather is a general result relating the expressive capacity of arbitrary depth-$L$ ConvACs and $(L, r^\\prime, \\lambda, 0)$ ConvACs with decaying widths.\n\n- Central to Theorem 5.2 is the observation that a densely connected ConvAC can be viewed as a standard ConvAC, only with ""virtually enlarged"" hidden layers (of width $\\tilde{r}_\\ell = (1 + 1/\\lambda)r_\\ell$ for $k=1$, using the notation of the paper), and blocks of weights fixed to represent the identity mapping. This is a relatively simple idea, and one that seems to hold for general architectures. Thus, I believe Theorem 5.2 can be shown more simply and in greater generality, and without use of the tensor algebra machinery.\n\n- There is some intuitive inconsistency in Theorem 5.3 which I would like some help resolving. We have seen that dense ConvACs can be viewed as standard ConvACs with larger hidden layers and some weights fixed. Effectively, the proof of Theorem 5.3 argues for a regime on $r, \\lambda, M$ where this induced ConvAC uses its full representational capacity. This is surprising to me however, as I would have guessed that having some weights fixed makes this impossible. It would be very helpful if the authors could weigh in on this confusion. Perhaps there is an issue with the application of Lemmas 2 & 3 in the proof of Theorem 5.3. In Lemmas 2 & 3, we assume the tensors $\\mathcal{A}$ and $\\mathcal{B}$ are random. These Lemmas are applied in the proof of Theorem 5.3 to tensors $\\phi^{\\alpha, j, \\gamma}$ appearing in the construction of the dense ConvAC grid tensor. However, the $\\phi^{\\alpha, j, \\gamma}$ tensors do not seem completely random, as there are blocks of fixed weights. Can the authors please clarify how the randomness assumption is satisfied?\n\n(3.) Lastly, I am concerned that the authors do not at least sketch how to generalize these results to architectures of more practical interest. As the authors point out, there is previous work generalizing theoretical results for ConvACs to convolutional rectifier networks. The authors should discuss whether a similar strategy might apply in this case.', 'The paper attempts to provide a theoretical justification for ""DenseNet"", a neural net architecture proposed by Huang et al. that contains connections between non-successive layers.  The general goal is to look at ""arithmetic circuit"" (AC) variants of DenseNets, in which ReLUs are replaced by linear combinations and pooling layers are replaced by products.  In AC versions of a network, the complexity of the final function computed (score function) can be understood via the rank of a certain tensor associated with the network. \n\nThe paper shows bounds on the rank, and attempts to identify situations in which dense connections are likely to help increase the complexity of the function computed.\n\nWhile the goal is good, I find too many aspects of the paper that are confusing, at least to someone not an expert on ConvACs.\n\n- first, the definition of growth rate is quite different from the paper of Huang et al. (here, the rate is defined as the number of forward-layers a given layer is connected to, while Huang et al. define it as the number of \'new features\' that get generated in the current layer). \n\n- second, if ReLUs are replaced by simple summations, then I feel that the point of dense blocks is lost (where the non-linearities in each step potentially add complexity). The paper adds the extra step of forward connections across blocks, but this makes the setup quite different from Huang et al.\n\n- third, it appears that the bounds in Theorems 5.1, 5.2 are only _upper bounds_ on the rank.  From the definition of the dense gain, it seems that one would like to _lower bound_ the gain (as this would show that there is no ConvAC with small r\' and k=0 that can realize a ConvAC with higher k and a given r).  Only theorem 5.3 says something of this kind, and even this looks very weak. The gap between r and r\' is rather small.\n\n- finally, the only ""practical take-aways"" (which the paper advertises) seem to be that if the dense gain is close to the general bound on G_w, then dense connections don\'t help. This seems quite weak to me.  Furthermore, it\'s not clear how G_w can be computed (given tensor rank is hard).\n\nOverall, I found that the paper has too many red flags, and the lack of clarity in the writing makes it hard to judge.  I believe the paper isn\'t ready for publication in its current form.', "" The authors first extend the convolutional arithmetic circuits to\nincorporate the dense connections. The expressiveness of the score\nfunction(to be optimized while training) of the convolutional\narithmetic circuits, can be understood by the rank of a tensor\nappearing in a decomposition of the network. Authors derive this\nform for the DenseNet variant of convolutional arithmetic circuits,\nand give bounds on the rank of the associated tensor and using these\nbounds argue the expressive power of the network. The authors also\nclaim these bounds can help in practical guidelines while designing\nthe network.\nThe motivation and attempt is quite good, But the paper is written\nquite poorly without any flow, it is very difficult for the reader\nto understand the novelty or significance of the work, no intuition\nis given and descriptions and so short and cryptic.\nAfter Proposition 1, it is written there is no 'clear advantage' for\nlarge N on using dense connections on a shallow convAC. It is not\nvery clear or obvious since the upper bound for the rank is\nincreasing with some parameter increase. This style of writing is\nprevalent throughout the paper.\nThe DenseNet variant is deviating a lot from original Huang et al,\nRelU is dropped, forward connections across blocks etc. Interblock\nconnections is not intuitively motivated. Most readers would find it\nvery difficult, which of the results apply in case of inter and\nintra block connections. Looks like the results are mostly for inter\nblock connections, for which the empirical results are not there.\nTheorem 5.1 and 5.2 gives some upper bound on dense gain(quantity\nrough defines how much expressive power comes in by adding dense\nconnections, compared to standard convAC), but it is not clear how\nan upper bound is helpful here. A lower bound would have been\nhelpful. The statement after theorem 5.1, by tailoring M and widths\n'such that we exploit the expressiveness added by dense\nconnections'. This seems to very loosely written.\nOverall I feel, the motivation and attempt is fine. But partly due\nto the poor presentation style, deviation from DenseNets and unclear\nnature of the practical usefulness of the results, the paper may not\nbe of contribution to the community at this stage.""]","[-40, -70, -50]","[20, 20, 20]","[""The sentiment score is -40 because while the reviewer acknowledges the interesting nature of the problem and the impressive tensor algebra machinery, they express significant concerns about the presentation, lack of intuition, and potential issues with the proofs. The overall tone is critical, suggesting major revisions are needed. The politeness score is 20 because the reviewer uses respectful language throughout, framing criticisms as suggestions or questions (e.g., 'Can the authors please clarify...'), and acknowledges positive aspects of the work. However, the extensive critique and questioning of the paper's soundness prevents a higher politeness score."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out multiple issues with the paper, including confusion in definitions, weak theoretical results, and lack of practical takeaways. The final statement that 'the paper isn't ready for publication in its current form' clearly indicates a negative sentiment. However, it's not entirely negative as the reviewer acknowledges that 'the goal is good'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I find' and 'I believe' to soften their criticisms, and they explain their concerns in detail rather than dismissing the paper outright. The reviewer also acknowledges the potential of the paper's goal at the beginning. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -50 because while the reviewer acknowledges the good motivation and attempt, they express significant concerns about the paper's presentation, clarity, and practical usefulness. The review starts positively but becomes increasingly critical, concluding that the paper may not contribute to the community at this stage. The politeness score is 20 because the reviewer uses relatively polite language, acknowledging positive aspects and using phrases like 'I feel' to soften criticism. However, the criticism is direct and not overly cushioned with politeness, keeping the score only slightly positive. The reviewer maintains a professional tone throughout, avoiding harsh or rude language even when expressing strong criticisms.""]"
"[""Summary: This paper proposes a new graph-convolution architecture, based on Cayley transform of the matrix. Succinctly, if L denotes the Laplacian of a graph, this filter corresponds to an operator that is a low degree polynomial of C(L) = (hL - i)/(hL+i), where h is a scalar and i denotes sqrt(-1). The authors contend that such filters are interesting because they can 'zoom' into a part of the spectrum, depending on the choice of h, and that C(L) is always a rotation matrix with eigenvalues with magnitude 1. The authors propose to compute them using Jacobi iteration (using the diagonal as a preconditioner), and present experimental results.\n\nOpinion: Though the Cayley filters seem to have interesting properties,  I find the authors theoretical and experimental justification insufficient to conclude that they offer sufficient advantage over existing methods. I list my major criticisms below:\n1. The comparison to Chebyshev filters  (small degree polynomials in the Chebyshev basis) at several places is unconvincing. The results on CORA (Fig 5a) compare filters with the same order, though Cayley filters have twice the number of variables for the same order as Chebyshev filters. Similarly for Fig 1, order 3 Cayley should be compared to Order 6 Chebyshev (roughly).\n\n2. Since Chebyshev polynomials blow up exponentially when applied to values larger than 1, applying Chebyshev filters to unnormalized Laplacians (Fig 5b) is an unfair comparison.\n\n3. The authors basically apply Jacobi iteration (gradient descent using a diagonal preconditioner) to estimate the Cayley filters, and contend that a constant number of iterations of Jacobi are sufficient. This ignores the fact that their convergence rate scales quadratically in h and the max-degree of the graph. Moreover, this means that the Filter is effectively a low degree polynomial in (D^(-1)A)^K, where A is the adjacency matrix of the graph, and K is the number of Jacobi iterations. It's unclear how (or why) a choice of K might be good, or why does it make sense to throw away all powers of D^(-1)Af, even though we're computing all of them.\nAlso, note that this means a K-fold increase in the runtime for each evaluation of the network, compared to the Chebyshev filter.\n\nAmong the other experimental results, the synthetic results do clearly convey a significant advantage at least over Chebyshev filters with the same number of parameters. The CORA results (table 2) do convey a small but clear advantage. The MNIST result seems a tie, and the comparison for MovieLens doesn't make it obvious that the number of parameters is the same. \n\nOverall, this leads me to conclude that the paper presents insufficient justification to conclude that Cayley filters offer a significant advantage over existing work."", 'The paper proposes a new filter for spectral analysis on graphs for graph CNNs. The filter is a rational function based on the Cayley transform. Unlike other popular variants, it is not strictly supported on a small graph neighborhood, but the paper proves an exponential-decay property on the norm of a filtered vertex indicator function.\n\nThe paper argues that Cayley filters allow better spectral localization than Chebyshev filters. While Chebyshev filters can be applied efficiently using a recursive method, evaluation of a  Cayley filter of order r requires solving r linear system in dimension corresponding to the number of vertices, which is expensive. The paper proposes to stop after a small number of iterations of Jacobi\'s method to alleviate this problem.\n\nThe paper is clear and well written.\n\nThe proposed method seems of interest, although I find the experimental section only partly convincing. \n\nThere seems to be a tradeoff here. The paper demonstrates that CayleyNet achieves similar efficiency as ChebNet in multiple experiments while using smaller filter orders. Although using smaller filter orders (and better-localized filters) is an interesting property, it is not necessarily a key objective, especially as this seems to come at the cost of a significantly increased computational complexity. \n\nThe paper could help us understand this tradeoff better. For instance:\n- Middle and right panels of Figure 4 could use a more precise Y scale. How much slower is CayleyNet here with respect to the ChebNet?\n\n- Figure 4 mentions time corresponds to ""test times on batches of 100 samples"". Is this an average value over multiple 100-sample batches? What is the standard deviation? How do the training times compare?\n\n- MNIST accuracies are very similar (and near perfect) -- how did the training and testing time compare? Same for the MovieLens experiment. The improvement in performance is rather small, what is the corresponding computational cost?\n\n- CORA results are a bit confusing to me. The filter orders used here are very small, and the best amongst the values considered seems to be r=1. Is there a reason only such small values have been considered? Is this a fair evaluation of ChebNet which may possibly perform better with larger filter orders?\n\n- The paper could provide some insights as to why ChebNet is unable to work with unnormalized Laplacians while CayleyNet is (and why the ChebNet performance seems to get worse and worse as r increases?).\n', 'This paper is on construction graph CNN using spectral techniques. The originality of this work is the use of Cayley polynomials to compute spectral filters on graphs, related to the work of Defferrard et al. (2016) and Monto et al. (2017) where Chebyshev filters were used. Theoretical and experimental results show the relevance of the Cayley polynomials as filters for graph CNN.\n\nThe paper is well written, and connections to related works are highlighted. We recommend the authors to talk about some future work.']","[-60, 20, 80]","[20, 70, 70]","[""The sentiment score is -60 because the reviewer expresses significant criticisms and concludes that the paper provides 'insufficient justification' for its claims. While there are some positive aspects mentioned (e.g., 'interesting properties', 'small but clear advantage' in some results), the overall tone is critical and skeptical. The politeness score is 20 because the reviewer maintains a professional and objective tone throughout, avoiding personal attacks or harsh language. They use phrases like 'I find' and 'This leads me to conclude', which are polite ways of expressing criticism. However, the review is not overly complimentary or deferential, hence the moderate positive score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's clarity, well-written nature, and potential interest of the proposed method. However, they express some reservations about the experimental section and request further clarification on several points, indicating a mixed but generally positive sentiment. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement without harsh or dismissive comments. They use phrases like 'The paper could help us understand this tradeoff better' and 'The paper could provide some insights', which are polite ways of requesting additional information. The reviewer also acknowledges the paper's strengths before presenting their concerns, which is a courteous approach to peer review."", ""The sentiment score is 80 (positive) because the review begins with a clear acknowledgment of the paper's originality and relevance, stating that it shows 'the relevance of the Cayley polynomials as filters for graph CNN.' The reviewer also notes that the paper is 'well written' and makes good connections to related works. The only slight criticism is a recommendation to discuss future work, which is a constructive suggestion rather than a negative comment. The politeness score is 70 (polite) because the language used is professional and respectful throughout. The reviewer uses phrases like 'we recommend' instead of giving direct orders, which maintains a courteous tone. The overall positive feedback is delivered in a matter-of-fact manner without excessive praise, maintaining a polite but professional distance.""]"
"['The paper proposes a budgeted online kernel algorithm for multi-task learning. The main contribution of the paper is an online update of the output kernel, which measures similarity between pairs of tasks. The paper also proposes a removal strategy that bounds the number of support vectors in the kernel machine. The proposed algorithm is tested on 3 data sets and compared with several baselines.\n  Positives:\n- the output kernel update is well justified\n- experimental results are encouraging\n  Negatives:\n- the methodological contribution of the paper is minimal\n- the proposed approach to maintain the budget is simplistic\n- no theoretical analysis of the proposed algorithm is provided\n- there are issues with the experiments: the choice of data sets is questionable (all data sets are very small so there is not need for online learning or budgeting; newsgroups is a multi-class problem, so we would want to see comparisons with some good multi-class algorithms; spam data set might be too small), it is not clear what were hyperparameters in different algorithms and how they were selected, the budgeted baselines used in the experiments  are not state of the art (forgetron and random removal are known to perform poorly in practice, projectron usually works much better), it is not clear how a practitioner would decide whether to use update (2) or(3)', 'Summary: The paper proposed a two-dimensional approach to lifelong learning, in the context of multi-task learning. It receives instances in an online setting, where both the prediction model and the relationship between the tasks are learnt using a online kernel based approach. It also proposed to use budgeting techniques to overcome computational costs. In general, the paper is poorly written, with many notation mistakes and inconsistencies. The idea does not seem to be novel, technical novelty is low, and the execution in experiments does not seem to be reliable. \n\nQuality: No obvious mistakes in the proposed method, but has very low novelty (as most methods follows existing studies in especially for online kernel learning). Many mistakes in the presentation and experiments.  \n\nOriginality: The ideas do not seem to be novel, and are mostly (trivially) using existing work as different components of the proposed technique. \n\nClarity: The paper makes many mistakes, and is difficult to read. [N] is elsewhere denoted as \\mathbb{N}. The main equation of Algorithm 2 merges into Algorithm 3. Many claims are made without justification (e.g. 2.2. “Cavallanti 2012 is not suitable for lifelong learning”… why?; “simple removal scheme … highest confidence” – what is the meaning of highest confidence?), etc. The removal strategy is not at all well explained – the objective function details and solving it are not discussed. \n\nSignificance: There is no theoretical guarantee on the performance, despite the author’s claiming this as a goal in the introduction itself (“goal of lifelong learner … computation”). The experiments are not reliable. Perceptron obtains a better performance than PA algorithms – which is very odd. Moreover, many of the multi-task baselines obtain a worse performance than a simple perceptron (which does not account for multi-task relationships). \n', 'CONTRIBUTION\nThe main contribution of the paper is not clearly stated.  To the reviewer, It seems “life-long learning” is the same as “online learning”.  However, the whole paper does not define what “life-long learning” is.\nThe limited budget scheme is well established in the literature. \n1. J. Hu, H. Yang, I. King, M. R. Lyu, and A. M.-C. So. Kernelized online imbalanced learning with fixed budgets. In AAAI, Austin Texas, USA, Jan. 25-30 2015. \u2028\n2. Y. Engel, S. Mannor, and R. Meir. The kernel recursive least-squares algorithm. IEEE Transactions on Signal Processing, 52(8):2275–2285, 2004.\nIt is not clear what the new proposal in the paper.\n\nWRITING QUALITY\nThe paper is not well written in a good shape. Many meanings of the equations are not stated clearly, e.g., $phi$ in eq. (7). Furthermore, the equation in algorithm 2 is not well formatted. \n\nDETAILED COMMENTS\n1. The mapping function $phi$ appears in Eq. (1) without definition.\n2. The last equation in pp. 3 defines the decision function f by an inner product. In the equation, the notation x_t and i_t is not clearly defined.  More seriously, a comma is missed in the definition of the inner product.\n3. Some equations are labeled but never referenced, e.g., Eq. (4).\n4. The physical meaning of Eq.(7) is unclear.  However, this equation is the key proposal of the paper.   For example, what is the output of the Eq. (7)? What is the main objective of Eq. (7)?  Moreover, what support vectors should be removed by optimizing Eq. (7)?  One main issue is that the notation $phi$ is not clearly defined.   The computation of f-y_r\\phi(s_r) makes it hard to understand.  Especially,  the dimension of $phi$ in Eq.(7) is unknown. \n\nABOUT EXPERIMENTS\n1.\tIt is unclear how to tune the hyperparameters.\n2.\tIn Table 1, the results only report the standard deviation of AUC. No standard deviations of nSV and Time are reported.\n']","[-40, -80, -70]","[20, -20, -20]","[""The sentiment score is -40 because while the reviewer acknowledges some positives ('well justified', 'encouraging results'), there are more negatives listed, including 'minimal methodological contribution', 'simplistic approach', lack of theoretical analysis, and several issues with the experiments. The overall tone leans negative, but not extremely so. The politeness score is 20 because the language is professional and objective, without personal attacks. The reviewer uses neutral phrases like 'it is not clear' rather than accusatory language. They also begin by acknowledging positives before moving to criticisms, which is a polite approach. However, the review doesn't go out of its way to be overly polite or encouraging, maintaining a mostly neutral, matter-of-fact tone."", ""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer states that the paper is 'poorly written,' has 'low novelty,' and the experiments are not 'reliable.' They also mention 'many mistakes' and 'inconsistencies.' There are very few positive comments, if any. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite harsh and direct. They don't soften their criticisms or offer much encouragement. Phrases like 'poorly written' and 'difficult to read' are quite blunt. However, they do maintain some level of professional language, which prevents the score from being even lower."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several major issues with the paper, including unclear contributions, lack of novelty, poor writing quality, and unclear experiments. There are no positive comments to balance these criticisms. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite direct and critical without any softening language or positive reinforcement. Phrases like 'The paper is not well written in a good shape' and 'It is not clear what the new proposal in the paper' come across as blunt and somewhat impolite. The reviewer also doesn't offer any constructive suggestions for improvement, which contributes to the slightly negative politeness score.""]"
"['This paper analyzes the role of skip connections with respect to generalization in recent architectures such as ResNets or DenseNets. The authors perform an analysis of the performance of ResNets and DenseNets under data scarcity constraints and noisy training samples. They also run some experiments assessing the importance of the number of skip connections in such networks.\n\nThe presentation of the paper could be significantly improved. The motivation is difficult to grasp and the contributions do not seem compelling.\n\nMy main concern is about the contribution of the paper. The hypothesis that skip connections ease the training and improve the generalization has already been highlighted in the ResNet and DenseNet paper, see e.g. [a].\n\n[a] https://arxiv.org/pdf/1603.05027.pdf\n\nMoreover, the literature review is very limited. Although there is a vast existing literature on ResNets, DenseNets and, more generally, skip connections, the paper only references 4 papers. Many relevant papers could be referenced in the introduction as examples of successes in computer vision tasks,  identity mapping initialization, recent interpretations of ResNets/DensetNets, etc.\n\nThe title suggests that the analysis is performed on DenseNet architectures, but experiments focus on comparing both ResNets and DenseNets to sequential convolutional networks and assessing the importance of skip connections.\n\nIn section 3.1. (1st paragraph) proposes adding noise to groundtruth labels; however, in section 3.1.2,. it would seem that noise is added by changing the input images (by setting some pixel channels to 0). Could the authors clarify that? Wouldn’t the noise added to the groundtruth act as a regularizer?\n\nIn section 4, the paper claims to investigate the role of skip connections in vision tasks. However, experiments are performed on MNIST, CIFAR100, a curve fitting problem and a presumably synthetic 2D classification problem. Performing the analysis on computer vision datasets such as ImageNet would be more compelling to back the statement in section 4.\n', 'The paper studies the effect of different network structures (plain CNN, ResNet and DenseNet). This is an interesting line of research to pursue, however, it gives an impression that a large amount of recent work in this direction has not been considered by the authors. The paper contains ONLY 4 references. \n\nSome references that might be useful to consider in the paper:\n- K. Greff et. al. Highway and Residual Networks learn Unrolled Iterative Estimation.\n- C. Zang et. al. UNDERSTANDING DEEP LEARNING REQUIRES RETHINKING GENERALIZATION\n- Q. Liao el. al. Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex\n- A. Veit et. al. Residual Networks Behave Like Ensembles of Relatively Shallow Networks\n- K. He at. Al Identity Mappings in Deep Residual Networks\n\nThe writing and the structure of the paper could be significantly improved. From the paper, it is difficult to understand the contributions. From the ones listed in Section 1, it seems that most of the contributions were shown in the original ResNet and DenseNet papers. Given, questionable contribution and a lack of relevant citations, it is difficult to recommend for acceptance of the paper. \n\nOther issues:\nSection 2: “Skip connection …. overcome the overfitting”, could the authors comment on this a bit more or point to relevant citation?  \nSection 2: “We increase the number of skip connections from 0 to 28”, it is not clear to me how this is done.\nSection 3.1.1 “deep Linear model”, what the authors mean with this? Multiple layers without a nonlinearity? Is it the same as Cascade Net?\nSection 3.2 From the data description, it is not clear how the training data was obtained. Could the authors provide more details on this?\nSection 3.2 “…, only 3 of them are chosen to be displayed…”, how the selection process was done?\nSection 3.2 “Instead of showing every layer’s output we exhibit the 3th, 5th, 7th, 9th, 11th, 13th and the final layer’s output”, according to the description in Fig. 7 we should be able to see 7 columns, this description does not correspond to Fig. 7.\nSection 4 “This paper investigates how skip connections works in vision tasks…” I do not find experiments with vision datasets in the paper. In order to claim this, I would encourage the authors to run tests on a CV benchmark dataset (e. g. ImageNet)\n', 'The ms analyses a number of simulations how skip connections effect the generalization of different network architectures. The experiments are somewhat interesting but they appear rather preliminary. To indeed show the claims made, error bars in the graphs would be necessary as well will more careful and more generic analysis. In addition clear hypotheses should be stated. \nThe fact that some behaviour is seen in MNIST or CIFAR in the simulations does not permit conclusion for other data sets. Typically extensive teacher student simulations are required to validly make points. Also formally the paper is not in good shape. ']","[-50, -60, -50]","[20, 20, 0]","[""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper such as lack of novelty, limited literature review, and unclear methodology. However, it's not entirely negative as it acknowledges the analysis performed and suggests improvements. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer constructive feedback. They use phrases like 'could be significantly improved' and 'Could the authors clarify that?' which maintain a respectful tone. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's contributions, lack of citations, and overall quality. They state it's 'difficult to recommend for acceptance' and point out several issues. However, they do mention the research line is interesting, preventing an extremely negative score. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'could be significantly improved' and 'could the authors comment' rather than using harsh language. They also provide constructive feedback and suggest additional references, which is helpful and polite. The score is only slightly positive as the review is still quite critical overall."", ""The sentiment score is -50 because the review is generally negative, pointing out several shortcomings of the manuscript. The reviewer describes the experiments as 'somewhat interesting but rather preliminary' and states that the paper is 'not in good shape'. However, it's not entirely negative as it acknowledges some interest in the work. The politeness score is 0 (neutral) because the language used is direct and matter-of-fact, without being overtly polite or rude. The reviewer states criticisms plainly without softening the language, but also without using harsh or insulting terms. The reasoning is based on the overall tone, specific criticisms (like the need for error bars and more careful analysis), and the lack of either particularly polite or rude phrasing.""]"
"['This paper proposes an approach to improve exploration in multiagent reinforcement learning by allowing the policies of the individual agents to be conditioned on an external coordination signal \\lambda. In order to find such parametrized policies, the approach combines deep RL with a variational inference approach (ELBO optimization). The paper presents an empirical evaluation, which seems encouraging, but that is also somewhat difficult to interpret given the lack of comparison to other state-of-the-art methods.\n\nOverall, the paper seems interesting, but (in addition to the not completely convincing empirical evaluation), it has two main weaknesses: lack of clarity and grounding in related literature.\n\n=Issues with clarity=\n\n-""This problem has two equivalent solutions"". \nThis is not so clear; depending on the movement of the preys it might well be that the optimal solution will switch to the other prey in certain cases?\n\n-It is not clear what is really meant with the term ""structured exploration"". It just seems to mean \'improved\'?\n\n-It is not clear that the improvements are due to exploration; my feeling is that is is due to improved statistical strength on a more abstract state feature (which is learned), not unlike:\nGeramifard, Alborz, et al. ""Online discovery of feature dependencies."" Proceedings of the 28th International Conference on Machine Learning (ICML-11). 2011.\nHowever, there is no clear indication that there is an improved exploration policy.\n\n-The problem setting is not quite clear:\nThe paper first introduces ""multi-agent RL"", which seems to correspond to a ""stochastic game"" (also ""Markov game""), but then moves on to restrict to the ""fully cooperative setting"" (which would make it a ""Multiagent MDP"", Boutilier \'96).\n\nIt subsequently says it deals only with deterministic problems (which would reduce the problem further to a learning version of a multiagent classical planning problem), but in the experiments do consider stochastically moving preys.\n\n-The paper says the problem is fully observable, but fails to make explicit if this is *individually* fully observable, or jointly. I am assuming the former, but is it not clear how the agents observe this full state in the experimental evaluation.\n\nThis is actually a crucial confusion, as it completely changes the interpretation of what the approach does: in the individually observable case, the approach is adding a redundant source of information which is more abstract and thus seems to facilitate faster learning. In the latter case, where agents would have individual observations, it is actually providing the agents with more information.\n\nAs such, I would really encourage the authors to better define the task they are considering. E.g., by building on the taxonomies of problems that researchers have developed in the community focusing on decentralized POMDPs, such as:\nGoldman, Claudia V., and Shlomo Zilberstein. ""Decentralized control of cooperative systems: Categorization and complexity analysis."" (2004).\n\n-""Compared to the single-agent RL setting, multi-agent RL poses unique difficulties. A central issue\nis the exploration-exploitation trade-off""\nThat now in particular happens to be a central issue in single agent RL too.\n\n-""Finding the true posteriors P (λ t |s t ) ∝ P (s t |λ t )P (λ t ) is intractable in general""\nThe paper did not explain how this inference task is required to solve the RL problem.\n\n-In general, I found the technical description impossible to follow, even after carefully looking at the appending. For instance, (also) there the term P (λ |s ) is suddenly introduced without explaining what the term exactly is? Why is the term P(a|λ) not popping up here? That also needs to be optimized, right? I suppose \\phi is the parameter vector of the variational approximation, but it is never really stated. The various shorthand notations introduced for clarity do not help at all, but only make the formulas very cryptic.\n\n-The main text is not readable since definitions, e.g., L(Q_r,\\tehta,\\phi), that are in the appendix are now missing.\n\n-It is not clear to me how the second term of (10) is now estimated?\n\n-""Shared (shared actor-critic): agents share a deterministic hidden layer,""\nWhat kind of layer is this exactly? How does it relate to \\lambda ?\n\n-""The key difference is that this model does not sample from the shared hidden layer""\nWhy would sampling help? Given that we are dealing with a fully observable multiagent MDP, there is no inherent need to randomize at all? (there should be a optimal deterministic joint policy?)\n\n-""There is shared information between the agents""\nWhat information is referred to exactly? \nAlso: It is not quite clear if for these domains cloned would be better than completely independent learners (without shared weights)?\n\n-I can\'t seem to find anywhere what is the actual shape (or type? I am assuming a vector of reals) of the used \\lambda.\n\n-in figure 5, rhs, what is being shown exactly? What do the colors mean? Why does there seem to be a \\lambda *per* agent now?\n\n\n\n=Related work=\n\nI think the paper could/should be hugely improved in this respect. \n\nThe idea of casting MARL as inference has also been considered by:\n\nLearning for Decentralized Control of Multiagent Systems in Large, Partially-Observable Stochastic Environments.\nM Liu, C Amato, EP Anesta, JD Griffith, JP How - AAAI, 2016\n\nStick-breaking policy learning in Dec-POMDPs\nM Liu, C Amato, X Liao, L Carin, JP How\nInternational Joint Conference on Artificial Intelligence (IJCAI) 2015\n\nWu, F.; Zilberstein, S.; and Jennings, N. R. 2013. Monte-carlo\nexpectation maximization for decentralized POMDPs. In Proc.\nof the 23rd Int’l Joint Conf. on Artificial Intelligence (IJCAI-\n13).\n\nI do not think that these explicitly make use of a mechanism to coordinate the policies, since they address to true Dec-POMDP setting where each agent only gets its own observations, but in the Dec-POMDP literature, there also is the notion of \'correlation device\', which is an additional controller (say corresponding to a dummy agent), which of which the states can be observed by other agents and used to condition their actions on:\n\nBernstein DS, Hansen EA, Zilberstein S. Bounded policy iteration for decentralized POMDPs. InProceedings of the nineteenth international joint conference on artificial intelligence (IJCAI) 2005 Jun 6 (pp. 52-57).\n\n(and clearly this could be directly included in the aforementioned learning approaches). \n\n\nThis notion of a correlation device also highlights to potential relation to methods to learn/compute correlated equilibria. E.g.,:\n\nGreenwald A, Hall K, Serrano R. Correlated Q-learning. In ICML 2003 Aug 21 (Vol. 3, pp. 242-249).\n\n\nA different connection between MARL and inference can be found in:\n\nZhang, Xinhua and Aberdeen, Douglas and Vishwanathan, S. V. N., ""Conditional Random Fields for Multi-agent Reinforcement Learning"", in (New York, NY, USA: ACM, 2007), pp. 1143--1150.\n\n\nThe idea of doing something hierarchical of course makes sense, but also here there are a number of related papers:\n\n-putting ""hierarchical multiagent"" in google scholar finds works by Ghavamzadeh et al., Saira & Mahadevan, etc.\n\n-Victor Lesser has pursued coordination for better exploration with a number of students.\n\nI suppose that Guestrin et al.\'s classical paper:\nGuestrin, Carlos, Michail Lagoudakis, and Ronald Parr. ""Coordinated reinforcement learning."" ICML. Vol. 2. 2002.\nwould deserve a citation, and the MARL field is moving ahead fast, an explanation of the differences with COMA:\nCounterfactual Multi-Agent Policy Gradients\nJ Foerster, G Farquhar, T Afouras, N Nardelli, S Whiteson\nAAAI 2018\nis probably also warranted.\n\n\n\n\n\n\n\n\n', 'The paper proposes a method to coordinate agent behaviour  by using policies that have a shared latent structure. The authors derive a variational policy optimisation method to optimise the coordinated policies. The approach is investigated empirically on 2 predator prey type games.\n\nThe method presented in the paper seems quite novel. The authors present a derivation of their variational, hierarchical  update. Not all steps in this derivation are equally well explained, especially the introduction of the variational posterior could be more detailed. The appendix also offers very little extra information compared to the main text, most paragraphs concerning the derivations are identical. The comparison to existing approaches using variational inference is quite brief. It would be nice to have a more detailed explanation of the novel steps in this approach.\n\n It also seems that by assuming a shared model, shared global state and a fully cooperative problem, the authors remove many of the complexities of a multi-agent system. This also brings the derivations closer to the single agent case.\n\nA related potential criticism is the feasibility of using this approach in a multi-agent system. The authors are essentially creating a (partially) centralised learner. The cooperative rewards and shared structure assumptions structures mentioned above seem limiting in a multi-agent system. Even giving each agent local state observations is known to potentially create coordination problems. The predator prey games where agents with agents physically distributed over the environment are probably not the best motivational examples.\n\nOther remarks: \n\nEmpirical result show a clear advantage for this method over the baselines. The evaluation domains are relatively simple, but it was nice to see that the authors also make an attempt to investigate the qualitative behaviour of their method.\n\nThe overview of related work was relatively brief and focused mostly on recent deep MARL approaches. There is a very large body on coordination in multi-agent RL. It would be nice to situate the research somewhat better within this field (or at least refer to an overview such as Busoniu et al, 2010).\n\nIt seems like a completely factorised approach (i.e. independent agents) would make a nice baseline for the experiments, in addition to the shared architecture approaches.\n\n', 'This paper suggests an interesting algorithmic innovation, consisting of hierarchical latent variables for coordinated exploration in multi-agent settings. \n\nMain concern: This work heavily relies on the multi-agent aspect for novelty : \n""Houthooft et al. (2016) learned exploration policies via information gain using variational methods. However, these only consider 1 agent"".  However, in the current form of the paper this is a questionable claim. As the problems investigated combine fully observable states, purely cooperative payouts and global latent variables, they reduce to single agent problems with a large action space. Effectively the \'different agents\' are nothing but a parameterized action space of a central controller. \nUsing hierarchical latent variables for large action spaces is like a good idea, but placing the work into multi-agent seems like a red herring. \n\nGiven that this is a centralized controller, it would be really helpful to compare quantitatively to other approaches for structured exploration, eg [3] and [4].\n\nDetailed comments:\n-""we restrict to fully cooperative MDPs that are fully observable, deterministic and episodic."" Since the rewards are also positive, a very relevant baseline (from a MARL point of view) is distributed Q-learning [1].\n-Figure 3: Showing total cumulative terminal rewards is difficult to interpret. I would be interested in seeing standard \'training curves\' which show the average return per episode after a given amount of training episodes. Currently it is difficult to judge whether training has converged on not.\n-Related work is missing a lot of relevant research. Apart from references below, please see [2] for a relevant, if dated, overview.\n-""Table 1: Total terminal reward (averaged over 5 best runs)"" - how does the mean and median compare across methods for all runs rather than just the top 5? \n\n\nReferences:\n[1] Lauer, M., Riedmiller, M.: An algorithm for distributed reinforcement learning in cooperative\nmulti-agent systems. In: Proceedings 17th International Conference on Machine Learning\n(ICML-00), pp. 535–542. Stanford University, US (2000)\n[2] L. Bus¸oniu, R. Babuska, and B. De Schutter: Multi-Agent Reinforcement Learning: An Overview\n[3] Nicolas Usunier, Gabriel Synnaeve, Zeming Lin, Soumith Chintala: Episodic Exploration for Deep Deterministic Policies: An Application to StarCraft Micromanagement Tasks\n[4] Matthias Plappert, Rein Houthooft, Prafulla Dhariwal, Szymon Sidor, Richard Y. Chen, Xi Chen, Tamim Asfour, Pieter Abbeel, Marcin Andrychowicz: Parameter Space Noise for Exploration\n\n\n\n']","[-30, -20, -20]","[20, 60, 50]","[""The sentiment score is -30 because while the reviewer acknowledges the paper as 'interesting', they point out several significant weaknesses, including lack of clarity, insufficient grounding in related literature, and an unconvincing empirical evaluation. The review is predominantly critical, listing numerous issues and areas for improvement. The politeness score is 20 because the reviewer uses generally polite language, starting with positive aspects before moving to criticisms. They use phrases like 'I would really encourage the authors' and 'I think the paper could/should be hugely improved', which are constructive rather than harsh. However, some direct criticisms like 'impossible to follow' and 'do not help at all' slightly reduce the politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The method presented in the paper seems quite novel', 'Empirical result show a clear advantage for this method over the baselines'), there are several criticisms and suggestions for improvement. The reviewer points out areas that need more explanation, potential limitations of the approach, and suggests additional comparisons and context.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and constructive language throughout. They phrase criticisms as suggestions ('It would be nice to have...', 'It seems like...') rather than direct attacks. The reviewer also balances negative points with positive observations, showing a fair and considerate approach. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper suggests 'an interesting algorithmic innovation', they express a 'main concern' about the novelty claim and question the multi-agent aspect of the work. The reviewer also points out missing comparisons and suggests improvements, indicating a generally critical stance. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positive aspects ('interesting algorithmic innovation') and framing criticisms as suggestions ('it would be really helpful to compare'). The reviewer maintains a professional tone, avoiding harsh language even when pointing out flaws. The detailed comments and references provided also show a constructive approach, aiming to improve the paper rather than simply criticize it.""]"
"[""1. The idea is interesting, but the study is not comprehensive yet\n2. need to visualize the input data space, with the training data, test data, the 'gaps' in training data [see a recent related paper - Stoecklein et al. Deep Learning for Flow Sculpting: Insights into Efficient Learning using Scientific Simulation Data. Scientific Reports 7, Article number: 46368 (2017).]. \n3. What's the effect of training data size? \n4. How do the intermediate feature maps look like? \n5. Is there an effect of number of layers? Maybe the network architecture is too deep for the simple data characteristics and size of training set. \n6. Other shapes are said to be part of future work, but I am not convinced that serious conclusions can be drawn from this study only? \n7. What about the possible effects of Batch normalization and dropout?  \n8. size of 'd' is critical for autoencoders, only one example in appendix does not do justice, also it seems other color channels show up in the results (fig 10), wasn't it binary input?"", ""The paper considers a toy problem: the space of images of discs of variable radius - a one dimensional manifold.\n\nAn autoencoder based on convolutional layers with ReLU is experimented with, with a 1D embedding.\n\nIt is shown that \n1) if the bias is not included, the resulting function is homogeneous (meaning f(ax)=af(x)), and so it fails because the 1D representation should be the radius, and the relationship from radius to image is more complex than a homogeneous function.\n- if we include the bias and L2 regularise only the encoder weights, it works better in terms of interpolation for a limited data sample.\n\nThe thing is that 1) is trivial (the composition of homogeneous functions is homogeneous... so their proof is overly messy btw). Then, they continue by further analysing (see proposition 2) the solution for this case. Such analysis does not seem to shed much light on anything relevant, given that we know the autoencoder fails in this case due to the trivial proposition 1.\n\nAnother point: since the homogeneous function problem will not arise for other non-linearities (such as the sigmoid), the focus on the bias as the culprit seems arbitrary.\n\nThen, the story about interpolation and regularisation is kind of orthogonal, and then is solved by an arbitrary regularisation scheme. The lesson learned from this case is basically the second last paragraph of section 3.2. In other words, it just works.\n\nSince it's a toy problem anyway, the insights seem somewhat trivial.\n\nOn the plus side, such a toy problem seems like it might lead somewhere interesting. I'd like to see a similar setup but with a suite of toy problems. e.g. vary the aspect ratio of an oval (rather than a disc), vary the position, intensity, etc etc."", ""This paper proposes a simple task (learning the manifold of all the images of disks) to study some properties of Autoencoders. They show that Autoencoders don't generalize to disks of radius not in the training set and propose several regularization to improve generalisation.\n\nThe task proposed in the paper is interesting but the study made is somewhat limited:\n\n- They only studied one choice of Autoencoder architecture, and the results shown depends heavily on the choice of the activation, in particular sigmoid should not suffer from the same problem. \n\n- It would be interesting to study the generalization in terms of the size of the gap.\n\n- The regularization proposed is quite simple and already known, and other regularization have been proposed (e.g. dropout, ...). A more detailed comparison with all previous regularization scheme would be much needed. \n\n- The choice of regularization at the end seems quite arbitrary, it works better on this example but it's not clear at all why, and if this choice would work for other tasks.\n\nAlso Denoising Autoencoders (Pascal et al.) should probably be mentioned in the previous work section, as they propose a solution to the regularization of Autoencoder.\n\nOverall nothing really new was discovered or proposed, the lack of generalization of those kind of architecture is a well known problem and the regularization proposed was already known. ""]","[-20, -50, -30]","[50, 0, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea is interesting, they express several concerns and suggest that the study is not comprehensive yet. The review lists multiple areas for improvement and questions the ability to draw serious conclusions from the study in its current state. The politeness score is moderately positive (50) as the reviewer uses neutral language and frames their comments as suggestions or questions rather than direct criticisms. They begin with a positive note about the interesting idea and use phrases like 'need to' and 'what about' instead of more confrontational language. The review maintains a professional and constructive tone throughout, offering specific recommendations for improvement without being overly harsh or dismissive."", ""The sentiment score is -50 because the reviewer expresses several criticisms and finds the insights 'somewhat trivial'. However, they do mention a 'plus side' and suggest potential future directions, which prevents the score from being more negative. The politeness score is 0 (neutral) because the reviewer uses direct and factual language without being overtly polite or rude. They critique the work but do so in a professional manner, stating observations and opinions without using inflammatory language or personal attacks."", ""The sentiment score is -30 because the review is generally critical, pointing out limitations of the study and suggesting that nothing really new was discovered. However, it's not entirely negative as it acknowledges the task as 'interesting'. The politeness score is 20 because the reviewer uses neutral language and offers constructive criticism without being harsh. They use phrases like 'it would be interesting' and 'should probably be mentioned', which are polite ways of suggesting improvements. The reviewer also acknowledges positive aspects before critiquing, which is a polite approach.""]"
"['In this paper, the authors propose a novel tracking loss to convert the RPN to a tracker. The internal structure of top layer features of RPN is exploited to treat feature points discriminatively. In addition, the proposed compression network speeds up the tracking algorithm. The experimental results on the VOT2016 dataset demonstrate its efficiency in tracking. \n\nThis work is the combination of Faster R-CNN (Ren et al. PAMI 2015) and tracking-by-detection framework. The main contributions proposed in this paper are new tracking loss, network compression and results. \n\nThere are numerous concerns with this work:\n\n1.\tThe new tracking loss shown in equation 2 is similar with the original Faster R-CNN loss shown in equation 1. The only difference is to replace the regression loss with a predefined mask selection loss, which is of little sense that the feature processing can be further fulfilled through one-layer CNN. The empirical operation shown in figure 2 seems arbitrary and lack of theoretical explanation. There is no insight of why doing so. Simply showing the numbers in table 1 does not imply the necessity, which ought to be put in the experiment sections. \n2.\tThe network compression is engineering and lack insight as well. To remove part of the CNN and retrain is a common strategy in the CNN compression methods [a] [b]. There is a lack of discussion with the relationship with prior arts.\n3.\tThe organization is not clear. Section 3.4 should be set in the experiments and Section 3.5 should be set at the beginning of the algorithm. The description of the network compression is not clear enough, especially the training details.  Meanwhile, the presentation is hard to follow. There is no clear expression of how the tracker performs in practice.\n4.\tIn addition, VOT 2016, the method should evaluate on the OTB dataset with the following trackers [c] [d].\n5.\tThe evaluation is not fair. In Sec 6, the authors indicate that MDNet runs at 1FPS while the proposed tracker runs at 1.6FPS. However, MDNet is based on Matlab and the proposed tracker is based on C++ (i.e., Caffe).\n\nReference:\n[a] On Compressing Deep Models by Low Rank and Sparse Decomposition. Yu et al. CVPR 2017.\n[b] Designing Energy-Efficient Convolutional Neural Network Using Energy-Aware Pruning. Yang et al. CVPR 2017.\n[c] ECO: Efficient Convolution Operators for Tracking. Danelljan et al. CVPR 2017.\n[d] Multi-Task Correlation Particle Filter For Robust Object Tracking. Zhang et al. CVPR 2017.\n', 'The paper derives from the popular RPN method and hypothesizes that pixels at different positions, in top feature maps for tracking, should be treated with various emphasis; and they design four matching (anchors and ground truth boxes) strategies to explore which of them are proper for tracking. This is most important idea proposed in the paper. The model compression part is for speed consideration and the model ensemble idea is a general trick to further improve the performance on VOT 2016.\n\nHowever, I think the paper is not ready for ICLR yet due to several reasons.\n\n- Novelty. The newly proposed tracking loss is still the standard, well-known classification loss with the novel part that ""matching strategy"" is different. I do like the analysis part as to why the first and fourth strategy is chosen in section 3.4. But this seems not to be a big difference from previous work. \n\n- Experiments not enough and not organized well. The paper spares the second half of its novelty to network compression (of which there is barely new; but I do understand the necessity to speed up algorithms in real-time products); however, there is no clear comparison (table or figure) to point out how the acceleration is. Only some words in the paper: ""The proposed network compression xxx four times"", ""our tracker accelerates 60% in speed"", etc. Figure 6 is not depicted in a clear manner. \n\nTable 2 lists the performance comparison across methods; what is the meaning of Information-gain loss? It is fair to compare the model ensemble version of yours to other methods? How about the results of the ensemble version of other methods? There is no ablative study in the experiment also. \n\nThe paper has many presentation drawbacks (syntax errors, format issues, etc.) For example, ""Basing on knowledge distillation theory xxx"" -> Based. I won\'t list all that I find here. ', 'This paper proposes a method to adapt a region proposal network (RPN) to the visual object tracking task. The authors also describe a method to compress the network to improve run-time performance. They also claim that an ensemble of the proposed trackers provides state-of-the-art performance on VOT 2016.\n\nThe main claimed contribution is ""a novel tracking loss which successfully converts a pre-trained object detector RPN to a state-of-the-art visual tracker..."" The idea to adapt an RPN to visual object tracking by generating samples for online learning was previously published in the CVPR 2016 workshops [1]. Some novelty is also claimed in the network compression, but it seems to be a straightforward implementation of knowledge distillation. In this reviewer\'s estimation, the novelty in this paper is limited to the specific design of the loss function described in Section 3.5.\n\nThe tracking loss is essentially a procedure to limit or gate back-propagation updates to proposal regions that have a high confidence to match the object being tracking. The intuition is that this strategy will enable better online learning and thus tracking performance. A small empirical study was conducted to determine which feature regions from the top layer of the RPN are most effective for this purpose. The authors argue that allowing only high matches could lead to centered but loose bounding boxes, while allowing further matches can improve the bounding box fit but might encourage drift. The loss function is combination of the two, with \\alpha and \\beta weighting the importance (it seems you only need one weight parameter here). No theoretical justification for the approach is given, it seems to be an ad hoc solution to adapt a region proposal architecture to perform online tracking.\n\nThe network compression in Section 4 seems to yield a nice increase in efficiency without any loss in performance. The network ensemble described in Section 5 improves tracking performance over a single network. These are nice technical improvements that push performance, but do not offer much in terms of novelty.\n\nThe proposed tracking network is tested on the VOT 2016 challenge data. The authors claim state-of-the-art performance on this dataset. The source code and raw results of participants of VOT 2016 are all publicly available - but unfortunately the no raw results or source code are provided for this paper either in supplementary material or in anonymous repository (it is not difficult to do this while keeping anonymity). Tracking papers usually provide some video results or, at minimum, still frames, to assist in the evaluation of performance, but none are provided here The Accuracy Rank and Robustness Rank numbers provided in Table 2 seem to be incorrectly computed - these numbers should be integers, see the VOT challenge report [2].\n\nPros:\n+ Strong practical and technical improvements to push performance\n+ State-of-the-art performance on VOT 2016\n\nCons:\n- Difficult to verify results\n- Limited novelty\n- Numerous language problems, making the paper difficult to read and understand in many places.\n\n\n[1] Zhu, G., Porikli, F., & Li, H. (2016). Robust visual tracking with deep convolutional neural network based object proposals on pets. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops (pp. 26-33).\n[2] VOT challenge report http://data.votchallenge.net/vot2016/presentations/vot_2016_paper.pdf\n\nMinor notes:\n* Clearly explain what an anchor point is\n* Figures are introduced out of order\n* What is the purpose of Figure 1? There seems to be no clear message\n* ""Although ground truths are not provided in tracking..."" - what do you mean by this?\n* Do you fix the aspect ratio of the anchors to 1:1 for tracking, or only to define the confidences in Fig 2?\n* ""RPN is a relative large network to tracking"" - I understand what you mean but it is not written clearly\n* Unclear how \\alpha:\\beta is computed\n* Figure 6 is too small to read.\n* Table 2 size should be increased.\n\n']","[-60, -60, -20]","[20, 20, 30]","[""The sentiment score is -60 because the review is predominantly critical. While it acknowledges some positive aspects in the first paragraph, the majority of the review lists 'numerous concerns' and points out significant weaknesses in the paper's methodology, organization, and evaluation. The politeness score is 20 because while the reviewer maintains a professional tone and uses polite language (e.g., 'the authors propose', 'There are numerous concerns'), the critique is direct and doesn't use many softening phrases. The reviewer also provides constructive feedback and references, which adds to the politeness, but the overall tone is more neutral than overtly polite."", ""The sentiment score is -60 because the reviewer states that the paper is 'not ready for ICLR yet' and lists several significant criticisms, including lack of novelty, insufficient experiments, and presentation issues. However, they do acknowledge some positive aspects, such as liking the analysis part, which prevents the score from being even lower. The politeness score is 20 because the reviewer uses generally polite language, such as 'I think' and 'I do like', and provides constructive feedback. However, the directness of the criticisms and the lack of more explicitly polite phrases keeps the score from being higher. The reviewer also refrains from using harsh or rude language, maintaining a professional tone throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper ('Strong practical and technical improvements', 'State-of-the-art performance'), they also highlight significant limitations ('Limited novelty', 'Difficult to verify results'). The overall tone suggests more concerns than praise. The politeness score is moderately positive (30) as the reviewer maintains a professional tone throughout, balancing criticism with recognition of positive aspects. They use neutral language like 'The authors claim' rather than directly accusatory statements. The reviewer also provides constructive feedback and specific suggestions for improvement, which is a polite approach to criticism. However, the politeness is not extremely high as the criticism, while professionally stated, is quite direct and extensive.""]"
"['This paper proposes two regularization terms to encourage learning disentangled representations. One term is applied to weight parameters of a layer just like weight decay. The other is applied to the activations of the target layer (e.g., the penultimate layer). The core part of both regularization terms is a compound hinge loss of which the input is the KL divergence between two softmax-normalized input arguments. Experiments demonstrate the proposed regularization terms are helpful in learning representations which significantly facilitate clustering performance.\n\nPros:\n(1) This paper is clearly written and easy to follow.\n\n(2) Authors proposed multiple variants of the regularization term which cover both supervised and unsupervised settings.\n\n(3) Authors did a variety of classification experiments ranging from time serials, image and text data.\n\nCons:\n(1) The design choice of the compound hinge loss is a bit arbitrary. KL divergence is a natural similarity measure for probability distribution. However, it seems that authors use softmax to force the weights or the activations of neural networks to be probability distributions just for the purpose of using KL divergence. Have you compared with other choices of similarity measure, e.g., cosine similarity? I think the comparison as an additional experiment would help explain the design choice of the proposed function.\n\n(2) In the binary classification experiments, it is very strange to almost randomly group several different classes of images into the same category. I would suggest authors look into datasets where the class hierarchy is already provided, e.g., ImageNet or a combination of several fine-grained image classification datasets.\n\nAdditionally, I have the following questions:\n(1) I am curious how the proposed method compares to other competitors in terms of the original classification setting, e.g., 10-class classification accuracy on CIFAR10. \n(2) What will happen for the multi-layer loss if the network architecture is very large such that you can not use large batch size, e.g., less than 10? \n\n(3) In drawing figure 2 and 3, if the nonlinear activation function is not ReLU, how would you exam the same behavior? Have you tried multi-class classification for the case “without proposed loss component” and does the similar pattern still happen or not?\n\nSome typos:\n(1) In introduction, “when the cosine between the vectors 1” should be “when the cosine between the vectors is 1”.\n\n(2) In section 4.3, “we used the DBPedia ontology dataset dataset” should be “we used the DBPedia ontology dataset”. \n\nI would like to hear authors’ feedback on the issues I raised.\n', 'The paper proposes techniques for encouraging neural network representations to be more useful for clustering tasks. The paper contains some interesting experimental results, but unfortunately lacks concise motivation and description of the method and quality of writing.\n\nIntroduction:\nThe introduction is supposed to present the problem and the \'chain of events\' that led to this present work, but does not do that. The first paragraph contains a too length explanation that in a classification task, representations are only concerned about being helpful for this task, and not any other task. The paragraph starting with \'Consider the case...\', describes in detailed some specific neural network architecture, and what will happen in this architecture during training. The main problem with this paragraph is that it does not belong in the introduction. Indeed, other parts of the introduction have no relation to this paragraph, and the first part of the text that related to this paragraph appears suddenly in Section 3. The fact that this paragraph is two thirds of the introduction text, this is very peculiar.\n\nFurthermore, the introduction does not present the problem well: \n1) What does is a better representation for a clustering task?\n2) Why is that important?\n\nMethod:\nThere are a few problematic statements in this part:\n""The first loss component L_single works on a single layer and does not affect the other layers in the network"". This is not exactly true, because it affect the layer it\'s related to, which affect upper layers through their feedforward input or bottom layer through the backward pass. \n""Recall from the example in the introduction that we want to force the model to produce divergent representations for the samples that belong to the same class, but are in fact substantively different from each other"". It is not clear why this is a corollary of the example in the introduction (that should be moved to the method part). \n""this loss component may help to learn a better representation only if the input to the target layer still contains the information about latent characteristics of the input data"". What does this mean? The representation always contains such information, that is relevant to the task at hand...\nAnd others. The main problem is that the work is poorly explained: starting from the task at hand, through the intuition behind the idea how to solve it. \n\nThe experiments parts contains results that show that the proposed method is superior by a substantial margin over the baseline approaches. However, the evaluation metrics and procedure are poorly explained; What are Adjusted Mutual Information (AMI) and Normalized Mutual Information  (NMI)? How are they calculated? Or at least, the mutual information between what and what are they measuring?\n\n\n', 'Summary\nThis paper proposes two regularizers that are intended to make the\nrepresentations learned in the penultimate layer of a classifier more conforming\nto inherent structure in the data, rather than just the class structure enforced\nby the classifier. One regularizer encourages the weights feeding into the\npenultimate layer to be dissimilar and the other encourages the activations\nacross samples (even if they belong to the same class) to be dissimilar.\n\nPros\n- The proposed regularizers are able to separate out the classes inherent in the\n  data, even if this information is not provided through class labels. This is\nvalidated on several datasets using visualizations as well as quantitative\nmetrics based on mutual information.\n\nCons\n- It is not explained why it makes sense to first convert the weight vectors\n  into probability distributions by applying the softmax function, and then\nmeasuring distances using KL divergence between the probability distributions.\nIt should be explained more clearly if there is there a natural interpretation\nof the weight vectors as probability distributions. Otherwise it is not obvious\nwhy the distance between the weight vectors is measured the way it is.\n\n- Similarly, the ReLU activations are also first converted into probability\n  distributions by applying a softmax. It should be explained why the model does\nthis, as opposed to simply using dot products to measure similarity.\n\n- The model is not compared to simpler alternatives such as adding an\n  orthogonality regularization on the weights, i.e., computing W^TW and making\nthe diagonals close to 1 and all other terms 0. Similar regularizers can be\napplied for activation vectors as well.\n\n- The objective of this paper seems to be to produce representations that are\n  easy to separate into clusters. This topic has a wealth of previous work. Of\nparticular relevance are methods such as t-SNE [1], parametric t-SNE [2], and\nDEC [3]. The losses introduced in this paper are fairly straight-forward.\nTherefore it would be good to compare to these baselines to show that a simple\nloss function is sufficient to achieve the objective.\n\n- Disentangling usually refers to disentangling factors of variation, for\n  example, lighting, pose, and object identity which affect the appearance of a\ndata point. This is different from separability, which is the property of a\nrepresentation that makes the presence of clusters evident. This paper seems to\nbe about learning separable representations, whereas the title suggests that it\nis about disentangled ones. \n\nQuality\nThe design choices made in the paper (such as the choice of distance function)\nis not well explained. Also, given that the modifications introduced are quite\nsimple, it can be improved by doing more thorough comparisons to other\nbaselines.\n\nClarity\nThe paper is easy to follow.\n\nOriginality\nThe novel aspect of the paper is the way distance is measured by converting the\nweights (and activations) to probability distributions and using KL divergence\nto measure distance. However, it is not explained what motivated this choice.\n\nSignificance\nThe objective of this model is to produce representations that are separable, which\nis of general interest. However, given the wealth of previous work done in\nclustering, this paper would only be impactful if it compares to other hard\nbaselines and shows clear advantages.\n\n[1] van der Maaten, Laurens and Hinton, Geoffrey. Visualizing\ndata using t-SNE. JMLR, 2008.\n\n[2] van der Maaten, Laurens. Learning a parametric embedding\nby preserving local structure. In International Conference\non Artificial Intelligence and Statistics, 2009.\n\n[3] Junyuan Xie, Ross Girshick, and Ali Farhadi. Unsupervised deep embedding for\nclustering analysis. ICML 2016.']","[50, -60, -20]","[80, -20, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges several pros of the paper, such as its clarity and the variety of experiments conducted. However, they also point out some cons and raise questions, indicating a balanced view. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and expresses interest in the authors' feedback. They use phrases like 'I would suggest' and 'I am curious' which maintain a polite and collaborative tone. The reviewer also acknowledges the paper's strengths before discussing its weaknesses, which is a polite approach to peer review."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several issues with the paper, including lack of concise motivation, poor description of the method, and quality of writing. They use phrases like 'unfortunately lacks' and 'problematic statements', indicating a negative sentiment. However, they do mention 'some interesting experimental results', which prevents the score from being even lower. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical without much attempt to soften the criticism. Phrases like 'This is not exactly true' and 'The main problem is that the work is poorly explained' are quite blunt. The reviewer doesn't use polite hedging language or positive reinforcement, which contributes to the slightly negative politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the paper, they list more cons and areas for improvement. The review suggests that the paper lacks thorough comparisons, clear explanations for design choices, and doesn't address relevant previous work. However, it's not entirely negative as the reviewer recognizes some positive aspects and the potential significance of the work. The politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They provide specific, actionable feedback without using harsh language. The reviewer balances criticism with acknowledgment of the paper's strengths and potential impact, which contributes to the polite tone.""]"
"['The authors of this paper proposed a data-driven black-box visualization scheme. The paper primarily focuses on neural network models in the experiment section. The proposed method iteratively optimize learnable masks for each training example to find the most relevant content in the input that was ""attended"" by the neural network.  The authors empirically demonstrated their method on image and text classification tasks. \n\nStrength:\n           - The paper is well-written and easy to follow. \n           - The qualitative analysis of the experimental results nicely illustrated how the learnt latent attention masks match with our intuition about how neural networks make its classification predictions.\n\n        Weakness:\n           - Most of the experiments in the paper are performed on small neural networks and simple datesets. I found the method will be more compiling if the authors can show visualization results on ImageNet models. Besides simple object recognition tasks, other more interesting tasks to test out the proposed visualization method are object detection models like end-to-end fast R-CNN, video classification models, and image-captioning models. Overall, the current set of experiments are limited to showcase the effectiveness of the proposed method.\n           - It is unclear how the hyperparameter is chosen for the proposed method. How does the \\beta affect the visualization quality? It would be great to show a range of samples from high to low beta values. Does it require tuning for different visualization samples? Does it vary over different datasets?\n  ', ""The main contribution of the paper is to propose to learn a Latent Attention Network (LAN) that can help to visualize the inner structure of a deep neural network. To this end, the paper propose a novel training objective that can learn to tell the importance of each dimension of input. It is very interesting. However, one question is what is the potential usage of the model? Since the model need to train an another network to visualize the structure of a trained neural network, it is expensive, and I don't think the model can help use to design a better structure (at least the experiments did not show this point). And maybe different structures of LAN will produce different understanding of the trained model. Hence people are still not sure what kind of structure is the most helpful."", 'The paper presents the formulation of Latent Attention Masks, which is a framework for understanding the importance of input structure in neural networks. The framework takes a pre-trained network F as target of the analysis, and trains another network A that generates masks for inputs. The goal of these masks is to remove parts of the input without changing the response of F. Generated masks are helpful to interpret the preferred patterns of neural networks as well as diagnose modes of error.\n\nThe paper is very well motivated and the formulation and experiments are well presented too. The experiments are conducted in small benchmarks and using simple fully connected networks. It would be interesting to report and discuss convergence properties of the proposed framework. Also, insights of what are the foreseeable challenges on scaling up the framework to real world scenarios.']","[20, -20, 80]","[60, 50, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges some strengths of the paper, such as it being well-written and easy to follow, and the qualitative analysis matching intuition. However, they also point out significant weaknesses, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging positives before discussing negatives, and phrases criticisms as suggestions for improvement rather than harsh judgments. They use phrases like 'It would be great to show' and 'Overall, the current set of experiments are limited' which maintain a constructive tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting proposal, they express significant doubts about its practical usage and effectiveness. The reviewer points out limitations such as the expense of training another network and the uncertainty about which structure is most helpful. However, the score isn't deeply negative as the reviewer does recognize the interesting nature of the work. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the interesting aspects of the work before presenting their concerns. They phrase their criticisms as questions and observations rather than direct attacks, maintaining a professional and courteous tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, describing it as 'very well motivated' with 'well presented' formulation and experiments. The reviewer also highlights the usefulness of the generated masks. The score is not 100 as the reviewer suggests some areas for improvement or expansion. The politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They offer praise where due and frame suggestions for improvement as interesting possibilities rather than criticisms. The tone is professional and courteous without being overly formal or effusive.""]"
"['This paper proposed to use deep AE to do rating prediction tasks in recommender systems.\nSome of the conclusions of the paper, e.g. deep models perform bettern than shallow ones, the non-linear activation\nfunction is important, dropout is necessary to prevent overfitting, are well known, and hence is of less novelty.\nThe proposed re-feeding algorithm to overcome natural sparseness of CF is interesting, however, I don\'t think it is enough to support being accepted by ICLR. \nSome reference about rating prediction are missing, such as ""A neural autoregressive approach to collaborative filtering, ICML2016"". And it would be better to show the performance of the model on implicit rating data, since it is more desirable in practice, since many industry applications have only implicit rating (e.g. whether the user watches the movie or not.).', 'This paper presents a deep autoencoder model for rating prediction. The autoencoder takes the user’s rating over all the items as input and tries to predict the observed ratings in the output with mean squared error. A few techniques are applied to make the training feasible without layer-wise pre-training: 1) SELU activation. 2) dropout with high probability. 3) dense output re-feeding. On the Netflix prize dataset, the proposed deep autoencoder outperforms other state-of-the-art approaches. \n\nOverall, the paper is easy to follow. However, I have three major concerns regarding the paper that makes me decide to reject it.\n\n1. Lack of novelty. The paper is essentially a deeper version of the U-AutoRec (Sedhain et al. 2015) with a few recently emerged innovations in deep learning. The dense output re-feeding is not something particularly novel, it is more or less a data-imputation procedure with expectation-maximization — in fact if the authors intend to seek explanation for this output re-feeding technique, EM might be one of the interpretations. And similar technique (more theoretically grounded) has been applied in image imputation for variational autoencoder (Rezende et al. 2014, Stochastic Backpropagation and Approximate Inference in Deep Generative Models). \n\n2. The experimental setup is also worth questioning. Using a time-split dataset is of course more challenging. However, the underlying assumption of autoencoders (or more generally, latent factor models like matrix factorization) is the all the ratings are exchangeable (conditionally independent given the latent representations), i.e., autoencoders/MF are not capable of inferring the temporal information from the data, Thus it is not even a head-to-head comparison with a temporal model (e.g., RNN in Wu et al. 2017). Of course you can still apply a static autoencoder to time-split data, but what ends up happening is the model will use its capacity to try to explain the temporal signal in the data — a deeper model certainly has more extra capacity to do so. I would suggest the authors comparing on a non-time-split dataset with other static models, like I(U)-AutoRec/MF/CF-NADE (Zheng et al. 2016)/etc.  \n\n3. Training deep models on recommender systems data is impressive. However, I would like to suggest we, as a community, start to step away from the task of rating predictions as much as we can, especially in more machine-learning-oriented venues (NIPS, ICML, ICLR, etc.) where the reviewers might be less aware of the shift in recommender systems research. (The task of rating predictions was made popular mostly due to the Netflix prize, yet even Netflix itself has already moved on from ratings.) Training (and evaluating) with RMSE on the observed ratings assumes all the missing ratings are missing at random, which is clearly far from realistic for recommender systems (see Marlin et al. 2007, Collaborative Filtering and the Missing at Random Assumption). In fact, understanding why some of the ratings are missing presents a unique challenge for the recommender systems. See, e.g., Steck 2010, Training and testing of recommender systems on data missing not at random, Liang et al. 2016, Modeling user exposure in recommendation, Schnabel et al. 2016, Recommendations as Treatments: Debiasing Learning and Evaluation. A model with good RMSE in a lot of cases does not translate to good recommendations (Cremonesi et al. 2010, Performance of recommender algorithms on top-n recommendation tasks\n). As a first step, at least start to use all the 0’s in the form of implicit feedback and focus on ranking-based metrics other than RMSE. ', 'In this paper the authors present a model for more accurate Netflix recommendations (rating predictions, RMSE).  In particular, the authors demonstrate that a deep autoencoder, carefully tuned, can out-perform  more complex RNN-based models that have temporal information.  The authors examine how different non-linear activations, model size, dropout, and a novel technique called ""dense re-feeding"" can together improve DNN-based collaborative filtering.\n\nPros:\n- The accuracy results are impressive and a useful datapoint in how to build a DNN-based recommender.  \n- The dense re-feeding technique seems to be novel with incremental (but meaningful) benefits.  \n\nCons:\n- Experimental results on only one dataset. \n- Difficult to know if the results are generalizable.\n\n']","[-30, -70, 60]","[20, 50, 50]","[""The sentiment score is slightly negative (-30) because the reviewer points out several limitations of the paper, such as lack of novelty in some conclusions and insufficient contribution to warrant acceptance. However, they do acknowledge an interesting aspect (the re-feeding algorithm). The politeness score is slightly positive (20) as the reviewer uses neutral language and offers constructive suggestions for improvement, without being overly critical or harsh. They use phrases like 'it would be better' and provide specific recommendations, which maintains a professional and respectful tone."", ""The sentiment score is -70 because the reviewer explicitly states they have decided to reject the paper due to three major concerns, which are then detailed. This indicates a strongly negative sentiment towards the paper's acceptance. However, the reviewer does acknowledge some positive aspects ('Overall, the paper is easy to follow') and provides constructive feedback, which prevents the score from being even lower. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, offering detailed explanations and suggestions for improvement. They use phrases like 'I would suggest' and 'I would like to suggest' which are polite ways of offering criticism. The reviewer also acknowledges the difficulty of the task ('Training deep models on recommender systems data is impressive'). However, the directness of the criticism and the clear rejection prevent the politeness score from being higher."", ""The sentiment score is 60 (positive) because the reviewer starts by highlighting the main contributions of the paper and lists several pros, including 'impressive' accuracy results and a novel technique. The cons mentioned are relatively minor. The politeness score is 50 (somewhat polite) because the reviewer uses neutral, professional language throughout, avoiding harsh criticism and acknowledging the paper's strengths. The reviewer presents both pros and cons in a balanced manner, which contributes to a polite tone without being overly deferential.""]"
"['Summary: The authors take two pages to describe the data they eventually analyze - Chinese license plates (sections 1,2), with the aim of predicting auction price based on the ""luckiness"" of the license plate number.  The authors mentions other papers that use NN\'s to predict prices, contrasting them with the proposed model by saying they are usually shallow not deep, and only focus on numerical data not strings. Then the paper goes on to present the model which is just a vanilla RNN, with standard practices like batch normalization and dropout.  The proposed pipeline converts each character to an embedding with the only sentence of description being ""Each character is converted by a lookup table to a vector representation, known as character embedding.""   Specifics of the data,  RNN training, and the results as well as the stability of the network to hyperparameters is also examined. Finally they find a ""a feature vector for each plate by summing up the output of the last recurrent layer overtime."" and the use knn on these features to find other plates that are grouped together to try to explain how the RNN predicts the prices of the plates. In section 7,  the RNN is combined with a handcrafted feature model he criticized in a earlier section for being too simple to create an ensemble model that predicts the prices marginally better. \n\nSpecific Comments on Sections: \nComments: Sec 1,2\nIn these sections the author has somewhat odd references to specific economists that seem a little off topic, and spends a little too much time in my opinion setting up this specific data.\n\nSec 3\nThe author does not mention the following reference: ""Deep learning for stock prediction using numerical and textual information"" by Akita et al. that does incorporate non-numerical info to predict stock prices with deep networks.\n\nSec 4\nWhat are the characters embedded with? This is important to specify. Is it Word2vec or something else? What does the lookup table consist of? References should be added to the relevant methods. \n\nSec 5\nI feel like there are many regression models that could have been tried here with word2vec embeddings that would have been an interesting comparison. LSTMs as well could have been a point of comparison. \n\nSec 6\n Nothing too insightful is said about the RNN Model. \n\nSec 7\nThe ensembling was a strange extension especially with the Woo model given that the other MLP architecture gave way better results in their table.\n\nOverall: This is a unique NLP problem, and it seems to make a lot of sense to apply an RNN here, considering that word2vec is an RNN. However comparisons are lacking and the paper is not presented very scientifically.  The lack of comparisons made it feel like the author cherry picked the RNN to outperform other approaches that obviously would not do well.\n', 'The authors present a deep neural network that evaluates plate numbers. The relevance of this problem is that there are auctions for plate numbers in Hong Kong, and predicting their value is a sensible activity in that context. I find that the description of the applied problem is quite interesting; in fact overall the paper is well written and very easy to follow. There are some typos and grammatical problems (indicated below), but nothing really serious.\n\nSo, the paper is relevant and well presented. However, I find that the proposed solution is an application of existing techniques, so it lacks on novelty and originality. Even though the significance of the work is apparent given the good results of the proposed neural network, I believe that such material is more appropriate to a focused applied meeting. However, even for that sort of setting I think the paper requires some additional work, as some final parts of the paper have not been tested yet (the interesting part of explanations). Hence I don\'t think the submission is ready for publication at this moment.\n\nConcerning the text, some questions/suggestions:\n- Abstract, line 1: I suppose ""In the Chinese society...""--- are there many Chinese societies?\n- The references are not properly formatted; they should appear at (XXX YYY) but appear as XXX (YYY) in many cases, mixed with the main text. \n- Footnote 1, line 2: ""an exchange"".\n- Page 2, line 12: ""prices. Among"".\n- Please add commas/periods at the end of equations.\n- There are problems with capitalization in the references. ', ""The author(s) proposed to use a deep bidirectional recurrent neural network to estimate the auction price of license plates based on the sequence of letters and digits. The method uses a learnable character embedding to transform the data, but is an end-to-end approach. The analysis of squared error for the price regression shows a clear advantage of the method over previous models that used hand crafted features. \nHere are my concerns:\n1) As the price shows a high skewness in Fig. 1, it may make more sense to use relative difference instead of absolute difference of predicted and actual auction price in evaluating/training each model. That is, making an error of $100 for a plate that is priced $1000 has a huge difference in meaning to that for a plate priced as $10,000. \n\n2) The time-series data seems to have a temporal trend which makes retraining beneficial as suggested by authors in section 7.2. If so, the evaluation setting of dividing data into three *random* sets of training, validation, and test, in 5.3 doesn't seem to be the right and most appropriate choice. It should however, be divided into sets corresponding to non-overlapping time intervals to avoid the model use of temporal information in making the prediction. ""]","[-30, -20, 50]","[20, 80, 80]","[""The sentiment score is -30 because while the reviewer acknowledges the uniqueness of the NLP problem and the appropriateness of using an RNN, they express several criticisms throughout the review. These include spending too much time on data setup, lacking important comparisons, not presenting the work scientifically, and potentially cherry-picking methods. The overall tone suggests more negative than positive sentiment, but not extremely negative.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout and uses relatively neutral language. They offer constructive criticism and suggestions for improvement rather than harsh condemnation. Phrases like 'I feel like' and 'in my opinion' soften the critique. However, the review is not overly polite or praising, maintaining a more neutral professional tone overall."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper interesting and well-written, they also point out significant issues such as lack of novelty and incomplete testing. The reviewer ultimately recommends against publication at this time. The politeness score is high (80) as the reviewer uses respectful language throughout, acknowledging positive aspects of the paper and providing constructive feedback. They use phrases like 'I find' and 'I believe' to soften criticisms, and offer specific suggestions for improvement. The tone is professional and courteous, even when pointing out flaws."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the advantages of the proposed method over previous models, but also raises two significant concerns. The overall tone is constructive rather than critical. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, presenting their concerns as suggestions rather than criticisms. Phrases like 'Here are my concerns' and 'it may make more sense' indicate a polite and considerate approach to feedback. The reviewer also acknowledges the authors' suggestions, showing respect for their work.""]"
"['The main take-away messages of this paper seem to be:\n\n1. GANs don\'t really match the target distribution. Some previous theory supports this, and some experiments are provided here demonstrating that the failure seems to be largely in under-sampling the tails, and sometimes perhaps in introducing spurious modes.\n\n2. Even if GANs don\'t exactly match the target distribution, their outputs might still be useful for some tasks.\n\n(I wouldn\'t be surprised if you disagree with what the main takeaways are; I found the flow of the paper somewhat disjointed, and had something of a hard time identifying what the ""point"" was.)\n\nMode-dropping being a primary failure mode of GANs is already a fairly accepted hypothesis in the community (see, e.g. Mode Regularized GANs, Che et al ICLR 2017, among others), though some extra empirical evidence is provided here.\n\nThe second point is, in my opinion, simultaneously (i) an important point that more GAN research should take to heart, (ii) relatively obvious, and (iii) barely explored in this paper. The only example in the paper of using a GAN for something other than directly matching the target distribution is PassGAN, and even that is barely explored beyond saying that some of the spurious modes seem like reasonable-ish passwords.\n\nThus though this paper has some interesting aspects to it, I do not think its contributions rise to the level required for an ICLR paper.\n\nSome more specifics:\n\nSection 2.1 discusses four previous theoretical results about the convergence of GANs to the true density. This overview is mostly reasonable, and the discussion of Arora et al. (2017) and Liu et al. (2017) do at least vaguely support the conclusion in the last section of this paragraph. But this section is glaringly missing an important paper in this area: Arjovsky and Bottou (2017), cited here only in passing in the introduction, who proved that typical GAN architectures *cannot* exactly match the data distribution. Thus the question of metrics for convergence is of central importance, which it seems should be important to the topic of the present paper. (Figure 3 of Danihelka et al. https://arxiv.org/abs/1705.05263 gives a particularly vivid example of how optimizing different metrics can lead to very different results.) Presumably different metrics lead to models that are useful for different final tasks.\n\nAlso, although they do not quite fit into the framing of this section, Nowozin et al.\'s local convergence proof and especially the convergence to a Nash equilibrium argument of Heusel et al. (NIPS 2017, https://arxiv.org/abs/1706.08500) should probably be mentioned here.\n\nThe two sample testing section of this paper, discussed in Section 2.2 and then implemented in Section 3.1.1, seems to be essentially a special case of what was previously done by Sutherland et al. (2017), except that it was run on CIFAR-10 as well. However, the bottom half of Table 1 demonstrates that something is seriously wrong with the implementation of your tests: using 1000 bootstrap samples, you should reject H_0 at approximately the nominal rate of 5%, not about 50%! To double-check, I ran a median-heuristic RBF kernel MMD myself on the MNIST test set with N_test = 100, repeating 1000 times, and rejected the null 4.8% of the time. My code is available at https://gist.github.com/anonymous/2993a16fbc28a424a0e79b1c8ff31d24 if you want to use it to help find the difference from what you did. Although Table 1 does indicate that the GAN distribution is more different from the test set than the test set is from itself, the apparent serious flaw in your procedure makes those results questionable. (Also, it seems that your entry labeled ""MMD"" in the table is probably n * MMD_b^2, which is what is computed by the code linked to in footnote 2.)\n\nThe appendix gives a further study of what went wrong with the MNIST GAN model, arguing based on nearest-neighbors that the GAN model is over-representing modes and under-representing the tails. This is fairly interesting; certainly more interesting than the rehash of running MMD tests on GAN outputs, in my opinion.\n\nMinor:\n\nIn 3.1.1, you say ""ideally the null hypothesis H0 should never be rejected"" – it should be rejected at most an alpha portion of the time.\n\nIn the description of section 3.2, you should clarify whether the train-test split was done such that unique passwords were assigned to a single fold or not: did 123456 appear in both folds? (It is not entirely clear whether it should or not; both schemes have possible advantages for evaluation.)', ""This paper considers the question of how well GANs capture the true data distribution. The train GAN models on MNIST, CIFAR and a pass word dataset and then use two-kernel ample tests to assess how well the models have modeled the data distribution. They find that in most cases GANs don't match the true distribution.\n\nIt is unclear to me what the contribution of this paper is. The authors appear to simple perform experiments done elsewhere in different papers. I have not learned anything new by reading this work.  Neither the method nor the results are novel contributions to the study of GANs. \n\nThe paper is also written in a very informal manner with several typos throughout. I would recommend the authors try to rewrite the work as perhaps more of a literature review + throughout experimentations of GAN evaluation techniques. In its current form I don't think it should be accepted. \n\nAdditional comments:\n- The authors claim GANs are able to perform well even when data is limited. Could the authors provide some examples to back up this claim. As far as I understand GANs require lots of data to properly train. \n- on page 3 the authors claim that using human assessments of GAN generated images is bad because humans have a hard time performing the density estimation (they might ignore tails of the distribution for example) .. I think this is missing up a bunch of different ideas.. First, a key questions is *what do we want our GANs for?* Density estimation is only one of those answers. If the goal is density estimation then of course human evaluation is an inappropriate measure of performance. But if the goal is realistic synthesis of thats then human perceptual measures are more appropriate. Using humans can be ban in other ways of course since they would have a hard time assessing generalizability (i.e. you could just sample training images and humans would think the samples looked great!). \n"", 'This paper tried to tell us something else about GANs except for their implicit generation power. The conclusion is GANs can capture some structure of the data in high dimensional space. \n\nTo me, the paper seems a survey paper instead of a research one.  The introduction part described the involving of generative models and some related work about GANs. However, the author did not claim what the main contributions are. Even in Section 2, I can see nothing new but all the others\' work. The experimental section included some simulation results, which are weird for me since they are not quite related to previous content. Moreover, the 3.1.1 ""KERNEL TWO-SAMPLE TEST"" is something which has been done in other paper [Li et al., 2017, Guo et al., 2017]. \n\nIt is suggested that the author should delete some of the parts describing their work and make clear claims about the main contributions of the paper. Meanwhile, the experimental results should support the claims. \n\n']","[-60, -70, -60]","[20, -20, 20]","[""The sentiment score is -60 because the reviewer expresses significant criticisms and states that the paper's contributions do not meet the standards for ICLR. They point out flaws in the methodology and argue that some key points are obvious or barely explored. However, they do acknowledge some 'interesting aspects', preventing an extremely negative score. The politeness score is 20 because the reviewer uses generally professional language and offers constructive feedback, but there are some blunt criticisms (e.g. 'something is seriously wrong with the implementation'). The reviewer also provides helpful suggestions and resources, which contributes to a slightly positive politeness score."", ""The sentiment score is -70 because the reviewer expresses a clearly negative opinion about the paper, stating that they don't see a clear contribution, haven't learned anything new, and don't think it should be accepted in its current form. The language is somewhat harsh, but not entirely dismissive, hence not the lowest possible score. The politeness score is -20 because while the reviewer provides some constructive feedback and suggestions, the overall tone is quite critical and blunt. The reviewer points out the paper's informality and typos, and directly states that it shouldn't be accepted, which comes across as somewhat impolite. However, they do offer some specific recommendations for improvement, which prevents the score from being extremely negative."", ""The sentiment score is -60 because the reviewer expresses several criticisms and disappointments with the paper. They state it seems more like a survey than original research, lacks clear contributions, and contains weird or unrelated experimental results. The reviewer also suggests significant revisions. However, it's not entirely negative as they acknowledge the paper's attempt to explore a different aspect of GANs.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'It is suggested' rather than making demands, and they explain their concerns rather than simply dismissing the work. The language is not overtly polite, but it avoids rudeness and maintains a respectful, constructive tone typical of academic peer reviews.""]"
"['The manuscript proposed to use prefix codes to compress the input to a neural network for text classification. It builds upon the work by Zhang & LeCun (2015) where the same tasks are used.\n\n\nThere are several issues with the paper and I cannot recommend acceptance of the paper in the current state. \n- It looks like it is not finished.\n- the datasets are not described properly. \n- It is not clear to me where the baseline results come from.\n They do not match up to the Zhang paper (I have tried to find the matching accuracies there).\n- It is not clear to me what the baselines actually are or how I can found more info on those.\n- the results are not remarkable. \n\nBecause of this, the paper needs to be updated and cleaned up before it can be properly reviewed. \n\nOn top of this, I do not enjoy the style the paper is written in, the language is convoluted. \nFor example: “The effort to use Neural Convolution Networks for text classification tasks is justified by the possibility of appropriating tools from the recent developments of techniques, libraries and hardware used especially in the image classification “\nI do not know which message the paper tries to get across here. \nAs a reviewer my impression (which is subjective) is that the authors used difficult language to make the manuscript look more impressive.\nThe acknowledgements should not be included here either. \n\n', 'This paper proposes a new character encoding scheme for use with character-convolutional language models. This is a poor quality paper, is unclear in the results (what metric is even reported in Table 6), and has little significance (though this may highlight the opportunity to revisit the encoding scheme for characters).', 'The paper proposed to encode text into a binary matrix by using a compressing code for each word in each matrix row. The idea is interesting, and overall introduction is clear.\n\nHowever, the work lacks justification for this particular way of encoding, and no comparison for any other encoding mechanism is provided except for the one-hot encoding used in Zhang & LeCun 2015. The results using this particular encoding are not better than any previous work.\n\nThe network architecture seems to be arbitrary and unusual. It was designed with 4 convolutional layers stacked together for the first layer, while a common choice is to just make it one convolutional layer with 4 times the output channels. The depth of the network is only 5, even with many layers listed in table 5.\n\nIt uses 1-D convolution across the word dimension (inferred from the feature size in table 5), which means the convolutional layers learn intra-word features for the entire text but not any character-level features. This does not seem to be reasonable.\n\nOverall, the lack of comparisons and the questionable choices for the networks render this work lacking significance to be published in ICLR 2018.']","[-80, -80, -60]","[-30, -60, 20]","[""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer states they 'cannot recommend acceptance' and lists several major issues with the paper, describing it as 'not finished' and the results as 'not remarkable'. There are no positive comments to offset these criticisms. The politeness score is -30 because while the reviewer maintains some professional language, there are instances of blunt criticism and subjective negative opinions. Phrases like 'I do not enjoy the style' and suggesting the authors used 'difficult language to make the manuscript look more impressive' come across as somewhat rude and unprofessional for a peer review. However, the reviewer does provide specific feedback and suggestions for improvement, which prevents the score from being even lower."", ""The sentiment score is -80 because the reviewer explicitly states that it is a 'poor quality paper' and criticizes its clarity and significance. The only slightly positive note is the mention of a potential opportunity, but this is overshadowed by the negative comments. The politeness score is -60 because the language is direct and harsh, using words like 'poor quality' and 'little significance' without any softening phrases or constructive feedback. The reviewer doesn't use explicitly rude language, but the tone is blunt and dismissive, lacking the courtesy typically expected in professional peer reviews."", ""The sentiment score is -60 because while the reviewer acknowledges the interesting idea and clear introduction, they express significant criticisms about the lack of justification, comparisons, and questionable network choices. The overall conclusion that the work lacks significance for publication indicates a predominantly negative sentiment. The politeness score is 20 because the reviewer uses relatively neutral language and acknowledges some positive aspects, but doesn't use overtly polite phrasing. They present criticisms directly but without harsh or rude language, maintaining a professional tone throughout the review.""]"
"['This paper consider a version of boosting where in each iteration only class weights are updated rather than sample weights and apply that to a series of CNNs for object recognition tasks.\n\nWhile the paper is comprehensive in their derivations (very similar to original boosting papers and in many cases one to one translation of derivations), it lacks addressing a few fundamental questions:\n\n- AdaBoost optimises exponential loss function via functional gradient descent in the space of weak learners. It\'s not clear what kind of loss function is really being optimised here. It feels like it should be the same, but the tweaks applied to fix weights across all samples for a class doesn\'t make it not clear what is that really gets optimised at the end.\n- While the motivation is that classes have different complexities to learn and hence you might want each base model to focus on different classes, it is not clear why this methods should be better than normal boosting: if a class is more difficult, it\'s expected that their samples will have higher weights and hence the next base model will focus more on them. And crudely speaking, you can think of a class weight to be the expectation of its sample weights and you will end up in a similar setup.\n- Choice of using large CNNs as base models for boosting isn\'t appealing in practical terms, such models will give you the ability to have only a few iterations and hence you can\'t achieve any convergence that often is the target of boosting models with many base learners.\n- Experimentally, paper would benefit with better comparisons and studies: 1) state-of-the-art methods haven\'t been compared against (e.g. ImageNet experiment compares to 2 years old method) 2) comparisons to using normal AdaBoost on more complex methods haven\'t been studied (other than the MNIST) 3) comparison to simply ensembling with random initialisations.\n\nOther comments:\n- Paper would benefit from writing improvements to make it read better.\n- ""simply use the weighted error function"": I don\'t think this is correct, AdaBoost loss function is an exponential loss. When you train the base learners, their loss functions will become weighted.\n-  ""to replace the softmax error function (used in deep learning)"": I don\'t think we have softmax error function', 'In conventional boosting methods, one puts a weight on each sample. The wrongly classified samples get large weights such that in the next round those samples will be more likely to get right.  Thus the learned weak learner at this round will make different mistakes.\nThis idea however is difficult to be applied to deep learning with a large amount of data. This paper instead designed a new boosting method which puts large weights on the category with large error in this round.  In other words samples in the same category will have the same weight \n\nError bound is derived.  Experiments show its usefulness though experiments are limited\n', 'This paper applies the boosting trick to deep learning. The idea is quite straightforward, and the paper is relatively easy to follow. The proposed algorithm is validated on several image classification datasets.\n\nThe paper is its current form has the following issues:\n1. There is hardly any baseline compared in the paper. The proposed algorithm is essentially an ensemble algorithm, there exist several works on deep model ensemble (e.g., Boosted convolutional neural networks, and Snapshot Ensemble) should be compared against.\n2. I did not carefully check all the proofs, but seems most of the proof can be moved to supplementary to keep the paper more concise.\n3. In Eq. (3), \\tilde{D} is not defined.\n4. Under the assumption $\\epsilon_t(l) > \\frac{1}{2\\lambda}$, the definition of $\\beta_t$ in Eq.8 does not satisfy $0 < \\beta_t < 1$.  \n5. How many layers is the DenseNet-BC used in this paper? Why the error rate reported here is higher than that in the original paper?\nTypo: \nIn Session 3 Line 7, there is a missing reference.\nIn Session 3 Line 10, “1,00 object classes” should be “100 object classes”.\nIn Line 3 of the paragraph below Equation 5, “classe” should be “class”.\n']","[-50, 20, -20]","[20, 0, 50]","[""The sentiment score is -50 because the review is predominantly critical, pointing out several fundamental issues with the paper and suggesting areas for improvement. However, it's not entirely negative as it acknowledges the paper's comprehensive derivations. The politeness score is 20 because while the reviewer doesn't use overtly polite language, they maintain a professional and constructive tone throughout. They use phrases like 'paper would benefit from' and 'it's not clear' rather than harsh or dismissive language. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's novel approach to boosting in deep learning and mentions that experiments show its usefulness. However, the reviewer also notes that the experiments are limited, which tempers the positive sentiment. The politeness score is neutral (0) as the review is straightforward and factual, without using particularly polite or impolite language. The reviewer simply states observations and critiques without embellishment or harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is straightforward and easy to follow, they list several issues and areas for improvement. The reviewer points out lack of baselines, suggests moving proofs to supplementary material, and identifies mathematical and typographical errors. These criticisms outweigh the initial positive comments.\n\nThe politeness score is moderately positive (50) because the reviewer uses neutral, professional language throughout. They begin with positive aspects before moving to criticisms, which is a polite approach. The issues are presented as factual observations rather than harsh judgments. The reviewer also uses phrases like 'I did not carefully check' which shows a degree of humility. However, the review doesn't go out of its way to be overly polite or encouraging, maintaining a professional, matter-of-fact tone.""]"
"[""This paper describes an attempt of improving information flow in deep networks (but is used and tested here with seq2seq models although it is reality unrelated to seq2seq models per se). Slightly different from Resnet the information flow is improved by not just adding the outputs from previous layers but instead concatenating the outputs from previous layers with the current outputs. The authors claim better convergence speed and better results for a similar number of parameters although the differences seems to be in the noise.  \n\nOverall this is an OK technique but in my opinion not really novel enough to justify a whole paper about it as it seems more like a relatively minor architecture tweak. The results seem to indicate that there were some problems with getting deeper networks to work for the baseline (why is in Table 3 baseline-6L worse than baseline-4L?) for which the reason could be a multitude of issues probably related to hyper-parameter tuning. What is also missing is a an analysis of the negative consequences of this technique -- for example, doesn't the number of parameters increase with the depth of the network because of the concatenation? Also, it would have been good to see more experiments with smaller baseline networks as well to match the smaller DenseNet networks in Table 1 and 2. Finally, the writing of the paper could be improved a lot: The basic idea is not well described (however, many times repeated) and the grammar is often wrong and also there are some typos. "", ""This work proposes to densely connected layers to RNNs by concatenating previously constructed layers together as an input to the current layer. In addition, attention context is computed for each layer, then, combined together as a single context. Experimental results on English-French and English-German translation tasks and text summarization show comparable performance to a conventional non-densely connected layers with few number of parameters.\n\nMotivation is clear in that it applies the densely connected networks in vision to texts and the gains achieved by smaller number of parameters look reasonable. However I have some concerns to this paper.\n\n- It is a combination of two techniques, dense connections and multiple attention and it is not clear where the actual gain come from. I'd expect more ablation studies by isolating the effects of dense connection and the use of multiple attention mechanisms.\n\n- It is not clear why the experiments for dense sticked to a particular hidden size, e.g., 256 for machine translation, and varies only the number of layers. Do you have experiments by fixing the number of layers and varying the hidden size?\n\nOther comment:\n\n- Section 3: sequence-to=sequence -> sequence-to-sequence\n\n- It is not clear why the concatenation of all layers is not experimented which is mentioned in section 3.2. Memory problem? "", 'The article proposes to use dense skip-connections on the ""vertical"" (between-layers) connections of recurrent networks. Moreover, the article proposes to use separate attention-heads that run on the outputs of each encoder\'s layer, with each attention selecting other regions in the input to attend to.\n\nThe experiments demonstrate that the changes yield small BLEU score improvements on translation and summarization tasks.\n\nI am not convinced by the presented results for the following reasons:\n1) the paper introduces two concepts - the dense skip-connections and the multi-head attention. Experiments only show their joint impact, yet claims are made about the effectiveness of the skip-connections - maybe what\'s helping is the multi-head attention?\n2) the results suggest that deeper model are better, with the densely connected networks being up to twice deeper than the baselines. What happens for deeper and narrower baselines that have a similar number of parameters?\n3) looking at the training curves (thanks for including them), the densely connected model seems to converge faster by annealing the learning faster (I treat the ""jumps"" in the training curves as signs of learning rate anneal). Maybe this is what helps? I know the authors use an automaton to anneal the learning rate, but maybe the impact of learning rates should be evaluated?\n\nQuality:\nGood\n\nClarity:\nThe paper is clearly written.\n\nOriginality:\nThe addition of dense connections to recurrent networks is trivial.\n\n\nPros&cons\n+ the proposed additions (dense skip connections) and multi-head attentions yield performance improvements\n- the impact of the two contributions is not disentangled in the paper\n- the two contributions are fairly obvious']","[-30, -20, -30]","[20, 60, 50]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges that the technique is 'OK', they express several criticisms. They state that the work is 'not really novel enough to justify a whole paper', point out potential issues with the baseline results, and mention missing analyses. The overall tone suggests that the reviewer is not particularly impressed with the work.\n\nThe politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout. They use phrases like 'in my opinion' and 'it would have been good to see' which soften their criticisms. However, the review is not overly polite, as it directly states shortcomings without much sugar-coating. The reviewer also points out issues with the writing quality, which is less polite but still expressed in a professional manner."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Motivation is clear', 'gains achieved by smaller number of parameters look reasonable'), they express several concerns and request additional experiments. This indicates a somewhat critical stance. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions ('I'd expect', 'Do you have experiments...?'), and acknowledges positive aspects before presenting concerns. The reviewer also provides constructive feedback and specific recommendations for improvement, which is considerate and helpful."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('small BLEU score improvements', 'paper is clearly written'), they express significant skepticism about the results and methodology. The phrase 'I am not convinced' and the list of concerns indicate a generally negative sentiment. However, it's not extremely negative as they do recognize some merits.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I am not convinced' rather than more harsh language, and they acknowledge positive aspects alongside their criticisms. The reviewer also thanks the authors for including training curves, which is a polite gesture. While not overly warm, the language is consistently courteous and constructive.""]"
"['While the idea is novel and I do agree that I have not seen other works along these lines there are a few things that are missing and hinder this paper significantly.\n\n1. There are no quantitative numbers in terms of accuracy improvements, overhead in computation in having two networks.\n2. The experiments are still at the toy level, the authors can tackle more challenging datasets where sampling goes from easy to hard examples like birdsnap. MNIST, FashionMNIST and CIFAR-10 are all small datasets where the true utility of sampling is not realized. Authors should be motivated to run the large scale experiments.\n\n', ""The authors purpose a method for creating mini batches for a student network by using a second learned representation space to dynamically selecting  examples by their 'easiness and true diverseness'. The framework is detailed and results on MNIST, cifar10 and fashion-MNIST are presented. The work presented is novel but there are some notable omissions: \n - there are no specific numbers presented to back up the improvement claims; graphs are presented but not specific numeric results\n- there is limited discussion of the computational cost of the framework presented \n- there is no comparison to a baseline in which the additional learning cycles used for learning the embedding are used for training the student model.\n- only small data sets are evaluated. This is unfortunate because if there are to be large gains from this approach, it seems that they are more likely to be found in the domain of large scale problems, than toy data sets like mnist. \n\n**edit\nIn light of the changes made, and in particular the performance gains achieved on CIFAR-100, i have increased my ratting from a 4 to a 6"", ""(Summary)\nThis paper is about learning a representation with curriculum learning style minibatch selection in an end-to-end framework. The authors experiment the classification accuracy on MNIST, FashionMNIST, and CIFAR-10 datasets.\n\n(Pros)\nThe references to the deep metric learning methods seem up to date and nicely summarizes the recent literatures.\n\n(Cons)\n1. The method lacks algorithmic novelty and the exposition of the method severely inhibits the reader from understand the proposed idea. Essentially, the method is described in section 3. First of all, it's not clear what the actual loss the authors are trying to minimize. Also, \\min_v E(\\theta, v; \\lambda, \\gamma) is incorrect. It looks to me like it should be E \\ell (...) where \\ell is the loss function. \n\n2. The experiments show almost no discernable practical gains over 'random' baseline which is the baseline for random minibatch selection.\n\n(Assessment)\nClear rejection. The method is poorly written, severely lacks algorithmic novelty, and the proposed approach shows no empirical gains over random mini batch sampling.""]","[-50, 20, -80]","[20, 50, -20]","[""The sentiment score is -50 because while the reviewer acknowledges the novelty of the idea, they express significant concerns about missing elements and limitations of the study. The phrase 'hinder this paper significantly' indicates a strong negative sentiment. However, it's not entirely negative as they do recognize the novelty of the work. The politeness score is 20 because the reviewer uses relatively neutral language and offers constructive criticism. They avoid harsh or rude phrasing, instead using phrases like 'there are a few things that are missing' and offering specific suggestions for improvement. The tone is professional and respectful, albeit direct in pointing out shortcomings."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty of the work and mentions increasing their rating from 4 to 6. However, they also point out several limitations and omissions, which tempers the positivity. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language without harsh criticism. They offer constructive feedback and suggestions for improvement rather than outright dismissal. The reviewer also acknowledges the authors' efforts to address previous concerns, which adds to the politeness."", ""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer states 'Clear rejection' and points out several major flaws in the paper, including lack of novelty, poor writing, and no empirical gains. The only positive aspect mentioned is the up-to-date references. The politeness score is -20 because while the language is not overtly rude, it is quite blunt and critical. Phrases like 'severely lacks' and 'poorly written' are harsh criticisms without much softening language. The reviewer does not attempt to balance negative feedback with positive points or use polite phrasing to soften the critique.""]"
"['The authors argue that ""good"" classifiers naturally represent the classes in a classification as well-separated manifolds, and that adversarial examples are low-confidence examples lying near to one of these manifolds. The authors suggest ""fixing"" adversarial examples by projecting them back to the manifold, essentially by finding a point near the adversarial example that has high confidence.\n\nThere are numerous issues here, which taken together, make the whole story pretty unconvincing.\n\nThe term ""manifold"" is used very sloppily. To be fair, this is unfortunately common in modern machine learning. An actual manifold is a specific mathematical structure with specific properties. In ML, what is generally hypothesized is that the data (often per class) lives ""near"" to some ""low-dimensional"" structure. In this paper, even the low-dimensionality isn\'t used --- the ""manifold assumption"" is used as a stand-in for ""the regions associated with different classes are well-separated."" (This is partially discussed in Section 6, where the authors point out correctly that the same defense as used here could be used with a 1-nn model.) This is fine as far as it goes, but the paper refs Basri & Jacobs 2016 multiple times as if it says anything relevant about this paper: Basri & Jacobs is specifically about the ability of deep nets to fit data that falls on (actual, mathematical) manifolds. This reference doesn\'t add much to the present story.\n\nThe essential argument of the paper rests on the ""Postulate: (A good model) F is confident on natural points drawn from the manifolds, but has low confidence on points outside of the manifolds."" \n\nThis postulate is sloppy and speculative. For instance, taken in its strong form, if believe the postulate, then a good model:\n1. Can classify all ""natural points"" from all classes with 100% accuracy.\n2. Can detect adversarial points with 100% accuracy because all high-confidence points are correct classifications and all low-confidence points are adversarial.\n3. All adversarial examples will be low-confidence.\n\nPoint 1 makes it clear that no good model F fully satisfying the postulate exists --- models never achieve 100% accuracy on difficult real-world distributions. But the method for dealing with adversarial examples seems to require Points 2 and 3 being true.\n\nTo be fair, the paper more-or-less admits that how true these points are is not known and is important. Nevertheless, I think this paper comes pretty close to arguing something that I *think* is not true, and doesn\'t do much to back up its argument. Because of the quality of the writing (generally sloppy), it\'s hard to tell, but I believe the authors are basically arguing that:\na. You can generally easily detect adversarial points because they are low confidence.\nb. If you go through a procedure to find a point near your adversarial point that is high-confidence, you\'ll get the ""correct"" (or perhaps ""original"") class back.\n\nI think b follows from a, but a is extremely suspect. I do not personally work in adversarial examples, and briefly looking at the literature, it seems that most authors *do* focus on how something is classified and not its confidence, but I don\'t think it\'s *that* hard to generate high-confidence adversarial examples. Early work by Goodfellow et al. (""Explaining and Harnessing Adversarial Examples"", Figure 1, shows an example where the incorrect classification has very high confidence. The present paper only uses Carlini-Wagner attacks. From a read of Carlini-Wagner, it seems they are heavily concerned with finding *minimal* perturbations to achieve a given misclassification; this will of course produce low-confidence adversaries, but I see no reason why this is a general property of all adversarial examples.\n\nThe experiments are weak. I applaud the authors for mentioning the experiments are very preliminary, but that doesn\'t make them any less weak. \n\nWhat are we to make of the one image discussed at the end of Section 5 and shown in Figure 1? The authors note that the original image gives low-confidence for the correct class. (Does this mean that the classifier isn\'t ""good""? Is it evidence against some kind of manifold assumption?) The authors note the adversarial category has significantly higher confidence, and say ""in this case, it seems that it is the vagueness of the signals/data that lead to a natural difficulty."" But the signals and data are ALWAYS vague. If they weren\'t, machine learning would be easy. This paper proposes something, looks at a tiny number of examples, and already finds a counterexample to the theory. What\'s the evidence *for* the theory? \n\nA lot of writing is given over to how this method is ""semantic"", and I just don\'t buy it. The connection to manifolds is weak. The basic argument here is really ""(1) If our classifiers produce smooth well-separated high-confidence regions, (2) then we can detect adversaries because they\'re low-confidence, and (3) we can correct adversaries by projecting them back to high-confidence."" (1) seems vastly unlikely to me based on all my experience: neural nets often get things wrong, they often get things wrong with high confidence, and when they\'re right, the confidence is at least sometimes low. The authors use a sloppy postulate about good models and so could perhaps argue I\'ve never seen a good model, but the methods of this paper require a good model. (2) seems to follow logically from (1). (3) is also suspect --- perturbations which are *minimal* can be corrected as this paper does (and Carlini-Wagner attacks are minimal by design), but there\'s no reason to expect general perturbations to be minimal.\n\nThe writing is poor throughout. It\'s generally readable, but the wordings are often odd, and sometimes so odd it\'s hard to tell what was meant. For instance, I spent awhile trying to decide whether the authors assumed common classifiers are ""good"" (according to the postulate) or whether this paper was about a way to *make* classifiers good (I eventually decided the former).', '\n1) Summary\nThis paper proposes a new approach to defending against adversarial attacks based on the manifold assumption of natural data. Specifically, this method takes inputs (possibly coming from an adversarial attack), project their semantic representation into the closest data class manifold. The authors show that adversarial attack techniques can be with their algorithm for attack prevention. In experiments, they show that using their method on top of a base model achieves perfect success rate on attacks that the base model is vulnerable to while retaining generalizability.\n\n\n2) Pros:\n+ Novel/interesting way of defending against adversarial attacks by taking advantage of the manifold assumption.\n+ Well stated formulation and intuition.\n+ Experiments validate the claim, and insightful discussion about the limitations and advantages of the proposed method.\n\n3) Cons:\nNumber of test examples used too small:\nAs mentioned in the paper, the number of testing points is a weakness. There needs to be more test examples to make a strong conclusion about the method’s performance in the experiments.\n\nComparison against other baselines:\nEven though the method proposes a new approach for dealing with adversarial attacks using Madry et al. as base model, it would be useful to the community to see how this method works with other base models.\n\nAlgorithm generalizability:\nAs mentioned by the authors, their method depends on assumptions of the learned embeddings by the model being used. This makes the method less attractive for people that may be interested in dealing with adversarial examples in, for example, reinforcement learning problems. Can the authors comment on this?\n\nAdditional comments:\nThe writing needs to be polished.\n\n\n4) Conclusion:\nOverall, this is a very interesting work on how to deal with adversarial attacks in deep learning, while at the same time, it shows encouraging results of the application of the proposed method. The experimental section could improve a little bit in terms of baselines and test examples as previously mentioned, and also the authors may give some comments on if there is a simple way to make their algorithm not depend on assumptions of the learned embeddings.\n', 'The manuscript proposes two objective functions based on the manifold assumption as defense mechanisms against adversarial examples. The two objective functions are based on assigning low confidence values to points that are near or off the underlying (learned) data manifold while assigning high confidence values to points lying on the data manifold. In particular, for an adversarial example that is distinguishable from the points on the manifold and assigned a low confidence by the model, is projected back onto the designated manifold such that the model assigns it a high confidence value. The authors claim that the two objective functions proposed in this manuscript provide such a projection onto the desired manifold and assign high confidence for these adversarial points. These mechanisms, together with the so-called shell wrapper around the model (a deep learning model in this case) will provide the desired defense mechanism against adversarial examples.\n\nThe manuscript at the current stage seems to be a preliminary work that is not well matured yet. The manuscript is overly verbose and the arguments seem to be weak and not fully developed yet. More importantly, the experiments are very preliminary and there is much more room to deliver more comprehensive and compelling experiments.']","[-80, 60, -50]","[-20, 80, 0]","[""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer uses phrases like 'numerous issues', 'pretty unconvincing', 'sloppy and speculative', and 'experiments are weak'. They consistently point out flaws in the paper's arguments and methodology without offering many positive comments. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical. They use phrases like 'sloppy' multiple times and describe the writing as 'poor throughout'. However, they do occasionally soften their criticism with phrases like 'To be fair' and 'I applaud the authors for mentioning...', which prevents the score from being lower."", ""The sentiment score is 60 (positive) because the review begins with a neutral summary, followed by a list of pros that highlight the paper's novelty, well-stated formulation, and validated claims. While there are some cons mentioned, they are presented as constructive criticism rather than major flaws. The overall conclusion is positive, describing the work as 'very interesting' with 'encouraging results'. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms as suggestions for improvement. Phrases like 'Can the authors comment on this?' and 'The authors may give some comments' demonstrate a courteous approach to requesting additional information or clarification."", ""The sentiment score is -50 because the review expresses a generally negative view of the manuscript, describing it as 'preliminary work that is not well matured yet,' 'overly verbose,' with 'weak' and 'not fully developed' arguments, and 'very preliminary' experiments. However, it's not entirely negative as it acknowledges the proposed mechanisms and their potential benefits. The politeness score is 0 (neutral) because the reviewer maintains a professional tone without being particularly polite or rude. They express criticism directly but without using harsh language or personal attacks. The reviewer focuses on the content of the manuscript rather than the authors themselves, which is appropriate for a peer review.""]"
"[""The authors propose investigating regions of the the parameter space under which the activations (over the entire training data set) remain unchanged.  They conjecture, and then attempt to argue for a simple network, that, over these regions, the loss function exhibits nice properties:  all local minima are global minima, all other local optima are saddle points, and the function is neither convex nor concave on these regions.  The proof of this statement seems relatively straightforward and appears to be correct.  Unfortunately it only applies to a special case.  Second, the authors argue that the loss function for their simple network has poor local minima.  Finally, the authors conclude with a simple set of experiments exploring the accuracy of random activations.  Overall, I found the main idea of the paper relatively straightforward, but the presentation is a bit awkward in places.\n\nI think the work is heading in an interesting direction, but I found it somewhat incremental.  It's nice to know that the loss function (squared loss in this case) has these properties, but as there are exponentially many regions corresponding to the different activations, it is unclear what the practical consequences of these theoretical observations are.  Could the authors elaborate on this?\n\nAnother question:  is it really true that the non-differentiability of the functions involved creates significant issues in practice  (not theoretically) - isn't the set of all points with this property of measure zero?\n"", ""This paper proposes to study the loss surfaces of neural networks with ReLU activations by viewing the loss surface as a sum of piecewise linear functions at each point in parameter space, i.e. one piecewise linear function per sample. The main result is that every local minimum of the total surface is a global minimum of the region where the ReLU activations corresponding to each sample do not change. \n\nQuality:\n- The paper's claims are correct, however most of the theoretical results follow easily from the definitions and I don't see how they are very useful. What is interesting about other recent theoretical works, which show (subject to various assumptions) that local minima are roughly equivalent to the global minimum, is that they compare local minima across all regions of the parameter space and show they are similar. Here, the results only hold within each local region of the space, and they don't say anything about how the global minima in different regions compare in terms of loss. Knowing that a local minumum is a global minimum of a local region is not very useful because the global minimum of that local region could still be much worse than that of the other regions. \n\n\nClarity:\n- The main claims/results in the paper are not stated very clearly, and the authors are not clear about what the contributions of the paper are or why they are useful. \n\nOriginality:\n- Studying loss surfaces by viewing ReLU networks as piecewise linear functions is by now standard. \n\nSignificance:\n- It is not clear how these results may be applied in practice or open new directions for future theoretical work. \n\n"", 'This paper attempts to extend analytical results pertaining to the loss surface of linear networks to a nonlinear network with a single hidden ReLU layer.  Unfortunately though, at this point I feel that the theoretical results, which constitute the majority of the paper, are of limited novelty and/or significance.  However, I still remain very open to counterarguments to this opinion and the points raised below.\n\nFirst, I don\'t believe that Lemma 2.2 is precisely true, at least as currently stated.  In particular, it would appear that L_f could have a differentiable local minima that is only a saddle point in L_gA.  For example, if there is a differentiable valley in L_f that terminates on the boundary of an activation region, then this phenomena could occur, since a local-minima-creating boundary in L_f might just lead to a saddle point in L_gA.  Regardless, the basic premise of this result is quite straightforward anyway.\n\nTurning to Lemma 2.3 and 2.4, I don\'t understand the relevance of these results.  Where are they needed later or applied?  Additionally, Theorem 2.5 is very related to results already proven for linear networks in earlier work (Kawaguchi, 2016), so there is little novelty here.\n\nThere also seem to be issues with Corollary 2.7, which as an aggregation result can be viewed as the main contribution of the paper.  Part (1) of this corollary is obvious.  Part (2) depends on Lemma 2.2, which as stated previously may be problematic.  Most seriously though, Part (3) only considers critical points (i.e., derivative equal to zero), not local minima occurring at non-differentiable locations.  To me this greatly mutes the value of this result, and the contribution of the paper overall, because local minimum are *very* likely to occur on the boundary between activation regions at non-differentiable points (e.g. as in Figure 2).  I therefore don\'t understand the utility of only considering the differentiable local minima.\n\nOverall though, the main point that within areas of fixed activation the network behaves much like a linear network (with all local minima also global minima when constrained within each region), is not especially noteworthy, because it provides no pathway for comparing minima from different activation regions, which is the main problem to begin with.\n\nBeyond this, the paper makes a few less-technical observations regarding bad local minima.  For example, in Section 3.1 the argument is made that the linear region created when all activations are equal to one, will have a local minimum, and this minimum might be suboptimal.  However, these arguments pertain to the surrogate function L_gA, and if the minima to L_gA occurs on the boundary to another activation region, then this solution might not be a local minima to L_f, the real objective we care about.  Am I missing something here?\n\nAs for Section 4.2, the paper needs to do a better job of explaining exactly what is been shown in Table 2.  I can maybe guess, but it is not at all clear what the accuracy percentage is referring to, nor precisely how rich and random minima are computed.  Also, the assumption that P(a = 1) = P(a = 0) = 0.5 is not very realistic, although admittedly this type of simplification is sometimes adopted in the literature.\n\nMinor comment:\n* Near the beginning in the introduction, it is claimed that ""the vanishing gradient problem has been solved by using rectified linear units.""  This is not actually true, and portends problematic claims later in the paper.']","[20, -60, -60]","[60, 0, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting direction of the work and the correctness of the proof, but also points out limitations and asks for elaboration. The overall tone is constructive rather than dismissive. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and framing criticisms as questions or suggestions for improvement. The reviewer avoids harsh or dismissive language, instead using phrases like 'I found' and 'Could the authors elaborate on this?' which maintain a polite and professional tone."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the paper's claims are correct but not very useful, and that the results are limited in scope and practical application. They also mention that the main claims are not stated clearly and the contributions are not well-explained. The originality is questioned, and the significance is doubted. These criticisms outweigh the initial acknowledgment of correctness, resulting in a negative sentiment.\n\nThe politeness score is 0 (neutral) because the reviewer maintains a professional and objective tone throughout. They do not use overtly polite language or phrases, but also avoid any rude or disrespectful comments. The criticism is presented in a straightforward manner without personal attacks or overly harsh language. The reviewer focuses on the content and quality of the paper rather than making subjective judgments about the authors."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's novelty, theoretical results, and overall contribution. They use phrases like 'limited novelty and/or significance', 'little novelty here', and 'not especially noteworthy'. However, they do mention being 'very open to counterarguments', which slightly mitigates the negative sentiment. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use polite phrases like 'I feel that', 'I don't understand', and 'Am I missing something here?', which soften the criticism. They also offer specific, constructive feedback, which is a polite approach to reviewing. However, the overall critical nature of the review prevents a higher politeness score.""]"
"['This paper addresses the well-known stability problem encountered when training GANs. As many other papers, they suggest adding a regularization penalty on the discriminator which penalizes the gradient with respect to the data, effectively linearizing the data manifold.\n\nRelevance: Although I think some of the empirical results provided in the paper are interesting, I doubt the scientific contribution of this paper is significant. First of all, the penalty the author suggest is the same as the one suggest by Gulrajani for Wasserstein GAN (there the motivation behind this penalty comes from the optimal transport plan). In this paper, the author apply the same penalty to the GAN objective with the alternative update rule which is also a lower-bound for the Wasserstein distance.\n\nJustification: The authors justify the choice of their regularization saying it linearizes the objective along the data manifold and claim it reduces the number of non-optimal fixed points. This might be true in the data space but the GAN objective is optimized over the parameter space and it is therefore not clear to me their argument hold w.r.t to the network parameters. Can you please comment on this?\n\nRegularizing the generator: Can the authors motivate their choice for regularizing the discriminator only, and not the generator? Following their reasoning of linearizing the objective, the same argument should apply to the generator.\n\nComparison to existing work: This is not the first paper that suggests adding a regularization. Given that the theoretical aspect of the paper are rather weak, I would at least expect a comparison to existing regularization methods, e.g.\nStabilizing training of generative adversarial networks through regularization. NIPS, 2017\n\nChoice of hyper-parameters: The authors say that the suggested value for lambda is 10. Can you comment on the choice of this parameter and how it affect the results? Have you tried  annealing lambda? This is a common procedure in optimization (see e.g. homotopy or continuation methods).\n\nBogonet score: I very much like the experiment where the authors select 100 different architectures to compare their method against the vanilla GAN approach. I here have 2 questions:\n- Did you do a deeper examination of your results, e.g. was there some architectures for which none of the method performed well?\n- Did you try to run this experiment on other datasets?\n', 'This paper contains a collection of ideas about Generative Adversarial Networks (GAN) but it is very hard for me to get the main point of this paper. I am not saying ideas are not interesting, but I think the author needs to choose the main point of the paper, and should focus on delivering in-depth studies on the main point.\n\n1. On the game theoretic interpretations \n\nThe paper, Generative Adversarial Nets, NIPS 2014, already presented the game theoretic interpretations to GANs, so it\'s hard for me to think what\'s new in the section. Best response dynamics is not used in the conventional GAN training, because it\'s very hard to find the global optimal of inner minimization and outer maximization.\nThe convergence of online primal-dual gradient descent method in the minimax game is already well-known, but this analysis cannot be applied to the usual GAN setting because the objective is not convex-concave. I found this analysis would be very interesting if the authors can find the toy example when GAN becomes convex-concave by using different model parameterizations and/or different f-divergence, and conduct various studies on the convergence and stability on this problem.\n\nI also found that the hypothesis on the model collapsing has very limited connection to the convex-concave case. It is OK to form the hypothesis and present an interesting research direction, but in order to make this as a main point of the paper, the author should provide more rigorous arguments or experimental studies instead of jumping to the hypothesis in two sentences. For example, if the authors can provide the toy example where GAN becomes convex-concave vs. non-convex-concave case, and how the loss function shape or gradient dynamics are changing, that will provide very valuable insights on the problem. \n\n2. DRAGAN\n\nAs open commenters pointed out, I found it\'s difficult to find why we want to make the norm of the gradient to 1.\nWhy not 2? why not 1/2? Why 1 is very special?\nIn the WGAN paper, the gradient is clipped to a number less than 1, because it is a sufficient condition to being 1-Lipshitz, but this paper provides no justification on this number.\nIt\'s OK not to have the theoretical answers to the questions but in that case the authors should provide ablation experiments. For example, sweeping gradient norm target from 10^-3, 10^-2, 10^-1, 1.0, 10.0, etc and their impact on the performance.\nAlso scheduling regularization parameter like reducing the size of lambda exponentially would be interesting as well.\nMost of those studies won\'t be necessary if the theory is sound. However, since this paper does not provide a justification on the magic number ""1"", I think it\'s better to include some form of ablation studies.\n\nNote that the item 1 and item 2 are not strongly related to each other, and can be two separate papers. I recommend to choose one direction and provide in-depth study on one topic. Currently, this paper tries to present interesting ideas without very deep investigations, and I cannot recommend this paper to be published.\n', ""Summary\n========\nThe authors present a new regularization term, inspired from game theory, which encourages the discriminator's gradient to have a norm equal to one. This leads to reduce the number of local minima, so that the behavior of the optimization scheme gets closer to the optimization of a zero-sum games with convex-concave functions.\n\n\nClarity\n======\nOverall, the paper is clear and well-written. However, the authors should motivate better the regularization introduced in  section 2.3.\n\n\nOriginality\n=========\nThe idea is novel and interesting. In addition, it is easy to implement it for any GANs since it requires only an additional regularization term. Moreover, the numerical experiments are in favor of the proposed method.\n\n\nComments\n=========\n- Why should the norm of the gradient should to be equal to 1 and not another value? Is this possible to improve the performance if we put an additional hyper-parameter instead?\n\n- Are the performances greatly impacted by other value of lambda and c (the suggested parameter values are lambda = c = 10)?\n\n- As mentioned in the paper, the regularization affects the modeling performance. Maybe the authors should add a comparison between different regularization parameters to illustrate the real impact of lambda and c on the performance.\n\n- GANs performance is usually worse on very big dataset such as Imagenet. Does this regularization trick makes their performance better?\n\n\n\nPost-rebuttal comments\n---------------------------------\n\nI modified my review score, according to the problems raised by Reviewer 1 and 3. Despite the idea looks pretty simple and present some advantages, the authors should go deeper in the analysis, especially because the idea is not so novel.""]","[-20, -60, 50]","[60, 20, 70]","[""Sentiment score: The review starts with a neutral tone, acknowledging the paper's attempt to address a known problem. However, it quickly expresses doubt about the scientific contribution, citing similarities to existing work and questioning the theoretical aspects. This suggests a slightly negative sentiment, hence the score of -20.\n\nPoliteness score: The reviewer maintains a professional and respectful tone throughout. They use polite phrases like 'Can you please comment on this?' and 'I very much like the experiment'. While raising concerns, they do so in a constructive manner, asking for clarifications rather than making outright criticisms. The language is not overly formal or deferential, but it is consistently courteous, warranting a score of 60.\n\nThe scores reflect a review that is slightly critical in content but expressed in a polite and professional manner."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's focus, depth, and justification of ideas. They state it's 'very hard to get the main point' and recommend choosing one direction for in-depth study. The reviewer cannot recommend publication, indicating a negative sentiment. However, they do acknowledge some ideas as 'interesting', preventing an extremely negative score. The politeness score is 20 because the reviewer uses generally respectful language, offering constructive criticism and suggestions for improvement. They avoid harsh personal criticism and use phrases like 'I think' and 'I recommend' to soften their critique. However, the overall tone remains professional rather than overtly polite, hence a moderately positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novelty, clarity, and interesting idea, but also points out areas for improvement and raises some concerns. The initial paragraphs are generally positive, praising the paper's clarity and originality. However, the post-rebuttal comments indicate a downgrade in the reviewer's assessment, suggesting deeper analysis is needed. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. Phrases like 'the authors should motivate better' and 'Maybe the authors should add' are polite ways of suggesting improvements. The reviewer also acknowledges the paper's strengths before presenting criticisms, which is a polite approach to reviewing.""]"
"[""Interesting ideas that extend LSTM to produce probabilistic forecasts for univariate time series, experiments are okay. Unclear if this would work at all in higher-dimensional time series. It is also unclear to me what are the sources of the uncertainties captured.\n\n\nThe author proposed to incorporate 2 different discretisation techniques into LSTM, in order to produce probabilistic forecasts of univariate time series. The proposed approach deviates from the Bayesian framework where there are well-defined priors on the model, and the parameter uncertainties are subsequently updated to incorporate information from the observed data, and propagated to the forecasts. Instead, the conditional density p(y_t|y_{1:t-1|, \\theta}) was discretised by 1 of the 2 proposed schemes and parameterised by a LSTM. The LSTM was trained using discretised data and cross-entropy loss with regularisations to account for ordering of the discretised labels. Therefore, the uncertainties produced by the model appear to be a black-box. It is probably unlikely that the discretisation method can be generalised to high-dimensional setting?\n\nQuality: The experiments with synthetic data sufficiently showed that the model can produce good forecasts and predictive standard deviations that agree with the ground truth. In the experiments with real data, it's unclear how good the uncertainties produced by the model are. It may be useful to compare to the uncertainty produced by a GP with suitable kernels. In Fig 6c, the 95pct CI looks more or less constant over time. Is there an explanation for that?\n\nClarity: The paper is well-written. The presentations of the ideas are pretty clear.\n\nOriginality: Above average. I think the regularisation techniques proposed to preserve the ordering of the discretised class label are quite clever.\n\nSignificance: Average. It would be excellent if the authors can extend this to higher dimensional time series.\n\nI'm unsure about the correctness of Algorithm 1 as I don't have knowledge in SMC."", 'The papers proposes a recurrent neural network-based model to learn the temporal evolution of a probability density function. A Monte Carlo method is suggested for approximating the high dimensional integration required for multi-step-ahead prediction.\n\nThe approach is tested on two artificially generated datasets and on two real-world datasets, and compared with standard approaches such as the autoregressive model, the Kalman filter, and a regression LSTM.\n\nThe paper is quite dense and quite difficult to follow, also due to the complex notation used by the authors.\n\nThe comparison with other methods is very week, the authors compare their approach with two very simple alternatives, namely a first-order autoregressive mode and the Kalman filter.  More sophisticated should have been employed.', ""This work proposes an LSTM based model for time-evolving probability densities. The model does not assume an explicit prior over the underlying dynamical systems, instead only uncertainty over observation noise is explicitly considered. Experiments results are good for given synthetic scenarios but less convincing for real data.  \n\nClarity: The paper is well-written. Some notations in the LSTM section could be better explained for readers who are unfamiliar with LSTMs. Otherwise, the paper is well-structured and easy to follow.\n\nOriginality: I'm not familiar with LSTMs, it is hard for me to judge the originality here.\n\nSignificance: Average. The work would be stronger if the authors can extend this to higher dimensional time series. There are also many papers on this topic using Gaussian process state-space (GP-SSM) models where an explicit prior is assumed over the underlying dynamical systems. The authors might want to comment on the relative merits between GP-SSMs and DE-RNNs.\n\nThe SMC algorithm used is a sequential-importance-sampling (SIS) method. I think it's correct but may not scale well with dimensions.""]","[20, -30, 20]","[50, 20, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges 'interesting ideas' and 'clever' regularization techniques, while also noting that the experiments are 'okay' and the paper is 'well-written'. However, they express concerns about the applicability to higher-dimensional time series and the sources of uncertainties, which tempers the positivity. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions without harsh or dismissive comments. They use phrases like 'It may be useful to' and 'I'm unsure about' which maintain a polite tone while expressing concerns or suggestions."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the paper's proposal and testing, they also point out significant issues. The reviewer states that the paper is 'quite dense and quite difficult to follow' and criticizes the comparison with other methods as 'very weak'. These criticisms outweigh the neutral description of the paper's content, resulting in a negative sentiment. The politeness score is slightly positive (20) because the reviewer uses professional and neutral language throughout, avoiding harsh or rude expressions. They use phrases like 'quite difficult' instead of more negative alternatives, and offer constructive criticism rather than outright dismissal. However, the politeness is not extremely high as the review is direct in its criticisms without much softening language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges good experimental results for synthetic scenarios and praises the paper's clarity and structure. However, they also express some reservations about the real data results and suggest improvements. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions without harsh criticism. They acknowledge their own limitations in judging originality and use phrases like 'The work would be stronger if...' rather than direct criticism. The tone is professional and courteous throughout.""]"
"['This paper presents a set of regularizers which aims for manipulating the statistical properties like sparsity, variance and covariance. While some of the proposed regularizers are applied to weights, most are applied to hidden representations of neural networks. Class-wise regularizations are also investigated for the purpose of fine-grained control of statistics within each class. Experiments over MNIST, CIFAR10 and CIFAR100 demonstrate the usefulness of this technique.\n\nThe following related work also studied the regularizations on hidden representations which are motivated from clustering perspective and share some similarities with the proposed one. It would be great to discuss the relationship.\n\nLiao, R., Schwing, A., Zemel, R. and Urtasun, R., 2016. Learning deep parsimonious representations. NIPS.\n\nPros:\n(1) The paper is clearly written.\n\n(2) The visualizations of hidden activations are very helpful in understanding the effect of different regularizers.\n\n(3) The proposed regularizations are simple and computationally efficient.\n\nCons:\n(1) The novelty of the paper is limited as most of the proposed regularizers are more or less straightforward modifications over DeCov.\n\n(2) When we manipulate the statistics of representations we aim for something, like improving generalization, interpretability. But as pointed out by authors, improvement of generalization performance is not the main focus. I also do not find significant improvement from all experiments. Then the question is what is the main benefit of manipulating various statistics? \n\nI have an additional question as below:\nIn measuring the ratio of dead units, I notice authors using the criterion of “not activated on all classes”. However, do you check this criterion over the whole epoch or just some mini-batches?\n\nOverall, I think the paper is technically sound. But the novelty and significance are a bit unsatisfactory. I would like to hear authors’ feedback on the issues I raised.\n', ""This is a well-written paper which starts on a good premise: DNNs learn representations; good representations are good for prediction; they can be seen as codes of the input information, so let us look at coding/communication/information theory for inspiration. This is fine and recent work from N Tishby's group develop some intriguing observations from this. But this paper doesn't follow through the information/communication story in any persuasive way. All that is derived is that it may be a good idea to penalise large variations in the representation -- within-class variations, in particular. The paper does a good job of setting up and comparing empirical performance of various regularizers (penalties on weights and penalties on hidden unit representations) and compares results against a baseline. Error rates (on MNIST, for example) are very small (baseline 3% versus the best in this paper 2.43%), but, if I am right, these are results quoted on a single test set. The uncertainties are over different runs of the algorithm and not over different partitions of the data into training and test sets. I find this worrying -- is there a case (in these datasets that have been around for so long and so widely tested), there is a commmunity-wide hill climbing on the test set -- reporting results that just happen to be better than a previous attempt on the specific test set? Is it not time to pool all the data and do cross validation (by training and testing on different partitions) so that we can evaluate the uncertainty in these results more accurarately?"", '1. Summary\nThe authors of the paper compare the learning of representations in DNNs with Shannons channel coding theory, which deals with reliably sending information through channels. In channel coding theory the statistical properties of the coding of the information can be designed to fit the task at hand. With DNNs the representations cannot be designed in the same way. But the representations, learned by DNNs, can be affected indirectly by applying regularization. Regularizers can be designed to affect statistical properties of the representations, such as sparsity, variance, or covariance. The paper extends the regularizers to perform per-class regularization. This makes sense, because, for example, forcing the variance of a representation to go towards zero is undesirable as it would state that the unit always has the same output no matter the input. On the other hand having zero variance for a class is desirable as it means that the unit has a consistent activation for all samples of the same class. The paper compares different regularization techniques regarding their error performance. They find that applying representation regularization outperforms classical approaches such as L1 and L2 weight regularization. They also find, that performing representation regularization on the last layer achieves the best performance. Class-wise methods generally outperform methods that apply regularization on all classes.\n\n2. Remarks\nShannons channel coding theory was used by the authors to derive regularizers, that manipulate certain statistical properties of representations learned by DNNs. In the reviewers opinion, there is no theoretical connection between DNNs and channel theory. For one, DNNs are no channels in the sense that they transmit information. DNNs are rather pipes that transform information from one domain to another, where representations are learned as an intermediate model as the information is being transformed. Noise introduced in the process is not due to a faulty channel but due to the quality of the learned representations themselves. The paper falls short in explaining how DNNs and Shannons channel coding theory fit together theoretically and how they used it to derive the proposed regularizers. Despite the theoretical gap between the two was not properly bridged by the authors, channel coding theory is still a good metaphor for what they were trying to achieve.\nThe authors recognize that there is similar research being done independently by Belharbi et al. (2017). The similarities and differences between the proposed work and Belharbi et al. should be discussed in more detail.\nThe authors conclude that it is unclear which statistical properties of representations are generally helpful when being strengthened. It would be nice if they had derived at least a set of rules of thumb. Especially because none of the regularizers described in the paper only target one specific statistical property but multiple. One good example that was provided, is that L1-rep consistently failed to train on CIFAR-100, because too much sparsity can hurt performance, when having many different classes (100 in this case). These kinds of conclusions will make it easier to transfer the presented theory into practice.\n\n3. Conclusion\nThe comparison between DNNs and Shannons channel coding theory stands on shaky ground. The proposed regularizes are rather simple, but perform well in the experiments. The effect of each regularizer on the statistical properties of the representation and the relations to previous work (especially Belharbi et al. (2017)) should be discussed in more detail. ']","[-20, -20, -20]","[60, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('clearly written', 'helpful visualizations', 'simple and efficient regularizations'), they express concerns about limited novelty and significance. The overall tone suggests the paper is not quite meeting expectations, with phrases like 'novelty is limited' and 'novelty and significance are a bit unsatisfactory'. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. They use polite phrases like 'It would be great to discuss', and 'I would like to hear authors' feedback', which contribute to a courteous tone even while expressing concerns."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is 'well-written' and has a 'good premise', they express significant concerns about the paper's execution and methodology. The reviewer states that the paper 'doesn't follow through the information/communication story in any persuasive way' and raises worries about the statistical validity of the results. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, starting with positive comments and framing criticisms as questions or suggestions rather than direct attacks. They use phrases like 'if I am right' and 'Is it not time to' which soften the critique. The reviewer maintains a professional tone while expressing their concerns."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper, such as the good performance of the proposed regularizers, they also express significant concerns about the theoretical foundation of the work. The reviewer states that the connection between DNNs and Shannon's channel coding theory is not well-established, which is a major criticism. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They acknowledge the authors' efforts and use phrases like 'in the reviewer's opinion' to soften their criticisms. The reviewer also provides specific examples and suggestions for improvement, which is a polite way to offer feedback.""]"
"['This work addresses brain state  decoding (intent to move) based on intra-cranial ""electrocorticography (ECoG) grids"". ECoG signals are generally of much higher quality than more conventional EEG signals acquired on the skalp, hence it appears meaningful to invest significant effort to decode.  \nPreprocessing is only descibed in a few lines in Section 2.1, and the the feature space is unclear (number of variables etc)\n\nLinear discriminants, ""1-state and 2-state"" hidden markov models, and LSTMs are considered for classification (5 classes, unclear if prior odds are uniform). Data involves multiple subjects (4 selected from a larger pool). Total amount of data unclear. ""A validation set is not used due to the limited data size.""  The LSTM setup and training follows conventional wisdom.\n""The model used for our analyses was constructed with 100 hidden units with no performance gain identified using larger or stacked networks.""\nA simplistic but interesting  transfer scheme is proposed amounting to an affine transform of features(??) - the complexity of this transform is unclear.\n\nWhile limited novelty is found in the methodology/engineering - novelty being mainly related to the affine transfer mechanism, results are disappointing.  \nThe decoding performance of the LSTMs does not convincingly exceed that of the simple baselines. \n\nWhen analyzing the transfer mechanism only the LSTMs are investigated and it remains unclear how well trans works.\n\nThere is an interesting visualization (t-SNE) of the latent representations. But very limited discussion of what we learn from it, or how such visualization could  be used to provide neuroscience insights.\n\nIn the discussion we find the claim: ""In this work, we have shown that LSTMs can model the variation within a neural sequence and are a good alternative to state-of-the-art decoders.""  I fail to see how it can be attractive to obtain similar performance with a model of 100x (?) the complexity\n\n\n\n', 'The paper describes an approach to use LSTM’s for finger classification based on ECOG. and a transfer learning extension of which two variations exists. From the presented results, the LSTM model is not an improvement over a basic linear model. The transfer learning models performs better than subject specific models on a subset of the subjects. Overall, I think the problem Is interesting but the technical description and the evaluation can be improved. I am not confident in the analysis of the model. Additionally, the citations are not always correct and some related work is not referenced at all. For the reasons above, I am not willing to recommend the paper for acceptance at his point.\n\nThe paper tackles a problem that is challenging and interesting. Unfortunately, the dataset size is limited. \nThis is common for brain data and makes evaluation much more difficult.\n The paper states that all hyper-parameters were optimized on 75% of subject B data.\nThe actual model training was done using cross-validation. \nSo far this approach seems more or less correct but in this case I would argue that subject B should not be considered for evaluation since its data is heavily used for hyper-parameter optimization and the results obtained on this subject are at risk of being biased.\nOmitting subject B from the analysis, each non-transfer learning method  performs best on one of the remaining subjects.\nTherefore it is not clear that an LSTM model is an improvement. \nFor transfer learning (ignoring B again) only C and D are improved but it is unclear what the variance is.\nIn the BCI community there are many approaches that use transfer learning with linear models. I think that it would be interesting how linear model transfer learning would fare in this task. \n\nA second issue that might inflate the results is the fact that the data is shuffled randomly. While this is common practice for most machine learning tasks, it is dangerous when working with brain data due to changes in the signal over time. As a result, selecting random samples might inflate the accuracy compared to having a proper train and test set that are separated in time. Ideally the cross-validation should be done using contiguous folds. \n\nI am not quite sure whether it should be possible to have an accuracy above chance level half a second before movement onset? How long does motor preparation take? I am not familiar with this specific subject, but a quick search gave me a reaction time for sprinters of .15 seconds. Is it possible that cue processing activity was used to obtain the classification result? Please discuss this effect because I am do not understand why it should be possible to get above chance level accuracy half a second before movement onset. \n\nThere are also several technical aspects that are not clear to me. I am confident that I am unable to re-implement the proposed method and their baseline given the information provided.\n\nLDA baseline:\n—————————\nFor the LDA baseline, how is the varying sequence length treated? \nLedoit wolf analytic  regularization is used, but it isn not referenced. If you use that method, cite the paper. \nThe claim that LDA works for structured experimental tasks but not in naturalistic scenarios and will not generalize when electrode count and trial duration increases is a statement that might be true. However, it is never empirically verified.  Therefore this statement should not be in the paper. \n\nHMM baseline\n—————————\nHow are the 1 and the 2 state HMM used w.r.t. the 5 classes? It is unclear to me how they are used exactly. Is there a single HMM per class? Please be specific. \n\nLSTM Model\n—————\nWhat is the random and language model initialization scheme? I can only find the sequence auto-encoder in the Dai and Le paper. \n\n\nModel analysis\n——————————-\nIt is widely accepted in the neuroimaging community that linear weight vectors should not be interpreted directly. It is actually impossible to do this.  Therefore this section should be completely re-done. Please read the following paper on this subject.\nHaufe, Stefan, et al. ""On the interpretation of weight vectors of linear models in multivariate neuroimaging.""\xa0Neuroimage\xa087 (2014): 96-110.\n\nReferences\n———— \nLedoit wolf regularization is used but not cited. Fix this.\nThere is no citation for the random/language model initialization of the LSTM model. I have no clue how to do this without proper citation.\nLe at al (2011) are referenced for auto-encoders. This is definitely not the right citation. \nRumelhart, Hinton, & Williams, 1986a; Bourlard & Kamp, 1988; Hinton & Zemel, 1994 and Bengio, Lamblin, Popovici, & Larochelle, 2007; Ranzato, Poultney, Chopra, & LeCun, 2007 are probably all more relevant.\nPlease cite the relevant work on affine transformations for transfer learning especially the work by morioka et al who also learn an input transferm.\nMorioka, Hiroshi, et al. ""Learning a common dictionary for subject-transfer decoding with resting calibration."" NeuroImage 111 (2015): 167-178.\n', ""The ms applies an LSTM on ECoG data and studies tranfer between subjects etc. \n\nThe data includes only few samples per class. The validation procedure to obtain the model accuray is a bit iffy. \nThe ms says: The test data contains 'at least 2 samples per class'. Data of the type analysed is highly dependend, so it is not unclear whether this validation procedure will not provide overoptimistic results. Currently, I do not see evidence for a stable training procedure in the ms. I would be curious also to see a comparison to a k-NN classifier using embedded data to gauge the problem difficulty. \nAlso, the paper does not really decide whether it is a neuroscience contribution or an ML one. If it were a neuroscience contribution, then it would be important to analyse and understand the LSTM representation and to put it into a biological context fig 5B is a first step in this direction. \nIf it where a ML contribution, then there should be a comprehensive analysis that indeed the proposed architecture using the 2 steps is actually doing the right thing, i.e. that the method converges to the truth if more and more data is available. \nThere is also some initial experiments in fig 3A. Currently, I find the paper somewhat unsatisfactory and thus preliminary. ""]","[-50, -60, -60]","[20, 20, -20]","[""The sentiment score is -50 because the reviewer expresses disappointment with the results and questions the value of the proposed method. They state that 'results are disappointing' and that the LSTM performance doesn't 'convincingly exceed that of the simple baselines.' They also criticize the lack of clarity in some aspects of the methodology. However, the review isn't entirely negative, as it acknowledges some interesting aspects like the visualization and the potential meaningfulness of the research area.\n\nThe politeness score is 20 because the reviewer maintains a professional and relatively neutral tone throughout. They don't use harsh language or direct criticism of the authors. Instead, they focus on the work itself and use phrases like 'it appears meaningful,' 'interesting visualization,' and 'limited novelty' which are constructive rather than confrontational. However, the review isn't overly polite either, as it directly points out flaws and disappointments without much softening language."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper and is 'not willing to recommend the paper for acceptance'. They point out multiple issues with the methodology, analysis, and referencing. However, it's not entirely negative as they acknowledge the problem is 'challenging and interesting'. The politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They use phrases like 'I think', 'I am not quite sure', and 'Please discuss' which soften the criticism. They also offer specific suggestions for improvement, which is helpful and polite. The language is not overly formal or deferential, but it avoids rudeness or harsh language, striking a balance between directness and courtesy."", ""The sentiment score is -60 because the reviewer expresses several concerns and criticisms about the manuscript, describing it as 'unsatisfactory' and 'preliminary'. They point out issues with the validation procedure, lack of evidence for stable training, and the paper's unclear focus. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical without much softening. Phrases like 'a bit iffy', 'I do not see evidence', and 'Currently, I find the paper somewhat unsatisfactory' contribute to a somewhat impolite tone. The reviewer does use some mitigating language ('I would be curious', 'If it were...') which prevents the score from being lower, but overall the tone is more negative than polite.""]"
"['The topic discussed in this paper is interesting. Dialogue acts (DAs; or some other semantic relations between utterances) are informative to increase the diversity of response generation. It is interesting to see how DAs are used for conversational modeling, however this paper is difficult for me to follow. For example:\n\n1) the caption of section 3.1 is about supervised learning, however the way of describing the model in this section sounds like reinforcement learning. Not sure whether it is necessary to formulate the problem with a RL framework, since the data have everything that the model needs as for a supervised learning.\n2) the formulation in equation 4 seems to be problematic\n3) ""simplify pr(ri|si,ai) as pr(ri|ai,ui−1,ui−2) since decoding natural language responses from long conversation history is challenging"" to my understanding, the only difference between the original and simplified model is the encoder part not the decoder part. Did I miss something?\n4) about section 3.2, again I didn\'t get whether the model needs RL for training.\n5) ""We train m(·, ·) with the 30 million crawled data through negative sampling."" not sure I understand the connection between training $m(\\cdot, \\cdot)$ and the entire model.\n6) the experiments are not convincing. At least, it should show the generation texts were affected about DAs in a systemic way. Only a single example in table 5 is not enough.', 'The authors use a distant supervision technique to add dialogue act tags as a conditioning factor for generating responses in open-domain dialogues. In their evaluations, this approach, and one that additionally uses policy gradient RL with discourse-level objectives to fine-tune the dialogue act predictions, outperform past models for human-scored response quality and conversation engagement.\nWhile this is a fairly straightforward idea with a long history, the authors claim to be the first to use dialogue act prediction for open-domain (rather than task-driven) dialogue. If that claim to originality is not contested, and the authors provide additional assurances to confirm the correctness of the implementations used for baseline models, this article fills an important gap in open-domain dialogue research and suggests a fruitful future for structured prediction in deep learning-based dialogue systems.\n\nSome points:\n1. The introduction uses ""scalability"" throughout to mean something closer to ""ability to generalize."" Consider revising the wording here.\n2. The dialogue act tag set used in the paper is not original to Ivanovic (2005) but derives, with modifications, from the tag set constructed for the DAMSL project (Jurafsky et al., 1997; Stolcke et al., 2000). It\'s probably worth citing some of this early work that pioneered the use of dialogue acts in NLP, since they discuss motivations for building DA corpora.\n3. In Section 2.1, the authors don\'t explicitly mention existing DA-annotated corpora or discuss specifically why they are not sufficient (is there e.g. a dataset that would be ideal for the purposes of this paper except that it isn\'t large enough?)\n3. The authors appear to consider only one option (selecting the top predicted dialogue act, then conditioning the response generator on this DA) among many for inference-time search over the joint DA-response space. A more comprehensive search strategy (e.g. selecting the top K dialogue acts, then evaluating several responses for each DA) might lead to higher response diversity.\n4. The description of the RL approach in Section 3.2 was fairly terse and included a number of ad-hoc choices. If these choices (like the dialogue termination conditions) are motivated by previous work, they should be cited. Examples (perhaps in the appendix) might also be helpful for the reader to understand that the chosen termination conditions or relevance metrics are reasonable.\n5. The comparison against previous work is missing some assurances I\'d like to see. While directly citing the codebases you used or built off of is fantastic, it\'s also important to give the reader confidence that the implementations you\'re comparing to are the same as those used in the original papers, such as by mentioning that you can replicate or confirm quantitative results from the papers you\'re comparing to. Without that there could always be the chance that something is missing from the implementation of e.g. RL-S2S that you\'re using for comparison.\n6. Table 5 is not described in the main text, so it isn\'t clear what the different potential outputs of e.g. the RL-DAGM system result from (my guess: conditioning the response generation on the top 3 predicted dialogue acts?)\n7. A simple way to improve the paper\'s clarity for readers would be to break up some of the very long paragraphs, especially in later sections. It\'s fine if that pushes the paper somewhat over the 8th page.\n8. A consistent focus on human evaluation, as found in this paper, is probably the right approach for contemporary dialogue research.\n9. The examples provided in the appendix are great. It would be helpful to have confirmation that they were selected randomly (rather than cherry-picked).', 'The paper describes a technique to incorporate dialog acts into neural conversational agents.  This is very interesting work.  Existing techniques for neural conversational agents essentially mimic the data in large corpora of message-response pairs and therefore do not use any notion of dialog act.  A very important type of dialog act is ""switching topic"", often done to ensure that the conversation will continue.  The paper describes a classifier that predicts the dialog act of the next utterance.  The next utterance is then generated based on this dialog act.  The paper also describes how to increase the relevance of responses and the length of conversations by self reinforcement learning.  This is also very interesting.  The empirical evaluation demonstrates the effectiveness of the approach.  The paper is also well written.  I do not have any suggestion for improvement.  This is good work that should be published.']","[-50, 70, 100]","[20, 80, 80]","[""The sentiment score is -50 because while the reviewer acknowledges the topic as interesting, they express significant confusion and criticism about the paper's methodology, formulation, and experimental results. The review lists multiple areas of concern without balancing positive aspects, indicating an overall negative sentiment. The politeness score is 20 because the reviewer uses polite language such as 'interesting' and phrases like 'Not sure whether...' and 'Did I miss something?', which soften the criticism. However, the politeness is somewhat limited by the direct nature of the criticisms and lack of positive reinforcement or encouragement to the authors."", ""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, stating it 'fills an important gap' and 'suggests a fruitful future'. They also praise aspects like the human evaluation focus and examples in the appendix. However, it's not 100 as they do raise several points for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms constructively as suggestions (e.g. 'Consider revising', 'It would be helpful'), and acknowledges positive aspects. The tone is professional and helpful rather than harsh or dismissive."", ""The sentiment score is 100 (very positive) because the reviewer uses phrases like 'very interesting work', 'good work that should be published', and has no suggestions for improvement. They praise various aspects of the paper, including its novelty, importance, and empirical evaluation. The politeness score is 80 (quite polite) because the reviewer uses respectful and encouraging language throughout, acknowledging the value of the work without being overly effusive. They provide a balanced and constructive review, focusing on the paper's strengths without any criticism, which contributes to the polite tone.""]"
"['Summary: This paper studied the conditional image generation with two-stream generative adversarial networks. More specifically, this paper proposed an unsupervised learning approach to generate (1) foreground region conditioned on class label and (2) background region without semantic meaning in the label. During training, two generators are competing against each other to hallucinate foreground region and background region with a physical gating operation. An auxiliary “label difference cost” was further introduced to encourage class information captured by the foreground generator. Experiments on MNIST, SVHN, and CelebA datasets demonstrated promising generation results with the unsupervised two-stream generation pipeline.\n\n== Novelty/Significance ==\nControllable image generation is an important task in representation learning and computer vision. I also like the unsupervised learning through gating function and label difference cost. However, considering many other related work mentioned by the paper, the novelty in this paper is quite limited. For example, layered generation (Section 2.2.1) has been explored in Yan et al 2016 (VAEs) and Vondrick et al 2016 (GANs).\n\n== Detailed comments ==\nThe proposed two-stream model is developed with the following two assumptions: (1) Single object in the scene; and (2) Class information is provided for the foreground/object region. Although the proposed method learns to distinguish foreground and background in an unsupervised fashion, it is limited in terms of applicability and generalizability. For example, I am not convinced if the two-stream generation pipeline can work well on more challenging datasets such as MS-COCO, LSUN, and ImageNet. \n\nGiven the proposed method is controllable image generation, I would assume to see the following ablation studies: keeping two latent variables from (z_u, z_l, z_v) fixed, while gradually changing the value of the other latent variable. However, I didn’t see such detailed analysis as in the other papers on controllable image generation.\n\nIn Figure 7 and Figure 10, the boundary between foreground and background region is not very sharp. It looks like equation (5) and (6)  are insufficient for foreground and background separation (triplet/margin loss could work better). Also, in CelebA experiment, it is not a well defined experimental setting since only binary label (smiling/non-smiling) is conditioned. Is it possible to use all the binary attributes in the dataset.\n\nAlso, please either provide more qualitative examples or provide some type of quantitative evaluations (through user study , dataset statistics, or down-stream recognition tasks).\n\nOverall, I believe the paper is interesting but not ready for publication. I encourage authors to investigate (1) more generic layered generation process and (2) better unsupervised boundary separation. Hopefully, the suggested studies will improve the quality of the paper in the future submission.\n\n== Presentation ==\nThe paper is readable but not well polished. \n\n-- In Figure 1, the “G1” on the right should be “G2”;\n-- Section 2.2.1, “X_f” should be “x_f”;\n-- the motivation of having “z_v” should be introduced earlier;\n-- Section 2.2.4, please use either “alpha” or “\\alpha” but not both;\n-- Section 3.3, the dataset information is incorrect: “20599 images” should be “202599 images”;\n\nMissing reference:\n-- Neural Face Editing with Intrinsic Image Disentangling, Shu et al. In CVPR 2017.\n-- Domain Separation Networks, Bousmalis et al. In NIPS 2016.\n-- Unsupervised Image-to-Image Translation Networks, Liu et al. In NIPS 2017.\n', '\n- Paper summary\n\nThe paper proposes a label-conditional GAN generator architecture and a GAN training objective for the image modeling task. The proposed GAN generator consists of two components where one focuses on generating foreground while the other focuses on generating background. The GAN training objective function utilizing 3 conditional classifier. It is shown that through combining the generator architecture and the GAN training objective function, one can learn a foreground--background decomposed generative model in an unsupervised manner. The paper shows results on the MNIST, SVHN, and Celebrity Faces datasets.\n\n- Poor experimental validation\n\nWhile it is interesting to know that a foreground--background decomposed generative model can be learned in an unsupervised manner, it is clear how this capability can help practical applications, especially no such examples are shown in the paper. The paper also fails to provide any quantitative evaluation of the proposed method. For example, the paper will be more interesting if inception scores were shown for various challenging datasets.  In additional, there is no ablation study analyzing impacts of each design choices. As a result, the paper carries very little scientific value.', '[Overview]\n\nThis paper proposed a new generative adversarial network, called 3C-GAN for generating images in a composite manner. In 3C-GAN, the authors exploited two generators, one (G1) is for generating context images, and the other one (G2) is for generating semantic contents. To generate the semantic contents, the authors introduced a conditional GAN scheme, to force the generated images to match the annotations. After generating both parts in parallel, they are combined using alpha blending to compose the final image. This generated image is then sent to the discriminator. The experiments were conducted on three datasets, MNIST, SVHN and MS-CelebA. The authors showed qualitative results on all three datasets, demonstrating that AC-GAN could disentangle the context part from the semantic part in an image, and generate them separately.\n\n[Strenghts]\n\nThis paper introduced a layered-wise image generation, which decomposed the image into two separate parts: context part, and semantic part. Corresponding to these two parts are two generators. To ensure this, the authors introduced three strategies:\n\n1. Adding semantic labels: the authors used image semantic labels as the input and then exploited a conditional GAN to enforce one of the generators to generate semantic parts of images. As usual, the label information was added as the input of generator and discriminator as well.\n\n2. Adding label difference cost: the intuition behind this loss is that changing the label condition should merely affect the output of G2. Based on this, outputs of Gc should not change much when flipping the input labels.\n\n3. Adding exclusive prior: the prior is that the masks of context part (m1) and semantic part (m2) should be exclusive to each other. Therefore, the authors added another loss to reduce the sum of component-wise multiplication between m1 and m2.\n\nDecomposing the semantic part from the context part in an image based on a generative model is an interesting problem. However, to my opinion, completing it without any supervision is challenging and meaningless. In this paper, the authors proposed a conditional way to generate images compositionally. It is an interesting extension of previous works, such as Kwak & Zhang (2016) and Yang (2017).\n\n[Weaknesses]\n\nThis paper proposed an interesting and intuitive image generation model. However, there are several weaknesses existed:\n\n1. There is no quantitative evaluation and comparisons. From the limited qualitative results shown in Fig.2-10, we can hardly get a comprehensive sense about the model performance. The authors should present some quantitative evaluations in the paper, which are more persuasive than a number of examples. To do that, I suggest the authors exploited evaluation metrics, such as Inception Score to evaluate the overall generation performance. Also, in Yang (2017) the authors proposed adversarial divergence, which is suitable for evaluating the conditional generation. Hence, I suggest the authors use a similar way to evaluate the classification performance of classification model trained on the generated images. This should be a good indicator to show whether the proposed 3C-GAN could generate more realistic images which facilitate the training of a classifier.\n\n2. The authors should try more complicated datasets, like CIFAR-10. Recently, CIFAR-10 has become a popular dataset as a testbed for evaluating various GANs. It is easy to train since its low resolution, but also means a lot since it a relative complicated scene. I would suggest the authors also run the experiments on CIFAR-10.\n\n3. The authors did not perform any ablation study. Apart from several generation results based on 3C-GAN, iIcould not found any generation results from ablated models. As such, I can hardly get a sense of the effects of different losses and know about the relative performance in the whole GAN spectrum. I strongly suggest the authors add some ablation studies. The authors should at least compare with one-layer conditional GAN. \n\n4. The proposed model merely showed two-layer generation results. There might be two reasons: one is that it is hard to extend it to more layer generation as I know, and the other one reason is the inflexible formulation to compose an image in 2.2.1 and formula (6). The authors should try some datasets like MNIST-TWO in Yang (2017) for demonstration.\n\n5. Please show f1, m1, f2, m2 separately, instead of showing the blending results in Fig3, Fig4, Fig6, Fig7, Fig9, and Fig10. I would like to see what kind of context image and foreground image 3C-GAN has generated so that I can compare it with previous works like Kwak & Zhang (2016) and Yang (2017).\n\n6. I did not understand very well the label difference loss in (5). Reducing the different between G_c(z_u, z_v, z_l) and G_c(z_u, z_v, z_l^f) seems not be able to force G1 and G2 to generate different parts of an image. G2 takes all the duty  can still obtain a lower L_ld. From my point of view, the loss should be added to G1 to make G1 less prone to the variation of label information.\n\n7. Minor typos and textual errors. In Fig.1, should the right generator be G2 rather than G1? In 2.1.3 and 2.2.1, please add numbers to the equations.\n\n[Summary]\n\nThis paper proposed an interesting way of generating images, called 3C-GAN. It generates images in a layer-wise manner. To separate the context and semantic part in an image, the authors introduced several new techniques to enforce the generators in the model undertake different duties. In the experiments, the authors showed qualitative results on three datasets, MNIST, SVHN and CelebA. However, as I pointed out above, the paper missed quantitative evaluation and comparison, and ablation study. Taking all these into account, I think this paper still needs more works to make it solid and comprehensive before being accepted.']","[-30, -60, -30]","[50, -20, 60]","[""The sentiment score is -30 because while the reviewer acknowledges some interesting aspects of the paper, they ultimately conclude that it's 'not ready for publication' and has 'limited' novelty. They provide several criticisms and suggestions for improvement, indicating a generally negative sentiment. However, it's not extremely negative as they do see potential and encourage further work.\n\nThe politeness score is 50 because the reviewer uses respectful language throughout, even when criticizing. They use phrases like 'I encourage authors to...' and 'Hopefully, the suggested studies will improve...', which are constructive and polite. They also acknowledge positive aspects before critiquing. However, it's not extremely polite as it maintains a professional, direct tone rather than being overly deferential.\n\nThe reasoning is based on the overall tone, specific phrases used, balance of positive and negative comments, and the constructive nature of the criticism provided."", ""The sentiment score is -60 because the review is predominantly negative. While the first paragraph provides a neutral summary, the second paragraph is highly critical, stating the paper has 'very little scientific value' and 'fails to provide any quantitative evaluation'. The reviewer also mentions the lack of practical applications and ablation studies. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and dismissive. Phrases like 'Poor experimental validation' and 'carries very little scientific value' are particularly harsh and could be phrased more diplomatically. The reviewer doesn't use any polite language or acknowledge potential merits of the work, contributing to the negative politeness score."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some strengths of the paper, they also point out several significant weaknesses and conclude that 'this paper still needs more works to make it solid and comprehensive before being accepted.' The review begins positively but becomes increasingly critical. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions politely (e.g., 'I suggest', 'I would suggest', 'Please show'). The reviewer maintains a professional tone even when pointing out flaws, avoiding harsh or rude language.""]"
"['This paper examines the nature of convolutional filters in the encoder and a decoder of a VAE, and a generator and a discriminator of a GAN. The authors treat the inputs (X) and outputs (Y) of each filter throughout each step of the convolving process as a time series, which allows them to do a Discrete Time Fourier Transform analysis of the resulting sequences. By comparing the power spectral density of the input and the output, they get a Spectral Dependency Ratio (SDR) ratio that characterises a filter as spectrally independent (neutral), correlating (amplifies certain frequencies), or anti-correlating (dampens frequencies). This analysis is performed in the context of the Independence of Cause and Mechanism (ICM) framework. The authors claim that their analysis demonstrates a different characterisation of the inference/discriminator and generative networks in VAE and GAN, whereby the former are anti-causal and the latter are causal in line with the ICM framework. They also claim that this analysis can be used to improve the performance of the models.\n\nPros:\n-- SDR characterisation of the convolutional filters is interesting\n-- The authors show that filters with different characteristics are responsible for different aspects of image modelling\n\nCons:\n-- The authors do not actually demonstrate how their analysis can be used to improve VAEs or GANs\n-- Their proposed SDR analysis does not actually find much difference between the generator and the discriminator of the GAN \n-- The clarity of the writing could be improved (e.g. the discussion in section 3.1 seems inaccurate in the current form). Grammatical and spelling mistake are frequent. More background information could be helpful in section 2.2. All figures (but in particular Figure 3) need more informative captions\n-- The authors talk a lot about disentangling in the introduction, but this does not seem to be followed up in the rest of the text. Furthermore, they are missing a reference to beta-VAE (Higgins et al, 2017) when discussing VAE-based approaches to disentangled factor learning\n\n\nIn summary, the paper is not ready for publication in its current form. The authors are advised to use the insights from their proposed SDR analysis to demonstrate quantifiable improvements the VAEs/GANs.', 'The paper presents an application of a measure of dependence between the input power spectrum and the frequency response of a filter (Spectral Density Ratio from [Shajarisales et al 2015]) to cascades of two filters in successive layers of deep convolutional networks. The authors apply their newly defined measure to DCGANs and plain VAEs with ReLUs, and show that dependency between successive layers may lead to bad performance. \n\nThe paper proposed a possibly interesting approach, but I found it quite hard to follow, especially Section 4, which I thought was quite unstructured. Also Section 3 could be improved and simplified. It would be also good to add some more related work. I’m not an expert, but I assume there must be some similar idea in CNNs. \n\nFrom my limited point of view, this seems like a sound, novel and potentially useful application of a interesting idea. If the writing was improved, I think the paper may have even more impact.\n\nSmaller details: some spacing issues, some extra punctuation (pg 5 “. . Hence”), a typo (pg. 7 “training of the VAE did not lead to values as satisfactory AS what we obtained with the GAN”)\n', 'This work exploits the causality principle to quantify how the weights of successive layers adapt to each other.  Some interesting results are obtained, such as ""enforcing more independence between successive layers of generators may lead to better performance and modularity of these architectures"" . Generally, the result is interesting and the presentation is easy to follow. However, the proposed approach and the experiments are not convincible enough.  For example,  it is hard to obtain the conclusion ""more independence lead to better performance"" from the experimental results. Maybe more justifications are needed.']","[-50, 20, 20]","[50, 60, 50]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('Pros'), they ultimately conclude that 'the paper is not ready for publication in its current form'. This indicates a generally negative sentiment, though not extremely harsh. The 'Cons' section outlines several significant issues, which further supports the negative sentiment. The politeness score is 50 because the reviewer uses professional and respectful language throughout. They provide balanced feedback, acknowledging both pros and cons, and offer constructive suggestions for improvement. The use of phrases like 'The authors are advised to...' instead of more direct commands shows a degree of politeness. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral professional tone overall."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's potential ('possibly interesting approach', 'sound, novel and potentially useful application'), they also point out several areas for improvement in structure and clarity. The overall tone suggests the paper has merit but needs refinement. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging their own limitations ('From my limited point of view', 'I'm not an expert') and offering constructive criticism rather than harsh judgments. They also balance critiques with positive observations and suggest improvements in a helpful manner. The reviewer's tone is professional and considerate, even when pointing out minor errors."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the work as 'interesting' and 'easy to follow', but also expresses concerns about the convincingness of the approach and experiments. The politeness score is moderately positive (50) as the reviewer uses respectful language and balances positive comments with constructive criticism. They avoid harsh language and frame their concerns as suggestions for improvement rather than outright dismissals.""]"
"['The authors propose to evaluate how well generative models fit the training set by analysing their data augmentation capacity, namely the benefit brought by training classifiers on mixtures of real/generated data, compared to training on real data only. Despite the the idea of exploiting generative models to perform data augmentation is interesting, using it as an evaluation metric does not constitute an innovative enough contribution. \n\nIn addition, there is a fundamental matter which the paper does not address: when evaluating a generative model, one should always ask himself what purpose the data is generated for. If the aim is to have realistic samples, a visual turing test is probably the best metric. If instead the purpose is to exploit the generated data for classification, well, in this case an evaluation of the impact of artificial data over training is a good option.\n\nPROS:\nThe idea is interesting. \n\nCONS:\n1. The authors did not relate the proposed evaluation metric to other metrics cited (e.g., the inception score, or a visual turing test, as discussed in the introduction). It would be interesting to understand how the different metrics relate. Moreover, the new metric is introduced with the following motivation “[visual Turing test and Inception Score] do not indicate if the generator collapses to a particular mode of the data distribution”. The mode collapse issue is never discussed elsewhere in the paper. \n\n2. Only two datasets were considered, both extremely simple: generating MNIST digits is nearly a toy task nowadays. Different works on GANs make use of CIFAR-10 and SVHN, since they entail more variability: those two could be a good start. \n\n3. The authors should clarify if the method is specifically designed for GANs and VAEs. If not, section 2.1 should contain several other works (as in Table 1). \n\n4. One of the main statements of the paper “Our approach imposes a high entropy on P(Y) and gives unbiased indicator about entropy of both P(Y|X) and P(X|Y)” is never proved, nor discussed.\n\n5. Equation 2 (the proposed metric) is not convincing: taking the maximum over tau implies training many models with different fractions of generated data, which is expensive. Further, how many tau’s one should evaluate? In order to evaluate a generative model one should test on the generated data only (tau=1) I believe. In the worst case, the generator experiences mode collapse and performs badly. Differently, it can memorize the training data and performs as good as the baseline model. If it does actual data augmentation, it should perform better.\n\n6. The protocol of section 3 looks inconsistent with the aim of the work, which is to evaluate data augmentation capability of generative models. In fact, the limit of training with a fixed dataset is that the model ‘sees’ the data multiple times across epochs with the risk of memorizing. In the proposed protocol, the model ‘sees’ the generated data D_gen (which is fixed before training) multiple time across epochs. This clearly does not allow to fully evaluate the capability of the generative model to generate newer and newer samples with significant variability.\n\n\nMinor: \nSection 2.2 might be more readable it divided in two (exploitation and evaluation).   \n', 'The paper proposes a technique for analysis of generative models.\n\nThe main idea is to (1) define a classification task on the underlying data, (2) use the generative model to produce a training set for this classification task, and (3) compare performance on the classification task when training on generated and real training data. \n\nNote that in step (2) is it required to assign class labels to the generated samples. In this paper this is achieved by learning a separate generative model for each class label. \n\nSummary:\n\nI think the proposed technique is useful, but needs to be combined with other techniques to exclude the possibility that model just memorized the training set. To be stronger the paper needs to consider other more realistic tasks from the literature and directly compare to other evaluation protocols. \n\nPositive:\n+ the technique operates directly on the samples from the model. It is not required to compute the likelihood of the test set as for example is needed in  the ""perplexity"" measure). This makes the technique applicable for evaluation of a wider class of techniques.  \n\n+ I like the result in Fig. 1. There is a clear difference between results by WGAN and by other models. This experiment convinces me that the peroposed analysis by augmentation is a valuable tool. \n\n+ I think the technique is particularly valuable verify that samples are capturing variety of modes in the data. Verifying this via visual inspection is difficult.\n\nNegative: \n\n- I think this metric can be manipulated by memorizing training data, isn\'t it? The model that reproduces the training set will still achieve good performance at \\tau = 1, and the model that does simple augmentation like small shifts / rotations / scale and contrast changes might even improve over training data alone. So the good performance on the proposed task does not mean that the model generalized over the training dataset.\n\n- I believe that for tasks such as image generating none of the existing models generate samples that would be realistic enough to help in classification. Still some methods produce images that are more realistic than others. I am not sure if the proposed evalaution protocol would be useful for this type of tasks. \n\n- The paper does not propose an actual metric. Is the metric for performance of generative model defined by the best relative improvement over baseline after tuning \\tau as in Tab. 1?  Wouldn\'t it be better to fix \\tau, e.g. \\tau = 1?\n\n- Other datasets / methods and comparison to other metrics. This is perhaps the biggest limitation for me right now. To establish a new comparison method the paper needs to demonstrate it on relevant tasks (e.g. image generation?), and compare to existing metrics (e.g. ""visual inspection"" and ""average log-likelihood""). \n\n', 'The main idea is to use the accuracy of a classifier trained on synthetic training examples produced by a generative model to define an evaluation metric for the generative model. Specifically, compare the accuracy of a classifier trained on a noise-perturbed version of the real dataset to that of a classifier trained on a mix of real data and synthetic data generated by the model being evaluated. Results are shown on MNIST and Fashion MNIST.\n\nThe paper should discuss the assumptions needed for classifier accuracy to be a good proxy for the quality of a generative model that generated the classifier\'s training data. It may be the case that even a ""bad"" generative model (according to some other metric) can still result in a classifier that produces reasonable test accuracy. Since a classifier can be a highly nonlinear function, it can potentially ignore many aspects of its input distribution such that even poor approximations (as measured by, say, KL) lead to similar test accuracy as good approximations.\n\nThe sensitivity of the evaluation metric defined in equation 2 to the choice of hyperparameters of the classifier and the metric itself (e.g., alpha) is not evaluated. Is it possible that a different choice of hyperparameters can change the model ranking? Should the hyperparameters be tuned separately for each generative model being evaluated?\n\nThe intuition behind comparing against a classifier trained on a noise-perturbed version of the data is not explained clearly. Why not compare a classifier trained on only (unperturbed) real data to a classifier trained on both real and synthetic data?\n\nEvaluation on two datasets is not sufficient to provide insight into whether the proposed metric is useful. Other datasets such as ImageNet, Cifar10/100, Celeb A, etc., should also be included.']","[-50, 20, -20]","[20, 60, 50]","[""The sentiment score is -50 because while the reviewer acknowledges that the idea is interesting, they express significant concerns about the paper's contribution and methodology. The review lists more cons than pros and suggests that the paper's main idea is not innovative enough. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'The authors propose' and 'It would be interesting to understand', which are polite ways of offering criticism. However, the reviewer is also direct in pointing out flaws, which prevents the score from being higher. The reviewer balances critique with acknowledgment of the paper's merits, demonstrating a respectful but honest approach."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the usefulness of the proposed technique and provides several positive points, such as its wide applicability and ability to capture variety in data. However, they also express significant concerns and limitations, which temper the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, presenting both positive and negative points in a constructive manner. They use phrases like 'I think' and 'I believe' to soften criticisms, and provide specific suggestions for improvement rather than outright dismissals. The review maintains a professional and courteous tone while still clearly communicating areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the main idea of the paper, they raise several significant concerns and suggest major improvements. The reviewer points out multiple limitations and areas that need more explanation or evaluation, indicating a somewhat critical stance. However, the tone is not entirely negative, as they provide constructive feedback for improvement. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout. They phrase their criticisms as suggestions or questions rather than direct criticisms (e.g., 'The paper should discuss...', 'Is it possible that...'), which maintains a polite tone. The reviewer also acknowledges the work done ('Results are shown on MNIST and Fashion MNIST') before providing critiques, which is a polite approach in academic reviews.""]"
"['Overview:\nThis paper proposes a method for learning representations using a “non-linear transform”. Specifically, the approach is based on the form: Y =~ AX, where X is the original data, A is a projection matrix, and Y is the resulting representation. Using some assumptions, and priors/regularizers on Y and A, a joint objective is derived (eq. 10), and an alternating optimization algorithm is proposed (eq. 11 and 14). Both objective and algorithm use approximations due to hardness of the problem. Theoretical and empirical results on the quality and properties of the representation are presented.\nDisclaimer: this is somewhat outside my area of expertise, so this is a rather high-level review. I have not thoroughly checked proofs and claims.\n\nComments:\n-I found the presentation quality to be rather poor, making it hard to fully understand and evaluate the approach. In particular, the motivation and approach are not clear (sec. 1.2), making it hard to understand the proposed method. There is no explicit formulation, instead there are references to other models (e.g., sparsifying transform model) and illustrative figures (fig. 1 and 2). Those are useful following a formal definition, but cannot replace it. The separation between positive and negative elements of the representation is not motivated and explained in a footnote although it seems central to the proposed approach.\n- The paper is 17 pages long (24 pages with the appendix), so I had to skim through some parts. Due to the extensive scope, perhaps a journal submission would be more appropriate.\n\nMinors:\n- Vu & Monga 2016b and 2016c are the same.\n- p. 1: meaner => manner\n- p. 1: refereed => referred\n- p. 1: “a structural constraints”; p. 2: “a low rank constraints”, “a pairwise constraints”; p. 4: “a similarity concentrations”, “a numerical experiments”, and others...\n- p. 2, 7: therms => terms\n- p. 2: y_{c_1,k_2} => y_{c_1,k_1}?\n- p. 3, 4: “a the”\n- p. 5: “an parametric”\n- p. 8: ether => either\n- Other typos… the paper needs proofreading.\n', 'Summary:\nThe paper proposes a model to estimate a non-linear transform of data with labels, trying to increase the discriminative power of the transformation while preserving information. \n\nQuality:\nThe quality is potentially good but I misunderstood too many things (see below) to emit a confident judgement.\n\nClarity:\nClarity is poor. The paper is overall difficult to follow (at least for me) for different reasons. First, with 17 pages + references + appendix, the length of the paper is way above the «\xa0strongly suggested limit of 8 pages\xa0». Second, there are a number of small typos and the citations are not well formatted (use \\citep instead of \\citet). Third, and more importantly, several concepts are only vaguely formulated (or wrong), and I must say I certainly misunderstood some parts of the manuscript.\nA few examples of things that should be clarified:\n- p4: «\xa0per class c there exists an unknown nonlinear function […] that separates the data samples from different classes in the transformed domain\xa0». What does «\xa0separate\xa0» mean here? There exists as many functions as there are classes, do you mean that each function separates all classes? Or that when you apply each class function to the elements of its own class, you get a separation between the classes? (which would not be very useful)\n- p5: what do you mean exactly by «\xa0non-linear thresholding function\xa0»?\n- p5: «\xa0The goal of learning a nonlinear transform (2) is to estimate…\xa0»: not sure what you mean by «\xa0accurate approximation\xa0» in this sentence.\n- p5 equation 3: if I understand correctly, you not only want to estimate a single vector of thresholds for all classes, but also want it to be constant. Is there a reason for the second constraint?\n- p5 After equation 4, you define different «\xa0priors\xa0». The one on z_k seems to be Gaussian; however in equation 4, z_k seems to be the difference between the input and the output of the nonlinear threshold operator. If this is correct, then the nonlinear threshold operator is just the addition of a Gaussian random noise, which is really not a thresholding operator. I suppose I misunderstood something here, some clarification is probably needed.\n- p5 before equation 5, you define a conditional distribution of \\tau_c given y_{c,k} ; however if you define a prior on \\tau_c given each point (i.e., each $k$), how do you define the law of \\tau_c given all points?\n- p5 Equation 6: I dont understand what the word «\xa0approximation\xa0» refers to, and how equation 6 is derived. \n-p6 equation 7 : missing exponent in the Gaussian distribution\n- p6-7: to combine equations 7-8-9 and obtain 10, I suppose in equation 7 the distributions should be conditioned on A (at least the first one), and in equation 9 I suppose the second line should be removed and the third line should be conditioned on A; otherwise more explanations are needed.\n- Lemma 1 is just unreadable. Please at least split equations in several lines.\n\nOriginality:\nAs far as I can tell, the approach is quite original and the results proved are new.\n\nSignificance:\nThe method provides a new way to learn discriminative features; as such it is a variant of several existing methods, which could have some impact if clarity is improved and a public code is provided.', 'This paper proposes a method of learning sparse dictionary learning by introducing new types of priors. Specifically, they designed a novel idea of defining a metric to measure discriminative properties along with the quality of presentations.\nIt is also presented the power of the proposed method in comparison with the existing methods in the literature.\n\nOverall, the paper deals with an important issue in dictionary learning and proposes a novel idea of utilizing a set of priors. \n\nTo this reviewer’s understanding, the thresholding parameter $\\tau_{c}$ is specific for a class $c$ only, thus different classes have different $\\tau$ vectors. If so, Eq. (6) for approximation of the measure $D(\\cdot)$ is not clear how the similarity measure between ${\\bf y}_{c,k}$ and ${\\bf y}_{c1,k1}$, \\ie, $\\left\\|{\\bf y}_{c,k}^{+}\\odot{\\bf y}_{c1,k1}^{+}\\right\\|_{1}+\\left\\|{\\bf y}_{c,k}^{+}\\odot{\\bf y}_{c1,k1}^{+}\\right\\|_{1}$ and $\\left\\|{\\bf y}_{c,k}\\odot{\\bf y}_{c1,k1}\\right\\|_{2}^{2}$, works to approximate it. It would be appreciated to give more detailed description on it and geometric illustration, if possible.\n\nThere are many typos and grammatical errors, which distract from reading and understanding the manuscript.']","[-60, -50, 50]","[20, 20, 70]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the presentation quality is 'rather poor', making it hard to understand and evaluate the approach. They also mention that the motivation and approach are not clear, and that there's no explicit formulation. The length of the paper is criticized as potentially too long for the submission type. However, it's not entirely negative as the reviewer acknowledges some useful elements (like illustrative figures) and provides constructive feedback, hence not scoring at the extreme negative end.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively polite tone. They use phrases like 'I found' to soften criticism and provide a disclaimer about their expertise level, showing humility. They also offer constructive feedback and suggestions for improvement. However, the politeness is not extremely high as the criticism is quite direct in places. The reviewer also points out numerous typos and grammatical errors, which, while helpful, can come across as somewhat impolite if not balanced with more positive feedback."", ""The sentiment score is -50 because the review is predominantly negative, highlighting numerous issues with clarity and understanding. The reviewer states that the paper is 'difficult to follow' and mentions 'poor clarity' multiple times. However, they do acknowledge potential quality and originality, which prevents the score from being lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I misunderstood' and 'please at least split equations', which show respect and offer constructive feedback. The reviewer also acknowledges their own potential misunderstandings, which adds to the politeness. However, some direct criticisms like 'just unreadable' prevent the score from being higher."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance of the paper's topic and the novelty of its approach, stating it 'deals with an important issue' and 'proposes a novel idea'. However, they also point out areas needing clarification and mention typos, which tempers the positivity. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, such as 'It would be appreciated' when requesting clarification. They also frame their critique constructively, focusing on how improvements could enhance understanding. The mention of typos is stated factually without harsh criticism.""]"
"['In this paper the authors propose an autoregressive image generation model that incorporates a self-attention mechanism. The latter is inspired by the work of [Vaswani et al., 2016], which was proposed for sequences and is extended to 2D images in this work. The authors apply their model to super-resolution of face images, as well as image completion (aka inpainting) and generation, both unconditioned or conditioned on one of a small number of image classes from the CIFAR10 and ImageNet datasets. The authors evaluate their method in terms of visual quality of their generated images via an Amazon Mechanical Turk survey and quantitatively by reporting slightly improved log-likelihoods. \n\nWhile the paper is well written, the motivation for combining self-attention and autoregressive models remains unclear unfortunately, even more though as the reported quantitative improvement in terms of log-likelihood are only marginal. The technical exposition is at times difficult to follow with some design decisions of the network layout being quite ad hoc and not well motivated. Expressing the involved operations in mathematical terms would help comprehend some of the technical details and add to the reproducibility of the proposed model. \n\nAnother concern is the experimental evaluation. While the reported log-likelihoods are only marginally better, the authors report a significant boost in how often humans are fooled by the generated images. While the image generation is conditioned on the low-resolution input, the workers in the Amazon Mechanical Turk study get to see the high-resolution images only. Of course, a human observer would pick the one image out of the two shown images which is more realistic although it might have nothing to do with the input image, which seems wrong. Instead, the workers should see the low-res input image and then have to decide which high-res image seems a better match or more likely.\n\nOverall, the presented work looks quite promising and an interesting line of research. However, in its present form the manuscript doesn\'t seem quite ready for publication yet. Though, I would strongly encourage the authors to make the exposition more self-contained and accessible, in particular through rigorous mathematical terms, which would help comprehend the involved operations and help understand the proposed mechanism.\n\nAdditional comments:\n- Abstract: ""we also believe to look pretty cool"". Please re-consider the wording here. Generating ""pretty cool"" images  should not be the goal of a scientific work.\n', 'Summary\n\nThis paper extends self-attention layers (Vaswani et al., 2017) from sequences to images and proposes to use the layers as part of PixelCNNs (van den Oord et al., 2016). The proposed model is evaluated in terms of visual appearance of samples and log-likelihoods. The authors find a small improvement in terms of log-likelihood over PixelCNNs and that super-resolved CelebA images are able to fool human observers significantly more often than PixelRNN based super-resolution (Dahl et al., 2017).\n\nReview\n\nAutoregressive models are of large interest to the ICLR community and exploring new architectures is a valuable contribution. Using self-attention in autoregressive models is an intriguing idea. It is a little bit disappointing that the added model complexity only yields a small improvement compared to the more straight-forward modifications of the PixelCNN++. I think the paper would benefit from a little bit more work, but I am open to adjusting my score based on feedback.\n\nI find it somewhat surprising that the proposed model is only slightly better in terms of log-likelihood than a PixelRNN, but much better in terms of human evaluation –\xa0given that both models were optimized for log-likelihood. Was the setup used with Mechanical Turk exactly the same as the one used by Dahl et al.? These types of human evaluations can be extremely sensitive to changes in the setup, even the phrasing of the task can influence results. E.g., presenting images scaled differently can mask certain artifacts. In addition, the variance between subjects can be very high. Ideally, each method included in the comparison would be re-evaluated using the same set of observers. Please include error bars.\n\nThe CelebA super-resolution task furthermore seems fairly limited. Given the extreme downsampling of the input, the task becomes similar to simply generating any realistic image. A useful baseline would be the following method: Store the entire training set. For a given query image, look for the nearest neighbor in the downsampled space, then return the corresponding high-resolution image. This trivial method might not only perform well, it also highlights a flaw in the evaluation: Any method which returns stored high-resolution images –\xa0even if they don’t match the input –\xa0would perform at 50%. To fix this, the human observers should also receive the low-resolution image and be asked to identify the correct corresponding high-resolution image.\n\nUsing multiplicative operations to model images seems important. How does the self-attention mechanism relate to “gated” convolutions used in PixelCNNs? Could gated convolutions not also be considered a form of self-attention?\n\nThe presentation/text could use some work. Much of the text assumes that the reader is familiar with Vaswani et al. (2017) but could easily be made more self-contained by directly including the definitions used. E.g., the encoding of positions using sines and cosines or the multi-head attention model. I also felt too much of the architecture is described in prose and could be more efficiently and precisely conveyed in equations.\n\nOn page 7 the authors write “we believe our cherry-picked images for various classes to be of higher perceptual quality”. This is a meaningless result, not only because the images were cherry-picked. Generating realistic images is trivial - you just need to store the training images. Analyzing samples generated by a generative model (outside the context of an application) should therefore only be used for diagnostic purposes or to build intuitions but not to judge the quality of a model.\n\nPlease consider rephrasing the last sentence of the abstract. Generating images which “look pretty cool” should not be the goal of a serious machine learning paper or a respected machine learning conference.', 'This paper extends the PixelCNN/RNN based (conditional) image generation approaches with self-attention mechanism. \n\nPros:\n- qualitatively the proposed method has good results in several tasks\n\nCons:\n- writing needs to be improved\n- lack of motivation\n- not easy to follow technique details\n\n\nThe motivation part is missing. It seems to me that the paper simply try to combine the Transformer with PixelCNN/RNN based image generation without a clear explanation why this is needed. Why self-attention is so important for image generation? Why not just a deeper network with more parameters? Throughout the paper I cannot find a clear answer for this. Based on this I couldn\'t see a clear contribution. \n\nThe paper is difficult to keep the track given the current flow. Each subsection of section 3 starts with technique details without explaining why we do this. Some sentences like ""look pretty cool"" is not academic. \n\nThe experiments lack comparisons except the human evaluation, while the log-likelihood improvement is marginal. I am wondering how the human evaluation is conducted. Does it compare all the competing algorithms against the same sub-samples of the GT data? How many pairs have been compared for each algorithm?  Apart from this metric, I would like to see qualitative comparison between competing algorithms in the paper as well. Also other approaches e.g. SRGAN could be compared. \n\nI am also interested about the author\'s claim that the implementation error that influences the log-likelihood. Has this been fixed after the deadline?']","[-20, -20, -50]","[60, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the work is 'promising' and 'interesting', they express several concerns about the paper's clarity, motivation, and experimental evaluation. The reviewer states that the manuscript 'doesn't seem quite ready for publication yet', indicating a generally negative sentiment despite some positive aspects.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful language throughout and offers constructive criticism. They encourage the authors to improve the paper and provide specific suggestions for enhancement. The tone is professional and supportive, even when pointing out weaknesses. However, it's not extremely polite as it does directly criticize aspects of the work.\n\nThe reviewer uses phrases like 'I would strongly encourage the authors' and 'Please re-consider the wording', which are polite ways of offering criticism. They also balance negative feedback with positive comments, such as calling the work 'promising' and 'interesting'. The language is formal and appropriate for a scientific peer review, avoiding any rudeness or harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the value of the work, they express disappointment with the small improvements and suggest more work is needed. They also point out several limitations and issues with the study. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive criticism, and expresses openness to adjusting their opinion based on feedback. They use phrases like 'I think', 'Please consider', and 'I am open to adjusting my score' which contribute to a polite tone. However, some direct criticisms and the suggestion to rephrase the abstract's last sentence slightly reduce the politeness score from being very high."", ""The sentiment score is -50 because the review is predominantly negative. While it acknowledges some 'good results' qualitatively, it lists several significant cons including poor writing, lack of motivation, and difficulty in following technical details. The reviewer also expresses skepticism about the paper's contribution and the necessity of the proposed method. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I am wondering' and 'I am interested' to soften their criticisms, and provide specific suggestions for improvement. However, they also directly point out flaws without much sugar-coating, which prevents a higher politeness score.""]"
"['In this contribution, the authors propose an improvement of a tensor decomposition method for decoding spike train. Relying on a non-negative matrix factorization, the authors tackle the influence of the baseline activity on the decomposition. The main consequence is that the retrieved components are not necessarily non-negative and the proposed decomposition rely on signed activation coefficients. An experimental validation shows that for high frequency baseline (> 0.7 Hz), the baseline corrected algorithm yields better classification results than non-corrected version (and other common factorization techniques). \n\nThe objective function is defined with a Frobenius norm, which has an important influence on the obtained solutions, as it could be seen on Figure 2. The proposed method seems to provide a more discriminant factorization than the NMF one, at the expense of the sparsity of spatial and temporal components, impeding the biological interpretability.  A possible solution is to add a regularization term to the objective function to ensure the sparsity of the factorization.', 'This study proposes the use of non-negative matrix factorization accounting for baseline by subtracting the pre-stimulus baseline from each trial and subsequently decompose the data using a 3-way factorization thereby identifying spatial and temporal modules as well as their signed activation. The method is used on data recorded from mouse and pig retinal ganglion cells of time binned spike trains providing improved performance over non-baseline corrected data. \n\nPros:\nThe paper is well written, the analysis interesting and the application of the Tucker2 framework sound. Removing baseline is a reasonable step and the paper includes analysis of several spike-train datasets. The analysis of the approaches in terms of their ability to decode is also sound and interesting.\n\nCons:\nI find the novelty of the paper limited: \nThe authors extend the work by (Onken et al. 2016) to subtract baseline (a rather marginal innovation) of this approach. To use a semi-NMF type of update rule (as proposed by Ding et al .2010) and apply the approach to new spike-train datasets evaluating performance by their decoding ability (decoding also considered in Onken et al. 2016).\n\nMultiplicative update-rules are known to suffer from slow-convergence and I would suspect this also to be an issue for the semi-NMF update rules. It would therefore be relevant and quite easy to consider other approaches such as active set or column wise updating also denoted HALS which admit negative values in the optimization, see also the review by N. Giles\nhttps://arxiv.org/abs/1401.5226\nas well as for instance:\nNielsen, Søren Føns Vind, and Morten Mørup. ""Non-negative tensor factorization with missing data for the modeling of gene expressions in the human brain."" Machine Learning for Signal Processing (MLSP), 2014 IEEE International Workshop on. IEEE, 2014.\n\nIt would improve the paper to also discuss that the non-negativity constrained Tucker2 model may be subject to local minima solutions and have issues of non-uniqueness (i.e. rotational ambiguity). At least local minima issues could be assessed using multiple random initializations.\n\nThe results are in general only marginally improved by the baseline corrected non-negativity constrained approach. For comparison the existing methods ICA, Tucker2 should also be evaluated for the baseline corrected data, to see if it is the constrained representation or the preprocessing influencing the performance. Finally, how performance is influenced by dimensionality P and L should also be clarified.\n\nIt seems that it would be naturally to model the baseline by including mean values in the model rather than treating the baseline as a preprocessing step. This would bridge the entire framework as one model and make it potentially possible to avoid structure well represented by the Tucker2 representation to be removed by the preprocessing.\n\n\n\nMinor: \nThe approach corresponds to a Tucker2 decomposition with non-negativity constrained factor matrices and unconstrained core - please clarify this as you also compare to Tucker2 in the paper with orthogonal factor matrices.\n\nDing et al. in their semi-NMF work provide elaborate derivation with convergence guarantees.  In the present paper these details are omitted and it is unclear how the update rules are derived from the KKT conditions and the Lagrange multiplier and how they differ from standard semi-NMF, this should be better clarified. \n\n', ""In this paper, the authors present an adaptation of space-by-time non-negative matrix factorization (SbT-NMF) that can rigorously account for the pre-stimulus baseline activity. The authors go on to compare their baseline-corrected (BC) method with several established methods for dimensionality reduction of spike train data.\n\nOverall, the results are a bit mixed. The BC method often performs similarly to or is outperformed by non-BC SbT-NMF. The authors provide a possible mechanism to explain these results, by analyzing classification performance as a function of baseline firing rate. The authors posit that their method can be useful when sensory responses are on the order of magnitude of baseline activity; however, this doesn't fully address why non-BC SbT-NMF can strongly outperform the BC method in certain tasks (e.g. the step of light, Fig. 3b). Finally, while this method introduces a principled way to remove mean baseline activity from the sensory-driven response, this may also discount the effect that baseline firing rate and fast temporal fluctuations can have on the response (Destexhe et al., Nature Reviews Neuroscience 4, 2003; Gutnisky DA et al., Cerebral Cortex 27, 2017).""]","[50, -20, -20]","[75, 60, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the authors' proposed improvement and its better performance in certain conditions, but also points out limitations and suggests improvements. The review is balanced, recognizing both strengths and areas for enhancement. The politeness score is 75 (quite polite) as the reviewer uses neutral, professional language throughout. They objectively describe the work, its merits, and potential improvements without using harsh or critical language. The suggestion for improvement is presented constructively as a 'possible solution' rather than a demand or criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'interesting', 'sound'), they express significant concerns about the novelty and limitations of the study. The reviewer states 'I find the novelty of the paper limited' and provides several critiques and suggestions for improvement, indicating an overall slightly negative sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, balancing criticism with praise, and offering constructive suggestions. They use phrases like 'It would improve the paper to...' and 'It would be relevant...', which are polite ways of suggesting improvements. The reviewer also acknowledges the strengths of the paper before delving into criticisms, which is a polite approach to peer review."", ""The sentiment score is slightly negative (-20) because the reviewer points out mixed results and some limitations of the proposed method. They mention that the baseline-corrected (BC) method often performs similarly to or is outperformed by non-BC SbT-NMF, and that the authors' explanation doesn't fully address certain performance discrepancies. However, the review isn't entirely negative, as it acknowledges the authors' efforts to provide explanations and potential use cases for their method. The politeness score is moderately positive (50) because the reviewer uses neutral, professional language throughout. They present criticisms constructively, using phrases like 'the results are a bit mixed' and 'this doesn't fully address,' rather than using harsh or dismissive language. The reviewer also acknowledges the authors' contributions and attempts to explain their results, which contributes to the polite tone.""]"
"['In this paper, the authors present a computational framework for the active vision problem. Motivating the study biologically, the authors explain how the control policy can be learned to reduce the entropy of the posterior belief, and present an application (MNIST digit classification) to substantiate their proposal.\n\nI am not convinced about the novelty and contribution of the work. The active vision/sensing problem has been well studied and both the information theory and Bayes risk formulations have already been considered in previous works (see Najemnik and Geisler, 2005; Butko and Movellan, 2010; Ahmad and Yu, 2013).\n\nThe paper is also rife with spelling mistakes and grammatical errors and needs a thorough revision. Examples: foveate inspection the data (abstract), may allow to (motivation), tu put it clear (motivation), on contrary to animals retina (footnote 1), minimize at most the current uncertainty (perception-driven control), center an keep (fovea-based implementation), degrade te recognition (outlook and perspective). The citations are in non-standard format (section 1.2: Kalman (1960)).\n\nOverall, I think the paper considers an important problem but the contribution to the state of the art is minimal, and editing highly lacking. \n\n1. J Najemnik and W S Geisler. Optimal eye movement strategies in visual search. Nature, 434(7031):387–91, 2005.\n2. N J Butko and J R Movellan. Infomax control of eye movements. IEEE Transactions on Autonomous Mental Development, 2(2):91–107, 2010.\n3. S Ahmad and A J Yu. Active sensing as Bayes-optimal sequential decision-making. Uncertainty in Artificial Intelligence, 2013.', 'It is rather difficult to evaluate the manuscript. A large part of the manuscript reviews various papers from the active vision domain and subsequently proposes that this can directly be modeled using Friston’s free energy principle, essentially, by “analogy”, as the authors state. This extends up to page 4. I would argue, that this is quite a stretch, as the free energy principle is essentially blind to the idea of rewards and preferable states such that all tasks are essentially evaluated in terms surprise reduction. This is very much different from large part of the cited classic active vision literature. The authors furthermore introduce a simplification of the setting, i.e. that nothing changes in a scene during saccadic exploration, which is rather unusual for active vision problems. \nThe authors provide some detail about the actual implementation of their model, section 4, but the in depth details required at ICLR are missing. No comparisons to other gaze selection models or saliency models are given. \nFurthermore, the manuscript seems to suggest, that the simulation results are somehow related to human vision as it is stated:\n“The model provides apparently realistic saccades, for they cover the full range of the image and tend to point over regions that contain class-characteristic pixels.”\nbut no actual comparisons or evaluations are provided. ', 'This paper introduces a machine learning adaptation of the active inference framework proposed by Friston (2010), and applies it to the task of image classification on MNIST through a foveated inspection of images. It describes a cognitive architecture for the same, and provide analyses in terms of processing compression and ""confirmation biases"" in the model.\n– Active perception, and more specifically recognition through saccades (or viewpoint selection) is an interesting biologically-inspired approach and seems like an intuitive and promising way to improve efficiency. The problem and its potential applications are well motivated.\n– The perception-driven control formulation is well-detailed and simple to follow.\n– The achieved compression rates are significant and impressive, though additional demonstration of performance on more challenging datasets would have been more compelling\n\nQuestions and comments:\n– While an 85% compression rate is significant, 88% accuracy on MNIST seems poor. A plot demonstrating the tradeoff of \naccuracy for compression (by varying Href or other parameters) would provide a more complete picture of performance. Knowing baseline performance (without active inference) would help put numbers in perspective by providing a performance bound due to modeling choices.\n–\xa0What does the distribution of number of saccades required per recognition (for a given threshold) look like over the entire dataset, i.e. how many are dead-easy vs difficult?\n– Steady state assumption: How can this be relaxed to further generalize to non-static scenes?\n– Figure 3 is low resolution and difficult to read.\n\nPost-rebuttal comments:\n\nI have revised my score after considering comments from other reviewers and the revised paper. While the revised version contains more experimental details, the paper in its present form lacks comparisons to other gaze selection and saliency models which are required to put results in context. The paper also contains grammatical errors and is somewhat difficult to understand. Finally, while it proposes an interesting formulation of a well-studied problem, more comparisons and analysis are required to validate the approach.\n']","[-60, -60, -20]","[20, 20, 60]","[""The sentiment score is -60 because the reviewer expresses significant doubts about the novelty and contribution of the work, points out numerous errors, and states that the contribution to the state of the art is minimal. However, they do acknowledge that the paper considers an important problem, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone and provide specific examples to support their critique. They also offer some positive comments (e.g., 'the paper considers an important problem') which adds a degree of politeness. The language used is not overtly rude, but rather matter-of-fact in its criticism."", ""The sentiment score is -60 because the reviewer expresses significant criticism and skepticism throughout the review. They state it's 'difficult to evaluate the manuscript', argue that the authors' approach is 'quite a stretch', and point out missing comparisons and evaluations. The lack of positive comments and the focus on limitations suggest a negative sentiment. However, it's not entirely negative as the reviewer acknowledges some details provided about the model implementation.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively neutral tone. They use phrases like 'I would argue' and 'The authors provide some detail' which are not rude but also not overtly polite. The criticism is presented as objective observations rather than personal attacks. However, the lack of positive reinforcement or encouraging language prevents a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'well-detailed', 'simple to follow', 'impressive' compression rates), they also point out significant limitations. The reviewer notes poor accuracy on MNIST, lack of comparisons to other models, and the need for more analysis to validate the approach. The final paragraph indicates a downward revision of their score, suggesting an overall negative sentiment.\n\nThe politeness score is moderately positive (60) as the reviewer uses respectful and constructive language throughout. They begin with positive observations, use phrases like 'interesting' and 'promising', and frame criticisms as questions or suggestions for improvement rather than harsh critiques. The tone remains professional and helpful, even when pointing out weaknesses in the paper.""]"
"['This paper presents a new way of training stochastic neural network following an information relevance/compression framework similar to the Information Bottleneck. A new training objective is defined as a sum of mutual informations (MI) between the successive stochastic hidden layers plus a sum of mutual informations between each layer and the relevance variable. \n\nThe idea is interesting and to my knowledge novel. Experiments are carefully designed and presented in details, however assessing the impact of the proposed new objective is not straightforward. It would have been interesting to compare not only with SFNN but also to a model with the same architecture and same gradient estimator (Raiko et al. 2014) using maximum likelihood. This would allow to disentangle the impact of the learning mechanism from the impact of the learning objective. \n\nWhy is it important to maximise I(X_l, Y) for every layer? Does that impact the MI of the final layer and Y?  \n\nTo estimate the MI between a hidden layer and the relevance variable, a multilayer generalisation of the variational bound from Alemi et al. 2016. Computation of the bound requires integration over multiple layers (equation 15). How is this achieved in practice? With high-dimensional hidden layers a Monte-Carlo estimate on the minibatch can be very noisy and the resulting estimation of MI could be poor.\n\nMutual information between the successive layers is decomposed as an entropy plus a conditional entropy term (eq 17). How is the conditional entropy term estimated? The entropy term is first bounded by conditioning on the previous layer and then estimated using Monte Carlo sampling with a plug-in estimator. Plug-in estimators are known to be inefficient in high dimensions even using a full dataset unless the number of samples is very large. It thus seems challenging to use mini batch MC, how does the mini batch estimation compare to an estimation using the full dataset? What is the variance of the mini batch estimate?\n\nIn the related work section, the IB problem can also be solved efficiently for meta-Gaussian distribution as explained in Rey et al. 2012 (Meta-gaussian information bottleneck). \n\nThere is a small typo in (eq 5).\n', '# Paper overview:\nThis paper views the learning process for stochastic feedforward networks through the lens of an\niterative information bottleneck process; at each layer an attempt is made to minimise the mutual\ninformation (MI) with the feed-in layer while maximising the MI between that layer and the presumed-endogenous variable, \'Y\'.\n\nTwo propositions are made, (although I would argue that their derivations are trivially the consequence\nof the model structure and inference scheme defined), and experiments are run which compare the approach to maximum likelihood estimation for \'Y\' using an equivalent stochastic network architecture.\n\n# Paper discussion:\nIn general I like the idea of looking further into the effect of adding network structure on the original\ninformation bottleneck results (empirical and theoretical).  I would be interested to see if layerwise\ninput skip connections (i.e. between each network layer L_i and the original input variable \'X\') hastened the \'compression\' stage of learning e.g. (i.e. the time during which the intermediate layers minimise MI with \'X\').  I\'m also interested that clear examples of the information bottleneck principle in practice (e.g. CCA) are rarely mentioned.\n\nOn the other hand, I think this paper is not quite ready: it reads like work written in a hurry, and is at times hard to follow as a result.  There are several places where I think the terminology does not quite reflect what the authors perhaps hoped to express, or was otherwise slightly clumsy e.g:\n\n* ""...self-consistent equations are highly non-linear and still too abstract to be used for many..."", presumably what was implied was that the original solution to the information bottleneck as expressed by Tishby et al is non-analytic for most practical cases of interest?\n\n* ""Furthermore, we exploit the existing network architecture as variational decoders rather than resort to variational decoders that are not part of the neural network architecture."" -> The existing network architecture is used to provide a variational inference framework for I(Z,Y).\n\n* ""On average, 2H(X|Z) elements of X are mapped to the same code in Z."" In an ideal world I would like the assumptions required for this to hold true to be a fleshed out a little here.\n\n* ""The generated bottleneck samples are then used to estimate mutual information"" -> an empirical estimation of I(Z,X) would seem a very high variance estimator; the dimensionality of X is typically large in modern deep-learning problems---do you have any thoughts on how the learning process fares as this varies?  Further on you cite that L_PIB is intractable due to the high dimensionality of the bottleneck variables, I imagine that this still yields a high var MC estimator in your approximation (in practice)?  Was the performance significantly worse without the Raiko estimator?\n\n* ""In this experiment, we compare PIBs with ...."" -> I find this whole section hard to read, the description of how the models relate to each other is a little difficult to follow at first sight.\n\n* Information dynamics of learning process (Figures 3, 6, 7, 8) -> I am curious as to why you did not run the PIB for the same number of epochs as the SFNN?  I would also argue that you did not run either method as long as you should have (both approaches lack the longer term \'compression\' stage whereby layers near the input reduce I(X,Z_i) as compared to their starting condition)?  This property is visible in I(Z_2,X) for PIB in Figure 3, but otherwise absent.\n\n# Conclusion:\nIn conclusion, while interesting, for me the paper is not yet ready for publication.  I would recommend this work for a workshop presentation at this stage.\n', 'This paper proposes a learning method (PIB) based on the information bottleneck framework.\nPIB pursues the very natural intuition outlined in the information bottleneck literature: hidden layers of deep nets compress the input X while maintaining sufficient information to predict the output Y.\nIt should be noted that the limitations of the IB for deep learning are currently under heavy discussion on OpenReview.\nOptimizing the PIB objective is intractable and the authors propose an approximation that applies to binary valued stochastic networks.\nThey use a variational bound to deal with the relevance term, I(Z_l,Y), and  Monte Carlo sampling to deal with the layer-by-layer compression term, I(Z_l,Z_{l+1}).\nThey present results on MNIST aiming to demonstrate that using PIBs improves generalization and training speed.\n\nThis is a timely and interesting topic. I enjoyed learning about the authors’ proposed approach to a practical learning method based on the information bottleneck. However, the writing made it challenging and the experimental protocol raised some serious questions. In summary, I think the paper needs very careful editing for grammar and language and, more importantly, it needs solid experiments before it’s ready for publication. When that is done it would make an exciting contribution to the community. More details follow.\n\n\nComments:\n1. All architectures and objectives (both classic and PIB-based) are trained using a single, fixed learning rate (LR). In my opinion, this is a red flag. The PIB objective is new and different to the other objectives. Do all objectives happen to yield their best performance under the same LR? Maybe so, but we won’t know unless the experimental protocol prescribes a sufficient range of LRs for each architecture. In light of this, the fact that SFNN is given extra epochs in Figure 4 does not mean much.\n2. The batch size for MNIST classification is unusually low (8). Common batch sizes range from 64 to 1K (typically >= 128). Why did the authors make this choice? Is 8 good for architectures A through E?\n3. On a related note, the authors only seem to report results from a single random seed (ie. deterministic architectures are trained exactly once). I would like to see results from a few different random seeds. As a result of comments 1,2,3, even though I do believe in the merit of the intuition pursued and the techniques proposed, I am not convinced about the main claim of the paper. In particular, the experiments are not rigorous enough to give serious evidence that PIBs improve generalization and training speed. \n4. The paper needs some careful editing both for language (cf. following point) but also notation. The authors use notation p_D() in eqn (12) without defining it. My best guess is that it is the same as p_u(), the underlying data distribution, but makes parsing the paper hard. Finally there are a few steps that are not explained: for example, no justification is given for the inequality in eqn (13).\n5. Language: the paper needs some careful editing to correct numerous language/grammar issues. At times it is detrimental to understanding. For example I had to read the text leading up to eqn (8) a number of times.\n6. There is no discussion of computational complexity and wall-clock time comparisons. To be clear, I think that even if the proposed approach were to be slower than the state of the art it would still be very interesting. However, there should be some discussion and reporting of that aspect as well.\n\n\nMinor comments and questions:\n7. Mutual information is typically typeset using a semicolon instead of a comma, eg. I(X;Z).\n8. Why is the mutual information in Figure 3 so low? Are you perhaps using natural logarithms to estimate and plot I(Z;Y)? If this is base-2 logarithms I would expect a value close to 1. ']","[50, -30, -20]","[80, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer describes the paper's idea as 'interesting and novel', and notes that the experiments are 'carefully designed and presented in details'. However, they also express some concerns and suggest additional comparisons, indicating a balanced view. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions (e.g., 'It would have been interesting to...', 'Why is it important to...?'), and acknowledges the paper's strengths before offering critiques. The reviewer also points out a small typo in a non-judgmental way. The overall tone is constructive and professional, without any harsh or rude language."", ""The sentiment score is -30 because while the reviewer expresses some interest in the paper's ideas ('In general I like the idea...'), they ultimately conclude that the paper is not ready for publication ('...the paper is not yet ready for publication'). They point out several issues with clarity and terminology, suggesting the paper was 'written in a hurry'. However, the criticism is balanced with some positive comments, hence a moderately negative score rather than strongly negative. The politeness score is 50 because the reviewer uses generally polite language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'I would be interested to see...' and 'I am curious as to why...', which maintain a respectful tone. The reviewer also acknowledges positive aspects before presenting criticisms, which is a polite approach. However, the score is not higher as the review is direct in its criticisms without excessive softening language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting topic and potential contribution, they express significant concerns about the experimental protocol and writing quality. The reviewer states that the paper needs 'very careful editing' and 'solid experiments before it's ready for publication,' indicating that substantial revisions are required. However, the score is not deeply negative because the reviewer also mentions the paper's potential to make an 'exciting contribution' once revised. The politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They begin with positive comments about the paper's topic and their enjoyment in learning about the approach. The critique is presented as suggestions for improvement rather than harsh criticism. The reviewer uses phrases like 'I enjoyed learning,' 'I think,' and 'I would like to see,' which maintain a respectful tone. However, the score is not extremely high as the review is direct in pointing out flaws and doesn't use overly polite language.""]"
"['This paper presents an alternative approach to constructing variational lower bounds on data log likelihood in deep, directed generative models with latent variables. Specifically, the authors propose using approximate posteriors shared across groups of examples, rather than posteriors which treat examples independently. The group-wise posteriors allow amortization of the information cost KL(group posterior || prior) across all examples in the group, which the authors liken to the ""KL annealing"" tricks that are sometimes used to avoid posterior collapse when training models with strong decoders p(x|z) using current techniques for approximate variational inference in deep nets.\n\nThe presentation of the core idea is solid, though it did take two read-throughs before the equations really clicked for me. I think the paper could be improved by spending more time on a detailed description of the model for the Omniglot experiments (as illustrated in Figure 3). E.g., explicitly describing how group-wise and per-example posteriors are composed in this model, using Equations and pseudo-code for the main training loop, would have saved me some time. For readers less familiar with amortized variational inference in deep nets, the benefit would be larger.\n\nI appreciate that the authors developed extensions of the core method to more complex group structures, though I didn\'t find the related experiments particularly convincing. \n\nOverall, I like this paper and think the underlying group-wise posterior construction trick is worth exploring further. Of course, the elephant in the room is how to determine the groups across which the posteriors can be shared and their information costs amortized.', '- Good work on developing VAEs for few-shot learning.\n- Most of the results are qualitative and I reckon the paper was written in haste.\n- The rest of the comments are below:\n\n- 3.1: I got a bit confused over what X actually is:\n -- ""We would like to learn a generative model for **sets X** of the form"".\n --""... to refer to the **class X_i** ..."".\n -- ""we can lower bound the log-likelihood of each **dataset X** ...""\n\n- 3.2: ""In general, if we wish to learn a model for X in which each latent variable ci affects some arbitrary subset Xi of the data (**where the Xi may overlap**), ..."": Which is just like learning a Z for a labeled X but learning it in an unsupervised manner, i.e. the normal VAE, isn\'t it? If not, could you please elaborate on what is different (in the case of 3.2 only, I mean)? i.e. Could you please elaborate on what\'s different (in terms of learning) between 3.2 and a normal latent Z that is definitely allowed to affect different classes of the data without knowing the classes?\n\n- Figure 1 is helpful to clarify the main idea of a VHE.\n\n- ""In a VHE, this recognition network takes only small subsets of a class as input, which additionally ..."": And that also clearly leads to loss of information that could have been used in learning. So there is a possibility for potential regularization but there is definitely a big loss in estimation power. This is obviously possible with any regularization technique, but I think it is more of an issue here since parts of the data are not even used in learning.\n\n- ""Table 4.1 compares these log likelihoods, with VHE achieving state-of-the-art. To"": Where is Table 4.1??\n\n- This is a minor point and did not have any impact on the evaluation but VAE --> VHE, reparameterization trick --> resampling trick. Maybe providing rather original headings is better? It\'s a style issue that is up to tastes anyway so, again, it is minor.\n\n- ""However, sharing latent variables across an entire class reduces the encoding cost per element is significantly"": typo.\n\n- ""Figure ?? illustrates"".\n', 'The paper presents some conceptually incremental improvements over the models in “Neural Statistician” and “Generative matching networks”. Nevertheless, it is well written and I think it is solid work with reasonable convincing experiments and good results. Although, the authors use powerful PixelCNN priors and decoders and they do not really disentangle to what degree their good results rely on the capabilities of these autoregressive components.']","[60, -20, 50]","[80, 50, 60]","[""The sentiment score is 60 (moderately positive) because the reviewer expresses overall approval of the paper, stating 'I like this paper' and that the core idea is 'worth exploring further'. However, they also mention some areas for improvement and express skepticism about certain experiments, which prevents a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. Phrases like 'I appreciate' and 'I think the paper could be improved by' demonstrate a courteous tone. The reviewer also admits personal difficulty in understanding parts of the paper, which shows humility rather than harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges 'good work' at the beginning, they also mention that the paper seems hastily written and most results are qualitative. They point out several issues and missing elements, which contributes to the overall negative sentiment. However, it's not extremely negative as they do provide constructive feedback. The politeness score is moderately positive (50) because the reviewer uses generally polite language, starting with a positive comment, and phrases their criticisms as questions or suggestions rather than harsh criticisms. They use phrases like 'Could you please elaborate' and acknowledge when a point is minor. The tone is professional and constructive throughout, even when pointing out issues."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'solid work' with 'reasonable convincing experiments and good results', despite noting that the improvements are 'conceptually incremental'. The reviewer also praises the paper as 'well written'. However, the score is not higher due to the critique about the reliance on PixelCNN components. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, balancing praise with constructive criticism. They use phrases like 'I think' to soften their opinions and acknowledge the paper's strengths before mentioning limitations. The tone is professional and courteous, without being overly formal or effusive.""]"
"['Interesting work, but I’m not convinced by the arguments nor by the experiments. Similar models have been trained before; it’s not clear that the proposed pretraining procedure is a practical step forwards. And quite some decisions seem ad-hoc and not principled. \n\nNevertheless, interesting work for everyone interested in RBMs as priors for “binary VAEs”. \n\n', ""While I acknowledge that training generative models with binary latent variables is hard, I'm not sure this paper really makes valuable progress in this direction. The only results that seem promising are those on binarized MNIST, for the non-convolutional architecture, and this setting isn't particularly exciting. All other experiments seem to suggest that the proposed model/algorithm is behind the state of the art. Moreover, the proposed approach is fairly incremental, compared to existing work on RWS, VIMCO, etc.\n\nSo while this work seem to have been seriously and thoughtfully executed, I think it falls short of the ICLR acceptance bar."", 'Summary of the paper:\nThe paper proposes to augment a variational auto encoder (VAE) with an binary restricted Boltzmann machine (RBM) in the role of the prior of the generative model. To yield a good initialisation of the parameters of the RBM and the inference network a special pertaining procedure is introduced. The model produces competitive Likelihood results on MNIST and was further tested on CIFAR 10. \n\nClarity and quality: \n\n1. From the description of the pertaining procedure and the appendix B I got the impression that the inference network maps into [0,1] and not into {0,1}.  Does it mean, you are not really considering binary latent variables (making the RBM model the values in [0,1] by its probability p(z|h))? \n\n2. on page 2:\nRWS....""derive a tighter lower bound"": Where does the ""tighter"" refer to? \n\n3. ""multivariate Bernoulli modeled by an RBM"": Note,  while in a multivariate Bernoulli the binary variables would be independent from each others, this is usually not the case for the visible variables of RBMs (only in the conditional distribution given the state of the hidden variables).\n\n4. The notation could be improved, e.g.:\n-x_data and x_sample are not explained\n- M is not defined in equation 5. \n\n5. ""this training method has been previously used to produce the best results on MNIST"" Note, that parallel tempering often leads to better results when training RBMs (see http://proceedings.mlr.press/v9/desjardins10a/desjardins10a.pdf) . Furthermore, centred RBMs are also get better results than vanilla RBMs (see: http://jmlr.org/papers/v17/14-237.html).\n\nOriginality and significance:\nAs already mentioned in a comment on open-review the current version of the paper misses to mention one very related work: ""discrete variational auto encoders"". Also ""bidirectional Helmholtz machines"" could be mentioned as generative model with discrete latent variables.  The results for both should also be reported in Table 1 (discrete VAEs: 81,01, BiHMs: 84,3). \n\nFrom the motivation the advantages of the model did not become very clear to me. Main advantage seems to be the good likelihood result on MNIST (but likelihood does not improve compared to IWAE on CIFAR 10 for example). However, using an RBM as prior has the disadvantage that sampling from the generative model requires running a Markov chain now while having a solely directed generative model allows for fast sampling. \n\nExperiments show good likelihood results on MNIST. Best results are obtained when using a ResNet decoder. I wondered how much a standard VAE is improved by using such a powerful decoder. Reporting this, would allow to understand, how much is gained from using a RBM for learning the prior. \n\nMinor comments:\npage 1:\n""debut of variational auto encoder (VAE) and reparametrization trick"" -> debut of variational auto encoders (VAE) and the reparametrization trick"",\npage 2:\n""with respect to the parameter of  p(x,z)"" -> ""with respect to the parameters of  p(x,z)""\n""parameters in p"" -> ""parameters of p"" \n""is multivariate Bernoulli"" ->  ""is a multivariate Bernoulli""\n""we compute them"" -> ""we compute it"" \npage 3:\n""help find a good"" ->  ""help to find a good""\npage 7:\n""possible apply"" -> ""possible to apply""']","[-30, -60, -20]","[20, 20, 60]","[""The sentiment score is slightly negative (-30) because the reviewer expresses skepticism about the work's novelty and arguments, using phrases like 'not convinced' and 'not clear that the proposed pretraining procedure is a practical step forwards'. However, they do acknowledge it as 'interesting work', which prevents the score from being more negative. The politeness score is slightly positive (20) as the reviewer uses polite language like 'Interesting work' and avoids harsh criticism. They express their concerns in a professional manner, though they don't use overtly polite phrases. The tone is more neutral than explicitly polite, hence the moderate positive score."", ""The sentiment score is -60 because the reviewer expresses significant doubts about the paper's value and contribution, stating it 'falls short of the ICLR acceptance bar' and that most results suggest the proposed model/algorithm is 'behind the state of the art'. However, it's not entirely negative as they acknowledge the work was 'seriously and thoughtfully executed'. The politeness score is 20 because while the reviewer is critical, they use relatively polite language, acknowledging the difficulty of the task and the effort put into the work. They avoid harsh or rude phrasing, instead using more neutral terms like 'I'm not sure' and 'I think'. The reviewer also starts with a positive acknowledgment before moving to criticism, which is a polite approach."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('competitive Likelihood results'), they raise several concerns and questions about the paper's clarity, methodology, and originality. The reviewer points out missing comparisons, unclear advantages, and potential improvements, indicating a somewhat critical stance. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They use polite language such as 'I got the impression' and 'I wondered', and frame criticisms as questions or suggestions rather than direct attacks. The reviewer also provides specific recommendations for improvement and acknowledges the paper's strengths, which contributes to the overall polite tone.""]"
"['Authors of this paper derived an efficient quantum-inspired learning algorithm based on a hierarchical representation that is known as tree tensor network, which is inspired by the multipartite entanglement renormalization ansatz approach where the tensors in the TN are kept to be unitary during training. Some observations are: The limitation of learnability of TTN strongly depends on the physical indexes and the geometrical indexes determine how well the TTNs approximate the limit; TTNs exhibit same increase level of abstractions as CNN or DBN; Fidelity and entanglement entropy can be considered as some measurements of the network.\n\nAuthors introduced the two-dimensional hierarchical tensor networks for solving image recognition problems, which suits more the 2-D nature of images. In section 2, authors stated that the choice of feature function is arbitrary, and a specific feature map was introduced in Section 4. However, it is not straightforward to connect (10) to (1) or (2). It is better to clarify this connection because some important parameters such as the virtual bond and input bond are related to the complexity of the proposed algorithm as well as the limitation of learnability. For example, the scaling of the complexity O(dN_T(b_v^5 + b_i^4)) is not easy to understand. Is it related to specific feature map? How about the complexity of eigen-decomposition for one tensor at each iterates. And also, whether the tricks used to accelerate the computations will affect the convergence of the algorithm? More details on these problems are required for readers’ better understanding.\n\nFrom Fig 2, it is difficult to see the relationship between learnability and parameters such input bond and virtual bond because it seems there are no clear trends in the Fig 2(a) and (b) to make any conclusion. It is better to clarify these relationships with either clear explanation or better examples.\n\nFrom Fig 3, authors claimed that TN obtained the same levels of abstractions as in deep learning. However, from Fig 3 only, it is hard to make this conclusion. First, there are not too many differences from Fig 3(a) to Fig 3(e).  Second, there is no visualization result reported from deep learning on the same data for comparison. Hence, it is not convincing to draw this conclusion only from Fig 3. \n\nIn Section 4.2, what strategy is used to obtain these parameters in Table 1?\n\nIn Section 5, it is interesting to see more experiments in terms of fidelity and entanglement entropy.\n', 'The paper studies the mapping of a mathematical object representing quantum entanglement to a neural network architecture that can be trained to predict data, e.g. images. A contribution of the paper is to propose a 2D tensor network model for that purpose, which has higher representation power than simple tensor networks used in previous works.\n\nThere are several issues with the paper: \n\nFirst, it is hard to relate the presented model to its machine learning counterpart. e.g. it is not stated clearly what is the underlying function class (are they essentially linear classifiers built on some feature space representation?).\n\nThe benchmark study doesn’t bring much evidence about the modeling advantages brought by the proposed method. Separating pairs of CIFAR-10 classes is relatively easy and can be done with reasonable accuracy without much nonlinearity. Similarly, an error rate of 5% on MNIST is already achievable by basic machine learning classifiers.\n\nThe concept of bond and bond dimensions, which are central in this paper due to their relation to model complexity, could be better explained.', 'Full disclosure: the authors\' submission is not anonymous. They included a github link at the bottom of page 6 and I am aware of the name of the author and coauthors (and have previously read their work and am a fan of it). Thus, this review is not double blind. I notified the area chair last week and we agreed that I submit this review. \n\n---\n\nThis is an interesting application of tensor networks to machine learning. The work proposes using a tree tensor network for image classification. Each image is first mapped into a higher-dimensional space. Then the input features are contracted with the tensors of the tensor network. The maximum value of the final layer of the network gives the predicted class. The training algorithm is inspired by the multipartite entanglement renormalization ansatz: it corresponds to updating each tensor in the network by performing a singular value decomposition of the environment tensor (everything in the cost function after removing the current tensor to be updated).\n\nOverall, I think this is an interesting, novel contribution, but it is not accessible to non-physicists right now. The paper could be rewritten to be accessible to non-physicists and would be a highly-valuable interdisciplinary contribution.\n\n* Consider redoing the experiments with a different cost function: least squares is an unnatural cost function to use for classification. Cross entropy would be better.\n\n* discuss the scalability: why did you downsample MNIST from 28x28 pixels to 16x16 pixels? Why is training accuracy not reported on the 10-class model in Table 1? If it is because of a slow implementation, that\'s fine. But if it is because of the scalability of the method, it would be good to report that. In either case it wouldn\'t hurt the paper, it is just important to know. \n\n* In section 5, you say ""input vectors are still initially arranged ... according to their spatial locations in the image"". But don\'t you change the spatial locations of the image to follow equation (10)? It would be good to add a sentence clarifying this. \n\n---\n\nIn its current form, reading the paper requires a physics background. \n\nThere are a few things that would make it easier to read for a general machine learning audience:\n\n* connect your method to matrix factorization and tensor decomposition approaches\n\n* include an algorithm box for Strategy-I and Strategy-II\n\n* include an appendix, with a brief review of upward and downward indices which is crucial for understanding your method (few people in machine learning are familiar with Einstein notation)\n\n* relate your interesting ideas about quantum states to existing work in information theory. I am skeptical of the label \'quantum\': how do quantum mechanical tools apply to images? What is a \'quantum\' many-body state here? There is no intrinsic uncertainty principle at play in image classification. I would guess that the ideas you propose are equivalent to existing work in information theory. That would make it less confusing.\n\n* in general, maybe mention the inspiration of your work from MERA, but avoid using physics language when there are no clear physical systems. This will make your work more understandable and easier to follow. A high-level motivation for MERA from a physics perspective suffices; the rest can be phrased in terms of tensor decompositions.  \n\n---\n\nMinor nits:\n\n* replace \\citet with \\citep everywhere - all citations are malformed\n\n* figure 1 could be clarified - say that see-through gray dots are dimensions, blue squares are tensors, edges are contractions\n\n* all figure x and y labels and legends are too small\n\n* some typos: ""which classify an input image by choosing""; ""we apply different feature map to each""; small grammar issues in many places\n\n* Figure 4: ""up-down"" and ""left-right"" not defined anywhere']","[20, -50, 50]","[60, 20, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the authors' work and provides constructive feedback. They mention interesting aspects of the paper and suggest areas for improvement, indicating a generally positive but critical stance. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, avoiding harsh criticism and instead offering suggestions for clarification and improvement. They use phrases like 'it is better to clarify' and 'it is interesting to see more experiments,' which maintain a polite and constructive tone. The reviewer also balances critique with positive observations, contributing to the overall polite tone of the review."", ""The sentiment score is -50 because the review starts with a neutral description of the paper's content, but then lists several issues, indicating a generally negative sentiment. However, it's not extremely negative as it acknowledges the paper's contribution. The politeness score is 20 because the language is professional and constructive, avoiding harsh criticism. The reviewer uses phrases like 'it is hard to relate' and 'could be better explained' instead of more direct criticisms. The tone is polite but not overly deferential, maintaining a neutral to slightly positive politeness level."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the work as 'interesting' and 'novel', and sees potential value in it, but also points out several areas for improvement and accessibility issues. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as recommendations rather than demands. The reviewer also acknowledges potential biases upfront and provides detailed, helpful feedback to improve the paper.""]"
"['In this paper the authors address the very important challenges of current deep learning approaches, which is that these algorithms typically need an extraordinarily large number of training rounds to learn their strategies.  The authors note that in real life, this type of training will outstrip both the training and time budget of most real world problems.  The solution they propose is to take a high level approach and to learn more like humans do by creating strategies that involve relationships between entities rather than trying to build up strategies from pixels. \nThe authors credit their reframing of their approach to AI to the “continental philosophers” (e.g. Heidegger) in opposition to the “analytical philosophers” such as Wittgenstein.  The authors associate current machine learning approaches with the analytic philosophers, based on propositions that are either provably true or untrue and their own approach as in opposition to these, however from my reading of this paper what the authors are saying is that if you start learning with higher level concepts (relationships between entities) rather than doing analysis on low level information such as pixels.   Starting with low level concepts makes learning very difficult at first and leads to a path where many trials are required.  Staring from higher level concepts such as relationships between entities allows learning to happen quickly and in a manner much more similar in nature to what humans actually do.\nWhile the authors bring up many valid points, and in essence I believe that they may be correct, the flaw in this paper is that they do not provide methods for teaching computers to learn these higher level concepts.  The algorithms they present all require human knowledge to be encoded in the algorithms to identify the higher level concepts.  The true power of the deep learning approach is that it can actually learn from low level data, without humans hand crafting the higher level entities on their behalf.\n\nWhile I agree with Dreyfus that understanding what is important and interesting given a situation would be an incredible boon to any AI algorithm, it remains an unsolved problem as to how to teach a computer to understand what is interesting in a scene with the same intuition that a human has.  In the first experiment the authors need to pre-define the concepts of a straight road and a curved road and identify them for the algorithm.  They also need to tell the algorithm exactly how to count the number of sections that the track has.  In the second experiment, to identify the “Me” in the game, the authors instruct the computer to recognize “me” as the things that move when the controller is activated.  While in some ways this is clever, mimicking what a child might do to see what moves in the world when it issues a command to move from its own brain and thus learning what “me” is, children take year to develop a sense of “self” and part of that is learning that a “concept of self” is an interesting and useful thing to have.  In their work the authors know, from their human intelligence, what are the important concepts in the game (again from a human perspective) and devise simple methods for the computer to learn these.  Again the problem here is that the human has to define the important concepts for the computer and define a specific strategy for the computer to learn to identify these important policies.  Data intensive deep learning algorithms are able to infer strategies without these concepts being defined for them.\n\nThis reframing does point out a different and perhaps better path for AI, but it is not entirely new and this paper does not present a method for getting from sensed data to higher level concepts.  For each of the experiments, the strategies used rely on human intuition to define policies.  In the first experiment with slot cars, a human needs to provide n laps of driving to imitate.  The authors identify the “shortest lap” and store it for the “AI” to replay.  The only “learning” is from an optimization that minimizes the difference between the AI’s lap time and the best lap time (tbest) of the human by scaling that recorded sample of the human driving.  This results is a strategy that is essentially just trying to replicate (imitate) what the human is doing will not lead to a generalizable learning strategy that could ever exceed a human example.   This is at best a very limited form of imitation learning.  The learning process for the second example is explained in even less detail.\nOverall, this paper presents a different way of thinking about AI, one in which the amount of training time and training data required for learning is greatly reduced, however what is missing Is a generalizable algorithmic strategy for implementing this framework.m  \n\n \n\n\n\n', ""The authors argue that many machine learning systems need a large amount of data and long training times.  To mend those shortcomings their proposed algorithm takes the novel approach of combining mathematical category theory and continental philosophy.  Instead of computation units, the concept of entities and a 'me' is introduced to solve reinforcement learning tasks on a cyber-physical system as well as the Atari environment. This allows for an AI that is understandable for humans at every step of the computation in comparison to the 'black box learning of an neural network. \n\xa0\n\xa0\nPositives:\n\t•\tNovel approach towards more explainable and shorter training times/ less data\n\t•\tSolid mathematical description in part 3.3\n\t•\tSetup well explained\n\xa0\n\xa0\nNegatives:\n\t•\tUse of colloquial language (the first sentence of the abstract alone contains the word 'very' twice)\n\t•\tSome paragraphs are strangely structured\n\t•\tIncoherent abstract \n\t•\tOnly brief and shallow motivation given (No evidence to support the claim)\n\t•.      Brief and therefore confusing mention of methods \n\t•\tNo mention of results\n\t•\tVery short in general\n\t•\tMany grammatical errors (wrong tense use, misuse of a/an,... )\n\t•\tRelated Work is either Background or an explanation of the two test systems. While related approaches in those systems are also provided, the section is mainly used to introduce the test beds \n\t•\tNo direct comparison between algorithm and existing methods is given. It is stated that some extra measures from other measures such as sensors are not used and that it learns to rank with a human in under a minute. However, many questions remain unanswered: But how good is this? How long do other systems need? Is this a valid point to raise? What score functions do other papers use?\n\t•\t2.2: Title choice could have been  more descriptive of the subsection. 'Video Games' indicates a broader analysis of RL in any game but the section mainly restricts itself to the Atari Environment\n\t•\tWhile many methods are mentioned they are not set in context but only enumerated. Many concepts are only named without explanation or how they fit into the picture the authors are trying to paint.\n\xa0\n\t•\tA clear statement of the hypothesis and reason/motivation behind pursuing this approach is missing. Information is indirectly given in the third section where the point is raised that the approach was chosen in contrast to 'black box NNs'. This seems to be a very crucial point that could have been highlighted more. The achieved result are by no means comparable to the NN approaches but they are faster and explainable for a human. \n\t•\tDreyfus' criticism of AI is presented as the key initiator for this idea. Ideas by other authors that utilise this criticism as their foundation are conceptually similar, they could have therefore been mentioned in the related work section.\n\t•\tThe paper fails to mention the current movement in the AI community to make AI more explainable. One of their two key advantages seems to be that they develop a more intuitive explainable system. However, this movement is completely ignored and not given a single mention. The paper, therefore,  does not set their approach in context and is not able to acknowledge related work in this area. \n\t•\tThe section about continental based philosophy is rather confusing\n\t•\tInstead of explaining the philosophy, analytical philosophy is described in details and continental philosophy is only described as not following analytical patterns. A clear introduction to this topic is missing.\n\t•\tWhen described, it is stated that it's a mix of different German and French doctrines that are name dropped but not explained\\ and leave the reader confused.\n\t•\tResult section not well structured and results lack credibility:\n\t•\tLong sections in the result section describe the actual algorithm. This should have been discussed before the results.\n\t•\tResults for slot car are not convincing:\n\t•\tTable 1 only shows the first the last and the best lap (and in most of them the human is better) \n\t•\tNot even an average measure is given only samples. This is very suspicious.\n\t•\tWhy the comparison with DQN and only DQN? How was this comparison initialised? Which parameters were used? Neither is the term DQN resolved as Deep Q-Network nor is any explanation given. There are many methods/method classes performing RL on the Atari Environment. The mention of only one comparison  leaves reasonable doubt about the claim that the system learns faster.   \n\xa0\nSUMMARY: Reject. Even though the idea presented is a novel contribution and has potential the paper itself is highly unstructured and confusing and lacks a proper grammar check. No clear hypothesis is formed until section 3. The concept of Explainable AI which could have been a good motivation does not find any mentioning. Key concepts such as continental philosophy are not explained in a coherent way. The results are presented in a questionable way. As the idea is promising it is recommended to the authors to restructure the paper and conduct more experiments to be able to get accepted. \n"", 'For me, this paper is such a combination of unusual (in the combinations of ideas that it presents) and cryptic (in its presentation) that I have found it exceedingly hard to evaluate fairly. For example, Section 4 is very unclear to me. Its relationship to Section 3.3 is also very unclear to me. \n\nBefore that point in the paper, there are many concepts and ideas alluded to, some described with less clarity than others, but the overall focus is unclear to me and the relationship to the actual algorithms and implementation is also unclear to me. That relationship (conceptual motivation --> implementation) is exactly what would be needed in order to fully justify the inclusion (in an ICLR paper) of so much wide-ranging philosophical/conceptual discussion in the paper.\n\nMy educated guess is that other reviewers at ICLR may have related concerns. In its current state, it therefore does not feel like an appropriate paper for this particular conference. If the authors do feel that the content itself is indeed a good fit, then my strong recommendation would be to begin by re-writing it so that it makes complete sense to someone with a ""standard"" machine learning background. The current presentation just makes it very hard to assess, at least for this reviewer.\n\nIf other reviewers are more easily able to read and understand this paper, then I will be glad to defer to their assessments of it and will happily retract my own.']","[-30, -70, -60]","[50, 20, 40]","[""The sentiment score is -30 because while the reviewer acknowledges the importance of the topic and some valid points made by the authors, they ultimately find significant flaws in the paper's approach and lack of novel contributions. The reviewer points out that the paper doesn't provide methods for teaching computers higher-level concepts and relies heavily on human knowledge, which undermines its proposed solution. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, acknowledging the authors' efforts and the potential value of their ideas, while also providing constructive criticism. They use phrases like 'While I agree...' and 'Overall, this paper presents...' to soften their critiques, demonstrating politeness in their feedback."", ""The sentiment score is -70 because the review is predominantly negative. While there are a few positive points mentioned at the beginning, the majority of the review consists of a long list of criticisms and shortcomings of the paper. The reviewer ultimately recommends rejection, which strongly indicates a negative sentiment. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They offer constructive feedback and suggestions for improvement, which shows a degree of politeness. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score. The reviewer uses phrases like 'it is recommended to the authors' which adds a slight element of politeness to an otherwise critical review."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's clarity, structure, and appropriateness for the conference. They describe it as 'unusual' and 'cryptic', and state that it's 'exceedingly hard to evaluate fairly'. The reviewer also suggests that the paper may not be suitable for ICLR in its current state. However, the score is not lower because the reviewer leaves room for other interpretations and offers constructive feedback. The politeness score is 40 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'my educated guess' and 'if other reviewers are more easily able to read and understand this paper, then I will be glad to defer to their assessments', which show consideration and openness to other viewpoints. The reviewer also offers suggestions for improvement, which is a polite way to provide criticism.""]"
"['This paper proposes a fast way to learn convolutional features that later can be used with any classifier. The acceleration of the training comes from a reduced number of training epocs and a specific schedule decay of the learning rate. \nIn the evaluation the features are used with support vector machines (SVN) and extreme learning machines on MNIST and CIFAR10/100 datasets.\n\nPros:\nThe paper compares different classifiers on three datasets.\n\nCons:\n- Considering an adaptive schedule of the learning decay is common practice in modern machine learning. Showing that by varying the learning rate the authors can reduce the number of training epocs and still obtain good performance is not a contribution and it is actually implemented in most of the recent deep learning libraries, like Keras or Pytorch.\n- It is not clear why, once a CNN has been trained, one should want to change the last layer and use a SVN or other classifiers.\n- There are many spelling errors\n- Comparing CNN based methods with hand-crafted features as in Fig. 1 and Tab.3 is not interesting anymore. It is well known that CNN features are much better if enough data is available.\n', 'This paper deals with early stopping but the contributions are limited. This work would fit better a workshop as a preliminary result, furthermore it is too short. Following a short review section per section.\n\nIntro: The name SFC is misleading as the method consists in stopping early the training with an optimized learning schedule scheme. Furthermore, the work is not compared to the appropriate baselines.\n\nProposal: The first motivation is not clear. The training time of the feature extractor has never been a problem for transfer learning tasks for example: once it is trained, you can reuse the architecture in a wide range of tasks. Besides, the training time of a CNN on CIFAR10 or even ImageNet is now quite small(for reasonable architectures), which allows fast benchmarking.\nThe second motivation, w.r.t. IB seems interesting but this should be empirically motivated(e.g. figures) in the subsection 2.1, and this is not done.\n\nThe section 3 is quite long and could be compressed to improve the relevance of this experimental section. All the accuracies(unsup dict, unsup, etc) on CIFAR10/CIFAR100 are reported from the paper (Oyallon & Mallat, 2015), ignoring 2-3 years of research that leads to new numerical results. Furthermore, this supervised technique is only compared to unsupervised or predefined methods, which is is not fair and the training time of the Scattering Transform is not reported, for example. \n\nFinally, extracting features is mainly useful on ImageNet (for realistic images) and this is not reported here.\n\nI believe re-thinking new learning rate schedules is interesting, however I recommend the rejection of this paper.', ""I am not sure how to interpret this paper. The paper seems to be very thin technically, unless I missed some important details. Two proposals in the paper are:\n\n(1) Using a learning rate decay scheme that is fixed relative to the number of epochs used in training, and \n(2) Extract the penultimate layer output as features to train a conventional classifier such as SVM.\n\nI don't understand why (1) differs from other approaches, in the sense that one cannot simply reduce the number of epochs without hurting performance. And for (2), it is a relatively standard approach in utilizing CNN features. Essentially, if I understand correctly, this paper is proposing to prematurely stop training an use the intermediate feature to train a conventional classifier (which is not that away from the softmax classifier that CNNs usually use). I fail to see how this would lead to superior performance compared to conventional CNNs.""]","[-60, -70, -50]","[20, -20, 20]","[""The sentiment score is -60 because the review is predominantly negative. While it acknowledges one pro (comparing different classifiers on three datasets), it lists several significant cons. The reviewer criticizes the paper's main contribution as not novel, questions the methodology, points out spelling errors, and dismisses some comparisons as uninteresting. This indicates a largely unfavorable view of the paper. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone. They use neutral language like 'It is not clear why...' and 'Comparing ... is not interesting anymore' rather than using harsh or insulting language. The reviewer also begins by objectively summarizing the paper's content before moving on to critiques, which is a polite approach in academic reviews."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the contributions are limited, suggests it would be better suited for a workshop, and ultimately recommends rejection. They point out several shortcomings and criticisms throughout the review. The politeness score is -20 because while the reviewer isn't overtly rude, the language is quite direct and critical without much attempt to soften the feedback. Phrases like 'the contributions are limited' and 'is not fair' are quite blunt. The reviewer does use some milder language like 'I believe' and 'I recommend' which prevents the score from being lower, but overall the tone is more critical than polite."", ""The sentiment score is -50 because the reviewer expresses significant doubts about the paper's technical contributions and novelty. They state they are 'not sure how to interpret this paper' and describe it as 'very thin technically.' The reviewer questions the uniqueness and effectiveness of the proposed methods, suggesting they don't see how they would lead to superior performance. However, the score is not lower because the reviewer leaves room for the possibility that they 'missed some important details.' The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and non-confrontational manner. They use phrases like 'I don't understand' and 'I fail to see' rather than making accusatory statements. The reviewer also acknowledges the possibility of their own misunderstanding, which adds a level of politeness to the critique.""]"
"['This paper presents three different techniques for model specialization, i.e. adapting a pretrained network to a more specific task and reduce its computational cost while maintaining the performance. The three techniques are distillation, weight pruning and cascades. Evaluation compares how effective each technique is and how they interact with each other. In certain settings the obtained speed-up reaches 5x without loss of accuracy.\n\nPros:\n- The idea of reducing the computational cost of specialized models makes sense.\n- In some setting the speed-up can reach more than 5x, which is quite relevant.\n\nCons:\n- The fact that the models are specialized to simpler tasks is not explicitly used in the approach. The authors should test what would happen when using their cascade for classification on all classes of ImageNet for instance. Would it be the gain in speed much lower?\n- It is not clear if the distillation on smaller networks is really improving the models accuracy. The authors compared the distilled models with models trained from scratch. There should be an additional experiment with the small models trained on Imagenet first and then fine-tuned to the task. If in that case there is non gain, then, what is the advantage of distilling in these settings? ImageNet annotations need to be used anyway to train the teacher network.\n- In section 3.2 it seems that the filters of a CNN are globally ranked based on their average activation values. Those with the lowest average activation will be removed. However, in my understanding, the ranking can work better if performed layer specific and not globally.\n- In section 3.4, the title says ""end-to-end specialization pipeline"", but actually, the specialization is done in 3 steps, therefore in my understanding it is not end-to-end.\n- There are some spelling errors, for instance in the beginning of section 4.1\n- Pruning does not seem to produce much speed-up.\n- The experimental part is difficult to read. In particular Fig. 4 should be better explained. There are some symbols in the legend that do not appear in the graph, and others (baselines only) that appear multiple times, but it is not clear what they represent. Also, at the end of the explanation of Fig. 4 the authors mention a gain of 8%, which in my understanding is not really relevant compared with the total speed-up, which can be in the order of 500%\n\nOverall, the idea of model specialization seem interesting. However, in my understanding the main source of speed-up is a cascade approach with a reduced model, in which is not clear how much speed-up is actually due to the specialized task.', 'The authors review and evaluate several empirical methods to create faster versions of big neural nets for vision without sacrificing accuracy. They show using the ResNet architecture that combining distillation, pruning, and cascades are complementary and can yield pretty nice speedups.\n\nThis is a great idea and could be a strong paper, but it\'s really hard to glean useful recommendations from this for several reasons:\n\n- The writing of the paper makes it hard to understand exactly what\'s being compared and evaluated. For a paper like this it\'s really crucial to be precise. When the authors say ""specialization"" or ""specialized model"", they sometimes mean distillation, sometimes filter pruning, and sometimes cascades. The distinction of ""task-aware"" also seems arbitrary to me and obfuscates the contribution of the paper as well. As far as I can tell, the technique is exactly the same, all that\'s changing is a slight modification. It\'s not like any of the intuitions or objectives are changing, so adding this new terminology just complicates things. For example, just say ""We distill a parent model to a child model with a subset of the labels."" \n\n- In terms of substance, the experiments don\'t really add much value in terms of general lessons. For example, the Cat/Dog from ImageNet distillation only works if the target labels are exactly a subset of the original. Obviously if the parent model was overcomplete before, it is certainly overcomplete now. The proposed cascade method is also fairly trivial -- a cheap distilled model backs off to the reference model. Why not train the whole cascade end-to-end? What about multiple levels of cascades? The only useful conclusion I can draw from the experiments is that (1) distillation still works (2) cascades also still work (3) pruning doesn\'t seem that useful in comparison. Training a cascade also involves a bunch of non-trivial design choices which are largely ignored -- how to set pass through, how to train the model, etc. etc.\n\n- Nit: where are the blue squares in Figure 4? (Distill only) shouldn\'t those be the fastest methods (aside from pruning)? \n\nAn ideal story would for a paper like this would be: here are some complementary ideas that we can combine in non-obvious ways for superlinear benefits, e.g. it turns out that by distilling into a cascade in some end-to-end fashion, you can get much better accuracy vs. speed trade-offs. Instead this paper is a grab-back of tricks. Such a paper can also provide value, but to do that right, the tricks need to be obvious *in retrospect only* and/or the experiments need to show a lot of precise practical lessons. All in all this paper reads like a tech report but not a conference publication.', 'The paper presents an approach to do task aware distillation, task-specific pruning and specialized cascades. The main result is that such methods can yield smaller, efficient and sometimes more accurate models.\n\nThe proposed approach is simple and easy to understand. The task aware distillation relies on the availability of data that is target specific. In practice, I believe this is not an unreasonable requirement.\n\nThe speedups and accuracy gains of this paper are impressive. The fact that the proposed technique is simple yet yields such speedups is encouraging. However, evaluating on simple datasets like Kaggle cat/dog and Oxford Flowers diminishes the value of the paper. I would strongly encourage the authors to try harder datasets such as COCO, VOC etc. This will make the paper more valuable to the community.\n\nMissing citations\nDo Deep Nets Really Need to be Deep? - Ba & Caruana 2014']","[-20, -50, 50]","[50, 20, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), there are more 'Cons' listed, and the overall tone suggests that the paper has significant areas for improvement. The reviewer points out several issues with the methodology, clarity, and presentation of results. However, the score is not deeply negative as the reviewer still finds the core idea interesting.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use neutral language to present their critiques, avoiding harsh or personal comments. The review is structured with 'Pros' and 'Cons', which is a balanced approach. The reviewer also uses phrases like 'in my understanding' which shows a degree of respect for the authors' perspective. However, the score is not extremely high as the review is direct in its criticisms without excessive softening language."", ""The sentiment score is -50 because while the reviewer acknowledges the potential of the paper ('This is a great idea and could be a strong paper'), they express significant criticisms about the paper's clarity, substance, and overall value as a conference publication. The reviewer points out several major issues with the paper's writing, experiments, and conclusions, suggesting that it falls short of expectations for a conference paper. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'This is a great idea' and offering constructive criticism. However, they don't use overtly polite language or soften their criticisms extensively, keeping the tone more neutral than explicitly polite."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the impressive speedups and accuracy gains, and finds the approach simple and easy to understand. However, they also suggest improvements, which prevents a higher score. The politeness score is 75 (quite polite) due to the use of respectful language throughout, such as 'I believe' and 'I would strongly encourage'. The reviewer offers constructive criticism and suggestions without using harsh or negative language. The overall tone is professional and supportive, while still providing honest feedback.""]"
"['Quality\n\nThis is a very clear contribution which elegantly demonstrates the use of extensions of GAN variants in the context of neuroimaging.\n\nClarity\n\nThe paper is well-written. Methods and results are clearly described. The authors state significant improvements in classification using generated data. These claims should be substantiated with significance tests comparing classification on standard versus augmented datasets.\n\nOriginality\n\nThis is one of the first uses of GANs in the context of neuroimaging. \n\nSignificance \n\nThe approach outlined in this paper may spawn a new research direction.\n\nPros\n\nWell-written and original contribution demonstrating the use of GANs in the context of neuroimaging.\n\nCons\n\nThe focus on neuroimaging might be less relevant to the broader AI community.', 'This paper proposes to use 3D conditional GAN models to generate\nfMRI scans. Using the generated images, paper reports improvement\nin classification accuracy on various tasks.\n\nOne claim of the paper is that a generative model of fMRI\ndata can help to caracterize and understand variability of scans\nacross subjects.\n\nArticle is based on recent works such as Wasserstein GANs and AC-GANs\nby (Odena et al., 2016).\n\nDespite the rich literature of this recent topic the related work\nsection is rather convincing.\n\nModel presented extends IW-GAN by using 3D convolution and also\nby supervising the generator using sample labels.\n\nMajor:\n\n- The size of the generated images is up to 26x31x22 which is limited\n(about half the size of the actual resolution of fMRI data). As a\nconsequence results on decoding learning task using low resolution\nimages can end up worse than with the actual data (as pointed out).\nWhat it means is that the actual impact of the work is probably limited.\n\n- Generating high resolution images with GANs even on faces for which\nthere is almost infinite data is still a challenge. Here a few thousand\ndata points are used. So it raises too concerns: First is it enough?\nUsing so-called learning curves is a good way to answer this. Second\nis what are the contributions to the state-of-the-art of the 2\nmethods introduced? Said differently, as there\nis no classification results using images produced by an another\nGAN architecture it is hard to say that the extra complexity\nproposed here (which is a bit contribution of the work) is actually\nnecessary.\n\nMinor:\n\n- Fonts in figure 4 are too small.\n', 'The work is motivated by a real challenge of neuroimaging analysis: how to increase the amount of data to support the learning of brain decoding.\nThe contribution seems to mix two objectives: on one hand to prove that it is possible to do data augmentation for fMRI brain decoding, on the other hand to design (or better to extend) a new model (to be more precise two models).\nConcerning the first objective the empirical results do not provide meaningful support that the generative model is really effective. The improvement is really tiny and a statistical test (not included in the analysis) probably wouldn\'t pass a significant threshold.  This analysis is missing a straw man. It is not clear whether the difference in the evaluation measures is related to the greater number of examples or by the specific generative model.\nConcerning the contribution of the model, one novelty is the conditional formulation of the discriminator. The design of the empirical evaluation doesn\'t address the analysis of the impact of this new formulation. It is not clear whether the supposed improvement is related to the conditional formulation. \nFigure 3 and Figure 5 illustrate the brain maps generated for Collection 1952 with ICW-GAN and for collection 503 with ACD-GAN. It is not clear how the authors operated the choices of these figures. From the perspective of neuroscience a reader,  would expect to look at the brain maps for the same collection with different methods. The pairwise brain maps would support the interpretation of the generated data. It is worthwhile to remember that the location of brain activations is crucial to detect whether the brain decoding (classification) relies on artifacts or confounds.\n\nMinor comments\n- typos: ""a first application or this"" => ""a first application of this"" (p.2)\n- ""qualitative quality"" (p.2)']","[80, -20, -50]","[70, 50, 20]","[""The sentiment score is 80 (positive) because the review begins with very positive language, describing the contribution as 'very clear' and 'elegantly' demonstrating the use of GANs in neuroimaging. The reviewer also highlights the paper as well-written, original, and potentially spawning a new research direction. The only slight criticism is about the focus on neuroimaging being potentially less relevant to the broader AI community, but this is presented as a minor point. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout, offering praise where due and constructive feedback for improvement. The suggestions for improvement (e.g., adding significance tests) are presented as helpful recommendations rather than harsh criticisms. The reviewer maintains a balanced and courteous tone, acknowledging both pros and cons of the paper."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'convincing' related work section), they raise significant concerns about the impact and methodology. The reviewer points out limitations in image size and data quantity, questioning the actual impact and contributions of the work. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using neutral language to express concerns (e.g., 'raises two concerns') and offering constructive feedback. They also acknowledge positive aspects before presenting criticisms. The review is structured and objective, avoiding harsh or personal criticisms, which contributes to its politeness."", ""The sentiment score is -50 because the review is generally critical of the work, pointing out several shortcomings in the study's objectives, empirical results, and analysis. The reviewer states that the improvement shown is 'really tiny' and that the study lacks statistical tests and a 'straw man' for comparison. They also question the effectiveness of the generative model and the impact of the new model formulation. However, the score is not lower because the reviewer does acknowledge the real challenge the work addresses and provides constructive feedback for improvement.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'it is not clear' and 'it is worthwhile to remember' rather than making blunt or harsh statements. The reviewer also provides specific suggestions for improvement and points out minor typos, which shows a level of engagement and care. The language is not overtly polite or complimentary, but it avoids rudeness and maintains a constructive approach.""]"
"['The contributions made by this paper is unclear. As one of the listed contributions, the authors propose using policy gradient. However, in this setting, the reward is a known differentiable function, and the action is continuous, and thus one could simply backpropagate through to get the gradients on the encoder. Also, it seems the reward is not a function of the future actions, which further questions the need for a reinforcement learning formulation.\n\nThe paper is written poorly. For instance, I don\'t understand what this sentence means: ""We condition the latent variables to come from rich distributions"". Observed accent labels are referred to as latent (hidden) variables.\n\nWhile the independent Wasserstein critic is useful to study whether models are overfitting (by comparing train/heldout numbers), their use for comparing across different model types is not justified. Moreover, since GAN-based methods optimize the Wasserstein distance directly, it cannot serve as a metric to compare GAN-based models with other models.\n\nAll of the models compared against do not use accent information during training (table 2), so this is not a fair comparison.\n\nOverall, the paper lacks any novel technical insight, contributions are not explained well, exposition is poor, and the evaluations are invalid.', 'The paper considers speech generation conditioned on an accent class.\nLeast Squares GAN and a reconstruction loss is used to train the network.\n\nThe network is using continuous latent variables. These variables are trained by policy gradients.\nI do not see a reason for the policy gradients. It would be possible to use the cleaner gradient from the discriminator.\nThe decoder is already trained with gradient from the discriminator.\nIf you are worried about truncated backpropagation through time,\nyou can bias it by ""Unbiasing Truncated Backpropagation Through Time"" by Corentin Tallec and Yann Ollivier.\n\n\nComments on clarity:\n- It would be helpful to add x, z, y, o labels to the Figure 1.\nI understood the meaning of `o` only from Algorithm 1.\n- It was not clear from the text what is called the ""embedding variable"". Is it `z`?\n- It is not clear how the skip connections connect the encoder and the decoder.\nAre the skip connections not used when generating?\n- In Algorithm 1, \\hat{y}_k is based on z_k, instead of \\hat{z}_k. That seems to be a typo.\n\nComments on evaluation:\n- It is hard to evaluate speech conditioned just on the accent class.\nOverfitting may be unnoticed.\nYou should do an evaluation on a validation set.\nFor example, you can condition on a text and generate samples\nfor text sentences from a validation set.\nPeople can then judge the quality of the speech synthesis.\nA good speech synthesis would be very useful.\n', 'This paper presents a method for generating speech audio in a particular accent. The proposed approach relies on a generative adversarial network (GAN), combined with a policy approach for joining together generated speech segments. The latter is used to deal with the problem of generating very long sequences (which is generally difficult with GANs).\n\nThe problem of generating accented speech is very relevant since accent plays a large role in human communication and speech technology. Unfortunately, this paper is hard to follow. Some of the approach details are unclear and the research is not motivated well. The evaluation does not completely support the claims of the paper, e.g., there is no human judgment of whether the generated audio actually matches the desired accent.\n\nDetailed comments, suggestions, and questions:\n- It would be very useful to situate the research within work from the speech community. Why is accented modelling important? How is this done at the moment in speech synthesis systems? The paper gives some references, but without context. The paper from Ikeno and Hansen below might be useful.\n- Accents are also a big problem in speech recognition (references below). Could your approach give accent-invariant representations for recognition?\n- Figure 1: Add $x$, $y$, and the other variables you mention in Section 3 to the figure.\n- What is $o$ in eq. (1)?\n- Could you add a citation for eq. (2)? This would also help justifying that ""it has a smoother curve and hence allows for more meaningful gradients"".\n- With respect to the critic $C_\\nu$, I can see that it might be helpful to add structure to the hidden representation. In the evaluation, could you show the effect of having/not having this critic (sorry if I missed it)? The statement about ""more efficient layers"" is not clear.\n- Section 3.4: If I understand correctly, this is a nice idea for ensuring that generated segments are combined sensibly. It would be helpful defining with ""segments"" refer to, and stepping through the audio generation process.\n- Section 4.1: ""using which we can"" - typo.\n- Section 5.1: ""Figure 1 shows how the Wasserstein distance ..."" I think you refer to the figure with Table 1?\n- Figure 4: Add (a), (b) and (c) to the relevant parts in the figure.\n\nReferences that might be useful:\n- Ikeno, Ayako, and John HL Hansen. ""The effect of listener accent background on accent perception and comprehension."" EURASIP Journal on Audio, Speech, and Music Processing 2007, no. 3 (2007): 4.\n- Van Compernolle, Dirk. ""Recognizing speech of goats, wolves, sheep and… non-natives."" Speech Communication 35, no. 1 (2001): 71-79.\n- Benzeghiba, Mohamed, Renato De Mori, Olivier Deroo, Stephane Dupont, Teodora Erbes, Denis Jouvet, Luciano Fissore et al. ""Automatic speech recognition and speech variability: A review."" Speech communication 49, no. 10 (2007): 763-786.\n- Wester, Mirjam, Cassia Valentini-Botinhao, and Gustav Eje Henter. ""Are We Using Enough Listeners? No!—An Empirically-Supported Critique of Interspeech 2014 TTS Evaluations."" In Sixteenth Annual Conference of the International Speech Communication Association. 2015.\n\nThe paper tries to address an important problem, and there are good ideas in the approach (I suspect Sections 3.3 and 3.4 are sensible). Unfortunately, the work is not presented or evaluated well, and I therefore give a week reject.\n']","[-90, -20, -60]","[-30, 50, 50]","[""The sentiment score is -90 because the review is overwhelmingly negative. The reviewer states that the paper's contributions are unclear, the writing is poor, the evaluations are invalid, and the paper lacks novel technical insight. There are no positive comments to balance these criticisms. The politeness score is -30 because while the reviewer doesn't use explicitly rude language, the tone is quite harsh and dismissive. Phrases like 'The paper is written poorly' and 'Overall, the paper lacks any novel technical insight' are particularly blunt and could be seen as impolite in academic discourse. However, the reviewer does provide specific examples and explanations for their criticisms, which prevents the score from being even lower."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's topic and approach, they express several concerns and suggest improvements. The reviewer questions the use of policy gradients, points out potential typos, and recommends additional evaluation methods. These critiques indicate a somewhat critical stance towards the paper.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'It would be helpful' and 'You should' which are polite ways of suggesting improvements. The reviewer also acknowledges potential benefits of the research, stating 'A good speech synthesis would be very useful.' The language is not overly formal or deferential, but it avoids harsh or rude phrasing, maintaining a respectful tone while providing critical feedback."", ""The sentiment score is -60 because the review is overall negative, with phrases like 'hard to follow', 'unclear', 'not motivated well', and concluding with a 'weak reject'. However, it's not entirely negative as it acknowledges the importance of the problem and some good ideas in the approach. The politeness score is 50 because the reviewer uses polite language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'It would be very useful', 'Could you add', and 'I think you refer to', which are courteous ways of pointing out issues. The reviewer also provides helpful references and detailed comments, showing a considerate approach to the review process.""]"
"['This work explores some approaches in the object detection field of computer vision: (a) a soft attention map based on the activations on convolutional layers, (b) a classification regarding the location of an object in a 3x3 grid over the image, (c) an autoencoder that the authors claim to be aware of the multiple object instances in the image. These three proposals are presented in a framework of a robot vision module, although neither the experiments nor the dataset correspond to this domain.\n\nFrom my perspective, the work is very immature and seems away from current state of the art on object detection, both in the vocabulary, performance or challenges. The proposed techniques are assessed in a dataset which is not described and whose results are not compared with any other technique. This important flaw in the evaluation prevents any fair comparison with the state of the art.\n\nThe text is also difficult to follow. The three contributions seem disconnected and could have been presented in separate works with a more deeper discussion. In particular, I have serious problems understanding:\n\n1. What is exactly the contribution of the CNN pre-trained with IMageNet when learning the soft-attention maps ? The reference to a GAN architecture seems very forced and out of the scope.\n\n2. What is the interest of the localization network ? The task it addresses seems very simple and in any case it requires a manual annotation of a dataset of objects in each of the predefined locations in the 3x3 grid.\n\n3. The authors talk about an autoencoder architecture, but also on a classification network where the labels correspond to the object count. I could not undertstand what is exactly assessed in this section.\n\nFinally, the authors violate the double-bind review policy by clearly referring to their previous work on Experiental Robot Learning.\n\nI would encourage the authors to focus in one of the research lines they point in the paper and go deeper into it, with a clear understanding of the state of the art and the specific challenges these state of the art techniques may encounter in the case of robotic vision.', 'The paper is motivated with building robots that learn in an open-ended way, which is really interesting. What it actually investigates is the performance of existing image classifiers and object detectors. I could not find any technical contribution or something sufficiently mature and interesting for presenting in ICLR.\n\nSome issues:\n- submission is supposed to be double blind but authors reveal their identity at the start of section 2.1.\n- implementation details all over the place (section 3. is called ""Implementation"", but at that point no concrete idea has been proposed, so it seems too early for talking about tensorflow and keras).\n', 'The authors disclosed their identity and violated the terms of double blind reviews.\nPage 2 ""In our previous work (Aly & Dugan, 2017)\n\nAlso the page 1 is full of typos and hard to read.']","[-80, -60, -80]","[-20, 0, -50]","[""The sentiment score is -80 because the reviewer expresses strong negative opinions about the work, calling it 'very immature' and pointing out several significant flaws. They state that the work seems 'away from current state of the art' and has 'important flaw[s] in the evaluation.' The politeness score is -20 because while the reviewer doesn't use overtly rude language, their criticism is direct and unsparing. They do offer some constructive advice at the end, which prevents the score from being lower. However, phrases like 'I have serious problems understanding' and pointing out that the authors 'violate the double-bind review policy' contribute to a somewhat impolite tone."", ""The sentiment score is -60 because the reviewer expresses a generally negative view of the paper. While they acknowledge the interesting motivation, they state that they 'could not find any technical contribution or something sufficiently mature and interesting for presenting in ICLR.' This indicates a significant disappointment with the paper's content and suitability for the conference. The politeness score is 0 (neutral) because the reviewer's language is neither particularly polite nor rude. They state their criticisms directly but without using harsh or insulting language. The reviewer points out issues in a matter-of-fact manner, maintaining a professional tone throughout the review."", ""The sentiment score is highly negative (-80) because the reviewer points out two significant issues with the paper: a violation of review terms and poor writing quality. There are no positive comments to balance these criticisms. The politeness score is moderately negative (-50) due to the blunt, terse nature of the feedback. The reviewer doesn't use any polite language or constructive phrasing, instead stating the problems directly without any mitigation. The lack of greeting, closing, or any softening language contributes to the impolite tone. However, it's not extremely rude, as it doesn't use insulting language, hence not receiving the lowest possible score.""]"
"['the paper adapts the information bottleneck method where a problem has invariance in its structure. specifically, the constraint on the mutual information is changes to one on the conditional  entropy. the paper involves a technical discription how to develop proper estimators for this conditional entropy etc.\n\nthis is a nice and intuitive idea. how it interacts with classical regularizers or if it completely dominates classical regularizers would be interesting for the readers.', 'This paper proposes another entropic regularization term for deep neural nets. The key idea can be stated as follows: Let X denote the observed input, C the hidden class label taking values in a finite set, and Y the representation computed by a neural net. Then C -> X -> Y is a Markov chain. Moreover, assuming that the mapping X -> Y is deterministic (as is the case with neural nets or any other deterministic representations), we can write down the mutual information between X and Y as\n\nI(X;Y) = H(Y) - H(Y|X) = H(Y).\n\nA simple manipulation shows that H(Y) = I(C;Y) + H(Y|C). The authors interpret the first term, I(C;Y), as a data fit term that quantifies the statistical correlations between the class label C and the representation Y, whereas the second term, H(Y|C), is the amount by which the representation Y can be compressed knowing the class label C. The authors then propose to \'explicitly decouple\' the data-fit term I(C;Y) from the regularization penalty and focus on minimizing H(Y|C). In fact, they replace this term by the sum of conditional entropies of the form H(Y_{i,k}|C), where Y_{i,k} is the activation of the ith neuron in the kth layer of the neural net. The final step is to recognize that the conditional entropy may not admit a scalable and differentiable estimator, so they use the relation between a quantity called entropy power and second moments to replace the entropic penalty with the conditional variance penalty Var[Y_{i,k}|C]. Since the class-conditional distributions are unknown, a surrogate model Q_{Y|C} is used. The authors present some experimental results as well.\n\nHowever, this approach has a number of serious flaws. First of all, if the distribution of X is nonatomic and the mapping X -> Y is continuous (in the case of neural nets, it is even Lipschitz), then the mutual information I(X;Y) is infinite. In that case, the representation of I(X;Y) in terms of entropies is not valid -- indeed, one can write the mutual information between two jointly distributed random variables X and Y in terms of differential entropies as I(X;Y) = h(Y) - h(Y|X), but this is possible only if both terms on the right-hand side exist. This is not the case here, so, in particular, one cannot relate I(X;Y) to I(C;Y). Ironically, I(C;Y) is finite, because C takes values in a finite set, so I(C;Y) is at most the log cardinality of the set of labels. One can start, then, simply with I(C;Y) and express it as H(C) - H(C|Y). Both terms are well-defined Shannon entropies, where the first one does not depend on the representation, whereas the second one involves the representation. But then, if the goal is to _minimize_ the mutual information between I(C;Y), it makes sense to _maximize_ the conditional entropy H(C|Y). In short, the line of reasoning that leads to minimizing H(Y|C) is not convincing. Moreover, why is it a good idea to _minimize_ I(C;Y) in the first place? Shouldn\'t one aim to maximize it subject to structural constraints on the representation, along the lines of InfoMax?\n\nThe next issue is the chain of reasoning that leads to replacing H(Y|C) with Var[Y|C]. One could start with that instead without changing the essence of the approach, but then the magic words ""Shannon decay"" would have to disappear altogether, and the proposed method would lose all of its appeal.', 'The authors propose a particular variance regularizer on activations and connect it to the conditional entropy of the activation given the class label. They also present some competitive results on CIFAR-10 and ImageNet.\n\nDespite some promising results, I found some issues with the paper. The main one is that the connection between conditional entropy and the proposed variance regularizer seems tenuous. The chain of reasoning is as follows:\n\n- Estimation of H(Y|C) is difficult for two reasons: 1) when the number of classes is large, the number of samples needed calculate the entropy are high, and 2) naive estimators -- even when the number of classes are small -- have high variance. To solve these issues, the authors propose:\n\na) Introduce a latent code Z such that H(Y|C) = H(Y|Z). This solves problem 1).\n\nb) Use a variance upper bound on H(Y|Z). This solves problem 2).\n\nMy issue is with the reasoning behind a). H(Y|C) = H(Y|Z) relies on the assumption that I(Y;C) = I(Y;Z). The authors present a plausibility argument, but the argument was not sufficiently convincing to me to overcome my prior that I(Y;C) =/= I(Y;Z).\n\nApart from this, I found some other issues. \n\n* In the second paragraph of 2.2, the acronym LME in ""LME estimator"" was not defined, so I checked the reference provided. That paper did not mention a LME estimator, but did present a ""maximum likelihood estimator"" with the same convergence properties as those mentioned in the SHADE paper. Since the acronym LME was used twice, I\'m assuming this was not a typo. Perhaps this is a bug in the reference?\n\n* In section 4.4, it\'s hard to know if the curves actually show that ""SHADE produces less class-information filtering"". The curves are close throughout and are nearly identical at epoch 70. It is entirely possible that the difference in curves is due to optimization or some other lurking factor.\n\n* The final form of the regularization makes it look like a more principled alternative to batchnorm. It would have been nice if the authors more directly compared SHADE to BN.\n\n* There are two upper bounds here: that H(Y_l | C) <= \\sum_i H(Y_{l, i} | C), and the variance upper bound. The first one does not seem particularly tight, especially at the early layers where the representation is overcomplete. I understand that the authors argue that the upper bound is tight in footnote 3, but it is only plausible for later laters.\n\nMy Occam\'s razor explanation of this paper is that it forces pre-nonlinearity activations (and hence post-nonlinearity activations) to be binary, without having to resort to sigmoid or tanh nonlinearities. This is a nice property, but whether the regularizer connects to H(Y|C) still remains unsolved.', 'Summary:\n\nThe paper presents an information theoretic regularizer for deep learning\nalgorithms. The regularizer aims to enforce compression of the learned\nrepresentation while conditioning upon the class label so preventing the\nlearned code from being constant across classes. The presentation of the Z\nlatent variable used to simplify the calculation of the entropy H(Y|C) is \nconfusing and needs revision, but otherwise the paper is interesting.\n\nMajor Comments:\n\n- The statement that I(X;Y) = I(C;Y) + H(Y|C) relies upon several properties\n  of Y which are not apparent in the text (namely that Y is a function of X,\nso I(X;Y) should be maximal, and Y is a smaller code space than X so it should \nbe H(Y)). If Y is a larger code space than X then it should still be true, but\nthe logic is more complicated.\n\n- The latent code for Z is unclear. Given the use of ReLUs it seems like Y\n  will be O or +ve, and Z will be 0 when Y is 0 and 1 otherwise, so I\'m\nunclear as to when the value H(Y|Z) will be non-zero. The data is then\npartitioned within a batch based on this Z value, and monte carlo sampling is\nused to estimate the variance of Y conditioned on Z, but it\'s really unclear\nas to how this behaves as a regularizer, how the z is sampled for each monte\ncarlo run, and how this influences the gradient. The discussion in Appendix C\ndoesn\'t mention how the Z values are generated.\n\n- The discussion on how this method differs from the information bottleneck is\n  odd, as the bottleneck is usually minimising the encoding mutual information\nI(X;Y) minus the decoding mutual information I(Y;C). So directly minimising\nH(Y|C) is similar to the IB, and also minimising H(Y|C) will affect I(C;Y) as\nI(C;Y) = H(Y) - H(Y|C).\n\n- The fine tuning experiments (Section 4.2) contain no details on the\n  parameters of that tuning (e.g. gradient optimiser, number of epochs,\nbatch size, learning rates etc).\n\n- Section 4.4 is obvious, and I\'d consider it a bug if regularising with label\n  information performed worse than regularising without label information.\nEssentially it\'s still adding supervision after you\'ve removed the\nclassification loss, so it\'s natural that it would perform better. This\nexperiment could be moved to the appendix without hurting the paper.\n\n- In appendix A an upper bound is given for the reconstruction error in terms\n  of the conditional entropy. This bound should be related to one of the many\nupper bounds (e.g. Hellman & Raviv) for the Bayes rate of a predictor, as\nthere is a fairly wide literature in this area.\n\nMinor Comments:\n\n- The authors do not state what kind of input variations they are trying to\n  make the model invariant to, and as it applies to CNNs there are multiple\ndifferent kinds, many of which are not amenable to a regularization based\nsystem for inducing invariance.\n\n- The authors should remind the reader once that I(X;Y) = H(Y) - H(Y|X) = H(X) -\n  H(X|Y), as this fact is used multiple times throughout the paper, and it may\nnot necessarily be known by readers in the deep learning community.\n\n- Computing H(Y|C) does not necessarily require computing c separate\n  entropies, there are multiple different approaches for computing this\nentropy.\n\n- The exposition in section 3 could be improved by saying that H(X|Y) measures\n  how much the representation compresses the input, with high values meaning\nlarge amounts of compression, as much of X is thrown away when generating Y.\n\n- The figures are difficult to read when printed in grayscale, the graphs\n  should be made more readable when printed this way (e.g. different symbols,\ndashed lines etc).\n\n- There are several typos (e.g. pg 5 ""staking"" -> ""stacking"").\n']","[70, -70, -50, -20]","[50, 20, 20, 50]","[""The sentiment score is 70 (positive) because the reviewer describes the paper's idea as 'nice and intuitive', which indicates a favorable view. They also suggest an interesting area for further exploration, showing engagement with the work. The politeness score is 50 (slightly polite) as the language is professional and constructive without being overly formal or effusive. The reviewer offers a suggestion for improvement in a neutral, non-demanding way ('would be interesting for the readers'). The overall tone is respectful and encouraging, though not excessively polite."", ""The sentiment score is -70 because the reviewer identifies 'serious flaws' in the paper's approach and provides detailed criticism of the methodology and reasoning. The reviewer questions the validity of the paper's fundamental assumptions and mathematical derivations, indicating a strongly negative view of the work. However, it's not entirely negative as the reviewer acknowledges the authors' experimental results. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'However, this approach has a number of serious flaws' rather than more aggressive language. The reviewer also explains their criticisms in detail, which is a respectful approach. However, some phrases like 'Ironically' and 'magic words... would have to disappear altogether' have a slightly sarcastic tone, preventing a higher politeness score."", ""The sentiment score is -50 because the review starts with acknowledging some promising results but quickly moves to highlighting several issues with the paper. The reviewer expresses skepticism about the main argument and points out multiple other problems, indicating a generally negative sentiment. However, it's not entirely negative as the reviewer does acknowledge some positive aspects. The politeness score is 20 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They use phrases like 'I found some issues' and 'My issue is with the reasoning' rather than more confrontational language. The reviewer also provides detailed explanations for their concerns, which is a polite way to give feedback. However, the score is not higher because the review is primarily focused on criticisms without much positive reinforcement."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the paper 'interesting', they also point out several major issues and areas of confusion that need revision. The reviewer states that 'the presentation... is confusing and needs revision', which indicates a negative sentiment. However, they do not completely dismiss the paper, acknowledging its interesting aspects.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'The authors should...' and 'The exposition could be improved by...', which are polite ways of suggesting improvements. The reviewer also balances criticism with positive remarks, such as calling the paper 'interesting'. However, the review is not overly effusive or deferential, maintaining a neutral, professional tone overall.\n\nThe reviewer provides detailed, specific feedback and suggestions for improvement, which is a polite and constructive approach to peer review. They also include both major and minor comments, showing a thorough and respectful engagement with the paper. The language used is direct but not harsh or personal, focusing on the content of the paper rather than criticizing the authors themselves.""]"
"['This paper proposes a generative model called matching auto-encoder to carry out the learning from unaligned data.\nHowever, it is very disappointed to read the contents after the introduction, since most of the contributions are overclaimed.\n\nDetailed comments:\n- Figure 1 is incorrect because the pairs (x, z) and (y, z) should be put into two different plates if  x and y are unaligned.\n\n- Lots of contents in Sec. 3 are confusing to me. What is the difference between g_l(x) and g_l(y) if g_l : H_{l−1} → H_l and f_l: H_{l−1} → H_l are the same? What are e_x and e_y? Why is there a λ if it is a generative model?\n\n- If the title is called \'text decipherment\', there should be no parallel data at all, otherwise it is a huge overclaim on the decipherment tasks. Please add citations of Kevin Knight\'s recent papers on deciperment.\n\n- Reading the experiment results of \'Sentiment Transfer\' is a disaster to me. I couldn\'t get much information on \'sentiment transfer\' from a bunch of ungrammatical unnatural language sentences. I would prefer to see some results of baseline models for comparison instead of a pure qualitative analysis.\n\n- The claim on ""FMAEs are state of the art for neural machine translation with limited supervision on EN-DE and EN-FR"" is not exciting to me. Semi-supervised learning is interesting, but in the scenario of MT we do have enough parallel data for many language pairs. Unless the model is able to exceed the \'real\' state-of-the-art that uses the full set of parallel data, otherwise we couldn\'t identify whether the models are able to benefit NMT.  Interestingly, the authors didn\'t provide any of the results that are experimented with full parallel data set. Possibly it is because the introduction of stochastic variables that prevent the models from overfitting on small datasets.\n\n', '\nThe paper is sloppily written where math issues and undefined symbols make it hard to understand. The experiments seem to be poorly done and does not convey any clear points, and not directly comparable to previous results.\n\n(3) evaluates to 0, and is not a penalty. Same issue in (4). Use different symbols. I also do not understand how this is adversarial, as these are just computed through forward propagation.\n\nAlso what is this two argument f in eq 3? It seems to be a different and unspecified function from the one introduced in 2)\n\n4.1: a substitution cipher has an exact model, and there is no reason why a neural networks would do well here. I understand the extra-twist is that training set is unaligned, but there should be an actual baseline which correctly models the cipher process and decipher it. You should include that very natural baseline model.\n\n4.2 does not give any clear conclusions. The bottom is a draw from the model conditioned on the top? What was the training data, what is draw supposed to be? Some express the same sentiment, others different, and I have no idea if they are supposed to express the same meaning or not.\n\n4.3: why are all the results non-overlapping with previous results? You have to either reproduce some of the previous results, or run your own experiment in matching settings. The current result tables show your model is better than some version of the transformer, but not necessarily better than the ""big"" transformer. The setup and descriptions do not inspire confidence.\n\nMinor issues\n\n3.1: effiency => efficiency\n\nData efficiency is used as a task/technique, which I find hard to parse. ""Data efficiency and alignment have seen most success for dense, continuous data such as images.""\n""powerful data efficiency and alignment""\n', ""This work propose a generative model for unsupervised learning of translation model using a variant of auto-encoder which reconstruct internal layer representation in two directions. Basic idea is to treat the intermediate layers as feature representation which is reconstructed from the other direction. Experiments on substitution cipher shows improvement over a state of the art results. For translation, the proposed method shows consistent gains over baselines, under a condition where supervised data is limited.\n\nOne of the problems of this paper is the clarity.\n- It is not immediately clear how the feature mapping explained in section 2 is related to section 3. It would be helpful if the authors could provide what is reconstructed using the transformer model as an example.\n- The improved noisy attention in section 3.3 sounds orthogonal to the proposed model. I'd recommend the authors to provide empirical results.\n- MT experiments are unclear to me. When running experiments for 2M data, did you use the remaining 2.5M for unsupervised training in English-German task?\n- It is not clear whether equation 3 is correct: The first term sounds g(e_x, e_y) instead of f(...)? Likewise, equation 4 needs to replace the first f(...) with g(...).\n""]","[-70, -80, 50]","[-30, -30, 60]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses disappointment with the paper's content after the introduction, stating that 'most of the contributions are overclaimed.' They also describe reading the experiment results as 'a disaster' and find many aspects of the paper confusing or unimpressive. The politeness score is -30 because while the reviewer provides specific feedback, the language used is quite direct and occasionally harsh. Phrases like 'very disappointed,' 'a disaster to me,' and 'overclaim' contribute to a somewhat impolite tone. However, the reviewer does provide detailed comments and suggestions, which prevents the score from being even lower."", ""The sentiment score is -80 because the review is highly critical, pointing out numerous issues with the paper's writing, experiments, and comparisons. The reviewer uses phrases like 'sloppily written,' 'poorly done,' and 'does not inspire confidence,' indicating a strongly negative sentiment. The politeness score is -30 because while the reviewer doesn't use explicitly rude language, the tone is quite blunt and critical. The reviewer doesn't soften their criticisms or use many polite phrases. They directly point out flaws without much attempt to cushion the feedback. However, it's not extremely impolite, as they stick to critiquing the work rather than making personal attacks, which is why it's not scored lower."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the proposed model's improvements and consistent gains over baselines, while also pointing out some issues with clarity. The review starts with a neutral summary of the work and then highlights both positive aspects and areas for improvement. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticism. Phrases like 'It would be helpful if...' and 'I'd recommend...' indicate a polite and collaborative tone. The reviewer also frames issues as questions or requests for clarification rather than direct criticisms, which contributes to the overall politeness of the review.""]"
"[""The paper develops a technique to understand what nodes in a neural network are important\nfor prediction. The approach they develop consists of using an Indian Buffet Process \nto model a binary activation matrix with number of rows equal to the number of examples. \nThe binary variables are estimated by taking a relaxed version of the \nasymptotic MAP objective for this problem. One question from the use of the \nIndian Buffet Process: how do the asymptotics of the feature allocation determine \nthe number of hidden units selected? \n\nOverall, the results didn't warrant the complexity of the method. The results are neat, but \nI couldn't tell why this approach was better than others.\n\nLastly, can you intuitively explain the additivity assumption in the distribution for p(y')"", 'The paper intends to interpret a well-trained multi-class classification deep neural network by discovering the core units of one or multiple hidden layers for prediction making. However, these discovered core units are specific to a particular class, which are retained to maintain the deep neural network’s ability to separate that particular class from the other ones. Thus, these non-core units for a particular class could be core units for separating another class from the remaining ones. Consequently, the aggregation of all class-specific core units could include all hidden units of a layer. Therefore, it is hard for me to understand what’s the motivation to identify the core units in a one-vs-remaining manner. At this moment, these identified class-specific core units are useful for neither reducing the size of the network, nor accelerating computation. ', 'Pros\n- The paper proposes a novel formulation of the problem of finding hidden units\n  that are crucial in making a neural network come up with a certain output.\n- The method seems to be work well in terms of isolating a few hidden units that\n  need to be kept while preserving classification accuracy.\n\nCons\n- Sections 3.1 and 3.2 are hard to understand. There seem to be inconsistencies\n  in the notation. For example,\n(1) It would help to clarify whether y^b_n is the prediction score or its\ntransformation into [0, 1]. The usage is inconsistent.\n(2) It is not clear how ""y^b_n can be expressed as \\sum_{k=1}^K z_{nk}f_k(x_n)""\nin general. This is only true for the penultimate layer, and when y^b_n denotes\nthe input to the output non-linearity. However, this analysis seems to be\napplied for any hidden layer and y^b_n is the output of the non-linearity unit\n(""The new prediction scores are transformed into a scalar ranging from 0 to 1,\ndenoted as y^b_n."")\n(3) Section 3.1 denotes the DNN classifier as F(.), but section 3.2 denotes the\nsame classifier as f(.).\n(4) Why is r_n called the ""center"" ? I could not understand in what sense is\nthis the center, and of what ? It seems that the max value has been subtracted\nfrom all the logits into a softmax (which is a fairly standard operation).\n\n- The analysis seems to be about finding neurons that contribute evidence for\n  a particular class. This does not address the issue of understanding why the\nnetwork makes a certain prediction for a particular input. Therefore this\napproach will be of limited use.\n\n- The paper should include more analysis of how this method helps interpret the\n  actions of the neural net, once the core units have been identified.\nCurrently, the focus seems to be on demonstrating that the classifier\nperformance is maintained as a significant fraction of hidden units are masked.\nHowever, there is not enough analysis on showing whether and how the identified\nhidden units help ""interpret"" the model.\n\nQuality\nThe idea explored in the paper is interesting and the experiments are described\nin enough detail. However, the writing still needs to be polished.\n\nClarity\nThe problem formulation and objective function (Section 3.1) was hard to follow.\n\nOriginality\nThis approach to finding important hidden units is novel.\n\nSignificance\nThe paper addresses an important problem of trying to have more interpretable\nneural networks. However, it only identifies hidden units that are important for\na class, not what are important for any particular input.  Moreover, the main\nthesis of the paper is to describe a method that helps interpret neural network\nclassifiers. However, the experiments only focus on identifying important hidden\nunits and fall short of actually providing an interpretation using these hidden\nunits.']","[-20, -50, -20]","[50, 0, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's development of a new technique and describes the results as 'neat', they also express skepticism about the method's complexity and its superiority over other approaches. The phrase 'Overall, the results didn't warrant the complexity of the method' indicates a negative sentiment towards the paper's overall contribution. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They ask questions and express concerns without using harsh or dismissive language. The reviewer also acknowledges positive aspects ('The results are neat') while presenting criticisms, which contributes to the polite tone."", ""The sentiment score is -50 because the reviewer expresses significant doubts about the usefulness and motivation of the paper's approach. They state it's 'hard to understand' the motivation and that the identified core units are 'useful for neither reducing the size of the network, nor accelerating computation.' This indicates a negative sentiment, though not entirely dismissive. The politeness score is 0 (neutral) because the language used is professional and objective, without being particularly polite or rude. The reviewer states their concerns directly but without using harsh or overly critical language. They focus on the content and methodology rather than making personal comments."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('novel formulation', 'works well'), they list more cons than pros and express several concerns about clarity, inconsistencies, and limitations of the approach. The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement without using harsh language. They acknowledge the paper's strengths and potential significance while pointing out areas that need work, which is a balanced and respectful approach to peer review.""]"
"['The main idea of this paper is to replace the feedforward summation\ny = f(W*x + b)\nwhere x,y,b are vectors, W is a matrix\nby an integral\n\\y = f(\\int W \\x + \\b)\nwhere \\x,\\y,\\b are functions, and W is a kernel. A deep neural network with this integral feedforward is called a deep function machine. \n\nThe motivation is along the lines of functional PCA: if the vector x was obtained by discretization of some function \\x, then one encounters the curse of dimensionality as one obtains finer and finer discretization. The idea of functional PCA is to view \\x as a function is some appropriate Hilbert space, and expands it in some appropriate basis. This way, finer discretization does not increase the dimension of \\x (nor its approximation), but rather improves the resolution. \n\nThis paper takes this idea and applies it to deep neural networks. Unfortunately, beyond rather obvious approximation results, the paper does not get major mileage out of this idea. This approach amounts to a change of basis - and therefore the resolution invariance is not surprising. In the experiments, results of this method should be compared not against NNs trained on the data directly, but against NNs trained on dimension reduced version of the data (eg: first fixed number of PCA components). Unfortunately, this was not done. I suspect that in this case, the results would be very similar. \n\n', 'This paper extends the framework of neural networks for finite-dimension to the case of infinite-dimension setting, called deep function machines. This theory seems to be interesting and might have further potential in applications.', 'This paper deals with the problem of learning nonlinear operators using deep learning. Specifically, the authors propose to extend deep neural networks to the case where hidden layers can be infinite-dimensional. They give results on the quality of the approximation using these operator networks, and show how to build neural network layers that are able to take into account topological information from data. Experiments on MNIST using the proposed deep function machines (DFM) are provided. \n\nThe paper attempts to make progress in the region between deep learning and functional data analysis (FDA). This is interesting. Unfortunately, the paper requires significant improvements, both in terms of substance and in terms of presentation. My main concerns are the following:\n\n1) One motivation of DFM is that in many applications data is a discretization of a continuous process and then can be represented by a function. FDA is the research field that formulated the ideas about the statistical data analysis of data samples consisting of continuous functions, where each function is viewed as one sample element. This paper fails to consider properly the work in its FDA context. Operator learning has been already studied in FDA. See for e.g. the problem of functional regression with functional responses. Indeed the functional model considered in the linear case is very similar to Eq. 2.5 or Eq. 3.2. Moreover, extension to nonparametric/nonlinear situations were also studied. The authors should add more information about previous work on this topic so that their results can be understood with respect to previous studies.\n\n2) The computational aspects of DFM are not clear in the paper. From a practical computational perspective, the algorithm will be implemented on a machine which processes on finite representations of data. The paper does not clearly provide information about how the functional nature and the infinite dimensional can be handled in practice. In FDA, generally this is achieved via basis function approximations.\n\n3) Some parts of the paper are hard to read. Sections 3 and 4 are not easy to understand. Maybe adding a section about the notation and developing more the intuition will improve the reading of the manuscript. \n\n4) The experimental section can be significantly improved. It will be interesting to compare more DFM with its discrete counterpart. Also, other FDA approaches for operator learning should be discussed and compared to the proposed approach.\n']","[-50, 60, -50]","[0, 50, 50]","[""The sentiment score is -50 because the reviewer expresses skepticism about the paper's contributions and suggests that the results may not be as significant as presented. The reviewer states that 'beyond rather obvious approximation results, the paper does not get major mileage out of this idea' and criticizes the experimental comparison. However, the review is not entirely negative, as it acknowledges the paper's motivation and approach. The politeness score is 0 (neutral) because the reviewer uses professional language without being overly polite or rude. The criticism is direct but not personal, and the tone remains objective throughout the review."", ""The sentiment score is 60 (positive) because the reviewer describes the paper's theory as 'interesting' and mentions it 'might have further potential in applications', indicating a favorable view. However, it's not extremely positive as the language is somewhat reserved ('seems to be', 'might have'). The politeness score is 50 (slightly polite) because the reviewer uses neutral, professional language without any negative or critical comments. The tone is respectful and constructive, acknowledging the paper's contribution without being overly effusive."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper, stating it 'requires significant improvements, both in terms of substance and in terms of presentation.' The reviewer lists several major issues, including lack of proper consideration of previous work, unclear computational aspects, and the need for improvement in the experimental section. However, the score is not lower because the reviewer acknowledges the paper's attempt to make progress in an interesting area.\n\nThe politeness score is 50 because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'Unfortunately, the paper requires significant improvements' instead of harsh criticism. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism. The language is not overly formal or excessively polite, but it maintains a respectful tone while delivering critique.""]"
"['The problem of pruning DNNs is an active area of study.\nThis paper addresses this problem by posing the Net-trim objective function as  a Difference of convex(DC) function. This allows for an immediate application of DC function minimization using existing techniques. An analysis of Generalization error \nis also given. \n\nThe main novelty seems to be the interesting connection to DC function minimization. The benefits seem to be a faster algorithm for pruning. \n\nAbout the generalization error the term C_2 needs to be more well defined otherwise the coefficient of  A would be -ve which may lead to complications.\n\nExperimental investigations are reasonable and the results are convincing.\n\nA list of Pros:\n1. Interesting connection to DC function\n2. Attempt to analyze generalization error \n3. Faster speed of convergence empirically\n\nA list of Cons:\n1. The contribution in posing the objective as a DC function looks limited as it is very straightforward. Also the algorithm is \ndirect application\n2. The time complexity analysis is imprecise. Since the proposed algorithm is iterative time complexity would depend on the number of iterations.\n\n\n\n\n', 'The manuscript mainly presents a cheap pruning algorithm for dense layers of DNNs. The proposed algorithm is an improvement of Net-Trim (Aghasi et al., 2016), which is to enforce the weights to be sparse.\n\nThe main contribution of this manuscript is that the non-convex optimization problem in (Aghasi et al., 2016) is reformulated as a difference of convex (DC) problem, which can be solved quite efficiently using the DCA algorithm (Tao and An, 1997). The complexity of the proposed algorithm is much lower than Net-Trim and its fast version LOBS (Dong et al., 2017). The authors also analyze the generalization error bound of DNN after pruning based on the work of (Sokolic et al., 2017).\n\nAlthough this is an incremental work built upon (Aghasi et al., 2016) and an existing algorithm (Tao and An, 1997) is adopted for optimization, the contribution is valuable since the complexity is significantly reduced by utilizing the proposed difference of convex reformulation. Although the main idea is clearly presented, there are many syntax errors and I suggest the authors carefully checking the manuscript.\n\nPros:\n1.\tThe motivation is clear and the presented reformulation is reasonable.\n\n2.\tThe generalization error analysis and the conclusion of “layers closer to the input are exponentially less robust to pruning” is interesting.\n\nCons:\n1.\tThere are many syntax errors, e.g., “Closer to our approach recently in Aghasi et al. (2016) the authors”, “an cheap pruning algorithm”, etc. Besides, there is no discussion for the results in Table 1.\n\n2.\tAlthough the complexity of the proposed method is much lower than the compared approaches (Net-Trim and LOBS), there seems to be a large sacrifice on accuracy. For example, the accuracy drops from 95.2% to 91% compared with Net-Trim in the LeNet-5 model and from 80.5% to 74.6% compared with LOBS in the CifarNet model. The proposed method is only better than hard-thresholding.\n', ""This paper casts the pruning optimization problem of NetTrim as a difference of convex problems, and uses DCA to obtain the smaller weight matrix; this algorithm is also analyzed theoretically to provide a bound on the generalization error of the pruned network.\n\nHowever, there are many questions that aren't answered in the paper that make it difficult to evaluate: in particular, some experimental results leave open more questions for performance analysis. \n\nQuality: of good quality, but incomplete.\nClarity: clear with some typos\nOriginality: a new approach to the NetTrim algorithm, which is somewhat original, and a new generalization bound for the algorithm.\nSignificance: somewhat significant.\n\nPROS\n- A very efficient algorithm for pruning, which can run orders of magnitude faster than the approaches that were compared to on certain architectures.\n- An interesting generalization bound for the pruned network which is in line experimentally with decreasing robustness to pruning on layers close to the input.\n\nCONS\n- Non-trivial loss of accuracy on the pruned network, which cannot be estimated for larger-scale pruning as the experiments only prune one layer.\n- No in-depth analysis of the generalization bound.\n\nMain questions:\n- You mention you use a variant of DCA: could you detail what differences Alg. 2 has with classical DCA?\n- Where do you use the 0-1 loss in Thm. 3.2?\n- I think your result in Theorem 3.2 would be significantly stronger if you could provide an analysis of the bound you obtain: in which cases can we expect certain terms to be larger or smaller, etc.\n- Your experiments in section 4.2 show a non-trivial degradation of the accuracy with FeTa. Although the time savings seem worth the tradeoff to prune *one* layer, have you run the same experiments when pruning multiple layers? Could you comment on how the accuracy evolves with multiple pruned layers?\n- It would be nice to see the curves for NetTrim and/or LOBS in Fig. 2.\n- Have you tried retraining the network after pruning? Did you observe the same behavior as mentioned in (Dong et al., 2017) and (Wolfe et al., 2017)? \n- It would be interseting to plot the theoretical (pessimistic) GE bound as well as the experimental accuracy degradation. \n\nNitpicks:\n-Ubiquitous (first paragraph)\n-difference of convex problemS\n- The references should be placed before the appendix.\n- The amount of white space should be reduced (e.g. around Eq. (1)).""]","[50, 50, 20]","[75, 70, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and novelty, particularly the connection to DC function minimization and faster pruning algorithm. They also mention that the experimental results are convincing. However, they point out some limitations, such as the straightforward nature of the DC function connection and imprecise time complexity analysis, which prevents a higher positive score. The politeness score is 75 (quite polite) because the reviewer uses neutral and respectful language throughout, presenting both pros and cons in a balanced manner. They avoid harsh criticism and use phrases like 'interesting connection' and 'reasonable investigations,' which contribute to a polite tone. The reviewer also provides constructive feedback, such as suggesting better definition for the C_2 term, which is a polite way to point out areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the value of the contribution despite it being incremental. They mention clear pros such as clear motivation and interesting analysis, but also point out significant cons like syntax errors and accuracy sacrifices. The overall tone is balanced but leans positive.\n\nThe politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout. They acknowledge the work's value and provide constructive feedback. The use of phrases like 'I suggest' and 'the contribution is valuable' indicates a polite approach. However, the directness in pointing out errors prevents a higher score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's good quality, clarity, and originality. They mention several pros, including an efficient algorithm and interesting generalization bound. However, they also point out cons and areas for improvement, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms constructively, and asks questions to encourage improvement rather than making harsh judgments. They use phrases like 'could you detail' and 'it would be nice to see,' which maintain a polite tone. The reviewer also balances positive and negative feedback, showing consideration for the authors' work while providing honest critique.""]"
"['The main object of the paper is the (entropy regularized) policy updates. Policy iterations are viewed as a gradient flow in the small timestep limit. Using this, (and following Jordan et al. (1998)) the desired PDE (Equation 21) is obtained. The rest of the paper discusses the implications of Equation 21 including but not limited to what happens when the time derivative of the policy is zero, and the link to noisy gradients.\n\nEven though the topic is interesting and would be of interest to the community, the paper mainly presents known results and provides an interpretation from the point of view of policy dynamics. I fail to see the significance nor the novelty in this work (esp. in light of  Jordan et al. (1998) and Peyre (2015)).\n\nThat said, I believe that exposing such connections will prove to be useful, and I encourage the authors to push the area forward. In particular, it would be useful to see demonstrations of the idea, and experimental justifications even in the form of references would be a welcome addition to the literature.', 'The paper ‘Diffusing policies: Towards Wasserstein policy gradient flows’ explores \nthe connections between reinforcement learning and the theory of quadratic optimal transport (i.e.\nusing the Wasserstein_2 as a regularizer of an iterative problem that converges toward\nan optimal policy). Following a classical result from Jordan-Kinderlehrer-Otto, they show that \nthe policy dynamics are governed by the heat equation, that translates in an advection-diffusion \nscheme. This allows to draw insights on the convergence of empirical practices in the field.\n\nThe paper is clear and well-written, and provides a comprehensive survey of known results in the \nfield of Optimal Transport. The insights on why empirical strategies such as additive gradient noise\nare very interesting and helps in understanding why they work in practical settings. That being said, \nmost of the results presented in the paper are already known (e.g. from the book of Samtambrogio or the work \nof G. Peyré on entropic Wasserstein gradient flows) and it is not exactly clear what are the original\ncontributions of the paper. The fact that the objective is to learn policies\nhas little to no impact on the derivations of calculus. It clearly suggests that the entropy \nregularized Wasserstein_2 distance should be used in numerical experiments but this point is not \nsupported by experimental results. Their direct applications is rapidly ruled out by highlighting the \ncomputational complexity of solving such gradient flows but in the light of recent papers (see \nthe work of Genevay https://arxiv.org/abs/1706.00292 or another paper submitted to ICLR on large scale optimal transport \nhttps://openreview.net/forum?id=B1zlp1bRW) numerical applications should be tractable. For these reasons \nI feel that the paper would clearly be more interesting for the practitioners (and maybe to some extent \nfor the audience of ICLR) if numerical applications of the presented theory were discussed or sketched \nin classical reinforcement learning settings.  \n\nMinor comments:\n - in Equation (10) why is there a ‘d’ in front of the coupling \\gamma ? \n - in Section 4.5, please provide references for why numerical estimators of gradient of Wasserstein distances\nare biased. \n', 'In this paper the authors studied policy gradient with change of policies limited by a trust region of Wasserstein distance in the multi-armed bandit setting. They show that in the small steps limit, the policy dynamics are governed by the heat equation (Fokker-Planck equation). This theoretical result helps us understand both the convergence property and the probability matching property in policy gradient using concepts in diffusion and advection from the heat equation. To the best of my knowledge, this line of research was dated back to the paper by Jordan et al in 1998, where they showed that the continuous control policy transport follows the Fokker-Planck equation. In general I found this line of research very interesting as it connects the convergence of proximal policy optimization to optimal transport, and I appreciate seeing recent developments on this line of work. \n\nIn terms of theoretical contributions, I see that this paper contains some novel ideas in connecting gradient flow with Wasserstein distance regularization to the Fokker-Planck equation. Furthermore its interpretation on the Brownian diffusion processes justifies the link between entropy-regularization and noisy gradients (with isotropic Gaussian noise regularization for exploration). I also think this paper is well-written and mathematically sound. While I understand the knowledge of this paper based on standard knowledge in PDE of diffusion processes and Ito calculus, I am not experienced enough in this field to judge whether these contributions are significant enough for a standalone contribution, as the problem setting is limited to multi-armed bandits.\n\nMy major critic to this paper is its practical value. Besides the proposed Sinkhorn-Knopp based algorithm in the Appendix that finds the optimal policy as fixed point of (44), I am unsure how these results lead to more effective policy gradient algorithms (with lower variance in gradient estimators, or with quasi-monotonic performance improvement etc.). There are also no experiments in this paper (for example to compare the standard policy gradient algorithm with the one that solves the Fokker-Planck equation) to demonstrate the effectiveness of the theoretical findings.']","[-20, 20, 50]","[50, 60, 80]","[""The sentiment score is slightly negative (-20) because the reviewer expresses skepticism about the novelty and significance of the work, stating 'I fail to see the significance nor the novelty in this work'. However, they do acknowledge that the topic is interesting and could be useful to the community, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges the potential value of the work, and offers constructive suggestions for improvement. They use phrases like 'I encourage the authors to push the area forward' which demonstrates a supportive tone despite the criticism. The reviewer balances their critique with positive comments and suggestions, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's clarity, comprehensive survey, and interesting insights. However, they also point out that most results are already known and express concerns about the lack of original contributions and experimental results. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'The paper is clear and well-written' and offer constructive suggestions for improvement. The tone remains professional and courteous, even when expressing concerns."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses interest in the research and appreciates the recent developments, but also raises concerns about practical value and lack of experiments. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledges their own limitations in judging the significance, and frames criticisms constructively. The reviewer uses phrases like 'I appreciate', 'I found this line of research very interesting', and 'I understand' which contribute to the polite tone. Even when expressing criticism, it's done in a professional manner, using phrases like 'My major critic to this paper is' rather than more harsh language.""]"
"['This paper provides an optimization approach for large batch training of CNN with layer-wise adaptive learning rates. \nIt starts from the observation that the ratio between the L2-norm of parameters and that of gradients on parameters varies\nsignificantly in the optimization,  and then introduce a local learning rate to consider this observation for a more stable and efficient optimization. Experimental results show improvements compared with the state-of-the-art algorithm.\n\nReview:\n(1) Pros\nThe proposed optimization method considers the dynamic self-adjustment of the learning rate in the optimization based on the ratio between the L2-norm of parameters and that of gradients on parameters  when the batch size increases, and shows improvements in experiments compared with previous methods.\n\n(2) Cons\ni) LR ""warm-up"" can mitigate the unstable training in the initial phase and the proposed method is also motivated by the stability but uses a different approach. However, it seems that the authors also combine with LR ""warm-up"" in your proposed method in the experimental part, e.g., Table 3. So does it mean that the proposed method cannot handle the problem in general?\n\nii) There is one coefficient that is independent from layers and needs to be set manually in the proposed local learning rate. The authors do not have a detail explanation and experiments about it. In fact, as can be seen in the Algorithm 1, this coefficient can be as an independent hyper-parameter (even is put with the global learning rate together as one fix term).\n\niii) In the section 6, when increase the training steps, experiments compared with previous methods should be implemented since they can also get better results with more epochs.\n\niv) Writing should be improved, e.g., the first paragraph in section 6. Some parts are confusing, for example, the authors claim that they use initial LR=0.01, but in Table 1(a) it is 0.02.  ', 'This paper proposes a training algorithm based on Layer-wise Adaptive Rate Scaling (LARS) to overcome the optimization difficulties for training with large batch size. The authors use a linear scaling and warm-up scheme to train AlexNet on ImageNet. The results show promising performance when using a relatively large batch size. The presented method is interesting. However, the experiments are poorly organized since some necessary descriptions and discussions are missing. My detailed comments are as follows.\n\nContributions：\n\n1.\tThe authors propose a training algorithm based LARS with the adaptive learning rate for each layer, and train the AlexNet and ResNet-50 to a batch size of 16K. \n2.\tThe training method shows stable performance and helps to avoid gradient vanishing or exploding.\n\nWeak points:\n\nThe training algorithm does not overcome the optimization difficulties when the batch size becomes larger (e.g. 32K), where the training becomes unstable, and the training based on LARS and warm-up can’t improve the accuracy compared to the baselines. \n\nSpecific comments: \n\n1.\tIn Algorithm 1, how to choose $ \\eta $ and $ \\beta $ in the experiment?\n2.\tUnder the line of Equation (3), $ \\nabla L(x_j, w_{t+1}) \\approx L(x_j, w_{t}) $ should be $ \\nabla L(x_j, w_{t+1}) \\approx \\nabla L(x_j, w_{t}) $.\n3.\tHow can the training algorithm based on LARS improve the generalization for the large batch? \n4.\tIn the experiments, what is the parameter iter_size? How to choose it?\n5.\tIn the experiments, no descriptions and discussions are given for Table 3, Figure 4, Table 4, Figure 5, Table 5 and Table 6. The authors should give more discussions on these tables and figures. Furthermore, the captions of these tables and figures confusing.\n6.\tOn page 4, there is a statement “The ratio is high during the initial phase, and it is rapidly decreasing after few epochs (see Figure 2).” This is quite confusing, since Figure 2 is showing the change of learning rates w.r.t. training epochs.\n', 'The paper proposes a new approach to determine learning late for convolutional neural networks. It starts from observation that for batch learning with a fixed number of epochs, the accuracy drops when the batch size is too large.  Assuming that the number or epochs and batch size are fixed, the contribution of the paper is a heuristic that assigns different learning late to each layer of a network depending on a ratio of the norms of weights and gradients in a layer.  The experimental results show that the proposed heuristic helps AlexNet and ResNet end up in a larger accuracy on ImageNet data.\n  Positives:\n- the proposed approach is intuitively justified\n- the experimental results are encouraging\n  Negatives:\n- the methodological contribution is minor\n- no attempt is made to theoretically justify the proposed heuristic\n- the method introduces one or two new hyperparameters and it is not clear from the experimental results what overhead is this adding to network training\n- the experiments are done only on a single data set, which is not sufficient to establish superiority of an approach\n  Suggestions:\n- consider using different abbreviation (LARS is used for least-angle regression) \n']","[50, -20, -20]","[70, 50, 50]","[""The sentiment score is 50 (slightly positive) because the review begins by acknowledging the paper's contributions and improvements over state-of-the-art algorithms. However, it also lists several cons, balancing out the positive aspects. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, presenting both pros and cons in a professional manner without harsh criticism. The reviewer uses phrases like 'it seems that' and poses questions rather than making accusatory statements, which contributes to the polite tone. The constructive nature of the feedback, such as suggesting improvements and additional experiments, also adds to the politeness of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('promising performance', 'interesting' method), they also point out significant weaknesses ('poorly organized', 'missing descriptions and discussions', 'does not overcome difficulties with larger batch sizes'). The overall tone suggests more criticism than praise. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They begin with positive comments before moving to criticisms, and phrase their concerns as 'comments' rather than direct criticisms. The use of phrases like 'The authors should' instead of more demanding language also contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positives ('intuitively justified', 'encouraging results'), there are more negatives listed ('minor contribution', 'no theoretical justification', 'insufficient experiments'). The overall tone suggests the reviewer is not fully convinced by the paper. The politeness score is moderately positive (50) as the reviewer uses neutral language and provides constructive feedback. They list both positives and negatives objectively, and offer suggestions for improvement without using harsh or critical language. The review maintains a professional tone throughout.""]"
"['This paper proposed a nonlinear unsupervised metric learning framework. The authors combine Coherent Point Drifting and the k-means approaches under the trace minimization framework. However, I am afraid that the novelty and insight of this work is not good enough for acceptance.\n\nPros:\nThe paper is well written and easy to follow.\n\nCons:\n1 The novelty of this paper is limited.\nThe authors mainly combine Coherent Point Drifting and the k-means under the trace minimization framework. The trace minimization is then solved with an EM-like iterative minimization.\nHowever, trace minimization is already well explored and this paper provides little insight. Furthermore, there is not any theoretical guarantee how this iterative minimization approach will converge to.\n\n2 For a method with limited novelty, comprehensive experiments are needed to verify its effectiveness. However, the experimental setting of this paper is biased.\nAn important line of works, namely deep learning based clustering, are totally missing.\nComprehensive experiments with other deep learning based clustering are required.\n', 'This paper proposed an unsupervised metric learning method, which is designed for clustering and cannot be used for other problems. The authors argued that unsupervised metric learning should not be a pre-processing method for the following clustering method due to the lack of any similarity/dissimilarity constraint. Consequently the proposed formulation plugs a certain metric learning objective, which is called CPD given in (1) and (3), into the k-means objective (2). After some linear algebra, it arrives the objective in (10) or its regularized version in (11). In order to solve (11), an alternative optimization is used to iteratively obtain the optimal Y given fixed Psi and obtain optimal Psi given fixed Y. More than one page of space is for proving the convexity of the latter subproblem.\n\nThe paper is overall well-written and I have only 1 question about the clarity: there is a very short Sec. 2.4 saying that ""So far, we developed and applied our proposed CPD-UML under input feature spaces. However, it can be further kernelized to improve the clustering performance for more complicated data."" I found this quite confusing. Just after (1), it is mentioned that Psi is the weight matrix for the Gaussian kernel functions and g is the Gaussian kernel function; it is also mentioned between (16) and (17) that G is a kernel (Gram) matrix with the Gaussian kernel. This issue of inconsistency should be clarified.\n\nThe main issues of the paper are the motivation and the experiments. While the argument of the authors is partially true, it is quite difficult to distinguish unsupervised metric learning from unsupervised feature/deep learning nowadays. The CPD model is limited in the nonlinearity to me: as shown in (1), the nonlinear function v is nonlinear in x via the so-called empirical kernel map G, and more importantly v is linear in its parameters namely Psi. If we would like to use a nonlinear-in-parameter model such as deep networks for v, the optimization for Y still works but the optimization for Psi can no longer work. This means the proposed learning objective is not model-free.\n\nThe experiments are correct to me, where 3 performance measures of clustering are reported for 10 methods on 6 datasets. However, all the datasets are quite small and thus cannot represent the most reliable comparisons of these methods. Moreover, the computational complexity of the proposed method is not discussed, but I guess it is quite high since both of the alternative subproblems require eigenvalue decomposition or solving a linear system.', ""This paper presents a scheme for unsupervised metric learning using coherent point drifting (CPD)-- the core idea is to learn a parametric model of CPD that shifts the input points such that the shifted points lead to better clustering in a K-Means setup. Following the work of Myronenko & Song, 2010, this paper uses a linear parametric model for the drift (in CPD) after mapping the input points to a kernel feature space using an RBF kernel. The CPD model is directly used within the KMeans objective -- the drift parameter matrix and the KMeans cluster assignment matrix are jointly learned using block-coordinate descent (BCD). The paper uses some interesting properties of the CPD model to derive an efficient optimization solver for the BCD subproblems. Experiments are provided on UCI datasets and demonstrate some promise.\n\nPros:\n1) The idea of using CPD for unsupervised metric learning is quite interesting\n2) The exploration into the convexity of the CPD parameter learning -- although straightforward -- is also perhaps interesting.\n3) The experiments show some promise. \n\nCons:\n1) Lacking motivation/Intuition \nThe main motivation for the approach, as far as I understand, is to learn cluster boundaries for non-linear data -- where K-Means fails. However, it is unclear to me why would one need to use K-Means for non-linear data, why not use kernelized kmeans? The proposed CPD model also is essentially learning a linear transformation of the kernelized feature space. So in contrast to kernelized kmeans, what is the advantage of the proposed framework? I see there is an improvement in performance compared to kernelized kmeans, however, intuitively I do not see how that improvement comes from? Perhaps providing some specific examples/scenarios or graphic illustrations will help appreciate the method.\n\n2) Novelty/Significance \nI think the novelty of this paper is perhaps marginal. The main idea is to directly use CPD from a prior work in a KMeans setup. There are a few parameters to be estimated in the joint learning objective, for which a block-coordinate descent strategy is proposed. The derivations are perhaps straightforward. As noted above, it is not clear what is the significance of this combination or how does it improve performance. As far as CPD goes, it looks to me that the performance depends heavily on the choice of the Gaussian RBF bandwidth parameter, and it is not clear to me how such a parameter can be selected in a unsupervised setting, when class labels are not available for cross-validation. The paper does not provide any intuitions on this front.\n\n3) Technical details.\nThere are a few important details that I do not quite follow in the paper.\n\na) The CPD is originally designed for the point matching problem, and its parametric form (\\Psi) is derived using a different a Tikhonov regularized regression model as described just above (1). The current paper directly uses this parametric form in a KMeans setup and solve the resultant problem jointly for the CPD parameter and the clustering assignment. However, it is not clear to me how the paper could use the optimal parametric form for Tikhonov regression as the optimum for the clustering problem. Ideally, I would think when formulating the joint optimization for the clustering problem, the optimal functional v(x) should also be learned/derived for the clustering problem, or some proof should be provided showing the functionals are the same. Without this, I am not convinced that the proposed formulation indeed learns the optimum drifts and the clusters jointly.\n\nb)  The subproblem on Y (the assignment matrix) looks like a standard SVD objective. It is not clear why would it be necessary to resort to Ky Fan's theorem for its optimal solution.\n\nc) The paper talks about manifold embedding in the abstract and in Sec. 2.2. However, it appears to be a straightforward dimensionality reduction (PCA) of data. If not, what is the precise manifold that is described here? \n\nd) Eq. 9, the definition of Y_c is incorrect and unclear. p is defined as a vector of ones, earlier. \n\ne) Although the assignment matrix Y has orthogonal columns, it is a binary matrix. If it is approximated by an orthonormal frame, how do you reduce it to a binary matrix? Does taking the largest values in each column suffice -- it does not look like so. However, in the paper, Y is relaxed to an orthonormal frame, which is estimated using PCA, the data points are then projected onto this low-dimensional subspace, and then k-means applied to get the Y matrix. The provided math does not support any of these steps. Thus, the technical exposition is imprecise and the solutions appear rather heuristic. \n\nf) The kernelized variant of the proposed scheme, described in Sec. 2.4 is missing important details. How precisely is the kernelization done? How is CPD extended to that setup and what would be the Gaussian kernel G in that case, and what does \\Psi signify? \n\ng) Figure 2, it seems that kernel kmeans and the proposed CPD-UML show similar cluster boundaries for low-kernel widths. Why are the high kernel widths beneficial?\n\n4) Experiments\nThere is some improvement of the proposed method -- however overall, the improvements are marginal. The discussion is missing any analysis of the results. Why it works at times, how well it improves on kernelized kmeans, and why? What is the advantage over other competitive schemes, etc. \n\nIn summary, while there is a minor novelty in connecting two separate ideas (CPD and UML) into a joint UML setup, the paper lacks sufficient motivations for proposing this setup (in contrast to say kernelized kmeans), the technical details are unconvincing, and the experiments lack sufficient details or analysis. Thus, I do not think this paper is ready to be accepted in its current form.\n\n\n""]","[-60, -20, -70]","[20, 50, 20]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the 'novelty and insight of this work is not good enough for acceptance' and lists more cons than pros. The single pro mentioned is outweighed by the significant criticisms regarding limited novelty and biased experimental settings. However, it's not entirely negative, as the reviewer acknowledges that the paper is well-written. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'I am afraid that' and 'However' to soften their criticisms, and they provide specific, constructive feedback. The language is not overly formal or polite, but it avoids rudeness or harsh language, striking a balance between honesty and courtesy."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is 'overall well-written', they raise several significant concerns about the motivation, experiments, and limitations of the proposed method. The reviewer points out issues with inconsistency, limited nonlinearity, small datasets, and potential high computational complexity. These criticisms outweigh the positive aspects, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, acknowledging positive aspects ('well-written') and framing criticisms as 'issues' or 'questions' rather than direct attacks. The reviewer also uses phrases like 'to me' when expressing opinions, which adds a polite, subjective tone. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a professional, matter-of-fact tone."", ""The sentiment score is -70 because the review is predominantly negative. While the reviewer acknowledges some positive aspects ('Pros'), the majority of the review focuses on significant concerns ('Cons') and concludes that the paper is not ready for acceptance. The reviewer points out issues with motivation, novelty, technical details, and experimental analysis. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'it is unclear to me' and 'I do not think' rather than harsh language. They also acknowledge some positive aspects before delving into criticisms. However, the score is not higher due to the direct and unambiguous nature of the criticisms, which could be perceived as somewhat blunt.""]"
"['Nice overview of adversarial techniques in natural language classification. The paper introduces the problem of adversarial perturbations, how they are constructed and demonstrate what effect they can have on a machine learning models. \n\nThe authors study several real-world adversarial examples, such as spam filtering, sentiment analysis and fake news and use these examples to test several popular classification models in context of adversarial perturbations. \n\nTheir results demonstrate the existence of adversarial perturbations in NLP and show that several different types of errors occur (syntactic, semantic, and factual). Studying each of these errors type can help defend and improve the classification algorithms via adversarial training.\n\nPros: Good analysis on real-world examples\nCons: I was expecting more actual solutions in addition to analysis', ""This paper proposes a method to generate adversarial examples for text classification problems. They do this by iteratively replacing words in a sentence with words that are close in its embedding space and which cause a change in the predicted class of the text. To preserve correct grammar, they only change words that don't significantly change the probability of the sentence under a language model.\n\nThe approach seems incremental and very similar to existing work such as Papernot et. al. The paper also states in the discussion in section 5.1 that they generate adversarial examples in state-of-the-art models, however, they ignore some state of the art models entirely such as Miyato et. al.\n\nThe experiments are solely missing comparisons to existing text adversarial generation approaches such as Papernot et. al and a comparison to adversarial training for text classification in Miyato et. al which might already mitigate this attack. The experimental section also fails to describe what kind of language model is used, (what kind of trigram LM is used? A traditional (non-neural) LM? Does it use backoff?).\n\nFinally, algorithm 1 does not seem to enforce the semantic constraints in Eq. 4 despite it being mentioned in the text. This can be seen in section 4.5 where the algorithm is described as choosing words that were far in word vector space. The last sentence in section 6 is also unfounded.\n\n\nNicolas Papernot, Patrick McDaniel, Ian Goodfellow, Somesh Jha, Z.Berkay Celik, and Ananthram Swami\nPractical Black-Box Attacks against Machine Learning.\nProceedings of the 2017 ACM Asia Conference on Computer and Communications Security\n\nTakeru Miyato, Andrew M. Dai and Ian Goodfellow\nAdversarial Training Methods for Semi-Supervised Text Classification.\nInternational Conference on Learning Representation (ICLR), 2017\n\n* I increased the score in response to the additional experiments done with Miyato et. al. However, the lack of a more extensive comparison with Papernot et. al. is still needed. The venue for that paper might not be well known but it was submitted to arXiv computer science too and the paper seems very related to this work. It's hard to say if Papernot et. al produces more perceptible samples without doing a proper comparison. I find the lack of a quantitative comparison to any existing adversarial example technique problematic."", 'The paper shows that neural networks are sensitive to adversarial perturbation for a set of NLP text classifications. They propose constructing (model-dependent) adversarial examples by optimizing a function J (that doesn\'t seem defined in the paper) subject to a constraint c(x, x\') < \\gamma (i.e. that the original input and adversarial input should be similar)\n\nc is composed of two constraints:\n1. || v - v\' ||_2 < \\gamma_1, where v and v\' are bag of embeddings for each input \n2. |log P(x\') - log P(x)| < \\gamma_2 where P is a language model\n\nThe authors then show that for 3 classification problems ""Trec07p"", ""Yelp"", and ""News"" and 4 models (Naive Bayes, LSTM, word CNNs, deep-char-CNNs) that the models that perform considerably worse on adversarial examples than on the test set.  Furthermore to test the validity of their adversarial examples, the authors show the following:\n1. Humans achieve somewhat similar accuracy on the original adverarial examples (8 points higher on one dataset and 8 points lower on the other two)\n2. Humans rate the writing quality of both the original and adversarial examples to be similar\n3. The adversarial examples only somewhat transfer across models\n\nMy main questions/complaints/suggestions for the paper are:\n\n-Novelty/Methodology. The paper has mediocre novelty given other similar papers recently. \n\nOn question I have is about whether the generated examples are actually close to the original examples. The authors do show some examples that do look good, but do not provide any systematic study (e.g. via human annotation)\n\n This is a key challenge in NLP (as opposed to vision where the inputs are continuous so it is easy to perturb them and be reasonably sure that the image hasn\'t changed much). In NLP however, the words are discrete, and the authors measure the difference between an original example and the adversary only in continuous space which may not actually be a good measure of how different they are.\n\nThey do have some constraint that the fraction of changed words cannot differ by more than delta, but delta = 0.5 in the experiments, which is really large! (i.e. 50% of the words could be different according to Algorithm 1)\n\n-Writing: the function J is never mathematically defined, neither is the function c (except that it is known to be composed of the semantic/syntactic similarity constraints).\n\nThe authors talk about ""syntactic"" similarity but then propose a language model constraint. I think is a better word is ""fluency"" constraint. \n\nThe results in Table 3 and Table 6 seem different, shouldn\'t the diagonal of Table 6 line up with the results in Table 3?\n\n-Experimental methodology (more of a question since authors are unclear): The authors write that ""all adversarial examples are generated and evaluated on the test set"".\n\nThere are many hyperparameters in the proposed authors\' approach, are these also tuned on the test set? That is unfair to the base classifier. The adversarial model should be tuned on the validation set, and then the same model should be used to generate test set examples. (The authors can even show the validation adversarial accuracy to show how/if it deviates from the test accuracy)\n\n-Lack of related work in NLP (see the anonymous comment for some examples). Even the related work in NLP that is cited e.g. Jia and Liang 2017 is obfuscated in the last page. The authors\' introduction only refers to related works in vision/speech and ignores related NLP work.\n\nFurthermore, adversarial perturbation is related to domain transfer  (since both involve shifts between the training and test distribution) and it is well known for instance that models that are trained on Wall Street Journal perform poorly on other domains.  See SJ Pan and Q Yang, A Survey on transfer learning, 2010, for some example references.']","[60, -40, -30]","[70, 20, 20]","[""The sentiment score is 60 (positive) because the reviewer provides a generally positive overview of the paper, highlighting its strengths such as 'Nice overview', 'good analysis on real-world examples', and the value of the results. However, it's not extremely positive due to the mention of a con and an expectation for more solutions. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, starting with 'Nice overview' and maintaining a professional tone. They provide balanced feedback, mentioning both pros and cons without harsh criticism. The reviewer's language is constructive and appreciative of the work done, while also offering gentle suggestions for improvement."", ""The sentiment score is -40 because the review is generally critical, pointing out several limitations and issues with the paper, such as the approach being incremental, missing comparisons to existing work, and lacking important experimental details. However, it's not entirely negative as it acknowledges some improvements made in response to previous feedback. The politeness score is 20 because the reviewer uses professional and neutral language throughout, avoiding harsh criticism while still clearly communicating the paper's shortcomings. The reviewer also acknowledges improvements made by the authors, which adds a polite tone. The language is constructive rather than dismissive, offering specific suggestions for improvement."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., showing sensitivity to adversarial perturbation, providing examples), they express several criticisms and concerns. These include 'mediocre novelty', questions about methodology, writing issues, and lack of related work. The overall tone suggests more negative than positive sentiment, but not extremely negative.\n\nThe politeness score is 20 because the reviewer uses generally professional and respectful language. They frame criticisms as 'questions/complaints/suggestions' and use phrases like 'My main questions are...' which softens the critique. The reviewer also acknowledges positive aspects of the work. However, some direct criticisms (e.g., 'mediocre novelty') prevent a higher politeness score.\n\nThe language is more formal and constructive than rude, but not overtly polite or deferential, hence a slightly positive score.""]"
"['The authors present an l-1 regularized SVRG based training algorithm that is able to force many weights of the network to be 0, hence leading to good compression of the model.  The motivation for l-1 regularization is clear as it promotes sparse models, which lead to lower storage overheads during inference. The use of SVRG is motivated by the fact that it can, in some cases, provide faster convergence than SGD.\n\nUnfortunately, the authors do not compare with some key literature. For example there has been several techniques that use sparsity, and group sparsity [1,2,3], that lead to the same conclusion as the paper here: models can be significantly sparsified while not affecting the test accuracy of the trained model.\n\nThen, the novelty of the technique presented is also unclear, as essentially the algorithm is simply SVRG with l1 regularization and then some quantization. The experimental evaluation does not strongly support the thesis that the presented algorithm is much better than SGD with l1 regularization. In the presented experiments, the gap between the performance of SGD and SVRG is small (especially in terms of test error), and overall the savings in terms of the number of weights is similar to Deep compression. Hence, it is unclear how the use of SVRG over SGD improves things. Eg in figure 2 the differences in top-1 error of SGD and SVRG, for the same number of weights is very similar (it’s unclear also why Fig 2a uses top-1 and Fig 2b uses top-5 error). I also want to note that all experiments were run on LeNet, and not on state of the art models (eg ResNets).\n\nFinally, the paper is riddled with typos. I attach below some of the ones I found in pages 1 and 2\n\nOverall, although the topic is very interesting, the contribution of this paper is limited, and it is unclear how it compares with other similar techniques that use group sparsity regularization, and whether SVRG offers any significant advantages over l1-SGD.\n\ntypos:\n“ This work addresses the problem by proposing methods Weight Reduction Quantisation”\n-> This work addresses the problem by proposing a Weight Reduction Quantisation method\n\n“Beside, applying with sparsity-inducing regularization”\n-> Beside, applying sparsity-inducing regularization\n\n“Our method that minibatch SVRG with l-1 regularization on non-convex problem”\n-> Our minibatch SVRG with l-1 regularization method on non-convex problem\n\n“As well as providing,l1 regularization is a powerful compression techniques to penalize some weights to be zero”\n-> “l1 regularization is a powerful compression technique that forces some weights to be zero”\n\n The problem 1 can\n->  The problem in Eq.(1) can\n\n“it inefficiently encourages weight”\n-> “it inefficiently encourages weights”\n\n————\n\n[1] Learning Structured Sparsity in Deep Neural Networks\nhttp://papers.nips.cc/paper/6504-learning-structured-sparsity-in-deep-neural-networks.pdf\n\n[2] Fast ConvNets Using Group-wise Brain Damage\nhttps://arxiv.org/pdf/1506.02515.pdf\n\n[3] Sparse Convolutional Neural Networks\nhttps://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liu_Sparse_Convolutional_Neural_2015_CVPR_paper.pdf\n\n\n', 'Summary: \nPaper proposes the compression method Delicate-SVRG-cumulative-L1 (combining minibatch SVRG with cumulative L1 regularization) which can significantly reduce the number of weights without affecting the test accuracy. Paper provides numerical experiments for MNIST and CIRAR10 on LeNet-300-100 and LeNet-5. \n\nComments: \nUp to my knowledge, Han et. al (2016) is not the leading result. There are (at least) two more results which are better than Han et. al. (2016) and also better than your results for LeNet-300-100 and LeNet-5 (MNIST), which were already published at ICML 2017 and NIPS 2016: \nhttp://papers.nips.cc/paper/6165-dynamic-network-surgery-for-efficient-dnns.pdf\nhttp://proceedings.mlr.press/v70/molchanov17a/molchanov17a.pdf\n\nThere is no theory supporting the proposed method (which is the combination of some existing methods). Therefore, you should provide more experiments to show the efficiency. MNIST and CIFAR10 on LeNet-300-100 and LeNet-5 are quite standard that people have already shown. \n\nMoreover, there is no guarantee for sparsity by using L1 regularization on nonconvex problems.  \n\nMinor comments: \nPage 3, section 2, first paragraph: typo in the last sentence: “dose” -> “does” \nSame typo above for page 5, the sentence right before (2) Bias-based pruning\n', 'It is very hard to follow this work, it feels like it tries to get several messages across while none of them properly. The work further contains number of unclear or incorrect claims, meaningless comparison with existing work, and unbelievable results (""0.737% error rate"" on CIFAR-10).\n\nIn introduction, first, the paper seems to be about L1-regularization, with few motivating remarks valid only for convex problems, then about novel optimization method, and suddenly main contribution is reducing memory requirements. Further, part on ""Cumulative l1 regularization"" need to be better explained if, as it seems, plays important role in what you do. In discussion about SVRG, I don\'t understand how claims about convergence and batch size make sense, please provide reference, and how is it important for what you do later. When you say ""Hence, a promising approach is to use..."" I don\'t understand how it either follows from discussion above, nor what is the problem that you address.\nIn Main Contributions, 2.1 - ""we analyse non-convex SVRG"" - I don\'t see any kind of analysis in the paper.\n\nSec 3. you use IFO of Agarwal and Bottou which is known not to include this kind of algorithm - see large red box above abstract in the last version of the cited paper. Even then it is not clear what you try to say in the section, and whether any of it is new.\n\nSec 3.1. What is the notion of ""larger dataset""? You regard CIFAR-10 as larger than MNIST.\n\nSec 4. After 4 pages of discussion on optimization algorithms, you write (very ambiguous) 4 lines about quantization, and compare against work not related to optimization at all. No explanation of what is presented in the table nor notation used. It requires lot of guessing to see what you try to do.\nIf I guessed correctly, you propose optimization method used together with particular objective function to train a model that is sparse in its final trained form, and then reduce numerical precision used to represent the model. And compare that to Han et al.\n1. If this is what you try to do, it is never clearly stated it up to this point, and much of the preceding text is irrelevant and it is sufficient to just refer to existing work... I now see you have a similar statement in Discussion, but if this is what you try to do and has to be explained at the beginning.\n2. It does not make any sense to compare against Han et al (precisely against the numbers presented in their paper), as you are compressing something else. If applied to your trained model, I believe it would achieve significantly better result.\n\nI did not properly look at the experiments, as it is not clear what you do/propose in first place, and you seems to report 0.737% error rate on CIFAR-10, and in the appendix, plots for CIFAR-10 show convergence to ~3% test error with LeNet-5.']","[-50, -50, -80]","[20, 0, -20]","[""The sentiment score is -50 because the review is generally critical of the paper. While the reviewer acknowledges the interesting topic and clear motivation, they point out several significant issues: lack of comparison with key literature, unclear novelty, limited experimental support, and numerous typos. The overall tone suggests that the paper's contribution is limited. However, the score is not extremely negative as the reviewer does recognize some positive aspects.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout, despite the criticisms. They use phrases like 'Unfortunately' and 'Overall, although the topic is very interesting' to soften their critiques. The reviewer also provides specific suggestions for improvement and references to relevant literature, which is helpful and courteous. However, the score is not higher because the review is direct in its criticisms and doesn't use overly polite language."", ""The sentiment score is -50 because the review is generally critical, pointing out significant shortcomings in the paper. The reviewer notes that the paper's results are not as good as some existing methods and that there's a lack of theoretical support for the proposed method. However, it's not entirely negative as the reviewer acknowledges the paper's contribution and provides constructive feedback.\n\nThe politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout. They don't use overly polite language, but they also don't use rude or disrespectful language. The criticism is presented in a straightforward, matter-of-fact manner. The reviewer points out issues and suggests improvements without personal attacks or overly harsh language.\n\nThe reasoning for these scores is based on the content and tone of the review. The reviewer provides specific criticisms (lack of theory, need for more experiments, outdated comparisons) but does so in a neutral, professional manner. They also offer constructive suggestions and point out minor typos, which shows attention to detail without being overly critical."", ""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer states that the work is 'very hard to follow', contains 'unclear or incorrect claims', and has 'unbelievable results'. They also point out numerous issues with the paper's structure, clarity, and content. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite harsh and critical. They use phrases like 'It is very hard to follow this work' and 'I don't understand' multiple times, which comes across as somewhat impatient and frustrated. However, they do provide specific feedback and suggestions for improvement, which prevents the score from being even lower.""]"
"['This paper describes DReLU, a shift version of ReLU. DReLU shifts ReLU from (0, 0) to (-\\sigma, -\\sigma). The author runs a few CIFAR-10/100 experiments with DReLU.\n\nComments:\n\n1. Using expectation to explain why DReLU works well is not sufficient and convincing. Although DReLU’s expectation is smaller than expectation of ReLU, but it doesn’t explain why DReLU is better than very leaky ReLU, ELU etc.\n2. CIFAR-10/100 is a saturated dataset and it is not convincing DReLU will perform will on complex task, such as ImageNet, object detection, etc.\n3. In all experiments, ELU/LReLU are worse than ReLU, which is suspicious. I personally have tried ELU/LReLU/RReLU on Inception V3 with Batch Norm, and all are better than ReLU. \n\nOverall, I don’t think this paper meet ICLR’s novelty standard, although the authors present some good numbers, but they are not convincing. \n\n\n', 'The key argument authors present against ReLU+BN is the fact that using ReLU after BN skews the values resulting in non-normalized activations. Although the BN paper suggests using BN before non-linearity many articles have been using BN after non-linearity which then gives normalized activations (https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md) and also better overall performance. The approach of using BN after non-linearity is termed ""standardization layer"" (https://arxiv.org/pdf/1301.4083.pdf). I encourage the authors to validate their claims against simple approach of using BN after non-linearity.  ', 'This paper proposes an activation function, called displaced ReLU (DReLU), to improve the performance of CNNs that use batch normalization. Compared to ReLU, DReLU cut the identity function at a negative value rather than the zero. As a result, the activations outputted by DReLU can have a mean closer to 0 and a variance closer to 1 than the standard ReLU. The DReLU is supposed to remedy the problem of covariate shift better. \n\nThe presentation of the paper is clear. The proposed method shows encouraging results in a controlled setting (i.e., all other units, like dropout, are removed). Statistical tests are performed for many of the experimental results, which is solid.\n\nHowever, I have some concerns. \n1) As DReLU(x) = max{-\\delta, x}, what is the optimal strategy to determine \\delta? If it is done by hyperparameter tuning with cross-validation, the training cost may be too high.\n2) I believe the control experiments are encouraging, but I do not agree that other techniques like Dropouts are not useful. Using DReLU to improve the state-of-art neural network in an uncontrolled setting is important. The arguments for skipping this experiments are respectful, but not convincing enough.  \n3) Batch normalization is popular, especially for the convolutional neural networks. However, its application is not universal, which can limit the use of the proposed DReLU. It is a minor concern, anyway. \n\n\n']","[-50, -20, 50]","[0, 50, 80]","[""The sentiment score is -50 because the reviewer expresses skepticism about the paper's novelty and convincingness, stating it doesn't meet ICLR's standards. They point out several limitations but acknowledge some 'good numbers', hence not entirely negative. The politeness score is 0 (neutral) as the reviewer maintains a professional tone without being particularly polite or rude. They directly state their concerns and criticisms without using overly harsh language or personal attacks, but also without using explicitly polite phrases or softening their critique."", ""The sentiment score is slightly negative (-20) because the reviewer challenges the authors' key argument and suggests that their claims may not be valid against a simple alternative approach. This indicates some skepticism towards the paper's main point. However, it's not strongly negative as the reviewer encourages further validation rather than outright dismissing the work. The politeness score is moderately positive (50) because the language used is professional and constructive. The reviewer uses phrases like 'I encourage the authors' which is polite and supportive. They also provide specific references to back up their points, which is respectful. The tone is not overly formal or effusive, hence not reaching the highest levels of politeness, but it maintains a courteous and helpful demeanor throughout."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's clear presentation and encouraging results in controlled settings. They also appreciate the use of statistical tests. However, they express some concerns, which prevents a higher positive score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting concerns. They use phrases like 'I believe' and 'I do not agree' to express disagreement politely, and describe the authors' arguments as 'respectful'. The tone is constructive and professional throughout.""]"
"[""This paper proposes leveraging labelled controlled data to accelerate reinforcement-based learning of a control policy.  It provides two main contributions: pre-training the policy network of a DDPG agent in a supervised manner so that it begins in reasonable state-action distribution and regalurizing the Q-updates of the q-network to be biased towards existing actions.  The authors use the TORCS enviroment to demonstrate the performance of their method both in final cumulative return of the policy and speed of learning.\n\nThis paper is easy to understand but has a couple shortcomings and some fatal (but reparable) flaws:.\n\n1) When using RL please try to standardize your notation to that used by the community, it makes things much easier to read.  I would strongly suggest avoiding your notation a(x|\\Theta) and using \\pi(x) (subscripting theta or making conditional is somewhat less important).  Your a(.) function seems to be the policy here, which is invariable denoted \\pi in the RL literature.  There has been recent effort to clean up RL notation which is presented here: https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf. You have no obligation to use this notation but it does make reading of your paper much easier on others in the community.  This is more of a shortcoming than a fundamental issue.\n\n2) More fatally, you have failed to compare your algorithm's performance against benchline implementations of similar algorithms.  It is almost trivial to run DDPG on Torcs using the openAI baselines package [https://github.com/openai/baselines].  I would have loved, for example, to see the effects of simply pre-training the DDPG actor on supervised data, vs. adding your mixture loss on the critic.  Using the baselines would have (maybe) made a very compelling graph showing DDPG, DDPG + actor pre-training, and then your complete method.\n\n3) And finally, perhaps complementary to point 2), you really need to provide examples on more than one environment.  Each of these simulated environments has its own pathologies linked to determenism, reward structure, and other environment particularities.  Almost every algorithm I've seen published will often beat baselines on one environment and then fail to improve or even be wors on others, so it is important to at least run on a series of these.  Mujoco + AI Gym should make this really easy to do (for reference, I have no relatinship with OpenAI).  Running at least cartpole (which is a very well understood control task), and then perhaps reacher, swimmer, half-cheetah etc. using a known contoller as your behavior policy (behavior policy is a good term for your data-generating policy.)\n\n4) In terms of state of the art you are very close to Todd Hester et. al's paper on imitation learning, and although you cite it, you should contrast your approach more clearly with the one in that paper.  Please also have a look at some more recent work my Matej Vecerik, Todd Hester & Jon Scholz: 'Leveraging Demonstrations for Deep Reinforcement Learning on Robotics Problems with Sparse Rewards' for an approach that is pretty similar to yours.\n\nOverall I think your intuitions and ideas are good, but the paper does not do a good enough job justifying empirically that your approach provides any advantages over existing methods.  The idea of pre-training the policy net has been tried before (although I can't find a published reference) and in my experience will help on certain problems, and hinder on others, primarily because the policy network is already 'overfit' somewhat to the expert, and may have a hard time moving to a more optimal space.  Because of this experience I would need more supporting evidence that your method actually generalizes to more than one RL environment."", '\nThe paper was fairly easy to follow, but I would not say it was well written. These are minor annoyances; there were some typos and a strange citation format. There is nothing wrong with the fundamental idea itself, but given the experimental results it just is not clear that it is working.\n\nThe bot performance significantly better than the fully trained agent. This leads to a few questions:\n\n1. What was the performance of the ""regression policy"", that was learned during the supervised pretraining phase?\n2. Given enough time would the basic RL agent reach similar performance? (Guessing no...) Why not?\n3. Considering the results of Figure 3 (right) shouldn\'t the conclusion be that the RL portion is essentially contributing nothing?\n\nPros:\nThe regularization of the Q-values w.r.t. the policy of another agent is interesting\n\nCons:\nNot very well setup experiments\nPerformance is lower than you would expect just using supervised training\nNot clear what parts are working and what parts are not\n\n\n', 'This paper proposes to combine reinforcement learning with supervised learning to speed up learning. Unlike their claim in the paper, the idea of combining supervised and RL is not new. A good example of this is a supervised actor-critic by Barto (2004). I think even alphaGo uses some form of supervision. However, if I understand correctly, it seems that combining supervision of RL at a later fine-tuning phase by considering supervision as a regularization term is an interesting idea that seems novel.\n\nHaving the luxury of some supervised episodes is of course useful. The first step of building a supervised initial model looks straight forward. The next step of the algorithm is less easy to follow, and presentation of the ideas could be much better. This part of the paper leaves me already with many questions such as why is it essential to consider only a deterministic case and also to consider greedy optimization? Doesn’t this prevent exploration? What are the network parameters (e.g. size of layers) etc. I am not sure I could redo the work from the provided information.\n\nOverall, it is unclear to me what the advantage of the algorithm is over pure supervised learning, and I don’t think a compelling case has been made. Since the influence of the supervision is increased by increasing alpha, it can be expected that results should be better for increasing alpha. The results seem to indicate that an intermediate level of alpha is best, though I would even question the statistical significance by looking at the curves in Figure 3. Also, what is the epoch number, and why is this 1 for alpha=0? If the combination of supervised learning with RL is better, than this should be clearly stated. Some argument is made that pure supervision is overfitting, but would one then not simply add some other regularizer? \n\nThe presentation could also be improved with some language edits. Several articles are wrongly placed and even some meaning is unclear. For example, the phrase “continuous input sequence” does not make sense; maybe you mean “input sequence of real valued quantities”.\n\nIn summary, while the paper contains some good ideas, I certainly think it needs more work to make a clear case for this method. \n']","[-30, -30, -20]","[50, 20, 50]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('easy to understand', 'intuitions and ideas are good'), they primarily focus on shortcomings and 'fatal (but reparable) flaws'. The overall tone suggests the paper needs significant improvements. The politeness score is 50 because the reviewer uses polite language throughout, such as 'I would strongly suggest', 'I would have loved', and 'Please also have a look'. They provide constructive criticism and offer specific recommendations for improvement, which is considerate. However, the use of terms like 'fatal flaws' and 'shortcomings' prevents a higher politeness score, as these could be perceived as somewhat harsh despite the overall respectful tone."", ""The sentiment score is -30 because the review is generally critical, pointing out several issues with the paper and its experiments. The reviewer states that the paper is 'not very well written' and has 'minor annoyances'. They also question the effectiveness of the proposed method, noting that 'it just is not clear that it is working'. However, the score is not extremely negative as the reviewer acknowledges some positive aspects, such as the 'interesting' regularization technique.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively polite tone throughout. They use phrases like 'fairly easy to follow' and frame their criticisms as questions or observations rather than harsh judgments. The reviewer also balances their critique by mentioning both 'Pros' and 'Cons'. However, the score is not higher because some statements are quite direct and potentially discouraging, such as 'Performance is lower than you would expect'."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some 'good ideas' and 'interesting' aspects, they express several criticisms and doubts about the paper's novelty, clarity, and overall contribution. The reviewer states that 'more work' is needed and questions the statistical significance of the results. However, it's not entirely negative as they do recognize some positive aspects.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'if I understand correctly' and 'I think' to soften criticisms, and they offer constructive feedback rather than harsh judgments. The reviewer also acknowledges the potential of the paper with phrases like 'contains some good ideas'. However, the score isn't higher because the criticism, while politely phrased, is still direct and substantial.""]"
"['This paper proposes a neural network architecture around the idea of layered scene composition.  Training is cast in the generative adversarial framework; a subnetwork is reused to generate and compose (via an output mask) multiple image layers; the resulting image is fed to a discriminator.  An encoder is later trained to map real images into the space of latent codes for the generator, allowing the system to be applied to real image segmentation tasks.\n\nThe idea is interesting and different from established approaches to segmentation.  Visualization of learned layers for several scene types (Figures 3, 7) shows that the network does learn a reasonable compositional scene model.\n\nExperiments evaluate the ability to port the model learned in an unsupervised manner to semantic segmentation tasks, using a limited amount of supervision for the end task.  However, the included experiments are not nearly sufficient to establish the effectiveness of the proposed method.  Only two scene types (bedroom, kitchen) and four object classes (bed, window, appliance, counter) are used for evaluation.  This is far below the norm for semantic segmentation work in computer vision.  How does the method work on established semantic segmentation datasets with many classes, such as PASCAL?  Even the ADE20K dataset, from which this paper samples, is substantially larger and has an established benchmarking methodology (see http://placeschallenge.csail.mit.edu/).\n\nAn additional problem is that performance is not compared to any external prior work.  Only simple baselines (eg autoencoder, kmeans) implemented by this paper are included.  The range of prior work on semantic segmentation is extensive.  How well does the approach compare to supervised CNNs on an established segmentation task?  Note that the proposed method need not necessarily outperform supervised approaches, but the reader should be provided with some idea of the size of the gap between this unsupervised method and the state-of-the-art supervised approach.\n\nIn summary, the proposed method may be promising, but far more experiments are needed.\n', ""This paper creates a layered representation in order to better learn segmentation from unlabeled images. It is well motivated, as Fig. 1 clearly shows the idea that if the segmentation was removed properly, the result would still be a natural image. However, the method itself as described in the paper leaves many questions about whether they can achieve the proposed goal.\n\nI cannot see from the formulation why would this model work as it is advertised. The formulation (3-4) looks like a standard GAN, with some twist about measuring the GAN loss in the z space (this has been used in e.g. PPGN and CVAE-GAN). I don't see any term that would guarantee:\n\n1) Each layer is a natural image. This was advertised in the paper, but the loss function is only on the final product G_K. The way it is written in the paper, the result of each layer does not need to go through a discriminator. Nothing seems to have been done to ensure that each layer outputs a natural image.\n\n2) None of the layers is degenerate. There does not seem to be any constraint either regularizing the content in each layer, or preventing any layer to be non-degenerate.\n\n3) The mask being contiguous. I don't see any term ensuring the mask being contiguous, I imagine normally without such terms doing such kinds of optimization would lead to a lot of fragmented small areas being considered as the mask.\n\nThe claim that this paper is for unsupervised semantic segmentation is overblown. A major problem is that when conducting experiments, all the images seem to be taken from a single category, this implicitly uses the label information of the category. In that regard, this cannot be viewed as an unsupervised algorithm.\n\nEven with that, the results definitely looked too good to be true. I have a really difficult time believing why such a standard GAN optimization would not generate any of the aforementioned artifacts and would perform exactly as the authors advertised. Even if it does work as advertised, the utilization of implicit labels would make it subject to comparisons with a lot of weakly-supervised learning papers with far better results than shown in this paper. Hence I am pretty sure that this is not up to the standards of ICLR.\n\nI have read the rebuttal and still not convinced. I don't think the authors managed to convince me that this method would work the way it's advertised. I also agree with Reviewer 2 that there is a lack of comparison against baselines."", 'Paper summary: The paper proposes a generative model that decomposes images into multiple layers. The proposed approach is GAN-based, where the objective of the GAN is to distinguish real images from images formed by combining the layers. Some of the layers correspond to objects that are common in specific scene categories. The method has been tested on kitchen and bedroom scenes.\n\nPaper Strengths:\n+ The idea of the paper is interesting.\n+ The learned masks for objects are neat.\n+ The proposed method outperforms a number of simple baselines.\n\nPaper Weaknesses:\n\n- The evaluation of the model is not great: (1) It would be interesting to combine bedroom and kitchen images and train jointly to see what it learns. (2) It would be good to see how the performance changes for different number of layers. (3) Regarding the fine-tuning baselines, the comparison is a bit unfair since the proposed method performs pooling over images, while the baseline (average mask) is not translation invariant.\n\n- It is unclear why ""contiguous"" masks are generated (e.g., in figure 4). Is there any constraint in the optimization? This should be explained in the rebuttal. \n\n- The method should not be called ""unsupervised"" since it knows the label for the scene category. Also, it should not be called ""semantic segmentation"" since there is no semantics associated to the object. It is just a binary foreground/background mask.\n\n- The plots in Figure 5 are a bit strange. The precision increases uniformly as the recall goes up, which is weird. It should be explained in the rebuttal why that happens.\n\n- Similar to most GAN-based models, the generated images are not that appealing.\n\n- The claim about object removal should be toned down. The method is not able to remove any object from a scene. Only, the learned layers can be removed.\n']","[-20, -80, -20]","[50, 20, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting idea and reasonable compositional scene model, they express significant concerns about insufficient experiments and lack of comparison to prior work. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positive aspects and framing criticisms constructively. They use phrases like 'The idea is interesting' and 'the proposed method may be promising,' while clearly stating areas for improvement without harsh language."", ""The sentiment score is -80 because the review is predominantly negative. The reviewer expresses significant doubts about the paper's methodology, claims, and results. They state that the paper 'leaves many questions,' that they 'cannot see... why would this model work,' and that the claims are 'overblown.' The reviewer also mentions that the results look 'too good to be true' and concludes that the paper is 'not up to the standards of ICLR.' The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I cannot see' and 'I don't see' rather than making accusatory statements. The reviewer also acknowledges the paper's motivation positively at the beginning. However, the overall tone is more matter-of-fact than overtly polite, hence the relatively low positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper ('interesting idea', 'neat learned masks', 'outperforms baselines'), there are more weaknesses listed than strengths. The criticisms are substantial, including issues with evaluation, methodology, terminology, and results presentation. However, the tone is not entirely negative, as the reviewer sees potential in the work.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They begin by acknowledging the paper's strengths before moving on to criticisms. The weaknesses are presented as constructive feedback rather than harsh criticism. Phrases like 'It would be interesting to...', 'It would be good to see...', and 'This should be explained...' suggest a collaborative approach to improving the paper rather than outright dismissal. The reviewer also uses neutral language when pointing out issues, avoiding accusatory or inflammatory statements.""]"
"['* PAPER SUMMARY *\n\nThis paper proposes a siamese net architecture to compare text in different languages. The proposed architecture builds upon siamese RNN by Mueller and Thyagarajan. The proposed approach is evaluated on cross lingual bitext retrieval.\n\n* REVIEW SUMMARY * \n\nThis paper is hard to read and need proof-reading by a person proficient in English. The experiments are extremely limited, on a toy task. No other baseline than (Mueller and Thyagarajan, 2016) is considered. The related work section lacks important references. It is hard to find positive points that would advocate for a presentation at ICLR.\n\n* DETAILED REVIEW *\n\nOn related work, the authors need to consider related work on cross lingual retrieval, multilingual document representation:\n\nBai, Bing, et al. ""Learning to rank with (a lot of) word features."" Information retrieval 13.3 (2010): 291-314. (Section 4).\n\nSchwenk, H., Tran, K., Firat, O., & Douze, M. Learning Joint Multilingual Sentence Representations with Neural Machine Translation, ACL Workshop on Representation Learning for NLP, 2017\n\nKarl Moritz Hermann and Phil Blunsom.  Multilingual models for compositional distributed semantics. In ACL 2014. pages 58–68.\n\nHieu Pham, Minh-Thang Luong, and Christopher D. Manning. Learning distributed representations for multilingual text sequences. In Workshop\non Vector Space Modeling for NLP. 2015\n\nXinjie Zhou, Xiaojun Wan, and Jianguo Xiao. Cross-lingual sentiment classification with bilingual document representation learning. In ACL 2016\n\n...\n\nOn evaluation, the authors need to learn about standard retrieval evaluation metrics such as precision at top 10, etc and use them. For instance, this book will be a good read.\n\nBaeza-Yates, Ricardo, and Berthier Ribeiro-Neto. Modern information retrieval. Vol. 463. New York: ACM press, 1999.\n\nOn learning objective, the authors might want to read about learn-to-rank objectives for information retrieval, for instance, \n\nLiu, Tie-Yan. ""Learning to rank for information retrieval."" Foundations and Trends in Information Retrieval 3.3 (2009): 225-331.\n\nBurges, Christopher JC. ""From ranknet to lambdarank to lambdamart: An overview."" Learning 11, no. 23-581 (2010): 81.\n\nChapelle, Olivier, and Yi Chang. ""Yahoo! learning to rank challenge overview."" Proceedings of the Learning to Rank Challenge. 2011.\n\nHerbrich, Ralf, Thore Graepel, and Klaus Obermayer. ""Large margin rank boundaries for ordinal regression."" (2000).\n\nOn experimental setup, the authors want to consider a setup with more than 8k training documents. More importantly, ranking a document set of 1k documents is extremely small, toyish. For instance, (Schwenk et al 2017) search through 1.5 million sentences. (Bai, Bing, et al 2009) search through 140k documents. Since you mainly introduces 2 modifications with respect to (Mueller and Thyagarajan, 2016), i.e  (i) not sharing the parameters on both branch of the siamese and (ii) the fully connected net on top, I would suggest to measure the effect of each of them both on multilingual data and on the SICK dataset used in (Mueller and Thyagarajan, 2016).', ""In the Following, pros and cons of the paper are presented.\n\nPros\n-------\n\n1. Many real-world applications.\n2. Simple architecture and can be reproduced (if given enough details.)\n\n\nCons\n----------------------\n\n1. Ablation study showing whether bidirectional LSTM contributing to the similarity would be helpful.\n2. Baseline is not strong. How about using just LSTM?\n4. It is suprising to see that only concatenation with MLP is used for optimization of capturing regularities across languages. \n5. Equation-11 looks like softplus function more than vanilla ReLU.\n6. How are the similarity assessments made in the gold standard dataset. The cost function used only suggest binary assessments. Please refer to some SemEval tasks for cross-lingual or cross-level assessments. As binary assessments may not be a right measure to compare articles of two different lengths or languages.\n\nMinor issues\n------------\n\n1. SNS is meant to be social networking sites?\n2. In Section 2.2, it denote that 'as the figure demonstrates'. No reference to the figure.\n3. In Section 3, 'discussed in detail' pointed to Section 2.1 related work section. Not clear what is discussed in detail there.\n4. Reference to Google Translate API is wrong.\n\n\nThe paper requires more experimental analysis to judge the significance of the approach presented.\n"", '\nThe paper studies the problem of estimating cross-lingual text similarity by mining news corpora. The motivation of the problem and applications are presented well, especially for news recommender systems.\n\nHowever, there are no novel scientific contributions. The idea of fusing standard bi-LSTM layers coupled with a dense fully-connected layer alone is not a substantial technical contribution. Did they try other deep architectures for the task? The authors cite some previous works to explain their choice of approach for this task. A detailed analysis of different architectures (recurrent and others) on the specifc task would have been more convincing. \n\nComparison against other relevant baselines (including other cross-lingual retrieval approaches) is missing. There are several existing works on learning cross-lingual word embeddings (e.g., Mikolov et al., 2013). Some of these also make available pre-trained embeddings in multiple languages. You could combine them to learn cross-lingual semantic similarities for the retrieval task. How does your approach compare to these other approaches besides the Siamese LSTM baseline? \n\nOverall, it is unclear what the contributions are — there has been a lot of work in the NLP/IR literature on the same task, yet there is no detailed comparison against any of these relevant baselines. The technical contributions are also not novel or strong  to make the paper convincing. \n']","[-80, -30, -60]","[-20, 20, 20]","[""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer states it is 'hard to find positive points', criticizes the paper as 'hard to read', calls the experiments 'extremely limited' and a 'toy task', and points out numerous deficiencies in related work, evaluation metrics, and experimental setup. The politeness score is -20 because while the language is not overtly rude, it is quite blunt and critical without much effort to soften the criticism. The reviewer directly states negative points without hedging or using polite language. However, they do provide extensive constructive feedback and references, which prevents the score from being lower."", ""The sentiment score is -30 because while the review acknowledges some pros (real-world applications, simple architecture), it lists more cons and issues, and concludes that 'more experimental analysis' is needed, indicating overall dissatisfaction. The tone is not entirely negative, hence not a lower score. The politeness score is 20 because the language used is professional and constructive, avoiding harsh criticism. The reviewer uses phrases like 'would be helpful' and 'please refer to' which are polite ways of suggesting improvements. However, it's not overly polite or effusive, maintaining a neutral professional tone overall."", ""The sentiment score is -60 because the review is predominantly negative. While it acknowledges the paper's good presentation of motivation and applications, it criticizes the lack of novel scientific contributions, insufficient comparison with baselines, and unclear overall contributions. The reviewer uses phrases like 'However, there are no novel scientific contributions' and 'Overall, it is unclear what the contributions are,' indicating a negative sentiment. The politeness score is 20 because the reviewer maintains a professional tone throughout, using neutral language and offering constructive criticism. They avoid harsh or rude phrasing, instead using more diplomatic expressions like 'would have been more convincing' and 'it is unclear.' The slightly positive politeness score reflects this professional courtesy while delivering critical feedback.""]"
"['The paper tries to build an interpretable and accurate classifier via stacking a supervised VAE (SVAE) and a differentiable decision tree (DTT). The problem is important and interesting. The authors list the contributions of each part but it seems that only the final contribution, i.e. analysis of the interpretability, is interesting and should be further extended and emphasized. Here with the detailed comments.\n\n1. I think Table 2 does not make sense at all. This is not only because the authors use the label information but also because the authors compare different quantities. The the previous methods evaluate log p(x) while the proposed method evaluates log p(x, y) which should be much lower as the proposed method potentially trains a separated model for each class of the x for evaluation.\n\n2. The generation results of the SVAE shown in Figure 7 in Appendix A seem strange as the diversity of the samples is much less than those from the vanilla VAEs. Could the authors explain this mode collapse phenomenon? \n\n3. The results in Table 1 are not interesting.  It is most useful to interpret the state-of-the-art classifier while the results of the proposed methods are far from the state-of-the-art even on such simple MNIST dataset.\n\n4. The most interesting results of this paper are shown in Figure 1. However, I think the results on the interpretability should be further extended. Several questions are as follows: \n\nWhy other dimensions are not so interpretable, compared with 21?\n\nCan we also interpret a VAE given labels by varying each dimension of the latent variables without jointly training a DTT? I personally think some of the dimensions of the latent variables of the vanilla VAEs can also be interpreted via interpolation in each dimension. \n\nCan these results be generalized to other datasets, consisting of natural images? \n\nOverall, this paper is below the acceptance threshold.\n ', 'This paper addresses a method of building an interpretable model for classification, where two key ingredients are (1) supervised variational autoencoder and (2) differentiable decision tree. Recently one important line of research is to build interpretable models which have more modeling capacity while maintaining interpretability, over existing models such as linear models or decision trees. In this sense, the current work is timely research. A few contributions are claimed in this paper: (1) differentiable decision tree which allows for gradient-based optimization; (2) supervised VAE where class-specific Gaussian prior is used for the probabilistic decoder in the VAE; (3) combination of these two models. Regarding the differentiable decision tree, I am not an expert in decision tree. However, I understand that there have been various work on probabilistic decision tree, Bayesian decision tree, and Mondrian tree. More literature survey might be needed to pin-point what\'s new and what\'s common with previous work. Regarding the supervised VAE, the term ""supervised VAE"" is misleading. To me, the current model is nothing but VAE with class-specific Gaussian prior. (3)  Regarding the combination of supervised VAE and DDT, it would be much better to show us a graphical illustration of the model to improve the readability. I see the encoder is common for both the decoder and DDT. However, it is not clear how DDT is coupled with the encoder. It seems that DDT takes the output of the encoder as input but the output of DDT is not coupled with VAE.  ', ""\nSummary\n\nThis paper proposes a hybrid model (C+VAE)---a variational autoencoder (VAE) composed with a differentiable decision tree (DDT)---and an accompanying training scheme.  Firstly, the prior is specified as a mixture distribution with one component per class (SVAE).  During training, the ELBO’s KL term uses the component that corresponds to the known label.  Secondly, the DDT’s leaves are parametrized with the encoder distribution q(z|x), and thus gradient information flows back through the DDT into the posterior approximations in order to make them more discriminative.  Lastly, the VAE and DDT are trained together by alternating optimization of each component (plus a ridge penalty on the decoder means).  Experiments are performed on MNIST, demonstrating tree classification performance, (supervised) neg. log likelihood performance, and latent space interpretability via the DDT.  \n\n\nEvaluation\n\nPros:  Giving the VAE discriminative capabilities is an interesting line of research, and this paper provides another take on tree-based VAEs, which are challenging to define given the discrete nature of the former and continuous nature of the latter.  Thus, I applaud the authors for combining the two in a way that admits efficient training.  Moreover, I like the qualitative experiment (Figure 2) in which the tree is used to vary a latent dimension to change the digit’s class.  I can see this being used for dataset augmentation or adversarial example generation, for instance.\n\nCons:  An indefensible flaw in the work is that the model is evaluated on only MNIST.  As there is no strong theory in the paper, this limited experimental evaluation is reason enough for rejection.  Yet, moreover, the negative log likelihood comparison (Table 2) is not an informative comparison, as it speaks only to the power of adding supervision.  Lastly, I do not think the interpretability provided by the decision tree is as great as the authors seem to claim.  Decision trees provide rich and interpretable structure only when each input feature has clear semantics.  However, in this case, the latent space is being used as input to the tree.  As the decision tree, then, is merely learning hard, class-based partitioning rules for the latent space, I do not see how the tree is representing anything especially revealing.  Taking Figure 2 as an example (which I do like the end result of), I could generate similar results with a black-box classifier by using gradients to perturb the latent ‘4’ mean into a latent ‘7’ mean (a la DeepDream).  I could then identify the influential dimension(s) by taking the largest absolute values in the gradient vector.  Maybe there is another use case in which a decision tree is superior; I’m just saying Section 4.3 doesn’t convince me to the extent that was promised earlier in the paper (and by the title).\n\nComment:  It's easier to make a latent variable model interpretable when the latent variables are given clear semantics in the model definition, in my opinion.  Otherwise, the semantics of the latent space become too entangled.  Could you, somehow, force the tree to encode an identifiable attribute at each node, which would then force that attribute to be encoded in a certain dimension of latent space?      \n""]","[-70, -20, -20]","[20, 50, 60]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that only one contribution is interesting, criticizes the methodology and results, and concludes that the paper is 'below the acceptance threshold.' However, it's not entirely negative as they acknowledge the problem as 'important and interesting' and find some aspects worth further exploration. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'Could the authors explain' and 'I think,' which soften the critique. The reviewer also provides specific suggestions for improvement, which is constructive. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the timeliness and importance of the research, they express several concerns and criticisms. They suggest more literature survey is needed, point out that the term 'supervised VAE' is misleading, and request clarification on how the model components are coupled. These critiques outweigh the initial positive remarks, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging their own limitations ('I am not an expert'), and offering constructive suggestions ('it would be much better to show us a graphical illustration'). The tone is professional and objective, without any harsh or rude comments, but also not overly deferential or excessively polite."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they also point out significant flaws ('Cons') that are 'reason enough for rejection'. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the authors' efforts ('I applaud the authors') and offering constructive criticism. They also use phrases like 'I like' and 'I can see' to soften critiques. The reviewer maintains a professional tone, avoiding harsh language even when pointing out flaws, and offers a suggestion for improvement at the end.""]"
"['This paper introduces a method for regularizing the REINFORCE algorithm by keeping around a small set of known high-quality samples as part of the sample set when performing stochastic gradient estimation.\n\nI question the value of program synthesis in a language which is not human-readable. Typically, source code as function representation is desirable because it is human-interpretable. Code written in brainfuck is not  readable by humans. In the related work, a paper by Nachum et al is criticized for providing a sequence of machine instructions, rather than code in a language. Since code in brainfuck is essentially a sequence of pointer arithmetic operations, and does not include any concept of compositionality or modularity of code (e.g. functions or variables), it is not clear what advantage this representation presents. Neither am I particularly convinced by the benchmark of a GA for generating BF code. None of these programs are particularly complex: most of the examples found in table 4 are quite short, over half of them 16 characters or fewer. 500 million evaluations is a lot. There are no program synthesis examples demonstrating types of functions which perform complex tasks involving e.g. recursion, such as sorting operations.\n\nThere is also an odd attitude in the writing of this paper, reflected in the excerpt from the first paragraph describing that traditional approaches to program synthesis “… typically do not make use of machine learning and therefore require domain specific knowledge about the programming languages and hand-crafted heuristics to speed up the underlying combinatorial search. To create more generic programming tools without much domain specific knowledge …”. Why is this a goal? What is learned by restricting models to be unaware of obviously available domain-specific knowledge? \n\nAll this said, the priority queue training presented here for reinforcement learning with sparse rewards is interesting, and appears to significantly improve the quality of results from a naive policy gradient approach. It would be nice to provide some sort of analysis of it, even an empirical one. For example, how frequently are the entries in the queue updated? Is this consistent over training time? How was the decision of K=10 reached? Is a separate queue per distributed training instance a choice made for implementation reasons, or because it provides helpful additional “regularization”? While the paper does demonstrate that PQT is helpful on this very particular task, it makes very little effort to investigate *why* it is helpful, or whether it will usefully generalize to other domains.\n\nSome analysis, perhaps even on just a small toy problem, of e.g. the effect of the PQT on the variance of the gradient estimates produced by REINFORCE, would go a long way towards convincing a skeptical reader of the value of this approach. It would also help clarify under what situations one should or should not use this. Any insight into how one should best set the lambda hyperparameters would also be very appreciated.', 'This paper presents an algorithm called Priority Queue Training (PQT) for\nprogram synthesis using an RNN where the RNN is trained in presence of a \nreward signal over the desired program outputs. The RNN learns a policy \nthat generates a sequence of characters in BF conditioned on a prefix of characters.\nThe key idea in PQT is to maintain a buffer of top-K programs at each \ngradient update step, and use them to perform additional supervised learning\nof the policy to guide the policy towards generating higher reward programs.\nPQT is compared against genetic algorithm (GA) and policy gradient (PG) based\napproaches on a set of BF benchmarks, where PQT is able to achieve the most \nnumber of average successes out of 25 runs.\n\nUnlike previous synthesis approaches that use supervision in terms of ground\ntruth programs or outputs, the presented technique only requires a reward \nfunction, which is much more general. It is impressive to see that a simple \ntechnique of using top-K programs to provide additional supervision during \ntraining can outperform strong GA and PG baselines.\n\nIt seems that the PQT approach is dependent on being able to come up with a \nreasonably good initial policy \\pi such that the top-K programs in the priority \nqueue are reasonable, otherwise the supervised signal might make the RNN policy\nworse. How many iterations are needed for PQT to come up with the target programs?\nIt would be interesting to see the curve that plots the statistics about the \nrewards of the top-K programs in the priority queue over the number of iterations.\n\nIs there also some assumption being made here in terms of the class of programs\nthat can be learnt using the current scoring function? For example, can the if/then\nconditional tasks from the AI Programmer paper be learnt using the presented \nscoring function?\n\nI have several questions regarding the evaluation and comparison metrics.\n\nFor the tuning task (remove-char), GA seems to achieve a larger number of\nsuccesses (12) compared to PQT (5) and PG+PQT (1). Is it only because the \nNPE is 5M or is there some other reasons for the large gap?\n\nThe criterion for success in the evaluation is not a standard one for program\nsynthesis. Ideally, the success criterion should be whether a technique is able\nto find any program that is consistent with the examples. Observing the results\nin Table 3, it looks like GA is able to synthesize a program for 3 more benchmarks\n(count-char, copy-reverse, and substring) whereas PQT is only able to solve one\nmore benchmark (cascade) than GA (on which PQT instead seems to overfit).\nIs there some insights into how the PQT approach can be made to solve those \ntasks that GA is able to solve?\n\nHow do the numbers in Table 3 look like when the NPE is 5M and when NPE is \nlarger say 100M?\n\nThere are many learnt programs in Table 4 that do not seem to generalize to new \ninputs. How is a learnt program checked to be correct in the results reported \nin Table 3? It seems the current criterion is just to check for correctness on \na set of 5 to 20 predefined static test cases used during training. For every \nbenchmark, it would be good to separately construct a set of held out test cases \n(possibly of larger lengths) to evaluate the generalization correctness of the \nlearnt programs. How would the numbers in Table 3 look with such a correctness \ncriterion of evaluating on a held-out set?\n\nAre there some insights regarding why programs such as divide-2, dedup or echo-thrice\ncan not be learnt by PQT or any other approach? The GA approach in the AI programmer \npaper is able to learn multiply-2 and multiply-3 programs that seems comparable to \nthe complexity of divide-2 task. Can PQT learn multiply-3 program as well?\n', 'This paper focuses on using RNNs to generate straightline computer programs (ie. code strings) using reinforcement learning.  The basic setup assumes a setting where we do not have access to input/output samples, but instead only have access to a separate reward function for each desired program that indicates how close a predicted program is to the correct one.  This reward function is used to train a separate RNN for each desired program.\n\nThe general space of generating straight-line programs of this form has been explored before, and their main contribution is the use of a priorty queue of highest scoring programs during training.  This queue contains the highest scoring programs which have been observed at any point in the training so far, and they consider two different objectives:  (1) the standard policy-gradient objective which tries to maximize the expected reward and (2) a supervised learning objective which tries to maximize the average probability of the top-K samples.  They show that this priority queue algorithm significantly improves the stability of the resulting synthesis procedure such that when synthesis succeeds at all, it succeeds for most of the random seeds used.\n\nThis is a nice result, but I did not feel as though their algorithm was sufficently different from the algorithm used by Liang et. al. 2017.  In Liang et. al. they keep around the best observed program for each input sample.  They argue that their work is different from Liang et. al. because they show that they can learn effectively using only objective (2) while completely dropping objective (1).  However I\'m quite worried these results only apply in very specific setups.  It seems that if the policy gradient objective is not used, and there are not K different programs which generate the correct output, then the Top-K objective alone will encourage the model to continue to put equal probability on the programs in the Top-K which do not generate an incorrect output.\n\nI also found the setup itself to be poorly motivated.  I was not able to imagine a reasonable setting where we would have access to a reward function of this form without input/output examples.  The paper did not provide any such examples, and in their experiments they implement the proposed reward function by assuming access to a set of input/output examples.  I feel as though the restriction to the reward function in this case makes the problem uncessarily hard, and does not represent an important use-case.  \n\nIn addition I had the following more minor concerns:\n\n1.  At the end of section 4.3 the paper is inconsistent about whether the test cases are randomly generated or hand picked, and whether they use 5 test cases for all problems, or sometimes up to 20 test cases.  If they are hand picked (and the number of test cases is hand chosen for each problem), then how dependant are the results on an appropriate choice of test cases?\n\n2.  They argue that they don\'t need to separate train and test, but I think it is important to be sure that the generated programs work on test cases that are not a part of the reward function.  They say that ""almost always"" the synthesizer does not overfit, but I would have liked them to be clear about whether their reported results include any cases of overfitting (i.e. did they ensure they the final generate program always generalized)? \n\n3.  It is worth noting that while their technique succeeds much more consistently than the baseline genetic algorithm, the genetic algorithm actually succeeds at least once, on more tasks (19 vs. 17).  The success rate is probably a good indicator of whether the technique will scale to more complex problems, but I would have prefered to see this in the results, rather than just hoping it will be true (i.e. by including my complicated problems where the genetic algorithm never succeeds).\n']","[-50, 50, -20]","[-20, 80, 50]","[""The sentiment score is -50 because the reviewer expresses significant skepticism and criticism about the paper's approach and value. They question the usefulness of the chosen programming language, the complexity of the examples, and the rationale behind avoiding domain-specific knowledge. However, they do acknowledge some positive aspects, such as the interesting priority queue training method, which prevents the score from being even lower. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism and dismissive language. Phrases like 'I question the value,' 'odd attitude,' and 'very little effort to investigate' come across as somewhat impolite. The reviewer doesn't use overtly rude language, but their critiques are direct and at times harsh, lacking in softening language that would make the feedback more constructive and polite."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and finds the technique 'impressive', but also raises several questions and concerns about the methodology and results. The overall tone is constructive rather than overtly critical or enthusiastic. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the strengths of the work. The reviewer uses phrases like 'It is impressive to see' and 'It would be interesting to see', which contribute to a polite and constructive tone. The questions and suggestions are presented in a way that invites further discussion rather than dismissing the work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('This is a nice result'), they express several concerns and criticisms about the paper. The reviewer questions the novelty of the algorithm, the motivation for the setup, and raises several minor concerns. However, the tone is not entirely negative, as they do recognize some merits of the work. The politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They phrase their criticisms constructively, using phrases like 'I did not feel as though...' and 'I would have prefered to see...' rather than making blunt or harsh statements. The reviewer also balances criticism with acknowledgment of positive aspects, which contributes to the polite tone.""]"
"['This paper baffles me. It appears to be a stochastic RNN with skip connections (so it\'s conditioned on the last two states rather than last one) trained by an adversarial objective (which is no small feat to make work for sequential tasks) with results shown on the firetruck category of the QuickDraw dataset. Yet the authors claim significantly more importance for the work than I think it merits.\n\nFirst, there is nothing variational about their variational RNN. They seem to use the term to be equivalent to ""stochastic"", ""probabilistic"" or ""noisy"" rather than having anything to do with optimizing a variational bound. To strike the right balance between pretension and accuracy, I would suggest substituting the word ""stochastic""  everywhere ""variational"" is used.\n\nSecond, there is nothing self-improving or collaborative about their self-improving collaborative GAN. Once the architecture is chosen to share the weights between the weak and strong generator, the only difference between the two is that the weak generator has greater noise at the output. In this sense the architecture should really be seen as a single model with different noise levels at alternating steps. In this sense, I am not entirely clear on what the difference is between the SIC-GAN and their noisy GAN baseline - presumably the only difference is that the noisy GAN is conditioned on a single timestep instead of two at a time? The claim that these models are somehow ""self-improving"" baffles me as well - all machine learning models are self-improving, that is the point of learning. The authors make a comparison to AlphaGo Zero\'s use of self-play, but here the weak and strong generators are on the same side of the game, and because there are no game rules provided beyond ""reproduce the training set"", there is no possibility of discovery beyond what is human-provided, contrary to the authors\' claim.\n\nThird, the total absence of mathematical notation made it hard in places to follow exactly what the models were doing. While there are plenty of papers explaining the GAN framework to a novice, at least some clear description of the baseline architectures would be appreciated (for instance, a clearer explanation of how the SIC-GAN differs from the noisy GAN). Also the description of the soft $\\ell_1$ loss (which the authors call the ""1-loss"" for some reason) would benefit from a clearer mathematical exposition.\n\nFourth, the experiments seem too focused on the firetruck category of the QuickDraw dataset. As it was the only example shown, it\'s difficult to evaluate their claim that this is a general method for improving variety without sacrificing quality. Their chosen metrics for variety and detail are somewhat subjective, as they depend on the fact that some categories in the QuickDraw dataset resemble firetrucks in the fine detail while others resemble firetrucks in outline. This is not a generalizable metric. Human evaluation of the relative quality and variety would likely suffice.\n\nLastly, the entire section on the strong-weak collaborative GAN seems to add nothing. They describe an entire training regiment for the model, yet never provide any actual experimental results using that model, so the entire section seems only to motivate the SIC-GAN which, again, seems like a fairly ordinary architectural extension to GANs with RNN generators.\n\nThe results presented on QuickDraw do seem nice, and to the best of my knowledge it is the first (or at least best) applications of GANs to QuickDraw - if they refocused the paper on GAN architectures for sketching and provided more generalizable metrics of quality and variety it could be made into a good paper.', 'Overall the paper is good: good motivation, insight, the model makes sense, and the experiments / results are convincing. I would like to see some evidence though that the strong generator is doing exactly what is advertised: that it’s learning to clean up the mistakes from variation. Can we have some sort of empirical analysis that what you say is true? \n\nThe writing grammar quality fluctuates. Please clean up.\n\nDetailed notes\nP1:\nWhy did you pass on calling it Self-improving collaborative adversarial learning (SICAL)?\nI’m very surprised you don’t mention VAE RNN here (Chung et al 2015) along with other models that leverage an approximate posterior model of some sort.\n\nP2:\nWhat about scheduled sampling?\nIs the quality really better? How do you quantify that? To me the ones at the bottom of 2(c) are of both lower quality *and* diversity.\n“Figure 2(d) displays human-drawn sketches of fire trucks which demonstrate that producing sequences–in this case sketches–with both quality and variety is definitely achievable in real-world applications”: I’m not sure I follow this argument. Because people can do it, ML should be able to?\n\nP3:\n“Recently, studies start to apply GANs to generate the sequential output”: fix this\nGrammar takes a brief nose-dive around here, making it a little harder to read.\nCaption: “bean search”\nChe et al also uses something close to Reinforcement learning for discrete sequences.\n“nose-injected”: now you’re just being silly\nMaybe cite Bahdanau et al 2016 “An actor-critic algorithm for sequence prediction”\n“does not require any variety reward/measure to train” What about the discriminator score (MaliGAN / SeqGAN)? Could this be a simultaneous variety + quality reward signal? If the generator is either of poor-quality or has low variety, the discriminator could easily distinguish its samples from the real ones, no?\n\nP6:\nDid you pass only the softmax values to the discriminator?\n\nP7:\nI like the score scheme introduced here. Do you see any connection to inception score?\nSo compared to normal GAN, does SIC-GAN have more parameters (due to the additional input)? If so, did you account for this in your experiments?', ""The paper proposed a method that tries to generate both accurate and diverse samples from RNNs. \nI like the basic intuition of this paper, i.e., using mistakes for creativity and refining on top of it. I also think the evaluation is done properly. I think my biggest concern is that the method was only tested on a single dataset hence it is not convincing enough. Also on this particular dataset, the method does not seem to strongly dominate the other methods. Hence it's not clear how much better this method is compared to previously proposed ones.""]","[-70, 50, 20]","[-20, 60, 50]","[""The sentiment score is -70 because the reviewer expresses significant criticism and skepticism throughout the review. They use phrases like 'baffles me,' 'nothing variational,' 'nothing self-improving,' and point out multiple issues with the paper's claims and methodology. The overall tone is quite negative, though they do acknowledge some positive aspects ('results presented on QuickDraw do seem nice'), preventing the score from being even lower. The politeness score is -20 because while the reviewer doesn't use overtly rude language, their tone is often dismissive and bordering on condescending. Phrases like 'baffles me' and 'strike the right balance between pretension and accuracy' come across as somewhat impolite. However, the reviewer does maintain a professional tone overall and offers constructive criticism, which prevents the score from being more negative."", ""The sentiment score is 50 (slightly positive) because the review starts with 'Overall the paper is good' and mentions several positive aspects, but also points out areas for improvement. The reviewer asks for more evidence and notes fluctuating writing quality, indicating a balanced but generally positive view. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as questions or polite requests (e.g., 'Can we have...', 'Please clean up.'). However, there are a few instances of more direct criticism ('now you're just being silly') that prevent a higher politeness score. The reviewer maintains a professional tone while providing detailed feedback, balancing praise with areas for improvement."", ""The sentiment score is slightly positive (20) because the reviewer expresses liking the basic intuition of the paper and acknowledges proper evaluation. However, they also raise concerns about limited testing and unclear superiority over existing methods, which tempers the positivity. The politeness score is moderately positive (50) as the reviewer uses respectful language, acknowledging positives before presenting criticisms, and phrases concerns as personal opinions ('I think') rather than harsh statements. The tone is professional and constructive without being overly formal or effusive.""]"
"['The paper studies catastrophic forgetting, which is an important aspect of deep reinforcement learning (RL). The problem formulation is connected to safe RL, but the emphasis is on tasks where a DQN is able to learn to avoid catastrophic events as long as it avoids forgetting. The proposed method is novel, but perhaps the most interesting aspect of this paper is that they demonstrate that “DQNs  are susceptible to periodically repeating mistakes”. I believe this observation, though not entirely novel, will inspire many researchers to study catastrophic forgetting and propose improved strategies for handling these issues.\n\nThe paper is accurate, very well written (apart from a small number of grammatical mistakes) and contains appealing motivations to its key contributions. In particular, I find the basic of idea of introducing a component that represents fear natural, promising and novel. \n\nStill, many of the design choices appear quite arbitrary and can most likely be improved upon. In fact, it is not difficult to design examples for which the proposed algorithm would be far from optimal. Instead I view the proposed techniques mostly as useful inspiration for future papers to build on. As a source of inspiration, I believe that this paper will be of considerable importance and I think many people in our community will read it with great interest. The theoretical results regarding the properties of the proposed algorithm are also relevant, and points out some of its benefits, though I do not view the results as particularly strong. \n\nTo conclude, the submitted manuscript contains novel observations and results and is likely to draw additional attention to an important aspect of deep reinforcement learning. A potential weakness with the paper is that the proposed strategies appear to be simple to improve upon and that they have not convinced me that they would yield good performance on a wider set of problems. \n', 'The paper addresses the problem of learners forgetting rare states and revisiting catastrophic danger states. The authors propose to train a predictive ‘fear model’ that penalizes states that lead to catastrophes. The proposed technique is validated both empirically and theoretically. \n\nExperiments show a clear advantage during learning when compared with a vanilla DQN. Nonetheless, there are some criticisms than can be made of both the method and the evaluations:\n\nThe fear radius threshold k_r seems to add yet another hyperparameter that needs tuning. Judging from the description of the experiments this parameter is important to the performance of the method and needs to be set experimentally. There seems to be no way of a priori determine a good distance as there is no way to know in advance when a catastrophe becomes unavoidable. No empirical results on the effect of the parameter are given.\n\nThe experimental results support the claim that this technique helps to avoid catastrophic states during initial learning.The paper however, also claims to address the longer term problem of revisiting these states once the learner forgets about them, since they are no longer part of the data generated by (close to) optimal policies.  This problem does not seem to be really solved by this method. Danger and safe state replay memories are kept, but are only used to train the catastrophe classifier. While the catastrophe classifier can be seen as an additional external memory, it seems that the learner will still drift away from the optimal policy and then need to be reminded by the classifier through penalties. As such the method wouldn’t prevent catastrophic forgetting, it would just prevent the worst consequences by penalizing the agent before it reaches a danger state. It would therefore  be interesting to see some long running experiments and analyse how often catastrophic states (or those close to them) are visited. \n\nOverall, the current evaluations focus on performance and give little insight into the behaviour of the method. The paper also does not compare to any other techniques that attempt to deal with catastrophic forgetting and/or the changing state distribution ([1,2]).\n\nIn general the explanations in the paper often often use confusing and  imprecise language, even in formal derivations, e.g.  ‘if the fear model reaches arbitrarily high accuracy’ or ‘if the probability is negligible’.\n\nIt is wasn’t clear to me that the properties described in Theorem 1 actually hold. The motivation in the appendix is very informal and no clear derivation is provided. The authors seem to indicate that a minimal return can be guaranteed because the optimal policy spends a maximum of epsilon amount of time in the catastrophic states and the alternative policy simply avoids these states. However, as the alternative policy is learnt on a different reward, it can have a very different state distribution, even for the non-catastrophics states.  It might attach all its weight to a very poor reward state in an effort to avoid the catastrophe penalty. It is therefore not clear to me that any claims can be made about its performance without additional assumptions.\n\nIt seems that one could construct a counterexample using a 3-state chain problem (no_reward,danger, goal) where the only way to get to the single goal state is to incur a small risk of visiting the danger state. Any optimal policy would therefore need to spend some time e in the danger state, on average. A policy that learns to avoid the danger state would then also be unable to reach the goal state and receive rewards. E.g pi* has stationary distribution (0,e,1-e) and return 0*0+e*Rmin + (1-e)*Rmax. By adding a sufficiently high penalty, policy pi~ can learn to avoid the catastrophic state with distribution (1,0,0) and then gets return 1*0+ 0*Rmin+0*Rmax= 0 < n*_M - e (Rmax - Rmin) = e*Rmin + (1-e)*Rmax - e (Rmax - Rmin).  This seems to contradict the theorem. It wasn’t clear what assumptions the authors make to exclude situations like this.\n\n[1] T. de Bruin, J. Kober, K. Tuyls and R. Babuška, ""Improved deep reinforcement learning for robotics through distribution-based experience retention,"" 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), Daejeon, 2016, pp. 3947-3952.\n[2] Kirkpatrick, J., Pascanu, R., Rabinowitz, N., Veness, J., Desjardins, G., Rusu, A. A., ... & Hassabis, D. (2017). Overcoming catastrophic forgetting in neural networks. Proceedings of the National Academy of Sciences, 201611835.', '\nSUMMARY\n\nThe paper proposes an RL algorithm that combines the DQN algorithm with a fear model.  The fear model is trained in parallel to predict catastrophic states.  Its output is used to penalize the Q learning target.\n\n\n\nCOMMENTS\n\nNot convinced about the fact that an agent forgets about catastrophic states. Because it does not experience it any more.  Shouldn’t the agent stop learning at some point in time?  Why does it need to keep collecting good data?  How about giving more weight to catastrophic data (e.g., replicating it)\n\nIs the catastrophic scenario specific to DRL or RL in general with function approximation?\n\nWhy not specify catastrophic states with a large negative reward?\n\nIt seems that catastrophe states need to be experienced at least once.\nIs that acceptable for the autonomous car hitting a pedestrian?\n']","[60, -20, -20]","[80, 50, 50]","[""The sentiment score is 60 (positive) because the reviewer expresses overall positive views about the paper, highlighting its novelty, potential impact, and well-written nature. They mention that it will inspire researchers and draw attention to an important aspect of deep reinforcement learning. However, they also point out some weaknesses, such as arbitrary design choices and potential for improvement, which prevents the score from being higher. The politeness score is 80 (very polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths and provide criticism in a tactful manner, using phrases like 'I believe' and 'I view' to soften their critiques. The reviewer also balances negative points with positive ones, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('clear advantage during learning', 'validated both empirically and theoretically'), they raise several significant criticisms and concerns. These include issues with hyperparameter tuning, limitations in addressing long-term problems, lack of comparison with other techniques, unclear explanations, and potential flaws in the theoretical claims. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'there are some criticisms that can be made' and 'it would be interesting to see' rather than harsh or dismissive language. The reviewer also provides specific suggestions for improvement and cites relevant literature, which is helpful and respectful to the authors."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's proposal, they express several doubts and criticisms about the approach. The reviewer questions the fundamental assumptions of the paper and points out potential limitations, indicating a somewhat skeptical stance. However, the tone is not entirely negative, as the reviewer engages with the ideas presented and offers constructive feedback.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns and frame their criticisms as questions or suggestions rather than direct attacks. The reviewer doesn't use any harsh or dismissive language, instead opting for a constructive approach to feedback. While not overly formal or deferential, the tone is appropriate and courteous for academic peer review.""]"
"['The paper is easy to read  for a physicist, but I am not sure how useful it would be for ICLR... it is not clear for me it there is an interest for quantum problems in this conference. This is something I will let to the Area Chair to deceede. Other than this, the paper is interesting, certainly correct, and provides a nice perspective on the future of learning with quantum computers. I like the  quantum ""boltzmann machine"" problems. \n\nI feel, however, but it might be a bit far from the main interest of the conference.\n\nComments:\n\n* What the authors called ""Free energy-based reinforcement learning"" seems to me just the minimization / maximiation of the free energy. This is simply maximum likelihood applied to the free energy and I think that calling it ""reinforcement learning"" is not only wrong, but also is very confusing, given this is usually reserved to an entirely different learning process.\n\n* While i liked the introduction of the quantum Boltzmann machine, I would be happy to learn what they can do? Are these useful, for instance, to study correlated fermions/bosons? The paper does not explain why one should be concerns with these devices.\n\n* The fact that the simulation on a classical computer agrees with the one on a quantum computer is promising, but I would say that this shows that, so far, there is not yet a clear advantage in using a quantum computer. This might change, but in the mean time, what is the benefits for the ICLR community?\n', ""There is no scientific consensus on whether quantum annealers such as the D-Wave 2000Q that use the transverse-field Ising models yield any gains over classical methods (c.f. https://arxiv.org/abs/1703.00622). However, it is an exciting research area and this paper is an interesting demonstration of the feasibility of using quantum annealers for reinforcement learning. \n\nThis paper builds on Crawford et al. (2016), an unpublished preprint, who develop a quantum Boltzmann machine reinforcement learning algorithm (QBM-RL). A QBM consists of adding a transverse field term to the RBM Hamiltonian (negative log likelihood), but the benefits of this for unsupervised tasks are unclear (c.f. https://arxiv.org/abs/1601.02036, another unpublished preprint). QBM-RL consists of using a QBM to model the state-action variables: it is an undirected graphical model whose visible nodes are clamped to observed state-action pairs. The hidden nodes model dependencies between states and actions, and the weights of the model are updated to maximize the free energy or Q function (value of the state-action pair).\n\nThe authors extend QBM-RL to work with quantum annealers such as the D-Wave 2000Q, which has a specific bipartite graph structure and requires special consideration because it can only yield samples of hidden variables in a fixed basis. To overcome this, the authors develop a Suzuki-Trotter expansion and call it 'replica stacking', where a classical Hamiltonian in one dimension higher is used to approximate the quantum Hamiltonian. This enables the use of quantum annealers. The authors compare their method to standard baselines in a grid world environment.\n\nOverall, I do not want to criticize the work. It is an interesting proof of concept. But given the high price of quantum annealers, limited applicability of the technique, and unclear benefits of the authors' method, I do not think it is relevant to this specific conference. It may be better suited to a workshop specific to quantum machine learning methods. \n=======================================\n+ please add an algorithm box for your method. It deviates significantly from QBM-RL. For example, something like: (1) init weights of boltzmann machine randomly (2) sample c_eff ~ C from the pool of configurations sampled from the transverse-field Ising model using a quantum annealer with chimera graph (3) using the samples, calculate effective classical hamiltonian used to approximate the quantum system (4) use the weight update rules derived from Bellman equations (spell out the rules). \n\n+ moving the details of sampling into the appendix would help; they are not important for understanding the main ingredients of your method\n\nThere are so many moving parts in your system, and someone without a physics background will struggle to understand it. Clarifying the algorithm in terms familiar to machine learning researchers will go a long way toward helping people understand your method. \n\n+ the benefits of your method is unclear - it looks like the method works, but doesn't outperform the others. this is fine, but it is better to be straightforward about this and bill it as a 'proof of concept' \n\n+ perhaps consider rebranding the paper as something like 'RL using replica stacking for sampling from quantum boltzmann machines with quantum annealers'. Elucidating why replica stacking is a crucial contribution of your work would be helpful, and could be of broad interest in the machine learning community. Right now it is too dense to be useful for the average person without a physics background: what difficulties are intrinsic to a quantum Hamiltonian? What is the intuition behind the Suzuki-Trotter decomposition you develop? What is the 'quantum' Boltzmann machine in machine learning terms (hidden-hidden connections in an undirected graphical model!)? What is replica-stacking in graphical model terms (this would be a great ML contribution in its own right!)? Really spelling these things out in detail (or in the appendix) would help\n==========================================\n1) eq 14 is malformed\n\n2) references are not well-formatted\n\n3) need factor of 1/2 to avoid double counting in sums over nearest neighbors (please be precise)"", ""Summary: The paper demonstrates the use of a quantum annealing machine to solve a free-energy based reinforcement learning problem. Experimental results are demonstrated on a toy gridworld task, where if I understand correctly it does better than a DQN and a method based on RBM-free-energy approximation (Sallans and Hinton, 2004)\n\nClarity: The paper is very hard to read. It seems to be targeted towards a physics/quantum hardware crowd rather than a machine learning audience. I think most readers, even those very familiar with probabilistic models and RL, would find reading the paper difficult due to jargon/terminology and poorly explained concepts. The paper would need a major rewrite to be of interest to the ML community.\n\nRelevance: RL, probabilistic models, and function approximators are all relevant topics. However, the focus of the paper seems to be on parts (like hardware aspects) that are not particularly relevant to the ML community. I have a hard time imagining follow-up work on this, given that the experiments are run on a toy task and require specialized hardware (so they would be extremely difficult to reproduce/improve upon).\n\nSoundness: I can't judge the technical soundness as it is mostly outside my expertise. I wonder if the main algorithm the work is based on (Crawford et al, 2016) has been peer-reviewed (citation appears to be a preprint, and couldn't find a conference/journal version).\n\nSignificance: It's good to know that the the quantum annealing machine can be used for RL. However, the method of choice (free-energy based Q-function approximation) seems a bit exotic, and the experimental results are extremely underwhelming (5x3 gridworld).""]","[20, -20, -50]","[60, 60, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper as 'interesting, certainly correct, and provides a nice perspective.' They also mention liking certain aspects of the paper. However, they express doubts about its relevance to the conference and point out some areas for improvement, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'I would be happy to learn' and 'I like,' which contribute to a polite tone. The reviewer also leaves some decisions to the Area Chair, showing respect for the process. While not overly effusive, the language is consistently professional and courteous."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'interesting' and a 'proof of concept', they ultimately do not recommend it for the conference and suggest it may be better suited for a workshop. They also point out several areas needing improvement. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, acknowledges the value of the work, and frames criticisms constructively as suggestions for improvement. They even explicitly state 'I do not want to criticize the work.' However, the review is not overly effusive in praise, maintaining a professional tone. The combination of polite phrasing with substantive critique results in a balanced, constructive review."", ""The sentiment score is -50 because the review is generally negative, highlighting significant issues with clarity, relevance, and significance of the paper. The reviewer states that the paper is 'very hard to read', 'poorly explained', and has 'extremely underwhelming' experimental results. However, it's not entirely negative as the reviewer acknowledges some positive aspects, such as the relevance of certain topics and the novelty of using a quantum annealing machine for RL. The politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively polite tone. They use phrases like 'if I understand correctly' and 'I wonder if', which show consideration. The reviewer also provides constructive feedback and explains their concerns, rather than being dismissive. However, the language is not overly polite or deferential, maintaining a neutral to slightly positive politeness level.""]"
"['The authors propose a method for graph classification by combining graph kernels and CNNs. In a first step patches are extracted via community detection algorithms.  These are then transformed into vector representation using graph kernels and fed to a neural network. Multiple graph kernels may serve as different channels. The approach is evaluated on synthetic and real-world graphs.\n\nThe article is well-written and easily comprehensible, but suffers from several weak points:\n\n* Features are not learned directly from the graphs, but the approach merely weights graph kernel features.\n* The weights refer to the RKHS and filters are not easily interpretable.\n* The approach is similar in spirit to Niepert, Ahmed, Kutzkov, ICML 2016 and thus incremental.\n* The experiments are not convincing: The improvement over the existing work is small on real-world data sets. The synthetic classification task essentially is to distinguish a clique from star graph and not very meaningful. Moreover, a comparison to at least one of the recent approaches similar to ""Convolutional Networks on Graphs for Learning Molecular Fingerprints"" (Duvenaud et al., NIPS 2015) or ""Message Passing Neural Networks"" (Gilmer et al., 2017)  would be desirable.\n\nTherefore, I cannot recommend the paper for acceptance.', 'This paper proposes a graph classification method by integrating three techniques, community detection, graph kernels, and CNNs.\n\n* This paper is clearly written and easy to follow. Thus the clarity is high.\n\n* The originality is not high as the application of neural networks for graph classification has already been studied elsewhere and the proposed method is a direct combination of three existing methods, community detection, graph kernels, and CNNs.\n\n* The quality and the significance of this paper it not high due to the following reasons:\n- The motivation is misleading in two folds.\n  First, the authors say that the graph kernel + SVM approach has a drawback due to two independent processes of graph representation and learning.\n  However, the parameters included in respective graph kernel is usually optimized via the SVM classification, hence they are not independent with each other.\n  Second, the authors say that the proposed method addresses the above issue of independence between graph representation and learning.\n  However, it also uses the two-step procedure as it first obtain the kernel matrix K via graph kernels and then apply CNN for classification, which is fundamentally the same as the existing approach.\n  Although community detection is used before graph kernels, such subgraph extraction process is already implicitly employed in various graph kernels.\n  I recommend to revise and clarify this point.\n- In experimental evaluation, why several kernels including SP, RW, and WL are not used in the latter five datasets?\n  This missing experiment significantly deteriorate the quality of empirical evaluation and I strongly recommend to add results for such kernels.\n- It is mentioned that the parameter h is fixed to 5 in the WL kernel. However, it is known that the performance of the WL kernel depends on the parameter and it should be tuned by cross-validation.\n  In contrast, parameters (number of epochs and the learning rate) are tuned in the proposed method. Thus the current comparison is not fair.\n- In addition to the above point, how are parameters for GR and RW?\n- Runtime is shown in Table 4 but there is no comparison with other methods. Although it is mentioned in the main text that the proposed method is faster than Graph CNN and Depp Graph Kernels, there is no concrete values and this statement is questionable (Runtime will easily vary due to the hardware configuration).\n\n* Additional comment:\n- Why is the community detection step needed? What will happen if K is directly constructed from given N graphs and what is the advantage of using not the original graphs but extracted subgraphs?\n- In the first step of finding characteristic subgraphs, frequent subgraph mining can be used instead community detection.\n  Frequent subgraph mining is extensively used in various methods for classification of graph-structured data, for example:\n  * Tsuda, K., Entire regularization paths for graph data, ICML 2007.\n  * Thoma, M. et al., Discriminative frequent subgraph mining with optimality guarantees, Statistical Analysis and Data Mining, 2010\n  * Takigawa, I., Mamitsuka, H., Generalized Sparse Learning of Linear Models Over the Complete Subgraph Feature Set, IEEE Transactions on Pattern Analysis and Machine Intelligence, 2017\n  What is the advantage of using the community detection compared to frequent subgraph mining or other subgraph enumeration methods?\n', ""The paper presents a method of using convolution neural networks for classifying arbitrary graphs. The authors proposed the following methodology\n1) Extract subgraph communities from the graphs, known as patches\n2) For each patch generate a graph kernel representation and subsampled them using nystrom method, producing the normalized patches\n3) Passes the set of normalized patches as input to the CNN \n\nThe paper is well written, proposes an interesting and original idea, provides experiments with real graph datasets from two domains, bioinformatics and social sciences, and a comparison with SoA algorithms both graph kernels and other deep learning architectures. Although the proposed algorithm seems to outperform on 7 out of 10 datasets, the performances are really close to the best SoA algorithm. Is there any statistical significance over the gain in the performances? It's not   really clear from the reported numbers. Moreover, the method makes an strong assumption that the graph is strongly characterized by one of its patches, ie its subgraph communities, which might not be the case in arbitrary graph structures, thus limiting their method. I am not really convince about the preprocessing step of patch extraction. Have the authors  tried to test what is the performance of graph kernel representation in the complete graph as input to the CNN, instead of a set of patches? Moreover, although the authors claim that typical graph kernel methods are two-stage approached decoupling representation from learning, their proposal also folds into that respect, as representation is achieved in the preprocessing step of patching extractions and normalization, while learning is achieved by the CNN. Finally, it is not also clear to me the what are the communities reported in Table 2 for the  bioinformatics datasets. Where they come from and what do they represent? ""]","[-70, -50, 50]","[20, 50, 70]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer points out several weaknesses of the paper and concludes by not recommending it for acceptance. However, it's not entirely negative as the reviewer acknowledges that the article is well-written and comprehensible. The politeness score is 20 because the language used is professional and respectful. The reviewer provides constructive criticism without using harsh or rude language. They acknowledge positive aspects before listing the weaknesses, which is a polite approach. However, the score is not higher because the review is direct in its criticism and doesn't use overly polite language or softening phrases."", ""The sentiment score is -50 because while the reviewer acknowledges that the paper is clearly written, they express significant concerns about the originality, quality, and significance of the work. They point out several issues with the methodology, experimental evaluation, and motivations, which suggests an overall negative sentiment. However, it's not entirely negative as they do provide constructive feedback and suggestions for improvement. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I recommend' and 'I strongly recommend' rather than making demands. They also acknowledge positive aspects ('clearly written') before diving into criticisms. The language is direct but not rude, striking a balance between critique and courtesy typical of academic peer reviews."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper is well-written, proposes an interesting and original idea, and provides experiments with real datasets. However, they also express some doubts and questions about the method's effectiveness and limitations. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, poses questions rather than making harsh criticisms, and acknowledges the paper's strengths before discussing potential weaknesses. They use phrases like 'It's not really clear' and 'I am not really convinced' instead of more confrontational language. The reviewer also offers constructive suggestions for improvement, which is a polite way to provide feedback.""]"
"[""This paper presents a very thorough empirical exploration of the qualities and limitations of very simple word-embedding based models. Average and/or max pooling over word embeddings (which are initialized from pretrained embeddings) is used to obtain a fixed-length representation for natural language sequences, which is then fed through a single layer MLP classifier. In many of the 9 evaluation tasks, this approach is found to match or outperform single-layer CNNs or RNNs.\n\nThe varied findings are very clearly presented and helpfully summarized, and for each task setting the authors perform an insightful analysis.\n\nMy only criticism would be the fact that the study is limited to English, even though the conclusions are explicitly scoped in light of this. Moreover, I wonder how well the findings would hold in a setting with a more severe OOV problem than is perhaps present in the studied datasets.\n\nBesides concluding from the presented results that these SWEMs should be considered a strong baseline in future work, one might also conclude that we need more challenging datasets!\n\nMinor things:\n- It wasn't entirely clear how the text matching tasks are encoded. Are the two sequences combined into a single sequence before applying the model, or something else? I might have missed this detail.\n\n- Given the two ways of using the Glove embeddings for initialization (direct update vs mapping them with an MLP into the task space), it would be helpful to know which one ended up being used (i.e. optimal) in each setting.\n\n- Something went wrong with the font size for the remainder of the text near Figure 1.\n\n** Update **\nThanks for addressing my questions in the author response.\n\nAfter following the other discussion thread about the novelty claims, I believe I didn't weigh that aspect strongly enough in my original rating, so I'm revising it. I remain of the opinion that this paper offers a useful systematic comparison that goes sufficiently beyond the focus of the two related papers mentioned in that thread (fasttext and Parikh's).\n"", 'This paper extensively compares simple word embedding based models (SWEMs) to RNN/CNN based-models on a suite of NLP tasks. \nExperiments on document classification, sentence classification, and natural language sequence matching show that SWEMs perform competitively or even better in the majority of cases.\nThe authors also propose to use max pooling to complement average pooling for combining information from word embeddings in a SWEM model to improve interpretability.\n\nWhile there is not much contribution in terms of technical novelty, I think this is an interesting paper that sheds new lights on limitations of existing methods for learning sentence and document representations. \nThe paper is well written and the experiments are quite convincing.\n- An interesting finding is that word embeddings are better for longer documents, whereas RNN/CNN models are better for shorter text. Do the authors have any sense on whether this is because of the difficulty in training an RNN/CNN model for long documents or whether compositions are not necessary since there are multiple predictive independent cues in a long text?\n- It would be useful to include a linear classification model that takes the word embeddings as an input in the comparison (SWEM-learned).\n- How crucial is it to retrain the word embeddings on the task of interest (from GloVe initialization) to obtain good performance?', 'This paper empirically investigates the differences realized by using compositional functions over word embeddings as compared to directly operating the word embeddings. That is, the authors seek to explore the advantages afforded by RNN/CNN based models that induce intermediate semantic representations of texts, as opposed to simpler (parameter-free) approaches to composing these, like addition. \n\nIn sum, I think this is exploration is interesting, and suggests that we should perhaps experiment more regularly with simple aggregation methods like SWEM. On the other hand, the differences across the models is relatively modest, and the data resists clear conclusions, so I\'m not sure that the work will be very impactful. In my view, then, this work does constitute a contribution, albeit a modest one. I do think the general notion of attempting to simplify models until performance begins to degrade is a fruitful path to explore, as models continue to increase in complexity despite compelling evidence that this is always needed.\n\nStrengths\n---\n+ This paper does highlight a gap in existing work, as far as I am aware: namely, I am not sure that there are generally known trade-offs associated with different compositional models over token embeddings for NLP. However, it is not clear that we should expect there to be a consistent result to this question across all NLP tasks.\n\n+ The results are marginally surprising, insofar as I would have expected the CNN/RNN (particularly the former) to dominate the simpler aggregation approaches, and this does not seem borne out by the data. Although this trend is seemingly reversed on the short text data, muddying the story. \n\nWeaknesses\n---\n- There are a number of important limitations here, many of which the authors themselves note, which mitigate the implications of the reported results. First, this is a small set of tasks, and results may not hold more generally. It would have been nice to see some work on Seq2Seq tasks, or sequence tagging tasks at least. \n\n- I was surprised to see no mention of the ""Fixed-Size Ordinally-Forgetting Encoding Method"" (FOFE) proposed by Zhang et al. in 2015, which would seem to be a natural point of comparison here, given that it sits in a sweet spot of being simple and efficient while still expressive enough to preserve word-order information. This actually seems like a pretty glaring omission given that it meets many of the desiderata the authors put forward. \n\n- The interpretability angle discussed seems underdeveloped. I\'m not sure that being able to identify individual words (as the authors have listed) meaningfully constitutes ""interpretability"" -- standard CNNs, e.g., lend themselves to this as well by tracing back through the filter activations. \n\n- Some of the questions addressed seem tangential to the main question of the paper -- e.g., word vector dimensionality seems an orthogonal issue to the composition function, and would influence performance for the more complex architectures as well.\n\nSmaller comments\n---\n- On page 1, the authors write ""By representing each word as a fixed-length vector, these embeddings can group semantically similar words, while explicitly encoding rich linguistic regularities and patterns"", but actually I would say that these *implicitly* encode such regularities, rather than explicitly. \n\n- ""architecture in Kim 2014; Collobert et al. 2011; Gan et al. 2017"" -- citation formatting a bit weird here.\n\n\n*** Update based on author response *** \n\nI have read the authors response and thank them for the additional details. \n\nRegarding the limited set of problems: of course any given work can only explore so many tasks, but for this to have general implications in NLP I would maintain that a standard (structured) sequence tagging task/dataset should have been considered. This is not about the number of datasets, but rather than diversity of the output spaces therein.\n\nI appreciated the additional details regarding FOFE, which as the authors themselves note in their response is essentially a generalization of SWEM. \n\nOverall, the response has not changed my opinion on this paper: I think this (exploring simple representations and baselines) is an important direction in NLP, but feel that the paper would greatly benefit from additional work.\n\n']","[70, 80, -20]","[80, 70, 60]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, praising its thoroughness, clear presentation, and insightful analysis. The reviewer does offer some criticisms and suggestions, but these are minor and constructive. The politeness score is 80 (quite polite) due to the reviewer's respectful tone throughout, use of phrases like 'very clearly presented' and 'helpfully summarized', and the constructive nature of the feedback. The reviewer also acknowledges the authors' response to their questions, showing respect for the dialogue. The language is professional and courteous throughout, without any harsh or rude comments."", ""The sentiment score is 80 (positive) because the reviewer expresses that the paper is 'interesting' and 'sheds new lights on limitations of existing methods'. They also state that the paper is 'well written' and the experiments are 'quite convincing'. While there is a minor criticism about lack of technical novelty, the overall tone is very positive. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms gently (e.g., 'While there is not much contribution in terms of technical novelty...'). The reviewer also asks questions in a polite manner, showing engagement with the work. The language is professional and courteous without being overly formal or effusive."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the work interesting and a contribution, they describe it as 'modest' and express doubts about its impact. They note several weaknesses and limitations that mitigate the results. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'I think' and 'In my view' to soften opinions, and thank the authors for their response. However, they don't use overtly polite language or praise, keeping the tone professional rather than highly courteous.""]"
"['--------------------\nReview updates:\nRating 6 -> 7\nConfidence 2 -> 4\n\nThe rebuttal and update addressed a number of my concerns, cleared up confusing sections, and moved the paper materially closer to being publication-worthy, thus I’ve increased my score.\n--------------------\n\nI want to love this paper. The results seem like they may be very important. However, a few parts were poorly explained, which led to this reviewer being unable to follow some of the jumps from experimental results to their conclusions. I would like to be able to give this paper the higher score it may deserve, but some parts first need to be further explained.\n\nUnfortunately, the largest single confusion I had is on the first, most basic set of gradient results of section 4.1. Without understanding this first result, it’s difficult to decide to what extent the rest of the paper’s results are to be believed.\n\nFig 1 shows “the histograms of the average sign of partial derivatives of the loss with respect to activations, as collected over training for a random neuron in five different layers.” Let’s consider the top-left subplot of Fig 1, showing a heavily bimodal distribution (modes near -1 and +1.). Is this plot made using data from a single neuron or from  multiple neurons? For now let’s assume it is for a single neuron, as the caption and text in 4.1 seem to suggest. If it is for a single neuron, then that neuron will have, for a single input example, a single scalar activation value and a single scalar gradient value. The sign of the gradient will either be +1 or -1. If we compute the sign for each input example and then AGGREGATE over all training examples seen by this neuron over the course of training (or a subset for computational reasons), this will give us a list of signs. Let’s collect these signs into a long list: [+1, +1, +1, -1, +1, +1, …]. Now what do we do with this list? As far as I can tell, we can either average it (giving, say, .85 if the list has far more +1 values than -1 values) OR we can show a histogram of the list, which would just be two bars at -1 and +1. But we can’t do both, indicating that some assumption above was incorrect. Which assumption in reading the text was incorrect?\n\nFurther in this direction, Section 4.1 claims “Zero partial derivatives are ignored to make the signal more clear.” Are these zero partial derivatives of the post-relu or pre-relu? The text (Sec 3) points to activations as being post-relu, but in this case zero-gradients should be a very small set (only occuring if all neurons on the next layer had either zero pre-relu gradients, which is common for individual neurons but, I would think, not for all at once). Or does this mean the pre-relu gradient is zero, e.g. the common case where the gradient is zeroed because the pre-activation was negative and the relu at that point has zero slope? In this case we would be excluding a large set (about half!) of the gradient values, and it didn’t seem from the context in the paper that this would be desirable.\n\nIt would be great if the above could be addressed. Below are some less important comments.\n\nSec 5.1: great results!\n\nFig 3: This figure studies “the first and last layers of each network”. Is the last layer really the last linear layer, the one followed by a softmax? In this case there is no relu and the 0 pre-activation is not meaningful (softmax is shift invariant). Or is the layer shown (e.g. “stage3layer2”) the penultimate layer? Minor: in this figure, it would be great if the plots could be labeled with which networks/datasets they are from.\n\nSec 5.2 states “neuron partitions the inputs in two distinct but overlapping categories of quasi equal size.” This experiment only shows that this is true in aggregate, not for specific neurons? I.e. the partition percent for each neuron could be sampled from U(45, 55) or from U(10, 90) and this experiment would not tell us which, correct? Perhaps this statement could be qualified.\n\nTable 1: “52th percentile vs actual 53 percentile shown”. \n\n> Table 1: The more fuzzy, the higher the percentile rank of the threshold\n\nThis is true for the CIFAR net but the opposite is true for ResNet, right?\n', ""The paper proposes to study the behavior of activations during training and testing to shed more light onto the inner workings of neural networks. This is an important area and findings in this paper are interesting!\n\nHowever, I believe the results are preliminary and the paper lacks an adequate explanation/hypothesis for the observed phenomenon either via a theoretical work or empirical experiments.\n- Could we look at the two distributions of inputs that each neuron tries to separate? \n- Could we perform more extensive empirical study to substantiate the phenomenon here? Under which conditions do neurons behave like binary classifiers? (How are network width/depth, activation functions affect the results).\n\nAlso, a binarization experiment (and finding) similar to the one in this paper has been done here:\n[1] Argawal et al. Analyzing the Performance of Multilayer Neural Networks for Object Recognition. 2014\n\n+ Clarity: The paper is easy to read. A few minor presentation issues:\n- ReLu --> ReLU\n\n+ Originality: \nThe paper is incremental work upon previous research (Tishby et al. 2017; Argawal et al 2014).\n\n+ Significance:\nWhile the results are interesting, the contribution is not significant as the paper misses an important explanation for the phenomenon. I'm not sure what key insights can be taken away from this.\n\n\n"", 'This paper presents an experimental study on the behavior of the units of neural networks. In particular, authors aim to show that units behave as binary classifiers during training and testing. \n\nI found the paper unnecessarily longer than the suggested 8 pages. The focus of the paper is confusing: while the introduction discusses about works on CNN model interpretability, the rest of the paper is focused on showing that each unit behaves consistently as a binary classifier, without analyzing anything in relation to interpretability.  I think some formal formulation and specific examples on the relevance of the partial derivative of the loss with respect to the activation of a unit will help to understand better the main idea of the paper. Also, quantitative figures would be useful to get the big picture. For example in Figures 1 and 2 the authors show the behavior of some specific units as examples, but it would be nice to see a graph showing quantitatively the behavior of all the units at each layer. It would be also useful to see a comparison of different CNNs and see how the observation holds more or less depending on the performance of the network.\n']","[20, -20, -30]","[60, 60, 20]","[""The sentiment score is slightly positive (20) because the reviewer expresses a desire to 'love this paper' and acknowledges that the results 'seem like they may be very important'. They also mention that the rebuttal addressed many concerns and improved the paper. However, the score is not higher due to the significant confusions and issues the reviewer still has with parts of the paper. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, expresses a desire to give a higher score, and frames criticisms as requests for clarification rather than direct attacks. Phrases like 'I want to love this paper' and 'It would be great if the above could be addressed' demonstrate a constructive and polite tone. The reviewer also acknowledges improvements made in the rebuttal, showing fairness and respect for the authors' efforts."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the research area and finds the results interesting, they express significant concerns about the preliminary nature of the results, lack of adequate explanation, and the need for more extensive empirical study. The reviewer also questions the significance of the contribution. However, the tone is not entirely negative, as they do highlight some positive aspects. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, offers constructive criticism, and balances negative feedback with positive comments. They use phrases like 'I believe' and 'Could we' to soften their criticisms, and they acknowledge the paper's strengths in clarity and readability. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism."", ""The sentiment score is -30 because the reviewer expresses several criticisms and concerns about the paper, such as it being unnecessarily long, having a confusing focus, and lacking quantitative figures. However, the reviewer also acknowledges some positive aspects, like the experimental study and the aim to show units behave as binary classifiers, which prevents the score from being more negative. The politeness score is 20 because the reviewer uses generally polite language, offering constructive criticism and suggestions for improvement rather than harsh criticism. Phrases like 'I found,' 'I think,' and 'it would be nice to see' indicate a respectful tone. However, the score is not higher as the review doesn't include explicitly polite language or praise, maintaining a mostly neutral, professional tone.""]"
"['Summary: This paper tackles the issue of combining TD learning methods with function approximation. The proposed algorithm constrains the gradient update to deal with the fact that canonical TD with function approximation ignores the impact of changing the weights on the target of the TD learning rule. Results with linear and non-linear function approximation highlight the attributes of the method.\n\nQuality: The quality of the writing, notation, motivation, and results analysis is low. I will give a few examples to highlight the point. The paper motivates that TD is divergent with function approximation, and then goes on to discuss MSPBE methods that have strong convergence results, without addressing why a new approach is needed. There are many missing references: ETD, HTD, mirror-prox methods, retrace, ABQ. Q-sigma. This is a very active area of research and the paper needs to justify their approach. The paper has straightforward technical errors and naive statements: e.g. the equation for the loss of TD takes the norm of a scalar. The paper claims that it is not well-known that TD with function approximation ignores part of the gradient of the MSVE. There are many others.\n\nThe experiments have serious issues. Exp1 seems to indicate that the new method does not converge to the correct solution. The grid world experiment is not conclusive as important details like the number of episodes and how parameters were chosen was not discussed. Again exp3 provides little information about the experimental setup.\n\nClarity: The clarity of the text is fine, though errors make things difficult sometimes. For example The Bhatnagar 2009 reference should be Maei.\n \nOriginality: As mentioned above this is a very active research area, and the paper makes little effort to explain why the multitude of existing algorithms are not suitable. \n\nSignificance: Because of all the things outlined above, the significance is below the bar for this round. ', 'This paper proposes adding a constraint to the temporal difference update to minimize the effect of the update on the next state’s value. The constraint is added by projecting the original gradient to the orthogonal of the maximal direction of change of the next state’s value. It is shown empirically that the constrained update does not diverge on Baird’s counter example and improves performance in a grid world domain and cart pole over DQN.\n\nThis paper is reasonably readable. The derivation for the constraint is easy to understand and seems to be an interesting line of inquiry that might show potential.\n\nThe key issue is that the justification for the constrained gradients is lacking. What is the effect, in terms of convergence, in modifying the gradient in this way? It seems highly problematic to simply remove a whole part of the gradient, to reduce effect on the next state. For example, if we are minimizing the changes our update will make to the value of the next state, what would happen if the next state is equivalent to the current state (or equivalent in our feature space)? In general, when we project our update to be orthogonal to the maximal change of the next states value, how do we know it is a valid direction in which to update? \n\nI would have liked some analysis of the convergence results for TD learning with this constraint, or some better intuition in how this effects learning. At the very least a mention of how the convergence proof would follow other common proofs in RL. This is particularly important, since GTD provides convergent TD updates under nonlinear function approximation; the role for a heuristic constrained TD algorithm given convergent alternatives is not clear. \n \nFor the experiments, other baselines should be included, particularly just regular Q-learning. The primary motivation comes from the use of a separate target network in DQN, which seems to be needed in Atari (though I am not aware of any clear result that demonstrates why, rather just from informal discussions). Since you are not running experiments on Atari here, it is invalid to simply assume that such a second network is needed. A baseline of regular Q-learning should be included for these simpler domains. \n\nThe results in Baird’s counter example are discouraging for the new constraints. Because we already have algorithms which better solve this domain, why is your method advantageous? The point of showing your algorithm not solve Baird’s counter example is unclear.\n\nThere are also quite a few correctness errors in the paper, and the polish of the plots and language needs work, as outlined below. \n\nThere are several mistakes in the notation and background section. \n1. “If we consider TD-learning using function approximation, the loss that is minimized is the squared TD error.“ This is not true; rather, TD minimizes the mean-squared project Bellman error. Further, L_TD is strangely defined: why a squared norm, for a scalar value? \n2. The definition of v and delta_TD w.r.t. to v seems unnecessary, since you only use Q. As an additional (somewhat unimportant) point, the TD-error is usually defined as the negative of what you have. \n3. In the function approximation case the value function and q functions parameterized by \\theta are only approximations of the expected return.\n4. Defining the loss w.r.t. the state, and taking the derivative of the state w.r.t. to theta is a bit odd. Likely what you meant is the q function, at state s_t? Also, are ignoring the gradient of the value at the next step? If so, this further means that this is not a true gradient.  \n\nThere is a lot of white space around the plots, which could be used for larger more clear figures. The lack of labels on the plots makes them hard to understand at a glance, and the overlapping lines make finding certain algorithm’s performance much more difficult. I would recommend combining the plots into one figure with a drawing program so you have more control over the size and position of the plots.\n\nExamples of odd language choices:\n\t-\t“The idea also does not immediately scale to nonlinear function approximation. Bhatnagar et al. (2009) propose a solution by projecting the error on the tangent plane to the function at the point at which it is evaluated. “ - The paper you give exactly solves for the nonlinear function approximation case. What do you mean does not scale to nonlinear function approximation? Also Maei is the first author on this paper.\n\t-\t“Though they do not point out this insight as we have” - This seems to be a bit overreaching.\n- “the gradient at s_{t+1} that will change the value the most”  - This is too colloquial. I think you simply mean the gradient of the value function, for the given s_t, but its not clear. ', ""This is an interesting idea, and written clearly. The experiments with Baird's and CartPole were both convincing as preliminary evidence that this could be effective. However, it is very hard to generalize from these toy problems. First, we really need a more thorough analysis of what this does to the learning dynamics itself. Baring theoretical results, you could analyze the changes to the value function at the current and next state with and without the constraint to illustrate the effects more directly. I think ideally, I would want to see this on Atari or some of the continuous control domains often used. If this allows the removing of the target network for instance, in those more difficult tasks, then this would be a huge deal.\n\nAdditionally, I do not think the current gridworld task adds anything to the experiments, I would rather actually see this on a more interesting linear function approximation on some other simple task like Mountain Car than a neural network on gridworld. The reason this might be interesting is that when the parameter space is lower dimensional (not an issue for neural nets, but could be problematic for linear FA) the constraint might be too much leading to significantly poorer performance. I suspect this is the actual cause for it not converging to zero for Baird's, although please correct me if I'm wrong on that.\n\nAs is, I cannot recommend acceptance given the current experiments and lack of theoretical results. But I do think this is a very interesting direction and hope to see more thorough experiments or analysis to support it.\n\nPros:\nSimple, interesting idea\nWorks well on toy problems, and able to prevent divergence in Baird's counter-example\n\nCons:\nLacking in theoretical analysis or significant experimental results\n""]","[-70, -30, -20]","[-20, 20, 60]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer points out numerous issues with the paper, including low quality of writing, missing references, technical errors, and problematic experiments. The reviewer states that the significance is 'below the bar for this round,' indicating a strong negative sentiment. However, it's not the lowest possible score as the reviewer does acknowledge that the paper tackles an important issue and that the clarity of the text is 'fine.' The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite critical and direct. Phrases like 'The quality... is low,' 'straightforward technical errors,' and 'naive statements' are quite blunt and could be perceived as impolite. The reviewer doesn't soften criticisms or use many polite phrases, but also doesn't resort to personal attacks or extremely harsh language, hence a slightly negative but not extremely low score."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('reasonably readable', 'interesting line of inquiry'), they express significant concerns about the paper's justification, analysis, and experimental design. The reviewer points out several issues and suggests major improvements, indicating an overall negative sentiment.\n\nThe politeness score is 20 because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I would have liked' and 'I would recommend' instead of more direct criticisms. The reviewer also acknowledges positive aspects before diving into critiques. However, some phrases like 'highly problematic' and 'discouraging' prevent a higher politeness score.\n\nThe scores are not at extremes because the review balances critique with constructive feedback and maintains a professional tone while expressing concerns."", 'The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea as interesting and the preliminary evidence as convincing, they ultimately cannot recommend acceptance due to lack of thorough experiments and theoretical results. The reviewer expresses hope for future improvements but the overall sentiment leans towards rejection in its current state. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the strengths of the work, and offering constructive criticism and suggestions for improvement. The reviewer maintains a professional tone, avoiding harsh language, and frames their concerns as opportunities for enhancement rather than outright criticisms.']"
"['Properly capturing named entities for goal oriented dialog is essential, for instance location, time and cuisine for restaurant reservation. Mots successful approaches have argued for separate mechanism for NE captures, that rely on various hacks and tricks. This paper attempt to propose a comprehensive approach offers intriguing new ideas, but is too preliminary, both in the descriptions and experiments. \n\nThe proposed methods and experiments are not understandable in the current way the paper is written: there is not a single equation, pseudo-code algorithm or pointer to real code to enable the reader to get a detailed understanding of the process. All we have a besides text is a small figure (figure 1). Then we have to trust the authors that on their modified dataset, the accuracies of the proposed method is around 100% while not using this method yields 0% accuracies?\n\nThe initial description (section 2)  leaves way too many unanswered questions:\n- What embeddings are used for words detected as NE? Is it the same as the generated representation?\n- What is the exact mechanism of generating a representation for NE EECS545? (end of page 2)\n- Is it correct that the same representation stored in the NE table is used twice? (a) To retrieve the key (a vector) given the value (a string)  as the encoder input. (b) To find the value that best matches a key at the decoder stage?\n- Exact description of the column attention mechanism: some similarity between a key embedding and embeddings representing each column? Multiplicative? Additive?\n- How is the system supervised? Do we need to give the name of the column the Attention-Column-Query attention should focus on? Because of this unknown, I could not understand the experiment setup and data formatting!\n\nThe list goes on...\n\nFor such a complex architecture, the authors must try to analyze separate modules as much as possible. As neither the QA and the Babi tasks use the RNN dialog manager, while not start with something that only works at the sentence level\n\nThe Q&A task could be used to describe a simpler system with only a decoder accessing the DB table. Complexity for solving the Babi tasks could be added later.\n', 'The paper proposes to generate embedding of named-entities on the fly during dialogue sessions. If the text is from the user, a named entity recognizer is used. If it is from the bot response, then it is known which words are named entities therefore embedding can be constructed directly. The idea has some novelty and the results on several tasks attempting to prove its effectiveness against systems that handle named entities in a static way.\n\nOne thing I hope the author could provide more clarification is the use of NER. For example, the experimental result on structured QA task (section 3.1), where it states that the performance different between models of With-NE-Table and W/O-NE-Table is positioned on the OOV NEs not present in the training subset. To my understanding, because of the presence of the NER in the With-NE-Table model, you could directly do update to the NE embeddings and query from the DB using a combination of embedding and the NE words (as the paper does), whereas the W/O-NE-Table model cannot because of lack of the NER. This seems to prove that an NER is useful for tasks where DB queries are needed, rather than that the dynamic NE-Table construction is useful. You could use an NER for W/O-NE-Table and update the NE embeddings, and it should be as good as With-NE-Table model (and fairer to compare with too).\n\nThat said, overall the paper is a nice contribution to dialogue and QA system research by pointing out a simple way of handling named entities by dynamically updating their embeddings. It would be better if the paper could point out the importance of NER for user utterances, and the fact that using the knowledge of which words are NEs in dialogue models could help in tasks where DB queries are necessary.', 'The paper addresses the task of dealing with named entities in goal oriented dialog systems. Named entities, and rare words in general, are indeed troublesome since adding them to the dictionary is expensive, replacing them with coarse labels (ne_loc, unk) looses information, and so on. The proposed solution is to extend neural dialog models by introducing a named entity table, instantiated on the fly, where the keys are distributed representations of the dialog context and the values are the named entities themselves. The approach is applied to settings involving interacting to a database and a mechanism for handling the interaction is proposed. The resulting model is illustrated on a few goal-oriented dialog tasks.\n\n\nI found the paper difficult to read. The concrete mappings used to create the NE keys and attention keys are missing. Providing more structure to the text would also be useful vs. long, wordy paragraphs. Here are some specific questions:\n\n1. How are the keys generated? That are the functions used? Does the ""knowledge of the current user utterance"" include the word itself? The authors should include the exact model specification, including for the HRED model.\n\n2. According to the description, referring to an existing named entity must be done by ""generating a key to match the keys in the NE table and then retrieve the corresponding value and use it"". Is there a guarantee that a same named entity, appearing later in the dialog, will be given the same key?  Or are the keys for already found entities retrieved directly, by value?\n\n3. In the decoding phase, how does the system decide whether to query the DB?\n\n4. How is the model trained?\n\nIn its current form, it\'s not clear how the proposed approach tackles the shortcomings mentioned in the introduction. Furthermore, while the highlighted contribution is the named entity table, it is always used in conjunction to the database approach. This raises the question whether the named entity table can only work in this context.\n\nFor the structured QA task, there are 400 training examples, and 100 named entities. This means that the number of training examples per named entity is very small. Is that correct? If yes, then it\'s not very surprising that adding the named entities to the vocabulary leads to overfitting. Have you compared with using random embeddings for the named entities?\n\nTypos: page 2, second-to-last paragraph: firs -> first, page 7, second to last paragraph: and and -> and\n\n']","[-50, 50, -50]","[0, 75, 20]","[""The sentiment score is -50 because the review expresses significant concerns about the paper's clarity and completeness, stating it is 'too preliminary' and lacks crucial details. However, it acknowledges some 'intriguing new ideas', preventing a more negative score. The politeness score is 0 (neutral) as the reviewer maintains a professional tone without being overly polite or rude. They directly state issues and ask questions without using harsh language, but also don't use particularly courteous phrasing. The review focuses on technical concerns and suggestions for improvement in a straightforward manner."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novelty and contribution to dialogue and QA system research, calling it a 'nice contribution'. However, they also express some concerns and suggest improvements, which prevents the score from being higher. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames their suggestions as hopes for clarification rather than demands. They also end on a positive note, highlighting the paper's strengths. The reviewer maintains a professional and courteous tone while providing detailed feedback."", ""The sentiment score is -50 because while the reviewer acknowledges the importance of the topic, they express significant concerns about the paper's readability and lack of clarity on key points. The review lists several critical questions and issues, indicating that the paper needs substantial improvements. However, it's not entirely negative as the reviewer recognizes the relevance of the research topic.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout, avoiding harsh language or personal criticisms. They use phrases like 'I found the paper difficult to read' instead of more confrontational statements. The reviewer also provides constructive feedback and specific questions to help improve the paper. However, the score is not higher because the review is quite direct in its criticisms and doesn't include many softening phrases or positive reinforcements.""]"
"['*Summary*\nThe paper studies recovery guarantees within the context of auto-encoders. Assuming a noise-corrupted linear model for the inputs x\'s, the paper looks at some sufficient properties (e.g., over the generating dictionary denoted by W) to recover the true underlying sparse signals (denoted by h). Several settings of increasing complexity are considered (from binary signals with no noise to noisy continuous signals). Evaluations are carried out on synthetic examples to highlight the theoretical findings.\n\nThe paper is overall difficult to read. Moreover, and importantly, no algorithmic perspectives are presented in the paper, in the sense that we do not know whether practical procedures would lead to W\'s satisfying the appropriate properties (unlike (not-mentioned) recent results for dictionary learning/ICA; see detailed comments). Also, assumptions are made (e.g., knowledge about expectations of h and x) for which it is unclear to see how practical/limiting they are. Finally (and as further discussed below), the paper does not sufficiently discuss related work.\n\n(note: I have not reviewed the appendix and supplementary material)\n\n*Detailed comments*\n\n-I think there is an insufficient literature review about recent recovery results in the context of sparse coding, dictionary learning and ICA (see some references at the bottom of the review). I think this is all the more important as the paper tries to draw connections with ICA (see Sec. 4.4).\nGiven that the paper positions itself on a theoretical level, detailed comparisons with existing sample complexities obtained in previous work for related models (e.g., sparse coding, dictionary learning and ICA) must be provided.\n\n-To the best of my understanding of the paper, the guarantees are about h_hat and the true h. It therefore seems that the paper\'s approach is very close to standard sparse inverse problems, up to the difference due to the (non-identity) activation function. If this is indeed the case, the paper should discuss its results when the activation is identity to see whether known results are recovered. \n\n-""...we consider linear activation s_d because it is a more general case."": Just after this statement, it is mentioned that non-linear activations are used in practice. Could this statement be therefore clarified?\n\n-Sec. 2 is unclear. For instance, it is not easy to see how one go from (1) to (2). Moreover, the concept of ""AE framework"" is not well defined.\n\n-In the bottom of page 3, why are p_i and (1-p_i) discarded?\n\n-In practice, how can we set the appropriate value of b_i?\n\n-What is the practical sense of being able to have access to E_h[x], E_x[x], and E_h[h]?\n\n-In Proposition 1 and 2, if the noise e is indeed random, it means the right-hand sides are also random variables. Then, what does the probability statement Pr mean on the left-hand side? Is is conditioned on the draw of e? Some clarifications are required.\n\n-Typo page 7: ""...that used to generate the data."" --> ""... used to generate the data.""\n-Typo page 9: ""...data are then generate..."" --> ""...data are then generated...""\n\n-In Sec. 5.3, to match W_hat and W, the Hungarian algorithm can probably be used.\n\n*References*\n\n(Arora2012) Arora, S.; Ge, R.; Moitra, A. & Sachdeva, S. Provable ICA with unknown Gaussian noise, with implications for Gaussian mixtures and autoencoders Advances in Neural Information Processing Systems (NIPS), 2012, 2375-2383\n\n(Arora2013) Arora, S.; Ge, R. & Moitra, A. New algorithms for learning incoherent and overcomplete dictionaries preprint arXiv:1308.6273, 2013\n\n(Chatterji2017) Chatterji, N. S. & Bartlett, P. L. Alternating minimization for dictionary learning with random initialization preprint arXiv:1711.03634, 2017\n\n(Gribonval2015) Gribonval, R.; Jenatton, R. & Bach, F. Sparse and spurious: dictionary learning with noise and outliers IEEE Transactions on Information Theory, 2015, 61, 6298-6319\n\n(Sun2015) Sun, J.; Qu, Q. & Wright, J. Complete dictionary recovery over the sphere Sampling Theory and Applications (SampTA), 2015 International Conference on, 2015, 407-410\n', 'This papers proposes to analyze auto-encoders under sparsity constraints of an underlying signal to be recovered.\nBased on concentration inequality, the reconstruction provided for a simple class of functions is guaranteed to be accurate in l1 norm with high probability.\nThe proof techniques are classical, but the results seem novel as far as I know.\nAs an open question, could the results be given for other lp norms, in particular for infinity-norm? Indeed, this is a privileged norm for support recovery.\n\n\n\nPresentation issues:\n- section should be Section when stating for instance ""section 1"". Idem for eq, equation, assumption...\n- bold fonts for vectors are randomly used: some care should be given to harmonizing symbols fonts.\n- equations should be cited with brackets\n\nReferences issues:\n- harmonize citations: if you add first name for some authors add it for all references: why writing Roland Makhzani and J. Wright?\n\n- Candes -> Cand\\`es\n\n- Consider citing ""Sparse approximate solutions to linear systems"", Natarajan 1995 when mentioning Amaldi and Kann 1998.\n\n\n\nSpecific comments:\npage 1:\n- hasn\'t -> has not.\n\npage 2:\n- ""activation function"": at this stage s_e and s_d are just functions. What is the ""activation"" refers to? Also a clarification on the space they act on should be stated. Idem for b_e and b_d.\n- ""the identity of h in eq. 1 is only well defined in the presence of l1 regularization due to the over-completeness of the dictionary"" : this is implicitly stating the uniqueness of the Lasso. Not that it is well known that there are cases where the Lasso is non-unique. Please, clarify your statement accordingly.\n- for simplicity b_d could be removed here.\n- in (4) it would be more natural to write f_j(h_j) instead of f(h_j)\n- ""has is that to be bounded""-> is boundedness?\n- what is l_max_j here? moreover the bold letters seem to represent vectors but this should be state explicitly somewhere.\n\npage 3:\n- what is the precise meaning of ""distributed"" when referring to representation\n- In remark 1: the font has changed weirdly for W and h.\n- ""two class""->two classes\n- Definition 1: again what is a precise definition of activation function?\n- ""if we set"": bold issue.\n- b should b_e in Theorem 1, right? Also, please recall the definition of the sigmoid function here. Moreover l_max and mu_h seem useless in this theorem... why referring to them?\n- ""if the rows of the weight matrix is""-> if the rows of the weight matrix are\n\npage 4:\n- Proposition 1 could be stated as a theorem and Th.1 as a corollary (with e=0). The same is true for proposition 2 I suspect.\n- Again the influence of l_max and mu_h are none here...\n- Please, provide the definition of the ReLu function here. Is this just x->x_+ ?\n\npage 6:\n- R^+m -> font issue again.\n- ""are maximally incoherent"": what is the precise meaning of this statement?\n- what the motivation for Theorem 3? This should be discussed.\n- De-noising -> de-noising\n- the discussion after (15) should be made more precise.\n\npage 7:\n- Figure 1 and 2 should be postponed to page 8.\n- in Eq. (16) one needs to known E_h(x) and E_h_i(h_i), but I suspect this quantity are usually unknown to the practitioner. Can the author comment on that?\n\npage 8:\n- ""the recovery is denoised through thresholding"": where is this step analyzed?\n\npage 9:\n- figure 3: sparseness-> sparsity; also what is the activation function used here?\n- ""are then generate""->are then generated\n- ""by greedily select""->by greedily selecting\n- ""the the""\n- ""and thus pre-process""-> and thus pre-processing\n\n\nSupplementary:\npage 1:\n- please define \\sigma, and its simple properties used along the proof.\n\npage 2:\n- g should be g_j (in eq 27 - > 31)\n- overall this proof relies on ingredients such as the one used for Hoeffding\'s inequality.\nMost ingredients could be taken from standard tools on concentration (see for instance Boucheron, Lugosi, Massart: ""Concentration Inequalities: A Nonasymptotic Theory of Independence"", 2013).\nMoreover, some elements should be factorized as they are shared among the next proofs. This should reduce the size of the supplementary dramatically.\n\npage 7:\n- Eq. (99): it should be reminded that W_ii=1 here.\n- the upper bound used on \\mu to get equation 105 seems to be in the wrong order.', 'This paper considers the following model of a signal x = W^T h + b, where h is an m-dimensional random sparse vector, W is an m by n matrix, b is an n dimensional fixed bias vector. The random vector h follows an iid sparse signal model, each coordinate independently have some probability of being zero, and the remaining probability is distributed  among nonzero values according to some reasonable pdf/pmf. The task is to recover h, from the observation x via the activation functions like Sigmoid or ReLU. For example, \\hat{h} = Sigmoid(W^T h + b).\n\nThe authors then show that, under the random sparsity model of h, it is possible to upper bound the probability P(||h-\\hat{h}|| > \\delta. m) in terms of the parameters of the distribution of h and W and b. In some cases noise can also be tolerated. In particular, if W is incoherent (columns being near-orthonormal), then the guarantee is stronger. As far as I understood, the proofs make sense - they basically use Chernoff-bound type argument. \n\nIt is my impression that a lot of conditions have to be satisfied for the recovery guarantee to be meaningful. I am unsure if real datasets will satisfied so many conditions. Also, the usual objective of autoencoders is to denoise  - i.e. recover x, without any access to W. The authors approach in this vein seem to be only empirical. Some recent works on associative memory also assume the sparse recovery model - connections to this literature would have been of interest. It is also not clear why compressed sensing-type recovery using a single ReLU or Sigmoid would be of interest: are their complexity benefits?']","[-50, 20, -20]","[20, 50, 50]","[""The sentiment score is -50 because the review expresses several significant concerns about the paper, including difficulty in reading, lack of algorithmic perspectives, unclear assumptions, and insufficient literature review. However, it's not entirely negative as it acknowledges the paper's study of recovery guarantees and evaluations on synthetic examples. The politeness score is 20 because the reviewer uses generally neutral language and offers constructive criticism. They provide specific recommendations for improvement and even point out typos, which is helpful. The tone is professional and not personally critical, though it doesn't go out of its way to be overtly polite either."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty of the results and the classical proof techniques used. They also pose an open question, showing engagement with the work. However, the bulk of the review consists of detailed critiques and suggestions for improvement, which tempers the positive sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'please clarify' and 'can the author comment on that?' instead of more direct criticisms. They also frame many comments as suggestions rather than demands. The review is thorough and critical but not harsh or dismissive, striking a balance between politeness and academic rigor."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's technical merits and the soundness of the proofs, they express several concerns and uncertainties about the practical applicability and relevance of the work. The reviewer mentions that 'a lot of conditions have to be satisfied for the recovery guarantee to be meaningful' and questions whether real datasets would meet these conditions. They also point out that the paper's approach to denoising seems to be only empirical and that connections to related literature are missing. These critiques suggest a somewhat skeptical view of the paper's overall contribution and impact.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns, such as 'It is my impression that...' and 'I am unsure if...', rather than making harsh or dismissive statements. The reviewer also acknowledges the technical correctness of the work, stating 'As far as I understood, the proofs make sense'. This balanced approach, combining constructive criticism with recognition of the paper's strengths, contributes to the overall polite tone of the review.""]"
"['This paper presents a model to encode and decode trees in distributed representations. \nThis is not the first attempt of doing these encoders and decoders. However, there is not a comparative evalution with these methods.\nIn fact, it has been demonstrated that it is possible to encode and decode trees in distributed structures without learning parameters, see ""Decoding Distributed Tree Structures"" and ""Distributed tree kernels"".\nThe paper should present a comparison with such kinds of models.\n', 'This paper proposes a tree-to-tree model aiming to encode an input tree into embedding and then decode that back to a tree. The contributions of the work are very limited.  Basic attention models, which have been shown to help model structures, are not included (or compared). Method-wise, the encoder is not novel and decoder is rather straightforward. The contributions of the work are in general very limited. Moreover, this manuscript contains many grammatical errors.  In general, it is not ready for publication. \n\nPros:\n- Investigating the ability of distributed representation in encoding input structured is in general interesting. Although there have been much previous work, this paper is along this line.\n\nCons:\n- The contributions of the work are very limited. For example, attention, which have been widely used and been shown to help capture structures in many tasks, are not included and compared in this paper.\n- Evaluation is not very convincing. The baseline performance in MT is too low. It is unclear if the proposed model is still helpful when other components are considered (e.g., attention). \n- For the objective function defined in the paper, it may be hard to balance the ""structure loss"" and ""content loss"" in different problems, and moreover, the loss function may not be even useful in real tasks (e.g, in MT), which often have their own objectives (as discussed in this paper). Earlier work on tree kernels (in terms of defining tree distances) may be related to this work. \n- The manuscript is full of grammatical errors, and the following are some of them:\n""encoder only only need to""\n""For for tree reconstruction task""\n""The Socher et al. (2011b) propose a basic form""\n""experiments and theroy analysis are done""\n', 'Summary: the paper proposes a tree2tree architecture for NLP tasks. Both the encoder and decoder of this architecture make use of memory cells: the encoder looks like a tree-lstm to encode a tree bottom-up, the decoder generates a tree top-down by predicting the number of children first. The objective function is a linear mixture of the cost of generating the tree structure and the target sentence. The proposed architecture outperforms recursive autoencoder on a self-to-self predicting trees, and outperforms an lstm seq2seq on En-Cn translation.\n\nComment:\n\n- The idea of tree2tree has been around recently but it is difficult to make it work. I thus appreciate the authors’ effort. However, I wish the authors would have done it more properly.\n- The computation of the encoder and decoder is not novel. I was wondering how the encoder differs from tree-lstm. The decoder predicts the number of children first, but the authors don’t explain why they do that, nor compare this to existing tree generators. \n- I don’t understand the objective function (eq 4 and 5). Both Ls are not cross-entropy because label and childnum are not probabilities. I also don’t see why using Adam is more convenient than using SGD.\n- I think eq 9 is incorrect, because the decoder is not Markovian. To see this we can look at recurrent neural networks for language modeling: generating the current word is conditioning on the whole history (not only the previous word).\n- I expect the authors would explain more about how difficult the tasks are (eg. some statistics about the datasets), how to choose values for lambda, what the contribution of the new objective is.\n\nAbout writing:\n- the paper has so many problems with wording, e.g. articles, plurality.\n- many terms are incorrect, e.g. “dependent parsing tree” (should be “dependency tree”), “consistency parsing” (should be “constituency parsing”)\n- In 3.1, Socher et al. do not use lstm\n- I suggest the authors to do some more literature review on tree generation\n']","[-20, -80, -40]","[0, -20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution, they point out significant limitations and suggest major improvements. The reviewer notes that this is not the first attempt at encoding and decoding trees in distributed representations and criticizes the lack of comparative evaluation with existing methods. They also mention that similar results have been achieved without learning parameters, implying that the paper's approach may not be novel or superior. The politeness score is neutral (0) as the language used is neither particularly polite nor rude. The reviewer states their points directly and professionally, without using overly harsh language or personal attacks, but also without any notably courteous phrases or softening of criticism."", ""The sentiment score is -80 because the review is predominantly negative. The reviewer states that the paper's contributions are 'very limited,' the evaluation is 'not very convincing,' and the manuscript is 'full of grammatical errors.' The only positive aspect mentioned is that the topic is 'in general interesting,' but this is outweighed by the numerous criticisms. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite blunt and dismissive. Phrases like 'not ready for publication' and the direct listing of cons without much softening language contribute to a somewhat impolite tone. However, the reviewer does attempt to provide some constructive feedback and acknowledges a positive aspect, which prevents the score from being lower."", ""The sentiment score is -40 because while the reviewer appreciates the authors' effort, they express several significant concerns about the paper's methodology, explanations, and writing quality. The reviewer points out multiple issues, including lack of novelty, unclear explanations, potential errors in equations, and writing problems. However, the score is not extremely negative as the reviewer does acknowledge the difficulty of the task and the authors' efforts. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I appreciate the authors' effort' and 'I suggest', which are polite. However, the criticism is direct and doesn't use many softening phrases, keeping the score only slightly positive rather than highly polite.""]"
"['The paper presents convergence rate of a quantized SGD, with biased quantization - simply taking a sign of each element of gradient.\n\nThe stated Theorem 1 is incorrect. Even if the stated result was correct, it presents much worse rate for a weaker notion of convergence.\n\nMajor flaws:\n1. As far as I can see, Theorem 1 should depend on 4th root of N_K, the last (omitted) step from the proof is done incorrectly. This makes it much worse than presented.\n2. Even if this was correct, the main point is that this is ""only"" d times worse - see eq (11). That is enormous difference, particularly in settings where such gradient compression can be relevant. Also, it is lot more worse than just d times:\n3. Again in eq (11), you compare different notions of convergence - E[||g||_1]^2 vs. E[||g||_2^2]. In particular, the one for signSGD is the weaker notion - squared L1 norm can be d times bigger again. If this is not the case for some reason, more detailed explanation is needed.\n\nOther than that, the paper contains several attempts at intuitive explanation, which I don\'t find correct. Inclusion of Assumption 3 would in particular require better justification.\n\nExperiments are also inconclusive, as the plots show convergence to significantly worse accuracy than what the models converged to in original contributions.', 'UPDATED REVIEW:\n\nI have checked all the reviews, also checked the most recent version.\nI like the new experiments, but I am not impressed much with them to increase my score. The assumption about the variance is fixing my concern, but as you have pointed out, it is a bit more tricky :) I would really suggest you work on the paper a bit more and re-submit it.\n\n--------------------------------------------------------------------\nIn this paper, authors provided a convergence analysis of Sign SGD algorithm for non-covex case.\nThe crucial assumption for the proof was Assumption 3, otherwise, the proof technique is following a standard path in non-convex optimization.   \n\nIn general, the paper is written nicely, easy to follow.\n\n==============================================\n""The major issue"":\nWhy Assumption 3 can be problematic in practice is given below:\nLet us assume just a convex case and assume we have just 2 kids of function in 2D:  f_1(x) = 0.5 x_1^2 and f_2(x) = 0.5 x_2^2.\nThen define the function f(x) = E [ f_i(x)  ].   where $i =1$  with prob 0.5 and $i=2$ with probability 0.5. \nWe have that   g(x) = 0.5 [ x_1, x_2 ]^T.\nLet us choose $i=1$ and choose $x = [a,a]^T$, where $a$ is some parameter.\n\nThen (4) says, that there has to exist a $\\sigma$ such that\nP [   | \\bar g_i(x) - g_i(x) | > t ] \\leq 2 exp( - t^2 / 2\\sigma^2).  forall ""x"".\n\nplugging our function inside it should be true that\n\nP [   | [ B ] - 0.5 a | > t ] \\leq 2 exp( - t^2 / 2\\sigma^2).  forall ""x"".\nwhere B is a random variable which has value ""a"" with probability 0.5 and value ""0"" with probability 0.5.\n\nIf we choose $t = 0.1a$ then we have that it has to be true that\n\n1 = P [   | [ B ] - 0.5 a | > 0.1a ] \\leq 2 exp( - 0.01 a^2 / 2\\sigma^2)   ---->  0 as $a \\to \\infty$.\n\nHence, even in this simple example, one can show that this assumption is violated unless $\\sigma = \\infty$.\n\nOne way to ho improve this is to put more assumption + maybe put some projection into a compact set?\n==============================================\n\nHence, I think the theory should be improved.\n\nIn terms of experiments, I like the discussion about escaping saddle points, it is indeed a good discussion. However, it would be nicer to have more numerical experiments.\nOne thing I am also struggling is the ""advantage"" of using signSGD: one saves on communication (instead of sending 4*8 bits per dimension, one just send only 1 bit, however, one needs ""d""times more iterations, hence, the theory shows that it is much worse then SGD (see (11) ).\n\n\n\n\n', 'Dear Authors,\nAfter reading the revised version I still believe that the assumption about the gradients + their variances to be distributed equivalently among all direction is very non-realistic, also for the case of deep learning applications.\n\nI think that the direction you are taking is very interesting, yet the theoretical work is still too preliminary and I believe that further investigation should be made in order to make a more complete manuscript.\n\nThe additional experiments are nice.  I therefore raised my score by a bit.\n\n\n$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n The paper explores SignGD --- an algorithm that uses the sign of the gradients instead of actual gradients for training deep models. The authors provide some guarantees regarding the convergence of SignGD to local minima in the stochastic optimization setting, and later compare SignSG to GD in two deep learning tasks.\n\nExploring signSGD is an important and interesting line of research, and this paper provides some preliminary result in this direction.\nHowever, in my view, this work is too preliminary and not ready for publish. This is since the authors do not illustrate any clear benefits of signSGD over SGD neither in theory nor in practice. I elaborate on this below:\n\n-The theory part shows that under some conditions, signGD  finds a local minima. Yet, as the authors themselves \nmention, the dependence on the dimension is much worse compared to SGD.\nMoreover, the authors do not mention that if the noise variance does not scale with the dimension (as is often the case), then the convergence of SGD will not depend on the dimension, while it seems that the convergence of signGD will still depend on the dimension.\n\n-The experiments are nice as a preliminary investigation, but not enough in order to illustrate the benefits of signSGD over SGD. In order to do so, the authors should make a more extensive experimental study.\n\n']","[-80, -30, -30]","[-20, 20, 50]","[""The sentiment score is -80 because the review is highly critical, pointing out major flaws in the paper's main theorem and methodology. The reviewer states that 'Theorem 1 is incorrect' and highlights several significant issues with the paper's approach and results. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite blunt and critical without much attempt to soften the criticism. Phrases like 'Major flaws:' and 'Even if this was correct...' contribute to a somewhat harsh tone. The reviewer also dismisses the authors' explanations as incorrect without offering much constructive feedback. However, the language isn't overtly impolite, which prevents the score from being lower."", ""The sentiment score is -30 because the reviewer expresses some dissatisfaction with the paper, suggesting it needs more work and resubmission. They state 'I am not impressed much' and point out a 'major issue' with one of the assumptions. However, they also mention some positive aspects like the new experiments and the paper being well-written, which prevents the score from being more negative. The politeness score is 20 because the reviewer uses generally polite language, such as 'I would really suggest' and 'In general, the paper is written nicely'. They also use a smiley face ':)' which adds a friendly tone. However, the criticism is direct and not overly softened, keeping the score from being higher. The reviewer maintains a professional tone throughout, balancing critique with constructive feedback."", ""The sentiment score is -30 because the reviewer expresses several concerns about the paper, stating it's 'too preliminary' and 'not ready for publish'. However, they do acknowledge some positive aspects like 'interesting line of research' and 'nice' additional experiments, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses respectful language throughout, addressing the authors directly and using phrases like 'I believe' and 'in my view' to soften criticisms. They also provide detailed explanations for their concerns, which is constructive. The tone is professional and not overtly negative, despite the criticisms.""]"
"['The authors propose a different type of GAN--the Dudley GAN--that is related to the Dudley metric. In fact, it is very much like the WGAN, but rather than just imposing the function class to have a bounded gradient, they also impose it to be bounded itself. This is argued to be more stable than the WGAN, as gradient clipping is said not necessary for the Dudley GAN. The authors empirically show that the Dudley GAN achieves a greater LL than WGAN for the MNIST and CIFAR-10 datasets.\n\nThe main idea [and its variants] looks solid, but with the plethora of GANs in the literature now, after reading I\'m still left wondering why this GAN is significantly better than others [BEGAN, WGAN, etc.]. It is clear that imposing the quadratic penalty in equation (3) is really the same constraint as the Dudley norm? The big contribution of the paper seems to be that adding some L_inf regularization to the function class helps preclude gradient clipping, but after reading I\'m unsure why this is ""the right thing"" to do in this case. We know that convergence in the Wasserstein metric is stronger than the Dudley metric, so why is using the weaker metric overweighed by the benefits in training?\n\nNits: Since the function class is parameterized by a NN, the IPM is not actually the Dudley metric between the two distributions. One would have to show that the NN is dense in Dudley unit ball w.r.t. L_inf norm, but this sort of misnaming had started with the ""Wasserstein"" GAN.', 'Ensuring Lipschitz condition in neural nets is essential of stablizing GANs. This paper proposes two contraint-based optimzation to ensure the Lips condtions , and these proposed approaches maintain suffcient capacity, as well as expressiveness of the network.  A simple theoritical result is given by emprical risk minimization. The content of this paper\nis written clearly, and there are certain contribution and orginality in the literature. However, I am not sure that the novelty is\nsignificant, since I think that the idea of proposing their optimization is trival. Here I am concerned with the following two questions:\n(1) How to parameterize the function space of f_w or h_w, since they are both multivariate and capacity of the network will be\nreduced if the used way of parametering functions is adopted inappropriatily.\n(2) The theoretical result in (4)  doesnot contain the information of Rademacher complexity, and it may be suboptimal in some sense. Besides, the parameter $\\gamma$ appears in the discriminator, which contradicts its role on the contraint of functions space.', 'It is clear that the problem studied in this paper is interesting. However, after reading through the manuscript, it is not clear to me what are the real contributions made in this paper. I also failed to find any rigorous results on generalization bounds. In this case, I cannot recommend the acceptance of this paper. ']","[20, -20, -50]","[60, 50, 20]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the solidity of the main idea and its variants, and notes some improvements over existing methods. However, they express reservations about the significance of the improvements and raise questions about the approach. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the authors' work while raising concerns in a constructive manner. They use phrases like 'The main idea looks solid' and frame their criticisms as questions or areas for clarification rather than direct attacks. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (clear writing, certain contributions, and originality), they express doubt about the significance of the novelty and raise concerns about two specific aspects of the work. The phrase 'I am not sure that the novelty is significant' and the subsequent questions indicate a somewhat critical stance. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting their concerns. They frame their criticisms as questions rather than direct criticisms, which is a polite approach. The reviewer maintains a professional tone without using overly formal or informal language."", ""The sentiment score is -50 because while the reviewer acknowledges the problem is interesting, they express significant concerns about the paper's contributions and lack of rigorous results, ultimately not recommending acceptance. This indicates a negative sentiment, but not extremely negative as they do recognize some merit. The politeness score is 20 because the reviewer uses relatively neutral language and avoids harsh criticism. They start with a positive note about the problem being interesting, and use phrases like 'it is not clear to me' and 'I failed to find' which soften the criticism. However, the overall tone is still professional rather than overtly polite, hence a slightly positive score.""]"
"['The authors propose to solve the inverse reinforcement learning problem of inferring the reward function from observations of a behaving agent, i.e. trajectories, albeit without observing state-action pairs as is common in IRL but only with the state sequences. This is an interesting problem setting. But, apparently, this is not the problem the authors actually solve, according to eq. 1-5. Particularly eq. 1 is rather peculiar. The main idea of RL in MDPs is that agents do not maximize immediate rewards but instead long term rewards. I am not sure how this greedy action should result in maximizing the total discounted reward along a trajectory. \nEquation 3 seems to be a cost function penalizing differences between predicted and observed states. As such, it implements a sort of policy imitation, but that is quite different from the notion of reward in RL and IRL. Similarly, equation 4 penalizes differences between predicted and observed state transitions. \nEssentially, the current manuscript does not learn the reward function of an MDP in the RL setting, but it learns some sort of a shaping reward function to do policy imitation, i.e. copy the behavior of the demonstrator as closely as possible. This is not learning the underlying reward function. So, in my view, the manuscript does a nice job at policy fitting, but this is not reward estimation. The manuscript has to be rewritten that way. \nOne could also argue that the manuscript would profit from a better theoretical analysis of the IRL problem, say:\nC. A. Rothkopf, C. Dimitrakakis. Preference elicitation and inverse reinforcement learning. ECML 2011\nOverall the manuscript leverages on deep learning’s power of function approximation and the simulation results are nice, but in terms of the soundness of the underlying RL and IRL theory there is some work to do.', 'This paper uses inverse reinforcement learning to infer additional shaping rewards from demonstrated expert trajectories.  The key distinction from many previous works in this area is that the expert’s actions are assumed to not be available, and the inferred reward on a transition is assumed to be a function of the previous and subsequent state.  The expert trajectories are first used to train either a generative model or an LSTM on next state prediction. The inferred reward for a newly experienced transition is then defined from the negative error between the predicted and actual next state.  The method is tested on several reacher tasks (low dimensional continuous control), as well as on two video games (Super Mario Bros and Flappy Bird).  The results are positive, though they are often below the performance of behavioral cloning (which only trains from the expert data but also uses the expert’s actions).  The proposed methods perform competitively with hand-designed dense shaping rewards for each task.\n\nThe main weakness of the proposed approach is that the addition of extra rewards from the expert trajectories seems to skew the system’s asymptotic behavior away from the objective provided by the actual environment reward.  One way to address this would be to use the expert trajectories to infer not only a reward function, but also an initial state value function (trained on the expert trajectories with the inferred reward).  This initial value function could be added to the learned value function and would not limit asymptotic performance (unlike the addition of inferred rewards as proposed here).  This connection between reward shaping and initial Q values was described by Wiewirora in 2003 (“Potential-based Shaping and Q-Value Initialization are Equivalent”).  \n\nI am also uncertain of the robustness of the proposed approach when the learning agent goes beyond the distribution of states provided by the expert (where the inferred reward model has support).  Will the inferred reward function in these situations go towards zero?  Will the inferred reward skew the learning algorithm to a worse policy?  How does one automatically balance the reward scale provided by the environment with the the reward scaling provided by psi, or is this also assumed to be manually crafted for each domain?  These questions make me uncertain of the utility of the proposed method.\n', 'To speed up RL algorithms, the authors propose a simple method based on utilizing expert demonstrations. The proposed method consists in explicitly learning a prediction function that maps each time-step into a state. This function is learned from expert demonstrations. The cost of visiting a state is then defined as the distance between that state and the predicted state according to the learned function. This reward is then used in standard RL algorithms to learn to stick close to the expert\'s demonstrations. An on-loop variante of this method consists of learning a function that maps each state into a next state according to the expert, instead of the off-loop function that maps time-steps into states.\nWhile the experiments clearly show the advantage of this method, this is hardly surprising or novel. The concept of encoding the demonstration explicitly in the form of a reward has been around for over a decade. This is the most basic form of teaching by demonstration. Previous works had used other models for generalizing demonstrations (GMMs, GPs, Kernel methods, neural nets etc..). This paper uses a three layered fully connected auto-encoder (which is not that deep of a model, btw) for the same purpose. The idea of using this model as a reward instead of directly cloning the demonstrations is pretty straightforward. \n\nOther comments:\n- Most IRL methods would work just fine by defining rewards on states only and ignoring actions all together. If you know the transition function, you can choose actions that lead to highly rewarding states, so you don\'t need to know the expert\'s executed actions.\n- ""We assume that maximizing likelihood of next step prediction in equation 1 will be globally optimized in RL"". Could you elaborate more on this assumption? Your model finds rewards based on local state features, where a greedy (one-step planning) policy would reproduce the expert\'s demonstrations (if the system is deterministic). It does not compare the global performance of the expert to alternative policies (as is typically done in IRL).\n- Related to the previous point: a reward function that makes every step of the expert optimal may not be always exist. The expert may choose to go to terrible states with the hope of getting to a highly rewarding state in the future. Therefore, the objective functions set in this paper may not be the right ones, unless your state description contains features related to future states so that you can incorporate future rewards in the current state (like in the reacher task, where a single image contains all the information about the problem). What you need is actually features that can capture the value function (like in DQN) and not just the immediate reward (as is done in IRL methods). \n- What if in two different trajectories, the expert chooses opposite actions for the same state appearing in both trajectories? For example, there are two shortest paths to a goal, one starts with going left and another starts with going right. If you try to generate a state that minimizes the sum of distances to the two states (left and right ones), then you may choose to remain in the middle, which is suboptimal. You wouldn\'t have this issue with regular IRL techniques, because you can explain both behaviors with future rewards instead of trying to explain every action of the expert using only local state description. ']","[-50, -20, -50]","[20, 50, 20]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the manuscript's approach and theoretical foundations. They point out that the authors are not actually solving the problem they claim to be addressing, and that the manuscript needs substantial rewriting. However, the score is not extremely negative as the reviewer acknowledges some positive aspects, such as the 'nice job at policy fitting' and 'nice' simulation results. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'interesting problem setting' and offering constructive suggestions for improvement. They avoid harsh language and frame their criticisms as observations rather than attacks. However, the score is not higher as the review is quite direct in its criticisms without much softening language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('The results are positive'), they also express significant concerns and uncertainties about the method's robustness and utility. The reviewer points out weaknesses and suggests alternative approaches, indicating a somewhat critical stance overall. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They present their criticisms constructively, using phrases like 'I am uncertain' and 'One way to address this would be...' rather than making blunt or harsh statements. The reviewer also acknowledges the paper's strengths before discussing its limitations, which is a polite approach to peer review."", ""The sentiment score is -50 because the reviewer expresses skepticism about the novelty and significance of the proposed method. They state that the concept has been around for over a decade and is 'hardly surprising or novel.' However, they do acknowledge that the experiments show an advantage to the method, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'Could you elaborate more on this assumption?' which shows respect. However, the overall critical nature of the review prevents a higher politeness score. The reviewer also provides constructive feedback and suggestions, which contributes to the slightly positive politeness score.""]"
"['Paper summary:\nAuthors extend [1] to form an auto-encoder CNN network for face mesh representation. Face mesh graph is represented by Fourier basis of graph Laplacian and therefore convolution operator is defined in Fourier space. Chebyshev polynomial is used for faster computations. Max pooling on graph is done by using Graclus multilevel clustering algorithm. Binary tree generated in pooling layers are kept for unpooling layers in decoder network. Authors captured a new facial dataset for their evaluation and reported better results than PCA.\n\nPositive points:\nAuthors tackle irregular data feature extraction and learning using CNNs which is a hot topic in deep learning.\n\nNegative points:\nAlthough proposed idea is interesting, paper has a number of critical problems. Firstly, experiments are the main weakness of the paper. Set of experiments does not prove claims of the paper. \n- It is not clear how authors uses PCA to reconstruct faces in the test set.\n- Authors do not compare to any state of the art on 3D face representation and reconstruction (e.g. [2]) using public datasets (e.g. BU-3DFE). \n- How network behaves by introducing noise on vertices?\n- What is the effect of network hyper-parameters?\n\nSecondly, paper has a lack of novelty. It is a simple extension of [1] without considering and solving problems in [1]. Also, it is not mentioned what is the loss function to train the network. I suppose it is L2 norm loss, but it must be clear in the paper.\n\n[1] M. Defferrard, X. Bresson, and P. Vandergheynst.  Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in Neural Information Processing Systems, pp. 3844–3852, 2016.\n[2] A. Brunton, T. Bolkart, and S. Wuhrer.  Multilinear wavelets: A statistical shape space for human faces. In European Conference on Computer Vision, pp. 297–312, 2014a.\n\nAfter rebuttal:\nThe current version of the paper still needs significant amount of work regarding the experimental part.', 'The paper is generally clear, and proposes to use a convolutional autoencoder based on 3D meshes. The novelty here how the problem is formulated.\n\nPros:\n- Interesting formulation. I have not seen this particular setup for processing meshes with neural networks in an autoencoder setting. \n- This work collected a new dataset for 3D face expression representation, which is great (the state of 3D face databases which are available to researchers is very limited, so this is a step in the right direction).\n\nCons:\n- The visual depiction of the auto-encoded meshes looks a bit strange. In particular, they exhibit some high frequency artefacts. These do not appear in the smoother PCA version. From a human standpoint, in those cases, the smoother meshes would in fact be preferable. I did not see a discussion about this, given that such problems are not captured by the metrics.\n- I am a bit confused by the requirement that all meshes need to have the same adjacency matrix. Does this mean that you need to convert the raw meshes coming from the 3D camera into a particular topology before you can use this algorithm? If yes, this seems like a rather large limitation.\n- Regarding the evaluation, you wrote:""In order to evaluate the interpolation capability of the autoencoder, we split the dataset in training and test samples in the ratio of 1:9. The test samples are obtained by picking consecutive frames of\nlength 10 uniformly at random across the sequences. "" - To me this is very unclear. You have very few sequeces/subjects. Did  you split by *subject*? I think this is CRUCIAL, and a lot of the results hinge on this answer.\n\nGeneral Questions\n\nI am  wondering how come you didn\'t consider a geometry image representation of the meshes, and went for a slightly more general, and yet very confined alternative (the adjacency requirement, which in some sense is the same type of constraint as geometry images). On geometry images, in particular it would be possible to apply standard convolutional architectures without any special processing.\n\nAnother question that I had is why use a L1 loss when in the evaluation you\'re using L2? It would make a lot of sense to use the same loss as the evaluation metric (not to mention the properties of PCA).', 'This paper introduces a convolutional autoencoder for irregular graphs, specifically surfaces in the form of discrete meshes in 3D. The underlying technique that is used to operate on the irregular graph is spectral decomposition, which enables convolutions in the spectral domain. \n\nThe spectral convolution methods have been applied to mesh data structures for about 5 years now, as stated in the paper as well [Bruna et al. 2013], [Defferrard et al. 2016], [Bronstein et al. 2017], [Li et al. 2017] ... The paper states that it builds upon the formulation in [Defferrard et al. 2016] as explained in section 3. \n\nGiven the facts above, I am having a hard time to understand the novelty of this paper? Is it the ""Mesh Upsampling"" operation defined at the end of page 4? If that is the case, it is not demonstrated in the paper that it actually works. The main reason is that the original face mesh graph that goes into the convolution/downsampling\n operations is topologically preserved through the upconvolutions. This means that the upsampling operation is not really upsampling a ""true"" graph/mesh. The topology is already known, the upsampling just predicts a function on this topology. \n\n The choice of the face domain is also suspicious, since all faces are topologically the same graph (even though there are geometric variations). Convolutions/downsampling-convolutions/upsampling that are demonstrated in the paper basically boil down to function prediction on the same exact global graph. Face topologies are so regular that they can even be represented with a height map like geometry encoding in the image plane (See [1\'] below). \n\n To demonstrate the ""mesh/graph generation"" capability truly, the authors need to experiment on novel topology generation. As is, the paper does not bear enough novelty on top of [Defferrard et al. 2016], or is not demonstrating it even if there exists any.\n\n[1\'] Z. Shu, E. Yumer, S. Hadap, K. Sunkavalli, E. Shechtman, D. Samaras. Neural Face Editing with Intrinsic Image Disentangling. CVPR 2017\n\nMINOR: \nFirst paragraph of Section 3: \n- The definition of a mesh (F=(V,E,A)) is not correct: Both E and A essentially define the same connectivity. Base your definition on F=(V,E) or F=(V,A). Since you are using A later in the section, probably the latter makes more sense for you.\n\n']","[-60, 20, -60]","[20, 60, 20]","[""The sentiment score is -60 because the review is predominantly negative. While it acknowledges some positive aspects ('Authors tackle irregular data feature extraction and learning using CNNs which is a hot topic in deep learning'), the majority of the review focuses on critical problems with the paper, including weak experiments, lack of novelty, and insufficient comparisons to state-of-the-art methods. The reviewer states that the paper 'has a number of critical problems' and 'needs significant amount of work', indicating a largely negative sentiment.\n\nThe politeness score is 20 because the reviewer maintains a professional and relatively neutral tone throughout. They present their criticisms in a factual manner without using harsh or insulting language. The reviewer acknowledges positive points before presenting negative ones, which is a polite approach. However, the score is not higher because the review is quite direct in its criticisms without much softening language, and doesn't offer much encouragement or positive reinforcement to the authors."", ""The sentiment score is slightly positive (20) because the reviewer starts by acknowledging the paper's clarity and novelty, and mentions some pros like the interesting formulation and new dataset collection. However, they also list several cons and raise questions, which balances out the positive aspects. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as observations or questions rather than direct attacks, and acknowledges positive aspects before discussing limitations. They use phrases like 'I am a bit confused' and 'I am wondering' which maintain a polite tone while raising concerns. The reviewer also provides constructive feedback and suggestions, which contributes to the polite tone."", 'The sentiment score is -60 because the reviewer expresses significant doubts about the novelty and effectiveness of the paper\'s contributions. They state they are \'having a hard time to understand the novelty\' and question if the main contribution actually works. The reviewer also suggests the paper may not have enough novelty over existing work. However, it\'s not entirely negative as they do acknowledge the paper\'s basis in established methods.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively polite tone. They phrase their criticisms as questions or observations rather than direct attacks. For example, \'I am having a hard time to understand\' and \'Is it the ""Mesh Upsampling"" operation?\' The reviewer also provides constructive feedback and suggestions for improvement. However, some phrases like \'suspicious\' and \'not correct\' slightly reduce the politeness score.']"
"['Although the problem addressed in the paper seems interesting, but there lacks of evidence to support some of the arguments that the authors make. And the paper does not contribute novelty to representation learning, therefore, it is not a good fit for the conference. Detailed critiques are as following:\n1. The idea proposed by the authors seems too quite simple. It is just performing random projections for 1000 times and choose the set of projection parameters that results in the highest compactness as the dimensionality reduction model parameter before one-class SVM.\n2. It says in the experiments part that the authors have used 3 different S_{attack} values, but they only present results for S_{attack} = 0.5. It would be nicer if they include results for all S_{attack} values that they have used in their experiments, which would also give the reader insights on how the anomaly detection performance degrades when the S_attack value change.\n3. The paper claims that the nonlinear random projection is a defence against adversary due to the randomness, but there is no results in the paper proving that other non-random projections are susceptible to adversary that is designed to target that projection mechanism and nonlinear random projection is able to get away with that. And PCA as a non-random projection would a nice baseline to compare against.\n4. The paper seems to misuse the term “False positive rate” as the y label of figure 3(d/e/f). The definition of false positive rate is FP/(FP+TN), so if the FPR=1 it means that all negative samples are labeled as positive. So it is surprising to see FPR=1 in Figure 3(d) when feature dimension=784 while the f1 score is still high in Figure 3(a). From what I understand, the paper means to present the percentage of adversarial examples that are misclassified instead of all the anomaly examples that get misclassified. The paper should come up with a better term for that evaluation.\n5. The conclusion, that robustness of the learned model increases wrt the integrity attacks increases when the projection dimension becomes lower, cannot be drawn from Figure 3(d). Need more experiment on more dimensionality to prove that. \n6. In the appendix B results part, sometimes the word ’S_attack’ is typed wrong. And the values in  “distorted/distorted” columns in Table 5 do not match up with the ones in Figure 3(c).', 'In this paper, the authors explore how using random projections can be used to make OCSVM robust to adversarially perturbed training data.  While the intuition is nice and interesting, the paper is not very clear in describing the attack and the experiments do not appropriately test whether this method actually provides robustness.\n\nDetails:\nhave been successfully in anomaly detection --> have been successfully used in anomaly detection\n\n""The adversary would select a random subset of anomalies, push them towards the normal data cloud and inject these perturbed points into the training set"" -- This seems backwards.  As in the example that follows, if the adversary wants to make anomalies seem normal at test time, it should move normal points outward from the normal point cloud (eg making a 9 look like a weird 7).\n\nAs s_attack increases, the anomaly data points are moved farther away from the normal data cloud, altering the position of the separating hyperplane.  -- This seems backwards from Fig 2.  From (a) to (b) the red points move closer to the center while in (c) they move further away (why?).  The blue points seem to consistently become more dense from (a) to (c).\n\nThe attack model is too rough.  It seems that without bounding D, we can make the model arbitrarily bad, no?  Assumption 1 alludes to this but doesn\'t specify what is ""small""?  Also the attack model is described without considering if the adversary knows the learner\'s algorithm.  Even if there is randomness, can the adversary take actions that account for that randomness?\n\nDoes selecting a projection based on compactness remove the randomness?\n\nExperiments -- why/how would you have distorted test data?  Making an anomaly seem normal by distorting it is easy.\n\nI don\'t see experiments comparing having random projections and not.  This seems to be the fundamental question -- do random projects help in the train_D | test_C case?\n\nExperiments don\'t vary the attack much to understand how robust the method is.', 'The authors propose a defense against attacks on the security of one-class SVM based anonaly detectors. The core idea is to perform a random projection of the data (which is supposed to decrease the impact from adversarial distortions). The approach is empirically tested on the following data: MNIST, CIFAR, and SVHN.\n\nThe paper is moderately well written and structured. Command of related work is ok, but some relevant refs are missing (e.g., Kloft and Laskov, JMLR 2012). The empirical results actually confirm that indeed the strategy of reducing the dimensionality using random projections reduces the impact from adversarial distortions. This is encouraging. What the paper really lacks in my opinion is a closer analysis of *why* the proposed approach works, i.e., a qualitative empirical analysis (toy experiment?) or theoretical justification. Right now, there is no theoretical justification for the approach, nor even a (in my opinion) convincing movitation/Intuition behind the approach. Also, the attack model should formally introduced.\n\nIn summary, I d like to encourage the authors to further investigate into their approach, but I am not convinced by the manuscript in the current form. It lacks both in sound theoretical justification and intuitive motivation of the approach. The experiments, however, show clearly advantages of the approach (again, here further experiments are necessary, e.g., varying the dose of adversarial points). ']","[-60, -60, -20]","[20, 20, 60]","[""The sentiment score is -60 because the review is generally negative, stating that the paper lacks evidence, doesn't contribute novelty, and is not a good fit for the conference. However, it's not entirely dismissive as it acknowledges the problem as interesting. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone and offer specific, constructive feedback. The language is not overtly polite but avoids rudeness, using phrases like 'it would be nicer if' and 'the paper should'. The reviewer provides detailed critiques and suggestions for improvement, which is helpful and respectful to the authors."", ""The sentiment score is -60 because the review is largely critical, pointing out several issues with the paper's clarity, methodology, and experiments. The reviewer states that while the intuition is 'nice and interesting', they find significant problems with how the attack is described and how the experiments are conducted. They also point out inconsistencies and areas that need clarification. However, it's not entirely negative, as they do acknowledge some positive aspects, hence not scoring at the extreme negative end. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'This seems backwards' and ask questions rather than making accusatory statements. The reviewer also offers specific suggestions for improvement, which is constructive. The language is not overly polite or deferential, but it avoids rudeness, striking a neutral to slightly polite tone typical of academic peer reviews."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('encouraging' results, 'clearly advantages'), they express significant reservations about the paper's current form. The reviewer states that the paper 'lacks both in sound theoretical justification and intuitive motivation' and is 'not convinced by the manuscript in the current form'. However, they do encourage further investigation, which prevents the score from being more negative. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and encourages the authors to continue their work. They use phrases like 'I'd like to encourage the authors' and provide specific suggestions for improvement, which is considerate and helpful. The tone is professional and not overly harsh, despite the criticisms.""]"
"['Interesting Problem, but Limited Novelty and Flawed Evaluation\n\n\nThe paper considers the problem of following natural language instructions given an first-person view of an a priori unknown environment. The paper proposes a neural architecture that employs an RNN to encode the language input and a CNN to encode the visual input. The two modalities are fused and fed to an RNN policy network. The method is evaluated on a new dataset consisting of short, simple instructions conveyed in simple environments.\n\nThe problem of following free-form navigation instructions is interesting and has achieved a fair bit of attention, previously with ""traditional"" structured approaches (rule-based and learned) and more recently with neural models. Unlike most existing work, this paper reasons over the raw visual input (vs., a pre-processed representation such as a bag-of-words model). HoA notable exception is the work of Chaplot et al. 2017, which addresses the same problem with a nearly identical architecture (see below). Overall, this paper constitutes a reasonable first-pass at this problem, but there is significant room for improvement to address issues related to the stated contributions and flawed evaluations.\n\nThe paper makes several claims regarding the novelty and expressiveness of the model and the contributions of the paper that are either invalid or not justified by the experimental results. As noted, a neural approach to instruction following is not new (see Mei et al. 2016) nor is a multimodal fusion architecture that incorporates raw images (see Chaplot et al.). The paper needs to make the contributions and novelty relative to existing methods clear (e.g., those stated in the intro are nearly identical to those of Mei et al. and Chaplot et al.). This includes discussion of the attention mechanism, for which the contributions and novelty are justified only by simple visualizations that are not very insightful. Related, the paper omits a large body of work in language understanding from the NLP and robotics domains, e.g., the work of Yoav Artzi, Thomas Howard, and Stefanie Tellex, among others (see below). While the approaches are different, it is important to describe this work in the context of these methods.\n\n\nThere are important shortcomings with the evaluation. First, one of the two scenarios involves testing on instructions from the training set. The test set should only include held-out environments and instructions, which the paper incorrectly refers to as the ""zero-shot"" scenario. This test set is very small, with only 19 instructions. Related, there is no mention of a validation set, and the discussion seems to suggest that hyperparameters were tuned on the test set. Further, the method is compared to incomplete implementations of existing baselines that admittedly don\'t attempt to replicate the baseline architectures. Consequently, it isn\'t clear what if anything can be concluded from the evaluation. There is a\n\n\n\nComments/Questions\n\n* The action space does not include an explicit stop action. Instead, a run is considered to be finished either when the agent reaches the destination or a timeout is exceeded. This is clearly not valid in practice. The model should determine when to stop, as with existing approaches.\n\n* The paper makes strong claims regarding the sophistication of the dataset that are unfounded. Despite the claims, the environment is rather small and the instructions almost trivially simple. For example, compare to the SAIL corpus that includes multi-sentence instructions with an average of 5 sentences/instruction (vs. 2); 37 words/instruction (vs. a manual cap of 9); and a total of 660 words (vs. 40); and three ""large"" virtual worlds (vs. 10x10 grids with 3-6 objects).\n\n* While the paper makes several claims regarding novelty, the contributions over existing approaches are unclear. For example, Chaplot et al. 2017 propose a similar architecture that also fuses a CNN-based representation of raw visual input with an RNN encoding of language, the result of which is fed to a RNN policy network. What is novel with the proposed approach and what are the advantages? The paper makes an incomplete attempt to evaluate the proposed model against Chaplot et al., but without implementing their complete architecture, little can be inferred from the comparison.\n\n* The paper claims that the fusion method realizes a *minimalistic* representation, but this statement is only justified by an experiment that involves the inclusion of the visual representation, but it isn\'t clear what we can conclude from this comparison (e.g., was there enough data to train this new representation?).\n\n* It isn\'t clear that much can be concluded from the attention visualizations in Figs. 6 and 7, particularly regarding its contribution. Regarding Fig 6. the network attends to the target object (large apple), but not the smaller apple, which would be necessary to reason over their relative size. Further, the attention figure in Fig. 7(b) seems to foveate on both bags. In both cases, the distractor objects are very close to the true target, and one would expect the behavior to be similar irrespective of which one was being attended to.\n\n* The conclusion states that the method is ""highly flexible"" and able to handle a ""rich set of natural language instructions"". Neither of these claims are justified by the discussion (please elaborate on what makes the method ""highly flexible"", presumably the end-to-end nature of the architecture) or the experimental results.\n\n* The significance of randomly moving non-target objects that the agent encounters is unclear. What happens when the objects are not moved, as in real scenarios?\n\n* A stated contribution is that the ""textual representations are semantically meaningful"" but the importance is not justified.\n\n* Figure captions should appear below the figure, not at top.\n\n* Figures and tables should appear as close to their first reference as possible (e.g., Table 1 is 6 pages away from its reference at the beginning of Section 7).\n\n\n* Many citations should be enclosed in parentheses.\n\n\n\nReferences:\n\n* Artzi and Zettlemoyer, Weakly Supervised Learning of Semantic Parsers for Mapping Instructions to Actions, TACL 2013\n\n* Howard, Tellex, and Roy, A Natural Language Planner Interface for Mobile Manipulators, ICRA 2014\n\n* Chung, Propp, Walter, and Howard, On the performance of hierarchical distributed correspondence graphs for efficient symbol grounding of robot instructions, IROS 2015\n\n* Paul, Arkin, Roy, and Howard, Efficient Grounding of Abstract Spatial Concepts for Natural Language Interaction with Robot Manipulators, RSS 2016\n\n* Tellex, Kollar, Dickerson, Walter, Banerjee, Teller and Roy, Understanding natural language commands for robotic navigation and mobile manipulation, AAAI 2011', ""Paper summary: The paper tackles the problem of navigation given an instruction. The paper proposes an approach to combine textual and visual information via an attention mechanism. The experiments have been performed on a 2D grid, where the agent has partial observation.\n\nPaper Strengths:\n- The proposed approach outperforms the baselines.\n- Generalization to unseen combination of objects and attributes is interesting.\n\nPaper Weaknesses:\nThis paper has the following issues so I vote for rejection: (1) The experiments have been performed on a toy environment, which is similar to the environments used in the 80's. There is no guarantee that the conclusions are valid for slightly more complex environments or real world. I highly recommend using environments such as AI2-THOR or SUNCG. (2) There is no quantitative result for the zero-shot experiments, which is one of the main claims of the paper. (3) The ideas of using instructions for navigation or using attention for combining visual and textual information have been around for a while. So there is not much novelty in the proposed method either. (4) References to attention papers that combine visual and textual modalities are missing.\n\nMore detailed comments:\n\n- Ego-centric is not a correct word for describing the input. Typically, the perspective changes in ego-centric views, which does not happen in this environment.\n\n- I do not agree that the attention maps focus on the right objects. Figures 6 and 7 show that the attention maps focus on all objects. The weights should be shown using a heatmap to see if the model is attending more to the right object.\n\n- I cannot find any table for the zero-shot experiments. In the rebuttal, please point me to the results in case I am missing them.\n\n\nPost Rebuttal:\nI will keep the initial rating. The environment is too simplistic to draw any conclusion from. The authors mention other environments are unstable, but that is not a good excuse. There are various environments that are used by many users. "", '**Paper Summary**\nThe paper studies the problem of navigating to a target object in a 2D grid environment by following given natural language description as well as receiving visual information as raw pixels. The proposed architecture consists of a convoutional neural network encoding visual input,  gated recurrent unit encoding natural language descriptions, an attention mechanism fusing multimodal input, and a policy learning network. To verify the effectiveness of the proposed framework, a new environment is proposed. The environment is 2-D grid based and it consists of an agent, a list of objects with different attributes, and a list of obstacles. Agents perceive the environment throught raw pixels with a limited visible region, and they can perform actions to move in the environment to reach target objects.\n\nThe problem has been studied for a while and therefore it is not novel. The proposed framework is incremental. The proposed environment is trivial and therefore it is unclear if the proposed framework is able to scale up to a more complicated environment. The experiemental results do not support several claims stated in the paper. Overall, I would vote for rejection.\n\n\n    - This paper solves the problem of navigating to the target object specified by language instruction in a 2D grid environment. It requires understanding of language, language grounding for visual features, and navigating to the target object while avoiding non-target objects. An attention mechanism is used to map a language instruction into a set of 1x1 convolutional filters which are intended to distinguish visual features described in the instruction from others. The experimental results show that the proposed method performs better than other methods.\n\n\n    - This paper presents an end-to-end trainable model to navigate an agent through visual sources and natural language instructions. The model utilizes a proposed attention mechanism to draw correlation between the objects mentioned in the instructions with deep visual representations, without requiring any prior knowledge about these inputs. The experimental results demonstrate the effectiveness of the learnt textual representation and the zero-shot generalization capabilities to unseen scenarios. \n\n\n**Paper Strengths**\n- The paper proposes an interesting task which is a navigation task with language instructions. This is important yet relatively unxplored.\n- The implementation details are included, including optimizers, learning rates with weight decayed, numbers of training epochs, the discount factor, etc. \n- The attention mechanism used in the paper is reasonable and the learned language embedding clearly shows meaningful relationships between instructions.\n- The learnt textual representation follows vector arithmetic, which enables the agent to perceive unseen instructions as a new combination of the attributes and perform zero-shot generalization.\n\n\n\n**Paper Weaknesses**\n- The problem of following natural language descriptions together with visual representations of environments is not completely novel. For example, Both the problem and the proposed method are similar to those already introduced in the Gated Attention method (Chaplot et al., 2017). Although the proposed method performs better than the prior work, the approach is incremental. \n\n- The proposed environment is simple. The vocabulary size is 40 and the longest instruciton only consists of 9 words. Whether the proposed framework is able to deal with more complicated environments is not clear. The experimental results shown in Figure 5 is not convincing that the proposed method only took less than 20k iterations to perform almost perfectly. The proposed environment is small and simple compared to the related work. It would be better to test the proposed method in a similar scale with the existing 3D navigation environments (Chaplot et al., 2017 and Hermann et al., 2017).\n\n- The novelty of the proposed framework is unclear. This work is not the first  one which proposes the multimodal fusion network incorporating a CNN achitecture dealing with visual information and a GRU architecture encoding language instructions. Also, the proposed attention mechanism is an obvious choice.\n\n- The shown visualized attention maps are not enough to support the contribution of proposing the attention mechanism. It is difficult to tell whether the model learns to attend to correct objects. Also, the effectiveness of incorporating the attention mechanism is unclear.\n\n- The paper claims that the proposed framework is flexible and is able to handle a rich set of natural language descriptions. However, the experiemental results are not enough to support the claim.\n\n- The presentaiton of the experiment is not space efficient at all.\n\n- The reference of the related papers which fuse multimodal data (vision and language) are missing.\n\n- Comapred to 8 pages was the suggested page limit, 13 pages is a bit too long.\n\n- Stating captions of figures above figures is not recommended.\n\n- It would be better to show where each 1x1 filter for multimodal fusion attends on the input image.  Ideally, one filter should attend on the target object and others should attend on non-target objects. However, I wonder how RNN can generate filters to detect non-target objects given an instruction. Although Figure 6 and Figure 7 try to show insights about the proposed attention model, they don’t tell which kernel is in charge of which visual feature. Blurred attention maps in Figure 6 and 7 make it hard to interpret the behavior of the model. \n\n- The graphs shown in the Figure 5 are hard to interpret because of their large variance. It would be better to smoothing curves, so that comparing methods clearly.\n\n- For zero-shot generalization evaluation, there is no detail about the training steps and comparisons to other methods.\n\n- A highly related paper (Hermann et al., 2017) is missing in the references.\n\n- Since the instructions are simple, the model does not require attention mechanism on the textual sources. If the framework can take more complex language, might be worthwhile to try visual-text co-attention mechanism. Such demonstration will be more convincing.\n\n- The attention maps of different attribute is not as clear as the paper stated. Why do we need several “non-target” objects highlight if one can learn to consolidate all of them?\n\n- The interpretation of n in the paper is vague, the authors should also show qualitatively why n=5 is better than that of n=1,10. If the attention maps learnt are really focusing on different attributes, given more and more objects, shouldn’t n=10 have more information for the policy learning?\n\n- The unseen scenario generalization should also include texture change on the grid environment and/or new attribute combinations on non-target objects to be more convincing.\n\n- The contribution in the visual part is marginal.\n\n\n** Preliminary Evaluation**\n- The modality fusion technique which leads to the attention maps is an effective and seem to work well approach, however, the author should present more thorough ablated analysis. The overall architecture is elegant, but the capability of it to be extended to more complex environment is in doubt. The vector arithmetic of the learnt textual embedding is the key component to enable zero-shot generalization, while the effectiveness of this method is not convincing if more complex instructions such that it contains object-object relations or interactions are perceived by the agent.  \n']","[-50, -80, -60]","[20, -20, 20]","[""The sentiment score is -50 because the review is overall critical, pointing out significant flaws in the paper's novelty claims, evaluation methods, and conclusions. However, it does acknowledge some positive aspects like the 'interesting problem' and that it's a 'reasonable first-pass'. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and provide constructive feedback. Phrases like 'Interesting Problem' and 'reasonable first-pass' soften the critique. The reviewer also offers specific suggestions for improvement and additional references, which is helpful and polite. However, some statements are quite blunt, preventing a higher politeness score."", ""The sentiment score is -80 because the reviewer explicitly states 'I vote for rejection' and lists several major weaknesses of the paper. The reviewer criticizes the experimental setup, lack of quantitative results for key claims, and lack of novelty. Even after the rebuttal, the reviewer maintains their negative stance. The politeness score is -20 because while the reviewer provides detailed feedback, the tone is quite critical and dismissive. Phrases like 'There is no guarantee that the conclusions are valid' and dismissing the authors' explanations as 'not a good excuse' come across as somewhat rude. However, the reviewer does acknowledge some strengths of the paper and provides specific recommendations, which prevents the score from being even lower."", ""The sentiment score is -60 because the review is overall negative, with the reviewer stating they would vote for rejection. The review points out several weaknesses and limitations of the paper, while acknowledging some strengths. The negative tone is established early with phrases like 'not novel', 'incremental', and 'trivial'. The politeness score is 20 because while the reviewer is critical, they maintain a professional and objective tone throughout. They use phrases like 'it would be better' and 'I wonder' rather than harsh language. The reviewer also acknowledges some positive aspects of the paper, which contributes to the politeness. However, the overall critical nature of the review prevents a higher politeness score.""]"
"['Minor comments:\n- page 3. “The observation equation and transition equations together (i.e., Equation (1,2,3)) together define “ - one “together” should be removed\n- page 4. “From Figure 2, the joint distribution (i.e., the likelihood function ” - there should be additional bracket\n- page 7. “We can further integral out αn “ -> integrate out\n\nMajor comments:\nThe paper is well-written. The paper considers structural time-series model with seasonal component and stochastic trend, which allow for change-points and structural breaks.\n\nSuch type of parametric models are widely considered in econometric literature, see e.g.\n[1] Jalles, João Tovar, Structural Time Series Models and the Kalman Filter: A Concise Review (June 19, 2009). FEUNL Working Paper No. 541. Available at SSRN: https://ssrn.com/abstract=1496864 or http://dx.doi.org/10.2139/ssrn.1496864 \n[2] Jacques J. F. Commandeur, Siem Jan Koopman, Marius Ooms. Statistical Software for State Space Methods // May 2011, Volume 41, Issue 1.\n[3] Scott, Steven L. and Varian, Hal R., Predicting the Present with Bayesian Structural Time Series (June 28, 2013). Available at SSRN: https://ssrn.com/abstract=2304426 or http://dx.doi.org/10.2139/ssrn.2304426 \n[4] Phillip G. Gould, Anne B. Koehler, J. Keith Ord, Ralph D. Snyder, Rob J. Hyndman, Farshid Vahid-Araghi, Forecasting time series with multiple seasonal patterns, In European Journal of Operational Research, Volume 191, Issue 1, 2008, Pages 207-222, ISSN 0377-2217, https://doi.org/10.1016/j.ejor.2007.08.024.\n[5] A.C. Harvey, S. Peters. Estimation Procedures for structural time series models // Journal of Forecasting, Vol. 9, 89-108, 1990\n[6] A. Harvey, S.J. Koopman, J. Penzer. Messy Time Series: A Unified approach // Advances in Econometrics, Vol. 13, pp. 103-143.\n\nThey also use Kalman filter and MCMC-based approaches to sample posterior to estimate hidden components.\n\nThere are also non-parametric approaches to extraction of components from quasi-periodic time-series, see e.g.\n[7] Artemov A., Burnaev E. Detecting Performance Degradation of Software-Intensive Systems in the Presence of Trends and Long-Range Dependence // 16th International Conference on Data Mining Workshops (ICDMW), IEEE Conference Publications, pp. 29 - 36, 2016. DOI: 10.1109/ICDMW.2016.0013\n[8] Alexey Artemov, Evgeny Burnaev and Andrey Lokot. Nonparametric Decomposition of Quasi-periodic Time Series for Change-point Detection // Proc. SPIE 9875, Eighth International Conference on Machine Vision, 987520 (December 8, 2015); 5 P. doi:10.1117/12.2228370;http://dx.doi.org/10.1117/12.2228370\n\nIn some of these papers models of structural brakes and change-points are also considered, see e.g. \n- page 118 in [6]\n- papers [7, 8]\n\nThere were also Bayesian approaches for change-point detection, which are similar to the model of change-point, proposed in the considered paper, e.g.\n[9] Ryan Prescott Adams, David J.C. MacKay. Bayesian Online Changepoint Detection // https://arxiv.org/abs/0710.3742\n[10] Ryan Turner, Yunus Saatçi, and Carl Edward Rasmussen. Adaptive sequential Bayesian change point detection. In Zaïd Harchaoui, editor, NIPS Workshop on Temporal Segmentation, Whistler, BC, Canada, December 2009.\n\nThus,\n- the paper does not provide comparison with relevant econometric literature on parametric structural time-series models,\n- the paper does not provide comparison with relevant advanced change-point detection methods e.g. [7,8,9,10]. The comparison is provided only with very simple methods,\n- the proposed model itself looks very similar to what can be found across econometric literature,\n- the datasets, used for comparison, are very scarce. There are datasets for anomaly detection in time-series data, which should be used for extensive comparison, e.g. Numenta Anomaly Detection Benchmark.\n\nTherefore, also the paper is well-written, \n- it lacks novelty,\n- its topic does not perfectly fit topics of interest for ICLR,\nSo, I do not recommend this paper to be published.', '\n\nSummary:\n\nThis paper develops a state space time series forecasting model in the Bayesian framework, jointly detects anomaly and change points. Integrated with an iterative MCMC method, the authors develop an efficient algorithm and use both synthetic and real data set to demonstrate that their algorithms outperform many other state-of-art algorithms. \n\nMajor comments:\nIn the beginning of section 3, the authors assume that all the terms that characterize the change-points and anomaly points are normally distributed with mean zero and different variance. However, in classic formulation for change-point or anomaly detection, usually there is also a mean shift other than the variance change. For example, we might assume $r_t \\sim N(\\theta, \\sigma_r^2)$ for some $\\theta>0$ to demonstrate the positive mean shift. I believe that this kind of mean shift is more efficient to model the structure of change-point. \n\nMy main concern is with the novelty. The work does not seem to be very novel.\n\nMinor comments:\n\n1. In the end of the page 2, the last panel is the residual, not the spikes. \n\n2. In page 12, the caption of figure 5 should be (left) and (right), not (top) and (bottom).', ""The paper introduces a Bayesian model for timeseries with anomaly and change points besides regular trend and seasonality. It develops algorithms for inference and forecasting. The performance is evaluated and compared against state-of-the-art methods on three data sets: 1) synthetic data obtained from the generative Bayesian model itself; 2) well-log data; 3) internet traffic data.\n\nOn the methodological side, this appears to be a solid and significant contribution, although I am not sure how well it is aligned with the scope of ICLR. The introduced model is elegant; the algorithms for inference are non-trivial.\n\nFrom a practical perspective, one cannot expect this contribution to be ground-breaking, since there has been more than 40 years of work on time series forecasting, change point and anomaly detection. In some situations the methodology proposed here will work better than previous approaches (particularly in the situation where the data comes from the Bayesian model itself - in that case, there clearly is no better approach), in other cases (which the paper might have put less emphasis on), previous approaches will work better. To position this kind of work, I think it is important the authors discuss the limitations of their approach. Some guidelines on when or when not to use it would be valuable. Clearly, these days one cannot introduce methodology in this area and expect it to outperform existing methods under all circumstances (and hence practitioners to always choose it over any other existing method).\n\nWhat is surprising is that relatively simple approaches like ETS or STL work pretty much equally well (in some cases even better in terms of MSE) than the proposed approach, while more recent approaches - like BSTS - dramatically fail. It would be good if the authors could comment on why this might be the case.\n\nSummary:\n+ Methodology appears to be a significant, solid contribution.\n- Experiments are not conclusive as to when or when not to choose this approach over existing methods\n- writing needs to be improved (large number of grammatical errors and typos, e.g. 'Mehtods')""]","[-70, -20, -20]","[20, 50, 50]","[""The sentiment score is -70 because the reviewer ultimately does not recommend the paper for publication, citing lack of novelty and poor fit for the conference. They acknowledge the paper is well-written but point out several major shortcomings, including lack of comparison with relevant literature and limited datasets. The politeness score is 20 because the reviewer uses generally polite language, acknowledging positive aspects ('well-written') and providing constructive feedback with specific references. However, the overall negative recommendation and critique of the paper's novelty and suitability for the conference prevent a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'outperform many other state-of-art algorithms'), they express concerns about the novelty of the work ('My main concern is with the novelty. The work does not seem to be very novel.'). This criticism, along with suggestions for improvement, indicates a somewhat negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They offer constructive criticism and suggestions without using harsh or rude language. The review begins with a summary of the paper's strengths and uses phrases like 'I believe' when offering suggestions, which contributes to a polite tone. The minor comments are presented factually without any negative connotations."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as a 'solid and significant contribution' methodologically, they express concerns about its practical significance, alignment with the conference scope, and the inconclusiveness of the experiments. The reviewer also points out the need for improvement in writing. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, balancing criticism with praise, and offering constructive suggestions. They use phrases like 'it would be good if the authors could comment' and 'I think it is important the authors discuss', which are polite ways of requesting improvements.""]"
"['This paper addresses an interesting problem of curriculum/self-paced versus random order of samples for faster learning. Specifically, the authors argue that adding samples in random order is as beneficial as adding them with some curriculum strategy, i.e. from easiest to hardest, or reverse. \nThe main learning strategy considered in this work is learning with growing sets, i.e. at each next stage a new portion of samples is added to the current available training set. At the last stage, all training samples are considered. The classifier is re-learned on each stage, where optimized weights in the previous stage are given as initial weights in the next stage. \n\nThe work has several flaws. \n-First of all, it is not surprising that learning with more training samples at each next stage (growing sets) gets better - this is the basic principle of learning. The question is how fast the current classifier converges to the optimal Bayes level when using Curriculum strategy versus Random strategy. The empirical evaluations do not show evidence/disprove regarding this matter. For example, it could happen that the classifier converges to the optimal on the first stage already, so there is no difference when training in random versus curriculum order with growing sets. \n-Secondly, easyness/hardness of the samples are defined w.r.t. some pre-trained (external) ensemble method. It is not clear how this definition of easiness/hardness translates when training the 3-layer neural network (final classifier). For example, it could well happen that all the samples are equally easy for training the final classifier, so the curriculum order would be the same as random order. In the original work on self-paced learning, Kumar et al (2010), easiness of the samples is re-computed on each stage of the classifier learning. \n-The empirical evaluations are not clear. Just showing the wins across datasets without actual performance is not convincing (Table 2). \n-I wonder whether the section with theoretical explanation is needed. What is the main advantage of learning with growing sets (when re-training the classifier)  and (traditional) learning when using the whole training dataset (last stage, in this work)? \n\n', 'Summary: \nThe paper proposes an algorithm to do incremental learning, by successively growing the training set in phases. However as opposed to training using curriculum learning or self paced learning, the authors propose to simply add training samples without any order to their ""complexity"". The authors claim that their approach, which is called ROGS, is better than the classical method and comparable to curriculum/self paced learning. The experiments are conducted on the UCI dataset with mixed results. \n\nReview: \nMy overall assessment of the paper is that it is extremely weak, both in terms of the novelty of method proposed, its impact, and the results of the experiments. Successively increasing the training set size in an arbitrary order is the first thing that one would try when learning incrementally. Furthermore, the paper does not clearly explain what does it mean by a method to ""win"" or ""lose"". Is some training algorithm A a winner over some training algorithm B, if A reaches the same accuracy as B in lesser number of epochs? In such a case, how do we decide on what accuracy is the upper bound. Also, do we tune the hyper-parameters of the model along the way? There are so many variables to account for here, which the paper completely ignores. \n\nFurthermore, even under the limited set of experiments the authors conducted, the results are highly inconclusive. While the authors test their proposed methodology on 36 UCI datasets, there is no clear indication whether the proposed approach has any superiority over the previous proposed ones, such as, CL and SPLI. \n\nGiven the above weaknesses of the paper i think the impact of this research is extremely marginal. \n\nThe paper is generally well written and easy to understand. There are some minor issues though. For example, I think Assumption (a) is quite strong and may not necessary hold in many cases. ', 'The paper proposes to study the influence of ordering in the Curriculum and Self paced learning. The paper is mainly based on empirical justification and observation. The results on 36 data sets show that to some extent the ordering of the training instances in the Curriculum and Self paced learning is not important. The paper involves some interesting ideas and experimental results. I still have some comments.\n\n1.\tThe empirical results show that different orderings still have different impact for data sets. How to adaptively select an appropriate ordering for given data set?\n2.\tThe empirical results show that some ordering has negative impact. How to avoid the negative impact? This question is not answered in the paper.\n3.\tThe ROGS is still clearly inferior to SPLI. It seems that such an observation does not strongly support the claim that ‘random is good enough’. \n']","[-50, -80, 20]","[20, 20, 50]","[""The sentiment score is -50 because the review starts with a positive note about the paper addressing an interesting problem, but then lists several significant flaws and criticisms. The reviewer uses phrases like 'The work has several flaws' and 'The empirical evaluations are not clear', indicating a generally negative sentiment towards the paper's content and methodology. However, it's not entirely negative, as the reviewer acknowledges the interesting nature of the problem. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use neutral language like 'It is not clear' and 'I wonder whether' rather than harsh or rude phrasing. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism in academic contexts."", ""The sentiment score is -80 because the reviewer's overall assessment is extremely negative. They describe the paper as 'extremely weak' in terms of novelty, impact, and results. They also state that the research impact is 'extremely marginal' and the results are 'highly inconclusive'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone and offer some positive feedback on the paper's writing style. They use phrases like 'The paper is generally well written and easy to understand' which shows a degree of politeness despite the overall negative assessment. The reviewer also provides specific critiques and explanations for their concerns, which is a polite way to offer negative feedback in academic contexts."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges 'interesting ideas and experimental results' and provides constructive feedback. However, the overall tone is not overwhelmingly positive, as the reviewer raises several questions and points out limitations. The politeness score is moderately positive (50) as the reviewer uses neutral language and phrases criticisms as questions or observations rather than direct criticisms. The reviewer maintains a professional tone throughout, avoiding harsh language or personal comments. The format of listing specific comments also contributes to the polite and constructive nature of the review.""]"
"['The authors propose an RNN that combines temporal shortcut connections from [Soltani & Jang, 2016] and Gated Recurrent Attention [Chung, 2014]. However, their justification about the novelty and efficacy of the model is not well demonstrated in the paper. The experiment part is modest with only one small dataset Penn Tree Bank is used. The results are not significant enough and no comparisons with models in [Soltani & Jang, 2016] and [Chung, 2014] are provided in the paper to show the effectiveness of the proposed combination. To conclude, this paper is an incremental work with limited contributions.\n\nSome writing issues:\n1. Lack of support in arguments,\n2. Lack of referencing to previous works. For example, the sentence “By selecting the same dropout mask for feedforward, recurrent connections, respectively, the dropout can apply to the RNN, which is called a variational dropout” mentions “variational dropout” with no citing. Or “NARX-RNN and HO-RNN increase the complexity by increasing recurrent depth. Gated feedback RNN has the fully connection between two consecutive timesteps” also mentions a lot of models without any references at all.\n3. Some related papers are not cited, e.g., Hierarchical Multiscale Recurrent Neural Networks [Chung, 2016]\n', ' This paper proposes a new type of RNN architectures called Dense RNNs. The authors combine several different RNN architectures and claim that their RNN can model long-term dependencies better, can learn multiscale representation of the sequential data, and can sidestep the exploding or vanishing gradients problem by using parametrized gating units.\n\nUnfortunately, this paper is hard to read, it is difficult to understand the intention of the authors. The authors make several claims without any supportive reference or experimental evidence. Both intuitive and theoretical justifications of the proposed architecture are not so convincing. The experiment is only done on PTB dataset, and the reported numbers are not that promising either. \n\nThis paper tries to combine three different features from previous works, and unfortunately, it is not so well conducted.\n', 'Summary: \n\nThis paper proposes a fully connected dense RNN architecture that has connections to every layer and the preceding connections of each layer. The connections are also gated by using a simple gating mechanism. The authors very briefly discusses about the effect of these on the dynamics of the learning. They report results on PTB character-level language modelling task.\n\n\nQuestions:\nWhat is the computational complexity of this approach compared to a vanilla RNN architecture?\nWhat is the implications of these skip connections in terms of memory consumption during BPTT?\nDid you use gradient clipping and have you used any specific type of initialization for the parameters?\nHow would this approach would compare against the Clockwork RNNs which has a block-diagonal weight matrices? [1]\nHow would dense-RNNs compare against to the MANNs [2]?\nHow would you implement this model efficiently?\n\nPros:\nInteresting idea.\nCons:\nLack of experiments and empirical results supporting the arguments.\nHand-wavy theory.\nLack of references to the relevant literature. \n\nGeneral Comments:\nIn general the paper is relatively well written despite having some minor typos. The idea is interesting, however the experiments in this paper is seriously lacking. The only results presented in this paper is on PTB. The results are quite behind the SOTA and PTB is a really tiny, toyish language modeling task. The theory is very hand-wavy, the connections to the previous attempts to come up with related properties of the recurrent models should be cited. The Figure 2 is very related to the Gersgorin circle theorem in [3]. The discussion about the skip-connections is very related to the results in [2]. \n\nOverall, I think this paper is rushed and not ready for the publication.\n\n[1] Koutnik, J., Greff, K., Gomez, F., & Schmidhuber, J. (2014, January). A clockwork rnn. In International Conference on Machine Learning (pp. 1863-1871).\n[2] Gulcehre, Caglar, Sarath Chandar, and Yoshua Bengio. ""Memory Augmented Neural Networks with Wormhole Connections."" arXiv preprint arXiv:1701.08718 (2017).\n[3] Zilly, Julian Georg, Rupesh Kumar Srivastava, Jan Koutník, and Jürgen Schmidhuber. ""Recurrent highway networks."" arXiv preprint arXiv:1607.03474 (2016).\n']","[-60, -70, -60]","[20, -20, 20]","[""The sentiment score is -60 because the review is generally negative, pointing out several shortcomings of the paper such as lack of novelty, limited experiments, and insufficient comparisons. However, it's not entirely dismissive, acknowledging the proposed model and suggesting improvements. The politeness score is 20 because while the reviewer maintains a professional tone and offers constructive criticism, the language is direct and doesn't use many polite phrases. The reviewer points out issues without softening the criticism, but also doesn't use harsh or rude language. The review provides specific recommendations for improvement, which is a polite and helpful approach in academic peer review."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer uses phrases like 'Unfortunately', 'difficult to understand', 'not so convincing', and 'not that promising', indicating a strong negative sentiment towards the paper. The only slightly positive aspect mentioned is the proposal of a new architecture, but this is quickly overshadowed by criticisms. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite critical and dismissive. Phrases like 'hard to read', 'difficult to understand', and 'not so well conducted' are direct criticisms without much softening language. The reviewer also doesn't offer many constructive suggestions for improvement, which contributes to the somewhat impolite tone."", ""The sentiment score is -60 because the review is generally negative. The reviewer states that the paper is 'rushed and not ready for publication', lacks experiments and empirical results, and has 'hand-wavy theory'. They also mention that the results are 'quite behind the SOTA'. However, it's not entirely negative as they do acknowledge it as an 'interesting idea' and that the paper is 'relatively well written'.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'Interesting idea' and 'relatively well written' which soften the criticism. They also pose questions and suggest comparisons rather than making outright negative statements in some cases. However, the directness of some criticisms (e.g., 'hand-wavy theory', 'seriously lacking') prevents the score from being higher.""]"
"[""This manuscript explores the idea of adding noise to the adversary's play in GAN dynamics over an RKHS. This is equivalent to adding noise to the gradient update, using the duality of reproducing kernels. Unfortunately, the evaluation here is wholly unsatisfactory to justify the manuscript's claims. No concrete practical algorithm specification is given (only a couple of ideas to inject noise listed), only a qualitative one on a 2-dimensional latent space in MNIST, and an inconclusive one using the much-doubted Parzen window KDE method. The idea as stated in the abstract and introduction may well be worth pursuing, but not on the evidence provided by the rest of the manuscript."", '\nIn this paper, the authors propose doubly stochastic adversarial autoencoder, which is essentially applying the doubly stochastic gradient for the variational form of maximum mean discrepancy. \n\nThe most severe issue is lacking novelty. It is a straightforward combination of existing work, therefore, the contribution of this work is rare. \n\nMoreover, some of the claims in the paper are not appropriate. For example, using random features to approximate the kernel function does not bring extra stochasticity. The random features are fixed once sampled from the base measure of the corresponding kernel. Basically, you can view the random feature approximation as a linear combination of fixed nonlinear basis which are sampled from some distribution. \n\nFinally, the experiments are promising. However, to be more convincing, more benchmarks, e.g., cifar10/100 and CelebA, are needed. ', ""Thank you for the feedback, and I have read it.\n\nThe authors claimed that they used techniques in [6] in which I am not an expert for this. However I cannot find the comparison that the authors mentioned in the feedback, so I am not sure if the claim is true.\n\nI still recommend rejection for the paper, and as I said in the first review, the paper is not mature enough.\n\n==== original review ===\n\nThe paper describes a generative model that replaces the GAN loss in the adversarial auto-encoder with MMD loss. Although the author claim the novelty as adding noise to the discriminator, it seems to me that at least for the RBF case it just does the following:\n1. write down MMD as an integral probability metric (IPM)\n2. say the test function, which originally should be in an RKHS, will be approximated using random feature approximations.\n\nAlthough the authors explained the intuition a bit and showed some empirical results, I still don't see why this method should work better than directly minimising MMD. Also it is not preferred to look at the generated images and claim diversity, instead it's better to have some kind of quantitative metric such as the inception score.\n\nFinally, given the fact that we have too many GAN related papers now, I don't think the innovation contained in the paper (which is using random features) is good enough to be published at ICLR. Also the paper is not clearly written, and I would suggest better not to copy-past paragraphs in the abstract and intro.\n\nThat said, I would welcome for the authors feedback and see if I have misunderstood something.""]","[-70, -50, -70]","[0, 0, 20]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the evaluation is 'wholly unsatisfactory' and that the manuscript's claims are not justified. They also mention that the practical algorithm specification is missing and the experiments are inconclusive. The only slightly positive note is that the idea 'may well be worth pursuing,' but this is immediately negated by 'not on the evidence provided.' The politeness score is 0 (neutral) because the language used is direct and professional without being overtly polite or rude. The reviewer states their criticisms plainly without using harsh language or personal attacks, but also without softening their critique with polite phrases or compliments."", ""The sentiment score is -50 because the review is generally negative, highlighting a 'severe issue' of lacking novelty and stating that the contribution is 'rare'. However, it's not entirely negative as it acknowledges that the experiments are 'promising'. The politeness score is 0 (neutral) because the language is direct and professional without being overtly polite or rude. The reviewer states criticisms plainly ('The most severe issue is...', 'Moreover, some of the claims... are not appropriate') but doesn't use insulting or overly harsh language. The tone is matter-of-fact throughout, maintaining a neutral level of politeness typical in academic peer reviews."", ""The sentiment score is -70 because the reviewer recommends rejection and states the paper is 'not mature enough'. They also express skepticism about the authors' claims and the novelty of the work. The politeness score is 20 because while the reviewer is critical, they use professional language and offer the authors a chance to provide feedback. They also thank the authors for their feedback at the beginning. However, some phrases like 'I still don't see why this method should work better' and 'it's better to have some kind of quantitative metric' come across as slightly dismissive, preventing a higher politeness score.""]"
"['This paper proposes a WGAN formulation for generating graphs based on random walks. The proposed generator model combines node embeddings, with an LSTM architecture for modeling the sequence of nodes visited in a random walk; the discriminator distinguishes real from fake walks.\n\nThe model is learned from a single large input graph (for three real-world networks) and evaluated against one baseline generative graph model: degree-corrected stochastic block models. \n\nThe primary claims of the paper are as follows:\ni) The proposed approach is a generative model of graphs, specifically producing ""sibling"" graphs\nii) The learned latent representation provides an interpretation of generated graph properties\niii) The model generalizes well in terms of link and node classification\n\nThe proposed method is novel and the incorporated ideas are quite interesting (e.g., discriminating real from fake random walks, generating random walks from node embeddings and LSTMs). However, from a graph generation perspective, the problem formulation and evaluation do not sufficiently demonstrate the utility of proposed method. \n\nFirst, wrt claim (i) the problem of generating ""sibling"" graphs is ill-posed. Statistical graph models are typically designed to generate a probability distribution over all graphs with N nodes and, as such, are evaluated based on how well they model that distribution. The notion of a ""sibling"" graph used in this paper is not clearly defined, but it seems to only be useful if the sibling graphs are likely under the distribution. Unfortunately, the likelihood of the sampled graphs is not explicitly evaluated. On the other hand, since many of the edges are shared the ""siblings"" may be nearly isomorphic to the input graph, which is not useful from a graph modeling perspective. \n\nFor claim (i), the comparison to related work is far from sufficient to demonstrate its utility as a graph generation model. There are many graph models that are superior to DC-SBM, including KPGMs, BETR, ERGMs, hierarchical random graph models and latent space models. Moreover, a very simple baseline to assess the LSTM component of the model, would be to produce a graph by sampling links repeatedly from the latent space of node embeddings. \n\nNext, the evaluation wrt to claim (ii) is novel and may help developers understand the model characteristics. However, since the properties are measured based on a set of random walks it is still difficult to interpret the impact on the generated graphs (since an arbitrary node in the final graph will have some structure determined from each of the regions). Do the various regions generate different parts of the final graph structure (i.e., focusing on only a subset of the nodes)?   \n\nLastly, the authors evaluate the learned model on link and node prediction tasks and state that the model\'s so-so performance supports the claim that the model can generalize. This is the weakest claim of the paper. The learned node embeddings appear to do significantly worse than node2vec, and the full model is worse than DC-SBM. Given that the proposed model is transductive (when there is significant edge overlap) it should do far better than DC-SBM which is inductive. \n\nOverall, while the paper includes a wide range of experimental evaluation, they are aimed too broadly (and the results are too weak) to support any specific claim of the work. If the goal is to generate transductively (with many similar edges), then it would be better to compare more extensively to alternative node embedding and matrix factorization approaches, and assess the utility of the various modeling choices (e.g., LSTM, in/out embedding). If the goal is to generate inductively, over the full distribution of graphs, then it would be better to (i) assess whether the sampled graphs are isomorphic, and (ii) compare more extensively to alternative graph models (many of which have been published since 2010).  \n', 'I am overall positive about the work but I would like to see some questions addressed. \n\nQuality: The paper is good but does not address some important issues. The paper proposes a GAN model to generate graphs with non-trivial properties. This is possibly one of the best papers on graph generation using GANs currently in the literature. However, there are a number of statistical issues that should be addressed. I fear the paper is not ready yet, but I am not opposed to publication as long as there are warnings in the paper about the shortcomings.\n\nOriginality: This is an original approach. Random walks sometimes are overused in the graph literature, but they seem justified in this work. But it also requires extra work to ensure they are generating meaningful graphs.\n\nSignificance: The problem is important. Learn to generate graphs is a key task in drug discovery, relational learning, and knowledge discovery.\n\nEvaluation: The link prediction task is too easy, as links are missing at random. It would be more useful to predict links that are removed with an unknown bias. The graph (wedge, claw, etc) characteristics are good (but simple) metrics; however, it is unclear how a random graph with the same size and degree distribution (configuration model) would generate for the same metrics (it is not shown for comparison). \n\nIssues that I wish were addressed in the paper: \na)\tHow is the method learning a generator from a single graph? What are the conditions under which the method is likely to perform well? It seems to rely on some mixing RW conditions to model the distinct graph communities. What are these mixing conditions? These are important questions that should have at least an empirical exploration.\nb)\tWhat is the spatial independence assumption needed for such a generator? \nc)\tWould this approach be able to generate a lattice? Would it be able to generate an expander graph? What about a graph with poorly connect communities? Is there any difficulties with power law graphs? \nd)\tHow is the RW statistically addressing the generation of high-order (subgraph) features?\ne)\tCan this approach be used with multiple i.i.d. graphs? \nf)\tIsn’t learning the random walk sample path a much harder / higher-dimensional task than it is necessary? Again, the short walk may be capturing the communities but the high-dimensional random walk sample path seems like a high price to pay to learn community structure.\ng)\tClearly, with a large T (number of RW steps), the RW is not modeling just a single community. Is there a way to choose T? How larger values of T to better model inter-community links? Would different communities have different choices of T? \nh)\tAnd a related question, how well can the method generate the inter-community links?\ni)\tThe RW model is actually similar to an HMM. Would learning a mixture of HMMs (one per community) have similar performance?\n', 'The authors proposed a generative model of random walks on graphs. Using GAN, the architecture allows for model-agnostic learning, controllable fitting, ensemble graph generation. It also produces meaningful node embeddings with semi-interpretable latent spaces. The overall framework could be relevant to multiple areas in graph analytics, including graph comparison, graph sampling, graph embedding and relational feature selection. The draft is well written with convincing experiments. I support the acceptances of this paper.\n\nI do have a few questions that might help further improve the draft. More baseline besides DC-SBM could better illustrate the power of GAN in learning longer random walk trajectories. DC-SBM, while a generative model, inherently can only capture first order random walks with target degree biases, and generally over-fits into degree sequences. Are there existing generative models based on walk paths?\n\nThe choice of early stopping is a very interesting problem especially for the EO-creitenrion. In Fig3 (b), it seems assortativity is over-fitted beyond 40k iterations. It might be helpful to discuss more about the over-fitting of different graph properties.\n\nThe node classification experiment could use a bit more refinement. The curves in Fig. 5(a) are not well explained. What is the ""combined""? The claim of competitive performance needs better justification according to the presentation of the F1 scores.\n\nThe Latent variable interpolation experiment could also use more explanations. How is the 2d subspace chosen? What is the intuition behind the random walks and graphs of Fig 6? Can you provide visualizations of the communities of the interpolated graphs in Fig 7? ']","[-50, 50, 80]","[50, 75, 70]","[""The sentiment score is -50 because while the reviewer acknowledges some novel and interesting aspects of the paper, they express significant concerns about the problem formulation, evaluation methods, and the strength of the claims made. The review points out several weaknesses and suggests that the results are too weak to support the paper's claims. However, it's not entirely negative as the reviewer does recognize some positive aspects.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'quite interesting' and 'novel' when discussing positive aspects. When expressing criticisms, they use diplomatic language such as 'do not sufficiently demonstrate' and 'the comparison to related work is far from sufficient' rather than harsh or rude phrasing. The reviewer also provides constructive feedback and suggestions for improvement, which is a polite approach to criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer starts with 'I am overall positive about the work' and mentions it's 'possibly one of the best papers on graph generation using GANs currently in the literature.' However, they also express concerns and state that the paper 'is not ready yet,' balancing out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'I would like to see some questions addressed'), and offers specific suggestions for improvement. The tone is professional and courteous, avoiding harsh or rude language even when pointing out shortcomings."", ""The sentiment score is 80 (positive) because the reviewer explicitly states support for the paper's acceptance and describes the draft as 'well written with convincing experiments.' They also highlight several positive aspects of the proposed model. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, framing their suggestions as questions or areas for improvement rather than criticisms. They use phrases like 'I do have a few questions that might help further improve the draft' which is constructive and polite. The reviewer maintains a professional and courteous tone while providing specific recommendations for enhancement, indicating a high level of politeness without being overly deferential.""]"
"[""This paper proposes a model for solving the WikiSQL dataset that was released recently.\n\nThe main issues with the paper is that its contributions are not new.\n\n* The first claimed contribution is to use typing at decoding time (they don't say why but this helps search and learning). Restricting the type of the decoded tokens based on the programming language has already been done by the Neural Symbolic Machines of Liang et al. 2017. Then Krishnamurthy et al. expanded that in EMNLP 2017 and used typing in a grammar at decoding time. I don't really see why the authors say their approach is simpler, it is only simpler because the sub-language of sql used in wikisql makes doing this in an encoder-decoder framework very simple, but in general sql is not regular. Of course even for CFG this is possible using post-fix notation or fixed-arity pre-fix notation of the language as has been done by Guu et al. 2017 for the SCONE dataset, and more recently for CNLVR by Goldman et al., 2017.\n\nSo at least 4 papers have done that in the last year on 4 different datasets, and it is now close to being common practice so I don't really see this as a contribution.\n\n* The authors explain that they use a novel loss function that is better than an RL based function used by Zhong et al., 2017. If I understand correctly they did not implement Zhong et al. only compared to their numbers which is a problem because it is hard to judge the role of optimization in the results.\n\nMoreover, it seems that the problem they are trying to address is standard - they would like to use cross-entropy loss when there are multiple tokens that could be gold. the standard solution to this is to just have uniform distribution over all gold tokens and minimize the cross-entropy between the predicted distribution and the gold distribution which is uniform over all tokens. The authors re-invent this and find it works better than randomly choosing a gold token or taking the max. But again, this is something that has been done already in the context of pointer networks and other work like See  et al. 2017 for summarization and Jia et al., 2016 for semantic parsing.\n\n* As for the good results - the data is new, so it is probable that numbers are not very fine-tuned yet so it is hard to say what is important and what not for final performance. In general I tend to agree that using RL for this task is probably unnecessary when you have the full program as supervision."", 'The paper claims to develop a novel method to map natural language queries to SQL. They claim to have the following contributions: \n\n1. Using a grammar to guide decoding \n2. Using a new loss function for pointer / copy mechanism. For each output token, they aggregate scores for all positions that the output token can be copied from.\n\nI am confident that point 1 has been used in several previous works. Although point 2 seems novel, I am not convinced that it is significant enough for ICLR. I was also not sure why there is a need to copy items from the input question, since all SQL query nouns will be present in the SQL table in some form.  What will happen if we restrict the copy mechanism to only copy from SQL table.\n\nThe references need work. There are repeated entries for the same reference (one form arxiv and one from conference). Please cite the conference version if one is available, many arxiv references have conference versions.\n\nRebuttal Response: I am still not confident about the significance of contribution 1, so keeping the score the same.', ""This paper presents a neural architecture for converting natural language queries to SQL statements. The model utilizes a simple typed decoder that chooses to copy either from the question / table or generate a word from a predefined SQL vocabulary. The authors try different methods of aggregating attention for the decoder copy mechanism and find that summing token probabilities works significantly better than alternatives; this result could be useful beyond just Seq2SQL models (e.g., for summarization). Experiments on the WikiSQL dataset demonstrate state-of-the-art results, and detailed ablations measure the impact of each component of the model. Overall, even though the architecture is not very novel, the paper is well-written and the results are strong; as such, I'd recommend the paper for acceptance.\n\nSome questions:\n- How can the proposed approach scale to more complex queries (i.e., those not found in WikiSQL)? Could the output grammar be extended to support joins, for instance? As the grammar grows more complex, the typed decoder may start to lose its effectiveness. Some discussion of these issues would be helpful.\n- How does the additional preprocessing done by the authors affect the performance of the original baseline system of Zhong et al.? In general, some discussion of the differences in preprocessing between this work and Zhong et al. would be good (do they also use column annotation)?""]","[-70, -50, 80]","[-20, 0, 70]","[""The sentiment score is -70 because the reviewer is predominantly critical of the paper's contributions, stating that they are 'not new' and have been done before in multiple other papers. The reviewer dismisses the claimed novelty and argues that the approaches used are already common practice. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite dismissive and critical without offering much constructive feedback or positive reinforcement. Phrases like 'I don't really see this as a contribution' and 'The authors re-invent this' come across as somewhat condescending. The reviewer does acknowledge some potential merit in the results, which prevents the scores from being even lower."", ""The sentiment score is -50 because the reviewer expresses skepticism about the novelty and significance of the paper's contributions. They state that one of the main claims has been used in previous works and are not convinced about the significance of the other claim. The reviewer also mentions issues with references and maintains their score even after a rebuttal. However, it's not entirely negative as they acknowledge some novelty in the second point.\n\nThe politeness score is 0 (neutral) because the reviewer's language is neither particularly polite nor rude. They express their opinions directly without using overly harsh language, but also without any notably courteous phrases. The tone is professional and straightforward, focusing on the content of the paper rather than personal comments."", ""The sentiment score is 80 (positive) because the reviewer recommends the paper for acceptance, praises it as well-written with strong results, and acknowledges its state-of-the-art performance. The positive tone is evident throughout, with phrases like 'results are strong' and 'this result could be useful beyond just Seq2SQL models'. The politeness score is 70 (polite) due to the constructive and respectful nature of the feedback. The reviewer offers suggestions and asks questions in a courteous manner, using phrases like 'Some discussion of these issues would be helpful' and 'Some discussion of the differences... would be good'. The language is professional and considerate throughout, without any harsh criticism or demanding tone.""]"
"['The idea of the paper is to use a GAN-like training to learn a novelty detection approach. In contrast to traditional GANs, this approach does not aim at convergence, where the generator has nicely learned to fool the discriminator with examples from the same data distribution. The goal is to build up a series of generators that sample examples close the data distribution boundary but are regarded as outliers. To establish such a behavior, the authors propose early stopping as well as other heuristics. \n\nI like the idea of the paper, however, this paper needs a revision in various aspects, which I simply list in the following:\n* The authors do not compare with a lot of the state-of-the-art in outlier detection and the obvious baselines: SVDD/OneClassSVM without PCA, Gaussian Mixture Model, KNFST, Kernel Density Estimation, etc\n* The model selection using the AUC of ""inlier accepted fraction"" is not well motivated in my opinion. This model selection criterion basically leads too a probability distribution with rather steep borders and indirectly prevents the outlier to be too far away from the positive data. The latter is important for the GAN-like training.\n* The experiments are not sufficient: Especially for multi-class classification tasks, it is easy to sample various experimental setups for outlier detection. This allows for robust performance comparison. \n* With the imbalanced training as described in the paper, it is quite natural that the confidence threshold for the classification decision needs to be adapted (not equal to 0.5)\n* There are quite a few heuristic tricks in the paper and some of them are not well motivated and analyzed (such as the discriminator training from multiple generators)\n* A cross-entropy loss for the autoencoder does not make much sense in my opinion (?)\n\n\nMinor comments:\n* Citations should be fixed (use citep to enclose them in ())\n* The term ""AI-related task"" sounds a bit too broad\n* The authors could skip the paragraph in the beginning of page 5 on the AUC performance. AUC is a standard choice for evaluation in outlier detection.\n* Where is Table 1?\n* There are quite a lot of typos.\n\n*After revision statement*\nI thank the authors for their revision, but I keep my rating. The clarity of the paper has improved but the experimental evaluation is lacking realistic datasets and further simple baselines (as also stated by the other reviewers)', ""This paper addresses the problem of one class classification. The authors suggest a few techniques to learn how to classify samples as negative (out of class) based on tweaking the GAN learning process to explore large areas of the input space which are out of the objective class.\n\nThe suggested techniques are nice and show promising results. But I feel a lot can still be done to justify them, even just one of them. For instance, the authors manipulate the objective of G using a new parameter alpha_new and divide heuristically the range of its values. But, in the experimental section results are shown only for a  single value, alpha_new=0.9 The authors also suggest early stopping but again (as far as I understand) only a single value for the number of iterations was tested. \n\nThe writing of the paper is also very unclear, with several repetitions and many typos e.g.:\n\n'we first introduce you a'\n'architexture'\n'future work remain to'\n'it self'\n\nI believe there is a lot of potential in the approach(es) presented in the paper. In my view a much stronger experimental section together with a clearer presentation and discussion could overcome the lack of theoretical discussion.\n"", 'The idea of using GANs for outlier detection is interesting and the problem is relevant. However, I have the following concerns about the quality and the significance:\n- The proposed formulation in Equation (2) is questionable. The authors say that this is used to generate outliers, and since it will generate inliers when convergence, the authors propose the technique of early stopping in Section 4.1 to avoid convergence. However, then what is learned though the proposed formulation? Since this approach is not straightforward, more theoretical analysis of the proposed method is desirable.\n- In addition to the above point, I guess the expectation is needed as the original formulation of GAN. Otherwise the proposed formulation does not make sense as it receives only specific data points and how to accumulate objective values across data points is not defined.\n- In experiments, although the authors say ""lots of datasets are used"", only two datasets are used, which is not enough to examine the performance of outlier detection methods. Moreover, outliers are artificially generated in these datasets, hence there is no evaluation on pure real-world datasets. To achieve the better quality of the paper, I recommend to add more real-world datasets in experiments.\n- As discussed in Section 2, there are already many outlier detection methods, such as distance-based outlier detection methods, but they are not compared in experiments.\n  Although the authors argue that distance-based outlier detection methods do not work well for high-dimensional data, this is not always correct.\n  Please see the paper:\n  -- Zimek, A., Schubert, E., Kriegel, H.-P., A survey on unsupervised outlier detection in high-dimensional numerical data, Statistical Analysis and Data Mining (2012)\n  This paper shows that the performance gets even better for higher dimensional data if each feature is relevant.\n  I recommend to add some distance-based outlier detection methods as baselines in experiments.  \n- Since parameter tuning by cross validation cannot be used due to missing information of outliers, it is important to examine the sensitivity of the proposed method with respect to changes in its parameters (a_new, lambda, and others). Otherwise in practice how to set these parameters to get better results is not obvious.\n\n* The clarity of this paper is not high as the proposed method is not well explained. In particular, please mathematically formulate each proposed technique in Section 4.\n\n* Since the proposed formulation is not convincing due to the above reasons and experimental evaluation is not thorough, the originality is not high.\n\nMinor comments:\n- P.1, L.5 in the third paragraph: architexture -> architecture\n- What does ""Cor"" of CorGAN mean?\n\nAFTER REVISION\nThank you to the authors for their response and revision. Although the paper has been improved, I keep my rating due to the insufficient experimental evaluation.']","[-20, -20, -60]","[60, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer initially states they 'like the idea of the paper', they follow with a long list of criticisms and areas needing revision. The reviewer maintains this stance even after revision, indicating the paper still lacks in experimental evaluation. The politeness score is moderately positive (60) as the reviewer uses polite language throughout, such as 'I like the idea', 'I thank the authors for their revision', and frames criticisms as suggestions or observations rather than direct attacks. The reviewer also provides detailed feedback, which is a courteous approach in academic review. However, the politeness is not at the highest level due to the directness of some criticisms and the maintained negative stance after revision."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the potential and promising results of the paper, they express significant concerns about the lack of justification, limited experimental results, and unclear writing. The reviewer suggests that 'a lot can still be done' and points out several areas for improvement. However, the score is not deeply negative as the reviewer sees potential in the approach.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I feel,' 'I believe,' and 'in my view,' which soften their criticisms. The reviewer also balances negative feedback with positive comments, acknowledging the 'nice' and 'promising' aspects of the work. However, the score is not extremely high as the criticism is direct and the reviewer doesn't use overtly polite language or excessive praise."", ""The sentiment score is -60 because the reviewer expresses several significant concerns about the paper's methodology, theoretical foundations, and experimental evaluation. While they acknowledge the interesting idea, the majority of the review focuses on criticisms and areas needing improvement. The politeness score is 20 because the reviewer uses professional language and offers constructive feedback, but the tone is predominantly critical. They use phrases like 'I have the following concerns' and 'I recommend' which maintain politeness while expressing criticism. The reviewer also acknowledges the authors' efforts in the revision, which adds to the politeness, but maintains their critical stance.""]"
"['The authors try to combine the power of GANs with hierarchical community structure detections. While the idea is sound, many design choices of the system is questionable. The problem is particularly aggravated by the poor presentation of the paper, creating countless confusions for readers. I do not recommend the acceptance of this draft.\n\nCompared with GAN, traditional graph analytics is model-specific and non-adaptive to training data. This is also the case for hierarchical community structures. By building the whole architecture on the Louvain method, the proposed method is by no means truly model-agnostic. In fact, if the layers are fine enough, a significant portion of the network structure will be captured by the sum-up module instead of the GAN modules, rendering the overall behavior dominated by the community detection algorithm. \n\nThe evaluation remains superficial with minimal quantitative comparisons. Treating degree distribution and clustering coefficient (appeared as cluster coefficient in draft) as global features is problematic. They are merely global average of local topological features which is incapable of capturing true long-distance structures in graphs. \n\nThe writing of the draft leaves much to be desired. The description of the architecture is confusing with design choices never clearly explained. Multiple concepts needs better introduction, including the very name of their model GTI and the idea of stage identification. Not to mention numerous grammatical errors, I suggest the authors seek professional English writing services.', 'The proposed approach, GTI, has many free parameters: number of layers L, number of communities in each layer, number of non-overlapping subgraphs M, number of nodes in each subgraph k, etc.  No analysis is reported on how these affect the performance of GTI.\n\nGTI uses the Louvain hierarchical community detection method to identify the hierarchy in the graph and METIS to partition the communities.  How important are these two methods to the success of GTI?\n\nWhy is it reasonable to restore a k-by-k adjacency matrix from the standard uniform distribution (as stated in Section 2.1)?\n\nWhy is the stride for the convolutional/deconvoluational layers set to 2 (as stated in Section 2.1)?\n\nEquation 1 has a symbol E in it.  E is defined (in Section 2.2) to be ""all the inter-subgraph (community) edges identified by the Louvain method for each hierarchy.""  However, E can be intra-community because communities are partitioned by METIS.  More discussion is needed about the role of edges in E. \n\nEquation 3 sparsifies (i.e. prunes the edges) of a graph -- namely $re_{G}$.  However, it is not clear how one selects a $re^{i}{G}$ from among the various i values.  The symbol i is an index into $CV_{i}$, the cut-value of the i-th largest unique weight-value.\n\nWas the edge-importance reported in Section 2.3 checked against various measures of edge importance such as edge betweenness?\n\nTable 1 needs more discussion in terms of retained edge percentage for ordered stages.  Should one expect a certain trend in these sequences?\n\nAlmost all of the experiments are qualitative and can be easily made quantitive by comparing PageRank or degree of nodes.\n\nThe discussion on graph sampling does not include how much of the graph was sampled.  Thus, the comparisons in Tables 2 and 3 are not fair.\n\nThe most realistic graph generator is the BTER model.  See http://www.sandia.gov/~tgkolda/bter_supplement/ and http://www.sandia.gov/~tgkolda/feastpack/doc_bter_match.html.\n\nA minor point: The acronym GTI is never defined.', 'Quality: The work has too many gaps for the reader to fill in. The generator (reconstructed matrix) is supposed to generate a 0-1 matrix (adjacency matrix) and allow backpropagation of the gradients to the generator. I am not sure how this is achieved in this work. The matrix is not isomorphic invariant and the different clusters don’t share a common model. Even implicit models should be trained with some way to leverage graph isomorphisms and pattern similarities between clusters. How can such a limited technique be generalizing? There is no metric in the results showing how the model generalizes, it may be just overfitting the data.\n\nClarity: The paper organization needs work; there are also some missing pieces to put the NN training together. It is only in Section 2.3 that the nature of G_i^\\prime becomes clear, although it is used in Section 2.2. Equation (3) is rather vague for a mathematical equation. From what I understood from the text, equation (3) creates a binary matrix from the softmax output using an indicator function. If the output is binary, how can the gradients backpropagate? Is it backpropagating with a trick like the Gumbel-Softmax trick of Jang, Gu, and Poole 2017 or Bengio’s path derivative estimator? This is a key point not discussed in the manuscript. \nAnd if I misunderstood the sentence “turn re_G into a binary matrix” and the values are continuous, wouldn’t the discriminator have an easy time distinguishing the generated data from the real data. And wouldn’t the generator start working towards vanishing gradients in its quest to saturate the re_G output?\n\nOriginality: The work proposes an interesting approach: first cluster the network, then learning distinct GANs over each cluster. There are many such ideas now on ArXiv but it would be unfair to contrast this approach with unpublished work. There is no contribution in the GAN / neural network aspect. It is also unclear whether the model generalizes. I don’t think this is a good fit for ICLR.\n\nSignificance: Generating graphs is an important task in in relational learning tasks, drug discovery, and in learning to generate new relationships from knowledge bases. The work itself, however, falls short of the goal. At best the generator seems to be working but I fear it is overfitting. The contribution for ICLR is rather minimal, unfortunately.\n\nMinor:\n\nGTI was not introduced before it is first mentioned in the into.\n\nY. Bengio, N. Leonard, and A. Courville. Estimating or propagating gradients through stochastic neurons for conditional computation. arXiv:1308.3432, 2013.\n\n']","[-80, -50, -70]","[-20, 0, 20]","[""The sentiment score is -80 because the review is predominantly negative. The reviewer does not recommend acceptance, points out numerous issues with the paper's approach and presentation, and uses strong negative language like 'questionable', 'poor', and 'problematic'. The only slightly positive note is acknowledging the idea as 'sound' at the beginning. The politeness score is -20 because while the reviewer isn't overtly rude, the language is quite direct and critical without much attempt to soften the criticism. Phrases like 'countless confusions', 'by no means truly model-agnostic', and 'leaves much to be desired' are particularly blunt. However, the reviewer does offer some constructive suggestions at the end, which prevents the score from being even lower."", ""The sentiment score is -50 because the review is predominantly critical, pointing out several issues and asking for clarifications without offering much positive feedback. However, it's not entirely negative as it suggests improvements and doesn't dismiss the work outright. The politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout, neither being particularly polite nor rude. They ask direct questions and make straightforward observations without using overly harsh language or personal attacks, but also without using explicitly polite phrases or compliments. The review focuses on technical aspects and improvements needed, maintaining a neutral, academic tone throughout."", ""The sentiment score is -70 because the review is predominantly negative, pointing out numerous flaws and gaps in the work. The reviewer expresses significant doubts about the methodology, generalizability, and overall contribution of the paper. Phrases like 'too many gaps', 'not sure how this is achieved', 'limited technique', and 'falls short of the goal' indicate a strongly negative sentiment. However, it's not at the extreme negative end as the reviewer does acknowledge some interesting aspects ('proposes an interesting approach'). The politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively respectful tone. They use phrases like 'I am not sure' and 'From what I understood' rather than making blunt accusations. The reviewer also provides constructive feedback and suggestions for improvement. However, the politeness is not extremely high as the criticism is quite direct and there are few overtly polite phrases or compliments.""]"
"['In this paper it is described a method that can be used to speed up the prediction process of ensembles of classifiers that output probabilistic predictions. The method proposed is very simple and it is based on the observation that in the case that the individual predictors are very sure about the potential class label, ensembling many predictions is not particularly useful. It seems it is most useful when the individual classifier are most unsure, as measured by the output probabilities. The idea proposed by the authors is to compute an estimate of the probability that the class with the highest probability will not change after querying more predictors from the ensemble. This estimate is obtained by using a t-student distribution for the distribution of the average maximum probability.\n\nThe paper is generally well written with a few mistakes that can be easily corrected using any spell checking tool.\n\nThe experiments carried out by the authors are convincing. It seems that their proposed approach can speed up the predictions of the ensemble by an important factor. The benefits of using ensemble methods are also evident, since they always improve the performance of a single classifier.\n\nAs far as I know this work is original. However, it is true that several similar ensemble pruning techniques exist for multi-class problems in which one uses majority voting for computing the combined prediction of the ensemble. Therefore it is unclear what are the advantages of the proposed method with respect to those ones. This is, in my opinion, the weakest point of the paper.\n', 'The authors propose and evaluate an adaptive ensembling threshold using estimated confidence intervals from the t-distribution, rather than a static confidence level threshold. They show it can provide significant improvements in accuracy at the same cost as a naive threshold.\n\nThis paper has a nice simple idea at its core, but I don\'t think it\'s fully developed. There\'s a few major conceptual issues going on:\n\n- The authors propose equation (3) as a stopping criterion because ""computing CIs for all labels is costly."" I don\'t see how this is true in any sense. The CI computation is literally just averages of a few numbers, which should be way less than the massive matrix multiplies needed to *generate* those numbers in the neural network. Computing pair-wise comparisons naively in O(n^2) time could potentially blow up if the number of output labels is massive, but then you should still be able to keep some running statistics to avoid having to do a quadratic number of comparisons (e.g. the threshold is just the highest bound of any CI you encounter, so you keep track of both the max predicted confidence and max CI so far...then you have your answer in O(n) time.) I think the real issue is that the authors state that the confidence interval computation code is written in Python. That is a huge knock against this paper: When writing a paper about inference time, it\'s just due diligence to do the most basic inference time optimizations (such as implementing an operation which should be effectively free in a C++ plugin.) \n\n- So by using (3) instead of the original proposed CI comparison that motivated this approach, the authors require that the predicted probability be greater than 1/2 + the CI at the given alpha level. This means that for problems with very large output spaces, getting enough probability mass to get over that 1/2 absolute threshold is potentially going to require a minimum number of evaluations and put a cap on the efficiency gain. This is what we see in Figure 3: for the few points evaluated, when the output space is large (ILSVRC 2012) there is no effective difference between the proposed method and a static threshold of 70%, indicating that the CI of 90% is roughly working out to be the 50% minimum + ~20% threshold from the CI. \n\n- Thus the experiments in this paper don\'t really add much value in understanding the benefits of this approach as currently written. For due diligence, there should be the following:\n\n1. Show the distribution of computing thresholds from the CI.  Then compute, for a CI of 0.8, 0.9, etc., what is the effective threshold on average? Then for every *average threshold* from the CI method, apply that as a static threshold. Then you will get exactly the delta of your method over the static threshold method.\n\n2. Do the same, but using the pairwise CI comparison method. \n\n3. The same again, but now show how effective this is as a function of the size of the output label space.  E.g. add these numbers to Table 1 and Table 2 (for every ""our adaptive ensemble"", put the equivalent static threshold.)\n\n4. Implement the CI computation efficiently if you are going to report actual runtimes. Note that for a paper like this, I don\'t think the runtimes are as important as the # of evaluations in the ensemble, so this is less important.\n\n- With the above experiments I think this would be a good paper.', 'Summary\n\nThe authors argue that ensemble prediction takes too much computation time and resource, especially in the case of deep neural networks. They then address the problem by proposing an adaptive prediction approach. The approach is based on the observation that it is most important for ensemble approaches to focus on the ""uncertain"" examples. The proposed approach thus conducts early-stopping prediction when the confidence (certainty) of the prediction is high enough, where the confidence is based on the confidence intervals of (multi-class) labels based on the student-t distribution. Experiments on vision datasets demonstrate that the proposed approach is effective in reducing computation resources while maintaining sufficient accuracy.\n\nComments\n\n* The experiments are limited in the scope of (image) multi-class classification. It is not clear whether the proposed approach is effective for other classification tasks, or even more sophisticated tasks like multi-label classification or sequence tagging.\n* The idea appears elegant but rather straightforward. One important baseline that is easy but not discussed is to set a static threshold on pairwise comparison (p_max - p_secondmax). Would this baseline be competitive with the proposed approach? Such a comparison is able to demonstrate the benefits of using confidence interval.\n* The overall improvement in computation time seems to be within a constant scale, which can be easily achieved by doing ensemble prediction in parallel (note that the proposed approach would require predicting sequentially). So are there real applications that can benefit from the improvement?\n* typo: p4, line19, neural ""netowkrs"" -> neural ""networks""\n']","[50, -20, -20]","[75, 20, 50]","[""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the paper's originality, convincing experiments, and potential benefits of the proposed method. However, they also point out a weakness regarding the comparison with existing ensemble pruning techniques. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They use phrases like 'generally well written' and 'convincing experiments' to soften their critique. The mention of easily correctable spelling mistakes is presented neutrally without harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges a 'nice simple idea at its core', they express several major concerns and state that the paper is not 'fully developed'. They point out conceptual issues and suggest that the experiments 'don't really add much value'. However, the reviewer does provide constructive feedback and suggests ways to improve the paper, which prevents the score from being more negative. The politeness score is slightly positive (20) as the reviewer maintains a professional tone throughout, uses phrases like 'I don't think' instead of more assertive language, and provides detailed suggestions for improvement. The reviewer also acknowledges positive aspects ('nice simple idea') before critiquing. However, some direct statements like 'That is a huge knock against this paper' prevent the score from being higher."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the work ('experiments demonstrate that the proposed approach is effective'), they also raise several critical points and limitations. The review points out limited scope, questions the novelty of the approach, and challenges the practical applicability of the improvements. These criticisms outweigh the positive aspects, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer uses neutral, professional language throughout. They offer constructive criticism without harsh or dismissive language, and even point out a typo in a helpful manner. The tone is academic and respectful, maintaining a balance between critique and acknowledgment of the work's merits.""]"
"['The authors propose to tackle the tree transduction learning problem using recursive NN architectures: the prediction of a node label is conditioned on the ancestors sequence and the nodes in the left sibling subtree  (in a serialized order)\nPros:\n- they identify the issue of locality as important (sequential serialization distorts locality) and they move the architecture closer to the tree structure of the problem\n- the architecture proposed moves the bar forward in the tree processing field\nCons: \n- there is still a serialization step (depth first) that can potentially create sharp dips to null probabilities for marginal changes in the conditioning sequence (the issue is not addressed or commented by the authors) \n- the experimental setup lacks a perturbation test: rather than a copy task, it would be of greater interest to assess the capacity to recover from noise in the labels (as the noise magnitude increases)\n- a clearer and more articulated comparison of the pros/cons w.r.t. competitive architectures would improve the quality of the work: what are the properties (depth, vocabulary size, complexity of the underlying generative process, etc) that are best dealt with by the proposed approach? \n- it is not clear if the is the vocabulary size in their model needs to increase exponentially with the tree depth: a crucial vocabulary size  vs performance experiment is missing\n', 'There may be some interesting ideas here, but I think in many places the mathematical\ndescription is very confusing and/or flawed. To give some examples:\n\n* Just before section 2.1.1, P(T) = \\prod_{p \\in Path(T)} ... : it\'s not clear \nat all clear that this defines a valid distribution over trees. There is an\nimplicit order over the paths in Path(T) that is simply not defined (otherwise\nhow for x^p could we decide which symbols x^1 ... x^{p-1} to condition\nupon?)\n\n* ""We can write S -> O | v | \\epsilon..."" with S, O and v defined as sets.\nThis is certainly non-standard notation, more explanation is needed.\n\n* ""The observation is generated by the sequence of left most \nproduction rules"". This appears to be related to the idea of left-most\nderivations in context-free grammars. But no discussion is given, and\nthe writing is again vague/imprecise.\n\n* ""Although the above grammar is not, in general, context free"" - I\'m not\nsure what is being referred to here. Are the authors referring to the underlying grammar,\nor the lack of independence assumptions in the model? The grammar\nis clearly context-free; the lack of independence assumptions is a separate\nissue.\n\n* ""In a probabilistic context-free grammar (PCFG), all production rules are\nindependent"": this is not an accurate statement, it\'s not clear what is meant\nby production rules being independent. More accurate would be to say that\nthe choice of rule is conditionally independent of all other information \nearlier in the derivation, once the non-terminal being expanded is\nconditioned upon.\n\n', 'The paper introduces a neural tree decoder architecture for binary trees that conditions the next node prediction on \nrepresentations of its ascendants (encoded with an LSTM recurrent net) and left sibling subtree (encoded with a binary LSTM recursive net) for right sibling nodes.     \nTo perform tree to tree transduction the input tree is encoded as a vector with a Tree LSTM; correspondences between input and output subtrees are not modelled directly (using e.g. attention) as is done in traditional tree transducers. \nWhile the term context-sensitive should be used with caution, I do accept the claim here, although the notation used does not make the exposition clear. \nExperimental results show that the architecture performs better at synthetic tree transduction tasks (relabeling, reordering, deletion) than sequence-to-sequence baselines. \n\nWhile neural approches to tree-to-tree transduction is an understudied problem, the contributions of this paper are very narrow and it is not shown that the proposed approach will generalize to more expressive models or real-world applications of tree-to-tree transduction. \nExisting neural tree decoders, such as Dong and Lapata or Alvarex-Melis and Jaakkola, could be combined with tree LSTM encoders without any technical innovations and could possibly do as well as the proposed model for the transduction tasks tested - no experiments are performed with existing tree-based decoder architectures. \n\nSpecific comments per section:\n\n1. Unclear what is meant be ""equivalent"" in first paragraph. \n2. The model does not assign an explicit probability to the tree structure - rather it seems to rely on the distinction between terminal and non-terimal symbols and the restriction to binary trees to know when closing brackets are implied - this is not made clear, and a general model should not have this restriction, as there are many cases where we want to generate non-binary trees.\nThe production rule notation used is incorrect and confusing, mixing sets with non-terminals and terminal symbols: \nA better notation for the rules in 2.1.1 would be something like S -> P | v | \\epsilon; P -> Q R | Q u | u Q | u w, where P, Q, R \\in O and u, w \\in v.\n2.1.2. Splitting production rules as ->_left, ->_right is not standard notation. Rather introduce intermediate non-terminals in the grammar:\nO -> O_L O_R; O_L -> a | Q, O_R -> b | Q. \n2.1.3 The context-sensitively here arise when conditioning on the entire left sibling subtree (not just the top non-terimal).\nThe rules should have a format such as O -> O_L O_R; O_L -> a | Q; \\alpha O_R -> \\alpha a | \\alpha Q, where \\alpha is an entire subtree rooted at O_L.\n2.1.4 Should be g(x|.) = exp( ), the softmax function includes the normalization which is done in the equation below. \n\n3. Note that is is possible to restrict the decoder to produce tree structures while keeping a sequential neural architecture. For some tasks sequential decoders do actually produce mostly well-formed trees, given enough training data. \nRNNG encodes completed subtrees recursively, and the stack LSTM encodes the entire partially-produced tree, so it does produce and condition on trees not just sequences. The model in this paper is not more expressive than RNNG, it just encodes somewhat different structural biases, which might or might not be suited for real tasks.  \n\n4. In the examples given, the same set of symbols are used as both terminals and non-terminals. How is the tree structure then predicted by the decoder?\nDetails about the training setup are missing: How is the training data generated, what is the size of the trees during training (compared to testing)?\n4.2 The steep drop in performance between depth 5 and 6 indicates that model is very sensitive to its memorization capacity and might not be generalizing over the given training data.\nFor real tree-to-tree applications involving these operations, there is good reason to believe that some kind of attention mechanism will be needed over the input tree during decoding. \n\nReference should generally be to published proceedings rather than to arxiv where available - e.g. Aharoni and Goldberg, Dong and Lapata, Erguchi et al, Rush et al. For Graehl and Knight there is a published journal paper in Computational Linguistics.']","[20, -70, -30]","[50, -20, 20]","[""The sentiment score is slightly positive (20) because the review starts with acknowledging the authors' contribution and lists some pros before moving on to the cons. The reviewer recognizes the importance of the work and its advancement in the field. However, the score is not higher due to the significant number of cons and suggestions for improvement. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents both pros and cons in a balanced manner. They offer constructive criticism without using harsh or dismissive language. The reviewer suggests improvements rather than outright criticizing, which contributes to the polite tone. The absence of personal attacks or overly negative language also supports this score."", ""The sentiment score is -70 because the review is predominantly negative, pointing out multiple flaws and confusing aspects of the paper. The reviewer states that 'there may be some interesting ideas here,' which prevents the score from being even lower. However, the repeated use of phrases like 'very confusing and/or flawed,' 'not clear at all,' 'non-standard notation,' 'vague/imprecise,' and 'not an accurate statement' indicate a strongly negative sentiment towards the paper's content and presentation. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite blunt and critical. The reviewer doesn't soften their criticisms or offer much encouragement, which comes across as somewhat impolite in academic discourse. However, the use of phrases like 'I think' and 'I'm not sure' slightly mitigates the harshness, preventing an even lower score."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'performs better at synthetic tree transduction tasks'), the overall tone is critical. The reviewer states that the contributions are 'very narrow' and questions the generalizability and novelty of the approach. The politeness score is 20 because the reviewer uses professional language and offers specific, constructive feedback. They avoid harsh language, instead using phrases like 'should be used with caution' and 'it is not shown that'. However, the critique is direct and doesn't use many softening phrases, preventing a higher politeness score.""]"
"['Summary: The authors propose a method for explaining why neural networks make mistakes by learning how to modify an image on a mistaken classification to make it a correct classification. They do this by perturbing the image in an encoded latent space and then reconstructing the perturbed image.  The explanation is the difference between the reconstructed perturbed encoded image and the reconstructed original encoded image.\n\nThe title is too general as this paper only offers an explanation in the area of image classification, which by itself, is still interesting.  \n\nA method for explaining the results of neural networks is still open ended and visually to the human eye, this paper does offer an explanation of why the 8 is misclassified. However, if this works very well for MNIST, more examples should be given. This single example is interesting but not sufficient to illustrate the success of this method.  \n\nThe examples from CelebA are interesting but inconclusive. For example, why should adding blue to the glasses fix the misclassification. If the explanation is simply visual for a human, then this explanation does not suffice. And the two examples with one receding and the other not receding hairlines look like their correct classifications could be flipped.\n\nRegarding epsilon, it is unclear what a small euclidean distance for epsilon is without more examples. It would also help to see how the euclidean distance changes along the path.  But also it is not clear why we care about the size of epsilon, but rather the size of the perturbation that must be made to the original image, which is what is defined in the paper as the explanation. \n\nSince it is the encoded image that is perturbed, and this is what causes the perturbations to be selective to particular features of the image, an analysis of what features in the encoded space that are modified would greatly help in the interpretability of this explanation. The fact that perturbations are made in the latent space, and that this perturbation gets reflected in particular areas in the reconstructed image, is the most interesting part of this work.  More discussion around this would greatly enhance the paper, especially since the technical tools of this method are not very strong.\n\nPros: Interesting explanation, visually selects certain parts of the image relevant to classification rather than obscure pixels\n\nCons: No discussion or analysis about the latent space where perturbations occur. Only one easy example from MNIST shown and examples on CelebA are not great. No way (suggested) to use this tool outside of image recognition. ', 'This paper proposes a method for explaining the classification mistakes of neural networks. For a misclassified image, gradient descent is used to find the minimal change to the input image so that it will be correctly classified. \n\nMy understanding is that the proposed method does not explain why a classifier makes mistakes. Instead, it is about: what can be added/removed from the input image so that it can be correctly classified. Strictly speaking, ""Explaining the Decisions of Neural Networks"" is not the most relevant title for the proposed method. \n\nBased on my understanding about what the paper proposes, I am not sure how useful this method is, from the application point of view. It is unclear to me how this method can shed light to the mistakes of a classifier. \n\nThe technical aspects of the paper are straight forward optimization problem, with a sensible formulation and gradient descent optimization problem. There is nothing extraordinary about the proposed technique. \n\nThe method assumes the availability of a generative model, VAE. The implicit assumption is that this VAE performs well, and it raises a concern about the application domains where VAE does not work well. In this case, would the visualization reflect the shortcoming of VAE or the mistake of the classifier? \n', 'In this paper, the authors aim to better understand the classification of neural networks. The authors explore the latent space of a variational auto encoder and consider the perturbations of the latent space in order to obtain the correct classification. They evaluate their method on CelebA and MNIST datasets.\n\nPros:\n\n 1) The paper explores an alternate methodology that uses perturbation in latent spaces to better understand neural networks \n2) It takes inspiration from adversarial examples and uses the explicit classifier loss to better perturb the $z$ in the latent space\n3) The method is quite simple and captures the essence of the problem well\n\nCons:\nThe main drawback of the paper is it claims to understand working of neural networks, however, actually what the authors end up doing are perturbations of the encoded latent space. This would evidently not explain why a deep network generates misclassifications for instance understanding the failure modes of ResNet or DenseNet cannot be obtained through this method. Other drawbacks include:\n\n1)     They do not show how their method would perform against standard adversarial attack techniques, since by explaining a neural network they should be able to guard against attacks, or at-least explain why they work well. \n2) The paper reports results on 2 datasets, out of which on 1 of them it does not perform well and gets stuck in a local minima therefore implying that it is not able to capture the diversity in the data well. \n\n3) The authors provide limited evaluation on a few attributes of CelebA. Extensive evaluation that would show on a larger scale with more attributes is not performed.\n\n4) The authors also have claimed that the added parts should be interpretable and visible. However, the perturbations of the latent space would yield small $\\epsilon$ variation in the image and it need not actually explain why the modification is yielding a correct classification, the same way an imperceptible adversarial attack yields a misclassification. Therefore there is no guarantee that the added parts would be interpretable. What would be more reasonable to claim would be that the latent transformations that yield correct classifications are projected into the original image space. Some of these yield interpretations that are semantically meaningful and some of these do not yield semantically meaningful interpretations.\n\n5)  Solving mis-classification does not seem to equate with explaining the neural network, but rather only suggest where it makes mistakes. That is not equal to an explanation about how it is making a classification decision. That would rather be done by using the same input and perturbing the weights of the classifier network. \n\nIn conclusion, the paper in its current form provides a direction in terms of using latent space exploration to understand classification errors and corrections to them in terms of perturbations of the latent space. However, these are not conclusive yet and actually verifying this would need a more thorough evaluation.']","[-20, -50, -20]","[50, 20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the work, they also point out several significant limitations and areas for improvement. The review begins with a neutral summary and mentions some positive aspects ('interesting explanation', 'visually selects certain parts of the image'), but the majority of the review focuses on criticisms and shortcomings of the paper. The politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and balance criticisms with acknowledgments of the paper's strengths. The language used is respectful and avoids harsh or dismissive statements, instead framing concerns as areas for potential enhancement or clarification."", ""The sentiment score is -50 because the reviewer expresses several concerns and doubts about the paper's usefulness and relevance, without offering much positive feedback. They question the title's appropriateness, the method's utility, and its ability to explain classifier mistakes. However, it's not entirely negative as they acknowledge the technical aspects as 'straight forward' and 'sensible'. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and non-confrontational manner. They use phrases like 'My understanding is...' and 'I am not sure...' which soften the criticism. The language is generally neutral and objective, avoiding harsh or rude expressions, but also not overtly polite or complimentary."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the paper, they list more cons and express significant reservations about the paper's claims and methodology. The review concludes that the paper's findings are 'not conclusive yet' and need 'more thorough evaluation'. The politeness score is moderately positive (60) because the reviewer uses professional and respectful language throughout, acknowledging the paper's strengths before detailing its weaknesses. They use phrases like 'the authors aim to' and 'the paper explores' rather than direct criticisms, and conclude with constructive suggestions for improvement rather than outright dismissal.""]"
"['This paper focuses on enhancing the transferability of adversarial examples from one model to another model. The main contribution of this paper is to factorize the adversarial perturbation direction into model-specific and data-dependent. Motivated by finding the data-dependent direction, the paper proposes the noise reduced gradient method. \n\nThe paper is not mature. The authors need to justify their arguments in a more rigorous way, like why data-dependent direction can be obtained by averaging; is it true factorization of the perturbation direction? i.e. is the orthogonal direction is indeed model-specific? most of explanations are not rigorous and kind of superficial.\n\n\n', 'This paper postulates that an adversarial perturbation consists of a model-specific and data-specific component, and that amplification of the latter is best suited for adversarial attacks.\n\nThis paper has many grammatical errors. The article is almost always missing from nouns. Some of the sentences need changing. For example:\n\n""training model paramater""  --> ""training model parameters"" (assuming the neural networks have more than 1 parameter)\n""same or similar dataset with"" --> ""same or a similar dataset to""\n""human eyes"" --> ""the human eye""!\n""in analogous to"" --> ""analogous to""\n""start-of-the-art"" --> ""state-of-the-art""\n\nSome roughly chronological comments follow:\n\nIn equation (1) although it is obvious that y is the output of f, you should define it. As you are considering the single highest-scoring class, there should probably be an argmax somewhere.\n\n""The best metric should be human eyes, which is unfortunately difficult to quantify"". I don\'t recommend that you quantify things in terms of eyes.\n\nIn section 3.1 I am not convinced there is yet sufficient justification to claim that grad(f||)^A is aligned with the inter-class deviation. It would be helpful to put equation (8) here. The ""human"" line on figure 1a doesn\'t make much sense. By u & v in the figure 1 caption you presumably the x and y axes on the plot. These should be labelled.\n\nIn section 4 you write ""it is meaningless to construct adversarial perturbations for the images that target models cannot classify correctly"". I\'m not sure this is true. Imagenet has a *lot* of dog breeds. For an adversarial attack, it may be advantageous to change the classification from ""wrong breed of dog"" to ""not a dog at all"".\n\nSomething that concerns me is that, although your methods produce good results, it looks like the hyperparameters are chosen so as to overfit to the data (please do correct me if this is not the case). A better procedure would be to split the imagenet validation set in two and optimise the hyperparameters on one split, and test on the second. You also ""try lots of \\alphas"", which again seems like overfitting.\n\nTarget attack experiments are missing from 5.1, in 5.2 you write that it is a harder problem so it is omitted. I would argue it is still worth presenting these results even if they are less flattering.\n\nSection 6.2 feels out of place and disjointed from the narrative of the paper.\n\nA lot of choices in Section 6 feel arbitrary. In 6.3, why is resnet34 the chosen source model? In 6.4 why do you select those two target models?\n\nI think this paper contains an interesting idea, but suffers from poor writing and unprincipled experimentation. I therefore recommend it be rejected.\n\nPros:\n- Promising results\n- Good summary of adversarial methods\n\nCons:\n-  Poorly written\n-  Appears to overfit to the test data\n', 'The problem of exploring the cross-model (and cross-dataset) generalization of adversarial examples is relatively neglected topic. However the paper\'s list of related work on that toopic is a bit lacking as in section 3.1 it omits referencing the ""Explaining and Harnessing..."" paper by Goodfellow et al., which presented the first convincing attempt at explaining cross-model generalization of the examples.\n\nHowever this paper seems to extend the explanation by a more principled study of the cross-model generalization. Again Section 3.1. presents a hypothesis on splitting the space of adversarial perturbations into two sub-manifolds. However this hypothesis seems as a tautology as the splitting is engineered in a way to formally describe the informal statement. Anyways, the paper introduces a useful terminology to aid analysis and engineer examples with improved generalization across models.\n\nIn the same vain, Section 3.2 presents another hypothesis, but is claimed as fact. It claims that the model-dependent component of adversarial examples is dominated by images with high-frequency noise. This is a relatively unfounded statement, not backed up by any qualitative or quantitative evidence.\n\nMotivated by the observation that most newly generated adversarial examples are perturbations by a high frequency noise and that noise is often model-specific (which is not measured or studied sufficiently in the paper), the paper suggests adding a noise term to the FGS and IGSM methods and give extensive experimental evidence on a variety of models on ImageNet demonstrating that the transferability of the newly generated examples is improved.\n\nI am on the fence with this paper. It certainly studies an important,  somewhat neglected aspect of adversarial examples, but mostly speculatively and the experimental results study the resulting algorithm rather than trying trying the verify the hypotheses on which those algorithms are based upon.\n\nOn the plus side the paper presents very strong practical evidence that the transferability of the examples can be enhanced by such a simple methodology significantly.\n\nI think the paper would be much more compelling (are should be accepted) if it contained a more disciplined study on the hypotheses on which the methodology is based upon.']","[-50, -60, -20]","[0, -20, 50]","[""The sentiment score is -50 because the review starts with a neutral description of the paper's focus and contribution, but then states that 'The paper is not mature' and points out several areas where the authors need to improve their arguments and explanations. This indicates a negative sentiment, though not extremely harsh. The politeness score is 0 (neutral) because the reviewer uses direct language without being overtly polite or rude. They state their criticisms plainly, using phrases like 'The authors need to justify' and 'most of explanations are not rigorous', which are neither particularly polite nor impolite, but rather professional and straightforward."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer recommends rejection, points out numerous grammatical errors, and expresses concerns about overfitting and arbitrary choices. While they acknowledge 'promising results' and a 'good summary', these positives are outweighed by the criticisms. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism ('Poorly written') and sarcasm ('I don't recommend that you quantify things in terms of eyes'). The reviewer also uses direct language like 'I'm not sure this is true' and 'Something that concerns me', which, while not overtly rude, lacks the softening language typical of more polite academic discourse."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and the strong practical evidence presented, they express significant reservations about the paper's methodology and lack of rigorous verification of hypotheses. The reviewer is 'on the fence' and suggests substantial improvements before acceptance. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and offers constructive criticism. They avoid harsh or dismissive language, instead using phrases like 'I think the paper would be much more compelling if...' which maintains a polite and professional tone.""]"
"['This paper presents a solid empirical analysis of a simple idea for learning embeddings of time series: training a convolutional network with a custom pooling layer that generates a fixed size representation to classify time series, then use the fixed size representation for other tasks. The primary innovation is a custom pooling operation that looks at a fraction of a sequence, rather than a fixed window. The experiments are fairly thorough (albeit with some sizable gaps) and show that the proposed approach outperforms DTW, as well as embeddings learned using Siamese networks. On the whole, I like the line of inquiry and the elegant simplicity of the proposed approach, but the paper has some flaws (and there are some gaps in both motivation and the experiments) that led me to assign a lower score. I encourage the authors to address these flaws as much as possible during the review period. If they succeed in doing so, I am willing to raise my score.\n\nQUALITY\n\nI appreciate this line of research in general, but there are some flaws in its motivation and in the design of the experiments. Below I list strengths (+) and weaknesses (-):\n\n+ Time series representation learning is an important problem with a large number of real world applications. Existing solutions are often computationally expensive and complex and fail to generalize to new problems (particularly with irregular sampling, missing values, heterogeneous data types, etc.). The proposed approach is conceptually simple and easy to implement, faster to train than alternative metric learning approaches, and learns representations that admit fast comparisons, e.g., Euclidean distance.\n+ The experiments are pretty thorough (albeit with some noteworthy gaps) -- they use multiple benchmark data sets and compare against strong baselines, both traditional (DTW) and deep learning (Siamese networks).\n+ The proposed approach performs best on average!\n\n- The custom pooling layer is the most interesting part and warrants additional discussion. In particular, the ""naive"" approach would be to use global pooling over the full sequence [4]. The authors should advance an argument to motivate %-length pooling and perhaps add a global pooling baseline to the experiments.\n- Likewise, the authors need to fully justify the use of channel-wise (vs. multi-channel) convolutions and perhaps include a multi-channel convolution baseline.\n- There is something incoherent about training a convolutional network to classify time series, then discarding the classification layer and using the internal representation as input to a 1NN classifier. While this yields an apples-to-apples comparison in the experiments, I am skeptical anyone would do this in practice. Why not simply use the classifier (I am dubious the 1NN would outperform it)? To address this, I recommend the authors do two things: (1) report the accuracy of the learned classifier; (2) discuss the dynamic above -- either admit to the reader that this is a contrived comparison OR provide a convincing argument that someone might use embeddings + KNN classifier instead of the learned classifier. If embeddings + KNN outperforms the learned classifier, that would surprise me, so that would warrant some discussion.\n- On a related note, are the learned representations useful for tasks other than the original classification task? This would strengthen the value proposition of this approach. If, however, the learned representations are ""overfit"" to the classification task (I suspect they are), and if the learned classifier outperforms embeddings + 1NN, then what would I use these representations for?\n- I am modestly surprised that this approach outperformed Siamese networks. The authors should report the Siamese architectures -- and how hyperparameters were tuned on all neural nets -- to help convince the reader that the comparison is fair.\n- To that end, did the Siamese convolutional network use the same base architecture as the proposed classification network (some convolutions, custom pooling, etc.)? If not, then that experiment should be run to help determine the relative contributions of the custom pooling layer and the loss function.\n- Same notes above re: triplet network -- the authors should report results in Table 2 and disclose architecture details.\n- A stronger baseline would be a center loss [1] network (which often outperforms triplets).\n- The authors might consider adding at least one standard unsupervised baseline, e.g., a sequence-to-sequence autoencoder [2,3].\n\nCLARITY\n\nThe paper is clearly written for the most part, but there is room for improvement:\n\n- The %-length pooling requires a more detailed explanation, particularly of its motivation. There appears to be a connection to other time series representations that downsample while preserving shape information -- the authors could explore this. Also, they should add a figure with a visual illustration of how it works (and maybe how it differs from global pooling), perhaps using a contrived example.\n- How was the %-length pooling implemented? Most deep learning frameworks only provide pooling layers with fixed length windows, though I suspect it is probably straightforward to implement variable-width pooling layers in an imperative framework like PyTorch.\n- Figure 1 is not well executed and probably unnecessary. The solid colored volumes do not convey useful information about the structure of the time series or the neural net layers, filters, etc. Apart from the custom pooling layer, the architecture is common and well understood by the community -- thus, the figure can probably be removed.\n- The paper needs to fully describe neural net architectures and how hyperparameters were tuned.\n\nORIGINALITY\n\nThe paper scores low on originality. As the authors themselves point out, time series metric learning -- even using deep learning -- is an active area of research. The proposed approach is refreshing in its simplicity (rather than adding additional complexity on top of existing approaches), but it is straightforward -- and I suspect it has been used previously by others in practice, even if it has not been formally studied. Likewise, the proposed %-length pooling is uncommon, but it is not novel per se (dynamic pooling has been used in NLP [5]). Channel-wise convolutional networks have been used for time series classification previously [6].\n\nSIGNIFICANCE\n\nAlthough I identified several flaws in the paper\'s motivation and experimental setup, I think it has some very useful findings, at least for machine learning practitioners. Within NLP, there appears to be gradual shift toward using convolutional, instead of recurrent, architectures. I wonder if papers like this one will contribute toward a similar shift in time series analysis. Convolutional architectures are typically much easier and faster to train than RNNs, and the main motivation for RNNs is their ability to deal with variable length sequences. Convolutional architectures that can effectively deal with variable length sequences, as the proposed one appears to do, would be a welcome innovation.\n\nREFERENCES\n\n[1] Wen, et al. A Discriminative Feature Learning Approach for Deep Face Recognition. ECCV 2016.\n[2] Fabius and van Amersfoort. Variational Recurrent Auto-Encoders. ICLR 2015 Workshop Track.\n[3] Tikhonov and Yamshchikov. Music generation with variational recurrent autoencoder supported by history. arXiv.\n[4] Hertel, Phan, and Mertins. Classifying Variable-Length Audio Files with All-Convolutional Networks and Masked Global Pooling. \n[5] Kalchbrenner, Grefenstette, and Blunsom. A Convolutional Neural Network for Modelling Sentences. ACL 2014.\n[6] Razavian and Sontag. Temporal Convolutional Neural Networks for Diagnosis from Lab Tests. arXiv.', '[Summary]\n\nThe paper is overall well written and the literature review fairly up to date.\nThe main issue is the lack of novelty.\nThe proposed method is just a straightforward dimensionality reduction based on\nconvolutional and max pooling layers.\nUsing CNNs to handle variable length time series is hardly novel.\nIn addition, as always with metric learning, why learning the metric if you can just learn the classifier?\nIf the metric is not used in some compelling application, I am not convinced.\n\n[Detailed comments and suggestions]\n\n* Since ""assumptions"" is the only subsection in Section 2, \nI would use \\texbf{Assumptions.} rather than \\subsection{Assumptions}.\n\n* Same remark for Section 4.1 ""Complexity analysis"".\n\n* Some missing relevant citations:\n\nLearning the Metric for Aligning Temporal Sequences.\nDamien Garreau, Rémi Lajugie, Sylvain Arlot, Francis Bach.\nIn Proc. of NIPS 2014.\n\nDeep Convolutional Neural Networks On Multichannel Time Series For Human Activity Recognition.\nJian Bo Yang, Minh Nhut Nguyen, Phyo Phyo San, Xiao Li Li, Shonali Krishnaswamy.\nIn Proc.  of IJCAI 2015.\n\nTime Series Classification Using Multi-Channels Deep Convolutional Neural Networks\nYi ZhengQi LiuEnhong ChenYong GeJ. Leon Zhao.\nIn Proc. of International Conference on Web-Age Information Management.\n\nSoft-DTW: a Differentiable Loss Function for Time-Series.\nMarco Cuturi, Mathieu Blondel.\nIn Proc. of ICML 2017.', 'Paper proposes to use a convolutional network with 3 layers (convolutional + maxpoolong + fully connected layers) to embed time series in a new space such that an Euclidian distance is effective to perform a classification. The algorithm is simple and experiments show that it is effective on a limited benchmark. It would be interesting to enlarge the dataset to be able to compare statistically the results with state-of-the-art algorithms. In addition, Authors compare themselves with time series metric learning and generalization of DTW algorithms. It would also be interesting to compare with other types of time series classification algorithms (Bagnall 2016) .']","[20, -50, 50]","[60, 20, 50]","[""The sentiment score is slightly positive (20) because the reviewer expresses appreciation for the line of inquiry and the simplicity of the approach, stating 'I like the line of inquiry and the elegant simplicity of the proposed approach'. However, they also mention 'flaws' and 'gaps' that led to a lower score, balancing out the positive aspects. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers encouragement ('I encourage the authors to address these flaws'), and expresses willingness to reconsider their score ('I am willing to raise my score'). The review provides a balanced mix of strengths and weaknesses, using constructive criticism rather than harsh language. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback."", ""The sentiment score is -50 because the review is predominantly negative, highlighting a 'lack of novelty' and questioning the usefulness of the proposed method. However, it does acknowledge some positives like 'well written' and 'up to date literature review', preventing it from being extremely negative. The politeness score is 20 because while the reviewer maintains a professional tone and offers constructive feedback, the criticism is direct and not particularly softened. The reviewer uses phrases like 'I am not convinced' and 'hardly novel', which are honest but not overly polite. The inclusion of specific suggestions for improvement and additional citations shows a helpful intent, slightly elevating the politeness score above neutral."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the effectiveness of the proposed algorithm on a limited benchmark and suggests interesting ways to improve the study, indicating a generally positive view with some constructive criticism. The politeness score is also 50 (moderately polite) as the reviewer uses neutral language and offers suggestions in a respectful manner, using phrases like 'It would be interesting' rather than making demands. The review is constructive without being overly critical or praising, maintaining a professional and courteous tone throughout.""]"
"['This paper aims to address the deep learning architecture search problem via incremental addition and removal of channels in intermediate layers of the network. Experiments are carried out on small-scale datasets such as MNIST and CIFAR, as well as an exploratory run on ImageNet (AlexNet).\n\nOverall, I find the approach proposed in the paper interesting but a little bit thin in content. Essentially, one increases or decreases the number of features based on equation 2. It would be much valuable to see ablation studies to show the effectiveness of such criterion: for example, simple cases one can think of is to model (1) a data distribution of known rank, (2) simple MLP/CNN models to show the cross-layer relationships (e.g. sudden increase and decrease of the number of channels across layers will be penalized by c^l_{f^{l+1}, t}), etc.\n\nThe experimentation section uses small scale datasets and as a result, it is relatively unclear how the proposed approach will perform on real-world applications. One apparent shortcoming of such approach is that training takes much longer time, and the algorithm is not easily made parallel (the sgd steps limit the level of parallelization that can be carried out). As a result, I am not sure about the applicability of the proposed approach.', 'The authors propose an approach to dynamically adjust the feature map depth of a fully convolutional neural network. The work formulates a measure of self-resemblance, to determine when to stop increasing the feature dimensionality at each convolutional layer. The experimental section evaluates this method on MNIST, CIFAR-10/100 and a limited evaluation of ImageNet. Generally, I am a very big proponent of structure learning in neural networks. In particular, we have seen a tremendous boost in performance in going from feature engineering to feature learning, and thus can expect similar effects while learning architectures rather than manually designing them. One important work in this area is ""Self-informed neural network structure learning"" by Farley et al. that is missing from the citations. \nHowever, this work falls short of its promises.\n\n1. The title is misleading. There really isn\'t much discussion about the architecture of networks, but rather the dimensionality of the feature maps. These are very different concepts.\n2. Novelty of this work is also limited, as the authors acknowledge, that much of the motivation is borrowed from Hao et al., while only the expansion mechanism is now normalized to avoid rescaling issues and threshold tuning.\n3. The general approach lacks global context. All decisions about individual feature depths are made locally both temporally and spatially. In particular, expanding the feature depth at layer f at time t, may have non trivial effect on layer f-1 at time t + 1. In other words, there must be some global state-space manifold to help make decisions globally. This resembles classical dynamic programming paradigms. Local decisions aren\'t always globally optimal.\n4. Rather than making decision on per layer basis at each iteration, one should wait for the model to converge, and then determine what is useful and what is not.\n5. Finally, the results are NOT promising. In table 1, although the final error has reduced in most cases, it comes at the expense of increases capacity, in extreme cases as much as ~5x, and always at the increased training time, in the extreme case ~14x, An omitted citation of ""Going deeper with Convolution"" is an example, where a much smaller footprint leads to a higher performance, further underlying the importance of a smaller footprint network as stated in the abstract.\n\n', 'This paper introduces a simple correlation-based metric to measure whether filters in neural networks are being used effectively, as a proxy for effective capacity. The authors then introduce a greedy algorithm that expands the different layers in a neural network until the metric indicates that additional features will end up not being used effectively.\n\nThe application of this algorithm is shown to lead to architectures that differ substantially from hand-designed models with the same number of layers: most of the parameters end up in intermediate layers, with fewer parameters in earlier and later layers. This indicates that common heuristics to divide capacity over the layers of a network are suboptimal, as they tend to put most parameters in later layers. It\'s also nice that simpler tasks yield smaller models (e.g. MNIST vs. CIFAR in figure 3).\n\nThe experimental section is comprehensive and the results are convincing. I especially appreciate the detailed analysis of the results (figure 3 is great). Although most experiments were conducted on the classic benchmark datasets of MNIST, CIFAR-10 and CIFAR-100, the paper also includes some promising preliminary results on ImageNet, which nicely demonstrates that the technique scales to more practical problems as well. That said, it would be nice to demonstrate that the algorithm also works for other tasks than image classification.\n\nI also like the alternative perspective compared to pruning approaches, which most research seems to have been focused on in the past. The observation that the cross-correlation of a weight vector with its initial values is a good measure for effective filter use seems obvious in retrospect, but hindsight is 20/20 and the fact is that apparently this hasn\'t been tried before. It is definitely surprising that a simple method like this ends up working this well.\n\nThe fact that all parameters are reinitialised whenever any layer width changes seems odd at first, but I think it is sufficiently justified. It would be nice to see some comparison experiments as well though, as the intuitive thing to do would be to just keep the existing weights as they are.\n\nOther remarks:\n\nFormula (2) seems needlessly complicated because of all the additional indices. Maybe removing some of those would make things easier to parse. It would also help to mention that it is basically just a normalised cross-correlation. This is mentioned two paragraphs down, but should probably be mentioned right before the formula is given instead.\n\npage 6, section 3.1: ""it requires convergent training of a huge architecture with lots of regularization before complexity can be introduced"", I guess this should be ""reduced"" instead of ""introduced"".']","[-20, -60, 80]","[50, 20, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer finds the approach 'interesting', they also describe it as 'a little bit thin in content' and express concerns about its applicability and performance on real-world applications. They suggest additional studies and point out shortcomings, indicating a somewhat critical view. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, such as 'I find the approach interesting' and 'It would be much valuable to see'. They express criticisms in a constructive manner, suggesting improvements rather than outright dismissing the work. The tone is professional and respectful, even when pointing out limitations."", ""The sentiment score is -60 because the review is predominantly negative. While the reviewer initially expresses support for the general concept of structure learning in neural networks, they quickly state that 'this work falls short of its promises.' The reviewer then lists five major criticisms, including a misleading title, limited novelty, lack of global context, questionable decision-making process, and unimpressive results. These criticisms significantly outweigh the initial positive comments.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout, avoiding personal attacks or harsh language. They use phrases like 'I am a very big proponent of' and 'Generally, I am a very big proponent of' which add a positive, supportive tone. However, the criticism is direct and unambiguous, without much softening language, which prevents the score from being higher. The use of capitalization in 'NOT promising' could be seen as slightly impolite, but overall the language remains professional."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper's contributions, methodology, and results. They use phrases like 'comprehensive', 'convincing', 'I especially appreciate', and 'I like', indicating a very positive view. The reviewer also notes that the work is novel and surprising in a good way. The score is not 100 because there are some suggestions for improvement, albeit minor ones. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively. They offer constructive criticism in a gentle manner, using phrases like 'it would be nice to' rather than demanding changes. The tone is professional and courteous throughout, without being overly formal or effusive.""]"
"['Summary\n*******\nThe paper provides a collection of existing results in statistics.\n\nComments\n********\nPage 1: references to Q-learning and Policy-gradients look awkwardly recent, given that these have been around for several decades.\n\nI dont get what is the novelty in this paper. There is no doubt that all the tools that are detailed here are extremely useful and powerful results in mathematical statistics. But they are all known.\n\nThe Gibbs variational principle is folklore, Proposition 1,2 are available in all good text books on the topic, \nand Proposition 4 is nothing but a transportation Lemma.\nNow, Proposition 3 is about soft-Bellman operators. This perhaps is less standard because contraction property of soft-Bellman operator in infinite norm is more recent than for Bellman operators.\nBut as mentioned by the authors, this is not new either. \nAlso I don\'t really see the point of providing the proofs of these results in the main material, and not for instance in appendix, as there is no novelty either in the proof techniques.\n\nI don\'t get the sentence ""we have restricted so far the proof in the bandit setting"": bandits are not even mentioned earlier.\n\nDecision\n********\nI am sorry but unless I missed something (that then should be clarified) this seems to be an empty paper: Strong reject.', 'This paper uses a well-known variational representation of the relative entropy (the so-called Donsker-Varadhan formula) to derive an expression for the Bellman error with entropy regularization in terms of a certain log-partition function. This is stated in Equation (13) in the paper. However, this precise representation of the Bellman error (with costs instead of rewards and with minimization instead of maximization) has been known in the literature on risk-sensitive control, see, e.g., P. D. Pra, L. Meneghini, and W. J. Runggaldier, “Connections between stochastic control and dynamic games,” Math. Control Signals Systems, vol. 9, pp. 303–326, 1996. The same applies to contraction results for the ""softmax"" Bellman operator -- these results are not novel at all, see, e.g., D. Hernandez-Hernandez and S. I. Marcus, “Risk sensitive control of Markov processes in countable state space,” Systems and Control Letters, vol. 29, pp. 147–155, 1996.\n\nAlso, there are some errors in the paper: for example, the functional of $\\pi(a|s)$ in Eq. (2) is concave, not convex, since the expression for the Shannon entropy in Eq. (3) has the wrong sign.', 'Clarity: The paper is easy to follow and presents quite well the equivalence. \n\nOriginality: The results presented are well known and there is no clear contribution algorithmic-wise to the field of RL. The originality comes from the conciseness of the proof and how it relates to other works outside ML. Thus, this contribution seems minor and out of the scope of the conference which focus on representation learning for ML and RL.\n\nSuggestion: I strongly suggest the authors to work on a more detailed proof for the RL case explaining for instance the minimal conditions (on the reward, on the ergodicity of the MDP) in which the equivalence holds and submit it to a more theoretically oriented conference such as COLT or NIPS.   \n']","[-90, -50, -20]","[-30, 0, 50]","[""The sentiment score is -90 because the reviewer expresses strong negative sentiment throughout the review. They state that the paper seems to be 'empty', question its novelty, and conclude with a 'Strong reject' decision. The politeness score is -30 because while the reviewer maintains some level of professional language, there are instances of blunt and dismissive phrasing. For example, 'I dont get what is the novelty in this paper' and 'I am sorry but unless I missed something (that then should be clarified) this seems to be an empty paper' are rather direct and potentially offensive statements. The reviewer does use some polite language like 'I am sorry', but the overall tone is critical and somewhat harsh, particularly in the final decision statement."", ""The sentiment score is -50 because the reviewer points out that the main contributions of the paper are not novel and have been previously published in other literature. They also mention errors in the paper, which contributes to the negative sentiment. However, the reviewer does acknowledge that the paper uses a well-known formula and derives an expression, which prevents the score from being extremely negative. The politeness score is 0 (neutral) because the reviewer's language is direct and matter-of-fact, without being overtly polite or rude. They state their criticisms plainly without using harsh language, but also without softening their critique with polite phrases or compliments."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's clarity and conciseness, they express concerns about its originality and suitability for the conference. The reviewer suggests that the contribution is 'minor' and 'out of the scope of the conference'. However, it's not entirely negative as they do recognize some positive aspects. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive suggestions and avoiding harsh criticism. They use phrases like 'I strongly suggest' rather than more demanding language, and provide specific recommendations for improvement and alternative venues for submission, which is considerate and helpful.""]"
"['* This paper models images with a latent code representation, and then tries to modify the latent code to minimize changes in image space, while changing the classification label. As the authors indicate, it lies in the space of algorithms looking to modify the image while changing the label (e.g. LIME etc).\n\n* This is quite an interesting paper with a sensible goal. It seems like the method could be more informative than the other methods.  However, there are quite a number of problems, as explained below.\n\n* The explanation of eqs 1 and 2 is quite poor. \\alpha in (1) seems to be \\gamma in Alg 1 (line 5). ""L_target is a target objective which can be a negative class probability .."" this assumes that the example is a positive class. Could we not also apply this to negative examples?\n\n""or in the case of heart failure, predicted BNP level"" -- this doesn\'t make sense to me -- surely it would be necessary to target an adjusted BNP level? Also specific details should be reserved until a general explanation of the problem has been made.\n\n* The trade-off parameter \\gamma is a ""fiddle factor"" -- how was this set for the lung image and MNIST examples? Were these values different?\n\n* In typical ICLR style the authors use a deep network to learn the encoder and decoder networks. It would be v interesting (and provide a good baseline) to use a shallow network (i.e. PCA) instead, and elucidate what advantages the deep network brings.\n\n* The example of 4/9 misclassification seems very specific. Does this method also work on say 2s and 3s? Why have you not reported results for these kinds of tasks?\n\n* Fig 2: better to show each original and reconstructed image close by (e.g. above below or side-by-side).\n\nThe reconstructions show poor detail relative to the originals.  This loss of detail could be a limitation.\n\n* A serious problem with the method is that we are asked to evaluate it in terms of images like Fig 4 or Fig 8. A serious study would involve domain experts and ascertain if Fig 4 conforms with what they are looking for.\n\n* The references section is highly inadequate -- no venues of publication are given. If these are arXiv give the proper ref. Others are published in conferences etc, e.g. Goodfellow et al is in Advances in Neural Information Processing Systems 27, 2014.\n\n* Overall: the paper contains an interesting idea, but given the deficiencies raised above I judge that it falls below the ICLR threshold.\n\n* Text:\n\nsec 2 para 4. ""reconstruction loss on the validation set was similar to the reconstruction loss on the validation set."" ??\n\n* p 3 bottom -- give size of dataset\n\n* p 5 AUC curve -> ROC curve\n\n* p 6 Fig 4 use text over each image to better specify the details given in the caption.\n\n\n\n', 'The main contribution of the paper is a method that provides visual explanations of classification decisions. The proposed method uses \n - a generator trained in a GAN setup\n - an autoencoder to obtain a latent space representation\n - a method inspired by adversarial sample generation to obtain a generated image from another class - which can then be compared to the original image (or rather the reconstruction of it). \nThe method is evaluated on a medical images dataset and some additional demonstration on MNIST is provided.\n\n\n - The paper proposes a (I believe) novel method to obtain visual explanations. The results are visually compelling although most results are shown on a medical dataset - which I feel is very hard for most readers to follow. The MNIST explanations help a lot.  It would be great if the authors could come up with an additional way to demonstrate their method to the non-medical reader.\n\n - The paper shows that the results are plausible using a neat trick. The authors train their system with the testdata included which leads to very different visualizations. It would be great if this analysis could be performed for MNIST as well.\n\n\nFrom the related work, it would be nice to mention that generative models (p(x|c)) also often allow for explaining their decisions, e.g. the work by Lake and Tenenbaum on probabilistic program induction.\nAlso, there is the work by Hendricks et al on Generating Visual Explanations. This should probably also be referenced.\n\nminor comments: \n- some figures with just two parts are labeled ""from left to right"" - it would be better to just write left: ... right: ...\n- figure 2: do these images correspond to each other? If yes, it would be good to show them pairwise.\n- figure 5: please explain why the saliency map is relevant. This looks very noisy and non-interesting.\n\n', 'The authors address two important issues: semi-supervised learning from relatively few labelled training examples in the presence of many unlabelled examples, and visual rationale generation: explaining the outputs of the classifiier by overlaing a visual rationale on the original image. This focus is mainly on medical image classification but the approach could potentially be useful in many more areas. The main idea is to train a GAN on the unlabeled examples to create a mapping from a lower-dimensional space in which the input features are approximately Gaussian, to the space of images, and then to train an encoder to map the original images into this space minimizing reconstruction error with the GAN weights fixed. The encoder is then used as a feature extractor for classification and regression of targets (e.g. heard disease). The visual rationales are generated by optimizing the encoded representation to simultaneously reconstruct an image close to the original and to minimize the probability of the target class. This gives an image that is similar to the original but with features that caused the classification of the disease removed. The resulting image can be subtracted from the original encoding to highlight problematic areas. The approach is evaluated on an in-house dataset and a public NIH dataset, demonstrating good performance, and illustrative visual rationales are also given for MNIST.\n\nThe idea in the paper is, to my knowledge, novel, and represents a good step toward the important task of generating interpretable visual rationales. There are a few limitations, e.g. the difficulty of evaluating the rationales, and the fact that the resolution is fixed to 128x128 (which means discarding many pixels collected via ionizing radiation), but these are readily acknowledged by the authors in the conclusion.\n\nComments:\n1) There are a few details missing, like the batch sizes used for training (it is difficult to relate epochs to iterations without this). Also, the number of hidden units in the 2 layer MLP from para 5 in Sec 2.\n2) It would be good to include PSNR/MSE figures for the reconstruction task (fig 2) to have an objective measure of error.\n3) Sec 2 para 4: ""the reconstruction loss on the validation set was similar to the reconstruction loss on the validation set"" -- perhaps you could be a little more precise here. E.g. learning curves would be useful.\n4) Sec 2 para 5: ""paired with a BNP blood test that is correlated with heart failure"" I suspect many readers of ICLR, like myself, will not be well versed in this test, correlation with HF, diagnostic capacity, etc., so a little further explanation would be helpful here. The term ""correlated"" is a bit too broad, and it is difficult for a non-expert to know exactly how correlated this is. It is also a little confusing that you begin this paragraph saying that you are doing a classification task, but then it seems like a regression task which may be postprocessed to give a classification. Anyway, a clearer explanation would be helpful. Also, if this test is diagnostic, why use X-rays for diagnosis in the first place?\n5) I would have liked to have seen some indicative times on how long the optimization takes to generate a visual rationale, as this would have practical implications.\n6) Sec 2 para 7: ""L_target is a target objective which can be a negative class probability or in the case of heart failure, predicted BNP level"" -- for predicted BNP level, are you treating this as a probability and using cross entropy here, or \nmean squared error?\n7) As always, it would be illustrative if you could include some examples of failure cases, which would be helpful both in suggesting ways of improving the proposed technique, and in providing insight into where it may fail in practical situations.']","[-30, 50, 70]","[50, 80, 80]","[""The sentiment score is -30 because while the reviewer acknowledges the paper as 'quite interesting' with a 'sensible goal', they also point out 'quite a number of problems' and ultimately conclude it 'falls below the ICLR threshold'. This indicates a generally negative sentiment, though not extremely so. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions (e.g. 'It would be v interesting...', 'better to show...') rather than harsh criticism. They also acknowledge positive aspects before discussing issues. However, the tone remains professional rather than overtly polite, hence the moderate positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and visual appeal of the proposed method, while also providing constructive feedback for improvement. The reviewer describes the results as 'visually compelling' and praises the authors' 'neat trick' for demonstrating plausibility. However, they also suggest areas for improvement, such as adding more non-medical examples and expanding the analysis. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout. They use phrases like 'It would be great if...' and 'please explain' when making suggestions, which maintains a courteous tone. The reviewer also balances critique with praise, acknowledging the paper's strengths before suggesting improvements. The overall tone is constructive and supportive, aiming to help the authors improve their work rather than criticize it harshly."", ""The sentiment score is 70 (positive) because the reviewer acknowledges the novelty and importance of the work, praising it as 'a good step toward the important task of generating interpretable visual rationales.' They also mention that the limitations are 'readily acknowledged by the authors.' The overall tone is supportive and constructive. The politeness score is 80 (polite) due to the reviewer's respectful language throughout. They use phrases like 'it would be good to include' and 'I would have liked to have seen,' which are polite ways of suggesting improvements. The reviewer also acknowledges their own potential lack of expertise in certain areas, which is a humble and polite approach. The review provides specific, constructive feedback without using harsh or critical language, maintaining a professional and courteous tone throughout.""]"
"['This paper discusses the problem of action segmentation in long videos, up to 10 minutes long. The basic idea is to use a temporal convolutional encoder-decoder architecture, where in the enconder 1-D temporal convolutions are used. In the decoder three variants are studied:\n\n(1) One that uses only several bidirectional LSTMs, one after the other.\n(2) One that first applies successive layers of deconvolutions to produce per frame feature maps. Then, in the end a bidirectional LSTM in the last layer.\n(3) One that first applies a bidirectional LSTM, then applies successively 1-D deconvolution layer.\n\nAll variants end with a ""temporal softmax""  layer, which outputs a class prediction per frame.\n\nOverall, the paper is of rather limited novelty, as it is very similar to the work of Lea et al., 2017, where now the decoder part also has the deconvolutions smoothened by (bidirectional) LSTMs. It is not clear what is the main novelty compared to the aforementioned paper, other than temporal smoothing of features at the decoder stage.\n\nAlthough one of the proposed architectures (TricorNet) produces some modest improvements, it is not clear why the particular architectures are a good fit. Surely, deconvolutions and LSTMs can help incorporate some longer-term temporal elements into the final representations. However, to begin with, aren\'t the 1-D deconvolutions and the LSTMs (assuming they are computed dimension-wise) serving the same purpose and therefore overlapping? Why are both needed?\n\nSecond, what makes the particular architectures in Figure 3 the most reasonable choice for encoding long-term dependencies, is there a fundamental reason? What is the difference of the L_mid from the 1-D deconv layers afterward? Currently, the three variants are motivated in terms of what the Bi-LSTM can encode (high or low level details). \n\nThird, the qualitative analysis can be improved. For instance, the experiment with the ""cut lettuce"" vs ""peel cucumber"" is not persuasive enough. Indeed, longer temporal relationships can save incorrect future predictions. However, this works both ways, meaning that wrong past predictions can persist because of the long-term modelling. Is there a mechanism in the proposed approach to account for that fact?\n\nAll in all, I believe the paper indeed improves over existing baselines. However, the novelty is insufficient for a publication at this stage.', ""The paper proposed a combination of temporal convolutional and recurrent network for video action segmentation. Overall this paper is written and easy to follow.\n\nThe novelty of this paper is very limited. It just replaces the decoder of ED-TCN (Lea et al. 2017) with a bi-directional LSTM. The idea of applying bi-directional LSTM is also not new for video action segmentation. In fact, ED-TCN used it as one of the baselines. The results also do not show much improvement over ED-TCN, which is much easier and faster to train (as it is fully convolutional model) than the proposed model. Another concern is that the number of layers parameter 'K'. The authors should show an analysis on how the performance varies for different values of 'K' which I believe is necessary to judge the generalization of the proposed model. I also suggest to have an analysis on entire convolutional model (where the decoder has 1D-deconvolution) to be included in order to get a clear picture of the improvement in performance due to bi-directional LSTM . Overall, I believe the novelty, contribution and impact of this work is sub-par to what is expected for publication in ICLR. "", ""I will be upfront: I have already reviewed this paper when it was submitted to NIPS 2017, so this review is based heavily on the NIPS submission. \n\nI am quite concerned that this paper has been resubmitted as it is, word by word, character by character. The authors could have benefited from the feedback they obtained from the reviewers of their last submissions to improved their paper, but nothing has been done. Even very easy remarks, like bolding errors (see below) have been kept in the paper.\n\nThe proposed paper describes a method for video action segmentation, a task where the video must be temporally densely labeled by assigned an action (sub) class to each frame. The method proceeds by extracting frame level features using convolutional networks and then passing a temporal encoder-decoder in 1D over the video, using fully supervised training.\n\nOn the positive side, the method has been tested on 3 different datasets, outperforming the baselines (recent methods from 2016) on 2 of them.\n\nMy biggest concern with the paper is novelty. A significant part of the paper is based on reference [Lea et al. 2017], the differences being quite incremental. The frame-level features are the same as in [Lea et al. 2017], and the basic encoder-decoder strategy is also taken from [Lea et al. 2017]. The encoder is also the same. Even details are reproduced, as the choice of normalized Relu activations.\n\nThe main difference seems to me that the decoder is not convolutional, but a recurrent network.\n\nThe encoder-decoder architecture seems to be surprisingly shallow, with only K=2 layers at each side.\n\nThe paper is well written and can be easily understood. However, a quite large amount of space is wasted on obvious and known content, as for example the basic equation for a convolutional layer (equation (1)) and the following half page of text and equations of LSTM and Bi-directional LSTM networks. This is very well known and the space can be used for more details on the paper's contributions.\n\nWhile the paper is generally well written, there are a couple of exceptions in the form of ambiguous sentences, for example the lines before section 3.\n\nThere is a bolding error in table 2, where the proposed method is not state of the art (as indicated) w.r.t. to the accuracy metric.\n\nTo sum it up, the positive aspect of nicely executed experiments is contrasted by low novelty of the method.  To be honest, I am not totally sure whether the contribution of the paper should be considered as a new method or as architectural optimizations of an existing one. This is corroborated by the experimental results on the first two datasets (tables 2 and 3): on 50 salads, where ref. [Lea et al. 2017]. seems currently to obtain state of the art performance, the improvement obtained by the proposed method allows it to get state of the art performance. On GTEA, where [Lea et al. 2017] does not currently deliver state of the art performance, the proposed method performs (slightly) better than [Lea et al. 2017] but does not obtain state of the art performance.\n\nOn the third dataset, JIGSAWS, reference [Lea et al. 2017]. has not been tested, which is peculiar given the closeness.\n""]","[-50, -60, -60]","[20, 20, 20]","[""The sentiment score is -50 because the review is generally critical of the paper's novelty and contributions. The reviewer states that the paper has 'rather limited novelty' and is 'very similar' to existing work. They also mention that the 'novelty is insufficient for a publication at this stage.' However, the score is not extremely negative as the reviewer acknowledges some modest improvements over baselines. The politeness score is 20 because the reviewer maintains a professional and objective tone throughout, avoiding harsh language. They use phrases like 'I believe' and 'it is not clear' rather than making blunt criticisms. The reviewer also provides constructive feedback and specific questions for improvement, which adds to the politeness. However, the score is not extremely high as the review is still quite critical and doesn't use overtly polite language."", ""The sentiment score is -60 because the review is predominantly negative. While it starts with a mild positive comment about the paper being well-written, it quickly shifts to criticizing the paper's novelty, contribution, and impact. The reviewer states that the paper's novelty is 'very limited,' the results don't show much improvement, and overall considers the work 'sub-par' for ICLR publication. These are strong negative sentiments, though not entirely dismissive, hence the score of -60 rather than lower.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout, avoiding personal attacks or harsh language. They use phrases like 'I believe' and 'I suggest,' which soften the criticism. The reviewer also acknowledges some positive aspects (e.g., 'well written and easy to follow'). However, the politeness is relatively mild rather than overtly courteous, so the score is only slightly positive at 20."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's novelty and lack of improvements from previous submissions. They use phrases like 'quite concerned', 'low novelty', and mention that the differences from previous work are 'quite incremental'. However, they do acknowledge some positive aspects, such as outperforming baselines on 2 out of 3 datasets and the paper being well-written, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I will be upfront' and 'To be honest', which add a personal touch without being rude. They also balance criticism with positive remarks. However, the overall critical nature of the review prevents a higher politeness score.""]"
"['The paper proposes a neural net architecture that uses a predefined orthogonal binary basis to construct the filter weights of the different convolutional layers. Since only the basis weights need to be stored this leads to an exponential reduction in memory. The authors propose to compute the filter weights on the fly in order to tradeoff memory for computation time. Experiments are performed on ImageNet, MNIST, CIFAR datasets with comparisons to BinaryConnect, Binary-weight-networks and studies showing the memory vs time vs accuracy tradeoff.\n\nPositives\n- The idea of using a predefined basis to estimate filter weights in a neural network is novel and leads to significant reduction in memory usage.\n\nNegatives\n- The proposed method seems significantly worse than other binary techniques on ImageNet, CIFAR and SVHN. On Imagenet in particular binary-weight-network is 21% better at only 2x the model size. Would a binary-weight-network of the same model size be better than the proposed approach? It would help to provide results using the proposed method with the same model size as binary-weight-networks on the different datasets.  \n- The citation to binary-weight-networks is missing.\n- The descriptions in section 3.3, 3.4 need to be more rigorous. For instance, how many basis weights are needed for a filter of size N. Does N need to be a power of 2 or are extra dimentions from the basis just ignored?\n', 'This paper proposes using a set of orthogonal basis and their combination to represent convolutional kernels. To learn the set of basis,  the paper uses an existing algorithm (OSVF)\n\n-- Related Work\n\nRelated work suggests there is redundancy in the number of parameters (According to Denil et al) but the training can be done by learning a subset directly without drop in accuracy. I am not really sure this is strictly correct as many approaches (including Denil et al) suggest the additional parameters are needed to help the optimization process (therefore hard to learn directly a small model).\n\nAs in the clarity point below, please be consistent. Acronyms are not properly defined.\n\n\n-- Method / Clarity\n\nIt is nice to read section 3.1 but at the same time probably redundant as it does not add any value (at least the first two paragraphs including Eq. 1). Reading the text, it is not clear to me why there is a lower number of parameters to be updated. To the best of my understanding so far in the explanation, the number of parameters is potentially the same but represented using a single bit. Rephrasing this section would probably improve readability.\n\nRuntime is potentially reduced but not clear in current hardware.\n\nSection 3.2 is nice as short overview but happens to take more than the actual proposal (so I get lost). \n\nFigures 2 and 3. I am surprissed the FlexModule (a building block of BinaryFlex) is not mentioned in the binaryflex architecture and then, sparse blocks are not defined anywhere. Would be nice to be consistent here. Also note that filter banks among other details are not defined. \n\n\nNow, w and b in eq 2 are meant to be binary, is that correct? The text defines them as real valued so this is confusing. \n\n- From the explanations in the text, it is not clear to me how the basis and the weights are learned (except using backprop). How do we actually generate the filter bank, is this from scratch? or after some pretraining / preloaded model? What is the difference between BinaryFlex models and how do I generate them when replicating these results? It is correct to assume f_k is a pretrained kernel that is going to be approximated?\n\n\n\n\n-- more on clarity\n\n\nI would also appreciate rephrasing some parts of the paper. For instance, the paragraph under section 4.1 is confusing. There is no consistency with namings / acronyms and seems not to be in the right order. Note that the paragraph starts talking about ImageNet and then suggests different schedules for different datasets. The naming for state-of-the-art methods is not consistent. \nAlso note that acronyms are later used (such as BWN) but not defined here. This should be easy to improve.\n\nI guess Figurre 4 needs clarification. What are the axis? Why square and cercles? Same for Figure 5. \n\nOverall, text needs reviewing. There are typos all over the text. I think ImageNet is not a task but classification using ImageNet.\n\n-- Results\n\nI find it hard to follow the results. Section 4.1.1 suggests accuracy is comparable when constraints are relaxed and then only 7% drop in accuracy for a 4.5x model reduction. I have not been able to match these numbers with those in table 2. How do I get to see 7% lower accuracy for BinaryFlex-1.6? \n\nResults suggest a model under 2MB is convenient for using in ARM, is this actually a fact (is it tested in an ARM?) or just guessing? This is also a point made in the introduction and I would expect at least an example of running time there (showing the benefit compared to competitors). It is also interesting the fact that in the text, the ARM is said to have 512KB while in the experiments there is no model achieving that lower-bound.\n\nI would like to see an experiment on ImageNet where the proposed BinaryFlex leads to a model of approximately 7.5MB and see what the preformance is for that model (so comparable in size with the state-of-the-art).\n\nI missed details for the exact implementation for the other datsets (as said in the paper). There are modifications that are obscure and the benefits in model size (at least compared to a baseline) are not mentioned. Why?\n\n', 'The paper presents a binary neural network architecture that operated on predefined orthogonal binary basis. The binary filters that are used as basis are generated using Orthogonal Variable Spreading Factor. \nBecause the filters are weighted combinations of predefined basis, only the weights need to be trained and saved. The network is tested on ImageNet and able to achieve top-5 accuracy of 65.9%.\n\nThe paper is clearly written. Few mistakes and questions: \nIs Equation 2 used to measure the quality of the kernel approximation?\n\nIn Figure 2, what is Sparse layer? Is it FlexModule?\n\nIn 4.1 Results Section, the paper states that “On ImageNet, BinaryFlex is compared to BinaryConnect and BinaryNeuralNet; otherwise, BinaryFlex is compared to BinaryConnect and BNN.” It should be Binary Weight Network instead of BinaryNeuralNet. \n\nBased on Results in Table 1, BinaryFlex is able to reduce the model size and provide better accuracy than BinaryConnect (2015). However, the accuracy results are significantly worse than Binary-Weight-Network (2016). Could you comment on that? The ImageNet results are worrying, while BNN (7.8Mb) achieves 79.4%, this BinaryFlex (3.4Mb) achieves 65.7%. The accuracy difference is huge.\n']","[-20, -30, -20]","[50, 20, 60]","['The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty of the proposed method, they express significant concerns about its performance compared to other techniques. The reviewer points out that the proposed method performs worse than other binary techniques on several datasets, which is a major drawback. The politeness score is moderately positive (50) because the reviewer maintains a professional tone throughout, balancing positive and negative feedback. They use neutral language to express their concerns and provide constructive suggestions for improvement, such as including additional comparisons and clarifying certain aspects of the methodology. The reviewer also starts with a positive point before moving on to the negatives, which is a polite approach to giving feedback.', ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('It is nice to read section 3.1', 'Section 3.2 is nice as short overview'), the overall tone is critical and points out numerous issues with clarity, consistency, and results interpretation. The reviewer expresses confusion and requests many clarifications, indicating dissatisfaction with the current state of the paper. However, it's not entirely negative, as the reviewer offers constructive feedback for improvement.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I would appreciate' and 'please be consistent'. They offer suggestions for improvement rather than harsh criticisms. However, the score is not higher because the review is quite direct in pointing out flaws and doesn't use many overtly polite phrases or soften criticisms. The reviewer's language is more neutral than explicitly polite, but still maintains a respectful tone appropriate for academic peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is clearly written, they raise several concerns and questions about the methodology and results. The reviewer points out significant accuracy differences compared to other methods, which they describe as 'worrying'. This indicates a level of skepticism about the paper's contributions. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, asking questions politely and offering constructive feedback. They begin with a neutral summary of the paper and phrase their criticisms as questions or observations rather than direct attacks. The tone is professional and courteous, even when pointing out potential issues.""]"
"['**Strengths**\nIn general, the paper makes an important observation that even in textual dialog, it might often make sense to reason or “imagine” how visual instances look, and this can lead to better more grounded dialog. \n\n**Weakness**\nIn general, the paper has some major weaknesses in how the dataset has been constructed, details of the models provided and generally the novelty of the proposed model. While the model on its own is not very novel, the paper does make an interesting computational observation that it could help to reason about vision even in textual dialog, but the execution of the dataset curation is not satisfactory, making the computational contribution less interesting. \n\nMore specific details below:\n1. The paper does not write down an objective that they are optimizing for any of the three stages in the model, and it is unclear what is the objective especially for the video context prediction task -- the distribution over the space of images (or videos) for a given piece of text is likely multimodal and gaussian likelihoods might not be sufficient to model this properly. Not clear if the sequence to sequence models are used in teacher forcing model when training in Stage 1, or there is sampling going on. In general, the paper lacks rigor in writing down what it optimizes, and laying out details of the model clearly. \n\n2. The manner in which the dataset has been constructed is unsatisfying -- it assumes that two consecutive pieces of subtitles in news channels constitutes a dialog. This is very likely an incorrect and unsatisfying assumption which does not take into account narrative, context etc. Right now the dataset seems more like skip-thought vectors [A] which models the distribution over contextual sentences given a source sentence than any kind of dialog.\n\n3. The setup and ultimately the motivation in context of the setup is fairly artificial -- the dataset does have images corresponding to each “dialog” so it is unclear why the associative model is needed in this case. Further, it would have been useful to see quantitative evaluation of the proposed approach or statistics of the dataset to establish context for the dataset being a valid benchmark, and providing a baseline / numerical checkpoint for future works to compare to. Without any of these things, the work seems fairly incomplete.\n\nClarity:\n1. Figure 2 captions are pretty unclear and hard to understand what they are conveying.\n2. For a large part the paper talks about how visual instances are not available for textual phrases and then proceeds to assume access to aligned text and visual data. It would be good to clarify from the start that the model does need paired videos and text, and state exactly how much aligned data is needed.\n3. Already learned CNN (Page. 4, Sec. 2.2.1): Would be good to mention which CNN was used.\n4. Page 4: “the textual and visual context vectors of the spider are generated, respectively”: Would be good to clarify that textual and visual context vectors for the spider are attended to, as opposed to saying they are generated.\n\nReferences:\n\n[A]: Kiros, Ryan, Yukun Zhu, Ruslan R. Salakhutdinov, Richard Zemel, Raquel Urtasun, Antonio Torralba, and Sanja Fidler. 2015. “Skip-Thought Vectors.” In Advances in Neural Information Processing Systems 28, edited by C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, 3294–3302. Curran Associates, Inc.', '\n\nThe authors describe a method to be used in text dialogue systems. The contribution of the paper relies on the usage of visual information to enhance the performance of a dialogue system. An input phrase is expanded with visual information (visual context vectors), next visual and textual information is merged in a deep model that provides the final answer. \n\nAlthough  the idea is interesting, I found the methodology fairly straightforward (only using known models in each step) and not having a particular component as contribution. What is more, the experimental evaluation is limited and purely qualitative: a few examples are provided. Also, I am not convinced on the evaluation protocol: the authors used captions from  video+videos as input data, and used ""the next caption"" as the response of the dialogue system. I am not very familiar with this type of systems, but it is clear to me that the evaluation is biased and does not prove the working hypothesis of the authors. Finally, no comparison with related works is provided.\n\n\nEnglish needs to be polished \n', ""The paper proposes to augment (traditional) text-based sentence generation/dialogue approaches by incorporating visual information.  The idea is that associating visual information with input text, and using that associated visual information as additional input will produce better output text than using only the original input text.\n\nThe basic idea is to collect a bunch of data consisting of both text and associated images or video.  Here, this was done using Japanese news programs.  The text+image/video is used to train a model that requires both as input and that encodes both as context vectors, which are then combined and decoded into output text.  Next, the image inputs are eliminated, with the encoded image context vector being instead associatively predicted directly from the encoded text context vector (why not also use the input text to help predict the visual context?), which is still obtained from the text input, as before.  The result is a model that can make use of the text-visual associations without needing visual stimuli.  This is a nice idea.\n\nActually, based on the brief discussion in Section 2.2.2, it occurs to me that the model  might not really be learning visual context vectors associatively, or, that this doesn't really have meaning in some sense.  Does it make sense to say that what it is really doing is just learning to associate other concepts/words with the input text, and that it is using the augmenting visual information in the training data to provide those associations?  Is this worth talking about?\n\nUnfortunately, while the idea has merit, and I'd like to see it pursued, the paper suffers from a fatal lack of validation/evaluation, which is very curious, given the amount of data that was collected, the fact that the authors have both a training and a test set, and that there are several natural ways such an evaluation might be performed.  The two examples of Fig 3 and the additional four examples in the appendix are nice for demonstrating some specific successes or weaknesses of the model, but they are in no way sufficient for evaluation of the system, to demonstrate its accuracy or value in general.\n\nPerhaps the most obvious thing that should be done is to report the model's accuracy for reproducing the news dialogue, that is, how accurately is the next sentence predicted by the baseline and ACM models over the training instances and over the test data?  How does this compare with other state-of-the-art models for dialogue generation trained on this data (perhaps trained only on the textual part of the data in some cases)?\n\nSecond, some measure of accuracy for recall of the associative image context vector should be reported; for example, on average, how close (cosine similarity or some other appropriate measure) is the associatively recalled image context vector to the target image context vector?  On average?  Best case?  Worst case?  How often is this associative vector closer to a confounding image vector than an appropriate one?\n\nA third natural kind of validation would be some form of study employing human subjects to test it's quality as a generator of dialogue.\n\nOne thing to note, the example of learning to associate the snowy image with the text about university entrance exams demonstrates that the model is memorizing rather than generalizing.  In general, this is a false association (that is, in general, there is no reason that snow should be associated with exams on the 14th and 15th—the month is not mentioned, which might justify such an association.)\n\nAnother thought: did you try not retraining the decoder and attention mechanisms for step 3?  In theory, if step 2 is successful, the retraining should not be necessary.  To the extent that it is necessary, step 2 has failed to accurately predict visual context from text.  This seems like an interesting avenue to explore (and is obviously related to the second type of validation suggested above).  Also, in addition to the baseline model, it seems like it would be good to compare a model that uses actual visual input and the model of step 1 against the model of step 3 (possibly bot retrained and not retrained) to see the effect on the outputs generated—how well do each of these do at predicting the next sentence on both training and test sets?\n\nOther concerns:\n\n1. The paper is too long by almost a page in main content.\n\n2. The paper exhibits significant English grammar and usage issues and should be carefully proofed by a native speaker.\n\n3. There are lots of undefined variables in the Eqs. (s, W_s, W_c, b_s, e_t,i, etc.)  Given the context and associated discussion, it is almost possible to sort out what all of them mean, but brief careful definitions should be given for clarity. \n\n4. Using news broadcasts as a substitute for true dialogue data seems kind of problematic, though I see why it was done.\n""]","[-50, -60, -20]","[20, 20, 60]","[""The sentiment score is -50 because while the reviewer acknowledges some strengths of the paper, they point out several major weaknesses and issues with the dataset construction, model details, and novelty. The overall tone is more critical than positive. The politeness score is 20 because the reviewer uses professional language and provides constructive feedback, but doesn't use overtly polite phrases. They maintain a neutral, academic tone while pointing out flaws, which keeps the review from being impolite but also prevents it from being exceptionally polite."", ""The sentiment score is -60 because the reviewer expresses several significant criticisms of the paper, including a straightforward methodology, limited experimental evaluation, questionable evaluation protocol, and lack of comparison with related works. While the reviewer acknowledges the idea as interesting, the overall tone is predominantly negative. The politeness score is 20 because the reviewer maintains a professional tone throughout, avoiding harsh language. They use phrases like 'I found' and 'I am not convinced' to express opinions, which is relatively polite. The suggestion to polish the English is direct but not impolite. The reviewer balances criticism with some positive acknowledgment, which contributes to a slightly positive politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the merit of the idea and expresses interest in seeing it pursued, they also point out a 'fatal lack of validation/evaluation' and several other concerns. The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and balances negative feedback with positive comments. They use phrases like 'nice idea' and 'I'd like to see it pursued' to soften criticism, and offer specific suggestions for improvement rather than just pointing out flaws.""]"
"['This paper formulates a variant of convolutional neural networks which models both activations and filters as continuous functions composed from kernel bases. A closed-form representation for convolution of such functions is used to compute in a manner than maintains continuous representations, without making discrete approximations as in standard CNNs.\n\nThe proposed continuous convolutional neural networks (CCNNs) project input data into a RKHS with a Gaussian kernel function evaluated at a set of inducing points; the parameters defining the inducing points are optimized via backprop. Filters in convolutional layers are represented in a similar manner, yielding a closed-form expression for convolution between input and filters. Experiments train CCNNs on several standard small-scale image classification datasets: MNIST, CIFAR-10, STL-10, and SVHN.\n\nWhile the idea is interesting and might be a good alternative to standard CNNs, the paper falls short in terms of providing experimental validation that would demonstrate the latter point. It unfortunately only experiments with CCNN architectures with a small number (eg 3) layers. They do well on MNIST, but MNIST performance is hardly informative as many supervised techniques achieve near perfect results. The CIFAR-10, STL-10, and SVHN results are disappointing. CCNNs do not outperform the prior CNN results listed in Table 2,3,4. Moreover, these tables do not even cite more recent higher-performing CNNs. See results table in (*) for CIFAR-10 and SVHN results on recent ResNet and DenseNet CNN designs which far outperform the methods listed in this paper.\n\nThe problem appears to be that CCNNs are not tested in a regime competitive with the state-of-the-art CNNs on the datasets used. Why not? To be competitive, deeper CCNNs would likely need to be trained. I would like to see results for CCNNs with many layers (eg 16+ layers) rather than just 3 layers. Do such CCNNs achieve performance compatible with ResNet/DenseNet on CIFAR or SVHN? Given that CIFAR and SVHN are relatively small datasets, training and testing larger networks on them should not be computationally prohibitive.\n\nIn addition, for such experiments, a clear report of parameters and FLOPs for each network should be included in the results table. This would assist in understanding tradeoffs in the design space.\n\nAdditional questions:\n\nWhat is the receptive field of the CCNNs vs those of the standard CNNs to which they are compared? If the CCNNs have effectively larger receptive field, does this create a cost in FLOPs compared to standard CNNs?\n\nFor CCNNs, why does the CCAE initialization appear to be essential to achieving high performance on CIFAR-10 and SVHN? Standard CNNs, trained on supervised image classification tasks do not appear to be dependent on initialization schemes that do unsupervised pre-training. Such dependence for CCNNs appears to be a weakness in comparison.', 'This paper aims to provide a continuous variant of CNN. The main idea is to apply CNN on Hilbert maps of the data. The data is mapped to a continuous Hilbert space via a reproducing kernel and a convolution layer is defined using the kernel matrix. A convolutional Hilbert layer algorithm is introduced and evaluated on image classification data sets.\n\nThe paper is well written and provides some new insights on incorporating kernels in CNN.\n\nThe kernel matrix in Eq. 5 is not symmetric and the kernel function in Eq. 3 is not defined over a pair of inputs. In this case, the projections of the data via the kernel are not necessarily in a RKHS. The connection between Hilbert maps and RKHS in that sense is not clear in the paper.\n\nThe size of a kernel matrix depends on the sample size. In large scale situations, working with the kernel matrix can be computational expensive. It is not clear how this issue is addressed in this paper.\n\nIn section 2.2, how \\mu_i and \\sigma_i are computed?\n\nHow the proposed approach can be compared to convolutional kernel networks (NIPS paper) of Mairal et al. (2014)?', ""The paper introduces the notion of continuous convolutional neural networks. \nThe main idea of the paper is to project examples into an RK Hilbert space\nand performs convolution and filtering into that space. Interestingly, the\nfilters defined in the Hilbert space  have parameters that are learnable.\n\nWhile the idea may be novel and interesting, its motivation is not clear for\nme. Is it for space? for speed? for expressivity of hypothesis spaces? \nMost data that are available for learning are in discrete forms and hopefully,\nthey have been digitalized according to Shannon theory. This means that they bring\nall necessary information for rebuilding their continuous counterpart. Hence, it is\nnot clear why projecting them back into continuous functions is of interest. \n\nAnother point that is not clear or at least misleading is the so-called Hilbert Maps.\nAs far as I understand, Equation (4) is not an embedding into an Hilbert space but\nis more a proximity space representation [1]. Hence, the learning framework of the\nauthors can be casted more as a learning with similarity function than learning\ninto a RKHS [2]. A proper embedding would have mapped $x$ into a function\nbelonging to $\\mH$. In addition, it seems that all computations are done\ninto a \\ell^2 space instead of in the RKHS (equations 5 and 11). \nLearning good similarity functions is also not novel [3] and Equations\n(6) and (7) corresponds to learning these similarity functions.\nAs far as I remember, there exists also some paper from the nineties that\nlearn the parameters of RBF networks but unfortunately I have not been able to\ngoogle some of them.\n\n\nPart 3 is the most interesting part of the paper, however it would have been\ngreat if the authors provide other kernel functions with closed-form convolution \nformula that may be relevant for learning.\nThe proposed methodology is evaluated on some standard benchmarks in vision. While\nresults are pretty good, it is not clear how the various cluster sets have been obtained\nand what are their influence on the performances (if they are randomly initialized, it \nwould be great to see standard deviation of performances with respect to initializations).\nI would also be great to have intuitions on why a single continuous filter works betters\nthan 20 discrete ones (if this behaviour is consistent accross initialization).\n\nOn the overall, while the idea may be of interested, the paper lacks in motivations\nin connecting to relevant previous works and in providing insights on why it works.\nHowever, performance results seem to be competitive and that's the reader may\nbe eager for insights.\n\n\nminor comments\n---------------\n\n* the paper employs vocabulary that is not common in ML. eg. I am not sure what\noccupancy values, or inducing points are. \n\n* Supposingly that the authors properly consider computation in RKHS, then \\Sigma_i\nshould be definite positive right? how update in (7) is guaranteed to be DP? \nThis constraints may not be necessary if instead they used proximity space representation.\n\n\n\n\n\n[1] https://alex.smola.org/papers/1999/GraHerSchSmo99.pdf\n[2] https://www.cs.cmu.edu/~avrim/Papers/similarity-bbs.pdf\n[3] A. Bellet, A. Habrard and M. Sebban. Similarity Learning for Provably Accurate Sparse Linear Classification. ""]","[-50, 50, -20]","[20, 75, 50]","[""The sentiment score is -50 because while the reviewer acknowledges the interesting idea of CCNNs, they express significant disappointment with the experimental results and validation. The reviewer points out that the CCNNs do not outperform prior CNN results and that the paper fails to compare with more recent, higher-performing CNNs. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'While the idea is interesting' and 'I would like to see', which soften the criticism. However, they are also direct in their critique, using words like 'disappointing' and 'falls short', which prevents the score from being higher. The reviewer also provides constructive feedback and suggestions for improvement, which contributes to the slightly positive politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges that the paper is well-written and provides new insights, which is positive. However, they also raise several concerns and questions, which tempers the positivity. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and phrases criticisms as questions or observations rather than direct attacks. The reviewer maintains a professional tone, offering constructive feedback without being overly critical or harsh."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the idea may be novel and interesting, they express several concerns and criticisms about the paper's motivation, clarity, and connections to previous work. The reviewer states 'the paper lacks in motivations in connecting to relevant previous works and in providing insights on why it works,' indicating overall dissatisfaction despite some positive aspects. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive criticism, and balances negative points with positive ones. They use phrases like 'it would have been great if' and 'the reader may be eager for insights,' which maintain a polite tone while expressing concerns. The review also offers specific suggestions for improvement, which is a polite way to provide criticism.""]"
"['The paper discusses ways to guard against adversarial domain shifts with so-called counterfactual regularization. The main idea is that in several datasets there are many instances of images for the same object/person, and that taking this into account by learning a classifier that is invariant to the superficial changes (or “style” features, e.g. hair color, lighting, rotation etc.) can improve the robustness and prediction accuracy. The authors show the benefit of this approach, as opposed to the naive way of just using all images without any grouping, in several toy experimental settings.\n\nAlthough I really wanted to like the paper, I have several concerns. First and most importantly, the paper is not citing several important related work. Especially, I have the impression that the paper is focusing on a very similar setting (causally) to the one considered in  [Gong et al. 2016] (http://proceedings.mlr.press/v48/gong16.html), as can be seen from Fig. 1. Although not focusing on classification directly, this paper also tries to a function T(X) such that P(Y|T(X)) is invariant to domain change. Moreover, in that paper, the authors assume that even the distribution of the class can be changed in the different domains (or interventions in this paper).\nBesides, there are also other less related papers, e.g. http://proceedings.mlr.press/v28/zhang13d.pdf, https://www.aaai.org/ocs/index.php/AAAI/AAAI15/paper/view/10052/0, https://arxiv.org/abs/1707.09724, (or potentially https://arxiv.org/abs/1507.05333 and https://arxiv.org/abs/1707.06422), that I think may be mentioned for a more complete picture. Since there is some related work, it may be also worth to compare with it, or use the same datasets.\n\nI’m also not very happy with the term “counterfactual”. As the authors mention in footnote, this is not the correct use of the term, since counterfactual means “against the fact”. For example, a counterfactual query is “we gave the patient a drug and the patient died, what would have happened if we didn’t give the drug?” In this case, these are just different interventions on possibly the same object. I’m not sure that in the practical applications one can assure that the noise variables stay the same, which, as the authors correctly mention, would make it a bit closer to counterfactuals. It may sound pedantic, but I don’t understand why use the wrong and confusing terminology for no specific reason, also because in practice the paper reduces to the simple idea of finding a classifier that doesn’t vary too much in the different images of the single object.\n\n**EDIT**: I was satisfied with the clarifications from the authors and I appreciated the changes that they did with respect to the related work and terminology, so I changed my evaluation from a 5 (marginally below threshold) to a 7 (good paper, accept).', ""Proposal is to restrict the feasible parameters to ones that have produce a function with small variance over pre-defined groups of images that should be classified the same. As authors note, this constraint can be converted into a KKT style penalty with KKT multiplier lambda.  Thus this is very  similar to other regularizers that increase smoothness of the function, such as total variation or a graph Laplacian defined with graph edges connecting the examples in each group, as well as manifold regularization (see e.g. Belkin, Niyogi et al. JMLR).  Heck, in practie ridge regularization will also do something similar for many function classes. \n\nExperiments didn't compare to any similar smoothness regularization (and my preferred would have been a comparison to graph Laplacian or total variation on graphs formed by the same clustered examples). It's also not clear either how important it is that they hand-define the groups over which to minimize variance or if just generally adding smoothness regularization would have achieved the same results.   That made it hard to get excited about the results in a vacuum. \n\nWould this proposed strategy have thwarted the Russian tank legend problem? Would it have fixed the Google gorilla problem? Why or why not?\n\nOverall, I found the writing a bit bombastic for a strategy that seems to require the user to hand-define groups/clusters of examples. \n\nPage 2: calling additional instances of the same person “counterfactual observations” didn’t seem consistent with the usual definition of that term… maybe I am just missing the semantic link here, but this isn't how we usually use the term counterfactual in my corner of the field.\n\nRe: “one creates additional samples by modifying…” be nice to quote more of the early work doing this, I believe the first work of this sort was Scholkopf’s, he called it “virtual examples” and I’m pretty sure he specifically did it for rotation MNIST images (and if not exactly that, it was implied).  I think the right citation is “Incorporating invariances in support vector learning machines\n“ Scholkopf, Burges, Vapnik 1996, but also see Decoste * Scholkopf 2002 “Training invariant support vector machines.” "", 'This paper aims at robust image classification against adversarial domain shifts. In the used model, there are two types of latent features, ""core"" features and ""style"" features, and the goal is to achieved by avoiding using the changing style features. The proposed method, which makes use of grouping information, seems reasonable and useful. \n\nIt is nice that the authors use ""counterfactual regularization"". But I failed to see a clear, new contribution of using this causal regularization, compared to some of the previous methods to achieve invariance (e.g., relative to translation or rotation). For examples of such methods, one may see the paper ""Transform Invariant Auto-encoder"" (by Matsuo et al.) and references therein.\n\nThe data-generating process for the considered model, given in Figure 2, seems to be consistent with Figure 1 of the paper ""Domain Adaptation with Conditional Transferable Components"" (by Gong et al.). Perhaps the authors can draw the connection between their work and Gong et al.\'s work and the related work discussed in that paper.\n\nBelow are some more detailed comments. In Introduction, it would be nice if the authors made it clear that ""Their high predictive accuracy might suggest that the extracted latent features and learned representations resemble the characteristics our human cognition uses for the task at hand."" Why do the features human cognition uses give an optimal predictive accuracy? On page 2, the authors claimed that ""These are arguably one reason why deep learning requires large sample sizes as large sample size is clearly not per se a guarantee that the confounding effect will become weaker."" Could the authors give more detail on this? A reference would be appreciated. ']","[20, -30, 20]","[60, 20, 60]","[""The sentiment score is 20 (slightly positive) because while the reviewer initially expresses concerns, they ultimately change their evaluation to 'good paper, accept' after the authors made changes. This indicates a positive final sentiment, but the initial criticisms temper it. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, such as 'I really wanted to like the paper' and 'I appreciated the changes', while also providing constructive criticism. They avoid harsh language and frame their concerns professionally. However, it's not extremely polite as it does contain direct criticisms."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the proposal's similarity to existing methods, they express skepticism about its novelty and effectiveness. The reviewer notes that the experiments didn't compare to similar smoothness regularization techniques and questions the importance of hand-defining groups. They also found it 'hard to get excited about the results' and described the writing as 'a bit bombastic'. However, the review isn't entirely negative, as it does provide constructive feedback and suggestions for improvement. The politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout, offers specific recommendations, and uses phrases like 'Would this proposed strategy have...?' and 'be nice to quote more of the early work...', which are polite ways of suggesting improvements. The reviewer also acknowledges when they might be missing something ('maybe I am just missing the semantic link here'). While there are critical comments, they are presented in a constructive manner rather than being rudely dismissive."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's reasonable and useful approach, and appreciates the use of 'counterfactual regularization'. However, they also express some concerns about the lack of clear new contributions and suggest drawing connections with previous work. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions without harsh or dismissive comments. They use phrases like 'It is nice that...' and 'It would be nice if...', which contribute to a polite tone. The reviewer also asks for clarification and additional details in a courteous manner, using phrases like 'Could the authors give more detail on this?' rather than demanding or criticizing.""]"
"['This paper presents a sensitivity-penalized loss (the loss of the classifier has an additional term in squart of the gradient of the classifier w.r.t. perturbations of the inputs), and a minimax (or maximin) driven algorithm to find attacks and defenses. It has a lemma which claims that the ""minimax and the maximin solutions provide the best worst-case defense and attack models, respectively"", without proof, although that statement is supported experimentally.\n\n+ Prior work seem adequately cited and compared to, but I am not really knowledgeable in the adversarial attacks subdomain.\n- The experiments are on small/limited datasets (MNIST and CIFAR-10). Because of this, confidence intervals (over different initializations, for instance) would be a nice addition to Table 5.\n- There is no exact (""alternating optimization"" could be considered one) evaluation of the impact of the sensitivy loss vs. the minimax/maximin algorithm.\n- The paper is hard to follow at times (and probably that dealing with the point above would help in this regard), e.g. Lemma 1 and experimental analysis.\n- It is unclear (from Figures 3 and 7) that ""alternative optimization"" and ""minimax"" converged fully, and/or that the sets of hyperparameters were optimal.\n+ This paper presents a game formulation of learning-based attacks and defense in the context of adversarial examples for neural networks, and empirical findings support its claims.\n\n\nNitpicks:\nthe gradient descent -> gradient descent or the gradient descent algorithm\nseeming -> seemingly\narbitrary flexible -> arbitrarily flexible\ncan name ""gradient descent that maximizes"": gradient ascent.\nThe mini- max or the maximin solution is defined -> are defined\nis the follow -> is the follower\n', 'The game-theoretic approach to attacks with / defense against adversarial examples is an important direction of the security of deep learning and I appreciate the authors to initiate this kind of study. \n\nLemma 1 summarizes properties of the solutions that are expected to have after reaching equilibria. Important properties of saddle points in the min-max/max-min analysis assume that the function is convex/concave w.r.t. to the target variable.  In case of deep learning, the convexity is not guaranteed and the resulting solutions do not have necessarily follow Lemma 1.\u3000Nonetheless, this type of analysis can be useful under appropriate solutions if non-trivial claims are derived; however, Lemma 1 simply explains basic properties of the min-max solutions and max-min solutions works and does not contain non-tibial claims.\n\nAs long as the analysis is experimental, the state of the art should be considered. As long as the reviewer knows, the CW attack gives the most powerful attack and this should be considered for comparison. The results with MNIST and CIFAR-10 are different. In some cases, MNIST is too easy to consider the complex structure of deep architectures. I prefer to have discussions on experimental results with both datasets.\n\nThe main takeaway from the entire paper is not clear very much. It contains a game-theoretic framework of adversarial examples/training, novel attack method, and many experimental results.\n\nMinor:\nDefinition of g in the beginning of Sec 3.1 seems to be a typo. What is u? This is revealed in the latter sections but should be specified here.\n\nIn Section 3.1, \n>This is in stark contrast with the near-perfect misclassification of the undefended classifier in Table 1.\nThe results shown in the table seems to indicate the “perfect” misclassification.\n\nSentence after eq. 15 seems to contain a grammatical error\n\nThe paragraph after eq. 17 is duplicated with a paragraph introduced before\n', 'The authors describe a mechanism for defending against adversarial learning attacks on classifiers. They first consider the dynamics generated by the following procedure. They begin by training a classifier, generating attack samples using FGSM, then hardening the classifier by retraining with adversarial samples, generating new attack samples for the retrained classifier, and repeating.  \n\nThey next observe that since FGSM is given by a simple perturbation of the sample point by the gradient of the loss, that the fixed point of the above dynamics can be optimized for directly using gradient descent. They call this approach Sens FGSM, and evaluate it empirically against the various iterates of the above approach. \n\nThey then generalize this approach to an arbitrary attacker strategy given by some parameter vector (e.g. a neural net for generating adversarial samples). In this case, the attacker and defender are playing a minimax game, and the authors propose finding the minimax (or maximin) parameters using an algorithm which alternates between maximization and minimization gradient steps. They conclude with empirical observations about the performance of this algorithm.\n\nThe paper is well-written and easy to follow. However, I found the empirical results to be a little underwhelming. Sens-FGSM outperforms the adversarial training defenses tuned for the “wrong” iteration, but it does not appear to perform particularly well with error rates well above 20%. How does it stack up against other defense approaches (e.g. https://arxiv.org/pdf/1705.09064.pdf)? Furthermore, what is the significance of FGSM-curr (FGSM-81) for Sens-FGSM? It is my understanding that Sens-FGSM is not trained to a particular iteration of the “cat-and-mouse” game. Why, then, does Sens-FGSM provide a consistently better defense against FGSM-81? With regards to the second part of the paper, using gradient methods to solve a minimax problem is not especially novel (i.e. Goodfellow et al.), thus I would liked to see more thorough experiments here as well. For example, it’s unlikely that the defender would ever know the attack network utilized by an attacker. How robust is the defense against samples generated by a different attack network? The authors seem to address this in section 5 by stating that the minimax solution is not meaningful for other network classes. However, this is a bit unsatisfying. Any defense can be *evaluated* against samples generated by any attacker strategy. Is it the case that the defenses fall flat against samples generated by different architectures? \n\n\nMinor Comments:\nSection 3.1, First Line. ”f(ul(g(x),y))” appears to be a mistake.']","[20, 20, -20]","[50, 60, 60]","[""The sentiment score is slightly positive (20) because while the review points out several limitations and areas for improvement, it also acknowledges the paper's contributions and empirical support for its claims. The review begins and ends with positive points, sandwiching the criticisms in between. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents criticisms as suggestions for improvement rather than harsh judgments. The use of '+' and '-' to organize points also contributes to a professional tone. The reviewer acknowledges their own limitations ('I am not really knowledgeable in the adversarial attacks subdomain') which adds to the politeness. The 'Nitpicks' section at the end is presented separately and in a matter-of-fact manner, which maintains the overall polite tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the importance of the research direction and appreciates the authors' initiative. However, they also point out several limitations and areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and framing criticisms constructively. They use phrases like 'I appreciate' and 'I prefer' which add a polite tone. The reviewer also provides detailed feedback and suggestions for improvement, which is a courteous approach in academic review. The lack of strongly negative language or dismissive comments further contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and easy to follow, they express disappointment with the empirical results, calling them 'underwhelming'. They also raise several questions and concerns about the significance and robustness of the proposed methods. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They phrase their concerns as questions or suggestions rather than direct criticisms, which maintains a polite tone. The use of phrases like 'I would liked to have seen' and 'It's my understanding' further contribute to the polite framing of the feedback.""]"
"['The paper conducts an empirical study on 2nd-order algorithms for deep learning, in particular on CNNs to answer the question whether 2nd-order methods are useful for deep learning.  More modestly and realistically, the authors compared stochastic Newton method (SHG) and stochastic Quasi- Newton method (SR1, SQN) with stochastic gradient method (SGD).  The activation function ReLu is known to be singular at 0, which may lead to poor curvature information, but the authors gave a good numerical comparison between the performances of 2nd-order methods with ReLu and the smooth function, Tanh.  The paper presented a reasonably good overview of existing 2nd-order methods, with clear numerical examples and reasonably well written.\n\nThe paper presents several interesting empirical findings, which will no doubt lead to follow up work. However, there are also a few critical issues that may undermine their claims, and that need to be addressed before we can really answer the original question of whether 2nd-order methods are useful for deep learning. \n\n1. There is no complexity comparison, e.g. what is the complexity for a single step of different method.\n\n2. Relatedly, the paper reports the performance over epochs, but it is not clear what ""per epoch"" means for 2nd-order methods.  In particular, it seems to me that they did not count the inner CG iterations, and it is known that this is crucial in running time and important for quality.  If so, then the comparison between 1st-order and 2nd-order methods are not fair or incomplete.\n\n3. The results on 2nd-order methods behave similarly to 1st-order methods, which makes me wonder how many CG iterations they used for 2nd-order method in their experiment, and also the details of the data.  In particular, are they looking at parameter/hyperparameter settings for which 2nd-order methods aren\'t really necessary.\n\n4. In deep learning setting, the training objective is non-convex, which means the Hessian can be non-PSD.  It is not clear how the stochastic inexact-Newton method mentioned in Section 2.1 could work.  Details on implementations of 2nd-order methods are important here.\n\n5. For 2nd-order methods, the author used line search to tune the step size.  It is not clear in the line search, the author used the whole training objective or batch loss.  Assuming using the batch loss, I suspect the training curve will be very noisy (depending on how large the batch size is).  But the paper only show the average training curves, which might be misleading.\n\nHere are other points.\n\n1. There is no figure showing training/ test accuracy.  Aside from being interested in test error, it is also of interest to see how 2nd order methods are similar/different than 1st order methods on training versus test.\n\n2. Since it is a comparison paper, it only compares three 2nd-order methods with SGD.  The choices made were reasonable, but 2nd-order methods are not as trivial to implement as SGD, and it isn\'t clear whether they have really ""spanned the space"" of second order methods\n\n3. In the paper, the settings of LeNet, AlexNet are different with those in the original paper.  The authors did not give a reason.\n\n4. The quality of figures is not good.\n\n5. The setting of optimization is not clear, e.g. the learning rate of SGD, the parameter of backtrack line search.  It\'s hard to reproduce results when these are not described.\n\n', 'A good experimentation of second order methods for training large DNNs in comparison with the popular SGD method has been lacking in the literature. This paper tries to fill that gap. Though there are some good experiments, I feel it could have been much better and more complete.\n\nSeveral candidates for second order methods are considered. However, their discussion and the final choice of the three methods is too rapid. It would have been useful to include an appendix with more details about them.\n\nThe results are mostly negative. The second order methods are much slower (in time) than SGD. The quasi-Newton methods are way too sensitive to hyperparameters. SHG is better in that sense, but it is far too slow. Distributed training is mentioned as an alternative, but that is just a casual statement - communication bottleck can still be a huge issue with large DNN models.\n\nI wish the paper had been bolder in terms of making improvements to one or more of the second order methods in order to make them better. For example, is it possible to come up with ways of choosing hyperparameters associated with the quasi-Newton implementations so as to make them robust with respect to batch size? Second order methods are almost dismissed off for RelU - could things be better with the use of a smooth version of RelU? Also, what about non-differentiability brought in my max pooling?\n\nOne disappointing thing about the paper is the lack of any analysis of the generalization performance associated with the methods, especially with the authors being aware of the works of Keskar et al and Kawaguchi et al. Clearly, the training method is having an effect on generlaization performance, with noise associated with stochastic methods being a great player for leading solutions to flat regions where generalization is better. One obvious question I have is: could it be that, methods such as SHG which have much less noise in them, have poor generalization properties? If so, how do we correct that?\n\nOverall, I like the attempt of exploring second order methods, but it could have come out a lot better.', 'This paper presents a comparative study on second-order optimization methods for CNNs. Overall, the topic is interesting and would be useful for the community.\n\nHowever, I think there are important issues about the paper:\n\n1) The paper is not very well-written. The language is sometimes very informal, there are many grammatical mistakes and typos. The paper should be carefully proofread.\n\n2) For such a comparative study, the number of algorithms and the number of datasets are quite little. The authors do not mention several important methods such as (not exhaustive)\n\nSchraudolph, N. N., Yu, J., and Günter, S. A stochastic quasi-Newton method for online convex optimization.\nGurbuzbalaban et al, A globally convergent incremental Newton method (and other papers of the same authors)\nA Linearly-Convergent Stochastic L-BFGS Algorithm, Moritz et al\n\n3) The experiment details are not provided. It is not clear what parameters are used and how. \n\n4) There are some vague statements such as ""this scheme does not work"" or ""fixed learning rates are not applicable"". For instance, for the latter I cannot see a reason and the paper does not provide any convincing results.\n\nEven though the paper attempts to address an important point in deep learning, I do not believe that the presented results form evidence for such rather bold statements.']","[-20, -20, -50]","[50, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('reasonably good overview', 'interesting empirical findings'), they also highlight several critical issues and areas for improvement. The overall tone suggests that significant revisions are needed before the paper can effectively answer its main research question. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'reasonably well written' and frame their criticisms as suggestions for improvement rather than harsh judgments. The reviewer maintains a professional tone, focusing on the content rather than making personal comments about the authors."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's attempt to fill a gap in the literature and mentions some good experiments, they express disappointment with the overall execution and results. The reviewer uses phrases like 'could have been much better,' 'results are mostly negative,' and 'disappointing thing about the paper,' indicating a generally critical stance. However, they also mention positive aspects, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'I wish,' 'I feel,' and 'Overall, I like the attempt,' which soften the criticism. They also provide constructive feedback and suggestions for improvement, which is a polite way to express concerns. The language is not overly formal or deferential, but it avoids rudeness or harsh criticism, striking a balance between honesty and courtesy."", ""The sentiment score is -50 because while the reviewer acknowledges the topic is interesting and useful, they express several significant concerns about the paper. The review starts positively but quickly shifts to a critical tone, listing multiple important issues. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I think' and 'I do not believe' rather than making blunt statements. They also begin with a positive comment. However, the criticism is direct and not particularly softened, preventing a higher politeness score. The scores were determined by analyzing the overall tone, the balance of positive and negative comments, and the language used to express criticism.""]"
"['This paper proposes a method to solve the \'word analogy problem\', which was proposed as a way of understanding and evaluating word embeddings by Mikolov et al. There are some nice analyses in the paper which, if better organised, could lead to an improved understanding of semantic word spaces in neural nets. \n\ncomments: \n\nThe word analogy task was developed as an interesting way to analyse and understand word embedding spaces, but motivation for learning word embeddings was as general-purpose representations for language processing tasks (as in collobert et al, 2011), not as a way of resolving analogy questions. The authors develop a specialist method for resolving analogies, and it works (mostly) better than using the additive geometry of word-embedding spaces. But I don\'t think that comparison is \'fair\' - the analogy thing is just a side-effect of word embedding spaces. \n\nGiven that the authors focus on the word-analogy problem as an end in itself, I think there should be much more justification of why this is a useful problem to solve. Analogy seems to be fundamental to human cognition and reasoning, so maybe that is part of the reason, but it\'s not clear to the reader. \n\nThe algorithm seems to be simple and intuitive, but the presentation is overly formal and unclear. It would be much easier for the reader to simply put into plain terms what the algorithm does.\n\nUsing a POS-tagger to strip out nouns is a form of supervision (the pos-tagger was trained on labelled data) that word-embedding methods do not use, which should at least be acknowledged when making a comparison. Similarly, it is nice that the present method works on less data, but the beauty of word embeddings is that they can be trained on any text - i.e. data is not a problem, and \'work\' for any word type. Stripping away everything but nouns clearly allows co-occurrence semantic patterns to emerge from less data, but at the cost of the supervision mentioned above. Moreover, I suspect that the use of wikipedia is important for the proposed algorithm, as the pertinent relations are often explicit in the first sentence of articles ""Paris the largest city and capital of France..."". Would the same method work on any text? I would expect this question to be explored, even if the answer is negative. \n\nThe goal of understanding word2vec and embedding spaces in general (section 5) is a really important one (as it can tell us a lot about how language and meaning is encoded in deep learning models in general), and I think that\'s one of the strongest aspects of this work. However, the conclusions from this section (and other related conclusions in other sections) are a little unclear to me. Perhaps that is because I don\'t quite get algorithm 3, which would be mitigated by an intuitive explanation to complement the pseudocode. I\'m also confused by the assertion that Vec(A) - Vec(B) conveys the \'common information\' in A and B. How can a non-symmetric operation convey \'common information\'. Surely it conveys something about the relationship between A and B?\n\nMinor point:\n""may not the be indicative of the model\'s ability to learn the relationship between a word pair the way a human does"" (Abstract)\n- I\'m not sure we know how humans learn the relationships between word pairs. Are you referring to formal semantic relations i.e. in taxonomies in WordNet? This sentence seems dangerous, and the claim about humans is not really treated in the article itself. \n\nThe a+cknowledgements compromise the anonymity of the authors. ', 'This paper presents, and analyzes, a method for learning word relationships based on co-occurrence.  In the method, relationships between pairs of words (A, B) are represented by the terms that tend to occur around co-mentions of A and B in text.  The paper shows the start of some interesting ideas, but needs revisions and much more extensive experiments.\n\nOn the plus side, the method proposed here does perform relatively well (Table 1) and probably merits further investigation.  The experiments in Table 1 can only be considered preliminary, however.  They only evaluate over a small number of relationships (three) -- looking at 20 or so different relationships would greatly improve confidence in the conclusions.\n\nBeyond Table 1 the paper makes a number of claims that are not supported or weakly supported (the paper uses only a handful of examples as evidence).  An attempt to explain what Word2Vec is doing should be made with careful experiments over many relations and hundreds of examples, whereas this paper presents only a handful of examples for most of its claims.  Further, whether the behavior of the proposed algorithm actually reflects what word2vec is doing is left as a significant open question.\n\nI appreciate the clarity of Assumption 1 and Proposition 1, but ultimately this formalism is not used and because Assumption 1 about which nouns are ""semantically related"" to which other nouns attempts to trivialize a complex notion (semantics) and is clearly way too strong -- the paper would be better off without it.  Also Assumption 1 does not actually claim what the text says it claims (the text says words outside the window are *not* semantically related, but the assumption does not actually say this) and furthermore is soon discarded and only the frequency of noun occurrences around co-mentions is used.  I think the description of the algorithm could be retained without including Assumption 1.\n\nminor:\n\nReferences to numbered algorithms or assumptions should be capitalized in the text.\n\nwhat the introduction means about the ""dynamics"" of the vector equation is a little unclear\n\nA submission shouldn\'t have acknowledgments, and in particular with names that undermine anonymity\n\nMLE has a particular technical meaning that is not utilized here, I would just refer to the most frequent words as ""most related nouns"" or similar\n\nIn Table 1, are the ""same dataset"" results with w2v for the nouns-only corpus, or with all the other words?\n\nThe argument made assuming a perfect Zipf distribution (with exponent equal to one) should be made with data.\n\nwill likely by observed -> will likely be observed\n\nlions:dolphins probably ends up that way because of ""sea lions""\n\nTable 4 caption: frequencies -> currencies\n\nTable 2 -- claim is that improvements from k=10 to k=20 are \'nominal\' but they look non-negligible to me\n\nI did not understand how POS lying in the same subspace means that Vec(D) has to be in the span of Vecs A-C.', 'This paper proposes a new method for solving the analogy task, which can potentially provide some insight as to why word2vec recovers word analogies.\n\nIn my view, there are three main issues with this paper: (1) the assumptions it makes about our understanding of the analogy phenomenon; (2) the authors\' understanding of the proposed method, what it models, and its relation to prior art; (3) the very selective subset of analogies that the author used for evaluation.\n\n\nASSUMPTIONS\nThe author assumes that there the community does not understand why word embedding methods such as word2vec recover analogies. I believe that, in fact, we do have a good understanding of this phenomena. Levy & Goldberg [1] showed that optimizing x for\nargmax(cos(x, A - B + C))\nis equivalent to optimizing x for\nargmax(cos(x, A) - cos(x, B) + cos(x, C))\nwhich means that one can interpret this objective as searching for a word x that is similar to A, similar to C, and dis-similar to B. Linzen [2] cemented this explanation by removing the negative term (-cos(x, B)) and showing that for a wide variety of analogies, the method still works. Drozd et al [3] and Rogers et al [4] also argue that the original datasets used by Mikolov et al were too easy because they focused on encyclopedic facts, and expand these datasets to other non-encyclopedic relations, which are significantly more difficult to solve using simple vector arithmetic.\n\nIn other words, we know why word2vec is able to solve analogies via vector arithmetic: because many analogies (like those in Mikolov et al\'s original dataset) are ""gameable"", and can be solved by finding a term that is similar to A and similar to C at the same time. For example, if A=""woman"" and C=""king"", then x=""queen"" fits the bill.\n\n\nMETHOD\nFrom what I can understand, the proposed method models the 3-way co-occurrence between A, B, and a context noun (let\'s call it R). Leveraging the distribution of (X, R, Y) for solving problems in lexical semantics has been studied quite a bit in the past, e.g. Latent Relational Analysis [5] and even Hearst patterns. I think the current description overlooks this major deviation from word2vec and other distributional methods, which only model the 2-way co-occurrence (X, R). This is a much more profound difference than just filtering non-nouns. I think the proposed method should be redescribed in these terms, and compared to other work that modeled 3-way co-occurrences.\n\n\nEVALUATION DATA\nThe author evaluates their method on a subset of the original analogy task, which is very limited. I would like to see an evaluation on (A) the original two datasets of Mikolov et al (without non-nouns), and (B) the larger datasets provided by Drozd et al [3] and Rogers et al [4].\n\nIn addition, since I think the analogy phenomenon is well understood, I would like to see some demonstration that this method has added value beyond the analogy benchmark.\n\n\nMISCELLANEOUS COMMENTS\n* The author does not state the important fact that when searching for the closest x to A - B + C, the search omits A, B, and C. It is often the case that the result is A or C without this omission.\n* The paper is partially de-anonymized (e.g. links and acknowledgements).\n* One of the problems with modeling 3-way co-occurrences (as opposed to 2-way co-occurrences) is that they are much sparser. I think this is a more precise explanation for why the currency relation is particularly hard to capture with this method.\n\n[1] http://www.aclweb.org/anthology/W14-1618 \n[2] http://anthology.aclweb.org/W16-2503 \n[3] http://aclweb.org/anthology/C/C16/C16-1332.pdf \n[4] http://www.aclweb.org/anthology/S17-1017 \n[5] https://arxiv.org/pdf/cs/0508053.pdf \n']","[-20, -20, -50]","[50, 60, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('nice analyses', 'could lead to an improved understanding'), they express several criticisms and concerns about the paper's approach, motivation, and clarity. The overall tone suggests the paper needs significant improvements.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I think' and 'Perhaps' to soften criticisms, and offer specific suggestions for improvement. However, they don't use overtly polite language or praise the authors excessively, keeping the tone neutral to slightly positive in terms of politeness.\n\nThe reviewer balances critique with recognition of potential value, and frames most criticisms as suggestions or questions rather than harsh judgments, contributing to both the slightly negative sentiment and the moderately polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('performs relatively well', 'merits further investigation'), they also point out significant shortcomings and areas for improvement. The review suggests that the paper needs 'revisions and much more extensive experiments' and that many claims are 'not supported or weakly supported'. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. They use phrases like 'I appreciate' and offer specific suggestions for improvement rather than harsh criticisms. The reviewer maintains a professional tone, even when pointing out weaknesses in the paper."", ""The sentiment score is -50 because the reviewer identifies three main issues with the paper and provides detailed criticism throughout. However, they do acknowledge some potential value in the proposed method, preventing a more negative score. The politeness score is 20 because the reviewer maintains a professional tone and uses respectful language like 'In my view' and 'I would like to see'. They also provide constructive feedback and suggestions for improvement. However, the critique is direct and doesn't use overly polite language, keeping the score moderately positive rather than highly positive. The reviewer also provides helpful references and explains their reasoning, which contributes to a more collegial tone.""]"
"['This paper presents a new model for composing representations of characters into word embeddings. The starting point of their argument is to include position-specific embeddings of characters rather than just position-independent characters. By adding together position-specific vectors, reasonable results are obtained.\n\nThis is an interesting result, but I have a few recommendations to improve the paper.\n1) It is a bit hard to assess since it is not evaluated on a standard datasets. There are a number standard datasets for open vocabulary language modeling. E.g., the MWC corpus (http://k-kawakami.com/research/mwc), or even the Penn Treebank (although it is conventionally modeled in closed vocabulary form).\n2) There are many existing models for composing characters into words. In addition to those cited in the paper, see the citations listed below. Comparison with those is crucial in a paper like this.\n3) Since the predictions are done at the word type level, it is unclear how vocabulary set of the corpus is determined, and what is done with OOV word types at test time (while it is possible to condition on them using the technique in the paper, it is not possible to use this technique for generation).\n4) The analysis is interesting, but a more intuitive explanation would be to show nearest neighbor plots.\n\nSome missing citations:\n\nComposing characters into words:\n\ndos Santos and Zadrozny. (2014 ICML) http://proceedings.mlr.press/v32/santos14.pdf\nLing et al. (2015 EMNLP) Finding Function in Form. https://arxiv.org/abs/1508.02096\n\nAdditionally, using explicit positional features in modeling language has been used:\nVaswani et al. (2017) Attention is all you need https://arxiv.org/abs/1706.03762\nand a variety of other sources.', 'The authors propose a neural network architecture which takes the characters of a word as input along with their positions, and output a word embedding. They then use these as inputs to a GRU language model, which is evaluated on two medium size data sets made from a series of novels and the Project Gutenberg Canada books respectively.\n\nWhile the idea has merit, the experimental protocol is too flawed to draw any reliable conclusions. Why use Wheel of Time, which is not in the public domain, rather than e.g. text8? Why not train the model to convergence (Figure 3)? Do the learned embeddings exhibit any morphological significance, or does the model only serve a regularization purpose?\n\nAs for the model itself: are the position agnostic character embeddings actually helpful in the spelling model? Does the model have the expressivity to learn the same embeddings as a look-up table?\n\nThe authors are also missing a significant amount of relevant literature on the topic of building word embeddings from characters, for example:\nFinding Function in Form: Compositional Character Models for Open Vocabulary Word Representation, Ling et al., 2015\nEnriching Word Vectors with Subword Information, Bojanowski et al. 2017\nCompositional Morphology for Word Representations and Language Modelling, Botha and Blunsom 2014\n\nPros:\n- Valid idea\n\nCons:\n- Too many missing references\n- Some modeling choices lack justification\n- Experiments do not provide meaningful comparisons and are not reproducible\n', 'The paper uses both position agnostic and position aware embeddings for tokens in a language modeling task. To obtain token embeddings, they concatenate two embeddings: the sum of character embeddings and the sum of (character, position) embeddings, the former being position agnostic and the latter being position aware. In a language modeling task, they find that using a combination of both improves perplexity over the standard token embedding baseline with fewer parameters. \n\nThe paper shows that the character embeddings are more sparse, measured with the Gini coefficient, than token embeddings and are more robust to overfitting. They also find that while dropout increases overall sparsity, it makes a few tokens homogenous. The paper does not give a crisp answer to why such sparsity patterns are observed. \n\nThe paper falls a bit  short both empirically and technically. While their technique is interesting, they do not compare it to the baseline of using convolutions over characters. More empirical evidence is needed for the technique to be adopted by the community.  On the theory side, they should dig deeper into the reasons for sparsity and how it might help to train better models. \n\nIf the papers shows that the approach can work well in machine translation or language modeling of morphologically rich languages, it might encourage practitioners to use the technique. ']","[20, -50, -20]","[70, 20, 50]","[""The sentiment score is slightly positive (20) because the reviewer describes the paper as presenting an 'interesting result' and provides constructive feedback for improvement. The overall tone is not overwhelmingly positive, but it's not negative either. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, such as 'interesting result' and 'I have a few recommendations to improve the paper.' The reviewer also provides specific, actionable feedback and additional resources, which is helpful and considerate. The language is professional and constructive without being overly formal or effusive."", ""The sentiment score is -50 because while the reviewer acknowledges that the idea has merit, they express significant concerns about the experimental protocol, missing literature, and lack of justification for modeling choices. The overall tone is critical, with more cons than pros listed. The politeness score is 20 because the reviewer uses relatively neutral language and offers constructive criticism. They acknowledge the potential of the idea and frame their concerns as questions or suggestions rather than harsh criticisms. However, the directness of some statements (e.g., 'the experimental protocol is too flawed') prevents a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the paper, they also point out several shortcomings. The review starts positively by describing the paper's approach, but then criticizes it for falling short both empirically and technically. The reviewer suggests that more evidence and deeper analysis are needed, indicating a somewhat negative overall sentiment.\n\nThe politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout. They acknowledge the paper's contributions before offering criticisms, and phrase their suggestions constructively. For example, they use phrases like 'The paper falls a bit short' rather than using harsher language. The reviewer also offers specific suggestions for improvement, which is a polite way to provide criticism.""]"
"['Summary\n\nThe paper addresses the issues of fair pricing and secure transactions between model and data providers in the context of machine learning real-world application.\n\nMajor\n\nThe paper addresses an important issue regarding the real-world application of machine learning, that is, the transactions between data and model provider and the associated aspects of fairness, pricing, privacy, and security.\n\nThe originality and significance of the work reported in this paper are difficult to comprehend. This is largely due to the lack of clarity, in general, and the lack of distinction between what is known and what is proposed. I failed to find any clear description of the proposed approach and any evaluation of the main idea.\n\nMost of the discussions in the paper are difficult to follow due to that many of the statements are vague or unclear. There are some examples of this vagueness illustrated under “minor issues”. Together, the many minor issues contribute to a major communication issue, which significantly reduces readability of the paper. A majority of the references included in the reference section lack some or all of the required meta data.\n\nIn my view, the paper is out of scope for ICLR. Neither the CFP overview nor the (non-exhaustive) list of relevant topics suggest otherwise. In very general terms, the paper could of course be characterised as dealing with machine learning implementation/platform/application but the issues discussed are more connected to privacy, security, fair transactions, and pricing.\n\nIn summary; although there is no universal rule on how to structure research papers, a more traditional structure (introduction, aim & scope, background, related work, method, results, analysis, conclusions & future work) would most certainly have benefitted the paper through improved clarity and readability. Although some interesting works on adversarial learning, federated learning, and privace-preserving training are cited in the paper, the review and use of these references did not contribute to a better understanding of the topic or the significance of the contribution in this paper. I was unable to find any support in the paper for the strong general result stated in the abstract (“We successfully show that without running the data through the model, one can approximate the value of the data”).\n\nMinor issues (examples)\n\n- “Models trained only a small scale of data” (missing word)\n- “to prevent useful data from not being paid” (unclear meaning)\n- “while the company may decline reciprocating gifts such as academic collaboration, while using the data for some other service in the future” (unclear meaning)\n- “since any data given up is given up ” (unclear meaning)\n- “a user of a centralized service who has given up their data will have trouble telling if their data exchange was fair at all (even if their evaluation was purely psychological)” (unclear meaning)\n- “For a generally deployed model, it can take any form. Designing a transaction strategy for each one can be time-consuming and difficult to reason about” (unclear meaning)\n- “(et al., 2017)” (unknown reference)\n- “Osbert Bastani, Carolyn Kim, and Hamsa Bastani. Interpreting blackbox models via model extraction, 2017” (incomplete reference data)\n- “Song Han, Huizi Mao, and William J. Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding, 2015.\nGeoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network, 2015.\nPang Wei Koh and Percy Liang. Understanding black-box predictions via influence functions, 2017.” (Incomplete reference data)\n- “H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agera y Arcas. Communication-efficient learning of deep networks from decentralized data. 2016.” (Incomplete reference data)\n- “et al. Richard Craid.” (Incorrect author reference style)\n- “Ryo Yonetani, Vishnu Naresh Boddeti, Kris M. Kitani, and Yoichi Sato. Privacy-preserving visual learning using doubly permuted homomorphic encryption, 2017.\nChiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization, 2016.” (Incomplete reference data)', ""This paper's abstract is reasonably interesting and has importance given the landscape that is developing.  Unfortunately, however, the body of the paper disappoints, as it has no real technical content or contribution.  The paper also needs a spelling, grammar, typesetting, and writing check.  \n\nI don't mind the restriction of the setting under study to be adding a small dataset to a model trained on a large dataset, but I don't agree with the way the authors have stated things in the first paragraph of the paper because there are many real-world domains and applications that are necessarily of the small data variety.\n\nIn Section 3.3., the authors should either make a true information-theoretic statement or shorten significantly.\n"", 'The paper discusses a setting in which an existing dataset/trained model is augmented/refined by adding additional datapoints. Issues of how to price the new data are discussed in a high level, abstract way, and arguments against retrieving the new data for free or encrypting it are presented.\n\nOverall, the paper is of an expository nature, discussing high-level ideas rather than actually implementing them, and does not  experimentally or theoretically substantiate any of its claims. This makes the technical contribution rather shallow. Interesting questions do arise, such as how to assess the value of new data and how to price datapoints, but these questions are never addressed (neither theoretically nor empirically). Though main points are valid, the paper is also rife with informal statements  and logical jumps, perhaps due to the expository/high-level approach taken in discussing these issues.\n\nDetailed comments:\n\nThe (informal) information theoretic argument has a few holes. The claim is roughly that every datapoint (~1Mbyte image) contributes ~1M bits of changes in a model, which can be quite revealing. As a result, there is no benefit from encrypting the datapoint, as the mapping from inputs to changes is insecure (in an information-theoretic sense) in itself. This assumes that every step of stochastic gradient descent (one step per image) is done in the clear; this is not what one would consider secure in cryptography literature.  A secure function evaluation (SFE) would encrypt the data and the computation in an end-to-end fashion; in particular, it would only reveal the final outcome of SGD over all images in the dataset without revealing any intermediate steps. Presuming that the new dataset is large (i.e., having N images), the ""information theoretic"" limit becomes ~N x 1Mbyte inputs for ~1M function outputs (the finally-trained model). In this sense, this argument that ""encryption is hopeless"" is somewhat brittle.\n\nEncryption-issues aside, the paper would have been much stronger if it spent more effort in formalizing or evaluating different methods for assessing the value of data. The authors approach this by treating the ML algorithm as a blackbox, and using influence functions (a la Bastani 2017) to assess the impact of different inputs on the finally trained model (again, this is proposed but not implemented/explored/evaluated in any way). This is a design choice, but it is not obvious. There is extensive literature in statistics and machine learning on the areas of experimental design and active learning. Both are active, successful research areas, and both can be provide tools to formally reason about the value of data/labels not yet seen; the paper summarily ignores this literature.\n\n\nExamples of imprecise/informal statements:\n\n""The fairness in the pricing is highly questionable""\n""implicit contracts get difficult to verify""\n""The fairness in the pricing is dubious""\n""As machine learning models become more and more complicated, its (sic) capability can outweigh the privacy guarantees encryption gives us""\n""as an image classifier\'s model architecture changes, all the data would need to be collected and purchased again""\n""Interpretability solutions aim to alleviate the notoriety of reasonability of neural networks""']","[-80, -50, -50]","[20, 20, 20]","[""The sentiment score is -80 because the reviewer expresses significant concerns about the paper's clarity, originality, and relevance to the conference. They state that the paper's main ideas are difficult to comprehend, lack clear description and evaluation, and are out of scope for ICLR. The reviewer also mentions numerous issues with clarity and referencing. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'In my view' and 'I failed to find' rather than making blunt accusations. They also acknowledge that the paper addresses an important issue, which shows some respect for the authors' work. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -50 because the review starts with a mildly positive comment about the abstract being 'reasonably interesting,' but quickly turns negative, stating that the paper 'disappoints' and has 'no real technical content or contribution.' The reviewer also points out several areas needing improvement. The overall tone is more negative than positive, but not extremely harsh. The politeness score is 20 because while the reviewer is critical, they use relatively polite language. They start with a positive note and use phrases like 'I don't mind' and 'I don't agree' rather than more aggressive language. The reviewer also offers specific suggestions for improvement, which is constructive. However, the directness of some criticisms (e.g., 'the paper disappoints') prevents a higher politeness score."", ""The sentiment score is -50 because the reviewer expresses several criticisms, describing the paper's technical contribution as 'rather shallow' and noting that it doesn't experimentally or theoretically substantiate its claims. The reviewer also points out 'holes' in the paper's arguments and mentions 'informal statements and logical jumps'. However, the score isn't lower because the reviewer does acknowledge some valid points and interesting questions raised by the paper. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'the paper would have been much stronger if' rather than direct attacks, and provide detailed explanations for their criticisms. The language is not overtly polite, but it avoids rudeness and focuses on the content rather than personal critiques.""]"
"['This paper proposes an iterative approach to train deep neural networks based on morphism of the network structure into more complex ones. The ideas are rather simple, but could be potentially important for improving the performance of the networks. On the other hand, it seems that an important part of the work has already been done before (in particular Wei et al. 2016), and that the differences from there are very ad-hoc and intuition for why they work is not present. Instead, the paper justifies its approach by arguing that the experimental results are good. Personally, I am skeptical with that, because interesting ideas with great added value usually have some cool intuition behind them. The paper is easy to read, and there does not seem to exist major errors. Because I am not an active researcher in the topic, I cannot judge if the benefits that are shown in the experiments are enough for publication (the theoretical part is not the strongest of the paper).', 'This submission develops a learning scheme for training deep neural networks with adoption of network morphism (Wei et al., 2016), which optimizes a dynamic objective function in an iterative fashion capable of adapting its function form when being optimized, instead of directly optimizing a static objective function. Overall, the idea looks interesting and the manuscript is well-written. The shown experimental results should be able to validate the effectiveness of the learning scheme to some extent.\n\nIt would be more convincing to include the performance evaluation of the learning scheme in some representative applications, since the optimality of the training objective function is not necessarily the same as that of the trained network in the application of interest.\n\nBelow are two minor issues:\n\n- In page 2, it is stated that Fig. 2(e) illustrates the idea of the proposed network iterative learning scheme for deep neural networks based on network morphism. However, the idea seems not clear from Fig. 2(e).\n\n- In page 4, “such network iterative learning process” should be “such a network iterative learning process”.', 'This paper proposed an iterative learning scheme to train a very deep convolutional neural network. Instead of learning a deep network from scratch, the authors proposed to gradually increase the depth of the network while transferring the knowledge obtained from the shallower network by applying network morphism. \n\nOverall, the paper is clearly written and the proposed ideas are interesting. However, many parts of the ideas discussed in the paper (Section 3.3) are already investigated in Wei et al., 2016, which limits the novel contribution of the paper. Besides, the best performances obtained by the proposed method are generally much lower than the ones reported by the existing methods (e.g. He et al., 2016) except cifar-10 experiment, which makes it hard for the readers to convince that the proposed method is superior than the existing ones. More thorough discussions are required.\n']","[-20, 70, -20]","[50, 80, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some potential importance of the work, they express skepticism about its novelty and intuition. The reviewer points out that a significant part of the work has been done before and that the differences are ad-hoc. They also mention being skeptical about the approach's justification. However, the score is not deeply negative as the reviewer does note some positive aspects, such as the paper being easy to read and potentially important for improving network performance. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, acknowledging their own limitations ('I am not an active researcher in the topic') and presenting criticisms in a constructive manner. They avoid harsh language and present their concerns diplomatically, such as saying they are 'skeptical' rather than outright dismissive. The tone is professional and balanced, offering both positive and negative observations without being overly critical or confrontational."", ""The sentiment score is 70 (positive) because the reviewer describes the idea as 'interesting' and the manuscript as 'well-written'. They also state that the experimental results 'should be able to validate the effectiveness of the learning scheme'. However, it's not a perfect score as they suggest including more performance evaluations. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticism. They use phrases like 'It would be more convincing' and 'Below are two minor issues', which are polite ways to offer improvements. The reviewer also acknowledges the positive aspects of the work before suggesting changes."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is clearly written and the ideas are interesting, they express significant concerns about the novelty of the contribution and the performance compared to existing methods. The reviewer states that 'many parts of the ideas discussed in the paper are already investigated' in previous work, and that the performance is 'generally much lower than the ones reported by the existing methods'. These criticisms outweigh the initial positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, acknowledging positive aspects ('clearly written', 'interesting ideas') before presenting criticisms. They also use phrases like 'more thorough discussions are required' instead of more direct or harsh language. The tone is professional and constructive, even when pointing out limitations.""]"
"['The paper presents a combination of evolutionary computation (EC) and variational EM for models with binary latent variables represented via a particle-based approximation.\n\nThe scope of the paper is quite narrow as the proposed method is only applicable to very specialised models. Furthermore, the authors do not seem to present any realistic modelling problems where the proposed approach would clearly advance the state of the art. There are no empirical comparisons with state of the art, only between different variants of the proposed method.\n\nBecause of these limitations, I do not think the paper can be considered for acceptance.\n\nDetailed comments:\n\n1. When revising the paper for next submission, please make the title more specific. Papers with very broad titles that only solve a very small part of the problem are very annoying.\n\n2. Your use of crossover operators seems quite unimaginative. Genomes have a linear order but in the case of 2D images you use it is not obvious how that should be mapped to 1D. Combining crossovers in different representations or 2D crossovers might fit your problem much better.\n\n3. Please present a real learning problem where your approach advances state of the art.\n\n4. For the results in Fig. 7, please run the algorithm until convergence or justify why that is not necessary.\n\n5. Please clarify the notation: what is the difference between y^n and y^(n)?\n', '## Review summary\n\nOverall, the paper makes an interesting effort to tightly integrate\nexpectation-maximization (EM) training algorithms with evolutionary algorithms\n(EA). However, I found the technical description lacking key details and the\nexperimental comparisons inadequate. There were no comparisons to non-\nevolutionary EM algorithms, even though they exist for the models in question.\nFurthermore, the suggested approach lacks a principled way to select\nand tune key hyperparameters. I think the broad idea of using EA as a substep\nwithin a monotonically improving free energy algorithm could be interesting,\nbut needs far more experimental justification.\n\n\n## Pros / Stengths\n\n+ effort to study more than one model family\n\n+ maintaining monotonic improvement in free energy\n\n\n## Cons / Limitations\n\n- poor technical description and justification of the fitness function\n\n- lack of comparisons to other, non-EA algorithms\n\n- lack of study of hyperparameter sensitivity\n\n\n## Paper summary\n\nThe paper suggests a variant of the EM algorithm for binary hidden variable\nmodels, where the M-step proceeds as usual but the E-step is different in two\nways. First, following work by J. Lucke et al on Truncated Posteriors, the\ntrue posterior over the much larger space of all possible bit vectors is\napproximated by a more tractable small population of well-chosen bit vectors,\neach with some posterior weight. Second, this set of bit vectors is updated\nusing an evolutionary/genetic algorithm. This EA is the core contribution,\nsince the work on Trucated Posteriors has appeared before in the literature.\nThe overall EM algorithm still maintains monotonic improvement of a free\nenergy objective.\n\nTwo well-known generative models are considered: Noisy-Or models for discrete\ndatasets and Binary Sparse Coding for continuous datasets. Each has a\npreviously known, closed-form M-step (given in supplement). The focus is on\nthe E-step: how to select the H-dimensional bit vector for each data point.\n\nExperiments on artificial bars data and natural image patch datasets compare\nseveral variants of the proposed method, while varying a few EA method\nsubsteps such as selecting parents by fitness or randomly, including crossover\nor not, or using generic or specialized mutation rates.\n\n\n## Significance\n\nCombining evolutionary algorithms (EA) within EM has been done previously, as\nin Martinez and Vitria (Pattern Recog. Letters, 2000) or Pernkopf and\nBouchaffra (IEEE TPAMI, 2005) for mixture models. However, these efforts seem\nto use EA in an ""outer loop"" to refine different runs of EM, while the present\napproach uses EA in a substep of a single run of EM. I guess this is\ntechnically different, but it is already well known that any E-step method\nwhich monotonically improves the free energy is a valid algorithm. Thus, the\npaper\'s significance hinges on demonstrating that the particular E step chosen\nis better than alternatives. I don\'t think the paper succeeded very well at\nthis: there were no comparisons to non-EA algorithms, or to approaches that\nuse EA in the ""outer loop"" as above.\n\n\n## Clarity of Technical Approach\n\nWhat is \\tilde{log P} in Eq. 7? This seems a fundamental expression. Its\nplain-text definition is: ""the logarithm of the joint probability where\nsummands that do not depend on the state s have been elided"". To me, this\ndefinition is not precise enough for me to reproduce confidently... is it just\nlog p(s_n, y_n | theta)? I suggest revisions include a clear mathematical\ndefinition. This omission inhibits understanding of this paper\'s core\ncontributions.\n\nWhy does the fitness expression F defined in Eq. 7 satisfy the necessary\ncondition for fitness functions in Eq. 6? This choice of fitness function does\nnot seem intuitive to me. I think revisions are needed to *prove* this fitness\nfunction obeys the comparison property in Eq. 6.\n\nHow can we compute the minimization substep in Eq. 7 (min_s \\tilde{logP})? Is\nthis just done by exhaustive search over bit vectors? I think this needs\nclarification.\n\n\n## Quality of Experiments\n\nThe experiments are missing a crucial baseline: non-EA algorithms. Currently\nonly several varieties of EA are compared, so it is impossible to tell if the\nsuggested EA strategies even improve over non-EA baselines. As a specific\nexample, previous work already cited in this paper -- Henniges et al (2000) --\nhas developed a non-EA EM algorithm for Binary Sparse Coding, which already\nuses the truncated posterior formulation. Why not compare to this?\n\nThe proposed algorithm has many hyperparameters, including number of\ngenerations, number of parents, size of the latent space H, size of the\ntruncation, etc. The current paper offers little advice about selecting these\nvalues intelligently, but presumably performance is quite sensitive to these\nvalues. I\'d like to see some more discussion of this and (ideally) more\nexperiments to help practitioners know which parameters matter most,\nespecially in the EA substep.\n\nRuntime analysis is missing as well: Is runtime dominated by the EA step? How\ndoes it compare to non-EA approaches? How big of datasets can the proposed\nmethod scale to?\n\nThe reader walks away from the current toy bars experiment somewhat confused.\nThe Noisy-Or experiment did not favor crossover and and favored specialized\nmutations, while the BSC experiment reached the opposite conclusions. How does\none design an EA for a new dataset, given this knowledge? Do we need to\nexhaustively try all different EA substeps, or are there smarter lessons to\nlearn?\n\n\n\n## Detailed comments\n\nBottom of page 1: I wouldn\'t say that ""variational EM"" is an approximation to\nEM. Sometimes moving from EM to variational EM can mean we estimate posteriors\n(not point estimates) for both local (example-specific) and global parameters.\nInstead, the *approximation* comes simply from restricting the solution space\nto gain tractability.\n\nSec. 2: Make clear earlier that hidden var ""s"" is assumed to be discrete, not\ncontinuous.\n\nAfter Mutation section: Remind readers that ""N_g"" is number of generations\n', 'This paper proposes an evolutionary algorithm for solving the variational E step in expectation-maximization algorithm for probabilistic models with binary latent variables. This is done by (i) considering the bit-vectors of the latent states as genomes of individuals, and by (ii) defining the fitness of the individuals as the log joint distribution of the parameters and the latent space.\n \nPros:\nThe paper is well written and the methodology presented is largely clear.\n\nCons:\nWhile the reviewer is essentially fine with the idea of the method, the reviewer is much less convinced of the empirical study. There is no comparison with other methods such as Monte carlo sampling.\nIt is not clear how computationally Evolutionary EM performs comparing to Variational EM algorithm and there is neither experimental results nor analysis for the computational complexity of the proposed model.\nThe datasets used in the experiments are quite old. The reviewer is concerned that these datasets may not be representative of real problems.\nThe applicability of the method is quite limited. The proposed model is only applicable for the probabilistic models with binary latent variables, hence it cannot be applied to more realistic complex model with real-valued latent variables.']","[-70, -50, -20]","[-20, 20, 50]","[""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper's scope is narrow, lacks realistic modeling problems, and doesn't advance the state of the art. They explicitly state 'I do not think the paper can be considered for acceptance.' The politeness score is -20 because while the language isn't overtly rude, it's quite direct and critical. The reviewer uses phrases like 'very annoying' and 'quite unimaginative,' which come across as somewhat impolite. However, they do provide specific recommendations for improvement, which slightly mitigates the negative tone."", ""The sentiment score is -50 because the review expresses significant concerns about the paper's technical description, experimental comparisons, and lack of justification for key aspects. While it acknowledges some positive points ('interesting effort', 'maintaining monotonic improvement'), the overall tone is critical. The politeness score is 20 because the reviewer uses professional and respectful language throughout, avoiding harsh or personal criticisms. They offer constructive feedback and suggestions for improvement, which contributes to the politeness. However, the score is not higher due to the directness of some criticisms and the lack of more explicitly positive or encouraging statements."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros ('well written', 'methodology presented is largely clear'), they express more concerns and criticisms. The cons outweigh the pros, with issues raised about lack of comparison with other methods, unclear computational performance, outdated datasets, and limited applicability. However, the sentiment isn't strongly negative as the reviewer states they are 'essentially fine with the idea of the method'. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout. They present their criticisms constructively, using phrases like 'The reviewer is concerned' and 'It is not clear' rather than making blunt or harsh statements. The review maintains a balanced tone, acknowledging both pros and cons, which contributes to its politeness.""]"
"['This paper learns to construct masks and feature representations from an input image, in order to represent objects. This is applied to the relatively simple domain of Atari games video input (compared to natural images). The paper is completely inadequate in respect to related work; it re-invents known techniques like non-maximum suppression and matching for tracking; fails to learn convincing objects according to visual inspection; and fails to compare with earlier methods for these tasks. (The comment above about re-invention is the most charitable intepretation -- the worst case would be using these ideas without citation.)\n\n\n1) The related work section is outrageous, containing no references before 2016.  Do the authors think researchers never tried to do this task before then? This is the bad side of the recent deep nets hype, and ICLR is particularly susceptible to this. Examples include\n\n@article{wang-adelson-94,\n  author        = ""Wang,  J. Y. A. and Adelson, E. H."",\n  title         = {{Representing Moving Images with Layers}},\n  journal       = {{IEEE Transactions on Image Processing}},\n  year          = ""1994"",\n  volume        = ""3(5)"",\n  pages         = {625-638}\n}\nsee http://persci.mit.edu/pub_pdfs/wang_tr279.pdf\n\nand\n\n@article{frey-jojic-03,\n   author    = {Frey, B. J. and Jojic, N.},\n   title     = {{Transformation Invariant Clustering Using the EM Algorithm}},\n   journal   = {IEEE Trans Pattern Analysis and Machine Intelligence},\n   year      = {2003},\n   volume    = {25(1)},\n   pages     = {1-17}\n}\nwhere mask and appearances for each object of interest are learned. There is a literature which follows on from the F&J paper.  The methods used in Frey & Jojic are different from what is proposed in the paper, but there needs to be comparisons.\n\nThe AIR paper also contains references to relevant previous work.\n\n2) p 3 center -- this seems to be reinventing non-maximum suppression\n\n3) p 4 eq 3 and sec 3.2 -- please justify *why* it makes sense to use\nthe concrete transform.  Can you explain better (e.g. in the supp mat)\nthe effect of this for different values of q_i?\n\n4) Sec 3.5 Matching objects in successive frames using the Hungarian \nalgorithm is also well known, e.g. it is in the matlab function\nassignDetectionsToTracks .\n\n5) Overall: in this paper the authors come up with a method for learning objects from Atari games video input. This is a greatly restricted setting compared to real images. The objects learned as shown in Appendix A are quite unconvincing, e.g. on p 9. For example for Boxing why are the black and white objects broken up into 3 pieces, and why do they appear coloured in col 4?\n\nAlso the paper lacks comparisons to other methods (including ones from before 2016) which have tackled this problem.\n\nIt may be that the methods in this paper can outperform previous ones -- that would be interesting, but it would need a lot of work to address the issues raised above.\n\nText corrections:\n\np 2 ""we are more precise"" -> ""we give more details""\n\np 3 and p 2 -- local maximum (not maxima) for a single maximum.  [occurs many times]\n', 'The paper proposes a neural architecture to map video streams to a discrete collection of objects, without human annotations, using an unsupervised pixel reconstruction loss. The paper uses such object representation to inform state representation for reinforcement learning. Each object is described by a position, appearance feature and confidence of existence (presence). The proposed network predicts a 2D mask image, where local maxima  correspond to object locations, and values of the maxima correspond to presence values. The paper uses a hard decision on the top-k objects (there can be at most k objects) in the final object list, based on the soft object presence values (I have not understood if these top k are sampled based on the noisy presence values or are thresholded, if the authors could kindly clarify).  \n The final presence values though are sampled using Gumbell-softmax.\n\nObjects are matched across consecutive frames using non parametric (not learnable) deterministic matching functions, that takes into account the size and appearance of the objects. \n\nFor the unsupervised reconstruction loss, a static background is populated with objects, one at a time, each passing its state and feature through deconvolution layers to generate RGB object content.\n\nThen a policy network is trained with deep Q learning whose architecture takes into account the objects in the scene, in an order agnostic way, and pairwise features are captured between pairs of objects, using similar layers as visual interaction nets.\n\nPros\nThe paper presents interesting ideas regarding unsupervised object discovery\n\nCons:\nThe paper shows no results. The objects discovered could be discovered with mosaicing (since the background is static) and background subtraction. \n', 'The paper proposes a method  for learning object representations from pixels and then use such representations for doing reinforcement learning.  This method is based on convnets that map raw pixels to a mask and feature map. The mask contains information about the presence/absence of objects in different pixel locations and the feature map contains information about object appearance. \n\nI believe that the current method can only learn and track simple objects in a constant background, a problem which is  well-solved in computer vision. Specifically, a simple method such as ""background subtraction"" can easily infer the mask (the outlying pixels which correspond to moving objects)  while simple tracking methods (see a huge literature over decades on computer vision) can allow to track these objects across frames.  The authors completely ignore all this previous work and their ""related work"" section  starts citing papers from 2016 and onwards!  Is it any benefit of learning objects with the current (very expensive) method compared to simple methods such as  ""background subtraction""? \n\nFurthermore, the paper is very badly written since it keeps postponing the actual explanations to later sections (while these  sections eventually refer to the appendices).  This makes reading the paper very hard. For example, during the early sections you  keep referring to a loss function which will allow for learning the objects, but you never really give the form of this loss (which you should as soon as  you mentioning it) and the reader needs to search into the appendices to find out what is happening.  \n\nAlso, experimental results are very preliminary and not properly analyzed.  For example the results in Figure 3 are unclear and need to be discussed in detail in the main text. ']","[-80, -20, -70]","[-20, 50, -30]","[""The sentiment score is -80 because the review is highly critical of the paper. The reviewer states that the paper is 'completely inadequate' in terms of related work, 're-invents known techniques', 'fails to learn convincing objects', and 'fails to compare with earlier methods'. These are strong negative criticisms. The politeness score is -20 because while the reviewer provides specific feedback and suggestions, the language used is quite direct and at times harsh. Phrases like 'outrageous' and 'this is the bad side of the recent deep nets hype' come across as impolite. However, the reviewer does provide constructive feedback and suggestions for improvement, which prevents the score from being even lower."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some 'interesting ideas' in the paper, they also point out significant cons, particularly that the paper 'shows no results' and that the objects discovered could potentially be found through simpler methods. This suggests overall dissatisfaction with the paper's contribution. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout and even uses phrases like 'if the authors could kindly clarify', which shows respect. However, the criticism, while valid, is presented quite directly without much softening language, preventing a higher politeness score."", ""The sentiment score is -70 because the reviewer expresses significant criticism throughout the review. They question the novelty and effectiveness of the proposed method, criticize the writing style, and state that the experimental results are preliminary and unclear. The only slightly positive aspect is the initial acknowledgment of the paper's proposal, but this is quickly followed by criticism. The politeness score is -30 because while the reviewer doesn't use explicitly rude language, their tone is quite harsh and dismissive. They use phrases like 'very badly written,' 'completely ignore,' and 'very preliminary,' which come across as impolite in academic discourse. The reviewer also doesn't offer any positive feedback or constructive suggestions for improvement, which further contributes to the impolite tone.""]"
"['This paper describes improvements to a system described in a blog post for musical style transfer.  Such a system is difficult to evaluate, but examples are presented where the style of one song is applied to the content of another.  These audio examples show that the system produces somewhat reasonable mixtures of two songs, but suggest that if the system instead followed the (mostly) accepted rules for cover song generation, it could make the output much more pleasant to listen to.  Additional evaluation includes measuring correlations between style songs and the output to ensure that it is not being used directly as well as some sort of measure of key invariance that is difficult to interpret.  The paper does not completely define the mathematical formulation of the system, making it difficult to understand what is really going on.\n\nThe current paper changes the timbre, rhythm, and harmony of the target content song.  Changing the harmony is problematic as it can end up clashing with the generated melody or just change the listener\'s perception of which song it is.  I suggest instead attempting to generate a cover version of the content song in the style of the style song. Cover songs are re-performances of an existing (popular) song by another artist.  For example, Jimi Hendrix covered Bob Dylan\'s ""All along the watchtower"" and the Hendrix version became more popular than the original.  This is essentially artist A performing a song by artist B, which is very similar to the goal of the current paper.  Cover songs almost always maintain the lyrics, melody, and harmony of the original, while changing the timbre, vocal style, tempo, and rhythmic information.  This seems like a good way to structure the problem of musical style transfer.  Many systems exist for identifying cover songs, see the relevant publications at the International Society for Music Information Retrieval (ISMIR) Conference.  Few systems do something with cover songs after they have been identified, but they could be used for training a system like the one proposed here, if it could be trained. \n\nAnother musically questionable operation is pooling across frequency in the constant-Q transform representation.  In western music, adjacent notes are very different from one another and are usually not played in the same key, for example C and C#.  Thus, pooling them together to say that one of them is present seems to lose useful information.  As part of the pooling discussion, the paper includes an investigation of the key-invariance of the model.  Results from this are shown in figure 5, but it is difficult to interpret this figure.  What units is the mean squared error measured in?  What would be a big value?  What would be a small value?  What aspects of figure 5 specifically ""confirm that changing key between style [and] content has less of an effect on our proposed key-invariant content representations""?\n\nSection 3.1, which describes the specifics of the model, is confusing.  What exactly are S, C, W, and G?  What are their two dimensions indexed by i and j?  How do you compute them from the input?  Which parameters in this model are learned and which are just calculated?  Is there any training or is L(X,C,S) just optimized at test time?\n\nFinally, the evaluation of the texture generation part of the algorithm could be compared to existing texture generation algorithms (there are several) such as McDermott & Simoncelli (2011, NEURON), which even has code available online.\n\n\n\nMinor comments\n--------------\n\np2: ""in the this work"" typo\n\np2: ""an highly"" typo\n\np2: ""The first method... The latter class of methods"" confusing wording.  Is the second one a different method or referring back to the previous method?  If it\'s different, say ""The second method...""\n\np7: Please describe kernel sizes in real units (e.g., ms, Hz, cents) as well as numbers of bins\n\n\n\nAfter revision/response\n--------------------------------\nThe revisions of the paper have made it clearer as to what is going on, although the description of the algorithm itself could still be described more mathematically to really make it clear.  It is more clear what\'s going on in figure 5, although it could also be further clarified whether the green bars are showing the distance between log magnitude STFTs of the transposed ""style"" snippets and the untransposed ""content"" snippets directly and so provide an upper bound on the distances. My overall rating of the paper has not changed.', 'This paper studies style transfer for musical audio, and largely proposes some additions to the framework proposed by Ulyanov and Lebedev.  The changes are designed to improve the long-term temporal structure and harmonic matching of the stylized audio.  They carry out a few experiments to demonstrate how their proposed approach improves upon the baseline model.\n\nOverall, I don\'t think this paper provides sufficiently novel or justified contributions compared to the baseline approach of Ulyanov and Lebedev.  It largely studies what happens when a different spectrogram representation is used on the input, and when somewhat different network architectures are used.  These changes are interesting, but don\'t provide a lot of additional information which I believe would be interesting to the ICLR community.  They seem better suited for an (audio) signal processing venue, or a more informal venue.  In addition, the results are not terribly compelling.  If the proposed changes (which are heuristically, not theoretically motivated) resulted in huge improvements to sound quality, I might be convinced.  More concretely, the results are still very far away from being able to be used in a commercial application (in contrast with image style transfer, whose impressive results were immediately commercially applied).  One reason I think the results remain bad is that the audio signal is still fundamentally represented as a phase-invariant representation.  Even if you backpropagate through the time-frequency transformation, the transformation itself discards phase, and so various signals (with different phase characteristics) will appear the same after transformation.  I believe this contributes the most to the fact that the resulting audio sounds very artifact-ridden and unrealistic.  If the paper had been able to overcome this limitation, I might be more convinced, but as-is I don\'t think it warrants acceptance at ICLR.\n\nSpecific comments:\n\n- The description of Ulyanov & Lebedev\'s algorithm in 3.1 is confusingly structured.  For example, the sentence ""The L2\ndistance between the generated audio and the content audio’s feature maps..."" is basically a concatenation of roughly 6 thoughts which should be separated into different sentences.  The location of the equations (1), (2) do not correspond to where they are introduced in the text.  In addition, I don\'t understand how S and C are generated.  It is written that S and C are the ""log-magnitude feature maps for style and content"".  But the ""feature maps"" X are themselves a log-magnitude time frequency representation (x) convolved with the filterbank.  So how are S and C ""log-magnitude feature maps""?  Surely you aren\'t computing the log of the output of the filterbank?  More equations would be helpful here.  Finally, it would be helpful to provide an equation both for G and W instead of just saying that W is analogously defined.\n- I don\'t see any reason to believe that a mel-scaled spectrogram would better capture longer time scales or rhythmic information.  Mel-scaling your spectrogram just changes the frequency axis to a mel scale, which makes it somewhat closer to our perception; it does not modify the way time is represented in any way.  In fact, in musical machine learning tasks usually swapping between CQT and mel-scaled spectrograms (with a comparable number of frequency bins) has little effect, so I don\'t see any compelling reason to use one for ""rhythm"".  You need to provide strong empirical or theoretical evidence to back up your claim that this is a principled approach.  Instead, I would expect that your change of convolutional structure (to the dilated convolutions, etc) for the ""mel spectrogram"" branch of your network would account more heavily for stronger modeling of longer timescales.\n- You refer to ""WaveNet auto-encoders"" and cite van den Oord et al.  The original wavenet paper did not propose an auto-encoder structure; Engel et al. did.\n- ""neither representation is capable of representing spatial patterns along the frequency axis"" What do you mean by this?  Mel or linear-frequency (or CQT) spectrograms exhibit very strong patterns along their frequency axis.\n- The method for automatically setting the scales of the different loss terms seems interesting, but I can\'t find anywhere a description of how you apply each of the beta terms.  Are they analogous to the alpha and beta parameters in equation (4)?  If so, it appears that gamma is shared across each beta term; this would mean that changing the value of gamma simply changed the scale of all loss terms at once, which would have no effect on optimization.\n- ""This is entirely possible though the ensemble representation"" typo, through -> through\n- That instance normalization causes noisy audio is an interesting empirical result, but I\'m interested in a principled explanation of why this would happen.\n- ""the property of having 0 mean and unit variance"" - you use this to describe the SeLU nonlinearity.  That\'s not a property of the nonlinearity, it\'s a property of the activations of different layers when using the nonlinearity (given correct initialization).\n- How are the ""Inter-Onset Interval Length Distributions"" computed?  How are you getting the onsets, etc?\n- "" the maximum cross-correlation value between the time-domain audio waveforms are not significantly affected by the length of this field"" - there are many ways effective copying could happen without the time-domain cross-correlation being large.', 'Summary\n-------\nThis paper describes a method for style transfer in musical audio recordings.\nThe proposed method uses three spectral representations to encode rhythm (Mel spectra), harmony (pseudo-constant-Q), and content (STFT), and the shared representation designed to allow synthesis of the time domain signal directly without resorting to phase retrieval methods.\nSome quantitative evaluation is presented for texture synthesis and key invariance, but the main results seem to be qualitative analysis and examples included as supplemental material.\n\n\nQuality\n-------\n\nI enjoyed reading this paper, and appreciate the authors\' attention to the specifics of the audio domain.\nThe model design choices make sense in general, though they could be better motivated in places (see below).\nI liked the idea of the rhythm evaluation, but again, I have some questions about the specific implementation.\nThe supplementary audio examples are somewhat hit or miss in my opinion, and a bit more qualitative analysis or a listener preference study would strengthen the paper considerably.\n\n\nClarity\n-------\n\nWhile for the most part, the writing is clear and does a good job of describing the representations used, there are a few parts that could be made more explicit:\n\n- Section 3.2: The motivation for using the Mel spectrum to capture rhythm seems shaky.  Each frame has the same temporal resolution as the input STFT representation, so any ability to\n  capture rhythmic content should be due to down-stream temporal modeling (dilated residual block, in the model).  This does not necessitate or suggest a Mel spectrum, though dimensionality\n  reduction is probably beneficial.  It would be good to provide a bit more motivation for the choices made here.\n\n- Section 3.2.1: the description of the Mel spectrogram leaves out a few important details, such as the min/max frequencies, shape of the filters, and number of filters.\n\n- Section 3.2.2: the ""pseudo-CQT"" described here is just a different log-frequency projection of the STFT (and not constant-Q), and depending on the number of parameters, could be quite\n  redundant with the Mel spectrum.  A bit more detail here about the parametrization (filter shapes, etc) and distinction from the Mel basis would be helpful.\n\n- Section 3.3: I didn\'t completely follow the setup of the objective function.  Is there a difference gamma parameter for each component of the model?\n\n- Section 3.4: What is the stride of the pooling operator in the harmony component of the model?  It seems like this could have a substantial impact on any key-invariance properties.\n\n- Section 4.1: the idea to measure IOI distributions is clever, but how exactly is it implemented?  Does it depend on a pre-trained onset detector?  If so, which one?  I could imagine\n  texture synthesis preserving some aspects of rhythm but destroying onset detection accuracy due to phase reconstruction (whooshiness) problems, and that does not seem to be controlled in\n  this experiment.\n\n- Figure 4: how is Phi_{XY} defined?  The text does not convey this clearly.\n\n- Section 4.2: why is MSE of the log-stft a good metric for this problem?  Changing the key of a piece would substantially change its (linear) spectrum, but leave it relatively constant in\n  other representations (eg Mel/MFCC, depending on the bin resolution).  Maybe I don\'t entirely understand what this experiment is measuring.\n\n- General note: please provide proper artist attribution for the songs used in the examples (eg Figure 2).\n\n\nOriginality\n-----------\n\nThe components of the model are not individually novel, but their combination and application are compelling.\nThe approaches to evaluation, while still somewhat unclear, are interesting and original to the best of my knowledge, and could be useful for other practitioners in need of ways to evaluate\nstyle transfer in music.\n\n\n\nSignificance\n------------\n\nThis paper will definitely be of interest to researchers working on music, audio, or creative applications, particularly as a proof of concept illustrating non-trivial style transfer outside\nof visual domains.\n']","[-20, -70, 50]","[50, 20, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('somewhat reasonable mixtures', 'improvements'), they express several criticisms and suggest significant changes. The overall tone indicates the paper needs substantial work. The politeness score is moderately positive (50) as the reviewer uses professional language, offers constructive suggestions, and avoids harsh criticism. They use phrases like 'I suggest' and 'could be compared to' rather than making demands. The reviewer also provides detailed explanations for their critiques, which is a polite way to give feedback."", ""The sentiment score is -70 because the reviewer expresses significant criticism of the paper, stating it lacks novelty and justification, and recommending against acceptance. They use phrases like 'I don't think this paper provides sufficiently novel or justified contributions' and 'I don't think it warrants acceptance at ICLR'. However, it's not entirely negative as they do acknowledge some interesting aspects. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use polite phrases like 'I might be more convinced' and provide detailed, constructive feedback. The language is not overtly rude, but the criticism is direct and unambiguous, preventing a higher politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses enjoyment and appreciation for the paper, stating 'I enjoyed reading this paper, and appreciate the authors' attention to the specifics of the audio domain.' However, they also point out several areas for improvement and clarification, balancing the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism in a considerate manner. They use phrases like 'I liked the idea' and 'It would be good to provide' which maintain a polite tone while suggesting improvements. The reviewer also acknowledges the paper's strengths and potential significance, further contributing to the polite tone.""]"
"['\nThis paper considers hyperparameter searches in which all of the\ncandidate points are selected in advance.  The most common approaches\nare uniform random search and grid search, but more recently\nlow-discrepancy sequences have sometimes been used to try to achieve\nbetter coverage of the space.  This paper proposes using a variant of\nthe determinantal point process, the k-DPP to select these points.\nThe idea is that the DPP provides an alternative form of diversity to\nlow-discrepancy sequences.\n\nSome issues I have with this paper:\n\n1. Why a DPP? It\'s pretty heavyweight. Why not use any of the other\n(potentially cheaper) repulsive point processes that also achieve\ndiversity?  Is there anything special about it that justifies this\nwork?\n\n2. What about all of the literature on space-filling designs, e.g.,\nlatin hypercube designs?  Statisticians have thought about this for a\nlong time.\n\n3. The motivation for not using low-discrepancy sequences was discrete\nhyperparameters.  In practice, people just chop up the space or round.\nIs a simple kernel with one length scale on a one-hot coding adding\nvalue? In this setup, each parameter can only contribute ""same or\ndifferent"" to the diversity assessment.  In any case, the evaluations\ndidn\'t have any discrete parameters.  Given that the discrete setting\nwas the motivation for the DPP over LDS, it seems strange not to even\nlook at that case.\n\n4. How do you propose handling ordinal variables? They\'re a common\ncase of discrete variables but it wouldn\'t be sensible to use a\none-hot coding.\n\n5. Why no low discrepancy sequence in the experimental evaluation of\nsection 5?  Since there\'s no discrete parameters, I don\'t see what the\nlimitation is.\n\n6. Why not evaluate any other low discrepancy sequences than Sobol?\n\n7. I didn\'t understand the novelty of the MCMC method relative to\nvanilla M-H updates.  It seems out of place.\n\n8. The figures really need error bars --- Figure 3 in particular.  Are\nthese differences statistically significant?\n', 'The authors propose k-DPP as an open loop (oblivious to the evaluation of configurations) method for hyperparameter optimization and provide its empirical study and comparison with other methods such as grid search, uniform random search, low-discrepancy Sobol sequences, BO-TPE (Bayesian optimization using tree-structured Parzen estimator) by Bergstra et al. (2011). The k-DPP sampling algorithm and the concept of k-DPP-RBF over hyperparameters are not new, so the main contribution here is the empirical study. \n\nThe first experiment by the authors shows that k-DPP-RBF gives better star discrepancy than uniform random search while being comparable to low-discrepancy Sobol sequences in other metrics such as distance from the center or an arbitrary corner (Fig. 1).\n\nThe second experiment shows surprisingly that for the hard learning rate range, k-DPP-RBF performs better than uniform random search, and moreover, both of these outperform BO-TPE (Fig. 2, column 1).\n\nThe third experiment shows that on good or stable ranges, k-DPP-RBF and its discrete analog slightly outperform uniform random search and its discrete analog, respectively.\n\nI have a few reservations. First, I do not find these outcomes very surprising or informative, except for the second experiment (Fig. 2, column 1). Second, their study only applies to a small number like 3-6 hyperparameters with a small k=20. The real challenge lies in scaling up to many hyperparameters or even k-DPP sampling for larger k. Third, the authors do not compare against some relevant, recent work, e.g., Springenberg et al. (http://aad.informatik.uni-freiburg.de/papers/16-NIPS-BOHamiANN.pdf) and Snoek et al. (https://arxiv.org/pdf/1502.05700.pdf) that is essential for this kind of empirical study. \n\n  ', 'In this paper, the authors consider non-sequential (in the sense that many hyperparameter evaluations are done simultaneously) and uninformed (in the sense that the hyperparameter evaluations are chosen independent of the validation errors observed) hyperparameter search using determinantal point processes (DPPs). DPPs are probability distributions over subsets of a ground set with the property that subsets with more ""diverse"" elements have higher probability. Diverse here is defined using some similarity metric, often a kernel. Under the RBF kernel, the more diverse a set of vectors is, the closer the kernel matrix becomes to the identity matrix, and thus the larger the determinant (and therefore probability under the DPP) grows. The authors propose to do hyperparameter tuning by sampling a set of hyperparameter evaluations from a DPP with the RBF kernel.\n\nOverall, I have a couple of concerns about novelty as well as the experimental evaluation for the authors to address. As the authors rightly point out, sampling hyperparameter values from a DPP is equivalent to sampling proportional to the posterior uncertainy of a Gaussian process, effectively leading to a pure exploration algorithm. As the authors additionally point out, such methods have been considered before, including methods that directly propose to batch Bayesian optimization by choosing a single exploitative point and sampling the remainder of the batch from a DPP (e.g., [Kathuria et al., 2016]). The default procedure for parallel BayesOpt used by SMAC [R2] is (I believe) also to choose a purely explorative batch. I am unconvinced by the argument that ""while this can lead to easy parallelization within one iteration of Bayesian optimization, the overall algorithms are still sequential."" These methods can typically be expanded to arbitrarily large batches and fully utilize all parallel hardware. Most implementations of batch Bayesian optimization in practice (SMAC and Spearmint as examples) will even start new jobs immediately as jobs finish -- these implementations do not wait for the entire batch to finish typically.\n\nAdditionally, while there has been some work extending GP-based BayesOpt to tree-based parameters [R3], at a minimum SMAC in particular is known well suited to the tree-based parameter search considered by the authors. I am not sure that I agree that TPE is state-of-the-art on these problems: SMAC typically does much better in my experience. \n\nUltimately, my concern is that--considering these tools are open source and relatively stable software at this point--if DPP-only based hyperparameter optimization is truly better than the parallelization approach of SMAC, it should be straightforward enough to download SMAC and demonstrate this. If the argument that BayesOpt is somehow ""still sequential"" is true, then k-DPP-RBF should outperform these tools in terms of wall clock time to perform optimization, correct?\n\n[R1] Kathuria, Tarun and Deshpande, Amit and Kohli, Pushmeet. Batched Gaussian Process Bandit Optimization via Determinantal Point Processes, 2016.\n\n[R2] Several papers, see: http://www.cs.ubc.ca/labs/beta/Projects/SMAC/\n\n[R3] Jenatton, R., Archambeau, C., González, J. and Seeger, M., 2017, July. Bayesian Optimization with Tree-structured Dependencies. In International Conference on Machine Learning (pp. 1655-1664).']","[-50, -20, -50]","[20, 50, 50]","[""The sentiment score is -50 because the review is predominantly critical. While the first paragraph provides a neutral summary, the rest of the review consists of a list of issues and questions, indicating significant concerns with the paper. However, it's not entirely negative as the reviewer engages with the content seriously. The politeness score is 20 because the language is professional and constructive, avoiding harsh or personal criticism. The reviewer uses phrases like 'Some issues I have' and poses questions rather than making blunt statements. The tone is academic and respectful, though not overtly warm or encouraging."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the work, they express several reservations and criticisms. The reviewer notes that the main contribution is empirical study, implying a lack of theoretical novelty. They find only one experiment's outcome surprising or informative, and point out limitations in the study's scope and comparisons. However, the tone is not entirely negative, as they do recognize some positive results from the experiments. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout. They present their criticisms constructively, using phrases like 'I have a few reservations' rather than harsh or dismissive language. The reviewer also acknowledges the authors' findings and describes the work objectively before presenting their concerns."", ""The sentiment score is -50 because the reviewer expresses several concerns about the paper's novelty and experimental evaluation. They question the authors' claims about the advantages of their method over existing approaches, particularly in terms of parallelization. The reviewer also suggests that the authors' comparisons may not be against the most appropriate state-of-the-art methods. However, the score is not extremely negative as the reviewer does acknowledge some of the authors' points and provides constructive feedback. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I have a couple of concerns' and 'I am unconvinced by the argument' rather than harsh or dismissive language. The reviewer also provides specific references and suggestions for improvement, which is helpful and courteous. However, the score is not extremely high as the review is direct in its criticism and doesn't use overtly polite language.""]"
"['The paper proposes to use LSH to approximate softmax, which greatly speeds up classification with large output space. The paper is overall well-written. However, similar ideas have been proposed before, such as ""Deep networks with large output spaces"" by Vijayanarasimhan et. al. (ICLR 2015). And this manuscript does not provide any comparison to any of those similar methods.\n\nA few questions about the implementation,\n(1) As stated in the manuscript, the proposed method contains three steps, hashing, lookup and distance. GPU is not good at lookup, so the manuscript proposes to do lookup on CPU. Does that mean the data should go back and forth between CPU and GPU? Would this significantly increase the overhead?\n(2) At page 6, the LSH structure returns m list of C candidates. Is it a typo? C is the total number of classes. And how do you guarantee that each LSH query returns the same amount of candidates?\n\nExperiment-wise, the manuscript leaves something to be desired.\n(1) More baselines be evaluated and compared. In this manuscript, only IS and NS are compared. And pure negative sampling is actually rarely used in language modeling. In addition to Vijayanarasimhan\'s LSH method, there are also a few other methods out there, such as hierarchical softmax, NCE, D-sothat ftmax (""Strategies for Training Large Vocabulary Neural Language Models"" by Chen et. al. ACL 2016), adaptive softmax (""Efficient softmax approximation for GPUs"" by Grave et. al).\n(2) The results of the proposed method is not impressive. D-softmax and adaptive softmax can achieve 147 ppl on text 8 with 512 hidden units as described in other paper, while the proposed method can only achieve 224 ppl with 650 hidden units. Even the exact softmax have large difference in ppl. It looks like the authors do not tune the hyper-parameters well. With this suboptimal setting, it is hard to judge the significance of this manuscript.\n(3) Why one billion word dataset is used in eval but not used for training? It is one of the best datasets to test the scalability of language models.\n(4) We can see, as reported in the manuscript, that NS has bigger speedup than the proposed method. So it would be nice to show ppl vs time curve for all methods. Eventually, what we want is the best model given a fixed amount of training time. With the same amount of epochs, NS loses the advantage of being faster.', 'In this paper, the authors propose a new approximation of the softmax, based on approximate nearest neighbors search and sampling.\nMore precisely, they propose to approximate to partition function (which is the bottleneck to compute the softmax and its gradient), by using:\n- the top-k classes (retrieved using LSH) ;\n- uniform samples (to account for the tail of the distribution).\nThey describe how this technique can be used for learning, by performing sparse updates for the gradient (corresponding to the elements used to compute the partition function), and re-hashing the updated element of the softmax layers.\nIn section 5, they show how this method can be implemented on GPU, using standard operations available in neural networks framework such as TensorFlow or PyTorch.\nFinally, they compare their approach to importance sampling and negative sampling, using language modeling as a benchmark.\nThey use 3 standards datasets to perform the evaluations: penn treebank, text8 and wikitext-2.\n\nPros:\n - well written and easy to read paper\n - interesting theoretical guarantees of the approximation\nCons:\n - a bit incremental\n - weak empirical evaluations\n - no support for the claim of efficient GPU implementation\n\n== Incremental ==\n\nWhile the theoretical justification of the methods are interesting, these are not a contribution of the paper (but of previous work by Mussmann et al.).\nIn fact, the main contribution of this paper is to show how to apply the technique of Mussmann et al. in the setup of neural network.\nThe main difference with Mussmann et al. is the necessity of re-hashing the updated elements of the softmax at each step.\nOther previous works have also proposed to use LSH to speed up computations in neural network, but are not discussed in the paper (see list of references).\n\n== Weak evaluations ==\n\nI believe that the empirical evaluation of section 6 are a bit weak.\nFirst, there is a large gap between the perplexity obtained using the proposed method and the exact softmax (e.g. 97 v.s. 83 on ptb, 115 v.s. 95 on wikitext-2).\nThus, I do not believe that the experiments support the claim that the proposed method ""perform on-par with computing the exact softmax"".\nMoreover, these numbers are pretty far from what other papers have reported on these datasets with similar models (I am wondering if the gap would be even larger with SOTA models).\nSecond, the authors do not report any runtime numbers for their method and the baselines on GPUs.\nI believe that it would be more fair to plot the learning curves (Fig. 1) using the runtime instead of the number of epochs.\n\n== Efficient implementation ==\n\nIn section 5, the authors claims that their approach can be efficiently implemented on GPUs.\nHowever, several of the operations used by their approach are inefficient, especially when using mini-batches.\nThe authors state that only step 2 is inefficient, but I also believe that step 3 is (compared to sampling approaches).\nIndeed, for their method, each example of a mini-batch uses a different set of elements to approximate the partition function (while for other sampling methods, the same set is used for the whole batch).\nThus a matrix-matrix multiplication is replaced by n matrix-vector multiplication (n is the batch size).\nWhile these can be performed in parallel, it is much less efficient than a matrix-matrix multiplication.\nFinally, the only runtime numbers provided by the authors comparing their approach to sampling is for a CPU implementation with a batch of size 1.\nThis setting is super favorable to their approach, but a bit unrealistic for most practical settings.\n\n== Missing references ==\n\nScalable and Sustainable Deep Learning via Randomized Hashing\nRyan Spring, Anshumali Shrivastava\n\nA New Unbiased and Efficient Class of LSH-Based Samplers and Estimators for Partition Function Computation in Log-Linear Models\nRyan Spring, Anshumali Shrivastava\n\nDeep networks with large output spaces\nSudheendra Vijayanarasimhan, Jonathon Shlens, Rajat Monga & Jay Yagnik', 'Authors present LSH Softmax - a fast, approximate nearest neighbor search based, approach for computing softmax that utilizes the Gumbel distribution and it relies on an LSH implementation of the maximum inner product search.\n\nIn general the work presented in this paper is very interested and the proposed method is very appealing especially on large datasets. For the most part it draws from a previous work which is my main concern. It is very much inline with the previous work by Mussmman et al. and authors don’t really do a good job in emphasizing the relationship with this work which uses two datasets for their empirical analysis. This in turn gives the overall impression that their work is a simple addition to it. \n\nWith this in mind, my other concern is that their empirical analysis are only focused on a single task from the NLP domain (language modeling). \nIt would be good to see how well does the model generalizes across tasks in other domains outside of NLP. \nHow do the different softmax approaches perform across different model configurations? It appears that the analysis were performed using a single architecture. \nWhat about a performance comparison on an extrinsic task?\nAuthors should discuss the performance of LSH Softmax on the PTB train set. It appears that it outperforms the exact (i.e. “full”) Softmax or perhaps it’s an overlook on my end. \n\nOverall it feels that the paper was written really close to the conference deadline. Given the fact that the work is mostly based on the previous work by Mussmman et al. what would make the paper stronger and definitely ready to be presented at this conference is more in-depth performance analysis that would answer some of the above questions. \n\nLSH is typically an abbreviation for “Locality Sensitive” rather than “Locally-Sensitive” Hashing. At least this is the case with the original LSH approach.\n\nFor better clarity try rephrasing or splitting the first sentence in the second paragraph of the introduction. \n\nI think the authors spent too much time in background section of the paper where they give an overview of concepts that should be well known to the reader (NNs and Softmax). \n\nTheorem 3: Second sentence should be rephrased - “...and  $\\mathcal{T}$, and $l$ uniform samples from…”\nTheorem 3:  $\\epsilon$ and $\\delta$ should be formally introduced. \nSection 5: pretty much covers well known concepts related to GPU implementations. Authors should spent more time focusing on the empirical analysis of their approach. \n\nSection 6.1: “...to benchmark language modeling models...” should be rephrased.\nHow were the number of epochs chosen across the 3 collections? \n\nSection 6.1.1: “...note that the final perplexities are evaluated with using the full softmax…” - This sentence is very confusing and it should be rephrased.\n']","[-30, -30, -20]","[50, 20, 50]","[""The sentiment score is -30 because while the reviewer acknowledges that the paper is 'overall well-written', they express several significant concerns about the novelty, implementation, and experimental results. The reviewer points out that similar ideas have been proposed before and that the manuscript lacks comparison to these methods. They also raise questions about the implementation and express that the experimental results are 'not impressive' and leave 'something to be desired'. These criticisms outweigh the initial positive comment, resulting in a slightly negative overall sentiment. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout. They use polite phrases like 'It would be nice to show' and frame criticisms as questions or suggestions rather than direct attacks. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral to slightly positive level of politeness typical in academic discourse."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('well written and easy to read paper', 'interesting theoretical guarantees'), they express more significant concerns ('a bit incremental', 'weak empirical evaluations', 'no support for the claim of efficient GPU implementation'). The review is predominantly critical, pointing out several limitations and areas for improvement. The politeness score is 20 because the reviewer maintains a professional and objective tone throughout, using phrases like 'I believe' and 'I am wondering' to soften criticisms. They also acknowledge positive aspects before delving into concerns. However, the language is not overly polite or deferential, maintaining a neutral academic tone for the most part."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the work 'very interested' and 'appealing', they express several concerns. These include the paper's similarity to previous work, limited empirical analysis, and the impression that it was written close to the deadline. The reviewer suggests more in-depth analysis to strengthen the paper. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They avoid harsh or dismissive language, instead using phrases like 'It would be good to see' and 'Authors should discuss'. The tone is professional and aimed at helping the authors improve their work, rather than being overly critical.""]"
"['The authors propose a method for reducing the computational burden when performing inference in deep neural networks. The method is based a previously-developed approach called incomplete dot products, which works by pruning some of the inputs in the dot products via the introduction of pre-specified coefficients. The authors of this paper extend the method by introducing a task-wise learning procedure that sequentially optimizes a loss function for decreasing percentage of included features in the dot product. \n\nUnfortunately, this paper was hard to follow for someone who does not actively work in this field, making it hard to judge if the contribution is significant or not. While the description of the problem itself is adequate, when it comes to describing the TESLA procedure and the alternative training procedure, the relevant passages are, in my opinion, too vague to allow other researchers to implement this procedure.\n\nPositive points:\n- The application seems relevant, and the task-wise procedure seems like an improvement over the original IDP proposal.\n- Application to two well-known benchmarking datasets.\n\nNegative points:\n- The method is not described in sufficient detail to allow reproducibility, the algorithms are no more than sketches.\n- It is not clear to me what the advantage of this approach is, as opposed to alternative ways of compressing the network (e.g. via group lasso regularization), or training an emulator on the full model for each task.\n\nMinor point:\n- Figure 1 is unclear and requires a better caption. ', ""This paper presents a modification of a numeric solution: Incomplete Dot Product (IDP), that allows a trained network to be used under different hardware constraints. The IDP method works by incorporating a 'coefficient' to each layer (fully connected or convolution), which can be learned as the weights of the model are being optimized. These coefficients can be used to prune subsets of the nodes or filters, when hardware has limited computational capacity. \n\nThe original IDP method (cited in the paper) is based on iteratively training for higher hardware capacities. This paper improves upon the limitation of the original IDP by allowing the weights of the network be trained concurrently with these coefficients, and authors present a loss function that is linear combination of loss function under original or constrained network setting. They also present results for a 'harmonic' combination which was not explained in the paper at all.\n\nOverall the paper has very good motivation and significance. \nHowever the writing is not very clear and the paper is not self-contained at all. I was not able to understand the significance of early stopping and how this connects with loss aggregation, and how the learning process differs from the original IDP paper, if they also have a scheduled learning setting. \n\nAdditionally, there were several terms that were unexplained in this paper such as 'harmonic' method highlighted in Figure  3. As is, while results are promising, I can't fully assess that the paper has major contributions.  "", 'An approach to adjust inference speed, power consumption or latency by using incomplete dot products McDanel et al. (2017) is investigated.\n\nThe approach is based on `profile coefficients’ which are learned for every channel in a convolution layer, or for every column in the fully connected layer. Based on the magnitude of this profile coefficient, which determines the importance of this `filter,’ individual components in a neural net are switched on or off. McDanel et al. (2017) propose to train such an approach in a stage-by-stage manner.\n\nDifferent from a recently proposed method by McDanel et al. (2017), the authors of this submission argue that the stage-by-stage training doesn’t fully utilize the deep net performance. To address this issue a `loss aggregation’ is proposed which jointly optimizes a deep net when multiple fractions of incomplete products are used.\n\nThe method is evaluated on the MNIST and CIFAR-10 datasets and shown to outperform work on incomplete dot products by McDanel et al. (2017) by 32% in the low resource regime.\n\nSummary:\n——\nIn summary, I think the paper proposes an interesting approach but more work is necessary to demonstrate the effectiveness of the discussed method. The results are preliminary and should be extended to CIFAR-100 and ImageNet to be convincing. In addition, the writing should be improved as it is often ambiguous. See below for details.\n\nReview:\n—————\n1. Experiments are only provided on very small datasets. According to my opinion, this isn’t sufficient to illustrate the effectiveness of the proposed approach. As a reader I wouldn’t want to see results on CIFAR-100 and ImageNet using multiple network architectures, e.g., AlexNet and VGG16.\n\n2. Usage of the incomplete dot product for the fully connected layer and the convolutional layer seems inconsistent. More specifically, while the profile coefficient is applied for every input element in Eq. (1), it’s applied based on output channels in Eq. (2). This seems inconsistent and a comment like `These two approaches, however, are equivalent with negligible difference induced by the first hidden layer’ is more confusing than clarifying.\n\n3. The writing should be improved significantly and statements should be made more precise, e.g., `From now on, x% DP, where \\leq x \\geq 100, means the x% of terms used in dot products’. While sentences like those can be deciphered, they aren’t that appealing.\n\n4. The loss functions in Eq. (3) should be made more precise. It remains unclear whether the profile coefficients and the weights are trained jointly, separately, incrementally etc.\n\n5. Algorithm 1 and Algorithm 2 call functions that aren’t described/defined.\n\n6. Baseline numbers for training on datasets without incomplete dot products should be provided.\n']","[-30, -20, -20]","[50, 50, 50]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('Positive points'), the overall tone is critical. The reviewer states the paper was 'hard to follow' and lists several 'Negative points', indicating that the contribution's significance is unclear and the method description is insufficient. However, it's not entirely negative, as some merits are recognized.\n\nThe politeness score is 50 because the reviewer uses respectful language throughout, even when criticizing. They use phrases like 'Unfortunately' and 'in my opinion' to soften negative feedback. The reviewer also balances criticism with positive observations. However, the score isn't higher because the review is direct in its criticisms without excessive softening language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's 'very good motivation and significance' and 'promising' results, they express several concerns about clarity, self-containment, and unexplained terms. The reviewer states they 'can't fully assess that the paper has major contributions' due to these issues. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, balancing criticism with positive remarks. They avoid harsh or accusatory language, instead framing their concerns as observations (e.g., 'I was not able to understand') rather than direct criticisms of the authors."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper proposes an 'interesting approach', they also state that 'more work is necessary' and the results are 'preliminary'. The reviewer provides several critiques and suggestions for improvement, indicating they are not fully satisfied with the current state of the paper. The politeness score is moderately positive (50) as the reviewer uses polite and professional language throughout. They begin with a neutral summary and use phrases like 'I think' and 'According to my opinion' when giving feedback. The reviewer also provides specific, constructive suggestions for improvement rather than harsh criticisms. However, the score is not extremely high as the review is still direct in pointing out flaws and areas needing improvement.""]"
"['Overview:\nThe paper aim to model non-linear, intrinsically low-dimensional structure, in data by estimating ""transport operators"" that predict how points move along the manifold. This is an old idea, and the stated contribution of the paper is:\n""The main contribution of this paper is to show that the manifold representation learned in the transport operators is valuable both as a probabilistic model to improve general machine learning tasks as well as for performing transfer learning in classification tasks."" \nThe paper provide nice illustrative experiments arguing why transport operators may be a useful modeling tool, but does not go beyond illustrative experiments.\nWhile I follow the intuitions behind transport operators I am doubtful if they will generalize beyond very simple manifold structures (see detailed comments below).\n\nQuality:\nThe paper is well-written and fairly easy to follow. In particular, I appreciate that the authors make no attempt to overclaim contributions. From a methodology point-of-view, the paper has limited novelty (transport operators, and learning thereof has been studied elsewhere), but there are some technical insights (likelihood model, use in data augmentation). Since the provided experiments are mostly illustrations, I would argue that the significance of the paper is limited. I\'d say that to really convince a broader audience that this old idea is worth revisiting, the work must go beyond illustrations and apply to a real data problem.\n\nDetailed Comments and Questions:\n*) Equation 1 of the paper describe the key dynamics of the applied transport operators. Basically, the paper assume that the underlying data manifold is locally governed by a linear differential equation. This is a very suitable assumption, e.g., for the swiss roll data set, but it is unclear to this reader why it is a suitable assumption beyond such toy data. I would very much appreciate a detailed discussion of when this is a suitable modeling choice, and when it is not. My intuition is that this is mostly a suitable model when the data manifold appears due to simple transformations (e.g. rotations) of data. This is also exactly the type of data considered in the paper.\n*) In Eq. 3, should it be ""expm"" instead of ""exp"" ?\n*) The first two paragraphs of Sec. 2 are background material, whereas paragraph 3 and beyond describe material that is key to the paper. I would recommend introducing a \\subsection (or something like it) to make this more clear.\n*) The idea of working with transformations of data rather than the actual data is the corner-stone of Ulf Grenander\'s renowned ""Pattern Theory"". A citation to this seminal work would be appropriate.\n*) In the first paragraph of the introduction links are drawn to the neuroscience literature; it would be appropriate to cite a suitable publication.\n\nPros(+) & Cons(-):\n+ Well-written.\n+ Good illustrative experiments.\n- Real-life experiments are lacking.\n- Limited methodology contribution.\n- The assumed dynamics might be too simplistic (at least a discussing of this is missing).\n\nFor the AC:\nThe submitted paper acknowledges several grants (including grant numbers), which can directly be tied to the authors identity. This may be a violation of the double blind review policy. I did not use this information to determine the authors identity, though, so this review is still double blind.\n\nPost-rebuttal comments:\nThe paper has improved with the incorporated revisions, but my main concerns remain. I find the Swiss Roll / rotated-USPS examples to be too contrived as the dynamics are exactly tailored to the linear ODE assumption. These are examples where the model assumptions are perfect. What is unclear is how the model behaves when the linear ODE assumption is not-quite-correct-but-also-not-totally-incorrect, i.e. how the model behaves in real life. I didn\'t get that from the newly added experiment. So, I\'ll keep my rating as is. ', 'Summary:\n\nThe paper considers the framework of manifold transport operator learning of Culpepper and Olshausen (2009), and interpret it as obtaining a MAP estimate under a probabilistic generative model. Motivated by this interpretation, the authors propose a new similarity metric between data points, which leads to a new manifold embedding method. This also leads the authors to propose a new transfer learning mechanism that can lead to improvements in classification accuracy.\nSome representative simulation results are included to demonstrate the efficacy of the proposed methods.\n\nMain comments:\n\nThis direction is interesting.  But unfortunately the paper is confusingly written and several points are never made clear. The conveyed impression is that the proposed methods are mainly incremental additions to the framework of Culpepper and Olshausen.\n\nIt would be far more helpful if the authors would have clearly described the following in more detail:\n-  The new manifold embedding algorithm in Section 2 --  a proper explanation of the similarity measure, what the role of the MSE is in this algorithm, how to choose the parameters gamma and zeta etc.\n- Why the authors claim that this method is more robust than other classical manifold learning methods. There certainly seems to be some robustness improvement over Isomap -- but this is a somewhat weak strawman since Isomap is notoriously prone to improper neighborhood selection.\n- Why the transport operator viewpoint is an improvement over other out-of-sample approaches in manifold learning.\n- Why the data augmentation using learned transport operators would be more beneficial than augmentation using other mechanisms (manual rotations, other generative models).\n\netc.\n\n\nOther comments/questions:\n\n- Bit confused about the experiment for Figure 1. Why set gamma = 0? Also, you seem to be fixing the number of dictionary elements to two (suggesting an ell-0 constraint), but also impose an ell-1 constraint. Why both?\n- From what distribution are the random coefficients governing the transport operators drawn (uniform? gaussian?) how to choose the anchor points?\n- The experiment in USPS digits is somewhat confusing. Rotations are easy to generate, so the ""true rotation"" curve is probably the easiest to implement and also the best performing -- so why go through the transport operator training process at all?  In any case, I would be careful to not draw too many conclusions from a single experiment on MNIST.\n\n================\n\nPost-rebuttal comments:\n\nThanks for the response. Still not convinced, unfortunately. I would go back to the classification example: it is unclear what the benefits of the transport operator viewpoint is over simply augmenting the dataset using rotations (or ""true rotations"" as you call them), or translations, or some other well-known parametric family. Even for the faces dataset, it seems that the transformations to model ""happiness"" or ""sadness"" are fairly simple to model and one does not need to solve a complicated sparse regression problem to guess the basis elements.  Consider fleshing this angle out a bit more in detail with some more compelling evidence (perhaps test on a bigger/more complex dataset?). \n', ""This paper propose to learn manifold transport operators via a dictionary learning framework that alternatively optimize a dictionary of transformations and coefficients defining the transformation between random pairs of data points. Experiments on the swiss roll and synthetic rotated images on USPS digits show that the proposed method could learn useful transformations on the data manifold.\n\nHowever, the experiments in the paper is weak. As the paper mentioned, manifold learning algorithms tend to be quite sensitive to the quality of data, usually requiring dense data at each local neighborhood to successfully learn the manifold well. However, this paper, claiming to be learn more rubust representations, lacks solid supporting experiments. The swiss roll is a very simple synthetic dataset. The USPS is also simple, and the manifold learning is performed on synthetic (rotated) USPS digits with only 1 manifold dimension. I would recommend testing the proposed algorithm on more complicated datasets (e.g. Imagenet or even CIFAR images) to see how well it performs in practice, in order to provide stronger empirical supports for the proposed method. At the current state, I don't think it is good for publishing at ICLR.\n\n=========================\nPost-rebuttal comments\n\nThanks for the updates of the paper and added experiments. I think the paper has improved over the previous version and I have updated my score.""]","[-30, -50, -50]","[50, 20, 20]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('well-written', 'good illustrative experiments'), they express significant doubts about the paper's broader applicability and impact ('doubtful if they will generalize', 'significance of the paper is limited'). The overall tone suggests more concerns than praise. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledges positive aspects, and phrases criticisms constructively ('I would recommend', 'I would appreciate'). However, it's not extremely polite, maintaining a professional, somewhat neutral tone. The reviewer also provides balanced feedback with both pros and cons listed."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's clarity and contributions. They state that the paper is 'confusingly written' and that the methods seem to be 'mainly incremental additions'. However, they do acknowledge that the direction is 'interesting', which prevents the score from being more negative. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'It would be far more helpful if...' and 'Thanks for the response' which add a degree of politeness. However, the directness of the criticism and the lack of strongly positive language keeps the score from being higher. The reviewer also provides specific suggestions for improvement, which is a constructive approach."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'could learn useful transformations'), they express significant concerns about the weakness of the experiments and conclude that the paper is not suitable for publication in its current state. This indicates a generally negative sentiment, though not extremely harsh. The politeness score is 20 because the reviewer uses polite and professional language throughout, offering constructive criticism and recommendations for improvement. They avoid harsh or rude language, instead using phrases like 'I would recommend' and 'Thanks for the updates'. However, the politeness is not overly effusive, maintaining a professional tone.""]"
"['This paper presents a new reinforcement learning approach to handle environments with a mix of discrete and\ncontinuous action spaces. The authors propose a parameterized deep Q-network (P-DQN) and leverage learning\nschemes from existing algorithms such as DQN and DDPG to train the network. The proposed loss function and\nalternating optimization of the parameters are pretty intuitive and easy to follow. My main concern is\nwith lack of sufficient depth in empirical evaluation and analysis of the method.\n\nPros:\n1. The setup is an interesting and practically useful one to investigate. Many real-world environments require individual actions\n that are further parameterized over a continuous space.\n2. The proposed method is simple and intuitive.\n\nCons:\n1. The evaluation is performed only on a single environment in a restricted fashion. I understand the authors are restricted in the choice of environments which require a hybrid action space. However,\n even domains like Atari could be used in a setting where the continuous parameter x_k refers to the number of\n repetitions for action k. This is similar to the work of Lakshminarayanan et al. (2017). Could you test your algorithm in such a setting?\n2. Comparison of the algorithm is performed only against DDPG. Have you tried other options like PPO (Schulman et al., 2017)?\n Also, considering that the action space is simplified in the experimental setup (""we use the default parameters of skills provided by the game environment, usually pointing to\nthe opponent hero\'s location""), with only the move(\\alpha) action being a hybrid, one could imagine discretizing the move\ndirection \\alpha and training a DQN (or any other algorithms over discrete action spaces) as another baseline.\n3. The reward structure seems to be highly engineered. With so many components in the reward, it is not clear\nwhat the individual contributions are and what policies are actually learned.\n4. The authors don\'t provide any analysis of the empirical results. Do the P-DQN and DDPG converge to the same policy?\nWhat factor(s) contribute most to the faster learning of P-DQN? Do the values of \\alpha and \\beta for the two-timescale\nupdates affect the results considerably?\n5. (minor) The writing contains a lot of grammatical errors which makes this draft below par for an ICLR paper.\n\n\nOther Questions:\n1. In eq. 5.3, the loss over \\theta is defined as the sum of Q values over different k. Did you try other formulations of\nthe loss? (say, product of the Q values for instance) One potential issue with the sum could be that if some values of k dominate this sum, Q(s, k, x_k; w) might not be maximized for all k.\n2. Some terms of the reward function seem to be overly dependent on historic actions (ex. difference in gold and hitpoints). This could swamp the\ninfluence of the other terms which are more dependent on the current action a_t, which might be an issue, especially with the Markovian assumption?\n\nReferences:\n Lakshminarayanan et al, 2017; Dynamic Action Repetition for Deep Reinforcement Learning; AAAI\n Schulman et al., 2017; Proximal Policy Optimization Algorithms; Arxiv\n', 'This paper examines a modified NN architecture and algorithm (P-DQN) for learning in hybrid discrete/continuous action spaces. The authors come up with a clever way of modifying the architecture of parameterized-action-space DDPG (as in Hausknecht & Stone 16) in such a way that the actor only outputs values for the continuous actions and the critic outputs values for all discrete actions, parameterized by the actor’s choice of continuous actions.  Overall, I think this is an interesting and valid modification to the DDPG architecture, with results to show improved sample complexity. However, there is no quantitative analysis of why the new architecture works better, insufficient understanding of the new domain and learning task, and overall rough presentation.\n\nClarity: The writing clarity is rough, but understandable, with numerous minor grammar mistakes. The paper is overly long and could be improved by a more compact presentation of background, algorithms, and results.\n\nOriginality: The paper builds on DDPG and explores a novel modification to the architecture. \n\nSignificance: It’s hard to evaluate the significance of this result because of the lack of videos + information on the Moba environment. The proposed P-DQN architecture is interesting and, if the results on the Moba environment are general, could be of use in future hybrid-discrete-continuous action space domains. \n\nPros:\n•\tThe modification to DDPG is genuinely interesting and does result in an algorithm that is a hybrid between DQN and DDPG.\n•\tThe learning curves show evidence of faster learning using the P-DQN architecture.\n\nCons:\n•\tIt’s difficult to confidently evaluate the merits of P-DQN vs DDPG based only on learning curves from a single, new domain. It would be nice to have explored results on additional domains such as Robot Soccer (HFO), where algorithm could have been compared directly to DDPG.\n•\tThere is very little analysis of why P-DQN exhibits better sample complexity. The authors claim the difference stems from explicit computation over the discrete actions, but this is never analyzed.\n•\tVery difficult to read the axes on the plots in Fig 3.\n•\tNot much detail is given about the domain – who or what is the agent playing against? Is the agent playing against a bot or just learning to kill creeps? Would be great to have a video of the learned policy (or evaluation against human / scripted opponent) so that others can understand the quality of the learned policy.\n', 'In this paper, the authors investigate RL agents whose action space contains discrete dimensions, and some continuous dimensions. They approach the problem by tackling the continuous dimensions with DDPG, max-marginalizing out the continuous actions, and tackling the remaining dimensions with classical Q-learning. They apply their method to a MOBA-game, King of Glory.\nMethodologically, the method is a somewhat straightforward combination of DDPG and Q-learning; experimentally, they demonstrate improved performance (2-3x sample efficiency) compared to a modified DDPG algorithm from Hausknecht and Stone. Overall, methodologically, the paper is on the incremental side; experimentally, the authors attack a hard problem, and obtain moderate improvements. The most interesting part of the paper in my mind is the challenging domain of application; maybe trying their algorithm on slightly more difficult settings (different \'heroes\', higher AI level) would have made the benefits of their method more evident.\n\nMinor:\n- Paper is significantly over the page limit; in many places, writing could be improved, many typos in paper\n(in the first page: ""project of design""-> ""project of designing""; ""farmework""->""framework""; ""we consider the scenario"" ""problems that are once"" are clumsy).\nThe used of \'parameters\' for what is effectively a continuous action is a bit confusing; I realize this is borrowed from Hausknecht and Stone, but the use of the term deserves a bit more clarification (they are effectively continuous actions, but in this particular game, they parametrize a particular discrete action).\n- Equation 2.2: Note that the term (r_t+ \\gamma ...) is not differentiated even though it appears in the loss, various paper use different notations to denote this. As it is, the loss is slightly incorrect; same issue with the last equation on page 3.\n- just after equation 2.3, the multiplier of \\grad \\log p_\\theta for REINFORCE is not the reward r_t but the return R_t.\n']","[-20, 20, -20]","[60, 60, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they express more concerns ('Cons') and areas for improvement. The review starts with a neutral tone but then focuses more on the limitations and suggestions for enhancement, indicating a somewhat critical stance. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, frames criticisms as suggestions or questions, and acknowledges the paper's strengths. They use phrases like 'Could you test...?' and 'Have you tried...?' which are polite ways of suggesting improvements. The reviewer also balances criticism with positive comments, which contributes to the overall polite tone."", ""For the sentiment score, I assigned 20 (slightly positive) because the reviewer acknowledges the paper's interesting and valid modification to the DDPG architecture, and notes improved sample complexity. However, they also point out several significant shortcomings, balancing the positive aspects. The overall tone is cautiously optimistic but with substantial reservations.\n\nFor the politeness score, I assigned 60 (moderately polite) because the reviewer maintains a professional and respectful tone throughout. They begin by acknowledging the clever approach and interesting modification. When presenting criticisms, they use neutral language like 'It's difficult to evaluate' and 'It would be nice to have' rather than harsh or accusatory statements. The reviewer also balances critiques with positive observations, demonstrating fairness. However, the score is not higher as the review doesn't go out of its way to be exceptionally polite or encouraging."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (improved performance, challenging domain), they also point out that the method is 'somewhat straightforward' and 'on the incremental side'. The reviewer suggests that the paper could have been more impactful with additional experiments. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'in my mind' to soften criticism, and offering constructive suggestions. They also balance negative points with positive ones. However, the review is not overly effusive in its praise, keeping it from scoring higher on politeness. The reviewer points out several issues, including typos and equation errors, but does so in a matter-of-fact manner without harsh language.""]"
"['The paper proposes training neural networks using a trust region method, in which at each iteration a (non-convex) quadratic approximation of the objective function is found, and the minimizer of this quadratic within a fixed radius is chosen as the next iterate, with the radius of the trust region growing or shrinking at each iteration based on how closely the gains of the quadratic approximation matched those observed on the objective function. The authors claim that this approach is better at avoiding ""narrow"" local optima, and therefore will tend to generalize better than minibatched SGD. The main novelty seems to be algorithm 2, which finds the minimizer of the quadratic approximation within the trust region by performing GD iterations until the boundary is hit (if it is--it might not, if the quadratic is convex), and then Riemannian GD along the boundary.\n\nThe paper contains several grammatical mistakes, and in my opinion could explain things more clearly, particularly when arguing that the algorithm 2 will converge. I had particular difficulty accepting that the phase 1 GD iterates would never hit the boundary if the quadratic was strongly convex, although I accept that it is true due to the careful choice of step size and initialization (assumptions 1 and 2).\n\nThe central claim of the paper, that a trust region method will be better at avoiding narrow basins, seems plausible, since if the trust region is sufficiently large then it will simply pass straight over them. But if this is the case, wouldn\'t that imply that the quadratic approximation to the objective function is poor, and therefore that line 5 of algorithm 1 should shrink the trust region radius? Additionally, at some times the authors seem to indicate that the trust region method should be good at escaping from narrow basins (as opposed to avoiding them in the first place), see for example the left plot of figure 4. I don\'t see why this is true--the quadratic approximation would be likely to capture the narrow basin only.\n\nThis skepticism aside, the experiments in figure 2 do clearly show that, while the proposed approach doesn\'t converge nearly as quickly as SGD in terms of training loss, it does ultimately find a solution that generalizes better, as long as both SGD and TR use the same batch size (but I don\'t see why they should be using the same batch size). How does SGD with a batch size of 1 compare to TR with the batch sizes of 512 (CIFAR10) or 1024 (STL10)?\n\nSection 4.3 (Figure 3) contain a very nice experiment that I think directly explores this issue, and seems to show that SGD with a batch size of 64 generalizes better than TR at any of the considered batch sizes (but not as well as the proposed TR+SGD hybrid). Furthermore, 64 was the smallest batch size considered, but SGD was performing monotonically better as the batch size decreased, so one would expect it to be still better for 32, 16, etc.\n\nSmaller comments:\n\nYou say that you base the Hessian and gradient estimates on minibatched samples. I assume that the same is true for the evaluations of F on line 4 of Algorithm 1? Do these all use the same minibatch, at each iteration?\n\nOn the top of page 3: ""M is the matrix size"". Is this the number of elements, or the number of rows/columns?\n\nLemma 1: This looks correct to me, but are these the KKT conditions, which I understand to be first order optimality conditions (these are second order)? You cite Nocedal & Wright, but could you please provide a page number (or at least a chapter)?\n\nOn the top of page 5, ""Line 10 of Algorithm 1"": I think you mean Line 11 of Algorithm 2.', 'The paper develops an efficient algorithm to solve the subproblem of the trust region method with an asymptotic linear convergence guarantee, and they demonstrate the performances of the trust region method incorporating their efficient solver in deep learning problems.  It shows better generation errors by trust region methods than SGD in different tasks, despite slower running time, and the authors speculate that trust-region method can escape sharp minima and converge to wide minima and they illustrated that through some hybrid experiment.\nThe paper is organized well.\n\n1.  The result in Section 4.3 empirically showed that Trust Region Method could escape from sharp local minimum.  The results are interesting but not quite convincing.  The terms about sharp and wide minima are ambiguous.  At best, this provides a data point in an area that has received attention, but the lack of precision about sharp and wide makes it difficult to know what the more general conclusions are.  It might help to show the distance between the actual model parameters that those algorithms converge to.\n\n2. As well know, VGG16 with well training strategy (learning rate decay) could achieve at least 92 percent accuracy. In the paper, the author only got around 83 percent accuracy with SGD and 85 percent accuracy with TR.  Why is this.\n\n3. In section 4.2, it said ""Although we can also define Hessian on ReLU function, it is not well supported on major platforms (Theano/PyTorch).  Likewise, we find max-pooling is also not supported by platforms to calculate higher order derivative, one way to walk around is to change all the max-pooling layers to avg- pooling, it hurts accuracy a little bit, albeit this is not our primary concern."" It is my understanding that Pytorch support higher order derivative both for ReLu and Max-pooling.  Hence, it is not an explanation for not using ReLu and Max-pooling.  Please clarify\n\n4. In section 4.3, the authors claimed that numerical diffentiation only hurts 1 percent error for second derivative. Please provide numerical support.\n\n5. The setting of numerical experiments is not clear, e.g. value of N1 and N2.  This makes it hard to reproduce results.\n\n5. It\'s not clear whether this is a theoretical paper or an empirical paper.  For example, there is a lot of math, but in Section 4.5 the authors seem to hedge and say ""We give an intuitive explanation ... and leave the rigorous analysis to future works.""  Please clarify.\n\n', '**I am happy to see some good responses from the authors to my questions. I am raising my score a bit higher. \n\nSummary: \nA new stochastic method based on trust region (TR) is proposed. Experiments show improved generalization over mini-batch SGD, which is the main positive aspect of this paper. The main algorithm has not been properly developed; there is too much focus on the convergence aspects of the inner iterations, for which there are many good algorithms already in the optimization literature. There are no good explanations for why the method yields better generalization. Overall, TR seems like an interesting idea, but it has neither been carefully expanded or investigated. \n\nLet me state the main interesting results before going into criticisms:\n1. TR method seems to generalize better than mini-batch SGD. \n2. TR seems to lose generalization more gracefully than SGD when batch size is increased. [But note here that mini-batch SGD is not a closed chapter. With better ways of adjusting the noise level via step-size control (larger step sizes mean more noise) the loss of generalization associated with large mini-batch sizes can be brought down. See, for example: https://arxiv.org/pdf/1711.00489.pdf.]\n3. Hybrid method is even better. This only means that more understanding is needed as to how TR can be combined with SGD.\n\nTrust region methods are generally batch methods. Algorithm 1 is also stated from that thinking and it is a well-known optimization algorithm. The authors never mention mini-batch when Algorithm 1 is introduced. But the authors clearly have only the stochastic min-batch implementation of the algorithm in mind. \n\nOne has to wait till we go into the experiments section to read something like:\n""Lastly, although in theory, we need full gradient and full Hessian to guarantee convergence, calculating them in each iteration is not practical, so we calculate both Hessian and gradient on subsampled data to replace the whole dataset""\nfor readers to realize that the authors are talking about a stochastic mini-batch method. This is a bad way of introducing the main method. This stochastic version obviously requires a step size; so it would have been proper to state the stochastic version of the algorithm instead of the batch algorithm in Algorithm 1.\n\nInstead of saying that in passing why not explicitly state it in key places, including the abstract and title? I suggest TR be replaced by ""Stochastic TR"" everywhere. Also, what does ""step size"" mean in the TR method? I suggest that all these are fully clarified as parts of Algorithm 1 itself. \n\nTrust region subproblem (TRS) has been analyzed and developed so much in the optimization literature. For example, the conjugate gradient-based method leading to the Steihaug-Toint point is so much used. [Note: Here, the gradient refers to the gradient of the quadratic model, and it uses only Hessian-vector products.] http://www.ii.uib.no/~trond/publications/papers/trust.pdf. The authors spend so much effort developing their own algorithm! Also, in actual implementation, they only use a crude version of the inner algorithm for reasons of efficiency.\n\nThe paper does not say anything about the convergence of the full algorithm. How good are the trust region updates based on q_t given the huge variability associated with the mini-batch operation? The authors should look at several existing papers on stochastic trust region and stochastic quasi-Newton methods, e.g., papers from Katya Scheinberg (Lehigh) and Richard Byrd (Colorado)\'s groups.\n\nThe best-claimed method of the method, called ""Hybrid method"" is also mentioned only in passing, and that too in a scratchy fashion (see end of subsec 4.3):\n""To enjoy the best of both worlds, we also introduce a “hybrid” method in the Figure 3, that is, first run TR method for several epochs to get coarse solution and then run SGD for a while until fully converge. Our rule of thumb is, when the training accuracy raises slowly, run SGD for 10 epochs (because it’s already close to minimum). We find this “hybrid” method is both fast and accurate, for both small batch and large batch.""\n\nExplanations of better generalization properties of TR over SGD are important. I feel this part is badly done in the paper. For example, there is this statement:\n""We observe that our method (TR) converges to solutions with much better test error but\nworse training error when batch size is larger than 128. We postulate this is because SGD is easy to overfit training data and “stick” to a solution that has a high loss in testing data, especially with the large batch case as the inherent noise cannot push the iterate out of loss valley while our TR method can.""\nFrankly, I am unable to decipher what is being said here.\n\nThere is an explanation indicating that switching from SGD to TR causes an uphill movement (which I presume, is due to the trust region radius r being large); but statements such as - this will lead to climbing over to a wide minimum etc. are too strong; no evidence is given for this.\n\nThere is a statement - ""even if the exact local minima is reached, the subsampled Hessian may still have negative curvature"" - again, there is no evidence.\n\nOverall, the paper only has a few interesting observations, but there is no good and detailed experimental analysis that help explain these observations.\n\nThe writing of the paper needs a lot of improvement.\n\n\n\n\n\n\n']","[-20, -20, 20]","[50, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'experiments in figure 2 do clearly show... it does ultimately find a solution that generalizes better'), there are several criticisms and expressions of skepticism throughout. The reviewer points out grammatical mistakes, unclear explanations, and questions the central claim of the paper. However, the tone is not entirely negative, as the reviewer also offers constructive feedback and acknowledges some merits of the work. The politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'in my opinion' and 'I had particular difficulty accepting' rather than making blunt criticisms. The reviewer also offers specific suggestions for improvement and asks clarifying questions, which is a polite way to address concerns. The language is not overly formal or deferential, but it avoids any rudeness or harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The paper is organized well'), they raise several significant concerns and criticisms. These include questioning the convincingness of results, pointing out potential inaccuracies, and requesting clarifications on multiple points. The overall tone suggests the reviewer sees potential in the work but has reservations about its current state.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'Please clarify' and 'It might help to...' which are constructive and polite ways of suggesting improvements. The reviewer also acknowledges positive aspects of the work before presenting criticisms. However, the score is not higher because the review is primarily focused on pointing out issues rather than offering praise, which is appropriate for a peer review but results in a more neutral rather than overtly polite tone."", ""The sentiment score is slightly positive (20) because the reviewer starts by saying they are 'happy to see some good responses' and raises their score, indicating some satisfaction. They also note some 'interesting results' and 'positive aspects'. However, this is balanced by numerous criticisms and areas for improvement, keeping the overall sentiment only mildly positive. The politeness score is moderately positive (50) as the reviewer uses professional language throughout and frames criticisms constructively, e.g. 'I suggest', 'The authors should look at', rather than using harsh or rude phrasing. They also acknowledge positive aspects before diving into critiques. However, some direct criticisms like 'This is a bad way of introducing the main method' and 'Frankly, I am unable to decipher what is being said here' prevent the score from being higher.""]"
"['The paper presents a method for feature projection which uses a two level neural network like structure to generate new features from the input features. The weights of the NN like structure are optimised using a genetic search algorithm which optimises the cross-validation error of a nearest neighbor classifier. The method is tested on four simple UCI datasets. There is nothing interesting or novel about the paper. It is not clear whether the GA optimisation takes place on the level of cross validation error estimation or within an internal validation set as it should have been the case. The very high accuracies reported seem to hint the latter, which is a serious methodological error. The poor language and presentation does not help in clearing that, as it does not help in general. ', 'The main issue is the scientific quality. What the authors call ""intelligent mapping and combining system"" for the proposed system is simply a fully connected neural network. Such systems have been largely investigated in the literature. The use of genetic algorithms has also been considered. Moreover, mapping features to some appropriate feature space has been widely investigated, including the choice of appropriate mapping. We didn\'t find anything ""intelligent"" in the proposed mapping. \n\nThere are many spelling and grammatical errors.\n', ""This paper proposes using a feedforward neural network (FFNN) to extract intermediate features which are input to a 1NN classifier. The parameters of the FFNN are updated via a genetic algorithm with a fitness function defined as the error on the downstream classification, on a held-out set. The performance of this approach is measured on several UCI datasets and compared with baselines.\n– The paper’s main contribution seems to be a neural network with a GA optimization for classification that can learn “intelligent combinations of features”, which can be easily classified by a simple 1NN classifier. But isn't this exactly what neural networks do – learn intelligent combinations of features optimized (in this case, via GA) for a downstream task? This has already been successfully applied in multiple domains eg. in computer vision (Krizhevsky et al, NIPS 2011), NLP (Bahdanau et al 2014), image retrieval (Krizhevsky et al. ESANN 2011) etc, and also studied comprehensively in autoencoding literature. There also exists prior work on optimizing neural nets via GA (Leung, Frank Hung-Fat et al., IEEE Transactions on Neural networks 2003). However, this paper claims both as novelties while not offering any improvement / comparison. \n– The claim “there is no need to use more powerful and complex classifier anymore” is unsubstantiated, as the paper’s approach still entails using a complex classifier (a FFNN) to learn an optimal intermediate representation.\n– The choice of activations is not motivated, and performance on variants is not reported. For instance, why is that particular sigmoid formulation used? \n– The use for a genetic algorithm for optimization is not motivated, and no comparison is made to the performance and efficiency of other approaches (like standard backpropagation). So it is unclear why GA makes for a better choice of optimization, if at all.\n– The primary baselines compared to are unsupervised methods (PCA and LDA), and so demonstrating improvements over those with a supervised representation does not seem significant or surprising. It would be useful to compare with a simple neural network baseline trained for K-way classification with standard backpropagation (though the UCI datasets may potentially be too small to achieve good performance).\n– The paper is poorly written, containing several typos and incomplete, unintelligible sentences, incorrect captions (eg. Table 4) etc.\n""]","[-80, -80, -70]","[-20, -20, -20]","[""The sentiment score is -80 because the review is highly critical and negative. The reviewer states there is 'nothing interesting or novel about the paper', points out a potential 'serious methodological error', and criticizes the 'poor language and presentation'. These are strong negative statements that indicate a very unfavorable view of the paper. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite blunt and dismissive. Phrases like 'There is nothing interesting or novel' and 'The poor language and presentation' are quite harsh and could be phrased more diplomatically. However, the reviewer does maintain some level of professional language, preventing the score from being even lower."", ""The sentiment score is -80 because the review is highly critical of the scientific quality of the work. The reviewer states that the main issue is scientific quality and dismisses the authors' claims of an 'intelligent mapping and combining system' as simply a fully connected neural network. They also mention that there's nothing 'intelligent' in the proposed mapping, indicating a strong negative sentiment towards the core aspects of the paper. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and dismissive. The reviewer doesn't use any softening language or positive remarks to balance the criticism. The mention of 'many spelling and grammatical errors' without any positive feedback also contributes to the slightly impolite tone. However, the reviewer does maintain a professional tone overall, which prevents the score from being lower."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer criticizes the paper's claimed novelty, points out unsubstantiated claims, questions methodological choices, and highlights poor writing quality. There are no positive comments about the paper's contributions or merits. The politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite critical and dismissive. The reviewer uses phrases like 'isn't this exactly what neural networks do', 'unsubstantiated', and 'poorly written', which come across as somewhat harsh. However, the reviewer does maintain a professional tone overall, avoiding personal attacks or overly emotional language, which prevents the score from being lower.""]"
"['The authors present a method that aims to remove domain-specific information while preserving the relevant biological information between biological data measured in different experiments or ""batches"". A network is trained to learn the transformations that minimize the Wasserstein distance between distributions. The wasserstein distance is also called the ""earth mover distance"" and is traditionally formulated as the cost it takes for an optimal transport plan to move one distribution to another. In this paper they have a neural network compute the wasserstein distance using a different formulation that was used in Arjovsky et al. 2017, finds a lipschitz function f, which shows the maximal difference when evaluated on samples from the two distributions. Here these functions are formulated as affine transforms of the data with parameters theta that are computed by a neural network. Results are examined mainly by looking at the first two PCA components of the data.  \n\n\nThe paper presents an interesting idea and is fairly well written. However I have a few concerns:\n1. Most of the ideas presented in the paper rely on works by Arjovsky et al. (2017), Gulrajani et al. (2017), and Gulrajani et al. (2017). Some selections, which are presented in the papers are not explained, for example, the gradient penalty, the choice of \\lambda and the choice of points for gradient computation.\n2. The experimental results are not fully convincing, they simply compare the first two PC components on this Broad Bioimage benchmark collection. This section could be improved by demonstrating the approach on more datasets.\n3. There is a lack comparison to other methods such as Shaham et al. (2017). Why is using earth mover distance better than MMD based distance? They only compare it to a method named CORAL and to Typical\nVariation Normalization (TVN). What about comparison to other batch normalization methods in biology such as SEURAT? \n4. Why is the affine transform assumption valid in biology? There can definitely be non-linear effects that are different between batches, such as ion detection efficiency differences. \n5. Only early stopping seems to constrain their model to be near identity. Doesn\'t this also prevent optimal results ? How does this compare to the near-identity constraints in resnets in Shaham et al. ?\n\n', 'This contribution deal with nuisance factors afflicting biological cell images with a domain adaptation approach: the embedding vectors generated from cell images show spurious correlation. The authors define a Wasserstein Distance Network to find  a suitable affine transformation that reduces the nuisance factor. The evaluation on a real dataset yields correct results, this approach is quite general and could be applied to different problems.\n\nThe contribution of this approach could be better highlighted. The early stopping criteria tend to favor suboptimal solution, indeed relying on the Cramer distance is possible improvement.\n\nAs a side note, the k-NN MOA is central to for the evaluation of the proposed approach. A possible improvement is to try other means for the embedding instead of the Euclidean one.\n\n', ""The paper discusses a method for adjusting image embeddings in order tease apart technical variation from biological signal. A loss function based on the Wasserstein distance is used. \nThe paper is interesting but could certainly do with more explanations. \n\nComments:\n1. It is difficult for the reader to understand a) why Wasserstein is used and b) how exactly the nuisance variation is reduced.\nA dedicated section on motivation is missing.\n\n2. Does the Deep Metric network always return a '64-dim' vector? \nHave you checked your model using different length vectors?\n\n3. Label the y-axis in Fig 2.\n\n4. The fact that you have early-stopping as opposed to a principled regularizer also requires further substantiation. ""]","[-20, 60, -20]","[60, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting' and 'fairly well written', they express several concerns and criticisms. The reviewer points out multiple areas for improvement, including lack of explanation for certain choices, limited experimental results, insufficient comparisons to other methods, and questions about the validity of assumptions. These criticisms outweigh the initial positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout. They begin with positive aspects before presenting their concerns, and phrase their criticisms as suggestions or questions rather than direct attacks. The use of phrases like 'The paper presents an interesting idea' and the structured, professional tone contribute to the polite nature of the review, even while expressing criticisms."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the correct results, the general applicability of the approach, and its potential for different problems. However, it's not extremely positive as the reviewer suggests improvements. The politeness score is 50 (slightly polite) because the language is professional and constructive, offering suggestions for improvement without harsh criticism. The reviewer uses phrases like 'could be better highlighted' and 'possible improvement' which are polite ways of suggesting changes. The overall tone is respectful and focused on the work rather than personal criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer mentions the paper is 'interesting', they also state that it 'could certainly do with more explanations' and list several areas for improvement. This suggests a generally critical stance, albeit not harshly negative. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, such as 'interesting' and phrasing criticisms as suggestions or questions rather than direct criticisms. They also avoid harsh or rude language. The tone is professional and constructive, which is typical of academic peer reviews.""]"
"['Strengths:\n1. This paper proposes a novel method called Concept Activation Vectors (CAV) which facilitates interpretability of neural networks by explaining how much a specific concept influences model predictions. \n2. The proposed method tries to incorporate multiple desiderata, namely, accessibility to non ML experts, customizability w.r.t. being able to explain any concept of interest, plug-in readiness i.e., providing explanations\nwithout requiring retraining of the model. \n\nWeaknesses:\n1. While this work is conceptually interesting, the technical novelty and contributions seem fairly minimal. \n2. The presentation of this paper is one of its weakest points. The organization of the content is quite incoherent. The paper also makes a lot of claims (e.g., hypothesis testing) which are not really justified. \n3. The experimental evaluation of this paper is quite rudimentary. Lots of details are missing. \n\nSummary: This paper proposes a novel framework for explaining the functionality of neural networks by using a simple idea. The intuition behind the proposed approach is as follows: by using the weight vectors of linear classifiers, which take as inputs the activation layer outputs of a given neural network (NN) model and predict the concepts of interest, we can understand the influence of specific concepts of interest on the NN model behavior. The authors claim that this simple approach can be quite useful in providing explanations that can be useful for a variety of purposes including testing specific hypothesis which is never really demonstrated or explained well in the paper. Furthermore, lot of details are lacking in both the experimentation section and the methods section (detailed comments below). The experiments also do not correspond well to the claims made in the introduction and abstract. This paper is also very hard to read which makes understanding the proposed method and other details quite challenging. \n\nNovelty: The novelty of this paper mainly stems from its proposed method of using prototypes which serve as positive and negative examples w.r.t. a specific concept, and leveraging the weight vectors obtained when predicting the positive/negative classes using activation layer outputs to understand the influence of concepts of interest.  The technical novelty of the proposed approach is fairly minimal. The experiments also do not support a lot of novelty claims made about the proposed approach. \n\nOther detailed comments:\n1. I would first encourage the authors to improve the overall presentation and organization of this paper. \n2. Please add some intuition about the approach in the introduction. Also, please be succinct in explaining what kind of interpretability is provided by the explanations. I would advise the authors to refrain from making very broad claims and using words such as hypothesis testing without discussing them in detail later in the paper. \n3. Sections 2.3 and 2.4 are quite confusing and can probably be organized and titled differently. In fact, I would advise the authors to structure related work as i. inherently interpretable models ii. global explanations \niii. local explanations iv. neuron level investigation methods. Highlight how existing methods do not incorporate plug-in readiness and/or other desiderate wherever appropriate within these subsections. \n4. Additional related work on inherently interpretable models and global explanations: \ni. Interpretable classifiers using rules and Bayesian analysis, Annals of Applied Statistics, 2015\nii. Interpretable Decision Sets: A joint framework for description and prediction, KDD, 2016\niii. A Bayesian Framework for Learning Rule Sets for Interpretable Classification, JMLR, 2017\niv. Interpretable and Explorable Explanations of Black Box Models, FAT ML, 2017\n5. In section 3, clearly identify what are the inputs and outputs of your method. Also, clearly highlight the various ways in which outputs of your method can be used to understand the model behavior. While Secction 3.2 and 3.3 attempt to describe how the CAV can be used to explain the model behavior, the presentation in these sections can be improved. \n6. I think the experimental sections suffers from the following shortcomings: i. it does not substantiate all the claims made in the introduction ii. some of the details about which layer outputs are being studied are missing through out the section. \n\nOverall, while this paper proposes some interesting ideas, I think it can be improved significantly in terms of its clarity, claims, and evaluation.  \n', 'This paper tries to analyze the interpretability of a trained neural network, by representing the concepts, as their hidden features (vectors) learned on training data. They used images of several example of a concept or object to compute the mean vector, which represent the concept, and analyzed, both qualitatively and quantitatively, the relationship between different concepts. The author claimed that this approach is independent of concept represented in training data, and can be expanded to any concepts, i.e. zero shot examples. \n\nMajor comments:\n\n1- The analysis in the experiment is limited on few examples on how different concept in the training set is related, measures by relative importance, or not related by created a negative concept vector of un related or random images. However, this analysis severely lacks in situation where training set is limited and induces biases towards existing concepts\n\n2-The author claims that this approach encompass following properties,\naccessibility: Requires little to no user expertise in machine learning. \ncustomization: Adapt to any concept of interest (e.g., gender) on the fly without pre-listing a set of concepts before training. \nplug-in readiness: Work without retraining or modifying the model. \nquantification: Provide quantitative and testable information.\n\nRegarding 1) analyzing the relationship between concepts vectors and their effect of class probability need some minimal domain knowledge, therefore this claim should be mitigated\nRegarding 2) Although some experiment demonstrates the relationship between different colors or properties of the object wearing a bikini can shed a light in fairness of the model, it is still unclear that how this approach can indicates the biases of training data that is learned in the model. In case of limited train data, the model is incapable of generalize well in capturing the relationship between all general concepts that does not exist in the training data. Therefore, a more rigorous analysis is required.\nRegarding 3) compare to deepdream that involved an optimization step to find the image maximizing a neuron activation, this is correct. However, guided back propagation or grad-cam method also does not need any retraining or model tweaking.\n\nMinor comments:\n \n1- there are many generic and implicit statements with no details in the paper which need more clarification, for example, \n\nPage 4, paragraph 2: “For example, since the importance of features only needs to be truthful in the vicinity of the data point of interest, there is no guarantee that the method will not generate two completely conflicting explanations.”\n\n2- equation 1: subscript “i” is missing\n\n3- section 4.2: definition for I^{up/down} of equation 1 is inconsistent with the one presented in this section\n', ""The paper deals with concept activation vectors, which the authors aim at using for interpretability in deep feed-forward networks. This is a critical sub-field of deep learning and its importance is only rising. While deep networks have yielded grounbreaking results across several application domains, without explanations for why the network predicts a certain class for a data point, its applicability in sensitive fields, such as medicine, will be limited. The authors put forth four desiderata and aim to construct a methodology that satisfies all of them. The concept vector is the 2-class logistic regression solution that discriminates between two classes of images (a grounded idea and other). This vector is used to amplify or diminish the effect of a concept at a certain layer, thus leading to differing output probabilities. The difference in probability can be used to understand, qualitatively, the importance of the concept. I have a few major and minor concerns, which I detail below. \n\n* The structure and exposition of the paper needs to be significantly improved. Important sections of the paper are difficult to parse, for instance, Sections 2.3 and 2.4 seem abrupt. Also, the text and the contributions have a mismatch. The authors make several strong claims (hypothesis testing, testable quantifying information, etc.) about their approach which are not entirely validated by the results. The authors should especially consider rewriting portions of Sections 1 and 2; many of the statements are difficult to understand. There are many instances (e.g., the ears of the cat example) where a picture or graphic of some kind will greatly benefit the reader. What would also be useful is a Table with the rows being the 4 desiderata and the columns being various previous approaches. \n\n* Am I right in assuming that the concept vector discriminator is simple (un-regularized) logistic regression?\n\n* I don't quite understand why the weights of a discriminator of activations stands as a concept activation vector. The weights of the discriminator would be multiplied by the activations to figure out whether are in the concept class or not; I especially don't grasp why adding those weights should help tease the effect. \n\n* Is the idea limited to feed-forward networks, or is it also applicable for recurrent-like networks? If not, I would encourage the authors to clarify in the title and abstract that this is the case. \n\n* For Equation (1), what is the index 'i' over? \n\n* In reference to Figure 1, have you experimented with using more data for the concepts that are difficult to discriminate? Instead of asking the practitioners for a set amount of examples, one could instead ask them for as much as to discriminate the classes with a threshold (say, 70%) accuracy. \n\n* In the same vein, if a certain concept has really poor predictability, I would assume that the interpretability scores will be hampered as well. How should this be addressed?\n\n* The authors desire a quantitative and testable explanation. I'm not sure what the authors do for the latter. \n"", 'Summary\n---\nThis paper proposes the use of Concept Activation Vectors (CAVs) for interpreting deep models. It shows how concept activation vectors can be used to provide explanations where the user provides a concept (e.g., red) as a set of training examples and then the method provides explanations like ""If there were more red in this image then the model would be more likely to classify it as a fire truck.""\n\nFour criteria are enumerated for evaluating interpretability methods:\n1. accessibility: ML background should not be required to interpret a model\n2. customization: Explanations should be generated w.r.t. user-chosen concepts\n3. plug-in readiness: Should be no need to re-train/modify the model under study\n4. quantification: Explanations should be quantitative and testable\n\nA Concept Activation Vector is simply the weight vector of a linear classifier trained on some examples (100-500) of a user-provided concept of interest using features extracted from an intermediate network layer. These vectors can be trained in two ways:\n1. 1-vs-all: The user provides positive examples of a concept and all other existing training data is treated as negatives\n2. 1-vs-1: The user provides sets of positive and negative examples, allowing the negative examples to be targeted to one category\n\nOnce a CAV is obtained it is used in two ways:\nFirst, it provides further verification that higher level concepts tend to be ""disentangled"" in deeper network layers while low level concepts are ""disentangled"" earlier in the network. This work shows that linear classifier accuracy increases significantly using deeper features for higher level concepts but it only increases marginally (or even decreases) when modeling lower level concepts.\n\nSecond, and this is the main point of the paper, relative importance of concepts w.r.t. a particular task can be evaluated. Suppose an image (e.g., of a zebra) produces a feature vector f_l at layer l and v_l is a concept vector learned to classify the presence of stripes from layer l features. Then the probability the model assigns to the zebra class can be evaluated using features f_l and then f_l + v^c_l. If the latter probability is greater then adding stripes will increase the model\'s confidence in the zebra class. Furthermore, the method goes on to measure how often stripes increase zebra confidence across all images. Rather than explaining the network\'s decision for a particular image, this average metric measures the global importance of the stripes concept for zebra. The paper reports examples of the relative importance of certain concepts with respect to others in figure 5.\n\n\nPros\n---\n\nThe paper proposes a simple and novel idea which could have a major impact on how deep networks are explained. At a high level the novelty comes from replacing the gradient (or something similar) used in saliency methods with a directional derivative. Users can align the direction to any concept they find relevant, so the concept space used to explain a prediction is no longer fixed a-priori (e.g. to pixels in the input space). It can adapt to user suspicions and expectations.\n\n\nCons\n---\n\nConcerns about story/presentation:\n\n* The second use of CAVs, to test relative importance of concepts, is basically an improved saliency method. It\'s advantages over other saliency methods are stated clearly in 2.1, but it should not be portrayed as fundamentally different.\n\nThe two quantities in eq. 1 can be thought of in terms of directional derivatives. To compute I_w^up start by computing a finite differences approximation of directional derivative of the linear classifier probability p_k(y) with respect to layer l features in the direction of the CAV v_C^l. Call this quantity g_i (for the ith example). Then I_w^up is the average of 1(g_i > 0) over all examples. I think the notion of relative importance used here is basically the idea of a directional derivative.\n\nThis doesn\'t change the contribution of the paper but it should be mentioned and section 2.1 should be changed so it doesn\'t suggest this method is fundamentally different than saliency methods in terms of criteria 4.\n\n* Evaluation and Desiderata 4: The fourth criteria for interpretability laid out by the paper says an explanation should be quantitative and testable. I\'m not sure exactly what this is supposed to mean. I see two ways to interpret the quantitative criterion.\n\nOne way to interpret the ""quantifiability"" criterion is to say that it requires explanations to be presented as numeric values. But most methods do this.  In particular, saliency methods report results in terms of pixel brightness (that is a numeric quantity) even though humans may not know how to interpret that correctly. I do not think this is what was intended, so my second option is to say that the criterion requires an explanation be judged good or bad according to some quantitative metric. But this paper provides no such metric. The explanations in figure 5 are not presented as good or bad according to any metric.\n\nWhile it is significant that the method meets the first 3 criteria, these do not establish the fidelity of the method. Do humans generalize these explanations to valid inferences about model behavior? Maybe consider some evaluation options from section 3 of Doshi-Velez and Kim 2017 (cited in the paper).\n\n* Section 4.1.1: ""This experiment does not yet show that these concept activation vectors align with the concepts that makes sense semantically to humans.""\n\nIsn\'t test set accuracy a better measure of alignment with the human concept than the visualizations? Given a choice between a concept vector which produced good test accuracy and poor visualizations and another concept vector which produced poor test accuracy and good visualizations I would think the one with good test accuracy is better aligned to the human concept. I would still prefer a concept vector which satisfies both.\n\n* Contrary to the description in section 2.2, I think DeepDream optimizes a natural image (non-random initialization) rather than starting from a random image. It looks like these visualization start from a random initialization. Which method is used? Maybe cite this paper, which gives a nice overview: ""Multifaceted Feature Visualization: Uncovering the Different Types of Features Learned By Each Neuron in Deep Neural Networks"" by Nguyen et. al. in the Visualization for Deep Learning workshop at ICML 2016\n\n* In section 4.1.3 I\'m not quite sure what the point is. Please state it more clearly. Is the context class the same as the negative set used to train the classifier? Why should it be different/harder to sort corgi examples according to a concept vector as opposed to sorting all examples according to a concept vector? This seems like a useful way of testing to be sure CAV\'s represent human concepts, but I\'m not sure what context concepts like striped/CEO provide.\n\n* Relative vs absolute importance and user choice: Section 4.2 claims that figure 5 shows that a CAV ""captures an important aspect of the prediction."" I would be a bit more careful about the distinction between relative and absolute here. If red makes images more probably fire trucks then it doesn\'t necessarily mean that red is important for the fire truck concept in an absolute sense. Can we be sure that there aren\'t other concepts which more dramatically affect outputs? What if a user makes a mistake and only requests explanations with respect to concepts that are irrelevant to the class being explained? Do we need to instruct users on how to best interpret the explanation?\n\n* How practical is this method? Is it a significant burden for users to provide 100-500 images per concept? Are the top 100 or so images from a search engine good enough to specify a CAV?\n\n\nMinor missing experimental settings and details:\n\n* Section 3 talks about a CAV defined with respect to a non-generic set D of negative examples. Is this setting ever used in the experiments or is the negative set always the same? How does specifying a narrow set of negatives change the CAV for concept C?\n\n* I assume the linear classifier is a logistic regressor, but this is never stated.\n\n* TCAV measures importance/influence as an average over a dataset. This is a validation set, right? For how many of these images are both the user concept and target concept unrelated to the image content (e.g., stripes and zebra for an image of a truck)? When that happens is it reasonable to expect meaningful explanations? They may not be meaningful because the data distribution used to train the CAV probably does not even sparsely cover all concepts in the network\'s train set. (related to ""reference points"" in ""The (Un)reliability of Saliency Methods"" submitted to ICLR18)\n\n* For relative importance testing it would be nice to see a note about the step size selection (1.0) and experiments that show the effect of different step sizes. Hopefully influence is monotonic in step size so that different step sizes do not significantly change the results.\n\n* How large is the typical difference between p_k(y) and p_k(y_w) in eq. 1? If this difference is small then is it meaningful? Are small differences signal or noise?\n\n\nFinal Evaluation\n---\nI would like to see this idea published, but not in its current form. The method meets a relevant set of criteria that no other method seems to meet, but arguments set forth in the story need some revision and the empirical evaluation needs improvement, especially with respect to model fidelity. I would be happy to change my rating if the above points are addressed.']","[-30, -30, -20, -30]","[50, 50, 60, 50]","[""The sentiment score is -30 because while the reviewer acknowledges some strengths of the paper, they point out several significant weaknesses and areas for improvement. The overall tone suggests that the paper needs substantial work, but it's not entirely negative as they recognize the interesting concepts and potential of the work. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement without using harsh language. They use phrases like 'I would encourage' and 'I would advise' which are polite ways of giving feedback. However, the criticism is direct and doesn't use overly deferential language, keeping it from scoring higher on the politeness scale."", ""The sentiment score is -30 because while the reviewer acknowledges the paper's attempt to analyze neural network interpretability, they raise several major concerns and limitations of the approach. The review is not entirely negative, as it recognizes some merits of the work, but the criticisms outweigh the positive aspects. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism without being harsh or dismissive. They use phrases like 'The author claims' and 'it is still unclear' rather than more confrontational language. The review also provides specific suggestions for improvement, which is a polite way to offer criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic and some positive aspects of the paper, they express several major and minor concerns. The review begins positively but then lists multiple issues with the paper's structure, exposition, and methodology. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions, and acknowledges the paper's contributions. They use phrases like 'I have a few major and minor concerns' and 'Am I right in assuming' which maintain a polite tone while expressing critiques. The reviewer also offers constructive suggestions for improvement, which contributes to the polite tone."", ""The sentiment score is slightly negative (-30) because while the reviewer sees potential in the paper's novel idea, they express several significant concerns and state that the paper should not be published in its current form. They list multiple 'cons' and areas needing improvement, outweighing the 'pros'. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges the paper's contributions, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. They use phrases like 'I would like to see this idea published' and 'I would be happy to change my rating if the above points are addressed', indicating a collegial tone despite the critical feedback.""]"
"['The paper compares some recently proposed method for validation of properties\nof piece-wise linear neural networks and claims to propose a novel method for\nthe same. Unfortunately, the proposed ""branch and bound method"" does not explain\nhow to implement the ""bound"" part (""compute lower bound"") -- and has been used \nseveral times in the same application, incl.:\n\nRuediger Ehlers. Planet. https://github.com/progirep/planet,\nChih-Hong Cheng, Georg Nuhrenberg, and Harald Ruess.  Maximum resilience of artificial neural networks. Automated Technology for Verification and Analysis\nAlessio Lomuscio and Lalit Maganti.  An approach to reachability analysis for feed-forward relu neural networks. arXiv:1706.07351\n\nSpecifically, the authors say: ""In our experiments, we use the result of \nminimising the variable corresponding to the output of the network, subject \nto the constraints of the linear approximation introduced by Ehlers (2017a)""\nwhich sounds a bit like using linear programming relaxations, which is what\nthe approaches using branch and bound cited above use. If that is the case,\nthe paper does not have any original contribution. If that is not the case,\nthe authors may have some contribution to make, but have not made it in this\npaper, as it does not explain the lower bound computation other than the one\nbased on LPs.\n\nGenerally, I find a jarring mis-fit between the motivation (deep learning\nfor driving, presumably involving millions or billions of parameters) and\nthe actual reach of the methods proposed (hundreds of parameters).\nThis reach is NOT inherent in integer programming, per se. Modern solvers\nroutinely solve instances with tens of millions of non-zeros in the constraint\nmatrix, but require a strong relaxation. The authors may hence consider\nimproving the LP relaxation, noting that the big-M constraint are notorious\nfor producing weak relaxations.', 'The paper studies methods for verifying neural nets through their piecewise\nlinear structure. The authors survey different methods from the literature,\npropose a novel one, and evaluate them on a set of benchmarks.\n\nA major drawback of the evaluation of the different approaches is that\neverything was used with its default parameters. It is very unlikely that these\ndefaults are optimal across the different benchmarks. To get a better impression\nof what approaches perform well, their parameters should be tuned to the\nparticular benchmark. This may significantly change the conclusions drawn from\nthe experiments.\n\nFigures 4-7 are hard to interpret and do not convey a clear message. There is no\nclear trend in many of them and a lot of noise. It may be better to relate the\nstructure of the network to other measures of the hardness of a problem, e.g.\nthe phase transition. Again parameter tuning would potentially change all of\nthese figures significantly, as would e.g. a change in hardware. Given the kind\nof general trend the authors seem to want to show here, I feel that a more\ntheoretic measure of problem hardness would be more appropriate here.\n\nThe authors say of the proposed TwinStream dataset that it ""may not be\nrepresentative of real use-cases"". It seems odd to propose something that is\nentirely artificial.\n\nThe description of the empirical setup could be more detailed. Are the\nproperties that are being verified different properties, or the same property on\ndifferent networks?\n\nThe tables look ugly. It seems that the header ""data set"" should be ""approach""\nor something similar.\n\nIn summary, I feel that while there are some issues with the paper, it presents\ninteresting results and can be accepted.', 'Summary:\n\nThis paper:\n- provides a compehensive review of existing techniques for verifying properties of neural networks\n- introduces a simple branch-and-bound approach\n- provides fairly extensive experimental comparison of their method and 3 others (Reluplex, Planet, MIP) on 2 existing benchmarks and a new synthetic one\n\nRelevance: Although there isn\'t any learning going on, the paper is relevant to the conference.\n\nClarity: Writing is excellent, the content is well presented and the paper is enjoyable read.\n\nSoundness: As far as I can tell, the work is sound.\n\nNovelty: This is in my opinion the weakest point of the paper. There isn\'t really much novelty in the work. The branch&bound method is fairly standard, two benchmarks were already existing and the third one is synthetic with weights that are not even trained (so not clear how relevant it is). The main novel result is the experimental comparison, which does indeed show some surprising results (like the fact that BaB works so well).\n\nSignificance: There is some value in the experimental results, and it\'s great to see you were able to find bugs in existing methods. Unfortunately, there isn\'t much insight to be gained from them. I couldn\'t see any emerging trend/useful recommendations (like ""if your problem looks like X, then use algorithm B""). This is unfortunately often the case when dealing with combinatorial search/optimization. ']","[-70, 20, 50]","[-20, 50, 80]","[""The sentiment score is -70 because the review is largely negative. The reviewer states that the paper's main claim of a novel method is not actually novel, and that the paper lacks original contribution if it's using existing methods. The reviewer also criticizes the mismatch between the paper's motivation and the actual reach of the proposed methods. The politeness score is -20 because while the reviewer isn't overtly rude, the language is quite direct and critical without much attempt to soften the criticism. Phrases like 'Unfortunately,' 'does not explain,' 'jarring mis-fit,' and the suggestion that the authors may not have made any contribution if they're using existing methods, contribute to a somewhat impolite tone. However, the reviewer does provide specific references and suggestions for improvement, which prevents the score from being even lower."", ""The sentiment score is slightly positive (20) because while the reviewer points out several issues with the paper, they conclude that it 'presents interesting results and can be accepted.' This indicates an overall positive sentiment despite the criticisms. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They offer constructive criticism without harsh or rude phrasing, using phrases like 'It may be better to...' and 'The description... could be more detailed.' The reviewer also acknowledges the paper's strengths, which contributes to the polite tone. However, the score is not extremely high as the review is primarily focused on pointing out areas for improvement rather than praising the work."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges several strengths of the paper, such as its comprehensive review, excellent writing, and sound work. However, they also point out weaknesses, particularly in novelty and significance. The overall tone is balanced, leaning slightly positive.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout. They offer constructive criticism without being harsh, and they acknowledge the paper's strengths before discussing its limitations. Phrases like 'enjoyable read' and 'it's great to see' contribute to the polite tone. The reviewer also uses hedging language like 'in my opinion' and 'as far as I can tell,' which adds to the politeness by showing respect for the authors' work.""]"
"['quality: this paper is of good quality\nclarity: this paper is very clear\noriginality: this paper combines original ideas with existing approaches for pruning to obtain dramatic space reduction in NN parameters.\nsignificance: this paper seems significant.\n\nPROS\n- a new approach to sparsifying that considers different thresholds for each layer\n- a systematic, empirical method to obtain optimal sparsity levels for a given neural network on a task.\n- Very interesting and extensive experiments that validate the reasoning behind the described approach, with a detailed analysis of each step of the algorithm.\n\nCONS\n- Pruning time. Although the authors argue that the pruning algorithm is not prohibitive, I would argue that >1 month to prune LeNet-5 for MNIST is certainly daunting in many settings. It would benefit the experimental section to use another dataset than MNIST (e.g. CIFAR-10) for the image recognition experiment.\n- It is unclear whether this approach will always work well; for some neural nets, the currently used sparsification method (thresholding) may not perform well, leading to very little final sparsification to maintain good performance.\n- The search for the optimal sparsity in each level seems akin to a brute-force search. Although possibly inevitable, it would be valuable to discuss whether or not this approach can be refined.\n\nMain questions\n- You mention removing ""unimportant and redundant weights"" in the pruning step; in this case, do unimportant and redundant have the same meaning (smaller than a given threshold), or does redundancy have another meaning (e.g. (Mariet, Sra, 2016))?\n- Algorithm 1 finds the best sparsity for a given layer that maintains a certain accuracy. Have you tried using a binary search for the best sparsity instead of simply decreasing the sparsity by 1% at each step? If there is a simple correlation between sparsity and accuracy, that might be faster; if there isn\'t (which would be believable given the complexity of neural nets), it would be valuable to confirm this with an experiment.\n- Have you tried other pruning methods than thresholding to decide on the optimal sparsity in each layer?\n- Could you please report the final accuracy of both models in Table 2?\n\nNitpicks:\n- paragraph break in page 4 would be helpful.', ""This paper inherits the framework proposed by Han[1]. A pruning, weight sharing, quantization pipeline is refined at each stage. At the pruning stage, by taking into account difference in the distribution across the layers, this paper propose a dynamic threshold pruning, which partially avoids mistakenly pruning important connections. As for the weight sharing stage, this paper explores several ways to initialize the clustering method. The introduction of error tolerance gives us more fine-grained control over the compression process.\n\nHere are some issues to be paid attention to:\n\n1. The overall pipeline including the last two stage looks quite similar to Han[1]. Though different initialization methods are tested in this paper, final conclusion does not change.\n\n2. The dynamic threshold pruning seems to be very time-consuming. As indicated from the paper, only 42 iterations for MNIST and 32 iterations for Cityscapes are required. Whether these number works for each layer or total network should be clarified.\n\n3. Fig 7(a) says it's error rate while it plots accuracy rate.\n\n4. Experiments on popular network structure such as residual connection should be conducted, as they are widely used nowadays.\n\n\nReferences:\n[1] Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149, 2015 \n"", 'The paper presents a method for iteratively pruning redundant weights in deep networks. The method is primarily based on a 3-step pipeline to achieve this objective. These three steps consist of pruning, weight sharing and quantization. The authors demonstrate reduction in model size and number of parameters significantly while only undergoing minor decrease in accuracy.\n\nSome of the main points of concern are below :\n\n - Computational complexity - The proposed method of iterative pruning seems quite computationally expensive. In the conclusion, it is mentioned that it takes 35 days of training for MNIST. This seems extremely high, and given this, it is unclear if there is much benefit in further reduction in model sizes and parameters (by the proposed method) than those obtained by existing method such as Han etal.\n\n - The novelty in the paper is quite limited and is mainly based on combining existing methods for pruning, weight sharing and quantization. The main difference from existing method seems to be the inclusion of layerwise threshold for weight pruning instead of using a single global threshold.\n\n - The results shown in Table 2 do not indicate much difference in terms of number of parameters between the proposed method and that of Han etal. For instance, the number of overall remaining parameters is 6.5% for the proposed method versus 8% for Deep Compression. As a result, the impact of the proposed method seems quite limited. \n\n - The paper in the title and abstract refers to segmentation as the main area of focus. However, there does not seem to be much related to it except an experiment on the CityScapes dataset.']","[70, -20, -50]","[80, 50, 20]","[""The sentiment score is 70 (positive) because the review starts with positive comments about the paper's quality, clarity, originality, and significance. The reviewer lists several pros and acknowledges the paper's interesting experiments and detailed analysis. While there are some cons and questions, they are presented as constructive feedback rather than major criticisms. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions for improvement rather than harsh judgments. The use of phrases like 'It would benefit...', 'It would be valuable...', and polite questions further contribute to the courteous tone. The reviewer also balances critique with praise, maintaining a professional and considerate approach."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'refined at each stage', 'partially avoids mistakenly pruning important connections'), they also point out several issues and limitations. The overall tone suggests that the paper's contributions are incremental rather than groundbreaking. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They provide constructive feedback and specific recommendations without using harsh or dismissive language. The reviewer maintains a respectful tone while clearly communicating areas for improvement."", ""The sentiment score is -50 because the review is predominantly critical, pointing out several concerns with the paper. The reviewer acknowledges some positive aspects (e.g., demonstrating reduction in model size) but focuses more on limitations and shortcomings. The politeness score is 20 because while the reviewer expresses criticism, they do so in a professional and constructive manner, using phrases like 'Some of the main points of concern are' and avoiding harsh language. The reviewer presents their concerns as objective observations rather than personal attacks, maintaining a respectful tone throughout.""]"
"[""The authors consider the problem of ultra-low precision neural networks motivated by \nlimited computation and bandwidth. Their approach first posits a Bayesian neural network\na discrete prior on the weights followed by central limit approximations to efficiently \napproximate the likelihood. The authors propose several tricks like normalization and cost \nrescaling to help performance. They compare their results on several versions of MNIST. The \npaper is promising, but I have several questions:\n\n1) One major concern is that the experimental results are only on MNIST. It's important \nto have another (larger) dataset to understand how sensitive the approach is to \ncharacteristics of the data. It seems plausible that a more difficulty problem may \nrequire more precision.\n\n2) Likelihood weighting is related to annealing and variational tempering\n\n3) The structure of the paper could be improved:\n - The introduction contains way too many details about the method \n    and related work without a clear boundary.\n - I would add the model up front at the start of section 2\n - Section 2.1 could be reversed or equations 2-5 could be broken with text \n   explaining each choice \n\n4) What does training time look like? Is the Bayesian optimization necessary?"", 'In this work, discrete-weight NNs are trained using the variational Bayesian framework, achieving similar results to other state-of-the-art models. Weights use 3 bits on the first layer and are ternary on the remaining layers.\n\n\n- Pros:\n\nThe paper is well-written and connections with the literature properly established.\n\nThe approach to training discrete-weights NNs, which is variational inference, is more principled than previous works (but see below).\n\n- Cons:\n\nThe authors depart from the original motivation when the central limit theorem is invoked. Once we approximate the activations with Gaussians, do we have any guarantee that the new approximate lower bound is actually a lower bound? This is not discussed. If it is not a lower bound, what is the rationale behind maximizing it? This seems to place this work very close to previous works, and not in the ""more principled"" regime the authors claim to seek.\n\nThe likelihood weighting seems hacky. The authors claim ""there are usually many more NN weights than there are data samples"". If that is the case, then it seems that the prior dominating is indeed the desired outcome. A different, more flat prior (or parameter sharing), can be used, but the described reweighting seems to be actually breaking a good property of Bayesian inference, which is defecting to the prior when evidence is lacking.\n\nIn terms of performance (Table 1), the proposed method seems to be on par with existing ones. It is unclear then what the advantage of this proposal is.\n\nSparsity figures are provided for the current approach, but those are not contrasted with existing approaches. Speedup is claimed with respect to an NN with real weights, but not with respect existing NNs with binary weights, which is the appropriate baseline.\n\n\n- Minor comments:\n\nPage 3: Subscript t and variable t is used for the targets, but I can\'t find where it is defined.\n\nOnly the names of the datasets used in the experiments are given, but they are not described, or even better, shown in pictures (maybe in a supplementary).\n\nThe title of the paper says ""discrete-valued NNs"". The weights are discrete, but the activations and outputs are continuous, so I find it confusing. As a contrast, I would be less surprised to hear a sigmoid belief network called a ""discrete-valued NN"", even though its weights are continuous.', ""Summary: \nThe paper considers a Bayesian approach in order to infer the distribution over a discrete weight space, from which they derive hardware-friendly low precision NNs. This is an alternative to a standard quantization step, often performed in cases such as emplying NNs on embedded devices.\nThe NN setting considered here contains sign activation functions.\nThe experiments conducted show that the proposed model achieves nice performance on several real world data Comments\n\nDue to an error in the openreview platform, I didn't have the chance to bid on time. This is not within my areas of expertise. Sorry for any inconvenience.""]","[20, -20, 0]","[60, 60, 50]","[""The sentiment score is slightly positive (20) because the reviewer describes the paper as 'promising' and provides constructive feedback. However, they also express concerns and suggest improvements, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing their comments as questions or suggestions rather than direct criticisms. They acknowledge the potential of the work while providing specific, actionable feedback. The reviewer maintains a professional tone, avoiding harsh language or personal comments, which contributes to the politeness of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros (well-written paper, principled approach), they list more cons and express significant concerns about the methodology and its advantages over existing approaches. The reviewer questions the theoretical foundations, the likelihood weighting method, and the lack of clear performance improvements. However, the score is not deeply negative as the reviewer does recognize some positive aspects.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns, such as 'It is unclear then what the advantage of this proposal is' rather than using harsh or dismissive language. The reviewer also acknowledges the positive aspects of the paper before delving into criticisms. The use of phrases like 'The paper is well-written' and the inclusion of both pros and cons demonstrates a balanced and courteous approach to the review."", ""The sentiment score is 0 (neutral) because the reviewer does not provide any evaluation of the paper's content. They simply state that due to an error, they were unable to bid on time and that the paper is not within their area of expertise. There is no positive or negative sentiment expressed towards the paper itself. The politeness score is 50 (somewhat polite) because the reviewer apologizes for any inconvenience caused, which is a polite gesture. However, the review doesn't go out of its way to be exceptionally polite, maintaining a neutral, professional tone overall. The reviewer's acknowledgment of the mistake and apology shows consideration, which contributes to the slightly positive politeness score.""]"
"['The paper proposes a new method to train knowledge base embeddings using a least-squares loss. For this purpose, the paper introduces a reweighting scheme of the entries in the original adjacency tensor. The reweighting is derived from an analysis of the cross-entropy loss. In addition, the paper discusses the connections of the margin and cross-entropy loss and evaluates the proposed method on WN18 and FB15k.\n\n The paper tackles an interesting problem, as learning from knowledge bases via embedding methods has become increasingly important for tasks such as question answering. Providing additional insight into current methods can be an important contribution to advance the state-of-the-art.\n\nHowever, I\'m concerned about several aspects in the current form of the paper. For instance, the derivation in Section 4 is unclear to me, as eq.4 suddenly introduces a weighted sum over expectations using the degrees of nodes. The derivation also seems to rely on a very specific negative sampling assumption (uniform sampling without checking whether the corrupted triple is a true negative). This sampling method isn\'t used consistently across models and also brings its own problems, e.g., see the LCWA discussion in [4]\n\nIn addition, the semantics that are introduced by the weighting scheme are not clear to me either. Using the proposed method, the probability of edges between high-degree nodes are down-weighted, since the ground-truth labels are divided by the node degrees. Since these weighted labels are then fitted using a least-squares loss, this implies that links between high-degree nodes should be less likely, which seems the opposite of what the scores should look like.\n\nWith regard to the significance of the contributions: Using a least-squares loss in combination with tensor methods is attractive because it enables ALS algorithms with closed-form updates that can be computed very fast. However, the proposed method still relies on SGD optimization. In this context, it is not clear to me why a tensor framework/least-squares loss would be preferable.\n\nFurther comments:\n- The paper seems to equate ""tensor method"" with using a least squares loss. However, this doesn\'t have to be the case. For instance see [1,2] which propose Logistic and Poisson tensor factorizations, respectively.\n- The distinction between tensor factorization and neural methods is unclear. Tensor factorization can be interpreted just as a particular scoring function. For instance, see [5] for a detailed discussion.\n- The margin based ranking loss has been proposed earlier than in (Collobert et al, 2011). For instance see [3]\n- p1: corrupted triples are not described entirely correct, typically only one of s or o is corrputed. \n- Closed-form tensor in Table 1: This should be least-squares loss of f(s,p,o) and log(...)?\n- p6: Adding the constant to the tensor as proposed in (Levy & Goldberg, 2014) can done while gathering the minibatch and is therefore equivalent to the proposed approach.\n\n[1] Nickel et al: Logistic Tensor Factorization for Multi-Relational Data, 2013.\n[2] Chi et al: ""On tensors, sparsity, and nonnegative factorizations"", 2012\n[3] Collobert et al: A unified architecture for natural language processing, 2008\n[4] Dong et al: Knowledge Vault: A Web-Scale Approach to Probabilistic Knowledge Fusion, 2014\n[5] Nickel et al: A Review of Relational Machine Learning for Knowledge Graphs, 2016.', ""This paper deals with the problem of representation learning from knowledge bases (KB), given in form of subject-relationship-object triplets. The paper has two main contributions: (1) Showing that two commonly used loss functions, margin-based and negative sampling-based, are closely related to each other; and (2) many of the KB embedding approaches can be reduced to a tensor decomposition problem where the entries in the tensor are a certain transformation of the original triplets values. \n\nContribution (1) related to the connection between margin-based and negative sampling-based loss functions is sort of obvious in hindsight and I am not sure if it has been not recognized in prior work (I'm not very well-versed in this area). Regardless, even though this connection  is moderately interesting, I am not sure of its practical usefulness. I would like the authors to comment on this aspect.\n\nContribution (2) that shows that KB embedding approaches based on some of the popularly used loss functions such as margin-based or negative sampling can be cast as tensor factorization of a certain transformation of the original data is also interesting. However, similar connections have been studied for word-embedding methods. For example, prior work has shown that word embedding methods that optimize loss functions such as negative sampling can be seen as doing implicit matrix factorization of a transformed version of the word-counts. Therefore contribution (2) seems similar in spirit to this line of work.\n\nOverall, the paper does have some interesting insights but it is unclear if these insights are non-trivial/surprising, and are of that much practical utility. I would like to authors to respond to these concerns."", ""The paper proposes a unified view of multiple methods for learning knowledge base embeddings.\n\nThe paper's motivations are interesting but the execution does fit standard for a publication at ICLR.\nMain reasons:\n* Section 3 does not bring much value. It is a rewriting trick that many knew but never thought of publishing\n* Section 4.1 is either incorrect or clearly misleading. What happens to the summation terms related to the negative samples (o~=o' and s!=s') between the last equation and the 2 before that (on the expectations) at the bottom of page 4? They vanished while they are depending on the single triple (s, r, o), no?\n* The independence assumption at the top of page 5 is indeed clearly too strong in the case of multi-relational graphs, where triples are all interconnected.\n* In 4.2, writing that both RESCAL and KBTD explain a RDF triple through a similar latent form is not an observation that could explain intrinsic similarities between the methods but the direct consequence of the deliberate choice made for f(.) at the line before.\n* The experiments are hard to use to validate the model because they are based on really outdated baselines. Most methods in Table 4 and 5 are performing well under their best known performance.\n\n""]","[-50, -20, -60]","[50, 50, 20]","[""The sentiment score is -50 because while the reviewer acknowledges the interesting problem and potential importance of the work, they express significant concerns about several aspects of the paper. The review lists multiple issues with the derivation, semantics, and significance of the contributions. The overall tone suggests the reviewer is not convinced by the paper's approach and results. For politeness, the score is 50 because the reviewer uses respectful language throughout, starting with positive aspects before moving to criticisms. They phrase concerns as personal observations (e.g., 'is unclear to me') rather than absolute statements. The reviewer also provides constructive feedback and references to support their points, which is helpful and courteous. However, the politeness doesn't reach the highest levels as the criticism, while professionally delivered, is quite direct and extensive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some 'interesting insights' in the paper, they express skepticism about the novelty and practical utility of the contributions. Phrases like 'sort of obvious in hindsight', 'not sure of its practical usefulness', and 'unclear if these insights are non-trivial/surprising' indicate a somewhat critical stance. However, the reviewer does not completely dismiss the work, recognizing it as 'moderately interesting' and having 'some interesting insights', which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use polite language such as 'I would like the authors to comment' and 'I would like the authors to respond', showing consideration for the authors' perspective. The reviewer also balances critique with acknowledgment of the paper's merits, which contributes to the polite tone."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the paper's execution doesn't meet ICLR standards and lists several critical issues with the paper's content and methodology. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone and provide specific, constructive feedback. The language used is not rude, but rather matter-of-fact in pointing out the paper's shortcomings. The reviewer acknowledges the interesting motivations of the paper at the beginning, which adds a slight positive note to an otherwise critical review.""]"
"['The author present Autostacker, a new algorithm for combining the strength of different learning algorithms during hyper parameter search. During the first step, the hyperparameter search is done in a conventional way. At the second step, the output of each primitives is added to the features of the original dataset and the training and hyperparameter search starts again. This process is repeated for some number of steps. The experiments are performed on 15 small scale dataset and show that Autostacker is performing better  than random forest almost systematically and better than TPOT, the external baseline, 13 times out of 15. Also the speed comparison favor Autostacker vs TPOT.\n\nThis algorithm is not highly innovative. Using the output of some algorithms as the input of another one for learning was seen numerous time in the literature. The novelty here is how exactly it is performed, which is a bit ad hoc. \n\nWhile testing on numerous dataset is important to verify the strength of a learning algorithm, final statistical significance test should be provided e.g. Sign Test, Wilcoxon Signed Rank Test.\n\nThe experiment compares with a weak baseline and a baseline that is unknown to me. Also, the datasets are all small scale which is not representative of modern machine learning. This leaves me very uncertain about the actual quality of the proposed algorithm. \n\nThe strength of the Random Forest baseline could easily be augmented by simply considering the best learning algorithm over validation across the hyper parameter search (i.e. the choice of the learning algorithm is also a hyperparameter). Also a very simple and fast ensemble could be considered by using Agnostic Bayesian Learning of Ensembles (Lacoste et. al.). It is also common to simply consider a linear combination of the output of the different estimator obtained during cross validation and very simple to implement. This would provide other interesting baselines.\n\nFinally the writing of the paper could be highly improved. Many typos, including several badly formatted citations (consider using \\citet and \\citep for a proper usage of parenthesis).\n', 'In this work, the authors propose to apply parallel hill climbing to learn a stacked machine learning model architecture for a particular machine learning problem. Modest experimental results suggests it compares favorably to another evoluation-inspired AutoML algorithm.\n\nWhile the idea of Autostacker is presented clearly, the paper has two severe limitations (detailed comments below). First, the contribution itself is fairly minimal; second, even if the contribution were more substantial, the current presentation does not relate to “learning representations” in any meaningful way.\n\n=== Major comments\n\nFirst, as mentioned above, this paper leans heavily on existing work. Stacking and ensemble methods have become standard approaches in practical machine learning settings (for example, in Kaggle challenges). Likewise, parallel hill climbing (and the closely-related beam search) are common local search strategies for difficult optimization problems. However, it is unclear that combining these yields any unexpected synergies. \n\nIndeed, very similar approaches have been proposed in the literature already. For example, [Welchowski, T. & Schmidt, M. A framework for parameter estimation and model selection in kernel deep stacking networks. Artificial Intelligence in Medicine, 2016, 70, 31-40], propose a very similar model, including search with hill climbing and using the original data at each layer. While they do restrict the considered primitive model type, neither paper offers any compelling theoretical results, so this is largely an implementation detail in terms of novelty.\n\nAdditionally, the paper lacks any discussion about how the architectures may change during search, as well as what sorts of architectures are learned. For example, the given number of layers and nodes are maximums; however, the text just above Algorithm 1 points out that the first step in the algorithm is to “generate N completed pipelines.” What exactly does this mean? If PHC randomly changes one of the architecture hyperparameters, what happens? e.g., which layer is removed? Ultimately, what types of architectures are selected?\n\nFinally, ICLR does not seem like a good venue for this work. As presented, the work does not discuss learning representations in any way; likewise, none of the primitive models in Table 1 are typically considered “representation learning models.” Thus, it is not obvious that Autostacker would be especially effective at optimizing the hyperparameters of those models. Experimental results including these types of models could, in principle, demonstrate that Autostacker is applicable, but the current work does not show this.\n\n=== Minor comments\n\nSection 3.3 seems to advocate training on the testing data. Even if the described approach is common practice (e.g., looking at 10-fold CV results, updating the model, and running CV again), selecting among the models using inner- and outer-validation sets would avoid explicitly using information about the testing set for improving the model.\n\nHow sensitive is the approach to the choice of the number of layers and nodes, both in terms of accuracy and resource usage?\n\nIt would be helpful to include basic characteristics of the datasets used in this study, perhaps as a table in the appendix.\n\n=== Typos, etc.\n\nThe paper has numerous typos and needs thorough editing. The references in the text are not formatted correctly. I do not believe this affects understanding the paper, but it definitely disrupts reading.\n\nThe references are inconsistently and incorrectly formatted (e.g., “Bayesian” should be capitalized).\n', 'The authors introduce a simple hill climbing approach to (very roughly) search in the space of cascades of classifiers.\nThey first reinvent the concept of cascades of classifiers as an extension of stacking (https://en.wikipedia.org/wiki/Cascading_classifiers). Cascading is like stacking but carries over all original model inputs to the next classifier.\nThe authors cast this nicely into a network view with nodes that are classifiers and layers that use the outputs from previous layers. However, other than relating this line of work to the ICLR community, this interpretation of cascading is not put to any use. \nThe paper incorrectly claims that existing AutoML frameworks only allow using a specific single model. In fact, Auto-sklearn (Feurer et al, 2015) automatically constructs ensembles of up to 50 models, helping it to achieve more robust performance.\n\nI have some questions about the hillclimbing approach: \n- How is the ""one change"" implemented in the hill climber? Does this evaluate results for each of several single changes and pick the best one? Or does it simply change one classifier and continue? Or does it evaluate all possible individual changes and pick the best one? I note that the term ""HillClimber"" would suggest that some sort of improvement has to be made in each step, but the algorithm description does not show any evaluation step at this point. The hill climbing described in the text seems to make sense, but the pseudocode appears broken.\n\nSection 4.2: I am surprised that there is only a comparison to TPOT, not one to Auto-sklearn. Especially since Auto-sklearn constructs ensembles posthoc this would be an interesting comparison.\nAs the maximum range of number of layers is 5, I assume that scaling is actually an issue in practice after all, and the use of hundreds of primitive models alluded to in the introduction are not a reality at this point.\n\nThe paper mentions guarantees twice:\n- ""This kind of guarantee of not being worse on average comes from the the characteristic of AutoStacked""\n- ""can be guaranteed to do better on average""\nI am confident that this is a mistake / an error in choosing the right expression in English. I cannot see why there should be a guarantee of any sort.\n\nEmpirically, Autostacker appears better than RandomForest, but that is not a big feat. The improvements vs. TPOT are more relevant. One question: the data sets used in Olson et al are very small. Does TPOT overfit on these? Since AutoStacker does not search as exhaustively, could this explain part of the performance difference? How many models are evaluated in total by each of the methods?\n\nI am unsure about the domain for the HillClimber. Does it also a search over which classifiers are used where in the pipeline, or only about their hyperparameters?\n\nMinor issues:\n- The authors systematically use citations wrongly, apparently never using citep but only having inline citations.\n- Some parts of the paper feel unscientific, such as using phrases like ""giant possible search space"". \n- There are also several English grammar mistakes (e.g., see the paragraph containing ""for the discover"") and typos.\n- Why exactly would a small amount of data be more likely to be unbalanced?\n- The data ""cleaning"" method of throwing out data with missing values is very unclean. I hope this has only been applied to the training set and that no test set data points have been dropped?\n- Line 27 of Algorithm 1: sel_pip has not been defined here\n\nOverall, this is an interesting line of work, but it does not seem quite ready for publication.\n\nPros: \n- AutoML is a topic of high importance to both academia and industry\n- Good empirical results \n\nCons: \n- Cascading is not new\n- Unclear algorithm: what exactly does the Hillclimber function do?\n- Missing baseline comparison to Auto-sklearn\n- Incorrect statements about guarantees']","[-20, -60, -40]","[50, 20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the work (e.g., 'Autostacker is performing better than random forest almost systematically'), they also express significant criticisms. The reviewer points out that the algorithm is 'not highly innovative', the experiments use 'small scale dataset[s]' which are 'not representative of modern machine learning', and there are concerns about the baselines used. The writing quality is also criticized. However, the tone is not entirely negative, hence the score is only slightly below neutral.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and objective tone throughout. They offer constructive criticism and suggestions for improvement rather than harsh condemnation. The language used is respectful and focuses on the work rather than personal attacks. Phrases like 'could be highly improved' and 'consider using' indicate a helpful rather than confrontational approach. However, the review doesn't go out of its way to be overly polite or complimentary, keeping the score from being higher."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out 'severe limitations' of the paper, describes the contribution as 'minimal', and states that ICLR is not a good venue for this work. They also mention numerous typos and formatting issues. However, they do acknowledge that the idea is presented clearly, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'it would be helpful' and provide detailed explanations for their concerns, which shows respect for the authors. The reviewer also offers constructive suggestions for improvement. However, the use of strong negative language like 'severe limitations' prevents the score from being higher on the politeness scale."", ""The sentiment score is -40 because the review is generally critical, pointing out several issues with the paper such as unclear algorithms, missing comparisons, and incorrect statements. However, it does acknowledge some positive aspects like 'interesting line of work' and 'good empirical results', preventing a more negative score. The politeness score is 20 because the reviewer uses professional language and offers constructive criticism. They phrase concerns as questions and use polite expressions like 'I am surprised' instead of more direct criticisms. The reviewer also balances negative points with positive ones, showing a respectful approach. However, the overall critical nature of the review prevents a higher politeness score.""]"
"['In this paper, the authors consider symmetric (3rd order) CP decomposition of a PPMI tensor M (from neighboring triplets), which they call CP-S. Additionally, they propose an extension JCP-S, for n-order tensor decompositions. This is then compared with random, word2vec, and NNSE, the latter of two which are matrix factorization based (or interpretable) methods. The method is shown to be superior in tasks of 3-way outlier detection, supervised analogy recovery, and sentiment analysis. Additionally, it is evaluated over the MEN and Mturk datasets.\n\n\nFor the JCP-S model, the loss function is unclear to me. L is defined for 3rd order tensors only;  how is the extended to n > 3? Intuitively it seems that L is redefined, and for, say, n = 4, the model is M(i,j,k,n) = \\sum_1^R u_ir u_jr u_kr u_nr. However, the statement ""since we are using at most third order tensors in this work"" I am further confused. Is it just that JCP-S also incorporates 2nd order embeddings? I believe this requires clarification in the manuscript itself.\n\nFor the evaluations, there are no other tensor-based methods evaluated, although there exist several well-known tensor-based word embedding models existing:\n\nPengfei Liu, Xipeng Qiu∗ and Xuanjing Huang, Learning Context-Sensitive Word Embeddings with Neural Tensor Skip-Gram Model,  IJCAI 2015\n\nJingwei Zhang and Jeremy Salwen, Michael Glass and Alfio Gliozzo. Word Semantic Representations using Bayesian Probabilistic Tensor Factorization, EMNLP 2014\n\nMo Yu, Mark Dredze, Raman Arora, Matthew R. Gormley, Embedding Lexical Features via Low-Rank Tensors\n\nto name a few via quick googling.\n\nAdditionally, since it seems the main benefit of using a tensor-based method is that you can use 3rd order cooccurance information, multisense embedding methods should also be evaluated. There are many such methods, see for example \n\nJiwei Li, Dan Jurafsky, Do Multi-Sense Embeddings Improve Natural Language Understanding?\n\nand citations within, plus quick googling for more recent works.\n\nI am not saying that these works are equivalent to what the authors are doing, or that there is no novelty, but the evaluations seem extremely unfair to only compare against matrix factorization techniques, when in fact many higher order extensions have been proposed and evaluated, and especially so on the tasks proposed (in particular the 3-way outlier detection). \n\nObserve also that in table 2, NNSE gets the highest performance in both MEN and MTurk. Frankly this is not very surprising; matrix factorization is very powerful, and these simple word similarity tasks are well-suited for matrix factorization. So, statements like ""as we can see, our embeddings very clearly outperform the random embedding at this task"" is  an unnecessary inflation of a result that 1) is not good and 2) is reasonable to not be good. \n\nOverall, I think for a more sincere evaluation, the authors need to better pick tasks that clearly exploit 3-way information and compare against other methods proposed to do the same.\n\nThe multiplicative relation analysis is interesting, but at this point it is not clear to me why multiplicative is better than additive in either performance or in giving meaningful interpretations of the model. \n\nIn conclusion, because the novelty is also not that big (CP decomposition for word embeddings is a very natural idea) I believe the evaluation and analysis must be significantly strengthened for acceptance. ', 'The paper presents the word embedding technique which consists of: (a) construction of a positive (i.e. with truncated negative values) pointwise mutual information order-3 tensor for triples of words in a sentence and (b) symmetric tensor CP factorization of this tensor. The authors propose the CP-S (stands for symmetric CP decomposition) approach which tackles such factorization in a ""batch"" manner by considering small random subsets of the original tensor. They also consider the JCP-S approach, where the ALS (alternating least squares) objective is represented as the joint objective of the matrix and order-3 tensor ALS objectives. The approach is evaluated experimentally on several tasks such as outlier detection, supervised analogy recovery, and sentiment analysis tasks.\n\nCLARITY: The paper is very well written and is easy to follow. However, some implementation details are missing, which makes it difficult to assess the quality of the experimental results.\n\nQUALITY: I understand that the main emphasis of this work is on developing faster computational algorithms, which would handle large scale problems, for factorizing this tensor. However, I have several concerns about the algorithms proposed in this paper:\n\n  - First of all, I do not see why using small random subsets of the original tensor would give a desirable factorization. Indeed, a CP decomposition of a tensor can not be reconstructed from CP decompositions of its subtensors. Note that there is a difference between batch methods in stochastic optimization where batches are composed of a subset of observations (which then leads to an approximation of desirable quantities, e.g. the gradient, in expectation) and the current approach where subtensors are considered as batches. I would expect some further elaboration of this question in the paper. Although similar methods appeared in the tensor literature before, I don\'t see any theoretical ground for their correctness.\n\n  - Second, there is a significant difference between the symmetric CP tensor decomposition and the non-negative symmetric CP tensor decomposition. In particular, the latter problem is well posed and has good properties (see, e.g., Lim, Comon. Nonengative approximations of nonnegative tensors (2009)). However, this is not the case for the former (see, e.g., Comon et al., 2008 as cited in this paper). Therefore, (a) computing the symmetric and not non-negative symmetric decomposition does not give any good theoretical guarantees (while achieving such guarantees seems to be one of the motivations of this paper) and (b) although the tensor is non-negative, its symmetric factorization is not guaranteed to be non-negative and further elaboration of this issue seem to be important to me.\n\n  - Third, the authors claim that one of their goals is an experimental exploration of tensor factorization approaches with provable guarantees applied to the word embedding problem. This is an important question that has not been addressed in the literature and is clearly a pro of the paper. However, it seems to me that this goal is not fully implemented. Indeed, (a) I mentioned in the previous paragraph the issues with the symmetric CP decomposition and (b) although the paper is motivated by the recent algorithm proposed by Sharan&Valiant (2017), the algorithms proposed in this paper are not based on this or other known algorithms with theoretical guarantees. This is therefore confusing and I would be interested in the author\'s point of view to this issue.\n\n  - Further, the proposed joint approach, where the second and third order information are combined requires further analysis. Indeed, in the current formulation the objective is completely dominated by the order-3 tensor factor, because it contributes O(d^3) terms to the objective vs O(d^2) terms contributed by the matrix part. It would be interesting to see further elaboration of the pros and cons of such problem formulation.\n\n  - Minor comment. In the shifted PMI section, the authors mention the parameter alpha and set specific values of this parameter based on experiments. However, I don\'t think that enough information is provided, because, given the author\'s approach, the value of this parameter most probably depends on other parameters, such as the bach size.\n\n  - Finally, although the empirical evaluation is quite extensive and outperforms the state-of the art, I think it would be important to compare the proposed algorithm to other tensor factorization approaches mentioned above. \n\nORIGINALITY: The idea of using a pointwise mutual information tensor for word embeddings is not new, but the authors fairly cite all the relevant literature. My understanding is that the main novelty is the proposed tensor factorization algorithm and extensive experimental evaluation. However, such batch approaches for tensor factorization are not new and I am quite skeptical about their correctness (see above). The experimental evaluation presents indeed interesting results. However, I think it would also be important to compare to other tensor factorization approaches. I would also be quite interested to see the performance of the proposed algorithm for different values of parameters (such as the butch size).\n\nSIGNIFICANCE: I think the paper addresses very interesting problem and significant amount of work is done towards the evaluation, but there are some further important questions that should be answered before the paper can be published.  To summarize, the following are the pros of the paper:\n\n  - clarity and good presentation;\n  - good overview of the related literature;\n  - extensive experimental comparison and good experimental results.\n\nWhile the following are the cons:\n\n  - the mentioned issues with the proposed algorithm, which in particular does not have any theoretical guarantees;\n  - lack of details on how experimental results were obtained, in particular, lack of the details on the values of the free parameters in the proposed algorithm;\n  - lack of comparison to other tensor approaches to the word embedding problem (i.e. other algorithms for the tensor decomposition subproblem);\n  - the novelty of the approach is somewhat limited, although the idea of the extensive experimental comparison is good.\n\n\n', ""The paper proposes to extend the usual PPMI matrix factorization (Levy and Goldberg, 2014) to a (3rd-order) PPMI tensor factorization. The paper chooses symmetric CP decomposition so that word representations are tied across all three views. The MSE objective (optionally interpolated with a 2nd-order tensor) is optimized incrementally by SGD. \n\nThe paper's most clear contribution is the observation that the objective results in multiplicative compositionality of vectors, which indeed does not seem to hold in CBOW. \n\nWhile the paper reports superior performance, the empirical claims are not well substantiated. It is *not* true that given CBOW, it's not important to compare with SGNS and GloVe. In fact, in certain cases such as unsupervised word analogy, SGNS is clearly and vastly superior to other techniques (Stratos et al., 2015). The word similarity scores are also generally low: it's easy to achieve >0.76 on MEN using the plain PPMI matrix factorization on Wikipedia. So it's hard to tell if it's real improvement. \n\nQuality: Borderline. The proposed approach is simple and has an appealing compositional feature, but the work is not adequately validated and the novelty is somewhat limited. \n\nClarity: Clear.\n\nOriginality: Low-rank tensors have been used to derive features in many prior works in NLP (e.g., Lei et al., 2014). The paper's particular application to learning word embeddings (PPMI factorization), however, is new although perhaps not particularly original. The observation on multiplicative compositionality is the main strength of the paper.\n\nSignificance: Moderate. For those interested in word embeddings, this work suggests an alternative training technique, but it has some issues (described above).  ""]","[-50, -30, -20]","[20, 60, 50]","[""The sentiment score is -50 because the reviewer expresses several significant concerns and criticisms about the paper, including unclear methodology, unfair comparisons, and lack of novelty. However, they do acknowledge some interesting aspects and don't completely dismiss the work. The politeness score is 20 because the reviewer uses generally professional language and offers constructive feedback, but there are a few instances of blunt criticism (e.g., 'unnecessary inflation of a result'). The reviewer balances critique with suggestions for improvement, maintaining a mostly polite tone while clearly communicating their concerns."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects of the paper (such as clarity, good presentation, and extensive experimental comparison), they express several significant concerns about the proposed algorithms and their theoretical foundations. The overall tone suggests that substantial revisions are needed before the paper can be published. The politeness score is 60 because the reviewer uses respectful and professional language throughout, acknowledging the paper's strengths while clearly articulating their concerns. They use phrases like 'I would be interested in the author's point of view' and 'I think it would be important to', which maintain a constructive and collegial tone even when expressing criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'simple and has an appealing compositional feature'), they also point out several significant limitations and concerns. The reviewer states that 'empirical claims are not well substantiated', 'novelty is somewhat limited', and the work is 'not adequately validated'. The overall tone suggests the paper is borderline in quality with moderate significance.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They provide constructive criticism without using harsh language. The reviewer acknowledges the paper's strengths (e.g., 'clear contribution', 'appealing compositional feature') alongside its weaknesses. The language used is objective and focuses on the content rather than making personal remarks about the authors.""]"
"['The paper provides an analysis of the representations learnt in convolutional neural networks that take raw audio waveforms as input for a speaker emotion recognition task. Based on this analysis, an architecture is proposed and compared to other architectures inspired by other recent work. The proposed architecture overfits less on this task and thus performs better.\n\nI think this work is not experimentally strong enough to draw the conclusions that it draws. The proposed architecture, aptly called ""SimpleNet"", is relatively shallow compared to the reference architectures, and the task that is chosen for the experiments is relatively small-scale. I think it isn\'t reasonable to draw conclusions about what convnets learn in general from training on a single task, and especially not a small-scale one like this. \n\nMoreover, SoundNet, which the proposed architecture is compared to, was trained on (and designed for) a much richer and more challenging task originally. So it is not surprising at all that it overfits dramatically to the tasks chosen here (as indicated in table 1), and that a much shallower network with fewer parameters overfits less. This seems obvious to me, and contrary to what\'s claimed in the paper, it provides no convincing evidence that shallow architectures are inherently better suited for raw audio waveform processing. This is akin to saying that LeNet-5 is a better architecture for image classification than Inception, because the latter overfits more on MNIST. Perhaps using the original SoundNet task, which is much more versatile, would have lent some more credibility to these claims.\n\nThe analysis in section 2.2 is in-depth, but also not very relevant: it ignores the effects of nonlinearities, which are an essential component of modern neural network architectures. Studying their effects in the frequency domain would actually be quite interesting. It is mentioned that the ReLU nonlinearity acts as a half-wave rectifier, but the claim that its effect in the frequency domain is small compared to aliasing is not demonstrated. The claim that ""ReLU and non-linear activations can improve the network performance, but they are not the main factors in the inner workings of CNNs"" is also unfounded.\n\nThe conclusion that stacking layers is not useful might make sense in the absence of nonlinearities, but when each layer includes a nonlinearity, the obvious point of stacking layers is to improve the expressivity of the network. Studying aliasing effects in raw audio neural nets is a great idea, but I feel that this work takes some shortcuts that make the analysis less meaningful.\n\n\n\n\nOther comments:\n\nThe paper is quite lengthy (11 pages of text) and contains some sections that could easily be removed, e.g. 2.1.1 through 2.1.3 which explain basic signal processing concepts and could be replaced by a reference. In general, the writing could be much more concise in many places.\n\nThe paper states that ""it remains unknown what actual features CNNs learn from waveforms."". There is actually some prior work that includes some analysis on what is learnt in the earlier layers of convnets trained on raw audio: \n""Learning the Speech Front-end With Raw Waveform CLDNNs"", Sainath et al.\n""Speech acoustic modeling from raw multichannel waveforms"", Hoshen et al.\n""End-to-end learning for music audio"", Dieleman & Schrauwen\nOnly the first one is cited, but not in this context. I think saying ""it remains unknown"" is a bit too strong of an expression.\n\nThe meaning of the following comment is not clear to me: ""because in computer vision, the spatial frequency is not the only information the model can use"". Surely the frequency domain and the spatial domain are two different representations of the same information contained in an image or audio signal? So in that sense, spatial frequency does encompass all information in an image.\n\nThe implication that high-frequency information is less useful for image-based tasks (""the spatial frequency of images is usually low"") is incorrect. While lower frequencies dominate the spectrum more obviously in images than in audio, lots of salient information (i.e. edges, textures) will be high-frequency, so models would still have to learn high-frequency features to perform useful tasks.\n\nWaveNet is mentioned (2.2.4) but not cited. WaveNet is a fairly different architecture than the ones discussed in this paper and it would be useful to at least discuss it in the related work section. A lot of the supposed issues discussed in this paper don\'t apply to WaveNet (e.g. there are no pooling layers, there is a multiplicative nonlinearity in each residual block).\n\nThe paper sometimes uses concepts without clearly defining them, e.g. ""front-end layers"". Please clearly define each concept when it is first introduced.\n\nThe paper seems to make a fairly arbitrary distinction between layers that perform signal filtering operations, and layers that don\'t - but every layer can be seen as a (possibly nonlinear) filtering operation. Even if SimpleNet has fewer ""front-end layers"", surely the later layers in the network can still introduce aliasing? I think the implicit assumption that later layers in the network perform a fundamentally different kind of operation is incorrect.\n\nIt has been shown that even random linear filters can be quite frequency-selective (see e.g. ""On Random Weights and Unsupervised Feature Learning"", Saxe et al.). This is why I think the proposed ""changing rate"" measure is a poor choice to show effective training. Moreover, optimization pathways don\'t have to be linear in parameter space, and oscillations can occur. Why not measure the difference with the initial values (at iteration 0)? It seems like that would prove the point a bit better.\n\nManually designing filters to initialize the weights of a convnet has been done in e.g. Sainath et al. (same paper as mentioned before), so it would be useful to refer to it again when this idea is discussed.\n\nIn SpecNet, have the magnitude spectrograms been log-scaled? This is common practice and it can make a dramatic difference in performance. If you haven\'t tried this, please do.\n', 'Summary: \n\nThe authors aim to analyze what deep CNNs learn, and end up proposing “SimpleNet”, which essentially reduces the early feature extraction stage of the network to a single convolutional layer, which is initialized using pre-defined filters. The authors step through a specific example involving bandpass filters to illustrate that multiple layers of filtering can be reduced to a single layer in the linear case, as well as the limitations of pooling. Results on a 4-class speaker emotion recognition task demonstrate some advantage over other, deeper architectures that have been proposed, as well as  predefined feature processing.\n\nReview:\n\nThe authors’ arguments and analysis are in my assessment rudimentary---the effects of pooling and cascading multiple linear convolutions are well appreciated by researchers in the field. Furthermore, the adaptation of “front-end” signal processing modules in and end-to-end manner has been considered extensively before (e.g. Sainath et al., 2015), and recent work on very deep networks for signal processing that shows gains on more substantial tasks have not been cited (e.g. Dai, Wei, et al. below). Finally, the experimental results, considering the extensive previous work in this area, are insufficient to establish novel performance in lieu of novel ideas.\n\nOverall Recommendation: \n\nOverall, this paper is a technical report that falls well below the acceptance threshold for ICLR for the reasons cited above. Reject. \n', 'The paper proposes a CNN-based based approach for speech processing using raw waveforms as input. An analysis of convolution and pooling layers applied on waveforms is first presented. An architecture called SimpleNet is then presented and evaluated on two speech tasks: emotion recognition and gender classification. \n\nThis paper propose a theoretical analysis of convolution and pooling layers to motivate the SimpleNet architecture. To my understanding, the analysis is flawed (see comments below). The SimpleNet approach is interesting but not sufficiently backed with experimental results. The network analysis is minimal and provides almost no insights. I therefore recommend to reject the paper. \n\nDetailed comments:\n\nSection 1:\n\n* “Therefore, it remains unknown what actual features CNNs learn from waveform”. This is not true, several works on speech recognition have shown that a convolution layer taking raw speech as input can be seen as a bank of learned filters. For instance in the context of speech recognition, [9] showed that the filters learn phoneme-specific responses, [10] showed that the learned filters are close to Mel filter banks and [7] showed that the learned filters are related to MRASTA features and Gabor filters. The authors should discuss these previous works in the paper.\n\nSection 2:\n\n* Section 2.1 seems unnecessary, I think it’s safe to assume that the Shannon-Nyquist theorem and the definition of convolution are known by the reader.\n\n* Section 2.2.2 & 2.2.3: I don\'t follow the justification that stacking convolutions are not needed: the example provided is correct if two convolutions are directly stacked without non-linearity, but the conclusion does not hold with a non-linearity and/or a pooling layer between the convolutions: two stacked convolutions with non-linearities are not equivalent to a single convolution. To my understanding, the same problem is present for the pooling layer: the presented conclusion that pooling introduces aliasing is only valid for two directly stacked pooling layers and is not correct for stacked blocks of convolution/pooling/non-linearity.\n\n* Section 2.2.5: The ReLU can be seen as a half-wave rectifier if it is applied directly to the waveform. However, it is usually not the case as it is applied on the output of the convolution and/or pooling layers. Therefore I don’t see the point of this section. \n\n* Section 2.2.6: In this section, the authors discuss the differences between spectrogram-based and waveforms-based approaches, assuming that spectrogram-based approach have fixed filters. But spectrogram can also be used as input to CNNs (i.e. using learned filters) for instance in speech recognition [1] or emotion recognition [11]. Thus the comparison could be more interesting if it was between spectrogram-based and raw waveform-based approaches when the filters are learned in both cases.  \n\nSection 3:\n\n* Figure 4 is very interesting, and is in my opinion a stronger motivation for SimpleNet that the analysis presented in Section 2.\n\n* Using known filterbanks such as Mel or Gammatone filters as initialization point for the convolution layer is not novel and has been already investigated in [7,8,10] in the context of speech recognition. \n\nSection 4:\n\n* On emotion recognition, the results show that the proposed approach is slightly better, but there is some issues: the average recall metric is usually used for this task due to class imbalance (see [1] for instance). Could the authors provide results with this metric ? Also IEMOCAP is a well-used corpus for this task, could the authors provide some baselines performance for comparison (e.g. [11]) ? \n\n* For gender classification, there is no gain from SimpleNet compared to the baselines. The authors also mention that some utterances have overlapping speech. These utterances are easy to find from the annotations provided with the corpus, so it should be easy to remove them for the train and test set. Overall, in the current form, the results are not convincing.\n\n* Section 4.3: The analysis is minimal: it shows that filters changed after training (as already presented in Figure 4). I don\'t follow completely the argument that the filters should focus on low frequency. It is more informative, but one could expect that the filters will specialized, thus some of them will focus on high frequencies, to model the high frequency events such as consonants or unvoiced event. \nIt could be very interesting to relate the learned filters to the labels: are some filters learned to model specific emotions ? For gender classification, are some filters focusing on the average pitch frequency of male and female speaker ?\n\n* Finally, it would be nice to see if the claims in Section 2 about the fact that only one convolution layer is needed and that stacking pooling layers can hurt the performance are verified experimentally: for instance, experiments with more than one pair of convolution/pooling could be presented.\n\nMinor comments:\n\n* More references for raw waveforms-based approach for speech recognition should be added [3,4,6,7,8,9] in the introduction.\n\n* I don’t understand the first sentence of the paper: “In the field of speech and audio processing, due to the lack of tools to directly process high dimensional data …”. Is this also true for any pattern recognition fields ?  \n\n* For the MFCCs reference in 2.2.2, the authors should cite [12].\n\n* Figure 6: Only half of the spectrum should be presented.\n\nReferences: \n\n[1] H. Lee, P. Pham, Y. Largman, and A. Y. Ng. Unsupervised feature learning for audio classification using convolutional deep belief networks. In Advances in Neural Information Processing Systems 22, pages 1096–1104, 2009.\n\n[2] Schuller, Björn, Stefan Steidl, and Anton Batliner. ""The interspeech 2009 emotion challenge."" Tenth Annual Conference of the International Speech Communication Association. 2009.\n\n[3] N. Jaitly, G. Hinton, Learning a better representation of speech sound waves using restricted Boltzmann machines, in: Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2011, pp. 5884–5887.\n\n[4] D. Palaz, R. Collobert, and M. Magimai.-Doss. Estimating Phoneme Class Conditional Probabilities from Raw Speech Signal using Convolutional Neural Networks, INTERSPEECH 2013, pages 1766–1770.\n\n[5] Van den Oord, Aaron, Sander Dieleman, and Benjamin Schrauwen. ""Deep content-based music recommendation."" Advances in neural information processing systems. 2013.\n\n[6] Z.Tuske, P.Golik, R.Schluter, H.Ney, Acoustic Modeling with Deep Neural Networks Using Raw Time Signal for LVCSR,\nin: Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH), Singapore, 2014, pp. 890–894.\n\n[7] P. Golik, Z. Tuske, R. Schlu ̈ter, H. Ney, Convolutional Neural Networks for Acoustic Modeling of Raw Time Signal in LVCSR, in: Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH), 2015, pp. 26–30.\n\n[8] Yedid Hoshen and Ron Weiss and Kevin W Wilson, Speech Acoustic Modeling from Raw Multichannel Waveforms, International Conference on Acoustics, Speech, and Signal Processing, 2015.\n\n[9] D. Palaz, M. Magimai-Doss, and R. Collobert. Analysis of CNN-based Speech Recognition System using Raw Speech as Input, INTERSPEECH 2015, pages 11–15.\n\n[10] T. N. Sainath, R. J. Weiss, A. Senior, K. W. Wilson, and O. Vinyals. Learning the Speech Front-end With Raw Waveform CLDNNs. Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH), 2015.\n\n[11] Satt, Aharon & Rozenberg, Shai & Hoory, Ron. (2017). Efficient Emotion Recognition from Speech Using Deep Learning on Spectrograms. 1089-1093. Interspeech 2017.\n\n[12] S. Davis and P. Mermelstein. Comparison of parametric representations for monosyllabic word recognition in continuously spoken sentences. IEEE Transactions on Acoustics, Speech and Signal Processing, 28(4):357–366, 1980.']","[-60, -80, -70]","[20, -20, 20]","[""The sentiment score is -60 because the reviewer expresses significant criticism of the paper's methodology, conclusions, and experimental design. They state that the work is 'not experimentally strong enough', that conclusions are not reasonable, and that some claims are 'unfounded'. However, it's not entirely negative as they do acknowledge some positive aspects, like the in-depth analysis in section 2.2 and the idea of studying aliasing effects. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'I think' and 'Perhaps' to soften criticisms, and provide constructive feedback and suggestions for improvement. The reviewer also acknowledges positive aspects of the paper alongside the criticisms. However, some statements are quite direct, which prevents a higher politeness score."", ""The sentiment score is -80 because the reviewer expresses strong negative opinions about the paper, calling the arguments 'rudimentary' and stating that the paper 'falls well below the acceptance threshold'. They also criticize the lack of novel ideas and insufficient experimental results. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite dismissive and blunt. Phrases like 'rudimentary' and 'insufficient to establish novel performance in lieu of novel ideas' are rather harsh criticisms without much attempt to soften the blow. The reviewer also doesn't offer any positive feedback or constructive suggestions for improvement, which contributes to the slightly impolite tone."", ""The sentiment score is -70 because the reviewer recommends rejecting the paper, stating that the analysis is flawed and the experimental results are insufficient. They use phrases like 'the analysis is flawed' and 'the results are not convincing', indicating a strongly negative sentiment. However, they do acknowledge some positive aspects ('The SimpleNet approach is interesting', 'Figure 4 is very interesting'), which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'To my understanding' and 'I don't follow completely' rather than making blunt accusations. They also provide detailed feedback and suggestions for improvement, which is considerate. However, the overall critical nature of the review prevents the politeness score from being higher.""]"
"['This paper presents an embedding algorithm for text corpora that allows known\ncovariates, e.g. author information, to modify a shared embedding to take context\ninto account. The method is an extension of the GloVe method and in the case of\na single covariate value the proposed method reduces to GloVe. The covariate-dependent\nembeddings are diagonal scalings of the shared embedding. The authors demonstrate\nthe method on a corpus of books by various authors and on a corpus of subreddits.\nThough not technically difficult, the extension of GloVe to covariate-dependent\nembeddings is very interesting and well motivated. Some of the experimental results\ndo a good job of demonstrating the advantages of the models. However, some of the\nexperiments are not obvious that the model is really doing a good job.\n\nI have some small qualms with the presentation of the method. First, using the term\n""size m"" for the number of values that the covariate can take is a bit misleading.\nUsually the size of a covariate would be the dimensionality. These would be the same\nif the covariate is one hot coded, however, this isn\'t obvious in the paper right now.\nAdditionally, v_i and c_k live in R^d, however, it\'s not really explained what\n\'d\' is, is it the number of \'topics\', or something else? Additionally, the functional\nform chosen for f() in the objective was chosen to match previous work but with no\nexplanation as to why that\'s a reasonable form to choose. Finally, the authors\nsay toward the end of Section 2 that ""A careful comparision shows that this\napproximation is precisely that which is implied by equation 4, as desired"". This is\ncryptic, just show us that this is the case.\n\nRegarding the experiments there needs to be more discussion about how the\ndifferent model parameters were determined. The authors say ""... and after tuning\nour algorithm to emged this dataset, ..."", but this isn\'t enough. What type of\ntuning did you do to choose in particular the latent dimensionality and the\nlearning rate? I will detail concerns for the specific experiments below.\n\nSection 4.1:\n- How does held-out data fit into the plot?\n\nSection 4.2:\n- For the second embedding, what exactly was the algorithm trained on? Just the\n  book, or the whole corpus?\n- What is the reader supposed to take away from Table 1? Are higher or lower\n  values better? Maybe highlight the best scores for each column.\n\n\nSection 4.3:\n- Many of these distributions don\'t look sparse.\n- There is a terminology problem in this section. Coordinates in a vector are\n  not sparse, the vector itself is sparse if there are many zeros, but\n  coordinates are either zero or not zero. The authors\' use of \'sparse\' when\n  they mean \'zero\' is really confusing.\n- Due to the weird sparsity terminology Table 1 is very confusing. Based on how\n  the authors use \'sparse\' I think that Table 1 shows the fraction of zeros in\n  the learned embedding vectors. But if so, then these vectors aren\'t sparse at all\n  as most values are non-zero.\n\nSection 5.1:\n- I don\'t agree with the authors that the topics in Table 3 are interpretable.\n  As such, I think it\'s a reach to claim the model is learning interpretable topics.\n  This isn\'t necessarily a problem, it\'s fine for models to not do everything well,\n  but it\'s a stretch for the authors to claim that these results are a positive\n  aspect of the model. The results in Section 5.2 seem to make a lot of sense and\n  show the big contribution of the model.\n\nSection 5.3:\n- What is the ""a : b :: c : d"" notation?\n', ""This paper produces word embedding tensors where the third order gives covariate information, via venue or author. The model is simple: tensor factorization, where the covariate can be viewed as warping the cosine distance to favor that covariate's more commonly cooccuring vocabulary (e.g. trump on hillary and crooked)\n\n\nThere is a nice variety of authors and words, though I question if even with all those books, the corpus is big enough to produce meaningful vectors. From my own experience, even if I spend several hours copy-pasting from project gutenberg, it is not enough for even good matrix factorization embeddings, much less tensor embeddings. It is hard to believe that meaningful results are achieved using such a small dataset with random initialization. \n\nI think table 5 is also a bit strange. If the rank is > 1000 I wonder how meaningful it actually is. For the usual analogies task, you can usually find what you are looking for in the top 5 or less. \n\nIt seems that table 1 is the only evaluation of the proposed method against any other type of method (glove, which is not a tensor-based method). I think this is not sufficient. \n\nOverall, I believe the idea is nice, and the initial analysis is good, but I think the evaluation, especially against other methods, needs to be stronger. Methods like neelakantan et al's multisense embedding, for example, which the work cites, can be used in some of these evaluations, specifically on those where covariate information clearly contributes (like contextual tasks). The addition of one or two tables with either a standard task against reported results or created tasks against downloadable contextual / tensor embeddings would be enough for me to change my vote. "", 'The authors present a method for learning word embeddings from related groups of data. The model is based on tensor factorization which extends GloVe to higher order co-ocurrence tensors, where the co-ocurrence is of words within subgroups of the text data. These two papers need to be cited:\n\nRudolph et al., NIPS 2017, ""Sturctured Embedding Models for Grouped Data"": This paper also presents a method for learning embeddings specific for subgroups of the data, but based on hierarchical modeling. An experimental comparison is needed.\n\nCotterell et al., EACL 2017 ""Explaining and Generalizing Skip-Gram through Exponential Family Principal Component Analysis"": This paper also derives a tensor factorization based approach for learning word embeddings for different covariates. Here the covariates are morphological tags such as part-of-speech tags of the words.\n\nDue to these two citations, the novelty of both the problem set-up of learning different embeddings for each covariate and the novelty of the tensor factorization based model are limited.\n\nThe writing is ok. I appreciated the set-up of the introduction with the two questions. However, the questions themselves could have been formulated differently: \nQ1: the way Q1 is formulated makes it sound like the covariates could be both discrete and continuous while the method presented later in the paper is only for discrete covariates (i.e. group structure of the data).\nQ2: The authors mention topic alignment without specifying what the topics are aligned to. It would be clearer if they stated explicitly that the alignment is between covariate-specific embeddings. It is also distracting that they call the embedding dimensions topics.\nAlso, why highlight the problem of authorship attribution of Shakespear\'s work in the introduction, if that problem is not addressed later on?\n\nIn the model section, the paragraphs ""notation"" and ""objective function and discussion"" are clear.  I also liked the idea of having the section ""A geometric view of embeddings and tensor decomposition"", but that section needs to be improved. For example, the authors describe RandWalk (Arora et al. 2016) but how their work falls into that framework is unclear.\nIn the third paragraph, starting with ""Therefore we consider a natural extension of this model, ..."" it is unclear which model the authors are referring to. (RandWalk or their tensor factorization?).\nWhat are the context vectors in Figure 1?  I am guessing the random walk transitions are the ellipsoids? How are they to be interpreted? \n\nIn the last paragraph, beginning with ""Note that this is essentially saying..."", I don\'t agree with the argument that the ""base embeddings"" decompose into independent topics. The dimensions of the base embeddings are some kind of latent attributes and each individual dimension could be used by the model to capture a variety of attributes. There is nothing that prevents the model from using multiple dimensions to capture related structure of the data. Also, the qualitative results in Table 3 do not convince me that the embedding dimensions represent topics. For example ""horses"" has highest value in embedding dimension 99. It\'s nearest neighbours in the embedding space (i.e. semantically similar words) will also have high values in coordinate 99. Hence, the apparent semantic coherence in what the authors call ""topics"".\n\nThe authors present multiple qualitative and quantitative evaluations. The clustering by weight (4.1.) is nice and convincing that the model learns something useful. 4.2, the only quantitative analysis was missing some details. Please give references for the evaluation metrics used, for proper credit and so people can look up these tasks. Also, comparison needed to fitting GloVe on the entire corpus (without covariates) and existing methods Rudolph et al. 2017 and Cotterell et al. 2017.   \nSection 5.2 was nice and so was 5.3. However, for the covariate specific analogies (5.3.) the authors could also analyze word similarities without the analogy component and probably see similar qualitative results. Specifically, they could analyze for a set of query words, what the most similar words are in the embeddings obtained from different subsections of the data.\n\nPROS:\n+ nice tensor factorization model for learning word embeddings specific to discrete covariates.\n+ the tensor factorization set-up ensures that the embedding dimensions are aligned \n+ clustering by weights (4.1) is useful and seems coherent\n+ covariate-specific analogies are a creative analysis\n\nCONS:\n- problem set-up not novel and existing approach not cited (experimental comparison needed)\n- interpretation of embedding dimensions as topics not convincing\n- connection to Rand-Walk (Aurora 2016) not stated precisely enough\n- quantitative results (Table 1) too little detail:\n        * why is this metric appropriate?\n        * comparison to GloVe on the entire corpus (not covariate specific)\n        * no reference for the metrics used (AP, BLESS, etc.?)\n- covariate specific analogies presented confusingly and similar but simpler analysis might be possible by looking at variance in neighbours v_b and v_d without involving v_a and v_c (i.e. don\'t talk about analogies but about similarities)']","[50, -20, -20]","[75, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer begins by praising the paper as 'very interesting and well motivated' and acknowledges the advantages of the model. However, they also express some concerns and criticisms, balancing out the overall sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'I have some small qualms'), and offers specific suggestions for improvement rather than harsh criticism. The reviewer maintains a professional tone, using phrases like 'needs to be more discussion' instead of more confrontational language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the idea is 'nice' and the initial analysis is 'good', they express several concerns about the methodology and evaluation. They question the dataset size, the meaningfulness of results, and the sufficiency of the evaluation against other methods. The overall tone suggests that significant improvements are needed.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and constructive language throughout. They acknowledge positive aspects of the work and offer specific suggestions for improvement. The critique is presented in a professional manner without harsh or dismissive language. Phrases like 'I think', 'I believe', and 'I question' are used to soften criticisms, and the reviewer offers a clear path for the authors to potentially change their vote."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('PROS'), there are more critical comments ('CONS') and suggestions for improvement. The reviewer points out limitations in novelty, interpretation, and methodology, which outweigh the positive remarks. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive criticism, and balances negative feedback with positive observations. The reviewer uses phrases like 'I appreciated', 'nice', and 'creative', which contribute to a polite tone. However, the critique is direct and doesn't use overly deferential language, keeping it from scoring higher on politeness.""]"
"['This paper proposes to train recursive neural network on subtask graphs in order to execute a series of tasks in the right order, as is described by the subtask graph\'s dependencies. Each subtask execution is represented by a (non-learned) option. Reward shaping allows the proposed model to outperform simpler baselines, and experiments show the model generalizes to unseen graphs.\n\nWhile this paper is as far as I can tell novel in how it does what it does, the authors have failed to convey to me why this direction of research is relevant.\n- We know finding options is the hard part about options\n- We already have good algorithms that take subtask graphs and execute them in the right order from the planning litterature\n\nAn interesting avenue would be if the subtask graphs were instead containing some level of uncertainty, or representing stochasticity, or anything that more traditional methods are unable to deal with efficiently, then I would see a justification for the use of neural networks. Alternatively, if the subtask graphs were learned instead of given, that would open the door to scaling an general learning. Yet, this is not discussed in the paper.\n\nAnother interesting avenue would be to learn the options associated with each task, possibly using the information from the recursive neural networks to help learn these options.\n\n\nThe proposed algorithm relies on fairly involved reward shaping, in that it is a very strong signal of supervision on what the next action should be. Additionaly, it\'s not clear why learning seems to completely ""fail"" without the pre-trained policy. The justification given is that it is ""to address the difficulty of training due to the complex nature of the problem"" but this is not really satisfying as the problems are not that hard. This also makes me question the generality of the approach since the pre-trained policy is rather simple while still providing an apparently strong score.\n\n\nIn your experiments, you do not compare with any state-of-the-art RL or hierarchical RL algorithm on your domain, and use a new domain which has no previous point of reference. It it thus hard to properly evaluate your method against other proposed methods.\n\nWhat the authors propose is a simple idea, everything is very clearly explained, the experiments are somewhat lacking but at least show an improvement over more a naive approach, however, due to its simplicity, I do not think that this paper is relevant for the ICLR conference. \n\nComments:\n- It is weird to use both a discount factor \\gamma *and* a per-step penalty. While not disallowed by theory, doing both is redundant because they enforce the same mechanism.\n- It seems weird that the smoothed logical AND/OR functions do not depend on the number of inputs; that is unless there are always 3 inputs (but it is not explained why; logical functions are usually formalised as functions of 2 inputs) as suggested by Fig 3.\n- It does not seem clear how the whole training is actually performed (beyond the pre-training policy). The part about the actor-critic learning seems to lack many elements (whole architecture training? why is the policy a sum of ""p^{cost}"" and ""p^{reward}""? is there a replay memory? How are the samples gathered?). (On the positive side, the appendix provides some interesting details on the tasks generations to understand the experiments.)\n- The experiments cover different settings with different task difficulties. However, only one type of tasks is used. It would be good to motivate (in addition to the paragraph in the intro) the cases where using the algorithm described in the paper may be (or not?) the only viable option and/or compare it to other algorithms. Even tough not mandatory, it would also be a clear good addition to also demonstrate more convincing experiments in a different setting.\n- ""The episode length (time budget) was randomly set for each episode in a range such that 60% − 80% of subtasks are executed on average for both training and testing."" --> this does not seem very precise: under what policy is the 60-80% defined? Is the time budget different for each new generated environment?\n- why wait until exactly 120 epochs for NTS-RProp before fine-tuning with actor-critic? It seems that much less would be sufficient from figure 4?\n- In the table 1 caption, it is written ""same graph structure with training set"" --> do you mean ""same graph structure than the training set""?', ""\nSummary: the paper proposes an idea for multi-task learning where tasks have shared dependencies between subtasks as task graph. The proposed framework, task graph solver (NTS), consists of many approximation steps and representations: CNN to capture environment states, task graph parameterization, logical operator approximation; the idea of reward-propagation policy helps pre-training. The framework is evaluated on a relevant multi-task problem.\n\nIn general, the paper proposes an idea to tackle an interesting problem. It is well written, the idea is well articulated and presented. The idea to represent task graphs are quite interesting. However it looks like the task graph itself is still simple and has limited representation power. Specifically, it poses just little constraints and presents no stochasticity (options result in stochastic outcomes).\n\nThe method is evaluated in one experiment with many different settings. The task itself is not too complex which involves 10 objects, and a small set of deterministic options. It might be only complex when the number of dependency layer is large. However, it's still more convinced if the paper method is demonstrated in more domains.\n\n\nAbout the description of problem statement in Section 3:\n\n- How the MDP M and options are defined, e.g. transition functions, are tochastic?\n\n- What is the objective of the problem in section 3\n\nRelated work: many related work in robotics community on the topic of task and motion planning (checkout papers in RSS, ICRA, IJRR, etc.) should also be discussed."", ""In the context of multitask reinforcement learning, this paper considers the problem of learning behaviours when given specifications of subtasks and the relationship between them, in the form of a task graph. The paper presents a neural task graph solver (NTS), which encodes this as a recursive-reverse-recursive neural network. A method for learning this is presented, and fine tuned with an actor-critic method. The approach is evaluated in a multitask grid world domain.\n\nThis paper addresses an important issue in scaling up reinforcement learning to large domains with complex interdependencies in subtasks. The method is novel, and the paper is generally well written. I unfortunately have several issues with the paper in its current form, most importantly around the experimental comparisons.\n\nThe paper is severely weakened by not comparing experimentally to other learning (hierarchical) schemes, such as options or HAMs. None of the comparisons in the paper feature any learning. Ideally, one should see the effect of learning with options (and not primitive actions) to fairly compare against the proposed framework. At some level, I question whether the proposed framework is doing any more than just value function propagation at a task level, and these experiments would help resolve this.\n\nAdditionally, the example domain makes no sense. Rather use something more standard, with well-known baselines, such as the taxi domain.\n\nI would have liked to see a discussion in the related work comparing the proposed approach to the long history of reasoning with subtasks from the classical planning literature, notably HTNs.\n\nI found the description of the training of the method to be rather superficial, and I don't think it could be replicated from the paper in its current level of detail.\n\nThe approach raises the natural questions of where the tasks and the task graphs come from. Some acknowledgement and discussion of this would be useful.\n\nThe legend in the middle of Fig 4 obscures the plot (admittedly not substantially).\n\nThere are also a number of grammatical errors in the paper, including the following non-exhaustive list:\n2: as well as how to do -> as well as how to do it\nFig 2 caption: through bottom-up -> through a bottom-up\n3: Let S be a set of state -> Let S be a set of states\n3: form of task graph -> form of a task graph\n3: In addtion -> In addition\n4: which is propagates -> which propagates\n5: investigated following -> investigated the following""]","[-50, 50, -50]","[20, 75, 50]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects (e.g., 'everything is very clearly explained'), they express significant doubts about the relevance and novelty of the research. The reviewer states that they don't see why this direction of research is relevant and suggests that the paper is not suitable for the ICLR conference. However, it's not entirely negative as they do recognize some merits of the work.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout and offers constructive criticism. They use phrases like 'It would be good to...' and 'An interesting avenue would be...' which suggest improvements rather than just pointing out flaws. However, some statements are quite direct (e.g., 'the authors have failed to convey to me why this direction of research is relevant'), which prevents the score from being higher. The reviewer also provides detailed comments and suggestions, which is a polite way to help the authors improve their work."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's merits, such as being well-written and presenting an interesting idea, while also pointing out limitations and areas for improvement. The overall tone is balanced, with positive aspects slightly outweighing the criticisms. The politeness score is 75 (fairly polite) because the reviewer uses respectful language throughout, offering constructive feedback without harsh criticism. They use phrases like 'well written,' 'well articulated,' and 'quite interesting,' which contribute to a polite tone. The reviewer also frames suggestions as possibilities rather than demands, such as 'it's still more convinced if...' and 'should also be discussed,' which maintains a courteous approach to feedback."", ""The sentiment score is -50 because while the reviewer acknowledges the importance of the topic and the novelty of the method, they express several significant concerns about the paper. The reviewer states 'I unfortunately have several issues with the paper in its current form' and lists multiple criticisms, including lack of experimental comparisons, questionable example domain, superficial description of training, and grammatical errors. These criticisms outweigh the initial positive comments, resulting in a slightly negative overall sentiment.\n\nThe politeness score is 50 because the reviewer uses generally polite language throughout. They start with positive comments and use phrases like 'I would have liked to see' and 'Some acknowledgement and discussion of this would be useful' when suggesting improvements. The criticisms are presented as professional observations rather than personal attacks. However, the score is not higher because some phrases like 'the example domain makes no sense' could be considered somewhat blunt.""]"
"['The key contributions of this paper are:\n(a) proposes to reduce the vocabulary size in large sequence to sequence mapping tasks (e.g., translation) by first mapping them into a ""standard"" form and then into their correct morphological form,\n(b) they achieve this by clever use of character LSTM encoder / decoder that sandwiches a bidirectional LSTM which captures context,\n(c) they demonstrate clear and substantial performance gains on the OpenSubtitle task, and\n(d) they demonstrate clear and substantial performance gains on a dialog question answer task.\n\nTheir analysis in Section 5.3 shows one clear advantage of this model in the context of long sequences. \n\nAs an aside, the authors should correct the numbering of their Figures (there is no Figure 3) and provide better captions to the Tables so the results shown can easily understood at a glance. \n\nThe only drawback of the paper is that this does not advance representation learning per se though a nice application of current models.', 'In this work, the authors propose a sequence-to-sequence architecture that learns a mapping from a normalized sentence to a grammatically correct sentence. The proposed technique is a simple modification to the standard encoder-decoder paradigm which makes it more efficient and better suited to this task. The authors evaluate their technique using three morphologically rich languages French, Polish and Russian and obtain promising results.\n\nThe morphological agreement task would be an interesting contribution of the paper, with wider potential. But one concern that I have is regarding the evaluation metrics used for it. Firstly, word accuracy rate doesn\'t seem appropriate, as it does not measure morphological agreement. Secondly, sentence accuracy (w.r.t. the sentences from which the normalized sentences are derived) is not indicative of morphological agreement: even ""wrong"" sentences in the output could be perfectly valid in terms of agreement. A grammatical error rate (fraction of grammatically wrong sentences produced) would probably be a better measure.\n\nAnother concern I have is regarding the quality of the baseline: Additional variants of the baseline models should be considered and the best one reported. Specifically, in the conversation task, have the authors considered switching the order of normalized answer and context in the input? Also, the word order of the normalized answer and/or context could be reversed (as is done in sequence-to-sequence translation models).\n\nAlso, many experimental details are missing from the draft:\n-- What are the sizes of the train/test sets derived from the OpenSubtitles database?\n-- Details of the validation sets used to tune the models.\n-- In Section 5.4, no details of the question-answer corpus are provided. How many pairs were extracted? How many were used for training and testing?\n-- In Section 5.4.1, how many assessors participated in the evaluation and how many questions were evaluated?\n-- In some of the tables (e.g. 6, 7, 8) which show example sentences from Polish, Russian and French, please provide some more information in the accompanying text on how to interpret these examples (since most readers may not be familiar with these languages).\n\nPros:\n-- Efficient model\n-- Proposed architecture is general enough to be useful for other sequence-to-sequence problems\n\nCons:\n-- Evaluation metrics for the morphological agreement task are unsatisfactory\n-- It would appear that the baselines could be improved further using standard techniques', 'The paper is a pain to read. Most of the citation styles are off (i.e., without parentheses). Most of the sentences are not grammatically correct. Most, if not all, of the determiners are missing. It is ironic that the paper is proposing a model to generate grammatically correct sentences, while most of the sentences in the paper are not grammatically correct.\n\nThe experimental numbers look skeptical. For example, 1/3 of the training results are worse than the test results in Table 1. It also happens a few times in Table 5. Either the models are not properly trained, or the models are heavily tuned on the test set.\n\nThe running times in Table 9 are also skeptical. Why are the Concorde models faster than unigrams and bigrams? Maybe this can be attributed to the difference in the size of the vocabulary, but why is the unigram model slower than the bigram model?']","[80, -20, -80]","[60, 60, -50]","[""The sentiment score is 80 (positive) because the reviewer highlights multiple key contributions and 'clear and substantial performance gains' of the paper. They use positive language like 'clever use' and 'clear advantage'. The only negative point is a minor drawback mentioned at the end. The politeness score is 60 (moderately polite) because the reviewer maintains a professional tone throughout, offering constructive feedback. They politely suggest corrections for figure numbering and table captions using 'should' rather than demanding language. The review is objective and focuses on the paper's merits without personal attacks or overly effusive praise."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('promising results', 'interesting contribution', 'efficient model'), they express several concerns and criticisms about the evaluation metrics, baselines, and missing experimental details. These concerns outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, framing criticisms as 'concerns' and offering constructive suggestions for improvement. They also acknowledge the positive aspects of the work before diving into critiques. The reviewer maintains a professional tone without using harsh or dismissive language, even when pointing out shortcomings in the research."", ""The sentiment score is -80 because the reviewer expresses strong negative opinions about the paper, calling it 'a pain to read' and pointing out numerous issues with grammar, citations, and experimental results. The reviewer also uses the word 'ironic' to criticize the paper's premise. The politeness score is -50 because while the reviewer doesn't use explicitly rude language, the tone is quite harsh and critical. Phrases like 'a pain to read' and 'ironic' are particularly blunt. The reviewer doesn't offer any positive feedback or soften their criticisms, which contributes to the negative politeness score. However, the language isn't overtly insulting, which is why the score isn't lower.""]"
"['The paper focuses on a very particular HMM structure which involves multiple, independent HMMs. Each HMM emits an unobserved output with an explicit duration period. This explicit duration modelling captures multiple scale of temporal resolution. The actual observations are a weighted linear combination of the emissions from each latent HMM. The structure allows for fast inference using a spectral approach.\n\nI found the paper unclear and lacking in detail in several key aspects:\n\n1. It is unclear to me from Algorithm 2 how the weight vectors w are estimated. This is not adequately explained in the section on estimation.\n\n2. The authors make the assumption that each HMM injects noise into the unobserved output which then gets propagated into the overall observation. What are reasons for his choice of model over a simpler model where the output of each HMM is uncorrupted?\n\n3. The simulation example does not really demonstrate the ability of the MSHMM to do anything other than recover structure from data simulated under an MSHMM. It would be more interesting to apply to data simulated under non-Markovian or other setups that would enable richer frequency structures to be included and the ability of MSHMM to capture these.\n\n4. The real data experiments shows some improvements in predictive accuracy with fast inference. However, the authors do not give a sufficiently broad exploration of the representations learnt by the model which allows us to understand the regimes in which the model would be advantageous.\n\nOverall, the paper presents an interesting approach but the work lacks maturity. Furthermore, simulation and real data examples to explore the properties and utility of the method are required. \n', 'The paper presents an interesting spectral algorithm for multiscale hmm. The derivation and analysis seems correct. However, it is well-known that spectral algorithm is not robust to model mis-specification. It is not clear whether the proposed algorithm will be useful in practice. How will the method compare to EM algorithms and neural network based approaches? ', 'This paper proposes a variant of hierarchical hidden Markov Models (HMMs) where the chains operate at different time-scales with an associate d spectral estimation procedure that is computationally efficient.\n\nThe model is applied to artificially generated data and to high-frequency equity data showing promising results.\n\nThe proposed model and method are reasonably original and novel.\n\nThe paper is well written and the method reasonably well explained (I would add an explanation of the spectral estimation in the Appendix, rather than just citing Rodu et al. 2013).\n\nAdditional experimental results would make it a stronger paper.\n\nIt would be great if the authors could include the code that implements the model.']","[-50, 0, 70]","[20, 50, 80]","[""The sentiment score is -50 because the review is generally critical, pointing out several key aspects where the paper is unclear or lacking. The reviewer states that the paper 'lacks maturity' and requires more exploration of the method's properties and utility. However, it's not entirely negative as the reviewer acknowledges that the paper presents 'an interesting approach'. The politeness score is 20 because while the reviewer is critical, they maintain a professional and constructive tone throughout. They use phrases like 'I found' and 'It would be more interesting' rather than making blunt criticisms. The reviewer also provides specific recommendations for improvement, which is a polite way to offer criticism in academic contexts."", ""The sentiment score is 0 (neutral) because the review contains both positive and negative elements. It acknowledges the paper as 'interesting' and the derivation as 'correct', but also raises concerns about practical usefulness and robustness. The politeness score is 50 (somewhat polite) because the language is professional and constructive, avoiding harsh criticism. The reviewer uses phrases like 'it is not clear' instead of more direct negative statements, and poses questions for improvement rather than making demands. However, it doesn't reach the highest levels of politeness as it doesn't include explicit praise or encouragement."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper. They describe the model as 'reasonably original and novel', the paper as 'well written', and the results as 'promising'. The only criticisms are minor suggestions for improvement, such as adding more experimental results and including code. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticisms. Phrases like 'It would be great if...' and 'I would add...' are polite ways of suggesting improvements. The overall tone is professional and courteous, maintaining a positive and encouraging attitude towards the authors' work.""]"
"[""This paper describes an approach to stochastic control using RL that extends DDPG with a stochastic policy.  A standard DDPG setup is extended such that the actor now produces M actions at each timestep.  Only one of the M actions will be executed in the environment using a uniform sampling.  The sampled action is the only that will receive a gradient update from the critic network. The authors demonstrate that such a stochastic policy performs better on average in a series of benchmark control tasks.\n\nI find the general idea of the work compelling, but the particular approach is rather poor.  The fact that we are choosing the number of modes in the uniform distribution is a bit underwhelming (a more compelling architecture could have proposed a policy conditioned on gaussian noise for example, thus having better coverage of the distribution). I found the proposed apprach to be under-analyzed and the stochastic aspects of the policy are undervalued.   The main claim being argued in the paper is that the proposed stochastic policy has better final performance on average than a deterministic policy, but the only practical difference seems to be a slightly more structured approach to exploration.  \nHowever, very little attention is paid to trying different exploration methods with the deterministic policy (incidentally, Ornstein-Uhlenbeck process noise is not something I'm familiar with, a citation to the use of this noise for exploration as well as a more explicit explanation would have been appreciated).  One interpretation is that each of the M sub-policies follows a different mode of the Q-value distribution over the action space.  But is this indeed the case?  There is a brief analysis of this with cartpole, but a more complete look at how actions are clustered in the action space would make this paper much more compelling.  Even in higher-dimensional action spaces, you could look at a t-SNE projection or cluster analysis to try and see how many modes the agent is reasoning over.  Additionally, the baseline agent should have used additional exploration methods as these can quickly change the performance of the agent.\n\nI also think that better learning is not the only redeeming aspect of a stochastic policy.  In the face of a non-stationary environment, a stochastic policy will likely be much more robust.  Additionally, it will have much better performance against adversarial environments.  Given the remaining available space in the paper it would have been interesting to provide more insight into the proposed methods gains in these areas."", ""In this paper, the authors investigate a simple method for improving the performance of networks trained with DDPG: instead of outputting a single action, they output several actions (through distinct output layers), and choose one uniformly at random. The selected action is updated using deterministic policy gradient. The critic Q is updated with a Bellman backup where the the choice of the action is marginalized out. Authors show improved performance on a large number of standard continuous control environment (openAI gym and TORCS).\n\nThe paper is well written, and the idea seems to work perhaps surprisingly well. The authors do a good job of investigating the behavior of their algorithm (in particular the increase of standard deviation in states where multiple optimal actions exist). \n\nSimilar ideas (mixture of gaussians for action distribution in policy gradient setups, or multi-modal action distribution through the use of latent variables) are often difficult to make work - I am curious why this particular method works so well.\nIn particular, it would be interesting to investigate how the algorithm avoids collapsing all actions into the same one; as implied by section 3.2, in a state with multiple optimal actions, there is no difference in loss between having all actions be nearly identical (and optimal), and all actions being distinct optimal actions. Furthermore, as the loss does not encourage diversity, once two actions are set to be similar in a state, intuitively it would be hard for the actions to become distinct again. Imagine for instance the cart pole problem with M=2. If both action layers start with the same 'tendency' (towards clock-wise or counter clock-wise motion), it is likely that the same tendency would be reinforced for both, and the network with M=2 would end up having a similar behavior to a classical network with M=1.\n\nIs this problem avoided by using a large value of M? It would be interesting to investigate the behavior of the algorithm in a toy environment (perhaps a simple 2d navigation  task with distinct 'paths' with same cost) where the number of distinct basins of optimality is know for various states, and investigate in more details how diversity is maintained (perhaps as a function of M).\n\n\nMinor: \n- typo rho -> $\\rho$\n- Given the paper fits comfortably within the page limit, it would have been worthwhile to give mathematical details to the Algorithm 1 box (even if they are easy to find in text or appropriate references)"", 'This work introduces a particular parametrization of a stochastic policy (a uniform mixture of deterministic policies). They find this parametrization, when trained with stochastic value gradient outperforms DDPG on several OpenAI gym benchmarks.\n\nThis paper unfortunately misses many significant pieces of prior work training stochastic policies. The most relevant is [1] which should definitely be cited. The algorithm here can be seen as SVG(0) with a particular parametrization of the policy. However, numerous other works have examined stochastic policies including [2] (A3C which also used the Torcs environment) and [3].\n\nThe wide use of stochastic policies in prior work makes the introductory explanation of the potential benefits for stochastic policies distracting, instead the focus should be on the particular choice and benefits of the particular stochastic parametrization chosen here and the choice of stochastic value gradient as a training method (as opposed to many on-policy methods).\n\nThe empirical comparison is also hampered by only comparing with DDPG, there are numerous stochastic policy algorithms that have been compared on these environments. Additionally, the DDPG performance here is lower for several environments than the results reported in Henderson et al. 2017 (cited in the paper, table 2 here, table 3 Henderson) which should be explained.\n\nWhile this particular parametrization may provide some benefits, the lack of engagement with relevant prior work and other stochastic baselines significant limits the impact of this work and makes assessing its significance difficult.\n\nThis work would benefit from careful copyediting.\n\n[1] Heess, N., Wayne, G., Silver, D., Lillicrap, T., Erez, T., & Tassa, Y. (2015). Learning continuous control policies by stochastic value gradients. In Advances in Neural Information Processing Systems (pp. 2944-2952).\n\n[2] Mnih, V., Badia, A. P., Mirza, M., Graves, A., Lillicrap, T., Harley, T., ... & Kavukcuoglu, K. (2016, June). Asynchronous methods for deep reinforcement learning. In International Conference on Machine Learning (pp. 1928-1937).\n\n[3] Schulman, J., Moritz, P., Levine, S., Jordan, M., & Abbeel, P. (2015). High-dimensional continuous control using generalized advantage estimation. arXiv preprint arXiv:1506.02438.\n\n']","[-30, 80, -50]","[20, 90, 20]","[""The sentiment score is -30 because while the reviewer finds the general idea 'compelling', they describe the approach as 'rather poor' and 'underwhelming'. They point out several limitations and areas where the paper falls short, indicating a generally negative sentiment. However, it's not extremely negative as they do acknowledge some positive aspects. The politeness score is 20 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They use phrases like 'I find' and 'I think' to soften their critiques, and offer constructive suggestions for improvement. The tone is generally polite, though not overly formal or deferential."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'well written' and noting that the idea 'works perhaps surprisingly well'. The reviewer also commends the authors for their investigation of the algorithm's behavior. The score is not 100 as the reviewer does raise some questions and suggests areas for further investigation. The politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They offer praise where due and frame their questions and suggestions in a curious and encouraging manner, rather than as criticisms. The reviewer also uses polite phrases like 'it would be interesting to investigate' when making suggestions for improvement."", ""The sentiment score is -50 because the review is generally critical, pointing out significant shortcomings in the paper such as missing prior work, limited comparisons, and the need for copyediting. However, it's not entirely negative as it acknowledges some potential benefits of the work. The politeness score is 20 because the reviewer uses polite language and constructive criticism, avoiding harsh or rude phrasing. They use phrases like 'unfortunately misses' and 'would benefit from' rather than more direct criticisms. The reviewer also provides specific suggestions for improvement and references to include, which is helpful and courteous.""]"
"['This paper compares 2 CNN architectures (Alexnet and a VGG variant) for the task of classifying images of lung cancer from CT scans. The comparison is trivial and does not go in depth to explain why one architecture works better than the other. Also, no effort is made to explain the data beyond some superficial description. No example of input data is given (what does an actual input look like). The authors mention ""the RCNN object detector"" in step 18, that presumably does post-processing after the CNN. But there is no explanation of that module anywhere. Instead the authors spend most of the paper listing in wordy details the architecture of their VGG variant. Also, a full page is devoted to detailed explanation of what precision-recall and Matthews Correlation Coefficient is! Overall, the paper does not provide any insight beyond: i tried this, i tried that and this works better than that; a strong reject.', ""The paper compares AlexNet and a custom CNN in predicting malignant lung nodules, and shows that the proposed CNN achieves significantly lower false positives and false negative rates.\n\nMajor comments\n\n- I did not fully understand the motivation of the custom CNN over AlexNet. \n\n- Some more description of the dataset will be helpful. Do the 888 scans belong to different patients, or same patient can be scanned at different times? What is the dimensionality of each CT scan?\n\n- Are the authors predicting the location of the malignant nodule, or are they classifying if the image has a malignant nodule? How do the authors compute a true positive? What threshold is used?\n\n- What is 'Luna subsets'? What is 'unsmoothed and smoothed image'?\n\nMinor comments\n\n- The paper is difficult to read, and contains a lot of spelling and grammatical errors."", 'The authors compare a standard DL machine (AlexNet) with a custom CNN-based solution in the well known tasks of classifying lung tumours into benign or cancerous in the Luna CT scan dataset, concluding that the proposed novel solution performs better.\nThe paper is interesting, but it has a number of issues that prevents it from being accepted for the ICLR conference.\n\nFirst, the scope of the paper, in its present form, is very limited: the idea of comparing the novel solution just with AlexNet is not adding much to the present landscape of methods to tackle this problem.\nMoreover, although the task is very well known and in the last few year gave rise to a steady flow of solutions and was also the topic of a famous Kaggle competition, no discussion about that can be found in the manuscript.\nThe novel solution is very briefly sketched, and some of the tricks in its architecture are not properly justified: moreover, the performance improvement w.r.t . to AlexNet is hardly supporting the claim.\nExperimental setup consists of just a single training/test split, thus no confidence intervals on the results can be defined to show the stability of the solution.\nThe whole sections 2.3 and 2.4 include only standard material unnecessary to mention given the target venue, and the references are limited and incomplete.\nThis given, I rate this manuscript as not suitable for ICLR 2018.']","[-80, -20, -70]","[-20, 50, 20]","[""The sentiment score is -80 because the review is highly critical and ends with a 'strong reject' recommendation. The reviewer points out multiple shortcomings without mentioning any positives, indicating a very negative sentiment. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and dismissive. Phrases like 'The comparison is trivial' and 'Overall, the paper does not provide any insight beyond: i tried this, i tried that' come across as somewhat harsh. The reviewer doesn't use any polite language or soften their criticisms, leading to a slightly negative politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution in comparing AlexNet and a custom CNN, they express several major concerns and indicate that the paper is difficult to read. The reviewer points out multiple areas where clarification or additional information is needed, suggesting that the paper has significant room for improvement. However, the tone is not entirely negative, as the reviewer seems to be providing constructive feedback rather than outright rejection.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns and frame their comments as questions or suggestions rather than harsh criticisms. The use of phrases like 'Some more description... will be helpful' and 'I did not fully understand' indicate a polite approach to giving feedback. However, the final comment about spelling and grammatical errors is more direct, which slightly reduces the overall politeness score."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper has 'a number of issues that prevents it from being accepted' and concludes by rating it 'not suitable for ICLR 2018'. They point out several limitations and shortcomings of the paper, indicating a clearly negative sentiment. However, it's not at the extreme end of negativity as the reviewer does acknowledge that the paper is 'interesting' at the beginning. The politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively polite tone throughout. They use neutral language to express their criticisms and avoid personal attacks or harsh language. The slight positive score reflects the reviewer's effort to start with a positive comment and their use of phrases like 'The paper is interesting, but...' which softens the criticism somewhat.""]"
"['The paper presents a multi-task, multi-domain model based on deep neural networks. The proposed model is able to take inputs from various domains (image, text, speech) and solves multiple tasks, such as image captioning, machine translation or speech recognition. The proposed model is composed of several features learning blocks (one for each input type) and of an encoder and an auto-regressive decoder, which are domain-agnostic. The model is evaluated on 8 different tasks and is compared with a model trained separately on each task, showing improvements on each task.\n\nThe paper is well written and easy to follow.\n\nThe contributions of the paper are novel and significant. The approach of having one model able to perform well on completely different tasks and type of input is very interesting and inspiring. The experiments clearly show the viability of the approach and give interesting insights. This is surely an important step towards more general deep learning models. \n\nComments:\n\n* In the introduction where the 8 databases are presented, the tasks should also be explained clearly, as several domains are involved and the reader might not be familiar with the task linked to each database. Moreover, some databases could be used for different tasks, such as WSJ or ImageNet.\n\n* The training procedure of the model is not explained in the paper. What is the cost function and what is the strategy to train on multiple tasks ? The paper should at least outline the strategy.\n\n* The experiments are sufficient to demonstrate the viability of the approach, but the experimental setup is not clear. Specifically, there is an issue about the speech recognition part of the experiment. It is not clear what the task exactly is: continuous speech recognition, isolated word recognition ? The metrics used in Table 1 are also not clear, they should be explained in the text. Also, if the task is continuous speech recognition, the WER (word error rate) metric should be used. Information about the detailed setup is also lacking, specifically which test and development sets are used (the WSJ corpus has several sets).\n\n* Using raw waveforms as audio modality is very interesting, but this approach is not standard for speech recognition, some references should be provided, such as:\nP. Golik, Z. Tuske, R. Schluter, H. Ney, Convolutional Neural Networks for Acoustic Modeling of Raw Time Signal in LVCSR, in: Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH), 2015, pp. 26–30.\nD. Palaz, M. Magimai Doss and R. Collobert, (2015, April). Convolutional neural networks-based continuous speech recognition using raw speech signal. In Acoustics, Speech and Signal Processing (ICASSP), 2015 IEEE International Conference on (pp. 4295-4299). IEEE.\nT. N. Sainath, R. J. Weiss, A. Senior, K. W. Wilson, and O. Vinyals. Learning the Speech Front-end With Raw Waveform CLDNNs. Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH), 2015.\n\nRevised Review:\nThe main idea of the paper is very interesting and the work presented is impressive. However, I tend to agree with Reviewer2, as a more comprehensive analysis should be presented to show that the network is not simply multiplexing tasks. The experiments are interesting, except for the WSJ speech task, which is almost meaningless. Indeed, it is not clear what the network has learned given the metrics presented, as the WER on WSJ should be around 5% for speech recognition.\nI thus suggest to either drop the speech experiment, or the modify the network to do continuous speech recognition. A simpler speech task such as Keyword Spotting could also be investigated.\n', ""The paper describes a neural end-to-end architecture to solve multiple tasks at once.  The architecture consists of an encoder, a mixer, a decoder, and many modality networks to cover different types of input and output pairs for different tasks.  The engineering endeavor is impressive, but the paper has little scientific value.  Below are a few suggestions to make the paper stronger.\n\nIt is possible that the encoder, mixer, and decoder are just multiplexing tasks based on the input.  One way to analyze whether this happens is to predict the identity of the task from the hidden vectors.  If this is the case, how to prevent it from happening?  If this does not happen, what is being shared across tasks?  This can be analyzed by embedding the inputs from different tasks and looking for inputs from other tasks within a neighborhood in the embedding space.\n\nWhy multitask learning help the model perform better is still unclear.  If the model is able to leverage knowledge learned from one task to perform another task, then we expect to see either faster convergence or good performance with fewer samples.  The authors should analyze if this is the case, and if not, what are we actually benefiting from multitask learning?\n\nIf the modality network is shared across multiple tasks, we expect the learned hidden representation produced by the modality network is more universal.  If that is the case, what information of the input is being retained when training with multiple tasks and what information of the input is being discarded when training with a single task?\n\nReporting per-token accuracies, such as those in Table 2, is problematic.  It's unclear how to compute per-token accuracies for structured prediction tasks, such as speech recognition, parsing, and translation.  Furthermore, based on the results in Table 2, the model clearly fails on the speech recognition task.  The author should also report the standard speech recognition metric, word error rates (WER), for the speech recognition task in Table 1.\n"", 'The paper presents a multi-task architecture that can perform multiple tasks across multiple different domains. The authors design an architecture that works on image captioning, image classification, machine translation and parsing.\n\nThe proposed model can maintain performance of single-task models and in some cases show slight improvements. This is the main take-away from this paper. \n\nThere is a factually incorrect statement - depthwise separable convolutions were not introduced in Chollet 2016. Section 2 of the same paper also notes it (depthwise convolutions can be traced back to at least 2012).']","[50, -50, 50]","[75, 20, 0]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novelty, significance, and good writing, but also points out several areas for improvement. The initial paragraphs are quite positive, praising the approach as 'very interesting and inspiring' and calling it 'an important step towards more general deep learning models.' However, the latter part of the review lists several concerns and suggestions for improvement, balancing out the overall sentiment.\n\nThe politeness score is 75 (fairly polite) because the reviewer uses respectful and constructive language throughout. They begin with positive comments and frame their criticisms as suggestions or areas for clarification rather than direct attacks. Phrases like 'The paper is well written and easy to follow' and 'The contributions of the paper are novel and significant' set a positive tone. Even when pointing out issues, the reviewer uses polite language such as 'should be explained' or 'Information about the detailed setup is also lacking' rather than more aggressive phrasing. The reviewer also offers helpful suggestions and references, which is a polite way to guide improvements."", ""The sentiment score is -50 because the reviewer states that 'the paper has little scientific value,' which is a significant criticism. However, they do acknowledge the 'impressive' engineering effort and provide constructive suggestions for improvement, which prevents the score from being more negative. The politeness score is 20 because the reviewer uses professional and respectful language throughout, offering suggestions rather than harsh criticisms. They use phrases like 'It is possible that...' and 'The authors should analyze...' which are polite ways of pointing out areas for improvement. The reviewer also balances negative feedback with positive acknowledgments, such as recognizing the 'impressive' engineering work. However, the directness of some statements (e.g., 'the model clearly fails on the speech recognition task') prevents the politeness score from being higher."", ""The sentiment score is 50 (slightly positive) because the review acknowledges the paper's main contribution and its ability to maintain or slightly improve performance compared to single-task models. However, it also points out a factual error, which prevents it from being more positive. The politeness score is 0 (neutral) because the language used is straightforward and professional, without being particularly polite or rude. The reviewer states facts and observations without using overly positive or negative language, maintaining a neutral tone throughout the review.""]"
"['The paper proposes a hierarchical probabilistic model that learns both static representations and the dynamics of the data. The model iteratively updates its latent representations of the data in order to improve its generative power. The model is applicable to both static images (iterative improvements of the samples) and videos (predictive coding like repesentations).\n\nPros:\n\n-- the motivation for the work and its connections to the cognitive/philosophical models of concepts and predictive coding is very interesting\n-- the iterative improvements in the celebA samples in Fig. 3 and the corresponding improvements in the log-likelihood in Tbl. 1 vs the vanilla VAE baseline are promising and suggest that the approach has potential\n\nCons:\n\n-- The major problem with this paper in my opinion is that the methods section is very confusing:\n    1) The section is too brief and there is absolutely no description of the model until page 4\n    2) The figures are hard to understand and the annotations are not informative (e.g. what is the difference between Fig.1 and Fig.2?) \n    3) The notation is unconventional and keeps changing (e.g. the generator is referred to as either \\varphi_A, \\varphi_X,  \\varphi_X(Z_t), X_t|Z_t, or \\mu_X; \\sigma_X... the dimensionality of the image is denoted as i, N * c or Nc... I can go on).  \n    4) The rescaling of the latent parameters seems engineered and arbitrary (e.g. \\beta scaling factor in Eq. 8 is chosen so that the sigmoid reaches 0.75 when the value is 0.5\\sigma of the threshold).\n\nDue to the points above I failed to fully understand the model despite trying hard to do so. In particular, I did not understand the most important part of the paper addressing the iterative update of the latents vs backprop update of the generative weights. \n\nMinor points:\n-- The introduction is too long and repetitive. The space saved should be used to describe the model more precisely.\n-- The parametrisation of S_t should be described when it is first introduced, not 2 paragraphs later.\n-- How does an inner product of two vectors result in a matrix (Sec. 3.3)?\n-- GANs also do not have an encoder network (despite what the authors claim in Sec. 4.1) and should be used as a baseline\n-- Why does the VAE baseline have a different decoder architecture than the proposed model?\n-- What is the pre-processing done for CelebA?\n-- What is the ground truth that was supposed to be matched by \\mu_S_t in the dynamic dataset?\n-- Figs. 4-5 are hard to understand. What do the different colours of the lines mean? The time stamps where the behaviours are changing should be marked in the plot (not just described in the text).\n\nTo conclude, the authors are advised to shorten the introduction and literature review sections and use the extra space to re-write and expand the methods section to make it very clear how their model works using the standard notation used in the literature. The results section detailing the dynamic setup of their approach needs to be made more clear as well. In the current form the paper is not ready for publication.\n\n\n\n\n\n\n', 'This paper, to me, is a clear rejection from these basic observations:\n\nA *model* is not a computation graph and should never be presented that way. \nCalling a computation graph a Bayesian network without even writing down how *inference* can ever result in such a computation graph is a basic error. \nThe authors claim this: ""So, no encoder or inference models are used since the generators also serve as their inverse transformations."" Well, then this is not a Bayesian network. \nThe authors spend a lot of time analyzing constant inputs theoretically, and I\'m not sure why this is even relevant. ', ""Summary:\n\nThe paper proposed an Bayesian network model, realized as a neural network, that learns\n1. latent representation of observed data (images in the paper).\n2. dynamics of interaction in sequential data in the form of a linear dynamical system w.r.t. latent representation, controlled by secondary latent variables.\n\nThe model is evaluated in two scenarios:\n1. Static images on CelebA dataset, where it shows that iterative guided updates of the latent representation improve reconstruction quality, compared to VAE.\n2. Sequential data experiment, the authors show that the interaction states can be used for semantic action segmentation.\n\n-------------------------------------------------------\nPros:\n1. The proposed model is unsupervised, and it can iteratively improve the latent representation and consequently the systhesized output, given more observations at inference.\n\n2. The paper proposes novel strategies to update the latent distributions' parameters.\n\n-------------------------------------------------------\nCons:\n1. The problem fornulation with Z, X and S are not clearly defined at the beginning, the reviewer must read further into page 4 and 5 to understand. Brief description should be provided in/around Fig 1. Furthermore, the log likelihood loss is not clearly defined before Eq (1).\n\n2. The proposed updates to mu_z, sigma_z, mu_s and sigma_s in Eq (2,3,6,9) and their convergence properties as well as stability are not justified by actual experiments and analysis.\n\n3. The overall training procedure is unclear: do the hidden layer weights get updated given repeated observations in the case of static model?\n\n4. In the static image experiment, why the authors did not compare to at least GAN (or better if GLO [Bojsnowski et al. 2017] is included)?\nThe iterative updates clearly give the proposed model advantage over VAE. VAE also relies on reconstruction loss, hence the synthesized output are often blurry.\nGAN, which can generate high quality images, should provide a better benchmark. One can use the same method as this paper, backpropagating the reconstruction error of GAN generator to the input layer to find the suitable noise vector of an image, then synthesize the image with the generator from that noise input.\n\n5. One the two objectives of the paper, image reconstruction in sequence, is not evaluated in the dynamic experiment. The paper does not provide any analysis for A, Z and \\hat{X} in the dynamic setting.\nInstead, the secondary latent states S are used for sequence segmentation. Why is it not compared to HMM baseline at least, in that case?\nFurthermore, the paper does not provide a standard methodology to segment actions from video, but rather, the reviewer must look at the plot in Fig 4 & 5 and read the description in page 8 to see the correspondence between the variation of S and the action switch in the video.\nIn addition, the segmentation is only carried out on one video in the paper.\nMoreover, the paper only experiments with S of length 2. Given the limited evaluation, the authors can try and report the results with different lengths of S (e.g. 1 or 3, 4)."", 'The authors propose an architecture and generative model for static images and video sequences, with the purpose of generating an image that looks as similar as possible to the one that is supplied. This is useful for for example frame prediction in video and detection of changes in video as a consequence to changes in the dynamics of objects in the scene.\nThe architecture minimizes the error between the generated image(s) and the supplied image(s) by refining the generated image over time when the same image is shown and by adapting when the image is changed. The model consists of three neural networks (F_Zµ, F_Zsigma, f_X|Z) and three multivariate Gaussian distributions P(S_t), P(Z_t) and P(X_t,Z_t) with diagonal covariances. The NNs do not change over time but they relate the three Gaussian distributions in different ways and these distributions are changing over time in order to minimize the error of the generated image(s).\n\nThe paper took a while to understand due to its structure and how it is written. A short overview of the different components of Figure 1 giving the general idea and explaining\n* what nodes are stochastic variables and NNs\n* what is trained offline/online\nIt would also help the structure if the links/arrows/nodes had numbers corresponding to the relevant equations defining the relations/computations. Some of these relations are defined with explicit equation numbers, others are baked into the text which makes it difficult to jump around in the paper when reading it and trying to understand the architecture.\n\nThere are also numerous language errors in the paper and many of them are grammatical. For example:\n  Page 5, second paragraph: ""osculations"" -> ""oscillations""\n  Page 5, fourth paragraph: ""Defining .. is defined as..""\n\nThe results seem impressive and the problem under consideration is important and have several applications. There is however not much in terms of discussion nor analysis of the two experiments.\nI find the contribution fairly significant but I lack some clarity in the presentation as well as in the experiments section.\nI do not find the paper clearly written. The presentation can be improved in several chapters, such as the introduction and the method section.\nThe paper seem to be technically correct. I did not spot any errors.\n\nGeneral comments:\n- Why is 2 a suitable size of S?\n- Why use two by two encoding instead of stride for the VAE baseline? How does this affect the experiments?\n- How is S_0 and the Z_0 prior set (initialized) in the experiments?\n- It would improve the readability of the paper, not least for a broader audience, if more details are added on how the VAE baseline architecture differ from the proposed architecture.\n\n- In the first experiment: \n-- How many iterations does it take for your method to beat VAE?\n-- What is the difference between the VAE basline and your approach that make VAE perform better than your approach initially (or even after a few iterations)? \n-- What affect does the momentum formulation have on the convergence rate (number of iterations necessary to reach VAE and your methods result at t=10)?  \n\n- In the second experiment and Figure 5 in particular it was observed that some actions are clearly detected while others are not. It is mentioned that those that are not detected by the approach are more similar. In what sense are the actions more similar, which are the most prominent (from a humans perspective) such actions, what is making the model not detecting them and what can be done (within your approach) in order to improve or adjust the detection fidelity?\n\nPlease add more time labels under the time axis in Figure 4 and Figure 5. Also please annotate the figures at the time points where the action transitions are according to the ground truth.']","[-60, -90, -50, -20]","[20, -60, 20, 50]","[""The sentiment score is -60 because while the reviewer acknowledges some positive aspects ('pros'), the overall tone is critical and concludes that 'the paper is not ready for publication'. The reviewer lists several major issues with the methods section and other minor points, indicating a predominantly negative sentiment. The politeness score is 20 because the reviewer uses professional language and offers constructive criticism. They acknowledge positive aspects and use phrases like 'the authors are advised to' rather than using harsh or rude language. However, the directness of the criticism and the conclusion that the paper is not ready for publication prevent a higher politeness score."", ""The sentiment score is -90 because the reviewer starts with 'This paper, to me, is a clear rejection' and proceeds to list several fundamental issues with the paper. The tone is highly critical throughout, pointing out 'basic errors' and questioning the relevance of parts of the paper. The politeness score is -60 because while the reviewer doesn't use explicitly rude language, the tone is blunt and dismissive. Phrases like 'basic error' and 'I'm not sure why this is even relevant' come across as somewhat condescending. The reviewer makes no attempt to soften their criticism or acknowledge any positive aspects of the paper, which contributes to the overall negative and impolite tone."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('Pros'), there are more extensive and critical 'Cons' listed. The reviewer points out several significant issues with the paper, including unclear problem formulation, lack of justification for proposed updates, unclear training procedures, and limited evaluation. These criticisms outweigh the positive points, indicating a generally negative sentiment.\n\nThe politeness score is 20 because the reviewer maintains a professional and objective tone throughout. They use neutral language to present both pros and cons, and their criticisms are presented as constructive feedback rather than harsh judgments. Phrases like 'The paper does not provide...' or 'Why is it not compared to...' are used to raise questions and suggest improvements politely. However, the score is not higher because the review doesn't include explicitly polite language or praise, maintaining a mostly neutral, matter-of-fact tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem and the impressive results, they express several concerns about the paper's clarity, structure, and lack of detailed analysis. The reviewer points out multiple areas for improvement, including the paper's organization, language errors, and the need for more discussion on experiments.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and frame criticisms as opportunities to enhance the paper rather than outright dismissals. The language used is respectful and focuses on the content rather than making personal comments about the authors.\n\nThe reviewer balances critique with recognition of the paper's strengths, which contributes to both the slightly negative sentiment and the polite tone. They use phrases like 'The results seem impressive' and 'I find the contribution fairly significant' while also pointing out areas that need work, demonstrating a balanced and considerate approach to the review.""]"
"['This paper investigates the effect of adversarial training. Based on experiments using CIFAR10, the authors show that adversarial training is effective in protecting against ""shared"" adversarial perturbation, in particular against universal perturbation. In contrast, it is less effective to protect against singular perturbations. Then they show that singular perturbation are less robust to image transformation, meaning after image transformation those perturbations are no longer effective. Finally, they show that singular perturbations can be easily detected.\n\nI like the message conveyed in this paper. However, as the statements are mostly backed by experiments, then I think it makes sense to ask how statistically significant the present results are. Moreover, is CIFAR 10 experiments conclusive enough. ', ""Summary:\n\nThis paper empirically studies adversarial perturbations dx and what the effects are of adversarial training (AT) with respect to shared (dx fools for many x) and singular (only for a single x) perturbations. Experiments use a (previously published) iterative fast-gradient-sign-method and use a Resnet on CIFAR.\n\nThe authors conclude that in this experimental setting:\n- AT seems to defend models against shared dx's.\n- This is visible on universal perturbations, which become less effective as more AT is applied.\n- AT decreases the effectiveness of adversarial perturbations, e.g. AT decreases the number of adversarial perturbations that fool both an input x and x with e.g. a contrast change.\n- Singular perturbations are easily detected by a detector model, as such perturbations don't change much when applying AT.\n\nPro:\n- Paper addresses an important problem: qualitative / quantitative understanding of the behavior of adversarial perturbations is still lacking.\n- The visualizations of universal perturbations as they change during AT are nice.\n- The basic observation wrt the behavior of AT is clearly communicated.\n\nCon:\n- The experiments performed are interesting directions, although unfocused and rather limited in scope. For instance, does the same phenomenon happen for different datasets? Different models?\n- What happens when we use adversarial attacks different from FGSM? Do we get similar results?\n- The papers lacks a more in-depth theoretical analysis. Is there a principled reason AT+FGSM defends against universal perturbations?\n\nOverall:\n- As is, it seems to me the paper lacks a significant central message (due to limited and unfocused experiments) or significant new theoretical insight into the effect of AT. A number of questions addressed are interesting starting points towards a deeper understanding of *how* the observations can be explained and more rigorous empirical investigations.\n\nDetailed:\n-\n"", ""This paper analyses adversarial training and its effect on universal adversarial examples as well as standard (basic iteration) adversarial examples. It also analyses how adversarial training affects detection.\n\nThe robustness results in the paper are interesting and seem to indicate that interesting things are happening with adversarial training despite adversarial training not fixing the adversarial examples problem. The paper shows that adversarial training increases the destruction rate of adversarial examples so that it still has some value though it would be good to see if other adversarial resistance techniques show the same effect. It's also unclear from which epoch the adversarial examples were generated from in figure 5. Further the transformations in figure 5 are limited to artificially controlled situations, it would be much more interesting to see how the destruction rate changes under real-world test scenarios.\n\nThe results on the detector are not that surprising since previous work has shown that detectors can learn to classify adversarial examples and the additional finding that they can detect adversarial examples for an adversarially trained model doesn't seem surprising. There is also no analysis of what happens for adversarial examples for the detector.\n\nAlso, it's not clear from section 3.1 what inputs are used to generate the adversarial examples. Are they a random sample across the whole dataset?\n\nFinally, the paper spends significant time on describing MaxMin and MinMax and the graphical visualizations but the paper fails to show these graphical profiles for real models.""]","[50, -20, 20]","[75, 50, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by saying they 'like the message conveyed in this paper,' which is a positive statement. However, they follow this with some concerns about the statistical significance and the conclusiveness of the experiments, which tempers the positivity. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the positive aspects of the paper before raising concerns. They phrase their criticisms as questions rather than direct criticisms, which is a polite way to provide feedback. The reviewer also uses phrases like 'I think it makes sense to ask' which softens the critique. Overall, the tone is constructive and professional, maintaining a balance between praise and suggestions for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pro' section), they express more concerns and limitations ('Con' section). The overall tone suggests that the paper lacks significant central message and needs more in-depth analysis. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, balancing critique with recognition of the paper's strengths. They offer constructive feedback without using harsh or dismissive language, maintaining a courteous tone even when pointing out weaknesses."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting results and the value of adversarial training, despite pointing out some limitations. The reviewer uses phrases like 'interesting things are happening' and 'it still has some value,' indicating a generally positive view. However, they also mention several areas for improvement and express some skepticism about certain aspects, which prevents the score from being higher. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They offer constructive criticism without using harsh language, and they balance positive observations with suggestions for improvement. The reviewer uses phrases like 'it would be good to see' and 'it's not clear,' which are polite ways of pointing out areas that need more work or clarification.""]"
"['**Summary**\nThe paper proposes an extension of the attend, infer, repeat generative model of Eslami, 2016 and extends it to handle ``visual attribute descriptions. This straightforward extension is claimed to improve image quality and shown to improve performance on a previously introduced image caption ranking task. In general, the paper shows improvements on an image caption agreement task introduced in Kuhnle and Copestake, 2017.  The paper seems to have weaknesses pertaining to the approach taken, clarity of presentation and comparison to baselines which mean that the paper does not seem to meet the acceptance threshold for ICLR. See more detailed points below in Weaknesses.\n\n**Strengths**\nI like the high-level motivation of the work, that one needs to understand and establish that language or semantics can help learn better representations for images. I buy the premise and think the work addresses an important issue. \n\n**Weakness**\n\nApproach:\n* A major limitation of the model seems to be that one needs access to both images and attribute vectors at inference time to compute representations which is a highly restrictive assumption (since inference networks are discriminative). The paper should explain how/if one can compute representations given just the image, for instance, say by not using amortized inference. The paper does propose to use an image-only encoder but that is intended in general as a modeling choice to explain statistics which are not captured by the attributes (in this case location and orientation as explained in the Introduction of the paper).\n\nClarity:\n* Eqn. 5, LHS can be written more clearly as \\hat{a}_k. \n\n* It would also be good to cite the following related work, which closely ties into the model of Eslami 2016, and is prior work: \n\nEfficient inference in occlusion-aware generative models of images,\nJonathan Huang, Kevin Murphy.\nICLR Workshops, 2016\n\n* It would be good to clarify that the paper is focusing on the image caption agreement task from Kuhnle and Copestake, as opposed to generic visual question answering.\n\n* The claim that the paper works with natural language should be toned down and clarified. This is not natural language, firstly because the language in the dataset is synthetically generated and not “natural”. Secondly, the approach parses this “synthetic” language into structured tuples which makes it even less natural. Also, Page. 3. What does “partial descriptions” mean?\n\n* Section 3: It would be good to explicitly draw out the graphical model for the proposed approach and clarify how it differs from prior work (Eslami, 2016).\n\n* Sec. 3. 4 mentions that the “only image” encoder is used to obtain the representation for the image, but the “only image” encoder is expected to capture the “indescribable component” from the image, then how is the attribute information from the image captured in this framework? One cannot hope to do image caption association prediction without capturing the image attributes...\n\n*, In general, the writing and presentation of the model seem highly fragmented, and it is not clear what the specifics of the overall model are. For instance, in the decoder, the paper mentions for the first time that there are variables “z”, but does not mention in the encoder how the variables “z” were obtained in the first place (Sec. 3.1). For instance, it is also not clear if the paper is modeling variable length sequences in a similar manner to Eslami, 2016 or not, and if this work also has a latent variable [z, z_pres] at every timestep which is used in a similar manner to Eqn. 2 in Eslami, 2016. Sec. 3.4 “GEN Image Encoder” has some typo, it is not clear what the conditioning is within q(z) term.\n\n* Comparison to baselines: \n  1. How well does this model do against a baseline discriminative image caption ranking approach, similar to [D]? This seems like an important baseline to report for the image caption ranking task.\n  2. Another crucial baseline is to train the Attend, Infer, Repeat model on the ShapeWorld images, and then take the latent state inferred at every step by that model, and use those features instead of the features described in Sec. 3.4 “Gen Image Encoder” and repeat the rest of the proposed pipeline. Does the proposed approach still show gains over Attend Infer Repeat?\n  3. The results shown in Fig. 7 are surprising -- in general, it does not seem like a regular VAE would do so poorly. Are the number of parameters in the proposed approach and the baseline VAE similar? Are the choices of decoder etc. similar? Did the model used for drawing Fig. 7 converge? Would be good to provide its training curve. Also, it would be good to evaluate the AIR model from Eslami, 2016 on the same simple shapes dataset and show unconditional samples. If the claim from the work is true, that model should be just as bad as a regular VAE and would clearly establish that using language is helping get better image samples.\n\n* Page 2: In general the notion of separating the latent space into content and style, where we have labels for the “content” is an old idea that has appeared in the literature and should be cited accordingly. See [B] for an earlier treatment, and an extension by [A]. See also the Bivcca-private model of [C] which has “private” latent variables for vision similar to this work (this is relevant to Sec. 3.2.)\n\nReferences:\n[A]: Upchurch, Paul, Noah Snavely, and Kavita Bala. 2016. “From A to Z: Supervised Transfer of Style and Content Using Deep Neural Network Generators.” arXiv [cs.CV]. arXiv. http://arxiv.org/abs/1603.02003.\n\n[B]: Kingma, Diederik P., Danilo J. Rezende, Shakir Mohamed, and Max Welling. 2014. “Semi-Supervised Learning with Deep Generative Models.” arXiv [cs.LG]. arXiv. http://arxiv.org/abs/1406.5298.\n\n[C]: Wang, Weiran, Xinchen Yan, Honglak Lee, and Karen Livescu. 2016. “Deep Variational Canonical Correlation Analysis.” arXiv [cs.LG]. arXiv. http://arxiv.org/abs/1610.03454.\n\n[D]: Kiros, Ryan, Ruslan Salakhutdinov, and Richard S. Zemel. 2014. “Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models.” arXiv [cs.LG]. arXiv. http://arxiv.org/abs/1411.2539.\n', 'Summary: The authors observe that the current image generation models generate realistic images however as the dimensions of the latent vector is fully entangled, small changes to a single neuron can effect every output pixel in arbitrary ways. In this work, they explore the effect of using partial natural language scene descriptions for the task of disentangling the latent entities visible in the image.  The proposed Generative Entity Networks jointly generates the natural language descriptions and images from scratch. The core model is Variational Autoencoders (VAE) with an integrated visual attention mechanism that also generates the associated text. The experiments are conducted on the Shapeworld dataset.\n\nStrengths:\nSimultaneous text and image generation is an interesting research topic that is relevant for the community.\nThe paper is well written, the model is formulated with no errors (although it could use some more detail) and supported by illustrations (although there are some issues with the illustrations detailed below). \nThe model is evaluated on tasks that it was not trained on which indicate that this model learns generalizable latent representations. \n\nWeaknesses:\nThe paper gives the impression to be rushed, i.e. there are citations missing (page 3 and 6), the encoder model illustration is not as clear as it could be. Especially the white boxes have no labels, the experiments are conducted only on one small-scale proof of concept dataset, several relevant references are missing, e.g. GAN, DCGAN, GAWWN, StackGAN. Visual Question answering is mentioned several times in the paper, however no evaluations are done in this task.\n\nFigure 2 is complex and confusing due to the lack of proper explanation in the text. The reader has to find out the connections between the textual description of the model and the figure themselves due to no reference to particular aspects of the figure at all. In addition the notation of the modules in the figure is almost completely disjoint so that it is initially unclear which terms are used interchangeably.\n\nDetails of the “white components” in Figure 2 are not mentioned at all. E.g., what is the purpose of the fully connected layers, why do the CNNs split and what is the difference in the two blocks (i.e. what is the reason for the addition small CNN block in one of the two)\n\nThe optimization procedure is unclear. What is the exact loss for each step in the recurrence of the outputs (according to Figure 5)? Or is only the final image and description optimized. If so, how is the partial language description as a target handled since the description for a different entity in an image might be valid, but not the current target. (This is based on my understanding that each data point consists of one image with multiple entities and one description that only refers to one of the entities).\n\nAn analysis or explanation of the following would be desirable: How is the network trained on single descriptions able to generate multiple descriptions during evaluation. How does thresholding mentioned in Figure 5 work?\n\nIn the text, k suggests to be identical to the number of entities in the image. In Figure 5, k seems to be larger than the number of entities. How is k chosen? Is it fixed or dynamic?\n\nEven though the title claims that the model disentangles the latent space on an entity-level, it is not mentioned in the paper. Intuitively from Figure 5, the network generates black images (i.e. all values close to zero) whenever the attention is on no entity and, hence, when attention is on an entity the latent space represents only this entity and the image is generated only showing that particular entity. However, confirmation of this intuition is needed since this is a central claim of the paper.\n\nAs the main idea and the proposed model is simple and intuitive, the evaluation is quite important for this paper to be convincing. Shapeworlds dataset seems to be an interesting proof-of-concept dataset however it suffers from the following weaknesses that prevent the experiments from being convincing especially as they are not supported with more realistic setups. First, the visual data is composed of primitive shapes and colors in a black background. Second, the sentences are simple and non-realistic. Third, it is not used widely in the literature, therefore no benchmarks exist on this data. \n\nIt is not easy to read the figures in the experimental section, no walkthrough of the results are provided. For instance in Figure 4a, the task is described as “showing the changes in the attribute latent variables” which gives the impression that, e.g. for the first row the interpolation would be between a purple triangle to a purple rectangle however in the middle the intermediate shapes also are painted with a different color. It is not clear why the color in the middle changes.\n\nThe evaluation criteria reported on Table 1 is not clear. How is the accuracy measured, e.g. with respect to the number of objects mentioned in the sentence, the accuracy of the attribute values, the deviation from the ground truth sentence (if so, what is the evaluation metric)? No example sentences are provided for a qualitative comparisons. In fact, it is not clear if the model generates full sentences or attribute phrases.\n\nAs a summary, this paper would benefit significantly with a more extensive overview of the existing relevant models, clarification on the model details mentioned above and a more through experimental evaluation with more datasets and clear explanation of the findings.', 'This paper presented a Generative entity networks (GEN). It is a multi-view extension of variational autoencoder (VAE) for disentangled representation. It uses the image and its attributes.  The paper is very well motivated and tackles an important problem. However, the presentation of the method is not clear, the experiment is not sufficient, and the paper is not polished. \n\nPros:\n1. This paper tackles an important research question. \nLearning a meaningful representation is needed in general. For the application of images, using text description to refine the representation is a natural and important research question. \n\n2. The proposed idea is very well motivated, and the proposed model seems correct. \n\nCons and questions:\n1. The presentation of the model is not clear. \nFigure 2 which is the graphic representation of the model is hard to read. There is no meaningful caption for this important figure.  Which notation in the figure corresponds to which variable is not clear at all.  This also leads to unclarity of the text presentation of the model, for example, section 3.2. Which latent variable is used to decode which part?\n\n2. Missing important related works.\nThere are a couple of highly related work with multi-view VAE tracking similar problem have been proposed in the past. The paper did not discuss these related work and did not compare the performances. Examples of these related work include [1] and [2] (at the end of the review).\nAdditionally, the idea of factorized representation idea (describable component and indescribable component) has a long history.  It can be traced back to [3], used in PGM setting in [4] and used in VAE setting in [1]. This group of related work should also be discussed. \n\n3. Experiment evaluation is not sufficient. \nFirstly, only one toy dataset is used for experimental evaluations. More evaluations are needed to verify the method, especially with natural images. \nSecondly, there are no other state-of-the-art baselines are used. The baselines are various simiplied versions of the proposed model. More state-of-the-art baselines are needed, e.g. [1] and [2].\n\n4. Maybe overclaiming.\nIn the paper, only attributes of objects are used which is not semi-natural languages.\n\n5. The paper, in general, needs to be polished. \nThere are missing links and references in the paper and un-explained notations, and non-informative captions.\n\n6. Possibility to apply to natural images. \nThis method does not model spatial information. How can the method make sure that  simple adding generated images with each component will lead to a meaningful image in the end? Especially with natural images,  the spacial location and the scale should be critical. \n\n[1] Wang, Weiran, Honglak Lee, and Karen Livescu. ""Deep variational canonical correlation analysis."" arXiv preprint arXiv:1610.03454 (2016).\n[2] Suzuki, Masahiro, Kotaro Nakayama, and Yutaka Matsuo. ""Joint Multimodal Learning with Deep Generative Models."" arXiv preprint arXiv:1611.01891 (2016).\n[3] Tucker, Ledyard R. ""An inter-battery method of factor analysis."" Psychometrika 23.2 (1958): 111-136.\n[4] Zhang, Cheng, Hedvig Kjellström, and Carl Henrik Ek. ""Inter-battery topic representation learning."" European Conference on Computer Vision. Springer International Publishing, 2016.\n\n']","[-50, -20, -30]","[20, 60, 50]","[""The sentiment score is -50 because while the reviewer acknowledges some strengths and the importance of the topic, they identify numerous weaknesses in approach, clarity, and comparison to baselines. The overall tone suggests the paper does not meet the acceptance threshold. The politeness score is 20 because the reviewer uses polite language like 'I like' and 'It would be good to', while offering constructive criticism. They maintain a professional tone throughout, even when pointing out flaws. The reviewer balances critique with positive comments and provides detailed suggestions for improvement, indicating a respectful approach to the review process."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they also point out several significant weaknesses and areas for improvement. The review begins with positive comments about the relevance and writing quality, but then lists numerous concerns about missing details, unclear explanations, and limited experimental evaluation. The overall tone suggests the paper needs substantial revisions.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'would benefit significantly' and 'clarification... is needed' rather than harsh criticism. The reviewer also balances negative points with positive ones, acknowledging the paper's strengths before discussing its weaknesses. However, the score is not higher because the review is quite direct in pointing out flaws and doesn't use many explicitly polite phrases or softening language."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('very well motivated', 'tackles an important problem'), the overall tone is critical with numerous cons listed. The reviewer points out significant issues with presentation, related work, experimental evaluation, and potential overclaiming. The politeness score is 50 because the reviewer uses respectful language throughout, balancing positive and negative feedback. They use phrases like 'Pros' and 'Cons and questions' to structure the feedback, and employ polite language such as 'Maybe overclaiming' instead of making accusatory statements. The reviewer also provides constructive suggestions and references to improve the paper, which contributes to the polite tone.""]"
"['This paper proposes a language independent text encoding method for cross-language classification. The proposed approach demonstrates better performance than machine translation based classifier. \n\nThe proposed approach  performs language independent common representation learning for cross-lingual text classification. Such representation learning based methods have been studied in the literature. The authors should provide a review and comparison to related methods. \n\nTechnical contribution of the paper is very limited. The approach section is too short to provide a clear presentation of the model. Some descriptions about the input text representation are actually given in the experimental section. \n\nThe proposed approach uses comparable texts across different languages to train the encoders, while using the topic information as auxiliary supervision label information. In the experiments, it shows the topics are actually fine-grained class information that are closely related to the target class categories. This makes the zero-shot learning scenario not to be very practical. With such fine-grained supervision knowledge, it is also unfair to compare to other cross-lingual methods that use much less auxiliary information. \n\nIn the experiments, it states the data are collected by “For pages with multiple categories we select one at random”.  Won’t this produce false negative labels on the constructed data? How much will this affect the test performance?\n\nThe experimental results are not very convincing without empirical comparisons to the state-of-the-art cross-lingual text classification methods. ', 'This paper addresses the problem of learning a cross-language text categorizer with no labelled information in the target language. The suggested solution relies on learning cross-lingual embeddings, and training a classifier using labelled data in the source language only.\n\nThe idea of using cross-lingual or multilingual representations to seamlessly handle documents across languages is not terribly novel as it has been use in multilignual categorization or semantic similarity for some time. This contribution however proposes a clean separation of the multiligual encoder and classifier, as well as a good (but long) section on related prior art.\n\nOne concern is that the modelling section stays fairly high level and is hardly sufficient, for example to re-implement the models. Many design decisions (e.g. #layers, #units) are not justified. They likely result from preliminary experiments, in that case it should be said.\n\nThe main concern is that the experiments could be greatly improved. Given the extensive related work section, it is odd that no alternate model is compared to. The details on the experiments are also scarce. For example, are all accuracy results computed on the same 8k test set? If so this should be clearly stated. Why are models tested on small subsets of the available data? You have 493k Italian documents, yet the largest model uses 158k... It is unclear where many such decisions come from -- e.g. Fig 4b misses results for 1000 and 1250 dimensions and Fig 4b has nothing between 68k and 137k, precisely where a crossover happens.\n\nIn short, it feels like the paper would greatly improve from a clearer modeling description and more careful experimental design.\n\nMisc:\n- Clarify early on what ""samples"" are in your categorization context.\n- Given the data set, why use a single-label multiclass setup, rather than multilabel?\n- Table 1 caption claims an average of 2.3 articles per topic, yet for 200 topics you have 500k to 1.5M articles?\n- Clarify the use of the first 200 words in each article vs. snippets\n- Put overall caption in Figs 2-4 on top of (a), (b), otherwise references like Fig 4b are unclear.', 'The draft proposes an approach to cross-lingual text classification through the use of comparable corpora, as exemplified through the use of Wikipedia via the inter-language links. A single task is featured: the prediction of categories for the Italian Wikipedia articles. Two models are contrasted to the proposed zero-shot classification approach, a monolingual classifier and a machine translation-based model.\n\nI have a number of issues with the paper, and for these I vote strong reject. I briefly list some of these issues.\n\n1) The model brings no novelty, or to put it bluntly, it is rather simplistic. Yet, at the same time, its description is split over multiple sections and thus rather convoluted, in effect obscuring the before-mentioned over-simplicity.\n2) The experiment is also oversimplified, as it features only one target language and a comparison to an upper bound and just a single competing system.\n3) In contrast to the thin experiments and (lack of) technical novelty, the introduction & related work writeups are overdrawn and uninteresting.\n\nI am sorry to say that I have learned very little from this paper, and that in my view it does not make for a very compelling ICLR read.']","[-50, -30, -80]","[0, 20, -20]","['The sentiment score is -50 because the review is generally critical, pointing out several limitations and issues with the paper. While it acknowledges some positive aspects (e.g., better performance than machine translation), the majority of the review focuses on shortcomings. The reviewer criticizes the limited technical contribution, unclear presentation, potential unfairness in comparisons, and unconvincing experimental results. The politeness score is 0 (neutral) because the language used is professional and objective, without being particularly polite or rude. The reviewer states criticisms directly but without using harsh or insulting language, maintaining a neutral, academic tone throughout the review.', ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects (e.g., 'clean separation of the multiligual encoder and classifier', 'good (but long) section on related prior art'), they express several concerns and criticisms. The reviewer points out that the idea is 'not terribly novel', the modeling section is 'hardly sufficient', and the experiments 'could be greatly improved'. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is 20 because the reviewer uses generally polite language and constructive criticism. They offer specific suggestions for improvement and use phrases like 'it feels like the paper would greatly improve from...' rather than harsh or dismissive language. However, the tone is not overly polite or deferential, maintaining a professional and slightly critical stance."", ""The sentiment score is -80 because the reviewer expresses strong negative sentiment throughout the review. They vote for a 'strong reject' and list multiple issues with the paper, stating they 'learned very little' and that it's not 'a very compelling read'. The politeness score is -20 because while the reviewer maintains some level of professional language, there are instances of blunt and somewhat harsh criticism. Phrases like 'to put it bluntly' and 'I am sorry to say' attempt to soften the blow, but the overall tone is still quite critical. The reviewer doesn't use overtly rude language, but the criticism is direct and leaves little room for positive interpretation.""]"
"['This paper illustrates the benefits of using normalized gradients when training deep models.\nBeyond exploring the ""vanilla"" normalized gradient algorithm they also consider adaptive versions, i.e., methods that employ per block (adaptive) learning rates using ideas from AdaGrad and Adam.\nFinally, the authors provide a theoretical analysis of NG with adaptive step-size, showing convergence guarantees in the stochastic convex optimization setting.\n\nI find this paper both very interesting and important. \nThe normalized gradient method was previously shown to overcome some non-convex phenomena which are hurdles to SGD, yet there was still the gap of  combining NG with methods which automatically tune the learning rate.\n\nThe current paper addresses this gap by a very simple (yet clever) combination of NG with AdaGrad and Adam, and the authors do a great job by illustrating the benefits of their scheme by testing it over a very wide span of deep learning \nmodels. In light of their experiments it seems like AdamNG and NG should be adopted as the new state-of-the-art methods in deep-learning applications.\n\nAdditional comments:\n-In the experiments the authors use the same parameters as is used by Adam/AdaGrad, etc..\nDid the authors also try to fine tune the parameters of their NG versions? If so what is the benefit that they get by doing so?\n-It will be useful if the authors can provide some intuition about why is the learning rate  chosen per block for NG?\nDid the authors also try to choose a learning rate per weight vector rather than per block? If so, what is the behaviour that they see.\n-I find the theoretical analysis a bit incomplete. The authors should spell out the choice of the learning rate in Thm. 1 and compare to AdaGrad.\n', 'This paper proposes a family of first-order stochastic optimization schemes based on (1)  normalizing (batches of) stochastic gradient descents and (2) choosing from a step size updating scheme. The authors argue that iterative first-order optimization algorithms can be interpreted as a choice of an update direction and a step size, so they suggest that one should always normalize the gradient when computing the direction and then choose a step size using the normalized gradient. \n\nThe presentation in the paper is clear, and the exposition is easy to follow. The authors also do a good job of presenting related work and putting their ideas in the proper context. The authors also test their proposed method on many datasets, which is appreciated.\n\nHowever, I didn\'t find the main idea of the paper to be particularly compelling. The proposed technique is reasonable on its own, but the empirical results do not come with any measure of statistical significance. The authors also do not analyze the sensitivity of the different optimization algorithms to hyperparameter choice, opting to only use the default. Moreover, some algorithms were used as benchmarks on some datasets but not others. For a primarily empirical paper, every state-of-the-art algorithm should be used as a point of comparison on every dataset considered. These factors altogether render the experiments uninformative in comparing the proposed suite of algorithms to state-of-the-art methods. The theoretical result in the convex setting is also not data-dependent, despite the fact that it is the normalized gradient version of AdaGrad, which does come with a data-dependent convergence guarantee.\n\nGiven the suite of optimization algorithms in the literature and in use today, any new optimization framework should either demonstrate improved (or at least matching) guarantees in some common (e.g. convex) settings or definitively outperform state-of-the-art methods on problems that are of widespread interest. Unfortunately, this paper does neither. \n\nBecause of these points, I do not feel the quality, originality, and significance of the work to be high enough to merit acceptance. \n\nSome specific comments:\np. 2: ""adaptive feature-dependent step size has attracted lots of attention"". When you apply feature-dependent step sizes, you are effectively changing the direction of the gradient, so your meta learning formulation, as posed, doesn\'t make as much sense.\np. 2: ""we hope the resulting methods can benefit from both techniques"". What reason do you have to hope for this? Why should they be complimentary? Existing optimization techniques are based on careful design and coupling of gradients or surrogate gradients, with specific learning rate schedules. Arbitrarily mixing the two doesn\'t seem to be theoretically well-motivated.\np. 2: ""numerical results shows that normalized gradient always helps to improve the performance of the original methods when the network structure is deep"". It would be great to provide some intuition for this.  \np. 2: ""we also provide a convergence proof under this framework when the problem is convex and the stepsize is adaptive"". The result that you prove guarantees a \\theta(\\sqrt{T}) convergence rate. On the other hand, the AdaGrad algorithm guarantees a data-dependent bound that is O(\\sqrt{T}) but can also be much smaller. This suggests that there is no theoretical motivation to use NGD with an adaptive step size over AdaGrad.\np. 2-3: ""NGD can find a \\eps-optimal solution....when the objective function is quasi-convex. ....extended NGD for upper semi-continuous quasi-convex objective functions..."". This seems like a typo. How are results that go from quasi-convex to upper semi-continuous quasi-convex an extension?\np. 3: There should be a reference for RMSProp.\np. 3: ""where each block of parameters x^i can be viewed as parameters associated to the ith layer in the network"". Why is layer parametrization (and later on normalization) a good way idea? There should be either a reference or an explanation.\np. 4: ""x=(x_1, x_2, \\ldots, x_B)"". Should these subscripts be superscripts?\np. 4: ""For all the algorithms, we use their default settings."" This seems insufficient for an empirical paper, since most problems often involve some amount of hyperparameter tuning. How sensitive is each method to the choice of hyperparameters? What about the impact of initialization?\np. 4-8: None of the experimental results have error bars or any measure of statistical significance.\np. 5: ""NG... is a variant of the NG_{UNIT} method"". This method is never motivated.\np. 5-6: Why are SGD and Adam used for MNIST but not on CIFAR? \np. 5: ""we chose the best heyper-paerameter from the 56 layer residual network."" Apart from the typos, are these parameters chosen from the training set or the test set? \np. 6: Why isn\'t Adam tested on ImageNet?\n\n  \nPOST AUTHOR RESPONSE: After reading the author response and taking into account the fact that the authors have spent the time to add more experiments and clarify their theoretical result, I have decided to upgrade my score from a 3 to a 4. However, I still do not feel that the paper is up to the standards of the conference. \n\n\n\n\n\n ', 'This paper proposes a variation to the familiar AdaGrad/Adam/etc family of optimization algorithms based a gradient magnitude normalization. More precisely, the components of the gradient are split into blocks (one block per layer), and each block is normalized by its L2 norm. The concatenation of these normalized gradients are used in place of the standard gradient in AdaGrad/Adam/SGD. The authors find the resulting optimizer performs slightly better than its competitors on four tasks.\n\nI feel this paper would be much stronger focusing extensively on one or two small problems and models, providing insight into how normalization affects optimization, rather than chasing state-of-the-art numbers on a variety of datasets and models. I believe the significance and originality of this work to be lacking.\n\n## Pros ##\n\nThe paper is easy to follow. The algorithm and experiment setups are clearly explained, and the plots are easy to understand. I appreciate the variety in experimental setups. The authors provide a proof of convergence for the AdaGrad variant on convex functions.\n\n## Cons ##\n\nThe paper fails to provide new insights to the reader. It succeeds in asking a question (how do normalized gradients impact training of neural networks?), but fails to add theoretical or empirical knowledge that furthers the field. While effectively changing the geometry of the problem, no motivation (theoretical or intuitive) is given as to why this normalization scheme should be effective.\n\nFrom the empirical side, the authors compare the proposed optimizers on many datasets and models, but concerningly only using the baselines\' default hyperparameters. Even ADAM, a supposedly ""hands-free"" optimizer, has been shown to vary greatly in performance when its hyperparameters are well chosen (https://arxiv.org/abs/1705.08292). This is simply unfair to the baselines, and conclusions cannot meaningfully be drawn from this alone. In addition, different tasks use different optimizers, which strikes me as odd, and no error bars are added to any plots.\n\nFrom the theoretical side, the authors show a convergence bound that is minimized when the number of blocks is one. This, however, is not what the authors use in experiments, and no reasoning about the choice of blocks == network layers is given.\n\n## Specific comments ##\n\np1: ""Gradient computation is expensive"" is not a good justification. All empirical risk minimization, convex or not, requires a full pass over the dataset. Many convex problems outside of ERM involve very expensive gradient computations.\n\np1: ""These two challenges indicate that for each iteration, stochastic gradient might be the best practical first order information we can get"". See loads of work in approximate second-order methods that show otherwise! Hessian-free Optimization, K-FAC, Learning to Learn Gradient Descent, ACKTR\'s use of Kronecker-factored Trust Region.\n\np2: You may want to reference Layer-Specific Adaptive Learning Rates for Deep Networks (https://arxiv.org/pdf/1510.04609.pdf), as it appears relevant to the layer-wise nature of your paper.\n\np2: ""Recently, provably correct algorithms..."" I\'m fairly confident that Adam and RMSProp lack provable correctness. You may want to soften this statement.\n\np3: The expression being minimized is the sample risk, rather than the expected risk.\n\np5: The relationship between NG and NG_{UNIT} is confusing. I suggest keeping only the vanilla method analyzed in this paper, or that the second method be better motivated.']","[90, -60, -50]","[80, 20, 50]","[""The sentiment score is 90 (very positive) because the reviewer describes the paper as 'very interesting and important', praises the authors for doing 'a great job', and suggests that their methods 'should be adopted as the new state-of-the-art'. The overall tone is highly supportive and appreciative of the work. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames their additional comments as questions or suggestions rather than criticisms. The reviewer acknowledges the authors' efforts and contributions positively, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is -60 because the reviewer expresses significant criticisms of the paper and ultimately recommends rejection, stating 'I do not feel the quality, originality, and significance of the work to be high enough to merit acceptance.' However, they do acknowledge some positives like clear presentation and extensive testing. The politeness score is 20 because the reviewer uses professional and respectful language throughout, offering constructive feedback and specific suggestions for improvement. They avoid harsh personal criticisms and frame their concerns objectively. The slightly positive politeness score reflects the reviewer's effort to balance criticism with recognition of the paper's strengths, though the overall tone remains critical."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's significance, originality, and methodology. They state that the paper 'fails to provide new insights' and that its significance and originality are 'lacking'. However, the score is not lower because the reviewer does acknowledge some positive aspects, such as the paper being easy to follow and the variety in experimental setups. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, balancing criticism with positive feedback. They use phrases like 'I feel this paper would be much stronger' and 'I appreciate the variety in experimental setups', which soften the criticism. The reviewer also provides specific, constructive feedback without using harsh or dismissive language.""]"
"[""The authors proved that convolutional neural networks with Leaky ReLU activation function are nonlinear frames, and similar results hold for non-uniformly sampled time-series as well. My main concern on this part is that theory is too rough and its link to the later part of the paper is weak. Although frames are stable representations, the ones with lower bound much smaller than the upper bound are close to unstable. That's why in classical applications of frames in signal and image processing tight frames are vastly preferred. Furthermore, the authors did not explicitly state the reliance of the lower frame bound on the parameter alpha in Leaky ReLU. It seems to me that the representation gets more unstable as alpha decreases, and the lower bound will be zero when ReLU is used. \n\nIn Section 2, the authors used CMF conditions to constraint filters which leads to a much more stable representation than in the previous section. The idea is very similar to previous work on data-driven tight frame (Cai et al. Applied & Computational Harmonic Analysis, vol. 37, no. 1, p. 89-105, 2014) and AdaFrame (Tai and E, arXiv:1507.04835). Furthermore, there has been multiple work on introducing tight-frame-like constraints to filters of convolutional neural networks (see for example Huang et al., arXiv:1710.02338). All of these work is not mentioned by the authors. Although the CMF constraints used by the authors seem new, the overall novelty is still weak in my opinion.\n\nThe experimental results are convincing, and the proposed architecture with wavelet-transform LSTM outperform the baseline model using standard LSTM. However, I am not familiar with the state-of-the-art models on the data sets used in the paper. Therefore, I am not certain whether the proposed method achieves state-of-the-art or not. "", 'Pros:\n- combination of wavelets & CNN\n\nCons:\n- lack of motivation\n\nI am not sure to understand the motivation of good reconstruction/homeomorphism w.r.t. the numerical setting or combination with a CNN. (except for the first experiment) ; I give some comments section per section\n\nSection 1:\nDefinition 1.1: why is it squared?\nDefinition 1.3: with this definition, ""the framing constants"" are not unique, so it should be ""some framing constants""\nThere is a critical assumption to have an inverse, which is its stability. In particular, the ratio B/A is the quantity of interest. Indeed, a Gaussian filtering is Bi-Lipschitz-Invertible with this definition, yet, however it is quite hard to obtain the inverse which is not stable (and this is the reason why regularization is required in this inverse problem) Consequently, the assumption that CNNs are full rank does not really help in this setting(you can check the singular values). The conditioning is the good quantity to consider.\n\nThe Proposition 1.4 is trivial to prove, however I do not understand the following: \n""With such vanishing gradients, it is possible to find series of inputsequences that diverge in l2(Z) while their outputs through the RNN are a Cauchy sequence"" \n\nHow would you prove it or do you have some numerical experiments to do so?\n\nSection 2:\nThe figure of the Theorem 2 is not really clear and could be improved. Furthermore, the 1x1 convolutions which follows the conjugate mirror filtering are not necessarily unitary.. This would require some additional constraints.\n\nSubsection2.3: \nThe modulus is missing in the first sentence (on the fourier transform)\n\nSection 3:\nI find great the first experiment (which seems to indicate this particular problem is well conditioned). Nevertheless, the second experiment claims to improve the accuracy of the task while reducing the parameters, however it would be great to understand why there is this improvement. Similarly the last problem is better handled by the haar basis, is it because it permits the NN to learns to denoise or is it a conditioning issue? My guess is that it is because this basis sparsify the input signal, but it would require some additional experiments, in particular to understand how the NN uses it.', 'Summary\n\nThis article considers neural networks over time-series, defined as a succession of convolutions and fully-connected layers with Leaky ReLU activations. The authors provide relatively general conditions for transformations described by such networks to admit a Lipschitz-continuous inverse. They extend these results to the case where the first layer is a convolution with irregular sampling. Finally, they show that the first convolutional filters can be chosen so as to represent a discrete wavelet transform, and provide some numerical experiments.\n\n\nMain remarks\n\nWhile the introduction seemed promising, and I enjoyed the writing style, I was disappointed with this article.\n\n(1) There are many mistakes in the mathematical statements. First, in Theorem 1.1, I do not think that phi_L \\circ ... \\circ phi_1 \\circ F is a non-linear frame, because I do not see why it should be of the form of Definition 1.2 (what would be the functions psi_n?). For the same reason, I also do not understand Theorem 1.2. In Proof 1.4, the line of equalities after « Also with the Plancherel formula » is, in my opinion, not true, because the L^2 norm of a product of functions is not the product of the L^2 norms of the functions. It also seems to me that Theorem 1.3, from [Benedetto, 1992], is incorrect: it is not the limit of t_n/n that must be larger than 2R, but the limit of N_n/n (with N_n the number of t_i\'s that belong to the interval [-n;n]), and there must probably be a compatibility condition between (t_n)_n and R_1, not only between (t_n)_n and R. In Proposition 1.6, I think that the equality should be a strict inequality. Additionally, I do not say that Proof 2.1 is not true, but the fact that the undersampling by a factor 2 does not prevent the operator from being a frame should be justified.\n\n(2) The authors do not justify, in the introduction, why admitting a continuous inverse should be a crucial criterion of quality for the representation described by a neural network. Additionally, the existence of this continous inverse relies on the fact that the non-linearity that is used is a Leaky ReLU, which looks a bit like ""cheating"" to me, because the Lipschitz constant of the inverse of a Leaky ReLU, although finite, is large, so it seems to me that cascading several layers with Leaky ReLUs could encode a transformation with strictly positive, but still very poor frame bounds.\n\n(3) I also do not understand why having ""orthogonal outputs"", as in Section 2, is really desirable; I think that it should be better justified. Also, there are probably other ways to achieve orthogonality than using wavelets in the first layer, so the fact that wavelets achieve orthogonality does not really justify why using wavelets in the first layer is a good choice, compared to other filters.\n\n(4) I had understood in the introduction that the authors would explain how to define a (good) deep representation for data of the form (x_n)_{n\\in\\N}, where each x_n would be the value of a time series at instant t_n, with the t_n non-uniformly spaced. But all the representations considered in the article seem to be applicable to functions in L^2(\\R) only (like in Theorem 1.4 and Theorem 2.2), and not to sequences (x_n)_{n\\in\\N}. There is something that I did not get here.\n\n\nMinor remarks\n\n- Fourth paragraph, third line: ""this generalization frames""?\n- Last paragraph before ""Contributions & Organization"": ""that that"".\n- Paragraph about notations: it seems to me that what is defined as l^2(R) is denoted as l^2(Z) after the introduction.\n- Last line of this paragraph: R^d_1 should be R^{d_1}, and R^d_2 R^{d_2}.\n- I think ""smooth"" could be replaced by ""continuous"" (smoothness implies a notion of differentiability).\n- Paragraph before Proposition 1.1: \\sqrt{s} is not defined, and ""is supported"" should be ""are supported"".\n- Theorem 1.1: the f_k should be phi_k.\n- Definition 1.4: ""piece-linear"" -> ""piecewise linear""?\n- Lemma 1.2 and Proof 1.4: there are indices missing to \\tilde h and \\tilde g.\n- Proof 1.4: ""and finally"" -> ""And finally"".\n- Proof 1.5: I do not understand the grammatical structure of the second sentence.\n- Proposition 1.4: the definition of a RNN is the same as definition 1.2 (except for the frame bounds); I do not see why such transformations should model RNNs.\n- Paragraph before Proposition 1.5: ""in,formation"".\n- Proposition 1.6: it should be said on which space the frame is injective.\n- On page 8, ""Lipschitz"" is erroneously written (twice).\n- Proposition 1.7: ""ProjW,l""?\n- Definition 2.1: in the ""nested"" property, I think that the inclusion should be the other way around.\n- Before Theorem 2.1, the sentence ""Such Riesz basis is proven"" is unclear to me.\n- Theorem 2.1: ""filters convolution filters"".\n- I think the architecture described in Theorem 2.2 could be clarified; I am not exactly sure where all the arrows start from.\n- First line of Subsection 2.3: "". is always"" -> ""is always"".\n- First paragraph of Subsection 3.2: ""the the"".\n- Paragraph 3.2: could the previous algorithms developed for this dataset be described in slightly more detail? I also do not understand the meaning of ""must solely leverage the temporal structure"".\n- I think that the section about numerical experiments could be slightly rewritten, so that the architecture used in each experiment is clearer. In Paragraph 3.2 in particular, I did not get why the architecture presented in Figure 6 has far fewer parameters than the one in Figure 5; it would help if the authors clearly precised how many parameters each layer contains.\n- Conclusion: ""we can to"" -> ""we can"".\n- Definition 4.1: p_v(s) -> p_v(t).']","[-30, -30, -60]","[50, 20, 20]","['The sentiment score is -30 because the reviewer expresses several concerns and criticisms, particularly about the novelty and theoretical aspects of the work. However, they also acknowledge some positive aspects, such as convincing experimental results. The overall tone is more negative than positive, but not extremely negative. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh or rude expressions. They present their criticisms constructively and acknowledge the strengths of the work. The reviewer maintains a balanced and objective tone, which is polite in academic discourse, even when expressing concerns.', ""The sentiment score is -30 because the review is generally critical, pointing out several cons and areas for improvement. However, it's not entirely negative as it acknowledges some pros and finds some aspects 'great'. The politeness score is 20 because the reviewer uses polite language and phrases like 'I am not sure to understand' and 'it would be great to understand', showing respect for the authors. The reviewer also provides constructive feedback and suggestions rather than harsh criticism. The tone is professional and academic throughout, maintaining a respectful discourse even when pointing out issues."", ""The sentiment score is -60 because the reviewer expresses disappointment with the article and lists numerous criticisms and errors, indicating a largely negative view. However, they do mention enjoying the writing style, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I do not think' and 'I was disappointed' rather than harsh language. They also provide detailed explanations for their criticisms, which is constructive. The slightly positive score reflects that the reviewer is more polite than merely neutral, but not excessively formal or deferential.""]"
"['This paper proposed to learn a generative GAN model that generates the training data from the labels, given that only the black-box mapping $f$ from data to label is available, as well as an aux dataset that might and might not overlap with the training set. This approach can be regarded as a transfer learning version of ACGAN that generates data conditioned on its label.\n\nOverall I feel it unclear to judge whether this paper has made substantial contributions. The performance critically relies on the structure of aux dataset and how the supervised model $f$ interacts with it. It would be great if the author could show how the aux dataset is partitioned according to the function $f, and what is the representative sample from aux dataset that maximizes a given class label. In Fig. 4, the face of Leonardo DiCaprio was reconstructed successfully, but is that because in the aux dataset there are other identities who look very similar to him and is classified as Leonardo, or it is because GAN has the magic to stitch characteristics of different face identities together?  Given the current version of the paper, it is not clear at all. From the results on EMNIST when the aux set and the training set are disjoint, the proposed model simply picks the most similar shapes as GAN generation, and is not that interesting. In summary, a lot of ablation experiments are needed for readers to understand the proposed method better.\n\nThe writing is ok but a bit redundant. For example, Eqn. 1 (and Eqn. 2) which shows the overall distribution of the training samples (and aux samples) as a linear combinations of the samples at each class, are not involved in the method. Do we really need Eqn. 1 and 2?', 'This paper considers a new problem : given a classifier f trained from D_tr and a set of auxillary samples from D_aux, find D_tr conditioned on label t*. Its solution is based on a new GAN: preImageGAN. Three settings of the similarity between auxillary distribution and training distribution is considered: exact same, partly same, mutually exclusive. Experiments show promising results in generating examples from the original training distribution, even in the ""mutually exclusive"" setting.\n\nQuality: \n1. It is unclear to me if the generated distribution in the experiments is similar to the original distribution D_tr given y = t^*, either from inception accuracy or from pictorial illustration. Since we have hold out the training data, perhaps we can measure the distance between the generated distribution and D_tr given y = t^* directly.\n\n2. It would be great if we can provide experiments quantifying the utility of the auxillary examples. For example, when they are completely noise, can we still get sensible generation of images? \n\n3. How does the experimental result of this approach compare with model attack? For example, we can imagine generating labels by e_t^* + epsilon, where epsilon is random noise. If we invert these random labels, do we get a distribution of examples from class t^*?\n\nClarity:\n1. I think the key here is to first generate auxillary labels (as in Figure 2), then solve optimization problem (3) - this causes my confusion at first sight. (My first impression is that all labels, training or auxillary, are one-hot encoding - but this makes no sense since the dimension of f and y_aux does not match.)\n\nOriginality: I am not familiar with relevant literature - and I think the GAN formulation here is original.\n\nSignificance: I see this as a nice step towards inferring training data from trained classifiers. \n\n', 'The paper proposes the use of a GAN to learn the distribution of image classes from an existing classifier, that is a nice and straightforward idea. From the point of view of forensic analysis of a classifier, it supposes a more principled strategy than a brute force attack based on the classification of a database and some conditional density estimation of some intermediate image features. Unfortunately, the experiments are inconclusive.  \n\nQuality: The key question of the proposed scheme is the role of the auxiliary dataset. In the EMNIST experiment, the results for the “exact same” and “partly same” situations are good, but it seems that for the “mutually exclusive” situation the generated samples look like letters, not numbers, and raises the question on the interpolation ability of the generator. In the FaceScrub experiment is even more difficult to interpret the results, basically because we do not even know the full list of person identities. It seems that generated images contain only parts of the auxiliary images related to the most discriminative features of the given classifier. Does this imply that the GAN models a biased probability distribution of the image class? What is the result when the auxiliary dataset comes from a different kind of images? Due to the difficulty of evaluating GAN results, more experiments are needed to determine the quality and significance of this work.\n\nClarity: The paper is well structured and written, but Sections 1-4 could be significantly shorter to leave more space to additional and more conclusive experiments. Some typos on Appendix A should be corrected.\n\nOriginality: the paper is based on a very smart and interesting idea and a straightforward use of GANs. \n\nSignificance: If additional simulations confirm the author’s claims, this work can represent a significant contribution to the forensic analysis of discriminative classifiers.\n']","[-30, 60, -20]","[20, 70, 50]","[""The sentiment score is -30 because the reviewer expresses uncertainty about the paper's contributions and points out several areas needing clarification or improvement. However, it's not entirely negative as they acknowledge some successful aspects. The politeness score is 20 because the language is generally respectful and constructive, using phrases like 'it would be great if' and 'Overall I feel' to soften criticisms. The reviewer offers specific suggestions for improvement rather than outright dismissal. The slightly positive politeness score reflects the professional and considerate tone, despite the critical content."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting its originality, significance, and promising results. They describe it as a 'nice step' and mention 'promising results'. However, they also raise some questions and suggest improvements, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They phrase their suggestions as 'It would be great if...' and 'How does...', which are polite ways of requesting more information or suggesting improvements. The reviewer also acknowledges their own potential lack of knowledge ('I am not familiar with relevant literature') rather than criticizing the authors, which is a polite approach. The overall tone is professional and courteous, without being overly formal or effusive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's 'nice and straightforward idea' and potential significance, they also state that 'the experiments are inconclusive' and that 'more experiments are needed'. The review highlights several concerns and limitations, indicating a somewhat critical stance overall. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positive aspects ('well structured and written', 'very smart and interesting idea') alongside criticisms. They offer constructive feedback and suggestions rather than harsh criticism. The tone is professional and balanced, maintaining politeness while expressing concerns.""]"
"['This paper introduces a reversible network with absolute value used as\nthe activation function.  The network is run in the forward direction\nto classify and in the reverse direction to generate.\n\nThe key points of the network are the use of the absolute value\nactivation function and the use of (free) normalization to match\ntarget output. This allows the network to perfectly map inputs to any\npoint on a vector that goes through the one-hot encoding, allowing for\ndeterministic generation from different vectors (of different lengths)\nwith the same normalized output.\n\nI think there are a lot of novel and interesting ideas in this paper\nthough they have not been fully explored.  The use of the absolute\nvalue transfer function is new to me, though I was able to find a couple of old\nreferences to its use.   In a paper by Gad et al. (2000), it is stated \n"" For example, the algorithm presented in Lin and\nUnbehauen (1995) < I think they mean Lin and Unbehauen 1990)> \n is used to train networks with a single hidden layer\nemploying the absolute value as the activation function of the hidden\nneuron. This algorithm was further generalized to multilayer networks\nwith cascaded structures in Batruni (1991).""   Exploring the properties \nof the abs activation function seems worth exploring.\n\nMore details on the training are needed for full clarity in the paper.\n(Though it is recognized that some of these could be determined from\nlinks when made active, they should be included in the paper).  How\ndid you select the training parameters given at the bottom of page 5?\nHow many layers and units/layer did you use? And how were these\nselected?  (The use of the links for providing code and visualizations (when active)\n is a nice feature of this paper).\n\nAlso, did you compare to using the leaky ReLU activation function --\nThat would be interesting as it also doesn\'t have any areas of zero\nslope?  Did you compare the generated digits to those obtained using GANs?\n\nI am also curious, how does accuracy on digit classification differ\nwhen trained only to optimize the forward error?\n\nThe MNIST site referenced lists 60,000 training data and test data of\n10,000.  How/why did you select 42,000 and then split it to 39900 in\nthe train set and 2100 in the dev set?\n\nAlso, the goal for the paper is presented as creating highly\ninterpretable representations of the input data.  My interpretation of\ninterpretable is that the hidden units are ""interpretable"" and that it\nis clear how the combined hidden unit representations allow for\naccurate classification.  Towards that end, it would be nice to see\nsome of the interpretations of the hidden unit representations.  In\nthe abstract it states "" ...These representations are generated by\npenalizing the learning of the network in such a way that those\nlearned representations correspond to the respective labels present in\nthe labelled dataset used for supervised training"".  Does this\nstatement refer only to the encoding of the representation vector or\nalso the hidden layers?  If the former, isn\'t that true for all\nsupervised algorithms.  If the latter, you should show this.\n\nBatruni, R. (1991). A multilayer neural network with piecewise-linear\nstructure and backpropagation learning. IEEE Transactions on Neural\nNetworks, 2, 395–403.\n\nLin, J.-N., & Unbehauen, R. (1995). Canonical piecewise-linear neural\nnetworks. IEEE Transactions on Neural Networks, 6, 43–50.\n\nLin, J.-N, & Unbehauen, R. (1990). Adaptive Nonlinear Digital Filter with Canonical Piecewise-Linear Structure,\nIEEE Transactions on Circuits and Systems, 37(3) 347-353.\n\nGad, E.F et al (2000). A new algorithm for learning in piecewise-linear neural networks.\nNeural Networks 13,  485-505.\n', 'The paper proposes using the absolute value activation function in (what seems to be) an autoencoder architecture with an additional supervised learning term in the objective function that encourages the bottleneck layer representation to be discriminative. A few examples of reconstructed images and classification performance are reported for the MNIST dataset.\n\nThe contribution of the paper is not clear. The idea of combining autoencoders with supervised learning has been explored before, see e.g., ""Learning Deep Architectures for AI"" by Bengio, 2009, and many other papers. Alternative activation functions have also been studied in many papers, see https://arxiv.org/pdf/1710.05941.pdf for a recent example. Even without novel algorithmic contributions, the paper would have been interesting if there was an extensive evaluation across several challenging datasets of different ways of combining autoencoders with supervised learning and different activation functions that gives better insight into what works and why.\n\nIt would be helpful not to introduce new terminology like ""bidirectional artificial neuron"" unless there is a significant difference from existing concepts. It is not clear from the paper how a network of bidirectional neurons is different from an autoencoder.', 'SUMMARY \n\nThe model is an ANN whose units have the absolute value function abs as their activation function (in place of ReLU, sigmoid, etc.). The network has bi-directional connections (with equal weights) between consecutive layers, but it operates only in one direction at a time. In the forward direction, it is a feed-forward net from image to classification (say); in the reverse direction, it is a feed-forward net from classification to image. In both directions it operates in supervised fashion, trained with backpropagation (subject to the constraint that the weight matrix is symmetric). In the forward direction, the activation vector y over the classification layer is L2-normalized so the activation of a class c is the cosine of the angle between y and the 1-hot vector for c.\nAlthough there is a reverse pass through the net, the training loss function is not adversarial; the loss is just the classification error in the forward pass plus the reconstruction error in the backward pass.\nThe generalization accuracy in classification on 42k-image MNIST is 97.4%.\n\nSTRENGTHS\n\n* Comparisons are made of the reconstruction performance with the proposed abs activation function and with ReLU on one or both passes, and a linear activation function.\n* The model has the virtue of simplicity, as the authors point out.\n\nWEAKNESSES\n\n* The discussion of evaluation of the model is weak. \n  - No baselines are given. (A kaggle leaderboard shows the 50th-ranked model at 97.8% and the top 8 models at 100%.)\n  - The paper talks of a training set and a ""dev"" set, but no test set, and generalization performance is given for the dev set rather than a test set.\n  - No quantitative evaluation of the reconstruction (backward pass) performance is given, just by-eye comparison of the reconstruction error through figures.\n  - Some explanation is needed of why the ReLU cases were fatally plagued with NaN errors.\n* Claims of interpretability advantage seem unwarranted since the claimed interpretability applies to any classification ANN, as far as I can see.\n* The work seems to be at too preliminary a stage to warrant acceptance at ICLR.']","[50, -50, -60]","[80, 50, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges 'novel and interesting ideas' in the paper, while also pointing out areas that need more exploration or clarification. The overall tone is constructive rather than critical. The politeness score is 80 (quite polite) due to the use of respectful language throughout. The reviewer uses phrases like 'I think,' 'I am curious,' and 'it would be nice to see,' which soften critiques and suggestions. They also acknowledge positive aspects of the paper, such as the 'nice feature' of including links for code and visualizations. The reviewer asks questions and makes suggestions in a non-confrontational manner, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's contribution and novelty. They state that the paper's main ideas have been explored before and that the contribution is not clear. However, it's not entirely negative as they suggest ways the paper could have been more interesting. The politeness score is 50 because the reviewer uses professional and constructive language throughout. They offer suggestions for improvement and provide specific references to support their points, which is helpful and respectful. The tone is critical but not harsh or rude, maintaining a balance between pointing out weaknesses and offering constructive feedback."", ""The sentiment score is -60 because the review is predominantly negative. While it acknowledges some strengths ('virtue of simplicity', comparisons made), the weaknesses section is much more extensive and critical. The reviewer states the work is 'too preliminary' for acceptance, which is a strong negative sentiment. The politeness score is 20 because the language is professional and not overtly rude, but it's also not particularly warm or encouraging. The reviewer uses neutral language like 'weaknesses' and 'no baselines are given' rather than harsh criticism. However, the overall tone is more matter-of-fact than polite, hence the slightly positive but close to neutral score.""]"
"['The paper attempts to extend the predictive coding model to a multilayer network.  The math is developed for a learning rule, and some demonstrations are shown for reconstructions of CIFAR-10 images.\n\nThe overall idea and approach being pursued here is a good one, but the model needs further development.  It could also use better theoretical motivation - i.e., what sorts of representations do you expect to emerge in higher layers?  Can you demonstrate this with a toy example and then extend to real data?\n\nThat the model can reconstruct images per se is not particularly interesting.  What we would like to see is that it has somehow learned a more useful or meaningful representation of the data.  For example, what do the learned weights look like?  That would tell you something about what has been learned.\n', 'The paper ""A Deep Predictive Coding Network for Learning Latent Representations"" considers learning of a generative neural network. The network learns unsupervised using a predictive coding setup. A subset of the CIFAR-10 image database (1000 images horses and ships) are used for training. Then images generated using the latent representations inferred on these images, on translated images, and on images of other objects are shown. It is then claimed that the generated images show that the network has learned good latent representations.\n\nI have some concerns about the paper, maybe most notably about the experimental result and the conclusions drawn from them. The numerical experiments are motivated as a way to ""understand the capacity of the network with regards to modeling the external environment"" (abstract). And it is concluded in the final three sentences of the paper that the presented network ""can infer effective latent representations for images of other objects"" (i.e., of objects that have not been used for training); and further, that ""in this regards, the network is better than most existing algorithms [...]"".\n\nI expected the numerical experiments to show results instructive about what representations or what abstractions are learned in the different layers of the network using the learning algorithm and objectives suggested. Also some at least quantifiable (if not benchmarked) outcomes should have been presented given the rather strong claims/conclusions in abstract and discussion/conclusion sections. As a matter of fact, all images shown (including those in the appendix) are blurred versions of the original images, except of one single image: Fig. 4 last row, 2nd image (and that is not commented on). If these are the generated images, then some reconstruction is done by the network, fine, but also not unsurprising as the network was told to do so by the used objective function. What precisely do we learn here? I would have expected the presentation of experimental results to facilitate the development of an understanding of the computations going on in the trained network. How can the reader conclude any functioning from these images? Using the right objective function, reconstructions can also be obtained using random (not learned) generative fields and relatively basic models. The fact that image reconstruction for shifted images or new images is evidence for a sophisticated latent representations is, to my mind, not at all shown here. What would be a good measure for an ""effective latent representation"" that substantiates the claims made? The reconstruction of unseen images is claimed central but as far as I could see, Figures 2, 3, and 4 are not even referred to in the text, nor is there any objective measure discussed. Studying the relation between predictive coding and deep learning makes sense, but I do not come to the same (strong) conclusions as the author(s) by considering the experimental results - and I do not see evidence for a sophisticated latent representation learned by the network. I am not saying that there is none, but I do not see how the presented experimental results show evidence for this.\n\nFurthermore, the authors stress that a main distinguishing feature of their approach (top of page 3) is that in their network information flows from latent space to observed space (e.g. in contrast to CNNs). That is a true statement but also one which is true for basically all generative models, e.g., of standard directed graphical models such as wake-sleep approaches (Hinton et al., 1995), deep SBNs and more recent generative models used in GANs (Goodfellow et al, 2014). Any of these references would have made a lot of sense.\n\nWith my evaluation I do not want to be discouraging about the general approach. But I can not at all give a good evaluation given the current experimental results (unless substantial new evidence which make me evaluate these results differently is provided in a discussion).\n\n\nMinor:\n\n- no legend for Fig. 1\n\n-notes -> noted\n\nhave focused\n\n\n\n\n', 'Quality\n\nThe authors introduce a deep network for predictive coding. It is unclear how the approach improves on the original predictive coding formulation of Rao and Ballard, who also use a hierarchy of transformations. The results seem to indicate that all layers are basically performing the same. No insight is provided about the kinds of filters that are learned.\n\nClarity\n\nIn its present form it is hard to assess if there are benefits to the current formulation compared to already existing formulations. The paper should be checked for typos.\n\nOriginality\n\nThere exist alternative deep predictive coding models such as https://arxiv.org/abs/1605.08104. This work should be discussed and compared.\n\nSignificance \n\nIt is hard to see how the present paper improves on classical or alternative (deep) predictive coding results.\n\nPros\n\nRelevant attempt to develop new predictive coding architectures\n\nCons\n\nUnclear what is gained compared to existing work.']","[-20, -70, -50]","[50, 20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the overall idea and approach are good, they express that the model needs further development and better theoretical motivation. The reviewer also states that the current results (image reconstruction) are not particularly interesting, indicating a desire for more meaningful demonstrations. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the potential of the work while providing constructive criticism. They use phrases like 'The overall idea and approach being pursued here is a good one' and frame their suggestions as questions or recommendations rather than harsh criticisms."", ""The sentiment score is -70 because the reviewer expresses significant concerns about the paper, particularly regarding the experimental results and conclusions. The reviewer states that they 'have some concerns about the paper' and that they 'can not at all give a good evaluation given the current experimental results.' They also question the validity of the authors' claims and the evidence presented. However, it's not entirely negative as the reviewer acknowledges that 'studying the relation between predictive coding and deep learning makes sense.'\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'I expected,' 'I would have expected,' and 'To my mind,' which soften the criticism. The reviewer also states that they don't want to be 'discouraging about the general approach,' showing consideration for the authors' work. However, the criticism is direct and substantial, which prevents the score from being higher on the politeness scale."", ""The sentiment score is -50 because the review is generally critical, pointing out several shortcomings of the paper without many positive remarks. The reviewer questions the improvement over existing work, the lack of insights provided, and the difficulty in assessing benefits. However, it's not entirely negative as it acknowledges the relevance of the attempt. The politeness score is 20 because while the language is not overtly polite, it maintains a professional and constructive tone. The reviewer uses phrases like 'it is unclear' and 'it is hard to see' rather than direct criticisms, and provides specific recommendations for improvement. The review also includes a 'Pros' section, which shows an attempt at balance.""]"
"[""In the centre loss, the centre is learned. Now it's calculated as the average of the last layer's features\nTo enable training with SGD, the authors calculate the centre within a mini batch"", 'The paper studies the problem of DNN loss function design for reducing intra-class variance in the output feature space. The key contribution is proposing an isotropic variant of the softmax loss that can balance the accuracy of classification and compactness of individual class. The proposed loss has been compared extensively against a number of closely related approaches in methodology. Numerical results on benchmark datasets show some improvement of the proposed loss over softmax loss and center loss (Wen et al., 2016), when applied to distance-based classifiers such as k-NN and k-means. \n\nPros: \n\n- The idea of isotropic normalization for enhancing compactness of class is well motivated\n\n- The paper is mostly clearly organized and presented.\n\n- Numerical study shows some promise of the proposed method.\n\nCons:\n\n-  The novelty of method is mostly incremental given the prior work of (Wen et al., 2016) which has provided a slightly different isotropic variant of softmax loss.\n\n- The training procedure of the proposed method remains unclear in this paper. \n\n\n', 'After the rebuttal:\n\nI do not think I had a major misunderstanding of the paper. I was aware that the features mostly refers to the inputs to softmax. In my point 4, I was suggesting that in order to have clustering performance, one might alternatively work on the softmax outputs instead of the inputs.\n\nMy opinion on this paper remains, and I think the contribution of this paper to machine learning is not very clearer at the current stage. It might be the case that the considered scenarios indeed happen in computer vision related problems, but I am not an expert in that regard.\n\n========================================================================\n\nThis paper proposes a regularization to the softmax layer, which try to make the distribution of feature representation (inputs fed to the softmax layer) more meaningful according to the Euclidean distance. The proposed isotropic loss in equation 3 tries to equalize the squared distances from each point to the mean, so the features are encouraged to lie close to a sphere. Overall, the proposed method is a relatively simple tweak to softmax. The authors show that empirically, features learned under softmax loss + isotropic regularization outperforms other features in Euclidean metric-based tasks.\n\nMy main concern with this paper is the motivation: what are the practical scenarios in which one would want to used proposed method?\n1. It is true that features learned with the pure softmax loss may not presents the ideal  similarity under the  Euclidean metric (e.g. the problem depicted in Figure 1),  because they are not trained to do so: their purpose is just to predict the correct label.  While the proposed regularization does lead to a nicer Euclidean geometry, there is not sufficient motivation and evidence showing this regularization improves classification accuracy.\n\n2. In table 2, the authors seem to indicate that not using the label information in the definition of Isotropic loss is an advantage. But this does not matter since you already use the labels in the softmax loss.\n\n3. I can not easily think of scenarios in which, we would like to perform KNN in the feature space (Table 3) after training a softmax layer. In fact, Table 3 shows KNN is almost always worse than softmax in terms of classification accuracy. \n\n4. Running kmeans or agglomerative clustering in the feature space (Table 5) *using the Euclidean metric* is again ill-posed, because the softmax layer is not trained to do this. If one really wants good clustering performance, one shall always try to learn a good metric, or , why do not you perform clustering on the softmax output (a probability vector?)\n\n5.  The experiments on adversarial robustness and face verification seems more interesting to me, but the tasks were not carefully explained for someone not familiar with that literature. Perhaps for these tasks, multi-class classification is not the most correct objective, and maybe the proposed regularization can help, but the motivations are not given. \n\n\n\n']","[0, 50, -50]","[0, 75, 20]","['The review is very brief and factual, making it difficult to discern any clear sentiment or level of politeness. The reviewer simply states what the authors have done in their work without offering any evaluation or judgment. The language is neutral and matter-of-fact, neither particularly positive nor negative, and neither polite nor impolite. The lack of any evaluative comments, suggestions, or criticisms contributes to the neutral scores in both sentiment and politeness.', ""The sentiment score is 50 (slightly positive) because the review begins with a neutral summary of the paper's content, followed by a balanced list of pros and cons. The pros highlight the paper's strengths, such as well-motivated ideas and clear organization, while the cons point out areas for improvement without being overly critical. This balanced approach suggests a moderately positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses professional and respectful language throughout. They acknowledge the paper's contributions and strengths before presenting criticisms, which are framed constructively as 'cons' rather than direct attacks. The reviewer also uses phrases like 'well motivated' and 'shows some promise,' which maintain a positive and encouraging tone even when discussing limitations."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's motivation and practical applicability. They state that the 'contribution of this paper to machine learning is not very clear at the current stage' and raise several critical points about the method's usefulness. However, they do acknowledge some positive aspects, such as the empirical improvements in certain tasks, which prevents the score from being more negative. The politeness score is 20 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'I do not think' and 'My opinion' rather than making harsh statements. They also acknowledge their potential lack of expertise in certain areas. However, the critique is direct and doesn't use overly polite language, keeping the score only slightly positive.""]"
"['`The papers aims to provide a quality measure/test for GANs.   The objective is ambitious an deserve attention. As GANs are minimizing some f-divergence measure, the papers remarks that computing a  Wasserstein distance between two distributions made of a sum of Diracs is not a degenerate case and is tractable. So they propose evaluate the current approximation of a distribution learnt by a GAN by using this distance as a baseline performance (in terms of W distance and computed on a hold out dataset). \n\nA first remark is that the papers does not clearly develop the interest of puting things a trying to reach a treshold of performance in W distance rather than just trying to minimize the desired f-divergence. More specifically as they assess the performance in terms of W distance I would would be tempted to just minimize the given criterion. This would be very interesting to have arguments on why being better than the ""Dirac estimation"" in terms of W2 distance would lead to better performance for others tasks (as other f-divergences or image generation).\n\nAccording to the authors the core claims are:\n""1/ We suggest a formalisation of the goal of GAN training (/generative modelling more broadly) in terms of divergence minimisation. This leads to a natural, testable notion of generalisation. ""\nFormalization in terms of divergence minimization is not new (see O. Bousquet & all https://arxiv.org/pdf/1701.02386.pdf ) and I do not feel like this paper actually performs any ""test"" (in a statistical sense). In my opinion the contribution is more about exhibiting a baseline which has to be defeated for any algorithm interesting is learning the distribution in terms of W2 distance.\n\n""2/ We use this test to evaluate the success of GAN algorithms empirically, with the Wasserstein distance as our divergence.""\nHere the distance does not seems so good because the performance in generation does not seems to only be related to W2 distance. Nevertheless, there is interesting observations in the paper about the sensitivity of this metric to the bluring of pictures. I would enjoyed more digging in this direction. The authors proposes to solve this issue by relying to an embedded space where the L2 distance makes more sense for pictures (DenseNet). This is of course very reasonable but I would expect anyone working on distribution over picture to work with such embeddings. Here I\'m not sure if this papers opens a new way to improve the embedding making use on non labelled data. One could think about allowing the weights of the embeddings to vary while f-divergence is minimized but this is not done in the submitted work.\n\n ""3/ We find that whether our proposed test matches our intuitive sense of GAN quality depends heavily on the ground metric used for the Wasserstein distance.""\nThis claim is highly biased by who is giving the ""intuitive sense"". It would be much better evaluated thought a mechanical turk test.\n\n ""4/ We discuss how to use these insights to improve the design of WGANs more generally.""\nAs our understanding of the GANs dynamics are very coarse, I feel this is not a good thing to claim that ""doing xxx should improve things"" without actually trying it. \n', 'The quality of the paper is good, and clarity is mostly good. The proposed metric is interesting, but it is hard to judge the significance without more thorough experiments demonstrating that it works in practice.\n\nPros:\n - clear definitions of terms\n - overall outline of paper is good\n - novel metric\n\nCons\n - text is a bit over-wordy, and flow/meaning sometimes get lost. A strict editor would be helpful, because the underlying content is good\n - odd that your definition of generalization in GANs appears immediately preceding the section titled ""Generalisation in GANs""\n - the paragraph at the end of the ""Generalisation in GANs"" section is confusing. I think this section and the previous (""The objective of unsupervised learning"") could be combined, removing some repetition, adding some subtitles to improve clarity. This would cut down the text a bit to make space for more experiments.\n - why is your definition of generalization that the test set distance is strictly less than training set ? I would think this should be less-than-or-equal\n - there is a sentence that doesn\'t end at the top of p.3: ""... the original GAN paper showed that [ends here]""\n - should state in the abstract what your ""notion of generalization"" for gans is, instead of being vague about it\n - more experiments showing a comparison of the proposed metric to others (e.g. inception score, Mturk assessments of sample quality, etc.) would be necessary to find the metric convincing\n - what is a ""pushforward measure""? (p.2)\n - the related work section is well-written and interesting, but it\'s a bit odd to have it at the end. Earlier in the work (e.g. before experiments and discussion) would allow the comparison with MMD to inform the context of the introduction\n - there are some errors in figures that I think were all mentioned by previous commentators.', 'This paper proposed a procedure for assessing the performance of GANs by re-considering the key of observation. And using the procedure to test and improve current version of GANs. It demonstrated some interesting stuff. \n\nIt is not easy to follow the main idea of the paper. The paper just told difference stories section by section. Based on my understanding, the claims are 1) the new formalization of the goal of GAN training and 2) using this test to evaluate the success of GAN algorithms empirically?  I suggested that the author should reform the structure, ignore some unrelated content and make the clear claims about the contributions on the introduction part.  \n\nRegarding the experimental part, it can not make strong support for all the claims. Figure 2 showed almost similar plots for all the varieties. Meanwhile, the results are performed on some specific model configurations (like ResNet) and settings. It is difficult to justify whether it can generalize to other cases. Some of the figures do not have the notations of curvey, making people hard to compare. \n\nTherefore, I think the current version is not ready to be published. The author can make it stronger and consider next venue. ']","[-20, 20, -50]","[50, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the ambitious nature of the paper's objective, they express several criticisms and doubts about the claims and methods. The reviewer questions the novelty of the approach, the effectiveness of the proposed test, and the validity of some claims. However, they do note some interesting observations and potential for improvement, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I would enjoyed more digging in this direction' and 'This is of course very reasonable,' which indicate a constructive approach. The reviewer also offers suggestions for improvement rather than outright dismissal. However, the score is not higher as there are some direct criticisms and the tone, while not impolite, is not overly warm or encouraging either."", ""The sentiment score is slightly positive (20) because the reviewer starts by saying 'The quality of the paper is good' and mentions several pros, including 'clear definitions', 'good overall outline', and 'novel metric'. However, the score is not higher due to the numerous cons listed and the statement that 'it is hard to judge the significance without more thorough experiments'. The politeness score is moderately positive (50) as the reviewer uses neutral language and provides constructive feedback. They balance positive comments with areas for improvement, and use phrases like 'it's a bit odd' rather than harsh criticism. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback."", ""The sentiment score is -50 because the review is generally negative, stating that the paper is 'not ready to be published' and suggesting the authors 'consider next venue'. However, it's not entirely negative as it acknowledges some 'interesting stuff' and provides constructive feedback. The politeness score is 20 because the reviewer uses relatively polite language, offering suggestions rather than harsh criticisms. Phrases like 'I suggested' and 'The author can make it stronger' indicate a constructive tone. However, the politeness is not extremely high, as the review is direct in pointing out flaws without much softening language.""]"
"['The authors propose a first implementation of spiking LSTMs. This is an interesting and open problem. However, the present work somewhat incomplete, and requires further experiments and clarifications.\n\nPros:\n1. To my best knowledge, this is the first mapping of LSTMs to spiking networks\n2. The authors tackle an interesting and challenging problem.\n\nCons:\n1. In the abstract the authors mention that another approach has been taken, but is never stated what’s the problem that this new one is trying to address. Also, H&S 1997 tested several tasks, which is the one that the authors are referring to?\n2. Figure 1 is not very easy to read. The authors can spell out the labels of the axis (e.g. S could be input, S)\n3. Why are output and forget gates not considered here?\n4. A major point in mapping LSTMs to spiking networks is its biological plausibility. However, the authors do not seem to explore this. Of particular interest is its relationship to a recent proposal of a cortical implementation of LSTMs (Cortical microcircuits as gated-RNNs, NIPS 2017).\n5. The text should be improved, for example in the abstract: “that almost all resulting spiking neural network equivalents correctly..”, please rephrase.\n6. Current LSTMs are applied in much more challenging problems than the original ones. It would be important to test one of this, perhaps the relatively simple pixel-by-pixel MNIST task. If this is not feasible, please comment.\n\nMinor comments:\n1. Change in the abstract “can be substituted for” > “can be substituted by”\n2. A new body of research aims at using backprop in spiking RNNs (e.g. Friedemann and Ganguli 2017). The present work gets around this by training the analog version instead. It would be of interesting to discuss how to train spiking-LSTMs as this is an important topic for future research. \n3. As the main promise of using spiking nets (instead of rate) is their potential efficiency in neuromorphic systems, it would be interesting to contrast in the text the two options for LSTMs, and give some more quantitative analyses on the gain of spiking-LSTM versus rate-LSTMs in terms of efficiency.', 'First the authors suggest an adaptive analog neuron (AAN) model which can be trained by back-propagation and then mapped to an Adaptive Spiking Neuron (ASN). Second, the authors suggest a network module called Adaptive Analog LSTM Cell (AA-LSTM) which contains input cells, input gates, constant error carousels (CEC) and output cells. Jointly with the AA-LSTM, the authors describe a spiking model (AS-LSTM) that is meant to reproduce its transfer function. It is shown quantitatively that the transfer functions of isolated AAN and AA-LSTM units are well approximated by their spiking counterparts. Two sets of experiments are reported, a sequence prediction task taken from the original LSTM paper and a T-maze task solved with reward based learning.\n\nIn general, the paper presents an interesting idea. However, it seems that the main claims of the introduction are not sufficiently well proven later. Also, I believe that the tasks are rather simple and therefore it is not demonstrated that the approach performs well on practically relevant tasks.\n\nOn general level, it should be clarified whether the model is meant to reproduce features of biology or whether the model is meant to be efficient. If the model is meant to reproduce biology, some features of the model are problematic. In particular, that the CEC is modeled with an infinitely long integration time constant of the input current. This would produce infinitely long EPSPs. However, I think there is a chance that minor changes of the model could still work while being more realistic. For example, I would find it more convincing to put the CEC into the adaptation time constants by using a large tau_gamma or tau_eta.\n\nIf the model is meant to provide efficient spiking neural networks, I find the tasks too simple and too artificial. This is particularly true in comparison to the speech recognition tasks VAD and TIMIT which were already solved in Esser et al. with spiking and efficient feedforward networks. \n\nThe authors say in the introduction that they target to model recurrent neural networks. This is an important open question. The usage of the CEC is an interesting idea toward this goal.\nHowever, beside the presence of CEC I do not see any recurrence in the used networks. This seems in contradiction with what is implicitly claimed in the introduction, title and abstract. There are only input-output neuron connections in the sequence prediction task, and a single hidden layer for the T-maze (which does not seem to be recurrently connected). This is problematic as the authors mention that their goal is to reproduce the functionality of LSTMs with spiking neurons for which the network recurrence is an important feature. \n\n\nRegarding more low-level comments:\n\n- The authors used a truncated version of RTRL to train LSTMs and standard back-propagation for single neurons. I wonder why two different algorithms were used, as, in principle, they compute the same gradient\neither forward or backward.\nIs there a reason for this? Did the truncated RTRL bring any\nadditional benefit compared to the exact backpropagation already\nimplemented in automatic differentiation software?\n\n- The sigma-delta neuron model seems quite ad-hoc and incompatible\nwith most simulators and dedicated hardware. I wonder whether the\nAS-LSTM model would still be valid if the ASN model is replaced with a\nstandard SRM model for instance.\n\n- The authors claim in the introduction that they made an analytical conversion from discrete to continuous time. I did not find this in the main text.\n\n- The axes in Figure 1 are not defined (what is Delta S?) and the\ncaption does not match. ""Average output signal [...] as a function of its incoming PSC I"" output signal is not defined, and S is presented in the graph, but not I.', ""Here the authors propose a variant of an analog LSTM and then further propose a mechanism by which to convert it to a spiking network, in what a computational neuroscientist would call a 'mean-field' approach.  The result is a network that communicates using only spikes.  In general I think that the problem of training or even creating spiking networks from analog networks is interesting and worthy of attention from the ML community.  However, this manuscript feels very early and I believe needs further focus and work before it will have impact in the community. \n\nI can see three directions in which this work could be improved to provide wider interest:\n1. Neurophysiological realism -  It appears the authors are not interested in this direction given the focus of the manuscript ( other than mentioning the brain as motivation).\n\n2.  ML interest - From a pure ML point of view some interesting questions relate to training / computations / representations / performance.  However, in the manuscript the tasks trained are exceedingly simple and unconvincing from either a representations or performance perspective.  Since the main novelty of the manuscript is the 'spikification' algorithm, little is learned about how spiking networks function, or how spiking networks might represent data or implement computations.  \n\n3. Hardware considerations - There is no analysis of what has been made more efficient, more sped-up, how to meaningfully implement the algorithm, etc., etc.  A focus in this direction could find an applied audience.\n\nAs a minor comment, the paper could stand to be improved in terms of exposition.  In particular, the paper relies on ideas from other papers and the assumption is largely made that the reader is familiar with them, although the paper is self-contained.""]","[-20, -20, -20]","[60, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'interesting' and 'challenging', they also state that it is 'somewhat incomplete' and 'requires further experiments and clarifications'. The review lists more cons than pros, indicating areas that need improvement. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the novelty and importance of the work, and framing criticisms as suggestions for improvement rather than harsh judgments. The reviewer uses phrases like 'please rephrase' and 'it would be interesting to discuss', which maintain a polite and constructive tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper presents 'an interesting idea', they express several concerns about the claims not being sufficiently proven, the tasks being too simple, and some contradictions between the stated goals and the actual content. The reviewer also points out multiple issues with the model and methodology. However, the score isn't deeply negative because the reviewer does see some merit in the work. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, often framing criticisms as suggestions or questions ('I wonder why...', 'I find it more convincing to...') rather than direct attacks. They also begin by acknowledging the interesting aspects of the paper before moving on to criticisms. The tone is professional and constructive, even when pointing out flaws."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the topic is interesting and worthy of attention, they express that the manuscript feels early and needs further work. They provide three directions for improvement, suggesting the current state is not satisfactory. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the potential of the work and offering constructive feedback. They use phrases like 'I think' and 'I believe' to soften criticism, and provide specific suggestions for improvement rather than outright dismissal. The tone is professional and aimed at helping the authors improve their work.""]"
"['This paper studies the problem of representation learning in hyperedges.  The author claims their novelty for using several different models to build hyperedge representations.  To generate representations for hyperedge, this paper proposes to use several different models such as Denoising AutoEncoder, tensor decomposition, word2vec or spectral embeddings. Experimental results show the effectiveness of these models in several different datasets. \n\nThe author uses several different models (both recent studies like Node2Vec / sen2vec, and older results like spectral or tensor decomposition). The idea of studying embedding of a hypergraph is interesting and novel, and the results show that several different kinds of methods can all provide meaningful results for realistic applications. \n\nDespite the novel idea about hyperedge embedding generation, the paper is not easy to follow. \nThe introduction of ``hypergraph`` takes too much spapce in preliminary, while the problem for generating embeddings of hyperedge is the key of paper. \n\nFurther, the experiments only present several models this paper described. \nSome recent papers about hypergraph and graph structure (even though cannot generate embeddings directly) are still worth mention and compare in the experimental section. It will be persuasive to mention related methods in similar tasks. \n\nit would better better if the author can add some related work about hyperedge graph studies. ', 'The paper studies different methods for defining hypergraph embeddings, i.e. defining vectorial representations of the set of hyperedges of a given hypergraph. It should be noted that the framework does not allow to compute a vectorial representation of a set of nodes not already given as an hyperedge. A set of methods is presented : the first one is based on an auto-encoder technique ; the second one is based on tensor decomposition ; the third one derives from sentence embedding methods. The fourth one extends over node embedding techniques and the last one use spectral methods. The two first methods use plainly the set structure of hyperedges. Experimental results are provided on semi-supervised regression tasks. They show very similar performance for all methods and variants. Also run-times are compared and the results are expected. In conclusion, the paper gives an overview of methods for computing hypernode embeddings. This is interesting in its own. Nevertheless, as the target problem on hypergraphs is left unspecified, it is difficult to infer conclusions from the study. Therefore, I am not convinced that the paper should be published in ICLR\'18.\n\n* typos\n* Recent surveys on graph embeddings have been published in 2017 and should be cited as ""A comprehensive survey of graph embedding ..."" by Cai et al\n* Preliminaries. The occurrence number R(g_i) are not modeled in the hypergraphs. A graph N_a is defined but not used in the paper.\n* Section 3.1. the procedure for sampling hyperedges in the lattice shoud be given. At least, you should explain how it is made efficient when the number of nodes is large.\n* Section 3.2. The method seems to be restricted to cases where the cardinality of hyperedges can take a small number of values. This is discussed in Section 3.6 but the discussion is not convincing enough.\n* Section 3.3 The term Sen2vec is not common knowledge\n* Section 3.3 The length of the sentences depends on the number of permutations of $k$ elements. How can you deal with large k ?\n* Section 3.4 and Section 3.5. The methods proposed in these two sections should be related with previous works on hypergraph kernels. I.e. there should be mentions on the clique expansion and star expansion of hypergraphs. This leads to the question why graph embeddings methods on these expansions have not be considered in the paper.\n* Section 4.1. Only hyperedeges of cardinality in [2,6] are considered. This seems a rather strong limitation and this hypothesis does not seem pertinent in many applications. \n* Section 4. For online multi-player games, hypernode embeddings only allow to evaluate existing teams, i.e. already existing as hyperedges in the input hypergraph. One of the most important problem for multi-player games is team making where team evaluation should be made for all possible teams.\n* Section 5. Seems redundant with the Introduction.', 'This paper addresses the problem of embedding sets into a finite dimensional vector space where the sets have the structure that they are hyper-edges of a hyper graph. It presents a collection of methods for solving this problem and most of these methods are only adaptation of existing techniques to the hypergraph setting. The only novelty I find is in applying node2vec (an existing technique) on the dual of the hypergraph to get an embedding for hyperedges. \n\nFor several methods proposed, they have to rely on unexplained heuristics (or graph approximations) for the adaptation to work.  For example, why taking average line 9 Algorithm 1 solves problem (5) with an additional constraint that \\mathbf{U}s are same? Problem 5 is also not clearly defined: why is there superscript $k$ on the optimization variable when the objective is sum over all degrees $k$?\n\nIt is not clear why it makes sense to adapt sen2vec (where sequence matters) for the problem of embedding hyperedges (which is just a set). To get a sequence independent embedding, they again have to rely on heuristics.\n\nOverall, the paper only tries to use all the techniques developed for learning on hypergraphs (e.g., tensor decomposition for k-uniform hypergraphs, approximating a hypergraph with a clique graph etc.) to develop the embedding methods for hyperedges. It also does not show/discuss which method is more suitable to a given setting. In the experiments, they show very similar results for all methods. Comparison of proposed methods against a baseline is missing. \n\n\n']","[50, -50, -60]","[60, 50, 0]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and interesting aspects of the paper, stating 'The idea of studying embedding of a hypergraph is interesting and novel' and praising the results. However, they also point out some weaknesses, such as the paper being 'not easy to follow' and suggesting improvements. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'it would be better if' and 'worth mention' to suggest improvements, maintaining a professional and courteous tone. The reviewer balances positive feedback with areas for improvement, which is a polite approach to academic criticism."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('This is interesting in its own'), they ultimately conclude 'I am not convinced that the paper should be published in ICLR'18', indicating an overall negative sentiment. The review points out several limitations and areas for improvement, further supporting the negative sentiment. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and specific suggestions for improvement. They avoid harsh or dismissive language, instead framing their concerns as areas for clarification or expansion. The reviewer also acknowledges positive aspects of the work, which contributes to the polite tone."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that most methods are adaptations of existing techniques, with little novelty. They criticize the use of unexplained heuristics, unclear problem definitions, and question the appropriateness of certain adaptations. The reviewer also notes the lack of comparison against baselines and similar results across methods, indicating disappointment with the paper's contributions. However, it's not entirely negative, as they do acknowledge some novelty in applying node2vec to the hypergraph dual. The politeness score is 0 (neutral) because the language used is direct and professional, without being overtly polite or rude. The reviewer presents criticisms in a matter-of-fact manner, focusing on the content rather than using emotional or personal language.""]"
"['This paper proposes a geometric based approach to solving the problem of one-shot and few-shot learning. The basic idea is to use the feature vectors of a particular class to construct a simplex. (I am assuming the dimensions of the vectors are selected so as to exactly construct a simplex? It is not clearly written in the paper). The volume of the simplex is then taken to be a measure of class scatter, and classification happens by assigning the test feature vector to the nearest simplex, where the distances are normalized by the volume of the simplex. \n\nWhile the approach makes sense, I am not convinced that this geometric method plays an important role in increasing the performance on one-shot/few-shot tasks. In particular, one could try simpler approaches like k-NN where the distances to the cluster centers are also normalized by the variance within the clusters. I would suspect that this method is not superior to this simpler baseline. \n\nThe other issue I have with this paper is misleading claims about being state of the art on Omniglot. In particular see Kaiser et al (ICLR 2017), where on 5-way-1-shot an accuracy of 98.4% is reached compared to 94.6% in this paper, and on 5-way-5-shot an accuracy of 99.6% is reached compared to 99.1% in this work. The paper also misses evaluations on various other data sets such as GNMT etc., on which Kaiser et al evaluated their approach.', 'This paper proposes an approach for few-shot classification based on a geometric idea. The basic assumption is that a query instance will be closest to the polytope corresponding to the correct class than to other classes, where they consider polytopes formed by selecting samples from each class as vertices. As a distance metric, authors consider the variation of the volume of each class-polytope when a query instance is added to the corresponding class. Given that there is not a method to calculate the volume of a general convex polytope, they approximate the polytope by the corresponding simplex convex (convex polytope with the condition of n = d). Fortunately, in the case of the simplex, there is close form solution to obtain the volume.\n\nIn general, the paper is well presented and, as far as I know, the proposed idea is novel and sound. Experimentation is correct. Results indicate that the proposed method is able to outperform related state-of-the-art techniques, achieving a reasonable improvement, approx. 1-3% depending of the dataset. \n\nAs a drawback, for each query instance, the method needs to estimate the distance to the simplex of each class, therefore it does not scale well with the number of classes. Authors should comment about this issue, in particular, about the computational complexity of the proposed method. Also, in the cases presented in the paper, the selection of the training instances used to calculate the simplex is straight-forward, however, in a more general case, this could be a relevant problem. It will be good to comment about this issue.\n', 'This work proposes a method for few-shot classification that treats a set of embedded points belonging to a class as a simplex. Classification for an unlabeled test point is performed by selecting the class whose augmented simplex has the smallest volume relative to the original class simplex.\n\nStrengths\n- The use of simplices for representing classes in few-shot learning is novel.\n\nWeaknesses\n- A number of recent related few-shot learning approaches are missing from the related work.\n- In light of missing baselines, the proposed method does not perform better than recent few-shot approaches.\n\nI am not an expert on simplices, but the derivations in the paper appear to be correct, with two exceptions: (a) equation 6 appears to be the ratio of C^2(Y U t) / C(Y), (b) equation 6 appears to be missing a minus sign.\n\nThe writing of the paper is relatively clear, however there are several important issues:\n- Background on metric learning is missing.\n- The training loss is not described (i.e. how is the volume ratio from equation 7 converted into a probability distribution over classes?).\n- The local feature representation in Section 3 is unclear and should be explained in more detail.\n- Related work is missing recent few-shot learning approaches, including MAML [1], Prototypical Networks [2], and TCML [3].\n\nThe proposed method is a metric learning approach but it has some additional restrictions relative to other such techniques for few-shot learning such as Matching Networks or Prototypical Networks. One is that the computation of volume ratio involves matrix inversion of P and Q. Another is that the method is not defined when the number of points exceeds the dimensionality of the embedding space. These are not likely to be an issue for few-shot learning, but should be noted as interest in methods that scale gracefully from the few-shot to ordinary classification increases.\n\nRegarding Omniglot results, 20-way 1-shot/5-shot experiments are widely reported in related work but missing from the paper.\n\nWhen the results are viewed in light of missing baselines, such as Prototypical Networks (68.2% on 5-way 5-shot miniImagenet), the proposed method is more complicated and performs significantly worse.\n\nOverall, the proposed approach is interesting but there are significant issues with both background/related work and performance relative to missing baselines.\n\n[1] Finn, Chelsea, Pieter Abbeel, and Sergey Levine. ""Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks."" ICML 2017.\n[2] Snell, Jake, Kevin Swersky, and Richard S. Zemel. ""Prototypical Networks for Few-shot Learning."" NIPS 2017.\n[3] Mishra, Nikhil, et al. ""Meta-Learning with Temporal Convolutions."" arXiv preprint arXiv:1707.03141 (2017).\n\nEDIT: I have read the author\'s response. The background and related work issues are largely fixed in the latest revision of the paper. Thanks also to the authors for clarifying that training proceeds according to the minimization of cross-entropy loss, rather than a loss based on the simplex. In this case, the novelty of the proposed method then lies in the test-time procedure for making a classification decision when a few-shot episode is encountered. Thus the novelty is relatively low in my opinion. From an experimental perspective, I believe that a comparison of the proposed approach to other test-time classification decision rules is warranted to demonstrate that the simplex rule is better than simpler alternatives (for example, fitting a Gaussian distribution to the support examples of each few-shot class and then assigning a test example to  the class with highest posterior probability). My rating remains unchanged.']","[-50, 70, -40]","[50, 80, 50]","[""The sentiment score is -50 because the reviewer expresses significant doubts about the paper's approach and claims. They are 'not convinced' about the method's importance and suggest simpler approaches might be equally effective. They also point out 'misleading claims' about state-of-the-art performance. However, the review isn't entirely negative as it acknowledges that the approach 'makes sense'. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They use phrases like 'I am not convinced' and 'The other issue I have' rather than more confrontational language. The reviewer also provides specific examples and suggestions, which is constructive and polite in academic discourse."", ""The sentiment score is 70 (positive) because the reviewer states that the paper is 'well presented', the idea is 'novel and sound', and the experimentation is 'correct'. The results are described as showing 'reasonable improvement' over state-of-the-art techniques. While there are some drawbacks mentioned, they are presented as areas for improvement rather than major flaws. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. Phrases like 'As far as I know' and 'It will be good to comment' indicate a considerate tone. The reviewer provides specific suggestions for improvement without being harsh or dismissive."", ""The sentiment score is -40 because while the reviewer acknowledges some strengths and novelty in the approach, they point out significant weaknesses, missing baselines, and performance issues. The overall tone suggests the paper needs substantial improvements. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledges their own limitations ('I am not an expert on simplices'), and provides constructive feedback. They also thank the authors for their response and clarifications. However, the criticism is direct and unvarnished, preventing a higher politeness score.""]"
"['# Summary\nThis paper proposes a neural network framework for solving binary linear programs (Binary LP). The idea is to present a sequence of input-output examples to the network and train the network to remember input-output examples to solve a new example (binary LP). In order to store such information, the paper proposes an external memory with non-differentiable reading/writing operations. This network is trained through supervised learning for the output and reinforcement learning for discrete operations. The results show that the proposed network outperforms the baseline (handcrafted) solver and the seq-to-seq network baseline.\n\n[Pros]\n- The idea of approximating a binary linear program solver using neural network is new.\n\n[Cons]\n- The paper is not clearly written (e.g., problem statement, notations, architecture description). So, it is hard to understand the core idea of this paper.\n- The proposed method and problem setting are not well-justified. \n- The results are not very convincing.\n\n# Novelty and Significance\n- The problem considered in this paper is new, but it is unclear why the problem should be formulated in such a way. To my understanding, the network is given a set of input (problem) and output (solution) pairs and should predict the solution given a new problem. I do not see why this should be formulated as a ""sequential"" decision problem. Instead, we can just give access to all input/output examples (in a non-sequential way) and allow the network to predict the solution given the new input like Q&A tasks. This does not require any ""memory"" because all necessary information is available to the network.\n- The proposed method seems to require a set of input/output examples even during evaluation (if my understanding is correct), which has limited practical applications. \n\n# Quality\n- The proposed reward function for training the memory controller sounds a bit arbitrary. The entire problem is a supervised learning problem, and the memory controller is just a non-differentiable decision within the neural network. In this case, the reward function is usually defined as the sum of log-likelihood of the future predictions (see [Kelvin Xu et al.] for training hard-attention) because this matches the supervised learning objective. It would be good to justify (empirically) the proposed reward function. \n- The results are not fully-convincing. If my understanding is correct, the LTMN is trained to predict the baseline solver\'s output. But, the LTMN significantly outperforms the baseline solver even in the training set. Can you explain why this is possible?\n\n# Clarity\n- The problem statement and model description are not described well. \n1) Is the network given a sequence of program/solution input? If yes, is it given during evaluation as well?\n2) Many notations are not formally defined. What is the output (o_t) of the network? Is it the optimal solution (x_t)? \n3) There is no mathematical definition of memory addressing mechanism used in this paper.\n- The overall objective function is missing. \n\n[Reference]\n- Kelvin Xu et al., Show, Attend and Tell: Neural Image Caption Generation with Visual Attention', 'This paper proposes using long term memory to solve combinatorial optimization problems with binary variables. The authors do not exhibit much knowledge of combinatorial optimization literature (as has been pointed out by other readers) and ignore a lot of previous work by the combinatorial optimization community. In particular, evaluating on random instances is not a good measure of performance,  as has already been pointed out. The other issue is with the baseline solver, which also seems to be broken since their solution quality seems extremely poor. In light of these issues, I recommend reject.', 'Learning to solve combinatorial optimization problems using recurrent networks is a very interesting research topic. However, I had a very hard time understanding the paper. It certainly doesn’t help that I’m not familiar with the architectures the model is based on, nor with state-of-the-art integer programming solvers.\n\nThe architecture was described but not really motivated. The authors chose to study only random instances which are known to be bad representatives of real-world problmes, instead of picking a standard benchmark problem. Furthermore, the insights on how the network is actually solving the problems and how the proposed components contribute to the solution are minimal, if any.\n\nThe experimental issues (especially regarding the baseline) raised by the anonymous comments below were rather troubling; it’s a pity they were left unanswered.\n\nHopefully other expert reviewers will be able to provide constructive feedback.']","[-50, -80, -50]","[20, -20, 20]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('The idea of approximating a binary linear program solver using neural network is new'), the majority of the review focuses on criticisms and concerns. The reviewer lists several cons, questions the problem formulation, and expresses doubts about the results and clarity of the paper. However, the score is not extremely negative as the reviewer does recognize some merit in the work.\n\nThe politeness score is 20 because the reviewer maintains a professional and objective tone throughout, avoiding harsh language or personal attacks. They use phrases like 'To my understanding' and 'It would be good to justify' which show respect for the authors' perspective. However, the score is not higher because the review is quite direct in its criticisms without much softening language, and doesn't offer much encouragement or positive reinforcement to the authors."", 'The sentiment score is -80 because the review is overwhelmingly negative. The reviewer points out multiple significant issues with the paper, including lack of knowledge of relevant literature, ignoring previous work, poor evaluation methods, and issues with the baseline solver. The review concludes with a clear recommendation to reject the paper. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without any attempt to soften the criticism or provide positive feedback. The reviewer does not use polite phrases or acknowledge any strengths of the paper, which contributes to the slightly negative politeness score.', ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's clarity, methodology, and lack of insights. They mention having 'a very hard time understanding the paper' and raise issues with the choice of study instances and minimal insights provided. However, it's not entirely negative as they acknowledge the topic is 'very interesting'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone. They use phrases like 'Hopefully other expert reviewers will be able to provide constructive feedback' which shows consideration. The reviewer also acknowledges their own potential lack of expertise in certain areas, which adds a polite tone to the criticism.""]"
"['This paper presents an important application of modern deep reinforcement learning (RL) methods to learning optimal treatments for sepsis from past patient encounters. From a methods standpoint, it offers nothing new but does synthesize best practice deep RL methods with a differentiable multi-task Gaussian Process (GP) input layer. This means that the proposed architecture can directly handle irregular sampling and missing values without a separate resampling step and can be trained end-to-end to optimize reward -- patient survival -- without a separate ad hoc preprocessing step. The experiments are thorough and the results promising. Overall, strong application work, which I appreciate, but with several flaws that I\'d like the authors to address, if possible, during the review period. I\'m perfectly willing to raise my score at least one point if my major concerns are addressed.\n\nQUALITY\n\nAlthough the core idea is derivative, the work is executed pretty well. Pros (+) and cons (-) are listed below:\n\n+ discussion of the sepsis application is very strong. I especially appreciated the qualitative analysis of the individual case shown in Figure 4. While only a single anecdote, it provides insight into how the model might yield clinical insights at the bedside.\n+ thorough comparison of competing baselines and clear variants -- though it would be cool to apply offline policy evaluation (OPE) to some of the standard clinical approaches, e.g., EGDT, discussed in the introduction.\n\n- ""uncertainty"" is one of the supposed benefits of the MTGP layer, but it was not at all clear how it was used in practice, other than -- perhaps -- as a regularizer during training, similar to data augmentation.\n- uses offline policy evaluation ""off-the-shelf"" and does not address or speculate the potential pitfalls or dangers of doing so. See ""Note on Offline Policy Evaluation"" below.\n- although I like the anecdote, it tells us very little about the overall policy. The authors might consider some coarse statistical analyses, similar to Figure 3 in Raghu, et al. (though I\'m sure you can come up with more and better analyses!). \n- there are some interesting patterns in Table 1 that the authors do not discuss, such as the fact that adding the MGP layer appears to reduce expected mortality more (on average) than adding recurrences. Why might this be (my guess is data augmentation)?\n\nCLARITY\n\nPaper is well-written, for the most part. I have some nitpicks about the writing, but in general, it\'s not a burden to read.\n\n+ core ideas and challenges of the application are communicated clearly\n\n- the authors did not detail how they chose their hyperparameters (number of layers, size of layers, whether to use dropout, etc.). This is critical for fully assessing the import of the empirical results.\n- the text in the figures are virtually impossible to read (too small)\n- the image quality in the figures is pretty bad (and some appear to be weirdly stretched or distorted)\n- I prefer the X-axis labels that Raghu uses in their Figure 4 (with clinically interpretable increments) over the generic +1, +2, etc., labels used in Figure 3 here\n\nSome nitpicks on the writing\n\n* too much passive voice. Example: third paragraph in introduction (""Despite the promising results of EGDT, concerns arose.""). Avoid passive voice whenever possible.\n* page 3, sec. 2.2 doesn\'t flow well. You bounce back and forth between discussion of the Markov assumption and full vs. partial observability. Try to focus on one concept at a time (and the solution offered by a proposed approach). Note that RNNs do NOT relax the Markov assumption -- they simply do an end run around it by using distributed latent representations.\n\nORIGINALITY\n\nThis work scores relatively low in originality. It really just combines ideas from two MLHC 2017 papers [1][2]. One could read those two papers and immediately conclude this paper\'s findings (the GP helps; RL helps; GP + RL is the best). This paper adds few (if any) new insights.\n\nOne way to address this would be to discuss in greater detail some potential explanations for why their results are stronger than those in Raghu and why the MTGP models outperform their simpler counterparts. Perhaps they could run some experiments to measure performance as a function of the number of MC samples (if perhaps grows with the number of samples, then it suggests that maybe it\'s largely a data augmentation effect).\n\nSIGNIFICANCE\n\nThis paper\'s primary significance is that it provides further evidence that RL could be applied successfully to clinical data and problems, in particular sepsis treatment. However, this gets undersold (unsurprising, given the ML community\'s disdain for replication studies). It is also noteworthy that the MTGP gives such a large boost in performance for a relatively modest data set -- this property is worth exploring further, since clinical data are often small. However, again, this gets undersold.\n\nOne recommendation I would make is that the authors directly compare the results in this paper with those in Raghu and to point out, in particular, the confirmatory results. Interestingly, the shapes of the action vs. mortality rate plots (Figure 4 in Raghu, Figure 3 here) are quite similar -- that\'s not precisely replication, but it\'s comforting.\n\nNOTE ON OFFLINE POLICY EVALUATION\n\nThis work has the same flaw that Raghu, et al., has -- neither justifies the use of offline policy evaluation. Both simply apply Jiang, et al.\'s doubly robust approach [3] ""off the shelf"" without commenting on its accuracy in practice or discussing potential pitfalls (neither even considers [4] which seems to be superior in practice, especially with limited data). As far as I can tell (I\'m not an RL expert), the DR approach carries stronger consistency guarantees and reduced variance but is still only as good the data it is trained on, and clinical data is known to have significant bias, particularly with respect to treatment, where clinicians are often following formulaic guidelines. Can we trust the mortality estimates in Table 1? Why or why not? Why shouldn\'t I think that RL is basically guaranteed to outperform non-RL approaches under an evaluation that is itself an RL model learned from the same training data!\n\nWhile I\'m willing to accept that this is the best we can do in this setting (we can\'t just try the learned policy on new patients!), I think this paper (and similar works, like Raghu, et al.) *must* provide a sober and critical discussion of its results, rather than simply applaud itself for getting the best score among competing approaches.\n\nREFERENCES\n\n[1] Raghu, et al. ""Continuous State-Space Models for Optimal Sepsis Treatment - a Deep Reinforcement Learning Approach."" MLHC 2017.\n[2] Futoma, et al. ""An Improved Multi-Output Gaussian Process RNN with Real-Time Validation for Early Sepsis Detection."" MLHC 2017.\n[3] Jiang, et al. ""Doubly robust off-policy value evaluation for reinforcement learning."" ICML 2016.\n[4] Thompson and Brunskill. ""Data-Efficient Off-Policy Policy Evaluation for Reinforcement Learning."" ICML 2016.', 'The paper presents an application of deep learning to predict optimal treatment of sepsis, using data routinely collected in a hospital. The paper is very clear and well written, with a thorough review of related work. However, the approach is mainly an application of existing methods and the technical novelty is low. Further, the methods are applied to only a single dataset and there is no comparison against the state of the art, only between components of the method. This makes it difficult to assess how much of an improvement this collection of methods provides and how much it would generalize to data from other hospitals or applications. As written, the paper may be more appropriate for an application-focused venue.', 'The paper presents a reinforcement learning method that uses Q-learning with deep neural networks and a multi-output Gaussian process for imputation, all for retrospective analysis of treatment decisions for preventing mortality among patient with sepsis.\n\nWhile the work represents a combination of leading methods in the machine learning literature, key details are missing: most importantly, that the reinforcement learning is based on observational data and in a setting where the unconfoundedness assumption is very unlikely to hold. For example, an MGP imputation implicitly assumes MAR (missing at random) unless otherwise specified, e.g. through informative priors. The data is almost certainly MNAR (missing not at random). These concerns ought to be discussed at length.\n\nThe clarity of the work would be improved with figures describing the model (e.g. plate/architecture diagram) and pseudocode. E.g. as it stands, it is not clear how the doubly-robust estimation is being used and if it is appropriate given the above concerns. Similar questions for Dueling Double-Deep Q-network, Prioritized Experience Replay.\n\nThe medical motivation does frame the clinical problem well. The paper does serve as a way to generate hypotheses, e.g. greater use of abx and vasopressors but less IVF.\n\nThe results in Table 1 suggest that the algorithmic policy would prevent the death of ~1 in 12 individuals (ARR 8.2%) that a physician takes care of in your population. The text says ""might reduce mortality by as much as 8%"". The authors might consider expanding on this. What can/should be done convince the reader this number is real.\n\nAdditional questions: what is the sensitivity of the analysis to time interval and granularity of the action space (here, 4 hours; 3x3x5 treatments)? How would this work for whole order sets? In the example, abx 1 and abx 2 are recommended in the next 4 hours even after they were already administered. How does this relate to pharmacologic practice, where abx are often dosed at specific, wider intervals, e.g. vancomycin q12h? How could the model be updated for a clinician who acknowledges the action suggestion but dismisses it as incorrect?']","[50, -20, -20]","[75, 50, 60]","[""Sentiment score: The review begins with positive remarks about the paper's importance and thorough execution. The reviewer appreciates the application work and finds the results promising. However, they also point out several flaws and areas for improvement, indicating a mixed but overall positive sentiment. The willingness to raise the score if concerns are addressed further supports a moderately positive sentiment.\n\nPoliteness score: The reviewer maintains a professional and respectful tone throughout. They use phrases like 'I appreciate' and 'I'd like the authors to address' which are polite ways of expressing opinions. The critique is constructive, offering specific suggestions for improvement. The reviewer also balances criticism with praise, acknowledging the paper's strengths. However, some direct criticisms and the use of exclamation points in places slightly reduce the politeness score from being extremely high."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('very clear and well written', 'thorough review'), they express significant concerns about the paper's novelty, limited dataset, lack of comparisons, and potential generalizability. The overall tone suggests the paper may not be suitable for the intended venue. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, balancing criticism with praise, and avoiding harsh or dismissive phrasing. They offer constructive feedback and suggest an alternative venue, which is considerate."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'The medical motivation does frame the clinical problem well'), they express significant concerns about missing key details and methodological issues. The reviewer points out several areas where the paper falls short, such as the lack of discussion on unconfoundedness and MNAR data issues.\n\nThe politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'The clarity of the work would be improved...' and 'The authors might consider...', which suggest improvements without being harsh or dismissive. The reviewer also acknowledges the paper's strengths and potential contributions alongside the criticisms.\n\nOverall, the review balances critique with constructive feedback, maintaining a respectful tone while clearly communicating areas for improvement.""]"
"['This paper proposed to transfer the classifier from the model for face classification to the task of alignment and verification. The problem setting is interesting and valuable, however, the contribution is not clearly demonstrated. \n\nSpecifically, it proposed to utilize the teacher model from classification to other tasks, and proposed a unified objective function to model the transferability as shown in Equation (5). The two terms in (5), (7) and (9) are used to transfer the knowledge from the teacher model. It maybe possible to claim that the different terms may play different roles for different tasks. However, there should be some general guidelines for choosing these different terms for regularization, rather than just make the claim purely based on the final results. In table 4 and table 5, the results seem to be not so consistent for using the distillation loss. The author mentioned that it is due to the weak teacher model. However, the teacher model just differs in performance with around 3% in accuracy. How could we define the “good” or “bad” of a teacher model for model distillation/transfer?\n\nBesides, it seems that the improvement comes largely from the trick of initialization as mentioned in Section 3.2. Hence, it is still not clear which parts contribute to the final performance improvements. It could be better if the authors can report the results from each of the components together. \n\n The authors just try the parameter (\\alpha, \\beta) to be (0,0), (1,0), (0,1) and (1,1). I think the range for both values could be any positive real value, and how about the performance for other sets of combinations, like (0.5, 0.5)?', 'The paper proposes knowledge distillation on two very specific non-classification tasks. I find the scope of the paper is quite limited and the approach seems hard to generalize to other tasks. There is also very limited technical contribution. I think the paper might be a better fit in conferences on faces such as FG.\n\nPros:\n1. The application of knowledge distillation in face alignment is interesting. \n\nCons:\n1. The writing of the paper can be significantly improved. The technical description is unclear.\n2. The method has two parameters \\alpha and \\beta, and Section 4.2.3. mentions the key is to measure the relevance of tasks. It seems to me defining the relevance between tasks is quite empirical and often confusing. How are they actually selected in the experiments? Sometimes alpha=0, beta=0 works the best which means the added terms are useless?\n3. The paper works on a very limited scope of face alignment. How does the proposed method generalize to other tasks?', 'Summary:\nThe manuscript presents experiments on distilling knowledge from a face classification model to student models for face alignment and verification. By selecting a good initialization strategy and guidelines for selecting appropriate targets for non-classification tasks, the authors achieve improved performance, compared to networks trained from scratch or with different initialization strategies.\n\nReview:\nThe paper seems to be written in a rush. \nI am not sure about the degree of novelty, as pretraining with domain-related data instead of general-purpose ImageNet data has been done before, Liu et al. (2014), for example pretrain a CNN on face classification to be used for emotion recognition. Admitted, knowledge transfer from classification to regression and retrieval tasks is not very common yet, except via pretraining on ImageNet, followed by fine-tuning on the target task.\nMy main concern is with the presentation of the paper. It is very hard to follow! Two reasons are that it has too many grammatical mistakes and that very often a “simple trick” or a “common trick” is mentioned instead of using a descriptive name for the method used.\n\nHere are a few points that might help improving the work:\n1) Many kind of empty phrases are repeated all over the paper, e.g. the reader is teased with mention of a “simple trick” or a “common trick”. I don’t think the phrase “breaking point”, that is repeated a couple of times, is correctly used (see https://www.merriam-webster.com/dictionary/breaking%20point for a defininition).\n2) Section 4.1 does not explain the initialization but just describes motivation and notation.\n3) Clarity of the approach: Using the case of alignment as an example, do you first pretrain both the teacher and student on classification, then finetune the teacher on alignment before the distillation step? \n4) Table 1 mentions Fitnets, but cites Ba & Caruana (2014) instead of Romero et al. (2015)\n5) The “experimental trick” you mention for setting alpha and beta, seems to be just validation, comparing different settings and picking the one yielding the highest improvements. On what partition of the data are you doing this hyperparameter selection?\n6) The details of the architectures are missing, e.g. exactly what changes do you make to the architecture, when you change the task from classification to alignment or verification? What exactly is the “hidden layer” in that architecture?\n7) Minor: Usually there is a space before parentheses (many citations don’t have one)\n\nIn its current form, I cannot recommend the manuscript for acceptance. I get the impression that the experimental work might be of decent quality, but the manuscript fails to convey important details of the method, of the experimental setup and in the interpretation of the results. The overall quality of the write-up has to be significantly improved.\n\nReferences:\nLiu, Mengyi, Ruiping Wang, Shaoxin Li, Shiguang Shan, Zhiwu Huang, and Xilin Chen. ""Combining multiple kernel methods on riemannian manifold for emotion recognition in the wild."" In Proceedings of the 16th International Conference on Multimodal Interaction, pp. 494-501. ACM, 2014.']","[-30, -60, -70]","[50, 20, -20]","[""The sentiment score is -30 because the reviewer expresses some concerns about the paper's contribution and clarity, while acknowledging the interesting problem setting. The review points out several issues with the methodology and results, indicating a somewhat negative sentiment. However, it's not entirely negative as the reviewer suggests improvements and asks for clarifications.\n\nThe politeness score is 50 because the reviewer uses professional and respectful language throughout. They phrase criticisms as suggestions or questions rather than direct attacks. For example, 'It could be better if...' and 'How could we define...' show a polite approach to giving feedback. The reviewer also acknowledges positive aspects before presenting criticisms. However, the score is not higher as the language, while polite, is not overly warm or encouraging."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the paper's scope is limited, the approach is hard to generalize, and there is limited technical contribution. They also list more cons than pros. However, it's not entirely negative as they do mention one positive aspect (the application of knowledge distillation in face alignment is interesting). The politeness score is 20 because while the reviewer is direct in their criticism, they use relatively neutral language and avoid personal attacks. They use phrases like 'I find' and 'I think' which soften the critique. The reviewer also provides specific recommendations for improvement, which is constructive. However, the overall tone is more matter-of-fact than overtly polite, hence the modest positive score."", ""The sentiment score is -70 because the reviewer expresses significant concerns about the paper's presentation, clarity, and overall quality. They state that the paper 'seems to be written in a rush,' question its novelty, and ultimately cannot recommend it for acceptance. The politeness score is -20 because while the reviewer provides constructive feedback and suggestions for improvement, the tone is quite direct and critical. Phrases like 'It is very hard to follow!' and 'The overall quality of the write-up has to be significantly improved' come across as somewhat harsh. However, the reviewer does offer specific points for improvement and uses some polite language like 'Here are a few points that might help improving the work,' which prevents the score from being even lower.""]"
"['Paper presents an interesting attention mechanism for fine-grained image classification. Introduction states that the method is simple and easy to understand. However, the presentation of the method is bit harder to follow. It is not clear to me if the attention modules are applied over all  pooling layers. How they are combined? \n\nWhy use cross -correlation as the regulariser? Why not much stronger constraint such as orthogonality over elements of M in equation 1? What is the impact of this regularisation?\n\nWhy use soft-max in equation 1? One may use a Sigmoid as well? Is it better to use soft-max?\n\nEquation 9 is not entirely clear to me. Undefined notations.\n\nIn Table 2, why stop from AD= 2 and AW=2?  What is the performance of AD=1, AW=1 with G? Why not perform this experiment over all 5 datasets? Is this performances, dataset specific?\n\nThe method is compared against 5 datasets. Obtained results are quite good.\n\n', ""This paper proposes a feed-forward attention mechanism for fine-grained image classification. It is modular and can be added to any convolutional layer, the attention model uses CNN feature activations to find the most informative parts then combine with the original feature map for the final prediction. Experiments show that wide residual net together with this new attention mechanism achieve slightly better performance on several fine-grained image classification tasks.\n\nStrength of this work:\n1) It is end-to-end trainable and doesn't require multiple stages, prediction can be done in single feedforward pass.\n2) Easy to train and doesn't increase the model size a lot.\n\nWeakness:\n1) Both attention depth and attention width are small. The choice of which layer to add this module is unclear to me. \n2) No analysis on using the extra regularization loss actually helps.\n3) My main concern is the improvement gain is very small. In Table3, the gain of using the gate module is only 0.1%. It argues that this attention module can be added to any layer but experiments show only 1 layer and 1 attention map already achieve most of the improvement. From Table 4 to Table 7, WRNA compared to WRN only improve ~1% on average.  \n"", 'The manuscript describes a novel attentional mechanism applied to fine-grained recognition. \n\nOn the positive side, the approach seems to consistently improve the recognition accuracy of the baseline  (a wide residual net). The approach is also consistently tested on the main fine-grained recognition datasets (the Adience age and gender recognition benchmark, Caltech-UCSD Birds-200-2011, Stanford Dogs, Stanford Cars, and UEC Food-100).\n\nOn the negative side, the paper could be better written and motivated.\n\nFirst, some claimed are made about how the proposed approach ""enhances most of the desirable properties from previous approaches” (see pp 1-2) but these claims are never backed up. More generally since the paper focuses on attention, other attentional approaches should be used as benchmarks beyond the WRN baseline. If the authors want to claim that the proposed approach is ""more robust to deformation and clutter” then they should design an experiment that shows that this is the case. \n\nBeyond, the approach seems a little ad hoc. No real rationale is provided for the different mechanisms including the gating etc and certainly no experimental validation is provided to demonstrate the need for these mechanisms. More generally, it is not clear from reading the paper specifically what computational limitation of the CNN is being solved by the proposed attentional mechanism. \n\nSome of the masks shown in Fig 3 seem rather suspicious and prompt this referee to think that the networks are seriously overfitting to the data. For instance, why would attending to a right ear help in gender recognition? \n\nThe proposed extension adds several hyperparameters (for instance the number K of attention heads). Apologies if I missed it but I am not clear how this was optimized for the experiments reported. In general, the paper could be clearer. For instance, it is not clear from either the text or Fig 2 how H goes from XxYxK for the attention head o XxYxN for the output head.\n\nAs a final point, I would say that while some of the criticisms could be addressed in a revision, the improvements seem relatively modest. Given that the focus of the paper is already limited to fine-grained recognition, it seems that the paper would be better suited for a computer vision conference.\n\n\nMinor point: \n\n""we incorporate the advantages of visual and biological attention mechanisms” not sure this statement makes much sense. Seems like visual and biological are distinct attributes but visual attention can be biological (or not, I guess) and it is not clear how biological the proposed approach is. Certainly no attempt is made by the authors to connect to biology.\n\n""top-down feed-forward attention mechanism” -> it should be just feed-forward attention. Not clear what ""top-down feed-forward” attention could be...']","[20, 20, -20]","[60, 50, 50]","[""Sentiment Score (20): The review starts with a positive note, mentioning the paper presents an 'interesting attention mechanism'. However, it then points out several areas of confusion and questions, indicating a mix of positive and negative sentiment. The overall tone leans slightly positive as the reviewer acknowledges the 'quite good' results, but there are numerous critiques and questions throughout. This balance results in a slightly positive score.\n\nPoliteness Score (60): The language used in the review is generally polite and professional. The reviewer uses phrases like 'It is not clear to me' and 'Why not' to pose questions, which is a respectful way to address concerns. There are no harsh criticisms or rude language. The reviewer maintains a constructive tone throughout, focusing on seeking clarification and suggesting improvements. This approach is more polite than neutral, hence the moderately positive score."", ""The sentiment score is slightly positive (20) because the review acknowledges some strengths of the paper, such as its end-to-end trainability and ease of implementation. However, it also points out several weaknesses, particularly the small improvement gain, which tempers the overall positive sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents both strengths and weaknesses in a balanced manner without using harsh or critical language. The reviewer's concerns are expressed professionally, using phrases like 'My main concern is...' rather than more confrontational language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('consistently improve the recognition accuracy', 'consistently tested on main datasets'), they express more concerns and criticisms. These include issues with writing and motivation, lack of proper benchmarking, ad hoc approach, suspicion of overfitting, and modest improvements. The overall tone suggests the paper needs significant improvements.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use polite phrases like 'On the positive side' and 'Apologies if I missed it'. Even when expressing criticisms, the language remains respectful and focused on the work rather than the authors. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback.""]"
"['This paper studies the generalization properties of 2-layer neural networks based on Fourier analysis. Studying the generalization property of neural network is an important problem and Fourier-based analysis is a promising direction, as shown in (Lee et al., 2017). However, I am not satisfied with the results in the current version.\n\n1) The main theoretical results are on the sin activation functions instead of commonly used ReLU functions. \n\n2) Even if for sin activation functions, the analysis is NOT complete. The authors claimed in the abstract that gradient-based methods will converge to generalizable local minima. However, Corollary 3 is only a concentration bound on the gradient. There is a gap that how this corollary implies generalization. The paragraph below this corollary is only a high level intuition. \n\n\n', '\nThis work proposes to study the generalization of learning neural networks via the Fourier-based method. It first gives a Fourier-based generalization bound, showing that Rademacher complexity of functions with small bandwidth and Fourier l_1 norm will be small. This leads to generalization for 2-layer networks with appropriate bounded size. For 2-layer networks with sine activation functions, assuming that the data distribution has nice spectral property (ie bounded bandwidth), it shows that the local minimum of the population risk (if with isolated component condition) will have small size, and also shows that the gradient of the empirical risk is close to that of the population risk. Empirical results show that the size of the networks learned on random labels are larger than those learned on true labels, and shows that a regularizer implied by their Fourier-based generalization bound can effectively reduce the generalization gap on random labels. \n\nThe idea of applying the Fourier-based method to generalization is interesting. However, the theoretical results are not very satisfactory. \n-- How do the bounds here compared to those obtained by directly applying Rademacher complexity to the neural network functions? \n-- How to interpret the isolated components condition in Theorem 4? Basically, it means that B(P_X) should be a small constant. What type of distributions of X will be a good example? \n-- It is not easy to put together the conclusions in Section 6.1 and 6.2. Suppose SGD leads to a local minimum of the empirical loss. One can claim that this is an approximate local minimum (ie, small gradient) by Corollary 3. But to apply Theorem 4, one will need a version of Theorem 4 for approximate local minima. Also, one needs to argue that the local minimum obtained by SGD will satisfy the isolated component condition. The argument in Section 8.6 is not convincing, ie, there is potentially a large approximation error in (41) and one cannot claim that Lemma 1 and Theorem 4 are still valid without the isolated component condition. \n', 'Deep neural networks have found great success in various applications. This paper presents a theoretical analysis for 2-layer neural networks (NNs) through a spectral approach. Specifically, the authors develop a Fourier-based generalization bound. Based on this, the authors show that the bandwidth, Fourier l_1 norm and the gradient for local minima of the population risk can be controlled for 2-layer NNs with SINE activation functions. Numerical experimental results are also presented to verify the theory.\n\n(1) The scope is a bit limited. The paper only considers 2-layer NNs. Is there an essential difficulty in extending the result here to NNs with more layers? Also, the analysis for gradient-based method in section 6  is only for squared-error loss, SINE activation and a deterministic target variable. What would happen if Y is random or the activation is ReLU?\n(2) The generalization bound in Corollary 3 is only for the gradient w.r.t. \\alpha_j. Perhaps, an object of more interest is the gradient w.r.t. W. It would be intersting to present some analysis regarding the gradient w.r.t. W.\n(3) It is claimed that the bound is tighter than that obtained using only the Lipschitz property of the activation function. However, no comparison is clearly made. It would be better if the authors could explain this more?\n\nIn summary, the application domain of the theoretical results seems a bit restricted.\n\nMinor comments:\nEq. (1): d\\xi should be dx\nLemma 2: one \\hat{g} should be \\hat{f}']","[-50, -20, -20]","[0, 50, 50]","[""The sentiment score is -50 because the reviewer expresses dissatisfaction with the current version of the paper, stating 'I am not satisfied with the results in the current version.' They also point out two significant limitations of the study. However, the score is not lower because the reviewer acknowledges the importance of the topic and the promise of the approach. The politeness score is 0 (neutral) because the language used is professional and direct, without being particularly polite or rude. The reviewer states their concerns clearly but without using harsh language or personal attacks. They use phrases like 'I am not satisfied' and 'The analysis is NOT complete,' which are direct but not impolite in an academic context."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting idea of applying Fourier-based methods to generalization, they express significant concerns about the theoretical results. The review starts positively but then states 'However, the theoretical results are not very satisfactory,' followed by several critical questions and points. This indicates a predominantly critical stance, albeit not entirely negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the interesting aspects of the work before presenting criticisms. They phrase their concerns as questions or suggestions rather than direct criticisms, which is a polite approach. The reviewer also uses neutral academic language without any harsh or rude expressions."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, they express several limitations and areas for improvement. The review starts with a neutral summary but then lists multiple critiques, suggesting the scope is limited and more analysis is needed. The phrase 'a bit restricted' in the summary further indicates a somewhat negative sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, phrasing criticisms as suggestions or questions (e.g., 'Is there an essential difficulty...', 'It would be interesting...') rather than direct criticisms. The reviewer also acknowledges the paper's contributions and uses polite phrases like 'It would be better if...'. The tone is professional and constructive, avoiding harsh or rude language.""]"
"['The authors propose to use pretrained node embeddings in a deep learning model for link weight prediction in graphs. \nThe embedding of the source node and the destination node are concatenated and fed into a fully connected neural network which produces the link weight as its output.\nExisting work by Hou and Holder 2017 trains the same architecture, but the node embeddings are learned together with the weights of the neural network. In my professional opinion, the idea of using pretrained node embeddings and training only the neural network is not enough of a contribution.\n\nSince the proposed method does not build on the SBM or pWSBM the detailed equations on page 2 are not necessary. Also, Figure 1, 2, and 3 are not necessary. Fully connected neural networks are widely used and can be explained briefly without drawing the architecture. \n\nPros:\n+ interesting problem\n+ future work. evaluation of embeddings is indeed a hard problem worth solving.\n\nCons:\n- not novel', 'Although this paper aims at an interesting and important task, the reviewer does not feel it is ready to be published.\nBelow are some detailed comments:\n\nPros\n- Numerous public datasets are used for the experiments\n- Good introductions for some of the existing methods.\nCons\n- The novelty is limited. The basic idea of the proposed method is to simply concatenate the embeddings of two nodes (via activation separately) from both side of edges, which is straightforward and produces only marginal improvement over existing methods (the comparison of Figure 1 and Figure 3 would suggest this fact). The optimization algorithm is not novel either.\n- Lack of detailed description and analysis for the proposed model S. In Section 5.2, only brief descriptions are given for the proposed approach.\n- The selected baseline methods are too weak as competitors, some important relevant methods are also missing in the comparisons. For the graph embedding learning task, one of the state-of-the-art approach is conducting Graph Convolutional Networks (GCNs), and GCNs seem to be able to tackle this problem as well. Moreover, the target task of this paper is mathematically identical to the rating prediction problem (if we treat the weight matrix of the graph as the rating matrix, and consider the nodes as users, for example), which can be loved by a classic collaborative filtering solution such as matrix factorization. The authors probably need to survey and compared against the proposed approach.', 'The paper presents a generic approach to graph link weight prediction problems based on node enbeddings. After introducing several existing methods, the paper proposes a ""generic"" link weight prediction approach that uses the node embedding produced by any node embedding techniques. Six datasets are used for evaluation. \n\nOverall, the difference to the existing method [1] is minor. I don\'t think there is much novelty in the ""generic"" approach. More essential abstraction and comprehensive analysis is needed for a strong ICLR paper. \n\n[1] Yuchen Hou and Lawrence B Holder. Deep learning approach to link weight prediction. In Neural\nNetworks (IJCNN), 2017 International Joint Conference on, pp. 1855–1862. IEEE, 2017.\n\n']","[-60, -60, -50]","[20, 20, 0]","[""The sentiment score is -60 because the reviewer expresses a negative opinion about the paper's contribution, stating it is 'not enough of a contribution' and 'not novel'. However, they do mention some positive aspects ('interesting problem', 'future work... worth solving'), which prevents the score from being extremely negative. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer some positive feedback. They refer to their opinion as 'professional' and use phrases like 'the authors propose' rather than more confrontational language. The reviewer also provides specific recommendations for improvement, which is constructive."", ""The sentiment score is -60 because the review starts with a negative overall assessment ('does not feel it is ready to be published') and lists more cons than pros. The cons are also more substantial, criticizing the novelty, methodology, and comparisons. However, it's not entirely negative as it acknowledges some positive aspects. The politeness score is 20 because the language is generally professional and constructive, avoiding harsh criticism. The reviewer uses phrases like 'the reviewer does not feel' instead of more direct negative statements, and provides specific suggestions for improvement. However, it's not overly polite, maintaining a neutral, objective tone throughout."", ""The sentiment score is -50 because the reviewer expresses a negative opinion about the paper's novelty and contribution, stating that 'the difference to the existing method is minor' and that 'More essential abstraction and comprehensive analysis is needed for a strong ICLR paper.' However, it's not entirely negative as the reviewer acknowledges the paper's approach and evaluation efforts. The politeness score is 0 (neutral) because the reviewer's language is neither particularly polite nor rude. They present their critique in a straightforward, professional manner without using overly harsh language or excessive praise. The review focuses on the content and quality of the paper rather than personal comments or emotional language.""]"
"['The paper uses an echo state network to learn to classify image transformations (between pairs of images) into one of fives classes.  The image data is artificially represented as a time series, and the goal is generalization of classification ability to unseen image pairs.  The network dynamics are studied and are claimed to have explanatory power.\n\nThe paper is well-written and easy to follow, but I have concerns about the claims it makes relative to how convincing the results are.  The focus is on one simple, and frankly now-overused data set (MNIST).  Further, treating MNIST data as a time series is artificial and clunky.  Why does the series go from left to right rather than right to left or top to bottom or inside out or something else?  How do the results change if the data is ""temporalized"" in some other way?\n\nFor training in Section 2.4, is M the number of columns for a pair of images?  It\'s not clear how pairs are input in parallel--- one after the other? Concatenated? Interleaved columns?  Something else? What are k, i, j in computing $\\delta X_k$?  Later, in Section 3.2, it says, ""As in section 2.2, $xl(mn)$ is the differential reservoir state value of the $m$th reservoir node at time $n$ for input image $l$"", but nothing like this is discussed in Section 2.2; I\'m confused.\n\nThe generalization results on this one simple data set seem pretty good.  But, how does this kind of approach do on other kinds of or more complex data?  I\'m not sure that RC has historically had very good success scaling up to ""real-world"" problems to date.\n\nTable 1 doesn\'t really say anything.  Of course, the diagonals are higher than the off diagonals because these are dot products.  True, they are dot products of averages over different inputs (which is why they are less than 1), but still.  Also, what Table 1 really seems to say is that the off-diagonals really aren\'t all that different than the diagonals, and that especially the differences between same and different digits is not very different, suggesting that what is learned is pretty fragile and likely won\'t generalize to harder problems.  I like the idea of using dynamical systems theory to attempt to explain what is going on, but I wonder if it is not being used a bit simplistically or naively.\n\nWhy were the five transform classes chosen?  It seems like the ""transforms"" a (same) and e (different) are qualitatively different than transforms b-d (rotated, scaled, blurred).  This seems like it should talked about.\n\n""Thus, we infer, that the reservoir is in fact, simply training these attractors as opposed to training the entire reservoir space.""  What does this mean?  The reservoir isn\'t trained at all in ESNs (which is also stated explicitly for the model presented here)…\n\nFor 3.3, why did were those three classes chosen? Was this experiment tried with other subsets of three classes?  Why are results reported on only the one combination of rotated/blurred vs. rotated?  Were others tried?  If so, what were the results?  If not, why?  How does the network know when to take more than the highest output (so it can say that two transforms have been applied)?  In the case of combination, counting either transform as the correct output kind of seems like cheating a bit—it over states how well the model is doing.  Also, does the order in which the transforms are applied affect their relative representative strength in the reservoir?\n\nThe comparison with SNNs is kind of interesting, but I\'m not sure that I\'m (yet) convinced, as there is little detail on how the experiment was performed and what was done (or not) to try to get the SNN to generalize.  My suspicion is that with the proper approach, an SNN or similar non-dynamical system could generalize well on these tasks.  The need for a dynamical system could be argued to make sense for the camera task, perhaps, as video frames naturally form a time series; however, as already mentioned, for the MNIST data, this is not the case, and the fact that the SNN does not generalize here seems likely due to their under utilization rather than due to an inherent lack of capability.\n\nI don\'t believe that there is sufficient support for this statement in the conclusion, ""[ML/deep networks] do not work as well for generalization of learning. In generalized learning, RCNs outperform them, due to their ability to function as a dynamical system with ‘memory’.""  First of all, ML is all about generalization, and there are lots and lots and lots of results showing that many ML systems generalize very well on a wide variety of problems, well beyond just classification, in fact.  And, I don\'t think the the paper has convincingly shown that a dynamical system \'memory\' is doing something especially useful, given that the main task studied, that of character recognition (or classification of transformation or even transformation itself), does not require such a temporal ability.\n', 'The claimed results of  ""combining transformations"" in the context of RC was done in the works of Herbert Jaeger on conceptors [1], which also should be cited here.\n\nThe argument of biological plausibility is not justified. The authors  use an echo-state neural network with standard tanh activations, which is as far away from real neuronal signal processing than  ordinary RNNs used in the field, with the difference that the recurrent weights are not trained.  If the authors want to make the case of biological plausibility, they should use spiking neural networks.\n\nThe experiment on MNIST seems artificial, in particular transforming the image into a time-series and thereby imposing an artificial temporal structure. The assumption that column_i is obtained  by information  of column_{i-k},..,column_{i-1} is not true for images. To make a point, the authors should use a datasets with related sets of time-series data, e.g EEG or NLP data.\n\nIn total this paper does not have enough novelty for acceptance and the experiments are not well chosen for this kind of work. Also the authors overstate the claim of biological plausibility (just because we don\'t train the recurrent weights does not make a method biologically plausible).\n\n[1] H. Jaeger (2014): Controlling Recurrent Neural Networks by Conceptors. Jacobs University technical report Nr 31 (195 pages) \n\n', 'The technical part of the paper is a nice study for classification with Echo State Networks. The main novelty here is the task itself, classifying different distortions of MNIST data. The actual technique presented is not original, but an application of the standard ESN approach. The task is interesting but by itself I don\'t find it convincing enough. Moreover, the biological plausibility that is used as an argument at several places seems to be false advertising in my view. The mere presence of recurrent connections doesn\'t make the approach more biological plausible, in particular given that ridge regression is used for training of the output weights. If biological plausibility was the goal, a different approach should have been used altogether (e.g., what about local training of connections, unsupervised training, ...). Also there is no argument why biological plausibility is supposed to be an advantage. A small number of training examples would have been a more specific and better motivation, given that the number of ""training"" examples for humans is only discussed qualitatively and without a reference. \n\nThe analysis using the PCs is nice; the works by Jaeger on Conceptors (2014) make also use of the principal components of the reservoir states during presentation of patterns (introduction in https://arxiv.org/abs/1406.2671), so seem like relevant references to me. \n\nIn my view the paper would benefit a lot from more ambitious task (with good results), though even then I would probably miss some originality in the approach.']","[-40, -70, -50]","[20, -20, 20]","[""The sentiment score is -40 because while the reviewer acknowledges that the paper is well-written and easy to follow, they express several significant concerns about the claims, methodology, and results. They question the use of MNIST as a dataset, the artificial treatment of data as time series, and the generalizability of the results. The reviewer also expresses skepticism about some of the conclusions drawn. However, it's not entirely negative as they do recognize some positive aspects, hence the score is not at the extreme negative end.\n\nThe politeness score is 20 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I have concerns,' 'I'm not sure,' and 'I wonder if,' which are polite ways to express criticism. The reviewer also acknowledges positive aspects before presenting criticisms. However, the score is not higher because the review is quite direct in its criticisms and doesn't use many overtly polite phrases or softeners."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states that the paper 'does not have enough novelty for acceptance', the experiments are 'not well chosen', and the authors 'overstate the claim of biological plausibility'. These are significant criticisms that suggest the reviewer does not recommend the paper for publication. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite direct and critical without much attempt to soften the feedback. Phrases like 'overstate the claim' and 'not well chosen' are blunt criticisms. However, the reviewer does provide specific recommendations and references, which prevents the score from being even lower."", ""The sentiment score is -50 because the reviewer expresses mixed feelings about the paper. While they acknowledge some positive aspects ('nice study', 'interesting task'), they also point out significant shortcomings ('not original', 'false advertising', 'miss some originality'). The overall tone suggests that the reviewer is not convinced by the paper's contributions. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'nice study' and 'would benefit', while also providing constructive criticism. However, the criticism is direct and doesn't use many softening phrases, keeping the score only slightly positive. The reviewer balances politeness with honest feedback, avoiding harsh language while clearly expressing concerns.""]"
"[""This paper examines a number of sentence and document embedding methods for automatic summarization. It pairs a number of recent sentence embedding algorithms (e.g., Paragraph Vectors and Skip-Thought Vectors) with several simple summarization decoding algorithms for sentence selection, and evaluates the resulting output summary on DUC 2004 using ROUGE, based on the general intuition that the selected summary should be similar to the original document in the vector space induced by the embedding algorithm. It further provides a number of analyses of the sentence representations as they relate to summarization, and other aspects of the summarization process including the decoding algorithm.\n\nThe paper was well written and easy to understand. I appreciate the effort to apply these representation techniques in an extrinsic task.\n\nHowever, the signficance of the results may be limited, because the paper does not respond to a long line of work in summarization literature which have addressed many of the same points. In particular, I worry that the paper may in part be reinventing the wheel, in that many of the results are quite incremental with respect to previous observations in the field.\n\nGreedy decoding and non-redundancy: many methods in summarization use greedy decoding algorithms. For example, SumBasic (Nenkova and Vanderwende, 2005), and HierSum (Haghighi and Vanderwende, 2009) are two such papers. This specific topic has been thoroughly expanded on by the work on greedy decoding for submodular objective functions in summarization (Lin and Bilmes, 2011), as well as many papers which focus on how to optimize for both informativeness and non-redundancy (Kulesza and Taskar, 2012). \n\t\nThe idea that the summary should be similar to the entire document is known as centrality. Some papers that exploit or examine that property include (Nenkova and Vanderwende, 2005; Louis and Nenkova, 2009; Cheung and Penn, 2013)\n \nAnother possible reading of the paper is that its novelty lies in the evaluation of sentence embedding models, specifically. However, these methods were not designed for summarization, and I don't see why they should necessarily work well for this task out of the box with simple decoding algorithms without finetuning. Also, the ROUGE results are so far from the SotA that I'm not sure what the value of analyzing this suite of techniques is.\n  \nIn summary, I understand that this paper does not attempt to produce a state-of-the-art summarization system, but I find it hard to understand how it contributes to our understanding of future progress in the summmarization field. If the goal is to use summarization as an extrinsic evaluation of sentence embedding models, there needs to be better justification of this is a good idea when there are so many other issues in content selection that are not due to sentence embedding quality, but which affect summarization results.\n\nReferences:\n\nNenkova and Vanderwende, 2005. The impact of frequency on summarization. Tech report.\nHaghighi and Vanderwende, 2009. Exploring content models for multi-document summarization. NAACL-HLT 2009.\nLin and Bilmes, 2011. A class of submodular functions for document summarization. ACL-HLT 2011.\nKulesza and Taskar, 2012. Learning Determinantal Point Processes.\nLouis and Nenkova, 2009. Automatically evaluating content selection in summarization without human models. EMNLP 2009.\nCheung and Penn, 2013. Towards Robust Abstractive Multi-Document Summarization: A Caseframe Analysis of Centrality and Domain. ACL 2013.\n\nOther notes:\nThe acknowledgements seem to break double-blind reviewing."", 'The authors report a number of experiments using off-the-shelf sentence embedding methods for performing extractive summarisation, using a number of simple methods for choosing the extracted sentences. Unfortunately the contribution is too minor, and the work too incremental, to be worthy of a place at a top-tier international conference such as ICLR. The overall presentation is also below the required standard. The work would be better suited for a focused summarisation workshop, where there would be more interest from the participants.\n\nSome of the statements motivating the work are questionable. I don\'t know if sentence vectors *in particular* have been especially successful in recent NLP (unless we count neural MT with attention as using ""sentence vectors""). It\'s also not the case that the sentence reordering and text simplification problems have been solved, as is suggested on p.2. \n\nThe most effective method is a simple greedy technique. I\'m not sure I\'d describe this as being ""based on fundamental principles of vector semantics"" (p.4).\n\nThe citations often have the authors mentioned twice.\n\nThe reference to ""making or breaking applications"" in the conclusion strikes me as premature to say the least.\n', 'This paper explored the effectiveness of four existing sentence embedding models on ten different document summarization methods leveraging various works in the literature. Evaluation has been conducted on the DUC-2004 dataset and ROUGE-1 and ROUGE-2 scores are reported. \n\nOverall, the paper significantly suffered from an immature writing style, numerous typos/grammatical mistakes, inconsistent organization of content, and importantly, limited technical contribution. Many recent sentence embedding models are missed such as those from Lin et al. (2017), Gan et al. (2017), Conneau et al. (2017), Jernite et al. (2017) etc. The evaluation and discussion sections were mostly unclear and the results of poorly performing methods were not reported at all making the comparisons and arguments difficult to comprehend. \n\nIn general, the paper seemed to be an ordinary reporting of some preliminary work, which at its current stage would not be much impactful to the research community.']","[-30, -70, -70]","[50, -20, -20]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('well written and easy to understand', 'appreciate the effort'), the overall tone is critical. The reviewer expresses concerns about the paper's significance, novelty, and contribution to the field. They suggest the paper may be 'reinventing the wheel' and question its value given the results are 'far from the SotA'. However, the criticism is not extremely harsh, hence a moderately negative score rather than strongly negative. The politeness score is 50 because the reviewer uses polite language throughout, acknowledging positives and framing criticisms as concerns or questions rather than direct attacks. Phrases like 'I appreciate the effort' and 'I understand that this paper does not attempt to...' show a considerate tone. The reviewer also provides detailed explanations and references to support their points, which is a respectful approach. However, the score is not higher as the review doesn't go out of its way to be exceptionally polite or encouraging."", ""The sentiment score is -70 because the reviewer expresses a clearly negative opinion about the paper, stating it's 'too minor' and 'too incremental' for the conference, and that the presentation is 'below the required standard'. They also criticize some of the authors' statements as 'questionable' and 'premature'. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical without much attempt to soften the blow. They use phrases like 'unfortunately', 'I don't know if...', and 'I'm not sure I'd describe this as...', which come across as somewhat dismissive. However, they do suggest an alternative venue for the work, which slightly mitigates the overall negative tone."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out numerous flaws such as 'immature writing style', 'numerous typos/grammatical mistakes', 'inconsistent organization', and 'limited technical contribution'. The reviewer also states that the paper is 'an ordinary reporting of some preliminary work' that 'would not be much impactful'. These criticisms significantly outweigh the neutral opening statement about what the paper explored.\n\nThe politeness score is -20 because while the reviewer doesn't use explicitly rude language, the tone is quite harsh and direct. Phrases like 'significantly suffered from' and 'poorly performing methods' are quite blunt criticisms. The reviewer also doesn't offer many positive comments or constructive suggestions for improvement, which contributes to the somewhat impolite tone. However, the review isn't extremely rude, hence the score is only slightly negative.""]"
"['The authors of the paper advocate injecting noise into the activations of recurrent networks for regularisation. This is done  by replacing the deterministic units with stochastic ones.\n\nThe paper has several issues with respect to the method and related work. \n\n- The paper needs to mention [Graves 2011], which is one of the first works to inject noise into the dynamics of an RNN. It is also important to know how these two approaches differ. E.g.: Under what conditions are the two approaches equivalent? How do they compare experimentally?\n- While [Bayer & Osendorfer, 2014] and [Chung et al, 2015] appear in the list of references, these works are not discussed in the main text. I personally think these are extremely related, pioneering the use of stochastic units in a recurrent context. In the end, the original paper can be cast in these frameworks approximately by removing the KL term of the ELBO. This might be ok by itself, but that the authors are apparently aware of the work (as it is in the list of references) and not discussing them in the main text makes me highly skeptical.\n- The method is introduced for general exponential families, but a) not empirically evaluated for more than the Gaussian case and b) not a complete algorithm for e.g. the Bernoulli case. More specifically, the reader is left alone with the problem of estimating the gradients in the Bernoulli case, which is an active area of research by itself.\n- The paper makes use of the reparameterisation trick, but does not cite the relevant literature, e.g. [Kingma 2013, Rezende 2014, and another one I currently struggle to find].\n- The desiderate for noise seem completely arbitrary to me and are not justified. I don’t see why violation of any of them would lead to an inferior regularisation method.\n\n### References\n[Graves 2011] Graves, Alex. ""Practical variational inference for neural networks."" Advances in Neural Information Processing Systems. 2011.\n[Kingma 2013] Kingma, Diederik P., and Max Welling. ""Auto-encoding variational bayes."" arXiv preprint arXiv:1312.6114 (2013).\n[Rezende 2014] Rezende, Danilo Jimenez, Shakir Mohamed, and Daan Wierstra. ""Stochastic backpropagation and approximate inference in deep generative models."" arXiv preprint arXiv:1401.4082 (2014).\n', ""The RNN transition function is: h_t+1 = f(h_t,x_t)\nThis paper proposes using a stochastic transition function instead of a deterministic one.\ni.e h_{t+1} \\sim expfam(mean = f(h_t,x_t), gamma) where expfam denotes a distribution from the exponential family.\n\nThe experimental results consider text modeling (evaluating on perplexity) on Penn Treebank and Wikitext-2. The method of regularization is compared to a reimplementation of Variational Dropout and no regularization.\n\nThe work is written clearly and easy to follow.\n\nOverall, the core idea in this work is interesting but underexplored. \n\n* As of when I read this paper, all results on this work used 200 hidden units realizing results that were well off from the state of the art results on Penn Tree Bank (as pointed out by the external reader).\nThe authors responded by stating that this was done to achieve a relative comparison.  A more interesting comparison, in addition to the ones presented, would be to see how well each method performs while not controlling for hidden layer size. Then, it might be that restricting the number of hidden dimensions is required for the RNN without any regularization but for both Variational Dropout and Noisin, one obtains better results with a larger the hidden dimension.\n\n* The current experimental setup makes it difficult to assess when the proposed regularization is useful. Table 2 suggests the answer is sometimes and Table 3 suggests its marginally useful when the RNN size is restricted.\n\n* How does the proposed method's peformance compare to Zoneout https://arxiv.org/pdf/1606.01305.pdf?\n\n* Clarifying the role of variational inference: I could be missing something but I don't see a good reason why the prior (even if learned) should be close to the true posterior under the model. I fear the bound in Section (3) [please include equation numbers in the paper] could be quite loose.\n\n* What is the rationale for not comparing to the model proposed in [Chung et. al] where there is a stochastic and deterministic component to the transition function? In what situations do we expect the fully stochastic transition here to work better than a model that has both? Presumably, some aspect of the latent variable + RNN model could be expressed by having a small variance for a subset of the dimensions and large one for the others\nbut since gamma is the same across all dimensions of the model, I'm not sure this feature can be incorporated into the current approach. Such a comparison would also empirically verify what happens when learning with the prior versus doing inference with an approximate posterior helps.\n\n* The regularization is motivated from the point of view of sampling the hidden states to be from the exponential family, but all the experiments provided seem to use a Gaussian distribution. This paper would be strengthened by a discussion and experimentation with other kinds of distributions in the exponential family."", 'In order to regularize RNNs, the paper suggests to inject noise into hidden units. More specifically, the suggested technique resembles optimizing the expected log likelihood under the hidden states prior, a lower bound to the data log-likelihood.\n\nThe described approach seems to be simple. Yet, several details are unclear, or only available implicitly. For example, on page 5, the Monte Carlo estimation of Lt is given (please use equation number on every equation). What is missing here are some details on how to compute the gradient for U and Wl. A least zt is sampled from zt-1, so some form of e.g. reparameterization has to happen for gradient computation? Are all distributions from the exponential family amendable to this type of reparamterization? With respect to the Exp. Fam.: During all experiments, only Gaussians are used? why cover this whole class of distributions? Experiments seem to be too small: After all the paper is about regularization, why are there no truely large models, e.g. like state-of-the-art instances? What is the procedure at test time?']","[-70, -20, -20]","[20, 60, 50]","[""The sentiment score is -70 because the review is predominantly critical, pointing out several significant issues with the paper, including missing citations, lack of discussion on related work, incomplete algorithm presentation, and arbitrary desiderates. The reviewer uses phrases like 'has several issues', 'makes me highly skeptical', and 'completely arbitrary', indicating a negative sentiment. However, it's not entirely negative as the reviewer acknowledges the paper's main idea in the first paragraph. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use polite phrases like 'needs to mention' and 'I personally think' rather than harsh language. The reviewer also provides constructive feedback and specific references to improve the paper, which is considerate. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'interesting' and 'clearly written', they also point out several limitations and areas for improvement. The overall tone suggests that the paper is underexplored and lacks comprehensive comparisons. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects and framing criticisms as suggestions for improvement. They use phrases like 'The work is written clearly' and 'Overall, the core idea in this work is interesting' before presenting their concerns. The reviewer also uses polite language when making suggestions, such as 'A more interesting comparison would be...' and 'This paper would be strengthened by...', indicating a constructive approach rather than harsh criticism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the approach as 'simple', they point out several unclear details and missing information. They also suggest the experiments are too small and question why certain aspects were included. This indicates some dissatisfaction with the paper's completeness and experimental rigor. The politeness score is moderately positive (50) as the reviewer uses neutral language and phrases criticisms as questions or suggestions rather than direct criticisms. They use phrases like 'seems to be' and 'What is missing here' which soften the critique. The reviewer also acknowledges positive aspects ('simple' approach) before diving into criticisms, which is a polite reviewing technique.""]"
"['Summary:\nThe submission proposes a simple modification to the Value Iteration Networks (VIN) method of Tamar et al., basically consisting of assuming a stochastic policy and replacing the max-over-actions in value iteration with an expectation that weights actions proportional to their exponentiated Q-values. Since this change removes the main nondifferentiability of VINs, it is hypothesized that the resulting method will be easier to train than VINs, and experiments seem to support this hypothesis.\n\nPros:\n+ The proposed modification to VIN is simple, well-motivated, and addresses the nondifferentiability of VIN\n+ Experiments on synthetic data demonstrate a significant improvement over the standard VIN method\n\nCons:\n+ Some important references are missing (e.g., MaxEnt IOC with deep-learned features)\n+ Although intuitive, more detailed justification could be provided for replacing the max-over-actions with an exponentially-weighted average\n+ No baselines are provided for the experiments with real data\n+ All the experimental scenarios are fairly simple (2D grid-worlds with discrete actions, 1-channel input features)\n\nThe proposed method is simple, well-motivated, and addresses a real concern in VINs, which is their nondifferentiability. Although many of the nonlinearities used in CNNs for computer vision applications are nondifferentiable, the theoretical grounds for using these in conjunction with gradient-based optimization is obviously questionable. Despite this, they are widely used for such applications because of strong empirical results showing that such nonlinearities are beneficial in image-processing applications. However, it would be incorrect to assume that because such nonlinearities work for image processing, they are also beneficial in the context of unrolling value iteration.\n\nReplacing the max-over-actions with an exponentially-weighted average is an intuitively well-motivated alternative because, as the authors note, it incorporates the values of suboptimal actions during the training procedure. We would therefore expect better or faster training, as the values of these suboptimal actions can be updated more frequently. The (admittedly limited) experiments bear out this hypothesis.\n\nPerhaps the most significant downside of this work is that it fails to acknowledge prior work in the RL and IOC literature that result in similar  “smoothed” or “softmax"" Bellman updates: in particular, MaxEnt IOC [A] and linearly-solvable MDPs [B] both fall in this category. Both of those papers clearly derive approximate Bellman equations from modified optimal control principles; although I believe this is also possible for the proposed update (Eq. 11), along the lines of the sentence after Eq. 11, this should be made more explicit/rigorous, and the result compared to [A,B].\n\nAnother important missing reference is [C], which learned cost maps with deep neural networks in a MaxEnt IOC framework. As far as I can tell, the application is identical to that of the present paper, and [C] may have some advantages: for instance, [C] features a principled, fully-differentiable training objective while also avoiding having to backprop through the inference procedure, as in VIN. Again, this raises the question of how the proposed method compares to MaxEnt IOC, both theoretically and experimentally.\n\nThe experiments are also a bit lacking in a few ways. First, a baseline is only provided for the experiments with synthetic data. Although that experiment shows a promising, significant advantage over VIN, the lack of baselines for the experiment with real data is disappointing. Furthermore, the setting for the experiments is fairly simple, consisting of a grid-world with 1-channel input features. The setting is simple enough that even shallow IOC methods (e.g., [D]) would probably perform well; however, the deep IOC methods of [C] is also applicable and should probably also be evaluated as a baseline.\n\nIn summary, although the method proposes an intuitively reasonable modification to VIN that seems to outperform it in limited experiments, the submission fails to acknowledge important related work (especially the MaxEnt IOC methods of [A,D]) that may have significant theoretical and practical advantages. Unfortunately, I believe the original VIN paper also failed to articulate the precise advantages of VIN over this prior work—which is not to say there are none, but it is clear that VINs applied to problems as simple as the one considered here have real competitors in prior work. Clarifying this connection, both theoretically and experimentally, would make this work much stronger and would be a valuable contribution to the literature.\n\n[A] Ziebart, Brian D. Modeling purposeful adaptive behavior with the principle of maximum causal entropy. Carnegie Mellon University, 2010.\n[B] Todorov, Emanuel. ""Linearly-solvable Markov decision problems."" Advances in neural information processing systems. 2007.\n[C] Wulfmeier et al. Watch This: Scalable Cost-Function Learning for Path Planning in Urban Environments. IROS 2016\n[D] Ratliff, Nathan D., David Silver, and J. Andrew Bagnell. ""Learning to search: Functional gradient techniques for imitation learning."" Autonomous Robots 27.1 (2009): 25-53.\n', 'Summary:\n\nThe Value-Iteration-Network (VIN) architecture is modified to have a softmax loss function at the end. This is termed SVIN. It is then applied in a behavior cloning manner to the task of rover path planning from start to goal from overhead imagery.\n\nSimulation results on binary obstacle maps and using real-world Mars overhead orbiter maps are shown. On the simulation maps SVIN is shown to achieve 15-20% better lower training error than VIN.\n\nOne the Mars images it trains up to 45% training accuracy. (What was testing accuracy?)\n\n\nComments:\n\n- Section 1.1: ""Autonomous driving techniques also exist, though they lack the ability to do high level planning to choose paths that are advantageous for longer term navigation."" --This is not true. See any of the numerous good systems described in literature. See the special editions of the Journal of Field Robotics on DARPA Urban Challenge and Desert Challenge or any of the special editions for the Learning Applied to Ground Robots (LAGR) program for excellent literature describing real-world autonomous ground vehicle systems. And specifically for the case of predicting good long-term trajectories from overhead imagery see: Sofman, B., Lin, E., Bagnell, J. A., Cole, J., Vandapel, N., & Stentz, A. (2006). Improving robot navigation through self‐supervised online learning. Journal of Field Robotics. (Papers related to this have been cited in this paper already).\n\n- Section 4.1: ""During training the output from the VI module is fed to an action selection function to compare those results against actions chosen in the training data."": What is the action selection function? Is it a local planner (e.g. receding-horizon model-predictive control)? Is it a global planner with access to full map to the goal (e.g. A* run all the way to the goal location assuming that during training the entire map is available)? Same question for Figure 2 where the \'expert action\' block doesn\'t specify who is the expert here (computational or human).\n\n- Section 2: ""Imitation learning for navigation has been studied by other groups as well (Silver et al. 2010)"": That particular paper is about using inverse optimal control (aka inverse reinforcement learning) and not imitation learning for first learning a good terrain cost function and then using it in a receding-horizon fashion. For imitation learning in navigation see ""Learning Monocular Reactive UAV Control in Cluttered Natural Environments"" by Ross et al. and relevant literature cited therein.\n\n- My main concerns with the experiments is that they are not answering two main questions: 1. What is SVIN/VIN bringing to the table as a function approximator as opposed to using a more traditional but similar capacity CNN? 2. Why are the authors choosing to do essentially behavior cloning as opposed to imitation learning? It is well established (both theoretically and empirically) that imitation learning has mistake bounds which are linear in the time horizon while behavior cloning is quadratic. See Ross et al., ""A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning.""\n\n- Figure 6: Please mark the goal points. It is not obvious where it is from the field arrows.\n\n- Figure 8: Are white regions high/low cost? It is not obvious from the pictures what is being avoided by the paths.\n\n- What does 45% accuracy actually mean? Are the predicted paths still usable? No figures showing some qualitative good and bad examples are shown so hard to tell.\n\n- On the rover overhead imagery if a simple A*/Dijkstra search algorithm was run from start to goal using the DEM as a heuristic cost map, how well will it do compared to SVIN?\n', 'To my understanding, the focus of the paper is to learn a reward function based on expert trajectories. To do so, they use a Value Iteration Module to make the planning step differentiable.\nTo improve training, they propose to replace the max-operator in value iteration by a softmax operator.\n\nI believe the paper should be rejected. I will outline my major concerns below.\n\n1. I have a difficult time identifying the (large enough) novel contribution. The algorithm uses automatic differentiation through an approximate value iteration (approximate because it is only performed for k iterations) to learn a reward function. To me this seems like a very straightforward case of inverse reinforcement learning (with which I admittedly am not too familiar). I think at least inverse RL should be mentioned and the relationship to it should be discussed in the paper (which it is currently not). \n2. The experimental results are not convincing. In my opinion, the first experiment is too simple to showcase the algorithm. In particular, note that the number of total parameters learned are in the order of only 100 or less for the 2 layer reward network, depending on how many \'other layers\' are used as input (and everything else I understand to be fixed). Furthermore, one input layer corresponds to a one hot encoding of the goal, which is also a correct output of the reward function. Consequently, the reward function must only learn the identity function (or a multiple thereof). This is further simplified by only using 1x1 convolutions. The second experiment doesn\'t have a baseline to compare the results against so it is hard to judge how well the algorithm performs.\n3. I am not sure that there is enough similarity to Value Iteration Networks that it should be described as an extension thereof. As far as I understand it, the original Value Iteration Network consists of the Value-Iteration Module as well as several other modules. In the reviewed paper, it seems that only the Value Iteration Module is used. Furthermore, in the current paper, the transition kernels are not learned. \n\n\nSmaller notes:\n- One could include a background section briefly explaining Value Iteration Networks. Or leave out VINs completely as I\'m not sure there is too much similarity. But I might be wrong.\n- 1. Paragraph in ""3. Preliminaries"", last sentence: Albeit obvious, it should be included how $a_t$ and $s_t$ are drawn for $t>0$ and $t>1$ respectively\n- In 4.2: Traninable => trainable\n- In 4.3: As the algorithm is not actually tested on any mars rover, I wouldn\'t include that part in the ""Algorithm"" section. Maybe in the conclusion/outlook instead?\n- In 4.4, second paragraph: stacked = added? I guess both would work but what would be the advantage of stacking, especially when the kernel is known and fixed (and I assume simply performs a discounted addition?)\n- Please use a larger font in your plots\n- Figure 6: While I like the idea of having a qualitative analysis of the results, it would be nice if red and green arrows would be easier to tell apart. The green ones are hard to find at the moment.\n']","[-20, -50, -70]","[60, 20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pros'), they also point out several significant shortcomings ('Cons'). The review highlights missing references, lack of detailed justification, absence of baselines for real data experiments, and simplicity of experimental scenarios. The overall tone suggests that the work has potential but needs substantial improvements.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'well-motivated', 'addresses a real concern', and 'promising, significant advantage' when discussing positive aspects. Even when pointing out weaknesses, the language remains constructive and not personally critical. The reviewer offers suggestions for improvement and provides specific references, which is helpful and courteous. However, the score is not higher as the review doesn't go out of its way to be exceptionally polite or encouraging."", ""The sentiment score is -50 because the review is predominantly critical, pointing out several issues with the paper. The reviewer raises concerns about inaccurate statements, unclear methodologies, and limitations in the experiments. However, it's not entirely negative as the reviewer acknowledges some positive aspects like the simulation results showing improvements over VIN. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'My main concerns' and 'Please mark' which are polite ways of expressing issues. The reviewer also provides constructive feedback and suggestions for improvement, which is a polite approach to criticism. However, the review doesn't go out of its way to be overly polite or complimentary, hence the relatively low positive score."", ""The sentiment score is -70 because the reviewer explicitly states 'I believe the paper should be rejected' and outlines several major concerns. The overall tone is critical and negative, pointing out multiple shortcomings in the paper's novelty, experimental results, and comparisons to existing work. However, it's not entirely negative as the reviewer does acknowledge some positive aspects and provides constructive feedback. The politeness score is 20 because while the reviewer is direct in their criticism, they use polite language such as 'I believe' and 'In my opinion'. They also provide detailed explanations for their concerns and offer suggestions for improvement, which is considerate. The language is professional and avoids personal attacks, maintaining a respectful tone despite the negative evaluation.""]"
"['Make SVM great again with Siamese kernel for few-shot learning \n\n** PAPER SUMMARY **\n\nThe author proposes to combine siamase networks with an SVM for pair classification. The proposed approach is evaluated on few shot learning tasks, on omniglot and timit.  \n\n\n** REVIEW SUMMARY **\n\nThe paper is readable but it could be more fluent. It lacks a few references and important technical aspects are not discussed. It contains a few errors. Empirical contribution seems inflated on omniglot as the authors omit other papers reporting better results. Overall, the contribution is modest at best.\n\n** DETAILED REVIEW **\n\nOn mistakes, it is wrong to say that an SVM is a parameterless classifier. It is wrong to cite (Boser et al 92) for the soft-margin SVM. I think slack variables come from (Cortes et al 95). ""consistent"" has a specific definition in machine learning https://en.wikipedia.org/wiki/Consistent_estimator , you must use a different word in 3.2. You mention that a non linear SVM need a similarity measure, it actually need a positive definite kernel which has a specific definition, https://en.wikipedia.org/wiki/Positive-definite_kernel .\n\nOn incompleteness, it is not obvious how the classifier is used at test time. Could you explain how classes are predicted given a test problem? The setup of the experiments on TIMIT is extremely unclear. What are the class you are interested in? How many classes and examples does the testing problems have? \n\nOn clarity, I do not understand why you talk again about non-linear SVM in the last paragraph of 3.2. since you mention at the end of page 4 that you will only rely on linear SVMs for computational reasons. You need to mention explicitely somewhere that (w,\\theta) are optimized jointly. The sentence ""this paper investigates only the one versus rest approach"" is confusing, as you have only two classes from the SVM perspective i.e. pairs (x1,x2) where both examples come from the same class and pairs (x1,x2) where they come from different class. So you use a binary SVM, not one versus rest. You need to find a better justification for using L2-SVM than ""L2-SVM loss variant is considered to be the best by the author of the paper"", did you try classical SVM and found them performing worse? Also could you motivate your choice for L1 norm as opposed to L2 in Eq 3?\n\nOn empirical evaluation, I already mentioned that it impossible to understand what the classification problem on TIMIT is. I suspect it might be speaker identification. So I will focus on the omniglot experiments. \n\nFew-Shot Learning Through an Information Retrieval Lens, Eleni Triantafillou, Richard Zemel, Raquel Urtasun, NIPS 2017 [arxiv July\'17]\n\nand the reference therein give a few more recent baselines than your table. Some of the results are better than your approach. I am not sure why you do not evaluate on mini-imagenet as well as most work on few shot learning generally do. This dataset offers a clearer experimental setup than your TIMIT setting and has abundant published baseline results. Also, most work typically use omniglot as a proof of concept and consider mini-imagenet as a more challenging set. ', 'After reading the rebuttal:\n\nThis paper does have encouraging results. But as mentioned earlier, it still lacks systematic comparisons with existing (and strongest) baselines, and perhaps a better understanding the differences between approaches and the pros and cons. The writing also needs to be improved. So I think the paper is not ready for publication and my opinion remains.\n===========================================================\n\nThis paper presents an algorithm for few shot learning. The idea is to first learn representation of data using the siamese networks architecture, which predicts if a pair of two samples are similar (e.g., from the same class) or not using a SVM hinge loss, and then finetune the classifier using few labeled examples (with possibly a different set of labels). I think the idea of representation learning using a somewhat artificial task makes sense in this setting. \n\nI have several concerns for this submission.\n1. I am not very familiar with the literature of few shot learning. I think a very related approach that learns the representation using pretty much the same information is the contrastive loss:\n-- Hermann and Blunsom. Multilingual Distributed Representations without Word Alignment. ICLR 2014.\nThe intuition is similar: similar pairs shall have higher similarity in the learned representation, than dissimilar pairs, by a large margin. This approach is useful even when there is only weak supervision to provide the ""similarity/dissimilarity"" information. I wonder how does this approach compare with the proposed method.\n\n2. The experiments are conducted on a small dataset OMNIGLOT and TIMIT. I do not understand why the compared methods are not consistently used in both experiments. Also, the experiment of speaker classification on TIMIT (where the inputs are audio segments with different durations and sampling frequency) is a quite nonstandard task; I do not have a sense of how challenging it is. It is not clear why CNN transfer learning (the authors did not give details about how it works) performs even worse than the non-deep baseline, yet the proposed method achieves very high accuracy. It would be nice to understand/visualize what information have been extracted in the representation learning phase. \n\n3. Relatively minor: The writing of this paper is readable, but could be improved. It sometimes uses vague/nonstandard terminology (""parameterless"") and statement. The term ""siamese kernel"" is not very informative: yes, you are learning new representations of data using DNNs, but this feature mapping does not have the properties of RKHS; also you are not solving the SVM dual problem as one typically does for kernel SVMs. In my opinion the introduction of SVM can be shortened, and more focuses can be put on related deep learning methods and few shot learning.', 'Summary: \nThe paper proposes to pre-train a deep neural network to learn a similarity function and use the features obtained by this pre-trained network as input to an SVM model. The SVM is trained for the final classification task at hand using the last layer features of the deep network. The motivation behind all this is to learn the input features to the SVM as opposed to hand-crafting them, and use the generalization ability of the SVM to do well on tasks which have only a handful of training examples. The authors apply their technique to two datasets, namely, the Omniglot dataset and the TIMIT dataset and show that their model does a reasonable job in these two tasks. \n\nWhile the paper is reasonably clearly written and easy to read I have a number of objections to it. \n\nFirst, I did not see any novel idea presented in this paper. Lots of people have tried pre-training a neural network on auxiliary task(s) and using the features from it as input to the final SVM classifier. People have also specifically tried to train a siamese network and use its features as input to the SVM. These works go way back to the years 2005 - 2007, when deep learning was not called deep learning. Unless I have missed something completely, I did not see any novel idea proposed in this paper. \n\nSecond, the experiments are quite underwhelming and does not fully support the superiority claims of the proposed approach. For example, the authors compare their model against rather weak baselines. While the approach (as has been shown in the past) is very reasonable, I would have liked the experiments to be more thorough, with comparison to the state of the art models for the two datasets. \n']","[-50, -50, -60]","[20, 20, 20]","[""The sentiment score is -50 because the review is generally critical, pointing out several mistakes, incompleteness, and clarity issues. The reviewer states the contribution is 'modest at best' and that empirical results seem 'inflated'. However, it's not entirely negative as the reviewer acknowledges some positive aspects like readability. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'could you explain' and 'I do not understand' rather than accusatory language. The reviewer also provides constructive feedback and suggestions for improvement, which contributes to the politeness. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -50 because the reviewer expresses several concerns and states the paper is 'not ready for publication'. However, they do acknowledge some 'encouraging results', preventing a more negative score. The politeness score is 20 because the reviewer uses generally polite language, offering constructive criticism and suggestions rather than harsh criticism. They use phrases like 'I think' and 'It would be nice to' which soften their critiques. However, the tone remains professional rather than overtly friendly, hence the moderate positive score."", ""The sentiment score is -60 because the reviewer expresses several significant objections to the paper. They state that they 'have a number of objections' and that they 'did not see any novel idea presented'. The reviewer also describes the experiments as 'quite underwhelming'. These criticisms indicate a negative sentiment, though not extremely harsh. The politeness score is 20 because while the reviewer is critical, they use relatively polite language. They begin by acknowledging that the paper is 'reasonably clearly written and easy to read'. They also use phrases like 'I would have liked' rather than making blunt demands. The tone is professional and constructive, even while being critical, which indicates a slight positive in terms of politeness.""]"
"['This paper is an experimental paper. It investigates what sort of image representations are good for image captioning systems. \n\nOverall, the idea seems relevant and there are some good findings but I am sure that image captioning community is already aware of these findings.\n\nThe main issue of the paper is the lack of novelty. Even for an experimental paper, I would argue that novelty in the experimental methodology is an important fact. Unfortunately, I do not see any novel concept in the experimental setup.\n\nI recomend this paper for a workshop presentation.\n', 'The paper claims that image captioning systems work so well, while most recent state of the art papers show that they produce 50% errors, so far from perfect.\n\nThe paper lacks novelty, just reports some results without proper analysis or insights.\n\nMain weakness of the paper:\n - Missing many IC systems citations and comparisons (see https://competitions.codalab.org/competitions/3221#results)\n - According to ""SPICE: Semantic Propositional Image Caption Evaluation"" current metrics used in image captioning don\'t correlate with human judgement.\n- Most Image Caption papers which use a pre-trained CNN model, do fine-tune the image feature extractor to improve the results (see Vinyals et al. 2016). Therefore correlation of the image features with the captions is weaker that it could be.\n- The experiments reported in Table1 are way below state-of-the-art results, there a tons of previous work with much better results, see https://competitions.codalab.org/competitions/3221#results\n - To provide a fair comparison authors, should compare their results with other paper results.\n - Tables 2 and 3 are missing the original baselines.\nThe evaluation used in the paper don\'t correlate well with human ratings see (SPICE paper), therefore trying to improve them marginally doesn\'t make a difference.\n- Getting better performance by switching from VGG19 to ResNet152 is expected, however they obtain worse results than Vinyals et al. 2016 with inception_v3. \n- The claim ""The bag of objects model clusters these group the best"" is not supported by any evidence or metric.\n\nOne interesting experiment but missing in section 4.4 would be how the image features change after fine-tuning for the captioning task.\n\n\nTypos:\n - synsest-level -> synsets-level', ""This paper analyzes the effect of image features on image captioning. The authors propose to use a model similar to that of Vinyals et al., 2015 and change the image features it is conditioned on. The MSCOCO captioning and Flickr30K datasets are used for evaluation.\n\nIntroduction\n- The introduction to the paper could be made clearer - the authors talk about the language of captioning datasets being repetitive, but that fact is neither used or discussed later.\n- The introduction also states that the authors will propose ways to improve image captioning. This is never discussed.\n\nCaptioning Model and Table 1\n- The authors use greedy (argmax) decoding which is known to result in repetitive captions. In fact, Vinyals et al. note this very point in their paper. I understand this design choice was made to focus more on the image side, rather than the decoding (language) side, but I find it to be very limiting. In this regime of greedy decoding it is hard to see any difference between the different ConvNet features used for captioning - Table 1 shows meteor scores within 0.19 - 0.22 for all methods.\n- Another effect (possibly due to greedy decoding + choice of model), is that the numbers in Table 1 are rather low compared to the COCO leaderboard. The top 50 entries have METEOR scores >= 0.25, while the maximum METEOR score reported by the authors is 0.22. Similar trend holds for other metrics like BLEU-4.\n- The results of Table 5 need to be presented and interpreted in the light of this caveat of greedy decoding.\n\nExperimental Setup and Training Details\n- How was the model optimized? No training details are provided. Did you use dropout? Were hyperparamters fixed for training across different feature sizes of VGG19 and ResNet-152? What is the variance in the numbers for Table 1?\n\nMain claim of the paper\nDevlin et al., 2015 show a simple nearest neighbor baseline which in my opinion shows this more convincingly. Two more papers from the same group which use also make similar observations - tweaking the image representation makes image captioning better: (1) Fang et al., 2015: Multiple-instance Learning using bag-of-objects helps captioning (2) Misra et al. 2016 (not cited): label noise can be modeled which helps captioning. This claim has been both made and empirically demonstrated earlier.\n\nMetrics for evaluation\n- Anderson et al., 2016 (not cited) proposed the SPICE metric and also showed how current metrics including CiDER may not be suitable for evaluating image captions. The COCO leaderboard also uses this metric as one of its evaluation metrics. If the authors are evaluating on the test set and reporting numbers, then it is odd that they `skipped' reporting SPICE numbers.\n\nChoice of Datasets\n- If we are thoroughly evaluating the effect of image features, doing so on other datasets is very important. Visual Genome (Krishnan et al., not cited) and SIND (Huang et al., not cited) are two datasets which are both larger than Flickr30k and have different image distributions from MSCOCO. These datasets should show whether using more general features (YOLO-9k) helps.\nThe authors should evaluate on these datasets to make their findings stronger and more valuable.\n\nMinor comments\n- Figure 1 is hard to read on paper. Please improve it.\n- Figure 2 is hard to read even on screen. It is really interesting, so improving the quality of this figure will really help.""]","[-20, -80, -50]","[50, -20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some good findings and relevance, they express concerns about the lack of novelty and suggest the findings are already known in the community. The overall tone suggests the paper is not strong enough for full publication, recommending it for a workshop presentation instead. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positive aspects before presenting criticisms, and uses phrases like 'I would argue' to soften their critique. They also provide a constructive suggestion at the end rather than outright rejection."", ""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer criticizes the paper's claims, lack of novelty, missing citations, outdated metrics, weak experiments, and unsupported assertions. There are no positive comments about the paper. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without any softening language or positive feedback. The reviewer uses phrases like 'lacks novelty,' 'missing,' and 'weakness' without tempering them. The tone is matter-of-fact but borders on harsh in its criticism. The only somewhat constructive element is the suggestion for an additional experiment at the end, which slightly improves the politeness score from being even lower."", ""The sentiment score is -50 because the review is generally critical, pointing out several limitations and areas for improvement. The reviewer highlights issues with the introduction, experimental setup, and the main claim of the paper. However, it's not entirely negative as the reviewer also acknowledges some interesting aspects (e.g., Figure 2). The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and offer constructive feedback. They use phrases like 'could be made clearer' and 'I understand this design choice' which maintain a respectful tone. The reviewer also provides specific suggestions for improvement, which is helpful and polite. However, the overall tone is more neutral than overtly polite, hence the moderate positive score.""]"
"['This paper proposes a model for learning to generate data conditional on attributes. Demonstrations show that the model is capable of learning to generate data with attribute combinations that were not present in conjunction at training time.\n\nThe model is interesting, and the results, while preliminary, suggest that the model is capable of making quite interesting generalizations (in particular, it can synthesize images that consist of settings of features that have not been seen before).\n\nHowever, this paper is mercilessly difficult to read. The most serious problems are the extensive discussion of the fully unsupervised variant (rather than the semisupervised variant that is evaluated), poor use of examples when describing the model, nonstandard terminology (“concepts” and “context” are extremely vague terms that are not defined precisely) and discussions to vaguely related work that does not clarify but rather obscures what is going on in the paper.\n\nFor the evaluation, since this paper proposes a technique for learning a posterior recognition model, it would be extremely interesting to see if the model is capable of recognizing images appropriately that combine “contexts” that were not observed during training. The experiments show that the generation component is quite effective, but this is an obvious missing step.\n\nAnyway, some other related work:\nLample et al. (2017 NIPS). Fader Networks. I realize this work is more ambitious since it seeks to be a fully generative model including of the contexts/attributes. But I mostly bring it up because it is an impressively clear presentation of a model and experimental set up.', 'This paper introduces a conditional variant of the model defined in the Neural Statistician (https://arxiv.org/abs/1606.02185). The generative model defines the process that produces the dataset. This model is first a mixture over contexts followed by i.i.d. generation of the dataset with possibly some unobserved random variable. This corresponds to a mixture of Neural Statisicians. The authors suggest that such a model could help with disentangling factors of variation in data. In the experiments they only consider training the model with the context selection variable and the data variables observed.\n\nUnfortunately there is minimal quantitative evaluation (visualizing 264 MNIST samples is not enough). The only quantitative evaluation is in Table 1, and it seems the model is not able to generalize reliably to all rotations and all digits. Clearly, we can\'t expect perfect performance, but there are some troubling results: 5.2 accuracy on non-rotated 0s, 0.0 accuracy on non-rotated 6s. Every digit has at least one rotation that is not well classified, so this section could use more discussion and analysis. For example, how would this metric classify VAE samples with contexts corresponding only to digit type (no rotations)? How would this metric classify vanilla VAE samples that are hand labeled? Moreover, the context selection variable ""a"" should be considered part of the dataset, and as such the paper should report how ""a"" was selected.\n\nThis model is a relatively simple extension of the Neural Statistician, so the novelty of the idea is not enough to counterbalance the lack of quantitative evaluation. I do think the idea is well-motivated, and represents a promising way to incorporate prior knowledge of concepts into our training of VAEs. Still, the paper as it stands is not complete, and I encourage the authors to followup with more thorough quantitative empirical evaluations.\n', ""The authors propose an extension to the Neural Statistician which can model contexts with multiple partially overlapping features. This model can explain datasets by taking into account covariate structure needed to explain away factors of variation and it can also share this structure partially between datasets.\n\nA particularly interesting aspect of this model is the fact that it can learn these context c as features conditioned on meta-context a, which leads to a disentangled representation.\nThis is also not dissimilar to ideas used in 'Bayesian Representation Learning With Oracle Constraints' Karaletsos et al 2016 where similar contextual features c are learned to disentangle representations over observations and implicit supervision.\n\nThe authors provide a clean variational inference algorithm to learn their model. However, a key problem is the following: the nature of the discrete variables being used makes them hard to be inferred with variational inference. The authors mention categorical reparametrization as their trick of choice, but do not go into empirical details int heir experiments regarding the success of this approach. In fact, it would be interesting to study which level of these variables could be analytically collapsed (such as done in the Semi-Supervised learning work by Kingma et al 2014) and which ones can be sampled effectively using a form of reparametrization.\n\nThis also touches on the main criticism of the paper: While the model technically makes sense and is cleanly described and derived,  the empirical evaluation is on the weak side and the rich properties of the model are not really shown off. It would be interesting if the authors could consider adding a more illustrative experiment and some more empirical results regarding inference in this model and the marginal structures that can be learned with this model in controlled toy settings.\nCan the model recover richer structure that was imposed during data generation? How limiting is the learning of a?\nHow does the likelihood of the model behave under the circumstances?\nThe experiments do not really convey how well this all will work in practice.\n\n""]","[-20, -30, 20]","[20, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the model is 'interesting' and shows 'interesting generalizations', they also criticize the paper as being 'mercilessly difficult to read' and point out several issues with terminology, structure, and missing evaluations. The overall tone suggests more criticism than praise. The politeness score is slightly positive (20) because the reviewer uses professional language and offers constructive criticism. They acknowledge positive aspects before detailing issues, and use phrases like 'it would be extremely interesting' when suggesting improvements, which maintains a respectful tone. However, the use of 'mercilessly' in describing the paper's readability prevents a higher politeness score."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('well-motivated', 'promising'), the overall tone is critical, pointing out significant shortcomings in the paper's evaluation and completeness. The reviewer uses phrases like 'Unfortunately there is minimal quantitative evaluation' and 'the paper as it stands is not complete', indicating a generally negative sentiment. However, it's not extremely negative as the reviewer encourages further work and sees potential in the idea. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout. They use polite language such as 'I encourage the authors' and 'I do think the idea is well-motivated', softening their criticisms. The reviewer also provides specific suggestions for improvement, which is a polite way to offer criticism. While not overly formal or excessively polite, the review avoids harsh or rude language, maintaining a respectful tone even when pointing out flaws."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting aspects of the proposed model and its clean derivation. However, they also express significant criticisms about the empirical evaluation, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the strengths of the work while constructively pointing out areas for improvement. They use phrases like 'particularly interesting aspect' and 'cleanly described and derived', which contribute to a polite tone. The criticism is presented in a professional manner, suggesting improvements rather than dismissing the work outright.""]"
"[""This paper proposes integrating information from a semantic resource that quantifies the affect of different words into a text-based word embedding algorithm. \n\nThe affect lexical seems to be a very interesting resource (although I'm not sure what it means to call it 'state of the art'), and definitely support the endeavour to make language models more reflective of complex semantic and pragmatic phenomena such as affect and sentiment. \n\nThe justification for why we might want to do this with word embeddings in the manner proposed seems a little unconvincing to me:\n\n- The statement that 'delighted' and 'disappointed' will have similar contexts is not evident to me at least (other then them both being participle / adjectives).\n\n- Affect in language seems to me to be a very contextual phenomenon. Only a tiny subset of words have intrinsic and context-free affect. Most affect seems to me to come from the use of words in (phrasal, and extra-linguistic) contexts, so a more context-dependent model, in which affect is computed over phrases or sentences, would seem to be more appropriate. Consider words like 'expensive', 'wicked', 'elimination'...\n\nThe model proposes several applications (sentiment prediction, predicting email tone, word similarity) where the affect-based embeddings yield small improvements. However, in different cases, taking different flavours of affect information (V, A or D) produces the best score, so it is not clear what to conclude about what sort of information is most useful. \n\nIt is not surprising to me that an algorithm that uses both WordNet and running text to compute word similarity scores improves over one that uses just running text. It also not surprising that adding information about affect improves the ability to predict sentiment and the tone of emails. \n\nTo understand the importance of the proposed algorithm (rather than just the addition of additional data), I would like to see comparison with various different post-processing techniques using WordNet and the affect lexicon (i.e. not just Bollelaga et al.) including some much simpler baselines. For instance, what about averaging WordNet path-based distance metrics and distance in word embedding space (for word similarity), and other ways of applying the affect data to email tone prediction?\n\n"", 'This paper introduces modifications the word2vec and GloVe loss functions to incorporate affect lexica to facilitate the learning of affect-sensitive word embeddings. The resulting word embeddings are evaluated on a number of standard tasks including word similarity, outlier prediction, sentiment detection, and also on a new task for formality, frustration, and politeness detection.\n\nA considerable amount of prior work has investigated reformulating unsupervised word embedding objectives to incorporate external resources for improving representation learning. The methodologies of Kiela et al (2015) and Bollegala et al (2016) are very similar to those proposed in this work. The main originality seems to be captured in Algorithm 1, which computes the strength between two words. Unlike prior work, this is a real-valued instead of a binary quantity. Because this modification is not particularly novel, I believe this paper should primarily be judged based upon the effectiveness of the method rather than the specifics of the underlying techniques. In this light, the performance relative to the baselines is particularly important. From the results reported in Tables 1, 2, and 3, I do not see compelling evidence that +V, +A, +D, or +VAD consistently lead to significant performance increases relative to the baseline methods. I therefore cannot recommend this paper for publication.', 'This paper proposed to use affect lexica to improve word embeddings. They extended the training objective functions of Word2vec and Glove with the affect information. The resulting embeddings were evaluated not only on word similarity tasks but also on a bunch of downstream applications such as sentiment analysis. Their experimental results showed that their proposed embeddings outperformed standard Word2vec and Glove. In sum, it is an interesting paper with promising results and the proposed methods were carefully evaluated in many setups.\n\nSome detailed comments are:\n-\tAlthough the use of affect lexica is innovative, the idea of extending the training objective function with lexica information is not new. Almost the same method was proposed in K.A. Nguyen, S. Schulte im Walde, N.T. Vu. Integrating Distributional Lexical Contrast into Word Embeddings for Antonym-Synonym Distinction. In Proceedings of ACL, 2016.\n-\tAlthough the lexicons for valence, arousal, and dominance provide different information, their combination did not perform best. Do the authors have any intuition why?\n-\tIn Figure 2, the authors picked four words to show that valence is helpful to improve Glove word beddings. It is not convincing enough for me.  I would like to see to the top k nearest neighbors of each of those words.\n']","[-20, -70, 70]","[50, 20, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting aspects of the paper and supports the general endeavor, they express several criticisms and doubts about the approach and results. The reviewer finds the justification unconvincing, questions some of the claims, and suggests that the improvements shown are not surprising or conclusive. They also request additional comparisons and baselines, indicating that the current work may not be sufficient.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'seems a little unconvincing to me' and 'I would like to see' rather than making blunt criticisms. The reviewer also acknowledges positive aspects of the work before presenting criticisms. However, the score is not higher because the review is primarily focused on critiquing the paper rather than offering extensive praise or encouragement."", ""The sentiment score is -70 because the reviewer does not recommend the paper for publication, citing a lack of 'compelling evidence' for performance increases. The overall tone is critical, especially in the final sentences. However, it's not entirely negative as the reviewer acknowledges the paper's contributions and methodologies. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and provide specific reasons for their assessment. They avoid harsh or rude language, instead using phrases like 'I do not see compelling evidence' and 'I cannot recommend' which are firm but polite ways of expressing a negative opinion in academic contexts."", ""The sentiment score is 70 because the review begins with a positive tone, describing the paper as 'interesting' with 'promising results' and praising the careful evaluation. The reviewer acknowledges the innovative aspects and the outperformance of standard methods. However, it's not a perfect 100 as there are some critiques in the detailed comments. The politeness score is 60 because the language used is generally respectful and constructive. The reviewer uses phrases like 'I would like to see' instead of demanding changes, and frames criticisms as questions or observations rather than direct attacks. The tone remains professional throughout, though it doesn't go out of its way to be overly polite or complimentary.""]"
"['SUMMARY\nThe paper deal with the problem of RL.  It proposes a non-parametric approach that maps trajectories to the optimal policy.  It avoids learning parameterized policies.  The fundamental idea is to store passed trajectories.  When a policy is to be executed, it does nearest neighbor search to find then closest trajectory and executes it.\n\nCOMMENTS\n\nWhat happens if the agent finds it self  in a state that while is close to a state in the similar trajectory the action required to could be completely different.\n\nNot certain about the claim that standard RL policy learning algorithms make it difficult to assess the difficulty of a problem. \n\nHow do you execute a trajectory? Actions in RL are by definition stochastic, and this would make it unlikely that a same trajectory can be reproduced exactly.\n', 'This work shows that a simple non-parametric approach of storing state embeddings with the associated Monte Carlo returns is sufficient to solve several benchmark continuous control problems with sparse rewards (reacher, half-cheetah, double pendulum, cart pole) (due to the need to threshold a return the algorithms work less well with dense rewards, but with the introduction of a hyper-parameter is capable of solving several tasks there). The authors argue that the success of these simple approaches on these tasks suggest that more changing problems need to be used to assess new RL algorithms.\n\nThis paper is clearly written and it is important to compare simple approaches on benchmark problems. There are a number of interesting and intriguing side-notes and pieces of future work mentioned.\n\nHowever, the originality and significance of this work is a significant drawback. The use non-parametric approaches to the action-value function go back to at least [1] (and probably much further). So the algorithms themselves are not particularly novel, and are limited to nearly-deterministic domains with either single sparse rewards (success or failure rewards) or introducing extra hyper-parameters per task.\n\nThe significance of this work would still be quite strong if, as the author\'s suggest, these benchmarks were being widely used to assess more sophisticated algorithms and yet these tasks were mastered by such simple algorithms with no learnable parameters. Yet, the results do not support the claim. Even if we ignore that for most tasks only the sparse reward (which favors this algorithm) version was examined, these author\'s only demonstrate success on 4, relatively simple tasks.\n\nWhile these simple tasks are useful for diagnostics, it is well-known that these tasks are simple and, as the author\'s suggest ""more challenging tasks  .... are necessary to properly assess advances made by sophisticated, optimization-based policy algorithms."" Lillicrap et al. (2015) benchmarked against 27 tasks, Houtfout et al. (2016) compared in the paper also used Walker2D and Swimmer (not used in this paper) as did [2], OpenAI Gym contains many more control environments than the 4 solved here and significant research is pursing complex manipulation and grasping tasks (e.g. [3]). This suggests the author\'s claim has already been widely heeded and this work will be of limited interest.\n\n[1] Juan, C., Sutton, R. S., & Ram, A. Experiments with Reinforcement Learning in Problems with Continuous State and Action Spaces.\n\n[2] Henderson, P., Islam, R., Bachman, P., Pineau, J., Precup, D., & Meger, D. (2017). Deep reinforcement learning that matters. arXiv preprint arXiv:1709.06560.\n\n[3] Nair, A., McGrew, B., Andrychowicz, M., Zaremba, W., & Abbeel, P. (2017). Overcoming exploration in reinforcement learning with demonstrations. arXiv preprint arXiv:1709.10089.', 'This paper presents a nearest-neighbor based continuous control policy.  Two algorithms are presented: NN-1 runs open-loop trajectories from the beginning state, and NN-2 runs a state-condition policy that retrieves nearest state-action tuples for each state.  \n\nThe overall algorithm is very simple to implement and can do reasonably well on some simple control tasks, but quickly gets overwhelmed by higher-dimensional and stochastic environments.  It is very similar to ""Learning to Steer on Winding Tracks Using Semi-Parametric Control Policies"" and is effectively an indirect form of tile coding (each could be seen as a fixed voronoi cell).  I am sure this idea has been tried before in the 90s but I am not familiar enough with all the literature to find it (A quick google search brings this up: Reinforcement Learning of Active Recognition Behaviors, with a chapter on nearest-neighbor lookup for policies: https://people.eecs.berkeley.edu/~trevor/papers/1997-045/node3.html).\n\nAlthough I believe there is work to be done in the current round of RL research using nearest neighbor policies, I don\'t believe this paper delves very far into pushing new ideas (even a simple adaptive distance metric could have provided some interesting results, nevermind doing a learned metric in a latent space to allow for rapid retrainig of a policy on new domains....), and for that reason I don\'t think it has a place as a conference paper at ICLR.  I would suggest its submission to a workshop where it might have more use triggering discussion of further work in this area.']","[-20, -50, -50]","[0, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's approach, they raise several critical questions and concerns about the method. The reviewer doesn't outright dismiss the paper but expresses skepticism about some claims and the practicality of the approach. The politeness score is neutral (0) as the reviewer's language is neither particularly polite nor rude. They use direct, professional language to express their concerns without using overly harsh or complimentary terms. The reviewer asks questions and expresses doubts in a straightforward manner, maintaining a neutral tone throughout the review."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'clearly written', 'important to compare simple approaches'), they express significant concerns about the originality and significance of the work. The reviewer states that the approach is not novel and the results do not strongly support the authors' claims. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positive aspects before presenting criticisms, and provides detailed explanations for their concerns. They also use phrases like 'the authors suggest' and 'this work will be of limited interest' rather than more harsh or direct criticisms. The reviewer maintains a professional tone while providing constructive feedback."", ""The sentiment score is -50 because the reviewer expresses a generally negative view of the paper. While they acknowledge that the algorithm can perform reasonably well on simple tasks, they criticize its limitations in higher-dimensional and stochastic environments. The reviewer also suggests that the idea is not novel and doesn't push new ideas far enough to warrant publication at ICLR. The recommendation to submit to a workshop instead of a conference further indicates a negative sentiment. However, the score is not at the extreme negative end because the reviewer does acknowledge some positive aspects and potential for discussion. The politeness score is 20 because the reviewer maintains a professional tone throughout and offers constructive feedback. They avoid harsh language and provide suggestions for improvement. The use of phrases like 'I believe' and 'I would suggest' adds a polite tone. However, the score is not higher because the review is quite direct in its criticism and doesn't use many overtly polite phrases or soften the negative feedback extensively.""]"
"['The paper is about open sourcing AirNet, a database that has interpolated air quality metrics in a spatial form along with matching meteorological data obtained elsewhere. In addition, the paper also develops a few baseline methods and evaluated using standard metrics such as detection rate, false alarms etc. The work is original and significant from an applications point of view. It looks like the dataset is useful but the model development and experimental sections are weak.\n\nStrengths:\n- open source data set for air quality monitoring that is significantly better than existing ones.\n- baseline models using standard methods including RNN.\n\nWeaknesses:\n- The air quality data is measured at point locations (stations) which are interpolated to obtain spatial data. There is no evaluation on this step to make sure the interpolated data indeed reflects truth. \n- Experiments doesn\'t seem to be carefully done using hyper-parameter tuning/ cross-validation. The model results may be misleading.\n- Writing and formatting needs to be improved. Some examples - ""quality of air quality"", ""people attempted to apply deep learning"", ""in the computer vision field ."", ""Some people also used the hidden Makov model"", ""radial of longitude"", ""in 2:00AM, January 23"". The paper in general was not easy to follow at many places.\n- Is Table 3 incomplete with one box unlabeled?\n- Figure 3 is not clear. It is suggested to follow standard notations to represent the RNN structure (see Jurgen Schmidhuber\'s paper)\n- ""DEV"" in table 4 is not explained. Is this a development set? If so, what does it mean?\n- It is said that ""reduced LSTM is improved than LSTM"". But the test results in Table 4 shows that LSTM is better.', ""The major contribution lies in the producing of the data. There are several concerns.\n1. Since the major contribution lies in the production of the data, it is required for the authors to justify the quality of data. How accurate they are? What are the error bounds in terms of devices of measurement? What is the measurement precision? There is no such discussion for the data source in this submission, and thus it would be really hard for the reviewer to judge the validity of the dataset. The authors claim this is the largest dataset of such purpose, but they didn't demonstrate that the smaller datasets offered previously is indeed less competitive.\n\n2. Using interpolation to align data is questionable. There are obviously many better ways to do so.\n\n3. I would suggest the authors should use the two baseline models on other air-quality datasets for comparison. It can then convince the readers this dataset is indeed a better choice for the designed task. \n\n4. This paper is not very well written. The English has certain room for improvement, and some details are missing. For instance, in Table1, Table2 and Table3, there are no captions . It is also unclear what's the purpose of Figure3 for?"", 'This paper\'s main contribution is in the building of a spatio-temporal data set on air pollution indicators as the title states.\nThe data set is built from open source data to comprise pollutants measured at a number of stations and meteorological data. Then, an air pollutant predictor is built as a baseline machine learning model with a reducedLSTM model. \nMost of the first part\'s work is in the extraction of the public data from the above mentioned sources, aligning of the two source data and sampling considerations.\nThe paper lacks detailed explanation of the problem it is actually addressing by omitting the current systems\' performance: simply stating: 1.1/page 2 ""Thus it became essential and urgent to set up a larger scale training dataset to enhance the accuracy of the forecast results."" \nIt also lacks definition of certain application domain area terms and acronyms (PM2:5).\nCertain paragraphs need rewriting:\n     - 2.2/Page 3: ""Latitude ranges from 75 degrees to 132 degrees and the north latitude range of is from 18 degrees to 51 degrees"".\n     - 3.1/Page 4: ""We converted the problem of the pollutant prediction as time sequential prediction problems, as in the case of giving the past pollutant concentration x0 to xt\U001000001."".\nAlso, Table 1: GFS Field Description contains 6 features  not 7 as stated in 2.1\n\nFor air pollutant prediction a baseline machine learning model is built with a reducedLSTM model. \nResults seem promising but lack serious comparison with currently obtained results by other approaches as mentioned above. The statement in 5./Page 7:""Furthermore, reduced LSTM is improved than LSTM, we assumed this is because our equation considered air pollutant dynamics, thus we gave more information to model than LSTM while keeping LSTMs advantage."" attributes the enhanced results to extra data (quantity) fed to the model rather than the fact (quality) as stated in the paper that the meteorological conditions (dispersion etc.) influence the air pollutant presence/ concentrations in nearby stations.\nA rewriting and clarification of certain paragraphs is therefore recommended.']","[-20, -60, -30]","[50, 20, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the originality and significance of the work, particularly the open-source dataset, they also point out several weaknesses. The reviewer states that 'the model development and experimental sections are weak' and lists multiple areas for improvement. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, balancing criticism with recognition of the paper's strengths. They use neutral language like 'It looks like' and 'It is suggested' rather than harsh directives. The reviewer also provides specific, constructive feedback for improvement, which is a polite approach to criticism in academic reviews."", ""The sentiment score is -60 because the review is predominantly critical, highlighting several concerns and shortcomings of the paper. The reviewer acknowledges the main contribution (data production) but immediately follows with multiple criticisms about data quality, methodology, and writing. The lack of positive comments and the use of phrases like 'questionable' and 'not very well written' indicate a negative sentiment. However, it's not extremely negative as the reviewer does offer constructive suggestions for improvement. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'I would suggest' and frame their points as concerns rather than outright dismissals. The language is not overtly polite, but it avoids rudeness and maintains a respectful, constructive approach typical of academic peer reviews."", ""The sentiment score is -30 because the review is generally critical, pointing out several shortcomings of the paper, such as lack of detailed explanations, missing definitions, and paragraphs needing rewriting. However, it's not entirely negative as it acknowledges the paper's contribution in building a spatio-temporal dataset and mentions that results seem promising. The politeness score is 20 because the reviewer uses relatively neutral language and offers constructive criticism. They use phrases like 'lacks detailed explanation' and 'needs rewriting' rather than harsh or rude language. The reviewer also provides specific recommendations for improvement, which is a polite way to offer criticism. However, the tone is not overly polite or deferential, maintaining a professional and somewhat neutral stance.""]"
"['The paper proposes an analysis on different adaptive regularization techniques for deep transfer learning. \nSpecifically it focuses on the use of an L2-SP condition that constraints the new parameters to be close to the\nones previously learned when solving a source task. \n\n+ The paper is easy to read and well organized\n+ The advantage of the proposed regularization against the more standard L2 regularization is clearly visible \nfrom the experiments\n\n- The idea per se is not new: there is a list of shallow learning methods for transfer learning based \non the same L2 regularization choice\n[Cross-Domain Video Concept Detection using Adaptive SVMs, ACM Multimedia 2007]\n[Learning categories from few examples with multi model knowledge transfer, PAMI 2014]\n[From n to n+ 1: Multiclass transfer incremental learning, CVPR 2013]\nI believe this literature should be discussed in the related work section\n\n- It is true that the L2-SP-Fisher regularization was designed for life-long learning cases with a \nfixed task, however, this solution seems to work quite well in the proposed experimental settings. \nFrom my understanding L2-SP-Fisher can be considered the best competitor of L2-SP so I think\nthe paper should dedicate more space to the analysis of their difference and similarities both\nfrom the theoretical and experimental point of view. For instance:\n--  adding the L2-SP-Fisher results in table 2\n--  repeating the experiments of figure 2 and figure 3 with L2-SP-Fisher\n\n\n\n\n', 'This work addresses the scenario of fine-tuning a pre-trained network for new data/tasks and empirically studies various regularization techniques. Overall, the evaluation concludes with recommending that all layers of a network whose weights are directly transferred during fine-tuning should be regularized against the initial net with an L2 penalty during further training. \n\nRelationship to prior work:\nRegularizing a target model against a source model is not a new idea. The authors miss key connections to A-SVM [1] and PMT-SVM [2] -- two proposed transfer learning models applied to SVM weights, but otherwise very much the same as the proposed solution in this paper. Though the study here may offer new insights for deep nets, it is critical to mention prior work which also does analysis of these regularization techniques. \n\nSignificance:\nAs the majority of visual recognition problems are currently solved using variants of fine-tuning, if the findings reported in this paper generalize, then it could present a simple new regularization which improves the training of new models. The change is both conceptually simple and easy to implement so could be quickly integrated by many people.\n\nClarity and Questions:\nThe purpose of the paper is clear, however, some questions remain unanswered. \n1) How is the regularization weight of 0.01 chosen? This is likely a critical parameter. In an experimental paper, I would expect to see a plot of performance for at least one experiment as this regularization weighting parameter is varied. \n2) How does the use of L2 regularization on the last layer effect the regularization choice of other layers? What happens if you use no regularization on the last layer? L1 regularization?\n3) Figure 1 is difficult to read. Please at least label the test sets on each sub-graph.\n4) There seems to be some issue with the freezing experiment in Figure 2. Why does performance of L2 regularization improve as you freeze more and more layers, but is outperformed by un-freezing all. \n5) Figure 3 and the discussion of linear dependence with the original model in general seems does not add much to the paper. It is clear that regularizing against the source model weights instead of 0 should result in final weights that are more similar to the initial source weights. I would rather the authors use this space to provide a deeper analysis of why this property should help performance. \n6) Initializing with a source model offers a strong starting point so full from scratch learning isn’t necessary -- meaning fewer examples are needed for the continued learning (fine-tuning) phase. In a similar line of reasoning, does regularizing against the source further reduce the number of labeled points needed for fine-tuning? Can you recover L2 fine-tuning performance with fewer examples when you use L2-SP?\n\n[1] J. Yang, R. Yan, and A. Hauptmann. Adapting svm classifiers to data with shifted distributions. In ICDM Workshops, 2007.\n[2]  Y. Aytar and A. Zisserman. Tabula rasa: Model transfer for object category detection. In Proc. ICCV, 2011.\n\n------------------\nPost rebuttal\n------------------\nThe changes made to the paper draft as well as the answers to the questions posed above have convinced me to upgrade my recommendation to a weak accept. The experiments are now clear and thorough enough to provide a convincing argument for using this regularization in deep nets. Since it is simple and well validated it should be easily adopted. \n', ""The paper addresses the problem of transfer learning in deep networks. A pretrained network on a large dataset exists, what is the best way to retrain the model on a new small dataset? \nIt argues that the standard regularization done in conventional fine-tuning procedures is not optimal, since it tries to get the parameters close to zero, thereby forgetting the information learnt on the larger dataset.\nIt proposes to have a regularization term that penalizes divergence from initialization (pretrained network) as opposed to from zero-vector. It tries different norms (L2, L1, group Lasso) as well as Fisher information matrix to avoid interfering with important nodes, and shows the effectiveness of these alternatives over the standard practice of “weight decay”.\n\nAlthough the novelty of the paper is limited and have been shown for transfer learning with SVM classifiers prior to resurgence of deep learning, the reviewer is unable to find a prior work doing same regularization in deep networks. Number of datasets and experiments are moderately high, results are consistently better than standard fine-tuning and fine-tuning is a very common tool for ML practitioners in various application fields, so, I think there is benefit for transfer learning audience to be exposed to the experiments of this paper.\n\n---- Post rebuttal\nI think the paper has merits to be published. As I note above, it's taking a similar idea with transfer learning of SVM models from a decade ago to deep learning and fine-tuning. It's simple with no technical novelty but shows consistent improvement and has wide relevance. \n""]","[20, 50, 60]","[50, 75, 70]","[""The sentiment score is slightly positive (20) because the review starts with positive points about the paper being easy to read, well-organized, and showing clear advantages of the proposed method. However, it also includes significant criticisms and suggestions for improvement, which temper the overall positivity. The politeness score is moderately positive (50) as the reviewer uses neutral language and frames criticisms constructively, offering specific suggestions for improvement rather than harsh criticism. The reviewer acknowledges the paper's strengths before presenting areas for improvement, which is a polite approach. The language used is professional and respectful throughout, without any rude or overly negative phrasing."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the potential significance of the work and its clarity, while also pointing out several areas for improvement and missing connections to prior work. The overall tone is constructive and the reviewer ultimately upgrades their recommendation to a weak accept after the rebuttal. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the authors' efforts in addressing concerns. The reviewer maintains a professional and courteous tone, even when pointing out limitations or requesting clarifications."", ""The sentiment score is 60 (moderately positive) because the reviewer acknowledges the paper's merits and consistent improvements, despite limited novelty. They state it has 'benefit for transfer learning audience' and 'has merits to be published'. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and potential impact without harsh criticism. They use phrases like 'I think' to soften opinions and provide balanced feedback, noting both limitations and strengths. The tone is professional and constructive throughout.""]"
"['The main contribution of this paper are:\n(a) replacing the typical maximum likelihood criterion in neural language model training with a discriminative criterion,\n(b) propose two large margin criterion -- difference in likelihood and difference in rank (WER or BLUE ordered) hypotheses,\n(c) demonstrate performance gains two standard tasks -- an ASR task on Wall Street Journal (small task) and an MT task.\n\nIn addition, they provide examples in Figure (1) and (2) that illustrate the effect of the cost function on training. Their illustration in Figure 4 is also helpful in seeing the impact of using a warm start with a generative model.\n', ""This paper presents two methods for imposing a margin on discriminative loss functions, one which uses the margin between the reference transcription and alternatively hypothesized transcriptions (LMLM), and another which compares all alternative candidates and uses a margin between those with a better system objective (WER or bleu) and those with a worse system objective (rank-LMLM).  Some interesting results on the development set show the importance of things like warm starting on large language model training data.  The methods presented here could be of interest to those training language models for use in specific systems, and the paper reads reasonably clearly.\n\nThe principal shortcoming of the paper is that there was essentially no effort to establish that the baseline systems that are being improved through reranking via these methods are decent baselines for such a use, or to really specify these systems in a way that would allow for replication of the results being presented in the paper.  Sufficient specification of the exact training data and procedure is standard in papers that purport to establish methods to improve upon such baselines, yet such information is sorely lacking in this paper.  Further, the speech data sets, Fisher and Wall St. Journal, have what would seem to be very high word error rates versus what should be possible with standard open-source speech recognizers such as Kaldi.  For example, by referencing a page that attempts to establish the state of the art on standard data sets (https://github.com/syhw/wer_are_we), we can find links to papers by Povey et al (http://www.danielpovey.com/files/2016_interspeech_mmi.pdf) and the Deep 2 paper in your citations, which themselves include baselines from other papers that cut the error rate in half versus even your best scoring systems, let alone your baselines.  Similarly, your Bleu score on Vietnamese to English translation is way below what were reported (even by the organizer baseline) for the IWSLP conference where the data became available: https://github.com/magizbox/underthesea/wiki/SOTA-Machine-Translation:-IWSLT-2015\n\nGranted, the competing systems also were outperformed by the organizer baseline for that task at IWSLT 2015, but not by the degree to which your system is.  Again, your best performing system (using your new methods) has performance far below the worst reported competing system.  The cavalier presentation of specific details regarding your baseline systems (which is critical for any sort of replicability) and the uniformly weak performance of these systems relative to widely reported results, leads me to discount the probability that your methods would actually result in improvements on truly solid baselines.  I would have preferred one domain experiment carried out with appropriately rock solid documentation of the ball-park competitive baseline system to these results.\n\nOverall, the method is interesting and the dev set experiments were informative, but ultimately the experiments were not.\n\nRevision:  Having read the author response for this paper, I am encouraged by the updated baseline for WSJ and the additional explication about the competing Fisher systems.  The additional information about the systems included in section 4.4 is pretty nominal, though, and I worry about the ability of others to replicate these results.  I would have felt better about the results if there were reported results from other papers included here, instead of the authors' attempt to create a baseline from the given data, which may or may not (as we have seen) represent a strong enough baseline from which to draw conclusions.  That is to say that I still have some reservations (though less than I had before).  I am including this additional information in my review, for use by the area chair, but otherwise leaving my assessment as-is.\n"", 'A large margin , end to end language model that uses a discriminative objective function is proposed. The proposed objective imposes a hinge loss on the margin to ensure that the ground truth is at least  some fixed amount larger than the imposter. A variant on this, which also incorporates the ranks of the imposters sorted by a metric such as edit distance or BLEU metric with respect to the ground truth is also introduced.\n\nThe paper is missing some of the original references to a discriminative LM (DLM) as well as  references to the use of a NN LM directly in decoding (presented in ICASSP and Interspeech conferences over the last 5 years). For example, H.-K. J. Kuo, E. Fosler-Lussier, H. Jiang, and C.-H. Lee, “Discriminative training of language models for speech recognition,” in Proc. ICASSP,\nvol. 1, 2002, pp. 325–328.\n\nHave you considered the widely-used NCE method to handle the large vocabulary?\n\nThe dev perplexity quoted in Section 4 for a 5 gram LM is very high.  Also Table 4 and Table 5 on WSJ and  FIsher  show baseline experiments that are quite far away from the state-of-the-art in these tasks. Even if you assume that you use the simplest possible acoustic model and/or an open source tool kit for the decoder,  these error rates are high (WSJ error rates are lower than 10%, not 16.7%). Even if the LM is trained on the common-crawl corpus, it has  a very low OOV rate, and fine tuning on the tasks only lowers it b t 1%.  For reference,  please see papers from Saon et al., Seide et al, Povey et al, Yajie Miao et al in various ICASSP, Interspeech and arXiv papers. Comparisons with weak baselines can significantly color the conclusions. On the Fisher test set, the interpolated LM offers very little over the baseline LM in Table 5. This is contrary to what is observed in the literature.  There is not much difference between rankLM and LMLM as well to draw a clear conclusion between the two. Given that this is n-best rescoring, how are the N-best lists generated?  You state that they are extracted from  64 beam candidates, are they unique N-best lists?  Can this method be applied to lattices? What is the perplexity of all the language models corresponding to  Tables 4 and 5? This would have been useful to study in itself.\n\nIn the SMT tasks, the baselines reported seem to be far away from results presented in the literature on the IWSLT task (see http://workshop2015.iwslt.org/downloads/IWSLT_2015_EP_3.pdf)\n\nWhile the proposed objective is interesting and meaningful for several conversational applications, as well as sentence modeling, the presented experimental results are not convincing.']","[80, -50, -50]","[50, 20, 20]","[""The sentiment score is 80 (positive) because the reviewer highlights multiple contributions of the paper, including the novel approach, proposed criteria, and demonstrated performance gains. They also mention the helpfulness of figures and illustrations, indicating a positive view of the paper's content and presentation. The politeness score is 50 (slightly polite) because the language is professional and objective, focusing on the paper's merits without using overtly polite phrases or personal comments. The reviewer maintains a neutral tone while providing a constructive summary of the paper's strengths, which is slightly more polite than a completely neutral review."", ""The sentiment score is -50 because while the reviewer acknowledges some interesting aspects of the paper, they express significant concerns about the baseline systems and the overall validity of the results. The review starts positively but becomes increasingly critical, especially regarding the lack of proper documentation and weak performance compared to existing systems. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'interesting results' and 'could be of interest,' while also clearly stating their concerns. They avoid harsh language even when being critical, opting for more neutral phrases like 'principal shortcoming' and 'I would have preferred.' The reviewer also acknowledges the author's response in a revision, showing a willingness to consider additional information."", ""The sentiment score is -50 because the review is generally critical, pointing out several shortcomings in the paper such as missing references, high error rates, and unconvincing experimental results. However, it's not entirely negative as it acknowledges the proposed objective as 'interesting and meaningful'. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer constructive feedback. They ask questions and suggest improvements rather than simply dismissing the work. The tone is academic and respectful, even when pointing out flaws, which contributes to a slightly positive politeness score.""]"
"['This paper proposes an anytime neural network, which can predict anytime while training. To achieve that, the model includes auxiliary predictions which can make early predictions. Specifically, the paper presents a loss weighting scheme that considers high correlation among nearby predictions, an oscillating loss weighting scheme for further improvement, and an ensemble of anytime neural networks. In the experiments, test error of the proposed model was shown to be comparable to the optimal one at each time budget. \n\nIt is an interesting idea to add auxiliary predictions to enable early predictions and the experimental results look promising as they are close to optimal at each time budget. \n\n1. In Section 3.2, there are some discussions on the parallel computations of EANN. The parallel training is not clear to me and it would be great to have more explanation on this with examples.  \n\n2. It seems that EANN is not scalable because the depth is increasing exponentially. For example, given 10 machines, the model with the largest depth would have 2^10 layers, which is difficult to train. It would be great to discuss this issue.\n\n3. In the experiments, it would be great to add a few alternatives to be compared for anytime predictions. \n\n\n\n\n\n\n\n', 'This paper aims to endow neural networks the ability to produce anytime prediction. The authors propose several heuristics to reweight and oscillate the loss to improve the anytime performance. In addition, they propose to use a sequence of exponentially deepening anytime neural networks to reduce the performance gap for early classifiers. The proposed approaches are validated on two image classification datasets.\nPros:\n- The paper is well written and easy to follow. \n- It addresses an interesting problem with reasonable approaches. \nCons:\n- The loss reweighting and oscillating schemes appear to be just heuristics. It is not clear what the scientific contributions are.  \n- I do not fully agree with the explanation given for the “alternating weights”. If the joint loss leads to zero gradient for some weights, then why would you consider it problematic?\n- There are few baselines compared in the result section. In addition, the proposed method underperforms the MSDNet (Huang et al., 2017) on ILSVRC2012.\n- The EANN is similar to the method used by Adaptive Networks (Bolukbasi et al., 2017), and the baseline “Ensemble of ResNets (varying depth)” in the MSDNet paper. \n-  Could you show the error bar In Figure 2(a)? Usually an error difference less than 0.5% on CIFAR-100 is not considered as significant. \n- I’m not convinced that AANN really works significantly better than ANN according to the results in Table 1(a). It seems that ANN still outperform AANN in many cases.\n- I would suggest to show the results in Table 1(b) with a figure.', '1. Paper Summary\n\nThis paper adds a separate network at every layer of a residual network that performs classification. They minimize the loss of every classifier using two proposed weighting schemes. They also ensemble this model.\n\n\n2. High level paper\n\nThe organization of this paper is a bit confusing. Two weighing schemes are introduced in Section 3.1, then the ensemble model is described in Section 3.2, then the weighing schemes are justified in Section 4.1.\nOverall this method is essentially an cascade where each cascade classifier is a residual block. Every input is passed through as many stages as possible until the budget is reached. While this model is likely quite useful in industrial settings, I don\'t think the model itself is wholly original.\nThe authors have done extensive experiments evaluating their method in different settings. I would have liked to see a comparison with at least one other anytime method. I think it is slightly unfair to say that you are comparing with Xie & Tu, 2015 and Huang et al., 2017 just because they use the CONSTANT weighing schemes.\n\n\n3. High level technical\n\nI have a few concerns:\n- Why does AANN+LINEAR nearly match the accuracy of EANN+SIEVE near 3e9 FLOPS in Figure 4b but EANN+LINEAR does not in Figure 4a? Shouldn\'t EANN+LINEAR be strictly better than AANN+LINEAR?\n- Why do the authors choose these specific weighing schemes? Section 4.1 is devoted to explaining this but it is still unclear to me. They talk about there being correlation between the predictors near the end of the model so they don\'t want to distribute weight near the final predictors but this general observation doesn\'t obviously lead to these weighing schemes, they still seem a bit adhoc.\n\nA few other comments:\n- Figure 3b seems to contain strictly less information than Figure 4a, I would remove Figure 3b and draw lines showing the speedup you get for one or two accuracy levels.\n\nQuestions:\n- Section 3.1: ""Such an ideal θ* does not exist in general and often does not exist in practice."" Why is this the case? \n- Section 3.1: "" In particular, spreading weights evenly as in (Lee et al., 2015) keeps all i away from their possible respective minimum"" Why is this true?\n- Section 3.1: ""Since we will evaluate near depth b3L/4e, and it\nis the center of L/2 low-weight layers, we increase it weight by 1/8."" I am completely lost here, why do you do this?\n\n\n4. Review summary\n\nUltimately because the model itself resembles previous cascade models, the selected weighings have little justification, and there isn\'t a comparison with another anytime method, I think this paper isn\'t yet ready for acceptance at ICLR.']","[60, -20, -60]","[80, 50, 20]","[""The sentiment score is 60 (positive) because the reviewer describes the paper's idea as 'interesting' and the results as 'promising'. They also mention that the experimental results are 'close to optimal', which is a positive assessment. However, it's not extremely positive as the reviewer does provide some critiques and suggestions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, such as 'It would be great to...' when making suggestions. They also acknowledge the positive aspects of the work before offering constructive criticism. The reviewer's tone is professional and courteous, avoiding any harsh or negative language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written', 'interesting problem'), they raise several significant concerns and criticisms. These include questioning the scientific contributions, disagreeing with explanations, noting underperformance compared to baselines, and expressing skepticism about the significance of results. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, balancing praise with constructive criticism. They use phrases like 'I do not fully agree' and 'I'm not convinced' rather than harsh or dismissive language. The reviewer also offers specific suggestions for improvement, which is a polite way to provide feedback."", ""The sentiment score is -60 because the review is generally negative, with the reviewer stating that the paper 'isn't yet ready for acceptance at ICLR'. The reviewer points out several concerns and criticisms, such as lack of originality, unclear justifications, and absence of comparisons with other methods. However, it's not entirely negative as the reviewer acknowledges some positive aspects like extensive experiments. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'I would have liked to see' and 'I think' to soften their critiques, and they ask questions for clarification rather than making outright dismissals. The language is not overly polite, but it avoids rudeness and maintains a respectful, constructive tone.""]"
"['Summary:\n\nThis paper studies how to learn (hidden)-state-space models of environment dynamics, and integrate them with Imagination-Augmented Agents (I2A). The paper considers single-agent problems and tests on Ms Pacman etc.\n\nThere are several variations of the hidden-state space [ds]SSM model: using det/stochastic latent variables + using det/stochastic decoders. In the stochastic case, learning is done using variational methods. \n\n[ds]SSM is integrated with I2A, which generates rollouts of future states, based on the inferred hidden states from the d/sSSM-VAE model. The rollouts are then fed into the agent\'s policy / value function.\n\nMain results seem to be:\n1. Experiments on learning the forward model, show that latent forward models work better and faster than naive AR models on several Atari games, and better than fully model-free baselines. \n2. I2A agents with latent codes work better than model-free models or I2A from pixels. Deterministic latent models seem to work better than stochastic ones.\n\nPro:\n- Relatively straightforward idea: learn the forward model on hidden states, rather than raw states.\n- Writing is clear, although a bit dense in places.\n\nCon:\n- Paper only shows training curves for MS Pacman. What about the other games from Table 1?\n- The paper lacks any visualization of the latent codes. What do they represent? Can we e.g. learn a raw-state predictor from the latent codes?\n- Are the latent codes relevant in the stochastic model? See e.g. the discussion in ""Variational Lossy Autoencoder"" (Chen et al. 2016)\n- Experiments are not complete (e.g. for AR, as noted in the paper).\n- The games used are fairly reactive (i.e. do not require significant long-term planning), and so the sequential hidden-state-space model does not have to capture long-term dependencies. It would be nice to see how this technique fares on Montezuma\'s revenge, for instance.\n\nOverall:\nThe paper proposes a simple idea that seems to work well on reactive 1-agent games. However, the paper could give more insights into *how* this works: e.g. a better qualitative inspection of the learned latent model, and how existing questions surrounding sequential stochastic model affect the proposed method. Also, not all baseline experiments are done, and the impact on training is only evaluated on 1 game. \n\nDetailed:\n-\n', 'The paper proposes a method for inferring dynamical models from partial observations, that can later be used in model-based RL algorithms such as I2A. The essence of the method is to perform variational inference of the latent state, representing its distribution as Gaussian, and to use it in an ELBO to infer the dynamics of state and observation.\n\nWhile this is an interesting approach, many of the architectural choices involved seem arbitrary and unjustified. This wouldn\'t be so bad if they were justified by empirical success rather than principled design, but I\'m also a bit skeptical of the strength of the results.\n\nA few examples of such architectural choices:\n1. What\'s the significance of separating the stochastic state transition into a stochastic choice of z and a transition g deterministic in z?\n2. How is the representational power affected by having only the observations depend on z? What\'s the intuition behind calling this model VAE, when sSSM is also trained with variational inference?\n3. What is gained by using pool-and-inject layers? By the way, is this a novel component? If so please elaborate, if not please cite.\n\nAs for the strength of the results, in Table 1 the proposed methods don\'t seem to outperform ""RAR"" (i.e., RNN) in expected value. They do seem to have lower variance, and the authors would do well to underline the importance of this.\nIn Figure 3, it\'s curious that the model-free baseline remains unnamed, as it also does in the text and appendix. This makes it hard to evaluate whether the significant wins are indicative of the strength of the proposed method.\n\nFinally, a notational point that the authors should really get right, is that conditioning on future actions naively changes the distribution of the current state or observation in ways they didn\'t intend. The authors intended for actions to be used as ""interventions"", i.e. a-causally, and should denote this conditioning by some sort of ""do"" operator.', 'The authors provide a deeper exploration of Imagination Agents, by looking more closely at a variety of state-space models.  They examine what happens as both the representation of state, update algorithm, as well as the concept of time, is changed.  As in the original I2A paper, they experiment with learning how best to take advantage of a learned dynamics model.\n\nTo me, this strain of work is very important.  Because no model is perfect, I think the idea of learning how best to use an approximate model will become increasingly important.  The original I2A of learning-to-interpret models is here extended with the idea of learning-to-query, and a variety of solid variants on a few basic themes are well worked out.\n\nOverall, I think the strongest part of this paper is in its conceptual contributions - I find the work thought-provoking and inspiring.  On the negative side, I felt that the experiments were thin, and that the work was not well framed in terms of the literature of state-space identification and planning (there are a zillion ways to plan using a model; couldn\'t we have compared to at least one of them?  Or discussed a few popular ones, and why they aren\'t likely to work?  Since your model is fully differentiable, vanilla MPC would be a natural choice [In other words, instead of learning a rollout policy, do something simple like run MPC on the approximate model, and pass the resulting optimized action trajectory back to the agent as an input feature]).\n\nOf course, while we can always demand more and more experiments, I felt that this paper did a good enough job to merit publication.\n\nMinor quibble: I wasn\'t sure what to make of the sSSM ideas.  My understanding is that in any dynamical system model, the belief state update is always a deterministic function of previous belief state and observation; this suggests to me that the idea of ""state"" here differs from my definition of ""state"".  I don\'t think you should have to sample anything if you\'ve represented your state cleanly.']","[-20, -20, 60]","[50, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Pro' section), they also list several significant concerns ('Con' section) and conclude that the paper could provide more insights and has incomplete experiments. The overall tone suggests that the paper has potential but falls short in several areas.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They present their critique in a constructive manner, using phrases like 'It would be nice to see' and 'The paper could give more insights,' rather than using harsh or dismissive language. The reviewer also acknowledges the positive aspects of the paper before delving into criticisms, which is a polite approach to peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the approach as 'interesting', they express skepticism about the architectural choices and the strength of the results. The reviewer points out several areas of concern and suggests improvements, indicating a generally critical stance. However, the criticism is not overly harsh, hence the score is only mildly negative. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'interesting approach' and offer constructive feedback rather than outright dismissal. The reviewer also provides specific examples and suggestions for improvement, which is a polite way to offer criticism. The language is neither overly formal nor informal, striking a balance that is appropriate for a peer review."", ""The sentiment score is 60 (positive) because the reviewer expresses strong approval of the paper's conceptual contributions, calling them 'thought-provoking and inspiring'. They also recommend publication despite some criticisms. However, it's not 100 due to concerns about thin experiments and lack of comparison to existing methods. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, acknowledges the importance of the work, and frames criticisms constructively. They use phrases like 'I think', 'To me', and 'I felt', which soften their critiques. The minor quibble at the end is presented gently. The overall tone is professional and courteous, though not excessively formal or deferential.""]"
"['This work proposes to learn word vectors that are intended to specifically model the lexical entailment relationship. This is achieved in an unsupervised manner from unstructured data, through an approach heavily influenced by recent work by Henderson and Popa, which ""reinterprets word2vec"" by modeling distributions over discrete latent ""pseudo-phrase"" vectors. That is, instead of using two vectors per word, as in word2vec, a latent representation is introduced that models the joint properties of the target and context words. While Henderson and Popa represent the latent vector as the evidence for the target and context, or the likelihood, this work suggests to represent it based on the posterior distribution instead. The resultant representations are evaluated on Weeds et al.\'s (2014) version of BLESS, as well as the full BLESS dataset, where they do better than the original.\n\nThe paper is confusingly written, fails to mention a lot of related work, has a weak evaluation where it doesn\'t compare to related systems, and I feel that it would benefit from ""toning down"". Hence, I do not recommend it for acceptance. In more detail:\n\n1. The idea behind Henderson and Popa\'s model, as well as the suggested modification, should be easy to explain, but I really had to struggle to make sense of it. This work relies very heavily on that paper, and would be better off if it was more standalone. I think part of the confusion stems from using y for the latent representation but not specifying whether it is a word or latent representation in Equation 1 - that only becomes obvious later. The exposition clearly needs more work, and more precise technical writing.\n\n2. There is a lot of related work around word embeddings that is not mentioned, both on word2vec-style representation learning (e.g. it would be useful to relate this more to word2vec and what it learns, as in Omer Levy\'s work on ""interpreting"" word2vec, rather than reinterpreting) and word embeddings on hypernymy detection and lexical entailment (see e.g. Stephen Roller\'s thesis for references).\n\n3. There has been a lot of work on the Weeds BLESS dataset that is not mentioned, or compared against, including unsupervised approaches (e.g. Levy\'s work, Santus\'s work, Kiela\'s work, Roller\'s work, etc.), that perform better than the numbers in Table 1. There are many other datasets that measure lexical entailment, none of which are evaluated on (apart from the original BLESS set, which is mentioned in passing). It would make sense to show that the method works on more than one dataset, and to do a thorough comparison against other work; especially given that:\n\n4. The tone of the work appears to imply that word2vec was wrong and needs to be reinterpreted: the work leads to ""unprecedented results"" (not true), claims to be a completely novel method for inducing word representations (together with LSA, BOW and Word2Vec, third paragraph; not true), and suggests it has found ""the best way to extract information about the semantics of a word from this model"" (7th paragraph; not true). This, together with the ""reinterpretation of word2vec"" and the proposed ""new distributional semantic models"" almost makes it hard for me to take the work seriously.', ""I'm finding this paper really difficult to understand. The introduction is very abstract, and it is hard for me to understand the model as it is explained at the moment. Could the authors please clarify, perhaps in more algorithmic terms, how the model works?\n\nAs for the evaluation, BLESS is a nice dataset, but it certainly isn't enough to make a broad claim because it has certain artifacts in the way negative examples were constructed. I recommend looking at the collection of datasets used by Levy et al. [1] and Shwartz et al. [2], and evaluating on their union.\n\nAnother discrepancy that appears in the paper is that the authors cite Shwartz et al. [2] as achieving 44.1% average precision on BLESS, when in fact, this number reflects their performance on the WordNet-based dataset created by Weeds et al. [3].\n\n[1] http://www.aclweb.org/anthology/N15-1098\n[2] http://aclweb.org/anthology/E/E17/E17-1007.pdf \n[3] http://sro.sussex.ac.uk/53103/1/C14-1212.pdf \n"", 'The paper presents a word embedding algorithm for lexical entailment. The paper follows the work of Henderson and Popa (ACL,2016) that presented an interpretation of word2vec word representation in which each feature in a word vector corresponds to the probability of it being known/unknown, and suggested an operator to compute the degree of entailment between two words. In this paper, the authors train the word2vec algorithms to directly optimize the objective function suggested by Henderson and Popa (2016),\nI find the paper interesting. The proposed approach is novel and not standard and the paper reports significant improvement of entailment results  compared to previous state of the art\n \nThe method part of the paper (sections 2.1 and 2.2 ) which is the main contribution is not clearly written. The paper heavily relies on Henderson and Popa (2016). You dont need to restate in the current paper all the mathematical analysis that appears in the previous paper. You are expected, however, that the model description and the notation that is used here should be clearly explained. Maybe you can also add algorithm box. I think that the author should prepared a revised version of section 2.\n\nIn Word2vec, Levy and Goldberg provided an elegant analysis of the algorithm and showed that the global optimum is obtained at the PMI matrix. Can you derive a similar analysis for your variant of the word2vec algorithm?\n']","[-70, -30, 60]","[-20, 50, 70]","[""The sentiment score is -70 because the reviewer explicitly states 'I do not recommend it for acceptance' and provides several critical points about the paper's shortcomings. The review highlights issues with writing clarity, lack of related work, weak evaluation, and overstatement of results. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism ('confusingly written', 'weak evaluation') and the final paragraph suggests the reviewer is struggling to take the work seriously. The language isn't overtly rude, but it's more direct and critical than neutral or polite."", ""The sentiment score is -30 because the reviewer expresses difficulty understanding the paper and points out discrepancies, indicating a somewhat negative view. However, they offer constructive criticism and suggestions for improvement, which prevents the score from being more negative. The politeness score is 50 because the reviewer uses polite language such as 'Could the authors please clarify' and 'I recommend', showing respect while providing feedback. They also acknowledge positive aspects like 'BLESS is a nice dataset'. The tone is professional and constructive throughout, without any rudeness, but also not overly formal or deferential."", ""The sentiment score is 60 (positive) because the reviewer finds the paper 'interesting' and notes that the approach is 'novel' with 'significant improvement' over previous work. However, it's not extremely positive as the reviewer suggests improvements. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. The reviewer acknowledges the paper's strengths before suggesting improvements, which is a polite approach. The use of phrases like 'I find the paper interesting' and 'You are expected' maintain a professional and courteous tone.""]"
"[""The paper proposes variance regularizing adversarial learning (VRAL), a new method for training GANs.\n\nThe motivation is to ensure that the gradient for the generator does not vanish. The authors propose to use a discriminator whose output targets a mixture of two Gaussians (one component each for real and fake data).  The means and variances are fixed so that the discriminator does not overfit, which ensures that the generator learning is not hindered. \n\nThe discriminator itself is trained through two additional meta-discriminators (!) Are the meta-discriminators really necessary? Have you tried matching moments or using other methods for comparing the distributions?\n\nIt would be useful to write down the actual loss function so that it's easier to compare with other GAN variants. In particular, I'm curious to understand the difference between VRAL and Fisher-GAN. The authors discuss this in the end of Section 3, but a more careful comparison is needed.\n\nThe experimental results are pretty limited and lack detailed quantitative evaluation, which makes it harder to compare the performance of the proposed variant to existing algorithms.\n\nOverall, I think that the idea is interesting, but the paper needs more work and does not meet the ICLR acceptance bar.\n\nFYI, another concurrent submission showed that gradient penalties stabilize training of GANs:\nMANY PATHS TO EQUILIBRIUM: GANS DO NOT NEED TO DECREASE A DIVERGENCE AT EVERY STEP\nhttps://openreview.net/pdf?id=ByQpn1ZA-"", 'This paper studies how the variance of the discriminator affect the gradient signal provided to the generator and therefore how it might limit its ability to learn the true data distribution.\n\nThe approach suggested in this paper models the output of the discriminator using a mixture of two Gaussians (one for “fake” and the other for “not fake”). This seems like a rather crude approximation as the distribution of each “class” is likely to be multimodal. Can the authors comment on this? Could they extend their approach to use a mixture of multimodal distributions?\n\nThe paper mentions that fixing the means of the distribution can be “problematic during optimization as the discriminator’s goal is to maximize the difference between these two means.“. This relates to my previous comment where the distribution might not be unimodal. In this case, shifting the mean doesn’t seem to be a good solution and might just yield to oscillations between different modes. Can you please comment on this?\n\nMode collapse: Can you comment on the behavior of your approach w.r.t. to mode collapse?\n\nImplementation details: How is the mean of the two Gaussians initialized? \n\nRelation to instance noise and regularization techniques: Instance noise is a common trick being used to train GANs, see e.g. http://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/\nThis also relates to some regularization techniques, e.g. Roth et al., 2017 that provides a regularizer that amounts to convolving the densities with white Gaussian noise. Can you please elaborate on the potential advantages of the proposed solution over these existing techniques?\n\nComparison to existing baselines: Given that the paper addresses the stability problem, I would expect some empirical comparison to at least one or two of the stability methods cited in the introduction, e.g. Gulrajani et al., 2017 or Roth et al., 2017.\n\nRelation to Kernel MMD: Can the authors elaborate on how their method relates to approaches that replace the discriminator with MMD nets. e.g.\n- Training generative neural networks via Maximum Mean Discrepancy optimization, Dziugaite et al\n- Generative models and model criticism via optimized maximum mean discrepancy, Sutherland et al\nMore explicitly, the variance in these methods can be controlled via the bandwidth of the kernel and I therefore wonder what would one use a simple mixture of Gaussians instead?\n', 'The authors provided empirical analysis of different variants of GANs and proposed a regularization scheme to combat the vanishing gradient when the discriminator is well trained. \n\nMore specifically, the authors demonstrated the importance of intra-class variance in the discriminator’s output. Methods whose discriminators tend to map inputs of a class to single real values are unable to provide a reliable learning signal for the generator, such as the standard GAN and Least Squares GAN. Variance in the discriminator’s output is essential to allow the generator to learn in the presence of a well-trained discriminator. To ensure the discriminator’s output follows the mixture of two univariate Gaussians, the authors proposed to add two additional discriminators which are trained in a similar was as the original GAN formulation. The technique is related to Linear Discriminant Analysis. From a broader perspective, the new meta-adversarial learning can be applied to ensure various desirable properties in GANs.\n\nThe performance of variance regularization scheme was evaluated on the CIFAR-10 and CelebA data.\n\nSummary:\n——\nI think the paper discusses a very interesting topic and presents an interesting direction for training the GANs. A few points are missing which would provide significantly more value to readers. See comments below for details and other points.\n\nComments:\n——\n1.\tWhy would a bi-modal distribution be meaningful? Deep nets implicitly transform the data which is probably much more effective than using complex bi-modal Gaussian distribution; the bi-modal concept can likely be captured using classical techniques.\n\n2.\tOn page 4, in Eq. (8) and (9), it remains unclear what $\\mathcal{R}$ and $\\mathcal{F}$ really are beyond two-layer MLPs; are the results of those two-layer MLPs used as the mean of a Gaussian distribution, i.e., $\\mu_r$ and $\\mu_f$?\n\n3.\tRegarding the description above Eq. (12), what is really used in practice, i.e., in the experiments? The paper omits many details that seem important for understanding. Could the authors provide more details on choosing the generator loss function and why Eq. (12) provides satisfying results in practice?    \n\nMinor Comments:\n——\n1.\tIn Sec 2.1, the sentence needs to be corrected: “As shown in Arjovsky & Bottou (2017), the JS divergence will be flat everywhere important if P and Q both lie on low-dimensional manifolds (as is likely the case with real data) and do not prefectly align.”\n\n2.\tLast sentence in Conclusion: “which can be applied to ensure enforce various desirable properties in GANs.” Please remove either “ensure” or “enforce.”\n']","[-40, -20, 50]","[20, 60, 70]","[""The sentiment score is -40 because while the reviewer finds the idea 'interesting', they state that 'the paper needs more work and does not meet the ICLR acceptance bar'. They also point out several limitations such as 'limited' experimental results and lack of 'detailed quantitative evaluation'. The overall tone is critical but not entirely negative. The politeness score is 20 because the reviewer uses polite language and phrasing throughout, such as 'It would be useful' and 'I'm curious to understand', while also providing constructive criticism. They also acknowledge the interesting aspects of the work. However, the review is not overly effusive in its politeness, maintaining a professional tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's approach, they raise several critical questions and concerns about the methodology, assumptions, and lack of comparisons to existing techniques. This suggests the reviewer sees significant room for improvement. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrasing criticisms as questions or requests for clarification rather than direct criticisms. They use phrases like 'Can the authors comment on this?' and 'Can you please elaborate' which maintain a polite and constructive tone. The review is thorough and detailed, providing specific suggestions for improvement, which is a positive aspect in academic peer review."", ""The sentiment score is 50 (slightly positive) because the reviewer states that the paper discusses 'a very interesting topic' and presents 'an interesting direction for training the GANs'. However, they also mention that 'a few points are missing' which would provide more value, indicating some reservations. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the value of the work, and frames their criticisms as suggestions for improvement rather than harsh critiques. They use phrases like 'Could the authors provide more details' and 'Please remove either' which are polite ways of pointing out issues. The review maintains a professional and constructive tone throughout.""]"
"['The main emphasis of this paper is how to add background knowledge so as to improve the performance of NLU (specifically QA and NLI) systems. They adopt the sensible perspective that background knowledge might most easily be added by providing it in text format. However, in this paper, the way it is added is simply by updating word representations based on this extra text. This seems too simple to really be the right way to add background knowledge. \n\nIn practice, the biggest win of this paper turns out to be that you can get quite a lot of value by sharing contextualized word representations between all words with the same lemma (done by linguistic preprocessing; the paper never says exactly how, not even if you read the supplementary material). This seems a useful observation which it would be easy to apply everywhere and which shows fairly large utility from a bit of linguistically sensitive matching!  As the paper notes, this type of sharing is the main delta in this paper from simply using a standard deep LSTM (which the paper claims to not work on these data sets, though I\'m not quite sure couldn\'t be made to work with more tuning).\n\npp. 6-7: The main thing of note seems to be that sharing of representations between words with the same lemma (which the tables refer to as ""reading"" is worth a lot (3.5-6.0%), in every case rather more than use of background knowledge (typically 0.3-1.5%). A note on the QA results: The QA results are certainly good enough to be in the range of ""good systems"", but none of the results really push the SOTA. The best SQuAD (devset) results are shown as several percent below the SOTA. In the table the TriviaQA results are shown as beating the SOTA, and that\'s fair wrt published work at the time of submission, but other submissions show that all of these results are below what you get by running the DrQA (Chen et al. 2017) system off-the-shelf on TriviaQA, so the real picture is perhaps similar to SQuAD, especially since DrQA is itself now considerably below the SOTA on SQUAD. Similar remarks perhaps apply to the NLI results.\n\np.7 In the additional NLI results, it is interesting and valuable to note that the lemmatization and knowledge help much more when amounts of data (and the covarying dimensionality of the word vectors) is much smaller, but the fact that the ideas of this paper have quite little (or even negative) effects when run on the full data with full word vectors on top of the ESIM model again draws into question whether enough value is being achieved from the world knowledge.\n\nBiggest question:\n - Are word embeddings powerful enough as a form of memory to store the kind of relational facts that you are accessing as background knowledge?\n\nMinor notes:\n - The paper was very well written/edited. The only real copyediting I noticed was in the conclusion: and be used ➔ and can be used; that rely on ➔ that relies on.\n - Should reference to (Manning et al. 1999) better be to (Manning et al. 2008) since the context here appears to be IR systems?\n - On p.3 above sec 3.1: What is u? Was that meant to be z?\n - On p.8, I\'m a bit suspicious of the ""Is additional knowledge used?"" experiment which trains with knowledge and then tests without knowledge. It\'s not surprising that this mismatch might hurt performance, even if the knowledge provided no incremental value over what could be gained from standard word vectors alone.\n - In the supplementary material the paper notes that the numbers are from the best result from 3 runs. This seems to me a little less good experimental practice than reporting an average of k runs, preferably for k a bit bigger than 3.\n\n\n', 'The quality of this paper is good. The presentation is clear but I find lack of description of a key topic. The proposed model is not very innovative but works fine for the DQA task. For the TE task, the proposed method does not perform better than the state-of-the-art systems. \n\n- As ESIM is one of the key components in the experiments, you should briefly introduce ESIM and explain how you incorporated with your vector representations into ESIM.\n- The reference of ESIM is not correct.\n- Figure 1 is hard to understand. What do you indicate with the box and arrow? Arrows seem to have some different meanings. \n- What corpus did you use to pre-train word vectors? \n- As the proposed method was successful for the QA task, you need to explain QA data sets and how the questions are solved.\n- I also expect performance and  error analysis of the task results.  \n- To claim ""task-agnostic"", you need to try to apply your method to other NLP tasks as well.\n- Page 3. \\Sigma is not defined.', ""This paper proposes a model for adding background knowledge to natural language understanding tasks. The model reads the relevant text and then more assertions gathered from background knowledge before determining the final prediction. The authors show this leads to some improvement on multiple tasks like question answering and natural language inference (they do not obtain state of the art but improve over a base model, which is fine in my opinion).\n\nI think the paper does a fairly good job at doing what it does, it is just hard to get excited by it. \nHere are my major comments:\n\n* The authors explains that the motivation for the work is that one cannot really capture all of the knowledge necessary for doing natural language understanding because the knowledge is very dynamic. But then they just concept net to augment text. This is quite a static strategy, I was assuming the authors are going to use some IR method over the web to back up their motivation. As is, I don't really see how this motivation has anything to do with getting things out of a KB. A KB is usually a pretty static entity, and things are added to it at a slow pace.\n\n* The author's main claim is that retrieving background knowledge and adding it when reading text can improve performance a little when doing QA and NLI. Specifically they take text and add common sense knowledge from concept net. The authors do a good job of showing that indeed the knowledge is important to gain this improvement through analysis. However, is this statement enough to cross the acceptance threshold of ICLR? Seems a bit marginal to me.\n\n* The author's propose a specific way of incorporating knowledge into a machine reading algorithm through re-embeddings that have some unique properties of sharing embeddings across lemmas and also having some residual connections that connect embeddings and some processed versions of them. To me it is unclear why we should use this method for incorporating background knowledge and not some simpler way. For example, have another RNN read the assertions and somehow integrate that. The process of re-creating embeddings seems like one choice in a space of many, not the simplest, and not very well motivated. There are no comparisons to other possibilities. As a result, it is very hard for me to say anything about whether this particular architecture is interesting or is it just in general that background knowledge from concept net is useful. As is, I would guess the second is more likely and so I am not convinced the architecture itself is a significant contribution.\n\nSo to conclude, the paper is well-written, clear, and has nice results and analysis. The conclusion is that reading background knowledge from concept net boost performance using some architecture. This is nice to know but I think does not cross the acceptance threshold.\n\n""]","[-20, 20, -30]","[60, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper, they express significant doubts about the main approach and its effectiveness. The reviewer questions whether word embeddings are powerful enough to store relational facts from background knowledge, and notes that the improvements from the paper's main technique are often small or even negative in some cases. However, they do praise certain aspects like the usefulness of lemma-based representation sharing.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They offer constructive criticism and specific suggestions for improvement. The language used is not overly effusive but is consistently polite, using phrases like 'interesting and valuable to note' and acknowledging the paper as 'very well written/edited'. The reviewer also frames their critiques as questions or observations rather than harsh judgments."", ""The sentiment score is slightly positive (20) because the reviewer starts by saying 'The quality of this paper is good' and mentions that the proposed model 'works fine for the DQA task'. However, they also point out some limitations, such as lack of innovation and not outperforming state-of-the-art systems for the TE task, which prevents a higher positive score. The politeness score is moderately positive (50) as the reviewer uses neutral language and provides constructive feedback without harsh criticism. They offer specific recommendations for improvement in a professional manner, using phrases like 'you should' and 'I expect' rather than more demanding language. The review maintains a respectful tone throughout, balancing positive aspects with areas for improvement."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('fairly good job', 'nice results and analysis'), the overall tone is skeptical and critical. The reviewer expresses doubts about the paper's significance and contribution, stating it's 'hard to get excited by it' and questioning if it 'cross[es] the acceptance threshold'. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positives and framing criticisms as personal opinions ('I think', 'Seems to me'). They avoid harsh language, instead using more neutral phrases like 'hard to get excited' and 'a bit marginal'. The reviewer also provides detailed, constructive feedback, which is a polite approach to peer review.""]"
"['Paper Summary: The paper proposes an approach to perform object classification and changing the viewpoint simultaneously. The idea is that the viewpoint changes until the object is recognized. The results have been reported on ModelNet40.\n\nPaper Strength: The idea of combining active vision with object classification is interesting.\n\nPaper Weaknesses:\nI have the following concerns about this paper: (1) The paper performs the experiments on ModelNet40, which is a toy dataset for this task. The background is white and there is only a single object in each image. (2) The simple CNN baselines in MVCNN (Su et al., 2015) achieve higher performance than the proposed model, which is more complicated. (3) The paper seems unfinished. It mentions THOR and Active Vision, but there is no quantitative or qualitative results on them. (4) Some of the implementation details are unclear.\n\ncomments:\n\n- It is unfair to use (Ammirato et al., 2017) as the citation for active vision. Active vision has been around for decades.\n\n- It is not clear how the hierarchical soft-max layers have been implemented. There cannot be two consecutive soft-max layers. Also, for example, we cannot select an action from A, and then select an action from C since the operation is not differentiable. This should be clarified in the rebuttal.\n\n- In Table 3, why is there a difference between the performance with and without LSTM in the first column? The LSTM does not see any history at the first step so the performance should be the same in both cases.\n\n- According to Table 1 of MVCNN (Su et al., 2015), a simple CNN with one view as input achieves 83% accuracy (w/o fine-tuning), which is higher than the performance of the proposed method.\n\n- It is better not to call the approach navigation. It is just changing the azimuth of the camera view.', 'The ambition of this paper is to address multi-view object recognition and the associated navigation as a unified reinforcement learning problem using a deep CNN to represent the policy.\n\nMulti-view recognition and active viewpoint selection have been studied for more than 30 years, but this paper ignores most of this history.  The discussion of related work as well as the empirical evaluation are limited to very recent methods using neural networks.  I encourage the authors to look e.g. at Paletta and Pinz [1] (who solve a very similar and arguably harder problem in related ways) and at Bowyer & Dyer [2] as well as the references contained in these papers for history and context.  Active vision goes back to Bajcsy, Aloimonos, and Ballard; these should be cited instead of Ammirato et al.  Conversely, the related work cites a handful of papers (e.g. in the context of Atari 2600 games) that are unrelated to this work.\n\nThe navigation aspect is limited to fixed-size left or right displacements (at least for ModelNet40 task which is the only one to be evaluated and discussed).  This is strictly weaker than active viewpoint selection.  Adding this to the disregard of prior work, it is (at best) misleading to claim that this is ""the first framework to combine learning of navigation and object recognition"".\n\nCalling this ""multi-task"" learning is also misleading.  There is only one ultimate objective (object recognition), while the agent has two types of actions available (moving or terminating with a classification decision).\n\nThere are other misleading, vague, or inaccurate statements in the paper, for example:\n\n- ""With the introduction of deep learning to reinforcement learning, there has been ... advancements in understanding ... how humans navigate"": I don\'t think such a link exists; if it does, a citation needs to be provided.\n\n- ""inductive bias like image pairs"": Image pairs do not constitute inductive bias.  Either the term is misused or the wording must be clarified; likewise for other occurrences of ""inductive bias"".\n\n- ""a single softmax layer is biased towards tasks with larger number of actions"": I think I understand what this is intended to say, but a ""softmax layer"" cannot be ""biased towards tasks"" as there is only one, given, task.\n\n- I do not understand what the stated contribution of ""extrapolation of the action space to a higher dimension for multi-task learning"" is meant to be.\n\n- ""Our method performs better ... than state-of-the-art in training for navigation to the object"": The method does not involve ""navigation to the object"", at least not for the ModelNet40 dataset, the only for which results are given.\n\nIt is not clear what objective function the system is intended to optimize.  Since the stated task is object recognition and from Table 2 I was expecting it to be the misclassification rate, but this is clearly not the case, as the system is not set up to minimize it.  What ""biases"" the system towards classification actions (p. 5)?  Why is it bad if the agent shows ""minimal movement actions"" as long as the misclassification rate is minimized? No results are given to show whether this is the case or not.  The text then claims that the ""hierarchical method gives superior results"", but this is not shown either.\n\nTable 3 reveals that the system fails to learn much of interest at all.  Much of the time the agent chooses not to move and performs relatively poorly; taking more steps improves the results; often all 12 views are collected before a classification decision is made.  Two of the most important questions remain open: (1) What would be the misclassification rate if all views are always used? (2) What would be the misclassification rate under a random baseline policy not involving navigation learning (e.g., taking a random number of steps in the same direction)?\n\nExperiments using the THOR dataset are announced but are left underspecified (e.g., the movement actions), but no results or discussion are given.\n\nSUMMARY\n\nQuality: lacking in may ways; see above.\n\nClarity: Most of the paper is clear enough, but there are confusions and missing information about THOR and problems with phrasing and terminology.  Moreover, there are many grammatical and typographical glitches.\n\nOriginality: Harder tasks have been looked at before (using methods other than CNN).  Solving a simpler version using CNN I do not consider original unless there is a compelling pay-off, which this paper does not provide.\n\nSignificance: Low.\n\nPros: The problem would be very interesting and relevant if it was formulated in a more ambitious way (e.g., a more elaborate action space than that used for ModelNet40) with a clear objective function,\n\nCons: See above.\n\n\n[1] Lucas Paletta and Axel Pinz, Active object recognition by view integration and reinforcement learning, Robotics and Autonomous Systems 31, 71-86, 2000\n\n[2] Bowyer, K. W. and Dyer, C. R. (1990), Aspect graphs: An introduction and survey of recent results. Int. J. Imaging Syst. Technol., 2: 315–328. doi:10.1002/ima.1850020407\n', ' \nThe paper proposes LSD-NET, an active vision method for object classification. In the proposed method, based on a given view of an object, the algorithm can decide to either classify the object or to take a discrete action step which will move the camera in order to acquire a different view of the object. Following this procedure the algorithm iteratively moves around the object until reaching a maximum number of allowed moves or until a object view favorable for classification is reached.\n\nThe main contribution of the paper is a hierarchical action space that distinguishes between camera-movement actions and classification actions. At the top-level of the hierarchy, the algorithm decides whether to perform a movement or a classification -type action. At the lower-level, the algorithm either assign a specific class label (for the case of classification actions) or performs a camera movement (for the case of camera-movement actions). This hierarchical action space results in reduced bias towards classification actions.\n\n\nStrong Points\n- The content is clear and easy to follow.\n- The proposed method achieves competitive performance w.r.t. existing work.\n\nWeak Points\n- Some aspects of the proposed method could have been evaluated better.\n- A deeper evaluation/analysis of the proposed method is missing.\n\nOverall the proposed method is sound and the paper has a good flow and is easy to follow. The proposed method achieves competitive results, and up to some extent, shows why it is important to have the proposed hierarchical action space.\n\nMy main concerns with this manuscript are the following:\n\nIn some of the tables a LSTM variant? of the proposed method is mentioned. However it is never introduced properly in the text. Can you indicate how this LSTM-based method differs from the proposed method?\n\nAt the end of Section 5.2 the manuscript states: ""In comparison to other methods, our method is agnostic of the starting point i.e. it can start randomly on any image and it would get similar testing accuracies."" This suggests that the method has been evaluated over different trials considering different random initializations. However, this is unclear based on the evaluation protocol presented in Section 5. If this is not the case, perhaps this is an experiment that should be conducted.\n\nIn Section 3.2 it is mentioned that different from typical deep reinforcement learning methods, the proposed method uses a deeper AlexNet-like network. In this context, it would be useful to drop a comment on the computation costs added in training/testing by this deeper model.\n\nTable 3 shows the number of correctly and wrongly classified objects as a function  of the number of steps taken. Here we can notice that around 50% of the objects are in the step 1 and 12, which as correctly indicated by the manuscript, suggests that movement does not help for those cases. Would it be possible to have more class-specific (or classes grouped into intermediate categories) visualization of the results? This would provide a better insight of what is going on and when exactly actions related to camera movements really help to get better classification performance. \nOn the presentation side, I would recommend displaying the content of Table 3 in a plot. This may display the trends more clearly. Moreover, I would recommend to visualize the classification accuracy as a function of the step taken by the method. In this regard, a deeper analysis of the effect of the proposed hierarchical action space is a must.\n\nI would encourage the authors to address the concerns raised on my review.\n']","[-50, -70, 50]","[20, -20, 80]","[""The sentiment score is -50 because the review is predominantly critical. While it acknowledges the interesting idea of combining active vision with object classification, it lists several significant weaknesses and concerns about the paper. The reviewer points out issues with the dataset choice, performance compared to baselines, incomplete results, and unclear implementation details. These criticisms outweigh the single positive comment, indicating a generally negative sentiment.\n\nThe politeness score is 20 because the reviewer maintains a professional and objective tone throughout. They use neutral language to express their concerns, such as 'I have the following concerns' and 'It is better not to call the approach navigation.' The reviewer also provides specific suggestions for improvement and clarification, which is constructive. However, the score is not higher because the review is direct in its criticisms without much softening language, and there are limited positive remarks to balance the critique."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out numerous flaws, including ignoring prior work, misleading claims, inaccurate statements, and lack of clear objectives. They also state that the paper's quality is 'lacking in many ways' and its significance is 'Low'. The few positive comments (e.g., 'The problem would be very interesting and relevant if...') are heavily qualified. The politeness score is -20 because while the reviewer maintains a professional tone overall, there are several instances of blunt criticism (e.g., 'it is (at best) misleading', 'fails to learn much of interest at all') and the general tone is quite harsh. However, it doesn't descend into personal attacks or overtly rude language, hence not an extremely low score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges strong points of the paper, such as clarity and competitive performance, while also noting weak points and areas for improvement. The overall tone is constructive, indicating that the method is 'sound' and the paper has 'good flow', but there are 'main concerns' that need to be addressed. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers encouragement ('I would encourage the authors...'), and frames criticisms as suggestions or questions rather than direct attacks. Phrases like 'Can you indicate...', 'Would it be possible...', and 'I would recommend...' contribute to the polite tone. The reviewer also acknowledges the positive aspects before diving into critiques, which is a polite approach to peer review.""]"
"[""The paper describes a sequence to sequence auto-encoder model which is used to learn sequence representations. The authors show that for their application, better performance is obtained when the network is only trained to reconstruct a subset of the data measurements. The paper also presents some visualizations the similarity structure of the learned representations and proposes a window-based method for processing the data.\n\nAccording to the paper, the experiments are done using a data set which is obtained from measurements of an industrial production process. Figure 2 indicates that reconstructing fewer dimensions of this dataset leads to lower MSE scores. I don’t see how this is showing anything besides the obvious fact that reconstructing fewer dimensions is an easier task than reconstructing all of them.  The only conclusions I can draw from the visual analysis is that the context vectors are more similar to each other when they are obtained from time steps in the data stream which are close to each other. Since the paper doesn’t describe much about the privately owned data at all, there is no possibility to replicate the work. The paper doesn’t frame the work in prior research at all and the six papers it cites are only referred to in the context of describing the architecture.\n\nI found it very hard to distil what the main contribution of this work was according to the paper. There were also not many details about the precise architecture used. It is implied that GRU networks and were used but the text doesn’t actually state this explicitly. By saying so little about the data that was used, it was also not clear what the temporal correlations of the context vectors are supposed to tell us. \n\nThe paper describes how existing methods are applied to a specific data set. The benefit of only reconstructing a subset of the input dimensions seems very data specific to me and I find it hard to consider this a novel idea by itself. Presenting sequential data in a windowed format is a standard procedure and not a new idea either. All in all I don't think that the paper presents any new ideas or interesting results.\n\nPros:\n* The visualizations look nice.\n\nCons:\n* It is not clear what the main contribution is.\n* Very little information about the data. \n* No clear experiments from which conclusions can be drawn.\n* No new ideas.\n* Not well rooted in prior work.\n"", 'This writeup describes an application of recurrent autoencoder to analysis of multidimensional time series. The quality of writing, experimentation and scholarship is clearly below than what is expected from a scientific article. The method is explained in a very unclear way, there is no mention of any related work. I would encourage the authors to take a look at other ICLR submissions and see how rigorously written they are, how they position the reported research among comparable works. ', 'This paper proposes a strategy that is inspired by the recurrent auto-encoder model, such that clustering of multidimensional time series data can be performed based on the context vectors generated by the encoding process. Unfortunately, the paper in its current form is a bit thin on content.\n \nMain issues:\nNo related works (such as those using RNN for time series analysis or clustering of time series data streams etc.) were described by the paper, no baselines were used in the comparison evaluations, and no settings/details were provided in the experiment section. As a result, it is quite difficult to judge the merits and novelty of the paper.\n \nOther issues:\nsome contribution claims highlighted in the Discussion Section, i.e., Section 4, are arguable and should be further extended. For example, the authors claim that the proposed LSTM-based autoencoder networks can be natively scaled up to data with very high dimensionality. I would like the authors to explain it in more details or empirically demonstrate that, since a LSTM-based model could be computationally expensive. As another example, the authors claim that reducing the dimensionality of the output sequence is one of the main contributions of the paper. In this sense, further elaborations from that perspective would be very beneficial since some networks already employ such a mechanism. \n\nIn short, the paper in its current form does not provide sufficient details for the reviewer to judge its merits and contributions.']","[-80, -80, -60]","[20, -20, 20]","[""The sentiment score is -80 because the review is predominantly negative. The reviewer states that they find it hard to identify the main contribution, criticizes the lack of details about the data and architecture, and concludes that the paper presents no new ideas or interesting results. The few positive comments (e.g., 'The visualizations look nice') are vastly outweighed by the criticisms. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'I found it very hard' and 'I don't think' rather than making blunt accusations. The reviewer also acknowledges a positive aspect ('The visualizations look nice') which adds a touch of politeness. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is -80 because the review is highly critical, stating that the quality is 'clearly below' expectations, the method explanation is 'very unclear', and there's 'no mention of any related work'. These are significant criticisms that indicate a strongly negative sentiment. The politeness score is -20 because while the language isn't overtly rude, it's quite blunt and doesn't soften the criticisms. The reviewer directly states the work is subpar and encourages the authors to look at other submissions, implying their work doesn't measure up. However, the use of 'I would encourage' slightly mitigates the harshness, preventing an even lower politeness score."", ""The sentiment score is -60 because the review is generally negative, pointing out several major issues with the paper. The reviewer states that the paper is 'thin on content' and lacks important elements such as related works, baselines, and experimental details. The reviewer also expresses difficulty in judging the paper's merits and novelty due to these shortcomings. However, the score is not at the extreme negative end because the reviewer acknowledges the paper's proposed strategy and doesn't completely dismiss its potential.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and relatively courteous tone throughout. They use phrases like 'Unfortunately' and 'I would like the authors to explain' which soften the criticism. The reviewer also provides specific suggestions for improvement, which is constructive. However, the score is not higher because the language, while not rude, is also not overtly polite or encouraging.""]"
"['The authors present an evolution of the idea of fast weights: training a double recurrent neural network, one ""slow"" trained as usual and one ""fast"" that gets updated in every time-step based on the slow network. The authors generalize this idea in a nice  way and present results on 1 experiment. On the positive side, the paper is clearly written and while the fast-weights are not new, the details of the presented method are original. On the negative side, the experimental results are presented on only 1 experiment with a data-set and task made up by the authors. The results are good but the improvements are not too large, and they are measured over weak baselines implemented by the authors. For a convincing result, one would require an evaluation on a number of tasks, including long-studied ones like language modeling, and comparison to stronger related models, such as the Neural Turing Machine or the Transformer (from ""Attention is All You Need""). Without comparison to stronger baselines and with results only on 1 task constructed by the authors, we have to recommend rejection.', 'Summary\nThe paper proposes a neural network architecture for associative retrieval based on fast weights with context-dependent gated updates. The architecture consists of a ‘slow’ network which provides weight updates for the ‘fast’ network which outputs the predictions of the system. The experiments show that the architecture outperforms a couple of related models on an associative retrieval problem.\n\nQuality\nThe authors evaluate their architecture on an associative retrieval task which is similar to the variable assignment task used in Danihelka et al. (2016). The difference with the original task seems to be that the network is also trained to predict a ‘blank’ symbol which indicates that no prediction has been made. While this task is artificial, it does make sense in the context of what the authors want to show. The fact that the authors compare their results with three sensible baselines and perform some form of hyper-parameter search for all of the models, adds to the quality of the experiment. It is somewhat unfortunate that the paper doesn’t give more detail about the precise hyper-parameters involved and that there is no comparison with the associative LSTM from Danihelka et al. Did these hyper-parameters also include the sizes of the models? Otherwise it’s not very clear to me why the numbers of parameters are so much higher for the baseline models. While I think that this experiment is well done, it is unfortunate that it is the only experiment the authors carried out and the paper would be more impactful if there would have been results for a wider variety of tasks. It is commendable that the authors also discuss the memory requirements and increased wall clock time of the model.\n\nClarity\nI found the paper hard to read at times and it is often not very clear what the most important differences are between the proposed methods and earlier ones in the literature. I’m not saying those differences aren’t there, but the paper simply didn’t emphasize them very well and I had to reread the paper from Ba et al. (2016) to get the full picture.  \n\nOriginality/Significance\nWhile the architecture is new, it is based on a combination of previous ideas about fast weights, hypernetworks and activation gating and I’d say that the novelty of the approach is average. The architecture does seem to work well on the associative retrieval task, but it is not clear yet if this will also be true for other types of tasks. Until that has been shown, the impact of this paper seems somewhat limited to me.\n\nPros\nExperiments seem well done.\nGood baselines.\nGood results.\n\nCons\nHard to extract the most important changes from the text.\nOnly a single synthetic task is reported.\n\n', 'The paper proposed an extension to the fast weights from Ba et al. to include additional gating units for changing the fast weights learning rate adaptively. The authors empirically demonstrated the gated fast weights outperforms other baseline methods on the associative retrieval task.\n\nComment:\n\n- I found the paper very hard to follow. The authors could improve the clarity of the paper greatly by listing their contribution clearly for readers to digest. The authors should emphasize the first half of the method section are from existing works and should go into a separate background section.\n\n- Overall, the only contribution of the paper seems to be the modification to Ba et al. is the Eq. (8). The authors have only evaluated the method on a synthetic associative retrieval task. Without additional experiments on other datasets, it is hard for the reader to draw any meaningful conclusion about the proposed method in general.']","[-50, -20, -50]","[50, 50, 20]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('clearly written', 'original'), they ultimately recommend rejection due to limited experimental results and lack of comparison to stronger baselines. The overall tone leans negative, but not extremely so. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging both positive and negative aspects, and provides clear reasoning for their recommendation. They avoid harsh criticism and use phrases like 'On the positive side' and 'On the negative side' to balance their feedback. The language is professional and constructive, though not overly formal or deferential."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Experiments seem well done', 'Good baselines', 'Good results'), there are several criticisms and limitations pointed out. The reviewer mentions the paper being hard to read, lacking clarity on key differences, having only a single synthetic task, and having limited impact. The overall tone suggests the paper has merit but falls short in several areas. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'It is commendable' and 'I found' to soften criticisms, and provide balanced feedback by listing both pros and cons. The language is constructive rather than harsh, even when pointing out weaknesses."", ""The sentiment score is -50 because the review is generally critical, pointing out significant issues with the paper's clarity and limited contribution. The reviewer states the paper is 'very hard to follow' and suggests major improvements are needed. They also note that the paper's contribution seems limited to a single equation modification and lacks broader experimental validation. However, the score is not lower because the reviewer does acknowledge some positive aspects, such as the empirical demonstration of the method's performance on a specific task. The politeness score is 20 because while the reviewer is direct in their criticism, they use relatively neutral language and offer constructive suggestions for improvement. Phrases like 'The authors could improve...' and 'The authors should...' are polite ways of offering criticism. The reviewer also uses 'I found' to frame their critique as a personal observation rather than an absolute statement, which adds a degree of politeness.""]"
"[""This paper describes an approach to generating time sequences by learning state-action values, where the state is the sequence generated so far, and the action is the choice of the next value.  Local and global reward functions are learned from existing data sequences and then the Q-function learned from a policy gradient.\n\nUnfortunately, this description is a little vague, because the paper's details are quite difficult to understand.  Though the approach is interesting, and the experiments are promising, important explanation is missing or muddled.  Perhaps most confusing is the loss function in equation 7, which is quite inadequately explained.\n\nThis paper could be interesting, but substantial editing is needed before it is sufficient for publication."", 'This article is a follow-up from recent publications (especially the one on ""seqGAN"" by Yu et al. @ AAAI 2017) which tends to assimilate Generative Adversarial Networks as an Inverse Reinforcement Learning task in order to obtain a better stability.\nThe adversarial learning is replaced here by a combination of policy gradient and a learned reward function.\n\nIf we except the introduction which is tainted with a few typos and English mistakes, the paper is clear and well written. The experiments made on both synthetic and real text data seems solid.\nBeing not expert in GANs I found it pleasant to read and instructive.\n\n\n\n', 'This paper considers the problem of improving sequence generation by learning better metrics. Specifically, it focuses on addressing the exposure bias problem, where traditional methods such as SeqGAN uses GAN framework and reinforcement learning. Different from these work, this paper does not use GAN framework. Instead, it proposed an expert-based reward function training, which trains the reward function (the discriminator) from data that are generated by randomly modifying parts of the expert trajectories. Furthermore, it also introduces partial reward function that measures the quality of the subsequences of different lengths in the generated data. This is similar to the idea of hierarchical RL, which divide the problem into potential subtasks, which could alleviate the difficulty of reinforcement learning from sparse rewards. The idea of the paper is novel. However, there are a few points to be clarified.\n\nIn Section 3.2 and in (4) and (5), the authors explains how the action value Q_{D_i} is modeled and estimated for the partial reward function D_i of length L_{D_i}. But the authors do not explain how the rewards (or action value functions) of different lengths are aggregated together to update the model using policy gradient. Is it a simple sum of all of them?\n\nIt is not clear why the future subsequences that do not contain y_{t+1} are ignored for estimating the action value function Q in (4) and (5). The authors stated that it is for reducing the computation complexity. But it is not clear why specifically dropping the sequences that do not contain y_{t+1}. Please clarify more on this point.\n']","[-50, 70, 50]","[20, 80, 80]","[""The sentiment score is -50 because the review starts with a neutral description of the paper but quickly shifts to a negative tone. The reviewer states that the paper's details are 'difficult to understand', 'important explanation is missing or muddled', and that 'substantial editing is needed before it is sufficient for publication'. These criticisms outweigh the initial neutral description and the mention of 'promising experiments'. The politeness score is 20 because while the reviewer is critical, they use relatively polite language. They describe the approach as 'interesting' and avoid harsh or personal criticism. The use of 'unfortunately' and 'could be interesting' softens the negative feedback. However, the directness of the criticism prevents a higher politeness score."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper. They describe it as 'clear and well written', with 'solid' experiments, and 'pleasant to read and instructive'. The only negative point mentioned is some typos and English mistakes in the introduction. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They acknowledge their own expertise level ('Being not expert in GANs') and use phrases like 'I found it pleasant to read' which convey a polite and appreciative tone. The reviewer also balances their critique (mentioning typos) with positive feedback, which is a polite approach to reviewing."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty of the paper's idea and provides a balanced overview of the work. However, they also point out areas that need clarification, indicating a mix of positive and critical feedback. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as requests for clarification rather than direct criticisms, and begins with a neutral summary of the paper before moving to specific points. The reviewer's tone is professional and constructive, avoiding harsh or dismissive language.""]"
"[""This paper addresses the question of unsupervised clustering with high classification performance. They propose a deep variational autoencoder architecture with categorical latent variables at the deepest layer and propose to train it with modifications of the standard variational approach with reparameterization gradients. The model is tested on a medical imagining dataset where the task is to distinguish healthy from pathological lymphocytes from blood samples. \n\nI am not an expert on this particular dataset, but to my eye the results look impressive. They show high sensitivity and high specificity. This paper may be an important contribution to the medical imaging community.\n\nMy primary concern with the paper is the lack of novelty and relatively little in the way of contributions to the ICLR community. The proposed model is a simple variant on the standard VAE models (see for example the Ladder VAE https://arxiv.org/abs/1602.02282 for deep models with multiple stochastic layers). This would be OK if a thorough evaluation on at least two other datasets showed similar improvements as the lymphocytes dataset. As it stands, it is difficulty for me to assess the value of this model.\n\nMinor questions / concerns:\n\n- The authors claim in the first paragraph of 3.2 that deterministic mappings lack expressiveness. Would be great to see the paper take this claim seriously and investigate it.\n- In equation (13) it isn't clear whether you use q_phi to be the discrete mass or the concrete density. The distinction is discussed in https://arxiv.org/abs/1611.00712\n- Would be nice to report the MCC in experimental results."", 'Summary\n\nThe authors propose a hierarchical generative model with both continuous and discrete latent variables. The authors empirically demonstrate that the latent space of their model separates well healthy vs pathological cells in a dataset for Chronic lymphocytic leukemia (CLL) diagnostics. \n\n\nMain\n\nOverall the paper is reasonably well written. There are a few clarity issues detailed below.\nThe results seem very promising as the model clearly separates the two types of cells. But more baseline experiments are needed to assess the robustness of the results. \n\nNovelty\n\nThe model introduced is a variant of a deep latent Gaussian model, where the top-most layer is a discrete random variable. Furthermore, the authors employ the Gumbel-trick to avoid having to explicitly marginalize the discrete latent variables.\n\nGiven the extensive literature on combining discrete and continuous latent variables in VAEs, the novelty factor of the proposed model is quite weak. \n\nThe authors use the Gumbel-trick in order to avoid explicit marginalization over the discrete variables. However, the number of categories in their problem is small (n=2), so the computational overhead of an explicit marginalization would be negligible. The result would be equivalent to replacing the top of the model p(y) p(z_L|y) by a GMM p_{GMM}(z_L) with two Gaussian components only.\nGive these observations, it seems that this is an unnecessary complication added to the model as an effort to increase novelty. \nIt would be very informative to compare both approaches.\n\nI would perhaps recommend this paper for an applied workshop, but not for publication in a main conference.\n\nDetails:\n\n1) Variable h was not defined before it appeared in Eq. (5). From the text/equations we can deduce h = (y, z_1, …, z_L), but this should be more clearly stated.\n2) It is counter-intuitive to define the inference model before having defined the generative model structure, perhaps the authors should consider changing the presentation order.\n3) Was the VAE in VAE+SVM also trained with lambda-annealing?\n4) How does a simple MLP classifier compares to the models on Table 1 and 2?\n5) It seems that, what is called beta-VAE here is the same model HCDVAE but trained with a lambda that anneals to a value different than one (the value of beta). In this case what is the value it terminates? How was that value chosen?\n6) The authors used 3 stochastic layers, how was that decided? Is there a substantial difference in performance compared to 1 and 2 stochastic layers?\n7) How do the different models behave in terms train vs test set likelihoods. Was there overfitting detected for some settings? How does the choice of the MCC threshold affects train/test likelihoods?  \n8) Have the authors compared explicit marginalizing y with using the Gumbel-trick?\n\nOther related work:\n\nA few other papers that have explored discrete latent variables as a way to build more structured VAEs are worth mentioning/referring to:\n\n[1] Dilokthanakul N, Mediano PA, Garnelo M, Lee MC, Salimbeni H, Arulkumaran K, Shanahan M. Deep unsupervised clustering with gaussian mixture variational autoencoders. arXiv preprint arXiv:1611.02648. 2016 Nov 8.\n\n[2] Goyal P, Hu Z, Liang X, Wang C, Xing E. Nonparametric Variational Auto-encoders for Hierarchical Representation Learning. arXiv preprint arXiv:1703.07027. 2017 Mar 21.\n', ""The authors propose a deep hierarchical model for unsupervised classification by using a combination of latent continuous and discrete distributions.\n\nAlthough, the detailed description of flow cytometry and chronic lymphocytic leukemia are appreciated, they are probably out of the scope of the paper or not relevant for the presented approach.\n\nThe authors claim that existing approaches for clustering cell populations in flow cytometry data are sensitive to noise and rely on cumbersome hyperparameter specifications, which in some sense is true, however, that does not mean that the proposed approach is less sensitive to noise or that that the proposed model has less free-parameters to tune (layers, hidden units, regularization, step size, link function, etc.). In fact, it is not clear how the authors would be able to define a model architecture without label information, what would be the model selection metric to optimize, ELBO?. At least this very issue is not addressed in the manuscript.\n\nIn Figure 1, please use different colors for different cell types. It is not described, but it would be good to stress out that each of the 4 components in Figure 1 right, corresponds to a mixture component.\n\nThe results in Tables 1 and 2 are not very convincing without clarity on the selection of the thresholds for each of the models. It would be better to report threshold-free metrics such as area under the ROC or PR curve. From Figures 3 and 4 for example, it is difficult to grasp the performance gap between the proposed approach and \\beta-VAE.\n\n- FC and CLL are not spelled out in the introduction.\n- Equation (5) is confusing, what is h, y = h or is h a mixture of Gaussians with \\alpha mixing proportions?\n- Equation (6) should be q(z_L|z)\n- Equation (8) is again confusing.\n- Equation (10) is not correct, x can't be conditioned on h, as it is clearly conditioned on z_1.\n- Equation (11) it should be q_\\phi().\n- It is not clear why the probabilities are thresholded at 0.5\n- Figures 3 and 4 could use larger markers and font sizes.""]","[-20, -30, -30]","[60, 50, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the impressive results on the medical imaging dataset, they express concerns about the lack of novelty and limited contribution to the ICLR community. The reviewer also requests additional evaluations on other datasets to better assess the model's value. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges their lack of expertise in the specific dataset, and frames their concerns as questions or suggestions rather than harsh criticisms. The reviewer also provides specific, constructive feedback and references to relevant literature, which is a polite and helpful approach in academic peer review."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('results seem very promising'), they express significant concerns about novelty and suggest the paper is not suitable for a main conference. The overall tone is more critical than positive. The politeness score is 50 because the reviewer uses polite language throughout ('reasonably well written', 'would perhaps recommend'), offers constructive feedback, and frames criticisms diplomatically. However, they don't go out of their way to be overly polite or complimentary, maintaining a professional tone."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects of the paper, they raise several significant concerns and criticisms. The reviewer points out issues with the model selection, unclear equations, and unconvincing results. However, they also appreciate some aspects like the detailed description of flow cytometry.\n\nThe politeness score is slightly positive (20) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'please use' and 'it would be good to' when making suggestions, which adds a polite tone. The criticisms are presented as observations or questions rather than harsh judgments. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a mostly neutral, professional tone.""]"
"[""This paper proposes a framework called 'multi-instance learning', in which a time series is treated as a 'set' of observations, and label is assigned to the full set, rather than individual observations. In this framework, authors propose to do set-level prediction (using pooling) and observation level predictions (using various attention mechanisms). \nThey test their approach in a medical setting, where the goal is to annotate vital signs time series by clinical events. Their cohort is 2014 adults time series (average length 4 time steps), and their time series has dimension of 21 and their clinical events have dimension of 26. Their baselines are other 'multi-instance learning' prior work and results are achieved through cross-validation. A few of the relevant hyper-parameters are tuned and some important hyper-parameters (i.e. number of hidden states in the LSTMs, or optimization method and learning rate) are not tuned. \n\nOriginality - I find the paper to be very incremental in terms of originality of the method. \n\nQuality and Significance - Due to small size of the cohort and lack of additional dataset, it is difficult to reliably access quality of experiments. Given that results are reported via cross-validation and without a true held-out dataset, and given that a number of hyperparameters are not even tuned, it is difficult to be confident that the differences of all the methods reported are significant. \n\nClarity - The writing has good clarity.\n\nMajor issues with the paper: \n- Lack of reliable experiment section. Dataset is too small (2000 total samples), and model training is not described with enough details in terms of hyper-parameters tuned. \n"", ""==== Post Rebuttal ====\nI went through the rebuttal, which unfortunately claimed a number statements without any experimental support as requested. The revision didn't address my concerns, and I've lowered my rating.\n\n==== Original Review ====\nThis paper proposed a novel Multiple Instance Learning (MIL) formulation called Relation MIL (RMIL), and discussed a number of its variants with LSTM, Bi-LSTM, S2S, etc. The paper also explored integrating RMIL with various attention mechanisms, and demonstrated its usage on medical concept prediction from time series data.\n\nThe biggest technical innovation in this paper is it combines recurrent networks like Bi-LSTM with MIL to model the relations among instances. Other than that, the paper has limited technical innovations: the pooling functions were proposed earlier and their integration with MIL was widely studied before (as cited by the authors); the attention mechanisms are also proposed by others.\n\nHowever, I am doubtful whether it’s appropriate to use LSTM to model the relations among instances. In general MIL, there exists no temporal order among instances, so modeling them with a LSTM is unjustified. It might be acceptable is the authors are focusing on time-series data; but in this case, it’s unclear why the authors are applying MIL on it. It seems other learning paradigm could be more appropriate.\n\nThe biggest concern I have with this paper is the unconvincing experiments. First, the baselines are very weak. Both MISVM and DPMIL are MIL methods without using deep learning features. It them becomes very unclear how much of the gain on Table 3 is from the use of deep learning, and how much is from the proposed RMIL.\n\nAlso, although the authors conducted a number of ablation studies, they don’t really tell us much. Basically, all variants of the algorithm perform as well, so it’s confusing why we need so many of them, or whether they can be integrated as a better model.\n\nThis could also be due to the small dataset. As the authors are proposing a new MIL learning paradigm, I feel they should experiment on a number of MIL tasks, not limited to analyzing time series medical data. The current experiments are quite narrow in terms of scope.\n"", 'The paper addresses the classification of medical time-series data by formulating the problem as a multi-instance learning (MIL) task, where there is an instance for each timestep of each time series, labels are observed at the time-series level (i.e. for each bag), and the goal is to perform instance-level and series-level (i.e. bag-level) prediction.  The main difference from the typical MIL setup is that there is a temporal relationship between the instances in each bag.  The authors propose to model this using a recurrent neural network architecture.  The aggregation function which maps instance-level labels to bag-level labels is modeled using a pooling layer (this is actually a nice way to describe multi-instance classification assumptions using neural network terminology).  An attention mechanism is also used.\n\nThe proposed time-series MIL problem formulation makes sense.  The RNN approach is novel to this setting, if somewhat incremental.  One very positive aspect is that results are reported exploring the impact of the choice of recurrent neural network architecture, pooling function, and attention mechanism.  Results on a second dataset are reported in the appendix, which greatly increases confidence in the generalizability of the experiments.  One or more additional datasets would have helped further solidify the results, although I appreciate that medical datasets are not always easy to obtain.  Overall, this is a reasonable paper with no obvious major flaws.  The novelty and impact may be greater on the application side than on the methodology side.\n\nMinor suggestions:\n\n-The term ""relational multi-instance learning"" seems to suggest a greater level of generality than the work actually accomplishes.  The proposed methods can only handle time-series / longitudinal dependencies, not arbitrary relational structure.  Moreover, multi-instance learning is typically viewed as an intermediary level of structure ""in between"" propositional learning (i.e. the standard supervised learning setting) and fully relational learning, so the ""relational multi-instance learning"" terminology sounds a little strange. Cf.:\nDe Raedt, L. (2008). Logical and relational learning. Springer Science & Business Media.\n\n-Pg 3, a capitalization typo: ""the Multi-instance learning framework""\n\n-The equation for the bag classifier on page 4 refers to the threshold-based MI assumption, which should be attributed to the following paper:\nWeidmann, N., Frank, E. & Pfahringer, B. 2003. A two-level learning method for generalized multi-instance problems. In Proceedings of the 14th European Conference on Machine Learning,\nSpringer, 468-479.\n(See also: J. R. Foulds and E. Frank. A review of multi-instance learning assumptions. Knowledge Engineering Review, 25(1):1-25, 2010. )\n\n- Pg 5, ""Table 1"" vs ""table 1"" - be consistent.\n\n-A comparison to other deep learning MIL methods, i.e. those that do not exploit the time-series nature of the problem, would be valuable.  I wouldn\'t be surprised if other reviewers insist on this.']","[-50, -60, 60]","[20, 20, 80]","[""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper's originality, quality, and experimental design. The reviewer finds the work 'very incremental' and expresses doubts about the reliability of the results due to the small dataset and lack of proper hyperparameter tuning. However, it's not entirely negative as the reviewer acknowledges good clarity in writing. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use neutral language like 'I find' and 'it is difficult to' rather than harsh or rude phrasing. The reviewer also balances criticism with positive comments about clarity, which contributes to a more polite overall tone."", ""The sentiment score is -60 because the reviewer expresses significant doubts and concerns about the paper. They mention 'limited technical innovations', question the appropriateness of the methodology, and describe the experiments as 'unconvincing' with 'weak' baselines. The reviewer also states they've 'lowered their rating' after the rebuttal. However, it's not entirely negative as they acknowledge some novel aspects, hence not a lower score. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I am doubtful' and 'The biggest concern I have' rather than harsh or rude language. They also acknowledge positive aspects before critiquing, which is a polite approach. However, the criticism is direct and not overly softened, preventing a higher politeness score."", ""The sentiment score is 60 (moderately positive) because the reviewer describes the paper as 'reasonable' with 'no obvious major flaws', and mentions several positive aspects such as the novel approach, exploration of different components, and inclusion of results on a second dataset. However, they also note that the novelty may be greater on the application side than methodology. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the challenges in obtaining medical datasets, and frames their suggestions as 'minor'. They also use phrases like 'I appreciate' and 'I wouldn't be surprised if', which add a personal and considerate tone to the review.""]"
"['The paper proposes a new method to compute embeddings of multirelational graphs. In particular, the paper proposes so-called E-Cells and R-Cells to answer queries of the form (h,r,?), (?,r,t), and(h,?,t). The proposed method (GEN), is evaluated on standard datasets for link prediction as well as datasets for node classification.\n\nThe paper tackles an interesting problem, as learning from graphs via embedding methods has become increasingly important. The experimental results of the proposed model, especially for the node classification tasks, look promising. Unfortunately, the paper makes a number of claims which are not justified or seem to result from misconceptions about related methods. For instance, the abstract labels prior work as ""ad hoc solutions"" and claims to propose a principled approach. However, I do not see how the proposed method is a more principled than previously proposed methods. For instance, methods such as RESCAL, TransE, HolE or ComplEx can be motivated as compositional models that reflect the compositional structure of relational data. Furthermore, RESCAL-like models can be linked to prior research in cognitive science on relational memory [3]. HolE explicitly motivates its modeling through its relation to models for associative memory. \n\nFurthermore, due to their compositional nature, these model are all able to answer the queries considered in the paper (i.e, (h,r,?), (h,?,t), (?,r,t)) and are implicitly trained to do so. The HolE paper discusses this for instance when relating the model to associative memory. For RESCAL, [4] shows how even more complicated queries involving logical connectives and quantification can be answered. It is therefore not clear how to proposed method improves over these models.\n\nWith regard to the evaluation: It is nice that the authors provided an evaluation which compares to several SOTA methods. However, it is unclear under which setting these results where obtained. In particular, how were the hyperparameter for each model chosen and which parameters ranges were considered in the grid search. Appendix B.2 in the supplementary seems to specify the parameter setting for GEN, but it is unclear whether the same parameters where chosen for the competing models and whether they were trained with similar methods (e.g., dropout, learning rate decay etc.). The big difference in performance of HolE and ComplEx is also surprising, as they are essentially the same model (e.g. see [1,2]). It is therefore not clear to me which conclusions we can draw from the reported numbers.\n\nFurther comments:\n- p.3: The statement ""This is the actual way we humans learn the meaning of concepts expressed by a statement"" requires justification\n- p.4: The authors state that the model is trained unsupervised, but eq. 10 clearly uses supervised information in form of labels.\n- p.4: In 3.1, E-cells are responsible to answer queries of the form (h,r,?) and (?, r, t), while Section 3.2 says E-Cells are used to answer (h, ?, t). I assume in the later case, the task is actually to answer (h,r,?)?\n- p.2: Making a closed-world assumption is quite problematic in this context, especially when taking a principled approach. Many graphs such as Freebase are very incomplete and make an explicit open-world assumption. \n- The paper uses a unusual definition of one-shot/multi-shot learning, which makes it confusing to read at first. The authors might consider using different terms to improve readability.\n- Paper would benefit if the model is presented earlier. GEN Cells are defined only in Section 3.2, but the model is discussed earlier. Reversing the order might improve presentation.\n\n[1] K. Hayashi et al: ""On the Equivalence of Holographic and Complex Embeddings for Link Prediction"", 2017\n[2] T.Trouillon et al: ""Complex and holographic embeddings of knowledge graphs: a comparison"", 2017\n[3] G. Halford et al: ""Processing capacity defined by relational complexity: Implications for comparative, developmental, and cognitive psychology"", 1998.\n[4] D. Krompaß et al: ""Querying factorized probabilistic triple databases"", 2014', 'This paper tackles the task of learning embeddings of multi-relational graphs using a neural network. As much of previous work, the proposed architecture works on triples (h, r, t) wth h, t entities and r the relation type. \n\n\nDespite interesting experimental results, I find that the paper carries too many imprecisions as is.\n* One of the main originality of the approach is to be able for a given input triple to train by sequentially removing in turn the head h, then the tail t and finally the relation r. (called multi-shot in the paper). However, most (if not all) approaches learning embeddings of multi-relational graphs also create multiple examples given a triple. And that, at least since ""Learning Structured Embeddings of Knowledge Bases"" by Bordes et al. 2011 that was predicting h and t (not r). The only difference is that here it is done sequentially while most methods sample one case each time. Not really meaningful or at least not proved meaningful here.\n* The sequential/RNN-like structure is unclear and it is hard to see how it relates to the data.\n* Writing that the proposed method ""unsupervised, which is distinctly different from previous works"" is not true or should be rephrased. The only difference comes from that the prediction function (softmax and not ranking for instance) and the loss used.  But none of the methods compared in the experiments use more information than GEN (the original graph). GEN is not the only model using a softmax by the way.\n* The fact of predicting indistinctly a fact or its reverse seems rather worrying to me. Predicting that ""John is_father_of Paul"" or that ""John is_child_of Paul"" is not the same..! How is assessed the fact that a prediction is conceptually correct? Using types?\n* The bottom part of Table 2 is surprising. How come for the task of predicting Head, the model trained only at predicting heads (GEN(t,r => h)) performs worse than the model trained only at predicting tails (GEN(h,r => t))? \n\n\n\n', 'The paper is well-written and provides sufficient background on the knowledge graph tasks. The current state-of-the-art models are mentioned and the approach is evaluated against them. The proposed model is rather simple so it is really surprising that the proposed model performs on par or even outperforms existing state-of-the art approaches.\n\n\n? The E_CELLs share the parameters. So, there is a forced symmetry on the relation i.e. given input head h and relation r predicting x and given input relation r and tail t predicting y would result in the same entity embedding x=y with h=t?\n\n? In Table 2, you report the results of the retrained models GEN(x). There, the weights for the MLPs are learned based on the existing embeddings which do not get changed. I am missing a comparison of the change in the prediction score. Was it always better than the original model? Did all models improve in a similar fashion?\n\n? Did you try training the other models e.g. TransE with alternating objective functions for respectively predicting the head, tail or relation based on the information from the other two? \n\n? Are the last 3 Gen(x,y -> z) rows in Table 2 simple MLPs for the three different tasks and not the parts from the overall joint learned GEN model?\n\n? Why is a binary classifier for Q4 not part of the model?\n\n? Is the code with the parameter settings online?\n\n\n+ outperforms previous approaches\n\n+ proposes a general use case framework\n\n- no run-time evaluation although it is crucial when one deals with large-scale knowledge graphs\n\n\nFurther comments:\n* p.4: “it will take the embedding of h and r as input, and take r as its target label” -> “it will take the embedding of h and t as input, and take r as its target label”\n* “ComplEX” -> “ComplEx”\n']","[-30, -60, 60]","[50, 20, 70]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('interesting problem', 'promising' results), they express significant concerns about unjustified claims, potential misconceptions, and unclear experimental settings. The overall tone is more critical than positive. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positives before critiques, and phrases concerns as observations rather than accusations (e.g., 'It is therefore not clear to me...'). However, it doesn't reach a higher score due to the directness of some criticisms. The reviewer maintains a professional tone, balancing politeness with honest feedback."", ""The sentiment score is -60 because the review is predominantly critical. The reviewer states that the paper 'carries too many imprecisions' and lists several significant concerns about the methodology and claims. While they acknowledge 'interesting experimental results', this is outweighed by the numerous criticisms. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I find that' and asking questions rather than making blunt statements. However, the criticism is direct and doesn't use many softening phrases, keeping the score only slightly positive. The reviewer also uses some neutral academic language, which contributes to the slightly positive politeness score."", 'The sentiment score is 60 (positive) because the review starts with praise for the paper being well-written and providing sufficient background. It also mentions that the proposed model performs on par or even outperforms existing state-of-the-art approaches, which is seen as a significant positive. The reviewer lists both positive and negative points, but the overall tone is more positive than negative. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, phrases criticisms as questions rather than direct statements, and provides constructive feedback. The use of bullet points for summarizing key strengths and weaknesses is professional and courteous. The reviewer also offers helpful suggestions for minor corrections, which is a polite way to point out small errors.']"
"['This paper explores the idea of using policy gradients to learn a stochastic policy on complex control problems.  The central idea is to frame learning in terms of a new kind of Q-value that attempts to smooth out Q-values by framing them in terms of expectations over Gaussian policies.\n\nTo be honest, I didn\'t really ""get"" this paper.\n* As far I understand, all of the original work policy gradients involved stochastic policies.  Many are/were Gaussian.\n* All Q-value estimators are designed to marginalize out the randomness in these stochastic policies.\n* As far as I can tell, this is equivalent to a slightly different formulation, where the agent emits a deterministic action (\\mu,\\Sigma) and the environment samples an action from that distribution.  In other words, it seems that if we just draw the box a bit differently, the environment soaks up the nondeterminism, instead of needing to define a new type of Q-value.\n\nUltimately, I couldn\'t discern /why/ this was a significant advance for RL, or even a meaningful new perspective on classic ideas.\n\nI thought the little 2-mode MOG was a nice example of the premise of the model.\n\nWhile I may or may not have understood the core technical contribution, I think the experiments can be critiqued: they didn\'t really seem to work out.  Figures 2&3 are unconvincing - the differences do not appear to be statistically significant.  Also, I was disappointed to see that the authors only compared to DDPG; they could have at least compared to TRPO, which they mention.  They dismiss it by saying that it takes 10 times as long, but gets a better answer - to which I respond, ""Very well, run your algorithm 10x longer and see where you end up!""  I think we need to see a more compelling demonstration of why this is a useful idea before it\'s ready to be published.\n\nThe idea of penalizing a policy based on KL-divergence from a reference policy was explored at length by Bert Kappen\'s work on KL-MDPs.  Perhaps you should cite that?\n', 'I think I should understand the gist of the paper, which is very interesting, where the action of \\tilde Q(s,a) is drawn from a distribution. The author also explains in detail the relation with PGQ/Soft Q learning, and the recent paper ""expected policy gradient"" by Ciosek & Whiteson. All these seems very sound and interesting.\n\nWeakness:\n1. The major weakness is that throughout the paper, I do not see an algorithm formulation of the Smoothie algorithm, which is the major algorithmic contribution of the paper (I think the major contribution of the paper is on the algorithmic side instead of theoretical). Such representation style is highly discouraging and brings about un-necessary readability difficulties. \n\n2. Sec. 3.3 and 3.4 is a little bit abbreviated from the major focus of the paper, and I guess they are not very important and novel (just educational guess, because I can only guess what the whole algorithm Smoothie is). So I suggest moving them to the Appendix and make the major focus more narrowed down.', 'The paper introduces smoothed Q-values, defined as the value of drawing an action from a Gaussian distribution and following a given policy thereafter.  It demonstrates that this formulation can still be optimized with policy gradients, and in fact is able to dampen instability in this optimization using the KL-divergence from a previous policy, unlike preceding techniques.  Experiments are performed on an simple domain which nicely demonstrates its properties, as well as on continuous control problems, where the technique outperforms or is competitive with DDPG.\n\nThe paper is very clearly written and easy to read, and its contributions are easy to extract.  The appendix is quite necessary for the understanding of this paper, as all proofs do not fit in the main paper.  The inclusion of proof summaries in the main text would strengthen this aspect of the paper.\n\nOn the negative side, the paper fails to make a strong case for significant impact of this work; the solution to this, of course, is not overselling benefits, but instead having more to say about the approach or finding how to produce much better experimental results than the comparative techniques.  In other words, the slightly more stable optimization and slightly smaller hyperparameter search for this approach is unlikely to result in a large impact.\n\nOverall, however, I found the paper interesting, readable, and the technique worth thinking about, so I recommend its acceptance.']","[-60, 50, 60]","[20, 60, 80]","[""The sentiment score is -60 because the reviewer expresses significant skepticism and criticism towards the paper. They state they 'didn't really get' the paper, question its novelty and significance, and find the experiments unconvincing. The negative sentiment is clear, but not extremely harsh, hence the score of -60 rather than lower. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone and use phrases like 'To be honest' and 'I thought the little 2-mode MOG was a nice example'. They also offer constructive suggestions for improvement. The language is not overtly polite, but it avoids rudeness, resulting in a slightly positive politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by expressing interest in the paper's main idea and acknowledging its soundness. They use phrases like 'very interesting' and 'very sound,' indicating a positive view. However, they also point out significant weaknesses, which balances out the overall sentiment. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, even when pointing out weaknesses. They use phrases like 'I think' and 'I suggest,' which soften their criticisms. The reviewer also acknowledges the interesting aspects of the paper before discussing its weaknesses, which is a polite approach. However, they don't use overtly formal or excessively polite language, keeping the tone professional but not overly deferential."", ""The sentiment score is 60 (positive) because the reviewer recommends acceptance, finds the paper interesting and readable, and praises its clarity. However, they also mention some negative aspects, such as the lack of a strong case for significant impact, which prevents a higher score. The politeness score is 80 (quite polite) due to the reviewer's constructive and respectful tone throughout. They balance positive feedback with areas for improvement, using phrases like 'very clearly written' and 'interesting, readable' while also providing suggestions for enhancement without harsh criticism.""]"
"['The paper extends SGNS as follows. In SGNS, each word x is associated with vectors a_x and r_x. Given a set of context words C, the model calculates the probability that the target word is x by a dot product between a_x and the average of {r_c: c in C}.  The paper generalizes this computation to an arbitrary network: now each word x is associated with some network N_x whose input is a set of context words C and the output is the aforementioned probability. This is essentially an architectural change: from a bag-of-words model to a (3-layer) feedforward model. \n\nAnother contribution of the paper is a new form of regularization by tying a subset of layers between different N_x. In particular, the paper considers incorporating POS tags by tying within each POS group. For instance, the parameters of the first layer are shared across all noun words. (This assumes that POS tags are given.)\n\nWhile this is a natural extension to word2vec, the reviewer has some reservations about the execution of this work. Word embeddings are useful in large part because they can be used to initialize the parameters of a network. None of the chosen experiments shows this. Improvement in the log likelihood over SGNS is somewhat obvious because there are more parameters. The similarity between ""words"" now requires a selection of context vectors (7) which is awkward/arbitrary. The use of POS tags is not very compelling (though harmless). It\'s not necessary: contrary to the claim in the paper, word embeddings captures syntactic information if the context width is small and/or context information is provided. A more sensible experiment would be to actually plug in the entire pretrained word nets into an external model and see how much they help. \n\nEDIT: It\'s usually the case that even if the number of parameters is the same, extra nonlinearity results in better data fitting (e.g., Berg-Kirkpatrick et al, 2010), it\'s still not unexpected. \n\nAll of this is closely addressed in the following prior work: \n\nLearning to Embed Words in Context for Syntactic Tasks (Tu et al., 2017)\n\nQuality: Natural but questionable extension, see above. \n\nClarity: Clear. \n\nOriginality: Acceptable, but a very similar idea of embedding contexts is presented in Tu et al. (2017) which is not cited. \n\nSignificance: Minor/moderate, see above. \n\n', 'The paper presents a method to use non-linear combination of context vectors for learning vector representation of words. The main idea is to replace each word embedding by a neural network, which scores how likely is the current word given the context words. This also allowed them to use other context information (like POS tags) for word vector learning. I like the approach, although not being an expert in the area, cannot comment on whether there are existing approaches for similar objectives.\n\nI think the experimental section is weak. Most work on word vectors are evaluated on several word similarity and analogy tasks (See the Glove paper).  However, this paper only reports numbers on the task of predicting next word.\n\nResponse to rebuttal:\n\nI am still not confident about the evaluation. I feel word vectors should definitely be tested on similarity tasks (if not analogy). As a result, I am keeping my score the same. ', ""This paper presents another variant on neural language models used to learn word embeddings. In keeping with the formulation of Mikolov et al, the model learned is a set of independent binary classifiers, one per word. As opposed to other work, each classifier is not based on the dot product between an embedding vector and a context vector but instead is a per-word neural network which takes the context as input and produces a score for each term. An interesting consequence of using networks instead of vectors to parametrize the embeddings is that it's easy to see many ways to let the model use side information such as part-of-speech tags. The paper explores one such way, by sharing parameters across networks of all words which have the same POS tag (effectively having different parameterizations for words which occur with multiple POS tags).\n\nThe idea is interesting but the evaluation leaves doubts. Here are my main problems:\n 1. The quantitative likelihood-based evaluation can easily be gamed by making all classifiers output numbers which are close to 1. This is because the model is not normalized, and no attempt at normalization is claimed to be made during the likelihood evaluation. This means it's likely hyperparameter tuning (of, say, how many negative examples to use per positive example) is likely to bias this evaluation to look more positive than it should.\n 2. The qualitative similarity-based evaluation notes, correctly, that the standard metric of dot product / cosine between word embeddings does not work in the case of networks, and instead measures similarity by looking at the similarity of the predictions of the networks. Then all networks are ranked by similarity to a query network to make the now-standard similar word lists. While this approach is interesting, the baseline models were evaluated using the plain dot product. It's unclear whether this new evaluation methodology would have also produced nicer word lists for the baseline methods.\n\nIn the light that the evaluation has these two issues I do not recommend accepting this paper.""]","[-40, -20, -60]","[20, 50, 20]","[""The sentiment score is -40 because while the reviewer acknowledges the paper as a 'natural extension' with some positive aspects (clear presentation, acceptable originality), they express significant reservations about the execution and significance of the work. They point out several limitations and suggest that the improvements shown are somewhat obvious or expected. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'the reviewer has some reservations' rather than direct criticism. They also acknowledge positive aspects before presenting critiques. However, the overall tone is more critical than overtly polite, hence the relatively low positive score."", ""The sentiment score is slightly negative (-20) because while the reviewer initially expresses liking the approach, they criticize the experimental section as 'weak' and maintain their low score even after a rebuttal. The overall tone suggests more criticism than praise. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, such as 'I like the approach' and 'I think,' avoiding harsh or rude phrasing even when expressing criticism. They also acknowledge their own potential limitations ('not being an expert in the area'). The reviewer maintains a professional and respectful tone while providing constructive feedback."", ""The sentiment score is -60 because the reviewer expresses significant doubts about the paper's evaluation methods and ultimately does not recommend accepting it. While they acknowledge the idea is interesting, the critical issues raised outweigh the positive aspects. The politeness score is 20 because the reviewer uses professional and respectful language throughout, acknowledging positive aspects before presenting criticisms. They avoid harsh or personal comments, instead focusing on specific methodological concerns. The slightly positive politeness score reflects the reviewer's effort to provide constructive feedback while maintaining a professional tone, even when recommending rejection.""]"
"['The paper is well written, well-motivated and the idea is very interesting for the computer vision and robotic communities. The technical contribution is original. The vision-based agent localization approach is novel compared to the methods of the literature. However, the experimental validation of the proposed approach could be more convincing (e.g. by testing on real data, with different training and testing splitting configurations).  \n\nMajor concern: \n1) The authors depict in section 2 “there is no existing end-to-end neural network for visual SLAM to our best knowledge” but they should discuss the positioning with respect to the paper of M Garon and JF Lalonde, “Deep 6-DOF Tracking”, ISMAR 2017 which propose a fully neural network based camera tracking method.\n\nMinor concerns:\n2) Table 3: the comparison is not rigorous in the sense that the proposed method estimates a 2D pose (3-DOF) while ORB-SLAM and EKF-SLAM are methods designed for 3D pose estimation (6-DOF). Is it possible to generalize your method to this case (6-DOF) for a more consistent comparison? At least, the fact that your method is more restrictive should be discussed in the paper. \n\n3) In the same vein than point 2), ORB-SLAM and EKF-SLAM are methods based on regression while the proposed method is restricted to the classification pose estimation. Is it possible to test your method with a regression task? \n\n4) It would be interesting to test the proposed method on real data to measure its robustness in terms of noise sensor and in terms of motion blur.\n\n5) It would also be interesting to test the proposed method on datasets usually used in the SLAM community (e.g. using the sequences of the odometry benchmark of KITTI dataset).\n\n6) In the SLAM context, the running time aspect on the test phase is crucial. Hence, the authors should compare the running time of their method with algorithms of literature (e.g. ORB-SLAM). \n\n', 'Significance of Contributions Unclear\n\n\nThe paper describes a neural network architecture for monocular SLAM that is argued to take inspiration from neuroscience. The architecture is comprised of four components: one that estimates egomotion (HDU) much like prediction in a filtering framework; one that fuses the current image into a local 2D metric map (BVU); one that detects loop closures (PCU); and one that integrates local maps (GU). These modules along with their associated representations are learned in an end-to-end fashion. The method is trained and evaluated on simulated grid environments and compared to two visual SLAM algorithms. \n\nThe contributions and significance of the paper are unclear. SLAM is arguably a solved problem at the scales considered here, with existing solutions capable of performing localization and mapping in large (city-scale), real-world environments. That aside, one can appreciate the merits of representation learning in the context of SLAM and a handful of neural network-based approaches to SLAM and the related problem of navigation have been proposed of-late. However, the paper doesn\'t do a sufficient job making the advantages of the proposed approach over these methods clear. Further, the paper emphasizes parallels to neuroscience models for navigation as being a contribution, however these similarities are largely hand wavy and one could argue that they also exist for the many other SLAM algorithms that perform prediction (as in HDU), local/global mapping (as in BVU and GU) and loop closure detection (as in PCU). More fundamentally, the proposed method does not appear to account for motion or measurement noise that are inherent in any SLAM problem and, related, does not attempt to model the uncertainty in the resulting map or pose estimates.\n\nThe paper evaluates the individual components of the architecture. The results suggest that the different modules are doing something reasonable, though the evaluation is rather limited (in terms of spatial scale) and a bit arbitrary (e.g., comparing local maps to the ground truth at a seemingly arbitrary 32s). The evaluation of the loop closure is limited to a qualitative measure and is therefore not convincing. The authors should quantitatively evaluate the performance of loop closure in terms of precision and recall (this is particularly important given effects of erroneous loop closure detections and the claims that the proposed method is robust). Meanwhile, it isn\'t clear that much can be concluded from the ablation studies as there is relatively little difference in MSE between the two ablated models.\n\n\nAdditional comments/questions:\n\n\n* A stated advantage of this method over that of Gupta et al. is that the agent\'s motion is not assumed to be known. However, it isn\'t clear whether and how the model incorporates motion or measurement uncertainty, which is fundamental to any SLAM (or navigation) framework.\n\n* Related, an important aspect of any SLAM algorithm is an explicit estimate of the uncertainty in the agent\'s pose and the map, however it doesn\'t seem that the proposed model attempts to express this uncertainty.\n\n* The paper claims to estimate the agent\'s pose as it navigates, but it is not apparent how the pose is maintained beyond estimating egomotion by comparing the current image to a local map.\n\n* Related, it is not clear how the method balances egomotion estimates and exteroceptive measurements (e.g, as are fused with traditional filtering frameworks). There are vague references to ""eliminating discrepancies"" when merging measurements, but it isn\'t clear what this actually means, whether the output is consistent, or how the advantages of egomotion estimation and measurements are balanced.\n\n* The BVU module is stated as generating a ""local"" map, but it is not clear from the discussion what limits the resulting map to the area in the vicinity of the robot vs. the entire environment.\n\n* It is not clear why previous data is transformed to the agent\'s reference frame as a result of motion vs. the more traditional approach of transforming the agent\'s pose to a global reference frame.\n\n* The description of loop closure detection and the associated heuristics is confusing. For example, Section 3.4 states that the agent only considers positions that are distant from the most recent visited position as a means of avoiding trival loop closures, however Section 3.4 states that GU provides memory vectors near the current location for loop closure classification.\n\n* The description of the GU module is confusing. How does spatial indexing deal with changes to the map (e.g., as a result of loop closures/measurement updates) or transformations to the robot\'s frame-of-reference? What are h, H, w, and W and how are they chosen?\n\n* The architecture assumes a discrete (and course) action space, whereas actions are typically continuous. Have the authors tried regressing to continuous actions or experimenting with finer discretizations that are more suitable to real applications?\n\n* It is not clear what is meant by the statement that the PU ""learns to encode the representation of visited places"".\n\n* The means by which the architecture is trained is unclear. What is the loss that is optimized? How is the triplet loss (Eqn. 3) incorporated (e.g., is it weighted differently than other terms in the loss)?\n\n* Section 3.2 states that the ""agent has to learn to take actions to explore its surroundings"", however it isn\'t apparent that the method reasons over the agent\'s policy. Indeed, this is an open area of research. Instead, the results section suggests that the agent acts randomly.\n\n* Section 4.1 draws comparisons between HDU and Head Direction Cells, however the latter estimate location/orientation whereas the former (this method) predicts egomotion. While egomotion can be integrated to estimate pose (as is done in Fig 4), these are not the same thing.\n\n* The authors are encouraged to tone down claims regarding parallels to navigation models from neuroscience as they are largely unjustified.\n\n* The comparison to existing monocular SLAM baselines is surprising and the reviewer remains skeptical regarding the stated advantages of the proposed method. How much of this difference is a result of testing in simulation? It would be more convincing to compare performance in real-world environments, for which these baselines have proven effective.\n\n* Figure 1: ""Border"" --> ""Boundary""\n\n* Figure 1: The camera image should also go to the BVU block\n\n* Many of the citations are incorrectly not parenthesized\n\n* The paper should be proof-read for grammatical errors', 'The paper proposes a biologically inspired model of mammalian navigation which includes head direction cells, boundary vector cells, place cells, and grid cells. The proposed model includes modules for all of these kinds of cells and includes: an Neural Touring Machine, Spatial Transformer Network, Recurrent Neural Networks, and CNNs. The model is trained with supervision to output the overhead map of the global map. All components are trained with dense supervision (e.g. loop closure, ego motion with orientation-position, and the ground truth local overhead map). The model is trained on 5 mazes and tested on 2 others.\n\nI believe that this paper is severely flawed. Firstly, the model has ample free parameters to overfit when such a tiny test set is used. Are the test environments sufficiently different from the training ones? For example, when showing that the head direction cells generalize in the new mazes how can we be sure that it is not using a common lighting scheme common to both train and test mazes to orient itself? Also , because MSE is not scale free error measure it is hard to tell how significant the errors are. What is the maximal possible MSE error in these environments? \n\nTo quote the authors ""However, there is no existing end-to-end neural network for\nvisual SLAM to our best knowledge."" For example ""RatSLAM: a hippocampal model for simultaneous localization and mapping"" by Milford at al. was a successful biologically inspired SLAM algorithm (able to map neighborhoods using a car mounted monocular camera) first published in 2004--with many orders of magnitude fewer free parameters. ']","[50, -60, -80]","[75, 20, -20]","[""The sentiment score is 50 (slightly positive) because the reviewer starts with positive comments about the paper being well-written, well-motivated, and interesting, with an original technical contribution. However, they also express concerns about the experimental validation and list several major and minor concerns, which balances out the initial positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting concerns. They phrase their criticisms as suggestions or questions (e.g., 'Is it possible to...', 'It would be interesting to...') rather than direct criticisms. The reviewer also provides specific, constructive feedback, which is a polite way to help improve the paper."", ""The sentiment score is -60 because the review is largely critical, pointing out numerous issues with the paper's contributions, methodology, and claims. The reviewer states that the 'contributions and significance of the paper are unclear' and raises many concerns about the approach. However, it's not entirely negative as the reviewer acknowledges some merits of the work. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and offer constructive feedback. They use phrases like 'The authors are encouraged to...' and 'It would be more convincing to...', which maintain a respectful tone. The reviewer also provides detailed suggestions for improvement, which is a polite way to offer criticism."", ""The sentiment score is -80 because the reviewer states that the paper is 'severely flawed' and provides multiple criticisms without any positive comments. The reviewer questions the validity of the test set, the potential for overfitting, and the significance of the errors. They also point out that the authors' claim about no existing end-to-end neural network for visual SLAM is incorrect, citing a previous successful model. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical without any attempt to soften the criticism or provide constructive feedback. The use of phrases like 'severely flawed' and the questioning tone throughout the review contribute to a somewhat impolite tone, though it doesn't descend into personal attacks or extremely harsh language.""]"
"['The paper proposes an approach that offers speedup on common convolutional neural networks. It presents the approach well and shows results comparing with other popular frameworks used in the field.\n\nOriginality\n- The automation of parallelism across the different dimensions in each of the layers appears somewhat new. Although parallelism across each of the individual dimensions has been explored (batch parallel is most common and best supported, height and width is discussed at least in the DistBelief paper), automatically exploring this to find the most efficient approach is new. The splitting across channels seems not to have been covered in a paper before.\n\nSignificance\n- Paper shows a significant speedup over existing approaches on a single machine (16 GPUs). It is unclear how well this would translate across machines or to more devices, and also on newer devices - the experiments were all done on 16 K80s (3 generations old GPUs). While the approach is interesting, its impact also depends on the speedup on the common hardware used today.\n\nPros:\n- Providing better parallelism opportunities for convolutional neural networks\n- Simple approach to finding optimal global configurations that seems to work well\n- Positive results with significant speedups across 3 different networks\n\nCons:\n- Unclear if speedups hold on newer devices\n- Useful to see how this scales across more than 1 machine\n- Claim on overlapping computation with data transfer seems incorrect. I am pretty sure TensorFlow and possibly PyTorch supports this.\n\nQuestions:\n- How long does finding the optimal global configuration take for each model?\n', 'This paper develops a framework for parallelization of convolutional neural nets. In the framework, parallelism on different dimensions are explored for convolutional layers to accelerate the computation. An algorithm is developed to find the best global configuration.\n\nThe presentation needs to be more organized, it is not very easy to follow.\n\n1. Computation throughput is not defined.\n\n2. Although the author mentions DeePa with Tensorflow or Pytorch several times, I think it is not proper to make this comparison. The main idea of this paper is to optimize the parallelization scheme of CNN, which is independent of the framework used. It is more useful if the configuration searching can be developed on tensorflow / pytorch.\n\n3. The per layer comparison is not very informative for practice because the data transfer costs of convolution layers could be completely hidden in data parallelization. In data parallelism, the GPU devices are often fully occupied during the forward pass and backward pass. Gaps are only in between forward and backward, and between iterations. Model parallelism would add gaps everywhere in each layer. This could be more detrimental when the communication is over ethernet. To be more convincing, it is better to show the profile graph of each run to show which gaps are eliminated, rather than just numbers.\n\n4. The batch size is also a crucial factor, difference batch size would favor different methods. More comparisons are necessary.', 'The paper proposes a deep learning framework called DeePa that supports multiple dimensions of parallelism in computation to accelerate training of convolutional neural networks.  Whereas the majority of work on parallel or distributed deep learning partitions training over bootstrap samples of training data (called image parallelism in the paper), DeePa is able to additionally partition the operations over image height, width and channel.  This gives more options to parallelize different parts of the neural network.  For example, the best DeePa configurations studied in the paper for AlexNet, VGG-16, and Inception-v3 typically use image parallelism for the initial layers, reduce GPU utilization for the deeper layers to reduce data transfer overhead, and use model parallelism on a smaller number of GPUs for fully connected layers.  The net is that DeePa allows such configurations to be created that provide an increase in training throughput and lower data transfer in practice for training these networks.  These configurations for parellism are not easily programmed in other frameworks like TensorFlow and PyTorch.\n\nThe paper can potentially be improved in a few ways.  One is to explore more demanding training workloads that require larger-scale distribution and parallelism.  The ImageNet 22-K would be a good example and would really highlight the benefits of the DeePa in practice.  Beyond that, more complex workloads like 3D CNNs for video modeling would also provide a strong motivation for having multiple dimensions of the data for partitioning operations.']","[60, -20, 70]","[70, 50, 60]","[""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's contributions, noting its originality, significance, and positive results. The reviewer mentions 'significant speedup' and 'interesting' approach, indicating a generally positive view. However, it's not extremely high due to some concerns raised about applicability to newer devices and scaling across machines. The politeness score is 70 (polite) because the reviewer uses neutral, professional language throughout. They balance positive aspects ('Pros') with areas for improvement ('Cons') in a constructive manner. The use of phrases like 'appears somewhat new' and 'useful to see' when suggesting improvements indicates a polite, considerate tone. The reviewer also asks a question at the end, showing engagement with the work rather than dismissing it."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution in developing a framework for parallelization of CNNs, they express several concerns and suggest multiple improvements. The opening paragraph is neutral, but the subsequent points highlight issues with presentation, comparisons, and the need for more comprehensive analysis. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'it is better to show' and 'More comparisons are necessary' rather than harsh criticisms. They also begin with a neutral summary of the paper's content before moving into the critique, which is a polite approach. The language is constructive rather than dismissive, suggesting improvements rather than outright rejecting the work."", ""The sentiment score is 70 (positive) because the reviewer begins by summarizing the paper's contributions in a positive light, highlighting the novel aspects and benefits of the DeePa framework. The reviewer acknowledges the framework's advantages over existing methods and its practical improvements in training throughput and data transfer. The politeness score is 60 (polite) as the reviewer uses respectful and constructive language throughout. They offer suggestions for improvement in a gentle manner, using phrases like 'can potentially be improved' and 'would be a good example,' which maintain a collaborative tone. The reviewer also balances positive feedback with areas for potential enhancement, demonstrating a fair and considerate approach to the review process.""]"
"['\nThis paper introduces a different form of Memory cell for RNN which has more capabilities of long-term memorizing. Furthermore, it presents and efficient architecture for sequence-to-sequence mapping.\n\nWhile the claim of the paper sounds very ambitious and good, the paper has several flaws. First of all, the mathematical analysis is a bit problematic. Of course, it is known that Simple Recurrent Networks (SRN) have a vanishing gradient problem. However, the way you proof it is not correct, as you ignore the application of f() for calculating the output (which is routed to the input) and you use an upper bound to show a general behaviour.\nThe analysis of the Memory capabilities of LSTM is a bit simplified, however, it is okay. Note, that various experiments by Schmidhuber\'s group, as well as Otte & al have shown that LSTM can generalize and memorize to sequences of more than a million time steps, if the learning rates is small enough.\n\nThe extended memory which the authors call SLSTM-I has similar memory capabilities as LSTM. The other one (SLSTM-II) looses the capability of forgetting as it seems. An analysis would be crucial in this paper to show the benefits mathematically. \n\nThe authors should have a look at ""Evolving memory cell structures for sequence learning"" by Justin Bayer, Daan Wierstra, Julian Togelius and J¨urgen Schmidhuber, published in 2009. Note that the SLSTM belongs to the family of networks which could be generated by that paper as well.\n\nAlso ""Neural Architecture Search with Reinforcement Learning"" by Barret Zoph and Quoc V. Le would be interesting.\n\nIn your experiments it would be fair to compare to Cheng et al. 2016\n\nI suggest the authors being more modest with the name of the memory cell as well as with the abstract (especially in the POS experiment, SLSTM is not superior)', 'The paper proposes a new recurrent cell and a new way to make predictions for sequence tagging. It starts with a theoretical analysis of memory capabilities in different RNN cells and goes on with experiments on POS tagging and dependency parsing. There are serious presentation issues in the paper, which make it hard to understand the ideas and claims.\n\nFirst, I was not able to understand the message of the theoretical analysis from Section 2 and could not see how it is different from similar derivations (i.e. using a linearized version of an RNN and eigenvalue decomposition) that can be found in many other papers, including (Bengio et al, 1994) and (Pascanu et al, 2013). Novelty aside, the analysis has presentation issues. SRN is introduced without a nonlinearity from the beginning, although normally it should have one. From the classical upper bound with a power of the largest singular value the paper concludes that “Clearly, the memory will explode if \\lambda_{max} > 1”, which is not true: the memory *may* explode, having an exponentially growing upper bound does not mean that it *will* explode. The notation chosen from LSTM is  different from the standard in deep learning community and was very hard to understand (Y_t is used instead of h_t, and h_t is used instead of c_t). This notation also does not seem consistent with the rest of the paper, for example Equations 28 and 29 suggest that Y_t are discrete outputs and not vectors. \n\nThe novel cell SLSTM-I is meant to be different from LSTM by addition of “input weight vector c_i”, but is not explained where c_i come from. Are they trainable vectors, one for each time step? If yes, then how could such a cell be applied to sequence which are longer than the training ones?\n\nEquations 28, 29, 30 describe a very unusual kind of a Bidirectional Recurrent Network. To the best of my knowledge it is much more common to make one prediction based on future and past information, whereas the paper describes an approach in which first predictions are made separately based on the past and on the future. It is also very common to use several BiRNN layers, whereas the paper only uses one. As for the proposed DBRNN method, unfortunately, I was not able to understand it.\n\nI also have concerns regarding the experiments. Why is seq2seq without attention is used? On such small datasets attention is likely to make a big difference. What’s the point of reporting results of an LSTM without output nonlinearity (Table 5)?\n\nTo sum up, the paper needs a lot work on many fronts, but most importantly, presentation should be improved.\n', ""This submission first proposes a new variant of LSTM by introducing a set of independent weights for each time step, to learn longer dependency from the input. Then the submission propose a dependent bidirectional structure by using the output as input to the RNN cell to introduce the dependency of the outputs.\n\nWhile LSTM do have problem to learn very long term dependency, the model proposed in this paper is very inefficient, the number of parameters are depend on the the length of sequences. Also, there is no analysis about why adding these additional weights could help the model learn better long-term dependency. In the other word, why this approach is better than attention/ self-attention? How to handle very long sequence and also, how to deal with different length? Just ignore the additional weights?\n\nIn the second part, the author argued a standard seq2seq model is vulnerable to previous erroneous predictions. But I don't understand why the DBRNN can handle it. It essentially just a multitask learning function: L = L_f + L_b + L_fb where error signal backprop to different layer directly which is not new.\n\nThe experimental results are weak. It compare with Seq2Seq model without attention. The other baseline for POS tag is from 1997. ""]","[-50, -60, -60]","[20, 20, 0]","[""The sentiment score is -50 because while the reviewer acknowledges the paper's ambitious claims and introduces some positive aspects, they also point out several flaws and issues with the paper. The review is more critical than positive overall, suggesting significant improvements are needed. The politeness score is 20 because the reviewer uses generally polite language and offers constructive criticism. They suggest improvements and additional references rather than harshly criticizing. However, some phrases like 'the paper has several flaws' and 'I suggest the authors being more modest' slightly reduce the politeness score, as they are direct criticisms, albeit professionally stated."", ""The sentiment score is -60 because the review is predominantly negative, pointing out 'serious presentation issues' and stating the paper 'needs a lot work on many fronts'. The reviewer expresses difficulty understanding key concepts and has concerns about the experiments. However, it's not entirely negative as it acknowledges some novel ideas, hence not scoring lower. The politeness score is 20 because while the reviewer is direct in their criticisms, they use professional language and offer constructive feedback. Phrases like 'I was not able to understand' and 'unfortunately, I was not able to understand it' show a polite way of expressing confusion rather than blaming the authors. The reviewer also provides specific suggestions for improvement, which is courteous in academic contexts."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several significant issues with the proposed model, such as inefficiency, lack of analysis, and weak experimental results. They question the model's effectiveness and novelty. However, it's not entirely negative as they acknowledge the problem the authors are trying to address.\n\nThe politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout. They don't use overtly polite language, but they also don't use rude or disrespectful language. The criticism is direct but not personal or insulting. The reviewer uses phrases like 'I don't understand' and asks questions, which maintains a neutral, academic tone.""]"
"['This paper presents an interesting extension to Snell et al.\'s prototypical networks, by introducing uncertainty through a parameterised estimation of covariance along side the image embeddings (means). Uncertainty may be particularly important in the few-shot learning case this paper examines, when it is helpful to extract more information from limited number of input samples.\n\nHowever, several important concepts in the paper are not well explained or motivated. For example, it is a bit misleading to use the word ""covariance"" throughout the paper, when the best model only employs a scalar estimate of the variance. A related, and potentially technical problem is in computing the prototype\'s mean and variance (section 3.3). Eq. 5 and 6 are not well motivated, and the claim of ""optimal"" under eq.6 is not explained. More importantly, eq. 5 and 6 do not use any covariance information (off-diagonal elements of S) --- as a result, the model is likely to ignore the covariance structure even when using full covariance estimate. The distance function (eq. 4) is d Mahalanobis distance, instead of ""linear Euclidean distance"". While the paper emphasises the importance of the form of loss function, the loss function used in the model is given without explanation (and using cross-entropy over distances looks hacky).\n\nIn addition, the experiments are too limited to support the claimed benefits from encoding uncertainty. Since the accuracies on omniglot data from recent models are already close to perfect, it is unclear whether the marginally improved number reported here is significant. In addition, more analysis may better support existing claims. For example, showing subsampled images indeed had higher uncertainty, rather than only the histogram for all data points.\n\nPros:\n-Interesting problem and interesting direction.\n-Considers a number of possible alternative models\n-Intuitive illustration in Fig. 1\n\nCons:\n-Misleading use of ""covariance""\n-The several important concepts including prototype mean/variance, distance, and loss are not well motivated or explained\n-Evaluation is too limited', 'The paper extends the prototypical networks of Snell et al, NIPS 2017 for one shot learning. Snell et al use a soft kNN classification rule, typically used in standard metric learning work (e.g. NCA, MCML), over learned instance projections, i.e. distances are computed over the learned projections. Each class is represented by a class prototype which is given by the average of the projections of the class instances. Classification is done with soft k-NN on the class prototypes. The distance that is used is the Euclidean distance over the learned representations, i.e. (z-c)^T(z-c), where z is the projection of the x instance to be classified and c is a class prototype, computed as the average of the projections of the support instances of a given class.\n\nThe present paper extends the above work to include the learning of a Mahalanobis matrix, S, for each instance, in addition to learning its projection. Thus now the classification is based on the Mahalanobis distance: (z-c)^T S_c (z-c). On a conceptual level since S_c should be a PSD matrix it can be written as the square of some matrix, i.e. S_c = A_c^TA_c, then the Mahanalobis distance becomes (A_c z - A_c c)^T ( A_c z-A_c c), i.e. in addition to learning a projection as it is done in Snell et al, the authors now learn also a linear transformation matrix which is a function of the support points (i.e. the ones which give rise to the class prototypes). The interesting part here is that the linear projection is a function of the support points. I wonder though if such a transformation could not be learned by the vanilla prototypical networks simply by learning now a projection matrix A_z as a function of the query point z. I am not sure I see any reason why the vanilla prototypical networks cannot learn to project x directly to A_z z and why one would need to do this indirectly through the use of the Mahalanobis distance as proposed in this paper.\n\nOn a more technical level the properties of the learned Mahalanobis matrix, i.e. the fact that it should be PSD, are not really discussed neither how this can be enforced especially in the case where S is a full matrix (even though the authors state that this method was not further explored). If S is diagonal then the S generation methods a) b) c) in the end of section 3.1 will make sure that S is PSD, I do not think that this is the case with d) though.\n\nIn the definition of the prototypes the component wise weigthing (eq. 5) works when the Mahalanobis matrix is diagonal (even though the weighting should be done by the \\sqrt of it), how would it work if it was a full matrix is not clear.\n\nOn the experiments side the authors could have also experimented with miniImageNet and not only omniglot as is the standard practice in one shot learning papers. \n\nI am not sure I understand figure 3 in which the authors try to see what happens if instead of learning the Mahalanobis matrix one would learn a projection that would have as many additional dimensions as free elements in the Mahalanobis matrix. I would expect to see a comparison of the vanilla prototypical nets against their method for each one of the different scenarios of the free parameters of the S matrix, something like a ratio of accuracies of the two methods in order to establish whether learning the Mahalanobis matrix brings an improvement over the prototypical nets with an equal number of output parameters.  \n\n', 'SUMMARY: This work is about prototype networks for image classification. The idea is to jointly embed an image and a ""confidence measure"" into a latent space, and to use these embeddings to define prototypes together with confidence estimates. A Gaussian model is used for representing these confidences as covariance matrices. Within a class, the inverse covariance matrices of all corresponding images are averaged to for the inverse class-specific matrix S-C, and this S_C defines the tensor in the Mahalanobis metric for measuring the distances to the prototype.  \n\nEVALUATION:\nCLARITY: I found the paper difficult to read. In principle, the idea seems to be clear, but then the description and motivation of the model remains very vague. For instance, what is the the precise meaning of an image-specific covariance matrix (supported by just one point)? What is the motivation to just average the inverse covariance matrices to compute S_C? Why isn\'t the covariance matrix estimated in the usual way as the empirical covariance in the embedding space? \nNOVELTY: Honestly, I had difficulties to see which parts of this work could be sufficiently novel. The idea of using a Gaussian model and its associated Mahalanobis metric is certainly interesting, but also a time-honored concept. The experiments focus very specifically on the omniglot dataset, and it is not entirely clear to me what  should be concluded from the results presented. Are you sure that there is any significant improvement over the models in (Snell et al, Mishra et al, Munkhandalai & Yu, Finn et al.)?   \n\n\n']","[-30, -20, -50]","[50, 50, 0]","[""The sentiment score is -30 because while the reviewer acknowledges the paper as 'interesting' and having some positive aspects (listed under 'Pros'), the overall tone is critical. The reviewer points out several significant issues with the paper's explanations, motivations, and experimental support. The 'Cons' section outlines major concerns that outweigh the positives. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging positive aspects and framing criticisms as areas for improvement rather than harsh condemnations. The reviewer uses phrases like 'interesting extension' and 'interesting direction' which maintain a collegial tone. However, the score is not higher due to the directness of some criticisms, though these are presented factually rather than rudely."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's extension of previous work, they express several concerns and uncertainties about the approach. They question whether the proposed method offers significant advantages over existing techniques and point out some technical issues that are not adequately addressed. The reviewer also suggests additional experiments that could have been conducted.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I wonder though' and 'I am not sure I understand' to express doubts or request clarification, rather than making blunt criticisms. The reviewer also acknowledges the 'interesting part' of the work and provides constructive suggestions for improvement, which contributes to the overall polite tone."", ""The sentiment score is -50 because the reviewer expresses significant concerns and difficulties with the paper. They found it 'difficult to read', questioned the novelty, and had trouble seeing improvements over existing models. However, they do acknowledge some interesting aspects, preventing a more negative score. The politeness score is 0 (neutral) because the reviewer maintains a professional tone without being overly polite or rude. They express their criticisms directly but without harsh language, using phrases like 'I found' and 'Honestly, I had difficulties' to soften their critiques slightly.""]"
"['The authors study the convergence of a procedure for learning\nan autoencoder with a ReLu non-linearity.  The procedure is akin\nto stochastic gradient descent, with some parameters updated at\neach iteration in a manner that performs optimization with respect\nto the population risk.\n\nThe autoencoders that they study tie the weights of the decoder to\nthe weights of the encoder, which is a common practice.  There\nare no bias terms in the decoder, however.  I do not see where they\nmotivate this restriction, and it seems to limit the usefulness of\nthe bias terms in the encoder.\n\nTheir analysis is with respect to a mixture model.  This is described\nin the abstract as a sparse dictionary model, which it is, I guess.\nThey assume that the gaussians are very well separated.  \n\nThe statement of Theorem says that it concerns Algorithm 1.  The\ndescription of Algorithm 1 describes a procedure, with an\naside that describes a ""version used in the analysis"".\n\nThey write in the text that the rows of W^t are projected onto\na ball of radius c in each update, but this is not included\nin the description of Algorithm 1.  The statement of Theorem 1\nincludes the condition that all rows of W^t are always equal to\nc, but this may not be consistent with the updates given\nin Algorithm 1.  My best guess is that they intend of\nthe rows of W^t to be normalized after each update (which is\ndifferent than projecting onto the ball of radius c).  This\naspect of their procedure seems restrict its applicability.\n\nSuccessful initialization looks like a very strong condition to\nme, something that will occur exponentially rarely, as a function\nof d. (See Fact 10 of ""Agnostically learning halfspaces"", by Kalai, et al.)\nFor each row of W^*, the probability that any one row of W^o will be\nclose enough is exponentially small, so exponentially many rows\nare needed for the probability that any row is close enough to\nbe, say, 1/2.  I don\'t see anything in the conditions of Theorem 1\nthat says that n is large relative to d, so it seems like its\nclaim includes the case where k and n are constants, like 5.\nBut, in this case, it seems like the claim of the probability\nof successful initialization cannot be correct when d is large.\n\nIt looks like, after ""successful initialization"", especially\ngiven the strong separation condition, the model as already\n""got it"".  In particular, the effect of the ReLUs seems to\nbe limited in this regime.\n\nI have some other concerns about correctness, but I do not think\nthat the paper can be accepted even if they are unfounded.\n\nThe exposition is uneven.  They tell us that W^T is the transpose\nof W, but do not indicate that 1_{a^t (x\') > 0} is a componentwise\nindicator function, and that x\' 1_{a^t (x\') > 0} is its\ncomponentwise product with x\' (if this is correct).\n\n\n', 'This paper shows that an idealized version of stochastic gradient descent converges when learning autoencoders with ReLu non-linearities under strong sparsity assumptions. Convergence rates are also determined. The result is another one in the emerging line of proving convergence guarantees for non-convex optimization problems arising in machine learning, and aims to explain certain phenomena experienced in practice.\n\nThe paper is generally nicely written, providing intuitions, but there are several typos (both in the text and in the math, e.g., missing indices), which should also be corrected.\n\nOn the negative side, while the proof technique in general looks plausible, there seem to be some mistakes in the derivations, which must be corrected before the paper can be accepted. Also, the assumptions in the in the paper seem quite restrictive, and their implications are not discussed thoroughly. \n\nThe assumptions are the following:\n1. The input data is coming from a mixture distribution, in the form x=w_I + eps, where {w_1,...,w_k} is a collection of unit vectors, I is uniform in {1,...,K}, eps is some noise (independent for each sample). \n2. The maximum norm of the noise is O(1/k).\n3. The number n of hidden neurons in the autoencoder is Omega(k) (this is not explicitly assumed but is necessary to make the probability of ""incorrect"" initialization small as well as the results to hold).\n\nUnder these assumptions it is shown that the weights of the autoencoder converge to the centers {w_1,...,w_k} (i.e., for any i the autoencoder has at least one weight converging to w_i). The rate of convergence depends on the coherence of the vectors w_i: the less coherent they are the faster the convergence is.\n\nFirst notice that some assumptions are missing from the main statement, as the error probability delta is certainly connected to the probability of incorrect initialization: when n=1<k, the convergence result clearly cannot hold. This comes from the mistake that in Theorem 3 you state the bound for the probability P(F^\\infty) instead of the conditional probability P(F^\\infty|E_o) (this is present everywhere in the proof). Theorem 3 should also depend on delta_o, which is used in the definition of F^\\infty. \n\nTheorem 2 also seems incorrect. Intuitively, the question is why it cannot happen that two neurons contribute to reproducing a given w_i, and so neither of their weights converge to w_i: E.g., assuming that {w_1,...,w_k,w_1\',...,w_k\'} form an orthogonal system and the noise is 0, the weight matrix of size n=2k defined as W_{2i-1,*}^T = 1/sqrt{2}(w_i + w\'_i) and W_{2i,*}^T=1/sqrt{2}(w_i - w\'_i), i \\in [k], with 0 bias can exactly recover any x=w_i (indeed, W_{2j-1,*} x= W_{2j,*} x = 1/sqrt{2}, while the other products are 0, and so W^T W x = W^T W w_j = 1/sqrt{2}(W_{2j-1,*}+W_{2j,*})^T = w_j). Then SGD does not change the weights and hence cannot recover the original weights {w_i }, in particular, it cannot increase the coherence in any step, contradicting Theorem 2. This counterexample can be extended even to the situation when k>d, as--in fact--we only need that the existence of a single j such that w_j and w\'_j are orthogonal and also orthogonal to the other basis vectors.\n\nThe assumptions are also very strange in the sense that the norm of the noise is bounded by O(1/k), thus the more modes the input distribution has the more separable they become. What motivates this scaling? Furthermore, the parameters of the algorithm for which the convergence is claimed heavily depend on the problem parameters, which are not known. How can you instantiate the algorithm then (accepting the ideal definition of b)? What are the consequences?\n\nGiven the above, at this point I cannot recommend the paper for acceptance. However, if the above problems are resolved, I would be very happy to see the paper at the conference.\n\n\nOther comments\n-----------------------\n- Add a short derivation why the weights of the autoencoder should converge to the w_i.\n- Definition 3: C_j is not defined in the main text.\n- While it is mentioned multiple times that the interesting regime is d<n, this is actually never used, nor needed (personally, I have never seen such an autoencoder--please give some references). What is really needed is n>k, which is natural if one wants to preserve the information, and also k>d for a rich family of distributions.\n- The area of the spherical cap is well understood (up to multiplicative constants), and better bounds than yours are readily available: with a cap of height 1-t, for sqrt{2/d}<t<1, the relative surface of the cap is between P/6 and P/2 where \nP=1/(t \\sqrt{d}) (1-t^2)^{(d-1)/2}; see, e.g., A. Brieden, P. Gritzmann, R. Kannan, V. Klee, L. Lovasz, and M. Simonovits. Deterministic and randomized polynomial-time approximation of radii. Mathematika. A Journal of Pure and Applied Mathematics, 48(1-2):63–105, 2001. \n- The notation section should be brought forward (or referred the fist time the notation is actually used).\n- Instead of unit spherical Gaussian you could simply say uniform distribution on the unit sphere\n- While Algorithm 1 is called ""norm-controlled SGD training,"" it does not control the norm at all.\n\n\n', ""The paper considers training single-hidden-layer auto-encoders, using stochastic gradient descent, for data generated from a noisy sparse dictionary model. The main result shows that under suitable conditions, the algorithm is likely to recover the ground-truth parameters. \n\nAlthough non-convex dictionary learning has been extensively studied for linear models, extending such convergence results to nonlinear models is interesting, and the result (if true) would be quite nice. Unfortunately (and unless I missed something), there appears to be a crucial bug in the argument, which requires that random initialization lead to dictionary elements sufficiently close to the ground truth. Specifically, definition 1 and lemma 1 give a bound on the success probability, which is exponentially small in the dimension d (as it should, since it essentially bounds the probability that an O(1)-norm random vector has \\Omega(1) inner product with some fixed unit vector). However, the d exponent disappears when the lemma is used to prove the main theorem (bottom of pg. 10), as well as in the theorem statement, making it seem that the success probability is large. Of course, a result which holds with exponentially small probability is not very interesting. I should also say that I did not check the rest of the proof carefully.\n\nA few relatively more minor issues:\n- The paper makes the strong assumption that the data is generated from a 1-sparse dictionary model. In other words, each data point is simply a randomly-chosen dictionary element, plus zero-mean noise. With this model, dictionary learning is quite easy and could be solved directly by other methods (although I see the value of analyzing specifically the behavior of SGD on auto-encoders). \n- To make things go through, the paper makes a non-trivial assumption on how the bias terms are updated (not quite according to SGD). But unless I'm missing something, a bias term isn't even needed to learn in their model, so wouldn't it be simpler and more natural to just assume that the auto-encoder doesn't have a bias term (i.e., x-> W's(Wx))?.\n\n""]","[-50, -50, -60]","[20, 50, 20]","[""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper such as unclear motivations, inconsistencies in the algorithm description, and concerns about the correctness of claims. However, it's not entirely negative as it acknowledges the authors' work and provides detailed feedback. The politeness score is 20 because the reviewer uses neutral language and avoids harsh criticism. They phrase concerns as observations or questions (e.g., 'I do not see where they motivate this restriction') rather than direct attacks. The reviewer also uses phrases like 'My best guess is...' which shows a willingness to interpret charitably. However, the review doesn't go out of its way to be overtly polite or complimentary, maintaining a professional, matter-of-fact tone throughout."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('nicely written, providing intuitions'), they identify several significant issues that prevent them from recommending acceptance ('I cannot recommend the paper for acceptance'). They point out mistakes in derivations, restrictive assumptions, and potential flaws in the main theorems. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering constructive criticism and expressing willingness to reconsider ('I would be very happy to see the paper at the conference' if issues are resolved). They provide detailed explanations for their concerns and offer specific suggestions for improvement, which is a polite and helpful approach in academic peer review."", ""The sentiment score is -60 because the reviewer identifies a 'crucial bug' in the paper's argument, which significantly undermines the main result. The reviewer states that this error makes the paper's conclusion uninteresting, as it would only hold with 'exponentially small probability'. This is a major criticism that overshadows the initial positive remarks about the potential interest of the work. The politeness score is 20 because while the reviewer is direct in pointing out the flaws, they use relatively polite language such as 'unless I missed something' and 'I should also say that I did not check the rest of the proof carefully', which shows a degree of humility and consideration. The reviewer also acknowledges the potential value of the work if the results were true. However, the overall tone remains professional rather than overtly polite, hence the moderate positive score.""]"
"['This paper investigates learning representations for the problem of nearest neighbor (NN) search by exploring various deep learning architectural choices. The crux of the paper is the connection between NN and the angles between the closest neighbors -- the higher this angle, more data points need to be explored for finding the nearest one, and thus more computational expense. Thus, the paper proposes to learn a network that tries to reduce the angles between the inputs and the corresponding class vectors in a supervised framework using softmax cross-entropy loss. Three architectural choices are investigated, (i) controlling the norm of output layers of the CNN (using batch norm essentially), (ii) removing relu so that the outputs are well-distributed in both positive and negative orthants, and (iii) normalizing the class vectors. Experiments are given on multiMNIST and Sports 1M and show improvements. \n\nPros:\n1) The paper explores different architectural choices for the deep network to some depth and show extensive results.\n2) The results do demonstrate clearly the advantage of the various choices and is useful\n3) The theoretical connections between data angles and query times are quite interesting,\n\nCons:\n1) Unclear Problem Statement. \nI find the problem statement a bit vague. Standard NN search finds a data point in the database closest to a query under some distance metric. While, the current paper uses the cosine similarity as the distance, the deep framework is trained on class vectors using cross-entropy loss. I do not think class labels are usually assumed to be given in the standard definition of NN, and it is not clear to me how the proposed setup can accommodate NN without class labels.  Thus as such, I see this paper is perhaps proposing a classification problem and not an NN problem per se. \n\n2) Lacks Focus\nThe paper lacks a good organization in my opinion. Things that are perhaps technically important are moved to the Appendix. For example, I find the theoretical part of the paper (e.g., Theorem 1) quite elegant and perhaps the main innovation in this paper. However, that is moved completely to the Appendix. So it cannot be really considered a contribution. It is also not clear if those theoretical results are novel. \n\n2) Disconnect/Unclear Assumptions\nThere seems to be some disconnect between LSH and deep learning architectures explored in Sections 2 and 3 respectively. Are the assumptions used in the theoretical results for LSH also assumed in the deep networks? For example, as far as I know, the standard LSH works assumes the projection hyperplanes are randomly chosen and the theoretical results are based on such assumptions. It is not clear how a softmax output of a CNN, which is trained in a supervised way, follow such assumptions. It would be important if the paper could clarify such assumptions to make sure the sections are congruent. \n\n3) No Related Work\nThere have been several efforts for adapting deep frameworks into KNN. The paper ignores all such works. Thus, it is not clear how significant is the proposed contribution. There are also not comparisons what-so-ever to competitive prior works.\n\n4) Novelty\nThe main contribution of this paper is basically a set of experiments looking into architectural choices. However, the results of this study do not provide any surprises. It appears that batch normalization is essential for good performances, while using RELU is not so when one wants to use all directions for effective data encoding. Thus, as such, the novelty or the contributions of this paper are minor.\n\nOverall, while I find there are some interesting theoretical bits in this paper, it lacks focus, the experiments do not offer any surprises, and there are no comparisons with prior literature. Thus, I do not think this paper is ready to be accepted in its present form.\n', 'The authors are trying to improve the efficiency of similarity search on representations learned by a deep networks but it is somewhat unclear where the proposed solution will be applied and how. The idea of modifying the network learning process to obtain representations that allow for faster similarity search has definitely a lot of value. I believe that the manuscript needs some re-writing so that the problem(s) are better motivated and is easier to follow.\n\nSpecific comments:\n- Page 2, Sec 2.1, 2.2: The theoretical/empirical analysis is Section 2 has actually been properly formalized by Sanjiv Kumar, et al. [a], and Kaushik Sinha, et al.[b]\'s papers on relative contrast and related quantities [a]. It would be good to discuss the proposed quantity in reference to these existing quantities. The idea presented here appears too simplistic relative to the existing ones.\n- Page 2, Sec 2.1: Usually in NNS, the data is not ""well-spread"" and has an underlying intrinsic structure. And being able to capture this intrinsic structure is what makes NNS more efficient. So how valid is this ""well-spread""-ness assumption in the setting that is being considered? Is this common in the ""learned representations"" set up?\n- Page 4, After Eq 2: I think the properties 1,2 are only true if you are using softmax to predict label and care about predictive 0-1 accuracy. Is that the only place the proposed solution is applicable or am I misunderstanding something?\n- Figure 2, 4 and 7 don\'t seem to be referred anywhere.\n- Is the application of NNS in performing the softmax evaluation? This needs to be made clearer.\n- If the main advantage of the proposed solution is the improvement of training/testing time by solving angular NNS (instead of MIPS) during the softmax phase, a baseline using existing MIPS solution [c] need to be considered to properly evaluate the utility of the proposed solution.\n\n[a] He, Junfeng, Sanjiv Kumar, and Shih-fu Chang. ""On the Difficulty of Nearest Neighbor Search."" Proceedings of the 29th International Conference on Machine Learning (ICML-12). 2012.\n\n[b] Dasgupta, Sanjoy, and Kaushik Sinha. ""Randomized partition trees for exact nearest neighbor search."" Conference on Learning Theory. 2013.\n\n[c] Neyshabur, Behnam, and Nathan Srebro. ""On Symmetric and Asymmetric LSHs for Inner Product Search."" Proceedings of the 32nd International Conference on Machine Learning (ICML-15). 2015.', '\nThe context is indexing images with descriptor vectors obtained from a DNN. This paper studies the impact of changing the classification part on top of the DNN on the ability to index the descriptors with a LSH or a kd-tree algorithm. The modifications include: applying or not a ReLU and batch normalization (and in which order) and normalizing the rows of the last FC layer before softmax. \n\n+ : preparing good features for indexing has not been studied AFAIK, and empirical studies that pay attention to details deserve to be published, see eg. the series ""all about vlad"" and ""Three things everyone should know to improve object retrieval"" by Arandjelović, Zisserman \n\n+/- : the paper considers two indexing methods (kd-tree and LSH) but basically it evaluates how well the features cluster together in descriptor space according to their class. Therefore it should be applicable to more SOTA techniques like product quantization and variants.\n\n- : there is no end-to-end evaluation, except figure 7 that is not referenced in the text, that that has a weird evaluation protocol (""the probability of finding the correct nearest neighbor conditioned on the model being correct"")\n\n- : the evaluation context is supervised hashing, but the evaluation is flawed: when the same classes are used for evaluation as for training, there is a trivial encoding that consists in encoding the classifier output (see ""How should we evaluate supervised hashing?"" Sablayrolles et al). \n\n- : no comparison with the SOTA, both for the experimental setup and actual results. There are plenty of works that do feature extraction + indexing, see ""Deep Image Retrieval: Learning global representations for image search"", Gordo et al ECCV\'16, ""Neural codes for image retrieval"", Babenko et al ECCV\'14, ""Large-Scale Image Retrieval with Attentive Deep Local Features"", Noh et al ICCV\'17, etc. \n\n\nDetails: \n\nexample x comes from a domain X typically R^p --> X = R^p but is it an image or an embedding? does the training backprop on the embedding?\n\ntop equation of p4 -> if you don\'t use it don\'t introduce it\n\nsection 3.2 is a bit disappointing. After 3.1, the natural / ""ML-correct"" way of handing this would be to design a loss that enforces the desirable properties, but this is just a set of tricks, albeit carefully justified\n\nSection 4 could use some clarification. Is the backprop applied to the embedding (""we convert each frame to its VGG features"")? ""d taken between 256 and 1024"": which one? \n\nMore importantly, the whole section looks like a parametric evaluation with an intermediate objective (mean angle). \n\n\nOverall I think the paper does not have a significant enough contribution or impressive enough results to be published. \n\n\n']","[-60, -20, -60]","[20, 50, 20]","[""The sentiment score is -60 because the review is predominantly negative. While the reviewer acknowledges some pros, the cons are more numerous and substantial. The reviewer states that the paper 'lacks focus', has an 'unclear problem statement', and 'is not ready to be accepted in its present form'. These are strong negative statements that outweigh the positive aspects mentioned. The politeness score is 20 because the reviewer uses professional and respectful language throughout, even when criticizing. They use phrases like 'I find' and 'in my opinion' to soften critiques, and acknowledge positive aspects before presenting negatives. However, the score is not higher because the criticism, while politely phrased, is quite direct and extensive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the potential value of the work ('has definitely a lot of value'), they express several concerns and suggest that the manuscript needs significant revision ('needs some re-writing'). The overall tone indicates that the paper has potential but requires substantial improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh or dismissive statements. They use phrases like 'I believe' and 'It would be good to' which maintain a polite tone while providing feedback. The reviewer also offers specific suggestions and references to improve the paper, which is a courteous way to provide criticism."", ""The sentiment score is -60 because the review is predominantly negative. While the reviewer acknowledges some positive aspects ('preparing good features for indexing has not been studied AFAIK, and empirical studies that pay attention to details deserve to be published'), the majority of the comments are critical. The reviewer points out several flaws in the paper's methodology, lack of end-to-end evaluation, and absence of comparison with state-of-the-art techniques. The concluding statement 'Overall I think the paper does not have a significant enough contribution or impressive enough results to be published' clearly indicates a negative sentiment.\n\nThe politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use neutral language to express their concerns and provide specific examples to support their points. The reviewer also acknowledges some positive aspects of the paper, which adds to the politeness. However, the overall tone is more matter-of-fact than overtly polite, hence the relatively low positive score.""]"
"['I have to say that I do not have all the background of this paper, and the paper is not written very clearly. I think the major contribution of the paper is represented in a very vague way.', 'This paper presents a suite of algorithmic ideas to learn a network of generalized value functions.  The majority of the technical contribution is dedicated to a new algorithm, AdaGain, that adaptively selects a step size for an RL algorithm; the authors claim this algorithm has sparsifying properties.  AdaGain is used in the context of a larger algorithm designed to search for GVFs by constructing a simple grammar over GVF components.  By creating large numbers of random GVFs and then pruning away useless ones, the authors discover a state representation that is useful for prediction.\n\nWhile I am deeply sympathetic to the utility and difficulty of the discovery problem in this sort of state-space modeling, this paper ultimately felt a bit weak.  \n\nOn the positive side, I felt that it was well-written.  The work is well localized in the literature, and answers most questions one would naturally have.  The AdaGain algorithm is, to the best of my knowledge, novel, and the focus on ""stability, not convergence"" seems like an interesting idea (although ultimately, not well fleshed-out).\n\nHowever, I felt that the central ideas were only thinly vetted.  For example:\n\n* It seems that AdaGain is designed to tune a single parameter (\\alpha) adaptively.  This raises several questions:\n  - State-of-the-art stochastic optimizers (eg, Adam) typically introduce one step size per parameter; these are all tuned.  Why wasn\'t that discussed?  Would it be possible to apply something like Adam to this problem?\n  - How does AdaGain compare to other adaptive gain algorithms?\n  - There are ways to sparsify a representation - simple SGD + L1 regularization is a natural option.  How do we know how well AdaGain compares to this more common approach?\n\n* The experiments seemed thin.  While I appreciated the fact that it seems that AdaGain was pruning away something, I was left wondering:\n  - How generalizable are these results?  To be honest, the CompassWorld seems utterly uninteresting, and somewhat simplistic. \n  - I am convinced that AdaGain is learning.  But it would be interesting to know *what* it is learning.  Do the learned GVFs capture any sort of intuitive structure in the domains?', 'I really enjoyed reading this paper and stopped a few time to write down new ideas it brought up. Well written and very clear, but somewhat lacking in the experimental or theoretical results.\n\nThe formulation of AdaGain is very reminiscent of the SGA algorithm in Kushner & Yin (2003), and more generally gradient descent optimization of the learning rate is not new. The authors argue for the focus on stability over convergence, which is an interesting focus, but still I found the lack of connection with related work in this section a strange.\n\nHow would a simple RNN work for the experimental problems? The first experiment demonstrates that the regularization is using fewer features than without, which one could argue does not need to be compared with other methods to be useful. Especially when combined with Figure 5, I am convinced the regularization is doing a good job of pruning the least important GVFs. However, the results in Figure 3 have no context for us to judge the results within. Is this effective or terrible? Fast or slow? It is really hard to judge from these results. We can say that more GVFs are better, and that the compositional GVFs add to the ability to lower RMSE. But I do not think this is enough to really judge the method beyond a preliminary ""looks promising"".\n\nThe compositional GVFs also left me wondering: What keeps a GVF from being pruned that is depended upon by a compositional GVF? This was not obvious to me.\n\nAlso, I think comparing GVFs and AdaGain-R with an RNN approach highlights the more general question. Is it generally true that GVFs setup like this can learn to represent any value function that an RNN could have? There\'s an obvious benefit to this approach which is that you do not need BPTT, fantastic, but why not highlight this? The network being used is essentially a recurrent neural net, the authors restrict it and train it, not with backprop, but with TD, which is very interesting. But, I think there is not quite enough here.\n\nPros:\nWell written, very interesting approach and ideas\nConceptually simple, should be easy to reproduce results\n\nCons:\nAdaGain never gets analyzed or evaluated except for the evaluations of AdaGain-R.\nNo experimental context, we need a non-trivial baseline to compare with\n\n']","[-50, -30, 20]","[-20, 60, 60]","[""The sentiment score is -50 because the reviewer expresses a negative opinion about the paper's clarity and presentation of its main contribution. The phrases 'not written very clearly' and 'represented in a very vague way' indicate significant dissatisfaction with the paper. However, it's not extremely negative, as the reviewer acknowledges their potential lack of background knowledge. The politeness score is -20 because while the language isn't overtly rude, the reviewer's blunt criticism lacks the softening language typically used in polite academic discourse. The phrase 'I have to say' comes across as somewhat confrontational, and the overall tone is direct and critical without much attempt to mitigate the negative feedback."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('well-written', 'novel algorithm'), they ultimately express that the paper 'felt a bit weak' and raise several critical points about the central ideas being 'only thinly vetted'. The overall tone leans negative, but not extremely so. The politeness score is 60 because the reviewer uses respectful language throughout, acknowledging positives before presenting criticisms, and phrases concerns as questions rather than direct attacks. They use phrases like 'I felt that' and 'I was left wondering' which soften the critique. However, some direct criticisms (e.g., calling CompassWorld 'utterly uninteresting') prevent a higher politeness score."", ""The sentiment score is slightly positive (20) because the reviewer starts by saying they 'really enjoyed reading this paper' and found it 'well written and very clear'. However, they also mention it's 'somewhat lacking in the experimental or theoretical results', which tempers the positivity. Throughout the review, they balance positive aspects ('looks promising', 'very interesting approach') with critiques and suggestions for improvement. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'I found', 'I am convinced', and 'I think' to soften their critiques, and they provide both pros and cons at the end. The tone is professional and helpful rather than harsh or dismissive.""]"
"['[Main comments]\n\n* The authors made a really odd choice of notation, which made the equations hard to follow.\nApparently, that notation is used in differential geometry, but I have never seen it used in\nan ML paper. If you talk about outer product structure, show some outer products!\n\n* The function f that the authors differentiate is not even defined in the main manuscript!\n\n* The low-rank structure they describe only holds for a single sample at a time.\nI don\'t see how this would be ""understanding low rank structure of deep networks""\nas the title claims... What is described is basically an implementation trick.\n\n* Introducing cubic regularization seems interesting. However, either some\nextensive empirical evidence or some some theoretical evidence that this is useful are needed.\nThe present paper has neither (the empirical evidence shown is very limited).\n\n[Other minor comments]\n\n* Strictly speaking Adagrad has not been designed for Deep Learning.\nIt is an online algorithm that became popular in the DL community later on.\n\n* ""Second derivatives should suffice for now, but of course if a use arose for\nthird derivatives, calculating them would be a real option""\n\nThat sentence seems useless.\n\n* Missing citation:\n\nGradient Descent Efficiently Finds the Cubic-Regularized Non-Convex Newton Step. \nYair Carmon, John Duchi.\n', '\nThis paper proposes to set a global step size gradient-based optimization algorithms such as SGD and Adam using second order information. Instead of using second-order information to compute the update directly (as is done in e.g. Newton method), it is used to estimate the change of the objective function in a pre-computed direction. This is computationally much cheaper than full Newton because (a) the Hessian does not need to be inverted (b) vector-Hessian multiplication is only O(#parameters) for a single sample.\n\nThere are many issues.\n\n### runtime and computational issues ###\n\nFirstly, the paper does not clearly specify the algorithm it espouses. It states: ""once the step direction had been determined, we considered that fixed, took the average of gT Hg and gT ∇f over all of the sample points to produce m (α) and then solved for a single αj value"" You should present pseudo-code for this computation and not leave the reader to determine the detailed order of computation for himself. As it stands, it is not only difficult for the reader to infer these details, but also laborious to determine the computational cost per iteration on some network the reader might wish to apply your algorithm to. Since the paper discusses the computational cost of CR only in vague terms, you should at least provide pseudo-code.\n\nSpecifically, consider equation (80) at the very end of the appendix and consider the very last term in that equation. It contains d^2v/dwdw. This is a ""heavy"" term containing the second derivative of the last hidden layer with respect to weights. You do not specify how you compute this term or quantities involving this term. In a ReLU network, this term is zero due to local linearity, but since you claim that your algorithm is applicable to general networks, this term needs to be analyzed further.\n\nWhile the precise algorithm you suggest is unclear, it\'s purpose is also unclear. You only use the Hessian to compute the g^THg terms, i.e. for Hessian-vector multiplication. But it is well-known that Hessian-vector multiplication is ""relatively cheap"" in deep networks and this fact has been used for several algorithms, e.g. http://www.iro.umontreal.ca/~lisa/pointeurs/ECML2011_CAE.pdf and https://arxiv.org/pdf/1706.04859.pdf. How is your method for computing g^THg different and why is it superior? \n\nAlso note that the low-rank structure of deep gradients is well-known and not a contribution of this paper. See e.g. https://www.usenix.org/system/files/conference/atc17/atc17-zhang.pdf\n\n### Experiments ###\n\nThe experiments are very weak. In a network where weights are initialized to sensible values, your algorithm is shown not to improve upon straight SGD. You only demonstrate superior results when the weights are badly initialized. However, there are a very large number of techniques already that avoid the ""SGD on ReLU network with bad initial weights"" problem. The most well-known are batch normalization, He initialization and Adam but there are many others. I don\'t think it\'s a stretch to consider that problem ""solved"". Your algorithm is not shown to address any other problems, but what\'s worse is that it doesn\'t even seem to address that problem well. While your learning curves are better than straight SGD, I suspect they are well below the respective curves for He init or batchnorm. In any case, you would need to compare your algorithm against these state-of-the-art methods if your goal is to overcome bad initializations. Also, in appendix A, you state that CR can\'t even address weights that were initialized to values that are too large.\n\nYou claim that your algorithm helps with ""overcoming plateaus"". While I have heard the claim that deep network optimization suffers from intermediate plateaus before, I have not seen a paper studying / demonstrating this behavior. I suggest you cite several papers that do this and then replicate the plateau situations that arose in those papers and show that CR overcomes them, instead of resorting to a platenau situation that is essentially artificially induced by intentionally bad hyperparameter choices.\n\nI do not understand why your initial learning rate for SGD in figures 2 and 3 (0.02 and 0.01 respectively) differ so much from the initial learning rate under CR. Aren\'t you trying to show that CR can find the ""correct"" learning rate? Wouldn\'t that suggest that initial learning rate for SGD should be comparable to the early learning rates chosen by CR? Wouldn\'t that suggest you should start SGD with a learning rate of around 2 and 0.35 respectively? Since you are annealing the learning rate for SGD, it\'s going to decline and get close to 0.02 / 0.01 anyway at some point. While this may not be as good as CR or indeed batchnorm or Adam, the blue constant curve you are showing does not seem to be a fair representation of what SGD can do.\n\nYou say the minibatch size is 32. For MNIST, this means that 1 epoch is around 1500 iterations. That means your plots only show the first epoch of training. But MNIST does not converge in 1 epoch. You should show the error curve until convergence is reached. Same for CIFAR. \n\n""we are not interested in network performance measures such as accuracy and validation error"" I strongly suspect your readers may be interested in those things. You should show validation classification error or at least training classification error in addition to cross-entropy error. \n\n""we will also focus on optimization iteration rather than wall clock time"" Again, your readers care more about the latter. You need to show either error curves by clock time or the total time to convergence or supplement your iteration-based graphs with a detailed discussion of how long an iteration takes.\n\nThe scope of the experiments is limited because only a single network architecture is considered, and it is not a state-of-the art architecture (no convolution, no normalization mechanism, no skip connections).\n\nYou state that you ran experiments on Adam, Adadelta and Adagrad, but you do not show the Adam results. You say in the text that they were the least favorable for CR. This suggests that you omitted the detailed results because they were unfavorable to you. This is, of course, unacceptable!\n\n### (Un)suitability of ReLU for second-order analysis ###\n\nYou claim to use second-order information over the network to set the step size. Unfortuantely, ReLU networks do not have second-order information! They are locally linear. All their nonlinearity is contained in non-differentiable region boundaries. While this may lead to the Hessian being cheaper to compute, it means it is not representative of the actual behavior of the network. In fact, the only second-order information that is brought to bear in your experiments is the second-order information of the error function. I am not saying that this particular second-order information could not be useful, but you need to make a distinction in your paper between network second-order info and error function second-order info and make explicit that you only use the former in your experiments. As far as I know, most second-order papers use either tanh or a smoothed ReLU (such as the smoothed hinge used recently by Koh & Liang (https://arxiv.org/pdf/1703.04730.pdf)) for experiments to overcome the local linearity.\n\n### The \\sigma hyperparameter ###\n\nYou claim that \\sigma is not as important / hard to set as \\alpha in SGD or Adam. You state: ""We also found that this ap- proach requires less problem-specific information (e.g. an optimal initial learning rate) than other first-order methods in order to perform well."" You have not provided sufficient evidence for this claim. You say that \\sigma can be chosen by considering powers of 10. In many networks, choosing \\alpha by considering powers of 10 is sufficient! Even if powers of 2 are considered for \\alpha, this would reduce the search effort only by factor log_2(10). Also, what if the range of \\sigma values that need to be considered is larger than the range of \\alpha values? Then setting \\sigma would take more effort.\n\nYou do not give precise protocols how you set \\sigma and how you set \\alpha for non-CR algorithms. This should be clearly specified in Appendix A as it is central to your argument of easing hyperparameter search.\n\n### Minor points ###\n\n- Your introduction could benefit from a few more citations\n- ""The rank of the weighted sum of low rank components (as occurs with mini-batch sampling) is generally larger than the rank of the summed components, however."" I don\'t understand this. Every sum can be viewed as a weighted sum and vice versa.\n- Equation (8) could be motivated a bit better. I know it derives from Taylor\'s theorem, but it might be good to discuss how Taylor\'s theorem (and its assumptions) relate to deep networks.\n- why the name ""cubic regularization""? shouldn\'t it be something like ""quadratic step size tuning""?\n\n.\n.\n.\n\nThe reason I am giving a 2 instead of a 1 is because the core idea behind the algorithm given seems to me to have potential, but the execution is sorely lacking. \n\nA final suggestion: You advertise as one of your algorithms upsides that it uses exact Hessian information. Howwever, since you only care about the scale of the second-order term and not its direction, I suspect exact calculation is far from necessary and you could get away with very cheap approximations, using for example techniques such as mean field analysis (e.g. http://papers.nips.cc/paper/6322-exponential-expressivity-in-deep-neural-networks-through-transient-chaos.pdf).', 'Summary: \nThis paper shows the feedforward network (with ReLU activation functions in the hidden layers, softmax at the output, and cross entropy-loss) exhibits a low-rank derivative structure, which is able to use second-order information without approximating Hessian. For numerical experiments, the author(s) implemented Cubic Regularization on this network structure with SGD (on MNIST and CIFAR10) and Adagrad and Adadelta (on MNIST). \n\nComments: \nThe idea of showing low rank structure which makes it possible to use second-order information without approximations is interesting. This feedforward network with ReLU activation, output softmax and cross-entropy-loss is well-known structure for neural networks. \n\nI have some comments and questions as follows. \n\nHave you tried to apply this to another architecture of neural networks? Do you think whether your approach is able to apply to convolutional neural networks, which are widely used? \n\nThere is no gain on using CR with Adam as you mention in Discussion part of the paper. Do you think that CR with SGD (or with Adagrad and Adadelta) can be better than Adam? If not, why do people should consider this approach, which is more complicated, since Adam is widely used? \n\nThe author(s) should do more experiments to various dataset to be more convincing. \n\nI do like the idea of the paper, but at the current state, it is hard to evaluate the effective of this paper. I hope the author(s) could provide more experiments on different datasets. I would suggest to also try SVHN or CIFAR100. And if possible, please also consider CNN even if you are not able to provide any theory. \n']","[-60, 0, 20]","[-20, 0, 60]","[""The sentiment score is -60 because the review is predominantly negative, pointing out several significant issues with the paper such as odd notation choices, undefined functions, and limited empirical evidence. The reviewer does mention one potentially interesting aspect (cubic regularization), but overall the tone is critical. The politeness score is -20 because while the reviewer isn't overtly rude, the language is quite direct and occasionally dismissive (e.g., 'That sentence seems useless'). The reviewer doesn't use softening language or positive reinforcement, which contributes to a somewhat impolite tone. However, it's not extremely rude, hence the moderate negative score rather than a very low one."", 'ERROR', ""The sentiment score is slightly positive (20) because the reviewer expresses interest in the paper's idea and acknowledges its potential ('The idea of showing low rank structure which makes it possible to use second-order information without approximations is interesting'). However, they also express concerns and suggest more work is needed, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, poses questions rather than making demands, and offers constructive suggestions ('I hope the author(s) could provide more experiments'). The reviewer also expresses appreciation for the paper's concept ('I do like the idea of the paper'). The tone is professional and courteous, without being overly formal or effusive.""]"
"[""This paper provides a clean way of learning embeddings for structured features that can be discrete -- indicating presence / absence of a certain quality. Further, these features can be structured i.e. a set of them are of the same 'type'. Unlike, word2vec there is no hard constraint that similar objects must have similar representations and so, the learnt embeddings reflect the likelihood of the observed features. Therefore, this can be used as a multi-label classifier by using two feature types -- the input and the set of categories. This proposed scheme is evaluated on two datasets -- movies and education in a retrieval setting. \n\nI would like to see an evaluation of these features in a classification setting to further demonstrate the utility of these embeddings as compared to directly embedding the discrete features and then performing a K-way classification. For example, I am aware of -- http://manikvarma.org/downloads/XC/XMLRepository.html contains some interesting datasets which have a large number of discrete features and classes. "", 'SUMMARY.\n\nThe paper presents an extension of word2vec for structured features.\nThe authors introduced a new compatibility function between features and, as in the skipgram approach, they propose a variation of negative sampling to deal with structured features.\nThe learned representation of features is tested on a recommendation-like task.\n\n\n----------\n\nOVERALL JUDGMENT\nThe paper is not clear and thus I am not sure what I can learn from it.\nFrom what is written on the paper I have trouble to understand the definition of the model the authors propose and also an actual NLP task where the representation induced by the model can be useful.\nFor this reason, I would suggest the authors make clear with a more formal notation, and the use of examples, what the model is supposed to achieve.\n\n----------\n\nDETAILED COMMENTS\nWhen the authors refer to word2vec is not clear if they are referring to skipgram or cbow algorithm, please make it clear.\nBottom of page one: ""a positive example is \'semantic\'"", please, use another expression to describe observable examples, \'semantic\' does not make sense in this context.\nLevi and Goldberg (2014)  do not say anything about factorization machines, could the authors clarify this point?\nEquation (4), what do i and j stand for? what does \\beta represent? is it the embedding vector? How is this formula related to skipgram or cbow?\nThe introduction of structured deep-in factorization machine should be more clear with examples that give the intuition on the rationale of the model.\nThe experimental section is rather poor, first, the authors only compare themselves with word2ve (cbow), it is not clear what the reader should learn from the results the authors got.\nFinally, the most striking flaw of this paper is the lack of references to previous works on word embeddings and feature representation, I would suggest the author check and compare themselves with previous work on this topic.', ""Summary:\nThis paper proposes an approach to learn embeddings for structured datasets i.e. datasets which have heterogeneous set of features, as opposed to just words or just pixels. The paper proposes an approach called Feat2vec that relies on Structured Deep-In Factorization machines-- a paper that is concurrently under review at ICLR2018, which I haven't read in depth. The paper compares against a Word2vec baseline that pools all the heterogeneous content learns just one set of embeddings. Results are shown on IMDB movies and a proprietary education platform datasets. In both the tasks, Feat2vec leads to significant reduction in error compared to Word2vec.\n\nComments:\n\nThe paper is well written and addresses an important problem of learning word embeddings when there is inherent structure in the feature space. It is a very practically relevant problem. The novelty of the proposed approach seems limited in light of the related paper that is concurrently under review at ICLR2018, on which this paper heavily relies. Perhaps the authors should consider combining the two papers into one complete paper? The structured deep-in factorization machines allow higher-level interactions in embedding learning which allows the authors to learn embeddings for heterogeneous set of features. The sampling approaches proposed seem pretty straightforward adaptations of existing methods and not novel enough.\n""]","[60, -60, 50]","[70, 20, 75]","[""The sentiment score is 60 (moderately positive) because the reviewer begins by highlighting the paper's strengths and novel contributions, describing it as providing a 'clean way' of learning embeddings and noting its advantages over existing methods. The reviewer seems generally positive about the work, but suggests an additional evaluation, indicating room for improvement. The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits before offering a constructive suggestion. The phrase 'I would like to see' is a polite way of recommending additional work. The reviewer also demonstrates engagement by mentioning awareness of relevant datasets, which shows a collegial approach to the review process."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the clarity and quality of the paper. They state that the paper is 'not clear' and they are 'not sure what I can learn from it.' They also mention a 'striking flaw' in the lack of references. However, it's not entirely negative as they offer suggestions for improvement. The politeness score is 20 because while the reviewer is critical, they use relatively polite language. They use phrases like 'I would suggest' and 'please make it clear' rather than harsh or rude language. They also provide specific, constructive feedback. However, the tone is more neutral than overtly polite, hence the modest positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance and practical relevance of the problem addressed, and notes that the paper is well-written. However, they also express concerns about the novelty of the approach and suggest combining it with another paper. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and balances positive comments with areas for improvement. They avoid harsh criticism and frame suggestions in a considerate manner, such as 'Perhaps the authors should consider...'""]"
"[""This paper introduces a parameter server architecture to improve distributed training of CNNs in the presence of stragglers. Specifically, the paper proposes partial pulling where a worker only waits for first b blocks rather than all the blocks of the parameters. This technique is combined with existing methods such as partial pushing (Pan et. al. 2017) for a partial synchronous SGD method. The method is evaluated with Resnet -50 using synthetic delays.\n\nComments for the author:\n\nThe paper is well-written and easy to follow. The problem of synchronization costs being addressed is important but it is unclear how much of this is arising due to large blocks.\n\n1) The partial pushing method (Pan et. al. 2017, section 3.1) shows a clear evidence for the problem using a real workload with a large number of workers. Unfortunately, in your Figure 2, this is not as obvious and not real since it is using simulated delays. More specifically, it is not clear how the workers behave in a real environment and whether you get a clear benefit from using a partial number of blocks as opposed to sending all of them. \n\n2) Did you modify your code to support block-wise sending of gradients (some description of how the framework was modified will be helpful)? The idea is to send partial parameter blocks and when 'b' blocks are received, compute the gradients. I feel that, with such a design, you may actually end up hurting the performance by sending a large number of small packets in the no failure case. For real, large data centers, this may cause a packet storm and subsequent throughput collapse (e.g. the incast problem). You need to show the evidence that you do not hurt the failure-free case for a large number of workers.\n\n3) The evaluation is on fairly small workloads (CIFAR-10). Again, evaluating over Imagenet and demonstrating a clear speedup over existing sync methods will be helpful. Furthermore, a clear description of your “pull” configuration (such as in Figure 1) i.e. how many actual bytes or blocks are sent and what is the threshold will be helpful (beyond a vague 90%).\n\n4) Another concern with partial synchronization methods that I have is that how do you pick these configurations (pull 0.75 etc). These appear to be dataset specific and finding the optimal configuration here requires significant experimentation that takes significantly more time than just running the baseline.\n\nOverall, I feel there is not enough evidence for the problem specifically generating large blocks of gradients and this needs to be clearly shown. To propose a solution for stragglers, evaluation should be done in a datacenter environment with the presence of stragglers (and not small workloads with synthetic delays). Furthermore, the proposed technique despite the simplicity appears as a rather incremental contribution."", 'This paper considers distributed synchronous SGD, and proposes to use ""partial pulling"" to alleviate the problem with slow servers.\n\nThe motivation is that the server may be a straggler. The authors suggested one possibility, namely that the server and some workers are located on the same machine and the workers take most of the computational resource. However, if this is the case, a simple solution would be to move the server to a different node. A more convincing argument for a slow server should be provided.\n\nThough the authors claimed that they used 3 techniques to accelerate synchronous SGD, only partial pulling is proposed by them (the other 2 are borrowed straightforwardly from existing papers). The mechanism of partial pulling is very simple (just let SGD proceed after pulling a partial parameter block instead of the whole block). As mentioned by the authors in section 1, any relaxation in synchrony brings more noise and higher variance to the updates, and also may cause slow convergence or convergence to a poor solution. However, the authors provided no theoretical study on any of these aspects.\n\nExperimental results are not convincing. Only one relatively small dataset (cifar10) is used Moreover, the slow server problem is only simulated by artificially adding delays to the server.', 'Paper proposes a weak synchronization approach to synchronous SGD with the goal of improving even with slow parameter servers. This is an improvement on earlier proposals (e.g. Revisiting Synchronous SGD) that allow for slow workers. Empirical results on ResNet50 on CIFAR show promising results for simulations with slow workers and servers, with the proposed approach.\n\nIssues with the paper:\n- Since the paper is focused on empirical results, having results only for ResNet50 on CIFAR is very limiting\n- Empirical results are based on simulations and not real workloads. The choice of simulation constants (% delayed, and delay time) seems somewhat arbitrary as well.\n- For the simulated results, the comparisons seem unfair since the validation error is different. It will be useful to also provide time to a certain accuracy that all of them get to e.g. the validation error of 0.1609 (reached by the 3 important cases).\n\nOverall, the paper proposes an interesting improvement to this area of synchronous training, however it is unable to validate the impact of this proposal.']","[-30, -50, -20]","[60, 0, 50]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the paper is well-written and addresses an important problem, they express several concerns and criticisms. They state that the evidence for the problem is unclear, the evaluation is on small workloads, and the contribution seems incremental. However, it's not extremely negative as they do recognize some positives. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as suggestions for improvement rather than harsh judgments. They use phrases like 'will be helpful' and ask questions rather than making blunt statements. The tone is professional and aimed at improving the paper rather than dismissing it outright."", ""The sentiment score is -50 because the review is generally critical of the paper, pointing out several weaknesses without much positive feedback. The reviewer questions the motivation, criticizes the lack of theoretical study, and finds the experimental results unconvincing. However, it's not entirely negative as it acknowledges the paper's contribution of the 'partial pulling' technique.\n\nThe politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout without using overtly polite language or rude expressions. The criticism is direct but not personal or insulting. The reviewer uses phrases like 'should be provided' and 'are not convincing' which are straightforward but not impolite."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper proposes an 'interesting improvement' and shows 'promising results', they also point out significant limitations. The reviewer states that the paper is 'unable to validate the impact of this proposal' due to limited empirical results and reliance on simulations. The politeness score is moderately positive (50) as the reviewer uses neutral language and provides constructive criticism. They acknowledge positive aspects before listing issues, and use phrases like 'it will be useful' when suggesting improvements, which maintains a respectful tone. The review is direct but not rude, balancing critique with recognition of the paper's potential value.""]"
"['This paper considers a dichitomy between ML and RL based methods for sequence generation. It is argued that the ML approach has some ""discrepancy"" between the optimization objective and the learning objective, and the RL approach suffers from bad sample complexity. An alpha-divergence formulation is considered to combine both methods.\n\nUnfortunately, I do not understand main points made in this paper and am thus not able to give an accurate evaluation of the technical content of this paper. I therefore have no option but to vote for reject of this paper, based on my educated guess. \n\nBelow are the points that I\'m particularly confused about:\n\n1. For the ML formulation, the paper made several particularly confusing remarks. Some of them are blatantly wrong to me. For example, \n\n1.1 The q(.|.) distribution in Eq. (1) *cannot* really be the true distribution, because the true distribution is unknown and therefore cannot be used to construct estimators. From the context, I guess the authors mean ""empirical training distribution""?\n\n1.2 I understand that the ML objective is different from what the users really care about (e.g., blue score), but this does not seem a ""discrepancy"" to me. The ML estimator simply finds a parameter that is the most consistent to the observed sequences; and if it fails to perform well in some other evaluation criterion such as blue score, it simply means the model is inadequate to describe the data given, or the model class is so large that the give number of samples is insufficient, and as a result one should change his/her modeling to make it more apt to describe the data at hand. In summary, I\'m not convinced that the fact that ML optimizes a different objective than the blue score is a problem with the ML estimator.\n\nIn addition, I don\'t see at all why this discrepancy is a discrepancy between training and testing data. As long as both of them are identically distributed, then no discrepancy exists.\n\n1.3 In point (ii) under the maximum likelihood section, I don\'t understand it at all and I think both sentences are wrong. First, the model is *not* trained on the true distribution which is unknown. The model is trained on an empirical distribution whose points are sampled from the true distribution. I also don\'t understand why it is evaluated using p_theta; if I understand correctly, the model is evaluated on a held-out test data, which is also generated from the underlying true distribution.\n\n2. For the RL approach, I think it is very unclear as a formulation of an estimator. For example, in Eq. (2), what is r and what is y*? It is mentioned that r is a ""reward"" function, but I don\'t know what it means and the authors should perhaps explain further. I just don\'t see how one obtains an estimated parameter theta from the formulation in Eq. (2), using training examples.', 'The paper proposes another training objective for training neural sequence-to-sequence models. The objective is based on alpha-divergence between the true input-output distribution q and the model distribution p. The new objective generalizes  Reward-Augmented Maximum Likelihood (RAML) and entropy-regularized Reinforcement Learning (RL), to which it presumably degenerates when alpha goes to 1 or to 0 respectively.\n\nThe paper has significant writing issues. In Paragraph “Maximum Likelihood”, page 2, the formalization of the studied problem is unclear. Do X and Y denote the complete input/output spaces, or do they stand for the training set examples only?  In the former case, the statement “x is uniformly sampled from X” does not make sense because X is practically infinite. Same applies to the dirac distribution q(y|x), the true conditional distribution of outputs given inputs is multimodal even for machine translation. If X and Y were meant to refer to the training set, it would be worth mentioning the existence of the test set. Furthermore, in the same Section 2 the paper fails to mention that reinforcement learning training also does not completely correspond to the evaluation approach, at which stage greedy search or beam search is used.\n\nThe proposed method is evaluated on just one dataset. Crucially, there is no comparison to a trivial linear combination of ML and RL, which in one way or another was used in almost all prior work, including GNMT, Bahdanau et al, Ranzato et al. The paper does not argue why alpha divergence is better that the aforementioned combination method and also does not include it in the comparison.\n\nTo sum up, I can not recommend the paper to acceptance, because (a) an important baseline is missing (b) there are serious writing issues.\n', 'Summary of the paper: \n\nThis paper presents a method, called \\alpha-DM (the authors used this name because they are using \\alpha-Divergence to measure the distance between two distributions), that addresses three important problems simultaneously: \n(a) Objective score discrepancy: i.e., in ML we minimize a cost function but we measure performance using something else, e.g., minimizing cross entropy and then measuring performance using BLEU score in Machine Translation (MT). \n(b) Sampling distribution discrepancy: The model is trained using samples from true distribution but evaluated using samples from the learned distribution\n(c) Sample inefficiency: The RL model might rarely draw samples with high rewards which makes it difficult to compute gradients accurately for objective function’s optimization \n\nThen the authors present the results for machine translation task and also analysis of their proposed method.\n\nMy comments / feedback: \n\nThe paper is well written and the problem addressed by the paper is an important one. My main concerns about this work are have two aspects: \n(a)\tNovelty\n1.\tThe idea is a good one and is great incremental research building on the top of previous ideas. I do not agree with statements like “We demonstrate that the proposed objective function generalizes ML and RL objective functions …” that authors have made in the abstract. There is not enough evidence in the paper to validate this statement.\n(b)\tExperimental Results\n2.\tThe performance of the proposed method is not significantly better than other models in MT task. I am also wondering why authors have not tried their method on at least one more task? E.g., in CNN+LSTM based image captioning, the perplexity is minimized as cost function but the performance is measured by BLEU etc.  \n\nSome minor comments: \n\n1.\tIn page 2, 6th line after eq (1), “… these two problems” --> “… these three problems” \n2.\tIn page 2, the line before the last line, “… resolbing problem” --> “… resolving problem”\n']","[-80, -70, -20]","[-20, -20, 60]","[""The sentiment score is -80 because the reviewer explicitly states they don't understand the main points of the paper and are voting to reject it. They list several points of confusion and disagreement, indicating a strongly negative view of the paper. The politeness score is -20 because while the reviewer isn't overtly rude, their language is quite direct and critical. They use phrases like 'blatantly wrong' and 'I don't understand it at all', which come across as somewhat harsh. However, they do attempt to explain their reasoning and use some softening language like 'Unfortunately' and 'I guess', which prevents the score from being even lower."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer points out significant writing issues, lack of clarity in problem formalization, insufficient evaluation (only one dataset), and missing important baselines. The reviewer explicitly states they cannot recommend the paper for acceptance. However, it's not entirely negative as they do acknowledge the paper's attempt to propose a new training objective.\n\nThe politeness score is -20 because while the reviewer isn't overtly rude, the language is quite direct and critical without much attempt to soften the criticism. Phrases like 'The paper has significant writing issues' and 'I can not recommend the paper to acceptance' are quite blunt. However, the reviewer does provide specific reasons for their criticism, which prevents the score from being lower."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and addresses an important problem, they express significant concerns about the novelty of the work and the experimental results. The reviewer disagrees with some of the authors' claims and notes that the performance is not significantly better than other models. However, the score is not deeply negative as the reviewer still recognizes the value of the research as 'good incremental research.'\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They begin with positive comments about the paper being well-written and addressing an important problem. Even when expressing concerns, the language is constructive rather than harsh. The reviewer uses phrases like 'My main concerns' and 'I am wondering' rather than more confrontational language. The inclusion of minor comments for improvement also shows a helpful attitude. However, the score is not extremely high as the review is still direct in its criticism.""]"
"[""Summary:\n The paper presents an unsupervised method for detecting adversarial examples of neural networks. The method includes two independent components: an ‘input defender’ which tried to inspect the input, and a ‘latent defender’ trying to inspect a hidden representation. Both are based on the claim that adversarial examples lie outside a certain sub-space occupied by the natural image examples, and modeling this sub-space hence enables their detection. The input defender is based on sparse coding, and the latent defender on modeling the latent activity as a mixture of Gaussians. Experiments are presented on MInst, Cifar10, and ImageNet.\n \n-\tIntroduction: The motivation for detecting adversarial examples is not stated clearly enough. How can such examples be used by a malicious agent to cause damage to a system? Sketching some such scenarios would help the reader understand why the issue is practically important. I was not convinced it is. \nPage 4: \n-\tStep 3 of the algorithm is not clear:\no\tHow exactly does HDDA model the data (formally) and how does it estimate the parameters? In the current version, the paper does not explain the HDDA formalism and learning algorithm, which is a main building block in the proposed system (as it provides the density score used for adversarial examples detection). Hence the paper cannot be read as a standalone document. I went on to read the relevant HDDA paper, but it is also not clear which of the model variants presented there is used in this paper.\no\tWhat is the relation between the model learned at stage 2 (the centers c^i) and the model learnt by HDDA? Are they completely different models? Or are the C^I used when learning the HDDA model (and how)? \nIf these are separate models, how are they used in conjunction to give a final density score? If I understand correctly, only the HDDA model is used to get the final score, and the C^i are only used to make the \\phy(x) representation more class-seperable. Is that right?\n-\tFigure 4, b and c: it is not clear what the (x,y,z) measurements plotted in these 3D drawings are (what are the axis).\nPage 5:\n-\tSection 2: the risk analysis is done in a standard Bayesian way and leads to a ratio of PDFs in equation 5. However, this form is not appropriate for the case presented at this paper, since the method presented only models one of these PDFs (Specifically p(x | W1)  - there is not generative model of p(x|W2)).  \n-\tThe authors claim in the last sentence of the section that p(x|W2) is equivalent to 1-p(x|W1), but this is not true: these are two continuous densities, they do not sum to 1, and a model of p(x|W2) is not available (as far as I understand the method)\nPage 6:\n-\tHow is equation 7) optimized?\n-\tWhich patchs are extracted from images, for training and at inference time? Are these patchs a dense coverage of the image? Sparsely sampled? Densely sampled with overlaps?\n-\tIts not clear enough what exactly is the ‘PSNR’ value which is used for the adversarial example detection, and what exactly is ‘profile the PSNR of legitimate samples within each class’. A formal definition of PSNR and’profiling’ is missing (does profiling simply mean finding a threshold for filtering?)\nPage 7:\n-\tFigure 7 is not very informative. Given the ROC curves in figure 8  and table 1 it is redundant. \n\nPage 8:\n-\tThe results in general indicate that the method is much better than chance, but it is not clear if it is practical, because the false alarm rates for high detection are quite high. For example on ImageNet, 14.2% of the innocent images are mistakenly rejected as malicious to get 90% detection rate. I do not think this working point is useful for a real application\n-\tGiven the high flares alarm rate, it is surprising that experiments with multiple checkpoints are not presented (specifically as this case of multiple checkpoints is discussed explicitly in previous sections of the paper).  Experiments with multiple checkpoints are clear required to complete the picture regarding the empirical performance of this method\n-\tThe experiments show that essentially, the latent defenders are stronger than the input defender in most cases. However, an ablation study of the latent defender is missing: Specifcially, it is not clear a) how much does stage 2 (model refinement with clusters)  contribute to the accuracy (how does the model do without it? And 3) how important is the HDDA and the specific variant used (which is not clear) important: is it important to model the Gaussians using a sub-space? Of which dimension?\n\nOverall:\nPros:\n-\t A nice idea with some novelty,  based on a non-trivial observation\n-\tThe experimental results how the idea holds some promise\nCons\n-\tThe method is not presented clearly enough: the main component modeling the network activity is not explained (the HDDA module used)\n-\tThe results presented show that the method is probably not suitable for a practical application yet (high false alarm rate for good detection rate)\n-\tExperimental results are partial: results are not presented for multiple defenders, no ablation experiments\n\n\nAfter revision:\nSome of my comments were addressed, and some were not.\nSpecifically, results were presented for multiple defenders and some ablation experiments were highlihgted\nThings not addressed:\n - The risk analysis is still not relevant. The authors removed a clearly flawed sentence, but the analysis still assumes that two densities (of 'good' and 'bad' examples) are modeled, while in the work presented only one of them is. Hence this analysis does not add anything to the paper-  it states a general case which does not fit the current scenario and its relation to the work is not clear. It would have been better to omit it and use the space to describe HDDA and the specific variant used in this work, as this is the main tool doing the distinction.\n\nI believe the paper should be accepted.\n"", ""This paper present a method for detecting adversarial examples in a deep learning classification setting.  The idea is to characterize the latent feature space (a function of inputs) as observed vs unobserved, and use a module to fit a 'cluster-aware' loss that aims to cluster similar classes tighter in the latent space. \n\nQuestions/Comments:\n\n- How is the checkpointing module represented?  Which parameters are fit using the fine-tuning loss described on page 3? \n\n- What is the rationale for setting the gamma (concentration?) parameters to .01?  Is that a general suggestion or a data-set specific recommendation?\n\n- Are the checkpointing modules designed to only detect adversarial examples?  Or is it designed to still classify adversarial examples in a robust way?\n\nClarity: I had trouble understanding some of this paper.  It would be nice to have a succinct summary of how all of the pieces presented fit together, e.g. the original victim network, fine-tuning loss, per-class dictionary learning w/ OMP.  \n\nTechnical: It is hard to tell how some of the components of this approach are technically justified. \n\nNovel: I am not familiar enough with adversarial deep learning to assess novelty or impact. "", 'This paper proposes an unsupervised method, called Parallel Checkpointing Learners (PCL), to detect and defend adversarial examples. The main idea is essentially learning the manifold of the data distribution and using Gaussian mixture models (GMMs) and dictionary learning to train a ""reformer"" (without seeing adversarial examples) to detect and correct adversarial examples. With PCL, one can use hypothesis testing framework to analyze the detection rate and false alarm of different neural networks against adversarial attacks. Although the motivation is well grounded, there are two major issues of this work: (i) limited  novelty - the idea of unsupervised manifold projection method has been proposed in the previous work; and (ii) insufficient attack evaluations - the defender performance is evaluated against weak attacks or attacks with improper parameters. The details are as follows.\n\n1.  Limited novelty and performance comparison - the idea of unsupervised manifold projection method has been proposed and well-studied in ""MagNet: a Two-Pronged Defense against Adversarial Examples"", appeared in May 2017. Instead of GMMs and dictionary learning in PCL,  MagNet trains autoencoders for defense and provides sufficient experiments to claim its defense capability. On the other hand, the authors of this paper seem to be not aware of this pioneering work and claim ""To the best of our knowledge, our proposed PCL methodology is the first unsupervised countermeasure that is able to detect DL adversarial samples generated by the existing state-of-the-art attacks"", which is obviously not true. More importantly, MagNet is able to defend the adversarial examples very well (almost 100% success) no matter the adversarial examples are close to the information manifold or not. As a result, the resulting ROC and AUC score are expected be better than PCL. In addition, the authors of MagNet also compared their performance in white-box (attacker knowing the reformer), gray-box (having multiple independent reformers), and black-box (attacker not knowing the reformer) scenarios, whereas this paper only considers the last case.\n\n2. Insufficient attack evaluations - the attacks used in this paper to evaluate the performance of PCL are either weak (no longer state-of-the-art) or incorrectly implemented. For FGSM, the iterative version proposed by (Kurakin, ICLR 2017) should be used. JSMA and deep fool are not considered strong attacks now (see Carlini\'s bypassing 10 detection methods paper). Carlini-Wagner attack is still strong, but the authors only use 40 iterations (should be at least 500) and setting the confidence=0, which is known to be producing non-transferable adversarial examples. In comparison, MagNet has shown to be effective against different confidence parameters. \n\nIn summary, this paper has limited novelty, incremental contributions, and lacks convincing experimental results due to weak attack implementation.  \n \n\n\n']","[20, -20, -80]","[60, 50, -20]","[""The sentiment score is slightly positive (20) because while the reviewer points out several issues and areas for improvement, they ultimately recommend acceptance of the paper after revisions. The reviewer acknowledges the 'nice idea with some novelty' and that experimental results show promise, which contributes to the positive sentiment. The politeness score is moderately high (60) as the reviewer maintains a professional and constructive tone throughout. They use phrases like 'I believe' and 'it would have been better' rather than harsh criticisms. The reviewer also balances critiques with positive observations ('pros' and 'cons'). However, the score is not maximally positive as the review is direct in pointing out flaws and doesn't use overtly polite language or praise excessively."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution, they express difficulty understanding parts of the paper and question some technical aspects. The reviewer states 'I had trouble understanding some of this paper' and 'It is hard to tell how some of the components of this approach are technically justified,' indicating some concerns. However, the review is not entirely negative, as it asks constructive questions and suggests improvements. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, framing criticisms as questions or suggestions rather than direct attacks. Phrases like 'It would be nice to have' and 'Questions/Comments:' demonstrate a polite approach to providing feedback. The reviewer also admits their own potential lack of expertise in assessing novelty, which shows humility."", ""The sentiment score is -80 because the review is highly critical of the paper, pointing out major issues such as limited novelty and insufficient attack evaluations. The reviewer states that the paper has 'limited novelty, incremental contributions, and lacks convincing experimental results.' The politeness score is -20 because while the reviewer maintains a professional tone overall, there are instances of blunt criticism. For example, the reviewer directly states that the authors' claim is 'obviously not true' and uses phrases like 'weak attacks' and 'incorrectly implemented.' The review does not use overtly rude language, but it is quite direct and critical without much attempt to soften the negative feedback.""]"
"[""The paper studies the problem of constructing small coreset for SVM.\nA coreset is a small subset of (weighted) points such that the optimal solution for the coreset is also a good approximation for the original point set. The notion of coreset was originally formulated in computational geometry by Agarwal et al.\n(see e.g., [A])\nRecently it has been extended to several clustering problems, linear algebra, and machine learning problems. This paper follows the important sampling approach first proposed in [B], and generalized by Feldman and Langberg. The key in this approach is to compute the sensitivity of points and bound the total sensitivity for the considered problem (this is also true for the present paper). For SVM, the paper presents a bad instance where the total sensitivity can be as bad as 2^d. Nevertheless,\nthe paper presents interesting upper bounds that depending on the optimal value and variance of the point set. The paper argues that in many data sets, the total sensitivity may be small, yielding small coreset. This makes sense and may have significant practical implications.\n\nHowever, I have the following reservation for the paper.\n(1) I don't quite understand the CHICKEN and EGG section. Indeed, it is unclear to me \nhow to estimate the optimal value. The whole paragraph is hand-waving. What is exactly merge-and-reduce? From the proof of theorem 9, it appears that the interior point algorithm is run on the entire dataset, with running time O(n^3d). Then there is no point to compute a coreset as the optimal solution is already known.\n\n(2) The running time of the algorithm is not attractive (in both theory and practice).\nIn fact, the experimental result on the running time is a bit weak. It seems that the algorithm is pretty slow (last in Figure 1). \n\n(3) The theoretical novelty is limited. The paper follows from now-standard technique for constructing coreset.\n\nOveral, I don't recommend acceptance.\n\nminor points:\nIt makes sense to cite the following papers where original ideas on constructing coresets were proposed initially.\n\n[A]Geometric Approximation via Coresets\nPankaj K. Agarwal Sariel Har-Peled Kasturi R. Varadarajan\n\n[B]Universal epsilon-approximators for integrals, by Langberg and Schulman\n\n---------------------------------------------------------\n\nAfter reading the response and the revised text, I understand the chicken-and-egg issue.\nI think the experimental section is still a bit weak (given that there are several very competitive SVM algorithms that the paper didn't compare with).\nI raised my score to 5. \n\n"", 'The paper suggests an importance sampling based Coreset construction for Support Vector Machines (SVM). To understand the results, we need to understand Coreset and importance sampling: \n\nCoreset: In the context of SVMs, a Coreset is a (weighted) subset of given dataset such that for any linear separator, the cost of the separator with respect to the given dataset X is approximately (there is an error parameter \\eps) the same as the cost with respect to the weighted subset. The main idea is that if one can find a small coreset, then finding the optimal separator (maximum margin etc.) over the coreset might be sufficient. Since the computation is done over a small subset of points, one hopes to gain in terms of the running time.\n\nImportance sampling: This is based on the theory developed in Feldman and Langberg, 2011 (and some of the previous works such as Langberg and Schulman 2010, the reference of which is missing). The idea is to define a quantity called sensitivity of a data-point that captures how important this datapoint is with respect to contributing to the cost function. Then a subset of datapoint are sampled based on the sensitivity and the sampled data point is given weight proportional to inverse of the sampling probability. As per the theory developed in these past works, sampling a subset of size proportional to the sum of sensitivities gives a coreset for the given problem.\n\nSo, the main contribution of the paper is to do all the sensitivity calculations with respect to SVM problem and then use the importance sampling theory to obtain bounds on the coreset size. One interesting point of this construction is that Coreset construction involves solving the SVM problem on the given dataset which may seem like beating the purpose. However, the authors note that one only needs to compute the Coreset of small batches of the given dataset and then use standard procedures (available in streaming literature) to combine the Coresets into a single Coreset. This should give significant running time benefits. The paper also compares the results against the simple procedure where a small uniform sample from the dataset is used for computation. \n\n\nEvaluation: \nSignificance: Coresets give significant running time benefits when working with very big datasets. Coreset construction in the context of SVMs is a relevant problem and should be considered significant.\n\nClarity: The paper is reasonably well-written. The problem has been well motivated and all the relevant issues point out for the reader. The theoretical results are clearly stated as lemmas a theorems that one can follow without looking at proofs. \n\nOriginality: The paper uses previously developed theory of importance sampling. However, the sensitivity calculations in the SVM context is new as per my knowledge. It is nice to know the bounds given in the paper and to understand the theoretical conditions under which we can obtain running time benefits using corsets. \n\nQuality: The paper gives nice theoretical bounds in the context of SVMs. One aspect in which the paper is lacking is the empirical analysis. The paper compares the Coreset construction with simple uniform sampling. Since Coreset construction is being sold as a fast alternative to previous methods for training SVMs, it would have been nice to see the running time and cost comparison with other training methods that have been discussed in section 2.\n', ""This paper studies the approach of coreset for SVM. In particular, it aims at sampling a small set of weighted points such that the loss function over these points provably approximates that over the whole dataset. This is done by applying an existing theoretical framework to the SVM training objective.\n\nThe coreset idea has been applied to SVM in existing work, but this paper uses a new theoretical framework. It also provides lower bound on the sample complexity of the framework for general instances and provides upper bound that is data dependent, shedding light on what kind of data this method is suitable for. \n\nThe main concern I have is about the novelty of the coreset idea applied to SVM. Also, there are some minor issues:\n-- Section 4.2: What's the point of building the coreset if you've got the optimal solution? Indeed one can do divide-and-conquer. But can one begin with an approximation solution? In general, the analysis of the coreset should still hold if one begins with an approximation solution. Also, even when doing divide-and-conquer, the solution obtained in the first line of the algorithm should still be approximate. The authors pointed out that Lemma 7 can be extended to this case, and I hope the proof can be written out explicitly.\n-- section 2, paragraph 4: why SGD-based approaches cannot be trivially extended to streaming settings? \n-- Definition 3: what randomness is the probability with respect to? \n-- For experiments: the comparison with CVM should be added.\n""]","[-60, 60, 20]","[20, 80, 60]","[""The sentiment score is -60 because the reviewer does not recommend acceptance and expresses several reservations about the paper. The overall tone is critical, pointing out limitations in theoretical novelty, practical applicability, and experimental results. However, it's not entirely negative as the reviewer acknowledges some interesting aspects of the work. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'I don't quite understand' and 'It makes sense to cite' rather than using harsh or dismissive language. The reviewer also provides constructive feedback and suggestions for improvement, which contributes to the politeness of the review."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the significance of the paper's contribution, its clarity, and originality. They state that the problem is relevant and the paper is 'reasonably well-written'. However, it's not a perfect score as they point out a lack in empirical analysis. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before mentioning areas for improvement. They use phrases like 'It is nice to know' and 'it would have been nice to see', which are constructive and polite ways to suggest improvements."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions, such as applying a new theoretical framework and providing bounds on sample complexity. However, they express concerns about novelty and list some minor issues, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing their concerns as questions or suggestions rather than direct criticisms. They use phrases like 'The main concern I have' and 'I hope' which maintain a polite tone. The reviewer also balances critique with recognition of the paper's merits, contributing to the overall politeness of the review.""]"
"[""The paper describes some interesting work but for a combination of reasons I think it's more like a workshop-track paper.\nThere is not much that's technically new in the paper-- at least not much that's really understandable.   There is some text about a variant of CTC, but it does not explain very clearly what was done or what the motivation was.\nThere are also quite a few misspellings.  \nSince the system is presented without any comparisons to alternatives for any of the individual components, it doesn't really shed any light on the significance of the various modeling decisions that were made.  That limits the value.\nIf rejected from here, it could perhaps be submitted as an ICASSP or Interspeech paper."", 'The paper is interesting, but needs more work, and should provide clear and fair comparisons. Per se, the model is incrementally new, but it is not clear what the strengths are, and the presentations needs to be done more carefully.\n\nIn detail:\n- please fix several typos throughout the manuscript, and have a native speaker (and preferably an ASR expert) proofread the paper\n\nIntroduction\n- please define HMM/GMM model (and other abbreviations that will be introduced later), it cannot be assumed that the reader is familiar with all of them (""ASG"" is used before it is defined, ...)\n- The standard units that most ASR systems use can be called ""senones"", and they are context dependent sub-phonetic units (see http://ssli.ee.washington.edu/~mhwang/), not phonetic states. Also the units that generate the alignment and the units that are trained on an alignment can be different (I can use a system with 10000 states to write alignments for a system with 3000 states) - this needs to be corrected.\n- When introducing CNNs, please also cite Waibel and TDNNs - they are *the same* as 1-d CNNs, and predate them. They have been extended to 2-d later on (Spatio-temporal TDNNs)\n- The most influential deep learning paper here might be Seide, Li, Yu Interspeech 2011 on CD-DNN-HMMs, rather than overview articles\n- Many papers get rid of the HMM pipeline, I would add https://arxiv.org/abs/1408.2873, which predates Deep Speech\n- What is a ""sequence-level variant of CTC""? CTC is a sequence training criterion\n- The reason that Deep Speech 2 is better on noisy test sets is not only the fact they trained on more data, but they also trained on ""noisy"" (matched) data\n- how is this an end-to-end approach if you are using an n-gram language model for decoding? \n\nArchitecture\n- MFSC are log Filterbanks ...\n- 1D CNNs would be TDNNs\n- Figure 2: can you plot the various transition types (normalized, un-normalized, ...) in the plots? not sure if it would help, but it might\n- Maybe provide a reference for HMM/GMM and EM (forward backward training)\n- MMI was also widely used in HMM/GMM systems, not just NN systems\n- the ""blank"" states do *not* model ""garbage"" frames, if one wants to interpret them, they might be said to model ""non-stationary"" frames between CTC ""peaks"", but these are different from silence, garbage, noise, ...\n- what is the relationship of the presented ASG criterion to MMI? the form of equation (3) looks like an MMI criterion to me?\n\nExperiments\n- Many of the previous comments still hold, please proofread\n- you say there is no ""complexity"" incrase when using ""logadd"" - how do you measure this? number of operations? is there an implementation of ""logadd"" that is (absolutely) as fast as ""add""?\n- There is discussion as to what i-vectors model (speaker or environment information) - I would leave out this discussion entirely here, it is enough to mention that other systems use adaptation, and maybe re-run an unadapted baselien for comparsion\n- There are techniques for incremental adaptation and a constrained MLLR (feature adaptation) approaches that are very eficient, if one wnats to get into this\n- it may also be interesting to discuss the role of the language model to see which factors influence system performance\n- some of the other papers might use data augmentation, which would increase noise robustness (did not check, but this might explain some of the results in table 4)\n- I am confused by the references in the caption of Table 3 - surely the Waibel reference is meant to be for TDNNs (and should appear earlier in the paper), while p-norm came later (Povey used it first for ASR, I think) and is related to Maxout\n- can you also compare the training times? \n\nConculsion\n- can you show how your approach is not so computationally expensive as RNN based approaches? either in terms of FLOPS or measured times\n', ""This paper applies gated convolutional neural networks [1] to speech recognition, using the training criterion ASG [2]. It is fair to say that this paper contains almost no novelty.\n\nThis paper starts by bashing the complexity of conventional HMM systems, and states the benefits of their approach. However, all of the other grapheme-based end-to-end systems enjoy the same benefit as CTC and ASG. Prior work along this line includes [3, 4, 5, 6, 7].\n\nUsing MFSC, or more commonly known as log mel filter bank outputs, has been pretty common since [8]. Having a separate subsection (2.1) discussing this seems unnecessary.\n\nArguments in section 2.3 are weak because, again, all other grapheme-based end-to-end systems have the same benefit as CTC and ASG. It is unclear why discriminative training, such as MMI, sMBR, and lattice-free MMI, is mentioned in section 2.3. Discriminative training is not invented to overcome the lack of manual segmentations, and is equally applicable to the case where we have manual segmentations.\n\nThe authors argue that ASG is better than CTC in section 2.3.1 because it does not use the blank symbol and can be faster during decoding. However, once the transition scores are introduced in ASG, the search space becomes quadratic in the number of characters, while CTC is still linear in the number characters. In addition, ASG requires additional forward-backward computation for computing the partition function (second term in eq 3). There is no reason to believe that ASG can be faster than CTC in both training and decoding.\n\nThe connection between ASG, CTC, and marginal log loss has been addressed in [9], and it does make sense to train ASG with the partition function. Otherwise, the objective won't be a proper probability distribution.\n\nThe citation style in section 2.4 seems off. Also see [4] for a great description of how beam search is done in CTC.\n\nDetails about training, such as the optimizer, step size, and batch size, are missing. Does no batching (in section 3.2) means a batch size of one utterance?\n\nIn the last paragraph of section 3.2, why is there a huge difference in real-time factors between the clean and other set? Something is wrong unless the authors are using different beam widths in the two settings.\n\nThe paper can be significantly improved if the authors compare the performance and decoding speed against CTC with the same gated convnet. It would be even better to compare CTC and ASG to seq2seq-based models with the same gated convnet. Similar experiments should be conducted on switchboard and wsj because librespeech is several times larger than switchboard and wsj. None of the comparison in table 4 is really meaningful, because none of the other systems have parameters as many as 19 layers of convolution. Why does CTC fail when trained without the blanks? Is there a way to fix it besides using ASG? It is also unclear why speaker-adaptive training is not needed. At which layer do the features become speaker invariant? Can the system improve further if speaker-adaptive features are used instead of log mels? This paper would be much stronger if the authors can include these experiments and analyses.\n\n[1] R Collobert, C Puhrsch, G Synnaeve, Wav2letter: an end-to-end convnet-based speech recognition system, 2016\n\n[2] Y Dauphin, A Fan, M Auli, D Grangier, Language modeling with gated convolutional nets, 2017\n\n[3] A Graves and N Jaitly, Towards End-to-End Speech Recognition with Recurrent Neural Networks, 2014\n\n[4] A Maas, Z Xie, D Jurafsky, A Ng, Lexicon-Free Conversational Speech Recognition with Neural Networks, 2015\n\n[5] Y Miao, M Gowayyed, F Metze, EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding, 2015\n\n[6] D Bahdanau, J Chorowski, D Serdyuk, P Brakel, Y Bengio, End-to-end attention-based large vocabulary speech recognition, 2016\n\n[7] W Chan, N Jaitly, Q Le, O Vinyals, Listen, attend and spell, 2015\n\n[8] A Graves, A Mohamed, G Hinton, Speech recognition with deep recurrent neural networks, 2013\n\n[9] H Tang, L Lu, L Kong, K Gimpel, K Livescu, C Dyer, N Smith, S Renals, End-to-End Neural Segmental Models for Speech Recognition, 2017""]","[-60, -30, -70]","[20, 20, -20]","[""The sentiment score is -60 because the review is generally negative. The reviewer states that the paper is more suitable for a workshop track, lacks technical novelty, has unclear explanations, contains misspellings, and doesn't provide comparisons to alternatives. The suggestion to submit to other conferences implies rejection. However, it's not entirely negative as the reviewer acknowledges 'some interesting work'. The politeness score is 20 because while the reviewer is critical, they use relatively polite language. They soften criticism with phrases like 'I think' and offer constructive suggestions for improvement and alternative submission venues. The tone is professional and not personally attacking, but also not overtly courteous."", ""The sentiment score is slightly negative (-30) because while the reviewer finds the paper 'interesting', they state it 'needs more work' and point out several areas for improvement. The overall tone suggests the paper is not yet ready for publication in its current form. The politeness score is mildly positive (20) as the reviewer uses polite language like 'please' multiple times and offers constructive feedback rather than harsh criticism. They provide detailed suggestions for improvement in a professional manner. However, some direct statements like 'this needs to be corrected' slightly reduce the politeness score from being higher."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer states the paper 'contains almost no novelty' and criticizes various aspects of the work, including weak arguments, missing details, and lack of meaningful comparisons. The reviewer also suggests numerous improvements, indicating significant dissatisfaction with the current state of the paper. The politeness score is -20 because while the language is not overtly rude, it is quite direct and critical. The reviewer uses phrases like 'bashing the complexity', 'arguments are weak', and 'something is wrong', which come across as somewhat harsh. However, the reviewer does provide constructive feedback and suggestions for improvement, which prevents the score from being lower.""]"
"['The paper puts forward Activation Norm Penalty (""ANR"", an L_2 type regularization on the activations), deriving it from the Information Bottleneck principle. As usual with Information Bottleneck style constructions, the loss takes on a variational form.\n\nThe experiments demonstrate small but consistent gains with ANR across a number of domains (Language modelling on small datasets, plus image classification) and baseline models.\n\nA couple of things that could be improved:\n\n- The abstract claims to ground the ANR in the variational dropout framework. When it is applied without dropout to image classification, shouldn\'t that be explained?\n\n- Maybe dropping the determinant term also deserves some justification.\n\n- Very recently, Activation Regularization by Merity (https://arxiv.org/abs/1708.01009) proposed a similar thing without theoretical justification. Maybe discuss it and the differences (if any) in the related work section?\n\n- The Information Bottleneck section doesn\'t feel like an integral part of the paper.\n\nMy two cents: this work has both theoretical justification (a rare thing these days) and reasonable experimental results.\n\nThere are a number of typos and oversights:\n\n- Abstract: ""variation dropout""\n- Section 2:\n  - x is never used\n  - m in b = m + \\sigma\\epsilon is never defined (is it the x above?)\n- In Section 3.2, equation 11 subscript of x_i is missing\n- Section 6, Ungrammatical sentence: ""Even though L_2 ...""\n', 'This paper tries to create a mapping between activation norm penalties and information bottleneck framework using variational dropout framework. While I find the path taken interesting, the paper itself is hard to follow, mostly due to constantly flipping notation (cons section below lists some of the issues) and other linguistic errors. In the current form, this work is somewhere between a theoretical paper and an empirical one, however for a theoretical one it lacks strictness, while for empirical one - novelty.\n\nFrom theoretical perspective:\nThe main claim in this paper seems to be (10), however it is not formalised in any form of theorem, and so -- lacks a lock of strictness. Even under the assumption that it is updated, and made more strict - what is a crucial problem is a claim, that after arriving at:\ntr[ K(X, X) ] - ln( det[ K(X, X) ] )\ndropping the log determinant is anyhow justified, to keep the reasoning/derivation of the whole method sound. Authors claim that quote ""As for the determinant of the covariance matrix of Gaussian Process, we cannot easily evaluate or\nderive its gradient, so we do not include it in our computation."" Which is not a justification for treating the derivation as a proper connection between penalising activities norm and information bottleneck idea. Terms like this will emerge in many other models, where one assumes diagonal covariance Gaussians; in fact the easiest model to justify this penalty is just to say one introduces diagonal Gaussian prior over activations, and that\'s it. Well justified penalty, easy to connect to many generalisation bound claims. However in the current approach the connection is simply not proven in the paper. \n\nFrom practical perspective:\nActivation norm penalties are well known objects, used for many years (L1 activation penalty for at least 6 years now, see ""Deep Sparse Rectiﬁer Neural Networks""; various activation penalties, including L2, changes in L2, etc. in Krueger PhD dissertation). Consequently for a strong empirical paper I would expect much more baselines, including these proposed by Krueger et al.\n\nPros:\n- empirical improvements shown on two different classes of problems.\n- interesting path through variational dropout is taken to show some equivalences\n\nCons:\n- there is no proper proof of claimed connection between IB and ANP, as it would require a determinant of K(X, X) to be 1.\n- work is not strict enough for a theoretical paper, and does not include enough comparison for empirical one\n- paper is full of typing/formatting/math errors/not well explained objects, which make it hard to read, to name a few:\n * fonts of objects used in equations change through the text - there is a \\textbf{W} and normal W, \\textbf{I} and normal I, similarly with X, Ts etc. without any explanation. I am assuming font are assigned randomly and they represent the same object.\n * dydp in (5) is in the wrong integral\n* \\sigma switches meaning between non-linearity and variance\n* what does it mean to define a normal distribution with 0 variance (like in (1)). Did authors mean  an actual ""degenerate Gaussian"", which does not have a PDF? But then p(y|t) is used in (5), and under such definition it does not exist, only CDF does. \n\n* \\Sigma_1 in 3.2 is undefined, was r(t) supposed to be following N(0, \\Sigma_1)  instead of written N(0, I)?', 'This paper proposes an L2 norm regularization of the output of penultimate layer of the network.  This regularizer is derived based on variational approximation to the information bottleneck objective. \n\nI’m giving this paper a low rating for the following main reasons:\n\n1. The activation norm penalty is derived using an approximation of the information bottleneck Lagrangian term.  However, the approximation in terms of a KL divergence itself contains two terms (Equation 10) and the authors ignore one of those (log-determinant) since it is intractable.  The regularizer is based only on the other term.  Dropping the log-determinant term, thus quality of the resulting regularizer, is not justified at all.  It is just stated that we can not easily evaluate the log-determinant term or its gradient hence it is being dropped.\n\n2. The paper is not very well written, contains errors, undefined symbols and loose sentences, which make it very hard to follow.   For example:\ni) Eq. 1: 0 \\cdot I_N … what is meant by this operation is not stated, also c_n not defined\nii) “The prior of weight vector … with probability p” … not sure what it means to have a Gaussian mixture with probability p.\niii) “q”, “m” not defined in Eq. 2\niv) Eq. 5 seems broken, the last integral has two dydt terms, also the inequalities in that equation seem incorrect.\n\nAuthors show a good gain on two language modeling tasks, CIFAR-10, and CIFAR-100.']","[60, -60, -70]","[70, 20, -20]","[""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting its theoretical justification and reasonable experimental results. The reviewer also offers constructive feedback for improvement, which indicates a favorable but not overwhelmingly positive sentiment. The politeness score is 70 (polite) due to the reviewer's respectful tone throughout. They use phrases like 'could be improved' and 'my two cents,' which are courteous ways to offer suggestions. The reviewer also acknowledges the paper's strengths before pointing out areas for improvement. The list of typos and oversights is presented factually without harsh criticism. Overall, the review maintains a professional and considerate tone while providing both positive feedback and constructive criticism."", ""The sentiment score is -60 because the review is predominantly critical. The reviewer points out numerous issues with the paper, including lack of strictness in theoretical aspects, insufficient novelty for an empirical paper, and multiple errors in notation and explanations. While there are some positive aspects mentioned ('interesting path', 'empirical improvements'), these are outweighed by the criticisms. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'I find the path taken interesting' and provide a balanced view with both 'Pros' and 'Cons' sections. The language is not overtly rude, but rather matter-of-fact in pointing out issues, which is appropriate for a peer review."", ""The sentiment score is -70 because the reviewer explicitly states they are 'giving this paper a low rating' and provides two main reasons for their negative assessment. They criticize the paper's methodology and writing quality, which are fundamental aspects of a scientific paper. The politeness score is -20 because while the reviewer doesn't use overtly rude language, their critique is direct and somewhat harsh. They use phrases like 'not justified at all' and 'very hard to follow,' which come across as slightly impolite in academic discourse. The reviewer also doesn't offer any positive comments or constructive suggestions for improvement, which contributes to the overall negative tone.""]"
"[""The paper addresses the problem of multi-label learning for text corpora and proposes to tackle the problem using tensor factorization methods. Some analysis and experimental results for the proposed algorithm are presented.\n\nQUALITY: I find the quality of the results in this paper rather low. The proposed probabilistic model is defined ambiguously. The authors then look at joint probability distributions of co-occurence of two and three words, which gives a matrix and a tensor, respectively. They propose to match these matrix and tensor to their sample estimates and refer to such procedure as the moment matching method, which it is not. They then apply a standard two step technique from the moment matching literature consisting of whitening and orthogonal tensor factorization. However, in their case this does not have much statistical meaning. Indeed, whitening of the covariance matrix is usually justified by the scaling unidentifiability of the problem. In their case, the mathematics works because of the orthogonal unidentifiability of the square root of a matrix. Furthermore, the proposed sample estimators do not actually estimate densities they are dealing with (see, e.g., Eq. (16) and (17)). Their theoretical analysis seems like a straightforward extension of the analysis by Anandkumar, et al. (2012, 2014), however, I find it difficult to assess this analysis due to numerous ambiguities in the problem formulation and method development. This justifies my statement in the beginning of the paragraph.\n\nCLARITY: The paper is not well written and, therefore, is difficult to assess. Many important details are omitted, the formulation of the model is self contradicting, the standard concepts and notations are sometimes abused, some statements are wrong. I provide some examples in the detailed comment below.\n\nORIGINALITY AND SIGNIFICANCE: The idea to apply tensor factorization approaches to the multi-label learning is novel up to my knowledge and is a pro of the paper. However, I have problems to find other pros in this submission because the clarity is quite low and in the present form there is no novelty in the proposed procedure. Moreover, the authors claim to work with densities, but end up estimating other quantities, which are not guaranteed to have the desirable form. They also emphasize the fact that there is the simplex constraint on the estimated parameters, but this constraint is completely ignored by the algorithm and, in general, won't be satisfied in practice. If think the authors should do some more work before this paper can be published.\n\n\n\nDETAILED COMMENTS: Since I am quite critical about the paper, I point out some examples of drawbacks or flaws of this paper:\n\n  - The proposed model (Section 2) is not well defined. In particular, the description in Section 2 is not sufficient to understand the proposed model; the plate diagram in Figure 2 is not consistent with the text. It is not mentioned how at least some conditional distributions behave (e.g., tokens given labels or states). The diagram in Fig. 1 does not help since it isn't consistent with the text (e.g. the elements of labels or states are not conditionally / independent). The model is very close to latent Dirichlet allocation by Blei, et al. (2003), but differences are not discussed.\n\n  - The standard terminology is often abused. For example, the proposed approach is referred to as the method of moments when it is not. In Section 2.1, the authors aim to match joint distributions (not the moments) to their empirical approximations (which are also wrong; see below). The usage of tokes and documents is interchanged without any explanations.\n\n  - The use of the whitening approach is not justified in their setting working with joint distributions of couples and triples and it has no statistical meaning. No explanation is provided. I would definitely not call this whitening.\n\n  - In Section 2.2, the notation is not defined and is different from what is usually used in the literature. For example, Eq. (15) does not make much sense as is. One could guess from the context that they are talking about the eigenvectors of an orthogonal tensor as defined in, e.g. Anandkumar, et al. (2014).\n\n  - In Section 3, the authors emphasize the fact that their parameters are constrained to the probability simplex, but this constraint is not ensured in the proposed algorithm (Alg. 1).\n\n  - Importantly, the estimators of the matrix M_2 and tensor M_3 do not make much sense to me. For example, for estimating M_2 it would be reasonable to average over all word pairs, i.e. something like [M_2]_{ij} = 1/L \\sum_{w_k \\not = w_l} P(w_k = v_i, w_l = v_j), where L is the number of pairs. This is different from the expression in Eq. (16), which is just a rescaled non-central second moment. Similar issue is true for the order-3 estimator.\n\n  - The factorization procedure does not ensure non-negativity of the obtained parameters and, therefore, the rescaling is not guaranteed to belong to the probability simplex. I could not find any explanations of this issue.\n\n  - I explain good plots in the experimental section, potentially, by the fact that the authors do algorithmically something different from what they aim to do, because the estimators do not estimate the desired entities (i.e. are not consistent). The procedure looks to me quite similar to the procedure for LDA, hence the reasonable results. However, the authors do not justify their proposed method."", 'The paper proposes to learn a latent variable model with spectral algorithm and apply it to multi-label learning. First of all, the connection to multi-label learning is very loose, and the majority of the paper deals with learning the latent variable model. Second, there is almost nothing new in the paper compared to Anandkumar et al 2012, except it uses probability as parameters but not expectations. This difference is trivial since they are only a normalization away. Third, the experiments shows the performance (AUC) compared with other algorithms is significantly worse although the memory consumption may be small.', 'This paper studies the problem of multi-label learning for text copora. The paper proposed a latent variable model for the documents and their labels, and used spectral algorithms to provably learn the parameters.\n\nThe model is fairly simplistic: the topic can be one of k topics (pure topic model), based on the topic, there is a probability distribution over documents, and a probabilistic distribution over labels. The model between document and topic is very similar to previous pure topic models (see more discussions below), and because it is a pure topic, the label is just modeled by a conditional distribution.\n\nThe paper tried to stress that the model is different from Anandkumar et al. because the use of ""expectations vs. probabilities"", but that is only different by a normalization factor. The model defined here is also very strange, especially Equation (2) is not really consistent with Equation (7). \n\nJust to elaborate: in equation (2), the probability of a document is related to the set of distinct words, so it does not distinguish between documents where a word appear multiple times or only once. This is different from the standard bag-of-words model where words are sampled independently and word counts do matter. However, in the calculation before Equation (7), it was trying to compute the probability that a pair of words are equal to v_i and v_j, and it assumed words w_1 and w_2 are independent and both of them satisfy the conditional distribution P[v_i|h = k], this is back to the standard bag-of-words model. To see why these models are different, if it is the model of (2), and we look at only distinct words, the diagonal of the matrix P[v_i,v_i] does not really make sense and certainly will not follow Equation (7). Equation (7) and also (9) only works in the standard bag-of-words model that is also used in Anandkumar et al. (the same equations were also proved).\n\nThe main novelty in this paper is that it uses the label as a third view of a multi-view model and make use of cross moments. The reviewer feels this alone is not enough contribution.']","[-80, -80, -60]","[-20, -20, 20]","[""The sentiment score is -80 because the reviewer expresses strong criticism throughout, stating the quality of results is 'rather low', the paper is 'not well written', and there are 'numerous ambiguities' and 'flaws'. They struggle to find positives beyond the basic idea. The politeness score is -20 as the reviewer is direct in their criticism without using overtly rude language, but also doesn't employ many polite phrases or soften their critique. They use phrases like 'I find it difficult to assess' and 'I have problems to find other pros' which are somewhat blunt. The reviewer does acknowledge one positive aspect ('The idea... is novel') which prevents the scores from being even lower."", ""The sentiment score is -80 because the review is overwhelmingly negative. The reviewer points out multiple significant issues with the paper, including a loose connection to multi-label learning, lack of novelty, and poor performance in experiments. There are no positive comments to balance these criticisms. The politeness score is -20 because while the language is not overtly rude, it is quite blunt and dismissive. The reviewer uses phrases like 'very loose,' 'almost nothing new,' and 'trivial,' which come across as somewhat harsh. The review lacks any softening language or acknowledgment of potential merits, making it seem somewhat impolite in academic context."", ""The sentiment score is -60 because the reviewer expresses several criticisms and doubts about the paper's novelty and consistency. They point out issues with the model's formulation, question its distinctiveness from previous work, and ultimately state that the main contribution is not sufficient. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'The reviewer feels' instead of making blunt statements, and provide detailed explanations for their concerns rather than dismissing the work outright. However, the language is not overtly polite or complimentary, hence the relatively low positive score.""]"
"[""In this paper a neural-network based method for multi-frame video prediction is proposed. It builds on the previous work of [Finn et al. 2016] that uses a neural network to predict transformation parameters of an affine image transformation for future frame prediction, an idea akin to the Spatial Transformer Network paper of [Jaderberg et al., 2015]. What is new compared to [Finn et al. 2016] is that the authors managed to train the network in combination with an adversarial loss, which allows for the generation of more realistic images. Time series modelling is performed via convolutional LSTMs. The authors evaluate their method based on a mechanical turk survey, where humans are asked to judge the realism of the generated images; additionally, they propose to measure prediction quality by the distance between the manually annotated positions of objects within ground truth and predicted frames.\n\nMy main concerns with this paper are novelty, reproducibility and evaluation.\n\n* Novelty. The network design builds heavily on the work of [Finn et al., 2106]. A number of design decisions (such as instance normalization) seem to help yield better results, but are minor contributions. A major contribution is certainly the combination with an adversarial loss, which is a non-trivial task. However, the authors claim that their method is the first to combine multi-frame video prediction with an adversarial loss, which is not true. A recent work, presented at CVPR this year also does multi-frame prediction featuring an adversarial loss and explicitly models and captures the full dense optical flow (though in the latent space) that allows non-trivial motion extrapolation to future frames. This work is neither mentioned in the related work nor compared to. \n \nLu et al. , Flexible Spatio-Temporal Networks for Video Prediction, CVPR 2017\n\nThis recent work builds on another highly relevant work, that is also not mentioned in the paper:\n\nPatraucean et al. Spatio-temporal video autoencoder with differentiable memory, arxiv 2017\n\nSince this is prior state-of-the-art and directly applicable to the problem, a comparison is a must. \n\n* Reproducibility and evaluation\nThe description of the network is quite superficial. Even if the authors released their code used for training (which is not mentioned), I think the authors should aim for a more self-contained exposition. I doubt that a PhD student would be able to reimplement the method and achieve comparable results given the paper at hand only. It is also not mentioned whether the other methods that the authors compare to are re-trained on their newly proposed training dataset. Hence, it remains unclear to what extend the achieved improvements are due to the proposed network design changes or the particular dataset they use for training. The authors also don't show any results on previous datasets, which would allow for a more objective comparison to existing state of the art. Another point of criticism is the way the Amazon Mechanical Turk evaluation was performed. Since only individual images were shown, the evaluation mainly measures the quality of the generated images. Since the authors combine their method with a GAN, it is not surprising that the generated images look more realistic. However, since the task is *video* prediction, it seems more natural to show small video snippets rather than individual images, which would also evaluate temporal consistency.\n\n* Further comments:\nThe paper contains a number of broken sentences, typos and requires a considerable amount of polishing prior to publication.\n"", 'This paper is concerned with video prediction, for use in robotic motion planning. The task is performed on tabletop videos of a robotic arm manipulator interacting with various small objects. They use a prior model proposed in Finn et al. 2016, make several incremental architectural improvements, and use an adversarial loss function instead of an L2 loss. They also propose a new metric, motion accuracy, which uses the accuracy of the predicted position of the object instead of conventional metrics like PSNR, which is more relevant for robotic motion planning.\n\nThey obtain significant quantitative improvements over the previous 2 papers in this domain (video prediction on tabletop with robotic arm and objects) on both type of metrics - image assessment and motion accuracy. They also evaluate realism images using AMT fooling - asking turks to chose the fake between between real and generated images, and obtain substantial improvements on this metric as well. \n\nA major point of concern is that they do not use the public dataset proposed in Finn et al. 2016, but use their own (smaller) dataset. They do not mention whether they train the previous methods on the new dataset, and some of their reported improvements may be because of this. They also do not report results on unseen objects, when occlusions are present, and on human motion video prediction, unlike the other papers.\n\nThe adversarial loss helps significantly only with AMT fooling or realism of images, as expected because GANs produce sharp images rather than distributions, and is not very relevant for robot motion planning. The incremental architectural changes, different dataset and training are responsible for most of the other improvements.', ""This is a fine paper that generally reads as a new episode in a series on motion-based video prediction with an eye towards robotic manipulation [Finn et al. 2016, Finn and Levine 2017, Ebert et al. 2017]. The work is rather incremental but is competently executed. It is in line with current trends in the research community and is a good fit for ICLR. The paper is well-written, reasonably scholarly, and contains stimulating insights.\n\nI recommend acceptance, despite some reservations. My chief criticism is a matter of research style: instead of this deluge of barely distinguishable least-publishable-unit papers on the same topic, in every single conference, I wish the authors didn’t slice so thinly, devoted more time to each paper, and served up a more substantial dish.\n\nSome more detailed comments:\n\n- The argument for evaluating visual realism never quite gels and is not convincing. The paper advocates two primary metrics: accuracy of the predicted motion and perceptual realism of the synthesized images. The argument for motion accuracy is clear and is clearly stated: it’s the measure that is actually tied to the intended application, which is using action-conditional motion prediction for control. A corresponding argument for perceptual realism is missing. Indeed, a skeptical reviewer may suspect that the authors needed to add perceptual realism to the evaluation because that’s the only thing that justifies the adversarial loss. The adversarial loss is presented as the central conceptual contribution of the paper, but doesn’t actually make a difference in terms of task-relevant metrics. A skeptical perspective on the paper is that the adversarial loss just makes the images look prettier but makes no difference in terms of task performance (control). This is an informative negative result. It's not how the paper is written, though.\n\n- The “no adversary”/“no adv” condition in Table 1 and Figure 4 is misleading. It’s not properly controlled. It is not the case that the adversarial loss was simply removed. The regression loss was also changed from l_1 to l_2. This is not right. The motivation for this control is to evaluate the impact of the adversarial loss, which is presented as the key conceptual contribution of the paper. It should be a proper control. The other loss should remain what it is in the full “Ours” condition (i.e., l_1).\n\n- The last sentence in the caption of Table 1 -- “Slight improvement in motion is observed by training with an adversary as well” -- should be removed. The improvement is in the noise.\n\n- Generally, the quantitative impact of the adversarial loss never comes together. The only statistically significant improvement is on perceptual image realism. The relevance of perceptual image realism to the intended task (control) is not substantiated, as discussed earlier.\n\n- In the perceptual evaluation procedure, the “1 second” restriction is artificial and makes the evaluated methods appear better than they are. If we are serious about evaluating image realism and working towards passing the visual Turing test, we should report results without an artificial time limit. They won’t look as flattering, but will properly report our progress on this journey. If desired, the results of timed comparisons can also be reported, but reporting just a timed comparison with an artificial limit of 1 second may mislead some readers into thinking that we are farther along than we actually are.\n\n\nThere are some broken sentences that mar an otherwise well-written paper:\n\n- End of Section 1, “producing use a learned discriminator and show improvements in visual quality”\n\n- Beginning of Section 3, “We first present the our overall network architecture”\n\n- page 4, “to choose to copy pixels from the previous frame, used transformed versions of the previous frame”\n\n- page 4, “convolving in the input image with”\n\n- page 5, “is know to produce”\n\n- page 5, “an additional indicating”\n\n- page 5, “Adam Kingma & Ba (2015)” (use the other cite command)\n\n- page 5, “we observes”\n\n- page 5, “smaller batch sizes degrades”\n\n- page 5, “larger batch sizes provides”\n"", '\n1) Summary\nThis paper proposes a flow-based neural network architecture and adversarial training for multi-step video prediction. The neural network in charge of predicting the next frame in a video implicitly generates flow that is used to transform the previously observed frame into the next. Additionally, this paper proposes a new quantitative evaluation criteria based on the observed flow in the prediction in comparison to the groundtruth. Experiments are performed on a new robot arm dataset proposed in the paper where they outperform the used baselines.\n\n\n2) Pros:\n+ New quantitative evaluation criteria based on motion accuracy.\n+ New dataset for robot arm pushing objects.\n\n3) Cons:\nOverall architectural prediction network differences with baseline are unclear:\nThe differences between the proposed prediction network and [1] seem very minimal. In Figure 3, it is mentioned that the network uses a U-Net with recurrent connections. This seems like a very minimal change in the overall architecture proposed. Additionally, there is a paragraph of “architecture improvements” which also are minimal changes. Based on the title of section 3, it seems that there is a novelty on the “prediction with flow” part of this method. If this is a fact, there is no equation describing how this flow is computed. However, if this “flow” is computed the same way [1]  does it, then the title is misleading.\n\n\nAdversarial training objective alone is not new as claimed by the authors:\nThe adversarial objective used in this paper is not new. Works such as [2,3] have used this objective function for single step and multi-step frame prediction training, respectively. If the authors refer to the objective being new in the sense of using it with an action conditioned video prediction network, then this is again an extremely minimal contribution. Essentially, the authors just took the previously used objective function and used it with a different network. If the authors feel otherwise, please comment on why this is the case.\n\n\nIncomplete experiments:\nThe authors only show experiments on videos containing objects that have already been seen, but no experiments with objects never seen before. The missing experiment concerns me in the sense that the network could just be memorizing previously seen objects. Additionally, the authors present evaluation based on PSNR and SSIM on the overall predicted video, but not in a per-step paradigm. However, the authors show this per-step evaluation in the Amazon Mechanical Turk, and predicted object position evaluations.\n\n\nUnclear evaluation:\nThe way the Amazon Mechanical Turk experiments are performed are unclear and/or not suited for the task at hand.\nBased on the explanation of how these experiments are performed, the authors show individual images to mechanical turkers. If we are evaluating the video prediction task for having real or fake looking videos, the turkers need to observe the full video and judge based on that. If we are just showing images, then they are evaluating image synthesis, which do not necessarily contain the desired properties in videos such as temporal coherence.\n\n\nAdditional comments:\nThe paper needs a considerable amount of polishing.\n\n\n4) Conclusion:\nThis paper seems to contain very minimal changes in comparison to the baseline by [1]. The adversarial objective is not novel as mentioned by the authors and has been used in [2,3]. Evaluation is unclear and incomplete.\n\n\nReferences:\n[1] Chelsea Finn, Ian Goodfellow, and Sergey Levine. Unsupervised learning for physical interaction through video prediction. In NIPS, 2016.\n[2] M. Mathieu, C. Couprie, and Y. LeCun. Deep multi-scale video prediction beyond mean square error. In ICLR, 2016.\n[3] Ruben Villegas, Jimei Yang, Seunghoon Hong, Xunyu Lin, Honglak Lee. Decomposing Motion and Content for Natural Video Sequence Prediction. In ICLR, 2017\n']","[-50, 50, 20, -60]","[20, 20, 50, 20]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'A major contribution is certainly the combination with an adversarial loss'), they express significant concerns about novelty, reproducibility, and evaluation. The review is predominantly critical, pointing out several shortcomings and areas for improvement. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'My main concerns' and 'Another point of criticism' rather than harsh language. They also offer constructive feedback and suggestions for improvement. However, the overall critical nature of the review prevents a higher politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges significant quantitative improvements and substantial improvements in AMT fooling. However, they also express concerns about the dataset used and some limitations in the study's scope. The politeness score is 20 (slightly polite) as the reviewer uses neutral language throughout, presenting both positive aspects and concerns in a professional manner without using overly harsh or complimentary language. The reviewer objectively states their observations and concerns without using emotionally charged words or personal attacks, maintaining a respectful tone while providing constructive feedback."", ""The sentiment score is slightly positive (20) because the reviewer recommends acceptance and describes the paper as 'fine', 'competently executed', and 'well-written'. However, they also express reservations and criticisms, which temper the positivity. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without being harsh. They balance positive comments with areas for improvement. The reviewer maintains a professional tone, even when pointing out flaws, using phrases like 'I wish' and 'A skeptical perspective' rather than direct accusations. The detailed comments are presented as suggestions rather than demands, further contributing to the polite tone."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several significant issues with the paper, including minimal architectural differences from baseline, lack of novelty in the adversarial training objective, incomplete experiments, and unclear evaluation. The conclusion states that the paper contains 'very minimal changes' and that the evaluation is 'unclear and incomplete'. However, the reviewer does acknowledge some positive aspects (new evaluation criteria and dataset), which prevents the score from being even lower. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'please comment' and 'if the authors feel otherwise', which show respect. The reviewer also organizes their thoughts clearly with pros and cons sections, which is helpful. However, some statements are quite blunt (e.g., 'The paper needs a considerable amount of polishing'), which prevents a higher politeness score.""]"
"[""Science is about reproducible results and it is very commendable from scientists to hold their peers accountable for their work by verifying their results. It is also necessary to inspect claims that are made by researchers to avoid the community straying in the wrong direction. However, any critique needs to be done properly, by 1) attending to the actual claims that were made in the first place, by 2) reproducing the results in the same way as in the original work, 3) by avoiding introducing false claims based on a misunderstanding of terminology and 4) by extensively researching the literature before trying to affirm that a general method (here, Deep RL) cannot solve certain tasks.\n\nThis paper is a critique of deep reinforcement learning methods for learning to navigate in 3D environments, and seems to focus intensively on one specific paper (Mirowski et al, 2016, “Learning to Navigate in Complex Environments”) and one of the architectures (NavA3C+D1D2L) from that paper. It conducts an extensive assessment of the methods in the critiqued paper but does not introduce any alternative method. For this reason, I had to carefully re-read the critiqued paper to be able to assess the validity of the arguments made in this submission and to evaluate its merit from the point of view of the quality of the critique. The (Mirowski et al, 2016) paper shows that a neural network-based agent with LSTM-based memory and auxiliary tasks such as depth map prediction can learn to navigate in fixed environments (3D mazes) with a fixed goal position (what they call “static maze”), and in fixed mazes with changing goal environments (what they call “environments with dynamic elements” or “random goal mazes”).\n\nThis submission claims that:\n[a] “[based on the critiqued paper] one might assume that DRL-based algorithms are able to 'learn to navigate' and are thus ready to replace classical mapping and path-planning algorithms”,\n[b] “following training and testing on constant map structures, when trained and tested on the same maps, [the NavA3C+D1D2L algorithm] is able to choose the shorter paths to the goal”,\n[c] “when tested on unseen maps the algorithm utilizes a wall-following strategy to find the goal without doing any mapping or path planning”,\n[d] “this state-of-the-art result is shown to be successful on only one map, which brings into question the repeatability of the results”,\n[e] “Do DRL-based navigation algorithms really 'learn to navigate'? Our results answer this question negatively.”\n[f] “we are the first to evaluate any DRL-based navigation method on maps with unseen structures”\n\nThe paper also conducts an extensive analysis of the performance of a different version of the NavA3C+D1D2L algorithm (without velocity inputs, which probably makes learning path integration much more difficult), in the same environments but by introducing unjustified changes (e.g., with constant velocities and a different action space) and with a different reward structure (incorporating a negative reward for wall collisions). While the experimental setup does not match (Mirowski et al, 2016), thereby invalidating claim [d], the experiments are thorough and do show that that architecture does not generalize to unseen mazes. The use of attention heat maps is interesting.\n\nThe main problem however is that it seems that this submission completely misrepresents the intent of (Mirowski et al, 2016) by using a straw man argument, and makes a rather unacademic and unsubstantiated accusation of lack of repeatability of the results.\n\nRegarding the former, I could not find any claim that the methods in (Mirowski et al, 2017) learn mapping and path planning in unseen environments, that could support claim [a]. More worryingly, when observing that the method of (Mirowski et al, 2017) may not generalize to unseen environments in claim [c], the authors of this submission seem to confuse navigation, cartography and SLAM, and attribute to that work claims that were never made in the first place, using a straw man argument. Navigation is commonly defined as the goal driven control of an agent, following localization, and is a broad skill that involves the determination of position and direction, with or without a map of the environment (Fox 1998, ” Markov Localization: A Probabilistic Framework for Mobile Robot Localization and Navigation”). This widely accepted definition of navigation does not preclude being limited to known environments only.\n\nRegarding repeatability, the claim [d] is contradicted in section 5 when the authors demonstrate that the NavA3C+D1D2L algorithm does achieve a reduction in latency to goal in 8 out of 10 experiments on random goal, static map and random or static spawns. The experiments in section 5.3 are conducted in simple but previously unseen maps and cannot logically contradict results (Mirowski et al, 2016) achieved by training on static maps such as their “I-maze”. Moreover, claim [d] about repeatability is also invalidated by the fact that\xa0the experiments described in the paper use different observations (no velocity inputs), different action space, different reward structure, with no empirical evidence to support these changes. It seems, as the authors also claim in [b], that the work of (Mirowski et al, 2017), which was about navigation in known environments, actually is repeatable.\n\nAdditionally, some statements made by the authors are demonstrably untrue. First, the authors claim that they are the first to train DRL agents in all random mazes [f], but this has been already shown in at least two publications (Mnih et al, 2016 and Jaderberg et al, 2016).\n\nSecond, the title of the submission, “Do Deep Reinforcement Learning Algorithms Really Learn to Navigate” makes a broad statement [e] that cannot be logically invalidated by only one particular set of experiments on a particular model and environment, particularly since it directly targets one specific paper (out of several recent papers that have addressed navigation) and one specific architecture from that paper, NavA3C+D1D2L (incidentally, not the best-performing one, according to table 1 in that paper). Why did the authors not cite and consider (Parisotto et al, 2017, “Neural Map: Structured Memory for Deep Reinforcement Learning”), which explicitly claims that their method is “capable of generalizing to environments that were not seen during training”? It seems that the authors need to revise both their bibliography and their logical reasoning: one cannot invalidate a broad set of algorithms for a broad goal, simply by taking a specific example and showing that it does not fit a particular interpretation of navigation *in previously unseen environments*.\n"", ""This paper proposes to re-evaluate some of the methods presented in a previous paper with a somewhat more general evaluation method. \n\nThe previous paper (Mirowski et al. 2016) introduced a deep RL agent with auxiliary losses that facilitates learning in navigation environments, where the tasks were to go from a location to another in a first person viewed fixed 3d maze, with the starting and goal locations being either fixed or random. This proposed paper rejects some of the claims that were made in Mirowski et al. 2016, mainly the capacity of the deep RL agent to learn to navigate in such environments. \n\nThe proposed refutation is based on the following experiments:\n- an agent trained on random maps does much worse on fixed random maps that an agent trained on the same maps its being evaluated on (figure 4)\n- when an agent is trained on fixed number of random map, its performance on random unseen maps doesn't increase with the number of training maps beyond ~100 maps. (figure 5). The authors argue that the reason for those diminishing returns is that the agent is actually learning a trivial wall following strategy that doesn't benefit from more maps.\n- when evaluated on hand designed small maps, the agent doesn't perform very well (figure 6).\n\nThere is addition experimental data reported which I didn't find very conclusive nor relevant to the analysis, particularly the attention heat map and the effect of apples and texture.\n\nI don't think any of the experiments reported actually refute any of the original paper's claim. All of the reported results are what you would expect. It boils down to these simple commonly known facts about deep RL agents:\n- When evaluated outside of its training distribution, it might not generalized very well (figure 4/6)\n- It has a limited capacity so if the distribution of environments is too large, its performance will plateau (figure 5). By the way to me results presented in figure 5 are not enough to claim that the agent trained on random map is implementing a purely reactive wall-following strategy. In fact, an interesting experiment here would have been to do ablation studies e.g. by replacing the LSTM with a feed forward fully connected network. To me the reported performance plateau with number of map size is normal expected behavior, only symptomatic that this deep RL agent has finite capacity.\n\nI think this paper does not provide compelling pieces of evidence of unexpected pathological behavior in the previous paper, and also does not provide any insight of how to improve upon and address the obvious limitations of previous work. I therefore recommend not to accept this paper in its current form."", ""The paper evaluates one proposed Deep RL-based model (Mirowski et al. 2016) on its ability to generally navigate. This evaluation includes training the agent on a set of training mazes and testing it's performance on a set of held-out test mazes. Evaluation metrics include repeated latency to the goal and comparison to the shortest route. Although there are some (minor) differences between the implementation with Mirowski et al. 2016, I believe the conclusions made by the authors are mostly valid. \n\nI would firstly like to point out that measuring generalization is not standard practice in RL. Recent successes in Deep RL--including Atari and AlphaGo all train and test on exactly the same environment (except for random starts in Atari and no two games of Go being the same). Arguably, the goal of RL algorithms is to learn to exploit their environment as quickly as possible in order to attain the highest reward. However, when RL is applied to navigation problems it is tempting to evaluate the agent on unseen maps in order to assess weather the agent has learned a generic mapping & planning policy. In the case of Mirowski et al. this means that the LSTM has somehow learned to do general SLAM in a meta-learning sense. To the best of my knowledge, Mirowski et al. never made such a bold claim (despite the title of their paper). \n\nSecondly, there seems to be a big disconnect between attaining a high score in navigation tasks and perfectly solving them by doing general SLAM & optimal path planning. Clearly if the agent receives the maximal possible reward for a well designed navigation task it must, by definition, be doing perfect SLAM & path planning. However at less than optimal performance the reward fails to quality  the agent's ability to do SLAM. The relationship between reward and ability to do general SLAM is not clear. Therefore it is my opinion that reinforcement learning approaches to SLAM lack a concrete goal in what they are trying to show. \n\nMinor points: Section 5.3 Square map: how much more reward will the agent gain by taking the optimal path? Perhaps not that much? Wrench map: the fact that the paths taken by the agent are not distributed evenly makes me suspicious. Could the authors generate many wrench maps (same topology, random size, random wall textures) to make sure there is no bias? ""]","[-60, -70, 20]","[20, 20, 60]","[""The sentiment score is -60 because the reviewer is largely critical of the paper, pointing out numerous flaws in methodology, logic, and claims. They state that the paper misrepresents previous work, makes unsubstantiated accusations, and contains demonstrably untrue statements. However, it's not entirely negative as the reviewer acknowledges some positive aspects, such as thorough experiments and interesting use of attention heat maps. The politeness score is 20 because while the reviewer is direct in their criticism, they maintain a professional tone throughout. They use phrases like 'The main problem however is...' and 'It seems that...' which soften the critique. The reviewer also acknowledges positive aspects of the work, showing a balanced approach. However, some statements are quite direct, such as 'statements made by the authors are demonstrably untrue,' which prevents a higher politeness score."", ""The sentiment score is -70 because the reviewer expresses strong disagreement with the paper's claims and recommends not accepting it. They state that the paper doesn't refute the original claims, doesn't provide compelling evidence, and lacks insights for improvement. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I don't think' and 'I therefore recommend' rather than harsh language. They also acknowledge some aspects of the paper, such as 'There is additional experimental data reported,' before critiquing it. However, the overall tone is more neutral than overtly polite, hence the relatively low positive score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the validity of the authors' conclusions and recognizes the novelty of evaluating generalization in RL. However, they also express some reservations about the approach and its goals. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'I would firstly like to point out...'), and offers suggestions for improvement. The reviewer also acknowledges the authors' efforts and the challenges in the field. The language is professional and courteous, avoiding harsh or dismissive statements.""]"
"[""This paper proposes to optimize neural networks considering the three different terms: original loss function, quantization error and the sum of bits. While the idea makes sense, the paper is not well executed, and I cannot understanding how gradient descend is performed based on the description of Section 4.\n\n1. After equation (5), I don't understand how the gradient of L(tilde_W) w.r.t. B(i) is computed. B(i) is discrete. The update rule seems to be clearly wrong.\n2. The experimental section of this paper needs improvement.\n   a. End-to-end trained quantized networks have been studied in various previous works including stochastic neuron (Bengio et al 2013), quantization + fine tuning (Wu et al 2016 Quantized Convolutional Neural Networks for Mobile Devices), Binary connect (Courbariaux et al 2016) etc. None of these works have been compared with.\n   b. All the baseline methods use 8 bits per value. This choice is quite ad-hoc.\n   c. Only MNIST and CIFAR10 dataset with Lenet32 are used in the experiment. I find the findings not conclusive based on these.\n   d. No wall-time and real memory numbers are reported."", 'This paper proposes a direct way to learn low-bit neural nets. The idea is introduced clearly and rather straightforward.\n\npros:\n(1) The idea is introduced clearly and rather straightforward.\n(2) The introduction and related work are well written.\n\ncons:\nThe provided experiments are weak to demonstrate the effectiveness of the proposed method.\n(1) only small networks on relatively small datasets are tested.\n(2) the results on MNIST and CIFAR 10 are not good enough for practical deployment.', ""The paper proposes a technique for training quantized neural networks, where the precision (number of bits) varies per layer and is learned in an end-to-end fashion. The idea is to add two terms to the loss, one representing quantization error, and the other representing the number of discrete values the quantization can support (or alternatively the number of bits used). Updates are made to the parameter representing the # of bits via the sign of its gradient. Experiments are conducted using a LeNet-inspired architecture on MNIST and CIFAR10.\n\nOverall, the idea is interesting, as providing an end-to-end trainable technique for distributing the precision across layers of a network would indeed be quite useful. I have a few concerns: First, I find the discussion around the training methodology insufficient. Inherently, the objective is discontinuous since # of bits is a discrete parameter. This is worked around by updating the parameter using the sign of its gradient. This is assuming the local linear approximation given by the derivative is accurate enough one integer away; this may or may not be true, but it's not clear and there is little discussion of whether this is reasonable to assume.\n\nIt's also difficult for me to understand how this interacts with the other terms in the objective (quantization error and loss). We'd like the number of bits parameter to trade off between accuracy (at least in terms of quantization error, and ideally overall loss as well) and precision. But it's not at all clear that the gradient of either the loss or the quantization error w.r.t. the number of bits will in general suggest increasing the number of bit (thus requiring the bit regularization term). This will clearly not be the case when the continuous weights coincide with the quantized values for the current bit setting. More generally, the direction of the gradient will be highly dependent on the specific setting of the current weights. It's unclear to me how effectively accuracy and precision are balanced by this training strategy, and there isn't any discussion of this point either.\n\nI would be less concerned about the above points if I found the experiments compelling. Unfortunately, although I am quite sympathetic to the argument that state of the art results or architectures aren't necessary for a paper of this kind, the results on MNIST and CIFAR10 are so poor that they give me some concern about how the training was performed and whether the results are meaningful. Performance on MNIST in the 7-11% test error range is comparable to a simple linear logistic regression model; for a CNN that is extremely bad. Similarly, 40% error on CIFAR10 is worse than what some very simple fully connected models can achieve.\n\nOverall, while I like the and think the goal is good, I think the motivation and discussion for the training methodology is insufficient, and the empirical work is concerning. I can't recommend acceptance. ""]","[-60, -20, -60]","[20, 50, 50]","[""The sentiment score is -60 because the review is predominantly negative. The reviewer states that the paper is 'not well executed' and expresses confusion about key aspects of the methodology. They also point out several shortcomings in the experimental section. However, it's not entirely negative as they acknowledge that 'the idea makes sense'. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They use phrases like 'I don't understand' and 'I find the findings not conclusive' rather than making harsh personal judgments. The reviewer also provides specific, constructive feedback for improvement, which is a polite approach to criticism in academic contexts."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('pros'), they also highlight significant weaknesses ('cons') in the experimental results. The criticism outweighs the praise, particularly noting that the results are 'not good enough for practical deployment'. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents both pros and cons in a balanced manner. They avoid harsh criticism and use phrases like 'rather straightforward' and 'well written', which contribute to a polite tone. However, the directness in pointing out the weaknesses prevents it from being extremely polite."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's methodology and results. While they find the idea interesting, they highlight several issues with the training methodology and are particularly concerned about the poor experimental results. The reviewer ultimately cannot recommend acceptance, which indicates a negative sentiment overall. However, it's not entirely negative as they do acknowledge the potential value of the idea.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I find,' 'It's difficult for me to understand,' and 'I would be less concerned' which soften their criticisms. They also acknowledge positive aspects, such as finding the idea interesting and being sympathetic to the argument about not needing state-of-the-art results. However, the score is not higher because the criticism, while politely phrased, is quite direct and substantial.""]"
"['The authors proposed a convolutional framework based on merging ego-networks. It combines graph embedding layers with task driven output layers, producing interpretable results for critical structure detection. While based on existing embedding methods such as Patchy-San, the contribution of ego-centric convolution and multi-layer architechture is novel and has a lot of potential in applications. The overall presentation of the draft is also of high quality. I recommend its publication at ICLR.\n\nHere is a list of suggested changes to further improve the draft,\n\n1. The two panels of Figure 1 seems redundant.\n\n2. Figure 4 does not provide useful information, especially in terms of how overlapping neighborhoods are aggregated at deeper layers.\n\n3. There seems to be a mistake in Figure 5 with the top neighborhood in white\n\n4. The connection between weight-tying and scale-free structure needs better explanation. Are the authors trying to say that fractal processes generates power-law degree distributions?\n\n5. The visualization of critical structures are very helpful. However, it might be better to look into structures in high level layers for truly global signatures. This is especially the case for the reddit dataset, where visualizations at the node and edge level creates hairballs.\n\n', 'Dear authors,\n\nThank you for your contribution to ICLR. The problem you are addressing with your work is important. Your paper is well-motivated. Detecting and exploiting ""critical structures"" in graphs for graph classification is indeed something that is missing in previous work. \n\nAfter the introduction you discuss some related work. While I really appreciate the effort you put into this section (including the figures etc.) there are several inaccuracies in the portrayal of existing methods. Especially the comparison to Patchy-san is somewhat vague. Please make sure that you clearly state the differences between patchy-san and Ego-CNNs. What exactly is it that Patchy cannot achieve that you can. I believe I understood what the advantages of the proposed method are but it took a while to get there. Just one example to show you what I mean; you write:\n\n""The reason why the idea of Patchy-San fails to generalize into multiple layers is that its definition of\nneighborhood, which is based on adjacency matrix, is not static and may not corresponding to local\nregions in the graph. ""\n\nIt is very difficult to understand what it is that you want to express with the above sentence. Its definition of neighborhood is based on adjacency matrix - what does that mean? A neighborhood is a set of nodes, no? Why is it that their definition of neighborhood might not correspond to local regions? In general, you should try to be more precise and concise when discussing related work. \n\nSection 3, the most important section in the paper that describes the proposed Ego-CNN approach, should also be written more clearly. For instance, it would be good if you could define the notion of an ""Ego-Convolution layer."" You use that term without properly defining it and it is difficult to make sense of the approach without understanding it. Also, you contrast your approach with patchy and write that ""Our main idea is to use the egocentric design, i.e. the neighborhood at next\nlayer is defined on the same node."" Unfortunately, I find it difficult to understand what this means. In general, this section is very verbose and needs a lot more work. This is at the moment also the crucial shortcoming of the paper. You should spent more time on section 3 and formally and more didactically introduce your approach. In my opinion, without a substantial improvement of this section, the paper should not be accepted. \n\nThe experiments are standard and compare to numerous existing state of the art methods. The data sets are also rather standard. The one thing I would add to the results are the standard deviations. It is common to report those. Also, in the learning for graph structured data, the variance can be quite high and providing the stddev would at least indicate how significant the improvements are. \n\nI also like the visualizations and the discussion of the critical structures found in some of the graphs.\n\nOverall, I think this is an interesting paper that has a lot of potential. The problem, however, is that the presentation of the proposed approach is verbose and partially incomprehensible. What exactly is different to existing approaches? What exactly is the formal definition of the method? All of this is not well presented and, in my opinion, requires another round of editing and reviews.\n\n', 'The paper proposes a new method (Ego-CNN) to compute supervised embeddings of graphs based on the neighborhood structure of nodes. Using an approach similar to attention and deconvolution, the paper also aims to detect substructures in graphs that are important for a given supervised task.\n\nLearning graph representations is an important task and fits well into ICLR. The paper pursues interesting ideas and shows promising experimental results. I\'ve also found the focus of the paper on interpretability (by detecting important substructures) interesting and promising. However, in its current form, I am concerned about both the novelty and the clarity of the paper.\n\nRegarding novelty: The general idea of Ego-CNN seems to be quite closely related to the model of Kipf and Welling [2]. Unfortunately, this connection is neither made clear in the discussion of related work, nor does the experimental evaluation include a comparison. In particular, the paper mentions that Ego-CNN is similar to the Weißfeiler-Lehman (WL) algorithm. However, the same is the case for [2] (see Appendix A in [2] for a discussion). It would therefore be important to discuss the benefits of Ego-CNN over [2] clearly, especially since [2] is arguably simpler and doesn\'t require a fixed-size neighborhood.\n\nRegarding clarity: In general, the paper would greatly benefit from a clearer discussion of methods and results. For instance,\n- The paper lacks a complete formal definition of the model.\n- Detecting critical substructures is an explicit focus of the paper. However, Section 4.1 provides only a very short description of the proposed approach and lacks again any formal definition. Similarly, the experimental results in Section 5.3 require a deeper analysis of the detected substructures as the presented examples are mostly anecdotal. For instance, quantitative results on synthetic graphs (where the critical substructures are known) would improve this section.\n- The discussion of scale-free regularization in Section 4.2 is very hand-wavy. It lacks again any formal proof that the proposed approach exploits scale-free structures or even a proper motivation why this regularization should improve results. Furthermore, the experimental results in Section 5.2 are only evaluated on a single dataset and it is difficult to say whether the improvement gains are due to some scale-free property of the model. For instance, the improvement could also just stem from the different architecture and/or decreased overfitting due to the decreased number of parameters from weight-tying.\n \nFurther comments:\n- The discussion of related work is sometimes unclear. For instance, precisely why can\'t Neural Fingerprint detect critical structures? Similarly, how is the k-node neighborhood constraint of Patchy-San different than the one of Ego-CNN?\n- In graph theory, the standard notion of neighborhood are all nodes adjacent to a given node, e.g., see [1]\n- The writing could be improved, since I found some passages difficult to read due to typos and sentence structure.\n\n[1] https://en.wikipedia.org/wiki/Neighbourhood_(graph_theory)\n[2] Kipf et al. ""Semi-supervised classification with graph convolutional"", 2017.']","[80, -20, -20]","[70, 60, 60]","[""The sentiment score is 80 (positive) because the reviewer recommends publication and describes the work as having 'a lot of potential' and being of 'high quality'. The overall tone is very supportive. The politeness score is 70 (polite) due to the constructive nature of the feedback and the use of phrases like 'suggested changes' and 'to further improve'. The reviewer provides specific, actionable feedback without harsh criticism. The language is professional and respectful throughout, maintaining a positive tone even when pointing out potential issues."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the work and its potential, they express significant concerns about the clarity and presentation of the method. The reviewer states that 'without a substantial improvement of this section, the paper should not be accepted,' indicating a negative sentiment towards the current state of the paper. However, they also mention positive aspects like the well-motivated problem and good visualizations, which prevents the score from being more negative. The politeness score is moderately positive (60) as the reviewer uses polite language throughout, starting with 'Thank you for your contribution' and using phrases like 'I really appreciate the effort.' They provide constructive criticism and suggestions for improvement rather than harsh criticism. The tone is professional and respectful, even when pointing out shortcomings."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting ideas', 'promising experimental results'), they express significant concerns about novelty and clarity. The reviewer states they are 'concerned about both the novelty and the clarity of the paper' and provides several critiques. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positives before presenting criticisms, and phrases concerns as suggestions for improvement rather than harsh criticisms. They use polite phrases like 'The paper would greatly benefit from...' and 'It would therefore be important to...'. The reviewer maintains a professional and constructive tone, even when pointing out shortcomings.""]"
"[""This paper experiments the application of NAS to some natural language processing tasks : machine translation and question answering.  \n\nMy main concern about this paper is its contribution. The difference with the paper of Zoph 2017 is really slight in terms of methodology. Moving from a language modeling task to machine translation is not very impressive neither really discussed. It could be interesting to change the NAS approach by taking into account this application shift.  \n\nOn the experimental part, the paper is not really convincing. The results on WMT are not state of the art. The best system of this year was a standard phrase based and has achieved 29.3 BLEU score (for BLEU cased, otherwise it's one point more). Therefore the results on mt tasks are difficult to interpret. \n\nAt the end , the reader can be sure these experiments required a significant computational power. Beyond that it is difficult to really draw meaningful conclusions. "", 'This paper proposes a method to find an effective structure of RNNs and attention mechanisms by searching programs over the stack-oriented execution engine.\n\nAlthough the new point in this paper looks only the representation paradigm of each program: (possibly variable length) list of the function applications, that could be a flexible framework to find a function without any prior structures like Fig.1-left.\n\nHowever, the design of the execution engine looks not well-designed. E.g., authors described that the engine ignores the binary operations that could not be executed at the time. But in my thought, such operations should not be included in the set of candidate operations, i.e., the set of candidates should be constrained directly by the state of the stack.\nAlso, including repeating ""identity"" operations (in the candidates of attention operations) seems that some unnecessary redundancy is introduced into the search space. The same expressiveness could be achieved by predicting a special token only once at the end of the sequence (namely, ""end-of-sequence"" token as just same as usual auto-regressive RNN-based decoder models).\n\nComparison in experiments looks meaningless. Score improvement is slight nevertheless authors paid much computation cost for searching accurate network structures. The conventional method (Zoph&Le,17) in row 3 of Table 1 looks not comparable with proposed methods because it is trained by an out-of-domain task (LM) using conventional (tree-based) search space. Authors should at least show the result by applying the conventional search space to the tasks of this paper.\nIn Table 2, the ""our baseline"" looks cheap because the dot product is the least attention model in those proposed in past studies.\n\nThe catastrophic score drop in the rows 5 and 7 in Table 1 looks interesting, but the paper does not show enough comprehension about this phenomenon, which makes the proposed method hard to apply other tasks.\nThe same problem exists in the setting of the hyperparameters in the reward functions. According to the footnote, there are largely different settings about the value of \\beta, which suggest a sensitivity by changing this parameter. Authors should provide some criterion to choose these hyperparameters.', 'The paper explores neural architecture search for translation and reading comprehension tasks. It is fairly clearly written and required a lot of large-scale experimentation. However, the paper introduces few new ideas and seems very much like applying an existing framework to new problems. It is probably better suited for presentation in a workshop rather than as a conference paper.\n\nA new idea in the paper is the stack-based search. However, there is no direct comparison to the tree-based search. A clear like for like comparison would be interesting.\n\nMethodology. The test set newstest2014 of WMT German-English officially contains 3000 sentences. Please check http://statmt.org/wmt14. \nAlso, how stable are the results you obtain, did you rerun the selected architectures with multiple seeds? The difference between the WMT baseline of 28.8 and your best configuration of 29.1 BLEU can often be simply obtained by different random weight initializations.\n\nThe Squad results (table 2) should list a more recent SOTA result to be fair as it gives the impression that the system presented here is SOTA.']","[-50, -50, -30]","[0, 20, 50]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's contribution and experimental results. They state that the methodology is only slightly different from previous work, the results are not state-of-the-art, and it's difficult to draw meaningful conclusions. However, they do acknowledge the computational effort involved, which prevents the score from being even lower. The politeness score is 0 (neutral) because the reviewer uses professional language without being overly polite or rude. They directly state their concerns and criticisms without using harsh language or personal attacks, but also without using particularly courteous phrases."", ""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper's methodology and experimental design. While the reviewer acknowledges some positive aspects ('could be a flexible framework'), they express more concerns than praise. The politeness score is 20 because the reviewer uses professional language and offers constructive criticism without being overly harsh. They use phrases like 'in my thought' and 'authors should' which maintain a respectful tone while still conveying their critiques. The reviewer also points out interesting aspects of the work, showing engagement with the material, which contributes to the slightly positive politeness score."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the paper's clear writing and extensive experimentation, they criticize it for introducing few new ideas and suggest it's more suitable for a workshop than a conference. The reviewer also points out several areas for improvement. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging positive aspects before offering criticisms, and phrases suggestions as questions or polite requests (e.g., 'Please check...', 'A clear like for like comparison would be interesting.'). The reviewer maintains a professional tone without using harsh or dismissive language, even when pointing out potential issues with the paper.""]"
"['The description of the proposed method is very unclear. From the paper it is very difficult to make out exactly what architecture is proposed. I understand that the prior on the z_i in each layer is a pixel-cnn, but what is the posterior? Equations 8 and 9 would suggest it is of the same form (pixel-cnn) but this would be much too slow to sample during training. I\'m guessing it is just a factorized Gaussian, with a separate factorized Gaussian pseudo-prior? That is, in figure 1 all solid lines are factorized Gaussians and all dashed lines are pixel-cnns?\n\n* The word ""layers"" is sometimes used to refer to latent variables z, and sometimes to parameterized neural network layers in the encoder and decoder. E.g. ""The top stochastic layer z_L in FAME is a fully-connected dense layer"". No, z_L is a vector of latent variables. Are you saying the encoder produces it using a fully-connected layer?\n* Section 2.2 starts talking about ""deterministic layers h"". Are these part of the encoder or decoder? What is meant by ""number of layers connecting the stochastic latent variables""?\n* Section 2.3: What is meant by ""reconstruction data""?\n\nIf my understanding of the method is correct, the novelty is limited. Autoregressive priors were used previously in e.g. the Lossy VAE by Chen et al. and IAF-VAE by Kingma et al. The reported likelihood results are very impressive though, and would be reason for acceptance if correct. However, the quality of the sampled images shown for CIFAR-10 doesn\'t match the reported likelihood. There are multiple possible reasons for this, but after skimming the code I believe it might be due to a faulty implementation of the variational lower bound. Instead of calculating all quantities in the log domain, the code takes explicit logs and exponents and stabilizes them by adding small quantities ""eps"": this is not guaranteed to give the right result. Please fix this and re-run your experiments. (I.e. in _loss.py don\'t use x/(exp(y)+eps) but instead use x*exp(-y). Don\'t use log(var+eps) with var=softplus(x), but instead use var=softplus(x)+eps or parameterize the variance directly in the log domain).', ""Update:  In light of Yoon Kim's retraction of replication, I've downgraded my score until the authors provide further validation (i.e. CIFAR and ImageNet samples).\n\nSummary\n\nThis paper proposes VAE modifications that allow for the use multiple layers of latent variables.  The modifications are: (1) a shared en/decoder parametrization as used in the Ladder VAE [1], (2) the latent variable parameters are functions of a CNN, and (3) use of a PixelCNN decoder [2] that is fed both the last layer of stochastic variables and the input image, as done in [3].  Negative log likelihood (NLL) results on CIFAR 10, binarized MNIST (dynamic and static), OMNIGLOT, and ImageNet (32x32) are reported.  Samples are shown for CIFAR 10, MNIST, and OMNIGLOT.        \n\n\nEvaluation\n\nPros:  The paper’s primary contribution is experimental: SOTA results are achieved for nearly every benchmark image dataset (the exception being statically binarized MNIST, which is only .28 nats off).  This experimental feat is quite impressive, and moreover, in the comments on OpenReview, Yoon Kim claims to have replicated the CIFAR result.  I commend the authors for making their code available already via DropBox.  Lastly, I like how the authors isolated the effect of the concatenation via the ‘FAME No Concatenation’ results.                 \n\nCons:  The paper provides little novelty in terms of model or algorithmic design, as using a CNN to parametrize the latent variables is the only model detail unique to this paper.  In terms of experiments, the CIFAR samples look a bit blurry for the reported NLL (as others have mentioned in the OpenReview comments).  I find the authors’ claim that FAME is performing superior global modeling interesting.  Is there a way to support this experimentally?  Also, I would have liked to see results w/o the CNN parametrization; how important was this choice?  \n\n\nConclusion\n\nWhile the paper's conceptual novelty is low, the engineering and experimental work required (to combine the three ideas discussed in the summary and evaluate the model on every benchmark image dataset) is commendable.  I recommend the paper’s acceptance for this reason.\n\n\n[1]  C. Sonderby et al., “Ladder Variational Autoencoders.”  NIPS 2016.\n[2]  A. van den Oord et al., “Conditional Image Generation with PixelCNN Decoders.” ArXiv 2016.\n[3]  I. Gulrajani et al., “PixelVAE: A Latent Variable Model for Natural Images.”  ICLR 2017.\n"", 'The paper combines several recent advances on generative modelling including a ladder variational posterior and a PixelCNN decoder together with the proposed convolutional stochastic layers to boost the NLL results of the current VAEs. The numbers in the tables are good but I have several comments on the motivation, originality and experiments.\n\nMost parts of the paper provide a detailed review of the literature. However, the resulting model is quite like a combination of the existing advances and the main contribution of the paper, i.e. the convolution stochastic layer, is not well discussed. Why should we introduce the convolution stochastic layers? Could the layers encode the spatial information better than a deterministic convolutional layer with the same architecture? What\'s the exact challenge of training VAEs addressed by the convolution stochastic layer? Please strengthen the motivation and originality of the paper.\n\nThough the results are good, I still wonder what is the exact contribution of the convolutional stochastic layers to the NLL results?  Can the authors provide some results without the ladder variational posterior and the PixelCNN decoder on both the gray-scaled and the natural images?\n\nAccording to the experimental setting in the Section 3 (Page 5 Paragraph 2), ""In case of gray-scaled images the stochastic latent layers are dense with sizes 64, 32, 16, 8, 4 (equivalent to Sønderby et al. (2016)) and for the natural images they are spatial (cf. Table 1). There was no significant difference when using feature maps (as compared to dense layers) for modelling gray-scaled images."" there is no stochastic convolutional layer.  Then is there anything new in FAME on the gray images? Furthermore, how could FAME advance the previous state-of-the-art? It seems because of other factors instead of the stochastic convolutional layer. \n\nThe results on the natural images are not complete. Please present the generation results on the ImageNet dataset and the reconstruction results on both the CIFAR10 and ImageNet datasets. The quality of the samples on the CIFAR10 dataset seems not competitive to the baseline papers listed in the table. Though the visual quality does not necessarily agree with the NLL results but such large gap is still strange. Besides, why FAME can obtain both good NLL and generation results on the MNIST and OMNIGLOT datasets when there is no stochastic convolutional layer? Meanwhile, why FAME cannot obtain good generation results on the CIFAR10 dataset? Is it because there is a lot randomness in the stochastic convolutional layer? It is better to provide further analysis and it is not safe to say that the stochastic convolutional layer helps learn better latent representations based on only the NNL results.\n\nMinor things:\n\nPlease rewrite the sentence ""When performing reconstructions during training ... while also using the stochastic latent variables z = z 1 , ..., z L."" in the caption of Figure 1.']","[-50, 50, -20]","[20, 75, 60]","[""The sentiment score is -50 because the review is generally critical, pointing out several unclear aspects of the paper and suggesting potential errors in implementation. However, it's not entirely negative as it acknowledges the impressive reported likelihood results. The politeness score is 20 because while the reviewer is direct in their criticism, they use professional language and offer constructive feedback. They use phrases like 'I understand that...' and 'I'm guessing...' which soften the critique. The reviewer also provides specific suggestions for improvement, which is helpful and courteous. However, some statements are quite blunt, such as 'The description of the proposed method is very unclear,' which prevents a higher politeness score."", ""The sentiment score is 50 (slightly positive) because while the reviewer acknowledges the paper's impressive experimental results and commends the authors for their work, they also point out some cons and areas for improvement. The reviewer recommends acceptance despite low conceptual novelty, indicating a generally positive but not overwhelmingly enthusiastic sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts, and provides constructive criticism. They use phrases like 'I commend the authors' and 'I like how the authors...', which contribute to a polite tone. The reviewer also balances praise with criticism in a professional manner, without using harsh or dismissive language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The numbers in the tables are good'), they express several concerns and criticisms about the paper's motivation, originality, and experiments. The reviewer asks for clarifications, additional results, and stronger justifications for the paper's contributions, indicating a somewhat skeptical stance overall. The politeness score is moderately positive (60) as the reviewer maintains a professional and constructive tone throughout. They use polite language such as 'Please strengthen...', 'Can the authors provide...', and 'It is better to provide further analysis...', which shows respect while offering criticism. The reviewer also acknowledges positive aspects before presenting concerns, which is a polite approach to feedback.""]"
"['Summary:\n\nThe paper proposes a framework for constructing spherical convolutional networks (ConvNets) based on a novel synthesis of several existing concepts.  The goal is to detect patterns in spherical signals irrespective of how they are rotated on the sphere.  The key is to make the convolutional architecture rotation equivariant.\n\nPros:\n\n+ novel/original proposal justified both theoretically and empirically\n+ well written, easy to follow\n+ limited evaluation on a classification and regression task is suggestive of the proposed approach\'s potential\n+ efficient implementation\n\nCons:\n\n- related work, in particular the first paragraph, should compare and contrast with the closest extant work rather than merely list them\n- evaluation is limited; granted this is the nature of the target domain\n\nPresentation:\n\nWhile the paper is generally written well, the paper appears to conflate the definition of the convolutional and correlation operators?  This point should be clarified in a revised manuscript.  \n\nIn Section 5 (Experiments), there are several references to S^2CNN.  This naming of the proposed approach should be made clear earlier in the manuscript.  As an aside, this appears a little confusing since convolution is performed first on S^2 and then SO(3). \n\nEvaluation:\n\nWhat are the timings of the forward/backward pass and space considerations for the Spherical ConvNets presented in the evaluation section?  Please provide specific numbers for the various tasks presented.\n\nHow many layers (parameters) are used in the baselines in Table 2?  If indeed there are much less parameters used in the proposed approach, this would strengthen the argument for the approach.  On the other hand, was there an attempt to add additional layers to the proposed approach for the shape recognition experiment in Sec. 5.3 to improve performance?\n\nMinor Points:\n\n- some references are missing their source, e.g., Maslen 1998 and Kostolec, Rockmore, 2007, and Ravanbakhsh, et al. 2016.\n\n- some sources for the references are presented inconsistency, e.g., Cohen and Welling, 2017 and Dieleman, et al. 2017\n\n- some references include the first name of the authors, others use the initial \n\n- in references to et al. or not, appears inconsistent\n\n- Eqns 4, 5, 6, and 8 require punctuation\n\n- Section 4 line 2, period missing before ""Since the FFT""\n\n- ""coulomb matrix"" --> ""Coulomb matrix""\n\n- Figure 5, caption: ""The red dot correcpond to"" --> ""The red dot corresponds to""\n\nFinal remarks:\n\nBased on the novelty of the approach, and the sufficient evaluation, I recommend the paper be accepted.\n\n', ""First off, this paper was a delight to read.  The authors develop an (actually) novel scheme for representing spherical data from the ground up, and test it on three wildly different empirical tasks: Spherical MNIST, 3D-object recognition, and atomization energies from molecular geometries.  They achieve near state-of-the-art performance against other special-purpose networks that aren't nearly as general as their new framework.  The paper was also exceptionally clear and well written.\n\nThe only con (which is more a suggestion than anything)--it would be nice if the authors compared the training time/# of parameters of their model versus the closest competitors for the latter two empirical examples.  This can sometimes be an apples-to-oranges comparison, but it's nice to fully contextualize the comparative advantage of this new scheme over others.  That is, does it perform as well and train just as fast?  Does it need fewer parameters?  etc.\n\nI strongly endorse acceptance."", 'The focus of the paper is how to extend convolutional neural networks to have built-in spherical invariance.  Such a requirement naturally emerges when working with omnidirectional vision (autonomous cars, drones, ...).\n\nTo get invariance on the sphere (S^2), the idea is to consider the group of rotations on S^2 [SO(3)] and spherical convolution [Eq. (4)]. To be able to compute this convolution efficiently, a generalized Fourier theorem is useful. In order to achieve this goal, the authors adapt tools from non-Abelian [SO(3)] harmonic analysis.  The validity of the idea is illustrated on 3D shape recognition and atomization energy prediction. \n\nThe paper is nicely organized and clearly written; it fits to the focus of ICLR and can be applicable on many other domains as well.\n']","[70, 90, 80]","[60, 80, 70]","[""The sentiment score is 70 (positive) because the reviewer recommends acceptance, lists several pros, and uses positive language like 'novel/original proposal' and 'well written'. The cons and suggestions for improvement are presented as minor issues. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as requests (e.g. 'Please provide...'). However, it's not extremely polite as it maintains a professional, direct tone rather than using overtly courteous language. The reasoning is based on the overall positive recommendation, the balance of pros vs cons, the constructive nature of the criticism, and the language used throughout the review."", ""The sentiment score is 90 because the reviewer expresses strong positive sentiment throughout. They describe the paper as 'a delight to read', praise its novelty and clarity, and 'strongly endorse acceptance'. The only minor criticism is framed as a suggestion. The politeness score is 80 because the language is consistently respectful and appreciative. The reviewer uses phrases like 'it would be nice if' when making suggestions, showing courtesy. They also balance their critique with positive feedback, demonstrating professional politeness. The scores aren't 100 as there's room for even more effusive praise or extreme politeness, but they're very high due to the overwhelmingly positive and courteous tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper. They describe it as 'nicely organized and clearly written,' state that it 'fits to the focus of ICLR,' and mention its potential applicability to many domains. The absence of criticism and the focus on positive aspects indicate a highly positive sentiment. The politeness score is 70 (polite) due to the professional and respectful tone throughout the review. The reviewer uses neutral language to describe the paper's content and methodology, and employs positive phrases like 'nicely organized' without resorting to overly effusive praise. The review maintains a courteous and constructive tone, typical of polite academic discourse.""]"
"['This paper applies recently developed ideas in the literature of robust optimization, in particular distributionally robust optimization with Wasserstein metric, and showed that under this framework for smooth loss functions when not too much robustness is requested, then the resulting optimization problem is of the same difficulty level as the original one (where the adversarial attack is not concerned). I think the idea is intuitive and reasonable, the result is nice. Although it only holds when light robustness are imposed, but in practice, this seems to be more of the case than say large deviation/adversary exists. As adversarial training is an important topic for deep learning, I feel this work may lead to promising principled ways for adversarial training. ', ""In this very good paper, the objective is to perform robust learning: to minimize not only the risk under some distribution P_0, but also against the worst case distribution in a ball around P_0.\n\nSince the min-max problem is intractable in general, what is actually studied here is a relaxation of the problem: it is possible to give a non-convex dual formulation of the problem. If the duality parameter is large enough, the functions become convex given that the initial losses are smooth. \n\nWhat follows are certifiable bounds for the risk for robust  learning and stochastic optimization over a ball of distributions. Experiments show that this performs as expected, and gives a good intuition for the reasons why this occurs: separation lines are 'pushed away' from samples, and a margin seems to be increased with this procedure."", 'This paper proposes a principled methodology to induce distributional robustness in trained neural nets with the purpose of mitigating the impact of adversarial examples. The idea is to train the model to perform well not only with respect to the unknown population distribution, but to perform well on the worst-case distribution in some ball around the population distribution. In particular, the authors adopt the Wasserstein distance to define the ambiguity sets. This allows them to use strong duality results from the literature on distributionally robust optimization and express the empirical minimax problem as a regularized ERM with a different cost. The theoretical results in the paper are supported by experiments.\n\nOverall, this is a very well-written paper that creatively combines a number of interesting ideas to address an important problem.']","[80, 80, 90]","[50, 50, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses a favorable opinion of the paper, describing the idea as 'intuitive and reasonable' and the result as 'nice'. They also mention that the work may lead to 'promising principled ways for adversarial training', indicating a positive outlook on its potential impact. The politeness score is 50 (slightly polite) because while the reviewer doesn't use overtly polite language, they maintain a professional and respectful tone throughout. They offer constructive feedback and acknowledge the paper's strengths without using any harsh or critical language. The reviewer's use of phrases like 'I think' and 'I feel' also adds a personal, considerate touch to the review."", ""The sentiment score is 80 (positive) because the review starts with 'In this very good paper,' indicating a strong positive sentiment. The reviewer also praises the paper's approach, results, and insights throughout. The politeness score is 50 (somewhat polite) because the language is professional and respectful, without being overly formal or effusive. The reviewer provides a balanced and objective assessment of the paper's content without using any negative or critical language. The tone is matter-of-fact and focused on the scientific content, which is appropriate for a peer review but doesn't go out of its way to be exceptionally polite."", ""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer describes the paper as 'very well-written' and praises its creativity and importance. They also mention that the theoretical results are supported by experiments, which is a strong positive point. The lack of any criticism or suggested improvements further indicates a highly positive sentiment. The politeness score is 80 because the language used is professional and respectful. The reviewer uses phrases like 'creatively combines' and 'interesting ideas' which show appreciation for the authors' work. The tone is formal and constructive throughout, without any harsh or critical language. While it's very polite, it doesn't go to extremes of politeness, maintaining a professional tone, hence the score of 80 rather than 100.""]"
"['The paper proposes a novel approach on estimating the parameters  \nof Mean field games (MFG). The key of the method is a reduction of the unknown parameter MFG to an  unknown parameter Markov Decision Process (MDP).\n\nThis is an important class of models and I recommend the acceptance of the paper.\n\nI think that the general discussion about the collective behavior application should be more carefully presented and some better examples of applications should be easy to provide.  In addition the authors may want to enrich their literature review and give references to alternative work on unknown MDP estimation methods cf. [1], [2] below. \n\n[1] Burnetas, A. N., & Katehakis, M. N. (1997). Optimal adaptive policies for Markov decision processes. Mathematics of Operations Research, 22(1), 222-255.\n\n[2] Budhiraja, A., Liu, X., & Shwartz, A. (2012). Action time sharing policies for ergodic control of Markov chains. SIAM Journal on Control and Optimization, 50(1), 171-195.', 'This paper attacks an important problems with an interesting and promising methodology.  The authors deal with inference in models of collective behavior, specifically at how to infer the parameters of a mean field game representation of collective behavior. The technique the authors innovate is to specify a mean field game as a model, and then use inverse reinforcement learning to learn the reward functions of agents in the mean field game.\n\nThis work has many virtues, and could be an impactful piece. There is still minimal work at the intersection of machine learning and collective behavior, and this paper could help to stimulate the growth of that intersection.  The application to collective behavior could be an interesting novel application to many in machine learning, and conversely the inference techniques that are innovated should be novel to many researchers in collective behavior.\n\nAt the same time, the scientific content of the work has critical conceptual flaws.  Most fundamentally, the authors appear to implicitly center their work around highly controversial claims about the ontological status of group optimization, without the careful justification necessary to make this kind of argument.  In addition to that, the authors appear to implicitly assume that utility function inference can be used for causal inference. \n\nThat is, there are two distinct mistakes the authors make in their scientific claims:\n1) The authors write as if mean field games represent population optimization (Mean field games are not about what a _group_ optimizes; they are about what _individuals_ optimize, and this individual optimization leads to certain patterns in collective behaviors)\n2) The authors write as if utility/reward function inference alone can provide causal understanding of collective or individual behavior\n\n1 - \n\nI should say that I am highly sympathetic to the claim that many types of collective behavior can be viewed as optimizing some kind of objective function.  However, this claim is far from mainstream, and is in fact highly contested.  For instance, many prominent pieces of work in the study of collective behavior have highlighted its irrational aspects, from the madness of crowds to herding in financial markets.\n\nSince it is so fringe to attribute causal agency to groups, let alone optimal agency, in the remainder of my review I will give the authors the benefit of the doubt and assume when they say things like ""population behavior may be optimal"", they mean ""the behavior of individuals within a population may be optimal"".  If the authors do mean to say this, they should be more careful about their language use in this regard (individuals are the actors, not populations).  If the authors do indeed mean to attribute causal agency to groups (as suggested in their MDP representation), they will run into all the criticisms I would have about an individual-level analysis and more.  Suffice it to say, mean field games themselves don\'t make claims about aggregate-level optimization.  A Nash equilibrium achieves a balance between individual-level reward functions. These reward functions are only interpretable at the individual level.  There is no objective function the group itself in aggregate is optimizing in mean field games.  For instance, even though the mean field game model of the Mexican wave produces wave solutions, the model is premised on people having individual utility functions that lead to emergent wave behavior.  The model does not have the representational capacity to explain that people actually intend to create the emergent behavior of a wave (even though in this case they do).  Furthermore, the fact that mean field games aggregate to a single-agent MDP does not imply that that the group can rightfully be thought of as an agent optimizing the reward function, because there is an exact correspondence between the rewards of the individual agents in the MFG and of the aggregate agent in the MDP by construction.\n\n2 -\n\nThe authors also claim that their inference methods can help explain why people choose to talk about certain topics. As far as the extent to which utility / reward function inference can provide causal explanations of individual (or collective) behavior, the argument that is invariably brought against a claim of optimization is that almost any behavior can be explained as optimal post-hoc with enough degrees of freedom in the utiliy function of the behavioral model. Since optimization frameworks are so flexible, they have little explanatory power and are hard to falsify.  In fact, there is literally no way that the modeling framework of the authors even affords the possibility that individual/collective behavior is not optimal.  Optimality is taken as an assumption that allows the authors to infer what reward function is being optimized. \n\nThe authors state that the reward function they infer helps to interpret collective behavior because it reveals what people are optimizing.  However, the reward function actually discovered is not interpretable at all. It is simply a summary of the statistical properties of changes in popularity of the topics of conversation in the Twitter data the authors\' study. To quote the authors\' insights: ""The learned reward function reveals that a real social media population favors states characterized by a highly non-uniform distribution with negative mass gradient in decreasing order of topic popularity, as well as transitions that increase this distribution imbalance.""  The authors might as well have simply visualized the topic popularities and changes in popularities to arrive at such an insight. To take the authors claims literally, we would say that people have an intrinsic preference for everyone to arbitrarily be talking about the same thing, regardless of the content or relevance of that topic.  To draw an analogy, this is like observing that on some days everybody on the street is carrying open umbrellas and on other days not, and inferring that the people on the street have a preference for everyone having their umbrellas open together (and the model would then predict that if one person opens an umbrella on a sunny day, everybody else will too).\n\nTo the authors credit, they do make a brief attempt to present empirical evidence for their optimization view, stating succinctly: ""The high prediction accuracy of the learned policy provides evidence that real population behavior can be understood and modeled as the result of an emergent population-level optimization with respect to a reward function."" Needless to say, this one-sentence argument for a highly controversial scientific claims falls flat on closer inspection. Setting aside the issues of correlation versus causation, predictive accuracy does not in and of itself provide scientific plausibility. When an n-gram model produces text that is in the style of a particular writer, we do not conclude that the writer must have been composing based on the n-gram\'s generative mechanism.  Predictive accuracy only provides evidence when combined in the first place with scientific plausibility through other avenues of evidence.\n\nThe authors could attempt to address these issues by making what is called an ""as-if"" argument, but it\'s not even clear such an argument could work here in general.  \n\nWith all this in mind, it would be more instructive to show that the inference method the authors introduce could infer the correct utility functions used in standard mean field games, such as modeling traffic congestion and the Mexican wave.  \n\n--\n\nAll that said, the general approach taken in the authors\' work is highly promising, and there are many fruitful directions I would be exicted to see this work taken --- e.g., combining endogenous and exogenous rewards or looking at more complex applications.  As a technical contribution, the paper is wonderful, and I would enthusiastically support acceptance.  The authors simply either need to be much more careful with the scientific claims about collective behavior they make, or limit the scope of the contribution of the paper to be modeling / inference  in the area of collective behavior.  Mean field games are an important class of models in collective behavior, and being able to infer their parameters is a nice step forward purely due to the importance of that class of games.  Identifying where the authors\' inference method could be applied to draw valid scientific conclusions about collective behavior could then be an avenue for future work.  Examples of plausible scientific applications might include parameter inference in settings where mean field games are already typically applied in order to improve the fit of those models or to learn about trade-offs people make in their utility functions in those settings.\n\n--\n\nOther minor comments:\n- (Introduction) It is not clear at all how the Arab Spring, Black Lives Matter, and fake news are similar --- i.e., whether a single model could provide insight into these highly heterogeneous events --- nor is it clear what end the authors hope to achieve by modeling them --- the ethics of modeling protests in a field crowded with powerful institutional actors is worth carefully considering.\n- If I understand correctly, the fact that the authors assume a factored reward function seems limiting. Isn\'t the major benefit of game theory it\'s ability to accommodate utility functions that depend on the actions of others?\n- The authors state that one of their essential insights is that ""solving the optimization problem of a single-agent MDP is equivalent to solving the inference problem of an MFG."" This statement feels a bit too cute at the expense of clarity. The authors perform inference via inverse-RL, so it\'s more clear to say the authors are attempting to use statistical inference to figure out what is being optimized.\n- The relationship between MFGs and a single-agent MDP is nice and a fine observation, but not as surprising as the authors frame it as. Any multiagent MDP can be naively represented as a single-agent MDP where the agent has control over the entire population, and we already know that stochastic games are closely related to MDPs.  It\'s therefore hard to imagine that there woudn\'t be some sort of correspondence. ', 'The paper considers the problem of representing and learning the behavior of a large population of agents, in an attempt to construct an effective predictive model of the behavior. The main concern is with large populations where it is not possible to represent each agent individually, hence the need to use a population level description.  The main contribution of the paper is in relating the theories of Mean Field Games (MFG) and Reinforcement Learning (RL) within the classic context of Markov Decision Processes (MDPs). The method suggested uses inverse RL to learn both the reward function and the forward dynamics of the MFG from data, and its effectiveness is demonstrated on social media data. \nThe paper contributes along three lines, covering theory, algorithm and experiment.  The theoretical contribution begins by transforming a continuous time MFG formulation to a discrete time formulation (proposition 1), and then relates the MFG to an associated MDP problem. The first contribution seems rather straightforward and appears to have been done previously, while the second is interesting, yet simple to prove. However, Theorem 2 sets the stage for an algorithm developed in section 4 of the paper that suggests an RL solution to the MFG problem. The key insight here is that solving an optimization problem on an MDP of a single agent is equivalent to solving the inference problem of the (population-level) MFG. Practically, this leads to learning a reward function from demonstrations using a maximum likelihood approach, where the reward is represented using a deep neural network, and the policy is learned through an actor-critic algorithm, based on gradient descent with respect to the policy parameters. The algorithm provides an improvement over previous approaches limited to toy problems with artificially created reward functions. Finally, the approach is demonstrated on real-world social data with the aim of recovering the reward function and predicting the future trajectory. The results compare favorably with two baselines, vector auto-regression and recurrent neural networks. \nI have found the paper to be interesting, and, although I am not an expert in MFGs, novel and well-articulated. Moreover, it appears to hold promise for modeling social media in general. I would appreciate clarification on several issues which would improve the presentability of the results.  \n1)\tThe authors discuss on p. 6 variance reduction techniques. I would appreciate a more complete description or, at least, a more precise reference than to a complete paper. \n2)\tThe experimental results use state that “Although the set of topics differ semantically each day, indexing topics in order of decreasing initial popularity suffices for identifying the topic sets across all days.” This statement is unclear to me and I would appreciate a more detailed explanation.  \n3)\tThe authors make the following statement: “ … learning the MFG model required only the initial population distribution of each day in the training set, while VAR and RNN used the distributions over all hours of each day.” Please clarify the distinction and between the algorithms here. In general, details are missing about how the VAR and RNN were run. \n4)\tThe approach uses expert demonstration (line 7 in Algorithm 1). It was not clear to me how this is done in the experiment.\n']","[80, -50, 70]","[70, 50, 80]","[""The sentiment score is 80 (positive) because the reviewer recommends acceptance of the paper and describes the work as 'important'. The overall tone is supportive, with only minor suggestions for improvement. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering suggestions rather than demands (e.g., 'may want to enrich'). The reviewer also acknowledges the paper's strengths before offering constructive feedback. The language is professional and courteous, without being overly formal or effusive."", ""The sentiment score is -50 because while the reviewer acknowledges the paper's virtues and potential impact, they also point out 'critical conceptual flaws' and fundamental mistakes in the authors' scientific claims. The review is balanced but leans negative due to these significant issues. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the paper's strengths and potential impact before delving into criticisms. They use phrases like 'To the authors credit' and 'I would be excited to see this work taken' which maintain a constructive tone. However, the criticism is direct and extensive, preventing a higher politeness score."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'interesting', 'novel', and 'well-articulated'. They also mention that it 'holds promise for modeling social media in general'. The reviewer acknowledges the paper's contributions in theory, algorithm, and experiment, and compares it favorably to previous approaches. However, it's not a perfect 100 as the reviewer does request clarifications on several issues. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges their own potential lack of expertise ('although I am not an expert in MFGs'), and frames their requests for clarification as polite suggestions ('I would appreciate clarification', 'Please clarify'). The tone is constructive and supportive, aiming to improve the paper rather than criticize it harshly.""]"
"[""One of the main problems with imitation learning in general is the expense of expert demonstration. The authors here propose a method for sidestepping this issue by using the random exploration of an agent to learn generalizable skills which can then be applied without any specific pretraining on any new task. \n\nThe proposed method has at its core a method for learning a parametric skill function (PSF) that takes as input a description of the initial state, goal state, parameters of the skill and outputs a sequence of actions (could be of varying length) which take the agent from initial state to goal state.\n\nThe skill function uses a RNN as function approximator and minimizes the sum of two losses i.e. the state mismatch loss over the trajectory (using an explicitly learnt forward model) and the action mismatch loss (using a model-free action prediction module) . This is hard to do in practice due to jointly learning both the forward model as well as the state mismatches. So first they are separately learnt and then fine-tuned together. \n\nIn order to decide when to stop, an independent goal detector is trained which was found to be better than adding a 'goal-reached' action to the PSF.\n\nExperiments on two domains are presented. 1. Visual navigation where images of start and goal states are given as input. 2. Robotic knot-tying with a loose rope where visual input of the initial and final rope states are given as input.\n\nComments:\n\n- In the visual navigation task no numbers are presented on the comparison to slam-based techniques used as baselines although it is mentioned that it will be revisited.\n\n- In the rope knot-tying task no slam-based or other classical baselines are mentioned.\n\n- My main concern is that I am really trying to place this paper with respect to doing reinforcement learning first (either in simulation or in the real world itself, on-policy or off-policy) and then just using the learnt policy on test tasks. Or in other words why should we call this zero-shot imitation instead of simply reinforcement learnt policy being learnt and then used. The nice part of doing RL is that it provides ways of actively controlling the exploration. See this pretty relevant paper which attempts the same task and also claims to have the target state generalization ability. \n\nTarget-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning by Zhu et al.\n\nI am genuinely curious and would love the authors' comments on this. It should help make it clearer in the paper as well.\n \nUpdate:\n\nAfter evaluating the response from the authors and ensuing discussion as well as the other reviews and their corresponding discussion, I am revising my rating for this paper up. This will be an interesting paper to have at the conference and will spur more ideas and follow-on work."", 'Summary:\nThe authors present a paper about imitation of a task presented just during inference, where the learning is performed in a completely self-supervised manner.\nDuring training, the agent explores by itself related (but different) tasks, learning a) how actions affect the world state, b) which action to perform given the previous action and the world state, and c) when to stop performing actions. This learning is done without any supervision, with a loss that tries to predict actions which result in the state achieved through self exploration (forward consistency loss).\nDuring testing, the robot is presented with a sequence of goals in a related but different task. Experiments show that the system achieves a better performance than different subparts of the system (through an ablation study), state of the art and common open source systems.\n\nPositive aspects:\nThe paper is well written and clear to understand. Since this is not my main area of research I cannot judge its originality in a completely fair way, but it is original AFAIK. The idea of learning the basic relations between actions and state through self exploration is definitely interesting.\nThis line of work is specially relevant since it attacks one of the main bottlenecks in learning complex tasks, which is the amount of supervised examples.\nThe experiments show clearly that a) the components of the proposed pipeline are important since they outperform ablated versions of it and b) the system is better than previous work in those tasks\n\nNegative aspects:\nMy main criticism to the paper is that the task learning achieved through self exploration seems relatively shallow. From the navigation task, it seems like the system mainly learns a discover behavior that is better than random motion. It definitely does not seem able to learn higher level concepts like certain scenes being more likely to be close to each other than others (e.g. it is likely to find an oven in the same room as a kitchen sink but not in a toilet). It is not clear whether this is achievable by the current system even with more training data.\nAnother aspect that worries me about the system is how it can be extended to higher dimensional action spaces. Extending control laws through self-exploration under random disturbances has been studied in character control (e.g. ""Domain of Attraction Expansion for Physics-based Character Control"" by Borno et al.), but the dimensionality of the problem makes this exploration very expensive (even for short time frames, and even in simulation). I wonder if the presented ideas won\'t suffer from the same curse of dimensionality.\nIn terms of experiments, it is shown that the system is more effective than others but not so much *how* it achieves this efficiency. It would be good to show whether part of its efficiency comes from effective image-guided navigation: does a partial image match entail with targetted navigation (e.g. matches in the right side of the image make the robot turn right)?\nA couple more specific comments:\n- I think that dealing with multimodal distributions of actions with the forward consistency loss is effective for achieving the goal, but not necessarily good for modeling multimodality. Isn\'t it possible that the agent learns only one way of achieving such goal?\n - It is not clear how the authors achieve to avoid the problem of starting from scratch by ""pre-train the forward model and PSF separately by blocking gradient flow"". Isn\'t it still challenging to update them independently, given that at the beginning both components are probably not very accurate?\n\n\nConclusion:\nI think the paper presents an interesting idea which should be exposed to the community. The paper is easy to read and its experiments show the effectiveness of the method. The relevance of the method to achieve a deeper sense of learning and performing more complex tasks is however unclear to me.', 'The authors propose an approach for zero-shot visual learning. The robot learns inverse and forward models through autonomous exploration. The robot then uses the learned parametric skill functions to reach goal states (images) provided by the demonstrator. The “zero-shot” refers to the fact that all learning is performed before the human defines the task. The proposed method was evaluated on a mobile indoor navigation task and a knot tying task. \n\nThe proposed approach is well founded and the experimental evaluations are promising. The paper is well written and easy to follow. \n\nI was expecting the authors to mention “goal emulation” and “distal teacher learning” in their related work. These topics seem sufficiently related to the proposed approach that the authors should include them in their related work section, and explain the similarities and differences. \n\nLearning both inverse and forward models is very effective. How well does the framework scale to more complex scenarios, e.g., multiple types of manipulation together? Do you have any intuition for what kind of features or information the networks are capturing? For the mobile robot, is the robot learning some form of traversability affordances, e.g., recognizing actions for crossings, corners, and obstacles? The authors should consider a test where the robot remains stationary with a fixed goal, but obstacles are move around it to  see how it affects the selected action distributions.\n\nHow much can change between the goal images and the environment before the system fails? In the videos, it seems that the people and chairs are always in the same place. I could imagine a network learning to ignore features of objects that tend to wander over time. The authors should consider exploring and discussing the effects of adding/moving/removing objects on the performance. \n\nI am very happy to see experimental evaluations on real robots, and even in two different application domains. Including videos of failure cases is also appreciated. The evaluation with the sequence of checkpoints was created by using every fifth image. How does the performance change with the number of frames between checkpoints? In the videos, it seems like the robot could get a slightly better view if it took another couple of steps. I assume this is an artifact of the way the goal recognizer is trained. For the videos, it may be useful to indicate when the goal is detected, and then let it run a couple more steps and stop for a second. It is difficult to compare the goal image and the video otherwise. ']","[50, 50, 80]","[75, 80, 90]","[""The sentiment score is 50 (slightly positive) because while the reviewer expresses some concerns and asks for clarifications, they ultimately revise their rating upward and state the paper will be 'interesting' and 'spur more ideas'. This indicates an overall positive view despite some critiques. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively, and expresses genuine curiosity about the authors' perspective. They use phrases like 'I am genuinely curious' and 'would love the authors' comments', which demonstrate politeness and openness to discussion."", ""The sentiment score is 50 (slightly positive) because the review begins with positive aspects, praising the paper as well-written, clear, and original. The reviewer acknowledges the relevance and importance of the work. However, there are also significant criticisms and concerns raised, which balance out the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges their potential limitations in judging originality, and frames criticisms constructively. The reviewer uses phrases like 'My main criticism' and 'Another aspect that worries me' to soften the impact of negative feedback. The conclusion is balanced and suggests the paper should be exposed to the community, which is a polite way of recommending publication while noting areas for improvement."", ""Sentiment score (80/100): The review is overall very positive. The reviewer states that the approach is 'well founded' and the evaluations are 'promising'. They also mention that the paper is 'well written and easy to follow'. The reviewer expresses appreciation for the experimental evaluations on real robots and the inclusion of failure cases. However, it's not a perfect 100 as the reviewer does suggest some improvements and additional considerations.\n\nPoliteness score (90/100): The language used is consistently polite and constructive. The reviewer uses phrases like 'I was expecting', 'The authors should consider', and 'I am very happy to see' which maintain a respectful and encouraging tone. They provide suggestions for improvement without being critical or harsh. The high score reflects the reviewer's consistent use of polite language and constructive feedback throughout the review.""]"
"['This work identifies a mistake in the existing proof of convergence of\nAdam, which is among the most popular optimization methods in deep\nlearning. Moreover, it gives a simple 1-dimensional counterexample with\nlinear losses on which Adam does not converge. The same issue also\naffects RMSprop, which may be viewed as a special case of Adam without\nmomentum. The problem with Adam is that the ""learning rate"" matrices\nV_t^{1/2}/alpha_t are not monotonically decreasing. A new method, called\nAMSGrad is therefore proposed, which modifies Adam by forcing these\nmatrices to be decreasing. It is then shown that AMSGrad does satisfy\nessentially the same convergence bound as the one previously claimed for\nAdam. Experiments and simulations are provided that support the\ntheoretical analysis.\n\nApart from some issues with the technical presentation (see below), the\npaper is well-written.\n\nGiven the popularity of Adam, I consider this paper to make a very\ninteresting observation. I further believe all issues with the technical\npresentation can be readily addressed.\n\n\n\nIssues with Technical Presentation:\n\n- All theorems should explicitly state the conditions they require\n  instead of referring to ""all the conditions in (Kingma & Ba, 2015)"".\n- Theorem 2 is a repetition of Theorem 1 (except for additional\n  conditions).\n- The proof of Theorem 3 assumes there are no projections, so this\n  should be stated as part of its conditions. (The claim in footnote 2\n  that they can be handled seems highly plausible, but you should be up\n  front about the limitations of your results.)\n- The regret bound Theorem 4 establishes convergence of the optimization\n  method, so it plays the role of a sanity check. However, it is\n  strictly worse than the regret bound O(sqrt{T}) for online gradient\n  descent [Zinkevich,2003], so it cannot explain why the proposed\n  AMSgrad method might be adaptive. (The method may indeed be adaptive\n  in some sense; I am just saying the *bound* does not express that.\n  This is also not a criticism of the current paper; the same remark\n  also applies to the previously claimed regret bound for Adam.)\n- The discussion following Corollary 1 suggests that sum_i\n  hat{v}_{T,i}^{1/2} might be much smaller than d G_infty. This is true,\n  but we should always expect it to be at least a constant, because\n  hat{v}_{t,i} is monotonically increasing by definition of the\n  algorithm, so the bound does not get better than O(sqrt(T)).\n  It is also suggested that sum_i ||g_{1:T,i}|| = sqrt{sum_{t=1}^T\n  g_{t,i}^2} might be much smaller than dG_infty, but this is very\n  unlikely, because this term will typically grow like O(sqrt{T}),\n  unless the data are extremely sparse, so we should at least expect\n  some dependence on T.\n- In the proof of Theorem 1, the initial point is taken to be x_1 = 1,\n  which is perfectly fine, but it is not ""without loss of generality"",\n  as claimed. This should be stated in the statement of the Theorem.\n- The proof of Theorem 6 in appendix B only covers epsilon=1. If it is\n  ""easy to show"" that the same construction also works for other\n  epsilon, as claimed, then please provide the proof for general\n  epsilon.\n\n\nOther remarks:\n\n- Theoretically, nonconvergence of Adam seems a severe problem. Can you\n  speculate on why this issue has not prevented its widespread adoption?\n  Which factors might mitigate the issue in practice?\n- Please define g_t \\circ g_t and g_{1:T,i}\n- I would recommend sticking with standard linear algebra notation for\n  the sqrt and the inverse of a matrix and simply using A^{-1} and\n  A^{1/2} instead of 1/A and sqrt{A}.\n- In theorems 1,2,3, I would recommend stating the dimension (d=1) of\n  your counterexamples, which makes them very nice!\n\nMinor issues:\n\n- Check accent on Nicol\\`o Cesa-Bianchi in bibliography.\n- Near the end of the proof of Theorem 6: I believe you mean Adam\n  suffers a ""regret"" instead of a ""loss"" of at least 2C-4.\n  Also 2C-4=2C-4 is trivial in the second but last display.\n', 'This paper examines the very popular and useful ADAM optimization algorithm, and locates a mistake in its proof of convergence (for convex problems). Not only that, the authors also show a specific toy convex problem on which ADAM fails to converge. Once the problem was identified to be the decrease in v_t (and increase in learning rate), they modified the algorithm to solve that problem. They then show the modified algorithm does indeed converge and show some experimental results comparing it to ADAM.\n\nThe paper is well written, interesting  and very important given the popularity of ADAM. \n\nRemarks:\n- The fact that your algorithm cannot increase the learning rate seems like a possible problem in practice. A large gradient at the first steps due to bad initialization can slow the rest of training. The experimental part is limited, as you state ""preliminary"", which is a unfortunate for a work with possibly an important practical implication. Considering how easy it is to run experiments with standard networks using open-source software, this can easily improve the paper. That being said, I understand that the focus of this work is theoretical and well deserves to be accepted based on the theoretical work.\n\n- On page 14 the fourth inequality not is clear to me.\n\n- On page 6 you talk about an alternative algorithm using smoothed gradients which you do not mention anywhere else and this isn\'t that clear (more then one way to smooth). A simple pseudo-code in the appendix would be welcome.\n\nMinor remarks:\n- After the proof of theorem 1 you jump to the proof of theorem 6 (which isn\'t in the paper) and then continue with theorem 2. It is a bit confusing.\n- Page 16 at the bottom v_t= ... sum beta^{t-1-i}g_i should be g_i^2\n- Page 19 second line, you switch between j&t and it is confusing. Better notation would help.\n- The cifarnet uses LRN layer that isn\'t used anymore.', ""The paper presents three contributions: 1) it shows that the proof of convergence Adam is wrong; 2) it presents adversarial and stochastic examples on which Adam converges to the worst possible solution (i.e. there is no hope to just fix Adam's proof); 3) it proposes a variant of Adam called AMSGrad that fixes the problems in the original proof and seems to have good empirical properties.\n\nThe contribution of this paper is very relevant to ICLR and, as far as I know, novel.\nThe result is clearly very important for the deep learning community.\nI also checked most of the proofs and they look correct to me: The arguments are quite standard, even if the proofs are very long.\n\nOne note on the generality of the results: the papers states that some of the results could apply to RMSProp too. However, it has been proved that RMSProp with a certain settings of its parameters is nothing else than AdaGrad (see Section 4 in  Mukkamala and Hein, ICML'17). Hence, at least for a certain setting of its parameters, RMSProp will converge. Of course, the proof in the ICML paper could be wrong, I did not check that...\n\nA general note on the learning rate: The fact that most of these algorithms are used with a fixed learning rate while the analysis assume a decaying learning rate should hint to the fact that we are not using the right analysis. Indeed, all these variants of AdaGrad did not really improve the AdaGrad's regret bound. In this view, none of these algorithms contributed in any meaningful way to our understanding of the optimization of deep networks *nor* they advanced in any way the state-of-the-art for optimizing convex Lipschitz functions.\nOn the other hand, analysis of SGD-like algorithms with constant step sizes are known. See, for example, Zhang, ICML'04 where linear convergence is proved in a neighbourhood of the optimal solution for strongly convex problems.\nSo, even if I understand this is not the main objective of this paper, it would be nice to see a discussion on this point and the limitations of regret analysis to analyse SGD algorithms.\n\nOverall, I strongly suggest to accept this paper.\n\n\nSuggestions/minor things:\n- To facilitate the reader, I would state from the beginning what are the common settings of beta_1 and beta_2 in Adam. This makes easier to see that, for example, the condition of Theorem 2 is verified.\n- \\hat{v}_{0} is undefined in Algorithm 2.\n- The graphs in figure 2 would gain in readability if the setting of each one of them would be added as their titles.\n- McMahan and Streeter (2010) is missing the title. (Also, kudos for citing both the independent works on AdaGrad)\n- page 11, last equation, 2C-4=2C-4. Same on page 13.\n- Lemma 4 contains x_1,x_2,z_1, and z_2: are x_1 and z_1 the same? also x_2 and z_2?""]","[70, 80, 80]","[80, 70, 70]","[""The sentiment score is 70 (positive) because the reviewer expresses strong interest in the paper's findings, calling it a 'very interesting observation' and stating that all issues 'can be readily addressed'. The overall tone is supportive and appreciative of the work's significance. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. Phrases like 'I would recommend' and the acknowledgment of the paper being 'well-written' contribute to the polite tone. The reviewer also provides detailed, helpful feedback without using dismissive or rude language."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'well written, interesting and very important'. They acknowledge the theoretical contribution and suggest its acceptance based on this work. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and acknowledges the paper's focus and strengths. They provide specific suggestions for improvement without being harsh or dismissive. The reviewer balances critique with praise, using phrases like 'this can easily improve the paper' and 'I understand that the focus of this work is theoretical', which maintain a polite and considerate tone."", ""The sentiment score is 80 (positive) because the reviewer strongly recommends acceptance, praises the paper's novelty and importance, and describes the contribution as 'very relevant'. The few criticisms are constructive and don't detract from the overall positive assessment. The politeness score is 70 (polite) due to the respectful tone throughout, use of phrases like 'I understand this is not the main objective', and the constructive nature of the suggestions. The reviewer maintains a professional and courteous tone while providing both praise and critique. The score isn't higher as the language, while polite, doesn't go out of its way to be exceptionally deferential.""]"
"['The authors has addressed my concerns, so I raised my rating. \n\nThe paper is grounded on a solid theoretical motivation and the analysis is sound and quite interesting.\n\nThere are no results on large corpora such as 1 billion tokens benchmark corpus, or at least medium level corpus with 50 million tokens. The corpora the authors choose are quite small, the variance of the estimates are high, and similar conclusions might not be valid on a large corpus. \n\n[1] provides the results of character level language models on Enwik8 dataset, which shows regularization doesn\'t have much effect and needs less tuning. Results on this data might be more convincing.\n\nThe results of MOS is very good, but the computation complexity is much higher than other baselines. In the experiments, the embedding dimension of MOS is slightly smaller, but the number of mixture is 15. This will make it less usable, I think it\'s necessary to provide the training time comparison.\n\nFinally experiments on machine translation or speech recognition should be done and to see what improvements the proposed method could bring for BLEU or WER. \n\n[1] Melis, Gábor, Chris Dyer, and Phil Blunsom. ""On the state of the art of evaluation in neural language models."" arXiv preprint arXiv:1707.05589 (2017).\n\n[2] Joris Pelemans, Noam Shazeer, Ciprian Chelba, Sparse Non-negative Matrix Language Modeling,  Transactions of the Association for Computational Linguistics, vol. 4 (2016), pp. 329-342\n\n[3] Shazeer et al. (2017). Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer. ICLR 2017\n', ""Language models are important components to many NLP tasks. The current state-of-the-art language models are based on recurrent neural networks which compute the probability of a word given all previous words using a softmax function over a linear function of the RNN's hidden state. This paper argues the softmax is not expressive enough and proposes to use a more flexible mixture of softmaxes. The use of a mixture of softmaxes is motivated from a theoretical point of view by translating language modeling into matrix factorization.\n\nPros:\n--The paper is very well written and easy to follow. The ideas build up on each other in an intuitive way.\n--The idea behind the paper is novel: translating language modeling into a matrix factorization problem is new as far as I know.\n--The maths is very rigorous.\n--The experiment section is thorough.\n\nCons:\n--To claim SOTA all models need to be given the same capacity (same number of parameters). In Table 2 the baselines have a lower capacity. This is an unfair comparison\n--I suspect the proposed approach is slower than the baselines. There is no mention of computational cost. Reporting that would help interpret the numbers. \n\nThe SOTA claim might not hold if baselines are given the same capacity. But regardless of this, the paper has very strong contributions and deserves acceptance at ICLR."", 'The authors argue in this paper that due to the limited rank of the  context-to-vocabulary logit matrix in the currently used version of the softmax output layer, it is not able to capture the full complexity of language. As a result, they propose to use a mixture of softmax output layers instead where the mixing probabilities are context-dependent, which allows to obtain a full rank logit matrix in complexity linear in the number of mixture components (here 15). This leads to improvements in the word-level perplexities of the PTB and wikitext2 data sets, and Switchboard BLEU scores.\n\nThe question of the expressiveness of the softmax layer, as well as its suitability for word-level prediction, is indeed an important one which has received too little attention. This makes a lot of the questions asked in this paper extremely relevant to the field. However, it is unclear that the rank of the logit matrix is the right quantity to consider. For example, it is easy to describe a rank D NxM matrix where up to 2^D lines have max values at different indices. Further, the first two ""observations"" in Section 2.2 would be more accurately described as ""intuitions"" of the authors. As they write themselves ""there is no evidence showing that semantic meanings are fully linearly correlated."" Why then try to link ""meanings"" to basis vectors for the rows of A?\n\nTo be clear, the proposed model is undoubtedly more expressive than a regular softmax, and although it does come at a substantial computational cost (a back-of-the envelope calculation tells us that computing 15 components of 280d MoS takes the same number of operations as one with dimension 1084 = sqrt (280*280*15)), it apparently manages not to drastically increase overfitting, which is significant.\n\nUnfortunately, this is only tested on relatively small data sets, up to 2M tokens and a vocabulary of size 30K for language modeling. They do constitute a good starting place to test a model, but given the importance of regularization on those specific tasks, it is difficult to predict how the MoS would behave if more training data were available, and if one could e.g. simply try a 1084 dimension embedding for the softmax without having to worry about overfitting.\n\nAnother important missing experiment would consist in varying the number of mixture components (this could very well be done on WikiText2). This could help validate the hypothesis: how does the estimated rank vary with the number of components? How about the performance and pairwise KL divergence? \n\nThis paper offers a promising direction for language modeling research, but would require more justification, or at least a more developed experimental section.\n\nPros:\n- Important starting question\n- Thought-provoking approach\n- Experimental gains on small data sets\n\nCons:\n- The link between the intuition and reality of the gains is not obvious\n- Experiments limited to small data sets, some obvious questions remain']","[20, 80, -20]","[50, 70, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges that their concerns have been addressed and they raised their rating. They also mention that the paper has a solid theoretical motivation and interesting analysis. However, they still have some criticisms and suggestions for improvement, which prevents a higher positive score. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging improvements and providing constructive feedback. They avoid harsh criticism and use phrases like 'I think it's necessary' instead of making demands. The tone is professional and courteous, though not overly effusive in praise."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, listing several pros and recommending acceptance despite some cons. They describe the paper as 'very well written', 'novel', and having 'very strong contributions'. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. They maintain a professional tone while still conveying enthusiasm for the work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the research question and the potential of the approach, they express several significant concerns and limitations of the study. The reviewer points out issues with the justification, limited experiments, and unanswered questions, which outweigh the positive aspects mentioned.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They acknowledge the merits of the work ('promising direction', 'thought-provoking approach') while offering constructive criticism. The language used is not overly formal or deferential, but it's also not harsh or dismissive, striking a balance between politeness and directness in academic discourse.""]"
"['This is a very well-written and nicely structured paper that tackles the problem of generating/inferring code given an incomplete description (sketch) of the task to be achieved. This is a novel contribution to existing machine learning approaches to automated programming that is achieved by training on a large corpus of Android apps. The combination of the proposed technique and leveraging of real data are a substantial strength of the work compared to many approaches that have come previously.\n\nThis paper has many strengths:\n1) The writing is clear, and the paper is well-motivated\n2) The proposed algorithm is described in excellent detail, which is essential to reproducibility\n3) As stated previously, the approach is validated with a large number of real Android projects\n4) The fact that the language generated is non-trivial (Java-like) is a substantial plus\n5) Good discussion of limitations\n\nOverall, this paper is a valuable addition to the empirical software engineering community, and a nice break from more traditional approaches of learning abstract syntax trees.', ""The authors introduce an algorithm in the subfield of conditional program generation that is able to create programs in a rich java like programming language. In this setting, they propose an algorithm based on sketches- abstractions of programs that capture the structure but discard program specific information that is not generalizable such as variable names. Conditioned on information such as type specification or keywords of a method they generate the method's body from the trained sketches. \n\xa0\nPositives:\n\xa0\n\t•\tNovel algorithm and addition of rich java like language in subfield of 'conditional program generation' proposed\n\t•\tVery good abstract: It explains high level overview of topic and sets it into context plus gives a sketch of the algorithm and presents the positive results.\n\t•\tExcellently structured and presented paper\n\xa0\n\t•\tMotivation given in form of relevant applications and mention that it is relatively unstudied\n\t•\tThe hypothesis/ the papers goal is clearly stated. It is introduced with 'We ask' followed by two well formulated lines that make up the hypothesis. It is repeated multiple times throughout the paper. Every mention introduces either a new argument on why this is necessary or sets it in contrast to other learners, clearly stating discrepancies.\n\t•\tExplanations are exceptionally well done: terms that might not be familiar to the reader are explained. This is true for mathematical aspects as well as program generating specific terms. Examples are given where appropriate in a clear and coherent manner\n\t•\tProblem statement well defined mathematically and understandable for a broad audience\n\t•\tMentioning of failures and limitations demonstrates a realistic  view on the project\n\t•\tComplexity and time analysis provided\n\t•\tPaper written so that it's easy for a reader to implement the methods\n\t•\tDetailed descriptions of all instantiations even parameters and comparison methods\n\t•\tSystem specified\n\t•\tValidation method specified\n\t•\tData and repository, as well as cleaning process provided\n\t•\tEvery figure and plot is well explained and interpreted\n\t•\tLarge successful evaluation section provided\n\t•\tMany different evaluation measures defined to measure different properties of the project\n\t•\tDifferent observability modes\n\t•\tEvaluation against most compatible methods from other sources \n\t•\t Results are in line with hypothesis\n\t•\tThorough appendix clearing any open questions \n\xa0\nIt would have been good to have a summary/conclusion/future work section\n\xa0\nSUMMARY: ACCEPT.  The authors present a very intriguing novel approach that  in a clear and coherent way. The approach is thoroughly explained for a large audience. The task itself is interesting and novel. The large evaluation section that discusses many different properties is a further indication that this approach is not only novel but also very promising. Even though no conclusive section is provided, the paper is not missing any information.\n"", 'This paper aims to synthesize programs in a Java-like language from a task description (X) that includes some names and types of the components that should be used in the program. The paper argues that it is too difficult to map directly from the description to a full program, so it instead formulates the synthesis in two parts. First, the description is mapped to a ""sketch"" (Y) containing high level program structure but no concrete details about, e.g., variable names. Afterwards, the sketch is converted into a full program (Prog) by stochastically filling in the abstract parts of the sketch with concrete instantiations.\n\nThe paper presents an abstraction method for converting a program into a sketch, a stochastic encoder-decoder model for converting descriptions to trees, and rejection sampling-like approach for converting sketches to programs. Experimentally, it is shown that using sketches as an intermediate abstraction outperforms directly mapping to the program AST. The data is derived from an online repository of ~1500 Android apps, and from that were extracted ~150k methods, which makes the data very respectable in terms of realisticness and scale. This is one of the strongest points of the paper.\n\nOne point I found confusing is how exactly the Combinatorial Concretization step works. Am I correct in understanding that this step depends only on Y, and that given Y, Prog is conditionally independent of X? If this is correct, how many Progs are consistent with a typical Y? Some additional discussion of why no learning is required for the P(Prog | Y) step would be appreciated.\n\nI\'m also curious whether using a stochastic latent variable (Z) is necessary. Would the approach work as well using a more standard encoder-decoder model with determinstic Z?\n\nSome discussion of Grammar Variational Autoencoder (Kusner et al) would probably be appropriate.\n\nOverall, I really like the fact that this paper is aiming to do program synthesis on programs that are more like those found ""in the wild"". While the general pattern of mapping a specification to abstraction with a neural net and then mapping the abstraction to a full program with a combinatorial technique is not necessarily novel, I think this paper adds an interesting new take on the pattern (it has a very different abstraction than say, DeepCoder), and this paper is one of the more interesting recent papers on program synthesis using machine learning techniques, in my opinion.\n']","[90, 90, 80]","[80, 80, 90]","[""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer uses phrases like 'very well-written,' 'nicely structured,' 'novel contribution,' and 'substantial strength.' They list five specific strengths and conclude that the paper is a 'valuable addition' to the field. The only slight limitation to a perfect score is the brief mention of 'limitations,' though this is presented as a positive aspect of the paper's discussion. The politeness score is 80 because the language is consistently respectful and appreciative. The reviewer uses polite and professional language throughout, offering praise and constructive comments. While not overly formal or excessively polite, the tone is consistently positive and encouraging, which contributes to its high politeness score."", ""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer lists numerous positives about the paper, including its novelty, clear structure, well-explained concepts, and thorough evaluation. The only minor criticism is the lack of a conclusion section, but this is outweighed by the many positives and the explicit 'ACCEPT' recommendation. The politeness score is 80 because the language used is consistently respectful and professional. The reviewer uses phrases like 'excellently structured', 'exceptionally well done', and 'very intriguing', which are polite and encouraging. The critique is presented constructively, and the overall tone is supportive and appreciative of the authors' work."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper's approach, data, and contribution to the field. They use phrases like 'one of the strongest points of the paper', 'I really like the fact that', and 'one of the more interesting recent papers'. The few criticisms are presented as questions or requests for clarification rather than negative judgments. The politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They phrase criticisms as questions or suggestions, use hedging language like 'I'm curious' and 'probably', and conclude with strong praise. The reviewer maintains a professional and courteous tone, balancing critique with appreciation for the work.""]"
"['This paper proposed a gradient-based meta-learning approach for continuous adaptation in nonstationary and adversarial environment. The idea is to treat a nonstationary task as a sequence of stationary tasks and train agents to exploit the dependencies between consecutive tasks such that they can deal with nonstationarities at test time. The proposed method was evaluated based on a nonstationary locomotion and within a competitive multi agent setting. For the later, this paper specifically designed the RomoSumo environment and defined iterated adaptation games to test various aspect of adaptation strategies. The empirical results in both cases demonstrate the efficacy of the proposed meta-learned adaptation rules over the baselines in the few-short regime. The superiority of meta-learners is further justified on a population level.\n\nThe paper addressed a very important problem for general AI and it is well-written. Careful experiment designs, and thorough comparisons make the results conniving. I\n\nFurther comments:\n\n1. In the experiment the trajectory number seems very small, I wonder if directly using importance weight as shown in (9) will cause high variance in the performance?\n\n2. One of the assumption in this work is that trajectories from T_i contain some information about T_{i+1}, I wonder what will happen if the mutually information is very small between them (The extreme case is that two tasks are independent), will current method still perform well?\n\nP7, For the RL^2 policy, the authors mentioned that “…with a given environment (or an opponent), reset the state once the latter changes” How does the agent know when an environment (or opponent) changes? \n\nP10, “This suggests that it meta-learned a particular…” This sentence need to be rewritten.\n\nP10, ELO is undefined\n', 'This is a dense, rich, and impressive paper on rapid meta-learning. It is already highly polished, so I have mostly minor comments.\n\nRelated work: I think there is a distinction between continual and life-long learning, and I think that your proposed setup is a form of continual learning (see Ring ‘94/‘97). Given the proliferation of terminology for very related setups, I’d encourage you to reuse the old term.\n\nTerminology: I find it confusing which bits are “meta” and which are not, and the paper could gain clarity by making this consistent. In particular, it would be good to explicitly name the “meta-loss” (currently the unnamed triple expectation in (3)). By definition, then, the “meta-gradient” is the gradient of the meta-loss -- and not the one in (2), which is the gradient of the regular loss.\n\nNotation: there’s redundancy/inconsistency in the reward definition: pick either R_T or \\bold{r}, not both, and maybe include R_T in the task tuple definition? It is also confusing that \\mathcal{R} is a loss, not a reward (and is minimized) -- maybe use another symbol?\n\nA question about the importance sampling correction: given that this spans multiple (long) trajectories, don’t the correction weights become really small in practice? Do you have some ballpark numbers?\n\nTypos:\n- “event their learning”\n- “in such setting”\n- “experience to for”\n', ""---- Summary ----\nThis paper addresses the problem of learning to operate in non-stationary environments, represented as a Markov chain of distinct tasks. The goal is to meta-learn updates that are optimal with respect to transitions between pairs of tasks, allowing for few-shot execution time adaptation that does not degrade as the environment diverges ever further from the training time task set.\n\nDuring learning, an inner loop iterates iterates over consecutive task pairs. For each pair, (T_i, T_{i+1}) trajectories sampled from T_i are used to construct a local policy that is then used to sample trajectories from T_{i+1}. By calculating the outer-loop policy gradient with respect to expectations of the trajectories sampled from T_i, and the trajectories sampled from T_{i+1} using the locally optimal inner-loop policy, the approach learns updates that are optimal with respect to the Markovian transitions between pairs of consecutive tasks.\n\nThe training time optimization algorithm requires multiple passes through a given sequence of tasks. Since this is not feasible at execution time, the trajectories calculated while solving task T_i are used to calculate updates for task T_{i+1} and these updates are importance weighted w.r.t the sampled trajectories' expectation under the final training-time policy.\n\nThe approach is evaluated on a pair of tasks. In the locomotion task, a six legged agent has to adapt to deal with an increasing inhibition to a pair of its legs. In the new RoboSumo task, agents have to adapt to effectively compete with increasingly competent components, that have been trained for longer periods of time via self-play.\n\nIt is clear that, in the locomotion task, the meta learning strategy maintains performance much more consistently than approaches that adapt through PPO-tracking, or implicitly by maintaining state in the RL^2 approach. This behaviour is less visible in the RoboSumo task (Fig 5.) but it does seem to present. Further experiments show that when the adaptation approaches are forced to fight against each other in 100 round iterated adaptation games, the meta learning strategy is dominant. However, the authors also do point out that this behaviour is highly dependent on the number of episodes allowed in each game, and when the agent can accumulate a large amount of evidence in a given environment the meta learning approach falls behind adaptation through tracking. The bias that allows the agent to learn effectively from few examples precludes it from effectively using many examples.\n\n---- Questions for author ----\nUpdates are performed from \\theta to \\phi_{i+1} rather than from \\phi_i to \\phi_{i+1}. Footnote 2 states that this was due to empirical observations of instability but it also necessitates the importance weight correction during execution time. I would like to know how the authors expect the sample in Eqn 9 to behave in much longer running scenarios, when \\pi_{\\phi} starts to diverge drastically from \\pi_{\\theta} but very few trajectories are available.\n\nThe spider-spider results in Fig. 6 do not support the argument that meta learning is better than PPO tracking in the few-shot regime. Do you have any idea of why this is?\n\n---- Nits ----\nThere is a slight muddiness of notation around the use of \\tau in lines 7 & 9 in  of Algorithm 1. I think it should be edited to line up with the definition given in Eqn. 8. \n\nThe figures in this paper depend excessively and unnecessarily on color. They should be made more printer, and colorblind, friendly.\n\n---- Conclusion ----\nI think this paper would be a very worthy contribution to ICLR. Learning to adapt on the basis of few observations is an important prerequisite for real world agents, and this paper presents a reasonable approach backed up by a suite of informative evaluations. The quality of the writing is high, and the contributions are significant. However, this topic is very much outside of my realm of expertise and I am unfamiliar with the related work, so I am assigning my review a low confidence.""]","[80, 80, 70]","[70, 70, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, calling it 'well-written' and praising its 'careful experiment designs' and 'thorough comparisons'. They state that the paper addresses 'a very important problem for general AI' and that the results are 'conniving' (likely meant 'convincing'). The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and questions without harsh criticism. They frame their comments as inquiries or suggestions rather than demands. The use of phrases like 'I wonder' and the professional tone contribute to the politeness. The score is not higher because while polite, it maintains a professional distance rather than being overly deferential."", ""The sentiment score is 80 (positive) because the reviewer starts by calling the paper 'dense, rich, and impressive' and mentions it's 'already highly polished'. This indicates a very positive overall impression. The score isn't higher because the reviewer does point out some areas for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering suggestions rather than demands (e.g., 'I'd encourage you to...', 'it would be good to...'), and frames criticisms as questions or observations rather than direct critiques. The reviewer also acknowledges the paper's strengths before offering suggestions. The score isn't higher because the language, while polite, is still direct and doesn't use excessive courtesy phrases."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper, stating it would be 'a very worthy contribution to ICLR' and praising the quality of writing and significance of contributions. They also note the importance of the topic. However, it's not a perfect score as the reviewer raises some questions and points out areas for improvement. The politeness score is 80 (polite) due to the constructive and respectful tone throughout. The reviewer offers praise where due, asks questions politely, and frames criticisms as suggestions for improvement rather than harsh judgments. The use of phrases like 'I would like to know' and 'Do you have any idea' contribute to the polite tone. The reviewer also humbly acknowledges their own limitations in expertise, which adds to the overall politeness.""]"
"['This paper borrows the classic idea of spectral regularization, recently applied to deep learning by Yoshida and Miyato (2017) and use it to normalize GAN objectives. The ensuing GAN, coined SN-GAN, essentially ensures the Lipschitz property of the discriminator. This Lipschitz property has already been proposed by recent methods and has showed some success. However,  the authors here argue that spectral normalization is more powerful; it allows for models of higher rank (more non-zero singular values) which implies a more powerful discriminator and eventually more accurate generator. This is demonstrated in comparison to weight normalization in Figure 4. The experimental results are very good and give strong support for the proposed normalization.\n\n\nWhile the main idea is not new to machine learning (or deep learning), to the best of my knowledge it has not been applied on GANs. The paper is overall well written (though check Comment 3 below), it covers the related work well and it includes an insightful discussion about the importance of high rank models. I am recommending acceptance, though I anticipate to see a more rounded evaluation of the exact mechanism under which SN improves over the state of the art. More details in the comments below.\n\nComments:\n1. One concern about this paper is that it doesn’t fully answer the reasons why this normalization works better. I found the discussion about rank to be very intuitive, however this intuition is not fully tested.  Figure 4 reports layer spectra for SN and WN. The authors claim that other methods, like (Arjovsky et al. 2017) also suffer from the same rank deficiency. I would like to see the same spectra included. \n2. Continuing on the previous point: maybe there is another mechanism at play beyond just rank that give SN its apparent edge? One way to test the rank hypothesis and better explain this method is to run a couple of truncated-SN experiments. What happens if you run your SN but truncate its spectrum after every iteration in order to make it comparable to the rank of WN? Do you get comparable inception scores? Or does SN still win?\n3. Section 4 needs some careful editing for language and grammar.\n', 'This paper proposes ""spectral normalization"" -- constraining the spectral norm of the weights of each layer -- as a way to stabilize GAN training by in effect bounding the Lipschitz constant of the discriminator function. The paper derives efficient approximations for the spectral norm, as well as an analysis of its gradient. Experimental results on CIFAR-10 and STL-10 show improved Inception scores and FID scores using this method compared to other baselines and other weight normalization methods.\n\nOverall, this is a well-written paper that tackles an important open problem in training GANs using a well-motivated and relatively simple approach. The experimental results seem solid and seem to support the authors\' claims. I agree with the anonymous reviewer that connections (and differences) to related work should be made clearer. Like the anonymous commenter, I also initially thought that the proposed ""spectral normalization "" is basically the same as ""spectral norm regularization"", but given the authors\' feedback on this I think the differences should be made more explicit in the paper.\n\nOverall this seems to represent a strong step forward in improving the training of GANs, and I strongly recommend this paper for publication.\n\nSmall Nits: \n\nSection 4: ""In order to evaluate the efficacy of our experiment"": I think you mean ""approach"".\n\nThere are a few colloquial English usages which made me smile, e.g. \n * Sec 4.1.1. ""As we prophesied ..."", and in the paragraph below \n * ""... is a tad slower ..."".', 'The paper is motivated by the fact that in GAN training, it is beneficial to constrain the Lipschitz continuity of the discriminator. The authors observe that the product of spectral norm of gradients per each layer serves as a good approximation of the overall Lipschitz continuity of the entire discriminating network, and propose gradient based methods to optimize a ""spectrally normalized"" objective.\n\nI think the methodology presented in this paper is neat and the experimental results are encouraging. However, I do have some comments on the presentation of the paper:\n\n1. Using power method to approximate matrix largest singular value is a very old idea, and I think the authors should cite some more classical references in addition to (Yoshida and Miyato). For example,\n\nMatrix Analysis, book by Bhatia\nMatrix computation, book by Golub and Van Loan.\n\nSome recent work in theory of (noisy) power method might also be helpful and should be cited, for example,\nhttps://arxiv.org/abs/1311.2495\n\n2. I think the matrix spectral norm is not really differentiable; hence the gradients the authors calculate in the paper should really be subgradients. Please clarify this.\n\n3. It should be noted that even with the product of gradient norm, the resulting normalizer is still only an upper bound on the actual Lipschitz constant of the discriminator. Can the authors give some empirical evidence showing that this approximation is much better than previous approximations, such as L2 norms of gradient rows which appear to be much easier to optimize?']","[70, 90, 50]","[80, 80, 80]","[""The sentiment score is 70 (positive) because the reviewer recommends acceptance and describes the paper's results as 'very good' and giving 'strong support' for the proposed method. They also praise the paper as 'well written' and having 'insightful discussion'. However, it's not 100 as they do have some concerns and suggestions for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their criticisms constructively as suggestions for improvement rather than harsh critiques. They use phrases like 'I would like to see' and 'maybe there is another mechanism' which are polite ways of suggesting changes. The language is professional and courteous throughout."", ""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer describes the paper as 'well-written', tackling 'an important open problem', and using a 'well-motivated and relatively simple approach'. They 'strongly recommend this paper for publication' and state it represents 'a strong step forward'. The only slight criticisms are minor suggestions for clarity. The politeness score is 80 because the reviewer uses respectful and encouraging language throughout. They acknowledge the authors' work positively and offer constructive feedback. The use of phrases like 'which made me smile' when pointing out colloquialisms shows a friendly tone. However, it's not 100 as there's still a professional distance maintained."", ""The sentiment score is 50 (slightly positive) because the reviewer states that the methodology is 'neat' and the results are 'encouraging', indicating a generally positive view. However, they also have some comments and suggestions for improvement, which tempers the positivity somewhat. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'I think the authors should...'), and acknowledges the positive aspects of the paper before offering suggestions. The reviewer also uses polite phrases like 'I think' and 'Please clarify' when making requests or observations.""]"
"[""The paper introduces an application of Graph Neural Networks (Li's Gated Graph Neural Nets, GGNNs, specifically) for reasoning about programs and programming. The core idea is to represent a program as a graph that a GGNN can take as input, and train the GGNN to make token-level predictions that depend on the semantic context. The two experimental tasks were: 1) identifying variable (mis)use, ie. identifying bugs in programs where the wrong variable is used, and 2) predicting a variable's name by consider its semantic context.\n\nThe paper is generally well written, easy to read and understand, and the results are compelling. The proposed GGNN approach outperforms (bi-)LSTMs on both tasks. Because the tasks are not widely explored in the literature, it could be difficult to know how crucial exploiting graphically structured information is, so the authors performed several ablation studies to analyze  this out. Those results show that as structural information is removed, the GGNN's performance diminishes, as expected. As a demonstration of the usefulness of their approach, the authors ran their model on an unnamed open-source project and claimed to find several bugs, at least one of which potentially reduced memory performance.\n\nOverall the work is important, original, well-executed, and should open new directions for deep learning in program analysis. I recommend it be accepted."", 'Summary:  The paper applies graph convolutions with deep neural networks to the problem of ""variable misuse"" (putting the wrong variable name in a program statement) in graphs created deterministically from source code.  Graph structure is determined by program abstract syntax tree (AST) and next-token edges, as well as variable/function name identity, assignment and other deterministic semantic relations.  Initial node embedding comes from both type and tokenized name information.  Gated Graph Neural Networks (GGNNs, trained by maximum likelihood objective) are then run for 8 iterations at test time.\n\nThe evaluation is extensive and mostly very good.  Substantial data set of 29m lines of code.  Reasonable baselines.  Nice ablation studies.  I would have liked to see separate precision and recall rather than accuracy.  The current 82.1% accuracy is nice to see, but if 18% of my program variables were erroneously flagged as errors, the tool would be useless.  I\'d like to know if you can tune the threshold to get a precision/recall tradeoff that has very few false warnings, but still catches some errors.\n\nNice work creating an implementation of fast GGNNs with large diverse graphs.  Glad to see that the code will be released.  Great to see that the method is fast---it seems fast enough to use in practice in a real IDE.\n\nThe model (GGNN) is not particularly novel, but I\'m not much bothered by that.  I\'m very happy to see good application papers at ICLR.  I agree with your pair of sentences in the conclusion: ""Although source code is well understood and studied within other disciplines such as programming language research, it is a relatively new domain for deep learning. It presents novel opportunities compared to textual or perceptual data, as its (local) semantics are well-defined and rich additional information can be extracted using well-known, efficient program analyses.""  I\'d like to see work in this area encouraged.  So I recommend acceptance.  If it had better (e.g. ROC curve) evaluation and some modeling novelty, I would rate it higher still.\n\nSmall notes:\nThe paper uses the term ""data flow structure"" without defining it.\nYour data set consisted of C# code.  Perhaps future work will see if the results are much different in other languages.\n', ""This paper presents a novel application of machine learning using Graph NN's on ASTs to identify incorrect variable usage and predict variable names in context. It is evaluated on a corpus of 29M SLOC, which is a substantial strength of the paper.\n\nThe paper is to be commended for the following aspects:\n1) Detailed description of GGNNs and their comparison to LSTMs\n2) The inclusion of ablation studies to strengthen the analysis of the proposed technique\n3) Validation on real-world software data\n4) The performance of the technique is reasonable enough to actually be used.\n\nIn reviewing the paper the following questions come to mind:\n1) Is the false positive rate too high to be practical?  How should this be tuned so developers would want to use the tool?\n2) How does the approach generalize to other languages? (Presumably well, but something to consider for future work.)\n\nDespite these questions, though, this paper is a nice addition to deep learning applications on software data and I believe it should be accepted.\n\n""]","[90, 70, 80]","[80, 80, 90]","[""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer describes the paper as 'well written, easy to read and understand,' with 'compelling' results. They state that the work is 'important, original, well-executed' and recommend acceptance. The only reason it's not 100 is because there's no explicit enthusiasm or excitement expressed.\n\nThe politeness score is 80 because the language used is professional and respectful throughout. The reviewer offers constructive feedback and praises the authors' work without using overly effusive language. They maintain a courteous tone while providing a thorough analysis. The score isn't higher because while polite, it doesn't go out of its way to be exceptionally warm or friendly."", ""The sentiment score is 70 (positive) because the reviewer expresses overall approval of the paper, recommending acceptance and praising various aspects such as the extensive evaluation, good application, and fast implementation. However, it's not 100 as the reviewer also points out some limitations and areas for improvement. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, offering constructive criticism and positive feedback. The reviewer acknowledges the paper's strengths with phrases like 'Nice work' and 'Great to see,' while also politely suggesting improvements. The tone is professional and encouraging, without any rudeness or harsh criticism."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, commending several aspects and recommending acceptance. The phrase 'nice addition' and the list of strengths indicate a very positive view. The score is not 100 as there are some questions raised, though they are presented as minor concerns. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'to be commended' and frames questions as considerations rather than criticisms. The language is professional and appreciative throughout, without any harsh or rude elements.""]"
"['The authors describe a method called WAGE, which quantize all operands and operators in a neural network, specifically, the weights (W), activations (A), gradients (G), and errors (E) . The idea is using quantizers with clipping (denoted in the paper with Q(x,k)) and some additional operators like shift (denoted with shift(x)) and stochastic rounding. The main motivation of the authors in this work is to reduce the number of bits for representation in a network for all the WAGE operations and operands which influences the power consumption and silicon area in hardware implementations.\n\nAfter introducing the idea and related work, the authors in Section 3 give details about how to perform the quantization. They introduce the additional operators needed for training in such network. Since quantization may loss some information, the authors need to quantize the signals in the network around the dynamic range in order not to ""kill"" the signal. The authors describe how to do that. Afterward, as in other techniques for quantization, they describe how to initialize the network values. Also, they argue that batch normalization in this network is replaced with the shift-quantize operations, and what is matter in this case is (1) the relative values (“orientations”) and not the absolute values and (2) small values in errors are negligible.\n\nAfterward, the authors conduct experiments on MNIST, SVHN, CIFAR10, and ILSVRC12 datasets, where they show promising results compared to the errors provided by previous works. The WAGE parameters (i.e., the quantized no. of bits used) are 2-8-8-8, respectively. For understand more the WAGE, the authors compare on CIFAR10 the test error rate with vanilla CNN and show is small loss in using their network. The authors investigate mainly the bitwidth of errors and gradients.\n\nIn overall, this paper is an accept since it shows good performance on standard problems and invent some nice tricks to implement NN in hardware, for *both* training and inference. For inference only, other works has more to offer but this is a promising technique for learning. The things that are still missing in this work are some power reduction estimates as well as area reduction estimations. This will give the hardware community a clear vision of how such methods may be implemented both in data centers as well as on end portable devices. \n', 'The authors propose WAGE, which discretized weights, activations, gradients, and errors at both training and testing time. By quantization and shifting, SGD training without momentum, and removing the softmax at output layer as well, the model managed to remove all cumbersome computations from every aspect of the model, thus eliminating the need for a floating point unit completely. Moreover, by keeping up to 8-bit accuracy, the model performs even better than previously proposed models. I am eager to see a hardware realization for this method because of its promising results. \n\nThe model makes a unified discretization scheme for 4 different kinds of components, and the accuracy for each of the kind becomes independently adjustable. This makes the method quite flexible and has the potential to extend to more complicated networks, such as attention or memory. \n\nOne caveat is that there seem to be some conflictions in the results shown in Table 1, especially ImageNet. Given the number of bits each of the WAGE components asked for, a 28.5% top 5 error rate seems even lower than XNOR. I suspect it is due to the fact that gradients and errors need higher accuracy for real-valued input, but if that is the case, accuracies on SVHN and CIFAR-10 should also reflect that. Or, maybe it is due to hyperparameter setting or insufficient training time?\n\nAlso, dropout seems not conflicting with the discretization. If there are no other reasons, it would make sense to preserve the dropout in the network as well.\n\nIn general, the paper was written in good quality and in detail, I would recommend a clear accept.\n', 'This paper proposes a method to train neural networks with low precision. However, it is not clear if this work obtains significant improvements over previous works. \n\nNote that:\n1)\tWorking with 16bit, one can train neural networks with little to no reduction in performance. For example, on ImageNet with AlexNet one gets 45.11% top-1 error if we don’t do anything else, and 42.34% (similar to the 32-bit result) if we additionally adjust the loss scale (e.g., see Boris Ginsburg, Sergei Nikolaev, and Paulius Micikevicius. “Training of deep networks with halfprecision float.” NVidia GPU Technology Conference, 2017). \n2)\tImageNet with AlexNet top-1 error (53.5%) in this paper seems rather high in comparison to previous works. Specifically, DoReFA and QNN, which used mostly lower precision (k_W=1, k_A=2 and k_E=6, k_G=32)  one can get much lower performance (47% and 49%, respectively). So, the main innovation here, in comparison, is k_G=12.\n3)\tComparison using other datasets is made with different architectures then previous works, so it is hard to quantify what is the contribution of the proposed method. For example, on MNIST, the authors use a convolutional neural network, while BC and BNN used a fully connected neural network (the so called “permutation invariant mnist” problem).\n4)\tCifar performance is good, but may seem less remarkable, given that “Gated XNOR Networks: Deep Neural Networks with Ternary Weights and Activations under a Unified Discretization Framework” already showed that k_G=k_W=k_A=2, k_E=32 is sufficient to get 7.5% error on CIFAR. So the main novelty, in comparison, is that k_E=12.\n\nTaking all the above into account, it hard to be sure whether the proposed methods meaningfully improve existing methods. Moreover, I am not sure if decreasing the precision from 16bit to 12bit (as was done on ImageNet) is very useful for hardware applications, especially if there is such a degradation in accuracy. If, for example, the authors would have demonstrated all-8bit training on all datasets with little performance degradation, this would seem much more useful.\n\nMinor: there are some typos that should be corrected, e.g.: “Empirically, We demonstrates” in abstract.\n\n%%% Following the authors response %%%\nThe authors have improved their results and have addressed my concerns. I therefore raised my scores.\n\n']","[70, 0, 0]","[50, 0, 0]","[""The sentiment score is 70 (positive) because the reviewer states that 'this paper is an accept' and describes the work as showing 'good performance' and being a 'promising technique'. They also mention 'promising results' compared to previous works. The overall tone is supportive, although they do point out some missing elements. The politeness score is 50 (somewhat polite) because the reviewer uses neutral, professional language throughout. They offer constructive criticism and suggestions without using harsh or negative language. The reviewer acknowledges the paper's strengths while also pointing out areas for improvement in a respectful manner. The language is not overly formal or excessively polite, but maintains a courteous and professional tone throughout."", 'ERROR', 'ERROR']"
"['This paper presents methods to reduce the variance of policy gradient using an action dependent baseline. Such action dependent baseline can be used in settings where the action can be decomposed into factors that are conditionally dependent given the state. The paper:\n(1) shows that using separate baselines for actions, each of which can depend on the state and other actions is bias-free\n(2) derive the optimal action-dependent baseline, showing that it does not degenerate into state-only dependent baseline, i.e. there is potentially room for improvement over state-only baselines.\n(3) suggests using marginalized action-value (Q) function as a practical baseline, generalizing the use of value function in state-only baseline case.\n(4) suggests using MC marginalization and also using the ""average"" action to improve computational feasibility\n(5) combines the method with GAE techniques to further improve convergence by trading off bias and variance\n\nThe suggested methods are empirically evaluated on a number of settings. Overall action-dependent baseline outperform state-only versions. Using a single average action marginalization is on par with MC sampling, which the authors attribute to the low quality of the Q estimate. Combining GAE shows that a hint of bias can be traded off with further variance reduction to further improve the performance.\n\nI find the paper interesting and practical to the application of policy gradient in high dimensional action spaces with some level of conditional independence present in the action space. In light of such results, one might change the policy space to enforce such structure.\n\nNotes:\n- Elaborate further on the assumption made in Eqn 9. Does it mean that the actions factors cannot share (too many) parameters in the policy construction, or that shared parameters can only be applied to the state?\n- Eqn 11 should use \\simeq\n- How can the notion of average be extended to handle multi-modal distributions, or categorical or structural actions? Consider expanding on that in section 4.5.\n- The discussion on the DAG graphical model is lacking experimental analysis (where separate baselines models are needed). How would you train such baselines?\n- Figure 4 is impossible to read in print. The fonts are too small for the numbers and the legends.\n', 'The paper proposes a variance reduction technique for policy gradient methods. The proposed approach justifies the utilization of action-dependent baselines, and quantifies the gains achieved by it over more general state-dependent or static baselines.\n\n\nThe writing and organization of the paper is very well done. It is easy to follow, and succinct while being comprehensive. The baseline definition is well-motivated, and the benefits offered by it are quantified intuitively. There is only one mostly minor issues with the algorithm development and the experiments need to be more polished. \n\nFor the algorithm development, there is an relatively strong assumption that z_i^T z_j = 0. This assumption is not completely unrealistic (for example, it is satisfied if completely separate parts of a feature vector are used for actions). However, it should be highlighted as an assumption, and it should be explicitly stated as z_i^T z_j = 0 rather than z_i^T z_j approx 0. Further, because it is relatively strong of an assumption, it should be discussed more thoroughly, with some explicit examples of when it is satisfied.\n\nOtherwise, the idea is simple and yet effective, which is exactly what we would like for our algorithms. The paper would be a much stronger contribution, if the experiments could be improved. \n- More details regarding the experiments are desirable - how many runs were done, the initialization of the policy network and action-value function, the deep architecture used etc.\n- The experiment in Figure 3 seems to reinforce the influence of \\lambda as concluded by the Schulman et. al. paper. While that is interesting, it seems unnecessary/non-relevant here, unless performance with action-dependent baselines with each value of \\lambda is contrasted to the state-dependent baseline. What was the goal here?\n- In general, the graphs are difficult to read; fonts should be improved and the graphs polished. \n- The multi-agent task needs to be explained better - specifically how is the information from the other agent incorporated in an agent\'s baseline?\n- It\'d be great if Plot (a) and (b) in Figure 5 are swapped.\n\nOverall I think the idea proposed in the paper is beneficial. Better discussing the strong theoretical assumption should be incorporated. Adding the listed suggestions to the experiments section would really help highlight the advantage of the proposed baseline in a more clear manner. Particularly with some clarity on the experiments, I would be willing to increase the score. \n\nMinor comments:\n1. In Equation (28) how is the optimal-state dependent baseline obtained? This should be explicitly shown, at least in the appendix. \n2. The listed site for videos and additional results is not active.\n3. Some typos\n- Section 2 - 1st para - last line: ""These methods are therefore usually more sample efficient, but can be less stable than critic-based methods."".\n- Section 4.1 - Equation (7) - missing subscript i for b(s_t,a_t^{-i}) \n- Section 4.2 - \\hat{Q} is just Q in many places', ""In this paper, the authors investigate variance reduction techniques for agents with multi-dimensional policy outputs, in particular when they are conditionally independent ('factored'). With the increasing focus on applying RL methods to continuous control problems and RTS type games, this is an important problem and this technique seems like an important addition to the RL toolbox. The paper is well written, the method is easy to implement, and the algorithm seems to have clear positive impact on the presented experiments.\n\n- The derivations in pages 4-6 are somewhat disconnected from the rest of the paper: the optimal baseline derivation is very standard (even if adapted to the slightly different situation situated here), and for reasons highlighted by the authors in this paper, they are not often used; the 'marginalized' baseline is more common, and indeed, the authors adopt this one as well. In light of this (and of the paper being quite a bit over the page limit)- is this material (4.2->4.4) mostly not better suited for the appendix? Same for section 4.6 (which I believe is not used in the experiments).\n\n- The experimental section is very strong; regarding the partial observability experiments, assuming actions are here factored as well, I could see four baselines \n(two choices for whether the baseline has access to the goal location or not, and two choices for whether the baseline has access to the vector $a_{-i}$). It's not clear which two baselines are depicted in 5b - is it possible to disentangle the effect of providing $a_{-i}$ and the location of the hole to the baseline?\n\n(side note: it is an interesting idea to include information not available to the agent as input to the baseline though it does feel a bit 'iffy' ; the agent requires information to train, but is not provided the information to act.  Out of curiosity, is it intended as an experiment to verify the need for better baselines? Or as a 'fair' training procedure?)\n\n- Minor: in equation 2- is the correct exponent not t'?  Also since $\\rho_\\pi$ is define with a scaling $(1-\\gamma)$ (to make it an actual distribution), I believe the definition of $\\eta$ should also be multiplied by $(1-\\gamma)$ (as well as equation 2).""]","[80, 0, 0]","[70, 0, 0]","[""The sentiment score is 80 (positive) because the reviewer finds the paper 'interesting and practical' and provides a detailed summary of the paper's contributions without major criticisms. The overall tone is supportive and appreciative of the work. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames suggestions as 'notes' rather than demands. The reviewer maintains a professional and courteous tone while providing specific recommendations for improvement."", 'ERROR', 'ERROR']"
"['The paper describes a number of modifications of GAN training that enable synthesis of high-resolution images. The modifications also support more automated longer-term training, and increasing variability in the results.\n\nThe key modification is progressive growing. First, a GAN is trained for image synthesis at very low resolution. Then a layer that refines the resolution is progressively faded in. (More accurately, a corresponding pair of layers, one in the generation and one in the discriminator.) This progressive fading in of layers is repeated, one octave at a time, until the desired resolution is reached.\n\nAnother modification reported in the paper is a simple parameter-free minibatch summary statistic feature that is reported to increase variation. Finally, the paper describes simple schemes for initialization and feature normalization that are reported to be more effective than commonly used initializers and batchnorm.\n\nIt\'s a very nice paper. It does share the ""bag of tricks"" nature of many GAN papers, but as such it is better than most of the lot. I appreciate that some of the tricks actually simplify training, and most are conceptually reasonable. The paper is also very well written.\n\nMy quibbles are minor. First, I would discuss [Huang et al., CVPR 2017] and the following paper more prominently:\n\n[Zhang et al., ICCV 2017] H. Zhang, T. Xu, H. Li, S. Zhang, X. Wang, X. Huang, and D. Metaxas. StackGAN: Text to photo-realistic image synthesis with stacked generative adversarial networks. In ICCV, 2017.\n\nI couldn\'t find a discussion of [Huang et al., CVPR 2017] at all, although it\'s in the bibliography. (Perhaps I overlooked the discussion.) And [Zhang et al., ICCV 2017] is quite closely related, since it also tackles high-resolution synthesis via multi-scale refinement. These papers don\'t diminish the submission, but they should be clearly acknowledged and the contribution of the submission relative to these prior works should be discussed.\n\nAlso, [Rabin et al., 2011] is cited in Section 5 but I couldn\'t find it in the bibliography.\n', 'This paper proposes a number of ideas for improving GANs for image generation, highlighting in particular a curriculum learning strategy to progressively increase the resolution of the generated images, resulting in GAN generators capable of producing samples with unprecedented resolution and visual fidelity.\n\n\nPros:\n\nThe paper is well-written and the results speak for themselves! Qualitatively they’re an impressive and significant improvement over previous results from GANs and other generative models.  The latent space interpolations shown in the video (especially on CelebA-HQ) demonstrate that the generator can smoothly transition between modes and convince me that it isn’t simply memorizing the training data. (Though I think this issue could be addressed a bit better -- see below.) Though quantification of GAN performance is difficult and rapidly evolving, there is a lot of quantitative analysis all pointing to significant improvements over previous methods.\n\nA number of new tricks are proposed, with the ablation study (tab 1 + fig 3) and learning curves (fig 4) giving insight into their effects on performance.  Though the field is moving quickly, I expect that several of these tricks will be broadly adopted in future work at least in the short to medium term.\n\nThe training code and data are released.\n\n\nCons/Suggestions:\n\nIt would be nice to see overfitting addressed and quantified in some way.  For example, the proposed SWD metric could be recomputed both for the training and for a held-out validation/test set, with the difference between the two scores measuring the degree of overfitting.  Similarly, Danihelka et al. [1] show that an independently trained Wasserstein critic (with one critic trained on G samples vs. train samples, and another trained on G samples vs. val samples) can be used to measure overfitting.  Another way to go could be to generate a large number of samples and show the nearest neighbor for a few training set samples and for a few val set samples.  Doing this in pixel space may not work well especially at the higher resolutions, but maybe a distance function in the space of some high-level hidden layer of a trained discriminator could show good semantic nearest neighbors.\n\nThe proposed SWD metric is interesting and computationally convenient, but it’s not clear to me that it’s an improvement over previous metrics like the independent Wasserstein critic proposed in [1].  In particular the use of 7x7 patches would seem to limit the metric’s ability to capture the extent to which global structure has been learned, even though the patches are extracted at multiple levels of the Laplacian pyramid.\n\nThe ablation study (tab 1 + fig 3) leaves me somewhat unsure which tricks contribute the most to the final performance improvement over previous work.  Visually, the biggest individual improvement is easily when going from (c) to (d), which adds the “Revised training parameters”, with the improvement from (a) to (b) which adds the highlighted progressive training schedule appearing relatively minor in comparison.  However, I realize the former large improvement is due to the arbitrary ordering of the additions in the ablation study, with the small minibatch addition in (c) crippling results on its own.  Ablation studies with large numbers of tweaks are always difficult and this one is welcome and useful despite the ambiguity.\n\nOn a related note, it would be nice if there were more details on the “revised training hyperparameters” improvement ((d) in the ablation study) -- which training hyperparameters are adjusted, and how?\n\n“LAPGAN” (Denton et al., 2015) should be cited as related work: LAPGAN’s idea of using a separate generator/discriminator at each level of a Laplacian pyramid conditioned on the previous level is quite relevant to the progressive training idea proposed here.  Currently the paper is only incorrectly cited as “DCGAN” in a results table -- this should be fixed as well.\n\n\nOverall, this is a well-written paper with striking results and a solid effort to analyze, ablate, and quantify the effect of each of the many new techniques proposed. It’s likely that the paper will have a lot of impact on future GAN work.\n\n\n[1] Danihelka et al., “Comparison of Maximum Likelihood and GAN-based training of Real NVPs” https://arxiv.org/abs/1705.05263', 'Before the actual review I must mention that the authors provide links in the paper that immediately disclose their identity (for instance, the github link). This is a violation of double-blindness, and in any established double-blind conference this would be a clear reason for automatic rejection. In case of ICLR, double-blindness is new and not very well described in the call for papers, so I guess it’s up to ACs/PCs to decide. I would vote for rejection. I understand in the age of arxiv and social media double-blindness is often violated in some way, but here the authors do not seem to care at all. \n\n—\n\nThe paper proposes a collections of techniques for improving the performance of Generative Adversarial Networks (GANs). The key contribution is a principled multi-scale approach, where in the process of training both the generator and the discriminator are made progressively deeper and operate on progressively larger images. The proposed version of GANs allows generating images of high resolution (up to 1024x1024) and high visual quality.\n\nPros:\n1) The visual quality of the results is very good, both on faces and on objects from the LSUN dataset. This is a large and clear improvement compared to existing GANs.\n2) The authors perform a thorough quantitative evaluation, demonstrating the value of the proposed approach. They also introduce a new metric - Sliced Wasserstein Distance.\n3) The authors perform an ablation study illustrating the value of each of the proposed modifications.\n\nCons:\n1) The paper only shows results on image generation from random noise. The evaluation of this task is notoriously difficult, up to impossible (Theis et al., ICLR 2016). The authors put lots of effort in the evaluation, but still:\n- it is unclear what is the average quality of the samples - a human study might help\n- it is unclear to which extent the images are copied from the training set.  The authors show some nearest neighbors from the training set, but very few and in the pixel space, which is known to be pointless (again, Theis et al. 2016). Interpolations in the latent space is a good experiment, but in fact the interpolations do not look that great on LSUN\n- it is unclear if the model covers the full diversity of images (mode collapse)\nIt would be more convincing to demonstrate some practical results, for instance inpainting, superresolution, unsupervised or semi-supervised learning, etc.\n2) The general idea of multi-scale generation is not new, and has been investigated for instance in LapGAN (Denton et al., ICLR 2015) or StackGAN (Zhang et al., ICCV2017, arxiv 2017). The authors should properly discuss this. \n3) The authors mention “unhealthy competition” between the discriminator and the generator several times, but it is not quite clear what exactly they mean - a more specific definition would be useful.\n\n(This conclusion does not take the anonymity violation into account. Because of the violation I believe the paper should be rejected. Of course I am open to discussions with ACs/PCs.) \nTo conclude, the paper demonstrates a breakthrough in the quality and resolution of images generated with a GAN. The experimental evaluation is thorough, to the degree allowed by the poorly defined task of generating images from random noise. Results on some downstream tasks, such as inpainting, image processing or un-/semi-supervised learning would make the paper more convincing. Still, the paper should definitely be accepted for publication. Normally, I would give the paper a rating of 8.']","[80, 0, 0]","[90, 0, 0]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'very nice' and 'better than most of the lot'. They appreciate aspects of the work and state that the paper is 'very well written'. The few criticisms are described as 'minor quibbles'. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'I appreciate' and 'I would discuss', offering suggestions rather than demands. They acknowledge the paper's strengths before mentioning areas for improvement, and describe their concerns as 'quibbles', which is a polite way to express minor criticisms."", 'ERROR', 'ERROR']"
"['This paper investigates the impact of character-level noise on various flavours of neural machine translation. It tests 4 different NMT systems with varying degrees and types of character awareness, including a novel meanChar system that uses averaged unigram character embeddings as word representations on the source side. The authors test these systems under a variety of noise conditions, including synthetic scrambling and keyboard replacements, as well as natural (human-made) errors found in other corpora and transplanted to the training and/or testing bitext via replacement tables. They show that all NMT systems, whether BPE or character-based, degrade drastically in quality in the presence of both synthetic and natural noise, and that it is possible to train a system to be resistant to these types of noise by including them in the training data. Unfortunately, they are not able to show any types of synthetic noise helping address natural noise. However, they are able to show that a system trained on a mixture of error types is able to perform adequately on all types of noise.\n\nThis is a thorough exploration of a mostly under-studied problem. The paper is well-written and easy to follow. The authors do a good job of positioning their study with respect to related work on black-box adversarial techniques, but overall, by working on the topic of noisy input data at all, they are guaranteed novelty. The inclusion of so many character-based systems is very nice, but it is the inclusion of natural sources of noise that really makes the paper work. Their transplanting of errors from other corpora is a good solution to the problem, and one likely to be built upon by others. In terms of negatives, it feels like this work is just starting to scratch the surface of noise in NMT. The proposed meanChar architecture doesn’t look like a particularly good approach to producing noise-resistant translation systems, and the alternative solution of training on data where noise has been introduced through replacement tables isn’t extremely satisfying. Furthermore, the use of these replacement tables means that even when the noise is natural, it’s still kind of artificial. Finally, this paper doesn’t seem to be a perfect fit for ICLR, as it is mostly experimental with few technical contributions that are likely to be impactful; it feels like it might be more at home and have greater impact in a *ACL conference.\n\nRegarding the artificialness of their natural noise - obviously the only solution here is to find genuinely noisy parallel data, but even granting that such a resource does not yet exist, what is described here feels unnaturally artificial. First of all, errors learned from the noisy data sources are constrained to exist within a word. This tilts the comparison in favour of architectures that retain word boundaries (such as the charCNN system here), while those systems may struggle with other sources of errors such as missing spaces between words. Second, if I understand correctly, once an error is learned from the noisy data, it is applied uniformly and consistently throughout the training and/or test data. This seems worse than estimating the frequency of the error and applying them stochastically (or trying to learn when an error is likely to occur). I feel like these issues should at least be mentioned in the paper, so it is clear to the reader that there is work left to be done in evaluating the system on truly natural noise.\n\nAlso, it is somewhat jarring that only the charCNN approach is included in the experiments with noisy training data (Table 6). I realize that this is likely due to computational or time constraints, but it is worth providing some explanation in the text for why the experiments were conducted in this manner. On a related note, the line in the abstract stating that “... a character convolutional neural network  is able to simultaneously learn representations robust to multiple kinds of noise” implies that the other (non-charCNN) architectures could not learn these representations, when in reality, they simply weren’t given the chance.\n\nSection 7.2 on the richness of natural noise is extremely interesting, but maybe less so to an ICLR audience. From my perspective, it would be interesting to see that section expanded, or used as the basis for future work on improve architectures or training strategies.\n\nI have only one small, specific suggestion: at the end of Section 3, consider deleting the last paragraph break, so there is one paragraph for each system (charCNN currently has two paragraphs).\n\n[edited for typos]', 'This paper empirically investigates the performance of character-level NMT systems in the face of character-level noise, both synthesized and natural. The results are not surprising:\n\n* NMT is terrible with noise.\n\n* But it improves on each noise type when it is trained on that noise type.\n\nWhat I like about this paper is that:\n\n1) The experiments are very carefully designed and thorough.\n\n2) This problem might actually matter. Out of curiosity, I ran the example (Table 4) through Google Translate, and the result was gibberish. But as the paper shows, it’s easy to make NMT robust to this kind of noise, and Google (and other NMT providers) could do this tomorrow. So this paper could have real-world impact.\n\n3) Most importantly, it shows that NMT’s handling of natural noise does *not* improve when trained with synthetic noise; that is, the character of natural noise is very different. So solving the problem of natural noise is not so simple… it’s a *real* problem. Speculating, again: commercial MT providers have access to exactly the kind of natural spelling correction data that the researchers use in this paper, but at much larger scale. So these methods could be applied in the real world. (It would be excellent if an outcome of this paper was that commercial MT providers answered it’s call to provide more realistic noise by actually providing examples.)\n\nThere are no fancy new methods or state-of-the-art numbers in this paper. But it’s careful, curiosity-driven empirical research of the type that matters, and it should be in ICLR.', 'This paper investigates the impact of noisy input on Machine Translation, and tests simple ways to make NMT models more robust.\n\nOverall the paper is a clearly written, well described report of several experiments. It shows convincingly that standard NMT models completely break down on both natural ""noise"" and various types of input perturbations. It then tests how the addition of noise in the input helps robustify the charCNN model somewhat. The extent of the experiments is quite impressive: three different NMT models are tried, and one is used in extensive experiments with various noise combinations.\n\nThis study clearly addresses an important issue in NMT and will be of interest to many in the NLP community. The outcome is not entirely surprising (noise hurts and training and the right kind of noise helps) but the impact may be. I wonder if you could put this in the context of ""training with input noise"", which has been studied in Neural Network for a while (at least since the 1990s). I.e. it could be that each type of noise has a different regularizing effect, and clarifying what these regularizers are may help understand the impact of the various types of noise. Also, the bit of analysis in Sections 6.1 and 7.1 is promising, if maybe not so conclusive yet.\n\nA few constructive criticisms:\n\nThe way noise is included in training (sec. 6.2) could be clarified (unless I missed it) e.g. are you generating a fixed ""noisy"" training set and adding that to clean data? Or introducing noise ""on-line"" as part of the training? If fixed, what sizes were tried? More information on the experimental design would help.\n\nTable 6 is highly suspect: Some numbers seem to have been copy-pasted in the wrong cells, eg. the ""Rand"" line for German, or the Swap/Mid/Rand lines for Czech. It\'s highly unlikely that training on noisy Swap data would yield a boost of +18 BLEU points on Czech -- or you have clearly found a magical way to improve performance.\n\nAlthough the amount of experiment is already important, it may be interesting to check whether all se2seq models react similarly to training with noise: it could be that some architecture are easier/harder to robustify in this basic way.\n\n[Response read -- thanks]\nI agree with authors that this paper is suitable for ICLR, although it will clearly be of interest to ACL/MT-minded folks.']","[60, 0, 0]","[80, 0, 0]","[""The sentiment score is 60 (positive) because the reviewer describes the paper as a 'thorough exploration' that is 'well-written and easy to follow'. They praise the novelty and the inclusion of natural sources of noise. However, they also point out some limitations, such as the artificialness of the 'natural' noise and the paper not being a perfect fit for ICLR, which prevents a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts and contributions. They offer constructive criticism and suggestions for improvement in a considerate manner, using phrases like 'it feels like' and 'it is worth providing some explanation' rather than making blunt criticisms. The reviewer also balances negative points with positive ones, showing a fair and courteous approach."", 'ERROR', 'ERROR']"
"['This paper presents a method for image classification given test-time computational budgeting constraints.  Two problems are considered:  ""any-time"" classification, in which there is a time constraint to evaluate a single example, and batched budgets, in which there is a fixed budget available to classify a large batch of images.  A convolutional neural network structure with a diagonal propagation layout over depth and scale is used, so that each activation map is constructed using dense connections from both same and finer scale features.  In this way, coarse-scale maps are constructed quickly, then continuously updated with feed-forward propagation from lower layers and finer scales, so they can be used for image classification at any intermediate stage.  Evaluations are performed on ImageNet and CIFAR-100.\n\nI would have liked to see the MC baselines also evaluated on ImageNet --- I\'m not sure why they aren\'t there as well?  Also on p.6 I\'m not entirely clear on how the ""network reduction"" is performed --- it looks like finer scales are progressively dropped in successive blocks, but I don\'t think they exactly correspond to those that would be needed to evaluate the full model (this is ""lazy evaluation"").  A picture would help here, showing where the depth-layers are divided between blocks.\n\nI was also initially a bit unclear on how the procedure described for batched budgeted evaluation achieves the desired result:  It seems this relies on having a batch that is both large and varied, so that its evaluation time will converge towards the expectation.  So this isn\'t really a hard constraint (just an expected result for batches that are large and varied enough).  This is fine, but could perhaps be pointed out if that is indeed the case.\n\nOverall, this seems like a natural and effective approach, and achieves good results.\n', 'This paper introduces a new model to perform image classification with limited computational resources at test time. The model is based on a multi-scale convolutional neural network similar to the neural fabric (Saxena and Verbeek 2016), but with dense connections (Huang et al., 2017) and with a classifier at each layer. The multiple classifiers allow for a finer selection of the amount of computation needed for a given input image. The multi-scale representation allows for better performance at early stages of the network. Finally the dense connectivity allows to reduce the negative effect that early classifiers have on the feature representation for the following layers.\nA thorough evaluation on ImageNet and Cifar100 shows that the network can perform better than previous models and ensembles of previous models with a reduced amount of computation.\n\nPros:\n- The presentation is clear and easy to follow.\n- The structure of the network is clearly justified in section 4.\n- The use of dense connectivity to avoid the loss of performance of using early-exit classifier is very interesting.\n- The evaluation in terms of anytime prediction and budgeted batch classification can represent real case scenarios.\n- Results are very promising, with 5x speed-ups and same or better accuracy that previous models.\n- The extensive experimentation shows that the proposed network is better than previous approaches under different regimes.\n\nCons:\n- Results about the more efficient densenet* could be shown in the main paper\n\nAdditional Comments:\n- Why in training you used logistic loss instead of the more common cross-entropy loss? Has this any connection with the final performance of the network?\n- In fig. 5 left for completeness I would like to see also results for DenseNet^MT and ResNet^MT\n- In fig. 5 left I cannot find the 4% and 8% higher accuracy with 0.5x10^10 to 1.0x10^10 FLOPs, as mentioned in section 5.1 anytime prediction results\n- How the budget in terms of Mul-Adds is actually estimated?\n\nI think that this paper present a very powerful approach to speed-up the computational cost of a CNN at test time and clearly explains some of the common trade-offs between speed and accuracy and how to improve them. The experimental evaluation is complete and accurate. \n\n', 'This work proposes a variation of the DenseNet architecture that can cope with computational resource limits at test time. The paper is very well written, experiments are clearly presented and convincing and, most importantly, the research question is exciting (and often overlooked). \n\nMy only major concern is the degree of technical novelty with respect to the original DenseNet paper of Huang et al. (2017). The authors add a hierarchical, multi-scale structure and show that DenseNet can better cope with it than ResNet (e.g., Fig. 3). They investigate pros and cons in detail adding more valuable analysis in the appendix. However, this work is basically an extension of the DenseNet approach with a new problem statement and additional, in-depth analysis.   \n\nSome more minor comments: \n\n-\tPlease enlarge Fig. 4. \n-\tI did not fully grasp the details in the first ""Solution"" paragraph on P5. Please extend and describe in more detail. \n\nIn conclusion, this is a very well written paper that designs the network architecture (of DenseNet) such that it is optimized to include CPU budgets at test time. I recommend acceptance to ICLR18.\n    \n\n\n']","[0, 0, 80]","[0, 0, 90]","['ERROR', 'ERROR', ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, praising its writing, experiments, and research question. They recommend acceptance and use phrases like 'very well written' and 'exciting'. The only major concern mentioned is about technical novelty, which slightly reduces the score from being maximally positive. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer offers praise, frames their concern diplomatically, and provides helpful suggestions for improvement. The language is professional and courteous throughout, without any harsh criticism or rude phrasing.""]"
"['The paper proposes an approach to train generators within a GAN framework, in the setting where one has access only to degraded / imperfect measurements of real samples, rather than the samples themselves. Broadly, the approach is to have a generator produce the ""full"" real data, pass it through a simulated model of the measurement process, and then train the discriminator to distinguish between these simulated measurements of generated samples, and true measurements of real samples. By this mechanism, the proposed method is able to train GANs to generate high-quality samples from only imperfect measurements.\n\nThe paper is largely well-written and well-motivated, the overall setup is interesting (I find the authors\' practical use cases convincing---where one only has access to imperfect data in the first place), and the empirical results are convincing. The theoretical proofs do make strong assumptions (in particular, the fact that the true distribution must be uniquely constrained by its marginal along the measurement). However, in most theoretical analysis of GANs and neural networks in general, I view proofs as a means of gaining intuition rather than being strong guarantees---and to that end, I found the analysis in this paper to be informative.\n\nI would make a  suggestions for possible further experimental analysis: it would be nice to see how robust the approach is to systematic mismatches between the true and modeled measurement functions (for instance, slight differences in the blur kernels, noise variance, etc.). Especially in the kind of settings the paper considers, I imagine it may sometimes also be hard to accurately model the measurement function of a device (or it may be necessary to use a computationally cheaper approximation for training). I think a study of how such mismatches affect the training procedure would be instructive (perhaps more so than some of the quantitative evaluation given that they at best only approximately measure sample quality).', 'The paper explores GAN training under a linear measurement model in which one assumes that the underlying state vector $x$ is not directly observed but we do have access to measurements $y$ under a linear measurement model plus noise. The paper explores in detail several practically useful versions of the linear measurement model, such as blurring, linear projection, masking etc. and establishes identifiability conditions/theorems for the underlying models.\nThe AmbientGAN approach advocated in the paper amounts to learning end-to-end differentiable Generator/Discriminator networks that operate in the measurement space. The experimental results in the paper show that this works much better than reasonable baselines, such as trying to invert the measurement model for each individual training sample, followed by standard GAN training.\nThe theoretical analysis is satisfactory. However, it would be great if the theoretical results in the paper were able to associate the difficulty of the inversion process with the difficulty of AmbientGAN training. For example, if the condition number for the linear measurement model is high, one would expect that recovering the target real distribution is more difficult. The condition in Theorem 5.4 is a step in this direction, showing that the required number of samples for correct recovery increases with the probability of missing data. It would be great if Theorems 5.2 and 5.3 also came with similar quantitative bounds.', 'Quick summary:\nThis paper shows how to train a GAN in the case where the dataset is corrupted by some measurement noise process. They propose to introduce the noise process into the generation pipeline such that the GAN generates a clean image, corrupts its own output and feeds that into the discriminator. The discriminator then needs to decide whether this is a real corrupted measurement or a generated one.  The method is demonstrated to the generate better results than the baseline on a variety of datasets and noise processes.\n\nQuality:\nI found this to be a nice paper - it has an important setting to begin with and the proposed method is clean and elegant albeit a bit simple. \n\nOriginality:\nI\'m pretty sure this is the first paper to tackle this problem directly in general.\n\nSignificance:\nThis is an important research direction as it is not uncommon to get noisy measurements in the real world under different circumstances. \n\nPros:\n* Important problem\n* elegant and simple solution\n* nice results and decent experiments (but see below)\n\nCons:\n* The assumption that the measurement process *and* parameters are known is quite a strong one. Though it is quite common in the literature to assume this, it would have been interesting to see if there\'s a way to handle the case where it is unknown (either the process, parameters or both).\n* The baseline experiments are a bit limited - it\'s clear that such baselines would never produce samples which are any better than the ""fixed"" version which is fed into them. I can\'t however, think of other baselines other than ""ignore"" so I guess that is acceptable.\n* I wish the authors would show that they get a *useful* model eventually - for example, can this be used to denoise other images from the dataset?\n\nSummary:\nThis is a nice paper which deals with an important problem, has some nice results and while not groundbreaking, certainly merits a publication.']","[80, 0, 70]","[90, 0, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They describe it as 'well-written and well-motivated' with 'convincing' empirical results. The reviewer finds the setup 'interesting' and the practical use cases 'convincing'. While they mention some limitations (strong assumptions in theoretical proofs), they still find the analysis 'informative'. The only criticism is a suggestion for further experimental analysis, which is presented constructively.\n\nThe politeness score is 90 (very polite) because the reviewer uses respectful and professional language throughout. They acknowledge the paper's strengths before mentioning any limitations, and frame their suggestion for improvement as a constructive recommendation rather than a criticism. Phrases like 'I would make a suggestion' and 'it would be nice to see' are particularly polite ways of offering feedback. The reviewer also uses hedging language ('I imagine', 'I think') when speculating, which adds to the politeness by avoiding overly assertive statements."", 'ERROR', ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'nice' multiple times, highlights several pros, and states that it 'merits a publication'. The overall tone is appreciative of the work, despite some cons mentioned. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. The reviewer maintains a professional and courteous tone, even when pointing out limitations.""]"
"[""This article aims at understanding the role played by the different words in a sentence, taking into account their order in the sentence. In sentiment analysis for instance, this capacity is critical to model properly negation.\nAs state-of-the-art approaches rely on LSTM, the authors want to understand which information comes from which gate. After a short remainder regarding LSTM, the authors propose a framework to disambiguate interactions between gates. In order to obtain an analytic formulation of the decomposition, the authors propose to linearize activation functions in the network.\nIn the experiment section, authors compare themselves to a standard logistic regression (based on a bag of words representation). They also check the unigram sentiment scores (without context).\nThe main issue consists in modeling the dynamics inside a sentence (when a negation or a 'used to be' reverses the sentiment). The proposed approach works fine on selected samples.\n\n\nThe related work section is entirely focused on deep learning while the experiment section is dedicated to sentiment analysis. This section should be rebalanced. Even if the authors claim that their approach is general, they also show that it fits well the sentiment analysis task in particular.\n\nOn top of that, a lot of fine-grained sentiment analysis tools has been developed outside deep-learning: the authors should refer to those works.\n\nFinally, authors should provide some quantitative analysis on sentiment classification: a lot of standard benchmarks are widely use in the literature and we need to see how the proposed method performs with respect to the state-of-the-art.\n\n\nGiven the chosen tasks, this work should be compared to the beermind system:\nhttp://deepx.ucsd.edu/#/home/beermind\nand the associated publication\nhttp://arxiv.org/pdf/1511.03683.pdf"", 'In this paper, the authors propose a new LSTM variant that allows to produce interpretations by capturing the contributions of the words to the final prediction and the way their learned representations are combined in order to yield that prediction. They propose a new approach that they call Contextual Decomposition (CD). Their approach consists of disambiguating interaction between LSTM’s gates where gates are linearized so the products between them is over linear sums of contributions from different factors. The hidden and cell states are also decomposed in terms of contributions to the “phrase” in question and contributions from elements outside of the phrase. The motivation of the proposed decomposition using LSTMs is that the latter are powerful at capturing complex non-linear interactions, so, it would be useful to observe how these interactions are handled and to interpret the LSTM’s predictions. As the authors intention is to build a way of interpreting LSTMs output and not to increase the model’s accuracy, the empirical results illustrate the ability of their decomposition of giving a plausible interpretation to the elements of a sentence. They compare their method with different existing method by illustrating samples from the Yelp Polarity and SST datasets. They also show the ability of separating the distribution of CD scores related to positive and negative phrases on respectively Yelp Polarity and SST.\n\nThe proposed approach is potentially of great benefit as it is simple and elegant and could lead to new methods in the same direction of research. The sample illustrations, the scatter plots and the CD score distributions are helpful to asses the benefit of the proposed approach.\n\nThe writing could be improved as it contains parts where it leads to confusion. The details related to the linearization (section 3.2.2), the training (4.1) could be improved. In equation 25, it is not clear what  π_{i}^(-1) and x_{π_{i}} represent but the example in equation 26 makes it clearer. The section would be clearer if each index and notation used is explained explicitly.\n\n(CD in known for Contrastive Divergence in the deep learning community. It would be better if Contextual Decomposition is not referred by CD.)\n\nTraining details are given in section 4.1 where the authors mention the integrated gradient baseline without mentioning the reference paper to it (however they do mention the reference paper at each of table 1 and 2). it would be clearer for the reader if the references are also mentioned in section 4.1 where integrated gradient is introduced. Along with the reference, a brief description of that baseline could be given. \n\nThe “Leave one out” baseline is never mentioned in text before section 4.4 (and tables 1 and 2). Neither the reference nor the description of the baseline are given. It would have been clearer to the reader if this had been the case.\n\nOverall, the paper contribution is of great benefit. The quality of the paper could be improved if the above explanations and details are given explicitly in the text.', 'The authors address the problem of making LSTMs more interpretable via the contextual decomposition of the state vectors. By linearizing the updates in the recurrent network, the proposed scheme allows one to extract word importance information directly from the gating dynamics and infer word-to-word interactions. \n\nThe problem of making neural networks more understandable is important in general. For NLP, this relates to the ability of capturing phrase features that go beyond single-word importance scores. A nice contribution of the paper is to show that this can highly improve classification performance on the task of sentiment analysis. However, the author could have spent some more time in explaining the technical consequences of the proposed linear approximation. For example, why is the linear approximation always good? And what is the performance loss compared to a fully nonlinear network? \n\nThe experimental results suggest that the algorithm can outperform state-of-the-art methods on various tasks.\n\nSome questions:\n- is any of the existing algorithms used for the comparison supposed to capture interactions between words and phrases? If not, why is the proposed algorithm compared to them on interaction related tasks?\n- why the output of the algorithms is compared with the logistic regression score? May the fact that logistic regression is a linear model be linked to the good performance of the proposed method? Would it be possible to compare the output of the algorithms with human given scores on a small subset of words? \n- the recent success of LSTMs is often associated with their ability to learn complex and non-linear relationships but the proposed method is based on the linearization of the network. How can the algorithm be able to capture non-linear interactions? What is the difference between the proposed model and a simple linear model?   ']","[20, 0, 0]","[50, 0, 0]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the merits of the paper and its potential in understanding sentence dynamics, particularly in sentiment analysis. However, they also point out several areas for improvement, which prevents the score from being higher. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout, offering specific suggestions for improvement without using harsh language. They acknowledge the paper's strengths before presenting critiques, which is a polite approach. The reviewer uses phrases like 'should be rebalanced' and 'should provide' rather than more demanding language, contributing to the politeness. The overall tone is academic and respectful, focusing on improving the paper rather than criticizing the authors."", 'ERROR', 'ERROR']"
"['This very well written paper covers the span between W-GAN and VAE. For a reviewer who is not an expert in the domain, it reads very well, and would have been of tutorial quality if space had allowed for more detailed explanations. The appendix are very useful, and tutorial paper material (especially A). \n\nWhile I am not sure description would be enough to reproduce and no code is provided, every aspect of the architecture, if not described, if referred as similar to some previous work. There are also some notation shortcuts (not explained) in the proof of theorems that can lead to initial confusion, but they turn out to be non-ambiguous. One that could be improved is P(P_X, P_G) where one loses the fact that the second random variable is Y.\n\n\nThis work contains plenty of novel material, which is clearly compared to previous work:\n- The main consequence of the use of Wasserstein distance is the surprisingly simple and useful Theorem 1. I could not verify its novelty, but this seems to be a great contribution.\n- Blending GAN and auto-encoders has been tried in the past, but the authors claim better theoretical foundations that lead to solutions that do not rquire min-max\n- The use of MMD in the context of GANs has also been tried. The authors claim that their use in the latent space makes it more practival\n\nThe experiments are very convincing, both numerically and visually.\n\nSource of confusion: in algorithm 1 and 2, \\tilde{z} is ""sampled"" from Q_TH(Z|xi), some one is lead to believe that this is the sampling process as in VAEs, while in reality Q_TH(Z|xi) is deterministic in the experiments.', 'This paper provides a reasonably comprehensive generalization to VAEs and Adversarial Auto-encoders through the lens of the Wasserstein metric. By posing the auto-encoder design as a dual formulation of optimal transport, the proposed work supports the use of both deterministic and random decoders under a common framework. In my opinion, this is one of the crucial contributions of this paper. While the existing properties of auto-encoders are preserved, stability characteristics of W-GANs are also observed in the proposed architecture. The results from MNIST and CelebA datasets look convincing, though could include additional evaluation to compare the adversarial loss with the straightforward MMD metric and potentially discuss their pros and cons. In some sense, given the challenges in evaluating and comparing closely related auto-encoder solutions, the authors could design demonstrative experiments for cases where Wassersterin distance helps and may be  its potential limitations.\n\nThe closest work to this paper is the adversarial variational bayes framework by Mescheder et.al. which also attempts at unifying VAEs and GANs. While the authors describe the conceptual differences and advantages over that approach, it will be beneficial to actually include some comparisons in the results section.', 'This paper satisfies the following necessary conditions for\nacceptance. The writing is clear and I was able to understand the\npresented method (and its motivation) despite not being too familiar\nwith the relevant literature. Explicitly writing the auto-encoder(s)\nas pseudo-code algorithms was particular helpful. I found no technical\nerrors. The problem addressed is one worth solving - building a\ngenerative model of observed data. There is some empirical testing\nwhich show the presented method in a good light.\n\nThe authors are careful to relate the presented method with existing\nones, most notably VAE and AAE. I suppose one could argue that the\nclose connection to existing methods means that this paper is not\ninnovative enough. I think that would be unfair - most new methods\nhave close relations with existing ones - it is just that sometimes\nthe authors do not flag this up as they should.\n\nWAE is a bit oversold. The authors state that WAE generates ""samples\nof better quality"" (than VAE) without any condition being put on when\nit does this. There is no proof that it is always better, and I can\'t\nsee how there could be. Any method of inferring a generative model\nfrom data must make some \'inductive\' assumptions. Surely one could\ndevise situations where VAE outperforms WAE. I think this issue should\nhave been examined in more depth.\n\nI found no typo or grammatical errors which is unusual - good careful\njob!\n\n']","[80, 0, 0]","[70, 0, 0]","[""The sentiment score is 80 (positive) because the reviewer starts with praising the paper as 'very well written' and mentions that it 'reads very well' and is of 'tutorial quality'. They also describe the experiments as 'very convincing'. While there are some minor criticisms, the overall tone is highly positive. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging their own potential lack of expertise in some areas, and framing criticisms constructively. They use phrases like 'while I am not sure' and 'could be improved' rather than making blunt criticisms. The reviewer also balances critiques with positive feedback, maintaining a courteous tone throughout the review."", 'ERROR', 'ERROR']"
"['To date the theoretical advantage of deep learning has focused on the concept of ""expressive efficiency"" where one network must grow much larger to replicate functions that another ""more efficient"" network can produce. This has focused so far on depth (i.e. shallow networks have to grow much larger than deeper networks to express the same set of networks)\n\nThe authors explore another dimension here, namely that of ""connectivity"". They study dilated convolutional networks and show that intertwining two dilated convolutional networks A and B at various stages (formalized via mixed tensor decompositions) it is more expressively efficient than not intertwining. \n\nThe authors\' experiments support their theory showing that their mixed strategy leads to gains over a vanilla dilated convolutional net.\n\nI found the paper very well written despite its level of mathematical depth (the authors provide many helpful pictures) and strongly recommend accepting this paper.\n\n', '(Emergency review—I have no special knowledge of the subfield, and I was told a cursory review was OK, but the paper was fascinating and I ended up reading fairly carefully)\n\nThis paper does many things. It adds to a series of publications that analyze deep network architectures as parameterized decompositions of intractably large tensors (themselves the result of discretizing the entire input-output space of the network), this time focusing on the WaveNet architecture for autoregressive sequence modeling. It shows (first theoretically, then empirically) that the WaveNet\'s structural assumption of a single (perfect) binary tree is holding it back, and that WaveNet-like architectures with more complex mixed tree structures perform better.\nThroughout the subject is treated with a high level of mathematical rigor, while relegating proofs and detailed walkthrough explanations to lengthy appendices which I did not have time to review.\n\nSome things I noticed:\n- The notation used is mostly consistent, except for some variation between dots (e.g., in Eq. 2) and bra-kets (in Fig. 1) for inner product. While I think I\'m in the minority here, I\'d personally be comfortable with going a little bit further with index notation and avoiding the cohabitation of tensor and vector notation styles by using indices even for dot products; that said, either kind of vector notation (dots or brakets) is certainly acceptable too.\n- There are a couple more nomenclature things that might trip up those of us in the deep learning crowd—we\'re used to referring to ""axes"" or ""dimensions"" of a tensor, but the tensor-analysis world apparently says ""modes"" (and this is called out once in a parenthetical). As ""dimension"" means something different to tensor folks (what DLers usually call the ""size"" of an axis), perhaps standardizing on the shared term ""axes"" would be worthwhile? Not sure if there\'s a distinction in the tensor world between the words ""axis"" and ""mode.""\n- The baseline WaveNet is only somewhat well described as ""convolutional;"" the underlying network unit is not always a ""size-2 convolution"" (except for certain values of g) and the ""size-1 convolutions"" that make it up are simply linear transformations. While the WaveNet derives from convolutional sequence architectures (and the choices of g explored in the original paper derive from the CNN literature) it has at least as much in common with recursive/tree-structured network architectures like TreeLSTMs and RNTNs. In fact, the WaveNet is a special case of a recursive neural network with a particular composition function *and a fixed (perfect) binary tree structure.* As this last condition is relaxed in the present paper, making the space of networks under analysis more similar to the traditional space of recursive NNs, it might be worth mentioning this ""alternative history"" of the WaveNet.\n- The choice of mixture nodes in Fig. 3 is a little unfortunate, because it includes all possible mixture nodes and doesn\'t make it as clear as the text does that a subset of these nodes can be chosen in the general case.\n- While I couldn\'t follow some of Section 5, I\'m a little confused that Theorem 1 appears at first glance to apply only to a non-generalized decomposition (a specific choice of g).\n- Caffe would not have been my first choice for such a complex, hierarchically structure architecture; I imagine it forced the authors to write a significant amount of custom code.', 'This paper theoretically validates that interconnecting networks with different dilations can lead to expressive efficiency, which indicates an interesting phenomenon that connectivity is able to enhance the expressiveness of deep networks. A key technical tool is a mixed tensor decomposition, which is shown to have representational advantage over the individual hierarchical decompositions it comprises.\n\nPros:\n\nExisting work have focused on understanding the depth of the networks and established that deep networks are expressively efficient with respect to shallow ones. On the other hand, this paper focused on the architectural feature of connectivity. The problem is fundamentally important and its theoretical development is solid. The conclusion is useful for developing new tools for deep network design. \n\nCons:\n\nIn order to show that the mixed dilated convolutional network is expressively efficient w.r.t. the corresponding individual dilated convolutional network, the authors prove it in two steps: Proposition 1 and Proposition 2. However, in the proof of Proposition 2 (see Theorem 1), the authors only focus on a particular case of convolutional arithmetic circuits, i.e., $g(a,b)= a*b$. In the experiments, see line 4 of page 9, the authors instead used ReLU activation $g(a, b)= max{a+b, 0}$. Can authors provide some justifications of such different choices of activation functions? It would be great if authors can discuss how to generate the activation function in Theorem 1 to more general cases.\n\n\n']","[90, 60, 60]","[80, 80, 80]","[""The sentiment score is 90 because the reviewer expresses strong positive sentiment throughout the review. They describe the paper as 'very well written' and 'strongly recommend accepting this paper'. The experiments are said to support the theory, which is another positive point. The politeness score is 80 because the reviewer uses respectful and professional language throughout. They acknowledge the mathematical depth of the paper while praising the authors for making it accessible with helpful pictures. The tone is consistently positive and constructive, without any harsh criticism or rude language. The reviewer's strong recommendation for acceptance is expressed politely and professionally."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as 'fascinating' and praises its mathematical rigor. They provide constructive feedback and suggestions, indicating overall approval. However, it's not extremely positive as they point out some issues and areas for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('I have no special knowledge of the subfield'), and frames criticisms as suggestions or personal opinions ('I'd personally be comfortable with...'). The reviewer also balances critiques with positive comments and uses phrases like 'might be worth mentioning' instead of more forceful language."", ""The sentiment score is 60 (positive) because the reviewer begins by highlighting the paper's theoretical validation and interesting findings, using positive language like 'interesting phenomenon' and 'expressive efficiency'. The reviewer also lists several pros, emphasizing the importance and solidity of the work. However, the score is not higher due to the presence of cons and suggestions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths before offering criticism, and phrase their suggestions as questions or requests rather than demands, using phrases like 'Can authors provide' and 'It would be great if'. The tone remains professional and courteous throughout the review.""]"
"['--------------\nSummary:\n--------------\nThis paper presents a series of experiments on language emergence through referential games between two agents. They ground these experiments in both fully-specified symbolic worlds and through raw, entangled, visual observations of simple synthetic scenes. They provide rich analysis of the emergent languages the agents produce under different experimental conditions. This analysis (especially on raw pixel images) make up the primary contribution of this work.\n\n\n--------------\nEvaluation:\n--------------\nOverall I think the paper makes some interesting contributions with respect to the line of recent \'language emergence\' papers. The authors provide novel analysis of the learned languages and perceptual system across a number of environmental settings, coming to the (perhaps uncontroversial) finding that varying the environment and restrictions on language result in variations in the learned communication protocols. \n\nIn the context of existing literature, the novelty of this work is somewhat limited -- consisting primarily of the extension of multi-agent reference games to raw-pixel inputs. While this is a non-trivial extension, other works have demonstrated language learning in similar referring-expression contexts (essentially modeling only the listener model [Hermann et.al 2017]). \n\nI have a number of requests for clarification in the weaknesses section which I think would improve my understanding of this work and result in a stronger submission if included by the authors.  \n\n--------------\nStrengths:\n--------------\n- Clear writing and document structure. \n\n\n- Extensive experimental setting tweaks which ablate the information and regularity available to the agents. The discussion of the resulting languages is appropriate and provides some interesting insights.\n\n\n- A number of novel analyses are presented to evaluate the learned languages and perceptual systems. \n\n\n--------------\nWeaknesses:\n--------------\n- How stable are the reported trends / languages across multiple runs within the same experimental setting? The variance of REINFORCE policy gradients (especially without a baseline) plus the general stochasticity of SGD on randomly initialized networks leads me to believe that multiple training runs of these agents might result is significantly different codes / performance. I am interested in hearing the author\'s experiences in this regard and if multiple runs present similar quantitative and qualitative results. I admit that expecting identical codes is unrealistic, but the form of the codes (i.e. primarily encoding position) might be consistent even if the individual mappings are not).\n\n\n- I don\'t recall seeing descriptions of the inference-time procedure used to evaluate training / test accuracy. I will assume argmax decoding for both speaker and listener. Please clarify or let me know if I missed something.\n\n\n- There is ambiguity in how the ""protocol size"" metric is computed. In Table 1, it is defined as \'the effective number of unique message used\'. This comes back to my question about decoding I suppose, but does this count the \'inference-time\' messages or those produced during training? \nFurthermore, Table 2 redefines ""protocol size"" as the percentage of novel message. I assume this is an editing error given the values presented and take these columns as counts. It also seems ""protocol size"" is replaced with the term ""lexicon"" from 4.1 onward.\n\n- I\'m surprised by how well the agents generalize in the raw pixel data experiments. In fact, it seems that across all games the test accuracy remains very close to the train accuracy. \n\nGiven the dataset is created by taking all combinations of color / shape and then sampling 100 location / floor color variations, it is unlikely that a shape / color combo has not been seen in training. Such that the only novel variations are likely location and floor color. However, taking Game A as an example, the probe classifiers are relatively poor at these attributes -- indicating the speaker\'s representation is not capturing these attributes well. Then how do the agents effectively differentiate so well between 20 images leveraging primarily color and shape?\n\nI think some additional analysis of this setting might shed some light on this issue. One thought is to compute upper-bounds based on ground truth attributes. Consider a model which knows shape perfectly, but cannot predict other attributes beyond chance. To compute the performance of such a model, you could take the candidate set, remove any instances not matching the ground truth shape, and then pick randomly from the remaining instances. Something similar could be repeated for all attributes independently as well as their combinations -- obviously culminating in 100% accuracy given all 4. It could be that by dataset construction, object location and shape are sufficient to achieve high accuracy because the odds of seeing the same shape at the same location (but different color) is very low. \n\nGiven these are operations on annotations and don\'t require time-consuming model training, I hope to see this analysis in the rebuttal to put the results into appropriate context.\n\n\n- What is random chance for the position and floor color probe classifiers? I don\'t think it is mentioned how many locations / floor colors are used in generation.  \n\n\n- Relatively minor complaint: Both agents are trained via the REINFORCE policy gradient update rule; however, the listener agent makes a fairly standard classification decision and could be trained with a standard cross-entropy loss. That is to say, the listener policy need not make intermediate discrete policy decisions. This decision to withhold available supervision is not discussed in the paper (as far as I noticed), could the authors speak to this point?\n\n\n\n--------------\nCuriosities:\n--------------\n- I got the impression from the results (specifically the lack of discussion about message length) that in these experiments agents always issued full length messages even though they did not need to do so. If true, could the authors give some intuition as to why? If untrue, what sort of distribution of lengths do you observe?\n\n- There is no long term planning involved in this problem, so why use reinforcement learning over some sort of differentiable sampler? With some re-parameterization (i.e. Gumbel-Softmax), this model could be end-to-end differentiable.\n\n\n--------------\nMinor errors:\n--------------\n[2.2 paragraph 1] LSTM citation should not be in inline form.\n[3 paragraph 1] \'Note that these representations do care some\' -> carry\n[3.3.1 last paragraph] \'still able comprehend\' --> to\n\n\n-------\nEdit\n-------\nUpdating rating from 6 to 7.', 'This paper presents a set of studies on emergent communication protocols in referential games that use either symbolic object representations or pixel-level representations of generated images as input. The work is extremely creative and packed with interesting experiments.\n\nI have three main comments.\n\n* CLARITY OF EXPOSITION\n\nThe paper was rather hard to read. I\'ll provide some suggestions for improvement in the minor-comments section below, but one thing that could help a lot is to establish terminology at the beginning, and be consistent with it throughout the paper: what is a word, a message, a protocol, a vocabulary, a lexicon? etc.\n\n* RELATION BETWEEN VOCABULARY SIZE AND PROTOCOL SIZE\n\nIn the compositional setup considered by the authors, agents can choose how many basic symbols to use and the length of the ""words"" they will form with these symbols. There is virtually no discussion of this interesting interplay in the paper. Also, there is no information about the length distribution of words (in basic symbols), and no discussion of whether the latter was meaningful in any way.\n\n* RELATION BETWEEN CONCEPT-PROPERTY AND RAW-PIXEL STUDIES\n\nThe two studies rely on different analyses, and it is difficult to compare them. I realize that it would be impossible to report perfectly comparable analyses, but the authors could at least apply the ""topographic"" analysis of compositionality in the raw-pixel study as well, either by correlating the CNN-based representational similarities of the Speaker with its message similarities, or computing similarity of the inputs in discretized, symbolic terms (or both?).\n\n* MINOR/DETAILED COMMENTS\n\nSection 1\n\nHow do you think emergent communication experiments can shed light on language acquisition?\n\nSection 2\n\nIn figure 1, the two agents point at nothing.\n\n\\mathbf{v} is a set, but it\'s denoted as a vector. Right below that, h^S is probably h^L?\n\nall candidates c \\in C: or rather their representations \\mathbf{v}?\n\nGive intuition for the reward function.\n\nSection 3\n\nWe use the dataset of Visual Attributes...: drop ""dataset""\n\nI think the pre-linguistic objects are not represented by 1-hot, but binary vectors.\n\ndo care some inherent structure: carry\n\nNote that symbols in V have no pre-defined semantics...: This is repeated multiple times.\n\nSection 3\n\nI couldn\'t find simulation details: how many training elements, and how is training accuracy computed? Also, ""training data"", ""training accuracy"" are probably misleading terms, as I suppose you measured performance on new combinations of objects.\n\nI find ""Protocol Size"" to be a rather counterintuitive term: maybe call Vocabulary Size ""Alphabet Size"", and Protocol Size ""Lexicon Size""?\n\nState in Table 1 caption that the topographic measure will be explained in a later section. Also, the -1 is confusing: you can briefly mention when you introduce the measure that since you correlate a distance with a similarity you expect an inverse relation? Also, you mention in the caption that all Spearman rhos are significant, but where are they presented again?\n\nSection 3.2\n\nDoes the paragraph starting with ""Note that the distractor"" refer to a figure or table that is not there? If not, it should be there, since it\'s not clear what are the data that support your claims there. Also, you should explain what the degenerate strategy the agents find is.\n\nNext paragraph:\n\n- I find the usage of ""obtaining"" to refer to the relation between messages and objects strange.\n\n- in which space are the reported pairwise similarities computed?\n\n- make clear that in the non-uniform case confusability is less influenced by similarity since the agents must learn to distinguish between similar objects that naturally co-occur (sheep and goats)\n\n- what is the expected effect on the naturalness of the emerged language?\n\nSection 3.3\n\nadhere to, the ability to: ""such as"" missing?\n\nIs the unigram chimera distribution inferred from the statistics over the distribution of properties across all concepts or what? (please clarify.)\n\nIn Tables 2 and 3, why is vocabulary size missing?\n\nIn Table 2, say that the protocol size columns report novel message percentage **for the ""test"" conditions***\n\nFigure 2: spelling of Levensthein\n\nSection 3.3.2\n\nwhile for languages (c,d)... something missing.\n\nwith a randomly initialized...: no a\n\nMore importantly, I don\'t understand this ""random"" setup: if architecture was fixed and randomly initialized, how could something be learned about the structure of the data?\n\nSection 4\n\nRefer to the images the agents must communicate about as ""scenes"", since objects are just a component of them.\n\nWhat are the absolute sizes of train and test splits?\n\nSection 4.1\n\nwe do not address this issue: the issue\n\nSection 4.2\n\nat least in the game C&D: games\n\nWhy is Appendix A containing information that logically follows that in Appendix B?\n', 'This paper presents an analysis of the communication systems that arose when neural network based agents played simple referential games. The set up is that a speaker and a listener engage in a game where both can see a set of possible referents (either represented symbolically in terms of features, or represented as simple images) and the speaker produces a message consisting of a sequence of numbers while the listener has to make the choice of which referent the speaker intends. This is a set up that has been used in a large amount of previous work, and the authors summarize some of this work. The main novelty in this paper is the choice of models to be used by speaker and listener, which are based on LSTMs and convolutional neural networks. The results show that the agents generate effective communication systems, and some analysis is given of the extent to which these communications systems develop compositional properties – a question that is currently being explored in the literature on language creation.\n\nThis is an interesting question, and it is nice to see worker playing modern neural network models to his question and exploring the properties of the solutions of the phone. However, there are also a number of issues with the work.\n\n1. One of the key question is the extent to which the constructed communication systems demonstrate compositionality. The authors note that there is not a good quantitative measure of this. However, this is been the topic of much research of the literature and language evolution. This work has resulted in some measures that could be applied here, see for example Carr et al. (2016): http://www.research.ed.ac.uk/portal/files/25091325/Carr_et_al_2016_Cognitive_Science.pdf\n\n2. In general the results occurred be more quantitative. In section 3.3.2 it would be nice to see statistical tests used to evaluate the claims. Minimally I think it is necessary to calculate a null distribution for the statistics that are reported.\n\n3. As noted above the main novelty of this work is the use of contemporary network models. One of the advantages of this is that it makes it possible to work with more complex data stimuli, such as images. However, unfortunately the image example that is used is still very artificial being based on a small set of synthetically generated images.\n\nOverall, I see this as an interesting piece of work that may be of interest to researchers exploring questions around language creation and language evolution, but I think the results require more careful analysis and the novelty is relatively limited, at least in the way that the results are presented here.']","[0, 0, -20]","[0, 0, 60]","['ERROR', 'ERROR', ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'interesting' and 'nice to see', they also point out several issues and limitations, stating that 'the novelty is relatively limited'. The overall tone suggests that the paper needs significant improvements. The politeness score is moderately positive (60) as the reviewer uses polite language throughout, such as 'it is nice to see' and 'this is an interesting piece of work', while providing constructive criticism. They maintain a professional and respectful tone even when pointing out weaknesses in the paper.""]"
"['I wonder how the ASGD compares to other optimization schemes applicable to DL, like Entropy-SGD, which is yet another algorithm that provably improves over SGD. This question is also valid when it comes to other optimization schemes that are designed for deep learning problems. For instance, Entropy-SGD and Path-SGD should be mentioned and compared with. As a consequence, the literature analysis is insufficient. \n\nAuthors provided necessary clarifications. I am raising my score.\n\n\n\n\n', 'I like the idea of the paper. Momentum and accelerations are proved to be very useful both in deterministic and stochastic optimization. It is natural that it is understood better in the deterministic case. However, this comes quite naturally, as deterministic case is a bit easier ;) Indeed, just recently people start looking an accelerating in stochastic formulations. There is already accelerated SVRG, Jain et al 2017, or even Richtarik et al (arXiv: 1706.01108, arXiv:1710.10737).\n\nI would somehow split the contributions into two parts:\n1) Theoretical contribution: Proposition 3 (+ proofs in appendix)\n2) Experimental comparison.\n\nI like the experimental part (it is written clearly, and all experiments are described in a lot of detail).\n\nI really like the Proposition 3 as this is the most important contribution of the paper. (Indeed, Algorithms 1 and 2 are for reference and Algorithm 3 was basically described in Jain, right?). \n\nSignificance: I think that this paper is important because it shows that the classical HB method cannot achieve acceleration in a stochastic regime.\n\nClarity: I was easy to read the paper and understand it.\n\nFew minor comments:\n1. Page 1, Paragraph 1: It is not known only for smooth problems, it is also true for simple non-smooth (see e.g. https://link.springer.com/article/10.1007/s10107-012-0629-5)\n2. In abstract : Line 6 - not completely true, there is accelerated SVRG method, i.e. the gradient is not exact there, also see Recht (https://arxiv.org/pdf/1701.03863.pdf) or Richtarik et al (arXiv: 1706.01108, arXiv:1710.10737) for some examples where acceleration can be proved when you do not have an exact gradient.\n3. Page 2, block ""4"" missing ""."" in ""SGD We validate""....\n4. Section 2. I think you are missing 1/2 in the definition of the function. Otherwise, you would have a constant ""2"" in the Hessian, i.e. H= 2 E[xx^T]. So please define the function as  f_i(w) = 1/2 (y - <w,x_i>)^2. The same applies to Section 3.\n5. Page 6, last line, .... was downloaded from ""pre"". I know it is a link, but when printed, it looks weird. \n\n', 'I only got access to the paper after the review deadline; and did not have a chance to read it until now. Hence the lateness and brevity.\n\nThe paper is reasonably well written, and tackles an important problem. I did not check the mathematics. \n\nBesides the missing literature mentioned by other reviewers (all directly relevant to the current paper), the authors should also comment on the availability of accelerated methods inn the finite sum / ERM setting. There, the questions this paper is asking are resolved, and properly modified stochastic methods exist which offer acceleration over SGD (and not through minibatching). This paper does not comment on these developments. Look at accelerated SDCA (APPROX, ASDCA), accelerated SVRG (Katyusha) and so on.\n\nProvided these changes are made, I am happy to suggest acceptance.\n\n\n\n']","[0, 0, 50]","[0, 0, 75]","['ERROR', 'ERROR', ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'reasonably well written' and addressing 'an important problem'. They also suggest acceptance with changes, indicating overall approval. However, they point out missing literature and areas for improvement, which prevents a higher positive score. The politeness score is 75 (quite polite) due to the reviewer's constructive tone, use of phrases like 'the authors should', and the polite suggestion for acceptance. They also apologize for the late review, showing consideration. The language is professional and respectful throughout, without any harsh criticism or rude remarks.""]"
"['This paper formulates the Jeopardy QA as a query reformulation task that leverages a search engine.  In particular, a user will try a sequence of alternative queries based on the original question in order to find the answer.  The RL formulation essentially tries to mimic this process.  Although this is an interesting formulation, as promoted by some recent work, this paper does not provide compelling reasons why it\'s a good formulation.  The lack of serious comparisons to baseline methods makes it hard to judge the value of this work.\n\nDetailed comments/questions:\n\t1. I am actually quite confused on why it\'s a good RL setting. For a human user, having a series of queries to search for the right answer is a natural process, but it\'s not natural for a computer program.  For instance, each query can be viewed as different formulation of the same question and can be issued concurrently. Although formulated as an RL problem,  it is not clear to me whether the search result after each episode has been used as the immediate environment feedback. As a result, the dependency between actions seems rather weak.\n\t2. I also feel that the comparisons to other baselines (not just the variation of the proposed system) are not entirely fair. For instance, the baseline BiDAF model has only one shot, namely using the original question as query.  In this case, AQA should be allowed to use the same budget -- only one query.  Another more realistic baseline is to follow the existing work on query formulation in the IR community.  For example, 20 shorter queries generated by methods like [1] can be used to compare the queries created by AQA.\n\n[1] Kumaran & Carvalho. ""Reducing Long Queries Using Query Quality Predictors"". SIGIR-09\n\t\nPros:\n\t1. An interesting RL formulation for query reformulation\n\nCons:\n\t1. The use of RL is not properly justified\n\t2. The empirical result is not convincing that the proposed method is indeed advantageous \n\n---------------------------------------\n\nAfter reading the author response and checking the revised paper, I\'m both delighted and surprised that the authors improved the submission substantially and presented stronger results.  I believe the updated version has reached the bar and recommend accepting this paper.  ', 'This paper proposes active question answering via a reinforcement learning approach that can learn to rephrase the original questions in a way that can provide the best possible answers. Evaluation on the SearchQA dataset shows significant improvement over the state-of-the-art model that uses the original questions. \n\nIn general, the paper is well-written (although there are a lot of typos and grammatical errors that need to be corrected), and the main ideas are clear. It would have been useful to provide some more details and carry out additional experiments to strengthen the merit of the proposed model. \n\nEspecially, in Section 4.2, more details about the quality of paraphrasing after training with the multilingual, monolingual, and refined models would be helpful. Which evaluation metrics were used to evaluate the quality? Also, more monolingual experiments could have been conducted with state-of-the-art neural paraphrasing models on WikiQA and Quora datasets (e.g. see https://arxiv.org/pdf/1610.03098.pdf and https://arxiv.org/pdf/1709.05074.pdf). \n\nMore details with examples should be provided about the variants of AQA along with the oracle model. Especially, step-by-step examples (for all alternative models) from input (original question) to question reformulations to output (answer/candidate answers) would be useful to understand how each module/variation is having an impact towards the best possible answer/ground truth.\n\nAlthough experiments on SearchQA demonstrate good results, I think it would be also interesting to see the results on additional datasets e.g. MS MARCO (Nguyen et al., 2016), which is very similar to the SearchQA dataset, in order to confirm the generalizability of the proposed approach. \n\n---------------------------------------------\nThanks for revising the paper, I am happy to update my scores.', 'This article clearly describes how they designed and actively trained 2 models for question reformulation and answer selection during question answering episodes. The reformulation component is trained using a policy gradient over a sequence-to-sequence model (original vs. reformulated questions). The model is first pre-trained using a bidirectional LSTM on multilingual pairs of sentences. A small monolingual bitext corpus is the uses to improve the quality of the results. A CNN binary classifier performs answer selection. \n\nThe paper is well written and the approach is well described. I was first skeptical by the use of this technique but as the authors mention in their paper, it seems that the sequence-to-sequence translation model generate sequence of words that enables the black box environment to find meaningful answers, even though the questions are not semantically correct. Experimental clearly indicates that training both selection and reformulation components with the proposed active scheme clearly improves the performance of the Q&A system. ']","[-50, 50, 0]","[50, 70, 0]","[""The sentiment score is -50 because the review starts with criticisms about the paper's lack of compelling reasons for its approach and insufficient comparisons to baselines. However, it's not entirely negative as it acknowledges the approach as 'interesting' and ends on a positive note after the author response. The politeness score is 50 because the reviewer uses respectful language throughout, framing criticisms as questions or observations rather than harsh statements. They also acknowledge the paper's strengths and show willingness to change their opinion based on the authors' response, which is quite polite. The language is professional and constructive throughout, avoiding any rudeness while still clearly communicating concerns."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper is well-written and the main ideas are clear, showing significant improvement over state-of-the-art models. However, they also point out areas for improvement, such as typos, grammatical errors, and the need for more details and experiments. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. The phrase 'It would have been useful' and the use of 'I think' show a considerate approach to feedback. The final line 'Thanks for revising the paper, I am happy to update my scores' is particularly polite and encouraging."", 'ERROR']"
"['The authors clearly describe the problem being addressed in the manuscript and motivate their solution very clearly. The proposed solution seems very intuitive and the empirical evaluations demonstrates its utility. My main concern is the underlying assumption (if I understand correctly) that the adversarial attack technique that the detector has to handle needs to be available at the training time of the detector. Especially since the empirical evaluations are designed in such a way where the training and test data for the detector are perturbed with the same attack technique. However, this does not invalidate the contributions of this manuscript.\n\nSpecific comments/questions:\n- (Minor) Page 3, Eq 1: I think the expansion dimension cares more about the probability mass in the volume rather than the volume itself even in the Euclidean setting.\n- Section 4: The different pieces of the problem (estimation, intuition for adversarial subspaces, efficiency) are very well described.\n- Alg 1, L3: Is this where the normal exmaples are converted to adversarial examples using some attack technique? \n- Alg 1, L12: Is LID_norm computed using a leave-one-out estimate? Otherwise, r_1(.) for each point is 0, leading to a somewhat ""under-estimate"" of the true LID of the normal points in the training set. I understand that it is not an issue in the test set.\n- Section 4 and Alg 1: S we do not really care about the ""labels/targets"" of the examples. All examples in the dataset are considered ""normal"" to start with. Is this assuming that the ""initial training set"" which is used to obtain the ""pre-trained DNN"" free of adversarial examples?\n- Section 5, Experimental Setup: Seems like normal points in the test set would get lesser values if we are not doing the ""leave-one-out"" version of the estimation.\n- Section 5: The authors have done a great job at evaluating every aspect of the proposed method.\n', 'The paper considers a problem of adversarial examples applied to the deep neural networks. The authors conjecture that the intrinsic dimensionality of the local neighbourhood of adversarial examples significantly differs from the one of normal (or noisy) examples. More precisely, the adversarial examples are expected to have intrinsic dimensionality much higher than the normal points (see Section 4).  Based on this observation they propose to use the intrinsic dimensionality as a way to separate adversarial examples from the normal (and noisy) ones during the test time. In other words, the paper proposes a particular approach for the adversarial defence.\n\nIt turns out that there is a well-studied concept in the literature capturing the desired intrinsic dimensionality: it is called the local intrinsic dimensionality (LID, Definition 1) . Moreover, there is a known empirical estimator of LID, based on the k-nearest neighbours. The authors propose to use this estimator in computing the intrinsic dimensionalities for the test time examples. For every test-time example X the resulting Algorithm 1 computes LID estimates of X activations computed for all intermediate layer of DNN. These values are finally used as features in classifying adversarial examples from normal and noisy ones. \n\nThe authors empirically evaluate the proposed technique across multiple state-of-the art adversarial attacks, 3 datasets (MNIST, CIFAR10, and SVHN) and compare their novel adversarial detection technique to 2 other ones recently reported in the literature. The experiments support the conjecture mentioned above and show that the proposed technique *significantly* improves the detection accuracy compared to 2 other methods across all attacks and datasets (see Table 1).\n\nInterestingly, the authors also test whether adversarial attacks can bypass LID-based detection methods by incorporating LID in their design. Preliminary results show that even in this case the proposed method manages to detect adversarial examples most of the time. In other words, the proposed technique is rather stable and can not be easily exploited.\n\nI really enjoyed reading this paper. All the statements are very clear, the structure is transparent and easy to follow. The writing is excellent. I found only one typo (page 8, ""We also NOTE that...""), otherwise I don\'t actually have any comments on the text.\n\nUnfortunately, I am not an expert in the particular field of adversarial examples, and can not properly assess the conceptual novelty of the proposed method. However, it seems that it is indeed novel and given rather convincing empirical justifications, I would recommend to accept the paper. \n', 'This paper tried to analyze the subspaces of the adversarial examples neighborhood. More specifically, the authors used Local Intrinsic Dimensionality to analyze the intrinsic dimensional property of the subspaces. The characteristics and theoretical analysis of the proposed method are discussed and explained. This paper helps others to better understand the vulnerabilities of DNNs.']","[0, 90, 0]","[0, 80, 0]","['ERROR', ""The sentiment score is 90 because the reviewer expresses very positive opinions about the paper. They state that they 'really enjoyed reading this paper', praise the clarity and structure, and recommend acceptance. The only slight hesitation is their admission of not being an expert in the field, which prevents a perfect 100 score. The politeness score is 80 because the reviewer uses respectful and encouraging language throughout, such as 'I really enjoyed reading this paper' and 'The writing is excellent'. They also provide constructive feedback and acknowledge their own limitations politely. The score is not 100 as the review maintains a professional tone rather than being excessively polite."", 'ERROR']"

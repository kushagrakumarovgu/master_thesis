reviews,sentiment_scores,politeness_scores,reasonings
"['This paper presents a new contribution for a largely understudied problem of label shift (also called target shift), a situation occurring when the class proportions vary between the training and test sets. The proposed contribution builds upon a recent work on the subject by Lipton et al., 2018 and addresses several of its weaknesses. The paper also gives several improved generalisation bounds w.r.t. that of Lipton et al. that are further used as guidelines to tune the regularisation parameter based on the size of source and target samples. Finally, the empirical results show that the proposed algorithm outperforms that of Lipton et al. especially in cases where the shift in proportions becomes quite important. \n\n*Pros: \n   - A work in an area with very view contributions and a certain lack of theoretical results\n    -Theoretical results that are actually used in the algorithmic implementation and that allow to define the regularisation parameter based on the size of the available samples\n    -Improved empirical results\n\n\n*Cons: \n    -An incomplete state-of-the-art section that does not cite several important contributions on the subject;\n    -Lack of baselines due to the incomplete state-of-the-art section;\n    -Lack of clear comparison with Lipton et al. both in terms of the proposed method and the obtained theoretical guarantees.  \n\n\n*Detailed comments:\nThis paper is rather interesting and well-written.\n\nI have several major concerns regarding this paper. They can be summarised as follows:\n\n    There is an important part of literature review on target shift that is missing in this paper. Even though, the paper mentioned the work of Chang, 2005 and Zhang, 2013, it completely ignores several other highly relevant methods such as [1,2]. These works also propose algorithms that allow to estimate class proportions that vary between training and test data. This estimation can then be used for cost-sensitive learning to correct the target shift. The paper should mention this work and add the corresponding methods to the baselines for comparison. \n\n    Several statements that justify the contribution of this paper are unsupported. For instance, the paper states that the estimator obtained with the inverse of the confusion matrix can be arbitrary bad when the sample size and/or the singular values are small. However, this exact dependence can be found in Lemma 1 for the proposed contribution also! This is repeated in the beginning of Section 2.2 to justify the regularised version of the estimator but once again no evidence was provided to support the claim. The obtained bound for the regularised algorithm also has these two terms and thus it is not clear why the regularised algorithm is supposed to work better. \n\n    The paper may want to clearly state the differences between the proposed algorithm and that of Lipton et al. and also between the obtained error bounds. The paper states that it achieves a k*log(k) improvement over Lipton et al. bounds but as fair as I can see this improvement is achieved only when h_0 is an ideal estimator. Furthermore, Lipton et al.’s bounds are linear in k while the proposed bounds replace this term with log(k/delta) so that when \\delta is small, ie the bound holds with high probability, the bound becomes much worse. I would suggest to add a brief discussion on the relationship between the two to better highlight the original contribution of the paper. \n\n    The proofs are quite badly written with many lacking results used to move from one inequality to another. For instance, Lemma 2 is proved using the theorem 1.4[Matrix Bernstein] and dilation technique from Tropp but it is not clear which results the authors are using in particular; Theorem 1.4 is related to the largest eigenvalue of the sum of matrices while the authors obtain an inequality for the norm of the sum without any further comment on how this transition was made. Also, I do not see why delta is smaller than 1/2 in Lemma 2. \n\n\n*Minor comments:\n\n   - p.1: expected have -> expected to have\n   - p.4: we are instead only gave access -> given access to \n   - I do not understand Figure 1. Should it be n_q*n_p on the y axis ?\n   - The inequality for n_q next to Figure 1 is derived from the bound (6). Why it is independent of k?\n   - Why the authors choose to the black box predictor h0 to be a two-layer fully connected neural? Is there any particular reason to use this classification model?\n\n[1] Class Proportion Estimation with Application to Multiclass Anomaly Rejection, AISTATS14\n[2] Mixture Proportion Estimation via Kernel Embeddings of Distributions, ICML16', '- The authors consider the problem of learning under label shifts, where the label proportions p(y) and q(y) of the training and test distributions differ, while the conditionals p(x|y) and q(x|y) are equal. They build upon the work by Lipton et al. 18 on estimating label proportion weights q(y)/p(y) using the confusion matrix, by proposing an improved estimator with regularization. They show that their estimator provides better weight estimates compared to the unregularized version, and it also gives better prediction accuracies under large label shift scenarios. \n\n- One question I have about this approach is the choice of h in the confusion matrix estimation. Since the theory holds for any fixed hypothesis h, is there any guidance on how we should pick h? The authors seem to use the same model class for the weight estimation and predictions in the experiments. How would using a simpler h for weight estimation (e.g., linear logistic regression) affect the results presented here? \n\n- The Dirichlet shifts described with only the parameter alpha is not particularly intuitive in conveying the size of shifts. The CIFAR10 and MNIST datasets contain about 6000 examples per class. How would a large shift with alpha=0.01 change the distribution, especially for the smallest class how many samples are retained? This can help the readers judge when the correction of label shifts are helpful. \n\n- To clarify, in the experiments for Figure 4 using Minority-Class shifts, with p=0.001, is it true that there are less than 100 training examples for each of the minority classes in the training set? This seems like a very extreme shift. \n\n- I also have trouble understanding Figure 3. RESNET-18 should give >90% accuracy on the original CIFAR10, but in 3b we see accuracies around 75% for small shifts. Also how is the F1-score in 3c computed? Is it micro-averaged or macro-averaged F1? Either way an F1 score below 20% is very low for the unweighted classifier, since RESNET-18 should give fairly good classification accuracy on each class separately if it has >90% overall accuracy. \n\n- The paper is quite solid in motivating the need for better weight estimators for reweighing label proportions and their derivations, and manage to show improvements over the unregularized estimator. Details on the experiments should be improved to give the readers better ideas on when correcting for label shifts help. Right now it looks like it only helps for cases with fairly extreme shifts. \n\n', ""Authors proposes a new algorithm for improving the stability of class importance weighting estimation procedure (Lipton et al., 2018) with a two-step procedure. The reparamaterization of w using the weight shift theta and lambda allows authors develop a generalization upperbound with terms rely on theta, sigma and lambda. \n\nThe problem of label shift is a known important issue in transfer learning but has been understudied.\n\nThe paper is very well written and the algorithm is well-motivated (introducing regularization to avoid the singularity) and post processing step looks sound (using lambda to de-biase). I only have a few minor questions: \n\n1. How realistic it is to assume we have prior knowledge on theta and sigma_min? \n\n2. If I understand correctly, the only experiment where lambda is varied is Sec 3.3? It would be interesting if authors also included BBSE in Sec 3.3 as a baseline. \n\n3. The authors mentioned in the discussion that the generalization guarantee is obtained with no prior knowledge q/p is needed. However, doesn't theta implicitly represent the knowledge in p/q?   \n\n------------------------------------------------\n\nI have read authors' comments. ""]","[20, 50, 80]","[60, 80, 90]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and potential ('new contribution', 'improved generalisation bounds', 'outperforms'), but also lists several significant concerns ('major concerns', 'incomplete state-of-the-art section', 'lack of baselines'). The overall tone suggests the paper has merit but needs substantial improvements. The politeness score is moderately high (60) as the reviewer uses respectful language throughout ('This paper is rather interesting and well-written', 'The paper may want to clearly state'), offers constructive criticism, and provides detailed explanations for their concerns. The reviewer also balances criticism with positive remarks ('Pros' section) and offers specific suggestions for improvement, which contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's solid motivation and derivations, and notes improvements over previous work. However, they also raise several questions and concerns about experimental details and clarity. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and acknowledges the paper's strengths. They use phrases like 'One question I have...' and 'To clarify...' which maintain a constructive tone. The review concludes with a balanced summary, recognizing both strengths and areas for improvement."", ""The sentiment score is 80 (positive) because the reviewer expresses that the paper is 'very well written' and the algorithm is 'well-motivated'. They also mention that the problem addressed is important but understudied, indicating the value of the research. The few questions raised are described as 'minor', suggesting overall approval. The politeness score is 90 (very polite) due to the respectful and constructive tone throughout. The reviewer uses phrases like 'I only have a few minor questions' and 'It would be interesting if...', which are polite ways to offer suggestions. They also acknowledge having read the authors' comments, showing engagement and respect for the authors' perspective. The language is consistently professional and courteous, without any harsh criticism or demanding language.""]"
"['The paper considers deep nets with piecewise linear activation functions, which are known to give rise to piecewise linear input-output mappings, and proposes loss functions which discourage datapoints in the input space from lying near the boundary between linear regions. These loss functions are well-motivated theoretically, and have the intended effect of increasing the distance to the nearest boundary and reducing the number of distinct linear regions. \n\nMy only concern is that while their method appears to effectively increase the l_1 and l_2 margin (as they have defined it), the utility of doing so is not clearly demonstrated. If improving the quality or validity of local linearization for explaining predictions is one of the main motivations for this work, showing that the proposed method does so would strengthen the overall message. However, I do feel that “establishing robust derivatives over larger regions” is an important problem in its own right. \n\nWith the exception of some minor typos, the exposition is clear and the theoretical claims all appear correct. The authors may have missed some relevant recent work [1], but their contributions are complementary. It is not immediately clear that the parallel computation of gradients proposed in section 4.1 is any faster than standard backpropagation, as this has to be carried out separately for each linear region. A basic complexity analysis or running time comparison would help clarify this. I think I am missing the point of the gradient visualizations in figure 4, panels b-e and g-j. \n\n\n[1] Elsayed, Gamaleldin F., et al. ""Large Margin Deep Networks for Classification."" arXiv preprint arXiv:1803.05598 (To appear in NIPS 2018).', '\n########## Updated Review ##########\n\nThe author(s) have presented a very good rebuttal, and I am impressed. My concerns have been addressed and my confusions have been clarified. To reflect this, I am raising my points to 8. It is a good paper, job well done. I enthusiastically recommend acceptance. \n\n################################\n\nA key challenge that presents the deep learning community is that state-of-the-art solutions are oftentimes associated with unstable derivatives, compromising the robustness of the network. In this paper, the author(s) explore the problem of how to train a neural network with stable derivatives by expanding the linear region associated with training samples. \n\nThe author(s) studied deep networks with piecewise linear activations, which allow them to derive lower bounds on the $l_p$ margin with provably stable derivatives. In the special case of $l_2$ metric, this bound is analytic, albeit rigid and non-smooth. To avoid associated computational issues, the author(s) borrowed an idea from transductive/semi-supervised SVM (TSVM) to derive a relaxed formulation. \n\nIn general, I find this paper rather interesting and well written. However, I do have a few concerns and confusions as listed below: \n\nMajor ones:\n\n- I would prefer some elaborations on why the relaxation proposed in Eqn (8) serves to encourage the margin of L2 ball? What\'s the working mechanism or heuristic behind this relaxation? This is supposedly one of the key techniques used in optimization, yet remains obscure. \n\n- On empirical gains, the author(s) claimed that ""about 30 times larger margins can be achieved by trading off 1% accuracy.""  It seems that consistently yields inferior prediction accuracy. In my opinion, the author(s) failed to showcase the practical utility of their solution. A better job should be done to validate the claim `` The problem we tackle has implications to interpretability and transparency of complex models. \'\' \n\n- As always, gradient-based penalties suffer from heavy computational overhead. The final objectives derived in this paper (Eqn (7) & Eqn (9)) seem no exception to this, and perhaps even worse since the gradient is taken wrt each neuron. Could the author(s) provide statistics on empirical wallclock performance? How much drain does this extra gradient penalty impose on the training efficiency? \n\nMinor ones:\n\n- Just to clarify, does the | - | used in Eqn (9) for |I(x,\\gamma)|  denote counting measure? \n\n- I do not see the necessity of introducing Lemma 7 in the text. Please explain. \n\n- Lemma 8, ``... then any optimal solutions for the problem is also optimal for Eqn (4). \'\' Do you mean ``the following problem\'\' (Eqn (5))? \n', '1. This is a very relevant and timely work related to robustness of deep learning models under adversarial attacks. \n\n2. In recent literature of verifiable/certifiable networks, (linear) ReLU network has emerged as a tractable model architecture where analytically sound algorithms/understanding can be achieved. This paper adopts the same setting, but very clearly articulates the differences between this work and the other recent works (Weng et al 2018, Wong et al. 2018).  \n\n3. The primary innovation here is that the authors not only identify the locally linear regions in the loss surface but expand that region by learning essentially leading to gradient stability. \n\n4. A very interesting observation is that the robustifying process does not really reduce the overall accuracy which is the case of many other methods. \n\n5. The visualizations show the stability properties nicely, but a bit more explanations of those figures would help the readers quite a bit.\n\n6. While I understand some of the feasibility issues associated with other existing methods, it would be interesting to try to compare performance (if not exact performance, the at least loss/gradient surfaces etc.) with some of them.\n\n7. The adversarial scenarios need to be explained better. ']","[60, 80, 80]","[80, 70, 60]","[""The sentiment score is 60 (positive) because the reviewer generally approves of the paper, praising its theoretical motivation and effectiveness. They mention only one main concern and some minor issues, indicating overall positive sentiment. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively. They use phrases like 'My only concern' and 'The authors may have missed' instead of more direct criticisms. The reviewer also balances critiques with positive comments, maintaining a courteous tone throughout the review."", ""The sentiment score is 80 because the reviewer expresses a very positive view in the first paragraph, stating they are 'impressed' and 'enthusiastically recommend acceptance'. They also raise their points to 8, indicating a high level of satisfaction. The politeness score is 70 because the reviewer uses respectful language throughout, acknowledging the authors' efforts and improvements. They use phrases like 'I find this paper rather interesting and well written' and 'job well done'. However, they also provide direct critiques, which keeps the tone professional rather than overly deferential. The reviewer maintains a balance between praise and constructive criticism, which is appropriate for a peer review."", ""The sentiment score is 80 (positive) because the reviewer uses phrases like 'very relevant and timely work', 'primary innovation', and 'very interesting observation', indicating a generally positive view of the paper. They also highlight the paper's strengths and contributions to the field. The politeness score is 60 (moderately polite) as the reviewer maintains a professional and respectful tone throughout, using phrases like 'it would be interesting' and 'a bit more explanations... would help the readers'. While not overly effusive, the language is consistently courteous and constructive. The reviewer offers suggestions for improvement without harsh criticism, balancing positive feedback with areas for potential enhancement.""]"
"['In this paper, the authors associated with the generalization gap of robust adversarial training with the distance between the test point and the manifold of training data. A so-called \'blind-spot attack\' is proposed to show the weakness of robust adversarial training.  Although the paper contains interesting ideas and empirical results, I have several concerns about the current version. \n\na) In the paper, the authors mentioned that ""This simple metric is non-parametric and we found that the results are not sensitive to the selection of k"". Can authors provide more details, e.g., empirical results, about it? What is its rationale?\n\nb) In the paper, ""We find that these blind-spots are prevalent and can be easily found without resorting to complex\ngenerative models like in Song et al. (2018). For the MNIST dataset which Madry et al. (2018) demonstrate the strongest defense results so far, we propose a simple transformation to find the blind-spots in this model."" Can authors provide empirical comparison between blind-spot attacks and the work by Song et al. (2018), e.g., attack success rate & distortion? \n\nc) The linear transformation x^\\prime = \\alpha x + \\beta yields a blind-spot attack which can defeat robust adversarial training. However, given the linear transformation, one can further modify the inner maximization (adv. example generation) in robust training framework so that the $\\ell_infty$ attack satisfies  max_{\\alpha, \\beta} f(\\alpha x + \\beta) subject to \\| \\alpha x + \\beta \\|\\leq \\epsilon. In this case, robust training framework can defend blind-spot attacks, right? I agree with the authors that the generalization error is due to the mismatch between training data and test data distribution, however, I am not convinced that blind-spot attacks are effective enough to robust training. \n\nd) ""Because we scale the image by a factor of \\alpha, we also set a stricter criterion of success, ..., perturbation must be less\nthan \\alpha \\epsilon to be counted as a successful attack."" I did not get the point. Even if you have a scaling factor in x^\\prime = \\alpha x + \\beta, the universal perturbation rule should still be | x - x^\\prime  |_\\infty \\leq \\epsilon. The metric the authors used would result in a higher attack success rate, right? \n', 'The paper is well written and the main contribution, a methodology to find “blind-spot attacks” well motivated and differences to prior work stated clearly.\n\nThe empirical results presented in Figure 1 and 2 are very convincing. The gain of using a sufficiently more complicated approach to assess the overall distance between the test and training dataset is not clear, comparing it to the very insightful histograms. Why for example not using a simple score based on the histogram, or even the mean distance? Of course providing a single measure would allow to leverage that information during training. However, in its current form this seems rather complicated and computationally expensive (KL-based). As stated later in the paper the histograms themselves are not informative enough to detect such blind-spot transformation. Intuitively this makes a lot of sense given that the distance is based on the network embedding and is therefore also susceptible to this kind of data. However, it is not further discussed how the overall KL-based data similarity measure would help in this case since it seems likely that it would also exhibit the same issue.\n', 'This paper provides some insights on influence of data distribution on robustness of adversarial training. The paper demonstrates through a number of analysis that the distance between the training an test data sets plays an important role on the effectiveness of adversarial training. To show the latter, the paper proposes an approach to measure the distance between the two data sets using combination of nonlinear projection (e.g. t-SNE), KDE, and K-L divergence. The paper also shows that under simple transformation to the test dataset (e.g. scaling), performance of adversarial training reduces significantly due to the large gap between training and test data set. This tends to impact high dimensional data sets more than low dimensional data sets since it is much harder to cover the whole ground truth data distribution in the training dataset.\n\nPros:\n- Provides insights on why adversarial training is less effective on some datasets.\n- Proposes a metric that seems to strongly correlate with the effectiveness of adversarial training.\n\nCons:\n- Lack of theoretical analysis. It could have been nice if the authors could show the observed phenomenon analytically on some simple distribution.\n- The marketing phrase ""the blind-spot attach"" falls short in delivering what one may expect from the paper after reading it. The paper would read much better if the authors better describe the phenomena based on the gap between the two distribution than using bling-spot. For some dataset, this is beyond a spot, it could actually be huge portion of the input space!\n\nMinor comments:\n- I believe one should not compare the distance shown between the left and right columns of Figure 3 as they are obtained from two different models. Though the paper is not suggesting that, it would help to clarify it in the paper. Furthermore, it would help if the paper elaborates why the distance between the test and training dataset is smaller in an adversarially trained network compared to a naturally trained network.\n- Are the results in Table 1 for an adversarially trained network or a naturally trained network? Either way, it could be also interesting to see the average K-L divergence between an adversarially and a naturally trained network on the same dataset.\n- Please provide more visualization similarly to those shown in Fig 4.\n']","[-20, 50, 50]","[60, 75, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges 'interesting ideas and empirical results', they express 'several concerns' about the current version. This indicates a mix of positive and negative sentiment, but leaning towards the negative side due to the multiple concerns raised. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, phrases their concerns as questions or suggestions (e.g., 'Can authors provide more details...?'), and acknowledges positive aspects of the paper. The reviewer maintains a professional tone without using harsh or dismissive language, even when expressing disagreement or skepticism about certain points."", ""The sentiment score is 50 (moderately positive) because the reviewer starts by praising the paper as 'well written' and the main contribution as 'well motivated'. They also describe the empirical results as 'very convincing'. However, the reviewer does raise some questions and concerns in the latter part, which prevents a higher positive score. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh or negative phrasing. They use phrases like 'not clear' instead of more critical alternatives, and frame their concerns as questions or suggestions rather than direct criticisms. The overall tone is professional and courteous."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's insights and contributions while also pointing out some limitations. The review starts with positive aspects ('provides some insights', 'demonstrates through a number of analysis') and lists pros before cons. However, it also includes constructive criticism and suggestions for improvement, balancing the positive and negative aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive feedback, and phrases criticisms as suggestions ('It could have been nice if...', 'The paper would read much better if...'). The reviewer also uses polite language in the minor comments section, offering helpful suggestions without being demanding ('Please provide more visualization...'). The overall tone is professional and courteous, maintaining a balance between praise and critique.""]"
"['The paper considers a number of streaming learning settings with various forms of dataset shift/drift of interest for continual learning research, and proposes a novel regularization-based objective enabled by a replay memory managed using the well known reservoir sampling algorithm.\n\nPros:\nThe new objective is not too surprising, but figuring out how to effectively implement this objective in a streaming setting is the strong point of this paper. \n\nTask labels are not used, yet performance seems superior to competing methods, many of which use task labels.\n\nResults are good on popular benchmarks, I find the baselines convincing in the supervised case.\n\nCons:\nDespite somewhat frequent usage, I would like to respectfully point out that Permuted MNIST experiments are not very indicative for a majority of desiderata of interest in continual learning, and i.m.h.o. should be used only as a prototyping tool. To pick one issue, such results can be misleading since the benchmark allows for “trivial” solutions which effectively freeze the upper part of the network and only change first (few) layer(s) which “undo” the permutation. This is an artificial type of dataset shift, and is not realistic for the type of continual learning issues which appear even in single task deep reinforcement learning, where policies or value functions represented by the model need to change substantially across learning.\n\nI was pleased to see the RL experiments, which I find more convincing because dataset drifts/shifts are more interesting. Also, such applications of continual learning solutions are attempting to solve a ‘real problem’, or at least something which researchers in that field struggle with. That said, I do have a few suggestions. At first glance, it’s not clear whether anything is learned in the last 3 versions of Catcher, also what the y axis actually means. What is good performance for each game is very specific to your actual settings so I have no reference to compare the scores with. The sequence of games is progressively harder, so it makes sense that scores are lower, but it’s not clear whether your approach impedes learning of new tasks, i.e. what is the price to pay for not forgetting?\n\nThis is particularly important for the points you’re trying to make because a large number of competing approaches either saturate the available capacity and memory with the first few tasks, or they faithfully model the recent ones. Any improvement there is worth a lot of attention, given proper comparisons. Even if this approach does not strike the ‘optimal’ balance, it is still worth knowing how much training would be required to reach full single-task performance on each game variant, and what kind of forgetting that induces. \n', 'The authors frame continual learning as a meta-learning problem that balances catastrophic forgetting against the capacity to learn new tasks. They propose an algorithm (MER) that combines a meta-learner (Reptile) with experience replay for continual learning. MER is evaluated on variants of MNIST (Permutated, Rotations, Many) and Omniglot against GEM and EWC. It is further tested in two reinforcement learning environments, Catcher and FlappyBird. In all cases, MER exhibits significant gains in terms of average retained accuracy.\n\nPro\'s\n\nThe paper is well structured and generally well written. The argument is both easy to follow and persuasive. In particular, the proposed framework for trading off catastrophic forgetting against positive transfer is enlightening and should be of interest to the community. \n\nWhile the idea of aligning gradients across tasks has been proposed before (Lopez-Paz & Ranzato, 2017), the authors make a non-trivial connection to Reptile that allows them to achieve the same goal in a surprisingly simple algorithm. That the algorithm does not require tasks to be identified makes it widely applicable and reported results are convincing. \n\nThe authors have taken considerable care to tease out various effects, such as how MER responds to the degree of non-stationarity in the data, as well as the buffer size.  I’m particularly impressed that MER can achieve such high retention rates using only a buffer size of 200. Given that multiple batches are sampled from the buffer for every input from the current task, I’m surprised MER doesn’t suffer from overfitting. How does the train-test accuracy gap change as the buffer size varies?\n\nThe paper is further strengthened by empirically verifying that MER indeed does lead to a gradient alignment across tasks, and by an ablation study delineating the contribution from the ER strategy and the contribution from including Reptile. Notably, just using ER outperforms previous methods, and for a sufficient large buffer size, ER is almost equivalent to MER. This is not surprising given that, in practice, the difference between MER and ER is an additional decay rate ( \\gamma) applied to gradients from previous batches. \n\nCon\'s\n\nI would welcome a more thorough ablation study to measure the difference between ER and MER. In particular, how sensitive is MER is to changes in \\gamma? And could ER + an adaptive optimizer (e.g. Adam) emulate the effect of \\gamma and perform on par with MER. Similarly, given that DQN already uses ER,  it would be valuable to report how a DQN with reservoir sampling performs.\n\nI am not entirely convinced though that MER maximizes for forward transfer. It turns continual learning into multi-task learning and if the new task is sufficiently different from previous tasks, MER’s ability to learn the current task would be impaired. The paper only reports average retained accuracy, so the empirical support for the claim is ambiguous.\n\nThe FlappyBird experiment could be improved. As tasks are defined by making the gap between pipes smaller, a good policy for task t is a good policy for task t-1 as well, so the trade-off between backward and forward transfer that motivates MER does not arise. Further, since the baseline DQN never finds a good policy, it is essentially a pseudo-random baseline. I suspect the only reason DQN+MER learns to play the game is because it keeps ""easy"" experiences with a lot of signal in the buffer for a longer period of time. That both the baseline and MER+DQN seems to unlearn from tasks 5 and 6 suggests further calibration might be needed.', 'The transfer/ interference perspective of lifelong learning is well motivated, and combining the meta-learning literature with the continual learning literature (applying reptile twice), even if seems obvious, wasn\'t explored before. In addition, this paper shows that a lot of gain can be obtained if one uses more randomized and representative memory (reservoir sampling). However, I\'m not entirely convinced with the technical contributions and the analysis provided to support the claims in the paper, good enough for me to accept it in its current form. Please find below my concerns and I\'m more than happy to change my mind if the answers are convincing.\n\nMain concerns:\n\n1) The trade-off between transfer and interference, which is one of the main contributions of this paper, has recently been pointed out by [1,2]. GEM[1] talks about it in terms of forward transfer and RWalk[2] in terms of ""intransigence"". Please clarify how ""transfer"" is different from these. A clear distinction will strengthen the contribution, otherwise, it seems like the paper talks about the same concepts with different terminologies, which will increase confusion in the literature.    \n\n2) Provide intuitions about equations (1) and (2). Also, why is this assumption correct in the case of ""incremental learning"" where the loss surface itself is changing for new tasks?\n\n3) The paper mentions that the performance for the current task isn\'t an issue, which to me isn\'t that obvious as if the evaluation setting is ""single-head [2]"" then the performance on current task becomes an issue as we move forwards over tasks because of the rigidity of the network to learn new tasks. Please clarify.\n\n4) In eq (4), the second sample (j) is also from the same dataset for which the loss is being minimized. Intuitively it makes sense to not to optimize loss for L(xj, yj) in order to enforce transfer. Please clarify.\n\n5) Since the claim is to improve the ""transfer-interference"" trade-off, how can we verify this just using accuracy? Any metric to quantify these? What about forgetting and forward transfer measures as discussed in [1,2]. Without these, its hard to say what exactly the algorithm is buying.\n\n6) Why there isn\'t any result showing MER without reservoir sampling. Also, please comment on the computational efficiency of the method (which is crucial for online learning), as it seems to be very slow. \n\n7)The supervised learning experiments are only shown on the MNIST. Maybe, at least show on CONV-NET/ RESNET (CIFAR etc).\n\n8) It is not clear from where the gains are coming. Do the ablation where instead of using two loops of reptile you use one loop.\n\nMinor:\n=======\n1) In the abstract, please clarify what you mean by ""future gradient"". Is it gradient over ""unseen"" task, or ""unseen"" data point of the same task. It\'s clear after reading the manuscript, but takes a while to reach that stage.\n2) Please clarify the difference between stationary and non-stationary distribution, or at least cite a paper with the proper definition.\n3) Please define the problem precisely. Like a mathematical problem definition is missing which makes it hard to follow the paper. Clarify the evaluation setting (multi/single head etc [2])\n4) No citation provided for ""reservoir sampling"" which is an important ingredient of this entire algorithm.\n5) Please mention appendix sections as well when referred to appendix.\n6) Provide citations for ""meta-learning"" in section 1.\n\n\n[1] GEM: Gradient episodic memory for continual learning, NIPS17.\n[2] RWalk: Riemannian walk for incremental learning: Understanding forgetting and intransigence, ECCV2018.']","[50, 70, -20]","[80, 80, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer provides a balanced view with both pros and cons. They acknowledge the paper's strengths, such as the novel objective implementation and good results on benchmarks, while also pointing out areas for improvement. The overall tone is constructive rather than overly critical or enthusiastic. The politeness score is 80 (quite polite) due to the respectful language used throughout. The reviewer uses phrases like 'I would like to respectfully point out' and 'I was pleased to see', which demonstrate courtesy. They also offer suggestions in a constructive manner, showing consideration for the authors' work while providing valuable feedback."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, praising its structure, persuasiveness, and the authors' care in conducting experiments. The reviewer uses phrases like 'well structured,' 'well written,' 'enlightening,' and 'impressive.' However, it's not a perfect score due to some criticisms in the 'Con's' section. The politeness score is 80 (very polite) because the reviewer maintains a professional and respectful tone throughout, even when offering criticisms. They use phrases like 'I would welcome,' and 'I am not entirely convinced,' which are polite ways to express concerns. The reviewer also balances criticism with praise, showing respect for the authors' work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'well motivated', 'wasn't explored before', 'a lot of gain can be obtained'), they express significant concerns and are 'not entirely convinced' with the technical contributions. The overall tone suggests the paper needs substantial revisions before acceptance. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, such as 'Please find below my concerns' and 'I'm more than happy to change my mind if the answers are convincing.' They also provide detailed, constructive feedback and use polite phrases like 'Please clarify' and 'Please comment' when requesting additional information or changes.""]"
"[""This paper puts forward a new global+local memory pointer network to tackle task-oriented dialogue problem.\n\nThe idea of introducing global memory is novel and experimental results show its effectiveness to encode external knowledge in most cases.\n\nHere're some comments:\n1. In global memory pointer, the users employ non-normalized probability (non-softmax). What is the difference in performance if one uses softmax?\n\n2. In (11), there's no linear weights. Will higher weights in global/local help?\n\n3. As pointed out in ablation study, it's weird that in task5 global memory pointer does not help.\n\n4. The main competitor of this algorithm is mem2seq. While mem2seq includes DSTC2 and In-car Assistant, and especially in-car assistant provides the first example dialogue, why does the paper not include expeirments on these two datasets?"", 'This is, in general, a well-written paper with extensive experimentation. \n\nThe authors tried to describe their architecture both with equations as well as graphically. However, I would like to mention the following: \n\nIn Section 2.1 I am not sure all the symbols are clearly defined. For example, I could not locate the definitions of n, l etc. Even if they are easy to assume, I am fond of appropriate definitions. Also, I suspect that some symbols, like n, are not used consistently across the manuscript.\n\nI am also confused about the loss function. Which loss function is used when?\n\nI am missing one more figure. From Fig 2 it\'s not so straightforward to see how the encoder/decoder along with the shared KB work at the same time (i.e. not independently)\n\nIn Section 2.3, it\'s not clear to me how the expected output word will be picked up from the local memory pointer. Same goes for the entity table.\n\nHow can you guarantee that that position n+l+1 is a null token?\n\nWhat was the initial query vector and how did you initialise that? Did different initialisations had any effect on performance?\n\nIf you can please provide an example of a memory position.\n\nAlso, i would like to see a description of how the OOV tasks are handled.\n\nFinally, your method is a NN end-to-end one and I was wondering how do you compare not with other end-to-end approaches, but with a traditional approach, such as pydial?\n\n\nAnd some minor suggestions:\n\nNot all the abbreviations are defined. For example QRN, GMN, KVR. It would also be nice to have the references of the respective methods included in the Tables or their captions.\n\nParts of Figs. 1&2 are pixelised. It would be nice to have everything vectorised.\n\n I would prefer to see the training details (in fact, I would even be favorable of having more of those) in the main body of the manuscript, rather than in the appendix.\n\nThere are some minor typos, such as ""our approach that utilizing the recurrent"" or ""in each datasets""', 'The paper presents a new model for reading and writing memory in the context of task-oriented dialogue. The model contains three main components: an encoder, a decoder, and an external KB. The external KB is in the format of an SVO triple store. The encoder encodes the dialogue history and, in doing so, writes its hidden states to memory and generates a ""global memory pointer"" as its last hidden state. The decoder takes as input the global memory pointer, the encoded dialogue state history, and the external KB and then generates a response using a two-step process in which it 1) generates a template response using tags to designate slots that need filling and 2) looks up the correct filler for each slot using the template+global memory pointer as a query. The authors evaluate the model on a simulated dialogue dataset (bAbI) and on a human-human dataset (Stanford Multi-domain Dialogue or SMD) as well as in a human eval. They show substantial improvements over existing models on SMD (the more interesting of the datasets) in terms of entity F1--i.e. the number of correctly-generated entities in the response. They also show improvement on bAbI specifically on cases involving OOVs. On the human evaluation, they show improvements in terms of both ""appropriateness"" and ""human-likeness"". \n\nOverall, I think this is a nice and well-motivated model. I very much appreciate the thoroughness of the evaluation (two different datasets, plus a human evaluation). The level of analysis of the model was also good, although there (inevitably) could have been more. Since it is such a complex model, I would have liked to see more thorough ablations or at least better descriptions of the baselines, in order to better understand which specific pieces of the model yield which types of gains. A few particular questions below:\n\n- You describe the auxiliary loss on the global pointer, and mention an ablation study that show that this improves performance. Maybe I am overlooking something, but I cannot find this ablation in the paper or appendix. It would be nice to see how large the effect is. \n- Following on the above, why no similar auxiliary losses on additional components, e.g. the template generation? Were these tried and deemed unnecessary or vice-versa (i.e. the default was no auxiliary loss and they were only added when needed)? Either way, it would be nice to better communicate the experiments/intuitions that motivated the particular architecture you arrived at.\n- I really appreciate that you run a human eval. But why not have humans evaluate objective ""correctness"" as well? It seems trivial to ask people to say whether or not the answer is correct/communicates the same information as the gold.\n']","[60, 50, 70]","[70, 80, 80]","[""The sentiment score is 60 (positive) because the reviewer acknowledges the novelty of the idea and its effectiveness in most cases. The opening paragraphs express a generally positive view of the paper. However, it's not extremely high as there are some critical comments and questions raised. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing their comments as suggestions or questions rather than direct criticisms. The use of phrases like 'Here're some comments' and the inquisitive nature of the points raised contribute to a polite tone. The reviewer also acknowledges the paper's strengths before presenting their questions, which is a courteous approach."", ""The sentiment score is 50 (slightly positive) because the review starts with a positive statement about the paper being 'well-written' and having 'extensive experimentation'. However, this is followed by a long list of questions and suggestions for improvement, which balances out the initial positivity. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, often phrasing criticisms as questions or suggestions (e.g., 'I would like to see', 'If you can please provide', 'I would prefer'). The reviewer also acknowledges the authors' efforts and provides constructive feedback. The high level of detail in the feedback also indicates respect for the authors' work."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as presenting a 'nice and well-motivated model' and appreciates the thoroughness of the evaluation. They mention 'substantial improvements' and positive results from human evaluation. However, it's not 100 as they also express some desires for additional information and analyses. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the work and framing suggestions as questions or areas for potential improvement rather than criticisms. Phrases like 'I very much appreciate' and 'I think this is a nice' contribute to the polite tone. The reviewer maintains a constructive and professional tone while providing feedback.""]"
"['This paper reinvestigate several recent works on network pruning and find that the common belief about the necessity to train a large network before pruning may not hold. The authors find that training the pruned model from scratch can achieve similar, if not better, performance given enough time of training. Based on these observations, the author conclude that training a larger model followed by pruning is not necessary for obtaining an efficient model with similar performance. In other words, the pruned architecture is more important than the weights inherited from the large model. It reminds researchers to perform stronger baselines before showing complex pruning methods. \n\nThe paper is well organized and written. It re-evaluate the recent progresses made on this topic. Instead of comparing approaches by simply using the numbers from previous paper, the authors perform extensive experiments to verify whether training the pruned network from scratch would work. The results are very interesting, it suggests the researchers to tune the baseline “hardly” and stick to simple approach. However, here are some places that I have concerns with:\n\n1. The two “common beliefs” actually state one thing, that is the weights of a pre-trained larger model can potentially help optimization for a smaller model. \n\n2. I don’t quite agree with that “training” is the first step of a pruning pipeline as illustrated in Figure 1.  Actually the motivation or the common assumption for pruning is that there are already existing trained models (training is already finished) with good performance. If a trained model does not even exist, then one can certainly train various thin/smaller model from scratch as before, this is still a trial and error process. \n\n3. “The value of pruning”. The goal of pruning is to explore a “thin” or “shallower” version of it with similar accuracy while avoiding the exhaustive architecture search with heavy training processes. Thus the first value of pruning is to explore efficient architecture while avoiding heavy training. Therefore, it should be fast and efficient, ideally with no retraining or little fine-tuning. When the pruning method is too complex to implement or requires much more time than training from scratch, it could be an overkill and adds little value, especially when the performance is not better enough. Therefore, it is more informative if the authors would report the time/complexities for pruning/fine-tuning .\n\n4. The second value of pruning lies at understand the redundancy of the model and providing insights for more efficient architecture designs. \n\n5. Comparing to random initialization, pruning simply provide an initialization point inherited from the larger network. The essential question the author asked is whether a subset of pre-trained weights can outperform random initialization. This seems to be a common belief in transfer learning, knowledge distillation and the studies on initialization. The authors conclude that the accuracy of an architecture is determined by the architecture itself, but not the initialization. If this is true, training from scratch should have similar (but not better) result as fine-tuning a pruned model.  As the inherited weights can also be viewed as a “random” initialization. Both methods should reach equivalent good solution if they are trained with enough number of epochs. Can this be verified with experiments?\n\n6. The experiments might not be enough to reject the common belief. The experiments only spoke that the pruned architectures can still be easily trained and encounter no difficulties during the optimization. One conjecture is that the pruned models in the previous work still have enough capacity for keeping good accuracy. What if the models are significantly pruned (say more than 70% of channels got pruned), is training from scratch still working well? It would add much value if the author can identify when training from scratch fails to match the performance obtained by pruning and fine-tuning.\n\n7. In Section 4.1, “scratch-trained models achieve at least the same level of accuracy as fine-tuned models”. First, the ResNet-34-pruned A/B for this comparison does not have significant FLOPs reduction (10% and 24% FLOPs reduction). Fine-tuning still has advantage as it only takes ¼ of training time compare to scratch-E. Second, it is interesting that fine-tuning has generally smaller variance than stratch-E (except VGG-19). Would this imply that fine-tuning a pruned model produce more stable result? It would be more complete if there is variance analysis for the imagenet result. \n\n8. What is the training/fine-tuning hyperparameters used in section 4.1?  Note that in the experiment of Li et al, 2017, scratch-E takes 164 epochs to train from scratch, while fine-tuning takes only 40 epochs. Like suggested above, if we fine-tune it with more epochs, would it achieve equivalent performance? Also, what is the hyperparameter used in scratch-E? Note that the original paper use batch size 128. If the authors adopts a smaller batch-size for scratch-E, then it has in more iterations and could certainly result in better performance according to recent belief that small batch-size generates better.\n\n9. The conclusion of section 5 is not quite clear or novel. Using uniform pruning ratio for pruning is expected to perform worse than automatic pruning methods as it does not consider the importance difference of each layer and. This comes back to my point 3 & 4 about the value of pruning, that is the value of pruning lies at the analysis of the redundancy of the network. There are a number of works worked on analyzing the importance of different layers of filters. So I think the “hypothesis” of “the value of automatic pruning methods actually lies in the resulting architecture rather than the inherited weight” is kind of straightforward. Also, why not use FLOPs as x-axis in Figure 3?\n\n\nMinor: It might be more accurate to use “L1-norm based Filter Pruning (Li et al., 2017)” as literally “channels” usually refers to feature maps, which are by-products of the model but not the model itself.\n\nI  will revise my score if authors can address above concerns.\n\n\n--------- review after rebuttal----------\n#1#2 It would be great if the authors can make it clear that training is not the always the first step and the value of pruning in introduction rather than mentioning in conclusion. Saving training time is still an important factor when training from scratch is expensive. \n\n#5 “fine-tuning with enough epochs”. \nI understand that the authors are mainly questioning about whether training from scratch is necessarily bad than pruning and fine-tuning. The author do find that “training from scratch is better when the number of epochs is large enough”. But we see that fine-tuning ResNet-56 A/B with 20 epochs does outperform (or is equivalent to) scratch training for the first 160 epochs, which validates “fine-tuning is faster to converge”.  However, training 320 epochs (16x more comparing to 20 epochs fine-tuning and 2x comparing with normal training from scratch) is not quite coherent with the setting of “scratch B”, as ResNet-56 B just reduce 27% FLOPs. \n\nThe other part of the question is still unclear, i.e., the author claimed that the accuracy of an architecture is determined by the architecture itself, but not the initialization, then both fine-tuning and scratch training should reach equivalent solution if they are well trained enough, regardless of the initialization or pruning method. The learning rate for scratch training is already well known (learning rate drop brings boost the accuracy). However, learning rate schedule for fine-tuning (especially for significantly pruned model as for reply#6) is not well explored. I wonder whether that a carefully tuned learning rate/hyperparameters for fine-tuning may get the same or better performance as scratch training.\n\nQuestions:\n- Are both methods using the same learning rate schedule between epoch 160 and epoch 320?\n- The ResNets-56 A/B results in the reply#8 does not match the reported performance in reply#5. e.g., it shows 92.67(0.09) for ResNet-56-B with 40-epochs fine-tuning in reply5,  but it turns out to be 92.68(±0.19) in reply#8.\n- It would be great if the authors can add convergence curves for fine-tuning and scratch training for easier comparison.\n\n\n#6 The failure case for sparse pruning on ImageNet is interesting and it would be great to have the imageNet result reported and discussed. \n\nThe authors find that “when the pruned ratio is large enough, training from scratch is better by a even larger margin than fine-tuning”.  This could be due to following reasons: \n      1. When the pruning ratio is large, the pruned model with preserved weights is significantly different from the original model, and fine-tuning with small learning rate and limited number of epochs is not enough to recover the accuracy. As mentioned earlier, tuning the hyperparameters for fine-tuning based on pruning ratio might improve the performance of fine-tuning. \n      2. Though the pruning ratio is large, the model used in this experiment may still have large capacity to reach good performance. How about pruning ResNet-56 with significant pruning ratios? \n\nFinally, based on above observations, it seems to me that the preserved weights is more essential for fast fine-tuning but less useful for significant pruning ratios.\n\n-------- update ----------------\n\nThe authors addressed most of my concerns. Some questions are still remaining in my comment “Review after rebuttal”,  specifically, fine-tuning a pruned network may still get good performance if the hyperparameters are carefully tuned based on the pruning ratios, or in other words, the preserved weights is more essential for fast fine-tuning but less useful for significant pruning ratios. The authors may need to carefully made the conclusion from the observations. I would hope the authors can address these concerns in the future version.\n\nHowever, I think the paper is overall well-written and existing content is inspiring enough for readers to further explore the trainability of the pruned network. Therefore I raised my score to 7.\n', 'This paper proposes to investigate recent popular approaches to pruning networks, which have roots in works by Lecun ‘90, and are mostly rooted in a recent series of papers by Song Han (2015-2016). The methods proposed in these papers consist of the following pipeline: (i) train a neural network, (ii) then prune the weights, typically by trimming the those connections corresponding to weights with lowest magnitude, (iii) fine tune the resulting sparsely-connected neural network. \n\nThe authors of the present work assert that traditionally, “each of the three stages is considered as indispensable”. The authors go on to investigate the contribution of each step to the overall pipeline. Among their findings, they report that fine-tuning appears no better than training the resulting pruned network from scratch. The assertion then is that the important aspect of pruning is not that it identifies the “important weights” but rather that it identifies a useful sparse architecture.\n\nOne problem here is that the authors may overstate the extent to which previous papers emphasize the fine-tuning, and they may understate the extent to which previous papers emphasize the learning of the architecture. Re-reading Han 2015, it seems clear enough that  the key point is “learning the connections” (it’s right there in the title) and that the “important weights” are a means to achieve this end. Moreover the authors may miss the actual point of fine-tuning. The chief benefit of fine-tuning is that it is faster than training from scratch at each round of retraining, so that even if it achieves the same performance as training from scratch, that’s still a key benefit.\n\nIn general, when making claims about other people’s beliefs, the authors need to provide citations. References are not just about credit attribution but also about providing evidence and here that evidence is missing. I’d like to see sweeping statements like “This is\nusually reported to be superior to directly training a smaller network from scratch” supported by precise references, perhaps even a quote, to spare the reader some time. \n\nTo this reader, the most interesting finding in the paper by far is surprisingly understated in the abstract and introduction, buried at the end of the paper. Here, the authors investigate what are the properties of the resulting sparse architectures that make them useful. They find that by looking at convolutional kernels from pruned architectures, they can obtain for each connection, a probability that a connection is “kept”. Using these probabilities, they can create new sparse architectures that match the sparsity pattern of the pruned architectures, a technique that they call “guided sparsification”. The method yields similar benefits to pruning. Note that while obtaining the sparsity patterns does require running a pruning algorithm in the first place, ***the learned sparsity patterns generalize well across architectures and datasets***. This result is interesting and useful, and to my knowledge novel. I think the authors should go deeper here, investigating the idea on yet more datasets and architectures (ImageNet would be nice). I also think that this result should be given greater emphasis and raised to the level of a major focal point of the paper. With convincing results and some hard-work to reshape the narrative to support this more important finding, I will consider revising my score. \n', 'This paper shows through a set of experiments that the common belief that a large neural network trained, then pruned and fine-tuned performs better than another network that has the same size of the pruned one, but trained from scratch, is actually false. That is, a pruned network does not perform better than a network with the same dimensions but trained from scratch. Also, the authors consider that what is important for good performance is to know how many weights/filters are needed at each layer, while the actual values of the weights do not matter. Then, what happens in a standard large neural network training can be seen as an architecture search, in which the algorithm learns what is the right amount of weights for each layer. \n\nPros:\n- If these results are generally true, then, most of the pruning techniques are not really needed. This is an important result.\n- If these results hold, there is no need for training larger models and prune them. Best results can be obtained by training from scratch the right architecture.\n- the intuition that the neural network pruning is actually performing architecture search is quite interesting.\n\nCons:\n- It is still difficult to believe that most of the previous work and previous experiments (as in Zhu & Gupta 2018) are faulty.\n- Another paper with opposing results is [1]. There the authors have an explicit control experiment in which they evaluate the training of a pruned network with random initialization and obtain worse performance than when pruned and pruned and retrained with the correct initialization.\n- Soft pruning techniques as [2] obtain even better results than the original network. These approaches are not considered in the analysis. For instance, in their tab. 1, ResNet-56 pruned 30% obtained a gain of 0.19% while your ResNet-50 pruned 30% obtains a loss of 4.56 from tab. 2. This is a significant difference in performance.\n\nGlobal evaluation:\nIn general, the paper is well written and give good insides about pruning techniques. However, considering the vast literature that contradicts this paper results, it is not easy to understand which results to believe. It would be useful to see if the authors can obtain good results without pruning also on the control experiment in [1]. Finally, it seems that the proposed method is worse than soft pruning. In soft pruning, we do not gain in training speed, but if the main objective is performance, it is a very relevant result and makes the claims of the paper weaker.\n\nAdditional comments:\n- top pag.4: ""in practice, we found that increasing the training epochs within a reasonable range is rarely harmful"". If you use early stopping results should not be affected by the number of training epochs (if trained until convergence).\n\n[1] The Lottery Ticket Hypothesis: Finding Small, Trainable Neural Networks, Jonathan Frankle, Michael Carbin, arXiv2018\n[2] Soft Filter Pruning for Accelerating Deep Convolutional Neural Networks, Yang He, Guoliang Kang, Xuanyi Dong, Yanwei Fu, Yi Yang, arXiv 2018\n']","[60, -20, -20]","[70, 50, 60]","[""The sentiment score is 60 (moderately positive) because the reviewer states the paper is 'well organized and written' and finds the results 'very interesting', while also providing several constructive criticisms and suggestions for improvement. The overall tone is supportive of the research while pushing for more rigorous analysis. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, phrases criticisms as 'concerns' or suggestions, and offers to revise their score if the authors address the points raised. The reviewer also acknowledges the value of the work while providing detailed feedback for improvement, which is a polite approach to peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting findings, they also point out several issues with the paper. The reviewer criticizes the authors for overstating claims, understating previous work, and burying what they consider the most interesting finding. However, the reviewer does offer constructive feedback and expresses willingness to reconsider their score if improvements are made.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'To this reader' and 'I'd like to see' which soften their criticisms. The reviewer also offers specific suggestions for improvement and expresses openness to revising their score, which is courteous. However, the review is not overly effusive or excessively polite, maintaining a balanced and objective tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the paper, they express significant doubts about the results and point out several cons. The reviewer states it's 'difficult to believe' the paper's findings contradict most previous work, and mentions other studies with opposing results. They also suggest the proposed method is worse than soft pruning techniques. However, the score isn't deeply negative because the reviewer does recognize some positive aspects and potential importance of the work.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'well written' and 'good insides', and frame their criticisms as suggestions or questions rather than direct attacks. The reviewer also balances negative points with positive ones, showing a fair approach. However, it's not extremely high as the language, while polite, is still direct in its criticisms and doesn't go out of its way to be overly courteous.""]"
"[""This paper proposes a method to synthesize speech from text input, with the style of an input voice provided with the text. Thus, we provide content - text - and style - voice. It leverages recent - phenomenal - progress in TTS with Deep Neural Networks as seen from exemplar works such as Tacotron (and derivatives), DeepVoice, which use seq2seq RNNs and Wavenet families of models. The work is extremely relevant in that audio data is hard to generate (expensive) and content-style modeling could be useful in a number of practical areas in synthetic voice generation. It is also quite applicable in the related problem of voice conversion. The work also uses some quite complex - (and very interesting!) - proposals to abstract style, and paste with content using generative modeling. I am VERY excited by this effort in that it puts together a number of sophisticated pieces together, in what I think is a very sensible way to implement a solution to this very difficult problem. However, I would like clarifications and explanations, especially in regards to the architecture.  \n\nDescription of problem: The paper proposes a fairly elaborate setup to inject voice style (speech) into text. At train time it takes in text samples $x_{txt}$, paired voice samples (utterances that have $x_{txt}$ as content) $s+$ and unpaired voice samples $s-$, and produces two voice samples $x+$ (for paired  <txt, utterance>) and $x-$ (for unpaired txt/utterance). The idea is that at test time, we pass in a text sample $x_{txt}$ and an UNPAIRED voice sample $x_{aud}$ and the setup produces voice in the style of $x_{aud}$ but whose content is $x_{txt}$, in other words it generates synthetic speech saying $x_{txt}$. The paper goes on to show performance metrics based on an autoencoder loss, WER and t-SNE embeddings for various attributes. \n\nContext:  The setup seems to be built upon the earlier work by Taigman et al (2016) which has the extremely interesting conception of using a {\\it ternary} discriminator loss to carry out domain adaptation between images. This previous work was prior to the seminal CycleGAN work for image translation, which many speech works have since used. Interestingly, the Taigman work also hints at a 'common' latent representation a la UNIT using coupled VAE-GANs with cycle consistency (also extremely pertinent), but done differently. In addition to the GAN framework by Taigman et al, since this work is built upon Tacotron and the GST (Global Style Tokens) work that followed it, the generative setup is a sophisticated recurrent attention based seq2seq model.\n\nFormulation:\nA conditional formulation is used wherein the content c (encoding generated by text) is passed along with other inputs in the generator and discriminator. The formulation in Taigman assumes that there is an invariant representation in both (image) domains with shared features. To this, style embeddings (audio) gets added on and then gets passed into the generator to generate the speech. Both c and s seem to be encoder outputs in the formulation. The loss components of what they call ‘adversarial’, ‘collaborative’ and ‘style’ losses. \n\nAdversarial losses\nThe ternary loss for D consists of \n\nDiscriminator output from ‘paired’ style embedding (i.e. text matching the content of paired audio sample)\nDiscriminator output from ‘unpaired’ style embedding (i.e text paired with random sample of some style)\nDiscriminator output from target ground truth style. The paper uses x_+, so I would think that it uses the paired sample (i.e. from the source) style.\n\nGenerator loss (also analogous to Taigman et al) consists of generations from paired and unpaired audio, possibly a loose analogue to source and target domains, although in this case we can’t as such think of ‘+’ as the source domain, since the input is text. \n\nCollaborative losses \nThis has two components, one for style (Gatys et al 2016) and a reconstruction component. The reconstruction component again has two terms, one to reconstruct the paired audio output ‘x+=x_audio+’ - so that the input content is reproduced -  and the other to encourage reconstruction of the latent code. \n\nDatasets and Results:\nThey use two datasets: one, an internal ‘EMT-4’ dataset with 20k+ English speakers, and the other, the VCTK corpus. Comparisons are made with a few good baselines in Tacotron2, GST and DeepVoice2. \n\nOne comparison technique to test disentanglement ability is to compare autoencoder reconstructions with the idea that a setup that has learnt to disentangle would produce higher reconstruction error because it has learnt to separate style and content. \n\nt-SNE embeddings are presented to show visualizations of various emotion styles (neutral, angry, sad and happy), and separation of male and female voices. A WER metric is also presented so that generations are passed into a classifier (an ASR system trained on Wavenet). All the metrics above seem to compare excellently (better than?) with the others. \n\nQuestions and clarifications:\n\n(Minor) There’s a typo in page 2, line 2. x_{aud}^+ should be x_{aud}^-.\n\nClarification on formulation: Making the analogy (is that even the right way of looking at this?) that the ‘source’ domain is ‘+’, and the target domain is ‘-’, in equation (5), the last term of the ternary discriminator has the source domain (x_{aud}^+) in it, while the Taigman et al paper uses the target term. Does this matter? I would think ‘no’, because we have a large number of terms here and each individual term in and of itself might not be relevant, nor is the current work a direct translation of the Taigman et al work. Nevertheless, I would like clarification, if possible, on the discrepancy and why we use the ‘+’ samples. \n\nClarification on reconstruction loss: I think the way it is presented, equation (8) is misleading. Apparently, we are sampling from the latent space of style and content embeddings for paired data. The notation seems to be quite consistent with that of the VAE, where we have a reconstruction and a recognition model, and in effect the equation (8) is sampling from the latent space in a stochastic way. However, as far as I can see, the latent space here produces deterministic embeddings, in that c = f(x_{txt}) and s = g(x_{aud}^+), with the distribution itself being a delta function. Also, the notation q used in this equation most definitely indicates a variational distribution, which I would think is misleading (unless I have misinterpreted what the style tokens mean). At any rate, it would help to show how the style token is computed and why it is not deterministic. \n\nClarification on latent reconstruction loss: In equation (9), how is the latent representation ‘l’ computed? While I can intuitively see that the latent space ‘l’ (or z, in more common notation) would be the ‘same’ between real audio samples and the ‘+’, ‘-’ fake samples, it seems to me that they would be related to s (as the paper says, ‘C’ and ‘Enc_s’ share all conv layers) and the text. But what, in physical terms is it producing? Is it like the shared latent space in the UNIT work, or the invariant representation in Taigman? This could be made clearer with an block diagram for the architecture. \n\n(Major) Clarification on network architecture\nThe work references Tacotron’s GST work (Wang et al 2018) and the related Skerry-Ryan work as the stem architecture with separate networks for style embeddings and for content (text). While the architecture itself might be available in the stem work by Wang et al, I think we need some diagrams for the current work as well for a high level picture. Although it is mentioned in words in section 3.3, I do not get a clear idea of what the encoder/decoder architectures look like. I was also surprised in not seeing attention plots which are ubiquitous in this kind of work. Furthermore, in the notes to the ‘inference’ network ‘C’ it is stated that C and Enc_s share all conv layers. Again, a diagram might be helpful - this also applies for the discriminator. \n\nClarification on stability/mode collapse: Could the authors clarify how easily this setup trained in this adversarial setup? \n\nNote on latent representation: To put the above points in perspective, a small note on what this architecture does in regards to the meaning of the latent codes would be useful. The Taigman et al 2016 paper talks about the f-constancy condition (and 'invariance'). Likewise, in the UNIT paper by Ming-Yu Liu - which is basically a set of coupled VAEs + cycle consistency losses, there is the notion of a shared latent space. A little discussion on these aspects would make the paper much more insightful to the domain adaptation practitioner.\n\nReference: This reference - Adversarial feature matching for text generation - (https://arxiv.org/abs/1706.03850) contains a reconstruction stream (as perhaps many other papers) and might be useful for instruction. \n\nOther relevant works in speech and voice conversion: This work comes to mind, using the StarGAN setup, also containing a survey of relevant approach in voice conversion. Although the current work is for TTS, I think it would be useful to include speech papers carrying out domain adaptation for other tasks.\n\nStarGAN-VC: Non-parallel many-to-many voice conversion with star generative adversarial networks. \nhttps://arxiv.org/abs/1806.02169 \n\nI would rate this paper as being acceptable if the authors clarify my concerns, and in particular, about the architecture. It is also hard to hard to assess reproducibility in a complex architecture such as this. "", 'This paper proposes to use a generative adversarial network to model speaking style in end-to-end TTS. The paper shows the effectiveness of the proposed method compared with Takotron2 and other variants of end-to-end TTS with intensive experimental verifications. The proposed method of using adversarial and collaborative games is also quite unique. The experimental part of the paper is well written, but the formulation part is difficult to follow. Also, the method seems to be very complicated, and I’m concerning about the reproducibility of the method only with the description in Section 3.\n\nComments\n- Page 2, line 2: x _{aud} ^{+} -> x _{aud} ^{-} (?)\n- Section 2: $T$ is used for audio and the number of words.\n', 'Overview: This paper describes an approach to style transfer in end-to-end speech synthesis by extending the reconstruction loss function and augmenting with an adversarial component and style based loss component.\n\nSummary: This paper describes an interesting technical approach and the results show incremental improvement to matching a reference style in end-to-end speech synthesis.  The three-component adversarial loss is novel to this task.  While it has technical merit, the presentation of this paper make it unready for publication.  The technical descriptions are difficult to follow in places, it makes some incorrect statements about speech and speech synthesis and its evaluation is lacking in a number of ways.   After a substantial revision and additional evaluation, this will be a very good paper.\n\nThe title of the paper and moniker of this approach as “TTS-GAN” seems to preclude the fact that in the last few years there have been a number of approaches to speech synthesis using GANs.  By using such a generic term, it implies that this is the “standard” way of using a GAN for TTS.  Clearly it is not. Moreover, other than the use of the term, the authors do not claim that it is. \n\nWhile the related works regarding style modeling and transfer in end-to-end TTS models are well described, prior work on using GANs in TTS is not.  (This may or may not be related to the previous point.)  For example, but not limited to:\nYang Shan, Xie Lei, Chen Xiao, Lou Xiaoyan, Zhu Xuan, Huang Dongyan, and Li Haizhou, Statistical Parametric Speech Synthesis Using Generative Adversarial Networks Under a Multi-task Learning Framework, ASRU, 2017\nYuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, Text-to-speech Synthesis using STFT Spectra Based on Low- /multi-resolution Generative Adversarial Networks, ICASSP 2018\nSaito Yuki, Takamichi Shinnosuke, and Saruwatari Hiroshi, Training Algorithm to Deceive Anti-spoofing Verification for DNN-based Speech Synthesis, ICASSP, 2017.\n\nSection 2 describes speech synthesis as a cross-domain mapping problem F : S -> T, where S is text and T is speech. (Why a text-to-speech mapping is formalized as S->T is an irrelevant mystery.)  This is a reasonable formulation, however, this is not a bijective mapping.  There are many valid realizations s \\subset T of a text utterance t \\in S.  The true mapping F is one-to-many.    Contrary to the statement in Section 2, there should not be a one-to-one correspondence between input conditions and the output audio waveform and this should not be assumed.  This formalism can be posed as a simplification of the speech synthesis mapping problem.  Overall Section 2 lays an incorrect and unnecessary formalism over the problem, and does very little in terms of “background” information regarding speech synthesis or GANs.  I would recommend distilling the latter half of the last paragraph.  This content is important -- the goal of this paper is to disentangle the style component (s) from the “everything else” component (z)  in x_{aud} by which the resultant model can be correctly conditioned on s and ignore z.\n\nSection 3.2 Style Loss: The parallel between artistic style in vision and speaking style in speech is misplaced.  Artistic style can be captured by local information by representing color choices, brush technique, etc.  Speaking style and prosodic variation more broadly is suprasegmental.  That is it spans multiple speech segments (typically defined as phonetic units, phonemes, etc.).  It is specifically not captured in local variations in the time-frequency domain.  The local statistics of a mel-spectrogram are empoverished to capture the long term variation spanning multiple syllables, words, and phrases that contribute to “speaking style”.  (In addition to the poor motivation of using low-level filters to capture speaking style, the authors describe “prosody” as “representing the low-level characteristics of sound”. This is not correct.)  These filter activations are more likely to capture voice quality and speaker identity characteristics than prosody and speaking style.\n\nSection 3.2: Reconstruction Loss: The training in this section is difficult to follow.  Presumably, l is the explicit style label from the data, the emotion label for EMT-4 and (maybe) speaker id for VCTK.  It is a rather confusing choice to refer to this as “latent” since this carries a number of implications from variational techniques and bayesian inference.  Similarly, It is not clear how these are trained. Specifically, both terms are minimized w.r.t. C but the second is minimized only w.r.t G.  I would recommend that this section be rewritten to describe both the loss functions, target variables, and the dependent variables that are optimized during training.\n\nSection 3.3 How are the coefficients \\alpha and \\beta determined?\n\nSection 3.3 “We train TTS-GAN for at least 200k steps.” Why be vague about the training?\n\nSection 3.3. “During training R is fixed weights” Where do these weights come from? Is it an ImageNet classifier similar with a smaller network than VGG-19?\n\nSection 5: The presentation of results into Table 1 and Table 2 is quite odd.  The text material references Table 1 in Section 5.1, then Table 2 in Section 5.2, then Table 1 in Section 5.3 and then Table 2 again in Section 5.3.  It would be preferable to include the tabular material which is being discussed in the same order as the text.\n\nSection 5: Evaluation.  It is surprising that there is no MOS or naturalness evaluation of this work.  In general increased flexibility of a style-enabled system results in decreased naturalness.  While there are WER results to show that intelligibility (at least machine intelligibility) may not suffer, the lack of an MOS result to describe TTS quality is surprising.\n\nSection 5: The captions of Tables 1 and 2 should provide appropriate context for the contained data.  There is not enough information to understand what is described here without reference to the associated text.\n\nSection 5.1: The content and style swapping is not evaluated.  While samples are provided, it is not at all clear that the claims made by the authors are supported by the data.  A listening study where subjects are asked to identify the intended emotion of the utterance would be a convincing way to demonstrate the effectiveness of this technique.  As it stands, I would recommend removing the section titled “Content and style swapping” as it is unempirical.  If the authors are committed to it, it could be reasonably moved to the conclusions or discussion section as anecdotal evidence.\n\nSection 5.3: Why use a pre-trained WaveNet based ASR model?  What is its performance on the ground truth audio?  This is a valuable baseline for the WER of the synthesized material.\n\nSection 5.3 Style Transfer: Without support that the subject ratings in this test follow a normal distribution a t-test is not a valid test to use here.  A non-parametric test like a Mann-Whitney U test would be more appropriate.\n\nSection 5.3 Style Transfer: “Each listened to all 15 permutations of content”.  From the previous paragraph there should be 60 permutations.\n\nSection 5.3 Style Transfer: Was there any difference in the results from the 10 sentences from the test set, and the 5 drawn from the web?\n\nTypos:\nSection 1 Introduction: “x_{aud}^{+} is unpaired” -> “x_{aud}^{-} is unpaired”\nSection 2: “Here, We” -> “Here, we”\nSection 5.3 “Tachotron” -> “Tacotron”', 'This paper proposes to use GAN to disentangle style information from speech content. The presentation of the core idea is clear but IMO there are some key missing details and experiments.\n\n* The paper mentions \'....the model could simply learn to copy the waveform information from xaud to the output and ignore s....\' \n--  Did you verify this is indeed the case? 1) The style embedding in Skerry-Ryan et al.\'18 serves as a single bottleneck layer, which could prevent information leaking. What dimension did you use, and did you try to use smaller size? 2) The GST layer in Wang et al.\'18 is an even more aggressive bottleneck layer, which could (almost) eliminate style info entangled with content info. \n\n* The sampling process to get x_{aud}^{-} needs more careful justifications/ablations.\n-- Is random sampling enough? What if the model samples a x_{aud}^{-} that has the same speaking style as x_{aud}^{+}? (which could be a common case).\n\n* Did you consider the idea in Fader Netowrks (Lample et al.\'17)\', which corresponds to adding a simple adversarial loss on the style embedding? It occurs to be a much simpler alternative to the proposed method.\n\n* Table 1. ""Tacotron2"" is often referred to Shen et al.\'18, not Skerry-Ryan et al.\'18. Consider using something like ""Prosody-Tacotron""?\n\n* The paramerters used for comparisons with other models are not clear. Some of them are important detail (see the first point above)\n\n* The author mentioned the distance between different clusters in the t-SNE plot. Note that the distance in t-SNE visualizations typically doesn\'t indicate anything.\n\n* \'TTS-GAN\' is too general as the name for the proposed method.']","[60, 50, -30, -20]","[80, 70, 50, 50]","[""The sentiment score is 60 (positive) because the reviewer expresses excitement about the work ('I am VERY excited by this effort') and praises its relevance and sophistication. However, they also have several questions and requests for clarification, which tempers the overall positivity. The politeness score is 80 (quite polite) due to the respectful tone throughout, use of phrases like 'Could the authors clarify' and 'I would like clarifications', and the constructive nature of the feedback. The reviewer balances praise with specific, detailed suggestions for improvement, maintaining a professional and courteous tone throughout."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the effectiveness and uniqueness of the proposed method, and praises the experimental part as well-written. However, they also express concerns about the formulation being difficult to follow and the method's complexity affecting reproducibility. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'The paper shows the effectiveness' and 'The experimental part of the paper is well written,' which are positive and polite. Even when expressing concerns, the reviewer maintains a professional tone, saying 'I'm concerning about' rather than using more critical language. The reviewer also provides specific, helpful comments for improvement, which is a polite way to offer feedback."", ""The sentiment score is -30 because while the reviewer acknowledges the paper's technical merit and potential ('After a substantial revision and additional evaluation, this will be a very good paper'), they also point out numerous issues and state the paper is 'unready for publication'. The overall tone is critical but constructive. The politeness score is 50 because the reviewer uses professional and respectful language throughout, offering specific suggestions for improvement rather than harsh criticism. They balance negative feedback with positive comments ('This paper describes an interesting technical approach'). The reviewer maintains a formal and objective tone, avoiding personal attacks or overly emotional language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the core idea is clear, they point out several missing details and experiments, and raise multiple questions and concerns about the methodology. This suggests a somewhat critical stance, though not overwhelmingly negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions (e.g., 'Did you consider...', 'Consider using...'), and uses polite hedging phrases like 'IMO'. The reviewer also provides constructive feedback and specific recommendations for improvement, which is a polite approach to peer review.""]"
"['The authors propose in this paper a series of results on the approximation capabilities of neural networks based on ReLU using quantized weights. Results include upper bounds on the depth and on the number of weights needed to reach a certain approximation level given the number of distinct weights usable. The paper is clear and as far as I know the results are both new and significant. My only negative remark is about the appendix that could be clearer. In particular, I think that figure 2 obscures the proof of Proposition 1 rather than the contrary. I think it might be much clearer to give an explicit neural network approximation of x^2 for say r=2, for instance.', 'The paper deals with the expressibility of quantized neural network, meaning where all weights come from a finite and small sized set. It proves that functions satisfying standard assumptions can be represented by quantized ReLU networks with certain size bounds, which are comparable to the bounds available in prior literature for general ReLU networks, with an overhead that depends on the level of quantization and on the target error.\n\nThe proofs generally go by simulating non-quantized ReLU networks with quantized ones, by means of replacing their basic operations with small quantized networks (""sub-networks"") that simulate those same operations with a small error. Then the upper bounds follow from known results on function approximation with (non-quantized) ReLU networks, with the overhead incurred by introducing the sub-networks.\nNotably, this approach means that the topology of the network changes. As such it not compatible with quantizing the weights of a given network structure, which is the more common scenario, but rather with choosing the network structure under a given level of quantization. This issue is discussed directly and clearly in the paper.\n\nOverall, while the paper is technically quite simple, it forms an interesting study and blends well into recent literature on an important topic. It is also well written and clear to follow.', 'This paper studies the expressive power of quantized ReLU networks from a theoretical point of view. This is well-motivated by the recent success of using quantized neural networks as a compression technique. This paper considers both linear quantization and non-linear quantization, both function independent network structures and function dependent network structures. The obtained results show that the number of weights need by a quantized network is no more than polylog factors times that of a unquantized network. This justifies the use of quantized neural networks as a compression technique. \n\nOverall, this paper is well-written and sheds light on a well-motivated problem, makes important progress in understanding the full power of quantized neural networks as a compression technique. I didn’t check all details of the proof, but the structure of the proof and several key constructions seem correct to me. I would recommend acceptance. \n\nThe presentation can be improved by having a formal definition of linear quantized networks and non-linear quantized networks, function-independent structure and function-dependent structure in Section 3 to make the discussion mathematically rigorous. Also, some of the ideas/constructions seem to follow (Yarotsky, 2017). It seems to be a good idea to have a paragraph in the introduction to have a more detailed comparison with (Yarotsky, 2017), highlighting the difference of the constructions, the difficulties that the authors overcame when deriving the bounds, etc. \n\nMinor Comment: First paragraph of page 2: extra space after ``to prove the universal approximability’’.\n']","[80, 80, 80]","[60, 70, 70]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'clear' and the results as 'new and significant'. The only negative comment is about the appendix, which is a minor issue. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the authors' work positively. The criticism is presented constructively, suggesting improvements rather than just pointing out flaws. The reviewer also uses phrases like 'as far as I know' which shows humility. However, the review doesn't go out of its way to be excessively polite, maintaining a professional tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They describe it as 'an interesting study' that 'blends well into recent literature on an important topic.' The reviewer also praises the paper as 'well written and clear to follow.' While they note that it is 'technically quite simple,' this is not presented as a significant criticism. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They acknowledge the paper's strengths and provide constructive feedback without using harsh or critical language. The reviewer also directly addresses the authors' approach to the topic, showing engagement with the material. The tone is consistently professional and courteous, though not excessively formal or deferential, hence the score of 70 rather than higher."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, stating it is 'well-written', 'sheds light on a well-motivated problem', and 'makes important progress'. The reviewer also recommends acceptance. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames suggestions as improvements rather than criticisms. The reviewer acknowledges the authors' work positively and provides specific, helpful recommendations for enhancing the paper. The slightly lower politeness score compared to sentiment is due to the directness of some comments, though they remain professionally phrased.""]"
"['The English, grammar and writing style is very good, as are the citations.\nThe technical quality appears to me to be very good (I am not an expert in Poincare spaces).\nThe authors demonstrate a good knowledge of the mathematical theory with the constructions made in Section 6.\nThe experimental write-up has been abbreviated.  The lexical entailment results Tables 6 and 7 are just sitting there without discussion, as far as I can see, as are the qualitative results Tables 4 and 5.   The entailment results are quite complex and really need supporting interpretation.  For instance, for Hyperlex, WN-Poincare is 0.512, above yours.\nFor your entailment score you say ""For simplicity, we propose dropping the dependence in μ"".  This needs more justification and discussion as it is counter-intuitive for those not expert in  Poincare spaces.\nSection 6.2 presents the entailment score.  Note Nickel etal. give us a nice single formula.  You however, provide 4 paragraphs of construction from which an astute reader would then have to work on to extract your actual method.  I would prefer to see a summary algorithm given somewhere.  Perhaps you need another appendix.\nRADAGRAD is discussed in Section 5, but I\'d have preferred to see it discussed again in Section 8 and discussed to highlight what was indded done and the differences.  It certainly makes the paper non-reproducible.\nA significant part of the theory in earlier sections is about the 50x2D method, but in experiments this doesn\'t seem to work as well.  Can you justify this some other how:  its much faster, its more interpretable?  Otherwise, I\'m left thinking, why not delete this stuff?\nThe paper justifies its method with a substantial and winning comparison against vanilla GloVe.  That by itself is a substantial contribution.\nBut now, one is then hit with a raft of questions.  Embedding methods are popping up like daisies all over the fields of academia.  Indeed, word similarity and lexical entailment tasks themselves are proliferating too.  To me, its really unclear what one needs to achieve in the empirical section of a paper.  To make it worse, some folks use 500D, some 100D, some 50D, so results aren\'t always comparible.  Demonstrating one\'s work is state-of-the-art against all comers is a massive implementation effort.  I notice some papers now just compare against one other (e.g., Klami etal. ECML-PKDD, 2018).\n\nMy overall feeling is that this paper tries to compress too much into a small space (8 pages).\nI think it really needs to be longer to present what is shown.   Moreover, I would want to see the inclusion of the work on 50x2D justified. So my criticisms are about the way the paper is written, not about the quality of the work.  \nMoroever, though, one needs to consider comparisons against models other than GloVe.\n\nAddendum:  You know, what I really love about ICLR is the effort authors make to refresh their paper and respond to reviewers.  You guys did a great job.  Really impressed.  50x2D now clarified and some of the hasty/unexplained bits fixed.', 'This paper adapts the Glove word embedding (Pennington et al 2014) to a hyperbolic space given by the Poincare half-plane model.  The embedding objective function is given by equation (3), where h=cosh^2 so that it corresponds to a hyperbolic geometry. The author(s) showed that their hyperbolic version of Glove is better than the original Glove. Besides that,  based on (Costa et al 2015), the author provided theoretical insights on the connection between hyperbolic embeddings with Gaussian word embeddings. Besides, the author(s) proposed a measure called ""delta-hyperbolicity"", that is based on (Gromov 1987) to study the model selection problem of using hyperbolic embeddings vs. traditional Euclidean embeddings.\n\nOverall, I find the contributions are interesting but incremental. Therefore it may not be significant enough to be published in ICLR. Moreover, the experimental evaluation is insufficient to show the advantages of the proposed Poincare Glove model.\n\nAn interesting theoretical insight is that there exists an isometry between the Fisher-geodesic distance of diagonal Gaussians and a product of Poincare half-planes. This is interesting as it revealed a connection between hyperbolic embeddings with Gaussian embeddings, which is not widely known. However, this is not an original contribution. This connection is not related to the optimization of the proposed embedding, as Gaussian word embeddings are optimized based on KL divergence etc. that are easy to compute.\n\nThe computation of analogy based on isometric transformations is interesting but straightforward by applying translation operations in the Poincare ball. The novel contribution is minor and mainly on related empirical results.\n\nThe definition of the delta-hyperbolicity is missing. The explicit form of the definition should be clearly given in section 7. Again, this is not a novel contribution but an application of previous definitions (Gromov 1987).\n\nIn the word similarity and analogy experiments, the baseline is the vanilla Glove, this is not sufficient as it is widely known that hyperbolic embeddings can improve over Euclidean embeddings on certain datasets. The authors are therefore suggested to include another hyperbolic word embedding (e.g. Nickel and Kiela 2017) into the baselines and discuss the advantages and disadvantages of the proposed method.\n\nThere are no novel and well-abstracted theoretical results (theorems) given in the submission.\n\nThe length of the paper is longer than the recommended length (9 pages of main text).', 'Summary: \nWords have implicit hierarchy among themselves in a text. Hyperbolic geometry due to the negative curvature and the delta-hyperbolicity is more suitable for representing hierarchical data in the continuous space. As a result it is natural to learn word representations/embeddings in the hyperbolic space. This paper proposes a promising approach that extends the approach presented in [1] to implement a GLOVE based hyperbolic word embedding model. The embeddings are optimized by using the Riemannian Optimization methods presented in [2]. Authors provide results on word-similarity and word-analogy tasks.\n\n\nQuestions: \nWhat are the reasons for choosing a Poincare Ball model of the hyperbolic space instead of hyperboloid or other models of the hyperbolic space?\nCan you expand on the role of gyr[.,.] in Equations 6 and 7.\nBesides the tasks that are presented in this paper including word-analogy and the word-similarity tasks. Have you considered using the embeddings learned in hyperbolic space in a down-stream task such as NLI? \n\nPros:\nThe paper is very well-written, the motivation and the goals are quite clear.\nThe relationship between the Gaussian embeddings and the product spaces is interesting and neat. The paper is theoretically strong and consistent.\nThe idea of learning word-embeddings in hyperbolic space with the proposed approach is novel and relevant.\n\nCons:\n\nThe weakest point of this paper is the experiments. Unfortunately the results reported are underwhelming on WBLESS and the Hyperlex tasks compared to other published results. The paper presents convincing results on Word-analogy and Word-similarity tasks. However they do not compare against the published results on those tasks.\n\n[1] Ganea, O. E., Bécigneul, G., & Hofmann, T. (2018). Hyperbolic Neural Networks. arXiv preprint arXiv:1805.09112.\n[2] Bécigneul, Gary, and Octavian-Eugen Ganea. ""Riemannian Adaptive Optimization Methods."" arXiv preprint arXiv:1810.00760 (2018).']","[50, -30, 50]","[75, 20, 80]","[""The sentiment score is 50 (moderately positive) because the reviewer expresses appreciation for the technical quality, knowledge demonstration, and significant contribution of the paper. However, they also point out several areas for improvement, creating a balanced view. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms constructively. They even express admiration for the authors' response to feedback in the addendum. The reviewer maintains a professional tone while providing detailed feedback, balancing praise with suggestions for improvement."", ""The sentiment score is -30 because the reviewer finds the contributions 'interesting but incremental' and states that the paper 'may not be significant enough to be published in ICLR'. They also mention that the 'experimental evaluation is insufficient'. These criticisms outweigh the positive aspects mentioned, resulting in a slightly negative sentiment. The politeness score is 20 because the reviewer uses polite and professional language throughout, acknowledging the interesting aspects of the work while providing constructive criticism. They use phrases like 'I find' and 'The authors are therefore suggested' which maintain a respectful tone. However, the criticism is direct and not overly softened, keeping the score only moderately positive."", ""The sentiment score is 50 (moderately positive) because the reviewer begins with a neutral summary of the paper's content, followed by a balanced mix of pros and cons. They praise the paper as 'well-written' and 'theoretically strong', but also point out that the experimental results are 'underwhelming' in some aspects. The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. They ask questions to encourage further explanation rather than making blunt criticisms. The use of phrases like 'promising approach' and 'novel and relevant' contribute to the polite tone, even when discussing limitations.""]"
"['# 1. Summary\nThis paper presents a model for future video prediction, which integrates 3D convolutions into RNNs. The internal operations of the RNN are modified by adding historical records controlled via a gate-controlled self-attention module. The authors show that the model is effective also for other tasks such as early activity recognition.\n\nStrengths:\n* Nice extensive experimentation on video prediction and early activity recognition tasks and comparison with recent papers\n* Each choice in the model definition are motivated, although some clarity is still missing (see below)\n\nWeaknesses:\n* Novelty: the proposed model is a small extension of a previous work (Wang et al., 2017) \n\n\n# 2. Clarity and Motivation\nIn general, the paper is clear and general motivation makes sense, however some points need to be improved with further discussion and motivation:\n\nA) Page 2 “Unlike the conventional memory transition function, it learns the size of temporal interactions. For longer sequences, this allows attending to distant states containing salient information”: This is not obvious. Can the authors add more details and motivate these two sentences? How is long-term relations are learned given Eq. 1? \nB) Page 5 “These two terms are respectively designed for short-term and long-term video modeling”: How do you make sure that Recall(.) does not focus on the short-term modeling instead? Not clear why this should model long-term relations.\nC) Page 5 and Eq 1: motivation why layer norm is required when defining C_t^k is not clear\nD) What if the Recall is instead modeled as attention? The idea is to consider only C_{1:t-1}^k (not consider R_t) and have an attentional model that learn what to recall based only on C. Also, why does Recall need to depend on R_t?\nE) Page 5 “to minimize the l1 + l2 loss over every pixel in the frame”: this sentence is not clear. How does it relate to Eq. 2?\n\n\n# 3. Novelty\nNovelty is the major concern of this paper. Although the introduced new concepts and ideas are interesting, the work seems to be an extension of ST-LSTM and PredRNN where Eq 1 is slightly modified by introducing Recall. \nIn addition the existing relation between the proposed model and ST-LSTM is not clearly state. Page 2, first paragraph: here the authors should state that model is and extension of ST-LSTM and highlight what are the difference and advantage of the new model.\n\n\n# 4. Significance of the work\nThis paper deals with an interesting and challenging topic (video prediction) as well as it shows some results on the early activity recognition task. These are definitively nice problem which are far to be solved. From the application perspective this work is significant, however from the methodological perspective it lacks a bit of significance because of the novelty issues highlighted above.\n\n\n# 5. Experimentation\nThe experiments are robust with nice comparisons with recent methods and ablation study motivating the different components of the model (Table 1 and 2). Some suggested improvements:\n\nA) Page 7 “Seq 1 and Seq 2 are completely irrelevant, and ahead of them, another sub-sequence called prior context is given as the input, which is exactly the same as Seq 2”: The COPY task is a bit unclear and need to be better explained. Why are Seq. 1 and 2 irrelevant? I would suggest to rephrase this part.\nB) Sec. 4.2, “Dataset and setup”: which architecture has been used here?\nC) Sec. 4.3, “Hyper-parameters and Baselines“: the something-something dataset is more realising that the other two “toy” dataset. Why did the authors choose to train a 2 layers 3D-CNN encoders, instead of using existing pretrained 3D CNNs? I would suspect that the results can improve quite a bit.\n\n\n# 6. Others\n* The term “self-supervised auxiliary learning” is introduced in the abstract, but at this point it’s meaning is not clear. I’d suggest to either remove it or explain its meaning.\n* Figure 1(a): inconsistent notation with 2b. Also add citation (Wang et al., 2017) since it ie the same model of that paper\n\n-------\n# Post-discussion\nI increased my rating: even if novelty is not high, the results support the incremental ideas proposed by the authors.\n', ""The paper proposes a spatiotemporal modeling of videos based on two currently available spatiotemporal modeling paradigms: RNNs and 3D convolutions. The main idea of this paper is to get the best world of both in a unified way. The method first encodes a sequence of frames using 3D-conv to capture short-term motion patterns, passes it to a specific type of LSTM (E3D-LSTM) which accepts spatiotemporal feature maps as input. E3D-LSTM captures long-term dependencies using an attention mechanism. Finally, there are 3D-conv based decoders which receive the output of E3D-LSTM and generate future frames. The message of the paper, I believe, is that 3D-conv and RNNs can be integrated to perform short and long predictions. They show in the experiments how the model can remember far past for reasoning and prediction.\nThe nice point of the method is that it is heavily investigated through experiments. It's evaluated on two datasets, with ablation studies on both. Moreover, the paper is well-written and clear. technically, the paper seems correct.\nHowever, my only big concern is about the limited novelty of the method. E3D-LSTM is the core of the novelty, which is basically an LSTM with extra gate, and attention mechanism.  \n\nother comments:\n- As the method by essence is a spatiotemporal learning model, why the method is not evaluated on full-length videos of the something-something dataset for classical action classification task, in order to compare it with the full architecture of I3D, or S3D?\n\n- While the paper discusses self-supervised learning, I would suggest showing its benefit on online action recognition task. One without frame-prediction loss and one with. \n\n- the something-something dataset has 174 classes, how was the process of selecting 41 classes out of it?"", ""AFTER REBUTTAL:\n\nThis is an overall good work, and I do think proves its point. The results on the TaxiBJ dataset (not TatxtBJ, please correct the name in the paper) are compelling, and the concerns regarding some of the text explainations have been corrected.\n\n-----\n\nThe proposed model uses a 3D-CNN with a new kind of 3D-conv. recurrent layer named E3D-LSTM, an extension of 3D-RCNN layers where the recall mechanism is extended by using an attentional mechanism, allowing it to update the recurrent state not only based on the previous state, but on a mixture of previous states from all previous time steps.\n\nPros:\nThe new approach displays outstanding results for future video prediction. Firstly, it obtains better results in short term predictions thanks to the 3D-Convolutional topology. Secondly, the recall mechanism is shown to be more stable over time: The prediction accuracy is sustained over longer preiods of time (longer prediction sequences) with a much smaller degradation. Regarding early action recognition, the use of future video prediction as a jointly learned auxiliary task is shown to significantly increase the prediction accuracy. The ablation study is compelling.\n\nCons:\nThe model does not compare against other methods regarding early action recognition. Since this is a novel field of study in computer vision, and not too much work exists on the subject, it is understandable. Also, it is not the main focus of the work.\n\nIn the introduction, the authors state that they account for uncertainty by better modelling the temporal sequence. Please, remove or rephrase this part. Uncertainty in video prediction is not due to the lack of modelling ability, but due to the inherent uncertainty of the task. In real world scenarios (eg. the KTH dataset used here) there is a continuous space of possible futures. In the case of variational models, this is captured as a distribution from which to sample. Adversarial models collapse this space into a single future in order to create more realistic-looking predictions. I don't believe your approach should necessarily model that space (after all, the novelty is on better modelling the sequence itself, not the possible futures, and the model can be easily extended to do so, either through GANs or VAEs), but it is important to not mislead the reader.\n\nIt would have been interesting to analyse the work on more complex settings, such as UCF101. While KTH is already a real-world dataset, its variability is very limited: A small set of backgrounds and actions, performed by a small group of individuals.\n\n""]","[20, 50, 60]","[60, 75, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges strengths like 'extensive experimentation' and 'motivated' model choices, but also points out significant weaknesses, particularly regarding novelty. The overall tone suggests cautious approval with reservations. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases concerns as suggestions for improvement rather than harsh criticisms. The reviewer also acknowledges the significance of the work despite its limitations. The language is professional and objective, avoiding personal attacks or overly negative phrasing."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as being well-investigated through experiments, well-written, and technically correct. However, they express a 'big concern' about limited novelty, which prevents a higher positive score. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames their concern and suggestions constructively. They use phrases like 'The nice point of the method is...' and 'I would suggest...', which contribute to a polite tone. The reviewer also provides specific, actionable feedback without using harsh or dismissive language."", ""The sentiment score is 60 (positive) because the reviewer starts by stating it's 'an overall good work' and that it 'proves its point'. They mention 'compelling' results and list several pros, indicating a generally positive view. However, they also point out some cons and areas for improvement, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the work while offering constructive criticism. They use phrases like 'Please, remove or rephrase this part' when suggesting changes, which is a polite way to give feedback. The reviewer also shows understanding for limitations (e.g., 'it is understandable' regarding lack of comparisons in early action recognition), further contributing to the polite tone.""]"
"['The paper aims to come up with a criterion for evaluating the quality of samples produced by a Generative Adversarial Network. The main goal is that the criterion should not reward trivial sample generation algorithms such as the one which generates samples uniformly at random from the samples in the training set. I personally feel that if sample generation is the only goal, then this trivial algorithm is perfectly fine because, statistically, the empirical distribution is in many, though not all, ways, a good estimator of the underlying true probability measure (this is the idea that is used in the statistical technique of Bootstrap for example). However the underlying goal in unsupervised learning problems where GANs are used is hardly sample generation. The GANs also output a whole function in the form of a generative network which converts random samples into samples from the underlying generating distribution. This generative network is arguably more important and more useful than just the samples that it generates. An evaluation scheme for GANs should focus on the generative network directly rather than on a set of its generating samples. \n\nEven if one were to regard the premise of the paper as valuable, the paper still does a poor job meeting its objective. A measure D_CNN is proposed as a benchmark. It must be remarked that D_CNN is not even properly defined (for example, there is a function \\Delta in its definition but it is never explained what this function is). D_CNN is a variant of the existing notion of Neural Network Divergences. Only a numerical study (with no theory) is done to illustrate the utility of D_CNN for evaluating samples generated by GANs. The entire paper is very anecdotal with very little rigorous theory. ', 'Summary:\nThe paper looks at the problem of benchmarking models that unconditionally generate images. In particular they focus on GAN models and discuss the Inception Score (IS) and Fréchet Inception Distance (FID) metrics. The authors argue that a good benchmark should not have a trivial solution (e.g. memorising the dataset) and find that a necessary condition for such a metric is a large number of samples. They also find that for IS and FID , a GAN is outperformed by a model that memorises the dataset, while a method based on neural network divergences (NND) does not show the same behaviour. NND works by training a discriminative model to discriminate between samples of the generative model and samples from a held out test set. The poorer the discriminative model performs, the better the generative model is.\n\nThe authors show a range of results using a CNN based divergence: on PixelCNN++, GANs, overfitted GANs, WGAN-GP and conclude that it’s a better metric than IS/FID at the expense of requiring much more computation to evaluate.  They also perform a test with limited compute and show that the results correlate well with a bigger dataset, but show some bias.\n\nReview:\nThe paper is well written, with a clear description of the properties a good benchmark should have, an analysis of the current solutions and their shortcomings and an extensive experimental evaluation of the CNN divergence metric. The authors also compared with non GAN methods and experimented with small datasets, both are not necessarily within scope but a welcome addition. The authors also open source their code.\n\nIn the section “Outperforming Memorization”, the authors mention a way to tune capacity of the “critic” network and influence its ability to overfit on the sample. This means that if someone wants to compare the generalisation and diversity of samples between GANs, they would need to train the exact same critic CNN to be able to make a comparison. However the authors do not provide any principled way to determine the right size of the ""critic"" network. In general, given evaluating the metric requires training a network from scratch, it will be very difficult to make this consistent. This makes the proposed benchmark more impractical to use than its alternatives.\n\nIn the section “training against the metric”, the authors mention that a main criticism is the fact that a GAN directly optimises for the NND loss. In table 3 we indeed see that this is the case, however the authors argue that perhaps the GAN is simply the better model. I am worried by the fact that both PixelCNN++ and IAF-VAE perform worse than the training set on this benchmark. It seems like this particular benchmark would then work well specifically for GANs, but would (still) not allow us to compare with models trained using maximum likelihood.\n\nIn conclusion, I think the paper is well written and the authors clearly make progress towards a dependable benchmark for GANs. The paper does not introduce any new method, but instead has a thorough analysis and discussion of current methods which is worthwhile by itself.\n\nNits:\nPage 7, second paragraph, fifth line, spurious “q”\n\n########\nRevision\n\nI would like to thank the authors for a thoughtful revision and response. I have updated my score to a 7 and think this paper is a worthy contribution to ICLR. The new drawback section is well written and informative.', 'This paper is quite interesting as it tries to find a new metric for evaluating GANs. IS is a terrible metric, as memorization would achieve high score and test log-likelihood cannot be evaluated. I like the long discussion at the beginning of the paper about what a metric for evaluating implicit generative models would need to be a valid and useful metric. This problem is of great importance for GANs as proving that GANs solve the density estimation problem would be extremely hard and even more so, making sure we are close to a good solution with any finite sample even more so (I am talking to non-trivial examples in high dimensions). It is clear that in order to make GANs, in particular, or implicit models, in general, useful, we need to find metrics that would allow us to achieve progress. This paper is a direction in what it needed. In this sense I think the paper can be a good starting point for the discussion that we are not having right now, because we are too focused on making sure they converge, but not how they can be useful. \n\nOn the down side, I think the proposed DNN metric is not exactly useful. It would be a subset of the metric that an MMD would give and it would focus only in some properties of the images but not on the whole distribution. So, if this metric does not capture the relevant aspects of the problem the GAN is trying to imitate, it will fail to provide that metric that we are looking for. \n\nI would see this paper as a great workshop paper, in the sense of old-fashion NIPS workshops in which new ideas were tested and discussed. But it clearly would like the polished papers that we see in conferences these days. Bernhard Schoelkopf told me once, after receiving the ICML reviews, “People now focus more on reasons to reject a paper than in reason for accepting a paper.” (note that I am quoting from memory, the bad use of English in mine not his). There are many reasons to reject this paper, but also some reason to accept the paper.  \n']","[-70, 80, 50]","[-20, 90, 80]","[""The sentiment score is -70 because the reviewer expresses significant criticism and skepticism about the paper's premise and execution. They question the fundamental goal of the research, stating that the paper 'does a poor job meeting its objective.' The reviewer also points out several flaws, such as improper definition of key concepts and lack of rigorous theory. The politeness score is -20 because while the reviewer doesn't use overtly rude language, their criticism is direct and somewhat harsh. Phrases like 'poor job' and describing the paper as 'very anecdotal with very little rigorous theory' are quite blunt and not cushioned with polite language. However, the reviewer does use some mitigating language like 'I personally feel' and 'Even if one were to regard the premise of the paper as valuable,' which prevents the score from being even lower."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, calling it 'well written' with a 'clear description' and 'extensive experimental evaluation'. They also mention that the paper makes 'progress towards a dependable benchmark'. The final score of 7 out of 10 further indicates a positive sentiment. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer acknowledges the authors' efforts, uses phrases like 'I would like to thank the authors', and provides specific, balanced feedback without harsh criticism. Even when pointing out concerns, the language remains professional and courteous."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses interest in the paper's topic and appreciates its potential for sparking important discussions. However, they also point out significant downsides, creating a balanced view. The politeness score is 80 (quite polite) due to the respectful tone throughout, use of phrases like 'I like' and 'I think,' and the inclusion of a personal anecdote. The reviewer offers criticism constructively and acknowledges both strengths and weaknesses of the paper.""]"
"['The paper is nice thread, easy to follow.\n\nThe paper proposed to apply SWA (Stochastic Weight Averaging) Izmailov et al. 2018 to the semi-supervised approached based on consistency regularization. The paper first describes the related work nicely and offers a succinct explanation of two semi-supervised approaches they study. The paper then present an analysis on SGD trajectories of these 2 approaches, drawing comparisons with the supervised training and then building a case of why SWA is a valid idea to apply. The analysis section is very well described, the theoretical explanations are easy to follow and Figure 1, Figure 2 are really helpful to understand this analysis. \n\nOverall, the paper offers a useful insight into semi-supervised model trainings and offers recipe of converging to supervised results which is a valid contribution.\n\nI have following questions to the authors:\n1. Did the authors do the analysis and apply SWA on ImageNet training besides Cifar-10 and Cifar-100\n2. The accuracy number reported in abstract (5.0% error) is top-1 error or top-5 error? I think it\'s top-5 but explicit mention would be great.\n3. In section 3.2, authors offer an analysis by chosing epoch 170, 180. How are these epochs chosen?\n4. In section 3.1, authors consider a simple model version where only small additive perturbations to student inputs are applied. Is this a practical setup i.e. is this ever the case in actual model training?\n5. In section 3.3, pg 6, do authors have intuition into why weight averaging has better improvement (1.18) vs ensembling (0.94)?\n6. In section 5.2, page 8 , can authors provide their intuition behind the results: ""We found that the improvement on VAT is not drastic – our base implementation obtains 11.26% error where fast-SWA reduces it to 10.97%"" - why did fast-SWA not improve much?', ""OVERVIEW:\nThe paper looks at the problem of self-supervised learning using consistency-enforcing approaches. Their main contributions are two-fold:\n1. Analysis to understand current state-of-the-art methods for self-supervised learning, namely the Mean Teacher model (MT) by Tarvainen and Valpola (2017) and the \\Pi model (Laine and Aila, 2017). They show a theoretical analysis (Sec.3.1) of a simplified version of the \\Pi model and show that it reaches flatter minima leading to good generalization. They show an analysis of the SDG trajectories (Sec. 3.2) that shows how these self-supervised models achieve flatter and lower minima compared to a fully supervised approach. They also provide an intuitive explanation to explore more solutions along the SGD trajectory. Finally, in Sec.3.3, they also discuss how ensembling and weight averaging help get better solutions.\n2. Fast-SWA, which is a tweak to the SWA procedure (Izmailov et al, 2018) that averages models in the weight space along the SGD trajectory with a cyclical learning rate.\nThey show good performance on CIFAR-10 and CIFAR-100 with their proposed Fast-SWA.\n\nPROS:\n1. The paper contains a lot of empirical analysis explaining the behavior of these models and providing intuition about the optimization leading to their proposed solution. The problem and experiments are very organized and explained very well.\n2. Exhaustive experiments, plots and tables showing very good performance on the standardized benchmark.\n\nCONS:\n1. The novel contribution (as I see it) is in the theoretical analysis of Sec. 3.1 & A.5 and the Fast-SWA procedure. The Fast-SWA is a minor tweak to the regular SWA. The theoretical analysis is the main novelty and it is hidden away in the appendix ! Also, the results seems to be derived on the basis of Avron and Toledo and the authors' contribution relative to that is not clear. Also, what is the difference between the regular \\Pi model and simplified \\Pi model and how big a difference does this make in your theory ?\n2. Can the Fast SWA be used directly say while supervised training of ImageNet ? Or is it applicable only to self-supervised problems ? Comments on the generalizability of this contribution might help increase novelty.\n\nOVERALL:\nI like the thorough analysis and good results of the paper. The novelty being a little weak results in the final rating of 7.5 (rounded up to 8, subject to change depending on other reviewers)."", 'This paper proposes to apply Stochastic Weight Averaging to the semi-supervised learning context. It makes an interesting argument that the semi-supervised MT/Pi models are especially amenable to SWA since they are empirically observed to traverse a large flat region of the weight space during the later stages of training. To speed up training, the authors propose fast-SWA.\n\nSecition 3.2 is a little confusing. \n- If a random direction is, with high probability, not penalized, then why is it so flat along a random direction? Or is this simply an argument for why it is not guaranteed to be penalized, and therefore adversarial rays exist? I think the claim needs to be more precise (though it remains unclear how accurate the claim would be).\n- I also think that there is maybe something special about measuring the SGD-SGD ray at epochs 170/180. It coincides with the regime of training where the signal is dominated by the consistency loss. Is it possible this somehow induces a near-linear path in the parameter space? I would be interested in seeing projections of other epoch’s SGD-SGD (e.g. 170/17x) vectors onto the 170/180 SGD-SGD ray and the extend to which they are co-linear. \n- It is also striking that traversing the SGD-SGD ray causes an error rate so similar to the adversarial ray for the supervised model; can the authors explain this phenomenon? \n- All this being said, I find the diversity argument compelling---though what would happen if we train the model even longer? Does it keep exploring?\n- Overall, I am not sure how comfortable we should be with interpreting the SGD-SGD ray results. It is important that the authors provide a convincing argument for the interpretability of the SGD-SGD ray results, as this appears to be the key to the “large flat region” claim.\n\nI think Mandt’s paper should be cited in-text, since this is what motivates Figure 2d.\n\nIs the benefit of Fast-SWA’s fast convergence (to a competitive/better solution than SWA) unique to semi-supervised learning? Or can it be demonstrated by fully-supervised learning too? Given the focus on the semi-supervised regime, I would prefer if what the authors are proposing is, in some sense, special to the semi-supervised regime.\n\nTable 1 is confusing to read. I just want to see a comparison between with and without using fast-SWA, *with all else kept equal*. Is the intention to compare “Previous Best CNN” and “Ours CNN”? Is this a fair comparison?\n\nPros:\n+ Interesting story\n+ Good empirical performance\nCons:\n- Unclear whether the story is entirely correct\n\nIf the authors can provide a convincing case for the interpretability of the SGD-SGD results, I am happy to raise my score.']","[80, 50, 20]","[70, 75, 60]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'nice', 'easy to follow', and 'very well described'. They also state that it offers 'useful insight' and is a 'valid contribution'. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, praising aspects of the paper and framing their questions as polite inquiries rather than criticisms. The reviewer offers constructive feedback and asks for clarifications in a professional manner. The slightly lower politeness score compared to sentiment is due to the directness of some questions, which is typical in academic reviews but not overly effusive."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as thorough analysis and good results, while also pointing out some weaknesses. The overall rating of 7.5/10 indicates a generally positive view, but with room for improvement. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, clearly separates pros and cons, and provides constructive feedback. They use phrases like 'I like the thorough analysis' and offer suggestions for improvement rather than harsh criticism. The reviewer maintains a professional tone while expressing both positive and negative aspects of the paper."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's 'interesting story' and 'good empirical performance'. However, they also express several concerns and request clarifications, which tempers the positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and expresses willingness to raise their score if concerns are addressed. The reviewer maintains a professional tone, balancing praise with constructive criticism.""]"
"['The paper presents a methodology for improved program synthesis by generating datasets for program induction and synthetic tasks from uniform distributions. This method is evaluate on two problem settings. \n\nThe methodology is presented in section 3. Even though the outline does not seem to be complicated, the presentation in section 3 leaves me puzzled. The the second paragraph two sets of silent variables are introduced X_1,...,X_n and Z_1,...,Z_m but never used again the rest of the paper. In the third and forth paragraph details about the Karel domain are presented without the Karel domain having been introduced. It seems you are using rejection sampling to sample from a uniform distribution. Why can you not sample from a uniform distribution directly? What do you mean with the notation X(s)? What are you proving in Appendix? Would maybe be clearer if you presented it as a theorem/lemma.\n\nThe remaining part of the paper evaluates this methodology on two specific problem settings, the Karel domain and Calculator domain. The generalization performance is increased when trained on datasets generated by the method presented in the paper. However, I cannot find and strong arguments in the paper why this property should generalize to other problem settings. To me the analysis and experimental results seems to be tailored to the two problems settings used in the paper.\n\n==== After revision ====\n\nThe authors have done a great job addressing the concerns I had about the clarity. Consequently, I have raised my score, whereas my fairly low confidence still remains.', 'This paper provides a good presentation of a serious problem in evaluating (as well as training!) performance of machine learning models for program synthesis / program induction: considering specifically the problem of learning a program which corresponds to given input/output pairs, since large datasets of ""real-world"" programs typically do not exist it necessary to construct a synthetic dataset for training and testing; this requires both (a) generating programs, and (b) generating input/output examples for these programs. Enumerating either all possible programs or examples is typically impossible, and so a sampling scheme is used to simulate ""reasonable"" programs and examples. This may hinder generalization to other data not often produced by the sampling scheme.\n\nTo address this, the paper then argues that programs should be synthesized from a distribution which as as uniform as possible over a set of user-specified statistics (the ""salient variables"") as well as over the input space. Intuitively, this makes sense: maximizing the entropy of the synthetic data should provide good coverage over the entire input space. However, there are a few ways in which the particular approach is unsatisfying:\n\n(1) It requires manual curation of salient random variables. This sort of punts the decision of ""what should my sampling procedure be"" to ""what is my choice of salient variables to make uniform"". I agree that this is still an improvement.\n\n(2) The procedure described for generating synthetic examples is essentially a rejection sampling algorithm, and it will fail to generate examples in a reasonable timeframe if the original proposal distribution is highly non-uniform, or if the salient random variables include values which fall in the tail of the proposal distribution.\n\nAlso, relatedly, I don\'t follow the description of correctness in section 8.2 at all. What is meant by the ""= 1"" at the end of the line right before ""… And thus…""? Clearly P_r[X=x] cannot both equal 1, and equal k. Is the ""=1"" meant to only mean the summand itself? If so, please fix the notation. Also, I assume that k is meant to be the cardinality of the set {s: X(s) = x}, but this is not defined anywhere. Notational issues aside, unless the mapping X(s) from sample to salient variable is one-to-one, then I\'m not clear how the P_q[X = X(s)] would relate to q(s). This should be made more clear. Also, I believe there need to be conditions on q(s), e.g. such that min_x P_q[X = x] must always be greater than zero.\n\n\nThese issues aside, the empirical demonstrations on the Karel the Robot examples are nicely presented and make the point well. My primary question here would be around section 5, the ""real-world benchmarks"", where it is observed that the baseline model performs less well than re-training on a uniform / homogenized dataset. While it is nice that it performed better, I don\'t understand why even the better number (19.4%) is so low; the performance of the uniform model in table 1 tends to be much higher (in the 60% to 70% range). This would suggest that the uniform model perhaps is significantly *underweighting* important parts of the space. What is causing this? e.g. what do the salient variables look like for real-world examples?\n\n\nFinally, I am not sure I understand how the calculator example fits into this paper. Unless I misunderstand, it is not a program synthesis task, but rather a regression task. Clearly it does still depend on generation of synthetic data, but that is more a different task (as described in section 2). I feel its inclusion somewhat dilutes the paper. Rather, it would be nice to see more discussion or investigation into the failure modes of these trained models; for example, looking deeper at the handling of control flow and recursion, or at whether particular values of salient variables tended to be correlated with success or failure under different train / test regimes.\n\n\n\n===== after updates =====\n\nThanks for the edits — I believe the overall paper is more clearly presented, now.\n\nI still think it is a stretch to consider the calculator domain is a program induction problem: it is a regression problem, from an input string to an output integer, or alternately a classification problem, since it computes the result mod 10. The only way I could understand this as a program induction problem is rather obliquely, if the meaning is that any system which is able to compute the result of the calculator evaluation has implicitly replicated internally, in some capacity, the sequence of instructions which are evaluated. I don\'t think this is really very clear though; for example, given two calculator programs, one a subprogram of another (e.g., ""4*(3+2)"" and ""3+2""), do the resulting ""induced"" computations share the same compositional structure? The examples of program induction in section 2 are largely architectures which are explicitly designed to have properties which mimic conventional programming languages (e.g. extra data structures as memories, compositionality, …). In contrast, the calculator example in this paper simply uses an LSTM. \n\nThat said, I think it\'s still a great example! Learning a fast differentiable model which accurately mimics existing non-differentiable model has tons of applications, and has exactly the same challenges regarding synthetic data. \n\n\n\nI have to say I find the new section 8.3 a bit intuitively challenging; e.g. it\'s not clear really how long a waiting time of 48 log(2|X|/\\delta) / (p|X|^2 z^2) really is. But, to that end, I appreciate the empirical discussion in 8.4–8.6.\n\nI\'ve updated my review to increase my score — I lean towards accepting this paper, as it is a timely contribution and I think it is important for future program synthesis papers to take the results here to heart. I\'ve reduced my confidence slightly, as I have not fully reviewed the new proof in 8.3.', 'This is a nice paper. It makes novel contributions by investigating (a) the problem of skewed dataset distributions in neural program synthesis, specifically program induction from given I/O pairs, and (b) the extent to which making them uniform would improve model performance. \n\nThe paper argues that there are inevitable and artificial sparsities as well as skews in existing datasets (e.g. pruning illegal I/O pairs, naive random sampling tends not to generate complex nested control-flow statements), and the principled way to minimize these sparsities and skews is to make distributions over salient random variables uniform. The authors evaluate their hypothesis empirically on two flavors of neural program synthesis methods: program inductions on explicit DSL represented by Karel, and implicit differentiable neural program synthesizers (such as stack, RAM, GPU as cited in section 2) represented by a Calculator example. In evaluations, they construct few challenging “narrower” datasets and show baseline models perform significantly worse than models trained on datasets with uniform distributions (by 39-66 pp). Along this line, they also show uniform models consistently perform much better than baseline ones on other out-of-distribution test sets. To show how bad a model would perform if it were trained on a skewed training set, they train models on narrower datasets and evaluate them on different narrower sets.\n\nThe strength of this paper are:\n(1) It has complete and empirically sound evaluations: both showing how much better uniform models would be and how much worse non-uniform models would be.\n\n(2) Although we might doubt the salient random variables are handcrafted and rejection sampling wouldn’t make the dataset completely uniform, they include evaluations on out-of-distribution datasets (e.g. CS106A dataset in section 5.2) to show that uniform models still perform better and thus their sampling scheme does cover some non-obvious sparsities and skews.\n\n(3) Despite the doubt on efficiencies of rejection sampling, they include both a proof and empirical results (section 8.3 and 8.4) to show they need sample O(1/ε) times before finishing.\n\nWeaknesses:\n(1) No new model. This work has solely using the existing model from Bunel et al. (2018) in the Karel domain and didn’t propose a new model that illustrates possibly a way to utilize/demonstrate the uniformity of dataset.\n\n(2) The calculator example is relatively too trivial to represent the whole genre of implicit differentiable neural program synthesizer (e.g. stack, GPU, RAM). \n\n(3) No statistical tests (such as chi-square test) to support the claim about uniformity (even on chosen salient variables) \n\nQuestions:\n(1) What if the distribution of real-world programs are skewed and neural synthesizers are supposed to take advantage of their skewness?\n\n(2) Why would you claim the calculator example is not a program synthesis task while intending to use it to represent another genre of program synthesis methods?\n\nSuggestions:\n(1) To show that current salient random variables do not make the dataset theoretically uniform but are still approximate enough, why not construct some distinct held-out salient variables (such as memory/grid/marker query times, executing time) from existing ones, construct narrower test sets accordingly, and hopefully show uniform models still perform significantly better than baseline?\n\n(2) In section 8.2, why not write the proportionality statement in two lines so that people wouldn’t be confused to think Pr[X=x] = 1 while intending to show Pr[X=x] ∝ 1(an arbitrary constant) so that Pr[X] is uniform?\n']","[50, 50, 70]","[70, 70, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges significant improvements in the revised version, stating 'The authors have done a great job addressing the concerns I had about the clarity.' However, they still express some reservations, noting 'my fairly low confidence still remains.' The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, particularly praising the authors' efforts in the revision. They offer constructive criticism in earlier paragraphs without using harsh or dismissive language, and the final paragraph is notably positive and encouraging. The reviewer maintains a professional and courteous tone, even when expressing concerns or confusion about certain aspects of the paper."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and importance, especially in the final paragraph where they lean towards accepting the paper. However, they also raise several concerns and suggest improvements, balancing the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges improvements made after updates, and frames criticisms constructively. Phrases like 'Thanks for the edits' and 'I appreciate the empirical discussion' demonstrate politeness. The reviewer maintains a professional tone while providing detailed feedback, avoiding harsh or rude language even when pointing out issues."", ""The sentiment score is 70 (positive) because the review starts with 'This is a nice paper' and highlights several strengths of the paper, including 'complete and empirically sound evaluations' and 'proof and empirical results'. While it does mention some weaknesses, these are presented as minor points and don't significantly detract from the overall positive tone. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's contributions, and frames criticisms constructively as 'weaknesses' rather than flaws. The reviewer also offers suggestions for improvement in a helpful manner, using phrases like 'why not' instead of more directive language. The questions posed are neutral and inquisitive rather than confrontational.""]"
"['1) Summary\nThis paper presents a graph neural network based architecture that is trained to locate and model the interactions of agents in an environment directly from pixels. They propose an architecture that is a composition of recurrent neural networks where each models a single object independently and communicate with other for the overall environment modeling. The model is trained with a variational recurrent neural network objective that allows for stochasticity in the predictions while at the same time allows to model the current and future steps simultaneously. In experiments, they show the advantage of using the proposed model for tasks of tracking as well as forecasting of agents locations.\n\n\n\n2) Pros:\n+ Novel recurrent neural network architecture to model structured dynamics of agents in an environment.\n+ Outperforms baseline methods.\n+ New dataset for partially observable prediction research.\n\n3) Cons:\n\nForecasting task:\n- The authors argue that a discretization needs to be performed because of the many possible futures given the past, and also provide an error measure based on likelihood. However, if trajectories are actually generated from these distributions, I suspect the many possible futures generated will be very shaky. Can the authors provide trajectories sampled from this? If sampling trajectories does not make sense somehow, can the authors comment on how we can sample multiple trajectories?\n\nLack of baselines:\n- The authors mention social LSTM and social GAN in the related work, however, no comparison is provided. From a quick glance, the authors of these papers work on trajectories. However, the “social” principle in those papers is general since it’s done from the computed feature vector. Could it have not been used on top of one of the baselines? If not, could the authors provide a reason why this is not the case?\n\n\nAdditional comments:\nAs the authors mention, it would be nice to extend this paper to an unsupervised or semi-supervised task. Here are a couple of papers that may interest you:\nhttps://arxiv.org/abs/1804.04412\nhttps://arxiv.org/abs/1705.02193\nhttps://arxiv.org/abs/1806.07823\n\n4) Conclusion\nOverall, the paper is well written, easy to understand, and seems to be simple enough to quickly reproduce. Additionally, the proposed dataset may be of use for the community. If the authors are able to successfully address the issues mentioned, I am willing to improve my score.', ""Summary: The paper proposes a method to predict the future state-spaces in a multi-agent system by combing the visual and temporal information using a mixed blend of Graph-Networks+VAE+RNN (G-VRNN) formulation. The proposed approach is evaluated on two sports datasets: (1). basketball sequences; (2). soccer sequences. The authors show how the overall formulation is better than each of individual components.\n\nPros: \n\n1. the multi-agent setting is interesting, very natural, and has potential for many applications.\n\n2. formulation encodes information about different aspects: agents, location, temporal activities, and each agent's relation to other.\n\nCons: \n\n1. The current evaluation is contrived. \n\n(a). the task for future state prediction in current basket-ball and soccer sequence is not very clear. A gaussian distribution defined with 'time' as standard deviation could give similar results? \n\n(b). no comparison with the existing approaches? I think the work of Felson et al. ICCV'17 is relevant for the given paper, and so it would be ideal to do evaluation on the datasets used in their work, and if possible compare the different baselines that they have used. \n\n(c). the goal is to predict the future state of an agent in a multi-agent setting, but it is not clear from the evaluation as how the presence of multiple agents influence the behavior of an individual. \n\n(d). a better way to demonstrate the future state-spaces could be through trajectory of ball or players (similar to ones shown by Walker et al ECCV'16, CVPR'14). The current qualitative analysis is not sufficient to understand what is happening in the proposed pipeline.\n\n(e). more challenging cases to demonstrate the proposed approach  -- consider any multi-person tracking dataset, and use the proposed formulation to predict multiple trajectories (and hence state-spaces at varying time) for the people. An amazing result could be shown as how a person changes trajectory as a group of people pass by.\n\n2. The running example of 'location of goalie' is ambiguous. By design, goalie has to be near the goal post. Even if there is no visual information or any other information, one can safely say this thing?\n\nOverall I think the work has the potential to be on something really interesting. However, I think it needs solid experiments and is not yet ready for publication."", 'The authors propose Graph VRNN. The proposed method models the interaction of multiple agents by deploying a VRNN for each agent. The interaction among the agents is modeled by the graph interaction update on the hidden states of the VRNNs. The model predicts the true state (e.g., location) of the agent via supervised auto-regressive learning. The proposed model can improve this estimation from partially-observed visual observations. In the experiment, the authors apply the proposed method to Basketball and Soccer data to model the positions of the players. \n\nThe paper is clearly written. However, Section 3.2 needs to be elaborated more because using graph interaction update in VRNN is one of the main contributions. \n\nI see two main weaknesses. The first is that the states are learned by supervised learning where obtaining the state label (i.e., the agent locations) is very expensive. Indeed, the authors had to develop their own soccer game to obtain these labels. The second weakness is the weak/inconsistent experiment results. It seems not clear whether having the graph structure or stochastic modeling is really helping or not. For example, for basketball experiment, Graph-RNN works poorly. And, for soccer, Graph-VRNN works just as good as Graph-RNN. The authors explained that this is due to the simplicity of the player behavior (not much stochastic), but the result in Table 2 shows good performance for Graph-VRNN for future prediction task. All these make it difficult to buy the claimed argument. It is also a limitation that the model requires to know and fix the number of agents.\n\nAs minor comments, \n\n- in Table 1. Graph-RNN works better for soccer t=4, but not indicated in bold. \n- Having a single RNN baseline will be helpful to compare with Graph-RNN.\n- It is confusing to call s_t a belief state because it is observed not latent.\n- In the qualitative results, I think it can be compared to the heatmap of true distribution.\n\nI think the following papers needs to be discussed as related works.\n- https://arxiv.org/pdf/1806.01242.pdf \n- https://arxiv.org/pdf/1802.03006.pdf\n\n']","[50, -50, -20]","[75, 50, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novelty, its advantages over baseline methods, and the introduction of a new dataset. However, they also point out some cons and areas for improvement, balancing the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and even suggests additional resources. They express willingness to improve their score if concerns are addressed, which is encouraging to the authors. The review maintains a professional and courteous tone while providing both praise and critique."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('pros') of the paper, the overall tone is critical and suggests that the work is not ready for publication. The reviewer points out several significant issues with the evaluation and methodology, which outweigh the positive points. The politeness score is 50 because the reviewer uses professional and respectful language throughout, acknowledging both strengths and weaknesses of the paper. They offer constructive criticism and suggestions for improvement, rather than harsh or dismissive comments. The reviewer also ends on a somewhat positive note, stating that the work has potential, which helps maintain a polite tone despite the overall negative assessment."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is clearly written'), they also point out 'two main weaknesses' and express skepticism about the claimed arguments ('All these make it difficult to buy the claimed argument'). The overall tone suggests more concerns than praise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and provides specific suggestions for improvement without using harsh or dismissive language. They maintain a professional tone, even when pointing out weaknesses, using phrases like 'I see two main weaknesses' rather than more confrontational language.""]"
"['The paper is very well written. The proposed approach is appropriate on modeling the node representations when the two types of events happen in the dynamic networks. Authors also clearly discussed the relevance and difference to related work. Experimental results show that the presented method outperforms the other baselines.\nOverall, it is a high-quality paper. \nThere are only some minor comments for improving the paper:\nν\tPage 6, there is a typo. “for node v by employing …”  should be “for node u”\nν\tPage 6, “Both GAT and GaAN has”   should be  “Both GAT and GaAN have”\nν\tIn section 5.1, it will be great if authors can explain more what are the “association events” and “communication events” with more details in these two evaluation datasets.\n', 'Overall, the contribution of the paper is somewhat limited [but a little more than my initial assessment, thanks to the rebuttal]. It is essentially an extension of (Trivedi et al. 2017), adding attention to provide self-exciting rates, applied to two types of edges (communication edges and “friendship” edges). Conditioned on past edges, future edges are assumed independent, which makes the math trivial. The work would be better described as modeling a Marked Point Process with marks k \\in {0,1}.\nOther comments:\n1.\t[addressed] DyRep-No-SP is as good as the proposed approach, maybe because the graph is assumed undirected and the embedding of u can be described by its neighbors (author rebuttal describes as Localized Propagation), as the neighbors themselves use the embedding of u for their own embedding (which means that self-propagation is never ""really off""). Highly active nodes have a disproportional effect in the embedding, resulting in the better separated embeddings of Figure 4. [after rebuttal: what is the effect of node activity on the embeddings?]\n2.\t[unresolved, comment still misundertood] The Exogenous Drive W_t(t_p – t_{p−1}) should be more personalized. Some nodes are intrinsically more active than others. [after rebuttal: answer ""$W_t(t_p - t_{p-1})$ is personalized as $t_p$ is node specific"", I meant personalized as in Exogenous Drive of people like Alice or Bob]\n3.\t[unresolved] Fig 4 embeddings should be compared against (Trivedi et al. 2017) [after rebuttal: author revision does not make qualitative comparison against Trivedi et al. (2017)]\n\nBesides the limited innovation, the writing needs work. \n4.\t[resolved] Equation 1 defines $g_k(\\bar{t})$ but does not define \\bar{t}. Knowing (Trivedi et al. 2017), I immediately knew what it was, but this is not standard notation and should be defined. \n5.\t[resolved] $g_k$ must be a function of u and v\n6.\t[resolved] “$k$ represent the dynamic process” = >  “$k$ represent the type of edge” . The way it is written $k$ would need to be a stochastic process (it is just a mark, k \\in {0,1})\n7.\t[resolved] Algorithm 1 is impossibly confusing. I read it 8 times and I still cannot tell what it is supposed to do. It contains recursive definitions like $z_i = b + \\lambda_k^{ji}(t)$, where $\\lambda_k^{ji}(t)$ itself is a function of $z_i(t)$. Maybe the z_i(t) and z_i are different variables with the same name?\n8.\t[resolved] The only hint that the graph under consideration is undirected comes from Algorithm 1, A_{uv}(t) = A_{vu}(t) = 1. It is *very* important information for the reader.\nRelated work (to be added to literature):\nDynamic graph embedding: (Yuan et al., 2017) (Ghassen et al., 2017)\nDynamic sub-graph embedding: (Meng et al., 2018)\n\nMinor:\nstate-of-arts => state-of-the-art methods\nlist enumeration “1.)” , “2.)” is strange. Decide either 1) , 2) or 1. , 2. . I have never seen both.\nMAE => mean absolute error (MAE)\n\nYuan, Y., Liang, X., Wang, X., Yeung, D. Y., & Gupta, A., Temporal Dynamic Graph LSTM for Action-Driven Video Object Detection. ICCV, 2017.\nJerfel,  , Mehmet E. Basbug, and Barbara E. Engelhardt. ""Dynamic Collaborative Filtering with Compound Poisson Factorization."" AISTATS 2017. \nMeng, C., Mouli, S.C., Ribeiro, B. and Neville, J., Subgraph Pattern Neural Networks for High-Order Graph Evolution Prediction. AAAI 2018.\n\n--- --- After rebuttal \n\nAuthors addressed most of my concerns. The paper has merit and would be of interest to the community. I am increasing my score.', 'Overall the paper suffers from a lack of clarity in the presentation, especially in algorithm 1, and does not communicate well why the assumption of different dynamical processes should be important in practice. Experiments show some improvement compared to (Trivedi et al. 2017) but are limited to two datasets and it is unclear to what extend end the proposed method would help for a larger variety of datasets. \n\nNot allowing for deletion of node, and especially edges, is a potential draw-back of the proposed method, but more importantly, in many graph datasets the type of nodes and edges is very important (e.g. a knowledge base graph without edges loses most relevant information) so not considering different types is a big limitation. \n\nComments on the method (sections 2-4).\n\nAbout equation (1):\n \\bar{t} is not defined and its meaning is not obvious. The rate of event occurrence does not seem to depend on l (links status) whereas is seems to be dependent of l in algorithm 1. \n\nI don’t see how the timings of association and communication processes are related, both \\lambda_k seem defined independently. Should we expect some temporal dependence between different types of events here? The authors mention that both point processes are “related through the mediation process and in the embedding space”, a more rigorous definition would be helpful here. \n\nThe authors claim to learn functions to compute node representations, however the representations z^u seem to be direct embeddings of the nodes. If the representations are computed as functions it should be clear what is the input and which functional form is assumed.\n\nI find algorithm 1 unclear and do not understand how it is formally derived, its justification seems rather fuzzy. It is also unclear how algorithm 1 relates to the loss optimisation presented in section 4. \n\nWhat is the mechanism for addition of new nodes to the graph? I don’t see in algorithm 1 a step where nodes can be added but this might be handled in a different part of the training. \n\nComments on the experiments section.\n\nSince the proposed method is a variation on (Trivedi et al. 2017), a strong baseline would include experiments performed on the same datasets (or at least one dataset) from that paper. \n\nIt is not clear which events are actually observed. I can see how a structural change in the network can be observed but what exactly constitutes a communication event for the datasets presented?\n']","[90, -20, -60]","[80, 30, 20]","[""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer describes the paper as 'very well written', 'high-quality', and states that the approach is 'appropriate' and the results 'outperform' baselines. The only criticisms are described as 'minor comments'. The politeness score is 80 because the language is consistently respectful and constructive. The reviewer uses phrases like 'it will be great if' when making suggestions, which is polite. The tone is professional and supportive throughout, with no harsh or rude language. However, it doesn't reach 100 as it maintains a formal, rather than overtly friendly, tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some merit in the paper after the rebuttal ('The paper has merit and would be of interest to the community'), they still express concerns about limited innovation and writing quality. The initial statement 'Overall, the contribution of the paper is somewhat limited' sets a negative tone. The politeness score is moderately positive (30) as the reviewer uses professional language throughout, acknowledges improvements after rebuttal, and provides constructive feedback. They avoid harsh criticism and use phrases like 'would be better described as' instead of more direct negative statements. The reviewer also takes time to explain their reasoning and provides detailed comments, which is considerate. However, some phrases like 'impossibly confusing' and 'needs work' prevent a higher politeness score."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several issues with the paper, including lack of clarity, limited experiments, and significant limitations of the proposed method. The opening statement directly states that the paper 'suffers from a lack of clarity' and subsequent paragraphs highlight various shortcomings. However, it's not entirely negative as it acknowledges some improvement over previous work, hence not scoring at the extreme negative end.\n\nThe politeness score is 20 because while the reviewer is critical, the language used is professional and constructive. The reviewer uses phrases like 'it is unclear', 'I don't see how', and 'a more rigorous definition would be helpful' rather than using harsh or dismissive language. The reviewer also offers specific suggestions for improvement, which is a polite way to provide criticism. However, the score is only slightly positive as the review doesn't go out of its way to be exceptionally polite or encouraging.""]"
"['Paper summary: \n\nThis paper presents a deep-learning based method for super-resolving low-resolution labels into high-resolution labels given the joint distribution between those low- and high- resolution labels. This is useful for many semantic segmentation tasks where high-resolution ground truth data is hard and expensive to collect. Its main contribution is a novel loss function that allows to minimize the distance between the distribution determined by a set of model outputs and the corresponding distribution given by low-resolution label over the same set of outputs. The paper also thoroughly evaluates the proposed method for two main tasks, the first being a land cover mapping task and the second being a medical imaging problem.\n\nFor the land cover application, adding low-resolution data to high-resolution data worsens the results when evaluating on the geographic area from which the high-resolution data was taken. However, when testing the model on new geographic areas and only adding the low-resolution data from this new area in training makes significant improvements.\n\nGenerally the paper is very well written, well structured, all explanations are clear, examples and figures are presented when needed and convey helpful information for the reader. The overall idea is fun, original, useful (especially in remote sensing) and is presented in a a convincing way. All major claims are supported by experimental evaluation. There are nevertheless a few concerns:\n\nMajor Concerns:\n\nOn a conceptual level, the main concern is that the paper assumes we are given a joint distribution of low and high resolution labels, “where we are given the joint distribution P(Y,Z)”, which seems the main limitation of this method. In fact, to correctly estimat this joint distribution either requires additional knowledge about low-resolution data such as the example presented on the NCLD data : “For instance, the “Developed, Medium Intensity” class [...] of the coarse classes”, or it requires actual high-resolution labelled data to correctly estimate this joint distribution. I think the paper would greatly benefit from including a section that discusses the impact of this limitation.\n\nAnother point is footnote 3 on page 5. This argument is valid but it would be more convincing to give a thorough explanation on why the choice of the presented loss function is better compared to the KL divergence based loss function or at least some evidence that the two perform similarly when evaluating the method.\n\nMinor Concerns: \n\n-\t“such as CRFs or iterative evaluation” I would include a citation on this type of work.\n-\tFormat of some references in the text need to be corrected, e.g. “into different land cover classes Demir et al. (2018); Kuo et al. (2018); Davydow et al. (2018); Tian et al. (2018).” \n\n', 'This paper presents a method to super-resolve coarse low-res segmentation labels, if the joint distribution of low-res and high-res labels are known. The problem formulation and the proposed solution are valid, given the examples of land cover super-resolution and lymphocyte segmentation.\nI like the paper in general, with the following concerns/thoughts:\n1. While matching the divergence of low-res and high-res segmentations, will the model simply collapse and predict noisy boundaries? Or is it already the case, as can be seen in Figure 8 of Appendix? It seems possible that the model is learning high resolution noises. I suggest the authors to do more careful analysis on this.\n2. I am curious to see if the proposed technique can be used in other aspects, like super-resolving the boundary of semantic segmentations.', ""The authors present a technique to exploit low resolution labels from a space Z to provide weak supervision to a semantic segmentation network which predicts high resolution labels from a different space Y, assuming that a joint distribution of Z, Y is known a-priori.\n\nThe paper is very well written and easy to follow, the main contribution is clearly and rigorously explained in the technical section.\nThe technical contribution is somehow limited, but it is substantially validated by a very well organized and convincing experimental evaluation.\nOverall, I have three main points of criticism (detailed in the following), which however aren't enough to not recommend this paper for acceptance.\n\nMain cons:\n\n1) At points, the paper reads more like a technical report about solving specific problems in land cover estimation and lymphocyte segmentation than a machine learning paper.\nMany paragraphs are devoted to describe the specifics of these two problems and to design methods to overcome them.\nThe main technical contribution of the paper seems to be specifically tailored to solve the particular setup encountered in land cover estimation, i.e. two different sets of labels with different resolution on the same segmentation data, which ties to the next point.\n\n2) One important limitation lies in the fact that the distribution p(c|z) needs to be known a-priori and somehow derived from additional problem-specific knowledge.\nThis is not an issue in the two tasks considered in the paper, but in my opinion it could severely limit the applicability of the proposed approach.\nI think the paper would benefit from the inclusion of some discussion about how this limitation could be overcome.\n\n3) It's not very clear to me why the gaussian approximation with the specific mean and variance values defined in eq.4 would be a good approximation for p_net(c_lk|X).\nCould the authors expand on this?""]","[70, 60, 50]","[80, 70, 80]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'very well written, well structured' with clear explanations and helpful figures. The reviewer also calls the idea 'fun, original, useful' and 'presented in a convincing way.' However, the score is not higher due to the 'few concerns' mentioned, including some 'major concerns' about conceptual limitations. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They begin with positive feedback, use phrases like 'the paper would greatly benefit from,' and frame criticisms as 'concerns' rather than flaws. The tone is professional and supportive, offering specific suggestions for improvement without being harsh or dismissive."", ""The sentiment score is 60 (positive) because the reviewer starts by stating they 'like the paper in general,' which indicates a positive overall impression. They also describe the problem formulation and proposed solution as 'valid.' However, the score is not higher because the reviewer expresses some concerns and suggestions for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, such as 'I like the paper' and 'I suggest,' which shows consideration for the authors. They also frame their concerns as 'thoughts' rather than criticisms. The reviewer maintains a professional and constructive tone, offering specific suggestions for improvement without being harsh or dismissive."", ""The sentiment score is 50 (slightly positive) because the reviewer starts with positive comments about the paper being well-written, easy to follow, and having a convincing experimental evaluation. However, they also mention 'three main points of criticism,' which balances out the positive aspects. The overall tone suggests a generally positive view with some reservations. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'The paper is very well written' and 'very well organized and convincing experimental evaluation.' Even when presenting criticisms, the language remains professional and constructive, using phrases like 'Could the authors expand on this?' rather than making blunt or harsh statements.""]"
"['This paper introduces a new framework to interactively interact document retriever and reader for open-domain question answering. While retriever-reader framework was often used for open-domain QA, this bi-directional interaction between the retriever and the reader is novel and effective because\n1) If the retriever fails to retrieve the right document at the first step, the reader can give a signal to the retriever so that the retriever can recover its mistake at the next step\n2) The idea of `reader state` from the reader to the retriever is new\n3) The retriever use question-independent representation of paragraphs, which does not require different representation depending on the question and makes the framework easily scalable.\n\nStrengths\n1) The idea of multi-step & bi-directional interaction between the retriever and the reader is novel enough (as mentioned above). The paper contains enough literature studies on existing retriever-reader framework in open-domain setting, and clearly demonstrates how their framework is different from them.\n2) The authors run the experiments on 4 different dataset, which supports the argument about the framework’s effectiveness.\n\nWeakness\n1) The authors seem to highlight multi-step `reasoning`, while it is not `reasoning` in my opinion. Multi-step reasoning refers to the task which you need evidence from different documents, and/or you need to find first evident to find the second evidence from a different document. I don’t think the dataset here are not multi-step reasoning dataset, and the authors seem not to claim it either. Therefore, I recommend using another term (maybe `multi-step interaction`?) instead of `multi-step reasoning`.\n2) While the idea of multi-step interaction and how it benefits the overall performance is interesting, the analysis is not enough. Figure 3 in the paper does not have enough description — for example, I got the left example means step 2 recovers the mistake from step 1, but what does the right example mean?\n\nQuestions on result comparison\n1) On TriviaQA (both open and full), the authors mentioned the result is on hidden test set — did you submit it to the leaderboard? I don’t see the same numbers on the TriviaQA leaderboard. Also, the authors claim they are SOTA on TriviaQA, but there are higher numbers on the leaderboard (which are submitted prior to the ICLR deadline).\n2) There are other published papers with higher result on Quasar-T, SearchQA and TriviaQA (such as https://aclanthology.info/papers/P18-1161/p18-1161 and https://arxiv.org/abs/1805.08092) which the authors did not compare with.\n3) In Section 4.2, is there a reason for the specific comparison to AQA (5th line), though AQA is not SOTA on SearchQA? I don’t think it means latent space is better than natural language space. They are totally different model and the only intersection is they contains interaction between two submodules.\n4) In Section 5, the authors mentioned their framework outperforms previous SOTA by 15% margin on TriviaQA, but what is that? I don’t see 15% margin in Table 2.\n\nMarginal comments:\n1) If I understood correctly, `TriviaQA-open` and `TriviaQA-full` in the paper are officially called `TriviaQA-full` and `open-domain TriviaQA`. How about changing the term for readers to better understand the task? Also, in Section 4, the authors said TriviaQA-open is larger than web/wiki setting, but to my knowledge, this setting is part of the wiki setting.\n2) It would be great if the authors make the capitalization consistent. e.g. EM, Quasar-T, BiDAF. Also, the authors can use EM instead of `exact match` after they mentioned EM refers to exact match in Section 4.2.\n\nOverall comment\nThe idea in the paper is interesting, and their model and experiments are concrete. My only worries is that the terms in the paper are confusing and performance comparison are weak. I would like to update the score when the authors update the paper.\n\n\nUpdate 11/27/2018\nThanks for the authors for updating the paper. The updated paper have more clear comparisons with other models, with more & stronger experiments with the additional dataset. Also, the model is claimed to perform multi-step interaction rather than multi-step reasoning, which clearly resolves my initial concern. The analysis, especially ablations in varying number of iterations, was helpful to understand how their framework benefits. I believe these make the paper stronger along with its initial novelty in the framework. In this regard, I vote for acceptance.', ""The authors improve a retriever-reader architecture for open-domain QA by iteratively retrieving passages and tuning the retriever with reinforcement learning. They first learn vector representations of both the question and context, and then iteratively change the vector representation of the question to improve results. I think this is a very interesting idea and the paper is generally well written.\n\nI find some of the description of the models, methods and training is lacking detail. For example, their should be more detail on how REINFORCE was implemented; e.g. was a baseline used?\n\nI am not sure about the claim that their method is agnostic to the choice of machine reader, given that the model needs access to internal states of the reader and their limited results on BiDAF.\n\nThe presentation of the results left a few open questions for me:\n\n  - It is not clear to me which retrieval method was used for each of the baselines in Table 2.\n  - Why does Table 2 not contain the numbers obtained by the DrQA model (both using the retrieval method from the DrQA method and their method without reinforcement learning)? That would make their improvements clear.\n  - Moreover, for TriviaQA their results and the cited baselines seem to all perform well below to current top models for the task (cf. https://competitions.codalab.org/competitions/17208#results).\n  - I would also like to see a better analysis of how the number of steps helped increase F1 for different models and datasets. The presentation should include a table with number of steps and F1 for different step numbers they tried. (Figure 2 is lacking here.)\n  - In the text, the authors claim that their result shows that natural language is inferior to 'rich embedding spaces'. They base this on a comparison with the AQA model. There are two problems with this claim: 1) The two approaches 'reformulate' for different purposes, retrieval and machine reading, so they are not directly comparable. 2) Both approaches use a 'black box' machine reading model, but the authors use DrQA as the base model while AQA uses BiDAF. Indeed, since the authors have an implementation of their model that uses BiDAF, an additional comparison based on matched machine reading models would be interesting.\n- Generally, it would be great to see more detailed results for their BiDAF-based model as well.\n"", 'The paper proposes a multi-document extractive machine reading model and algorithm. The model is composed of 3 distinct parts. First, the document retriever and the document reader that are states of the art modules. Then, the paper proposes to use a ""multi-step-reasoner"" which learns to reformulate the question into its latent space wrt its current value and the ""state"" of the machine reader.\n\nIn the general sense, the architecture can be seen as a specific case of a memory network. Indeed, the multi-reasoner step can be seen as the controller update step of a memory network type of inference. The retriever is the attention module and the reader as the final step between the controller state and the answer prediction.\n\nThe authors claim the method is generic, however, the footnote in section 2.3 mentioned explicitly that the so-called state of the reader assumes the presence of a multi-rnn passage encoding. Furthermore, this section 2.3 gives very little detailed about the ""reinforcement learning"" algorithms used to train the reasoning module.\n\nFinally, the experimental section, while giving encouraging results on several datasets could also have been used on QAngoroo dataset to assess the multi-hop capabilities of the approach. Furthermore, very little details are provided regarding the reformulation mechanism and its possible interpretability.']","[50, 50, -20]","[80, 60, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the novelty and strengths of the paper, but also points out several weaknesses and areas for improvement. The initial review was somewhat critical, but the update shows the reviewer was satisfied with the authors' revisions and ultimately voted for acceptance. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and acknowledges the authors' efforts to improve the paper. The reviewer provides detailed feedback and suggestions in a professional manner, without using harsh or dismissive language."", ""The sentiment score is 50 (moderately positive) because the reviewer starts by praising the paper as 'very interesting' and 'generally well written', but then lists several concerns and areas for improvement. This mix of positive and critical feedback suggests a balanced but overall positive sentiment. The politeness score is 60 (fairly polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions or questions (e.g., 'I would like to see...', 'It is not clear to me...') rather than direct criticisms. The reviewer also acknowledges the authors' work positively before offering critiques. However, the score is not higher as the review is primarily focused on improvements needed rather than praise."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('encouraging results'), they also point out several limitations and areas for improvement. The reviewer notes missing details, assumptions about the model's structure, and suggests additional experiments that could have been done. This indicates a somewhat critical stance, though not entirely negative. The politeness score is moderately positive (50) as the reviewer maintains a professional and objective tone throughout. They use neutral language to express their critiques and suggestions, avoiding harsh or dismissive phrasing. The review is constructive in nature, offering specific areas for improvement rather than outright criticism, which contributes to its politeness.""]"
"[""The authors design a program synthesizer that tries to satisfy per-instance specific syntactic and functional constraints,\nbased on sampling trajectories from an RL agent that at each time-step expands a partial-program.\n\nThe agent is trained with policy gradients with a reward shaped as the ratio of input/output examples that the synthesized program satisfies.\n\nWith the 'out-of-box' evaluation, the authors show that their agent can explore more efficiently the harder problems than their non-learning alternatives even from scratch.\n(My intuition is that the agent learns to generate the most promising programs)\nIt would be good to have a Monte Carlo Tree Search baseline on the'out-of-box' evaluation, to detect exploration exploitation trade-offs.\n\nThe authors show with the 'meta-solver' approach that the agent can generalize to and also speed up unseen (albeit easy-ish in the authors words) instances.\n\nClarity: Paper is clear and nicely written.\n\nSignificance: Imagine a single program synthesizer that could generate C++/Java/Python/DSLs  programs and learn from all its successes and failures! This is a step towards that.\n\nPros:\n+ Generating spec-following programs for different grammars.\n+ partial tree expansion takes care of syntactic constraints.\nNeutral\n· The grammar and specification diversity may be too low to feel impressive.\n· It would have been nicer by computing likelihood for unseen instances with unique and known solutions (that is, without finetuning).\nCons:\n- No Tree Search baseline.\n- No results on programs with control flow/internal state."", 'This paper presents a reinforcement learning based approach to learn a search strategy to search for programs in the generic syntax-guided synthesis (SyGuS) formulation. Unlike previous neural program synthesis approaches, where the DSL grammar is fixed or the specification is in the form of input-output examples only, the SyGuS formulation considers different grammars for different synthesis problems and the specification format is also more general. The main idea of the approach is to first learn a joint representation of the specification and grammar using a graph neural network model, and then train a policy using reinforcement learning to guide the search with a grammar adaptive policy network that is conditioned on the joint representation. Since the specifications considered here are richer logical expressions, it uses a SAT solver for checking the validity of the proposed solution and to also obtain counterexamples for future rewards. The technique is evaluated on 210 SyGuS benchmarks coming from the cryptographic circuit synthesis domain, and shows significant improvements in terms of number of instances solved compared to CVC4 and ESymbolic baseline search techniques from the formal methods community. Moreover, the learnt policy is also showed to generalize beyond the benchmarks on which it is trained and the meta-solver performs reasonably well compared to the per-task out-of-box solver.\n\nOverall, this paper tackles a more challenging synthesis problem than the ones typically considered in recent neural synthesis approaches. The previous synthesis approaches have mostly focused on learning programs in a fixed grammar (DSL) and with specifications that are typically based on either input-output examples or natural language descriptions. In the SyGuS formulation, each task has a different grammar and moreover, the specifications are much richer as they can be arbitrary logical expressions on program variables. The overall approach of using graph neural networks to learn a joint representation of grammars with the corresponding logical specifications, and then using reinforcement learning to learn a search policy over the grammar is quite interesting and novel. The empirical results on the cryptographic benchmarks compare favorably to state of the art CVC4 synthesis solver.\n\nHowever, there were some details in the model description and evaluation that were not very clear in the current presentation.\n\nFirst, the paper mentions that it uses the idea of Static Single Assignment (SSA) form for the graph representation. What is the SSA form of a grammar and of a specification? \n\nIt was also not very clear how the graphs are constructed from the grammar. For example, for the rule d1 -> X OR Y | d2 OR d2 in Figure 1, are there two d_OR nodes or a single node d_OR shared by both the rules? Similarly, what is the d_T node in the figure? It would be good to have a formal description of the nodes and edges in the graph constructed from the spec and grammar.\n\nSince the embedding matrix H_d can be of variable size (different sizes of expansion rules), it wasn’t clear how the policy learns a conditional distribution over the variable number of actions. Is there some form of padding of the matrix and then masking being used?\n\nFor the reward design, the choice of using additional examples in the set B_\\phi was quite interesting. But there was no discussion about how the interpolation technique works to generate more examples around a counterexample. Can you provide some more details on how the interpolation is being performed? \n\nAlso, how many examples were typically used in the experiments? It might be interesting to explore whether different number of examples lead to different results. How does the learning perform in the absence of these examples with the simple binary 0/1 reward?\n\nFrom last year’s SyGuS competition, it seems that the EUSolver solves 152 problems from the set of 214 benchmarks (Table 4 in http://sygus.seas.upenn.edu/files/SyGuSComp2017.pdf). For the evaluation, is ESymbolic baseline solver different that the EUSolver? Would it be possible to evaluate the EUSolver on the same hardware and timeout to see how well it performs on the 210 benchmarks? \n\nThe current transfer results are only limited to the cryptographic benchmarks. Since SyGuS also has benchmarks in many other domains, would it be interesting to evaluate the policy transfer to some other non-cryptographic benchmark domain?\n', 'This paper presents a (meta-)solver for particular program synthesis problems, where the model has access to a (logic) specification of the program to be synthesized, and a grammar that can change from one task instance to another. The presented model is an RL-based model that jointly trains 1) the joint graph-based embedding of the specification and the grammar, and 2) a policy able to operate on different (from instance to instance) grammars. Interestingly, not only can the model operate as a stand-alone solver, but it can be run as a meta-solver - trained on a subset of tasks, and applied (with tuning) on a new task. Experiments show that the model outperforms two baselines (one being a (near-to-)SOTA model) in the stand-alone setting and that the model successfully transfers knowledge (considers fewer candidates) in the meta-solving mode.\n\nFirst, I enjoyed reading the paper. I think the problem is interesting, particularly due to the model being able to train and operate on various grammars (from task to task), and not on a single, pre-specified grammar. The additional bonus is that the problem the paper solves does not require program as supervision, but an external verifier.\nThe evaluation shows that this approach not only makes sense but (significantly) outperforms, under same conditions, specialized program synthesis programs. However, there’s one issue here, and that’s what the comparison hasn’t been done to SOTA model but to a less performant model (see issues). \nThe particular approach of jointly training a specification+grammar graph embedding and learning a policy that acts on different grammars seems original and significant enough for publication.\nThe paper is well (with a few kinks) written, and mostly clear. There are still some issues in the paper.\n\nIssues:\n- The dataset used is 210 cryptographic circuit synthesis tasks from SyGuS 2017. Why only this particular subset of all the tasks, and not the other tasks/categories (there is 569 of them in total, no)?\n- Alur et al mention 214 examples in the said tasks, yet the paper says 210. Why?\n- The SyGuS results paper https://arxiv.org/abs/1711.11438 mentions EUSolver as the SOTA model, solving 152 tasks (out of 214). Why didn’t you compare your model to EUSolver?\n- The same paper reports CVC4 solving 117 tasks (out of 214), as opposed to 129 (out of 210) reported in your paper. Could you comment on the (possible) differences in the experimentation protocol?\n- you mention global graph embedding, but you never describe how you calculate it\n- abstract mentions outperforming two SOTA engines, but later you say ESymbolic is a baseline (which it seems by description)\n\nQuestions:\n- W for different edge types and different propagation steps t? Why is there a need for such a large number of parameters? What is the number of propagation steps?\n- In the extreme case where all inputs can be enumerated - how often does this happen in the tasks you solve?\n- figure 2 is not clear. There is too much information on one side (grammar) and too little on the other (what is the meaning of \\tau^(t-1)?)? Is the tree on the right a generated subtree?\n- details of the state s are unclear - it is tracked by an LSTM? Is there a concrete training signal for s, or is it a part of the architecture and everything is end-to-end trainable from the final reward? The same for s0=MLP(h(G)) - is that also trained in the same way?\n- can you provide some intuition on why you chose that particular architecture (state-tracking LSTM,  s0 as such, instead of something simpler?)\n- can you provide details on the state value estimator MLP architecture, as well as the s0 MLP, and the state-tracking LSTM?\n- the probability of each action (..) is defined as ….H_\\alpha^(i) - what does the i stand for? Was that supposed to be the t or \\alpha_t was supposed to be \\alpha_i?\n\nMinor stuff:\n- Figure 5a is referred to as Table 5a in the text\n- out-of-out-solver\n- global graph embedding, figure 1 - G(phi, G), figure 2 - h(G)\n- a figure of the policy architecture would be beneficial\n- Figure 1\n  - d_1 ->X OR Y in the graph is d1T, why isn’t it d1_OR, and connected to the OR node?\n  - why isn’t d1_OR connected to OR node?\n  - AST edge - but grammar is a DAG - (well, multigraph)\n  - what are the reversed links? e.g. if A->B, reversed link is B->A ?\n  - what is the meaning of the concrete figures in ‘one step’?\n- consider relating to ‘DREAMCODER: Bootstrapping Domain-Specific Languages for Neurally-Guided Bayesian Program Learning’ (https://uclmr.github.io/nampi/extended_abstracts/ellis.pdf), as it’s another model that steps away from the fixed-DSL story']","[60, 60, 60]","[70, 80, 80]","[""The sentiment score is 60 (positive) because the reviewer expresses several positive aspects of the paper, such as its clarity, significance, and potential impact. They mention pros like generating spec-following programs and handling syntactic constraints. The reviewer also notes that the paper is 'clear and nicely written.' However, they do point out some neutral points and cons, which prevent the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They offer balanced feedback, acknowledging both strengths and areas for improvement. The use of phrases like 'It would be good to have...' and 'It would have been nicer...' suggests polite recommendations rather than harsh criticism. The reviewer also uses positive phrases like 'Imagine a single program synthesizer...' to highlight the work's potential impact, which contributes to the overall polite tone."", ""The sentiment score is 60 (moderately positive) because the reviewer begins by highlighting the novelty and significance of the paper's approach, noting it tackles 'a more challenging synthesis problem' and uses an 'interesting and novel' method. The empirical results are also praised. However, the score is not higher because the reviewer raises several questions and areas for improvement in the latter part of the review. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as questions or suggestions rather than direct criticisms. Phrases like 'it would be good to have' and 'would it be interesting to' demonstrate a constructive and courteous tone. The reviewer also acknowledges the paper's strengths before delving into areas for improvement, which is a polite approach to peer review."", ""The sentiment score is 60 (positive) because the reviewer expresses enjoyment in reading the paper, finds the problem interesting, and acknowledges the significance and originality of the approach. They also highlight the model's ability to outperform baselines. However, they do point out some issues and questions, which prevents the score from being higher. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout, starting with positive comments, and framing criticisms as 'issues' and 'questions' rather than direct attacks. They use phrases like 'I enjoyed reading the paper' and 'Interestingly,' which contribute to a polite tone. The reviewer also provides constructive feedback and suggestions for improvement, which is a polite way to address shortcomings.""]"
"['In many machine learning applications, sorting is an important step such as ranking. However, the sorting operator is not differentiable with respect to its inputs. The main idea of the paper is to introduce a continuous relaxation of the sorting operator in order to construct an end-to-end gradient-based optimization. This relaxation is introduced as \\hat{P}_{sort(s)} (see Equation 4). The paper also introduces a stochastic extension of its method \nusing Placket-Luce distributions and Monte Carlo. Finally, the introduced deterministic and stochastic methods are evaluated experimentally in 3 different applications: 1. sorting handwritten numbers, 2. Quantile regression, and 3. End-to-end differentiable k-Nearest Neighbors.\n\nThe introduction of the differentiable approximation of the sorting operator is interesting and seems novel. However, the paper is not well-written and it is hard to follow the paper especially form Section 4 and on. It is not clear how the theoretical results in Section 3 and 4 are used for the experiments in Section 6. For instance:\n** In page 4, what is ""s"" in the machine learning application?\n** In page 4, in Equation 6, what are theta, s, L and f exactly in our machine learning applications?\n\nRemark: \n** The phrase ""Sorting Networks"" in the title of the paper is confusing. This term typically refers to a network of comparators applied to a set of N wires (See e.g. [1])\n** Page 2 -- Section 2 PRELIMINARIES -- It seems that sort(s) must be [1,4,2,3].\n\n[1] Ajtai M, Komlós J, Szemerédi E. An 0 (n log n) sorting network. InProceedings of the fifteenth annual ACM symposium on Theory of computing 1983 Dec 1 (pp. 1-9). ACM\n', 'After responses: I now understand the paper, and I believe it is a good contribution. \n\n================================================\n\nAt a high level, the paper considers how to sort a number of items without explicitly necessarily learning their actual meanings or values. Permutations are discrete combinatorial objects, so the paper proposes a method to perform the optimization via a continuous relaxation. \n\nThis is an important problem to sort items, arising in a variety of applications, particularly when the direct sorting can be more efficient than the two step approach of computing the values and then sorting.\n\nI like both the theoretical parts and the experimental results. In the context of ICLR, the specific theoretical modules comprise some cute results (Theorem 4; use of past works in Lemma 2 and Proposition 5). possibly of independent interest. The connections to the (Gumbel distribution <--> Plackett Luce) results are also nicely used. This Gumbel<-->PL result is well known in the social choice community but perhaps not so much in the ML community, and it is always nice to see more connections drawn between techniques in different communities. The empirical evaluations show quite good results.\n\nHowever, I had a hard time parsing the paper. The paper is written in a manner that may be accessible to readers who are familiar with this (or similar) line of research, but for someone like me who is not, I found it quite hard to understand the arguments (or lack of them) made in the paper connecting various modules. Here are some examples:\n\n- Section 6.1 states ""Each sequence contains n images, and each image corresponds to an integer label. Our goal is to learn to predict the permutation that sorts these labels"". One interpretation of this statement suggests that each row of Fig 3a is a sequence, that each sequence contains n=4 images (e.g., 4 images corresponding to each digit in 2960), and the goal is to sort [2960] to [0269]. However, according to the response of authors to my earlier comment, the goal is to sort [2960,1270,9803] to [1270,2960,9803]. \n\n- I did not understand Section 2.2.\n\n- I would appreciate a more detailed background on the concrete goal before going into the techniques of section 3 and 4.\n\n- I am having a hard time in connecting the experiments in Section 6 with the theory described in earlier sections. And this is so even after my clarifying questions to the authors and their responses. For instance, the authors explained that the experiments in Section 6.1 have \\theta as vacuous and that the function f represents the cross-entropy loss between permutation z and the true permutation matrix. Then where is this true permutation matrix captured as an argument of f in (6)? Is the optimisation/gradients in (7) over s or over the CNN parameters?\n', ""This work builds on a sum(top k) identity to derive a pathwise differentiable sampler of 'unimodal row stochastic' matrices. The Plackett-Luce family has a tractable density (an improvement over previous works) and is (as developed here) efficient to sample. \n\n[OpenReview did not save my draft, so I now attempt to recover it from memory.]\n\nQuestions:\n- How much of the improvement is attributable to the lower dimension of the parameterization? (e.g. all Sinkhorn varients have N^2 params; this has N params) Is there any reduction in gradient variance due to using fewer gumbel samples?\n- More details needed on the kNN loss (uniform vs inv distance wt? which one?); and the experiment overall: what k got used in the end?\n- The temperature setting is basically a bias-variance tradeoff (see Fig 5). How non-discrete are the permutation-like matrices ultimately used in the experiments? While the gradients are unbiased for the relaxed sort operator, they are still biased if our final model is a true sort. Would be nice to quantify this difference, or at least mention it.\n\nQuality:\nGood quality; approach is well-founded and more efficient than extant solutions. Fairly detailed summaries of experiments in appendices (except kNN). Neat way to reduce the parameter count from N^2 to N.\n\nI have not thoroughly evaluated the proofs in appendix.\n\nClarity:\nThe approach is presented well, existing techniques are compared in both prose and as baselines. Appendix provides code for maximal clarity. \n\nOriginality:\nFirst approach I've seen that reduces parameter count for permutation matrices like this. And with tractable density. Very neat and original approach.\n\nSignificance:\nMore scalable than existing approaches (e.g: only need N gumbel samples instead of N^2), yields better results.\n\nI look forward to seeing this integrated into future work, as envisioned (e.g. beam search)""]","[-20, 50, 80]","[50, 70, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting and novel idea, they also express significant concerns about the clarity and structure of the paper, especially from Section 4 onwards. The reviewer points out that it's hard to follow and that the connection between theoretical results and experiments is unclear. They also highlight specific areas of confusion and a potentially misleading title. These criticisms outweigh the initial positive remarks, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They phrase their concerns as questions or observations rather than direct attacks, and use neutral language like 'it is not clear' rather than more accusatory phrasing. The reviewer also provides specific examples and a reference to support their points, which is a constructive approach."", ""Sentiment Score (50): The review starts positively, stating 'I now understand the paper, and I believe it is a good contribution.' The reviewer praises aspects of the paper, including its theoretical parts and experimental results. However, they also express difficulties in understanding parts of the paper, which balances out the positive sentiment. This mix of positive feedback and constructive criticism leads to a moderately positive score.\n\nPoliteness Score (70): The reviewer maintains a professional and respectful tone throughout. They use phrases like 'I like both the theoretical parts and the experimental results' and 'it is always nice to see more connections drawn between techniques in different communities.' Even when expressing difficulties, they frame it politely: 'I had a hard time parsing the paper' rather than directly criticizing the authors. The reviewer also uses 'I would appreciate' when requesting more information, which is a polite way to make suggestions. The overall tone is constructive and courteous, hence the high politeness score."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the work, praising its originality, quality, clarity, and significance. They use phrases like 'Good quality', 'well-founded', 'more efficient', 'Very neat and original approach', and 'More scalable than existing approaches'. The reviewer also expresses enthusiasm about future applications. The score is not 100 as there are some questions and suggestions for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the strengths of the work, and frames suggestions as questions or areas for clarification rather than criticisms. The tone is professional and constructive. However, it's not extremely formal or overly deferential, hence not scoring 100.""]"
"['The paper proposes a method for neural network training under a hard energy constraint (i.e. the method guarantees the energy consumption to be upper bounded). Based on a systolic array hardware architecture the authors model the energy consumption of transferring the weights and activations into different levels of memory (DRAM, Cache, register file) during inference. The energy consumption is therefore determined by the number of nonzero elements in the weight and activation tensors. To minimize the network loss under an energy constraint, the authors develop a training framework including a novel greedy algorithm to compute the projection of the weight tensors to the energy constraint.\n\nPros:\n\nThe proposed method allows to accurately impose an energy constraint (in terms of the proposed model), in contrast to previous methods, and also yields a higher accuracy than these on some data sets. The proposed solution seems sound (although I did not check the proofs in detail, and I am not very familiar with hardware energy consumption subtleties).\n\nQuestions:\n\nThe experiments in Sec. 6.2 suggest that the activation mask is mainly beneficial when the data is highly structured. How are the benefits (in terms of weight and activation sparsity) composed in the experiments on Imagenet? How does the weight sparsity of the the proposed method compare to the related methods in these experiments? Is weight sparsity in these cases a good proxy for energy consumption?\n\nHow does the activation sparsity (decay) parameter (\\delta) q affect the accuracy-energy consumption tradeoff for the two data sets?\n\nThe authors show that the weight projection problem can be solved efficiently. How does the guarantee translate into wall-clock time?\n\nFilter pruning methods [1,2] reduce both the size of the weight and activation tensors, while not requiring to solve a complicated projection problem or introducing activation masks. It would be good to compare to these methods, or at least comment on the gains to be expected under the proposed energy consumption model.\n\nKnowledge distillation has previously been observed to be quite helpful when constraining neural network weights to be quantized and/or sparse, see [3,4,5]. It might be worth mentioning this.\n\nMinor comments:\n- Sec. 3.4. 1st paragraph: subscript -> superscript\n- Sec. 6.2 first paragraph: pattens -> patterns, aliened -> aligned\n\n[1] He, Y., Zhang, X., & Sun, J. (2017). Channel pruning for accelerating very deep neural networks. ICCV 2017.\n[2] Li, H., Kadav, A., Durdanovic, I., Samet, H., & Graf, H. P. Pruning filters for efficient convnets. ICLR 2017.\n[3] Mishra, A., & Marr, D. Apprentice: Using knowledge distillation techniques to improve low-precision network accuracy. ICLR 2018.\n[4] Tschannen, M., Khanna, A., & Anandkumar, A. StrassenNets: Deep learning with a multiplication budget. ICML 2018.\n[5] Zhuang, B., Shen, C., Tan, M., Liu, L., & Reid, I. Towards effective low-bitwidth convolutional neural networks. CVPR 2018.', 'The paper is dedicated to energy-based compression of deep neural networks. While most works on compression are dedicated to decreasing the number of parameters or decreasing the number of operations to speed-up or reducing of memory footprint, these approaches do not provide any guarantees on energy consumption. In this work the authors derived a loss for training NN with energy constraints and provided an optimization algorithm for it. The authors showed that the proposed method achieves higher accuracy with lower energy consumption given the same energy budget. The experimental results are quite interesting and include even highly optimized network MobileNetV2.\n\nSeveral questions and concerns.\n‘Our energy modeling results are validated against the industry-strength DNN hardware simulator ScaleSim’. Could the authors please elaborate on this sentence?\n\nOne of the main assumptions is the following. If the value of the data is zero, the hardware can skip accessing the data. As far as I know, this is a quite strong assumption, that is not supported by many architectures. How do the authors take into account overhead of using sparse data formats in such hardware in their estimations? Is it possible to simulate such behavior in ScaleSim? Moreover, in many modern systems DRAM can only be read in chunks. Therefore it can decrease number of DRAM accesses in (4).\n\nSmall typos and other issues:\nPage 8. ‘There exists an algorithm that can find an an \\epsilon’\nPage 8.’ But it is possible to fan approximate solution’\nPage 4.  It is better to put the sentence ‘where s convolutional stride’  after (2).\nIn formulation of the Theorem 3, it is better to explicitly state that A contains rational numbers only since gcd is used.\nOverall, the paper is written clearly and organized well, contains interesting experimental and theoretical results.\n', 'This paper describes a procedure for training neural networks via an explicit constraint on the energy budget, as opposed to pruning the model size as commonly done with standard compression methods.  Comparative results are shown on a few data sets where the proposed method outperforms multiple different approaches.  Overall, the concept is interesting and certainly could prove valuable in resource-constrained environments.  Still I retain some reservations as detailed below.\n\nMy first concern is that this paper exceeds the recommended 8 page limit for reasons that are seemingly quite unnecessary.  There are no large, essential figures/tables, and nearly the first 6 pages is just introduction and background material.  Likewise the paper consumes a considerable amount of space presenting technical results related to knapsack problems and various epsilon-accurate solutions, but this theoretical content seems somewhat irrelevant and distracting since it is not directly related to the greedy approximation strategy actually used for practical deployment.  Much of this material could have been moved to the supplementary so as to adhere to the 8 page soft limit.  Per the ICLR reviewer instructions, papers deemed unnecessarily long relative to this length should be judged more critically.\n\nAnother issue relates to the use of a mask for controlling the sparsity of network inputs.  Although not acknowledged, similar techniques are already used to prune the activations of deep networks for compression.  In particular, various forms of variational dropout essentially use multiplicative weights to remove the influence of activations and/or other network components similar to the mask M used is this work.  Representative examples include Neklyudov et al., ""Structured Bayesian Pruning via Log-Normal Multiplicative Noise,"" NIPS 2017 and Louizos et al., ""Bayesian Compression for Deep Learning,"" NIPS 2017, but there are many other related alternatives using some form of trainable gate or mask, possibly stochastic, to affect pruning (the major ML and CV conferences over the past year have numerous related compression papers).  So I don\'t consider this aspect of the paper to be new in any significant way.\n\nMoreover, for the empirical comparisons it would be better to compare against state-of-the-art compression methods as opposed to just the stated MP and SSL methods from 2015 and 2016 respectively.  Despite claims to the contrary on page 9, I would not consider these to be state-of-the-art methods at this point.\n\nAnother comment I have regarding the experiments is that hyperparameters and the use of knowledge distillation were potentially tuned for the proposed method and then simultaneously applied to the competing algorithms for the sake of head-to-head comparison.  But to me, if these enhancements are to be included at all, tuning must be done carefully and independently for each algorithm.  Was this actually done?  Moreover it would have been nice to see results without the confounding influence of distillation to isolate sources of improvement, but no ablation studies were presented.\n\nFinally, regarding the content in Section 5, the paper carefully presents an explicit bound on energy that ultimately leads to a constraint that is NP-hard just to project on to, although approximate solutions exist that depend on some error tolerance.  However, even this requires an algorithm that is dismissed as ""complicated.""  Instead a greedy alternative is derived in the Appendix which presumably serves as the final endorsed approach.  But at this point it is no longer clear to me exactly what performance guarantees remain with respect to the energy bound.  Theorem 3 presents a fairly inscrutable bound, and it is not at all transparent how to interpret this in any practical sense.  Note that after Theorem 3, conditions are described whereby an optimal projection can be obtained, but these seem highly nuanced, and unlikely to apply in most cases.\n\nAdditionally, it would appear that crude bounds on the energy could also be introduced by simply penalizing/constraining the sparsity on each layer, which leads to a much simpler projection step.  For example, a simple affine function of the L0 norm would be much easier to optimize and could serve as a loose bound on the energy, given that the latter should be a non-decreasing function of the L0 norm.  Any idea how such a bound compares to those presented given all the approximations and greedy steps that must be included?\n\n\nOther comments:\n- As an implementation heuristic, the proposed Algorithm 1 gradually decays the parameter q, which controls the sparsity of the mask M.  But this will certainly alter the energy budget, and I wonder how important it is to employ a complex energy constraint if minimization requires this type of heuristic.\n\n- I did not see where the quantity L(M,W) embedded in eq. (17) was formally defined, although I can guess what it is.\n\n- In general it is somewhat troublesome that, on top of a complex, non-convex deep network energy function, just the small subproblem required for projecting onto the energy constraint is NP-hard.  Even if approximations are possible, I wonder if this extra complexity is always worth it relative so simple sparsity-based compression methods which can be efficiently implemented with exactly closed-form projections.\n\n- In Table 1, the proposed method is highlighted as having the smallest accuracy drop on SqueezeNet.  But this is not true, EAP is lower.  Likewise on AlexNet, NetAdapt has an equally optimal energy.']","[60, 70, -40]","[80, 80, 20]","[""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's strengths, stating it 'allows to accurately impose an energy constraint' and 'yields a higher accuracy than these on some data sets'. The reviewer also mentions that the 'proposed solution seems sound'. However, it's not extremely positive as the reviewer raises several questions and suggests comparisons with other methods. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms as questions or suggestions (e.g., 'It would be good to compare...', 'It might be worth mentioning...'), and even points out minor typos in a constructive manner. The reviewer also acknowledges their own potential limitations ('I did not check the proofs in detail')."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, noting its interesting experimental results, clear writing, and good organization. They mention that the paper contains 'interesting experimental and theoretical results' and is 'written clearly and organized well'. However, it's not a perfect score as the reviewer does raise some questions and concerns. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, framing their concerns as questions rather than criticisms (e.g., 'Could the authors please elaborate...?'). They also balance their critique with positive feedback. The reviewer points out small typos in a constructive manner and concludes with a positive overall assessment, which contributes to the polite tone."", ""The sentiment score is -40 because while the reviewer acknowledges the paper's interesting concept and potential value, they express several significant concerns and reservations. These include issues with paper length, lack of novelty in some aspects, comparison with outdated methods, potential issues with hyperparameter tuning, and concerns about the complexity and practicality of the proposed method. The overall tone is more critical than positive. The politeness score is 20 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'I retain some reservations' and 'Another comment I have' rather than harsh or dismissive language. They also acknowledge positive aspects before presenting criticisms. However, the review is not overly polite or deferential, maintaining a neutral, academic tone for the most part.""]"
"['** Summary **\nThe authors propose a new training scheme with a learned auxiliary reward function to optimise transition policies, i.e. policies that connect the ending state of a previous macro action/option with good initiation states of the following macro action/option.\n\n** Quality & Clarity **\nThe paper is well written and features an extensive set of experiments.\n\n** Originality **\nI am not aware of similar work and believe the idea is novel.\n\n** Significance **\nSeveral recent papers have proposed to approach the topic of learning hierarchical policies not by training the hierarchy end-to-end, but by first learning useful individual behavioural patterns (e.g. skills) which then later can be used and sequentially chained together by higher-level policies. I believe the here presented work can be quite helpful to do so as the individual skills are not optimised for smooth composition and are therefore likely to fail when naively used sequentially.', 'The paper presents a method for learning policies for transitioning from one task to another with the goal of completing complex tasks. In the heart of the method is state proximity estimator, which measures the distance between states in the originator and destination tasks. This estimator is used in the reward for the transition policy. The method is evaluated on number of MojoCo tasks, including locomotion and manipulation.\n\nStrengths:\n+ Well motivated and relevant topic. One of the big downsides in the current state of the art is lack of understanding how to learn complex tasks. This papers tackles that problem.\n+ The paper is well written and the presentation is clear.\n+ The method is simple, yet original. Overall, an elegant approach that appears to be working well.\n+ Comprehensive evaluations over several tasks and several baselines.\n\nQuestions:\n- In the metapolicy, what ensures consistency, i.e. it selects the same policy in the consecutive steps?\n- Can the authors comment on the weaknesses and the limits of the method?', 'The paper proposes a scheme for transitioning to favorable starting states for executing given options in continuous domains. Two learning processes are carried out simultaneously: one learns a proximity function to favorable states from previous trajectories and executions of the option,  and the other learns the transition policies based on dense reward provided by the proximity function.\n\t\nBoth parts of the learning algorithms are pretty straightforward, but their combination turns out to be quite elegant. The experiments suggest that the scheme works,  and in particular does not get stuck in local minima. \n\nThe experiments involve fairly realistic robotic applications with complex options,  which renders credibility to the results.    \n\nOverall this is a nice contribution to the options literature. The scheme itself is quite simple and straightforward, but still useful. \n\nOne point that I would like to see elaborated is the choice of exponential (""discounted"") proximity function. Wouldn\'t a linear function of ""step"" be \n more natural here? The exponent loses sensitivity as the number of steps away increases, which may lead to sparser rewards.\n  \n']","[80, 80, 80]","[50, 70, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, describing it as 'well written' with 'extensive experiments', and noting its novelty and potential significance. They believe the work can be 'quite helpful' in the field. The politeness score is 50 (somewhat polite) as the reviewer uses professional and respectful language throughout, without being overly formal or effusive. They offer constructive comments and acknowledge the paper's strengths without using particularly warm or enthusiastic language. The tone is neutral and objective, which is appropriate for a scientific review, but doesn't go out of its way to be exceptionally polite."", ""The sentiment score is 80 (positive) because the review starts with a clear summary of the paper and then lists several strengths, using positive language like 'well motivated', 'relevant', 'well written', 'clear', 'elegant', and 'working well'. The reviewer also mentions 'comprehensive evaluations', which is a strong positive. The only slightly negative aspect is the presence of two questions at the end, but these are framed as inquiries rather than criticisms. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They acknowledge the paper's contributions and strengths without using overly effusive praise. The questions at the end are posed politely, asking for comments and clarification rather than demanding changes. The overall tone is constructive and collegial, maintaining a respectful distance while providing valuable feedback."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as a 'nice contribution' with an 'elegant' approach. They mention that the experiments are 'fairly realistic' and lend 'credibility to the results'. The overall tone is appreciative of the work. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, such as 'I would like to see elaborated' when suggesting improvements. They balance praise with constructive feedback, maintaining a professional and courteous tone. The reviewer avoids harsh criticism and frames their suggestion as a question, which is a polite way to offer feedback.""]"
"['This is a paper that communicates a large scale experiment on human object/semantic representations and a model of such representations.   The experiment could have been more carefully controlled (and described in the paper) and the modeling work is inconclusive.\n\nQuality, \nThe experiment design is conventional, based on rating pair-wise similarity among triplets. Compared to earlier experiments, this data has more objects and more triplets.  Additional control experiments on smaller subsets have been carried out to further address hypotheses.  The description of the experiment could have been more careful: What are the precise instructions, how are the object/images presented (it is well known that relative positions, asymmetry, etc can play an important role), are there any temporal/learning effects (how clear is the task to the workers?).\nThe modeling work is basic and contains a number of steps that have unknown influence on the final outcome. For example model dimension: Is you claim that ""D=49"" is a law of human nature?  Model predictive performance seems excellent, that is interesting! But we do not know how robust this is to the many heuristics\n\nClarity, \nThe presentation of the inference process is clear. Not so clear what the uncertainties are\n\nOriginality \nLimited. Mainly related to scale. But the data quality is unclear. The modeling approach involves a number of untested heuristics (non-negative, exponentiation etc). \n\nSignificance \nMostly related to the data.  I did not understand if it is planned to release the data.\n\nPros and cons \n\n+Large scale experiment\n+simple model, seem to have good accuracy\n\n-experiment needs more careful description\n-too many heuristics in model and inference, unclear how general the conclusions are\n\nOther comments:\nReferences have many issues\n\nThe authors have done a good job in the revision and have clarified points that were unclear in the first version. \nI have remaining reservations on significance, but move rating up a notch to reflect the extensive improvements and  the authors\' confirmation that they will release the data.\n\n\n', 'This is an interesting paper with a new approach to learn a sparse, positive (and hence interpretable) semantic space that maximizes human similarity judgements, by training to specifically maximize the prediction of human similarity judgements. The authors have collected the dataset themselves and have rating of sets of 3 objects from 1854 unique objects. They end up with a space (SPoSE) with relatively low dimensionality with respect to usual word embeddings (49 dimension) but perhaps not surprising when considering the small size of the words to embed. The authors run a set of experiment to show the usefulness of SPoSE. The most interesting one is the prediction of its dimensions by the CSLB features, which reveals a nice clustering in the different SPoSE dimensions. Perhaps the results would be a little more convincing if additional common word embeddings were also tested.\n\nDue to the different objects used in the different datasets, some of the experiments have a smaller set of words. A good extension of this work would be to combine a text-derived embedding  or the synsets to interpolate the SPoSE dimensions for missing words in the original set. Or perhaps the object similarity ratings could be used in a semi-supervised setting to inform the learning of a co-occurence word embedding. This will allow the model to better describe a larger set of words. Another possible extension is to test this larger set of words on a non-behavioral NLP task to show possible improvements that the behavioral data and the interpretable space give.\n\n', ""Following the suggested rubric:\n1. Briefly establish your personal expertise in the field of the paper.\n2. Concisely summarize the contributions of the paper.\n3. Evaluate the quality and composition of the work.\n4. Place the work in context of prior work, and evaluate this work's novelty.\n5. Provide critique of each theorem or experiment that is relevant to your judgment of the paper's novelty and quality.\n6. Provide a summary judgment if the work is significant and of interest to the community.\n\n1.  I work at the intersection of machine learning and biological vision\nand have worked on modeling word representations.\n\n2. This paper develops a new representation system for object\nrepresentations from training on data collected from odd-one-out human\njudgements of images.  The vector representation for objects is\ndesigned to be sparse and low dimensional (and ends up being about\n49D).  Similarity is measured by dot products in the space and\nprobabilities of which pair of items will be paired are modeled as the\nexponential of the similarity.\n\n\n3,5  The resulting embedding\tdoes a good job\tof predicting human similarity\njudgements and seems to cover similar features to those named by\nhumans.  They also explain typicality judgements and cluster semantic\ncategories well.   The creation of the upper limit based on noise between \nand within subjects was a nice addition.\n\n\n4. Some relevant related work is discussed and this seems like a novel\nand interesting contribution.  The authors might also want to compare\nto similar work that looked at similarities among triplets (Similarity\nComparisons for Interactive Fine-Grained Categorization\nhttp://ttic.uchicago.edu/~smaji/papers/similarity-cvpr14.pdf;\nConditional Similarity Networks https://arxiv.org/abs/1603.07810 ).\n\n\n6. While this paper is not especially surprising or ground breaking, the\nnumber and quality of the comparisons make it a worthwhile\ncontribution and the resulting embeddings are worth further exploration\nand could be very useful for future research.\n""]","[-20, 70, 60]","[50, 80, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Large scale experiment', 'simple model, seem to have good accuracy'), there are several criticisms and reservations expressed. The reviewer points out issues with experiment design, modeling work, and clarity of presentation. However, the reviewer also notes improvements in the revision, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They acknowledge the authors' efforts ('The authors have done a good job in the revision') and provide constructive feedback without using harsh or rude language. The reviewer balances criticism with positive remarks and presents their concerns in a diplomatic manner."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'interesting' with a 'new approach', and highlights several positive aspects such as the usefulness of SPoSE and the 'nice clustering' in the results. The reviewer also suggests extensions, which indicates engagement and interest in the work. The politeness score is 80 (polite) due to the use of respectful language throughout, such as 'interesting paper' and 'good extension'. The reviewer offers constructive suggestions without harsh criticism, maintaining a professional and courteous tone. The reviewer also acknowledges the authors' efforts in data collection and experimentation, further contributing to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally favorable view of the paper, noting its 'worthwhile contribution' and potential usefulness for future research. They highlight several strengths, such as the quality of comparisons and the novel approach. However, it's not extremely positive as they mention it's 'not especially surprising or ground breaking'. The politeness score is 80 (quite polite) due to the reviewer's constructive and respectful tone throughout. They offer balanced feedback, acknowledging both strengths and areas for improvement without harsh criticism. The language used is professional and courteous, offering suggestions rather than demands (e.g., 'The authors might also want to compare...'). The review follows a structured approach, addressing each point systematically and objectively, which contributes to its polite and professional tone.""]"
"['The algorithm described in this paper is part of the one-shot family of architecture search algorithms. In practice this means training an over-parameterized architecture, of which the architectures being searched for are sub-graphs. Once this bigger network is trained it is pruned into the desired sub-graph. The algorithm is similar to DARTS in that it it has weights that determine how important the various possible nodes are, but the interpretation here is stochastic, in that the weight indicates the probability of the component being active. Two methods to train those weights are being suggested, using REINFORCE and using BinaryConnect, both having different trade offs.\n\n- (minor) *cumbersome* network seems the wrong term, maybe over-parameterized network?\n- (minor) I do not think that the size of the search space a very meaningful metric\n\nPros:\n- Good exposition\n- Interesting and fairly elegant idea\n- Good experimental results\n\nCons\n- tested on a limited amount of settings, for something that claims that helps to automate the creation of architecture. I think this is the main shortcoming, although shared by many NAS papers\n- No source code available\n\nSome typos:\n\n- Fo example, when proxy strategy -> Fo*r* example\n- normal training in following ways. -> in *the* following ways\n- we can then derive optimized compact architecture.', 'It seems the authors propose an efficient method to search platform-aware network architecture aiming at high recognition accuracy and low latency. Their results on CIFAR-10 and ImageNet are surprisingly good.  But it is still hard to believe that the author can  achieve 2.08% error rate with only 5.7M parameter on CIFAR10 and 74.5% top-1 accuracy on ImageNet with less GPU hours/memories than prior arts.\n\nGiven my concerns above, the author must release their code and detail pipelines since NAS papers are difficult to be reproduced. \n\nThere is a small typo in reference part:\nJing-Dong Dong\'s work should be DPP-Net instead of PPP-Net (https://eccv2018.org/openaccess/content_ECCV_2018/papers/Jin-Dong_Dong_DPP-Net_Device-aware_Progressive_ECCV_2018_paper.pdf)\nand I think this paper ""Neural Architecture Optimization"" shoud be cited.', '\nThis paper addresses the problem of architecture search, and specifically seeks to do this without having to train on ""proxy"" tasks where the problem is simplified through more limited optimization, architectural complexity, or dataset size. The paper puts together a set of existing complementary methods towards this end, specifically 1) Training ""cumbersome"" networks as in One Shot and DARTS, 2) Path binarization to address memory requirements (optimized using ideas in BinaryConnect), and 3) optimizing a non-differentiable architecture using REINFORCE. The end result is that this method is able to find efficient architectures that achieve state of art performance with fewer parameters, can be optimized for non-differentiable objectives such as latency, and can do so with smaller amounts of GPU memory and computation.\n\nStrengths\n\n + The paper is in general well-written and provides a clear description of the methods.\n\n + Different choices made are well-justified in terms of the challenge they seek to address (e.g. non-differentiable objectives, etc.)\n\n + The results achieve state of art while being able to trade off other objectives such as latency\n\n + There are some interesting findings such as the need for specialized blocks rather than repeating blocks, comparison of architectures for CPUs vs. GPUs, etc. \n\nWeaknesses\n \n - In the end, the method is really a combination of existing methods (One Shot/DART, BinaryConnect, use of RL/REINFORCE, etc.). One novel aspect seems to be factorizing the choice out of N candidates by making it a binary selection. In general, it would be good for the paper to make clear which aspects were already done by other approaches (or if it\'s a modification what exactly was modified/added in comparison) and highlight the novel elements.\n\n - The comparison with One Shot and DARTS seems strange, as there are limitations place on those methods (e.g. cell structure settings) that the authors state they chose ""to save time"". While that consideration has some validity, the authors should explicitly state why they think these differences don\'t unfairly bias the experiments towards the proposed approach.\n\n - It\'s not clear that the REINFORCE aspect is adding much; it achieves slightly higher parameters when compared against Proxyless-G, and while I understand the motivation to optimize a non-differentiable function in this case the latency example (on ImageNet) is never compared to Proxyless-G. It could be that optimized the normal differentiable objective achieves similar latency with the smaller number of parameters. Please show results for Proxyless-G in Table 4.\n\n - There were several typos throughout the paper (""great impact BY automatically designing"", ""Fo example"", ""is build upon"", etc.)\n\n In summary, the paper presents work on an interesting topic. The set of methods seem to be largely pulled from work that already exists, but is able to achieve good results in a manner that uses less GPU memory and compute, while supporting non-differentiable objectives. Some of the methodological issues mentioned above should be addressed though in order to strengthen the argument that all parts of the the method (especially REINFORCE) are necessary. ']","[50, 50, 50]","[80, 60, 70]","[""The sentiment score is 50 (moderately positive) because the review begins with a neutral description of the algorithm, followed by a balanced list of pros and cons. The reviewer acknowledges 'good exposition', 'interesting and fairly elegant idea', and 'good experimental results', which are positive points. However, they also mention some limitations, such as limited testing settings and lack of source code. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, frames criticisms constructively (e.g., 'I think this is the main shortcoming'), and labels their suggestions as 'minor'. They also helpfully point out typos without being condescending. The overall tone is professional and courteous, aiming to provide constructive feedback rather than harsh criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the authors' proposed method as efficient and their results as 'surprisingly good'. However, they express skepticism about the claimed results, which tempers the positive sentiment. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, such as 'it seems' and 'I think'. They provide constructive feedback and even point out a typo in a considerate manner. The reviewer's request for code release is firm but politely phrased as a necessity rather than a demand. The overall tone is professional and courteous, while still expressing concerns and making requests for additional information."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges both strengths and weaknesses of the paper. They praise the clear writing, well-justified choices, and state-of-the-art results. However, they also point out several weaknesses, such as the combination of existing methods and some methodological issues. The overall tone is constructive rather than overtly negative or enthusiastic. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms as suggestions for improvement rather than harsh judgments. Phrases like 'It would be good for the paper to...' and 'Please show results for...' indicate a polite and constructive approach to feedback.""]"
"['The paper presents a novel end-to-end mechanistic generative model of electron flow in a particular type of chemical reaction (“Linear Electron Flow” reactions) . Interestingly, modeling the flow of electrons aids in the prediction of the final product of a chemical reaction over and above problems which attack this “product prediction problem” directly. The method is also shown to generalize well to held-out reactions (e.g. from a chemistry textbook).\n\nGeneral Impressions\n\n+ For me the biggest selling point is that it improves performance in predicting the ultimate reaction outcome. It should do because it provides strictly more supervision, but it’s great that it actually does. \n+ Because it models the reaction mechanism the model is interpretable, and it’s possible to enforce constraints, e.g. that dynamics are physically possible.\n+ Generalises outside of the dataset to textbook problems :-)\n+ Well-founded modeling choices and neural network architectures.\n- Only applies to a very particular type of reaction (heterolytic LEF). \n- Requires supervision on the level of electron paths. This seems to inhibit applying the model to more datasets or extending it to other types of reactions.\n- Furthermore the supervision extraction does not seem take advantage of symmetries noted in the section(s) about difficulty evaluating inference. \n- It would be nice to margin out the electron flow model and just maximize the marginal likelihood for the product prediction problem.\n\nNovelty\nI’m not an expert on the literature of applying machine learning to the problems of reaction {product, mechanism} prediction but the paper appears to conduct a thorough review of the relevant methods and occupy new territory in terms of the modeling strategy while improving over SOTA performance.\n\nClarity\nThe writing/exposition is in general extremely clear. Nicely done. There are some suggestions/questions which I think if addressed would improve clarity.\n\nWays to improve the paper\n1. Better motivate the use of machine learning on this problem. What are the limitations of the arrow-pushing models? \n\n2. Explain more about the Linear Electron Flow reactions, especially:\n- Why does the work only consider “heterolytic” LEF reactions, what other types of LEF reactions are omitted?\n- Is the main blocker to extending the model on the modeling front or the difficulties of extracting ground-truth targets? It appears to be the latter but this could be made more clear. Also that seems to be a pretty severe limitation to making the algorithm more general. Could you comment on this?\n\nQuestions\n1. Is splitting up the electron movement model into bond “removal” and “addition” steps just a matter of parameterization or is that physically how the movements work? \n\n2. It appears that Jin et al reports Top 6/8/10 whereas this work reports Top 1/3/5 accuracy on the USPTO dataset. It would be nice if there was overlap :-). Do your Top 6/8/10 results with the WLDN model agree with the Jin et al paper?\n\n\nNits\nSection 2.3, first paragraph “...(LEF) topology is by far the most important”: Could you briefly say why? It’s already noted that they’re the most common in the database. Why?\n\nSection 3.ElectionMovement, first paragraph. “Observer that since LEF reactions are a single path of electrons…”. Actually, it’s not super clear what this means from the brief description of LEF. Can you explain these reactions in slightly more detail?\n\nSection 3.ElectionMovement, second paragraph. “Differently, the above distribution can be split…”. Awkward phrasing. How about “In contrast, the above distribution can be split…”. \n\nSection 3.Training, last sentence “...minibatches of size one reaction”. Slightly awkward phrasing. Maybe “...minibatches consisting of a single reaction”?\n\nSection 5.2, second sentence. “However, underestimates the model’s actual predictive accuracy…”. It looks like a word accidentally got deleted here or something.\n\nSection 5.2, paragraph 4. “To evaluate if our model predicts the same major project”... Did you mean “the same major product”?\n\n', 'Review of ""A Generative Model for Electron Paths""\n\nPaper summary:\n\nThe paper proposes a new model for predicting arrow-pushing chemical\nreaction diagrams from raw reaction data.\n\nSection 1 summarizes the motivation: whereas other models only predict\nchemical reaction products from reactants, the proposed model attempts\nto also predict the reaction mechanism.\n\nSection 2 provides a background on related work. Previous models for\nmechanism prediction are limited to work which require expert-curated\ntraining sets. The proposed model is designed for a subset of\nreactions called ""linear electron flow"" (LEF) which is\nexplained. Contributions of this paper are an end-to-end model, a\ntechnique for identifying LEF reactions/mechanisms from\nreaction/product data, and an empirical study of how the model learns\nchemical knowledge.\n\nSection 3 explains the proposed generative model, which represents a molecule\nusing a graph (nodes are atoms and edges are bonds). It is proposed to\nlearn a series of electron actions that transform the reactants into\nthe products. The total probability is factorized into three parts:\nstarting location, electron movement, and reaction\ncontinuation. Figure 2 and Algorithm 1 are helpful.\n\nSection 4 explains the proposed method for creating mechanism data\nfrom chemical reactant/product databases. Figure 3 is helpful.\n\nSection 5 discusses results of predicting mechanisms and products on\nthe USPTO data set.\n\nComments:\n\nStrong points of the paper: (1) it is very well written and easy to\nunderstand, (2) the chemical figures are very well done and helpful,\nand (3) the method for predicting mechanisms seems to be new.\n\nThe major weak point of the paper is the results section, which needs\nto be improved before publication.\n\nIn particular Tables 2-3 (comparison of prediction accuracy) need to\nshow some measure of variance (standard deviation or confidence\ninterval) so the reader can judge if there is any significant\ndifference between models. Please use K-fold cross-validation, and\nreport mean/sd of test accuracy over the K test folds.\n\nThe term ""end-to-end"" should be defined. In section 2.2 it is written\n""End-to-End: There are many complex chemical constraints that limit\nthe space of all possible reactions. How can we differentiate through\na model subject to these constraints?"" which should be clarified using\nan explicit definition of ""end-to-end.""\n\nAlso there needs to be some comparison with baseline methods for\npredicting mechanisms.  It is claimed that no comparison can be made\nagainst the previous methods for mechanism prediction (Section 2.2),\nbecause ""they require expert-curated training sets, for which organic\nchemists have to hand-code every electron pushing step."" However the\ncurrent paper proposes a method for generating such steps/data for LEF\nreactions. So why not use those data to train those baseline models,\nand compare with them? That would make for a much stronger paper. Please\nadd at least one of the methods discussed in section 2.2 to your\naccuracy comparison in Table 2.\n\nIt would additionally be helpful to know what the ""uninformed\nbaseline"" / ""ignore the inputs"" / ""random guessing"" accuracy rates are\non your data set. For example in classification the uninformed\nbaseline always predicts the class which is most frequent in the\ntraining data, and in regression it predicts the mean of the\nlabels/outputs in the training data. What would the analogy be for\nyour two problems? (product and mechanism prediction)\n', 'Summary:\nThe paper presents a novel method for predicting organic chemical reactions, in particular, for learning (Robinson-Ingold\'s) \'\'arrow pushing"" mechanisms in an end-to-end manner. Organic molecules consist of covalent bonds (that\'s why we can model them as molecular graphs), and organic reactions are recombinations of these bonds. As seen in organic chemistry textbooks, traditional chemists would qualitatively understand organic reactions as an alternating series of electron movements by bond breaking (bond cleavage) and bond forming (bond formation). Though now quantum chemistry calculations can give accurate quantitative predictions, these qualitative understanding of organic reactions still also gives strong foundations to consider and develop organic reactions. The proposed method tries to learn these series of bond changes directly through differentiable architectures consisting of three graph neural networks: 1) the one for determining the initial atom where electron movements start, 2) the one for representing state transitions from  the previous bond change to the next, and 3) the one for determining when the electron movements end. Experimental evaluations illustrate the quantitative improvement in final product prediction against existing methods, as well as give chemical intuitions that the proposed method can detect a class of LEFs (linear electron flows).\n\nComment:\n- This study is a quite interesting contribution because many existing efforts focus on improving differentiable architecture design for graph transformation and test it using chemical reaction data without considering what is learned after all. In contrast, this paper gives the clear meaning to predict ""arrow pushing"" mechanism from chemical reaction data and also makes sure the limitation to LEFs that are heterolytic. Traditional graph rewrite systems or some recent methods directly borrowing ideas from NLP do not always give such clear interpretations even though it can somehow predict some outputs.\n\n- The presentation of the paper is clear and in very details, and also provides intuitive illustrative examples, and appendix details on data, implementations, and related knowledge. \n\n- The architecture is based on graph neural networks, and seem natural enough. Basically, I liked overall ideas and quite enjoyed them but several points also remained unclear though I\'m not sure at all about chemical points of view.\n\n1) the state transition by eq (2)-(4) seems to assume 1-st order Markovian, but the electron flow can have longer dependence intuitively. Any hidden states are not considered and shared between these networks, but is this OK with the original chemical motivations to somehow model electron movements? The proposed masking heuristics to prevent stalling would be enough practically...? (LEF limitations might come from this or not...?)\n\n2) One thing that confuses me is the difference from approaches a couple of work described at the beginning of section \'Mechanism prediction (p.3)\', i.e. Fooshee et al 2018; Kayala and Baldi, 2011, 2012; Kayala et al, 2011. I don\'t know much about these studies, but the paper describes as ""they require expert-curated training sets, for which organic chemists have to hand-code every electron pushing step"". But for ""Training"" (p.6) of the proposed method, it also describes ""this is evaluated by using a known electron path and intermediate products extracted from training data"". Does this also mean that the proposed method also needs a correct arrow pushing annotations for supervised learning?? Sounds a bit contradicting statements?\n\n3) Is it just for computational efficiency why we need to separate reactants and reagents? The reagent info M_e is only used for the network for ""starting location"", but it can affect any intermediate step of elementary transitions intuitively (to break through the highest energy barrier at some point of elementary transitions?). Don\'t we need to also pass M_e to other networks, in particular, the one for ""electron movement""?\n']","[60, 50, 60]","[80, 80, 80]","[""The sentiment score is 60 (positive) because the reviewer starts with a positive overview of the paper, highlighting its novel approach and improvements over existing methods. They list several positive points (prefixed with '+') before mentioning some limitations (prefixed with '-'). The overall tone is constructive and appreciative of the work's contributions.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout. They offer constructive criticism and suggestions for improvement without being harsh or dismissive. Phrases like 'Nicely done' and the use of smiley faces (':-)') add a friendly tone. The reviewer also frames their criticisms as 'Ways to improve the paper' rather than outright flaws, which is a polite approach.\n\nThe reviewer maintains a balanced perspective, acknowledging both strengths and limitations of the work. They provide specific, actionable feedback and ask clarifying questions, which demonstrates engagement with the paper and respect for the authors' work. The language used is consistently professional and courteous, even when pointing out areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by highlighting strong points of the paper, calling it 'very well written and easy to understand' with 'very well done and helpful' figures. However, they also point out a 'major weak point' and provide several suggestions for improvement, balancing the positive and negative aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions ('Please use K-fold cross-validation...') and asking questions rather than making demands ('Why not use those data to train those baseline models...?'). The reviewer also acknowledges the paper's strengths before discussing areas for improvement, which is a polite approach to giving feedback."", ""The sentiment score is 60 (positive) because the reviewer expresses interest in the study, calling it 'quite interesting' and stating they 'liked overall ideas and quite enjoyed them'. They also praise the clear presentation and detailed appendix. However, they do raise some questions and concerns, which prevents the score from being higher. The politeness score is 80 (polite) due to the reviewer's consistently respectful tone. They use phrases like 'I liked', 'I'm not sure', and frame their concerns as questions rather than criticisms. The reviewer also balances critique with praise, acknowledging the paper's strengths before discussing potential issues. This approach maintains a constructive and courteous tone throughout the review.""]"
"['This paper presents a methodology to infer shape programs that can describe 3D objects. The key intuition of the shape programs is to integrate bottom-up low-level feature recognition with symbolic high-level program structure, which allows the shape programs to capture both high-level structure and the low-level geometry of the shapes. The paper proposes a domain-specific language for 3D shapes that consists of “For” loops for capturing high-level regularity, and associates objects with both their geometric and semantic attributes. It then proposes an end-to-end differentiable architecture to learn such 3D programs from shapes using an interesting self-supervised mechanism. The neural program generator proposes a program in the DSL that is executed by a neural program execution module to render the corresponding output shape, which is then compared with the original shape and the difference loss is back-propagated to improve the program distribution. The technique is evaluated on both synthetic and ShapeNet tasks, and leads to significant improvements compared to Tulsiani et al. that embed a prior structure on learning shape representations as a composition of primitive abstractions. In addition, the technique is also paired with MarrNet to allow for a better 3D reconstruction from 2D images.\n\nOverall, this paper presents an elegant idea to describe 3D shapes as a DSL program that captures both geometric and spatial abstractions, and at the same time captures regularities using loops. CSGNet [Sharma et al. 2018] also uses programs to describe 2D and 3D shapes, but the DSL used here is richer as it captures more high-level regularities using loops and also semantic relationships such as top, support etc. The idea of training a neural program executor and using it for self-supervised training is quite elegant. I also liked the idea of guided adaption to make the program generator generalize beyond the synthetic template programs. Finally, the results show impressive improvements and generalization capability of the model.\n\nCan the authors comment on some notion of completeness of the proposed DSL? In other words, is this the only set of operators, shapes, and semantics needed to represent all of ShapeNet objects? Also, it might be interesting to comment more on how this particular DSL was derived. Some of the semantics operator such as “Support”, “Locker”, etc. look overly specific to chair and tables. Is there a way to possibly learn such abstractions automatically?\n\nWhat is the total search space of programs in this DSL? How would a naive random search perform in this synthesis task?\n\nI also particularly liked the decomposition of programs into draw and compound statements, and the corresponding program generator decomposition into 2 steps BlockLSTM and StepLSTM. At inference time, does the model use some form of beam search to sample block programs or are the results corresponding to top-1 prediction?\n\nWould it be possible to compare the results to the technique presented in CSGNet [Sharma et al. 2018]?  There are some key differences in terms of using lower-level DSL primitives and using REINFORCE for training the program generator, but it would be good to measure how well having higher-level primitives improve the results.\n\nI presume the neural program executor module was trained using a manually-written shape program interpreter. How difficult is it to write such an interpreter? Also, how easy/difficult is to extend the DSL with new semantics operator and then write the corresponding interpreter extension?\n\nMinor typos:\npage 3: consists a variable → consists of a variable\npage 5: We executes → We execute\npage 6: synthetica dataset → synthetic dataset\n', 'This paper introduces a high-level semantic description for 3D shapes. The description is given by the so-called ShapeProgram,  Each shape program consists of several program statements. A program statement can be either Draw, which describes a shape primitive as well as its geometric and semantic attributes, or For, which contains a sub-program and parameters specifying how the sub-program should be repeatedly executed. The ShapeProgram is connected with an input through two networks, the program generator (encoder) and a neural program executor (decoder). Both encoder/decoder are implemented using LSTM. The key ML contribution is on the decoder, which leverages a parametrization to make the decoder differentiable. The major advantage of the proposed technique is that it does not need to specify the ShapeProgram in advance. In the same spriit of training an auto-encoder. It can be learned in a semi-supervised manner. However, in practice, one has to start with a reasonably good initial program. In the paper, this initial program was learned from synthetic data. \n\nThe paper presents many experimental results, including evaluation on synthetic datasets, guided adaptation on ShapeNet, analysis of stability, connectivity measurement, and generalization, and application in shape completion. The presented evaluations, from the perspective of proposed experiments, is satisfactory. \n\nOn the downside, this paper does not present any baseline evaluation, party due to the fact that the proposed problem is new. In fact, existing inverse procedural modeling techniques require the users to specify the program. However, the proposed approach could be even more convincing if it evaluates the performance of semantic understanding. For example, would it be possible to evaluate the performance on shape segmentation?\n\nAdditional comments:\n1. How important is the initial program? \n\n2. The interactions among shape parts usually form a graph, not necessarily hierarchical. This should be discussed.\n\n3. What is the difference between 3D shapes and 3D scenes? Does this approach require a front/up-right orientation?\n\n4. It would be interesting to visualize/analyze the intermediate representations of the neural shape generator. Does it encode meaningful distributions among shape parts?\n\nOverall, it is a good paper, and I would like to see it at ICLR 2019.\n', ""This paper presents an approach to infer shape programs given 3D models. The programs include placing and arranging predefined primitives in layouts and can be written as a program over a domain-specific language (DSL). \n\nThe architecture consists of a recurrent network that encodes a 3D shape represented as a voxel grid and outputs the instructions using a LSTM decoder. The generation is two-step where the first step predicts a program ID and the second step predicts instructions within the program ID. This aspect wasn't completely clear to me, see questions below. A second module that renders the program to 3D is also implemented as a neural network in order to optimize the model parameter in a end-to-end manner by minimizing a reconstruction loss. \n\nThe method is evaluated on 3D shape reconstruction tasks for chairs and tables categories of the ShapeNet dataset. The approach compares favorably to Tulsiani et al., which considers a shape to be composed of a fixed number of cuboids.\n\nThe paper is well written and investigates an important problem. But it is hard to tease of the contributions and the relative importance of various steps in the paper:\n\n1. Structure search vs. prediction. How does the model perform relative to a search-based approach for program generation. That would be slower but perhaps more accurate. The prediction model can be thought of an amortized inference procedure for search problems. What advantages does the approach offer?\n\n2. Choice of the DSL. Compared to CSG modeling instructions of Sharma et al. the proposed DSL is more targeted to the shape categories. While this restricts the space of programs (e.g., no intersection, subtraction operations are used) leading to better generation of chairs and tables, it also limits the range and generalization of the learned models to new categories. Some discussion and comparison with the choice of DSL would be useful. \n\n3. Is the neural render necessary -- Wouldn't it be easier to simply use automatic differentiation to compute gradients of the rendering engine? \n\n4. It is also not clear to me how having a differentiable renderer allows training in an end-to-end manner since the output space is discrete and variable length. In CSGNet (Sharma et al.) policy-gradient techniques were used to optimize the LSTM parameters. The details of the guided adaptation were unclear to me (Section 4.3).\n\n5. Is the neural renderer reliable -- Is is not clear if the neural renderer can provide accurate gradients when the generated programs are incorrect since the model is trained on a clean samples. In practice this means that the encoder has to initialized well. Since the renderer is also learned, would it generalize to new programs within the same DSL but different distribution over primitives -- e.g., a set of tables that have many more legs. Some visualizations of the generated shapes from execution traces could be added, sampling programs from within and outside the program distributions used to train.\n\n6. All the above points give an impression that the choice of DSL and careful initialization are important to get the model to work. Some discussion on how robust the model is to these choices would be useful. In other words how meaningful is the generalization from the supervised training set of templates chairs and tables? \n\n7. Missing baselines: The model is trained on 100,000 chairs and tables with full supervision. What is the performance of a nearest neighbor prediction algorithm? This is an important baseline that is missing. A comparison with a simplified CSGNet with shape primitives and union operations is also important. Tulsiani et al. consider unions but constrain that all instances have the same number of primitives which can lead to poor reconstruction results. Furthermore the training sets are likely different making evaluations unclear. I suggest training the following decoders on the same training set used in this approach (1) fixed set of cuboids (e.g., Tulsiani et al.), (2) A recurrent decoder with cuboids, (3) CSGNet (different primitives and operations), (4) a nearest neighbor predictor with the Hamming or Chamfer distance metric. ""]","[80, 60, -20]","[90, 70, 60]","[""The sentiment score is 80 (positive) because the reviewer uses phrases like 'elegant idea', 'impressive improvements', and 'I liked the idea', indicating strong approval of the paper. They also highlight several strengths and innovations of the work. The score is not 100 as the reviewer does raise some questions and suggestions for improvement. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'Can the authors comment on...' and 'It might be interesting to...' when making suggestions, showing courtesy. They also acknowledge the paper's strengths before offering critiques. The score is not 100 as the language, while polite, doesn't go to extremes of formality or deference."", ""The sentiment score is 60 (positive) because the reviewer generally expresses a favorable view of the paper, noting its contributions and advantages. They state it's a 'good paper' and recommend it for ICLR 2019. However, they also point out some limitations and areas for improvement, which prevents the score from being higher. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as questions or possibilities rather than demands. They acknowledge the paper's strengths before discussing potential improvements, which is a polite approach. The tone is professional and courteous, without any harsh or rude language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the paper is well-written and investigates an important problem, they raise several critical points and questions about the methodology, contributions, and missing comparisons. The review is not overwhelmingly negative, but it does highlight significant areas for improvement.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They begin with positive comments about the paper being well-written and addressing an important problem. The criticisms are presented as questions or suggestions for improvement rather than harsh criticisms. Phrases like 'Some discussion and comparison would be useful' and 'I suggest' indicate a constructive tone.\n\nOverall, the review maintains a balance between acknowledging the paper's merits and providing detailed, constructive feedback for improvement, which is reflected in the slightly negative sentiment but positive politeness scores.""]"
"[""This paper describes a method for improving the (sequence-length) scalability of the Transformer architecture, with applications to modeling long-range interactions in musical sequences. The proposed improvement is applied to both global and local relative attention formulations of self-attention, and consists of a clever re-use (and re-shaping) of intermediate calculations. The result shaves a factor of L (sequence length) from the (relative) memory consumption, facilitating efficient training of long sequences. The method is evaluated on MIDI(-like) data of Bach chorales and piano performances, and compares favorably to prior work in terms of perplexity and a human listener evaluation.\n\nThe results in this paper seem promising, though difficult to interpret.  The quantitative evaluation consists of perplexity\nscores (Tables 2 and 3), and the qualitative listening study is analyzed by pairwise comparisons between methods. While the proposed method achieves the highest win-rate in the listening study, other results in the study (LSTM vs Transformer) run contrary to the ranking given by the perplexity scores in Table 3. This immediately raises the question of how perceptually relevant the (small) differences in perplexity might be, which in turn clouds the overall interpretation of the results. Of course, perplexity is not the whole story here: the focus of the paper seems to be on efficiency, not necessarily accuracy, but one might expect improved efficiency to afford higher model capacity and improve on accuracy.\n\n\nThe core contributions of this work are described in sections 3.4 and 3.5, and while I get the general flavor of the idea, I find the exposition here both terse and difficult to follow. Figures 1 and 2 should illustrate the core concept, but they lack axis labels (and generally sufficient detail to decode properly), and seem to use the opposite color schemes from each-other to convey the same ideas.  Concrete image maps using real data (internal feature activations) may have been easier to read here, along with an equation that describes how the array indices map after skewing.\n\nThe description in 3.4 of the improved memory enhancement is also somewhat difficult to follow.  The claim is a reduction from O(DL^2) to O(DL), but table 1 lists this as O(DL^2) to O(DL + L^2).  In general, I would expect L to dominate D, which still leaves the memory usage in quadratic space, so it's not clear how or why this constitutes an improvement. The improvement due to moving from global to local attention is clear, but this does not appear to be a contribution of this work."", 'In this paper the authors propose an algorithm to reduce the memory\nrequirements for calculating relative position vectors in a\nself-attention (transformer) network, based on the work of [Vaswani et\nal., 2017; Shaw et al. 2018]. The authors applied their model to a music\ngeneration task, and evaluated it on two datasets (J.S. Bach Chorales\nand Piano-e-Competition). Their model obtained improvements over the\nstate-of-the-art in the Piano-e-Competition set in terms of\nlog-likelihoods. Additionally, they performed human evaluation on the\nPiano-e-Competition set showing preference of the participants for their\nmethod over the state-of-the-art.\n\nThe application of the transformer network seems suitable for the task,\nand the authors fairly justify their motivations and choices. They show\nimprovements over the-state-of-the-art for one data-set and explained\ntheir results. They also show an interesting application of\nsequence-to-sequence models for generating complete pieces of music\nbased on a given melody.\n\nMy main concern is the novelty of the paper. The authors use the model\nproposed by [Shaw et al. 2018] with an additional modification to manage\nvery long sequences proposed by [Liu et al., 2018; Parmar et al., 2018],\n(chunking the input sequences in non-overlaping blocks and calculating\nattention only on the current and the previous blocks). Their main\ncontribution is to reduce the memory requirement for matrix operations\nfor calculating the relative position vectors of the self-attention\nfunction, which was sub-optimal in [Shaw et al. 2018]. The memory\nreduction is from O(L^2D+L^2) to O(LD+L^2). I would qualify this as an\noptimization in the implementation of the existing method rather than a\nnew approach.', 'The authors address the problem raised by applying a fully attentional network (FAN) to model music. \nThey argue clearly for the need of relational positional embedding in that problem (instead of absolute positional as in vanilla FAN), and highlight the quadratic memory footprint of the current solution (Shaw et al. 2018).\n\nThe main contribution of the paper is a solution to this, consisting in a smart idea (sect 3.4.1 and 3.4.2) which allows them to compute relative embeddings without quadratic overhead.\nThe model performs indeed better than Shaw et al.\'s on the single data-set they compared both. On the other one, the argument is that Shaw et al. 2018 cannot be applied because the sequences are too long.\n\nI have two concerns with the paper:\n\t1/ it is very hard to read at times. In particular, the main contribution took me several passes the understand. I list below a few recommendations for improvement \n\t2/ the main argument is that the model requires less memory and is faster. However, the only empirical evidence in that direction is given in the introduction (Sect 1.1., second paragraph).\n\t\tThe following points remain unclear to me:\n\t\t\ta) why can\'t the Relative Transformer be applied to Piano-e composition. What is the maximal length that is possible?\n\t\t\tb) how much faster / less memory is the relative music transformers? The only data-point is in Sect 1.1., which seems indeed impressive (but then one wonders why this is not exploited further). A deeper analysis of the comparative memory footprint would greatly strengthen the paper in my opinion.\n\t\t\t\nWhy ""music"" relative transformers? Nothing in the model restrict it to that use case. The use of FAN over audio has been explored with limited success, one of the reasons being that - similarly to this use-case here - audio sequences tend to be longer than text.\n\t\t\nminor comments:\n\t- abstract, ln9: there seems to be a verb missing\n\t- p1,ln-2: ""dramatic"" improvements seems to be exaggerated\n\t- p2,ln11: ""too long"". too long for what?\n\t- p4,ln15: (Table 1). is one sentence by itself. Also, a clear explanation of that table is missing\n\t- p5,item 2: an explanation in formula would be helpful for those not familiar with reshaping\n\t- Fig3: it seems very anecdotical. Similar green bloxes might be placed on the left plot\n\t- sect4.1.1,ln3. that sentence does not parse\n\t- Table 2: what is cpsi?\n\t- $l$ is nicer formatted as $\\ell$\n\t- care should be taken to render the Figures more readable (notably the quality of Fig 4, and labels of Fig 7)\n\t- footnotes in Figures are not displayed (Table 2 and 4)\n\t- the description of the human evaluation leaves some open questions. I could not come up with 180 ratings (shouldn\'t it be 180 * 3 ratings?). Also, at least the values of Relative Transformer vs other 3 models should be shown (or all 6 comparisons). Here you call ""relative transformer"" your model, previously you used that term to refer to (Shaw et al. 2018).\n\t\twhen reporting statistical significance, there are some omissions which should be clarified.\n\t- (Shaw et al. 2018) has been published at NAACL. For such an important citation, you should update the reference from the arxiv version.\n', ""This paper presents an implementation trick to reduce the memory footprint of relative attention within a transformer network. Specifically, the paper points out redudant computation and storage in the traditional implementation and re-orders matrix operations and indexing schemes to optimize. As an appllication, the paper applies the new implementation to music modeling and generation. By reducing the memory footprint, the paper is able to train the transformer with relative attention on longer musical sequences and larger corpora. The experimental results are compelling -- the transformer with relative attention outperforms baselines in terms of perplexity on development data (though test performance is not reported) and by manual evaluation in a user study.\n\nOverall, I'm uncomfortable accepting this paper in its current form because I'm not sure it constitutes a large enough unit of novel work. The novelty here, as far as I can tell, is essentially an implementation trick rather than an algorithm or model. Transformer networks have been applied to music in past work -- the only difference here is that because of the superior implementation the model can be trained from larger musical sequences. All that said, I do think the proposed implementation is useful and that the experimental results are compelling. Clearly, when trained from sufficient data, transformer networks have something to offer that is different from past techniques.""]","[-20, 50, -20, -20]","[50, 80, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges that the results seem promising, they express several concerns and criticisms. They find the results difficult to interpret, question the relevance of the perplexity differences, and describe the core sections as 'terse and difficult to follow'. They also point out inconsistencies in the memory improvement claims. However, the tone isn't entirely negative, as they do recognize the potential of the work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'seem promising' and 'clever re-use', which are encouraging. Even when expressing criticisms, they do so in a constructive manner, suggesting improvements (e.g., 'Concrete image maps... may have been easier to read here'). The language is not overly formal or deferential, but it avoids any harsh or rude phrasing, maintaining a balanced and objective tone typical of academic peer reviews."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as improvements over state-of-the-art and justification of choices, but also expresses concerns about novelty. The positive aspects are balanced with the criticism, resulting in a moderately positive sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' work, and frames the criticism constructively. The reviewer uses phrases like 'The authors fairly justify their motivations' and 'They show improvements,' which demonstrate respect for the authors' efforts. Even when expressing concerns, the reviewer maintains a professional and courteous tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions and clear arguments, they express two main concerns about readability and lack of empirical evidence. The reviewer also provides a list of minor comments and suggestions for improvement, indicating that the paper needs significant revisions. However, the tone is not entirely negative, as the reviewer recognizes the value of the work. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, framing their concerns as suggestions rather than harsh criticisms. They use phrases like 'I have two concerns' and 'The following points remain unclear to me,' which maintain a professional and courteous tone. The reviewer also provides detailed feedback and suggestions for improvement, which is a polite way to help the authors enhance their work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('experimental results are compelling'), they express discomfort with accepting the paper in its current form due to concerns about the novelty and significance of the work. The overall tone suggests more criticism than praise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths alongside criticisms. They avoid harsh or dismissive language, instead offering constructive feedback in a professional manner. The reviewer's careful wording, such as 'I'm uncomfortable accepting' rather than outright rejection, contributes to the polite tone.""]"
"['After the rebuttal and the authors providing newer experimental results, I\'ve increased my score. They have addressed both the issue with the phrasing of the auxiliary loss, which I\'m very happy they did as well as provided more solid experimental results, which in my opinion make the paper strong enough for publication. \n\n#####\nThe paper proposes a variational framework for learning a Model of both the environment and the actor\'s policy in Reinforcement Learning. Specifically, the model is a deterministic RNN which at every step takes as input also a new stochastic latent variable z_t. Compared to more standard approaches, the prior over z_t is not standard normal but depends on the previously hidden state. The inference model combines information from the forward generative hidden state and a backward RNN that looks only at future observations. Finally, an auxiliary loss is added to the model that tries to predict the future states of the backward RNN using the latent variable z_t.  The idea of the paper is quite well presented and concise. \n\nThe paper tests the proposed framework on several RL benchmarks. Using it for imitation learning outperforms two baseline models: behaviour cloning and behaviour cloning trained with an auxiliary loss of predicting the next observation. Although the results are good, it would have been much better if there was also a comparison against a Generative model (identical to the one proposed) without the auxiliary loss added? The authors claim that the results of the experiment suggest that the auxiliary loss is indeed helping, where I find the evidence unconvincing given that there is no comparison against this obvious baseline. Extra comparison against the method from [1] or GAIL would make the results even stronger, but it is understandable that one can not compare against everything, hence I do not see this as a major issue. \nThe authors also compare on long-horizon video prediction. Although their method outperforms the method proposed in Ha & Schmidhuber, this by no means suggests that the method is really that superior. I would argue that in terms of future video prediction that [3] provides significantly better results than the World Models, nevertheless, at least one more baseline would have supported the authors claims much better. \nOn the Model-Based planning, the authors outperform SeCTAR model on the BabyAI tasks and the Wheeled locomotion. This result is indeed interesting and shows that the method is viable for planning. However, given that similar result has been shown in [1] regarding the planning framework it is unclear how novel the result is. \n\nIn conclusion, the paper presents a generative model for training a model-based approach with an auxiliary loss. The results look promising, however, stronger baselines and better ablation of how do different components actually contribute would make the paper significantly stronger than it is at the moment. Below are a few further comments on some specific parts of the paper. \n\nA few comments regarding relevant literature: \n\nBoth in the introduction and during the main text the authors have not cited [1] which I think is a very closely related method. In this work similarly, a generative model of future segments is learned using a variational framework. In addition, the MPC procedure that the authors present in this paper is not novel, but has already been proposed and tried in [1] - optimizing over the latent variables rather than the actions directly, and there have been named Latent Action Priors. \n\nThe data gathering process is also not a new idea and using the error in a dynamics model for exploration is a well-known method, usually referred to as curiosity, for instance see [2] and some of the cited papers as Pathak et. al., Stadie et. al. - these all should be at least cited in section 3.2.2 as well not only in the background section regarding different topics. \n\n\nOn the auxiliary loss:\n\nThe authors claim that they train the auxiliary loss using Variational Inference, yet they drop the KL term, which is ""kinda"" an important feature of VI. Auxiliary losses are well understood that often help in RL, hence there is no need to over-conceptualize the idea of adding the extra term log p(b|z) as a VI and then doing something else. It would be much more clear and concise just to introduce it as an extra term and motivate it without referring to the VI framework, which the authors do not use for it (they still use it for the main generative model). The only way that this would have been acceptable if the experiment section contained experiments with the full VI objective as equation (6) suggest and without the sharing of the variational priors and posteriors and compared them against what they have done in the current version of the manuscript. \n\n\nA minor mistake seems to be that equation (5) and (7) have double counted log p(z_t|h_t-1) since they are written as an explicit term as well as they appear in the KL(q(z_t|..)|p(z_t|h_t-1)). \n\n\n\n[1] Prediction and Control with Temporal Segment Models [Nikhil Mishra, Pieter Abbeel, Igor Mordatch, 2017]\n\n[2] Large-Scale Study of Curiosity-Driven Learning [Yuri Burda, Harri Edwards, Deepak Pathak, Amos Storkey, Trevor Darrell, Alexei A. Efros, 2018]\n\n[3] Action-Conditional Video Prediction using Deep Networks in Atari Games [Junhyuk Oh, Xiaoxiao Guo, Honglak Lee, Richard Lewis, Satinder Singh, 2015]\n', 'The paper introduces an interesting approach to model learning for imitation and RL. Given the problem of maintaining multi-step predictions in the context of sequential decision making process, and deficiencies faced during planning with one-step models [1][2], it’s imperative to explore approaches that do multi-step predictions. This paper combines ideas from learning sequential latent models with making multi-step future predictions as an auxiliary loss to improve imitation learning performance, efficiency of planning and finding sub-goals in a partially observed domain.\n\nFrom what I understand there are quite a few components in the architecture. The generative part uses the latent variables z_t and LSTM hidden state h_t to find the factored autoregressive distribution p_\\theta. It’s slightly unclear how their parameters are structured and what parameters are shared (if any). I understand these are hard to describe in text, so hopefully the source code for the experiments will be made available.\n\nOn the inference side, the paper makes a few choices to make the posterior approximation. It would be useful to describe the intuitions behind the choices especially the dependence of the posterior on actions a_{t-1}:T because it seems like the actions _should_ be fairly important for modeling the dynamics in a stochastic system.\n\nIn the auxiliary cost, it’s unclear what q(z|h) you are referring to in the primary model. It’s only when I carefully read Eq 7, that I realized that it’s p_\\theta(z|h) from the generator. \n\nSlightly unsure about the details of the imitation and RL  (MPC + PPO + Model learning) experiments. How large is the replay buffer? What’s the value of k? It would be interesting how the value of k affects learning performance. It’s unclear how many seeds experiments were repeated with.\n\nOverall it’s an interesting paper. Not sure if the ideas really do scale to “long-horizon” problems. The MuJoCo tasks don’t need good long horizon models and the BabyAI problem seems fairly small.\n\n- Minor points\n\nSec 2.3: not sensitive *to* how different\nAlgorithm 2: *replay* buffer\n\n[1]: https://arxiv.org/abs/1612.06018\n[2]: https://arxiv.org/abs/1806.01825', 'The authors claim that long-term prediction as a key issue in model-based reinforcement learning. Based on that, they propose a fairly specific model to which is then improved with Z-forcing to achieve better performance.\n\n## Major\n\nThe main issue with the paper is that the premise is not convincing to me. It is based on four works which (to me) appear to focus on auto-regressive models. In this submission, latent variable models are considered. The basis for sequential LVMs suffering from these problems is therefore not given by the literature. \n\nThat alone would not be much of an issue, since the problem could also be shown to exist in this context in the paper. But the way I understand the experimental section, the approach without the auxiliary cost is not even evaluated. Therefore, we cannot assess if it is that alone which improves the method. The central hypothesis of the paper is not properly tested.\n\nApart from that, the paper appears to have been written in haste. There are numerous typos in text and in equations (e.g. $dz$ missing from integrals).\n\nTo reconsider my assessment, I think it should be shown that the problem of long-term future prediction exists in the context of sequential LVMs. Maybe this is obvious for ppl more knowledgeable in the field, but this paper fails to make that point by either pointing out relevant references or containing the necessary experiments. Especially since other works have made model-based control work in challenging environments:\n\n- Buesing, Lars, et al. ""Learning and Querying Fast Generative Models for Reinforcement Learning."" *arXiv preprint arXiv:1802.03006* (2018).\n- Karl, M., Soelch, M., Becker-Ehmck, P., Benbouzid, D., van der Smagt, \n  P., & Bayer, J. (2017). Unsupervised Real-Time Control through \n  Variational Empowerment. *arXiv preprint arXiv:1710.05101*.\n\n## Minor\n\n- The authors chose to use the latent states for planning. This turns the optimisation into a POMDP problem. How is the latent state inferred at run time? How do we assure that the policy is still optimal?\n- Application of learning models to RL is not novel, see references above. But maybe this is a misunderstanding on my side, as the Buesing paper is cited in the related work.\n\n']","[50, 50, -60]","[75, 70, 20]","[""The sentiment score is 50 (moderately positive) because the reviewer starts by mentioning they've increased their score after the authors' rebuttal and new results. They state the paper is now 'strong enough for publication,' which is a positive sentiment. However, they also point out areas for improvement and stronger baselines, which tempers the overall positivity.\n\nThe politeness score is 75 (quite polite) because the reviewer uses respectful language throughout. They acknowledge the authors' efforts to address previous concerns and provide constructive feedback. Phrases like 'I'm very happy they did' and 'The idea of the paper is quite well presented' demonstrate politeness. Even when suggesting improvements, the tone remains professional and courteous, avoiding harsh criticism.\n\nThe reviewer balances praise with constructive criticism, maintains a professional tone, and provides detailed, helpful feedback, all of which contribute to the positive politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as 'interesting' multiple times and acknowledges its importance in addressing deficiencies in current approaches. However, they also express some uncertainties and suggest areas for improvement, balancing the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions rather than direct attacks, and acknowledges the paper's contributions. The reviewer also uses phrases like 'it would be useful' and 'it would be interesting' when making suggestions, which maintains a constructive and polite tone. The minor points at the end are presented neutrally without harsh criticism."", ""The sentiment score is -60 because the reviewer expresses significant concerns about the paper's premise, methodology, and presentation. They state that the main issue is unconvincing, the central hypothesis is not properly tested, and the paper appears hastily written with numerous typos. These are major criticisms that indicate a largely negative sentiment. However, the reviewer does offer suggestions for improvement and acknowledges that some issues might be due to their own potential misunderstanding, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'to reconsider my assessment' and 'maybe this is obvious for ppl more knowledgeable in the field', which show a degree of respect and openness to dialogue. The reviewer also provides constructive feedback and suggestions for improvement, which is a polite approach to criticism.""]"
"['Pros:\nThe paper formulates the driving policy problem as a model-based RL problem. Most related work on driving policy has been traditional robotics planning methods such as RRT or model-free RL such as policy gradient methods.\n\nThe policy is learned through unrolling a learned model of the environment dynamics over multiple time steps, and training a policy network to minimize a differentiable cost over this rolled-out trajectory.\n\nThe cost combine the objective the policy seeks to optimize (proximity to other cars) and an uncertainty cost representing the divergence from the states it is trained on.\n\nCons:\n\nThe model based RL formulation is pretty standard except that the paper has a additional model uncertainty cost.\n\nRealistically, the output of driving policy should be planning decision, i.e. the waypoints instead of steering angles and acceleration / deceleration commands. There does not seem to be a need to solve the control problem using learning since PID and iLQR has solved the control problem very well. \n\nThe paper did not seem to reach a conclusion on why stochastic forward model does not yield a clear improvement over the deterministic model. This may be due to the limitation of the dataset or the prediction horizon which seems to be 2 second. \n\nThe dataset is only 45 minutes which captured by a camera looking down a small section of the road. So the policies learned might only do lane following and occasionally doing collision avoidance. I would encourage the authors to look into more diverse dataset. See the paper DESIRE: Distant Future Prediction in Dynamic Scenes with Interacting Agents, CVPR 2017.\n\nOverall, the paper makes an interesting contribution: formulate the driving policy problem as a model-based RL problem. The techniques used are pretty standard. There are some insights in the experimental section. However, due to the limitation of the dataset, it is not clear how much the results can generalize to complex settings such as nudging around other cars, cutting in, pedestrian crossing, etc.\n\nResponse to rebuttal:\nIt is good to know that the authors have a new modified VAE posterior distribution for the stochastic model which can achieve significant gain over the deterministic model. Is this empirical and specific to this dataset? Without knowing the details, it is not clear how general this new stochastic model is.\n\nI agree that it is worthwhile to test the model using the 45 minute dataset. However, I still believe the dataset is very limiting and it is not clear how much the experimental results can apply to other large realistic datasets.\n\nMy rating stays the same.\n\n', 'The paper addresses the difficulty of covariate shift in model-based reinforcement learning. Here, the distribution over trajectories during is significantly different for the behaviour or data-collecting policy and the target or optimised policy. As a mean to address this, the authors propose to add an uncertainty term to the cost, which is realised by the trace of the covariance of the outputs of a MC dropout forward model. The method is applied to driving in dense traffic, where even single wrong actions can be catastrophic.\n\nI want to stress that the paper was a pleasure to read. It was extraordinarily straightfoward to follow, because the text was well aligned with the necessary equations.\n\nThe introduction and related work seem complete to me, with two exceptions:\n\n- Depeweg, S., Hernandez-Lobato, J. M., Doshi-Velez, F., & Udluft, S. \n  (2018, July). Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning. In *International Conference on Machine Learning* (pp. 1192-1201).\n- Thomas, Philip S. *Safe reinforcement learning*. Diss. University of Massachusetts Libraries, 2015.\n\nThe work by Depeweg et al addresses quite the same question as the authors of this work, but with a broader scope (i.e. not limited to traffic) but very much the same machinery. There are some important theoretical insights in this work and the connection to this submission should be drawn. In particular, the proposed method needs to be either compared to this work or it needs to be clarified why it is not applicable.\n\nThe latter appears to be of less significance in this context, but I found robust offline policy evaluation underrepresented in the related work. \n\nI wonder if there is a way for a neural network to ""hack"" the uncertainty cost. I suppose that the proposed approach is an approximation to some entropy term, and it would be informative to see how exactly. \n\nThe approach shown by Eq 1 appears to be an adhoc way of estimating whether the uncertainty resulting from an action is due to the data or the model. What happens if this approach is not taken?\n\nThe objective function of the forward model is only given in the appendix. I think it needs to be moved to the main text, especially because the sum-of-squares term indicates a homoskedastic Gaussian for a likelihood. This has implications for the uncertainty estimates (see point above).\n\nOverall, the separation of data uncertainty/risk vs model uncertainty is not done. This indicates that heterskedastic environments are candidats where the method can fail, and this limitation needs to be discussed or pointed out.\n\nFurther, the authors did not observe a benefit from using a stochastic forward model. Especially, if the prior instead of the approximate posterior is used. My point would be that, depending on the exact grapical model and the way the sampling is done to train the policy, it is actually mathematically *right* to sample from the prior. This is also how it is described in the last equation of section 2. \n\n## Summary\n\nOverall, I liked the paper and the way it was written. However, there are some shortcomings, such as the comparison to the work by Depeweg et al, which does a very similar thing. Also, justifying the used heuristics as approximations to a principled quantity would help. It appears that the question why and how stochastic forward models should be used requires further investigation.', '- Does the paper present substantively new ideas or explore an under explored or highly novel question? \n\nSomewhat, the paper combines two popular existing approaches (Imitation Learning,  Model Based Control and Uncertainty Quantification using Dropout).  The novelty is in  combining pre-existing ideas. \n\n- Does the results substantively advance the state of the art? \n\nNo, the compared methods are not state-of-the-art.\n\n- Will a substantial fraction of the ICLR attendees be interested in reading this paper? \n\nYes. I think that the topics of this paper would be very interesting to ICLR attendees. \n\n-Quality:  \n\nUnclear motivation to penalize prediction uncertainty to make the predicted states stay in the training data.  Also, in some cases references to existing work that includes real robotic systems is out of context at minimum. So yes there are similarities between this paper and existing works  on  learning control for robotics systems using imitation learning, model based control and uncertainty aware cost function. However there is a profound difference in terms of working in simulation and working with a real system for which model and environment uncertainty is a very big issue. There are different challenges in working with a real uncertain system which you will have to actuate,  and working with set of images for making predictions in simulation.   \n\n \n\n-Clarity: \n\nEasy to read. Experimental evaluation is clearly presented. \n\n-Originality: \n\nSimilar uncertainty penalty was used in other paper (Kahn et al. 2017).  Therefore the originality is in some sense reduced.\n\n- Would I send this paper to one of my colleagues to read?\n\nYes I would definitely send this paper to my colleagues. \n\n- General Comment: \n\nDropout can be used to represent the uncertainty/covariance of the neural network model. The epistemic uncertainty, coming from the lack of data, can be gained through Monte Carlo sampling of the dropout-masked model during prediction. However, this type of uncertainty can only decrease by adding more explored data to current data set. Without any addition of data, the  variance reduction, which results  by penalizing the high variance during training, might indicate over-fitting to the current training data. As the penalty forces the model to predict states only in the training dataset, it is unclear how this shows better test-time performance. The output of the policy network will simply be biased towards the training set as a result of the uncertainty cost. More theoretical explanation is needed or perhaps some intuition.  \n\nThis observation is also related to the fact that the model based controller used  is essentially a  risk sensitive controller. \n']","[-20, 50, -20]","[60, 80, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting contribution', 'some insights'), they express several concerns and limitations of the paper. The cons outweigh the pros, and the reviewer maintains their rating even after the rebuttal. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout, offering constructive criticism and suggestions for improvement without harsh or dismissive phrasing. They acknowledge the authors' efforts in the rebuttal and provide balanced feedback, maintaining a courteous tone even when expressing concerns."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses overall positive sentiment, stating 'the paper was a pleasure to read' and 'Overall, I liked the paper'. However, they also point out several shortcomings and areas for improvement, which prevents the score from being higher. The politeness score is 80 (quite polite) due to the reviewer's consistently respectful and constructive tone. They use phrases like 'I want to stress', 'I wonder if', and 'I think', which are polite ways to express opinions and suggestions. The reviewer also balances criticism with praise, acknowledging the paper's strengths before discussing its weaknesses. The language throughout is professional and courteous, without any rude or harsh comments."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects (e.g., 'Easy to read', 'Yes I would definitely send this paper to my colleagues'), there are several critical comments. The reviewer notes that the paper doesn't substantially advance the state of the art, has unclear motivation for certain aspects, and lacks originality in some areas. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout, offering constructive criticism and balancing negative points with positive ones. The language used is not overly formal or effusive, but it's consistently polite and considerate of the authors' work.""]"
"['The paper proposes a way to speed up softmax at test time, especially when top-k words are needed. The idea is clustering inputs so that we need only to pick up words from a learn cluster corresponding to the input. The experimental results show that the model looses a little bit accuracy in return of much faster inference at test time. \n\n* pros: \n- the paper is well written. \n- the idea is simple but BRILLIANT. \n- the used techniques are good (especially to learn word clusters). \n- the experimental results  (speed up softmax at test time) are impressive. \n\n* cons: \n- the model is not end-to-end because word clusters are not continuous. But it not an important factor. \n- it can only speed up softmax at test time. I guess users are more interesting in speeding up at both test and training time.\n- it would be better if the authors show some clusters for both input examples and corresponding word clusters.\n\n\n', 'This paper presents an approximation to the softmax function to reduce the computational cost at inference time and the proposed approach is evaluated on language modeling and machine translation tasks. The main idea of the proposed approach is to pick a subset of the most probable outputs on which exact softmax is performed to sample top-k targets. The proposed method, namely Learning to Screen (L2S), learns jointly context vector clustering and candidate subsets in an end-to-end fashion, so that it enables to achieve competitive performance.\n\nThe authors carried out NMT experiments over the vocabulary size of 25K. It would be interesting if the authors provide a result on speed-up of L2S over full softmax with respect to the vocabulary size. Also, the performance of L2S on larger vocabularies such as 80K or 100K needs to be discussed.\n\nAny quantitative examples regarding the clustering parameters and label sets would be helpful.\nL2S is designed to learn to screen a few words, but no example of the screening part is provided in the paper.', 'This paper proposes a novel method to speedup softmax computation at test time. Their approach is to partition the large vocabulary set into several discrete clusters, select the cluster first, and then do a small scale exact softmax in the selected cluster. Training is done by utilizing the Gumbel softmax trick.\n\nPros:\n1. The method provides another way that allows the model to learn an adaptive clustering of vocabulary. And the whole model is made differentiable by the Gumbel softmax trick. \n2. The experimental results, in terms of precision, is quite strong. The proposed method is significantly better than baseline methods, which is a really exciting thing to see. \n3. The paper is written clearly and the method is simple and easily understandable. \nCons:\n1. I’d be really expecting to see how the model will perform if it is trained from scratch in NMT tasks. And I have reasons for this. Since the model is proposed for large vocabularies, the vocabulary of PTB (10K) is by no terms large. However, the vocabulary size in NMT could easily reach 30K, which would be a more suitable testbed for showing the advantage of the proposed method.  \n2. Apart from the nice precision results, the performance margin in terms of perplexity seems not as big as that of precision. And according to earlier discussions in the thread, the author confirmed that they are comparing the precision w.r.t. original softmax, not the true next words. This could raise a possible assumption that the model doesn’t really get the probabilities correct, but somehow only fits on the rank of the words that was predicted by the original softmax. Maybe that is related to the loss? However, I believe sorting this problem out is kind of beyond the scope of this paper.  \n3. In another scenario, I think adding some qualitative analysis could better present the work. For example, visualize the words that got clustered into the same cluster, etc. \n\nIn general, I am satisfied with the content and enjoys reading the paper. \n']","[80, 50, 70]","[70, 75, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, using words like 'BRILLIANT' and 'impressive' to describe the idea and results. The pros outweigh the cons, and the cons are presented as minor issues or suggestions rather than major flaws. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging both strengths and weaknesses of the paper. The reviewer offers constructive feedback and suggestions for improvement without using harsh or critical language. The use of bullet points for pros and cons also contributes to a clear and professional tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contribution and its competitive performance, but also suggests areas for improvement. The review starts with a neutral summary of the paper's content, followed by constructive suggestions for additional experiments and information. There's no overtly negative criticism, but the suggestions imply that the paper could be strengthened with more data.\n\nThe politeness score is 75 (quite polite) because the reviewer uses respectful and professional language throughout. They frame their suggestions as interesting possibilities ('It would be interesting if...') rather than demands. The reviewer also uses phrases like 'would be helpful' when requesting additional information, which is a polite way of making suggestions. There's no harsh or critical language, and the overall tone is collaborative and constructive."", ""The sentiment score is 70 (positive) because the reviewer expresses overall satisfaction with the paper, highlighting several pros and stating they 'enjoy reading the paper'. They also mention 'really exciting' results. However, it's not 100 as they do list some cons and areas for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively as suggestions or expectations (e.g., 'I'd be really expecting to see...'). The tone is professional and courteous, avoiding harsh or dismissive language even when pointing out limitations.""]"
"['In the submitted manuscript, the authors introduce a novel deep learning architecture to solve the  problem of supervised learning with sparse and irregularly sampled multivariate time series, with a specific interest in EHRs. The architecture is based on the use of a semi-parametric interpolation network followed by the application of a prediction network, and it is tested on two classification/regression tasks.\n\nThe manuscript is interesting and well written: the problem is properly located into context with extensive bibliography, the method is sufficiently detailed and the experimental comparative section is rich and supportive of the authors’ claim. However, there are a couple of issues that need to be discussed: \n\n\t▪\tthe reported performances represent only a limited improvement over the comparing baselines, indicating that the proposed model is promising but it is still immature\n\t▪\tthe model is sharing many characteristics with (referenced) published methods, which the proposed algorithm is a smart combination of - thus, overall, the novelty of the introduced method is somewhat limited.\n\n\n######### \n\nAfter considering the proposed improvements, I decided to raise my mark to 6. Thanks for the good job done!\n', 'Summary:\nThe authors propose a framework for making predictions on a sparse, irregularly sampled time-series data. The proposed model consists of an interpolation module, and the prediction module, where the interpolation module models the missing values in using three outputs: smooth interpolation, non-smooth interpolation, and intensity. The authors test the proposed method on two different datasets (MIMIC-III and UWave), although only one of the datasets are multi-variate. The proposed method shows comparable training time to other GRU variants, and outperforms all baseline models for mortality prediction and length-of-stay prediction.\n\nPros:\n- Possibly, simple yet effective solution to handle time series data with missing values.\n- I appreciate the thorough survey of the related works.\n\nIssues:\n- My biggest concern is that the authors spend some time to address the disadvantage of discretizing the timeline when modeling missing values (5th paragraph of section 2) and emphasize how their method does not have such limitation. But it seems that, when using the proposed method, the user still needs to pre-define evenly spaced reference points r_1, r_2, ..., r_T. So there is still this dilemma how dense you want the reference points to be. And I couldn\'t find the values used for the reference points in the experiments section. It\'s quite possible that one of the baselines can outperform the proposed method with different reference points, given that the evaluation scores overlap with each other wrt standard deviation ranges.\n- Method description in section 3.2.1 is quite confusing. I could follow until Eq.2, but afterwards, the first interpolants (x^{21}) and the second interpolants (x^{12}) become very confusing. It would have been helpful if the authors explicitly described what the interpolation channel \'c\' was before talking about the interpolants. \n- ""taking into account learned correlations"" in page 5: I suggest changing that to ""taking into account learnable/trainable correlations"" since ""learned correlations"" gives the impression that the correlations were already learned prior to training the model.\n- Can the authors test the proposed method on logistic regression (LR) and multi-layer perceptron (MLP)? It would be interesting to see if the proposed method improves the performance of LR and MLP.\n\nAfter considering the author feedback and their effort to address my concerns, I\'ve decided to raise my rating to 6. Thank you for the hard work.', 'I have mixed feelings about this submission, and as such, I look forward to discussing it with both the authors and my fellow reviewers. In short, I like the simplicity of the idea, but I am uncertain about the degree to which it satisfies ICLR\'s novelty criterion (""present substantively new ideas or explore an underexplored or highly novel question""); I do feel confident that some ICLR readers would (perhaps unfairly) describe this approach as ""obvious."" The paper\'s presentation suffers, and it fails to communicate essential details clearly. Finally, for folks familiar with healthcare data and MIMIC-III specifically, the results are underwhelming: yes, the proposed approach beats (the authors\' own implementations of) baselines, but it underperforms other published results on the MIMIC-III 48-hour mortality task ([1][2] report AUCs of 0.87 or higher). As such, I am assigning the paper a ""weak accept"" to communicate my ambivalence and reserve the right to adjust it up or down after discussion.\n\nSUMMARY\n\nThis paper proposes an ""interpolation layer"" to resample irregularly sampled time series before feeding them into a neural net architecture. The interpolation layer consists of parametric kernels, e.g., radial basis functions, configured to estimate the values of input time series at reference time points based on univariate temporal and then multivariate correlations. The outputs include smooth and transient interpolated values (controlled by kernel bandwidth) and counts (referred to as intensity) at each reference point. As far as I understand, this model can be trained end-to-end. The paper also proposes a simple strategy for combatting overfitting (add an autoencoder and reconstruction error term to the objective in combination with a heuristic in which some points are masked as inputs and must be interpolated from non-masked points). In experiments on two data sets (UWaveGesture and a medical data set) and two tasks (classification and regression) this approach outperforms the main competing approaches [3][4][5][6] in most contexts.\n\nBelow I provide a list of strengths, weaknesses, and general questions or feedback.\n\nSTRENGTHS\n\n- I applaud the simplicity of the idea: this much simpler framework leverages many of the intuitions behind the GP adapter framework (GP-GRU) [4][5] with comparable performance and appears to train orders of magnitude faster (caveat: on one data set and task)\n- It likewise outperforms both commonly used preprocessing (GRU-F) [2][3] and the much more complicated neural net architecture (GRU-HD) from [6] (across two datasets and tasks)\n- The simplicity of this approach probably lends itself to additional customization and innovation\n- The literature review seems quite thorough and does an especially nice job of covering recent work on RNNs for multivariate time series and irregular sampling or missing values\n- The experiments are thorough and well-designed overall. The authors use two data sets and two tasks (classification and regression). More data sets and tasks is always nice, but even two is pretty laudable (many authors might settle on just one given the experimental and computational effort required for these experiments). They include and beat or outperform two baselines that can justifiably be called state-of-the-art (GP-GRU and GRU-HD).\n\nI think a relatively safe takeaway is that for irregularly sampled data, this approach is is preferable to both heuristic preprocessing and more complex models. That seems like a not insignificant finding in empirical machine learning for messy time series data.\n\nWEAKNESSES\n\n- Section 3 is possibly the most critical section (since it describes the contribution) but is hard to follow: I don\'t envy the authors the task of explaining a variable with two superscripts and three subscripts (Equation 1), but it IS their paper, so it\'s on them to do it. See feedback section for other examples.\n- Although I consider the related work well done, I can\'t help but wonder if there isn\'t older work on RBFs, etc., that might have been missed (I mostly want to encourage the authors to look once more and then come back and tell me I\'m wrong).\n- The MIMIC-III experiments omit the GP-GRU model, which weakens the results by leaving the reader to imagine how it might compare (I would expect it to outperform the proposed approach by an even wider margin than it did for UWave).\n- I am sympathetic to the idea of fixing certain architectural choices, e.g., layers and units in the GRU and number of inducing points, across all models because it (a) gives the appearance of a ""fair comparison"" and (b) reduces burden of effort, but I do not agree that it yields a truly fair comparison. The GRU-* model performance on UWave is suspiciously bad, suggesting severe overfitting and the possibility that the models are overparameterized. It leaves the reader wondering if the architectural choices happen to be optimal for the proposed model only (whether by accident or design). A truly fair comparison requires independently tuning hyperparameters for each model.\n- Although the proposed approach outperforms baselines in these experiments, the overall results are underwhelming in the wider context of recent work using MIMIC-III. Multiple publications have reported AUCS of 0.87 [1][2] or higher for 48-hour risk of mortality (it is difficult to compare the LOS results since different papers use different units). Of course, the experiments use different cohorts and variables so they\'re not directly comparable, but it nonetheless diminishes the potential impact of the results presented here.\n\nFEEDBACK AND QUESTIONS\n\n- I had to read 3.2.1 multiple times to understand the relationships between the different ""layers"" in the interpolator, and I\'m still not sure what the relationship is between the smooth and transient kernels or exactly how the intensity values are estimated (are they just windowed counts or weighted sums?).\n- I\'m also not 100% clear on (a) which parameters (if any) in the interpolator are optimized during end-to-end learning and which are just fixed or tuned as hyperparameters. This should be stated clearly and even better, I\'d recommend writing down the gradient update rules for the interpolator parameters (you can put them in the appendix).\n- Since the model uses global structure for interpolation and requires pre-specifying the number of inducing points, could it be used to make continuous predictions (and how?), e.g., forecast mortality at each hour?\n- On a related note, if the number of inducing points is pre-specified, can the model be applied to sequences of different length?\n- How does performance depend on choice of number of inducing points?\n- How does the proposed approach handle time series that are missing entirely, e.g., if no pH values are measured?\n- What does Table 3 in the appendix mean by ""missingness?"" Given that the paper is concerned with irregular sampling (not missing data), I would expect statistics on sampling rates, not missingness...\n- Why derive your own MIMIC-III subset and tasks rather than use one of several pre-existing benchmarks (both of which include more variables and tasks) [1][2]?\n- FYI: the Che, et al., 2016, paper on missing values [6] has been published in JBIO, so you should cite that version.\n\nREFERENCES\n\n[1] Purushotham, et al. ""Benchmark of Deep Learning Models on Large Healthcare MIMIC Datasets."" arXiv preprint arXiv:1710.08531 (2017)\n[2] Harutyunyan, et al. ""Multitask learning and benchmarking with clinical time series data."" arXiv preprint arXiv:1703.07771 (2017)\n[3] Lipton, Kale, and Wetzel, 2016\n[4] Li and Marlin, 2016.\n[5] Futoma, et al., 2017.\n[6] Che, et al., 2016. <-- new JBIO 2018 version!']","[50, 50, -20]","[80, 80, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the manuscript as 'interesting and well written' with a 'rich and supportive' experimental section. However, they also point out limitations, such as 'limited improvement' and 'somewhat limited' novelty, balancing the positive aspects. The politeness score is 80 (quite polite) due to the reviewer's constructive tone, use of phrases like 'interesting and well written', and the positive acknowledgment of the authors' efforts in the final line ('Thanks for the good job done!'). The reviewer provides balanced feedback, highlighting both strengths and areas for improvement in a respectful manner."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges some pros of the paper, such as the 'simple yet effective solution' and 'thorough survey of related works'. However, they also raise several concerns and issues, which balances out the positive aspects. The overall tone suggests a mixed but slightly favorable view of the work. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'It would have been helpful if...'), and shows appreciation for the authors' efforts (e.g., 'I appreciate the thorough survey...'). The reviewer also thanks the authors for their hard work at the end, which is a particularly polite gesture."", ""Sentiment score: The review expresses mixed feelings, leaning slightly negative. The reviewer likes the simplicity of the idea but has concerns about novelty, presentation, and underwhelming results. They assign a 'weak accept' but reserve the right to adjust it, indicating overall ambivalence. The balance of strengths and weaknesses, with more emphasis on areas for improvement, suggests a slightly negative sentiment.\n\nPoliteness score: The language is generally polite and professional. The reviewer uses respectful phrases like 'I applaud the simplicity of the idea' and 'I look forward to discussing it'. They provide constructive criticism and balance negative points with positive ones. However, some phrases like 'it IS their paper, so it's on them to do it' are slightly less polite, preventing a higher score.""]"
"[""[Summary]:\nThis paper tackles the problem of automatic robot design. The most popular approach to doing this has been evolutionary methods which work by evolving morphology of agents in a feed-forward manner using a propagation and mutation rules. This is a non-differentiable process and relies on maintaining a large pool of candidates out of which best ones are chosen with the highest fitness. In robot design for a given task using rewards, training each robot design using RL with rewards is an expensive process and not scalable. This paper uses graph network to train each morphology using RL. Thereby, allowing the controller to share parameters and reuse information across generations. This expedites the score function evaluation improving the time complexity of the evolutionary process.\n\n[Strengths]:\nThis paper shows some promise when graph network-based controllers augmented with evolutionary algorithms. Paper is quite easy to follow.\n\n[Weaknesses and Clarifications]:\n=> Robot design area has been explored extensively in classical work of Sims (1994) etc. using ES. Given that, the novelty of the paper is fairly incremental as it uses NerveNet to evaluate fitness and ES for the main design search.\n=> Environment: The experimental section of the paper can be further improved. The approach is evaluated only in three cases: fish, walker, cheetah. Can it be applied to more complex morphologies? Humanoid etc. maybe?\n=> Baselines: The comparison provided in the paper is weak. At first, it compares to random graph search and ES. But there are better baselines possible. One such example would be to have a network for each body part and share parameters across each body part. This network takes some identifying information (ID, shape etc.) about body part as input. As more body parts are added, more such network modules can be added. How would the given graph network compare to this? This baseline can be thought of a shared parameter graph with no message passing.\n=> The results shown in Figure-4 (Section-4.2) seems unclear to me. As far as I understand, the model starts with hand-engineered design and then finetuned using evolutionary process. However, the original performance of the hand-engineered design is surprisingly bad (see first data point in any plot in Figure-4). Does the controller also start from scratch? If so, why? Also, it is not clear what is the meaning of generations if the graph is fixed, can't it be learned altogether at once?\n\n[Recommendation]:\nI request the authors to address the comments raised above. Overall, this is a reasonable paper but experimental section needs much more attention."", 'This paper discusses the optimization of robot structures, combined with their controllers. The authors propose a scheme\nbased on a graph representation of the robot structure, and a graph-neural-network as controllers. The experiments show\nthat the proposed scheme is able to produce walking and swimming robots in simulation. The results in this paper are impressive, and the paper seems free of technical errors. \n\nThe main criticism I have is that I found the paper harder to read. In particular, the exact difference between the proposed method and the ES baseline is not as clear as it could be. This makes the contribution of this paper in terms of the method\nhard to judge. Please include further description of the ES cost function and algorithm in the main body of the paper.\n\nThe second point is that the proposed approach seems to modify a few things from the ES baseline. The efficacy of the separate modifications should be tested. Therefore I would like to see experiments with the ES cost function, but with\ninclusion of the pruning step, and experiments with the AF-function but without the pruning step.', 'This paper proposes an approach for automatic robot design based on Neural graph evolution.\nThe overall approach has a flavor of genetical algorithms, as it also performs evolutionary operations on the graph, but it also allows for a better mechanism for policy sharing across the different topologies, which is nice.\n\nMy main concern about the paper is that, currently, the experiments do not include any strong baseline (the ES currently is not a strong baseline, see comments below). \nThe experiments currently demonstrate that optimizing both controller and hardware is better than optimizing just the controller, which is not surprising and is a phenomenon which has been previously studied in the literature.\nWhat instead is missing is an answer to the question: Is it worth using a neural graph? what are the advantages and disadvantages compared to previous approaches?\nI would like to see additional experiments to answer this questions.\n\nIn particular, I believe that any algorithms you compare against, you should optimize both G and theta, since optimizing purely the hardware is unfair.\nYou should use an existing ES implementation (e.g., from some well-known package) instead of a naive implementation, and as additional baseline also CMA-ES. \nIf you can also compare against one or two algorithms of your choice from the recent literature it would also give more value to the comparison.\n\nDetailed comments:\n- in the abstract you say that ""NGE is the first algorithm that can automatically discover complex robotic graph structures"". This statement is ambiguous and potentially unsupported by evidence. how do you define complex? that can or that did discover?\n- in the introduction you mention that automatic robot design had limited success. This is rather subject, and I would tend to disagree.  Moreover, the same limitations that apply to other algorithms to make them successful, in my opinion, apply to your proposed algorithm (e.g., difficulty to move from simulated to real-world).\n- The digression at the bottom of the first page about neural architecture search seem out of context and interrupts the flow of the introduction. What is the point that you are trying to make? Also, note that some of the algorithms that you are citing there have indeed applied beyond architecture search, eg. Bayesian optimization is used for gait optimization in robotics, and Genetic algorithms have been used for automatic robot design.\n- The stated contributions number 3 and 5 are not truly contributions. #3 is so generic that a large part of the previous literature on the topic fall under this category -- not new. #5 is weak, and tell us more about the limitations of random search and naive ES than necessarily a merit of your approach. \n- Sec 2.2: ""(GNNs) are very effective"" effective at what? what is the metric that you consider?\n- Sec 3 ""(PS), where weights are reused"" can you already go into more details or refer to later sections?\n- First line page 4 you mention AF, without introducing the acronym ever before.\n- Sec 3.1: the statements about MB and MF algorithms are inaccurate. Model-based RL algorithms can work in real-time (e.g. http://proceedings.mlr.press/v78/drews17a/drews17a.pdf) and have been shown to have same asymptotic performance of MB controllers for simple robot control (e.g. https://arxiv.org/abs/1805.12114) \n- ""to speed up and trade off between evaluating fitness and evolving new species"" Unclear sentence. speed up what? why is this a trade-off?\n- Sec 3.4 can you recap all the parameters after eq.11? going through Sec 3.2 and 2.2 to find them is quite annoying.\n- Sec 4.1:  would argue that computational cost is rarely a concern among evolutionary algorithms. The cost of evaluating the function is typically more pressing, and as a result it is important to have algorithms that can converge within a small number of iterations/generations.\n- Providing the same computational budget seem rather arbitrary at the moment, and it heavily depends from implementation. How many evaluations do you perform for each method? why not having the same budget of experiments?  ']","[-20, 60, -30]","[60, 70, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths ('shows some promise', 'easy to follow'), they also point out several weaknesses and areas for improvement. The overall tone suggests that the paper needs significant work, especially in the experimental section. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, such as 'I request the authors to address the comments' and 'This paper shows some promise'. They provide constructive criticism without using harsh or dismissive language. The reviewer also balances critique with positive observations, maintaining a professional and courteous tone."", ""The sentiment score is 60 (positive) because the reviewer starts by highlighting the impressive results and the paper being free of technical errors. However, they also express some criticisms, which prevents the score from being higher. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, framing their criticisms as suggestions for improvement rather than harsh critiques. They use phrases like 'The main criticism I have' and 'I would like to see' which maintain a professional and courteous tone. The reasoning for these scores is based on the overall positive tone of the review, balanced with constructive criticism, and the consistently polite and professional language used throughout the feedback."", ""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('which is nice'), they express significant concerns about the paper's experiments and comparisons. The reviewer requests additional experiments and stronger baselines, indicating that the current work is not yet satisfactory. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'I would like to see' and 'can you' which are polite ways of requesting changes. The reviewer also provides detailed comments to help the authors improve their work, which is a courteous approach to peer review.""]"
"['[REVISION]\nThe work is thorough and some of my minor concerns have been addressed, so I am increasing my score to 6. I cannot go beyond because of the incremental nature of the work, and the very limited applicability of the used continual learning setup from this paper.\n\n[OLD REVIEW]\nThe paper proposes a novel, regularization based, approach to the sequential learning problem using a fixed size model. The main idea is to add extra terms to the loss encouraging representation sparsity and combating catastrophic forgetting. The approach fairs well compared to other regularization based approaches on MNIST and CIFAR-100 sequential learning variants.\n\nPros:\nThorough experiments, competitive baselines and informative ablation study.\nGood performance on par or superior to baselines.\nClear paper, well written.\n\nCons:\nThe approach, while competitive in performance, does not seem to fix any significant issues with baseline methods. For example, task boundaries are still used, which limits applicability; in many scenarios which do have a continual learning problem there are no clear task boundaries, such as data distribution drift in both supervised and reinforcement learning.\nSince models used in the work are very different from SOTA models on those particular tasks, it is hard to determine from the paper how the proposed method influences these models. In particular, it is not clear whether these changes to the loss would still allow top performance on regular classification tasks, e.g. CIFAR-10 or MNIST even without sequential learning, or in multitask learning settings. \n\nSummary:\nAlthough the work is substantial and experiments are thorough, I have reservations about extrapolating from the results to settings which do have a continual learning problem. Although I am convinced results are slightly superior to baselines, and I appreciate the lengthy amount of work which went into proving that, the paper does not go sufficiently beyond previous work.\n', 'This paper deals with the problem of catastrophic forgetting in lifelong learning, which has recently attracted much attention from researchers. In particular, authors propose the regularized learning strategies where we are given a fixed network structure (without requiring additional memory increases in the event of new task arriving) in the sequential learning framework, without the access to datasets of previous tasks.  Performance comparisons were performed experimentally against diverse regularization methods including ones based on representation, based on parameter itself, and the superiority of representation-based regularization techniques was verified experimentally. Based on this, authors propose a regularization scheme utilizing the correlation between hidden nodes called SNI and its local version based on Gaussian weighting. Both regularizers are even extended to consider the importance of hidden nodes. Through MNIST, CIFAR, and tiny Imagenet datasets, it has been experimentally demonstrated that the proposed regularization technique outperforms state-of-the-art in sequential learning.\n\nIt is easy to follow (and I enjoyed the way of showing their final method, starting from SNI to SLNI and importance weighting). Also it is interesting that authors obtained meaningful results on several datasets beating state-of-the-arts based on very simple ideas.\n\nHowever, given Cogswell et al. (2015) or Xiong et al. (2016), it seems novelty is somehow incremental (I could recognize that this work is different in the sense that it considers  local/importance based weighting as well as penalizing correlation based on L1 norm). Moreover, there is a lack of reasoning about why representation based regularization is more effective for life-long learning setting. Figure 1 is not that intuitive and it does not seem clearly describe the reasons.   \n\nMy biggest concern with the proposed regularization technique is the importance of neurons in equation (6). It is doubtful whether the importance of activation of neurons based on ""current data"" is sufficiently verified in sequential learning (in the experimental section, avg performance for importance weight sometimes appears to come with performance improvements but not always). It would be great if authors can show some actual overlaps of activations across tasks (not just simple histogram as in Figure 5). And isn\'t g_i(x_m) a scalar? Explain why we need the norm when you get alpha.\n\nIt would be nice to clarify what the task sequence looks like in Figure 2. It is hard to understand that task 5, which is the most recent learning task, has the lowest performance in all tasks.\n\n-----------------------------------------------------------------------------------------------------\n- On figure 4: I knew histograms are given in figure 4 (I said figure 5 mistakenly, but I meant figure 4). But showing overlap patterns across tasks (at different layers for instance) might be more informative. \n- On figure 2: It looks weird to me because last task has the lowest accuracy even for ReLU (sequential learning w/o regularization); tuning for task 5 will lead catastrophic forgetting for previous tasks, meaning acc for task 1 be the lowest?\n\n-----------------------------------------------------------------------------------------------------\n-  My concerns about figures are solved; I want to thank authors for their efforts.', 'REVISION AFTER REBUTTAL\nWhile the revision does not address all of my concerns about clarity, it is much better. I still think that the introduction is overly long and the subsequent sections repeat information; if this were shortened there could be room for some of the figures that are currently in appendix. I appreciate the new figures; I think that it would be great if especially figure 10 were included in the main paper. \nI agree with the other two reviewers that the work is somewhat incremental, but the differences are well explained, the experimental results are interesting (particularly the differences of parameter vs representation-based sparsity, and the plots in appendix showing neuron importance over tasks), and the progression from SNI to SLNID is well-presented.  I think overall that this paper is a good contribution and I recommend acceptance. I have updated my review to a 7. \n===============\n""Activations"" ""Representation"" and ""Outputs"" are used somewhat interchangably throughout the work; for anyone not familiar it might be worth mentioning something about this in the intro.\n \nProblem setting is similar to open set learning (classification); could be worth mentioning algorithms for this in the related work which attempt to set aside capacity for later tasks.\n\nResults are presented and discussed in the introduction, and overall the intro is a bit long, resulting in parts later being repetitive.\n\nWorth discussing sparsity vs. distributed representations in the intro, and how/where we want sparsity while still having a distributed representation.\n\nShould be made clear that this is inspired by one kind of inhibition, and there are many others (i.e. inhibition in the brain is not always about penalizing neurons which are active at the same time, as far as I know)\n\nChanges in verb tense throughout the paper make it hard to follow sometimes. Be consistent about explaining equations before or after presenting them, and make sure all terms in the equation are defined (e.g. SNI with a hat is used before definition). Improper or useless ""However"" or ""On the other hand"" to start a lot of sentences.\n\nFigure captions could use a lot more experimental insight and explanation - e.g. what am I supposed to take away from Figure 10 (in appendix B4), other than that the importance seems pretty sparse? It looks to me like there is a lot of overlap in which neurons are important or which tasks, which seems like the opposite of what the regularizer was trying to achieve. This is a somewhat important point to me; I think this interesting and I\'m glad you show it, but it seems to contradict the aim of the regularizer.\n\nHow does multi-task joint training differ from ""normal"" classification? The accuracies especially for CIFAR seem very low.\n\nQuality: 7/10 interesting and thoughtful proposed regularizer and experiments; I would be happy to increase this rating if the insights from experiments, especially in the appendix, are a bit better explained\nClarity:  6/10 things are mostly clearly explained although frequently repetitive, making them seem more confusing than they are. If the paper is reorganized and the writing cleaned up I would be happy to increase my rating because I think the work is good. \nOriginality: 8/10 to my knowledge the proposed regularizer is novel, and I think think identifying the approach of ""selfless"" sequential learning is valuable (although I don\'t like the name)\nSignificance: 7/10 I am biased because I\'m interested in LLL, but I think these problems should receive more attention.\n\nPros:\n - proposed regularizer is well-explained and seems to work well, ablation study is helpful\n\nCons:\n - the intro section is almost completely repetitive of section 3 and could be significantly shortened, and make more room for some of the experimental results to be moved from the appendix to main text\n - some wording choices and wordiness make some sentences unclear, and overall the organization and writing could use some work\n\nSpecific comments / nits: (in reading order)\n1. I think the name ""selfless sequential learning"" is a bit misleading and sounds like something to do with multiagent cooperative RL; I think ""forethinking"" or something like that that is an actual word would be better, but I can\'t think of a good word... maybe frugal? \n2.  Mention continual/lifelong learning in the abstract\n3. ""penalize changes"" maybe ""reduce changes"" would be better?\n4. ""in analogy to parameter importance"" cite and explain parameter importance\n5. ""advocate to focus on selfless SL"" focus what? For everyone doing continual learning to focus on methods which achieve that through leaving capacity for later tasks? This seems like one potentially good approach, but I can imagine other good ones (e.g. having a task model)\n6. LLL for lifelong learning is defined near the end of the intro, should be at the beginning when first mentioned\n7. ""lies at the heart of lifelong learning"" I would say it is an ""approach to lifelong learning""\n8. ""fixed model capacity"" worth being specific that you mean (I assume) fixed architecture and number of parameters\n9. ""those parameters by new tasks"" cite this at the end of the sentence, otherwise it is unclear what explanation goes with which citation\n10.  ""hard attention masks, and stored in an embedding"" unclear what is stored in the embedding. It would be more helpful to explain how this method relates to yours rather than just describing what they do.\n11. I find the hat notation unclear; I think it would be better just to have acronyms for each setting and write out the acronyms in the caption\n12.""richer representation is needed and few active neurons can be tolerated"" should this be ""more active neurons""?\n13. Comparison with state of the art section is repetitive of the results sections']","[20, 50, 60]","[50, 70, 70]","[""The sentiment score is 20 (slightly positive) because the reviewer acknowledges improvements in the revised version and increases their score. However, they still express reservations about the work's applicability and incremental nature. The politeness score is 50 (moderately polite) as the reviewer uses professional language, acknowledges the thorough work done, and provides a balanced view of pros and cons without using harsh criticism. The reviewer's tone is constructive and respectful throughout, even when expressing concerns."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's merits, such as its clarity and interesting results, but also raises several concerns and criticisms. The reviewer appreciates the authors' approach and experimental results, but points out issues with novelty, reasoning, and some aspects of the methodology. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers constructive criticism, and acknowledges the authors' efforts. The reviewer uses phrases like 'It would be nice' and 'It would be great if' when suggesting improvements, which maintains a polite tone. The follow-up comments also show appreciation for the authors' responses, further indicating politeness."", ""The sentiment score is 60 (positive) because the reviewer recommends acceptance and has increased their rating to 7/10, indicating a generally positive view of the paper despite some remaining concerns. They mention that the revision is 'much better' and that the paper is 'a good contribution'. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges improvements, and provides constructive feedback. They use phrases like 'I appreciate', 'I think', and 'I recommend', which maintain a polite tone. The reviewer balances criticism with praise and offers specific suggestions for improvement, demonstrating a considerate approach to the review process.""]"
"['This work demonstrates that a particle dynamics model can be learned to approximate the interaction of various objects. The resulting differentiable simulator has a strong inductive bias, which makes it possible to efficiently solve complex manipulation tasks over deformable objects.\n\n# Quality\n\nThis work is an impressive proof-of-concept of the capabilities of differentiable programming for learning complex (physical) processes, such as particle dynamics. In my opinion, the resulting particle interaction network would deserve publication for itself. However, this work goes already one step further and demonstrates that the resulting differentiable simulator can be used for the manipulation of deformable objects.\n\nThe method is evaluated on a well-rounded set of experiments which demonstrates its potential. More real-world experiments would be welcome to leave any doubt.\n\nEDIT: However, the current manuscript lacks a proper comparison with (cited) previous work, such as 1806.08047. \n\n# Clarity\n\nThe paper is well written, although I do feel it was difficult to remain within the 8-page limit given the breadth of the work.\n\n# Originality\n\nAs far as I know, this work is (very) original. (That being said, I am not too familiar with the related work.)\n\nEDIT: This work is actually quite similar to 1806.08047. A proper discussion of the differences should be included. \n\n# Significance\n\nThis work will certainly be of interest for several research communities, including deep learning, physics, control and robotics.\n', '[Paper Summary]\nThis paper tackles the problem of learning dynamics of non-rigid objects in a physics simulator. This learned dynamics can then be used for planning later. The non-rigid objects are represented via a particle-based system. The dynamics model is learned using NVIDIA\'s particle-based simulator ""Flex"". The main idea is to adapt Interaction Networks [Battaglia, 2016] which was earlier proposed for rigid-body simulators to particle-based simulators. Instead of maintaining interactions at the level of objects as in [Battaglia, 2016], the proposed approach models interaction at the level of particles.\n\n[Paper Strengths]\nThe paper is clearly written and tackles an important research problem. The existing literature is presented well.\n\n[Paper Weaknesses]\n=> The introduction and the text in the first two pages seem to be introducing a new way to model ""dynamic"" interactions between particles for handling non-rigid transformations. However, upon reading the method section, the approach seems to be a direct application of the Interaction Graph Networks (originally applied to the rigid-body simulator) to the particle-based simulator. The only difference is that instead of maintaining a fully-connected graph (memory and computational bottleneck), each particle is only connected to the near-by particles within distance d.\n\n=> One of the major issue with the paper is the experimental section of the paper. Since the proposed method is quite incremental over the prior work, a strong empirical section is must to justify the approach. Here are the comments:\n   - Since the proposed approach is an adaptation of [Battaglia, 2016], it should be compared to other existing methods. The experiment section in its current state does not compare to any baseline. The well-written related work (section-2) talks about (Mrowca et.al. 2018) and (Schenck and Fox, 2018) as the works which investigate learning dynamics of deformable objects using a particle-based simulator. However, no comparison is provided to either of the methods. Hence, it is not possible to judge the quality of the presented results.\n\n   - All results in Figure-5 or Figure-3 are quite close to each other. It is not clear whether the improvement is significant or not since the error bars are not provided at all.\n\n   - No ablation is performed to test the sensitivity of the proposed method with respect to the hyper-parameters introduced; for instance, the distance \'d\'.\n\n=> The name ""Dynamic Particle Interaction"" is overloaded with terms, especially, the use of word \'dynamic\' here just refers to the interaction of particles to model deformable objects. This ""dynamic"" interaction is not ""learned"" but simply hard-coded by deleting the edges which are farther than d distance apart and adding near ones. Something like ""Particle-level Interaction Networks"" would be a more honest description of the approach.\n\n[Final Recommendation]\nI request the authors to address the comments raised above and will decide my final rating based on that. With the current set of experiments, the paper doesn\'t seem to be ready yet.', 'The authors present an algorithm for learning the dynamics prediction of deformable and fluid bodies by modeling them as (potentially hierarchical) systems of many interacting particles.  This model applies a shared encoder to the particle states (positions and velocities), a shared relation network to nearby pairs, and a shared propagator network to the summed relation network outputs.  In some cases this process is applied in a multi-scale hierarchical fashion.  The authors demonstrate accurate rollouts of system dynamics and usefulness for manipulative control of deformable objects.\n\nI find the motivation in the introduction persuasive and the algorithmic approach sound.  I also like the application to RL.  However, I do have some concerns, as follows:\n\n1)  The novelty of the method is questionable.  Specifically, the hierarchical interaction network proposed here seems extremely similar to the prior (and cited) paper (Mrowca et al., 2018), which the authors do not directly compare against.  If there is a non-negligible difference between the two algorithms, then the authors should explicitly discuss the difference and empirically compare the two, in order to benefit others in the community who otherwise would not know which to use.\n\n2)  The paper would benefit a lot from a diagram of the model.  Specifically, it would be good to have a diagram of the hierarchical interaction network demonstrating the multiscale propagation.  This could go in Figure 1, perhaps replacing elements (b) and (d) of the current Figure 1, which in my opinion are unnecessary and can be removed.\n\n3)  The paper uses domain-specific hyperparameters, yet does not discuss or analyze the effects of these hyperparameters much.  Specifically, for this method to be useful to others, we would like to know how to choose (i) the propagation step L, (ii) the number of roots, and (iii) the neighborhood distance d.  In the paper, these numbers are chosen differently for the different environments without explanation.  Graphs showing performance on each task over a range of values of these parameters would be good (perhaps in the supplementary material).  Also, using the same hyperparameters for all environments (or at least a common generating function) would help support the generality of this model.\n\n4)  The treatment of rigid bodies seems a bit hand-held.  Specifically, to determine the dynamics of rigid bodies, there is a ground-truth calculation which calculates computes the velocity and angular velocity of the body from the model predictions for its constituent particles.  Furthermore, if I understand correctly, there is a different motion predictor network for those particles in a rigid body than those in the surrounding fluid --- is this correct?  If so, this raises the questions:  (i) What happens if the same motion-predictor network is used for all particles, and (ii) What happens if the ground-truth rigid dynamics calculation is not done, so the model has to do all the work?  It would be interesting to have these as baselines.\n\n5)  It would be nice to see more generalization results.  There is only one generalization experiment, testing for generalization over particle number in FluidShake.  However, the FluidShake model is not hierarchical.  The hierarchical models are a big emphasis in the paper, so showing generalization on BoxBath or RiceGrip would be much more meaningful.\n\n6)  No confidence intervals for the quantitative results.  Confidence intervals would be good to see in the table in Figure 3-a.  Also, the bar graph in Figure 5 really would benefit from errorbars --- it is difficult to determine if the results are significant.\n\n7)  While the text is generally clear and definitely understandable, I have a couple of comments about it:  (i) The last three paragraphs of the introduction are repetitive and I think they can be removed, or at least shortened a lot.  There are also quite a number of grammatical errors throughout the paper, though it is still comprehensible.\n\nEDIT:  In their revision the authors addressed these concerns well and the paper is much more convincing (see longer comment below).  In light of this I have changed my rating from a 5 to an 8.\n']","[80, -60, 50]","[70, 20, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the work, calling it an 'impressive proof-of-concept' and stating that it 'would deserve publication for itself.' They also highlight its originality and significance. The only slight criticism is the request for more real-world experiments and a proper comparison with previous work, which prevents a perfect score. The politeness score is 70 (polite) as the reviewer uses respectful and constructive language throughout. They offer praise where due and frame suggestions for improvement in a considerate manner, such as 'More real-world experiments would be welcome' rather than demanding them. The tone is professional and courteous, though not excessively formal or deferential, hence the score of 70 rather than higher."", ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several major weaknesses, including the lack of comparison to baselines, insufficient experimental results, and concerns about the novelty of the approach. The reviewer states that 'the paper doesn't seem to be ready yet,' indicating a negative overall assessment. However, the score is not at the extreme negative end because the reviewer does acknowledge some strengths, such as clear writing and tackling an important research problem. The politeness score is 20 because while the reviewer's tone is generally professional and constructive, they use direct language to point out flaws. The reviewer offers specific recommendations for improvement and uses phrases like 'I request the authors to address the comments,' which maintains a level of politeness. However, the criticism is quite direct, preventing a higher politeness score."", ""The sentiment score is 50 (slightly positive) because the reviewer finds the motivation persuasive and the approach sound, but also expresses several concerns and suggestions for improvement. The initial positive comments are balanced by the list of issues to address. The final edit indicating the authors addressed concerns well and raising the rating from 5 to 8 further supports a moderately positive sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g. 'The paper would benefit from...'), and acknowledges improvements in the revision. The tone is professional and courteous, offering specific suggestions rather than harsh criticisms.""]"
"['Paper Summary -\nThe authors trained RNNs to recognize formal languages defined by random regular expressions, then measured the accuracy of decoders that predict states of the minimal deterministic finite automata (MDFA) from the RNN hidden states. They then perform a greedy search over partitions of the set of MDFA states to find the groups of states which, when merged into a single decoder target, maximize prediction accuracy. For both the MDFA and the merged classes prediction problems, linear decoders perform as well as non-linear decoders.\nClarity - The paper is very clear, both in its prose and maths.\nOriginality - I don\'t know of any prior work that approaches the relationship between RNNs and automata in quite this way.\nQuality/Significance - I have one major concern about the interpretation of the experiments in this paper.\n\nThe paper seems to express the following logic:\n1 - linear (and non-linear) decoders aren\'t so good at predicting MDFA states from RNN hidden states\n2 - if we make an ""abstract"" finite automata (FA) by merging states of the MDFA to optimize decoder performance, the linear (and non-linear) decoders are much better at predicting this new, smaller FA\'s states.\n3 - thus, trained RNNs implement something like an abstract FA to recognize formal languages.\n\nHowever, a more appropriate interpretation of these experiments seems to be:\n1 - (same)\n2 - if we find the output classes the decoder is most often confused between, then merge them into one class, the decoder\'s performance increases -- trivially. in other words, you just removed the hardest parts of the classification problem, so performance increased. note: performance also increases because there are fewer classes in the merged-state FA prediction problem (e.g., chance accuracy is higher).\n3 - thus, from these experiments it\'s hard to say much about the relationship between trained RNNs and finite automata.\n\nI see that the ""accuracy"" measurement for the merged-state FA prediction problem, \\rho, is somewhat more complicated than I would have expected; e.g., it takes into account \\delta and f(h_t) as well as f(h_{t+1}). Ultimately, this formulation still asks whether any state in the merged state-set that contains f(h) transitions under the MDFA to the any state in the merged state-set that contains f(h_{t+1}). As a result, as far as I can tell the basic logic of the interpretation I laid out still applies.\n\nPerhaps I\'ve missed something -- I\'ll look forward to the author response which may alleviate my concern.\n\nPros - very clearly written, understanding trained RNNs is an important topic\nCons - the basic logic of the conclusion may be flawed (will await author response)\n\nMinor -\nThe regular expression in Figure 6 (Top) is for phone numbers instead of emails.\n""Average linear decoding accuracy as a function of M in the MDFA"" -- I don\'t think ""M"" was ever defined. From contexts it looks like it\'s the number of nodes in the MDFA.\n""Average ratio of coarseness"" -- It would be nice to be explicit about what the ""ratio of coarseness"" is. I\'m guessing it\'s (number of nodes in MDFA)/(number of nodes in abstracted DFA).\nWhat are the integers and percentages inside the circles in Figure 6?\nFigures 4 and 5 are difficult to interpret because the same (or at least very similar) colors are used multiple times.\nI don\'t see ""a"" (as in a_t in the equations on page 3) defined anywhere. I think it\'s meant to indicate a symbol in the alphabet \\Sigma. Maybe I missed it.', 'This paper aims to show that an RNN trained to recognize regular languages effectively focuses on a more abstract representation of the FSA of the corresponding language. \n\nUnderstanding the type of information encoded in the hidden states of RNNs is an important research question. Recent results have shown connections between existing RNN architectures and both weighted (e.g., Chen et al., NAACL 2018, Peng et al., EMNLP 2018) and unweighted (Weiss et al., ACL 2018) FSAs. This paper asks a simple question: when trained to recognize regular languages, do RNNs converge on the same states as the corresponding FSA? While exploring solutions to this question is potentially interesting, there are significant clarity issues in this paper which make it hard to understand it. Also, the main claim of the paper — that the RNN is focusing on a low level abstraction of thew FSA — is not backed-up by the results.\n\nComments:\n\n— The authors claim that the RNN states map to FSA states with *low* coarseness, but Figure 3b (which is never referred to in text…) shows that in most cases the ratio of coarseness is at least 1/3, and in some cases > 1/2. \n\n— Clarity:\nWhile the introduction is relatively clear starting from the middle of section 3 there are multiple clarity issues in this paper. In the current state of affairs it is hard for me to evaluate the full contribution of the paper.\n\n- The definitions in section 3 were somewhat confusing. What is the conceptual difference between the two accuracy definitions? \n\n- When combining two states, does the new FSA accept most of the strings in the original FSAs? some of them? can you quantify that? Also, figure 6 (which kind of addresses this question) would be much more helpful if it used simple expressions, and demonstrated how the new FSA looks like after the merge.\n\n- section 4 leaves many important questions unanswered:\n1. Which RNN was used? which model? which parameters? which training regime? etc.\n2. How were the expressions sampled? the authors mention that they were randomly sampled, so how come they talk about DATE and EMAIL expressions?\n3. What is the basic accuracy of the RNN classifier (before decoding)? is it able to learn to recognize the language? to what accuracy? \n\n- Many of the tables and figures are never referred to in text (Figure 3b, Figure 5)\n\n- In Figure 6, there is a mismatch between the regular expression (e.g., [0-9]{3}….) and the transitions on the FSA (a-d, @).\n\n- How come Figure 3a goes up to 1.1? isn’t it bounded by 1? (100%?)\n\n- The negative sampling procedure should be described in the main text, not the appendix. Also, it is not clear how come shuffling the characters is considered an independent distribution.\n\n', 'This paper investigates internal working of RNN, by mapping its hidden states\nto the nodes of minimal DFAs that generated the training inputs and its \nabstractions. Authors found that in fact such a mapping exists, and a linear\ndecoder suffices for the purpose. \nInspecting some of the minimal DFAs that correspond to regular expressions, \ninduced state abstractions are intuitive and interpretable from a viewpoint of\ntraining RNNs by training sequences.\n\nThis paper is interesting, and the central idea of using formal languages to\ngenerate feeding inputs is good (in fact, I am also doing a different research\nthat also leverages a formal grammar with RNN).\n\nMost of the paper is clear, so I have only a few minor comments:\n\n- In Figures 4 and 5, the most complex MDFA of 14 nodes does not have the\n  lowest testing accuracies. In other words, testing accuracies is not\n  generally proportional to the complexity of MDFA. Why does this happen?\n\n- As noted in the footnote in page 5, state abstraction is driven by the idea\n  of hierarchical grammars. Then, as briefly noted in the conclusion, why not\n  using a simple CFG or PCFG to generate training sequences? \n  In this case, state abstractions are clear by definition, and it is curious\n  to see if RNN actually learns abstract states (such as NP and VP in natural\n  language) through mapping from hidden states to abstracted states.\n\n- Because this paper is exploratory, I would like to see more examples\n  beyond only the two in Figure 6. Is it possible to generate a regular \n  expression itself randomly to feed into RNN?\n']","[-50, -50, 60]","[60, 20, 80]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('very clearly written', 'understanding trained RNNs is an important topic'), they express a 'major concern' about the interpretation of the experiments. The reviewer suggests that the paper's main conclusion may be flawed, which is a significant negative point. However, the reviewer leaves room for clarification in the author response, so it's not entirely negative. The politeness score is 60 because the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively. They use phrases like 'Perhaps I've missed something' and 'I'll look forward to the author response', which show politeness and openness to dialogue. The reviewer also provides detailed feedback and suggestions for improvement, which is helpful and considerate. While critical, the tone remains professional and courteous throughout."", ""The sentiment score is -50 because the review expresses significant concerns about clarity issues and states that the main claim is not backed up by results. However, it's not entirely negative as it acknowledges the potential interest of the research question. The politeness score is 20 because the reviewer uses generally respectful language and frames criticisms as observations or questions rather than direct attacks. They use phrases like 'potentially interesting' and 'it is hard for me to evaluate' which maintain a polite tone. However, the review is also quite direct in pointing out flaws, which prevents a higher politeness score."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as 'interesting' and praises the central idea as 'good'. The overall tone is constructive and appreciative. However, it's not extremely positive as the reviewer does have some questions and suggestions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing their comments as 'minor' and using phrases like 'I would like to see' rather than making demands. The reviewer also acknowledges the exploratory nature of the work. The language is consistently professional and courteous, without any harsh criticism or rude remarks.""]"
"['This paper aims at matching people\'s voices to the images of their faces. It describes a method to train shared embeddings of voices and face images. The speech and image features go through separate neural networks until a shared embedding layer. Then a classification network is built on top of the embeddings from both networks.  The classification network predicts various combinations of covariates of faces and voices: gender, nationality, and identity.  The input to the classification network is then used as a shared representation for performing retrieval and matching tasks.\n\nCompared with similar work from Nagrani et al (2018) who generate paired inputs of voices and faces and train a network to classify if the pair is matched or not, the proposed method doesn\'t require paired inputs.  It does, however, require inputs that are labeled with the same covariates across modalities.  My feeling is that paired positive examples are easier to obtain (e.g., from unlabeled video) than inputs labeled with these covariates, although paired negative examples require labeling and so may be as difficult to obtain.\n\nSeveral different evaluations are performed, comparing networks that were trained to predict all subsets of identity, gender, and nationality.  These include identifying a matching face in a set of faces (1,2 or N faces) for a given voice, or vice versa. Results show that the network that predicts identity+gender tends to work best under a variety of careful examinations of various stratifications of the data.  These stratifications also show that while gender is useful overall, it is not when the gender of imposters is the same as that of the target individual.  The results also show that even when evaluating the voices and faces not shown in the training data, the model can achieve 83.2% AUC on unseen/unheard individuals, which outperforms the state-of-the-art method from Nagrani et al (2018).\n\nAn interesting avenue of future work would be using the prediction of these covariates to initialize a network and then refine it using some sort of ranking loss like the triplet loss, contrastive loss, etc.\n\n\nWriting:\n* Overall, ciations are all given in textual form Nagrani et al (2018) (in latex this is \\citet{} or \\cite{}), when many times parenthetical citations (Nagrani et al, 2018) (in latex this is \\citep{}) would be more appropriate.\n* The image of the voice waveform in Figures 1 and 2 should be replaced by log Mel-spectrograms in order to illustrate the network\'s input.\n* ""state or art"" instead of ""state-of-the-art"" on page 3. \n* In subsection 2.4: ""mGiven"" is written instead of ""Given"". \n* On Page 6 Section 3.1 ""1:2 matching"" paragraph. ""Nagrani et al."" is written twice. * * Page 6 mentions that there is a row labelled ""SVHF-Net"" in table 2, but there is no such row is this table. \n* Page 7 line 1, “G,N” should be ""G, N"".\n', '# Summary\n\nThe article proposes a deep learning-based approach aimed at matching face images to voice recordings belonging to the same person. \n\nTo this end, the authors use independently parametrized neural networks to map face images and audio recordings -- represented as spectrograms -- to embeddings of fixed and equal dimensionality. Key to the proposed approach, unlike related prior work, these modules are not directly trained on some particular form of the cross-modal matching task. Instead, the resulting embeddings are fed to a modality-agnostic, multiclass logistic regression classifier that aims to predict simple covariates such as gender, nationality or identity. The whole system is trained jointly to maximise the performance of these classifiers. Given that (face image, voice recording) pairs belonging to the same person must share equal for these covariates, the neural networks embedding face images and audio recordings are thus indirectly encouraged to map face images and voice recordings belonging to the same person to similar embeddings.\n\nThe article concludes with an exhaustive set of experiments using the VGGFace and VoxCeleb datasets that demonstrates improvements over prior work on the same set of tasks.\n\n# Originality and significance\n\nThe article follows-up on recent work [1, 2], building on their original application, experimental setup and model architecture. The key innovation of the article, compared to the aforementioned papers, lies on the idea of learning face/voice embeddings to maximise their ability to predict covariates, rather than by explicitly trying to optimise an objective related to cross-modal matching. While the fact that these covariates are strongly associated to face images and audio recordings had already been discussed in [1, 2], the idea of actually using them to drive the learning process is novel in this particular task.\n\nWhile the article does not present substantial, general-purpose methodological innovations in machine learning, I believe it constitutes a solid application of existing techniques. Empirically, the proposed covariate-driven architecture is demonstrated to lead to better performance in the (VGGFace, VoxCeleb) dataset in a comprehensive set of experiments. As a result, I believe the article might be of interest to practitioners interested in solving related cross-modal matching tasks.\n\n# Clarity\n\nThe descriptions of the approach, related work and the different experiments carried out are written clearly and precisely. Overall, the paper is rather easy to read and is presented using a logical, easy-to-follow structure.\n\nIn my opinion, perhaps the only exception to that claim lies in Section 3.4. If possible, I believe the Seen-Heard and Unseen-Unheard scenarios should be introduced in order to make the article self-contained. \n\n# Quality\n\nThe experimental section is rather exhaustive. Despite essentially consisting of a single dataset, it builds on [1, 2] and presents a solid study that rigorously accounts for many factors, such as potential confounding due to gender and/or nationality driving prediction performance in the test set. \n\nMultiple variations of the cross-modal matching task are studied. While, in absolute terms, no approach seems to have satisfactory performance yet, the experimental results seem to indicate that the proposed approach outperforms prior work.\n\nGiven that the authors claimed to have run 5 repetitions of the experiment, I believe reporting some form of uncertainty estimates around the reported performance values would strengthen the results.\n\nHowever, I believe that the success of the experimental results, more precisely, of the variants trained to predict the ""covariate"" identity, call into question the very premise of the article. Unlike gender or nationality, I believe that identity is not a ""covariate"" per se. In fact, as argued in Section 3.1, the prediction task for this covariate is not well-defined, as the set of identities in the training, validation and test sets are disjoint. In my opinion, this calls into question the hypothesis that what drives the improved performance is the fact that these models are trained to predict the covariates. Rather, I wonder if the advantages are instead a ""fortunate"" byproduct of the more efficient usage of the data during the training process, thanks to not requiring (face image, audio recording) pairs as input.\n\n# Typos\n\nSection 2.4\n1) ""... image.mGiven ...""\n2) Cosine similarity written using absolute value |f| rather than L2-norm ||f||_{2}\n3) ""Here we are give a probe input ...""\n\n# References\n\n[1] Nagrani, Arsha, Samuel Albanie, and Andrew Zisserman. ""Learnable PINs: Cross-Modal Embeddings for Person Identity."" arXiv preprint arXiv:1805.00833 (2018).\n[2] Nagrani, Arsha, Samuel Albanie, and Andrew Zisserman. ""Seeing voices and hearing faces: Cross-modal biometric matching."" Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.', 'Authors aim to reveal relevant dependencies between voice and image data (under a cross-modal matching framework) through common covariates (gender, ID, nationality). Each covariate is learned using a CNN from each provided domain (speak recordings and face images), then, a classifier is determined from a shared representation, which includes the CNN outputs from voice-based and image-based covariate estimations. The idea is interesting, and the paper ideas are clear to follow.\n\nPros:\n- New insights to support cross-modality matching from covariates.\n- Competitive results against state-of-the-art.\n-Convincing experiments.\n\nCons:\n-Fixing the output dimension to d (for both voice and image-based CNN outputs) could lead to unstable results. Indeed, the comparison of voice and face-based covariate estimates are not entirely fair due to the intrinsic dimensionality can vary for each domain. Alternatives as canonical correlation analysis can be coupled to joint properly both domains.\n- Table 4 - column ID results are not convincing (maybe are not clear for me).']","[70, 60, 60]","[80, 80, 50]","[""The sentiment score is 70 (positive) because the reviewer provides a detailed and generally favorable assessment of the paper. They highlight the paper's novel approach, its improvements over previous work, and its interesting results. The reviewer also suggests future work, indicating engagement with the research. However, it's not a perfect score as there are some critiques and suggestions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They offer suggestions and critiques in a professional manner, using phrases like 'An interesting avenue of future work would be...' and providing specific, helpful feedback on writing and formatting issues. The tone is consistently collegial and supportive, even when pointing out areas for improvement."", ""The sentiment score is 60 (positive) because the reviewer generally speaks favorably of the paper, noting its originality, clarity, and solid experimental results. They mention that the paper 'might be of interest to practitioners' and 'constitutes a solid application of existing techniques'. However, it's not extremely positive as they raise some questions about the premise and suggest improvements. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and balances positive comments with suggestions for improvement. They use phrases like 'I believe' to soften critiques and acknowledge the authors' efforts. The reviewer also provides helpful suggestions for minor improvements and even points out typos, which shows attentiveness and a desire to help improve the paper."", ""The sentiment score is 60 (positive) because the reviewer starts by describing the paper's aim and approach in a neutral tone, then explicitly states 'The idea is interesting, and the paper ideas are clear to follow.' The reviewer also lists several pros, including 'new insights,' 'competitive results,' and 'convincing experiments.' While there are some cons mentioned, they are presented as constructive criticism rather than major flaws. The politeness score is 50 (slightly polite) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to describe the paper's content and provide a balanced view of pros and cons. The criticism is presented constructively without harsh language. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a fairly neutral professional tone overall.""]"
"['This paper describes two distinct contributions: a new compound criterion for comparing a temporal clustering to a ground truth clustering and a new bayesian temporal clustering method. Globally the paper is clear and well illustrated. \n1) About the new criterion:\n*pros: *\n a) as clearly pointed out by the authors, using standard non temporal clustering comparison metrics for temporal clustering evaluation is in a way ""broken by design"" as standard metrics disregard the very specificity of the problem. Thus the introduction of metrics that take explicitly into account time is extremely important.\n b) the proposed criterion combines two parts that are very important: finding the length of the stable intervals (i.e. intervals whose instants are all classified into a single cluster) and finding the sequence of labels. \n*cons:*\n a) while the criterion seems new it is also related to criteria used in the segmentation literature (see among many other https://doi.org/10.1080/01621459.2012.737745) and it would have been a good idea to discuss the relation between temporal clustering and segmentation, even briefly.\nb) the reliance on a tradeoff parameter in the final criterion is a major problem: how shall one chose the parameter (more on this below)? The paper does not explore the effect of modifying the parameter.\nc) in the experimental section, TSS is mostly compared to NMI and to optimal matching (called Munkres here). Even considering the full list of criteria in the appendix, the normalized rand index (NRI) seems to be missing. This is a major oversight as the NRI is very adapted to comparing clusterings with different number of clusters, contrarily to NMI. In addition, the authors claim that optimal matching is completely opaque and difficult to analyse, while on the contrary it gives a proper way of comparing clusters from different clusterings, enabling fine grain analysis. \n\n2) about the new model\n*pros*: \n a) as far as I know, this is indeed a new model\n b) the way the model is structured emphasizes segmentation rather than temporal dependency: the so called procedure is arbitrary and no dependency is assumed from one segment to another. In descriptive analysis this is highly desirable (as opposed to say HMM which focuses on temporal dependencies). \n*cons*\na) the way the length of the segments in the sequence are generated (with sorting) this a bit convolved. Why not generating directly those lengths? What is the distribution of those lengths under the sampling model? Is this adapted? \nb) I find the experimental evaluation acceptable but a bit poor. In particular, nothing is said on how a practitioner would tune the parameters. I can accept that the model will be rather insensitive to hyper-parameters alpha and beta, but I\'ve serious doubt about the number of clusters, especially as the evaluation is done here in the best possible setting. In addition, the other beta parameter (of TSS) is not studied. \n\nMinor point:\n- do not use beta for two different things (the balance in TSS and the prior parameter in the model)', 'This is a hybrid paper, making contributions on two related fronts:\n1. the paper proposes a performance metric for sequence labeling, capturing salient qualities missed by other metrics, and\n2. the paper also proposes a new sequence labeling method based on inference in a hierarchical Bayesian model, focused on simultaneously labeling multiple sequences that have the same underlying procedure but with varying segment lengths.\n\n\nThis paper is not a great topic fit for ICLR: it\'s primarily about a hand-designed performance metric for sequence labeling and a hierarchical Bayesian model with Gaussian observations and fit with Gibbs sampling in a full-batch setting. The ICLR 2019 reviewer guidelines suggest ""Ask yourself: will a substantial fraction of ICLR attendees be interested in reading this paper?"" and based on my understanding of the ICLR audience I suspect not. Based on looking at past ICLR proceedings, this paper\'s topic and collection of techniques is not in the ICLR mainstream (though it\'s not totally unrelated). The authors could convince me that I\'m mistaken by pointing out closely related ICLR papers (e.g. with a similar mix of techniques in their methods, or similarly proposing a hand-designed performance metric); as far as I can tell, none of the papers cited in the references are from ICLR, but rather from e.g. NIPS, AISTATS, and IEEE TPAMI, which I believe would be better fits for this kind of work.\n\nOne way to make this work more relevant to the ICLR audience would be to add feature learning (especially based on neural network architectures). That might also entail additional technical contributions, like how to fit models like these in the minibatch setting (where the current Gibbs sampling method might not apply).\n\n\nOn the proposed performance metric, the discussion of existing metrics as they apply to the example in Fig 3 was really helpful. (I assume, but didn\'t check, that the authors\' characterization of the published performance metrics is accurate, e.g. ""no traditional clustering criteria can distinguish C_2 from C_3"".) The proposed metric seems to help.\n\nBut it\'s a bit complicated, with several free design decisions involved (e.g. choosing the scoring function \\mathcal{H} in Sec 3.1, the choice of conditional entropy H in Sec 3.2, the choice of \\beta in Sec 3.3, the choice of the specific algebraic forms of RSS, LASS, SSS, and TSS). Certainly the proposed metrics incorporate the kind of information that the authors argue can be important, but the design details of how that information is summarized into a single number aren\'t really explored or weighed against alternative designs choices. \n\nIf a primary aim of this paper is to propose a new performance metric, and presumably to have it catch on with the rest of the field, then the contribution would be much greater if the design space was clearly articulated, alternatives were considered, and multiple proposals were validated. Validation could be done with human labelers ranking the intuitive \'goodness\' of labeling results (and then compared to rankings derived from the proposed performance metrics), and with comparing how the metrics correlate with performance on various downstream tasks.\n\nAnother idea is to take advantage of a better segmentation performance metric and use it to automatically tune the hyperparameters of the sequence labeling methods considered in the experiments section. (IIUC hyperparameters were set by hand in the experiments.). That would make for more interesting experiments that give a more comprehensive summary of how these techniques can compare.\n\nHowever, as it stands, while the performance metric itself may have merit, in this paper it is not sufficiently well validated or compared to alternatives.\n\n\nOn the hierarchical Bayesian model, the current model design andinference algorithm are okay but don\'t constitute major technical contributions. I was surprised by some model details: for example, in ""Modeling the procedure"" of Sec 4.1, it would be much more satisfying to generate the (p_1, ..., p_s) sequence from an HMM instead of sampling the elements of the sequence independently, dropping any chance to learn transition structure as part of the Bayesian inference procedure. More importantly, it wasn\'t made clear if \'self-transitions\' where p_s = p_{s+1} were ruled out, though such transitions might confuse the model\'s semantics. As another example, in ""Modeling the realizations in each time-series"" of Sec 4.1, the procedure based on iid sampling and sorting seems unnatural, and might make inference more complex. Why not just sample the durations directly (rather than indirectly defining them via sorting independently-generated indices)? If there\'s a good reason, it should probably be discussed (e.g. maybe parameterizing the durations directly would make it easier to express prior distributions over *absolute* segment lengths, but harder to express distributions over *relative* segment lengths?). Finally, the restriction to conditionally iid Gaussian observations was disappointing.\n\nThe experimental results were solid on the task for which the model\'s extra assumptions paid off, but that\'s a niche comparison.\n\nOne suggestion on the baseline front: you can tie multiple HMMs to have the same procedure (i.e. the same state sequences not counting repeats) by fixing the number of states to be s (the length of the procedure sequence) and fixing the transition matrices to have an upper-bidiagonal support structure. A similar construction can be used for HSMMs. I think a natural Gibbs sampling procedure would emerge. This approach is probably written down in the HMM literature (it seems every conceivable HMM variant has been studied!) but I don\'t have a reference for it.\n\n\nOverall, this paper needs more work.\n\n\nMinor suggestions:\n- maybe refer to ""segment structure"" (e.g. in Sec 3), as ""changepoint structure"" (and consider looking into changepoint performance metrics if you haven\'t already)\n- if you used code from other authors in your baselines, it would be good to cite that code (e.g. GitHub links)', 'In ""Learning procedural abstractions and evaluating discrete latent temporal structure"" the authors develop a hierarchical Bayesian model for patterns across time in video data. They also introduce new metrics for understanding structure in time series (completeness and homogeneity). This work is appropriate for ICLR. They provide some applications to robotics, suggesting that this could be used to teach robots to act in environments by learning from videos.\n\nThis manuscript paid quite close attention to quality of segmentation, in which actions in videos are decomposed into component parts. It is quite hard to determine groundtruth in such situations and many metrics abound, and so a thorough discussion and comparison of metrics is useful.\n\nThe state of the art for Bayesian hierarchical models for segmentation is Fox et al., which is referenced heavily by this work (including the use of test data prepared in Fox et al.) I wonder why the authors drop the Bayesian nonparametric nature of the hierarchy in the section ""Modeling realizations in each time-series"" (i.e., for Fox et al., the first unnumbered equation in this section would have had arbitrary s).\n\nI found that the experiments were quite thorough, with many methods and metrics compared. However, I found the details of the model to be quite sparse, for example it\'s unclear how Figure 5 is that much different from Fox et al. But, overall I found this to be a strong paper.\n']","[20, -50, 60]","[60, 20, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's clarity, good illustrations, and the importance of the new criterion. They also highlight several pros for both contributions. However, the score is not higher due to the significant cons mentioned, such as oversight in comparison methods and issues with parameter tuning. The politeness score is moderately high (60) as the reviewer maintains a professional tone throughout, balancing praise with constructive criticism. They use phrases like 'clearly pointed out by the authors' and 'as far as I know,' which show respect for the authors' work. The reviewer also frames criticisms as suggestions for improvement rather than harsh judgments, contributing to the polite tone."", ""The sentiment score is -50 because the overall tone is critical and suggests significant improvements are needed. The reviewer states 'this paper needs more work' and points out several shortcomings, including that it's not a great fit for ICLR, the performance metric is not well validated, and the model design has limitations. However, some positive aspects are acknowledged, like the helpful discussion of existing metrics and solid experimental results in a niche area, preventing the score from being more negative. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They offer constructive suggestions for improvement and use phrases like 'One suggestion...' and 'Another idea is...' which soften the critique. The language is not overtly polite, but it avoids rudeness and maintains a respectful, academic tone."", ""The sentiment score is 60 (moderately positive) because the reviewer describes the paper as 'strong' and 'appropriate for ICLR', and praises the thorough experiments and attention to quality. However, they also point out some areas for improvement, such as sparse model details. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'I wonder why' and 'I found' to soften their critiques, maintaining a professional and courteous tone.""]"
"['General comment\n==============\nThe authors used policy gradient optimization for generating RNA sequences that fold into a target secondary structure, reporting clear accuracy and runtime improvements over the previous state-of-the-art. The authors used BOHR for optimizing hyper-parameters and present a new dataset for evaluating RNA design methods. The paper is well motivated and mostly clearly written. However, the methodological contributions are limited and I have some important concerns about their evaluation. Overall, I feel it’s a good paper for an ICLR workshop or biological journal if the authors address the outstanding comments.\n\nMajor comments\n=============\n1. The methodological contributions are limited. The authors used existing approaches (policy gradient optimization and BOHR for hyperparameter optimization) but do not report new methods, e.g. for sequence modeling. Performing hyper-parameter optimization is in my eyes not novel, but common practice in the field. It would me more informative if the authors compared reinforcement learning to other approaches for (conditional) sequence generations, e.g. RNNs, autoregressive models, VAEs, or GANs, which have been previously reported for biological sequence generation (e.g. http://arxiv.org/abs/1804.01694).\n\n2. Did the authors split all three datasets (Eterna, Rfam-Taneda, Rfam-learn-test) into train, eval, and test set, trained their method on the training set, optimized hyper-parameters on the eval set, and measured generalization and runtime on the test set? This is not described clearly enough in section 5. I suggest to summarize the number of sequences for each dataset and split in a table.\n\n3. Did the authors also optimize the most important hyperparameters of RL-LS and other methods? Otherwise it is unclear if the performance gain is due to hyperparameter optimization or the method itself.\n\n4. The time measurement (x-axis figure 3) is unclear. Is it the time that methods were given to solve a particular target structure and does figure 3 show the average number of solved structures in the test for a the time shown on the x-axis? \n\n5. Were all methods compared on the same hardware (section 5; 20 cores; Broadwell E5-2630v4 2.2 GHz CPUs) and can they be parallelized over multiple CPU or GPU cores? This is essential for a fair runtime comparison.\n\n6. The term ‘run’ (“unreliable outcomes in single runs”, section 4) is unclear. Is it a single sample from the model (one rollout), a particular hyperparameter configuration, or training the model once for a single target structure? This must be clarified for understanding the evaluation.\n\n7. How does the accuracy and runtime or LEARNA scale depending on the sequence (structure) length?\n\n8. How sensitive is the model performance depending on the context size k for representing the current state? Did the authors try to encode the entire target structure with, e.g. recurrent models, instead of using a window centered on the current position?\n\n9. The authors should more clearly describe the local optimization step (section 3.1; reward). Were all nucleotides that differ mutated independently, or enumerated exhaustively? The latter would have a high runtime of O(3^d), where d is the number of nucleotides that differ. When do the authors start with the local optimization? \n\nMinor comments\n=============\n10. The authors should replace ‘450x’ faster in the abstract by ‘clearly’ faster since the evaluation does not show that LEARNA is 450x faster than all other methods.\n\n11. Does “At its most basic form” (introduction) mean that alternative RNA nucleotides exist? If so, this should be cited.\n\n12. The authors should more clearly motive in the introduction why they created a new dataset.\n\n13. The authors should mention in section 2.1 that the dot-bracket notation is not the only notation for representing RNA structures (https://www.tbi.univie.ac.at/RNA/ViennaRNA/doc/html/rna_structure_notations.html).\n\n14. The authors should define the hamming distance (section 2.1). Do other distance metrics exist?\n\n15. For the Traveling Salesman Problem (section 2.2) should the reward be the *negative* tour length?\n\n16. The authors should more clearly describe the embedding layer (section 4). Are nucleotides one-hot encoded or represented as integers (0, 1  for ‘(‘ and ‘.’)?', ""This work tackles the difficult RNA design problem, i.e. that of finding a RNA primary sequence that is going to fold into a secondary/tertiary structure able to perform a desired biological function. More specifically, it used Reinforcement Learning (RL) to find the best sequence that will fold into a target secondary structure, using the Zuker algorithm and designing a new primary sequence 'from scratch'. A new benchmark data set is also introduced in the paper along .\n\nQuestions/remarks:\n - I struggle with your notations as soon as section 2.1. What is the star (*) superscript for? Was expecting the length of the RNA sequence instead. Same on p4, when introducing the notation of your decision process $ D_w $, explicitly introduce all the ingredients.\n - in Equation (2) on p4, maybe clarify the notation with '.', '(' and ')' for example as the reader could really struggle.\n - I didn't really understand the message in Section 4, not being an expert in the field. Could you clarify your contribution here?\n - your 'Ablation study' in Section 5.2; does it correspond to true uncertainty/noise that could be observed in real data?\n - why a new benchmark data set, when there exist good ones to compare your method to, e.g. in competitions like CASP for proteins?\n - do you make your implementation available?\n - quite like the clarification of the relationship of your work to that of Eastman et al. 2018. Could you also include discussions to other papers, e.g. Chuai et al. 2018 Genome Biol and Shi et al. 2018 SentRNA on arXiv?\n\nAltogether the paper reads well, seems to have adequate references, motivates and proposes 3 variations of a new algorithm for a difficult learning problem. Not being an expert in the field, I just can't judge about the novelty of the appraoch."", ""I'm happy with the revisions the authors have made, as I find that they call out the novel contributions a bit more explicitly. Specifically I see some novel work in the area of simultaneous multi-task/meta-RL and black box optimization of the policy net architectures. I don't think calling this NAS is justified; calling it bayesopt or black box opt is fair. NAS uses a neural net to propose experiments over structured graphs of computation nodes. This work appears to be simpler hyperparameter optimization.\n\n====\n\nQuality:\nThe work is well done, and the experiments are reasonable/competitive, showcasing other recent work and outperforming. \n\nClarity:\nI thought the presentation was tolerable. I was a bit confused by Table 1 until reading the prose at the bottom of page 7 indicated Table 1 is presenting percentages, not integer quantities. The local improvement step is not very clearly explained. Are all combos tried across all mismatched positions, or do we try each mismatched position independently holding the others to their predicted values? What value of zeta did you end up using? It seems like this is essential to getting good performance. It is completely unclear to me what the 'restart option' does.\n\nOriginality:\nUsing RL in this specific application setting seems relatively new (though also explored by RL-LS in https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6029810/). On the other hand, the approach used doesn't seem to be substantially different than anything else typically used for policy gradient RL. The meta-learning approach is interesting, though again not too different from multi-task approaches (though these are perhaps less common in RL than in general deep learning).\n\nSignificance:\nLikely to be of practical utility in the inverse design space, specifically therapeutics, CRISPR guide RNA design, etc. Interesting to ICLR as an application area but probably not much theory/methods interest.\n\n\nOn balance I lean slightly against accepting and think this is a better fit to either a workshop or a more domain-specific venue (MLHC http://mucmd.org/ for example).""]","[-20, 50, 20]","[50, 80, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('clear accuracy and runtime improvements', 'well motivated and mostly clearly written'), they express several major concerns and state the paper would be more suitable for a workshop or biological journal rather than the main ICLR conference. The overall tone suggests the work needs significant improvements. The politeness score is moderately positive (50) as the reviewer uses professional and constructive language throughout, offering specific suggestions for improvement rather than harsh criticism. They acknowledge positive aspects before diving into concerns, and use phrases like 'I suggest' and 'The authors should' rather than more demanding language. The review maintains a respectful tone while still clearly communicating areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by acknowledging the difficulty of the problem and the contribution of the paper, including the introduction of a new benchmark dataset. The overall tone is constructive, with the reviewer stating that the paper 'reads well' and has 'adequate references'. However, they also express some confusion and request clarifications, which prevents a higher positive score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing their comments as questions or suggestions rather than criticisms. They use phrases like 'Could you clarify' and 'I struggle with' instead of more direct or harsh language. The reviewer also compliments aspects of the paper, such as the clarification of relationships to other work, which adds to the politeness."", ""The sentiment score is slightly positive (20) because the reviewer expresses happiness with the revisions and acknowledges novel contributions, but also has some criticisms and leans slightly against accepting. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and provides constructive feedback. However, they maintain a professional tone rather than being overly polite. The reasoning is based on phrases like 'I'm happy with the revisions', balanced with critiques like 'I thought the presentation was tolerable', and the overall constructive yet critical nature of the review.""]"
"['** review score incremented following discussion below **\n\nStrengths:\n\nWell written and clear paper\nIntuition is strong: not all source-target class pairs are as beneficial to find adversarial examples for \n\nWeaknesses:\n\nCost matrices choices feel a bit arbitrary in experiments\nCIFAR experiments still use very small norm-balls\n\nThe submission builds on seminal work by Dalvi et al. (2004), which studied cost-sensitive adversaries in the context of spam detection. In particular, it extends the approach to certifiable robustness introduced by Wong and Kolter with a cost matrix that specifies for each pair of source-target classes whether the model should be robust to adversarial examples that are able to take an input from the source class to the target (or conversely whether these adversarial examples are of interest to an adversary).\n\nWhile the presentation of the paper is overall of great quality, some elements from the certified robustness literature could be reminded in order to ensure that the paper is self-contained. For instance, it is unclear how the guaranteed lower bound is derived without reading prior work. Adding this information in the present submission would make it easier for the reader to follow not only Sections 3.1 and 3.2 but also the computations behind Figure 1.b. \n\nThe experiments results are clearly presented but some of the details of the experimental setup are not always justified. If you are able to clarify the following choices in your rebuttal, this would help revise my review. First, the choice of cost matrices feels a bit arbitrary and somewhat cyclical. For instance, binary cost matrices for MNIST are chosen according to results found in Figure 1.b, but then later the same bounds are used to evaluate the performance of the approach. Yet, adversarial incentives may not be directly correlated with the “hardness” of a source-target class pair as measured in Figure 1.b. The real-valued cost matrices are better justified in that respect. Second, would you be able to provide additional justification or analysis of the choice of the epsilon parameter for CIFAR-10? For MNIST, you were able to improve the epsilon parameter from epsilon=0.1 to epsilon=0.2 but for CIFAR-10 the epsilon parameter is identical to Wong et al. Does that indicate that the results presented in this paper do not scale beyond simple datasets like MNIST?\n\nMinor comments:\n\n\nP2: The definition of adversarial examples given in Section 2.2 is a bit too restrictive, and in particular only applies to the vision domain. Adversarial examples are usually described as any test input manipulated by an adversary to force a model to mispredict.\nP3: typo in “optimzation” \nP5: trade off -> trade-off \nP8: the font used in Figure 2 is small and hard to read when printed.\n', 'The paper introduces a new concept of certified cost-sensitive robustness against adversarial attacks. A cost-sensitive robust optimization formulation is then proposed for deep adversarial learning. Experimental results on two benchmark datasets (MNIST, CIFAR-10) are reported to show the superiority of the proposed method to overall robustness method, both with binary and real-value cost matrices. \n\nThe idea of cost-sensitive adversarial deep learning is well motivated. The proposed method is clearly presented and the results are easy to access. My main concern is about the novelty of the approach which looks mostly incremental as a rather direct extension of the robust model (Wong & Kolter 2018) to cost-sensitive setting. Particularly, the duality lower-bound based loss function and its related training procedure are almost identical to those from (Wong & Kolter 2018), up to certain trivial modification to respect the pre-specified misclassification costs. The numerical results show some promise. However, as a practical paper, the current empirical study appears limited in data scale: I believe additional evaluation on more challenging data sets can be useful to better support the importance of approach. \n\nPros: \n\n- The concept of certified cost-sensitive robustness is well motivated and clearly presented.\n\nCons:\n\n-  The novelty of method is mostly incremental given the prior work of (Wong & Kolter 2018).\n- Numerical results show some promise of cost-sensitive adversarial learning in the considered settings, but still not supportive enough to the importance of approach.\n\n', 'The authors define the notion of cost-sensitive robustness, which measures the seriousness of adversarial attack with a cost matrix. The authors then plug the costs of adversarial attack into the objective of optimization to get a model that is (cost-sensitively) robust against adversarial attacks.\n\nThe initiative is novel and interesting. Considering the long history of cost-sensitive learning, the proposed model is rather ad-hoc for two reasons:\n\n(1) It is not clear why the objective should take the form of (3.1). In particular, if using the logistic function as a surrogate for 0-1 loss, shouldn\'t the sum of cost be in front of ""log""? If using the probability estimated from the network in a Meta-Cost guided sense, shouldn\'t the cost be multiplied by the probability estimate (like 1/(1+exp(...))) instead of the exp itself? The mysterious design of (3.1) makes no physical sense to me, or at least other designs used in previous cost-sensitive neural network models like\n\nChung et al., Cost-aware pre-training for multiclass cost-sensitive deep learning, IJCAI 2016\nZhou and Liu, Training cost-sensitive neural networks with methods addressing the class imbalance problem, TKDE 2006 (which is cited by the authors)\n\nare not discussed nor compared.\n\nUpdate: I thank the authors for providing updated information in the Appendix discussing about other alternatives. While I still think it worth comparing with other approaches (as it is still not clear whether Khan\'s approach is regarded as state-of-the-art for *general* cost-sensitive deep learning), I think the authors have sufficiently justified their choice.\n\n(2) It is not clear why the perturbed example should take the cost-sensitive form, while the original examples shouldn\'t (as the original examples follow the original loss). Or alternatively, if we optimize the original examples by the cost-sensitive loss, would it naturally achieve some cost-sensitive robustness (as the model would naturally make it harder to make high-cost mistakes)? Those issues are yet to be studied.\n\nUpdate: I thank the authors for providing additional experiments on this part.\n']","[50, -20, 20]","[70, 50, 60]","[""Sentiment Score (50): The review begins by highlighting strengths, acknowledging the paper as well-written and clear with strong intuition. However, it also points out weaknesses, such as arbitrary cost matrices choices and small norm-balls in CIFAR experiments. The overall tone is balanced, leaning slightly positive due to the praise for presentation quality and clear results. Politeness Score (70): The reviewer uses polite and constructive language throughout. They offer suggestions for improvement and ask for clarifications rather than making harsh criticisms. Phrases like 'if you are able to clarify' and 'would you be able to provide' demonstrate a respectful approach. The reviewer also acknowledges the quality of the work in several instances. The minor comments are presented neutrally without negative connotations."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well motivated', 'clearly presented', 'results are easy to access'), they express significant concerns about the novelty of the approach and the limited empirical study. The 'main concern' and 'cons' outweigh the 'pros', indicating a somewhat negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'I believe' to soften their suggestions, and their criticisms are presented as constructive feedback rather than harsh judgments. The review maintains a professional and courteous tone while still clearly communicating areas for improvement."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the initiative as 'novel and interesting', they raise significant concerns and questions about the approach. The initial criticism is somewhat softened by the updates, where the reviewer thanks the authors for additional information and experiments. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the authors' responses, and frames criticisms as questions or areas for further study rather than outright dismissals. The reviewer also uses phrases like 'I thank the authors' which contributes to the polite tone.""]"
"['This paper presents an algorithm to find adversarial attacks to binary neural networks.  Binary neural networks uses sign functions as nonlinearities, making the network essentially discrete.  Previous attempts at finding adversarial attacks for binary neural networks either rely on relaxation which cannot find very good adversarial examples, or calling a mixed integer linear programming (MILP) solver which doesn’t scale.  This paper proposes to decompose the problem and iteratively find desired representations layer by layer from the top to the input.  This so called Integer Propagation (IProp) algorithm is more efficient than solving the full MILP as it solves much smaller MILP problems, one for each layer, thus each step can be solved relatively quickly.  The authors then proposed a few more improvements to the IProp algorithm, including ways to do local adjustments to the solutions, and warming starting from an existing solution.  Experiments on binary neural nets trained for MNIST and Fashion MNIST show the superiority of the proposed method over MILP and relaxation based algorithms.\n\nOverall I found the paper to be very clear and the proposed method is sound.  I think combining ideas from discrete / combinatorial optimization with deep learning is an important research direction and can shed light on training and verifying models with discrete components, like the hard nonlinearities in the binary neural nets studied in this paper.\n\nIn terms of the particular proposed approach, it is hard for me to imagine the blind IProp that does not take the input into account until the last layer is ever going to work.  The small step size modifications make a lot more sense.  Regarding the selection of the set S, in the paper the authors simply sampled elements to be in S uniformly, but it seems possible to make use of the information from the forward pass, and choose the hidden units that are the closed to reaching the desired activations.  Would that be any better?\n\nA few minor comments:\n- when reporting warm start results, it would be good to also show the performance of the FGSM solution used for warm starting, in addition to the other two results shown in Figure 6 to have a more complete comparison\n- the hidden units h_{l,j} were formulated to be in {0, 1} in equation (7), but everywhere else in the paper they are assumed to be in {-1, +1}, which is not consistent and slightly confusing.\n\nOverall I think this is a solid paper and support accepting it for publication.', 'This paper proposed a new attack algorithm based on MILP on binary neural networks. In addition to the full MILP formulation, the authors proposed an integer target propagation algorithm (IProp) to find adversarial examples by solving a smaller (instead of the full) MILP.  \n\nThe topic is important but the clarity should be improved. It is less clear when describing the Iprop algorithm.  \n\nQuestions:\n1. Can IProp work for other architectures? It looks like the propagation steps work on only fully connected layers (or conv layers) with activation functions. Does it work for pooling layers?\n2. The results in Figure 2 look weird and might be wrong:\nsince MIP is the exact solution (green bar), how is it possible that the prediction flip rate of IProp larger than MIP? See top row figures where some red bars are larger than green bars. \n3. Also, is the FGSM method comparing in Figure 2 operating on the approximate BNN as described in the related work? How does the performance of PGD (Madry etal) compared to IProp?  \n4. How are the big M parameters in equation 4 and 5 computed? Is the formulation eq (1) to (8) the same as that in Tjeng 2018? Since BNN is a special case of general neural networks. Please elaborate. \n5. In Sec 2 related work, why ""there\'s no objective function"" for verification method? ', ""The authors study the problem of generating strong adversarial attacks on binarized neural networks (networks whose weights are binary valued and have a sign function nonlinearity).  Since these networks are not continuous (due to the sign function nonlinearity), it is possible that standard gradient-based attack algorithms are not effective at producing adversarial examples. While this problem can be encoded as a mixed integer linear program, off-the-shelf MILP solvers are not scalable to larger/deeper networks. Thus, the authors propose a new target propagation style algorithm that attempts to infer desired activations at each layer (from the perspective of maximizing the adversary's objective) starting at the final layer and moving towards the input. The propagation at each layer requires solving another MILP (albeit a much smaller one). Further, in order to prevent the target propagation from discovering assignments at upper layers that are unachievable given the constraints at lower layers, the authors propose two heuristics (making small moves and penalizing deviations from the previous target values) to obtain an effective attack algorithm. The authors validate their approach experimentally on MNIST/Fashion MNIST image classifiers.\n\nQuality: The paper is reasonably well written and the key ideas are communicated well. However, the experimental section needs to be improved significantly.\n\nClarity: The paper is easy to understand and organized well.\n\nOriginality: The application of target propagation in the context of adversarial examples is certainly novel and so are the specific enhancements proposed in the context of adversarial example generation. The \n\nSignificance: The study of adversarial examples for binarized networks is novel and important and effective attack generation algorithms are a significant first step towards training robust models of this type - this could enable deployment of robust and compact binarized classifiers in on-device settings (where model size is important).\n\nCons\nMy main concerns with this paper are regarding the experimental evaluation - I do not feel these are sufficient to justify the strength of the attack method proposed. Here are my broad concerns:\n1. Even though the datasets used are small (MNIST/Fashion MNIST), the experimental validation of adversarial attacks is only performed on 100 test examples. This is not sufficiently representative (given experimental evidence with adversarial attacks on non-binarized models) and this needs to be addressed for the results to be considered conclusive.\n\n2. The attack method is only compared to FSGM, which is known to be a rather poor attack even on non-binarized networks. The authors should compare to stronger gradient based attacks (like PGD) and gradient free attacks which have been used to break adversarial defenses that are nondifferentiable in prior work - https://arxiv.org/abs/1802.00420 and https://arxiv.org/abs/1802.05666). Further, the MILP approach used can be strengthened by doing better bound propagation (like in https://arxiv.org/pdf/1711.00455.pdf)\n\n3. The attack radii used are very small compared to what has been used in non-binarized networks, where networks have been trained to even be verifiably robust to adversarial pertrubations of much larger radii (see for example https://arxiv.org/pdf/1805.12514.pdf). Given the existence of this work, it is important to evaluate the algorithms proposed on larger radii (since it is possible to construct non-binarized networks that are indeed robust to perburbations of eps=.1-.3 on MNIST).\n\n4. Motivation for binarization: I assume that motivation for binarized models arising from faster training/inference times and smaller model sizes. However, to justify this, the authors need to compare their BNNs to comparable non-binarized neural networks (for example,ones that are similar  in terms of number of bits used to represent the model) on training time, inference time and adversarial robustness. Otherwise, it seems hard to see why binarized networks are valuable from a robustness.\n\n""]","[80, -20, 20]","[70, 50, 60]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They describe it as 'very clear' and 'sound', and explicitly state they 'support accepting it for publication'. The reviewer also praises the research direction and the paper's contributions. The score is not 100 as there are some minor suggestions for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as suggestions or questions rather than direct criticisms. The reviewer also balances critiques with praise. The score is not higher as the language, while polite, is not excessively formal or deferential."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the topic, they express concerns about clarity, particularly regarding the IProp algorithm. They also point out potential issues with the results and ask several critical questions, indicating some reservations about the paper. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns and frame their criticisms as questions, which is a polite way to address potential issues. The reviewer also begins by acknowledging the paper's contribution before moving on to areas for improvement, which is a courteous approach in academic reviews."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and importance of the work, praising its clarity and potential significance. However, they also express significant concerns about the experimental evaluation, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'My main concerns' and 'needs to be addressed' rather than harsh or dismissive language. The reviewer also provides constructive feedback and suggestions for improvement, which contributes to the polite tone.""]"
"['Overall, the paper is well-written and of high quality, therefore I recommend acceptance. \n\nPros:\n+ The work gives an accessible but still rigorous introduction to the literature on VIs which I find highly valuable, as it creates a bridge between the classical mathematical programming literature and applications in AI. \n\n+ The theory for optimization of VIs with stochastic gradients (though only in monotone setting) was very interesting to me and contains some novel results (Theorem 2, Theorem 4)\n\nCons:\n- I\'m a bit skeptical about the experiments on GANs. They indicate that for the specific choice of architectures and hyper-parameters ""ExtraAdam"" works better, but the chosen architectures are not state-of-the art. What would convince me if the algorithm can be used to improve a current best inception score of 8.2 reached with SNGANs. Also with WGAN-GP, scores of ~7.8 are reported which are much higher than the 6.4 reported in the paper. But I understand that producing state-of-the-art inception scores is not the focus of the paper, therefore I would suggest that the authors release an implementation of the proposed new optimizers (ExtraAdam) for a popular DL framework (e.g. pytorch) such that practitioners working with GANs can quickly try them out in a ""plug-and-play"" fashion.\n\n- Proposition 2 is a bit misleading. While for \\eta \\in (0, 1) implicit and extrapolation are similar, adding the remark that implicit method is stable for any \\eta > 0 (and therefore can lead to an arbitrary fast convergence) would give a more balanced view. Right now, only the advantages of extrapolation method and disadvantages of implicit method are mentioned which I find unfair for the implicit method.\n\n- The theory is presented for variational inequalities with monotone operators. For clarity it should be mentioned that GANs parametrized with neural nets lead to non-monotone VIs. A provably convergent algorithm for that setting is still an open problem, no?\n', 'This paper looks at solving optimization problems that arise in GANs, via a variational inequality perspective (VIP). VIP entails solving an optimization problem that is related to the first order condition of the optimization problem that we wish to solve. VIP have been very successful in solving min-max style problems. Given that, GAN formulations tend to be min-max style problems (though not necessarily 0 sum) the VIP perspective is very natural, though under-explored in machine learning. Two techniques that have been widely used to solve VIP problems are averaging and extragradient methods. The authors look at a simple GAN setup where both the generator and the discriminator are linear models. In this case two kinds of gradient updates can be derived. First are simultaneous updates, and the other is alternated updates. The authors show that simultaneous updates are not even bounded and diverge to infinity, whereas alternated updates are more stable and stay bounded, but need not necessarily converge. However, I think this behaviour is limited to only linear discriminator/generator and might not extend beyond the linear case. The second key idea is the use of extra-gradient updates. Extra-gradient updates perform an ""extra"" or fake gradient step to get to a new point, and then kind of retracks back and perform a gradient step using the gradient step obtained from the ""extra step"".  This extra-gradient method is a close approximation to Euler\'s method, though far more computationally efficient.  However, the extragradient step requires one to calculate gradient twice, which can be expensive in large models. For this reason, the authors suggest using gradients from past as the ""extragradient"" in the extragradient method. \n\nFor strongly-monotone operators (a generalization of strongly-convex functions) extrapolation updates are shown to have linear convergence.  Furthermore, the authors show that using extrapolation and averaging under the assumption that the operator is monotonic, and using constant step size SGD the rates of convergence are better than the rates obtained using plain SGD with averaging but without extrapolation. Authors also show how one can use these ideas using other first order methods such as ADAM instead of SGD. Experiments are shown on the DCGAN architecture. \n\nOn the whole this is a really nice paper, that shows how standard ideas from VIP can be useful for training GANs. I recommend acceptance', ""Summary:\nThe authors take a variational inequality perspective to the study of the saddle point problem that defines a GAN. By doing so, they are able to profit from the corresponding literature and propose a few methods that are variants of SGD. The authors show in a simple example (a bilinear function) these exhibit better performance than Adam and a basic gradient method. After showing theoretical guarantees of these methods (linear convergence) the authors propose to combine them with existing techniques, and show in fact this leads to better results.\n\nEvaluation\nThis is a very good paper and I cannot but recommend its acceptance:\nIt is clear and well written. \nIt has the right level of balance between theory and experiments. \nTheoretical results are far from trivial. \nI haven't seen something similar.\nThe authors's do not make overstatements: they do not claim to have solved the GAN problem, but they do report improvements which are due to a thorough analysis (see above points). These results are much appreciated.\n""]","[60, 80, 90]","[70, 70, 80]","[""The sentiment score is 60 (positive) because the review starts with an overall positive recommendation for acceptance and lists several pros before cons. The reviewer describes the paper as 'well-written and of high quality' and finds parts 'highly valuable' and 'very interesting'. However, it's not extremely positive due to the skepticism expressed about experiments and some critiques. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions (e.g. 'I would suggest'). The reviewer also shows understanding of the paper's focus when critiquing limitations. The tone remains professional and courteous, avoiding harsh or dismissive language."", ""The sentiment score is 80 because the review is overwhelmingly positive. The reviewer describes the paper as 'really nice' and recommends acceptance. They highlight the novelty and usefulness of applying VIP techniques to GANs, and appreciate the authors' contributions. The politeness score is 70 because the reviewer uses respectful and professional language throughout. They acknowledge the authors' work positively without being overly effusive. The reviewer provides constructive feedback and explains concepts clearly, which contributes to the polite tone. While not excessively formal, the language is appropriate and courteous for a peer review."", ""The sentiment score is 90 because the reviewer expresses a very positive opinion about the paper, using phrases like 'very good paper,' 'recommend its acceptance,' and listing several positive aspects without any significant criticisms. The politeness score is 80 because the reviewer uses respectful and professional language throughout, acknowledging the authors' work positively without being overly effusive. The reviewer provides a balanced and constructive evaluation, which is polite in academic contexts. The lack of negative comments or harsh criticisms also contributes to the high politeness score.""]"
"['The paper proposes ""style transfer"" approaches for text rewriting that allow for controllable attributes. For example, given one piece of text (and the conditional attributes associated with the user who generated it, such as their age and gender), these attributes can be changed so as to generate equivalent text in a different style.\n\nThis is an interesting application, and somewhat different from ""style transfer"" approaches that I\'ve seen elsewhere. That being said I\'m not particularly expert in the use of such techniques for text data.\n\nThe architectural details provided in the paper are quite thin. Other than the starting point, which as I understand adapts machine translation techniques based on denoising autoencoders, the modifications used to apply the technique to the specific datasets used here were hard to follow: basically just a few sentences described at a high level. Maybe to somebody more familiar with these techniques will understand these modifications fully, but to me it was hard to follow whether something methodologically significant had been added to the model, or whether the technique was just a few straightforward modifications to an existing method to adapt it to the task. I\'ll defer to others for comments on this aspect.\n\nOther than that the example results shown are quite compelling (both qualitatively and quantitatively), and the experiments are fairly detailed.\n', 'This work proposes a new model that controls several factors of variation in textual data where the condition on disentanglement is replaced with a simpler mechanism based on back-translation. It allows control over multiple attributes, and a more fine-grained control on the trade-off between content preservation and change of style with a pooling operator in the latent space.\n\nOne of the major arguments is it is unnecessary to have attribute-disentangled latent representations in order to have good style-transferring rewriting. In Table 2, the authors showed that ""a classifier that is separately trained on the resulting encoder representations has an easy time recovering the sentiment"" when the discriminator during training has been fooled. Is there any difference between the two discriminators/classifiers? If the post-fit classifier on top of the encoder representation can easily predict the correct sentiment, there should be enough signal from the discriminator to adapt the encoder in order to learn a more disentangled representation. On the other hand, this does not answer the question if a ""true"" disentangled representation would give better performance. The inferior performance from the adversarially learned models could be because of the ""entangled"" representations.\n\nAs the author pointed out, the technical contributions are the pooling operator and the support for multiple attributes since the loss function is the same as that in (Lample et. al 2018). These deserve more elaborated explanation and quantitative comparisons. After all, the title of this work is ""multiple-attribute text rewriting"". For example, the performance comparison between the proposed how averaged attribute  embeddings and simple concatenation, and the effect of the introduced trade-off using temporal max-pooling.\n\nHow important is the denoising autoencoder loss in the loss function (1)? From the training details in the supplementary material, it seems like the autoencoder loss is used as ""initialization"" to some degree. As pointed out by the authors, the main task is to get fluent, attribute-targeted, and content-preserving rewriting. As long as the ""back-translation"" gives expected result, it seems not necessary to have ""meaningful"" or hard ""content-preserving"" latent representations when the generator is powerful enough.\n\nI think the last and most critical question is what the expected style-transferred rewriting look like. What level or kind of ""content-preserving"" do we look for? In Table 4, it shows that the BLEU between the input and the referenced human rewriting is only 30.6 which suggest many contents have been modified besides the positive/negative attribute. This can also be seen from the transferred examples. In Table 8, one of the Male example: ""good food. my wife and i always enjoy coming here for dinner. i recommend india garden."" and the Female transferred rewriting goes as ""good food. my husband and i always stop by here for lunch. i recommend the veggie burrito"". It\'s understandable that men and women prefer different types of food even though it is imagination without providing context. But the transfer from ""dinner"" to ""lunch"" is kind of questionable. Is it necessary to change the content which is irrelevant to the attributes?\n\n\nOther issues:\n- Towards the end of Section 3, it says that ""without back-propagating through the back-translation generation process"". Can you elaborate on this and the reason behind this choice?\n- What does it mean by ""unknown words"" in ""... with 60k BPE codes, eliminating the presence of unknown words"" from Section 4?\n- There is no comparison with (Zhang et. al. 2018), which is the ""most relevant work"".\n- In Table 4, what is the difference among the three ""Ours"" model?\n- In Table 4, the perplexity of ""Input Copy"" is very high compared with generated sentences.\n- In Table 7, what does the ""attention"" refer to?\n- In the supplementary material, there are lambda_BT and lambda_AE. But there is only one lambda in the loss function (1).\n- Please unify the citation style.', 'This paper presents a model for text rewriting for multiple attributes, for example gender and sentiment, or age and sentiment. The contributions and strengths of the paper are as follows. \n\n* Problem Definition\nAn important contribution is the new problem definition of multiple attributes for style transfer. While previous research has looked at single attributes for rewriting, ""sentiment"" for example, one could imagine controlling more than one attribute at a time. \n\n* Dataset Augmentation\nTo do the multiple attribute style transfer, they needed a dataset with multiple attributes. They augmented the Yelp review dataset from previous related paper to add gender and restaurant category. They also worked with microblog dataset labeled with gender, age group, and annoyed/relaxed. In addition to these attributes, they modified to dataset to include longer reviews and allow a larger vocabulary size. In all, this fuller dataset is more realistic than the previously release dataset.\n\n* Model\nThe model is basically a denoising autoencoder, a well-known, relatively simple model. However, instead of using an adversarial loss term as done in previous style transfer research, they use a back-translation term in the loss. A justification for this modeling choice is explained in detail, arguing that disentanglement (which is a target of adversarial loss) does not really happen and is not really needed. The results show that the new loss term results in improvements.\n\n* Human Evaluation\nIn addition to automatic evaluation for fluency (perplexity), content preservation (BLEU score), and attribute control (classification), they ask humans to judge the output for the three criteria. This seems standard for this type of task, but it is still a good contribution.\n\nOverall, this paper presents a simple approach to multi-attribute text rewriting. The positive contributions include a new task definition of controlling multiple attributes, an augmented dataset that is more appropriate for the new task, and a simple but effective model which produces improved results.']","[50, -20, 80]","[75, 60, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer finds the paper 'interesting' and the results 'compelling', but also notes some limitations in the architectural details. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, acknowledges their own potential lack of expertise in certain areas, and offers constructive feedback. The reviewer uses phrases like 'interesting application', 'compelling results', and 'I'll defer to others', which contribute to both the positive sentiment and polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work's contributions, they raise several critical questions and point out areas that need more elaboration or improvement. The review is not overwhelmingly negative, but it does express some skepticism about certain aspects of the work. The politeness score is moderately positive (60) as the reviewer maintains a professional and respectful tone throughout, using phrases like 'Can you elaborate on this' and 'Please unify the citation style' rather than making harsh demands. The reviewer also acknowledges the authors' points and provides constructive feedback, which contributes to the polite tone. However, the score is not extremely high as the review is primarily focused on technical critiques rather than overt politeness."", ""The sentiment score is 80 because the review is predominantly positive, highlighting several strengths and contributions of the paper. The reviewer uses phrases like 'important contribution,' 'fuller dataset is more realistic,' and 'simple but effective model which produces improved results.' There are no significant criticisms mentioned. The politeness score is 50 because the language is professional and neutral, without being overly formal or particularly warm. The reviewer presents the information in a straightforward manner, focusing on the paper's content rather than using explicitly polite language. The tone is respectful but not excessively courteous.""]"
"['Summary:\nThe authors propose an extension of dual learning (DL). In DL, one leverages the duality of a dataset, by predicting both forward and backward, e.g. English to German, and German back to English. It’s been shown that training models using this duality is beneficial. This paper extends DL by introducing multiple models for the forward and backward, and using their output to regularise the training of the two main agents.\n\nThe authors show that this setup improves on the SotA, at only a training computation expense (inference/test time remains the same).\n\nReview:\nThe paper shows extensive experimentation and improves the previous result in all cases. The proposed method is a straightforward extension and can be readily implemented and used.\n\nI have difficulty understanding equation 8 and the paragraph below. It seems like the authors use an equal weighting for the additional agents, however they mention using Monte Carlo to “tackle the intractability resulting form the summation over the exponentially large space y”. According to the paper the size of y is the dataset, is it exponentially large? Do the authors describe stochastic gradient descent? Also what do the authors mean by offline sampling? Do they compute the targets for f_0 and g_0 beforehand using f_1…n and g_1…n?\n\nThe results mention computational cost a few times, I was wondering if the authors could comment on the increase in computational cost? e.g. how long does “pre-training” take versus training the dual? Can the training of the pre-trained agents be parallelised? Would it be possible to use dropout to more computationally efficient obtain the result of an ensemble?\n\nIn general I think the authors did an excellent job validating their method on various different datasets. I also think the above confusions can be cleared up with some editing. However the general contribution of the paper is not enough, the increase in performance is minimal and the increased computational cost/complexity substantial. I do think this is a promising direction and encourage the authors to explore further directions of multi-agent dual learning.\n\nTextual Notes:\n- Pg2, middle of paragraph 1: “which are pre-trained with parameters fixed along the whole process”. This is unclear, do you mean trained before optimising f_0 and g_0 and subsequently held constant?\n- Pg2, middle last paragraph: “typical way of training ML models”. While the cross entropy loss is a popular loss, it is not “typical”.\n- Pg 3, equation 4, what does “briefly” mean above the equal sign?\n- Perhaps a title referring to ensemble dual learning would be more appropriate, given the possible confusion with multi agent reinforcement learning. \n\n\n################\nRevision:\n\nI would like to thank the authors for the extensive revision, additional explanations/experiments, and pointing out extensive relevant literature on BLUE scores. The revision and comments are much appreciated. I have increased my score from 4 to 6.', 'The author\'s present a dual learning framework that, instead of using a single mapping for each mapping task between two respective domains, the authors learn multiple diverse mappings. These diverse mappings are learned before the two main mappings are trained and are kept constant during the training of the two main mappings. Though I am not familiar with BLEU scores and though I didn\'t grasp some of the details in 3.1, the algorithm yielded consistent improvement over the given baselines. The author\'s included many different experiments to show this.\n\nThe idea that multiple mappings will produce better results than a single mapping is reasonable given previous results on ensemble methods. \n\nFor the language translation results, were there any other state-of-the-art methods that the authors could compare against? It seems they are only comparing against their own implementations.\n\nObjectively saying that the author\'s method is better than CycleGAN is difficult. How does their ensemble method compare to just their single-agent dual method? Is there a noticeable difference there?\n\nMinor Comments:\n\nDual-1 and Dual-5 are introduced without explanation.\n\nPerhaps I missed it, but I believe Dan Ciresan\'s paper ""Multi-Column Deep Neural Networks for Image Classification"" should be cited.\n\n### After reading author feedback\nThank you for the feedback. After reading the updated paper I still believe that 6 is the right score for this paper. The method produces better results using ensemble learning. While the results seem impressive, the method to obtain them is not very novel; nonetheless, I would not have a problem with it being accepted, but I don\'t think it would be a loss if it were not accepted.', 'Summary\n\nThe paper proposes to modify the ""Dual Learning"" approach to supervised (and unsupervised) translation problems by making use of additional pretrained mappings for both directions (i.e. primal and dual). These pre-trained mappings (""agents"") generate targets from the primal to the dual domain, which need to be mapped back to the original input. It is shown that having >=1 additional agents improves training of the BLEU score in standard MT and unsupervised MT tasks. The method is also applied to unsupervised image-to-image ""translation"" tasks.\n\nPositives and Negatives\n+1 Simple and straightforward method with pretty good results on language translation.\n+2 Does not require additional computation during inference, unlike ensembling.\n-1 The mathematics in section 3.1 is unclear and potentially flawed (more below).\n-2 Diversity of additional ""agents"" not analyzed (more below).\n-3 For image-to-image translation experiments, no quantitative analysis whatsoever is offered so the reader can\'t really conclude anything about the effect of the proposed method in this domain.\n-4 Talking about ""agents"" and ""Multi-Agent"" is a somewhat confusing given the slightly different use of the same term in the reinforcement literature. Why not just ""mapping"" or ""network""?\n\n-1: Potential Issues with the Maths.\n\nThe maths is not clear, in particular the gradient derivation in equation (8). Let\'s just consider the distortion objective on x (of course it also applies to y without loss of generality). At the very least we need another ""partial"" sign in front of the ""\\delta"" function in the numerator. But again, it\'s not super clear how the paper estimates this derivative.  Intuitively the objective wants f_0 to generate samples which, when mapped back to the X domain, have high log-probability under G, but its samples cannot be differentiated in the case of discrete data. So is the REINFORCE estimator used or something? Not that the importance sampling matter is orthogonal. In the case of continuous data x, is the reparameterization trick used? This should at the very least be explained more clearly.\n\nNote that the importance sampling does not affect this issue.\n\n-2: Diversity of Agents.\n\nAs with ensembles, clearly it only helps to have multiple agents (N>2) if the additional agents are distinct from f_1 (again without loss of generality this applies to g as well). The paper proposes to use different random seeds and iterate over the dataset in a different order for distinct pretrained f_i. The paper should quantify that this leads to diverse ""agents"". I suppose the proof is in the pudding; as we have argued, multiple agents can only improve performance if they are distinct, and Figure 1 shows some improvement as the number of agents are increase (no error bars though). The biggest jump seems to come from N=1 -> N=2 (although N=4 -> N=5 does see a jump as well). Presumably if you get a more diverse pool of agents, that should improve things. Have you considered training different agents on different subsets of the data, or trying different learning algorithms/architectures to learn them? More experiments on the diversity would help make the paper more convincing.']","[50, -20, -20]","[75, 60, 50]","[""The sentiment score is 50 (moderately positive) because the reviewer acknowledges the extensive experimentation, improvement on state-of-the-art results, and the straightforward implementation of the proposed method. However, they also express some concerns about the overall contribution and computational cost. The increase from a previous score of 4 to 6 also indicates a positive shift. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, expresses appreciation for the authors' work ('excellent job validating their method'), and frames criticisms constructively ('I was wondering if the authors could comment on...'). The reviewer also thanks the authors for their revision and additional explanations, showing courtesy and professionalism."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (consistent improvement over baselines, reasonable idea), they also express several criticisms and doubts. The reviewer questions the comparison methods, the novelty of the approach, and ultimately gives a lukewarm recommendation ('I would not have a problem with it being accepted, but I don't think it would be a loss if it were not accepted'). The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the authors' efforts, and provides constructive feedback. They thank the authors for their feedback and explain their reasoning clearly without using harsh or dismissive language."", ""The sentiment score is -20 because while the reviewer notes some positives (+1, +2), there are more negatives (-1, -2, -3, -4) and the overall tone is critical, especially regarding mathematical issues and lack of quantitative analysis for image translation. However, it's not extremely negative as the reviewer acknowledges some merits. The politeness score is 50 because the language is professional and constructive, offering specific suggestions for improvement. The reviewer uses neutral phrasing like 'The paper should quantify' rather than harsh criticism. The tone is direct but respectful, maintaining a balance between pointing out flaws and acknowledging strengths.""]"
"['\nSUMMARY:\nThis work is about learning state-transition models in complex domains represented as sets of objects, their properties, ``""deictic"" reference functions between sets of objects, and possible actions (or action templates). A parametric model for the actions is assumed, and these parameters act on a neural net that learns the transition model (probabilistic rule) from the current state to the next one.  It is basically this nonlinear transition model implemented by a network which makes this work different from previous models described in the literature. The relational transition model proposed is sparse, based on the assumption that actions have only ``local effects on related objects. The prediction model itself is basically a Gaussian distribution whose mean and variances are represented by neural nets. For jointly learning multiple rules, a clustering strategy is presented which assigns experience samples to transition rules. The method is applied to simulated data in the context of predicting pushing stacks of blocks on a cluttered table top.\n\nEVALUATION: \nThe type of problems addressed in this paper is challenging and highly relevant for solving problems in the ``real\'\' world. Although the method proposed is in some sense a direct generalization of the work in [Pasula et al.], it still contains many novel and interesting aspects.Any single part of the model (like the use of Gaussians parametrized by functions implemented via neural nets) is somehow ``standard in deep latent variable models, but in complex real-world rule-learning problems the whole system presented  defines  certainly a big improvement over the state-of-the-art, which in my opinion has the potential to indeed advance this field of research.     \n ', 'An approach is proposed that learns transition rules in terms of local contexts. Specifically, transition rules make predictions as a distribution over the set of possible states based on local context of objects. A learning algorithm is described that learns the transition rules by maximizing the conditional likelihood. To learn the rules jointly with selecting the right samples for the transition rule, and EM algorithm is proposed. \n\nThe paper is well-written. The contribution seems significant considering that relational structure is integrated with neural networks in a systematic manner. Though written from the perspective of learning transition rules for tasks such as robotic manipulation, I think similar ideas can be for general tasks that can benefit from both relational structure and neural network representation.  Learning lifted rules has also been studied in  domains such as ILP and Statistical Relational Learning (Getoor and Taskar 07)(lifted rules with uncertainty). I think including their perspective and commenting on their relationship with the proposed work will be useful.\n\nExperiments are performed on a robotic manipulation task involving pushing a stack of blocks in a cluttered environment. A method that does not take object relations into account and simply predicts the state transition is used as baseline for comparison. The proposed approach shows the benefits of exploiting the structure between objects. There is not too much discussion on scalability. Does the propose method scale up for learning transition rules in real tasks? Are there any tradeoffs involved, etc. would be good to know.\nIn summary, this seems to be a well-written and novel contribution.', 'In the manuscript ""Learning sparse relational transition models"", the authors combine neural nets with relational models, using ideas from linguistics. They apply this to learning the representations of the space in which a simulated robot operates in a reinforcement learning ML paradigm. This work is of interest to the AI community and ICLR is a good venue for this work.\n\nThe authors apply their model in particular to a problem in which the simulated robot must rearrange objects in space, and they achieve reasonable accuracy.\n\nMajor points:\n\n- Organisationally, I thought that the authors could have gotten to the loss function sooner, as much of the development of the theory is lacking in motivation until specific tasks are defined.\n\n- The application domain seemed to lose some of the power of the linguistic analysis they were doing to develop the representation through ""properties"" and ""action templates"". These definitions were quite general, but it was unclear if more than a few (with few parameters) were used in the actual application, and so it\'s unclear that so much generality was required by the application.\n\n- The authors could have compared with more modern deep learning techniques for reinforcement learning such as DeepMimic (Peng et al 2018).\n\nMinor points:\n- Typesetting periods ""Pasula et al. and"" -> ""Pasula et al.\\ and""\n\n- Page 2: ""value of a note"" -> ""value of a node""\n\n- 3.1 was hard to follow.']","[80, 80, 50]","[70, 70, 75]","[""The sentiment score is 80 (positive) because the reviewer describes the work as 'challenging and highly relevant', containing 'many novel and interesting aspects', and having 'the potential to indeed advance this field of research'. They also state it's a 'big improvement over the state-of-the-art'. The politeness score is 70 (polite) as the reviewer uses respectful and professional language throughout, acknowledging the work's merits without being overly effusive. They provide a balanced view, noting both standard and novel aspects of the work. The tone is constructive and encouraging, without any harsh criticism or dismissive remarks."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe it as 'well-written' and state that the contribution seems 'significant'. The reviewer also mentions that the paper presents a 'novel contribution' in the summary. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticism. They use phrases like 'I think including...' and 'would be good to know', which are polite ways of suggesting improvements. The reviewer also acknowledges the paper's strengths before offering suggestions, which is a polite approach to feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by stating that the work is of interest to the AI community and ICLR is a good venue for it. They also mention that the authors achieve reasonable accuracy. However, the review includes several major and minor points for improvement, balancing out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'I thought that' and 'The authors could have' instead of more direct or negative phrasing. The reviewer also acknowledges the potential of the work while suggesting improvements, maintaining a professional and courteous tone.""]"
"['This article addresses the problem of domain adaptation of semantic segmentation methods from autonomous vehicle simulators to the real world. The key contribution of this paper is the use of privileged information for performing the adaptation. The method is of those called unsupervised domain adaptation as no labels from the target domain are used for the adaptation. The method is based on a GAN with: a) A generator that transforms the simulation images to real appearance; b) A discriminator that distinguish between real and fake images;  c) a privileged network that learns to perform depth estimation; and d) the task networks that learns to perform semantic segmentation. Privileged information is very few exploited in simulations and I consider it an important way of further exploit these simulators.\n\nThe article is clear, short, well written and very easy to understand. The method is effective as it is able to perform domain adaptation and improve over the compared methods. There is also an ablation study to evaluate the contribution of each module. This ablation study shows that the privileged information used helps to better perform the adaptation. The state of the art is comprehensive and the formulation seams correct.  The datasets used for the experiments (Synthia, Cityscapes and Vistas) is very adequate as they are the standard ones.\n\nSome minor concerns:\n - The use of 360x640 as resolution\n - The use of FCN8 instead of something based on Resnet or densenet\n\nI would like some more details on what is happening with Vistas dataset. SPIGAN-no-PI underperforms the source model. By looking at Figure 4 we can observe that the transformation of the images is not working properly as many artifacts appear. In SPIGAN those artifacts does not appear and then the adaptation works better. Could it be a problem in the training?\n\n\n', ""This papers presents an unsupervised domain adaptation algorithm for semantic segmentation. A generative adversarial network is envisaged to carry out synthetic-to-real image translation. In doing so, depth information extracted from a simulator is used as privileged information (PI) to boost the transfer on the target domain, regularizing the model and ensuring a better generalization. \n\n*Quality*\nThe paper addresses a relevant problem, which is the adaptation of methods from simulated data to real ones. The authors devise a convincing method which takes advantage of state-of-the art generative adversarial architectures and privileged information. \n\n*Clarity*\nThe paper is sufficiently well written. In general, the main idea and proposed method are clear and easy to follow. The only problem is that some background concepts (such as privileged information or unsupervised domain adaptation) are given for granted, compromising the readability for someone not familiar with those topics. \nOn a more technical side, for reproducibility purposes, the following aspects have to be clarified:\n1.\tDetails about the validation set used for grid search. Is the validation set extracted from the target domain? (In principled labels from the target domain should not be used during learning).\n2.\tNumber of iterations before convergence: is the training of the network numerically stable? Are there issues in convergence of some of the sub-modules? Which one is leading the learning?\n3.\tComments about the relative magnitudes of losses. This will maybe give some intuitions about the values used for the hyper-parameters (e.g., the L_PI is only weighted by 0.1).\n\n*Originality*\nThe way authors take advantage of depth information extracted from a simulator as privileged information is novel in the sense that, with respect to the original student-teacher paradigm of the paper by Vapnik & Vashist, here the idea of privileged information is interpreted as a regularizer to boost the training stage. \n\n*Significance*\nThe application of semantic segmentation in urban scenes for navigation tasks is relevant. The scored results are on pair with/ superior to state-of-the-art in unsupervised domain adaptation. \nHowever, the ablation study could be more extensive in order to understand the contribution of the several components, besides the PI network. In fact, it would be interesting to analyze the contribution of the perceptual loss (and others). Also, one could include the target-only result (as done in original LSD paper) to provide an upper bound on the best accuracy that is achievable.\n\n*Pros*\n1. The applicative setting of semantic segmentation in urban scenes for navigation is relevant. \n2. Using privileged information from simulators seems novel and well presented in this paper.\n3. Strong experimental results achieved in challenging benchmarks.\n\n*Cons*\n1. The regularization effect of the PI network could be supported by a more extensive ablation study of the model, for example by ablating the several losses used (in particular, the perceptual loss).\n2. A quite relevant amount of hyper-parameters need to be cross-validated. Is the method robust against different parameters’ configuration?\n3. Missing citations [1, 2]: there are works in the literature that can hallucinate a missing modality during testing. Although such works approach a different problem, authors should cite them.\n\n[1] Judy Hoffman, Saurabh Gupta, Trevor Darrell - Learning with Side Information through Modality Hallucination – CVPR 2016\n[2] Nuno Garcia, Pietro Morerio, Vittorio Murino - Modality Distillation with Multiple Stream Networks for Action Recognition – ECCV 2018\n\n*Final Evaluation*\nThe authors face the challenging synthetic-to-real adaptation setup, with an interesting usage of z-buffer from a simulator as privileged information. Overall, the work is fine, apart from the following points.\n1.\tIn addition to a few missing citations [1, 2], an ablation study on the perceptual loss is necessary to dissect the impact of each component of the pipeline. \n2.\tThe clarity of the paper can be improved by adding some background material on unsupervised domain adaptation and learning with privileged information (PI), as to better highlight the technical novelty of using PI within a L1 regularizer. \n3.\tThe training stage of all submodules could have better investigated, for instance, by providing some convergence plots of the loss functions across iterations.\n4.\tHow to do grid search for parameters in a domain adaptation setting is always a delicate aspect and authors seem elusive on that respect. \n5.\tAgain about hyper-parameters. Due to their high number, some sensitivity analysis should have provided.\nAs it is, the paper’s strengths slightly outperform the weaknesses, leading to an overall borderline-accept. If authors implement the suggested modification, a full acceptance will be feasible.\n\n[COMMENTS AFTER AUTHORS' RESPONSE]\nAfter the rebuttal provided by authors, all raised questions and criticisms have been fully solved. Therefore, I recommend for a full acceptance."", 'The paper focuses on the problem of semantic segmentation across domains. The most standard setting for this task involves real world street images as target and synthetic domains as sources with images produced by simulators of photo-realistic hurban scenes.  This work proposes to leverage further depth information which is actually produced by the simulator together with the source images but which is in general not taken into consideration.\nThe used deep architecture is a GAN where the generator learning is guided by three components: (1) the standard discriminator loss (2) the cross entropy loss for image segmentation that evaluates the correct label assignment to each image pixel (3) an  l1-based loss which evaluates the correct prediction of the depth values in the original and generated image. A further perceptual regularizer is introduced to support the learning.\n\n+ overall the paper is well organized and easy to read\n+ the proposed idea is smart: when starting from a synthetic domain there may be several hidden extra information that are generally neglected but that can instead support the learning task\n+ the experimental results seem promising \n\nStill, I have some concerns\n\n- if the main advantage of the proposed approach is in the introduction of the priviledged information, I would expect that disactivating the related PI loss we should get back to results analogous of those obtained by other competing methods. However from Table 2 it seems that SPIGAN-no-PI is already much better than the  FCN Source baseline in the Cityscape case and much worse in the Vistas case. This should be better clarified -- are the basic structure of SPIGAN and FCN analogous?  \n\n- the ablation does not cover an analysis on the role of the perceptual regularizer. This is also related to the point above: the use of a perceptual loss may introduce a basic difference with respect to competing methods. It should be better discussed.\n\n- section 4.1 mentions the use of a validation set. More details should be provided about it and on how the hyperparameters were chosen.\nA possible analysis on the robustness of the method to those parameters could provide some further intuition about the network stability.\nIt might be also interesting to check if the  the loss weights provide some intuition  about the relative importance of the losses in the learning process.\n\n- the negative transfer rate is another way to measure the advantage of using the PI with respect to not using it. However, since it is not evaluated for the competing methods its value does not add much information and indeed it is only quickly mentioned in the text. It should be better discussed.\n\n- some recent papers have shown better results than those considered here as baseline:\n[Learning to Adapt Structured Output Space for Semantic Segmentation, CVPR 2018]\n[Unsupervised Domain Adaptation for Semantic Segmentation via Class-Balanced Self-Training, ECCV 2018]\nthey should be included as related work and considered as reference for the experimental results.\n\nOverall I think that the proposed idea is valuable but the paper should better clarify the points mentioned above.\n\n']","[80, 60, 20]","[70, 70, 60]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the article. They describe it as 'clear, short, well written and very easy to understand', and state that the method is 'effective' and 'improves over the compared methods'. The reviewer also praises the use of privileged information as an 'important way of further exploit these simulators'. While there are some minor concerns and questions raised, these do not significantly detract from the overall positive sentiment.\n\nThe politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They acknowledge the strengths of the paper and frame their concerns as 'minor'. The questions and suggestions are presented in a constructive manner, such as 'I would like some more details...' and 'Could it be a problem in the training?', rather than as harsh criticisms. The tone is consistently collegial and aimed at improving the paper rather than tearing it down."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses overall approval of the paper, noting its relevance, novelty, and strong experimental results. However, they also point out several areas for improvement, leading to a 'borderline-accept' rather than a fully positive evaluation. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively presenting criticisms. They use phrases like 'the paper is sufficiently well written' and 'authors devise a convincing method', which maintain a professional and courteous tone. The reviewer also provides detailed suggestions for improvement rather than just criticizing, which is a polite approach to feedback."", ""The sentiment score is 20 (slightly positive) because the reviewer acknowledges several positive aspects of the paper, such as it being well-organized, having a smart idea, and promising results. However, they also express significant concerns and areas for improvement, which tempers the overall positivity. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their concerns as suggestions for improvement rather than harsh criticisms. They use phrases like 'I would expect,' 'This should be better clarified,' and 'It might be interesting to check,' which maintain a constructive tone. The reviewer also concludes with a balanced statement, recognizing the value of the idea while emphasizing the need for clarification on certain points.""]"
"[""In the paper, the authors try to analyze the convergence of stochastic gradient descent based method with stagewise learning rate and average solution in practice. The paper is very easy to follow, and the experimental results are clear. The following are my concerns:\n\n1. In function (3), for any x in R^d, if \\hat x  = prox_\\gamma f (x), then f(\\hat x ) <= f(x). This inequality looks not correct to me. If x = argmin_x f(x), the above inequality is obviously wrong.  It looks like that function (3) is a very important basis for the whole paper.\n \n2. By using the weakly convex assumption and solving f_s, the authors transform a nonconvex nonsmooth problem to a convex problem. However, the paper didn't mention how to select \\gamma in the algorithm. This parameter is nontrivial, if you set a small value, the problem is not convex and the analysis does not hold. In the experiment, the authors tune \\gamma from 1 to 2000, which means that u < 1 or u < 1/2000.  Given neural network is a u-weakly convex problem or u-smooth problem, the theory does not match the experiment. \n\n3. The authors propose a universal stagewise optimization framework and mention that the stagewise ADAGRAD obtains faster convergence than other analysis. My question is that, if it is a generic framework, how about the convergence rate for other methods? is there also acceleration for SGD or momentum SGD? \n"", 'Non-convex optimization is a hot topic since many machine learning problems can be formulated as non-convex problems. In this paper, the authors propose a universal stage-wise algorithm for weakly convex optimization problems. The idea is to add a strongly convex regularizer centered at an iterate of previous stage to the objective function. This builds a convex function which can be optimized by any standard methods in the convex optimization setting. The authors developed convergence rates in expectation in terms of the gradient of envelope. Empirical results are also reported to show the effectiveness of the method.\n\nComments:\n\n(1) The weakly-convex concept considered in this paper is very similar to the bounded non-convexity considered in the paper (Natasha: Faster Non-Convex Stochastic Optimization Via Strongly Non-Convex Parameter) (not cited). In particular, the Natasha paper also developed a multi-stage algorithm for bounded non-convexity optimization problems by adding strongly-convex regularizers centered at iterates of previous stages. The authors should discuss more extensively the related work to clarify their novelty.\n\n(2) The convergence rate is measured by $\\nabla\\phi_\\gamma(x_\\tau)$. However, according to (3) , this only guarantees an upper bound on $\\text{dist}(0,\\partial\\phi_\\gamma(\\text{prox}_{\\gamma\\phi_\\gamma}(x_\\tau)))$. The output of the algorithm is $x_\\tau$ instead of $\\text{prox}_{\\gamma\\phi_\\gamma}(x_\\tau)$. Is it possible to derive an upper bound on $\\text{dist}(0,\\partial\\phi_\\gamma(x_\\tau))$?', 'Summary:\nThe paper presents an analysis and numerical evaluation of stagewise SGD, ADAGRAD and Stochastic momentum methods for solving stochastic non-smooth non-convex optimization problems. \n\nComments:\nI find the ideas presented in this paper very interesting. The convergence analysis seems correct and the paper is reasonably well written, and tackles an important problem. \n\nThe analysis holds for μ-weekly convex functions. This assumption is really important for the development of the algorithm and the proposed analysis. I like the fact that the authors provide two examples showing that popular objective functions in machine learning satisfy this assumption.\n\nThe numerical evaluation is adequate showing the effectiveness  of the proposed stagewise algorithms.  However i have the follow suggestions/minor comments:\n\n1) It will be nice to have also some plots showing the performance of the proposed method on the ImageNet dataset. \n2) Another possible nice experiment will be a comparison of the four stagewise methods (SGD,ADAGRAD,SHB,SNAG) on the same dataset. Which one behaves better? \n\nMinor Comments:\n1) The captions of the figures can be more informative (mention also the division by column). First column is SGD, Second column Adagrad, etc.\n2) Typos: \nSection 1, last bullet point, second line: ""stagwise""\nSection 5, second paragraph , first line :""their their""\npage 8, 3 line from the bottom:  ""seems, indicate""\n\n2) Missing reference.\nIn the area of stochastic gradient methods with momentum many papers have been proposed recently for the case of convex optimization that worth to be mentioned:\nGadat, Sébastien, Fabien Panloup, and Sofiane Saadane. ""Stochastic heavy ball."" Electronic Journal of Statistics 12.1 (2018): 461-529.\nLoizou, Nicolas, and Peter Richtárik. ""Momentum and stochastic momentum for stochastic gradient, Newton, proximal point and subspace descent methods."" arXiv preprint arXiv:1712.09677 (2017).\nLan, Guanghui, and Yi Zhou. ""An optimal randomized incremental gradient method."" Mathematical programming (2017): 1-49.\n\nOverall, I suggest to accept this paper.']","[-20, 50, 80]","[60, 80, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('very easy to follow', 'experimental results are clear'), they express several significant concerns about the paper's methodology and conclusions. The concerns are substantial and fundamental to the paper's arguments, indicating a generally critical stance. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, framing their criticisms as 'concerns' and 'questions' rather than outright criticisms. They also begin with positive comments before moving to their concerns, which is a polite approach. The reviewer maintains a professional tone, avoiding harsh or personal criticisms, and instead focuses on specific technical issues in a constructive manner."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance of the topic and the contributions of the paper, including the proposed algorithm, convergence rates, and empirical results. However, they also point out areas for improvement, particularly in discussing related work and clarifying certain aspects of the analysis. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They begin by highlighting the paper's strengths and frame their comments as suggestions rather than criticisms. The use of phrases like 'The authors should discuss' and 'Is it possible to derive' indicates a collaborative and supportive tone rather than a demanding one."", ""The sentiment score is 80 (positive) because the reviewer finds the ideas 'very interesting', states that the convergence analysis 'seems correct', and the paper is 'reasonably well written'. The reviewer also likes certain aspects of the paper and suggests to 'accept this paper'. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offers constructive suggestions, and frames criticisms as 'minor comments'. The reviewer also uses phrases like 'It will be nice' and 'Another possible nice experiment' when making suggestions, which adds to the politeness. The overall tone is professional and supportive, without being overly formal or deferential.""]"
"[""edit:  the authors nicely revised the submission, I think it is a very good paper. I increased my rating.\n\n-----\n\nThis paper presents a method that learns to reproduce 'block towers' from a given image. A perception model, a physics engine model, and a rendering engine are first trained together on pairs of images.\nThe perception model predicts a representation of the scene decomposed into objects;  the physics engine predicts the object representation of a scene from an initial object representation; the rendering engine predicts an image given an object representation.\n\nEach training pair of images is made of the first image of a sequence when introducing an object into a scene, and of the last image of the sequence, after simulating the object's motion with a physics engine. The 3 parts of the pipeline (perception, physics, rendering) are trained together on this data.\n\nTo validate the learned pipeline, it is used to recreate scenes from reference images, by trying to introduce objects in an empty scene until the given scene can be reproduced. It outperforms a related pipeline that lacks a scene representation based on objects.\n\nThis is a very interesting paper, with new ideas:\n- The object-based scene representation makes a lot of sense, compared to the abstract representation used in recent work. \n- The training procedure, based on observing the result of an action, is interesting as the examples are easy to collect (except for the fact that the ground truth segmentation of the images is used as input, see below).\n\nHowever, there are several things that are swept 'under the carpet' in my opinion, and this should be fixed if the paper is accepted.\n\n* the input images are given in the form of a set of images, one image corresponding to the object segmentation. This is mentioned only once (briefly) in the middle of the paragraph for Section 2.1, while this should be mentioned in the introduction, as this makes the perception part easier. There is actually a comment in the discussion section and the authors promised to clarify this aspect, which should indeed be more detailed. For example, do the segments correspond to the full objects, or only the visible parts?\n\n* The training procedure is explained only in Section 4.1. Before reaching this part, the method remained very mysterious to me. The text in Section 4.1 should be moved much earlier in the paper, probably between current sections 2.3 and 2.4, and briefly explained in the introduction as well.\nThis training procedure is in fact fully supervised - which is fine with me: Supervision makes learning 'safer'. What is nice here is that the training examples can be collected easily - even if the system was not running in a simulation.\n\n* if I understand correctly the planning procedure, it proceeds as follows:\n- sampling 'actions' that introduce 1 object at a time (?)\n- for each sampled action, predicting the scene representation after the action is performed, by simulating it with the learned pipeline, \n- keeping the action that generates a scene representation close to the scene representation computed for the goal image of the scene.\n- performing the selected action in a simulator, and iterate until the number of performed actions is the same as the number of objects (which is assumed to be known).\n\n-> how do you compare the scene representation of the goal image and the predicted one before the scene is complete? Don't you need some robust distance instead of the MSE?\n-> are the actions really sampled randomly?  How many actions do you need to sample for the examples given in the paper?\n\nI also have one question about the rendering engine:  Why using the weighted average of the object images? Why not using the intensity of the object with the smallest predicted depth?  It should generate sharper images. Does using the weighted average make the convergence easier?\n"", 'Summary:\nThe paper presents a platform for predicting images of objects interacting with each other under the effect of gravitational forces. Given an image describing the initial arrangement of the objects in a scene, the proposed architecture first detects the objects and encode them using a perception module. A physics module then predicts the final arrangement of the object after moving under the effects of gravity. A rendering module takes as input the predicted final positions of objects and returns an image. The proposed architecture is trained by using pixel labels only, by reducing the gaps between the predicted rendered images and the images returned by the MuJuCo physics engine. This error\'s gradient is back-propagated to the physics and perception modules. The proposed platform is also used for planning object placements by sampling a large number of object shapes, orientations and colors, predicting the final configurations, and selecting initial placements that lead to final configurations that are as close as possible to given goal configurations using the L2 norm in the VGG features. Experiments performed in a simple blocks world show that the proposed approach is not only useful for prediction, but can also be used for planning object placements.\nClarity:\nThe paper is not very well written. The description of the architecture should be much more precise. Some details are given right before the conclusion, but they are still just numbers and leave a lot of questions unanswered. For instance, the perception module is explained in only a few line in subsection 2.1. Some concrete examples could help here. How are the object proposals defined? How are the objects encoded? What exactly is being encoded here? Is it the position and orientation? \nOriginality:\nThe proposed architecture seems novel, but there are many closely related works that are based on the same idea of decomposing the system into a perception,  a physics simulation, and a rendering module. Just from the top of my head, I can think of the SE3-Nets. There is also a large body of work from the group of Josh Tanenbaum on similar problems of learning physics and rendering. I think this concept is not novel anymore and the expectations should be raised to real applications. \nSignificance:\nThe simplicity of the training process that is fully based on pixel labeling makes this work interesting. There are however some issues related to the experimental evaluation that remains unsatisfactory. First, all the experiments are performed on a single benchmark, we cannot easily draw conclusions about a given algorithm based on a single benchmark. Second, this is a toy benchmark that with physical interactions that are way less complex than interactions that happen between real objects. The objects are also not diverse enough in their appearances and textures. I wonder why the authors avoided collecting a dataset of real images of objects and using it to evaluate their algorithm instead of the toy artificial data. I also suspect that with 60k training images, you can easily overfit this task. How can this work generalize to real physical interactions? How can you capture mass and friction, for example?\nPlanning is based on sampling objects of different shapes and colors, do you assume the existence of such library in advance? \nThe baselines that are compared to are also not very appropriate. For instance, comparing to no physics does not add much information. We know that the objects will fall after they are dropped, so the ""no physics"" baseline will certainly perform badly. Comparisons to SAVP are also unfair because it requires previous frames, which are not provided here, and SAVP is typically used for predicting the very next frames and not the final arrangements of objects, as done here.\nIn summary: I think the authors are on something here and the idea is great. However, the paper needs to be made much clearer and more precise, and the experimental evaluation should be improved by performing experiments in a real-world environment. Otherwise, this paper will not have much impact. \n\nPost-rebuttal update:\nThe paper was substantially improved. New experiments using real objects have been included, this clearly demonstrates the merits of the proposed method in robotic object manipulation. ', 'A method is proposed, which learns to reason on physical interactions of different objects (solids like cuboids, tetrahedrons etc.). Traditionally in related work the goal is to predict/forecast future observations, correctly predicting (and thus learning) physics. This is also the case in this paper, but the authors explicitly state that the target is to evaluate the learned model on downstream tasks requiring a physical understanding of the modelled environment.\n\nThe main contribution here lies in the fact that no supervision is used for object properties. Instead, a mask predictor is trained without supervision, directly connected to the rest of the model, ie. to the physics predictor and the output renderer. The method involves a planning phase, were different objects are dropped on the scene in the right order, targeting bottom objects first and top objects later. The premise here is that predicting the right order of the planning actions requires understanding the physics of the underlying scene.\n\nI particularly appreciated the fact, that object instance renderers are combined with a global renderer, which puts individual images together using predicted heatmaps for each object. With a particular parametrization, these heatmaps could be related to depth maps allowing correct depth ordering, but depth information has not been explicitly provided during training.\n\nImportant issues:\n\nOne of the biggest concerns is the presentation of the planning algorithm, and more importantly, a proper formalization of what is calculated, and thus a proper justification of this part. The whole algorithm is very vaguely described in a series of 4 items on page 4. It is intuitively almost clear how these steps are performed, but the exact details are vague. At several steps, calculated entities are “compared” to other entities, but it is never said what this comparison really results in. The procedure is reminiscent of particle filtering, in that states (here: actions) are sampled from a distribution and then evaluated through a likelihood function, resulting in resampling. However, whereas in particle filtering there is clear probabilistic formalization of all key quantities, in this paper we only have a couple of phrases which describe sampling and “comparisons” in a vague manner.\n\nSince the procedure performs planning by predicting a sequence of actions whose output at the end can be evaluated, thus translated into a reward, I would have also liked a discussion (or at least a remark) why reinforcement learning has not been considered here.\n\nI am also concerned by an overclaim of the paper. As opposed to what the paper states in various places, the authors really only evaluate the model on video prediction and not on other downstream tasks. A single downstream task is very briefly mentioned in the experimental section, but it is only very vaguely described, it is unclear what experiments have been performed and there is no evaluation whatsoever.\n\nOpen questions:\n\nWhy is the proposed method better than one of the oracles?\n\nMinor remarks:\n\nIt is unclear what we see in image 4, as there is only a single image for each case (=row) and method (=column). \n\nThe paper is not fully self-contained. Several important aspects are only referred to by citing work, e.g. CEM sampling and perceptual loss. These are concepts which are easy to explain and which do not take much space. They should be added to the paper.\n\nA threshold is mentioned in the evaluation section. A plot should be given showing the criterion as a function of this threshold, as is standard in, for instance, pose estimation literature.\n\nI encourage the authors to use the technical terms “unary terms” and “binary terms” in the equation in section 2.2. This is the way how the community referred to interactions in graphical models for relational reasoning long before deep learning showed up on the horizon, let’s be consistent with the past.\n\nI do not think that the physics module can be reasonable be called a “physics simulator” as has been done throughout the paper. It does not simulate physics, it predicts physics after learning, which is not a simulation.\n\nA cube has not been confused with a rectangle, as mentioned in the paper, but with a rectangular cuboid. A rectangle is a 2D shape, a rectangular cuboid is a 3D polyhedron.\n']","[70, -20, -20]","[60, 50, 60]","[""The sentiment score is 70 (positive) because the reviewer starts by stating 'This is a very interesting paper, with new ideas' and mentions several positive aspects. They also note that the authors 'nicely revised the submission' and increased their rating. However, it's not 100 because the reviewer does point out some issues that need addressing. The politeness score is 60 (somewhat polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively (e.g., 'However, there are several things that are swept 'under the carpet' in my opinion, and this should be fixed if the paper is accepted.'). The reviewer also asks questions in a polite manner. The score isn't higher because the language, while not rude, is quite direct in places."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('the idea is great', 'makes this work interesting'), they express several significant concerns about the paper's clarity, experimental design, and overall impact. The reviewer suggests substantial improvements are needed, indicating a generally critical stance.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and acknowledge positive aspects alongside criticisms. The language used is respectful and avoids harsh or personal criticism, focusing instead on the content of the paper.\n\nThe reasoning for these scores is based on the balance of positive and negative comments, the specific critiques provided, and the overall tone of the review. The reviewer's willingness to provide a post-rebuttal update with a more positive outlook also contributes to the politeness score, showing openness to improvements made by the authors."", ""Sentiment score: The review starts with a neutral to slightly positive tone, acknowledging the method's contributions and appreciating certain aspects. However, it then raises several important concerns and criticisms, particularly about the presentation of the planning algorithm, overclaiming, and lack of evaluation on downstream tasks. The balance of positive and negative comments, with the emphasis on 'important issues,' suggests a slightly negative overall sentiment, hence the score of -20.\n\nPoliteness score: The reviewer maintains a professional and respectful tone throughout. They use phrases like 'I particularly appreciated' and 'I encourage the authors,' which are polite ways of giving feedback. Even when pointing out issues, the language remains constructive rather than harsh. The reviewer also offers suggestions for improvement, which is a polite approach to criticism. However, the review is not overly effusive in its praise, maintaining a mostly neutral, academic tone. Therefore, a score of 60 reflects the polite but not excessively deferential nature of the review.""]"
"[""Pros:\n1. This work presents a novel construction of the popularly-used attention modules. It points out the problems lied in existing design that attention vectors are only computed based on parametric functions, instead of considering the interactions among each attention step and output variables. To achieve that, the authors re-write the joint distribution as a product of tractable terms at each timestamp and fully exploit the dependencies among attention and output variables across the sequence. The motivation is clear, and the proposed strategy is original and to the point. This makes the work relative solid and interesting for a publication. Furthermore, the authors propose 3 different formulation for prior attention, making the work even stronger.\n2. The technical content looks good, with each formula written clearly and with sufficient deductive steps. Figure 1 provides clear illustration on the comparison with traditional attentions and shows the advantage of the proposed model.\n3. Extensive experiments are conducted including 5 machine translation tasks as well as another morphological inflection task. These results make the statement more convincing. The authors also conducted further experiments to analyze the effectiveness, including attention entropy evaluation.\n\nCons:\n1. The rich information contained in the paper is not very well-organized. It takes some time to digest, due to some unclear or missing statements. Specifically, the computation for prior attention should be ordered in a subsection with a section name. The 3 different formulations should be first summarized and started with the same core formula as (4). In this way, it will become more clear of where does eq(6) come from or used for. Currently, this part is confusing.\n2. Many substitutions of variables take place without detailed explanation, e.g., y_{<t} with s_t, a with x_{a} in (11) etc. Could you explain before making these substitutions?\n3. As mentioned, the PAM actually computes hard attentions. It should be better to make the statement more clear by explicitly explaining eq(11) on how it assembles hard attention computation.\n\nQA:\n1. In the equation above (3) that computes prior(a_t), can you explain how P(a_{t-1}|y_{<t}) approximates P(a_{<t}|y_{<t})? What's the assumption?\n2. How is eq(5) computed using first order Taylor expansion? How to make Postr inside the probability? And where does x_a' come from?\n3. Transferring from P(y) on top of page 3 to eq(11), how do you substitute y_{<t}, a_t with s_t, x_j? Is there a typo for x_j?\n4. Can you explain how is the baseline Prior-Joint constructed? Specifically, how to compute prior using soft attention without postr?"", 'Originality: Existing attention models do not statistically express interactions among multiple attentions. The authors of this manuscript reformulate p(y|x) and define prior attention distribution (a_t depends on previous outputs y_<t) and posterior attention distribution (a_t depends on current output y_t as well), and essentially compute the prior attention at current position using posterior attention at the previous position. The hypothesis and derivations make statistical sense, and a couple of assumptions/approximations seem to be mild. \n\nQuality: The overall quality of this paper is technically sound. It pushs forward the development of attention models in sequence to sequence mapping.\n\nClarity: The ideas are presented well, if the readers go through it slowly or twice. However, the authors need to clarify the following issues: \nx_a is not well defined. \nIn Section 2.2, P(y) as a short form of Pr(y|x_1:m) could be problematic and confusing in interpretation of dependency over which variables.  \nPage 3: line 19 of Section 2.2.1, should s_{n-1} be s_{t-1}?\nIn Postr-Joint, Eq. (5) and others, I believe a\'_{t-1} is better than a\', because the former indicate it is attention for position t-1.\n\nI am a bit lost in the description of coupling energies. The two formulas for proximity biased coupling and monotonicity biased coupling are not well explained. \n\nIn addition to the above major issues, I also identified a few minors: \nsignificant find -> significant finding\nLast line of page 2: should P(y_t|y_<t, a_<n, a_n) be P(y_t|y_<t, a_<t, a_t)?\ntop-k -> top-K\na equally weighted combination -> an equally weighted combination\nSome citations are not used properly, such as last 3rd line of page 4, and brackets are forgotten in some places, etc.\nEnd of Section 3, x should be in boldface.\nnon-differentiability , -> non-differentiability,\nFull stop ""."" is missing in some places.\nLuong attention is not defined.\n\nSignificance: comparisons with an existing soft-attention model and an sparse-attention model on five machine translation datasets show that the performance of using posterior attention indeed are better than benchmark models. \n\nUpdate: I have read the authors\' response. My current rating is final.\n', 'This paper proposes a new sequence to sequence model where attention is treated as a latent variable, and derive novel inference procedures for this model. The approach obtains significant improvements in machine translation and morphological inflection generation tasks. An approximation is also used to make hard attention more efficient by reducing the number of softmaxes that have to be computed.  \n\nStrengths:\n- Novel, principled sequence to sequence model.\n- Strong experimental results in machine translation and morphological inflection.\nWeaknesses:\n- Connections can be made with previous closely related architectures.\n- Further ablation experiments could be included. \n\nThe derivation of the model would be more clear if it is first derived without attention feeding: The assumption that output is dependent only on the current attention variable is then valid. The Markov assumption on the attention variable should also be stated as an assumption, rather than an approximation: Given that assumption, as far as I can tell the (posterior) inference procedure that is derived is exact: It is indeed equivalent to the using the forward computation of the classic forward-backward algorithm for HMMs to do inference. \nThe model’s overall distribution can then be defined in a somewhat different way than the authors’ presentation, which I think makes more clear what the model is doing:\np(y | x) = \\sum_a \\prod_{t=1}^n p(y_t | y_{<t}, x, a_t) p(a_t | y_{<t}, x_ a_{t-1}).  \nThe equations derived in the paper for computing the prior and posterior attention is then just a dynamic program for computing this distribution, and is equivalent to using the forward algorithm, which in this context is:\n \\alpha_t(a) = p(a_t = a, y_{<=t}) = p(y_t | s_t, a_t =a) \\sum_{a’} \\alpha_{t-1}(a’) p(a_t = a | s_t, a_{t-1} = a’) \n\nThe only substantial difference in the inference procedure is then that the posterior attention probability is fed into the decoder RNN, which means that the independence assumptions are not strictly valid any more, even though the structural assumptions are still encoded through the way inference is done. \n[1] recently proposed a model with a similar factorization, although that model did not feed the attention distribution, and performed EM-like inference with the forward-backward algorithm, while this model is effectively computing forward probabilities and performing inference through automatic differentiation.\n\nThe Prior-Joint variant, though its definition is not as clear as it should be, seems to be assuming that the attention distribution at each time step is independent of the previous attention (similar to the way standard soft attention is computed) - the equations then reduce to a (neural) version of IBM alignment model 1, similar to another recently proposed model [2]. These papers can be seen as concurrent work, and this paper provides important insights, but it would strengthen rather than weaken the paper to make these connections clear. \n\nThe results clearly show the advantages of the proposed approach over soft and sparse attention baselines. However, the difference in BLEU score between the variants of the prior or posterior attention models is very small across all translation datasets, so to make claims about which of the variants are better, at a minimum statistical significance testing should be done. Given that the “Prior-Joint” model performs competitively, is it computationally more efficient that the full model? \n\nThe main missing experiment is not doing attention feeding at all. The other experiment that is not included (as I understood it) is to compute prior and posterior attention, but feed the prior attention rather than the posterior attention. \n\nThe paper is mostly written very clearly, there are just a few typos and grammatical errors in sections 4.2 and 4.3. \n\nOverall, I really like this paper and would like to see it accepted, although I hope that a revised version would make the assumptions the model is making clearer and make connections to related models clearer. \n \n[1] Neural Hidden Markov Model for Machine Translation, Wang et al, ACL 2018. \n[2] Hard Non-Monotonic Attention for Character-Level Transduction, Wu, Shapiro and Cotterell, EMNLP 2018. ']","[70, 60, 70]","[60, 70, 80]","[""The sentiment score is 70 (positive) because the review begins with several 'Pros' that highlight the novelty, technical soundness, and extensive experimentation of the work. The reviewer uses phrases like 'novel construction', 'clear motivation', 'original strategy', and 'extensive experiments', indicating a generally positive view. However, the score is not higher because there are also 'Cons' and questions raised, suggesting some areas for improvement. The politeness score is 60 (moderately polite) because the reviewer maintains a professional and respectful tone throughout, using phrases like 'Could you explain' and framing criticisms as suggestions for improvement rather than harsh judgments. The reviewer also balances positive and negative feedback. However, the score is not higher as the language is primarily neutral and matter-of-fact rather than overtly courteous."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting its originality, technical soundness, and significance. They state that the paper 'pushs forward the development of attention models' and that the performance results are 'better than benchmark models'. However, it's not extremely positive as they also point out several issues that need clarification.\n\nThe politeness score is 70 (polite) because the reviewer maintains a professional and respectful tone throughout. They acknowledge the paper's strengths before presenting their critiques, and phrase their suggestions as needs rather than demands (e.g., 'the authors need to clarify'). The reviewer also uses polite language like 'I believe' when making suggestions. The presence of detailed, constructive feedback also contributes to the polite tone. However, it's not extremely polite as it maintains a formal, direct style typical of academic reviews."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, noting its strengths, novel approach, and strong experimental results. The reviewer states 'I really like this paper and would like to see it accepted,' indicating a favorable opinion. However, it's not 100 as the reviewer also points out some weaknesses and suggests improvements. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They offer suggestions for improvement in a considerate manner, acknowledge the paper's strengths, and use phrases like 'I hope that' when suggesting revisions. The tone is professional and courteous, avoiding any harsh criticism.""]"
"['The main contributions of this work are essentially on the theoretical aspects. It seems that the proposed algorithm is not very original because its two parts, namely prediction (coefficient estimation) and learning (dictionary update) have been widely used in the literature, using respectively a IHT and a gradient descent. The authors need to describe in detail the algorithmic novelty of their work.\n\nThe definition of “recovering true factor exactly” need to be given. The proposed algorithm involves several tuning parameters, when alternating between two updating rules, an IHT-based update for coefficients and a gradient descent-based update for the dictionary. Therefore, an appropriate choice of their values need to be given.\n\nIn the algorithm, the authors need to define the HT function in (3) and (4).\n\nIn the experiments, the authors compare the proposed method to only the one proposed by Arora et al. 2015. We think that this is not enough, and more extensive experimental results would provide a better paper. \n\nThere are some typos that can be easily found, such as “of the out algorithm”.', 'The paper deals with the problem of recovering an exact solution for both the dictionary and the activation coefficients. As other works, the solution is based on a proper initialization of the dictionary. The authors suggest using Aurora 2015 as a possible initialization. The contribution improves Arora 2015 in that it converges linearly and recovers both the dictionary and the coefficients with no bias.\n\nThe main contribution is the use of a IHT-based strategy to update the coefficients, with a gradient-based update for the dictionary (NOODL algorithm). The authors show that, combined with a proper initialization, this has exact recovery guaranties. Interestingly, their experiments show that NOODL converges linearly in number of iterations, while Arora gets stuck after some iterations.\n\nI think the paper is relevant and proposes an interesting contribution. The paper is well written and the key elements are in the body. However, there is a lot of important material in the Appendix, which I think may be relevant to the readers. It would be nice to have some more intuitive explanations at least of Theorem 1. Also, it is clear in the experiments the superiority with respect to Arora in terms of iterations (and error), but what about computational time?', 'The paper considers the problem of dictionary learning. Here the model that we are given samples y, where we know that y = Ax where A is a dictionary matrix, and x is a random sparse vector. The goal is typically to recover the dictionary A, from which one can also recover the x under suitable conditions on A. The paper shows that there is an alternating optimization-based algorithm for this problem that under standard assumptions provably converges exactly to the true dictionary and the true coefficients x (up to some negligible bias).\n\nThe main comparison with prior work is with [1]. Both give algorithms of this type for the same problem, with similar assumptions (although there is some difference; see below). In [1], the authors give two algorithms: one with a better sample complexity than the algorithm presented here, but which has some systematic, somewhat large, error floor which it cannot exceed, and another which can obtain similar rates of convergence to the exact solution, but which requires polynomial sample complexity (the explicit bound is not stated in the paper). The algorithm here seems to build off of the former algorithm; essentially replacing a single hard thresholding step with an IHT-like step. This update rule is able to remove the error floor and achieve exact recovery. However, this makes the analysis substantially more difficult. \n\nI am not an expert in this area, but this seems like a nice and non-trivial result. The proofs are quite dense and I was unable to verify them carefully.\n\nComments:\n\n- The analysis in [1] handles the case of noisy updates, whereas the analysis given here only works for exact updates. The authors claim that some amount of noise can be tolerated, but do not quantify how much.\n\n- A.4 makes it sound like eps_t needs to be assumed to be bounded, when all that is required is the bound on eps_0.\n\n[1] Arora, S. Ge, R., Ma, T. and Moitra, A. Simple, Efficient, and Neural Algorithms for Sparse Coding. COLT 2015.']","[-40, 70, 60]","[20, 60, 80]","[""The sentiment score is -40 because the review is generally critical, pointing out several areas for improvement and questioning the originality of the work. However, it's not entirely negative as it acknowledges some theoretical contributions. The politeness score is 20 because while the language is not overtly rude, it's also not particularly polite. The reviewer uses direct language to point out issues ('need to describe', 'need to be given') but maintains a professional tone without personal attacks. The reviewer also uses phrases like 'we think' which softens the criticism slightly."", ""The sentiment score is 70 (positive) because the reviewer expresses that the paper is 'relevant and proposes an interesting contribution,' and is 'well written.' They also highlight the paper's improvements over previous work and its linear convergence. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and offering constructive suggestions. They use phrases like 'I think' and 'It would be nice' when making recommendations, which maintains a polite tone. The reviewer balances praise with gentle suggestions for improvement, without using any harsh or critical language."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as presenting a 'nice and non-trivial result' and acknowledges its improvements over prior work. The reviewer also notes the difficulty of the analysis and the paper's contribution to the field. However, it's not extremely positive as the reviewer mentions some limitations and areas for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('I am not an expert in this area'), and provides constructive feedback. The reviewer also balances positive comments with areas for improvement in a professional manner, without using harsh or critical language.""]"
"[""==========================\nI have read the authors' response and other reviewers' comments. Thanks the authors for taking great effort in answering my questions. Generally, I feel satisfied with the repsonse, and prefer an acceptance recommendation. \n==========================\nContributions:\n\nThe main contribution of this paper is the proposed RelGAN. First, instead of using a standard LSTM as generator, the authors propose using a relational memory based generator. Second, instead of using a single CNN as discriminator, the authors use multiple embedded representations. Third, Gumbel-softmax relaxation is also used for training GANs on discrete textual data. The authors also claim the proposed model has the ability to control the trade-off between sample quality and diversity via a single adjustable parameter. \n\nDetailed comments:\n\n(1) Novelty: This paper is not a breakthrough paper, mainly following previous work and propose new designs to improve the performance. However, it still contains some novelty inside, for example, the model choice of the generator and discriminator. I think the observation that the temperature control used in the Gumbel-softmax can reflect the trade-off between quality and diversity is interesting. \n\nHowever, I feel the claim in the last sentence of the abstract and introduction is a little bit strong. Though this paper seems to be the first to really use Gumbel-softmax for text generation, similar techniques like using annealed softmax to approximate argmax has already been used in previous work (Zhang et al., 2017). Since this is similar to Gumbel-softmax, I think this may need additional one or two sentences to clarify this for more careful discussion.  \n\nFurther, I would also recommend the authors discuss the following paper [a] to make this work more comprehensive as to the discussion of related work. [a] also uses annealed softmax approximation, and also divide the GAN approaches as RL-based and RL-free, similar in spirit as the discuss in this paper. \n\n[a] Adversarial Text Generation via Feature-Mover's Distance, NIPS 2018.\n\n(2) Presentation: This paper is carefully written and easy to follow. I enjoyed reading the paper. \n\n(3) Evaluation: Experiments are generally well-executed, with ablation study also provided. However, human evaluation is lacked, which I think is essential for this line of work. I have a few questions listed below. \n\nQuestions:\n\n(1) In section 2.4, it mentions that the generator needs pre-training. So, my question is: does the discriminator also need pre-training? If so, how the discriminator is pre-trained?\n\n(2) In Table 1 & 2 & 3, how does your model compare with MaskGAN? If this can be provided, it would be better. \n\n(3) Instead of using NLL_{gen}, a natural question is: what are the self-BLEU score results since it was used in previous work?\n\n(4) The \\beta_max value used in the synthetic and real datasets is quite different. For example, \\beta_max = 1 or 2 in synthetic data, while \\beta_max = 100 or 1000 is used in real data. What is the observation here? Can the authors provide some insights into this?\n\n(5) I feel Figure 3 is interesting. As the authors noted, NLL_gen measures diversity, NLL_oracle measures quality. Looking at Figure 3, does this mean GAN model produces higher quality samples than MLE pretrained models, while GAN models also produces less diverse samples than MLE models? This is due to NLL_gen increases after pretraining, while NLL_oracle further decreases after pretraining. However, this conclusion also seems strange. Can the authors provide some discussion on this? \n\n(6) Can human evaluation be performed since automatic metrics are not reliable enough?\n"", 'Update: the authors\' response and changes to the paper properly addressed the concerns below. Therefore the score was improved from 6 to 8.\n\n----\n\n\nThe paper makes several contributions: 1. it extends GAN to text via Gumbel-softmax relaxation, which seems more effective than the other approaches using REINFORCE or maximum likelihood principle. 2. It shows that using relational memory for LSTM gives better results. 3. Ablation study on the necessity of the relational memory, the relaxation parameter and multi-embedding in the discriminator is performed.\n\nThe paper\'s ideas are novel and good in general, and would make a good contribution to ICLR 2019. However, there are a few things in need of improvement before it is suite for publication. I am willing to improve the scores if the following comments are properly addressed.\n\nFirst of all, the paper does not compare with recurrent networks trained using only the ""teacher-forcing"" algorithm without using GAN. This means that at a high level, the paper is insufficient to show that GAN is necessary for text generation at all. That said, since almost every other text GAN paper also failed to do this, and the paper\'s contribution on using Gumbel-softmax relaxation and the relational memory is novel, I did not get too harsh on the scoring because of this.\n\nSecondly, whether using BLEU on the entire testing dataset is a good idea for benchmarking is controversial. If the testing data is too large, it could be easily saturated. On the other hand, if the testing data is small, it may not be sufficient to capture the quality well. I did not hold the authors responsible on this either, because it was used in previously published results. However, the paper did propose to use an oracle, and it might be a good idea to use a ""teacher-forcing"" trained RNN anyways since it is necessary to show whether GAN is a good idea for text generation to begin with (see the previous comment).\n\nA third comment is that I had wished the paper did more exploration on the relaxation parameter \\beta. Ideally, if \\beta is too large, the output would be too skewed towards a one-hot vector such that instability in the gradients occurs. On the other hand, if \\beta is too small, the output might not be close enough to one-hot vectors to make the discriminator focus on textual differences rather than numerical differences (i.e., between a continuous and a one-hot vector). It would make sense for the paper to show both ends of these failing cases, which is not apparent with only 2 hyper-parameter choices.\n\nFinally, the first paragraph in section 2.2.2 suggests that the gap between discrete and continuous outputs is the reason for mode collapsing. This is false. For image generation, when all the outputs are continuous, there is still mode collapsing happening with GANs. The authors could say that the discrete-continuous gap contributes to mode-collapsing, but this is not too good either because it will require the paper to conduct experiments beyond text generation to show this. Authors should make changes here.', 'Overall:\nThis paper proposes RelGAN, a new GAN architecture for text generation, consisting of three main components: a relational memory based generator for the long-distance dependency modeling, the Gumbel-Softmax relaxation for training GANs on discrete data, and multiple embedded representations in the discriminator to provide a more informative signal\nfor the generator updates.\n\nQuality and Clarity:\nThe paper is well-written and easy to read. \n\nOriginality :\nAlthough each of the components (relational memory, Gumbel-softmax) was already proposed by previous works, it is interesting to combine these into a new GAN-based text generator. \nHowever, the basic setup is not novel enough. The model still requires pre-training the generator using MLE. The major difference are the architectures (relational memory, multi-embedding discriminator) and training directly through Gumbel-softmax trick which has been investigated in (Kusner and Hernandez-Lobato, 2016). \n\nSignificance:\nThe experiments in both synthetic and real data are in detail, and the results are good and significant.\n\n-------------------\nComments:\n-- In (4), sampling is known as non-differentiable which means that we cannot get a valid definition of gradients. It is different to denote the gradient as 0.\n-- Are the multiple representations in discriminator simply multiple “Embedding” matrices?\n-- Curves using Gumbel-softmax trick + RM will eventually fall after around 1000 iterations in all the figures. Why this would happen?\n-- Do you try training from scratch without pre-training? For instance, using WGAN as the discriminator\n\n\nRelated work:\n-- Maybe also consider to the following paper which used Gumbel-softmax relaxation for improving the generation quality in neural machine translation related?\nGu, Jiatao, Daniel Jiwoong Im, and Victor OK Li. ""Neural machine translation with gumbel-greedy decoding."" arXiv preprint arXiv:1706.07518 (2017).\n']","[70, 50, 60]","[80, 70, 70]","[""The sentiment score is 70 (positive) because the reviewer expresses satisfaction with the authors' response and recommends acceptance in the first paragraph. They also praise aspects of the paper like its careful writing and well-executed experiments. However, they do raise some concerns and suggestions for improvement, preventing a higher score. The politeness score is 80 (polite) due to the reviewer's consistently respectful tone, use of phrases like 'Thanks the authors for taking great effort', and constructive framing of criticisms. They ask questions politely and offer suggestions in a helpful manner rather than being demanding. The reviewer maintains a professional and courteous tone throughout, even when pointing out potential weaknesses or areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novel ideas and potential contributions, but also points out several areas needing improvement. The initial paragraph indicates the paper 'makes several contributions' and 'would make a good contribution to ICLR 2019', showing a generally positive view. However, the reviewer lists multiple concerns and suggests changes, balancing the positive aspects.\n\nThe politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout. They begin by highlighting the paper's strengths before moving to criticisms, which are presented as suggestions rather than demands. Phrases like 'I am willing to improve the scores if the following comments are properly addressed' and 'I did not hold the authors responsible on this' demonstrate a considerate tone. The reviewer also acknowledges the limitations of their own criticisms in some cases. However, the score is not higher as the review maintains a professional, rather than overtly friendly, tone."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting it is 'well-written and easy to read' with 'good and significant' results. However, they also point out some limitations in originality, which prevents a higher score. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive criticism, and balances positive and negative feedback. They use phrases like 'it is interesting' and ask questions rather than making harsh criticisms. The tone is professional and courteous, though not excessively formal or deferential.""]"
"['Pros:\n- The finding that SVHN has larger likelihood than CIFAR according to networks is interesting. \n- The empirical and theoretical analyses are clear, seem thorough, and make sense.\n- Section 5 can provide some insight when the model is too rigid and too log-concave (e.g. Gaussian).\nCons:\n- The premises of the analyses are not very convincing, limiting the significance of the paper.\n- In particular, Section 4 is a series of empirical analyses, based on one dataset pair. In 3/4 of the pairs the author tried, this phenomenon is not there. Whether the findings generalize to other situations where the phenomenon appears is uncertain. \n- It is good that Section 5 has some theoretical analysis. But I personally find it very disturbing to base it on a 2nd order approximation of a probability density function of images when modeling something as intricate as models that generate images. At least this limitation should be pointed out in the paper.\n- Some parts of the paper feel long-winded and aimless.\n\n[Quality]\nSee above pros and cons.\nA few less important disagreement I have with the paper:\n- I don\'t think Glow necessarily is encouraged to increase sensitivity to perturbations. The bijection needs to map training images to a high-density region of the Gaussian, and that aspect would make the model think twice before making the volume term too large.\n- Figure 6(a) clearly suggests that the data mean for SVHN and CIFAR are very different, instead of similar.\n\n[Clarity]\nIn general, the paper is clear and easy to understand given enough reading time, but feels at times long-winded.\nSection 2 background takes too much space.\nSection 3 too much redundancy -- it just explains that SVHN has a higher likelihood when trained on CIFAR, and a few variations of the same experiment.\nSection 4 seems to lack a high-level idea of what it want to prove -- the hypothesis around the volume term is dismissed shortly after, and it ultimately proves that we do not know what is the reason behind the high SVHN likelihood, making it look like a distracting side-experiment.\nA few editorial issues:\n- On page 4 footnote 2, as far as I know the paper did not define BPD.\n- There are two lines of text between Fig. 4 and Fig. 5, which is confusing.\n\n[Originality]\nI am not an expert in this specific field (analyzing generative models), but I believe this analysis is novel.\nHowever, there are papers empirically analyzing novelty detection using generative model -- should analyze or at least cite:\n    Vít Škvára et al. Are generative deep models for novelty detection truly better? \n    ^ at first glance, their AUROC is never under 0.5, indicating that this phenomenon did not appear in their experiments although a lot of inlier-novelty pairs are tried.\nA part of the paper\'s contribution (section 5 conclusion) seem to overlap with others\' work. The section concludes that if the second dataset has small variances, it will get higher likelihood. But this is too similar to the cited findings on page 6 (models assign high likelihood to constant images).\n\n[Significance] \nThe paper has a very interesting finding; pointing out and in-depth analysis of negative results should benefit the community greatly.\nHowever, only 1 dataset pair is experimented -- there should be more to ensure the findings generalize, since Sections 3 and 4 rely completely on empirical analysis. According to the conclusions of the paper, such dataset pairs should be easy to find -- just find a dataset that ""lies within"" another. Did you try e.g. CIFAR-100 train and CIFAR-10 test?\nSection 5 is based on a 2nd order expansion on the $log p(x)$ given by a deep network -- I shouldn\'t be the judge of this, but from a realistic perspective this does not mean much.\n', '\nThis paper displays an occurrence of density models assigning higher likelihood to out-of-distribution inputs compared to the training distribution. Specifically, density models trained on CIFAR10 have higher likelihood on SVHN than CIFAR10. This is an interesting observation because the prevailing assumption is that density models can distinguish inliers from outliers. However, this phenomenon is not encountered when comparing MNIST and NotMNIST. The SVHN/CIFAR10 phenomenon has also been shown in concurrent work [1].\n\nGiven that you observed that SVHN has higher likelihood on all three model types (PixelCNN, VAE, Glow), why investigate a component specific to just flow-based models (the volume term)? It seems reasonable to suspect that the phenomenon may be due to a common cause in all three model types. For instance, the experiments seem to indicate that generalizing density estimation from CIFAR training set to CIFAR test set is likely challenging and thus the models underfit the true data distribution, resulting in the simpler dataset (SVHN) having higher likelihood. \n\nGiven the title of the paper, it would have been nice if this paper explored more than just MNIST vs NotMNIST and SVHN vs CIFAR10, so that the readers can gain a better feel for when generative models will be able to detect outliers. For instance, a scenario where the data statistics (pixel means and variances) are nearly equivalent for both datasets would be interesting. The second order analysis is good but it seems to come down to just a measure of the empirical variances of the datasets. \n\nThis paper is well written. I think the presentation of this density modelling shortcoming is a good contribution but leaves a bit to be desired. \n\n[1] Choi, H. and Jang, E. Generative Ensembles for Robust Anomaly Detection. https://arxiv.org/abs/1810.01392\n\n\nPros:\n- Interesting observation of density modelling shortcoming \n- Clear presentation\n\nCons:\n- Lack of a strong explanation for the results or a solution to the problem \n- Lack of an extensive exploration of datasets\n', 'I really enjoyed reading the paper! The exposition is clear with interesting observations, and most importantly, the authors walk the extra mile in doing a theoretical analysis of the observed phenomena.\n\nQuestions for the authors:\n1. (Also AREA CHAIR NOTE): Another parallel submission to ICLR titled “Generative Ensembles for Robust Anomaly Detection” makes similar observations and seemed to suggest that ensembling can help counter the observed CIFAR/SVHN phenomena unlike what we see in Figure 10. Their criteria also accounts for the variance in model log-likelihoods and is hence slightly different.\n2. Even though Figure 2b shows that SVHN test likelihoods are higher than CIFAR test likelihoods, the overlap in the histograms of CIFAR-train and CIFAR-test is much higher than the overlap in CIFAR-train and SVHN-test. If we define both maximum and minimum thresholds based on the CIFAR-train histogram, it seems like one could detect most SVHN samples just by the virtue that there likelihoods are much higher than even the max threshold determined by the CIFAR-train histogram?\n3. Why does the constant image (all zeros) in Figure 9 (appendix) have such a high likelihood? It’s mean (=0 trivially) is clearly different from the means of the CIFAR-10 images (Figure 6a) so the second order analysis of Section 5 doesn’t seem applicable.\n4. How much of this phenomena do you think is characteristic for images specifically? Would be interesting to test anomaly detection using deep generative models trained on modalities other than images.\n5. One of the anonymous comments on OpenReview is very interesting: samples from a CIFAR model look nothing like SVHN. This seems to call the validity of the anomalous into question. Curious what the authors have to say about this.\n\nMinor nitpick: There seems to be some space crunching going on via Latex margin and spacing hacks that the authors should ideally avoid :)']","[-20, -20, 80]","[50, 60, 90]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting finding', 'clear and thorough analyses'), there are more criticisms than praises. The cons outweigh the pros, with concerns about the paper's premises, generalizability, and some theoretical foundations. The reviewer also points out areas that feel 'long-winded and aimless'. However, the score is not deeply negative as the reviewer still finds value in the work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express criticisms ('not very convincing', 'limitation should be pointed out') rather than harsh or dismissive terms. The reviewer also balances negative points with positive ones, acknowledging the paper's strengths. The use of phrases like 'I personally find' and 'I shouldn't be the judge of this' shows a degree of humility and politeness in expressing opinions."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting observation and clear presentation, they also point out several limitations. The review mentions a 'lack of strong explanation', 'lack of extensive exploration', and states that the paper 'leaves a bit to be desired'. These criticisms outweigh the positive comments, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the paper's contributions and using phrases like 'it would have been nice' and 'I think' to soften criticisms. The reviewer also provides constructive feedback and suggestions for improvement, which contributes to the polite tone."", ""The sentiment score is 80 (positive) because the reviewer starts with 'I really enjoyed reading the paper!' and praises the clear exposition, interesting observations, and theoretical analysis. The overall tone is very positive, though not perfect (100) as there are some questions and a minor criticism. The politeness score is 90 (very polite) due to the respectful and constructive nature of the questions, the use of phrases like 'Curious what the authors have to say about this', and the gentle phrasing of the minor criticism as a 'nitpick'. The reviewer maintains a professional and courteous tone throughout, showing genuine interest in the authors' work and perspectives.""]"
"['Summary: the paper introduces a new way of fine-tuning neural networks. Instead of re-training the whole model or fine-tuning the last few layers, the authors propose to fine-tune a small set of model patches that affect the network at different layers. The results show that this way of fine-tuning is superior to above mentioned typical ways either in accuracy or in the number of tuned parameters in three different settings: transfer learning, multi-task learning and domain adaptation.\n\nQuality: the introduced way of fine-tuning is interesting alternative to the typical last layer re-training. I like that the authors present an intuition behind their approach and justify it by an illustrative example. The experiments are fair, assuming the authors explain the choice of hyper-parameters during the revision.\n\nClarity: in general the paper is well-written. The discussion of multi-task and domain adaptation parts can be improved though.\n\nOriginality: the contributions are novel to my best knowledge.\n\nSignificance: high, I believe the paper may facilitate a further developments in the area.\n\nI ask the authors to address the following during the rebuttal stage:\n* explain the choice of the hyper-parameters of RMSProp (paragraph under Table 1).\n* fix Figure 3, it\'s impossible to read in the paper-printed version\n* explain how the average number of parameters per model in computed in Tables 4 and 5. E.g. 700K params/model in the first column of Table 4 is misleading - I suppose the shared parameters are not taken into account. The same holds for 0 in the second column, etc.\n* add a proper discussion for domain adaptation part. The simple ""The results are shown in Table 5"" is not enough. \n* consider leaving the discussion of cost-efficient model cascades out. The presented details are too condensed and do not add value to the paper.\n* explain how different resolutions are managed by the same model in the domain adaptation experiments.', 'This paper explored the means of tuning the neural network models using less parameters. The authors evaluated the case where only the batch normalisation related parameters are fine tuned, along with the last layer, would generate competitive classification results, while using very few parameters comparing with fine tuning the whole network model. However, several questions are raised concerning the experiment design and analysis:\n1. Only MobilenetV2 and InceptionV3 are evaluated as classification model, while other mainstream models such as ResNet, DenseNet are not included. Would it be very different regarding the conclusion of this paper?\n2. It seems that the only effective manner is by fine tuning the parameters of both batch normalisation related and lasts layer, while fine tuning last layer seems to be having the main impact on the final result. In Table 4, authors do not even provide the results fine tuning last layer only.\n3. The organisation of the paper and the order of illustration is a bit confusing. e.g. later sections are frequently referred in the earlier sections. Personally I would prefer a plain sequence than keep turning pages for confirmation.', 'The authors proposed an interesting method for parameter-efficient transfer learning and multi-task learning. The authors show that in transfer learning fine-tuning the last layer plus BN layers significantly improve the performance of only fine-tuning the last layer. The results are surprisingly good and the authors also did analysis on the relationship between embedding space and biases. \n\n1. The memory benefit is obvious, it would be interesting to know the training speed compared to fine-tuning methods (both the last layer and the entire network)?\n2. It seems that DW patch has limited effects compared to S/B patch. It would be nice to have some analysis of this aspect.\n']","[70, -20, 80]","[80, 50, 70]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper. They describe the work as 'interesting,' 'fair,' and 'novel,' and state that the paper has 'high' significance. The reviewer also mentions liking certain aspects of the paper. However, it's not a perfect score as they do suggest some improvements. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their suggestions as requests rather than demands (e.g., 'I ask the authors to address...'). The tone is professional and constructive, offering specific recommendations for improvement without being harsh or critical."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's exploration of tuning neural networks with fewer parameters, they raise several critical questions and concerns about the experiment design and analysis. The reviewer points out limitations in the model selection, incomplete results presentation, and confusing organization of the paper. These criticisms outweigh the initial positive acknowledgment, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns, such as 'several questions are raised' and 'Personally I would prefer,' rather than using harsh or dismissive language. The reviewer also begins with a neutral summary of the paper's content before presenting their critiques, which is a polite approach in academic reviews."", ""The sentiment score is 80 (positive) because the reviewer describes the method as 'interesting' and the results as 'surprisingly good'. They also mention that the authors conducted additional analysis, which is viewed favorably. The overall tone is appreciative of the work. The politeness score is 70 (polite) as the language used is respectful and constructive. The reviewer offers suggestions for improvement in a gentle manner, using phrases like 'it would be interesting' and 'it would be nice'. There are no harsh criticisms or demanding language. The review maintains a professional and courteous tone throughout.""]"
"['This paper proposed a new network structure to learn GAN with incomplete data, and it is a nice extension of AmbientGAN. Two theorems are provided for better understanding the potential effect of the missing values. Improved results compared with state-of-the-art methods on MNIST, CIFAR-10 and CelebA are presented. Overall, the paper is well organized, and the experiment results are sufficient to demonstrate the advantages of the proposed method. I particular like figure5 where AmbientGAN failed in this case.\n\n Several suggestions about improving the paper. I notice the images used in the experiments are small size. It would be interesting to test the performance on a larger image. Another direction would be testing the robustness of the model, for example, what will happen if the observation is also noisy? Some discussion about the potential extensions will also be helpful. For example, can the proposed network be used to solve the compressive sensing problem with a real value mask instead of binary valued. \n\nI did not dive into the detail of the prove of theorems. And it seems valid by reading through each step.  Although these two theorems are not directly related to the properties of the proposed network structure. But it does provide some nice intuition.\n', 'Building upon the success of AmbientGAN by Bora, Price, and Dimakis, this paper studies one of the major issues that is not resolved in AmbientGAN: the distribution of the data corruption is typically unknown. In general this is an ill-defined problem to solve, as the data corruption distribution is not identifiable from the corrupted data. The major insight of this paper is to identify a plausible setting where such identifiability issues are not present. Namely, the corruption itself is identifiable from the corrupted data. The brilliance of this paper is in identifying this niche application of data imputation/missing data/incomplete data. \n\nOnce the goal is set to train a GAN on incomplete data, the solution somewhat follows in a straightforward manner from AmbientGAN. Pass the generated output through a masking operator, which is also trained. Train the masking operator on the masking pattern of the real (corrupted) data. Imputation generator and discriminator also follows in a straightforward manner. \n\nA major shortcoming of this paper is that the performance of the proposed approach is not fully supported by extensive experiments. For example, a major application of such imputation solution will be predicting missing data in real world applications, such as recommendation systems, or biological experimental data. A experimental setting in ""GAIN: Missing Data Imputation using Generative Adversarial Nets"" provides an excellent benchmark dataset, and imputation approaches should be compared against GAIN in those scenarios. \n\n\n', ""This is a good paper, as we have good experimental evidence that the proposed method seems to have some advantage over baseline methods.\n\nThe authors measure the success of their algorithm by computing FID scores for the randomly inputed images. That is the authors use a metric which measures a distance between the distribution of the generated images and images in a dataset. This is fine and interesting to know, but people also care about the distance of the completed pixels from the ground truth (missing) values. (E.g. https://www.cs.rochester.edu/u/jliu/paper/Ji-ICCV09.pdf)\n\nThis is important, because in a real life application, one would pick the mode of the distribution of the missing samples, and not sample from that distribution as the authors seems to be doing in this paper. \n\nI would therefore suggest adding experiments where authors pick the mode of the distribution and estimate an error metric such as root mean square error (RMSE or PSNR https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio ) \n\nI also found the 'marketing'/presentation of the algorithm little misleading, especially in the introduction, given that there exists another GAN based imputation algorithm. I think the authors should clearly state in the introduction that the other algorithm, abbreviated GAIN, exists as a GAN based missing data completion method. Then they should point out the differences of this algorithm from GAIN. Namely they should elaborate verbally on why learning the missing data distribution helps. Overall, what I am trying to say is, the key idea of this paper - that is learning the mask distribution - is not well motivated in this paper. \n\nDespite my concerns above, I recommend an accept. The algorithm seems novel, and there is some experimental results to back it up.  \n\n\n""]","[80, 60, 60]","[70, 80, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, praising its organization, experimental results, and theoretical contributions. They use phrases like 'nice extension,' 'well organized,' and 'sufficient to demonstrate the advantages.' The reviewer also mentions liking a specific figure. The score is not 100 as there are some suggestions for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than criticisms. They use phrases like 'Several suggestions about improving the paper' and 'It would be interesting to test,' which are polite ways of offering feedback. The reviewer also acknowledges the validity of the proofs without claiming expertise, which is a polite approach."", ""The sentiment score is 60 (positive) because the reviewer expresses appreciation for the paper's insights and approach, using phrases like 'major insight,' 'brilliance,' and 'success.' However, it's not extremely positive due to the mention of a 'major shortcoming' in the experimental support. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. The critique is presented in a professional manner without harsh or dismissive language. The reviewer also provides specific suggestions for improvement, which is a polite way to offer feedback."", ""The sentiment score is 60 (positive) because the reviewer starts by calling it a 'good paper' and recommends acceptance despite some concerns. They acknowledge the experimental evidence and novelty of the algorithm. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They use phrases like 'I would suggest' and 'I think the authors should' which are polite ways of giving feedback. The reviewer also balances critique with positive comments, ending on a positive note recommending acceptance.""]"
"['Review:\n\nThis paper proposes a method for finding optimal architectures for deep neural networks based on a teacher network. The optimal network is found by removing or shrinking layers or adding skip connections. A Bayesian Optimization approach is used by employing a Gaussian Process to guide the search and the acquisition function expected improvement. A special kernel is used in the GP to model the space of network architectures. The method proposed is compared to a random search strategy and a method based on reinforcement learning.\n\t\nQuality: \n\n\tThe quality of the paper is high in the sense that it is very well written and contains exhaustive experiments with respect to other related methods\n\nClarity: \n\n\tThe paper is well written in general with a few typos, e.g., \n\n\t""The weights of the Bi-LSTM θ, is learned during the search process. The weights θ determines""\n\nOriginality: \n\n\tThe proposed method is not very original in the sense that it is a combination of several known techniques. May be the most original contribution is the proposal of a kernel for network architectures based on recurrent neural networks.\n\n\tAnother original idea is the use of sampling to avoid the problem of doing kernel over-fitting. Something that can be questioned, however, in this regard is the fact that instead of averaging over kernels the GP prediction to account for uncertainty in the kernel parameters, the authors have suggested to optimize a different acquisition function per each kernel. This can be problematic since for each kernel over-fitting can indeed occur, although the experimental results suggest that this is not happening.\n\t\nSignificance:\n\n\tWhy N2N does not appear in all the CIRFAR-10 and CIFAR-100 experiments? This may question the significance of the results.\n\n\tIt also seems that the authors have not repeated the experiments several times since there are no error bars in the results.\n\tThis may also question the significance of the results. An average over several repetitions is needed to account for the randomness in for example the sampling of the network architectures to learn the kernels.\n\n\tBesides this, the authors may want to cite this paper\n\n\tHernández-Lobato, D., Hernandez-Lobato, J., Shah, A., & Adams, R. (2016, June). Predictive entropy search for multi-objective Bayesian optimization. In International Conference on Machine Learning (pp. 1492-1501).\t\n\n\twhich does multi-objective Bayesian optimization of deep neural networks (the objectives are accuracy and prediction time).\n\nPros:\n\n\t- Well written paper.\n\t\t\n\t- Simply idea.\n\n\t- Extensive experiments.\n\nCons:\n\t\n\t- The proposed  approach is a combination of well known methods.\n\n\t- The significance of the results is in question since the authors do not include error bars in the experiments.', '================\nPost-Rebuttal\n================\n\nI thank the authors for the larger amount of additional work they put into the rebuttal. Since the authors addressed my main concerns, i e. comparison to existing methods,  clarifications of the proposed approach, adding references to related work, I will  increase my score and suggest to accept the paper.\n\n\n\n\nThe paper describes a new neural architecture search strategy based on Bayesian optimization to find a compressed version of a teacher network. The main contribution of the paper is to learn an embedding that maps from a discrete encoding of an architecture to a continuous latent vector such that standard Bayesian optimization can be applied. \nThe new proposed method improves in terms of compressing the teacher network with just a small drop in accuracy upon an existing neural architecture search method based on reinforcement learning and random sampling.\n\n\nOverall, the paper presents an interesting idea to use Bayesian optimization on high dimensional discrete problems such as neural architecture search. I think a particular strength of this methods is that the embedding is fairly general and can be combined with various recent advances in Bayesian optimization, such as, for instance, multi-fidelity modelling.\nIt also shows on some compression experiments superior performance to other state-of-the-art methods.\n\nHowever, in its current state I do not think that the paper is read for acceptance:\n\n- Since the problem is basically just a high dimensional, discrete optimization problem, the paper misses comparison to other existing Bayesian optimization methods such as TPE [1] / SMAC [2] that can also handle these kind of input spaces. Both of these methods have been applied to neural architecture search [3][4] before. Furthermore, since the method is highly related to NASBOT [5], it would be great to also see a comparison to it.\n\n- I assume that in order to learn a good embedding, similar architectures need to be mapped to latent vector that are close in euclidean space, such that the Gaussian process kernel can model any correlation[7]. How do you make sure that the LSTM learns a meaningful embedding space? It is also a bit unclear why the performance f is not used directly instead of p(f|D). Using f instead of p(f|D) would probably also make continual training of the LSTM easier, since function values do not change.\n\n- The experiment section misses some details:\n  - Do the tables report mean performances or the performance of single runs? It would also be more convincing if the table contains error bars on the reported numbers.\n  - How are the hyperparameters of the Gaussian process treated?\n  \n- The related work section misses some references to Lu et al.[6] and Gomez-Bombarelli et al.[7] which are highly related.\n\n- What do you mean with the sentence  ""works on BO for NAS can only tune feed-forward structures"" in the related work section? There is no reason why other Bayesian optimization should not be able to also optimize recurrent architectures (see for instance Snoek et al.[8]). \n\n- Section 3.3 is a bit confusing and to be honest I do not get the motivation for the usage of multiple kernels. Why do the first architectures biasing the LSTM? Since Bayesian optimization with expected improvement samples around the global optimum, should not later evaluated, well-performing architectures more present in the training dataset for the LSTM?\n\n\n[1] Algorithms for Hyper-Parameter Optimization\n    J. Bergstra and R. Bardenet and Y. Bengio and B. Kegl\n    Proceedings of the 25th International Conference on Advances in Neural Information Processing Systems (NIPS\'11)\n\n[2] Sequential Model-Based Optimization for General Algorithm Configuration\n    F. Hutter and H. Hoos and K. Leyton-Brown\n    Proceedings of the Fifth International Conference on Learning and Intelligent Optimization (LION\'11)\n\n[3] Towards Automatically-Tuned Neural Networks\n    H. Mendoza and A. Klein and M. Feurer and J. Springenberg and F. Hutter\n    ICML 2016 AutoML Workshop\n\n[4] Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures\n    J. Bergstra and D. Yamins and D. Cox\n    Proceedings of the 30th International Conference on Machine Learning (ICML\'13)\n\n[5] Neural Architecture Search with Bayesian Optimisation and Optimal Transport\n    K. Kandasamy and W. Neiswanger and J. Schneider and B. P{\\\'{o}}czos and E. Xing\n    abs/1802.07191\n\n[6] Structured Variationally Auto-encoded Optimization\n    X. Lu and J. Gonzalez and Z. Dai and N. Lawrence\n    Proceedings of the 35th International Conference on Machine Learning\n\n[7] Automatic chemical design using a data-driven continuous representation of molecules\n    R. Gómez-Bombarelli and J. Wei and D. Duvenaud and J. Hernández-Lobato and B. Sánchez-Lengeling and D. Sheberla and J. Aguilera-Iparraguirre and T. Hirzel. and R. Adams and A. Aspuru-Guzik\n    American Chemical Society Central Science\n\n[8] Scalable {B}ayesian Optimization Using Deep Neural Networks\n    J. Snoek and O. Rippel and K. Swersky and R. Kiros and N. Satish and N. Sundaram and M. Patwary and Prabhat and R. Adams\n    Proceedings of the 32nd International Conference on Machine Learning (ICML\'15)', 'In this work, the authors propose a new strategy to compress a teacher neural network. Briefly, the authors propose using Bayesian optimization (BO) where the accuracy of the networks is modelled using a Gaussian Process function with a squared exponential kernel on continuous neural network (NN) embeddings. Such embeddings are the output of a bidirectional LSTM taking as input the “raw” (discrete) NN representations (when regarded as a covariance function of the “raw” (discrete) NN representations, the kernel is a deep kernel).\n\nThe authors apply this framework for model compression. In this application, the search space is the space of networks obtained by sampling reducing operations on a teacher network. In applications to CIFAR-10 and CIFAR-100 the authors show that the accuracies of the compressed network obtained through their method exceeds accuracies obtained through other methods for compression, manually compressed networks and random sampling.\n\nI have the following concerns/questions:\n\n1)\tThe authors motivate their work in the introduction by discussing the importance of learning a good embedding space over network architectures to “generate a priority ordering of architectures for evaluation”. Within the proposed BO framework, this would require the optimization of the expected improvement in a high-dimensional and discrete space (the space of NN architectures), which “is non-trivial”. In this work, the authors do not try to solve this general problem, but specialize their work to model compression, which has a much lower dimensional search space (space of networks obtained by sampling reducing operations on a teacher network). For this reason, I believe the presentation and motivation of this work is not presented clearly. Specifically, while I agree that the methods and results in this paper can be relevant to the problem of getting NN embeddings for a larger search space, this should be discussed in the conclusion/discussion as future direction, rather than as motivating example. Generally, I think the method should be described in the context of model compression rather than as a general method for neural architecture search (NAS) method (in my understanding, its use for NAS would be unfeasible). \n\n2)\tI have been wondering why the authors optimize the kernel parameters by maximizing the predictive GP posterior rather than maximizing the GP log marginal likelihood as in standard GP regression?\n\n3)\tThe sampling procedure should be explained in greater detail. How many reducing operations are sampled? This would be important to fully understand the random search method the authors consider for comparison in their experiments. I expect that the results from that method will strongly depend on the sampling procedure and different choices should probably be explored for a fair comparison. Do the authors have any comment on this?\n']","[20, 50, -20]","[60, 70, 60]","[""The sentiment score is slightly positive (20) because the review acknowledges the paper's high quality, good writing, and extensive experiments. However, it also points out some concerns about originality and significance of results, which prevents a higher score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, balancing praise with constructive criticism. They use phrases like 'well written' and 'extensive experiments' while politely suggesting improvements and pointing out issues. The reviewer maintains a professional tone without being overly critical or harsh."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by thanking the authors for their additional work and states they will increase their score and suggest acceptance. However, this is balanced by a long list of critiques and suggestions for improvement. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, such as 'I thank the authors', 'I think', and 'It would be great to see'. They also frame criticisms as suggestions or questions rather than direct attacks. The reviewer maintains a professional and constructive tone, even when pointing out areas for improvement."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty and potential of the work, they express several concerns and questions that suggest the paper needs significant improvements. The reviewer points out issues with the presentation, motivation, and methodology, indicating that the overall impression is somewhat critical. However, the tone is not entirely negative, as the reviewer also recognizes the relevance and potential applications of the work.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I have the following concerns/questions' and 'Do the authors have any comment on this?' which indicate a polite and constructive approach to criticism. The reviewer also acknowledges the potential value of the work while providing specific, detailed feedback for improvement. The language used is not overly formal or deferential, but it is consistently courteous and aimed at fostering academic dialogue.""]"
"['\n\nUPDATE: I\'ve increased my rating based on the authors\' thorough responses and the updates they\'ve made to the paper. However, I still have a concern over the static nature of the experimental environments.\n\n=====================\n\nThis paper proposes the use of iterative, linguistic corrections to guide (ie, condition and adjust) an RL policy. A major challenge in learning language-guided policies is grounding the language in environment states and agent actions. The authors tackle this challenge with a meta-learning approach.\n\nThe approach is fairly complex, blending imitation and supervised learning. It operates on a training set from a distribution of virtual pick-move-place tasks. The policy to be learned operates on this set and collects data, via something close to DAgger, for later supervised learning on the task distribution. The supervised-learning data comprises trajectories augmented with linguistic subgoal annotations, which are referred to as policy ""corrections."" By ingesting its past trajectories and the correction information, the policy is meant to learn to solve the task and to ground the corrections at the same time, end-to-end. Correction annotations are derived from an expert policy.\n\nThe idea of guiding a policy through natural language and the requisite grounding of language in environment states and policy actions have been investigated previously: for example, by supervised pretraining on a language corpus, as in the cited work of Andreas et al. (2018). The alternative meta-learning approach proposed here is both well-motivated and original.\n\nGenerally, I found the paper clear and easy to read. The authors explain convincingly the utility of guiding policies through language, especially with respect to the standard mechanisms of reward functions (sparse, engineered) and demonstrations (expertise required). The paper is also persuasive on the utility of iterative, interactive correction versus a fully-specified language instruction given a priori. The meta-learning algorithm and training/test setup are both explained well, despite their complexity. On the other hand, most architectural details necessary to reproduce the work are missing, at least from the main text. This includes various tensor dimensions, the structure of the network for perceiving the state, etc.\n\nI like the proposed experimental setting. It enables meta-learning on sequential decision making problems in a partially observable environment, which seems useful to the research community at large. Ultimately, however, this paper\'s significance is not evident to me, mainly because the proposed method lacks thorough experimental validation. No standard baselines are evaluated on the task (with or without meta-learning), nor is a detailed analysis of the learned policies undertaken. The ablation study is useful, and a good start, but insufficient in my opinion. Unfortunately, the results are merely suggestive rather than convincing.\n\nSome things I\'d like to see in an expanded results section before recommending this paper include:\n- Comparison to an RL baseline that attempts to learn the full task, without meta-training or language corrections.\n- Comparison to a baseline that learns from intermediate rewards. Instead of annotating data with corrections, you could provide +/- scalar rewards throughout each trajectory based on progress towards the goal (since you know the optimal policy). How effective might this be compared to using the corrections?\n- Comparison to a baseline that does some kind of pretraining on the language corrections, as in Andreas et al. (2018).\n- Quantification of how much meta-training data is required. What is the sample complexity like with/without language corrections?\n\nI also have concerns about the need for near-optimal agents on each task -- this seems very expensive and inefficient. The expert policy is obtained via RL on each individual task using ""ground truth"" rewards. It is not specified what these rewards are, nor is it stated how near to optimal the resulting policy is nor how this nearness affects the overall meta-learning process.\n\nIts unclear to me how the ""full information"" baseline processes and conditions on the full set of subgoals/corrections. Are they read as a single concatenated string converted to one vector by the bi-LSTM?\n\nThere also might be an issue with the experimental setup, unless I\'ve misunderstood it. The authors state that ""the agent only needs 2 corrections where the first correction is the location of the goal object and the second is the location of the goal square."" But if the specific rooms, indicated by colors, do not change location from task to task (and they appear not to from all the figures), then the agent can learn the room locations during meta-training and these two ""corrections"" tell it everything it needs to know to solve the task.\n\nPros:\n- Appealing, well-motivated idea for training policies via language.\n- Clear, pleasant writing and good communication of a complicated algorithm.\n- Good experimental setup that should be useful in other research (except for possible issue with static room locations).\n\nCons:\n- The need for a near-optimal policy for each task. \n- Overall complexity of the training process.\n- The so-called corrections are actually linguistic statements of subgoals computed from the optimal policy. There is much talk in the introduction of interactive policy correction by humans, which is an important goal and interesting problem, but the present paper does not actually investigate human interaction. This comes as a letdown after the loftiness of the introduction.\n- Various details needed for reproduction are lacking. Maybe they\'re in the supplementary material; if so, please state that in the main text.\n- Major lack of comparisons to alternative approaches.', 'Summary:\nThis paper studies how to teach agents to complete tasks via natural language instructions in an iterative way, e.g., correct the behavior of agents. This is a very natural way to learn as humans. The basic idea is to learn a model that takes correction and history as inputs and output what action to take. This paper formulates this in meta-learning setting in which each task is drawn from a pre-designed task distribution and then the models are able to adapt to new tasks very fast. The proposed method is evaluated in a virtual environment where the task is to pick up a particular object in a room and bring it to a particular goal location in a different room. There are two baselines: 1) instruction only (missing information), 2) full information (not iterative), the proposed method outperforms 1) with higher task completion rate and 2) with fewer number of corrections.\n\nStrength:\n- This paper addresses a very interesting problem in order to make agents learn more human like.\n\nComments:\n- Only one setting is studied. And, the task distribution seems not very complex.\n- How the proposed model performs if the task is a little bit out of distribution?\n', 'This paper provides a meta learning framework that shows how to learn new tasks in an interactive setup.  Each task is learned through a reinforcement learning setup, and then the task is being updated by observing new instructions. They evaluate the proposed method in a simulated setup, in which an agent is moving in a partially-observable environment. They show that the proposed interactive setup achieves better results than when the agent all the instructions are fully observable at the beginning. \n\nThe task setup is very interesting. However, the experiments are rather simplistic, and does not evaluate the full capability of the model. Moreover, the current experiments does not convince the reviewer if the claims are true in a more realistic setup. The authors compare the proposed method with one algorithm (their baseline) in which all the instructions are given at the beginning. I am wondering how the method will be compared with a state-of-the-art method that focuses on following instructions, e.g., Artzi and Zettlemoyer work. Moreover, the authors need to compare their method in an environment that has been previously used for other domains with instructions. ']","[-20, 50, -20]","[60, 70, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'clear and easy to read', 'well-motivated and original'), they express significant concerns about the lack of thorough experimental validation and comparisons to baselines. The reviewer states that 'the paper's significance is not evident' and that 'results are merely suggestive rather than convincing'. However, the score is not deeply negative because the reviewer does see potential in the work and offers constructive feedback for improvement. The politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I like', 'I found', and 'please state that' which contribute to a polite tone. The reviewer also balances criticism with praise, listing both 'Pros' and 'Cons'. The language is not overly formal or deferential, hence not scoring higher, but it consistently shows respect for the authors' work while providing honest feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting problem and its potential to make agents learn more like humans. They also note that the proposed method outperforms baselines in some aspects. However, the reviewer points out limitations, such as the study of only one setting and questions about out-of-distribution performance, which prevents a higher positive score. The politeness score is 70 (fairly polite) because the reviewer uses neutral, professional language throughout. They begin by summarizing the paper objectively, then clearly state a strength, and finally provide constructive comments without using harsh or critical language. The use of phrases like 'very interesting problem' and the objective tone contribute to the polite impression."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting task setup, they express significant concerns about the simplicity of the experiments and the lack of comparison with state-of-the-art methods. The reviewer suggests that the current experiments do not fully evaluate the model's capabilities or convince them of the claims' validity in a more realistic setup. These criticisms outweigh the initial positive remarks, resulting in a slightly negative overall sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful and professional language throughout. They begin by acknowledging the paper's contributions and frame their criticisms as suggestions for improvement rather than harsh judgments. The reviewer uses phrases like 'I am wondering' and 'The authors need to' which maintain a polite tone while still conveying their concerns.""]"
"['The paper considers a multiclass classification problem in which labels are grouped in a given number M of subsets c_j, which contain all individual labels as singletons. Training takes place through an active learning setting in which all training examples x_i are initially provided without their ground truth labels y_i. The learner issues queries of the form (x_i,c_j) where c_j is one of the given subsets of labels. The annotator only replies yes/no according to whether the true label y_i of x_i belongs to c_j or not. Hence, for each training example the learner maintains a ""version space"" containing all labels that are consistent with the answers received so far for that example. The active learning process consists of the following steps: (1) use the current learning model to score queries (x_i,c_j); (2) query the best (x_i,c_j); (3) update the model.\nIn their experiments, the authors use a mini-batched version, where queries are issued and re-ranked several times before updating the model. Assuming the learner generates predictive models which map examples to probability distributions over the class labels, several uncertainty measures can be used to score queries: expected info gain, expected remaining classes, expected decrease in remaining classes. Experiments are run using the Res-18 neural network architecture over CIFAR10, CIFAR100, and Tiny ImageNet, with training sets of 50k, 50k, and 100k examples. The subsets c_j are computed using the Wordnet hierarchy on the label names resulting in 27, 261, and 304 subsets for the three datasets. The experiments show the advantage of performing adaptive queries as opposed to several baselines: random example selection with binary search over labels, active learning over the examples with binary search over the labels, and others. \n\nThis paper develops a natural learning strategy combining two known approaches: active learning and learning with partial labels. The main idea is to exploit adaptation in both choosing examples and queries. The experimental approach is sound and the results are informative. In general, a good experimental paper with a somewhat incremental conceptual contribution.\n\nIn (2) there is t+1 on the left-hand side and t on the right-hand side, as if it were an update. Is it a typo?\n\nIn 3.1, how is the standard multiclass classifier making use of the partially labeled examples during training?\n\nHow are the number of questions required to exactly label all training examples computed? Why does this number vary across the different methods?\n\nWhat specific partial feedback strategies are used by AQ for labeling examples?\n\nEDC seems to consistently outperform ERC for small annotation budgets. Any intuition why this happens?', 'This paper proposes active learning with partial feedback, which means at each step, the learner actively chooses both which example to label and which binary question to ask, then learn the multi-class classifier with these partial labels. Three different sampling strategies are used during active learning. Experimental results demonstrate that the proposed ALPF strategy outperforms existing baselines on the predicting accuracy under a limited budget.\n\nThis paper is well-written. The main ideas and claims are clearly expressed. ALPF combines active learning with learning from partial labels. This setting is interesting and important, especially when the number of categories is large and share some hierarchical structure. The experimental results are promising. My main concern about this work is the lack of theoretical guarantees, which is usually important for active learning paper. it’s better to provide some analysis on the efficiency of ALPF to further improve the quality of the paper.\nI have the following questions for the authors:\n+Why vanilla active learning strategy does not work well? Which uncertainty measurement do you use here?\n+The performances of this work heavily rely on the taxonomy of labels, while in some cases the taxonomy of labels is not tree structure but a graph, i.e. a label may belong to multiple hyper-labels. Can ALPF still work on these cases?\n', 'The authors introduce a new Active Learning setting where instead of querying for a label for a particular example, the oracle offers a partial or weak label. This leads to a simpler and more natural way of retrieving this information that can be of use many applications such as image classification. \n\nThe paper is well-written and very easy to follow. The authors first present the overview of the learning scenario and then suggest three sampling strategies based on the existing AL insights (expected information gain, expected remaining classes, expected decrease in classes). \n\nAs the labels that the algorithm has to then use are partial, they make use of a standard algorithm to learn from partial labels -- namely, minimizing a partial log loss. It would be nice to properly reference related methods in the literature in Sec. 2.1.\n\nThe way of solving both the learning from partial labels and the sampling strategies are not particularly insightful. Also, there is a lack of theoretical guarantees to show value of a partial label as compared to the true label. However, as these are not the main points of the paper (introduction of a novel learning setting), I see these as minor concerns.\n\n']","[60, 60, 60]","[70, 80, 80]","[""The sentiment score is 60 (moderately positive) because the reviewer describes the paper as 'a good experimental paper' with 'sound' methods and 'informative' results, though they note the conceptual contribution is 'somewhat incremental'. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, asks questions for clarification rather than making accusations, and balances positive feedback with constructive criticism. The reviewer avoids harsh language and frames their points as inquiries or suggestions rather than demands."", ""The sentiment score is 60 (positive) because the reviewer expresses that the paper is 'well-written' with 'clearly expressed' ideas and 'promising' experimental results. They also note the importance and interesting nature of the work. However, it's not a perfect score due to the 'main concern' about lack of theoretical guarantees. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before mentioning concerns. They phrase their criticism constructively, suggesting improvements rather than just pointing out flaws. The use of phrases like 'it's better to' and posing questions for the authors at the end also contribute to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'well-written and very easy to follow.' They appreciate the introduction of a new Active Learning setting and its potential applications. However, they also mention some minor concerns, which prevents the score from being higher. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths and offer suggestions for improvement in a courteous manner, such as 'It would be nice to properly reference related methods.' The reviewer also frames their criticisms as 'minor concerns,' which maintains a polite tone.""]"
"['This paper provides several theoretical and practical insights on the impact of data distribution to adversarial robustness of trained networks. The paper reads well and provides analysis on two datasets MNIST and CIFAR10. I particularly like the result demonstrating that a lossless transformation on the data distribution could significantly impact the robustness of an adversarial trained models. The idea of using smoothness and saturation to bridge the gap between the MNIST and CIFAR10 datasets was also very interesting. One thing that is not clear from the paper is how one could use the findings from this paper and put it into practice. In other words, it would help if the authors could provide some insights on how to improve a model robustness w.r.t the changes in the data distribution. The authors did an attempt toward this in section 5, but that seems to only cover three factors that do not cause the difference in robustness.', ""The paper is interesting and topical: robustness to adversarial input presentation (or shifts in training data itself, even those of the nature described by the authors 'semantic-lossless' shifts). Adversarial inputs are investigated under l-inf bounded perturbations, while multiclass classification on images is the target problem considered. The theoretical parts of the paper, assigning lack of adversarial robustness to the shape of the input distribution (Section 2) is the strongest part of the paper, adding some simple and important insights. Unfortunately, the empirical part of the paper is weakened by an over-reliance of (custom perturbations of ) the popular MNIST and CIFAR10 datasets (which are themselves based on larger sets). Furthermore, the basic conclusion as to causes and remedies of lack of robustness is not evident, and it is not evident that it has been sufficiently investigated. Shape yes, differences in perturbable volume not (how does that concur with Section 2?), and inter-class distance also not. Are we to base these conclusions on 2 perturbed datasets? How are readers to synthesize the final conclusion that robustness is a 'complex interaction of tasks and data', other than what they would already expect? In short, a valiant effort, and a good direction, but one that needs more work."", 'A nice paper that clarifies the difference between the clean accuracy (accuracy of models on non-perturbed examples) and the robust accuracy (accuracy of models on adversarially perturbed examples) and it shows that changing the marginal distribution of the input data P(x) while preserving its semantic P(y|x) fixed affects the robustness of the model. Therefore, testing the robustness of the model should be performed in a careful manner. Comprehensive experiments were performed to show that changing the distribution of the MINST (smoothing) and CIFAR (saturation) data could lead to a significant difference in robust accuracy while the clean accuracy is almost steady. In addition, a set of experiments were performed in an attempt to search for the criteria required for choosing a proper dataset for testing adversarial attack to measure the robustness. \n\nAlthough I’m not expert in the field of adversarial attack but the paper is very nice to read and easy to follow (I have not checked the proof of the theorems though). \n']","[60, -20, 80]","[70, 50, 70]","[""The sentiment score is 60 (positive) because the reviewer expresses appreciation for several aspects of the paper, such as its theoretical and practical insights, readability, and interesting ideas. They use phrases like 'I particularly like' and 'very interesting'. However, it's not a perfect score as they also point out an area for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticism. They acknowledge the authors' efforts and use phrases like 'it would help if' when suggesting improvements, which is a polite way to offer feedback. The overall tone is professional and courteous."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper as 'interesting and topical' and praises the theoretical parts as the 'strongest part of the paper', they also express significant criticisms. The reviewer points out weaknesses in the empirical part, lack of clear conclusions, and the need for more work. The overall tone suggests the paper has potential but falls short in several areas.\n\nThe politeness score is moderately positive (50) as the reviewer uses respectful language throughout. They begin with positive comments and use phrases like 'interesting and topical', 'adding some simple and important insights', and 'valiant effort'. Even when expressing criticisms, the language remains professional and constructive, avoiding harsh or rude expressions. The reviewer concludes with a balanced statement acknowledging the paper's good direction while suggesting the need for more work, maintaining a polite and constructive tone."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'nice' and 'very nice to read and easy to follow'. They also mention 'comprehensive experiments' and highlight the paper's contributions. The politeness score is 70 (polite) due to the overall positive tone and the reviewer's acknowledgment of their own limitations ('I'm not expert in the field'). The language used is respectful and appreciative of the authors' work. The scores are not 100 in either case because the review, while positive and polite, doesn't use extremely enthusiastic language or go out of its way to be exceptionally courteous.""]"
"['\n- Summary\nThis paper proposes a multi-objective evolutionary algorithm for the neural architecture search. Specifically, this paper employs a Lamarckian inheritance mechanism based on network morphism operations for speeding up the architecture search. The proposed method is evaluated on CIFAR-10 and ImageNet (64*64) datasets and compared with recent neural architecture search methods. In this paper, the proposed method aims at solving the multi-objective problem: validation error rate as a first objective and the number of parameters in a network as a second objective.\n\n- Pros\n  - The proposed method does not require to be initialized with well-performing architectures.\n  - This paper proposes the approximate network morphisms to reduce the capacity of a network (e.g., removing a layer), which is reasonable property to control the size of a network for multi-objective problems.\n\n- Cons\n  - Judging from Table 1, the proposed method does not seem to provide a large contribution. For example, while the proposed method introduced the regularization about the number of parameters to the optimization, NASNet V2 and ENAS outperform the proposed method in terms of the accuracy and the number of parameters.\n  - It would be better to provide the details of the procedure of the proposed method (e.g., Algorithm 1 and each processing of Algorithm 1) in the paper, not in the Appendix.\n  - In the case of the search space II, how many GPU days does the proposed method require? \n  - About line 10 in Algorithm 1, how does the proposed method update the population P? Please elaborate on this procedure.\n', 'Summary:\nThe paper proposes LEMONADE, an evolutionary-based algorithm the searches for neural network architectures under multiple constraints. I will say it first that experiments in the paper only actually address to constraints, namely: log(#params) and (accuracy on CIFAR-10), and the method as currently presented does not show possible generalization beyond these two objectives, which is a weakness of the paper.\n\nAnyhow, for the sake of summary, let’s say the method can actually address multiple, i.e. more than 2, objectives. The method works as follows.\n\n1. Start with an architecture.\n\n2. Apply network morphisms, i.e. operators that change a network’s architecture but also select some weights that do not strongly alter the function that the network represents. Which operations to apply are sampled according to log(#params). Details are in the paper.\n\n3. From those sampled networks, the good ones are kept, and the evolutionary process is repeated.\n\nThe authors propose to use operations such as “Net2WiderNet” and “Net2DeeperNet” from Chen et al (2015), which enlarge the network but also choose a set of appropriate weights that do not alter the function represented by the network. The authors also propose operations that reduce the network’s size, whilst only slightly change the function that the network represented.\n\nExperiments in the paper show that LEMONADE finds architecture that are Pareto-optimal compared to existing model. While this seems like a big claim, in the context of this paper, this claim means that the networks found by LEMONADE are not both slower and more wrong than existing networks, hand-crafted or automatically designed.\n\nStrengths:\n1. The method solves a real and important problem: efficiently search for neural networks that satisfy multiple properties.\n\n2. Pareto optimality is a good indicator of whether a proposed algorithm works on this domain, and the experiments in the paper demonstrate that this is the case.\n\nWeaknesses:\n1. How would LEMONADE handle situations when there are more than one $f_{cheap}$, especially when different $f_{cheap}$ may have different value ranges? Eqn (8) and Eqn (9) does not seem to handle these cases.\n\n2. Same question with $f_{exp}$. In the paper the only $f_{exp}$ refers to the networks’ accuracy on CIFAR-10. What happens if there are multiple objectives, such as (accuracy on CIFAR-10, accuracy on ImageNet) or (accuracy on CIFAR-10, accuracy on Flowers, image segmentation on VOC), etc.\n\nI thus think the “Multi-Objective” is a bit overclaimed, and I strongly recommend that the authors adjust their claim to be more specific to what their method is doing.\n\n3. What value of $\\epsilon$ in Eqn (1) is used? Frankly, I think that if the authors train their newly generated children networks using some gradient descent methods (SGD, Momentum, Adam, etc.), then how can they guarantee the \\epsilon-ANM condition? Can you clarify and/or change the presentation regarding to this part?\n', ""This paper proposes LEMONADE, a random search procedure for neural network architectures (specifically neural networks, not general hyperparameter optimization) that handles multiple objectives.  Notably, this method is significantly more efficient more efficient than previous works on neural architecture search.\n\nThe emphasis in this paper is very strange.  It devotes a lot of space to things that are not important, while glossing over the details of its own core contribution.  For example, Section 3 spends nearly a full page building up to a definition of an epsilon-approximate network morphism, but this definition is never used.  I don't feel like my understanding of the paper would have suffered if all Section 3 had been replaced by its final paragraph.  Meanwhile the actual method used in the paper is hidden in Appendices A.1.1-A.2.   Some of the experiments (eg. comparisons involving ShakeShake and ScheduledDropPath, Section 5.2) could also be moved to the appendix in order to make room for a description of LEMONADE in the main paper.\n\nThat said, those complaints are just about presentation and not about the method, which seems quite good once you take the time to dig it out of the appendix.\n\nI am a bit unclear about how comparisons are made to other methods that do not optimize for small numbers of parameters? Do you compare against the lowest error network found by LEMONADE? The closest match in # of parameters?\n\nWhy is the second objective log(#params) instead of just #params when the introduction mentions explicitly that tuning the scales between different objectives is not needed in LEMONADE?\n\nIt seems like LEMONADE would scale poorly to more than 2 objectives, since it effectively requires approximating an #objectves-1 dimensional surface with the population of parents.  How could scaling be handled?\n""]","[20, -20, 20]","[60, 50, 50]","[""The sentiment score is slightly positive (20) because the review begins with a neutral summary and lists both pros and cons. The pros highlight positive aspects of the proposed method, but the cons point out significant limitations. The overall tone is more constructive than negative, hence the slightly positive score. The politeness score is moderately high (60) as the reviewer uses professional and respectful language throughout. They provide constructive criticism without using harsh or dismissive language. The use of phrases like 'It would be better to' and 'Please elaborate' indicate a polite approach to suggesting improvements. The reviewer also acknowledges the reasonable aspects of the proposed method, which contributes to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths of the paper, they also point out significant weaknesses and express concerns about overclaiming. The reviewer states that the 'Multi-Objective' aspect is 'a bit overclaimed' and 'strongly recommends' adjusting the claims. However, the review is not entirely negative as it recognizes the method solves 'a real and important problem' and demonstrates Pareto optimality.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I will say it first' and 'I think' to soften criticisms, and frame weaknesses as questions or suggestions for improvement rather than harsh criticisms. The reviewer also acknowledges strengths before discussing weaknesses, which is a polite approach. However, the language is not overly formal or deferential, maintaining a neutral scientific tone, which is why the score is not higher."", ""The sentiment score is slightly positive (20) because while the reviewer has some criticisms about the paper's presentation, they acknowledge that the proposed method 'seems quite good'. The reviewer also notes that the method is 'significantly more efficient' than previous works. However, the score is not higher due to the concerns raised about the paper's structure and some unclear aspects of the methodology. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, using phrases like 'I am a bit unclear' and 'It seems like' when raising questions or concerns. They also balance criticism with positive remarks. The reviewer doesn't use harsh language, but rather presents their feedback in a constructive manner, which contributes to the politeness of the review.""]"
"['In this paper, the authors claim that they are able to update the generator better to avoid generator mode collapse and also increase the stability of GANs training by indirectly increasing the entropy of the generator until it matches the entropy of the original data distribution using functional gradient methods.\n\nThe paper is interesting and well written. However, there is a lot of work coming out in the field of GANs currently, so I am not able to comment on the novelty of this regularization approach, and I am interested to know how this method performs when compared to other techniques to avoid mode collapse such as feature matching and mini-batch discrimination, etc.  \n\n', ""GANs (generative adversarial network) represent a recently introduced min-max generative modelling scheme with several successful applications. Unfortunately, GANs often show unstable behaviour during the training phase. The authors of the submission propose a functional-gradient type entropy-promoting approach to tackle this problem, as estimating entropy is computationally difficult.\n\nWhile the idea of the submission might be useful in some applications, the work is rather vaguely written, it is in draft phase:\n1. Abbreviations, notations are not defined: GAN, WGAN-GP, DNN, FID (the complete name only shows up in Section 4), softplus, sigmoid, D_{\\theta_{old}}, ...\n2. While the primary motivation of the work is claimed to be 'mode collapse', it does not turn out from the submission what mode collapse is.\n3. Estimating entropies is a standard practice in statistics and machine learning, with an arsenal of estimators; the motivation of the submission is questionable.\n4. Differentiation w.r.t. functions (or more generally elements in normed spaces) is a well-defined concept in mathematics, including the notions of Gateaux, Frechet and Hadamard differentiability. It is not clear why the authors neglect these classical concepts, and are talking about 'random functional perturbations', ... It is also unclear where the optimized transformation (T) lives; the authors are trying to differentiate over some function space which is undefined.\n\nWhile the idea of the work might be useful in practice, the current submission requires significant revision and work before publication.\n\n---\n\nAfter paper revisions: \n\nThank you for the updates. The submission definitely improved. I have changed my score to '6: Marginally above acceptance threshold'; the suggested regularization can be a useful heuristic for the GAN community. "", ""The authors make use of the theory of functional gradient, based on optimal transport, to develop a method that can promote the entropy of the generator distribution without directly estimating the entropy itself. Theoretical results are provided as well as necessary experiments to support their technique's outperformance in some data sets. I found that this is an interesting paper, both original ideal and numerical results."", 'Summary:\nThis paper proposes distributional concavity regularization for GANs which encourages producing generator distributions with higher entropy. The paper motivates the proposed method as follows:\n-       Using the concept of functional gradient, the paper interprets the update in the generator parameters as an update in the generator distribution\n-       Given this functional gradient perspective, the paper proposes updating the generator distribution toward a target distribution which has *higher entropy and satisfies monoticity*\n-       Then, the paper proves that this condition can be satisfied by ensuring that generator’s objective (L) is concave\n-       Since it’s difficult to ensure concavity when parametrizing generators as deep neural networks, the paper proposes adding a simple penalty term that encourages the concavity of generator objective\nExperiments confirm the validity the proposed approach. Interestingly, the paper shows that performance of multiple GAN variants can be improved with their proposed method on several image datasets\n \nStrengths:\n-   \tThe proposed method is very interesting and is based on sound theory\n-   \tConnection to optimal transport theory is also interesting\n-   \tIn practice, the method is very simple to implement and seems to produce good results\n \nWeaknesses:\n-       Readability of the paper can be generally improved. I had to go over the paper many times to get the idea.\n-       Figures should be provided with more detailed captions, which explain main result and providing context (e.g. explaining baselines).\n \nQuestions/Comments:\n-       Equation (7) has typos (uses theta_old instead of theta in some places)\n-       Section 4.1 (effect of monoticity) is a bit confusing. My understanding is that parameter update rule of equation (3) and (6) are equivalent, but you seem to use (6) there. Can you clarify what you do there and in general this experiment a bit more?\n-       Comparing with entropy maximization method of EGAN (Dai et al, 2017) is a good idea, but I’m wondering if you can compare it on low dimensional settings (e.g. as in Fig 2). It is also not clear why increasing entropy with EGAN-VI is worse than baselines in Table 1.\n\n \nOverall recommendation:\nThe paper is based on sound theory and provides very interesting perspective. The method seems to work in practice on a variety of experimental setting. Therefore, I recommend accepting it.\n']","[50, 20, 80, 80]","[75, 50, 50, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as 'interesting and well written', which is a positive comment. However, they also express some reservations about the novelty of the approach and request comparisons with other techniques, indicating a balanced view rather than overwhelmingly positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their concerns as questions or areas of interest rather than direct criticisms. The phrase 'I am interested to know' is particularly polite, showing engagement with the authors' work while suggesting improvements."", ""The sentiment score is 20 (slightly positive) because while the reviewer acknowledges improvements in the paper and suggests it's marginally above the acceptance threshold, they still point out several areas needing revision. The initial paragraph is critical, but the final comment is more positive. The politeness score is 50 (moderately polite) as the reviewer uses professional language, thanks the authors for updates, and provides constructive feedback without harsh criticism. They use phrases like 'might be useful' and 'requires significant revision' rather than outright dismissal, maintaining a respectful tone throughout."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'interesting' and 'original', and mentions that it provides both theoretical results and supporting experiments. The phrase 'outperformance in some data sets' also indicates a positive view of the work. The politeness score is 50 (slightly polite) because the language is professional and respectful, without being overly formal or effusive. The reviewer uses neutral, objective language to describe the paper's contents and merits, avoiding any harsh criticism or overly enthusiastic praise."", ""The sentiment score is 80 because the review is largely positive. The reviewer highlights several strengths of the paper, describes it as 'very interesting' and 'based on sound theory', and recommends accepting it. The few weaknesses mentioned are minor and constructive. The politeness score is 60 because the reviewer uses respectful language throughout, offers constructive criticism, and frames weaknesses as suggestions for improvement rather than harsh criticisms. The tone is professional and courteous, though not overly formal or effusive in its politeness.""]"
"['This paper investigates adversarial examples for audio data. The standard defense techniques proposed for images are studied in the context of audio. It is shown that these techniques are somewhat robust to adversarial attacks, but fail against adaptive attacks. A method exploiting the temporal dependencies of the data is then presented and shown to be robust to adversarial examples and to adaptive attacks.\n\nThe paper addresses an important issue, and the two main findings of the paper, the transformation methods used in computer vision are not useful against audio adversarial example and using temporal dependencies improves the defense capability are significant. The proposed TD method is novel.\n\nThe first part of the paper is easy to read (Section 1-3), but Section 4 is hard to follow, for the following reasons:\n* Section 4.1 presents the metrics used in the evaluation, which is nice. But in the following subsections, other metrics are used: effectiveness ratio, detection rate and relative perturbation. They should be clearly defined in 4.1, and the authors should discuss why they used these metrics.\n* Section 4.2 should be reorganized as it is hard to follow: there are three types of attack, so one subsection per attack should make the section clearer.\n* It\'s not always clear what each attack is doing and why it is used. I suggest the authors to have a separate subsection with the description of each attack and the motivation of why it is used.\n\nBecause of the above, it\'s hard to clearly assess the performance of each method for each attack, it would be better to have a Table that summarizes the results for the transformation methods. Also, I don\'t understand the statement in 4.2: ""We report that the autoencoder works fine for transforming benign instances (57.6% WER in Common Voice compared to 27.5%)"": given that it\'s not an attack, the PER should be the same with and without transform, as we don\'t want the transform to affect non-adversarial examples ? Please clarify that.\nThe experiments on the proposed TD method are clear enough to show the viability of the approach.\n\nOverall, the findings of this paper are significant and it is good step towards audio adversarial examples defense. But the experimental part is hard to follow and does not bring a clear picture. I am still willing to accept the paper if the authors improve and clarify Section 4.\n\nRevision after rebuttal:\nThe new version is definitely clearer and easier to read, hence I support the paper for acceptance and change my rating to 7. \nThere are still minor improvements that can be done in Section 4 to improve the overall clarity:\n* About the metrics, the ""Average attack success rate"" and the ""Target command recognition rate"" should be clearly defined, probably under the description of the attack methods.\n* The Adaptive attack approach could be introduced unter ""Attack methods"" in 4.1.\n* Table 4 is not easy to read, the authors should improve it.\n* The first paragraph in Section 4 (""The presentation flows ..."") is very interesting, but almost reads like a conclusion, so maybe the authors could move that to the end of Section 4 or to Section 5.', 'This paper presents a study of the problem of generating adversarial examples for speech processing systems. Two versions of this problem are considered: attacks against audio classification and against text to speech. The authors first study a the practice of input transformations as means of defense against adversarial examples. To do so, they evaluate three recent adversarial attacks on audio classification and TTS models trained on several datasets. It is found that input transformations have limited utility against adaptive attacks. Moreover, a novel type of defense is developed in which the prefix (of some fixed length) of the audio input is converted to text and compared with the prefix of the text output of the entire input, flagging the input as adversarial if sufficient mismatch is detected. It is found that this method is robust against a number of attacks.\n\nThis paper tackles a relevant problem and presents some surprising (the robustness of the prefix method) as well as some not surprising results. The evaluation has reasonable enough breadth to give the conclusions credibility. \n\nMy main complaint is that the exposition is somewhat hard to follow at places, especially in section 4. It is hard to keep track of which attack is applied to which scenario and what the conclusions were. Perhaps this could be summarized in some kind of high-level table. It would also be greatly beneficial if the attacks are briefly summarized somewhere. E.g., without following the references, it is completely unclear what is the ""Commander Song"" setting and what is it important. \nFinally, I would advise the authors to not use the term ""first k portion"". This made understanding their proposed defense much harder than it needed to be. Perhaps ""prefix of length k"" or something along these lines would be easier to follow. \n\nIn summary, if the authors commit to improving the clarity of the paper,  I would be willing to support its acceptance by virtue of the breadth of the investigation and the importance of the problem.', 'This paper proposed a study on audio adversarial examples and conclude the input transformation-based defenses do not work very well on the audio domain, especially for adaptive attacks. They also point out the importance of temporal dependency in designing defenses which is specific for the audio domain. This observation is very interesting and inspiring as temporal dependency is an important character that should be paid attention to in the field of audio adversarial examples. They also design some adaptive attacks to the defense based on temporal dependency but either fail to attack the system or can be detected by the defense.\n\nBased on the results in Table S7, it seems like being aware of the parameter k when designing attacks are very helpful for reducing the AUC score. My question is if the attacker uses the random sample K_A to generate the adversarial examples, then how the performance would be. Another limitation of this work is that the proposed defense can differentiate the adversarial examples to some extent, but the ASR is not able to make a right prediction for adversarial examples. In addition, the writing of Section 4 is not very clear and easy to follow.\n\nIn all, this paper proposed some interesting findings and point out a very important direction for audio adversarial examples. If the author can improve the writing in experiments and answer the above questions, I would support for the acceptance.\n\n\n']","[50, 20, 60]","[80, 60, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance of the paper's topic and the significance of its findings, while also providing constructive criticism. The reviewer states that they are 'willing to accept the paper if the authors improve and clarify Section 4,' indicating a generally positive view despite some concerns. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers specific suggestions for improvement, and frames criticisms constructively. Phrases like 'I suggest the authors to...' and 'Please clarify that' demonstrate a polite and collaborative tone. The reviewer also acknowledges improvements in the revised version, further indicating a respectful approach."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges the paper's relevance and credibility, they also express some concerns about clarity and presentation. The reviewer states they would support acceptance if improvements are made, indicating a generally positive but cautious stance. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They use phrases like 'I would advise' and 'It would be greatly beneficial,' which maintain a polite tone while providing feedback. The reviewer also acknowledges the paper's strengths and the importance of the topic, further contributing to the polite tone."", ""The sentiment score is 60 (positive) because the reviewer expresses interest in the paper's findings, calling them 'very interesting and inspiring'. They also support acceptance if certain improvements are made. However, it's not extremely positive as they point out some limitations and areas for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's contributions and framing criticisms as questions or suggestions rather than direct criticisms. They use phrases like 'My question is...' and 'If the author can improve...', which are polite ways of offering feedback. The overall tone is constructive and supportive, while still providing honest feedback.""]"
"[""This is an exciting paper with a simple idea for better representing audio data so that convolutional models such as generative adversarial networks can be applied. The authors demonstrate the reliability of their method on a large dataset of acoustic instruments and report human evaluation metrics. I expect their proposed method of preprocessing audio to become standard practice.\n\nWhy didn't you train a WaveNet on the high-resolution instantaneous frequency representations? In addition to conditioning on the notes, this seems like it would be the right fair comparison. \n\nI'm still not clear on unrolled phase which is central to this work. If you can, spend more time explaining this in detail, maybe with examples / diagrams? In figure 1,  in unrolled phase, why is time in reverse?\n\nSmall comments:\n\n- Figure 1 & 2: label the x-axis as time. Makes it a lot easier to understand.\n\n- I appreciate the plethora of metrics. The inception score you propose is interesting. Very cool that number of statistically-different bins tracks human eval!\n\n- sentence before sec 2.2, and other small grammatical mistakes. Reread every sentence carefully for grammar. \n\n- Figure 5 is low-res. Please fix. All the other figures are beautiful - nice work!"", 'This paper proposes a strategy to generate audio samples from noise with GANs. The treatment is analogous to image generation with GANs, with the emphasis being the changes to the architecture and representation necessary to make it possible to generate convincing audio that contains an interpretable latent code and is much faster than an autoregressive Wavenet based model (""Neural Audio Synthesis of Musical Notes with WaveNet AutoEncoders"" - Engel et al (2017)). Like the other two related works (WaveGAN - ""Adversarial Audio Synthesis"" - Donahue et al 2018) and the Wavenet model above, it uses the NSynth dataset for its experiments. \n\nMuch of the discussion is on the representation itself - in that, it is argued that using audio (WaveGAN) and log magnitude/phase spectrograms  (PhaseGAN) produce poorer results as compared with the version with the unrolled phase that they call \'IF\' GANs, with high frequency resolution and log scaling to separate scales.  \n\nThe architecture of the network is similar to the recently published paper  (Donahue et al 2018), with convolutions and transpose convolutions adapted for audio. However, there seem to be two important developments. The current paper uses progressive growing of GANs (the current state of the art for producing high resolution images), and pitch conditioning (Odena et al, where labels are used to help training dynamics). \n\nFor validation, the paper presents several metrics, with the recently proposed ""NDB"" metric figuring in the evaluations, which I think is interesting. The IF-Mel + high frequency resolution model seems to outperform the others in most of the evaluations, with good phase coherence and interpolation between latent codes. \n\nMy thoughts: \nOverall, it seems that the paper\'s contributions are centered around the representation (with ""IF-Mel"" being the best). The architecture itself is not very different from commonly used DCGAN variants - the authors say that using PGGAN is desirable, but not critical, and the use of labels from Odena et al. \n\nMany of my own experiments with GANs were plagued by instability (especially at higher resolution) and mode collapse problems without special treatment (largely documented, such as adding noise, adjusting learning rates and so forth). To this end, what do the authors see as \'high\' resolution vis a vis audio signals? \n\nI am curious if we can adapt these ideas for recurrent generators as might appear in TTS problems. \n\nI rate this paper as an accept since this is one of the few existing works that demonstrate successful audio generation from noise using GANs, and  owing to its novelty in exploring representation for audio. \n', ""This paper proposes an approach that uses GAN framework to generate audio through modeling log magnitudes and instantaneous frequencies with sufficient frequency resolution in the spectral domain. Experiments on NSynth dataset show that it gives better results then WaveNet. The most successful deep generative models are WaveNET,  Parallel WaveNet and Tacotran that are applied to speech synthesis, the method should be tested for speech synthesis and compared with WaveNet, Parallel WaveNet as well as Tacotran.\n\nFor WaveNet, the inputs are text features, but for Tacotran, the inputs are mel-spectrogram. Here the inputs are log magnitudes and instantaneous frequencies. So the idea is not that much new.\n\nGAN has been used in speech synthesis, see \nStatistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks\nIEEE/ACM Transactions on Audio, Speech, and Language Processing ( Volume: 26 , Issue: 1 , Jan. 2018 )\n\nSo for this work, GAN's application to sound generation is not new.""]","[80, 80, -20]","[70, 70, 0]","[""The sentiment score is 80 (positive) because the reviewer starts by calling the paper 'exciting' and praising its 'simple idea'. They also express high expectations for the method's future use. The politeness score is 70 (polite) due to the overall constructive tone, use of phrases like 'I appreciate' and 'nice work', and the way suggestions are phrased as questions or gentle recommendations. The reviewer balances praise with constructive criticism, maintaining a respectful and encouraging tone throughout. However, it's not maximally polite as there are direct instructions like 'Please fix' and mentions of 'mistakes', which prevent a perfect score."", ""The sentiment score is 80 (positive) because the reviewer expresses overall approval of the paper, stating it as an 'accept' and praising its novelty and contributions. The reviewer acknowledges the paper's importance in demonstrating successful audio generation using GANs and exploring new representations for audio. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and expresses curiosity about potential future applications. The reviewer also acknowledges the paper's strengths while providing thoughtful questions and suggestions, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'better results than WaveNet'), they also point out several limitations and suggest that the idea is not particularly novel. The reviewer states that 'the idea is not that much new' and 'GAN's application to sound generation is not new,' which indicates a somewhat critical stance. The politeness score is neutral (0) as the reviewer maintains a professional tone without being overtly polite or rude. They present their critiques in a straightforward manner without using overly harsh language or personal attacks, but also without any particularly courteous phrasing.""]"
"['This paper tries to analyze the impact of the staleness on machine learning models in different settings, including model complexity, optimization methods or the number of workers. In this work, they study the convergence behaviors of a wide array of ML models and algorithms under delayed updates, and propose a new convergence analysis of asynchronous SGD method for non-convex optimization.\n\nThe following are my concerns:\n1. ""For CNNs and DNNs, the staleness slows down deeper models much more than shallower counterparts."" I think it is straightforward. I want to see the theoretical analysis of the relation between model complexity and staleness.  \n2. ""Different algorithms respond to staleness very differently"".  This finding is quite interesting. Is there any theoretical analysis of this phenomenon?  \n3. The ""gradient coherence""  in the paper is not new. I am certain that ""gradient coherence"" is very similar to the ""sufficient direction"" in [1]. \n4. What is the architecture of the network? in the paper, each worker p can communicate with other workers p\'. Does it mean that it is a grid network? or it is just a start network. \n5. in the top of page 3, why the average delay under the model is 1/2s +1, isn\'t it (s-1)/2? \n6.  on page 5, ""This is perhaps not surprising, given the fact that deeper models pose more optimization challenges even under the sequential settings."" why it is obvious opposite to your experimental results in figure 1(a)? Could you explain why shallower CNN requires more iterations to get the same accuracy? it is a little counter-intuitive.\n7. I don\'t understand what does ""note that s = 0 execution treats each worker’s update as separate updates instead of one large batch in other synchronous systems"" mean in the footnote of page 5.\n\n\nAbove all, this paper empirically analyzes the effect of the staleness on the model and optimization methods. It would be better if there is some theoretical analysis to support these findings.\n\n[1] Training Neural Networks Using Features Replay  https://arxiv.org/pdf/1807.04511.pdf\n\n\n===after rebuttal===\nAll my concerns are addressed. I will upgrade the score.\n', ""This paper presents and empirical and theoretical study of the convergence of asynchronous stochastic gradient descent training if there are delays due to the asynchronous part of it. The paper can be neatly split in two parts: a simulation study and a theoretical analysis.\n\nThe simulation study compares, under fixed hyperparameters, the behavior of distributed training under different simulated levels of delay on different problems and different model architectures. Overall the results are very interesting, but the simulation could have been more thorough. Specifically, the same hyperparameter values were used across batch sizes and across different values of the distributed delay. Some algorithms failed to converge under some settings and others experienced dramatic slowdowns, but without careful study of hyperparameters it's hard to tell whether these behaviors are normal or outliers. Also it would have been interesting to see a recurrent architecture there, as I've heard much anecdotal evidence about the robustness of RNNs and LSTMs to asynchronous training. I strongly advise the authors to redo the experiments with some hyperparameter tuning for different levels of staleness to make these results more believable.\n\nThe theoretical analysis identifies a quantity called gradient coherence and proves that a learning rate based on the coherence can lead to an optimal convergence rate even under asynchronous training. The proof is correct (I checked the major steps but not all details), and it's sufficiently different from the analysis of hogwild algorithms to be of independent interest. The paper also shows the empirical behavior of the gradient coherence statistic during model training; interestingly this seems to also explain the heuristic commonly believed that to make asynchronous training work one needs to slowly anneal the number of workers (coherence is much worse in the earlier than later phases of training). This quantity is interesting also because it's somewhat independent of the variance of the stochastic gradient across minibatches (it's the time variance, in a way), and further analysis might also show interesting results."", 'The papers addresses the important issue with asynchronous SGD: stale gradients.\n\nConvergence is proven under an assumption on the path followed by the optimization walk. Namely, gradient are assumed to be all pointing to the close directions along the walk. My major concern is that this is a strong (if not completely wrong) hypothesis in the practical case of deep learning, with high dimensional models and totally non-convex loss functions (see e.g. \nChoromanska et al. 2014).\n\nThe paper illustrates empirically the convergence claims, but only under fixed hyper-parameters, which completely illustrates the recent concerns about the reproducibility crisis in ML.']","[-20, 50, -50]","[50, 80, 0]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's efforts and finds some aspects interesting, they express several concerns and suggest that theoretical analysis is lacking. The overall tone indicates that the paper needs significant improvements. The politeness score is moderately positive (50) as the reviewer uses respectful language, phrases concerns as questions or suggestions, and acknowledges interesting findings. The reviewer also shows flexibility by upgrading their score after the rebuttal, which demonstrates a fair and courteous approach. The language is professional and constructive throughout, without any rudeness or harsh criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the interesting aspects of the paper, particularly the theoretical analysis, while also providing constructive criticism for improvement. The reviewer finds the results 'very interesting' and the theoretical analysis 'of independent interest', but suggests more thorough simulations and hyperparameter tuning. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering suggestions rather than demands. Phrases like 'I strongly advise' and 'it would have been interesting' maintain a polite tone while conveying recommendations. The reviewer also acknowledges the correctness of the proof and the potential for further interesting results, which adds to the overall politeness and constructive nature of the review."", ""The sentiment score is -50 because the review expresses significant concerns about the paper's assumptions and methodology, particularly regarding the hypothesis being 'strong (if not completely wrong)' and issues with reproducibility. However, it's not entirely negative as it acknowledges the paper addresses an important issue. The politeness score is 0 (neutral) because the language is direct and professional without being overtly polite or rude. The reviewer states concerns clearly but doesn't use inflammatory language, maintaining a neutral tone throughout the review.""]"
"['This paper proposes a List Conditional Variational Autoencoder approach for the slate recommendation problem. Particularly, it learns the joint document distribution on the slate conditioned on user responses, and directly generates full slates. The experiments show that the proposed method surpasses greedy ranking approaches.\n\nPros:\n+ nice motivation, and the connection with industrial recommendation systems where candidate nomination and ranker is being used is engaging\n+ it provides a conditional generative modeling framework for slate recommendation\n+ the simulation experiments very clearly show that the expected number of clicks as obtained by the proposed List-CVAE is much higher compared to the chosen baselines. A similar story is shown for the YOOCHOOSE challenge dataset.\n\nCons: \n- Do the experiments explicitly compare with the nomination & ranking industry standard?\n- Comparison with other slate recommendation approaches besides the greedy baselines?\n- Comparison with non-slate recommendation models of Figure 1?\n\nOverall, this is a very nicely written paper, and the experiments both in the simulated and real dataset shows the promise of the proposed approach.', 'The latest revision is a substantially improved version of the paper. The comment about generalization still feels unsatisfying (""our model requires choosing c* in the support of P(c) seen during training"") but could spur follow-up work attempting a precise characterization.\nI remain wary of using a neural net reward function in the simulated environment, and prefer a direct simulation of Eqn5. With a non-transparent metric, it is much harder to diagnose whether the observed improvement in List-CVAE indeed corresponds to improved user engagement; or whether the slate recommender has gamed the neural reward function. Transparent metrics (that encourage non-greedy scoring) also have user studies showing they correlate with user engagement in some scenarios.\nIn summary, I think the paper is borderline leaning towards accept -- there is a novel idea here for framing slate recommendation problems in an auto-encoder framework that can spur some follow-up works.\n---\nThe paper proposes using a variational auto-encoder to learn how to map a user context, and a desired user response to a slate of item recommendations. During training, data collected from an existing recommender policy (user contexts, displayed slate, recorded user response) can be used to train the encoder and decoder of the auto-encoder to map from contexts to a latent variable and decode the latent variable to a slate. Once trained, we can invoke the encoder with a new user context and the desired user response, and decode the resulting latent variable to construct an optimal slate.\n\nA basic question for such an approach is: [Fig2] Why do we expect generalization from the user responses c(r) seen in training to c(r*) that we construct for testing? At an extreme, suppose our slate recommendation policy always picks the same k items and never gets a click. We can optimize Eqn3 very well on any dataset collected from our policy; but I don\'t expect deploying the VAE to production with c(r*) as the desired user response will give us anything meaningful.\nThe generalization test on RecSys2015-medium (Fig6d) confirms this intuition. Under what conditions can we hope for reliable generalization?\n\nThe comment about ranking evaluation metrics being unsuitable (because they favor greedy approaches) needs to be justified. There are several metrics that favor diversity (e.g. BPR, ERR) where a pointwise greedy scoring function will perform very sub-optimally.  Such metrics are more transparent than a neural network trained to predict Eqn6. See comment above for why I don\'t expect the neural net trained to predict Eqn6 on training data will not necessarily generalize to the testing regime we care about (at the core, finding a slate recommendation policy is asking how best to change the distribution P(s), which introduces a distribution shift between training and test regimes for this neural net).\n\nThere are 2 central claims in the paper: that this approach can scale to many more candidate items (and hence, we don\'t need candidate generation followed by a ranking step); and that this approach can reason about interaction-effects within a slate to go beyond greedy scoring. For the second claim, there are many other approaches that go beyond greedy (one of the most recent is Ai et al, SIGIR2018 https://arxiv.org/pdf/1804.05936.pdf; the references there should point to a long history of beyond-greedy scoring) These approaches should also be benchmarked in the synthetic and semi-synthetic experiments. At a glance, many neural rankers (DSSM-based approaches) use a nearly identical decoder to CVAE (one of the most recent is Zamani et al, CIKM2018 https://dl.acm.org/citation.cfm?id=3271800; the references there should point to many other neural rankers) These approaches should also be benchmarked in the expts.\nThis way, we have a more representative picture of the gain of CVAE from a more flexible (slate-level) encoder-decoder; and the gain from using item embeddings to achieve scalability.\n\n', 'This paper pr poses a conditional generative model for slate-based recommendations. The idea of slate recommendation is to model an ordered-list of items instead of modelling each item independently as is usually done (e.g., for computational reasons). This provides a more natural framework for recommending lists of items (vs. recommending the items with the top scores).\n\nTo generate slates, the authors propose to learn a mapping from a utility function (value) to an actual slate of products (i.e., the model conditions on the utility).  Once fitted, recommending good slates is then achieved by conditioning on the optimal utility (which is problem dependant) and generating a slate according to that utility. This procedure which is learned in a conditional VAE framework effectively bypasses the intractable combinatorial search problem (i.e., choosing the best ordered list of k-items from the set of all items) by instead estimating a model which generates slates of a particular utility. The results demonstrate empirically that the approach outperforms several baselines.      \n\nThis idea seems promising and provides an interesting methodological development for recommender systems. Presumably this approach, given the right data, could also learn interesting concepts such as substitution, complementarity, and cannibalization.\n\nThe paper is fairly clear although the model is never formally expressed: I would suggest defining it using math and not only a figure.  The study is also interesting although the lack of publicly available datasets limits the extent of it and the strength of the results. Overall, it would be good to compare to a few published baselines even if these were not tailored to this specific problem.\n\n\nA few detailed comments (in approximate decreasing order of importance):\n\n- Baselines. The current baselines seem to focus on what may be used in industry with a specific focus on efficient methods at test time.\n\n  For this venue, I would suggest that it is necessary to compare to other published baselines. Either baselines that use a similar setup or, at least, strong collaborative filtering baselines that frame the problem as a regression one.\n\n  If prediction time is important then you could also compare your method to others in that respect.\n\n- training/test mismatch. There seems to be a mismatch between the value of the conditioning information at train and at test. How do you know that your fitted model will generalize to this ""new"" setting?\n\n- In Figures: If I understand correctly the figures (4--6) report test performance as a function of training steps. Is that correct?\n\n  Could you explain why the random baseline seems to do so well? That is, for a large number of items, I would expect that it should get close to zero expected number of clicks.\n\n- Figure 6d. It seems like that subfigure is not discussed. Why does CVAE perform worse on the hardest training set?\n\n- The way you create slates from the yoochoose challenge seems a bit arbitrary. Perhaps I don\'t know this data well enough but it seems like using the temporal aspects of the observations to define a slate makes the resulting data closer to a subset selection problem than an ordered list.\n\n- Section 3. It\'s currently titled ""Theory"" but doesn\'t seem to contain any theory. Perhaps consider renaming to ""Method"" or ""Model""']","[80, 20, 50]","[90, 50, 70]","[""The sentiment score is 80 (positive) because the review starts with a clear summary of the paper's contribution and lists several pros, including 'nice motivation', 'engaging' connection to industry, and 'very clearly' demonstrated results. The reviewer concludes that it's a 'very nicely written paper' showing 'promise'. While there are some cons listed, they are framed as questions for improvement rather than criticisms. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses positive language like 'nice', 'engaging', and 'clearly', and frames criticisms as questions or suggestions for improvement rather than direct criticisms. The overall tone is encouraging and supportive, indicative of a polite and professional review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges substantial improvements in the paper and sees potential for follow-up work. They describe the paper as 'borderline leaning towards accept' and mention a 'novel idea' that can spur further research. However, they also express some reservations about certain aspects of the work, which prevents a higher positive score. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They offer specific suggestions for improvement and express their concerns without using harsh language. The reviewer balances critique with positive feedback, which contributes to the polite tone. They use phrases like 'I remain wary' and 'I think' to soften their criticisms, making them sound more like personal opinions rather than absolute statements."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's promising idea and interesting methodological development, while also providing constructive criticism and suggestions for improvement. The overall tone is balanced, recognizing both strengths and areas for enhancement. The politeness score is 70 (fairly polite) due to the reviewer's use of respectful language throughout. They offer suggestions using phrases like 'I would suggest' and 'It would be good to,' which maintain a courteous tone. The reviewer also acknowledges the paper's merits before diving into critiques, demonstrating professional courtesy. The language remains objective and constructive, avoiding harsh or dismissive statements.""]"
"['This paper proposed a new training algorithm, G-SGD, by exploring the positively scale-invariant space for relu neural networks. The basic idea is to identify the basis paths in the path graph, and convert the weight update in SGD to the weight rescaling in G-SGD. My major concerns are as follows:\n\n1. Empirical significance of G-SGD: While the idea of exploring the structures of relu neural networks for training based on group theory on graphs is interesting, I do not see significant improvement over SGD. The accuracy differences in Table 1 are marginal, training/testing behaviors in Fig. 3 are very similar, and more importantly there is no evidence to support the claims ""with little extra cost"" in the abstract/Sec. 4.3 in terms of computation. Therefore, I do not see the truly contribution of the proposed method.\n\nPS: After reading the revision, I am happy to see the results on computational time that support the authors\' claim. However, I still have doubts on the significance of the improvement on CIFAR10 and CIFAR100, because the performance is heavily dependent on network architectures. In my experience, using resnet101 it can easily achieve >96% accuracy. So can you achieve better than this using G-SGD? The training and testing behaviors on both datasets somehow show improvement over SGD, which I take it more importantly than just those numbers. Therefore, I am glad to raise my score.\n\n2. In Alg. 3 I do not quite understand how to apply step 3 to step 4. The connection needs more explanation.', 'Summary:\nIn prior deep learning papers it has been observed that ReLU networks are positively scale invariant due to the non-negative homogeneity property of the max(0, x) function. The present paper proposes to change the optimization procedure so that it is done in a space where this invariance is preserved (in contrast to the weight space, where it is not). To do so, the authors define the group G of positive scaling operators, and note that the ""value of path"" (product of weights along the path) is G-invariant and together with ""activation status of paths"" allows for the definition of an equivalence class. They then build a G-space which has fewer dimensions than the weight space, and proposed g-SGD to optimize the network in this space. In g-SGD gradients are computed normally, then projected to G-space via a sparse matrix in order to update the values of paths. The weights are then updated based on a ""weight allocation method"" that involves the inverse projection.\n\nThe authors conduct experiments on CIFAR-10 and -100 with a ResNet-34 and a similarly deep variant of VGG, showing significant benefits from G-SGD training in all cases. They also evaluate the performance of a simple MLP on Fashion-MNIST as a function of the invariant ratio H/m.\n\nComments:\nThe paper is organized well (with technical details of the proofs delegated to the appendix), and discusses the differences in comparison prior work. While evaluations on large-scale datasets would be helpful here, the present experiments suggest that optimization in G-space indeed consistently improves results, so the proposed method seems promising.\n\nFor completeness, it would be great to include Path-SGD results for the CIFAR experiments in Table 1, together with runtime information to highlight the benefits of the g-SGD algorithm and provide experimental proof that the computational overhead is indeed low.\n\nIf the authors are hoping for a wider adoption of the method, it would be helpful for the community to have the g-SGD code released within one of the standard deep learning frameworks.\n\nQuestions:\n- Does it matter which weights are chosen as ""free skeleton weights""? If these weights never get updated in the optimization procedure, could you please comment on the intuitive interpretation of the necessity of their presence?\n- The text states that the computational overhead of the gradient of path norm is ""very high"". The Path-SGD paper proposes a method costing (B + 1)T, where the overhead an be small for large batches. It would be good to clarify this a bit in the present text.\n- Is the advantage of g-SGD over SGD expected to be proportional to the invariant ratio for CNNs as well?\n', 'The paper proposes SGD for ReLU networks. The authors focuses on positive scale invariance of ReLU which can not be incorporated by naive SGD. To overcome this issue, a positively scale-invariant space is first introduced. The authors show the SGD procedure in that space, which is based on three component techniques: skeleton method, inverse-chain rule, and weight allocation.\n\nThe basic idea, directly optimizing weight in scale invariant space, is reasonable and would be novel, and experiments verify the claim. Readability might be low slightly.\n\nAnalysis about invariance group (e.g., theorem 3.6) is interesting and informative.\n\nCombining with other optimization algorithms (other than simple SGD) method would be valuable.\n']","[20, 70, 60]","[60, 80, 50]","[""The sentiment score is slightly positive (20) because while the reviewer expresses some concerns, they also acknowledge improvements in the revision and show willingness to raise their score. The reviewer recognizes the interesting aspects of the work but remains skeptical about its significance. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges positive changes in the revision, and frames criticisms as personal opinions or questions rather than harsh statements. The reviewer also uses phrases like 'I am happy to see' and 'I am glad to raise my score', which contribute to a polite tone."", ""The sentiment score is 70 (positive) because the reviewer expresses that the paper is well-organized, discusses differences from prior work, and shows promising results. They state that the 'proposed method seems promising' and suggest that the experiments 'consistently improves results'. The score is not higher as the reviewer suggests additional experiments and clarifications. The politeness score is 80 (polite) due to the constructive and respectful tone throughout. The reviewer uses phrases like 'it would be great to include', 'it would be helpful', and asks questions politely. They provide positive feedback and suggestions for improvement without harsh criticism. The language is professional and courteous throughout, maintaining a positive and supportive tone while still offering constructive feedback."", ""The sentiment score is 60 (positive) because the reviewer expresses that the paper's basic idea is 'reasonable and would be novel,' and that experiments verify the claim. They also find the analysis 'interesting and informative.' However, it's not extremely positive as they mention readability might be slightly low and suggest combining with other optimization algorithms. The politeness score is 50 (somewhat polite) because the language is professional and constructive without being overly formal or effusive. The reviewer offers balanced feedback, acknowledging strengths while also suggesting improvements, which is a polite approach in academic review. There are no rude or harsh comments, but also no explicitly polite phrases, resulting in a moderately positive politeness score.""]"
"['The paper presents a new convolution-like operation for parameterized manifolds, and demonstrates its effectiveness on learning problems involving spherical signals. The basic idea is to define the MeshConvolution as a linear combination (with learnable coefficients) of differential operators (identity, gradient, and Laplacian). These operators can be efficiently approximated using the 1-hop neighbourhood of a vertex in the mesh.\n\nIn general I think this is a strong paper, because it presents a simple and intuitive idea, and shows that it works well on a range of different problems. The paper is well written and mostly easy to follow. The appendix contains a wealth of detail on network architectures and training procedures.\n\nWhat is not clear to me is how exactly the differential operators are computed, and how the MeshConvolution layer is implemented. The authors write that ""differential operators can be efficiently computed using Finite Element basis, or derived by Discrete Exterior Calculus"", but no references or further detail is provided. The explanation of the derivative computation is:\n""The first derivative can be obtained by first computing the per-face gradients, and then using area-weighted average to obtain per-vertex gradients. The dot product between the per-vertex gradient value and the corresponding x and y vector fields are then computed to acquire grad_x F and grad_y F.""\nWhat are per-face gradients and how are they computed? Is the signal sampled on vertices or on faces? What area is used for weighting? What is the exact formula? What vector fields are you referring to? (I presume these are the coordinate vector fields). In eq. 5, what are F_i and F_j? What is the intuition behind the cotangent formula (eq. 5), and where can I read more? etc.\n\nPlease provide a lot more detail here, delegating parts to an appendix if necessary. Providing code would be very helpful as well.\n\nA second (minor) concern I have is to do with the coordinate-dependence of the method. Because the MeshConvolution is defined in terms of (lat / lon) coordinates in a non-invariant manner, and the sphere does not admit a global chart, the method will have a singularity at the poles. This is confirmed by the fact that in the MNIST experiment, digits are rotated to the equator ""to prevent coordinate singularity at the poles"". I think that for many applications, this is not a serious problem, but it would still be nice to be transparent and mention this as a limitation of the method when comparing to related work.\n\nIn ""Steerable CNNs"", Cohen & Welling also used a linear combination of basis kernels, so this could be mentioned in the related work under ""Reparameterized Convolutional Kernel"".\n\nTo get a feel for the differential operators, it may be helpful to show the impulse response (at different positions on the sphere if it matters).\n\nIn experiment 4.1 as well as in the introduction, it is claimed that invariant/equivariant models cannot distinguish rotated versions of the same input, such as a 6 and a 9. Although indeed an invariant model cannot, equivariant layers do preserve the ability to discriminate transformed versions of the same input, by e.g. representing a 9 as an upside-down 6. So by replacing the final invariant pooling layer and instead using a fully connected one, it should be possible to deal with this issue in such a network. This should be mentioned in the text, and could be evaluated experimentally.\n\nIn my review I have listed several areas for improvement, but as mentioned, overall I think this is a solid paper.', 'This article introduces a simple yet efficient method that enables deep learning on spherical data (or 3D mesh projected onto a spherical surface), with much less parameters than the popular approaches, and also a good alternative to the regular correlation based models.\n\nInstead of running patches of spherical filters, the authors takes a weighted linear combination of differential operators applied on the data. The method is shown to be effective on Spherical MNIST, ModelNet, Stanford 2D-3D-S and a climate prediction dataset, reaching competitive/state-of-the-art numbers with much less parameters..\n\nLess parameters is nice, but the argument could be strengthened if the authors could also show impressive results in terms of runtime. Typically number of parameters is not a huge issue for today’s deep networks, but for real-time robotics to be equipped with 3D perception, runtime is a much bigger factor.\n\nI also think that the Stanford 2D-3D-S experiments have some issues:\n\nUNet and FCN-8s are good baselines, but other prior work based on spherical convolution are omitted here. E.g. S2CNN and SphereNet. S2CNN has released their code so it should be benchmarked.\n\nAdditionally, comparison to PointNet++ could be a little unfair. \n\ni) What is the number of points used in PointNet++? The author reported 1000 points for ModelNet which is ok for that dataset but definitely too small for indoor scenes. The original paper used 8192 points for ScanNet indoor scenes.\n\nii) Point-based can have data-augmentation by taking subregions of the panoramic scene, where as sphere-based method can only take a single panoramic image. The state-of-the-art method (PointSIFT) achieves ~70 mIOU on this dataset. PointNet(++) can also achieve 40-50 mIOU. Maybe the difference is at using regular image or panoramic images, but the panoramic image is just a combination of regular images so I wouldn’t expect such a large difference.\n\nIn conclusion, this paper proposes a novel deep learning algorithm to handle spherical data based on differential operators. It uses much less parameters and gets impressive results. However, the large scale experiments has some weaknesses. Therefore I recommend weak accept.\n\n----\nSmall issues / questions:\n\n- Notation lacks clarity. What are x, y in Eqn. 1? The formulation of convolution is not very clear to me, but maybe due to my lack of familiarity in this literature.\n\n- In Figure 1, the terminology of “MeshConv” is first introduced, which should come earlier in the text to improve clarity.\n\n- In the article, the author distinguished their method with S2CNN that their method is not rotation invariant. I don’t understand this part. In the architecture diagram, if average pool is applied across all spherical locations, then why is it not rotation invariant?\n\n===\nAfter rebuttal: \nI thank the authors for addressing the comments in my review. It clarifies the questions I had about on the 2D3DS dataset (panorama vs. 3D points). Overall I feel this is a good model and have solid experiments. Therefore, I raise the score to 7.', 'Summary:\nThe paper proposes a novel convolutional kernel for CNN on the unstructured grids (mesh). Contrary to previous works, the proposed method formulates the convolution by a linear combination of differential operators, which is parameterized by kernel weights. Such kernel is then applied on the spherical mesh representation of features, which is appropriate to handle spherical data and makes the computation of differential operators efficient. The proposed method is evaluated on multiple recognition tasks on spherical data (e.g. 3d object classification and omnidirectional semantic segmentation) and demonstrates its advantages over existing methods.\n\nComments/suggestions:\nI think the paper is generally well-written and clearly delivers its key idea/advantages. However, I hope the authors can elaborate the followings:\n\n1) Analysis of computational cost\nIt would be helpful to elaborate more analysis on computational cost. The proposed formulation seems to involve the second-order derivatives in the backpropagation process (due to the first-order derivatives in Eq.(4)), which can be a computational bottleneck. It will be very useful to provide analysis on computational cost together with parameter efficiency study (Figure 3 and 4).\n\n2) Intuitive justification\nIt would be great if the authors provide more intuitive descriptions on Eq.(4) (and possibly elaborate captions of Figure 1); what is the intuition of using differential operators? Why is it useful to deal with unstructured grids? How does it lead to improvement over the existing techniques?\n\nConclusion: \nOverall, I think this paper has solid contributions; the proposed MeshConv operator is simple but effective to handle spherical data; the experiment results demonstrate its advantages over existing methods on broad applications, which are convincing. I think conveying more intuitions on the proposed formulation and providing additional performance analysis will help readers to understand paper better. \n']","[70, 60, 70]","[80, 70, 80]","[""The sentiment score is 70 (positive) because the reviewer states 'In general I think this is a strong paper' and mentions several positive aspects like 'simple and intuitive idea', 'works well on a range of different problems', and 'well written'. The overall tone is constructive and appreciative, despite some concerns raised. The politeness score is 80 (polite) due to the reviewer's respectful language throughout. They use phrases like 'Please provide', 'it would be nice', and 'In my review I have listed several areas for improvement, but as mentioned, overall I think this is a solid paper.' The reviewer offers constructive criticism and suggestions in a courteous manner, maintaining a professional and supportive tone throughout the review."", ""The sentiment score is 60 (moderately positive) because the reviewer praises the paper's novel method and impressive results, recommending a 'weak accept'. However, they also point out some weaknesses in the experiments. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions or questions. They also thank the authors for addressing their comments in the rebuttal. The tone is professional and courteous while still providing honest feedback."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, stating it is 'well-written' and has 'solid contributions'. The reviewer also mentions that the experimental results are 'convincing'. However, it's not a perfect score as the reviewer does suggest some improvements. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, such as 'I hope the authors can elaborate' and 'It would be helpful'. The reviewer also balances critique with praise, acknowledging the paper's strengths while suggesting improvements. The language is constructive and supportive, avoiding harsh criticism.""]"
"[""This paper introduces a verifier that obtains improvement on both the precision of the incomplete verifiers and the scalability of the complete verifiers. The proposed approaches combines over-parameterization, mixed integer linear programming, and linear programming relaxation. \n\nThis paper is well written and well organized. I like the simple example exposed in section 2, which is a friendly start. However, I begun to lose track after that. As far as I can understand, the next section listed several techniques to be deployed. But I failed to see enough justification or reasoning why these techniques are important. My background is more theoretical, but I'm looking for theorems here, considering the complicatedness of neural network. All I am looking for is probably some high level explanation.\n\nEmpirically, the proposed approach is more robust while time consuming that the AI2 algorithm. However, the contribution and the importance of this paper still seems incremental to me.  I probably have grumbled too much about the lack of reasonings. As this paper is purely empirical, which is totally fine and could be valuable and influential as well.  In that case, I found the current experiment unsatisfying and would love to see more extensive experimental results. \n"", 'In the paper, the authors provide a new approach for verifying the robustness of deep neural networks that combines complete yet expensive methods based on mixed integer-linear programming (MILP) and incomplete yet cheap methods based on abstract interpretation or linear-programming relaxation. Roughly speaking, the approach is to run an abstract interpreter but to refine its results at early layers of a neural network using mixed integer-linear programming and some of later layers using linear programming. The unrefined results of the abstract interpreter help these refinement steps. They help prioritize or prune the refinement of the abstract-interpretation results at neurons at a layer. Using neural networks with 3, 5, 6, 9 layers and the MNIST dataset, the authors compared their approach with AI^2, which uses only abstract interpretation. This experimental comparison shows that the approach can prove the robustness of more examples for all of these networks.\n\nI found the authors\' way of combining complete techniques and incomplete techniques novel and interesting. They apply complete techniques in a prioritized manner, so that those techniques do not incur big performance penalties. However, I feel that more experimental justifications are needed. The approach in the paper applies MILP to the first few layers of a given network, without any further simplification or abstraction of the network. One possible implication of this is that this MILP-based refinement is applicable only for the first few layers of the network. Of course, prioritization and timeout of the authors help, but I am not sure that this is enough. Also, I think that more datasets and networks should be tried. The experiments in the paper with different networks for MNIST show the promise, but I feel that they are not enough.\n\n* p3: Why is l6 = 0? I think that it is easy to figure out that max(0,x4) is at least 0.\n\n* p4: [li,yi] for ===> [li,ui] \n\n* p4: gamma_n(T^#_(x|->Ax+b)) ===> gamma_n(T^#_(x|->Ax+b)(a))\n\n* p4: subseteq T^#...  ===> subseteq gamma_n(T^#...)\n\n* p5: phi^(k)(x^(0)_1,...,x^(k-1)_p) ===> phi^(k)(x^(0)_1,...,x^k_p) \n\n* p6: I couldn\'t understand your sentence ""Note that the encoding ..."". Explaining a bit more about how bounds computed in previous layers are used will be helpful.\n\n* p6: I find your explanation on the way to compute the second ranking with weights confusing. Do you mean that your algorithm looks into the future layers of each neuron xi and adds the weights of edges in all the reachable paths from xi?\n\n* p7: Why did you reduce epsilon from 0.07 to 0.02, 0.15 and 0.017?\n', 'This paper proposed a mixed strategy to obtain better precision on robustness verifications of feed-forward neural networks with piecewise linear activation functions.\n\nThe topic of robustness verification is important. The paper is well-written and the overview example is nice and helpful. \n\nThe central idea of this paper is simple and the results can be expected: the authors combine several verification methods (the complete verifier MILP, the incomplete verifier LP and AI2) and thus achieve better precision compared with imcomplete verifiers while being more scalable than the complete verifiers. However, the verified networks are fairly small (1800 neurons) and it is not clear how good the performance is compared to other state-of-the-art complete/incomplete verifiers. \n\nAbout experiments questions:\n1. The experiments compare verified robustness with AI2 and show that RefineAI can verify more than AI2 at the expense of much more computation time (Figure 3). However, the problem here is how is RefineAI or AI2 compare with other complete and incomplete verifiers as described in  the second paragraph of introduction? The AI2 does not seem to have public available codes that readers can try out but for some complete and incomplete verifiers papers mentioned in the introductions,  I do find some public codes available:\n* complete verifiers\n1. Tjeng & Tedrake (2017): github.com/vtjeng/MIPVerify.jl\n2. SMT Katz etal (2017): https://github.com/guykatzz/ReluplexCav2017\n\n* incomplete verifiers\n3. Weng etal (2018) : https://github.com/huanzhang12/CertifiedReLURobustness\n4. Wong & Kolter (2018): http://github.com/locuslab/convex_adversarial\n\nHow does Refine AI proposed in this paper compare with the above four papers in terms of the verified robustness percentage on test set, the robustness bound (the epsilon in the paragraph Abstract Interpretation p.4) and the run time? The verified robustness percentage of Tjeng & Tedrake is reported but the robustness bound is not reported.  Also, can Refine AI scale to other datasets?\n\nAbout other questions:\n1. Can RefineAI handle only piece-wise linear activation functions? How about other activation functions, such as sigmoid? If so, what are the modifications to be made to handle other non-piece-wise linear activation functions? \n\n2. In Sec 4, the Robustness properties paragraph. ""The adversarial attack considered here is untargeted and therefore stronger than ..."". The approaches in Weng etal (2018) and Tjeng & Tedrake (2017) seem to be able to handle the untargeted robustness as well? \n\n3. In Sec 4, the Effect of neural selection heuristic paragraph. ""Although the number of images verified change by only 3 %... produces tighter output bounds..."". How tight the output bounds improved by the neuron selection heuristics? \n']","[-20, 50, 20]","[60, 80, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well written and well organized', 'friendly start'), they express several criticisms and concerns. They mention losing track of the content, failing to see justifications, finding the contribution incremental, and considering the experiments unsatisfying. These negative points outweigh the initial positive comments.\n\nThe politeness score is moderately positive (60) as the reviewer uses polite language throughout. They start with positive comments and use phrases like 'I like', 'As far as I can understand', and 'I'm looking for' which maintain a respectful tone. Even when expressing criticisms, they use softer language like 'I probably have grumbled too much' and 'I would love to see', which keeps the tone constructive rather than harsh. The reviewer also acknowledges that their background might influence their perspective, which shows consideration."", ""The sentiment score is 50 (slightly positive) because the reviewer finds the authors' approach 'novel and interesting' and acknowledges that it 'shows promise'. However, they also express concerns about the need for more experimental justifications and broader testing. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the positive aspects of the work, and phrases criticisms constructively (e.g., 'I feel that more experimental justifications are needed'). The reviewer also provides specific, helpful suggestions for improvements, which is a polite way to offer criticism."", 'The sentiment score is slightly positive (20) because the reviewer acknowledges the importance of the topic and praises the paper as well-written with a helpful overview example. However, they also express concerns about the limited scope of experiments and comparisons with other methods, which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, poses questions rather than making harsh criticisms, and offers constructive feedback. They begin with positive comments before moving to areas of concern, which is a polite approach. The reviewer also provides specific suggestions for improvement and additional comparisons, demonstrating engagement with the work rather than dismissing it outright.']"
"[""Summary:\nThis paper presents a Two-Timescale Network (TTN) that enables linear methods to be used to learn values. On the slow timescale non-linear features are learned using a surrogate loss. On the fast timescale, a value function is estimated as a linear function of those features. It appears to be a single network, where one head drives the representation and the second head learns the values.  They investigate multiple surrogate losses and end up using the MSTDE for its simplicity, even though it provides worse value estimates than MSPBE as detailed in their experiments.  They provide convergence results - regular two-timescale stochastic approximation results from Borkar, for the two-timescale procedure and provide empirical evidence for the benefits of this method compared to other non-linear value function approximation methods.\n\nClarity and Quality:\nThe paper is well written in general, the mathematics seems to be sound and the experimental results appear to be thorough. \n\nOriginality:\nUsing two different heads, one to drive the representation and the second to learn the values appears to be an architectural detail. The surrogate loss to learn the features coupled with a linear policy evaluation algorithm appear to be novel, but does not warrant, in my opinion, the novelty necessary for publication at ICLR. \n\nThe theoretical results appear to be a straightforward application of Borkar’s two-timescale stochastic approximation algorithm to this architecture to get convergence. This therefore, does not appear to be a novel contribution.\n\nYou state after equaltion (3) that non-linear function classes do not have a closed form solution. However, it seems that the paper Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation does indeed have a closed form solution for non-linear function approximators when minimizing the MSPBE (albeit making a linearity assumption, which is something your work seems to make as well). \n\nThe work done in the control setting appears to be very similar to the experiments performed in the paper: Shallow Updates for Deep Reinforcement Learning.\n\nSignificance:\nOverall, I think that the paper is well written and the experimental evaluation is thorough. However, the novelty is lacking as it appears to be training using a multi-headed approach (which exists) and the convergence results appear to be a straightforward application of Borkars two-timescale proof. The novelty therefore appears to be using a surrogate loss function for training the features which does not possess the sufficient novelty in my opinion for ICLR. \n\nI would suggest the authors' detail why their two-timescale approach is different from that of Borkars. Or additionally add some performance guarantee to the convergence results to extend the theory. This would make for a much stronger paper."", 'The paper proposes a two-timescale framework for learning the value function and a state representation altogether with nonlinear approximators. The authors provide proof of convergence and a good empirical evaluation.\n\nThe topic is very interesting and relevant to ICLR. However, I think that the paper is not ready for a publication.\nFirst, although the paper is well written, the writing can be improved. For instance, I found already the abstract a bit confusing. There, the authors state that they ""provide a two-timescale network (TTN) architecture that enables LINEAR methods to be used to learn values [...] The approach facilitates use of algorithms developed for the LINEAR setting [...] We prove convergence for TTNs, with particular care given to ensure convergence of the fast LINEAR component.""\nYet, the title says NONLINEAR and in the remainder of the paper they use neural networks. \n\nThe major problem of the paper is, however, its organization. The novelty of the paper (the proof of convergence) is relegated to the appendix, and too much is spent in the introduction, when actually the idea of having the V-function depending on a slowly changing network is also not novel in RL. For instance, the authors say that V depends on \\theta and w, and that \\theta changes at slower pace compared to w. This recalls the use of target networks in the TD error for many actor-critic algorithms. (It is not the same thing, but there is a strong connection).\nFurthermore, in the introduction, the authors say that eligibility traces have been used only with linear function approximators, but GAE by Schulman et al. uses the same principle (their advantage is actually the TD(\\lambda) error) to learn an advantage function estimator, and it became SOTA for learning the value function.\n\nI am also a bit skeptical about the use of MSBE in the experiment. First, in Eq 4 and 5 the authors state that using the MSTDE is easier than MSBE, then in the experiments they evaluate both. However, the MSBE error involves the square of an expectation, which should be biased. How do you compute it? \n(Furthermore, you should spend a couple of sentences to explain the problem of this square and the double-sampling problem of Bellman residual algorithms. For someone unfamiliar with the problem, this issue could be unclear.)\n\nI appreciate the extensive evaluation, but its organization can also be improved, considering that some important information are, again, in the appendix.\nFurthermore, results on control experiment are not significative and should be removed (at the current stage, at least). In the non-image version there is a lot of variance in your runs (one blue curve is really bad), while for the image version all runs are very unstable, going always up and down. \n\nIn conclusion, there is a lot of interesting material in this paper. Even though the novelty is not great, the proofs, analysis and evaluation make it a solid paper. However, because there is so much do discuss, I would suggest to reorganize the paper and submit directly to a journal track (the paper is already 29 pages including the appendix).', 'This paper proposes Two-Timescale Networks (TTNs), a reinforcement learning algorithm where feature representations are learned by a neural network trained on a surrogate loss function (i.e. value), and a value function is learned on top of the feature representation using a ""fast"" least-squares algorithm. The authors prove the convergence of this method using methods from two time-scale stochastic approximation. \n\nConvergent and stable nonlinear algorithms is an important problem in reinforcement learning, and this paper offers an interesting approach for addressing this issue. The idea of using a ""fast"" linear learner on top of a slowly changing representation is not new in RL (Levine et. al, 2017), but the authors somewhat motivate this approach by showing that it results in a stable and convergent algorithm. Thus, I view the convergence proof as the main contribution of the paper.\n\nThe paper is written clearly, but could benefit from more efficient use of space in the main paper. For example, I feel that the introduction and discussion in Section 3 on surrogate objectives could be considerably shortened, and a formal proof statement could be included from the appendix in Section 4, with the full proof in the appendix.\n\nThe experimental evaluation is detailed, and ablation tests show the value of different choices of surrogate loss for value function training, linear value function learning methods, and comparisons against other nonlinear algorithms such as DQN and Nonlinear GTD/TD/variants. A minor criticism is that it is difficult to position this work against the ""simpler but not sound"" deep RL methods, as the authors only compare to DQN on a non-standard benchmark task.\n\nAs additional related work, SBEED (Dai et. al, ICML 2018) also shows convergence for a nonlinear reinforcement learning algorithm (in the control setting), and quantifies the convergence rate while accounting for finite sample error. It would be good to include discussion of this work, although the proposed method and proofs are derived very differently.', 'The paper introduces an algorithm (TTN) for non-linear online and on-policy value function approximation. The main novelty of the paper is to view non-linear value estimation as two separate components. One of representation learning from a non-linear mapping and one of linear value function estimation. The soundness of the approach stems from the rate at which each component is updated. The authors argue that if the non-linear component is updated at a slower rate than the linear component, the former can be viewed as fixed in the limit and what remains is a linear value function estimation problem for which several sound algorithms exist. TTN is evaluated on 4 domains and compared to several other value estimation methods as well as DQN on a control problem with two variations on the task\'s state space.\n\nI\'ll start off the review by stating that I find the idea and theoretical justification of separating the non-linear and linear parts of value function estimation to be quite interesting, potentially impacting RL at large. Indeed, this view promises to reconcile latest developments in deep RL with the long-lasting work on RL with linear function approximators. However, there are a few unclear aspects that do not allow one to be fully convinced that this paper lives up to the aforementioned promise.\n\n- For the theoretical contribution. The authors claim that the main challenge was to deal with the potentially dependent features outputted by the neural network. It is dealt with by using a projection that projects the linear parameters of the value function to a compact subset of the parameter space. Bar the appendix, there is no mention of this projection in the paper, on how this compact subset (that must include the optimal parameter) is defined and if this projection is merely a theoretical tool or if it was necessary to implement it in practice. There is a projection for the neural net weights too but I can see how for these it might not be necessary to use in practice. However, for the linear weights, as their computation potentially involves inverting ill-conditioned matrices, they can indeed blow-up relatively fast.\n\n- I found the experimental validation to be quite rich but not done in a systematic enough manner. For instance, the experiment ""utility of optimizing the MSPBE"" demonstrates quite nicely the importance of each component but is only performed on a single task. As the theoretical analysis does not say anything about the improvements the representation learning can have on the linear value estimation nor if the loss used for learning the representation effectively yields better features for the MSPBE minimization, this experiment is rather important and should have been performed on more than a single domain.\n\nSecondly, I do not find the chosen baselines to be sufficiently competitive. The authors state in Sec. 2 that nonlinear-GTD has not seen widespread use, but having this algorithm as the main competitor does not provide strong evidence that TTN will know a better fate. In the abstract, it is implied that outside of nonlinear-GTD, value function approximation methods are not sound. In approximate policy iteration algorithms such as DDPG or TRPO, there is a need in performing value estimation. It is done by essentially a fitted-Q iteration procedure which is sound. Why wasn\'t TTN compared to these methods? If it is because they are not online, why being online in the experiments of the paper is important? Showing that TTN is competitive with currently widespread methods for value estimated would have been more convincing than the comparison with nonlinear-GTD.\n\nThirdly, for the sake of reproducibility, as LSTD seems to be the method of choice for learning the linear part, it would have been adequate to provide an algorithm box for this version as is done for GTD2/TDC. LSTD is essentially a batch algorithm and there could be many ways to turn it into an online algorithm. With which algorithm were the results in the experimental section obtained?\n\nFinally, on the control task, the authors add several modifications to their algorithm which results in an algorithm that is very close to that of Levine et al., 2017. Why was not the latter a baseline for this experiment? Especially since it was included in other experiments.']","[-30, -40, 60, -20]","[60, 50, 70, 60]","[""The sentiment score is -30 because while the reviewer acknowledges some positive aspects ('well written', 'sound mathematics', 'thorough experiments'), they express significant concerns about the paper's novelty and suitability for ICLR. The reviewer states that the work 'does not warrant, in my opinion, the novelty necessary for publication at ICLR' and suggests that key aspects are 'straightforward' applications of existing methods. This indicates a generally negative sentiment, though not extremely so.\n\nThe politeness score is 60 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think', 'I would suggest', and 'in my opinion', which soften their criticisms. The reviewer also acknowledges positive aspects of the paper before presenting their concerns. However, the score is not higher because the review is direct in its criticisms without excessive softening language, maintaining a balance between politeness and clear feedback."", ""The sentiment score is -40 because while the reviewer acknowledges the interesting topic and good empirical evaluation, they state that 'the paper is not ready for a publication' and list several major issues. The overall tone is critical, pointing out problems with organization, novelty claims, and experimental results. However, it's not entirely negative as they recognize potential in the work.\n\nThe politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think,' 'I appreciate,' and 'I would suggest,' which soften the criticism. They also acknowledge positive aspects of the paper before presenting critiques. However, the review doesn't go out of its way to be overly polite, maintaining a direct approach in pointing out issues."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, calling it an 'interesting approach' and praising its 'detailed' experimental evaluation. They view the convergence proof as the main contribution and consider the problem important. However, they also offer some criticisms, such as suggesting the introduction could be shortened and noting limitations in the comparisons to other methods, which prevents the score from being higher. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh critiques. They use phrases like 'could benefit from' and 'a minor criticism is' which maintain a polite tone while providing feedback. The reviewer also acknowledges the paper's strengths and contributions, further contributing to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the idea interesting and potentially impactful, they express several concerns and criticisms about the paper's methodology, experimental validation, and choice of baselines. The review starts positively but then lists multiple areas where the paper falls short of convincing the reviewer.\n\nThe politeness score is moderately positive (60) because the reviewer uses respectful and professional language throughout. They acknowledge the potential value of the work and frame their criticisms as suggestions for improvement rather than harsh judgments. Phrases like 'I find the idea... to be quite interesting' and 'I'll start off the review by stating...' contribute to a polite tone. The reviewer also uses hedging language like 'potentially' and 'quite' which softens their criticisms.\n\nOverall, the review maintains a balanced and constructive tone, offering both praise and criticism in a professional manner, which is typical of academic peer reviews.""]"
"[""This paper proposed a variational autoencoder-based method for semi-supervised dependency parsing. Given an input sentence s, an LSTM-based encoder generates a sentence embedding z, and a NN of Kiperwasser & Goldberg (2016) generates a dependency structure T. Gradients over the tree encoder are approximated by (1) adding a perturbation matrix over the weight matrix and (2) relax dynamic programming-based parsing algorithm to a differentiable format. The decoder combines standard LSTM and Graph Convolutional Network to generate the input sentence from z and T. The authors evaluated the proposed method on three languages, using 10% of the original training data as labeled and the rest as unlabeled data.\n\nPros\n1. I like the idea of this sentence->tree->sentence autoencoder for semi-supervised parsing. The authors proposed a novel and nice way to tackle key challenges in gradient computation. VAE involves marginalization over all possible dependency trees, which is computationally infeasible, and the proposed method used a Gumbel-Max trick to approximate it. The tree inference procedure involves non-differentiable structured prediction, and the authors used a peaked-softmax method to address the issue. The whole model is fully differentiable and can be thus trained end to end.\n\n2. The direction of semi-supervised parsing is useful and promising, not only for resource-poor languages, but also for popular languages like English. A successful research on this direction could be potentially helpful for lots of future work.\n\nCons, and suggestions on experiments\nMy main concerns are around experiments. Overall I think they are not strong enough to demonstrate that this paper has sufficient contribution to semi-supervised parsing. Below are details.\n\n1. The current version only used 10% of original training data as labeled and the rest as unlabeled data. This makes the reported numbers way below existing state-of-the-art performance. For example, the SOTA UAS on English PTB has been >95%. Ideally, the authors should be able to train a competitive supervised parser on full training data (English or other languages), and get huge amount of unlabeled data from other sources (e.g. News) to further push up the performance. The current setting makes it hard to justify how useful the proposed method could be in practice.\n\n2. The best numbers from the proposed model is lower than baseline (Kipperwasser & Goldberg) on English, and only marginally better on Swedish. This probably means the supervised baseline is weak, and it's hard to tell if the gains from VAE will retain if applied to a stronger supervised.\n\n3. A performance curve with different amount of labeled and unlabeled data would be useful to better understand the impact of semi-supervised learning.\n\n4. What's the impact of perturbation? One could simply use T=Eisner(W) as approximation. Did you observe any significant benefits from sampling?\n\nOther questions\n1. What's the impact of keeping the tree constraint on dependencies during backpropagation?  Have you tried removing the tree constraint like previous work?\n\n2. Are sentence embedding and trees generated from two separate LSTM encoders? Are there any parameter sharing between the two?\n\n"", '[Summary]\nThis paper proposes to do semi-supervised learning , via a generative model, of an arc-factored dependency parser by using  amortized variational inference.  The parse tree is the latent variable, the parser is the encoder that maps a sentence to a distribution over parse-trees, and the decoder is a generative model that maps a parse tree to a distribution over sentences.  \n\n[Pros]\nSemi-supervised learning for dependency parsing is both important and difficult and this paper presents a novel approach using variational auto-encoders. And the semi-supervised learning method in this paper gives a small but non-zero improvement over a reasonably strong baseline. \n\n[Cons]\n1. My main concern with this paper currently are the ""explanations"" provided in the paper which are quite hand-wavy. E.g. the authors state that using a KL term in semi-supervised learning is exactly opposite to the ""low density separation assumption"".  And therefore they set the KL term to be zero. One has to wonder that why is the ""low density separation assumption"" so critical for dependency parsing only? VAEs have been used with a prior for semi-supervised learning before, why didn\'t this assumption affect those models ? \n\nA better explanation will have been that since the authors first trained the parser in a supervised fashion, therefore their inference network already represents a ""good"" distribution over parses, even though this distribution is specified only upto sampling but not in a mathematically closed form. Finally, setting the KL divergence between the posterior of the inference network and the prior to be zero is the same as dynamically specifying the prior to be the same as the inference network\'s distribution.  \n\n2. A number of important details are missing in the submitted version of the paper which the authors addressed in their reply to my public comment.\n\n3. The current paper does not contain any comparison to self-training which is a natural baseline for this work. The authors replied to my comment saying that self-training requires a number of heuristics but it\'s not clear to me how much more difficult can these heuristics be than the tuning required for training their VAE.', 'The paper describes a VAE-based approach to semi-supervised learning\nof dependency parsing. The encoder in the VAE is a neural edge-factored\nparser allowing inference using Eisner\'s dynamic programming algorithms.\nThe decoder generates sentences left-to-right, at each point conditioning\non head-modifier dependencies specified by the tree. A key technical \nstep is to develop a method for ""differentiable"" sampling/parsing,\nusing a modification of the dynamic program, and the Gumbel-max trick.\n\nI thought this was an excellent paper - very clear, an important \nproblem, a very useful set of techniques and results. I would strongly\nrecommend acceptance.\n\nSome comments:\n\n* I do wonder how well this approach would work with orders of magnitude\nmore unlabeled data. The amount of unlabeled data used is quite small.\n\n* Similarly, I wonder how well the approach works as the amount of\nunlabeled data is decreased (or increased, for that matter). It should\nbe possible to provide graphs showing this.\n\n* Are there natural generalizations to multi-lingual data, for example\nsettings where supervised data is only available for languages other\nthan the language of interest?\n\n* It would be interesting to see an analysis of accuracy improvements\non different dependency labels. The ""root"" case is in some sense just\none of the labels (nsubj, dobj, prep, etc.) that could be analyzed.\n\n* I wonder also if this method would be particularly helpful in \ndomain transfer, for example from Wall Street Journal text to\nWikipedia or Web data in general. The improvements could be more\ndramatic in this case - that kind of effect has been seen with \nELMO for example.']","[50, -20, 90]","[80, 50, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer begins by highlighting the positive aspects of the paper, praising the novel idea and its potential usefulness. However, they also express significant concerns about the experiments, which balances out the initial positivity. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing criticisms as 'concerns' and offering constructive suggestions. They use phrases like 'I like the idea' and 'Ideally, the authors should be able to' which maintain a courteous tone even when pointing out weaknesses. The review is structured in a professional manner, clearly separating pros and cons, and ending with thoughtful questions that encourage further development of the work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('important and difficult' topic, 'novel approach', 'small but non-zero improvement'), they express several significant concerns. These include 'hand-wavy' explanations, missing important details, and lack of comparison to a relevant baseline. The tone is more critical than positive overall. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use neutral language to express concerns ('My main concern...', 'One has to wonder...') rather than harsh criticism. The reviewer also acknowledges the authors' responses to previous comments, showing engagement and consideration. The language is consistently polite and constructive, even when pointing out shortcomings."", ""The sentiment score is 90 because the reviewer explicitly states 'I thought this was an excellent paper' and 'I would strongly recommend acceptance', indicating a very positive view. The politeness score is 80 because the reviewer uses respectful language throughout, offers constructive suggestions, and frames criticisms as questions or areas for potential improvement rather than direct criticisms. The reviewer's tone is professional and encouraging, using phrases like 'I wonder' and 'It would be interesting' to suggest improvements in a polite manner.""]"
"['This paper proposed a new class of meta-algorithm for reinforcement learning and proved the monotone improvement for a local maximum of the expected reward, which could be used in deep RL setting. The framework seems to be quite general but does not include any specific example, like what non-linear dynamical model in detail could be included and will this framework cover the classical MDP setting? In theory, the dynamical model needs to satisfy L-Lipschitz. So which dynamical model in reality could satisfy this assumption? It seems that the focus of this paper is theoretical side. But the only guarantee is the non-decreasing value function of the policy. In RL, people may be more care about the regret or sample complexity. Previous model-based work with simpler model already can have such strong guarantees, such as linear dynamic (Y. Abbasi-Yadkori and Cs. Szepesvari (2011)), MDP (Agrawal and Jia (2017)). What kind of new insights will this framework give when the model reduces to simpler one (linear model)?\n\nIn practical implementation, the authors designed a Stochastic Lower Bound Optimization. Is there any convergence rate guarantee for this stochastic optimization? And also neural network is used for deep RL. So there is also no guarantee for the actual algorithm which is used?\n\nMinor:\n\n1. In (3.2), what norm is considered here?\n2. In page 4, the authors mentioned their algorithm can be viewed as an extension of the optimism-in-face-of-uncertainty principle to non-linear parameterized setting. This is a little bit confused. How this algorithm can be viewed as OFU principle? How does it recover the result in linear setting (Y. Abbasi-Yadkori and Cs. Szepesvari (2011))?\n3. The organization could be more informative. For example, Section 1 has 13 paragraphs but without any subsection.\n\nY. Abbasi-Yadkori and Cs. Szepesvari, Regret Bounds for the Adaptive Control of Linear Quadratic Systems, COLT, 2011.\nShipra Agrawal and Randy Jia. Optimistic posterior sampling for reinforcement learning: worst-case regret bounds. NIPS, 2017', 'The paper presents monotonic improvement bounds for model-based reinforcement learning algorithms. Based on these bounds, a new model-based RL algorithm is presented that performs well on standard benchmarks for deep RL.\n\nThe paper is well written and the bounds are very interesting. The algorithm is also interesting and seems to perform well. However, there is a slight disappointment after reading the paper because the resulting algorithm is actually quite far away from the assumptions made for deriving the bounds. The 2 innovations of the algorithm are:\n- Model and policy are optimized iteratively in an inner policy improvement loop. As far as I see it, this is independent of the presented theory. \n- The L2 norm is used to learn the model instead of the squared L2 norm. This is inspired by the theory.\n\nMore comments below:\n- I was confused by section 4.2. Could you please explain why the transformation is needed and how it is used? As I understand, this is not used at all in the algorithm any more? So what is the advantage of this derivation in comparison to Eq 4.6?\n- Please explain in more detail what the effects are from relaxing the assumptions for the algorithm? I assume none of the monotonic improvement results can be transferred to the algorithm?\n- Could you elaborate why the algorithm was not implemented as suggested by Section 4? Is the problem that the algorithm did not perform well or that the discrepency measure is hard to compute?\n- For the presented algorithm, the discrepency does not depend on the policy any more. I did not understand why the iterative optimization should be useful in this case.\n- The theory suggests that we have to do a combined optimization of the lower bound. However, effectively, the algorithm optimizes the policy over V and the policy over the L2 multi-step prediction loss. The difference to a standard model-based RL algorithm is minor and the many advantages of the nice theoretical framework are lost.\n- The only difference between Algo 3 and Algo 2 seems to be the additional for loop. As I said, its not clear to me why this should be useful as the optimization problems are independent of each other (except for the trajectories, but the model does not depend on the policy). Did you try Algo 3 with the same amount of Adam updates as Algo 2 (could be that I missed that).   \n\n ', 'The paper proposed a framework to design model-based RL algorithms. The framework is based on OFU and within this framework the authors develop an algorithm (a variant of SLBO) achieving SOTA performance on MuJoCo tasks.\n\nThe paper is very well written and the topic is important for the RL community. The authors do a good job at covering related works, the bounds are very interesting and the results quite convincing. \n\nQuestions/comments to the authors:\n1) In footnote 3 you state that ""[...] we only need to approximate the dynamical model accurately on the trajectories of the optimal policy"". Why only of the optimal policy? Don\'t you also need an accurate dynamic model for the current policy to perform a good policy improvement step? \n2) A major challenge in RL is that the state distribution \\rho^\\pi changes with \\pi and it is usually very hard to estimate. Therefore, many algorithms assume it does not change if the policy is subject to small changes (examples are PPO and TRPO). In Eq 4.3 it seems that you also do something similar, fixing \\rho^\\pi and constraining the KL of \\pi (and not of the joint distribution p(s,a)). Am I correct? Can you elaborate it a bit more, building a connection with other RL methods?\n3) In Eq. 6.1 and 6.2 you minimize the H-loss, defined as the prediction error of your model. Recently, Pathak et al. used the same loss function in many papers (such as Curiosity-driven Exploration by Self-supervised Prediction) and your Eq. 6.2 looks like theirs. The practical implementation of your algorithm looks very similar to theirs too. Can you comment on that? \n4) If I understood it correctly, your V-function directly depends on your model, i.e., you have V(M(s)) and you learn the model M parameters to maximize V. This means that you want to learn the model that, together with the policy, maximizes V. Am I correct? Can you comment a bit more on that? Did you try to optimize them (V and M) separately, i.e., to add a third parameter to learn (the V-function parameters)?\n5) How does you algorithm deal with environmental noise? The tasks used for the evaluation are all deterministic and I believe that this heavily simplifies the model learning. It would be interesting an evaluation on a simple problem (for example the swing-up pendulum) in the presence of noise on the observations and/or the transition function.\n6) I appreciate that you provide many details about the implementation in the appendix. Can you comment a bit more? Which are the most important hyperparameters? The number of policy optimization n_policy or of model optimization n_model? You mention that you observed policy overfitting at the first iterations. Did you also experience model overfitting? Did normalizing the state help a lot? ']","[-20, -20, 80]","[50, 60, 90]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the theoretical contribution of the paper, they express several concerns and questions about its practical applications and comparisons to existing work. The review begins with a neutral description but then raises multiple issues and limitations, indicating a somewhat critical stance. The politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use phrases like 'seems to be' and pose questions rather than making harsh criticisms. The language is formal and constructive, offering specific points for improvement without being confrontational. The reviewer also provides references to related work, which is a courteous academic practice."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is well-written and the bounds are interesting, they express disappointment that the resulting algorithm is 'quite far away from the assumptions made for deriving the bounds'. The reviewer also raises several questions and points of confusion, indicating some dissatisfaction with the paper's clarity and completeness. However, the overall tone is not severely critical, hence the score is only mildly negative. The politeness score is positive (60) as the reviewer uses respectful language throughout, phrasing criticisms as questions or suggestions rather than direct accusations. They use phrases like 'Could you please explain' and 'Please explain in more detail', which are polite ways of requesting clarification. The reviewer also begins with positive comments before moving to critiques, which is a courteous approach in academic review."", ""The sentiment score is 80 (positive) because the reviewer expresses a very positive view of the paper in the second paragraph, stating it is 'very well written', the topic is 'important', and the results are 'quite convincing'. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, poses questions and comments as suggestions rather than criticisms, and shows appreciation for the authors' work (e.g., 'I appreciate that you provide many details'). The reviewer also frames their points as questions or requests for elaboration, which is a polite way to address potential issues or seek clarification.""]"
"['The authors develop a tree structured extension to the recently proposed recurrent switching linear dynamical systems. Like switching linear dynamical systems (sLDS) the proposed models capture non-linear dynamics by switching between a collection of linear regimes. However, unlike SLDS, the transition between the regimes is a function of a latent tree as well as the preceding continuous latent state. Experiments on synthetic data as well as neural spike train data are presented to demonstrate the utility of the model.\n\nThe paper is clearly written and easy to read. The tree structured model (TrSLDS) is a sensible extension to rSLDS. While one wouldn’t expect TrSLDS to necessarily fit the data any better than rSLDS, the potential for recovering multi-scale, possibly more interpretable decompositions of the dynamic process is compelling. \n\nWhile the authors do provide some evidence of being able to recover such multi-scale structures, overall the experiments are underwhelming and somewhat sloppy. First, to understand whether the sampler is mixing well, it would be nice to include an experiment where the true dynamics and the entire latent structure (including the discrete states) are known, and then to examine how well this ground-truth structure is recovered. Second, for the results presented in section 5, how many iterations was the sampler run for? In the figures, what is being visualized?, the last sample?, the MAP sample? or something else? I am not sure what to make of the real data experiment in section 5.3. Wouldn’t rSLDS produce nearly identical results? What is TrSLDS buying us in this scenario? Do the higher levels of the tree capture interesting low resolution dynamics that are not shown for some reason? \n\nMy other big concern is scalability. To use larger number of discrete states one would need deeper (or wider if the binary requirement is relaxed) trees. How well does the sampler scale with the number of discrete states? How long did the sampler take for the various 4-state results presented in the paper? \n\nMinor:\na) There is a missing citation in the first para fo Section 5. \nb) Details of message passing claimed to be in the supplement are missing.\n\n============\nThere are interesting ideas in this paper. However, experimental section could better highlight the benefits afforded by the model and scalability concerns need to be addressed.\n\n', 'PAPER SUMMARY:\n\nThis paper introduces a probabilistic generative framework to model linear dynamical systems at multiple levels of resolution, where the entire complex, nonlinear dynamics is approximated via a hierarchy of local regimes of linear dynamics -- the global dynamic is then characterized as a switching process that switches between linear regimes in the hierarchy.\n\nNOVELTY & SIGNIFICANCE:\n\nThe key contributions of this paper are (a) the use of tree-structured stick breaking to partition the entire dynamic space into a hierarchy of linear regimes; (b) the design of a hierarchical prior that is compatible to the tree structure; and (c) the developed Bayesian inference framework for it in Section 4.\n\nBy exploiting the tree-structured stick breaking process (Adams et al., 2010), the proposed framework is able to partition the entire dynamic space into a hierarchy of switching linear regimes.\n\nThis allows the dynamic to be queried at multiple levels of resolution. This appears to be the key difference between the proposed framework and the previous work of (Linderman et al., 2017) on recurrent switching dynamical systems that partition the dynamic space sequentially at the same level of resolution.\n\nThis seems like a non-trivial extension to the previous work of (Linderman et al., 2017) & I tend to consider this a novel contribution. That said, the paper was also not positioned against existing literature on hierarchical switching linear dynamic systems (see below) & I find it hard to evaluate the significance of the proposed framework (which explains the borderline rating)\n\n""A Hierarchical Switching Linear Dynamical System applied to the detection of sepsis in neonatal condition monitoring"", Ioan Stanculescu, Christopher K. I. Williams and Yvonne Freer. In Proceeding of the 30th Conference on Uncertainty in AI (UAI-14), pages 752-761\n\nCould the authors please discuss the differences between the proposed work & (at least) the above? \n\nTECHNICAL SOUNDNESS:\n\nThe technical exposition makes sense to me. Please also discuss the processing complexity of the resulting TrSLDS framework. In exchange for the improved performance, how much slower TrSLDS is as compared\nto rSLDS? I am interested to see this demonstrated in the empirical studies.\n\nCLARITY:\n\nThe paper is clearly written.\n\nEMPIRICAL RESULTS:\n\nThe experiments look interesting and are very extensive on both test domains. However, I do not understand why the authors decided not to compare with rSLDS using its benchmark? \n\nI find this somewhat sloppy and hope the authors would clarify this too. \n\n****\n\nPost-rebuttal update: The authors have made significant revision to their work, which sufficiently addressed all my concerns. I have upgraded my score accordingly and I am willing to support the acceptance of this paper.', 'This paper introduces a probabilistic model to model nonlinear dynamic systems with multiple granularities. The nonlinearity is achieved by using multiple local linear approximations. The method is an extension to rSLDS (recurrent switching linear dynamical systems),  which in turn is an extension to SLDS. \n\nPros:\n1. Introducing the tree structure is a neat way of extending the existing rSLDS model to multiscale scenarios. \n2. The paper is written clearly. The background is well illustrated and the idea rises naturally from there. The paper is also solid in the part describing the model. \nCon:\n1. from the rSLDS paper (https://arxiv.org/pdf/1610.08466.pdf), the authors there was experimenting with some settings similar to those used in this paper. However, I am not able to find some explicit comparison between the TrSLDS and rSLDS in this work. I think it should be needed since TrSLDS itself is derived out from rSLDS, it would be good to show explicitly the advantage of the new model.\n']","[-20, 50, 50]","[60, 75, 80]","[""Sentiment score: The review starts positively, praising the paper as 'clearly written and easy to read' and describing the model as a 'sensible extension'. However, it then shifts to a more critical tone, describing the experiments as 'underwhelming and somewhat sloppy' and expressing concerns about scalability. The reviewer concludes that there are 'interesting ideas' but significant improvements are needed. This mix of positive and negative comments, with a slight lean towards the negative, justifies a score of -20.\n\nPoliteness score: The reviewer maintains a professional and respectful tone throughout. They use phrases like 'it would be nice to include' and 'I am not sure what to make of' rather than making blunt criticisms. The reviewer also acknowledges the positive aspects of the paper before presenting criticisms. However, some phrases like 'underwhelming and somewhat sloppy' are more direct. Overall, the language is polite but not excessively so, warranting a score of 60."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's novelty and contributions, calling it a 'non-trivial extension' and 'novel contribution'. However, they also express some reservations about positioning against existing literature and lack of comparison with rSLDS. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, phrases criticisms constructively (e.g. 'Could the authors please discuss...'), and ends on a positive note after the rebuttal. The reviewer maintains a professional tone while providing both praise and constructive feedback."", ""The sentiment score is 50 (slightly positive) because the review starts with a neutral description of the paper, followed by two clear pros and only one con. The positive aspects are highlighted first, indicating a generally favorable view. However, the presence of a significant con prevents a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout. They acknowledge the paper's strengths with phrases like 'neat way' and 'solid', and frame the criticism constructively as a suggestion for improvement rather than a harsh critique. The tone remains objective and courteous throughout the review.""]"
"['Overview:\nI thank the authors for their interesting and detailed work in this paper. I believe it has the potential to provide strong value to the community interested in using VAEs with an explicit and simple parameterization of the approximate posterior and likelihood as Gaussian. Gaussianity can be appropriate in many cases where no sequential or discrete structure needs to be induced in the model. I find the mathematical arguments interesting and enlightening. However, the authors somewhat mischaracterize the scope of applicability of VAE models in contemporary machine learning, and don\'t show familiarity with the broad literature around VAEs outside of this case (that is, where a Gaussian model of the output would be manifestly inappropriate). Since the core of the paper is valuable and salvageable from a clarity standpoint, my comments below are geared towards what changes the authors may make to move this paper into the ""pass"" category.\n\nPros: \n- Mathematical insights are well reasoned and interesting. Based on the insight from the analysis in the supplementary materials, the authors propose a two-stage VAE which separate learning the a parsimonious representation of the low-dimensional (lower than the ambient dimension of the input space), and the training a second VAE to learn the unknown approximate posterior. The two-stage training procedure is both theoretically motivated and appears to enhance the output quality of VAEs w.r.t. FID score, making them rival GAN architectures on this metric.\n\nCons:\n- The title and general tone of the paper is too broad: it is only VAE models with Gaussian approximate posteriors and likelihoods. This is hardly the norm for most applications, contrary to the claims of the authors. VAEs are commonly used for discrete random variables, for example. Many cases where VAEs are applied cannot use a Gaussian assumption for the likelihood, which is the key requirement for the proofs in the supplement to be valid (then, the true posterior is also Gaussian, and the KL divergence between that and the approximate posterior can be driven to zero during optimization--clearly a Gaussian approximate posterior will never have zero KL divergence with a non-Gaussian true posterior).\n- None of the proofs consider the approximation error garnered by only having access to empirical samples through a sample of the ground truth population. (The ground-truth distribution must be defined with respect to the population rather just the dataset in hand, otherwise we lose all generalizability from a model.) Moreover, the proofs hold asymptotically. Generalization bounds and error from finite time approximations are very pertinent issues and these are ignored by the presented analyses. Such concerns have motivated many of the recent developments in approximate posterior distributions. Overall, the paper contains little evidence of familiarity with the recent advances in approximate Bayesian inference that have occurred over the past two years.\n- A central claim of the paper is that the two-stage VAE obviates the need for highly adaptive approximate posteriors. However, no comparison against those models is done in the paper. How does a two-stage VAE compare against one with, e.g., a normalizing flow approximate posterior? I acknowledge that the purpose of the paper was to argue for the Gaussianity assumption as less stringent than previously believed, but all of the mathematical arguments take place in an imagined world with infinite time and unbounded access to the population distribution. This is not really the domain of interest in modern computational statistics / machine learning, where issues of generalization and computational efficiency are paramount.\n- While the mathematical insights are well developed, the specifics of the algorithm used to implement the two-stage VAE are a little opaque. Ancestral sampling now takes place using latent samples from a second VAE. An algorithm box is badly needed for reproducibility.\n\nRecommendations / Typos\n\nI noted a few typos and omissions that need correction.\n\n- Generally, the mathematical proofs in section 7 of the supplement are clear. At the top of page 11, though, the paragraph correctly begins by stating that the composition of invertible functions is invertible, but fails to establish that G is also invertible. Clearly it is so by construction, but the explicit reasons should be stated (as a prior sentence promises), and so I assume this is an accidental omission.\n- The title of Section 8.1 has a typo: clearly is it is the negative log of p_{theta_t} (x) which approaches its infimum rather than p_{theta_t} (x) approaching negative infinity.\n- Equation (4): the true posterior has an x as its argument instead of the latent z.\n- Missing parenthesis under Case 2 and wrong indentation. This analysis also seems to be cut off. Is the case r > d relevant here?\n\n* EDIT: I have read the authors\' detailed response. It has clarified a few key issues, and convinced me of the value to the community for publication in its present (slightly edited according to the reviwers\' feedback) form. I would like to see this published and discussed at ICLR and have revised my score accordingly. *', 'This paper proposed a two-stage VAE method to generate high-quality samples and avoid blurriness. It is accomplished by utilizing a VAE structure on the observation and latent variable separately. The paper exploited a collection of interesting properties of VAE and point out the problem existed in the generative process of VAE.  I have several concerns about the paper:\n\n1.\tIt is necessary to explain why the second-stage VAE can have its latent variable more closely resemble N(u|0,I). Even if the latent variable closely resemble N(u|0,I), How does it make sure the generated images are realistic? I admit that the VAE model can reconstruct realistic data based on its inferred latent variable, however, when given a random sample from N(u|0,I), the generated images are not good, which is true when the dimension of the latent space is high. I still can’t understand why a second-stage VAE can relief this problem.\n2.\tThe adversarial auto-encoder is also proposed to solve the latent space problem, by comparison, what is the advantage of this paper?\n3.\tWhy do you set the model as two separate stages? Will it enhance the performance if we train theses two-stages all together?\n4.\tThe proofs for the theory 2 and 3 are under the assumption that the manifold dimension of the observation is r, while in reality it is difficult to obtain this r, do these theories applicable if we choose a value for the dimension of the latent space that is smaller than the real manifold dimension of the observation? How will it affect the performance of the proposed method?\n5.\tThe value of r and k in each experiment should be specified.\n\n', 'The paper provides a number of novel interesting theoretical results on ""vanilla"" Gaussian Variational Auto-Encoders (VAEs) (sections 1, 2, and 3), which are then used to build a new algorithm called ""2 stage VAEs"" (Section 4). The resulting algorithm is as stable as VAEs to train (it is free of any sort of adversarial training, it comes with a little overhead in terms of extra parameters), while achieving a quality of samples which is *very impressive* for an Auto-Encoder (AE) based generative modeling techniques (Section 5). In particular, the method achieves FID score 24 on the CelebA dataset which is on par with the best GAN-based models as reported in [1], thus sufficiently reducing the gap between the generative quality of the GAN-based and AE-based models reported in the literature. \n\nMain theoretical contributions:\n\n1. In some cases the variational bound of Gaussian VAEs can get tight (Theorem 1).\nIn the context of vanilla Gaussian VAEs (Gaussian prior, encoders, and decoders) the authors show that if (a) the intrinsic data dimensionality r is equal to the data space dimensionality d and (b) the latent space dimensionality k is not smaller than r then there is a sequence of encoder-decoder pairs achieving the global minimum of the VAE objective and simultaneously (a) zeroing the variational gap and (b) precisely matching the true data distribution. In other words, in this setting the variational bound and the Gaussian model does not prevent the true data distribution from being recovered.\n\n2. In other cases Gaussian VAEs may not recover the actual distribution, but they will recover the real manifold (Theorems 2, 3, 4 and discussions on page 5).\nIn case when r < d, that is when the data distribution is supported on a low dimensional smooth manifold in the input space, things are quite different. The authors show that there are still sequences of encoder-decoder pairs which achieves the global minimum of the VAE objective. However, this time only *some* of these sequences converge to the model which is in a way indistinguishable from the true data distribution (and thus again Gaussian VAEs do not fundamentally prevent the true distribution from being recovered). Nevertheless, all sequences mentioned above recover the true data manifold in that (a) the optimal encoder learns to use r dimensional linear subspace in the latent space to encode the inputs in a lossless and noise-free way, while filling the remaining k - r dimensions with a white Gaussian noise and (b) the decoder learns to ignore the k - r noisy dimensions and use the r ""informative"" dimensions to produce the outputs perfectly landing on the true data manifold. \n\nMain algorithmic contributions:\n(0) A simple 2 stage algorithm, where first a vanilla Gaussian VAE is trained on the input dataset and second a separate vanilla Gaussian VAE is trained to match the aggregate posterior obtained after the first stage. The authors support this algorithm with a reasonable theoretical argument based on theoretical insights listed above (see end of page 6 - beginning of page 7). The algorithm achieves state-of-art FID scores across several data sets among AE based models existing in the literature. \n\nReview summary: \nI would like to say that this paper was a breath of fresh air to me. I really liked how the authors make a strong point that *it is not the Gaussian assumptions that harm the performance of VAEs* in contrast to what is usually believed in the field nowadays. Also, I think *the reported FID scores alone may be considered as a significant enough contribution*, because to my knowledge this is the first paper significantly closing the gap between generative quality of GAN-based models and non-adversarial AE-based methods. \n\n***************\n*** Couple of comments and typos:\n***************\n(0) Is the code / checkpoints going to be available anytime soon?\n(1) I would mention [2] which in a way used a very similar approach, where the aggregate posterior of the implicit generative model was modeled with a separate implicit generative model. Of course, two approaches are very different ([2] used an adversarial training to match the aggregate posterior), however I believe the paper is worth mentioning.\n(2) In light of the discussion on page 6 as well as some of the conclusions regarding commonly reported blurriness of the VAE models, results of Section 4.1 of [3] look quite relevant. \n(3) It would be nice to specify the dimensionality of the Sz matrix in definition 1.\n(4) Line ater Eq. 3: I think it should be $\\int p_gt(x) \\log p_\\theta(x) dx$ ?\n(5) Eq 4: p_\\theta(x|x)\n(6) Page 4: ""... mass to most all measurable..."".\n(7) Eq 34. Is it sqrt(\\gamma_t) or just \\gamma_t?\n(8) Line after Eq 40. Why exactly D(u^*) is finite?\n\nI only checked proofs of Theorems 1 and 2 in details and those looked correct. \n\n[1] Lucic et al., 2018.\n[2] Zhao et al., Adversarially regularized autoencoders, 2017, http://proceedings.mlr.press/v80/zhao18b.html\n[3] Bousquet et al., From optimal transport to generative modeling: the VEGAN cookbook. 2017, https://arxiv.org/abs/1705.07642']","[-20, -20, 90]","[60, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's potential value and interesting mathematical insights, they express significant concerns about the scope, methodology, and claims made. The reviewer lists more cons than pros and suggests major revisions are needed for the paper to be acceptable. However, the edit at the end indicates a more positive view after the authors' response, which somewhat mitigates the initial negative sentiment. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging the authors' work and providing constructive feedback. They use phrases like 'I thank the authors', 'I believe it has the potential', and frame criticisms as suggestions for improvement rather than harsh judgments. The tone remains professional and courteous even when pointing out flaws."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('interesting properties', 'proposed a two-stage VAE method'), they express 'several concerns' and raise multiple questions about the methodology and its advantages. This indicates a somewhat critical stance. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout. They frame their concerns as questions or suggestions rather than direct criticisms, using phrases like 'It is necessary to explain' and 'I still can't understand' which maintain a polite tone while expressing their doubts. The reviewer also acknowledges positive aspects before presenting their concerns, which is a polite approach in academic discourse."", ""The sentiment score is 90 because the reviewer expresses strong positive sentiment throughout the review. They describe the paper as 'a breath of fresh air', praise its 'novel interesting theoretical results', and highlight the 'very impressive' quality of samples. The reviewer also states that the reported FID scores alone could be considered a significant contribution. The politeness score is 80 because the reviewer uses respectful and professional language throughout. They offer constructive feedback and suggestions for improvement without any harsh criticism. The reviewer also acknowledges the authors' efforts and contributions positively. The slightly lower politeness score (compared to sentiment) is due to the direct nature of some comments, which is typical in academic reviews but not overly effusive in politeness.""]"
"['The paper proposes a method to check if a given point is a stationary point or not (if not, it provides a descent direction), and then classify stationary points as either local min or second-order stationary. The method works for a specific non-differentiable loss.  In the worst case, there can be exponentially many flat directions to check (2^L), but usually this is no the case.\n\nOverall, I\'m impressed. The analysis seems solid, and a lot of clever ideas are used to get around issues (such as exponential number of regions, and non-convex QPs that cannot be solved by the S-procedure or simple tricks). A wide-variety of techniques are used: non-smooth analysis, recent analysis of non-convex QPs, copositive optimization.\n\nThe writing is clear and makes most arguments easy to follow.\n\nThere are some limitations:\n\n(1) the technical details are hard to follow, and most are in a lengthy appendix, which I did not check\n\n(2) there was no discussion of robustness. If I find a direction eta for which the directional derivative is zero, what do you mean by ""zero""? This is implemented on a computer, so we don\'t really expect to find a directional derivative that is exactly zero.  I would have liked to see some discussions with epsilons, and give me a guarantee of an epsilon-SOSP or some kind of notion.  In the experiments, this isn\'t discussed (though another issue is touched on a little bit: you wanted to find real stationary points to test, but you don\'t have exactly stationary points, but rather can get arbitrarily close).  To make this practical, I think you need a robust theory.\n\n(3) The numerical simulations mainly provided some evidence that there are usually not too many flat directions, but don\'t convince us that this is a useful technique on a real problem.  The discussion about possible loss functions at the end was a bit opaque.  Furthermore, if you can\'t find a dataset/loss, then why is this technique useful?\n\nThe paper is interesting and novel enough that despite the limitations, I am supportive of publishing it. It introduces new ideas that I find refreshing. The technique many not ever make it into the state-of-the-art algorithms, but I think the paper has intellectual value regardless of practical value.\n\nIn short, quality = high, clarity=high, originality=very high, and significance=hard-to-predict', 'Summary:\nThis work proposes a theoretical algorithm for checking local optimality and escaping saddles when training two-layer ReLU networks. The proposed ""checking algorithm"" involves solving convex and non-convex quadratic programs (QP) which can be done in polynomial time. The paper is well organized and technically correct with detailed proofs.\n\nComments:\n1) Applicability issue: the conditions required by the proposed checking algorithm are too ideal, making it difficult to apply in practical applications. For example, the first step of the proposed algorithm is to check whether 0 belongs to the subdifferential. In practice, the iterates may get very close to a stationary point, but arriving to a stationary point might be too time-consuming and unrealistic. If the problem is smooth, then the gradient is expected to be small so that one can easily relax this first order optimality condition by allowing a small gradient. However, since here the problem is nonsmooth, in general the subgradient could be still very large even when the iterate is very close to a stationary point.  Therefore, one would need to relax the ideal conditions in the proposed algorithm to make it more applicable.\n\n2) Another concern is that the efficiency of the proposed method relies too much on the empirical result that the number of flat extreme ray is small. The computational complexities for the test of the local optimality is exponentially depending on the number of flat extreme rays. Thus to guarantee a high efficiency of the proposed test algorithm and to make the main theory sound, it is important to provide a theoretical bound on this number. Without appropriate theoretical guarantees on the upper-bound of this number, it is not persuasive to claim that the proposed theoretical algorithm is of high efficiency.\n \n3) The computational complexity is proportional to the number of training data points which could be huge. Is it possible to have a stochastic version?\n\nTypos:\n1) On page 2, under Section 2, ``$h(t):=$"" should be ``$h(x):=$""\n\n2) In section 2.1, at the end of the paragraph ""Bisection by boundary data points"": change $b_1$ by $\\delta_1$ in ``$\\Delta_1x_i+b_1$"".\n\n3) On page 4, when defining B_k, change x by x_i. \n\n4) On page 5, above Lemma 1, when defining C_k, N(x_i) is not well defined.', 'This paper proposes an efficient method to test whether a point is a local minimum in a 1-hidden-layer ReLU network. If the point is not a local minimum, the algorithm also returns a direction for descending the value of the loss function. \n\nThe tests include a first-order stationary point test (FOSP), and a second-order stationary point test (SOSP). As these test can be written as QPs, the core challenge is that if there are M boundary points in the dataset, i.e.,  data points on a non-differentiable region of the ReLU function, then the FOSP test requires 2^M tests of extreme rays -- each boundary partition the whole space into at least two parts. This paper observes that since the feasible sets are pointed polyhedral cones. Therefore checking only these extreme rays suffices. This results in an efficient test with only 2M tests. \n\nLastly, the paper performs experiments on synthetic data. It turns out there are surprisingly many boundary points.\n\nComments:\nThis paper proposes an interesting method of testing whether a given point is a local minimum or not in a ReLU network. The technique is non-trivial and requires some key observation to make it computationally efficient. However, I have the following concerns:\n1) such a test may need very high numeric precision. For instance, you cannot make sure whether a floating point number is strictly greater than 0 or not. The small error may critically affect the property of a point. \n2) boundary points of a ReLU network should have measure 0 (correct me if not). The finding in the experiment shows surprisingly many boundary points. This is counter-intuitive. Is it because of numeric issues? You might misclassify non-boundary points.\n3) Usefulness. \n    a. The paper claims that such a test would be very useful in practice. However, they cannot even perform an experiment on real datasets. \n    b. Such a method only works for one-hidden layer network. It is not clear deeper network admit similar structure. \n    c. Practical training of neural-network usually trains the network using SGD, which always obtain a solution with a non-zero gradient. In this sense, there is no need for such a testing. \n    d. It seems like it is much easier to perform a test with different activation function, e.g., sigmoid.\n    \nIf the authors can address these concerns convincingly, I would be happy to change the rating.\n', 'Updates:\nAuthor(s) acknowledged that they cannot get a robust analysis. Furthermore, the optimality test also requires a robust analysis. Therefore, I believe the current version is still incomplete so I changed my score. I encourage author(s) to add the robust analysis and submit to the next top machine learning conference.\n\n-------------------------------------------\nPaper Summary:\nThis paper gives a new algorithm to check whether a given point is a (generalized) second-order stationary point if not, it can return a strict descent direction even at this point the objective function (empirical risks of two-layer ReLU or Leaky-ReLU networks) is not differentiable.\nThe main challenge comes from the non-differentiability of ReLU. While testing a second-order stationary point is easy, because of the non-differentiability, one needs to test 2^M regions in the ReLU case. This paper exploits the special structure of two-layer ReLU network and shows it suffices to check only the extreme rays of the polyhedral cones which are the feasible sets of these 2^M linear programs. \n\nComments:\n1. About Motivation. While checking the optimality on a non-differentiable point is a  mathematically interesting problem, it has little use in deep learning.  In practice, SGD often finds a global minimum easily of ReLU-activated deep neural networks [1].\n2. This algorithm can only test if a point is a real SOSP. In practice, we can only hope to get an approximate SOSP. I expect a robust analysis, i.e., can we check whether it is a (\\epsilon,\\delta) SOSP?\n3. About writing: g(z,\\eta) and H(z,\\eta) appear in Section 1 and Section 2, and they are used to define generalized SOSP. However, their formal definitions are in Lemma 2. I suggest give the formal definitions in Section 1 or Section 2 and give more intuitions on their formulas.\n\nMinor Comments:\n1. Many typos in references, e.g., cnn -> CNN.\n2. Page 4: Big-Oh -> Big O.\n\n\n\nOverall I think this paper presents some interesting ideas but I am unsatisfied with the issues above. I am happy to see the authors’ response, and I may modify my score. \n\n\n[1] Zhang, C., Bengio, S., Hardt, M., Recht, B., & Vinyals, O. (2016). Understanding deep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530.\n']","[70, -20, -50, -50]","[80, 60, 50, 50]","[""The sentiment score is 70 (positive) because the reviewer expresses being 'impressed' with the paper, praising its solid analysis, clever ideas, and originality. They are supportive of publishing it despite some limitations. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively pointing out areas for improvement. They use phrases like 'I'm impressed' and 'The writing is clear,' which contribute to a positive tone. The reviewer also balances criticism with praise, showing consideration for the authors' work. The high scores in quality, clarity, and originality further support these assessments."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper is 'well organized and technically correct', they raise several significant concerns about the applicability and efficiency of the proposed method. The reviewer points out that the conditions required by the algorithm are 'too ideal' and may be difficult to apply in practice. They also express concern about the reliance on empirical results without theoretical guarantees.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They begin with positive comments about the paper's organization and technical correctness. When raising concerns, they use phrases like 'Another concern is...' and 'Is it possible to...' rather than using harsh or dismissive language. The reviewer also helpfully points out typos, which is a constructive way to improve the paper. The language is consistently formal and academic, avoiding any personal attacks or overly negative phrasing."", ""The sentiment score is -50 because while the reviewer acknowledges the paper's interesting method and non-trivial technique, they express several significant concerns about the work. The reviewer states they would be 'happy to change the rating' if these concerns are addressed, indicating a current negative sentiment. However, it's not extremely negative as they recognize some positive aspects. The politeness score is 50 because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting concerns. They use phrases like 'correct me if not' and offer to reconsider their rating, which shows politeness. The tone is professional and constructive, without any rudeness, but also not overly formal or deferential."", ""The sentiment score is -50 because the reviewer expresses dissatisfaction with the paper's current state, stating it is 'incomplete' and encouraging the authors to add robust analysis and resubmit. The reviewer also points out several issues and limitations of the work. However, the score is not extremely negative as the reviewer acknowledges some 'interesting ideas' and is open to modifying their score based on the authors' response. The politeness score is 50 because the reviewer uses respectful language throughout, offers constructive criticism, and expresses willingness to consider the authors' response. The reviewer also uses phrases like 'I suggest' and 'I encourage' which are polite ways of offering recommendations. The tone is professional and not overly harsh, despite the critical content.""]"
"['## Overview\n\nThis paper proposes a new way to stabilize the training process of GAN by regularizing the Discriminator to be robust to adversarial examples. Specifically, this paper proves that a discriminator which is robust to adversarial attacks also leads to a robust minimax objects. Authors provide theoretical analysis about the how the robustness of the Discriminator affects the properties of the objective function, and the proposed regularization term provides an efficient and effective way to regularize the discriminator to be robust. However, it does not build connection between the robustness of the Discriminator and why it can provide meaningful gradient to the Generator. Experimental results demonstrate the effectiveness of the proposed method. This paper is easy to understand.\n\n\n## Drawbacks\nThere are some problems in this paper. First, this paper is not highly motivated and lacks of intuition. I can hardly understand why the robustness can stabilize the training of GAN. Will it solve the problem of gradient vanishing problem or speed up the convergence of GAN? The toy example in Sec. 4.2 shows that it can regularize the Discriminator to provide a meaningful gradient to Generator, but no theoretical analysis is provided. The main gap between them is that the smoothness of D around the generated data points does not imply the effectiveness of gradients. Second, the theoretical analysis is inconsistent with the experimental settings. Theorem 4.3 holds true when f is non-positive, but WGAN’s loss function can be positive and this paper does not give any details about this part. Third, in Sec. 4.2, I can hardly distinguish the difference between robust loss, robust discriminator and regularized objectives.\n\nBesides, there are lots of typos in this paper. In Sec 3, Generative Adversarial Networks part, the notations of x and z are quiet confusing. In Definition 3.2, d which measures the distance between network outputs is not appeared above.\n\n## Summarization\nGenerally, this paper provides a novel way to stabilize the training of GAN. However, it does not illustrate its motivation clearly and no insight is provided.\n\n## After rebuttal\nSome of the issues are addressed. So I change my rating to 6.\n', ""The main idea that this paper presents is that making a discriminator robust to adversarial perturbations the GAN objective can be made smooth which results in better results both visually and in terms of FID. In addition to the  proposed adversarial regularisation the authors also propose a much stronger regularisation called robust feature matching which uses the features of the second last layer of the discriminator. I find the ideas presented in this paper interesting and novel.\nThe authors' claims are supported with sufficient theory and several experiments that prove their claims. The presented results show consistent improvements in terms of FID and actually some of the improvements reported are impressive"", ""The paper proposed a systematic way of training GANs with robustness regularization terms. Using the proposed method, training GANs is smoother and  \n\npros\n- The paper is solving an important problem of training GANs in a robust manner. The idea of designing regularization terms is also explored in other domains of computer vision research, and it's nice to see the its power in training GANs.\n- The paper provides detailed proofs and analysis of the approach, and visualizations of the regularization term help people to understand the ideas.\n- The presentation of the approach makes sense, and experimental results using several different GANs methods and competing regularization methods are extensive and good in general\n\ncons\n- I didn't find major issues of the paper. I think code in the paper should be made public as it could potentially be very useful for training GANs in general.""]","[-20, 80, 80]","[50, 50, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g. 'provides theoretical analysis', 'experimental results demonstrate effectiveness'), they also point out several significant drawbacks and issues. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (50) as the reviewer uses professional and respectful language throughout, avoiding harsh criticism and acknowledging both strengths and weaknesses. They provide constructive feedback and suggestions for improvement rather than outright dismissal of the work."", ""The sentiment score is 80 (positive) because the reviewer expresses clear approval of the paper, describing the ideas as 'interesting and novel' and noting 'consistent improvements' and 'impressive' results. The reviewer also states that the authors' claims are 'supported with sufficient theory and several experiments'. The politeness score is 50 (somewhat polite) because while the language is professional and respectful, it doesn't contain overtly polite phrases. The reviewer provides a balanced and objective assessment without using particularly formal or deferential language."", ""The sentiment score is 80 (positive) because the review is overwhelmingly positive. The reviewer states that the paper solves an important problem, provides detailed proofs and analysis, and has extensive and good experimental results. The only con mentioned is minor (making the code public). The politeness score is 70 (polite) because the language used is respectful and constructive. The reviewer uses phrases like 'it's nice to see' and 'I didn't find major issues', which are polite ways of expressing opinions. The reviewer also balances praise with a minor suggestion for improvement, which is a polite approach to feedback.""]"
"['PAPER SUMMARY\n-------------\n\nThe paper proposes a method for evaluating the failure probability of a learned agent, which is important in safety critical domains. \n\nUsing plain Monte Carlo for this evaluation can be too expensive, since discovering a failure probability of epsilon requires on the order of 1/epsilon samples. Therefore the authors propose an adversarial approach, which focuses on scenarios which are difficult for the agent, while still yielding unbiased estimates of failure probabilities. \n\nThe key idea of the proposed approach is to learn a failure probability predictor (FPP). This function attempts to predict at which initial states the system will fail. This function is then used in an importance sampling scheme to sample the regions with higher failure probability more often, which leads to higher statistical efficiency.\nFinding the FPP is itself a problem which is just as hard as the original problem of estimating the overall failure probability. However, the FPP can be trained using data from different agents, not just the final agent to be evaluated (for instance the data from agent training, containing typically many failure cases). The approach hinges on the assumption that these agents tend to fail in the same states as the final agent, but with higher probability. \n\nThe paper shows that the proposed method finds failure cases orders of magnitude faster than standard MC in simulated driving as well as a simulated humanoid task. Since the proposed approach uses data acquired during the training of the agent, it has more information at its disposal than standard MC. However, the paper shows that the proposed method is also orders of magnitudes more efficient than a naive approach using the failure cases during training.\n\n\nREVIEW SUMMARY\n--------------\n\nI believe that this paper addresses an important problem in a novel manner (as far as I can tell) and the experiments are quite convincing.\nThe main negative point is that I believe that the proposed method has some flaws which may actually decrease statistical efficiency in some cases (please see details below).\n\n\nDETAILED COMMENTS\n-----------------\n\n- It seems to me that a weak point of the method is that it may also severly reduce the efficiency compared to a standard MC method. If the function f underestimates the probability of failure at certain x, it would take a very long time to correct itself because these points would hardly ever be evaluated. It seems that the paper heuristically addresses this to some extent using the exponent alpha of the function. However, I think there should be a more in-depth discussion of this issue. An upper-confidence-bound type of algorithm may be a principled way of addressing this problem.\n\n- The proposed method relies on the ability to initialize the system in any desired state. However, on a physical system, where finding failure cases is particularly important, this is usually not possible. It would be interesting if the paper would discuss how the proposed approach would be used on such real systems.\n\n- On page 6, in the first paragraph, the state is called s instead of x as before. Furthermore, the arguments of f are switched.', 'This paper proposed an adversarial approach to identifying catastrophic failure cases in reinforcement learning. It is a timely topic and may have practical significance. The proposed approach is built on importance sampling for the failure search and function fitting for estimating the failure probabilities. Experiments on two simulated environments show significant gain of the proposed approaches over naive search. \n\nThe reviewer is not familiar with this domain, but the baseline, naive search, seems like straightforward and very weak. Are there any other methods for the same problem in the literature? The authors may consider to contrast to them in the experiments. \n\nWhat is the certainty equivalence approach? A reference would be helpful and improve the presentation quality of the paper.\n\nWhat is exactly the $\\theta_t$ in Section 3.3? What is the dimension of this vector in the experiments? What quantities should be encoded in this vector in practice? \n\nI am still concerned about the fact that the FPP depends on the generalization of the binary classification neural network, although the authors tried to give intuitive examples and discussions. Nonetheless, I understand the difficulty. Could the authors give some conditions under which the approach would fail? Any alternative approaches to the binary neural network? What is a good principle to design the network architecture? \n\nOverall, this paper addresses a practically significant problem and has proposed reasonable approaches. While I still have concerns about the practical performance of the proposed methods, this work along the right track in my opinion.\n\n', 'Summary:\nProposes an importance sampling approach to sampling failure cases for RL algorithms. The proposal distribution is based on a function learned via a neural network on failures that occur during agent training. The method is compared to random sampling on two problems where the ""true"" failure probability can be approximated through random sampling. The IS method requires substantially fewer samples to produce failure cases and to estimate the failure probability.\n\nReview:\nThe overall approach is technically sound, and the experiments demonstrate a significant savings in sampling compared to naive random sampling. The specific novelty of the approach seems to be fitting the proposal distribution to failures observed during training. \n\nI think the method accomplishes what it sets out to do. However, as the paper notes, creating robust agents will require a combination of methodologies, of which this testing approach is only a part. \n\nI wonder if learning the proposal distribution based on failures observed during training presents a risk of narrowing the range of possible failures being considered. Of course identifying any failure is valuable, but by biasing the search toward failures that are similar to failures observed in training, might we be decreasing the likelihood of discovering failures that are substantially different from those seen during training? One could imagine that if the agent has not explored some regions of the state space, we would actually like to sample test examples from the unexplored states, which becomes less likely if we preferentially sample in states that were encountered in training.\n\nThe paper is well-written with good coverage of related literature. I would suggest incorporating some of the descriptions of the models and methods in Appendix D into the main paper.\n\nComments / Questions:\n* Sec 4.2: How are the confidence bounds for the results calculated?\n* What are the ""true"" failure probabilities in the experiments?\n* Sec 4.3: There is a reference to non-existant ""Appendix X""\n\nPros:\n* Overall approach is sound and achieves its objectives\n\nCons:\n* Small amount of novelty; primarily an application of established techniques']","[50, 50, 50]","[80, 70, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer begins by stating that the paper addresses an important problem in a novel manner and that the experiments are convincing. However, they also mention a 'main negative point,' which balances out the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively pointing out areas for improvement. They use phrases like 'I believe' and 'It would be interesting if' which maintain a courteous tone. The reviewer also provides specific, detailed feedback without using harsh or dismissive language, demonstrating professional courtesy."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's timely topic, practical significance, and reasonable approach. They state it's 'along the right track' despite some concerns. The politeness score is 70 (fairly polite) due to the reviewer's constructive tone, use of phrases like 'may consider' and 'could the authors', and acknowledgment of the difficulty of the problem. The reviewer raises concerns and questions but does so in a respectful manner, balancing critique with positive feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges that the approach is technically sound and achieves its objectives, while also offering constructive criticism and suggestions for improvement. The overall tone is balanced, recognizing both pros and cons. The politeness score is 75 (quite polite) due to the reviewer's use of respectful language throughout, offering suggestions rather than demands, and acknowledging the paper's strengths. The reviewer uses phrases like 'I think' and 'I wonder' to soften critiques, and provides a mix of positive feedback and areas for improvement in a professional manner.""]"
"[""The paper is well written and easy to read. Exploration is one of the fundamental problems in RL, and the idea of using two agents for better exploration is interesting and novel. However, an explanation of the intuition behind the method would be useful. The experimental results show that the method works well in complex tasks. Since states are compared to each other in L2 distance, the method might not generalize to other domains where L2 distance is not a good distance metric.\n\nPros:\n- well written\n- a simple and novel idea tackling a hard problem\n- good results on hard tasks\n\nCons: \n- an explanation of why the method should work is missing\n- plot text is too small (what is the unit of X-axis?)\n\nQuestions:\n- what is the intuition behind the method?\n- during training, randomly sampled two states are compared. why it is a good idea? how the replay buffer size will affect it?\n- since it is a two-player game, is there anything you can say about its Nash equilibrium? \n- why A is better than B at the task?\n- when comparing states, are whole raw observations (including velocity etc.) used?\n- section 4.2 doesn't seem to be that relevant or helpful. is it really necessary? \n- fig 4 is missing CER alone results? why is that? it doesn't work by itself on those tasks? "", 'The authors propose a states relabeling strategy (CER) to encourage exploration in RL algorithms by organizing a competitive game between a pair of agents. \nTo verify their strategy, they extend MADDPG as their framework. Then, they compare the performance of agents trained with HER, and both variants of CER, and both variants of CER with HER. The experiments show that CER can improve the performance of HER with faster converge and higher accuracy.\n\nMy major concerns are as follows.\n1.\tThe authors may want to conduct more experiments to compare CER with other state-of-the-art methods such as PPO[1]. As illustrated in Figure 1, the performance of HER is better than that of CER. The authors may want to analyze whether CER strategy alone could properly address the sparse reward problems, and why CER strategy can improve HER. The authors have mentioned that CER is “orthogonal” to HER. I suggest authors provide more discussions on this statement. \n2.\tThe authors may want to improve the readability of this paper. \nFor example, in Figure 1, the authors may want to clarify the meanings of the axes and the plots. \nThe results shown in Figure 3 are confusing. How can the authors come to the conclusion that the optimal conﬁguration requires balancing the batch sizes used for the two agents? \nTo better illustrate the framework of CER, the authors may want to show its flow chart.\n3.\tThere are some typos. For example, in Section 2.1, the authors use T(s’|s,a) without index t; in Section 2.2, the authors use both Q(a,s,g) and Q(s,a,g). \nThere is something wrong with the format of the reference (“Tim Salimans and Richard Chen … demonstration/, 2018.”) in the bottom of page 10.\n\n[1] Schulman J, Wolski F, Dhariwal P, et al. Proximal Policy Optimization Algorithms[J]. 2017.\n\n', 'The authors propose a new method for learning from sparse rewards in model-free reinforcement learning settings. This is a challenging and important problem in model-free RL, mainly due to the lack of effective exploration. They propose a new way of densifying the reward by encouraging a pair of agents to explore different states (using competitive self-play) while trying to learn the same task. One of the agents (A) receives a penalty for visiting states that the other agent (B) also visits, while B is rewarded for visiting states found by A. They evaluate their method on a few tasks with continuous action spaces such as ant navigation in a maze and object manipulation by a simulated robotic arm.  Their method shows faster convergence (in some cases) and better performance than comparable algorithms.\n  \n\nStrengths:\nAttempts to solve a long-standing problem in model-free RL (effective exploration in sparse reward environments)\nClear writing and structure, easy to understand (except for some minor details)\nNovel, intuitive, and simple method building on ideas from previous works\nGood empirical results (better than state of the art, in terms of performance) on some challenging tasks\n\nWeaknesses:\nNot very clear why (and when) the method works -- more insight from experiments in less complex environments or some theoretical analysis would be helpful\nIt would also be useful to better understand the conditions under which we can expect this to bring significant gains and when we can expect this to fail (or not help more than other methods) \nNot clear how stable (to train) and robust (to different environment dynamics) the method is\n\n\nMain Comments / Questions:\nThe paper makes the claim that their technique “automatically generates a curriculum of exploration” which seems to be based more on intuition rather than clear experiments or analysis. I would suggest to either avoid making such claims or include stronger evidence for that. For example, you could consider visualizing the visited states by A and B (for a fixed goal and initial state) at different training epochs. Other such experiments and analysis would be very helpful.\nIt is known that certain reward shaping approaches can have negative consequences and lead to undesired behaviors (Ng et al., 1999; Clark & Amodei, 2016). Why can we expect that this particular type of reward shaping doesn’t have such side effects? Can it be the case that due to this adversarial reward structure, A learns a policy that takes it to some bad states from which it will be difficult to recover or that A & B get stuck in a cyclic behavior? Have you observed such behaviors in any of your experiments?\nDo you train the agents with using the shaped reward (from the exploration competition between A and B) for the entire training duration? Have you tried to continue training from sparse reward only (e.g. after the effect ratio has stabilized)? One problem I see with this approach is the fact that you never directly optimize the true sparse reward of the tasks, so in the late stages of training your performance might suffer because the agent A is still trying to explore different parts of the state space. \nCan you comment on how stable this method is to train (given its adversarial nature) and what potential tricks can help in practice (except for the discussion on batch size)?\nPlease make clear the way you are generating the result plots (i.e. is A evaluated on the full task with sparse reward and initial goal distribution with no relabelling?).\nIn Algorithm 1, can you include the initialization of the goals for A and B? Does B receive identical goals as A?\nIt would also be helpful to more clearly state the limitations and advantages of this method compared to other algorithms designed for more efficient exploration (e.g. the need for a resettable environment for int-CER but not for ind-CER etc.).\n\n\nMinor Comments / Questions:\nYou might consider including more references in the Related Work section that initializing from different state distributions such as Hosu & Rebedea (2016), Zhu et al. (2016), and Kakade & Langford (2002), and perhaps more papers tackling the exploration problem. \nCan you provide some intuition on why int-CER performs better than ind-CER (on most tasks) and why in Figure 1, HER + int-CER takes longer to converge than the other methods on the S maze?\nIn Figure 4, why are you not including ind-CER (without HER)?\nHave you considered training a pool of agents with self-play (for the competitive exploration) instead of two agents? Is there any intuition on expecting one or the other to perform better?\n\n\nPlots:\nWhat is the x-axis of the plots? Number of samples, episodes, epochs? Please label it.\nPlease be explicit about the variance shown in the plots. Is that the std?\nIt would be helpful if to have larger numbers on the xy-axes. It is difficult to read when on paper.\nCan you explain how you smoothed the curves -- whether before or after taking the average and perhaps include the min and max as well. I believe this could go in the Appendix.\n\nNotation:\nI don’t understand the need for calling the reward r_g instead of r. I believe this introduces confusion since the framework already has r taking as argument the goal g (eq. 1) while the g in the subscript doesn’t seem to refer to a particular g but rather to a general fact (that this is a reward for a goal-oriented task with sparse reward, where the goals are a subset of the states) (eq. 4)\nPlease use a consistent notation for Q. In sections 2.1 and 2.2, at times you use Q(s,a,g), Q(a,s,g) or Q(s,a).\n\nTypos:\nPage 6, last paragraph of section 4.1: Interestingly, even the … , is enough to support …\nPage 7, last paragraph of section 4.3: Interestingly, … adversely affects both ...\n\n', 'The author proposes to use a competitive multi-agent setting for encouraging exploration.\n\nI very much agree with most of previous reviewers, and their constructive suggestions. However, I find a major issue with this paper is the lack of baseline comparisons. The paper shows that CER + HER > HER ~ CER. I do not think CER should be compared to HER at all. CER to me attacks the exploration problem in a very different way than HER. It is not trying to ""reuse"" experience, which is the core in HER; instead, it uses 2 agents and their competition for encouraging visiting new states. This method should be compared to method that encourages exploration via some form of intrinsic motivation. There are methods proposed in the past, such as [1]/[2] that uses intrinsic motivation/curiosity driven prediction error to encourage exploration. Note that these methods are also compatible with HER. I\'d suggest comparing CER with one of these methods (if not all) both with and without HER.\n\nMinor:\nIn the beginning paragraph of 3.1, the paper states: \n""\nWhile the re-labelling strategy introduced by HER provides useful rewards for training a goal-conditioned\npolicy, it assumes that learning from arbitrary goals will generalize to the actual task goals. As such,\nexploration remains a fundamental challenge for goal-directed RL with sparse reward. We propose a relabelling\nstrategy designed to overcome this challenge.\n""\nI think overcoming this particular challenge is a bit overstating. The method proposed in this paper is not guaranteed to address the ""fundamental challenge"" either --- i.e., why can you assume that learning from arbitrary goals that results from the dynamics of two agents will generalize to the actual task goals?\n\nI will change my rating accordingly if there are more meaningful comparisons made in the rebuttal.\n\n[1] Curiosity-driven Exploration by Self-supervised Prediction, Pathak et. al.\n[2] Large-Scale Study of Curiosity-Driven Learning. Burda et. al.']","[50, -20, 50, -50]","[70, 60, 80, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer begins with positive comments about the paper being well-written and the idea being interesting and novel. They also mention good experimental results. However, they balance this with some criticisms and questions, indicating a mixed but generally positive sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions or questions rather than direct attacks. They acknowledge the paper's strengths before discussing areas for improvement, which is a polite approach. The use of 'Pros' and 'Cons' sections also provides a balanced and professional tone to the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the proposed strategy and its potential benefits, they express 'major concerns' and suggest several improvements and clarifications. The review is not entirely negative, as it recognizes the work's potential, but the emphasis on concerns and needed improvements indicates a somewhat negative sentiment. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, framing their concerns as suggestions ('The authors may want to...') rather than direct criticisms. They also provide specific, constructive feedback and even suggest additional references, which is helpful and courteous. The language is professional and avoids any harsh or rude phrasing, maintaining a polite tone while still conveying the need for improvements."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, such as addressing a challenging problem, clear writing, and good empirical results. However, they also point out several weaknesses and areas for improvement, balancing the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and phrases suggestions as questions or polite requests (e.g., 'Can you comment on...', 'Please make clear...'). The reviewer also acknowledges the paper's merits before discussing its limitations, which is a polite approach to peer review."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('I very much agree with most of previous reviewers'), they identify a 'major issue' with the paper, which is the lack of baseline comparisons. The reviewer suggests that the method should be compared to other exploration techniques, indicating significant room for improvement. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'I'd suggest' and 'I think', which are polite ways of offering feedback. The reviewer also acknowledges agreement with previous reviewers, showing respect for others' opinions. However, the review doesn't go out of its way to be overly polite, maintaining a professional tone.""]"
"['This paper builds upon recent work by Balestriero and Baraniuk (ICML 2018) that concern max-affine spline opertaor (MASO) interpretation of a substantial class of deep networks. In the new paper a special focus is put on Recurrent Neural Networks (RNNs), and it is highlighted based on theoretical considerations leveraging the MASO and numerical experiments that in the case of a piecewise affine and convex activation function, using noise in initial hidden state acts as regularization.  \nOverall I was impressed by the volume of contributions presented throughout the paper and also I very muched like the light shed on important classes of models that turn out to be not as black box as they could seem. My enthouasiasm was somehow tempered when discovering that the MASO modelling here was in fact a special case of Balestriero and Baraniuk (ICML 2018), but it seems that despite this the specific contribution is well motivated and justified, especially regarding application results. Yet, the other thing that has annoyed me and is causing me to only moderately champion the paper so far is that I found the notation heavy, not always well introduced nor explained, and while I believe that the authors have a clear understanding of things, it appears to me that the the opening sections 1 and 2 lack notation and/or conceptual clarity, making the paper hard to accept without additional care. To take a few examples:\na) In equation (3), the exponent (\\ell) in A and B is not discussed. On a different level, the term ""S"" is used here but doesn\'t seem to be employed much in next instances of MASOs...why? \nb) In equation (4), sure you can write a max as a sum with an approxiate indicator (modulo unicity I guess) but then what is called Q^{(\\ell)} here becomes a function of A^{(\\ell)}, B^{(\\ell)}, z^{(\\ell-1)}...?\nc) In proposition 1, the notation A_sigma is not introduced. Of course, there is a notation table later but this would help (to preserve the flow and sometimes clarify things) to introduce notations upon first usage...\nd) Still in prop 1, braket notation not so easy to grasp. What is A[z]z? \ne) Still in prop 1, recall that sigma is assumed piecewise-linear and convex? \nf) In th1, abusive to say that the layer ""is"" a mapping, isn\'t it?  \ng) In Theorem 2, what is f? A generic term for a deterministic function? \nAlso, below the Theorem, ""affine"" or ""piecewise affine""? \nh) I found section 4 somehow disconnected and flow-breaking. Put in appendix and use space to better explain the rest? \ni) Section 5 is a strong and original bit, it seems. Should be put more to the fore in abstract/intro/conclusion? ', 'In this paper, the authors provide a novel approach towards understanding\nRNNs using max-affine spline operators (MASO). Specifically, they rewrite RNNs\nwith piecewise affine and convex activations MASOs and provide some\nexplanation to the use of noisy initial hidden state. \n\nThe paper can be improved in presentation. More high level explanation should\nbe given on MASOs and why this new view of RNN is better. \n\nTo best of my knowledge, this is the first paper that related RNNs with MASOs\nand provides insights on this re-formulation. However, the authors failed to\nfind more useful applications of this new formulation other than finding that\nnoisy initial hidden state helps in regularization. Also, the re-formulation\nis restricted to piecewise affine and convex activation functions (Relu and\nleaky-Relu). \n\nIn general, I think this is an original work providing interesting viewing\npoint, but could be further improved if the authors find more applications of\nthe MASO form. \n', 'The paper rewrites equations of Elman RNN in terms of so-called max-affine spline operators. Paper claims that this reformulation allows better analysis and, in particular, gives an insight to use initial state noise to regularize hidden states and fight exploding gradients problem.\n\nThe paper seems to be theoretically sound. The experiment with sequential MNIST looks very promising, thought it would be great to check this method on other datasets (perhaps, toy data) to check that this is not a fluke. The bird audio dataset is not well benchmarked in the literature. The paper could make much stronger claim with more extensive experimentation.\n\nSome typos:\n- p3: an simple -> a simple\n- Figure 2 caption is not finished\n- p5 last paragraph: extra full stop\n- Fig 3: correct and negative probably switched around\n- p7: in regularize -> in regularization\n']","[20, 20, 50]","[30, 50, 70]","[""The sentiment score is slightly positive (20) because the reviewer expresses being 'impressed' by the volume of contributions and liking aspects of the paper. However, this enthusiasm is tempered by some criticisms, particularly about notation and clarity. The overall tone suggests moderate support ('only moderately champion the paper'). The politeness score is moderately positive (30) as the reviewer uses respectful language throughout, acknowledging the authors' understanding and providing constructive feedback. They use phrases like 'I was impressed' and 'I very much liked', which are polite. However, they also directly state criticisms, which keeps the score from being higher. The reviewer maintains a professional tone, offering specific suggestions for improvement without using harsh or rude language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and originality of the work, calling it 'the first paper' on this approach and 'an original work providing interesting viewing point'. However, they also point out areas for improvement, which tempers the positivity. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without harsh words. They use phrases like 'can be improved' and 'could be further improved' rather than more critical language. The reviewer also balances critique with praise, which contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper as 'theoretically sound' and finds the experiment with sequential MNIST 'very promising'. However, they also suggest more extensive experimentation and point out some typos, indicating room for improvement. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They use phrases like 'it would be great' and 'the paper could make much stronger claim', which are polite ways of suggesting improvements. The reviewer also helpfully points out specific typos, which is a courteous way to assist the authors in improving their paper.""]"
"['In this paper the authors propose a neural model that, given a logical formula as input, predicts whether the formula is a tautology or not. Showing that a formula is a tautology is important because if we can classify a formula A -> B as a tautology then we can say that B is a logical consequence of A. The structure of the formula is a feedforward neural network built in a top-down manner. The leaves of this network are vectors (each of them represents a particular occurrence of an atom) which, after the construction of the formula, are processed by some recurrent neural networks.\n\nThe proposed approach seems interesting. However, my main doubt concerns the model. It seems to outperform the state-of-the-art, but the authors do not give any explanations why. There is no theoretical or intuitive explanation of why the model works. Why we need RNNs and not feedforward NNs? I think this is an big issue.\nIn conclusion, I think that the paper is a bit borderline. The model should be better explained. However, I think that the approach is compelling and, after a minor revision, the paper could be considered for acceptance.\n\n[Minor comments]\nPage 4. \n“The dataset contains train (99876 pairs)”, pairs of what?\n\nPage 5. \nWhat is the measure of the values reported in Table 1? Precision? \n', 'Cons\n\n1.\tThere is no study of the representations developed by the model, which is unfortunate because this is a conference on learning representations and because there is little light shed on how the network achieves its rather high level of performance.\n2.\tIt seems less generally useful to have such a special-purpose network for computing global properties like tautologicality than to have a network that produces actual vector encodings of propositions, as typical of the bottom-up tree-structured models.\n\nPros\n\n3.\tThe paper is quite clear.\n4.\tThe problem is important.\n5.\tThe paper pursues the familiar path of a tree-structured network isomorphic to the parse tree of a propositional-calculus formula, but with the original twist of passing information top-down rather than bottom-up.\n6.\tThe results are impressively strong. In particular, it improves by 10% absolute over the special-purpose and highly performant PossibleWorldNet on the most difficult category of problems, the ‘massive’ category, achieving 83.6% accuracy.\n\nPro/Con mix\n\n7.\tAlthough the paper did not provide much insight into what was going on in the network to allow it to perform well (point 1 in ‘Cons’), I was able to convince myself I could understand a way the architecture *could* succeed (whether this possible approach matches the actual processing in the model I have no way of assessing). In brief, the vector that is passed down the network can be thought of as a list of truth values across multiple possible worlds of the tree node at which the vector resides. To search for a counterexample to tautologicalhood, the original input vector to the root node could be the zero (false) vector. If the kth value in the vector at a parent node labeled ‘or’ is 0 (the disjunction is false in world k) then in the two children the kth value must also be 0. If the kth value of the vector at an XOR node is 0, the kth value of the two children must both be 0 or both be 1; actually these values need not reside in position k so the children could both have value 0 at some position i and both have value 1 at another position j. Then in the RNN-Var component of the network, which checks for consistency across multiple tokens of the same proposition variable, each position k in all vectors for the same variable can be checked for equality, producing a value 1 in the output vector if all have value 1, producing 0 if all have value 0, and producing value -1 if the values do not all agree. Then RNN-All checks across all vectors for proposition variable types to see if there’s a position k in which no value -1 occurs; if so, the values of the variable vectors at position k give the truth values for all variables such that the overall proposition has the desired value 0: a counterexample exists. If no such position k exists, the proposition is a tautology. This seems roughly right, at least.', ""In this paper, the authors provide a new neural-net model of logical formulae. The key feature of the model is that it gathers information about a given formula by traversing its parse tree top-down. One neural net of the model traverses the parse tree of the formula from the root all the down toward the leaves, and generates vectors for the leaves of the tree. Then, another RNN-based neural net collects these generated vectors, and answers a query asked for the formula, such as logical entailment. When experimented with Evans et al.'s data set for logical entailment queries, the authors' model outperforms existing models that encode formulae by traversing their parse trees bottom-up.\n\nI found the idea of traversing a parse tree of a formula top-down and converting it to a vector very interesting. It is also good to know that the idea leads to a competitive model for at least one dataset. \n\nHowever, I am hesitant to be a strong supporter for this paper. I feel that the cons and pros of the model and its design decisions are not fully analyzed or explained in the paper; when reading this paper, I wanted to learn a rule of thumb for deciding when (and why if so) a top-down model of logical formulae works better than a bottom-up model. I understand that what I ask for is very difficult to answer, but experiments with more datasets and different types of queries (such as satisfiability) might have made me happier.\n\nHere are some minor comments.\n\n* Abstract: I couldn't quite understand your point about atoms. According to Figure 1, there is a neural net for each propositional symbol, and this means that your model tracks information about which occurrences of propositional symbols are about the same one. Is your point about the insensitivity of your model to a specific name given to each symbol? \n\n* p1: this future ===> this feature\n\n* p2: these constrains ===> these constraints\n\n* p2: recursively build model ===> recursively built model\n\n* p2: Change the font of R in the codomain of ci.\n\n* p3: p1 at the position of ===> p1 is at the position of\n""]","[-20, 50, 20]","[50, 75, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the approach as 'interesting' and 'compelling', they express significant doubts about the model's explanation and consider the paper 'borderline'. The reviewer suggests that 'after a minor revision, the paper could be considered for acceptance', indicating a cautiously optimistic view despite the concerns. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, framing criticisms as 'doubts' and 'issues' rather than outright flaws. They also offer constructive feedback and suggestions for improvement, which is a polite approach to reviewing. The use of phrases like 'I think' and 'it seems' further softens the critique, maintaining a courteous tone."", ""The sentiment score is 50 (slightly positive) because while the review lists some cons, it also highlights several pros and expresses admiration for the paper's results ('impressively strong', 'improves by 10% absolute'). The reviewer also demonstrates engagement with the work by providing their own understanding of how the model might function. The politeness score is 75 (quite polite) because the language used is professional and constructive throughout. The reviewer acknowledges the paper's strengths ('The paper is quite clear', 'The problem is important') and frames criticisms as suggestions for improvement rather than harsh judgments. The reviewer also takes time to explain their thought process, which shows respect for the authors' work."", ""The sentiment score is slightly positive (20) because the reviewer finds the idea interesting and acknowledges that it leads to a competitive model. However, they express hesitation in being a strong supporter and mention some concerns about the analysis and explanations in the paper. The politeness score is high (80) as the reviewer uses respectful language throughout, offers constructive criticism, and frames their concerns as personal opinions (e.g., 'I found', 'I am hesitant', 'I wanted to learn'). They also provide helpful minor comments in a neutral tone. The review maintains a professional and courteous tone while offering both positive feedback and areas for improvement.""]"
"[""update: The authors' feedback has addressed some of my concerns. I update my rating to 6.\n=================\noriginal:\nThis paper provides some new insights into classification bias. On top of the well known unbalanced group size, it shows that a large number of weak but asymmetry weak features also leads to bias. This paper also provides a method to reduces bias and remain the prediction accuracy.\n\nIn general, the paper is well written, but some description can be clearer. Some notation seems inconsistent. For example, D in equation (1) denotes the joint distribution (x,y), but it also refers to the marginal distribution of x somewhere else. \n\nIn the high level, I am not totally convinced of how significant the result is.  In particular, the bias this paper defines is on the probability (softmax) scale, but logistic regression is on logit scale--   not even aimed at the unbiasedness in the original scale. So the result in section 2 seems to be expected.  Given the fact that unbiasedness is not invariant under transformation, I am wondering why it should be the main target in the first place.  \n\nIn the bias reduction methods in equation 5 and 6, both the objective function and the constraint are empirical estimations. Will it be too noisy to adapt to the high dimensional setting? On the other hand, adding some sparsity regularization improves prediction seems well known in practice.\n\nI would also encourage the authors to have extended work both theoretically and experimentally.  The asymmetry feature is only illustrated by a single logistic regression. Is it a problem of weak features, or indeed a problem of logistic regression? What will happen in a more general case beyond mean-field Gaussian?  I would imagine in this simple case the authors may even derive the closed form expression to verify their heuristics.  \n\nBased on the evaluations above, I would recommend a weak reject. \n"", 'Summary:\n\nIn this paper the authors identify a specific source of marginal class probability bias that occurs when using logistic regression models. Using synthetic and real datasets they demonstrate this bias and explore characteristics of the data that exacerbate the issue. Finally, they propose two methods for correcting this bias in logistic regression models and neural network models with logistic output layers and evaluate these methods on several benchmark datasets.\n\nReview:\n\nOverall, I found the paper well-written, the problem well-motivated, and the proposed methods clear and reasonable. While I have a few concerns about presentation and experimentation, these are issues that can easily be remedied and I recommend acceptance.\n\nMajor comments:\n\n- The authors repeatedly say that gradient descent is the cause of the bias amplification (e.g. Section 2.2 title, ""...features that are systematically overestimated by gradient descent."", ""... i.e., a consequence of gradient descent\'s inductive bias."", ""... gradient descent may lead to systematic bias...""). The inductive bias they describe is coming from the use of logistic regression, not the use of gradient descent. Specifically, a logistic regression model has a convex likelihood, which means that regardless of what algorithm is used to maximize the likelihood, it should converge to the same point. In fact, most off-the-shelf implementations of logistic regression do not use vanilla gradient descent. Further, gradient descent may be used to estimate the parameters of any number of models which may or may not have the same inductive bias the authors describe.\n\n- I thought the related work section was well-written and would strongly recommend moving it to the beginning of the paper as it motivates the entire problem. I also think it could be helpful to ground the technical definitions of bias amplification in a meaningful example.\n\n- I think that the experimental setup for comparing \\ell_1 regularization to the proposed feature selection methods is not quite fair. In particular, the hyperparameters of the ""expert"" method are selected to minimize bias subject to the constraint that loss not increase. In contrast, the \\ell_1 regularization hyperparameter is selected purely to minimize bias. Instead, I would select the \\ell_1 regularization hyperparameter in the same way as the expert method, that is, to minimize bias subject to a constraint on loss. In general, I think hyperparameters should be selected using the same criterion for all methods.\n\n- The authors make a point of highlighting results on the ""prostate"" which showed a large increase in accuracy along with a large decrease in bias. I think the paper would benefit from some exploration of why this happened. Specifically, it would be valuable to answer the question: what are the properties of the ""prostate"" dataset that make this method so effective and are these properties general and identifiable a priori?\n\n- Section 2, paragraph 2, line 5: The stated goal in this paragraph is ""minimizing 0-1 loss on unknown future i.i.d. samples"". As stated in the introduction, this is, in fact, not the goal. The goal is to minimize loss while also minimizing bias. A larger criticism that I would have of this work is: if minimizing bias is a first order goal, then why are we using empirical risk minimization in the first place? Put another way, why use post-hoc correction for an objective function that does not match our actual stated goals rather than using an objective function that does?\n\nMinor comments:\n\n- Section 1, paragraph 4, line 2: ""Weak"" is not clearly defined here. Is it different than ""moderately-predictive""?\n\n- Section 2.1, last paragraph, line 1: I understand what the authors are saying when they say ""Bias amplification is unavoidable"", but it is avoidable by changing our objective function. I would consider rewording this statement to something like ""Using an ERM objective will lead to bias amplification when the learning rule...""\n\n- Equation 4: I believe h should be changed to f in this equation.\n\n- Equation 6: L is not defined anywhere.\n\n- Table 1: As defined in equation 1, B_D(h_s) should be between 0 and 1. Also, the accuracy results for the glioma dataset have the wrong result in bold.\n\n- Section 4, methodology paragraph, line 5: forthe --> for the\n\n- Section 5, paragraph 5, lines 5-6: Feature selection is not used ""only to improve accuracy"". For example, Kim, Shah, and Doshi-Valez (2015) use feature selection to improve interpretability (https://beenkim.github.io/papers/BKim2015NIPS.pdf).', 'In this paper, the authors studied bias amplification. They showed in some situations bias is unavoidable; however, there exist some situations in which bias is a consequence of weak features (features with low influence to the classifier and high variance). Therefore, they used some feature selection methods to remove weak features; by removing weak features, they reduced the bias substantially while maintaining accuracy (In many cases they even improved accuracy).  Showing that weak features cause bias is very interesting, especially in their real-world dataset in which they improved bias and accuracy simultaneously.  \n\n\nMy main concerns about this paper are its related work and its writing.\nAuthors did a great job in reviewing related work for bias amplification in NLP or vision. \nHowever, they studied bias amplification in binary classification, in particular, they looked at GNB; and they did not review the related work about bias in GNB.  I think it is clear that using MAP causes bias amplification. Therefore, I think changing theorem 1 to a proposition and shifting the focus of the paper to section 2.2 would be better. Right now, I found feature orientation and feature asymmetry section confusing and hard to understand. In the paper, the authors claimed bias is a consequence of gradient descent’s inductive bias, but they did not expound on the reasoning behind this claim. Although the authors ran their model on many datasets, there is no comparison with previous work. So it is hard to understand the significance of their work. It is also not clear why they don’t compare their model with \\ell_1 regularization in CIFAR.\n\n\nMinor:\n\nPaper has some typos that can be resolved.\nCitations have some errors, for example, Some of the references in the text does not have the year, One paper has been cited twice in two different ways, For more than two authors you should use et al., sometimes \\citet and \\citep are used instead of each other.\nAuthors sometimes refer to the real-world experiment without first explaining the data which I found confusing.']","[-20, 50, 20]","[50, 80, 60]","[""The sentiment score is -20 because while the reviewer acknowledges some positive aspects ('provides some new insights', 'well written'), they express significant concerns and ultimately recommend a 'weak reject'. The update at the beginning slightly improves the sentiment, but the overall tone remains critical. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement ('I would encourage the authors to have extended work'). They avoid harsh or rude phrasing, instead using diplomatic language like 'I am not totally convinced' and 'I would recommend'. The reviewer also balances criticism with positive remarks, which contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by saying they found the paper 'well-written, the problem well-motivated, and the proposed methods clear and reasonable.' They also recommend acceptance, which is positive. However, they do have several major and minor concerns, which tempers the positivity. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames their comments as suggestions rather than demands. They use phrases like 'I think', 'I would consider', and 'I recommend', which maintain a polite tone. The reviewer also balances criticism with praise, acknowledging the paper's strengths before diving into areas for improvement."", ""The sentiment score is slightly positive (20) because the reviewer begins with positive comments about the paper's interesting findings and the authors' good work on reviewing related literature. However, this is balanced by several concerns and criticisms raised later. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and framing criticisms as suggestions or concerns rather than harsh critiques. The reviewer uses phrases like 'My main concerns' and 'I think' to soften criticisms, and provides specific, constructive feedback. The tone remains professional and courteous even when pointing out areas for improvement.""]"
"['This is in a visual active tracking application. The paper proposes a novel reward function - ""partial zero sum"", which only encourages the tracker-target competition when they are close and penalizes whey they are too far.\n\nThis is a very interesting problem and I see why their contribution could improve the system performance. \n\nClarity: the paper is well-written. I also like how the author provides both formulas and a lot of details on implementation of the end-to-end system. \n\nOriginality: Most of the components are pretty standard, however I value the part that seems pretty novel to me - which is the ""partial zero-sum"" idea.\n\nEvaluation: the result obtained from the simulated environment in 2d and 3d are convincing. However, if 1) real-world test and results  2) a stronger baseline can be used, that would be a stronger acceptance. ', 'This paper presents a simple multi-agent Deep RL task where a moving tracker tries to follow a moving target. The tracker receives, from its own perspective, partially observed visual information o_t^{alpha} about the target (e.g., an image that may show the target) and the target receives both observations from its own perspective o_t^{beta} and a copy of the information from the tracker\'s perspective. Both agents are standard convnet + LSTM neural architectures trained using A3C and are evaluated in 2D and 3D environments. The reward function is not completely zero-sum, as the tracked agent\'s reward vanishes when it gets too far from a reference point in the maze.\n\nThe work is very incremental over Luo et al (2018) ""End-to-end Active Object Tracking and Its Real-world Deployment via Reinforcement Learning"", as the only two additions are extra observations o_t^{alpha} for the target, and a reward function that has a fudge factor when the target gets too far away. Citing Sun Tzu\'s ""Art of War"" (please use the correct citation format) is not convincing enough for adding the tracker\'s observations as inputs for the target agent. Should not the asymmetrical relationship work the other way round, with the tracker knowing more about the target?\n\nExperiments are conducted using two baselines for the target agent, one a random walk and another an agent that navigates to a target according to a shortest path planning algorithm. The ablation study shows that the tracker-aware observations and a target\'s reward structure that penalizes when it gets too far do help the tracker\'s performance, and that training the target agent helps the tracker agent achieve higher scores. The improvement is however quite small and the task is ad-hoc.\n \nThe paper would have benefitted from a proper analysis of the trajectories taken by the adversarial target as opposed to the heuristic ones, and from comparison with non-RL state-of-the-art on tracking tasks. Further multi-agent tasks could also have been considered, such as capture the flag tasks as in ""Human-level performance in first-person multiplayer games with population-based deep reinforcement learning"".', 'This work aims to address the visual active tracking problem in which the tracker is automatically adjusted to follow the target. A training mechanism in which tracker and the target serve as mutual opponents is derived to learning the active tracker. Experimental evaluation in both 2D and 3D environments is conducted.\n\nI think the contributions of this work is incremental compared with [Luo et al (2018)] in which the major difference is the partial zero sum reward structure is used and the observations and actions information from the tracker are incorporated into the target network, while the network architecture is quite similar to [Luo et al (2018)].\nIn addition, the explanation about importance of the tracker awareness to the target network seems not sufficient. The ancient Chinese proverb is not a good explanation. It would be better if some theoretical support can be provided for such design.\n\nFor active object tracking in real-world/3D environment, designing the reward function only based on the distance between the expected position and the tracked object position can not well reflect the tracker capacity. The scale changes of the target should also be considered when designing the reward function of the tracker. However, the proposed method does not consider the issue, and the evaluation using the reward function based on the position distance may not be sufficient.\n']","[70, -50, -30]","[80, 20, 20]","[""The sentiment score is 70 (positive) because the reviewer expresses interest in the problem and appreciation for the paper's contribution, clarity, and originality. They use phrases like 'very interesting problem' and 'I value the part that seems pretty novel'. The politeness score is 80 (polite) due to the constructive and respectful tone throughout. The reviewer offers positive feedback and suggestions for improvement without harsh criticism. They use phrases like 'I like how the author provides' and 'if... that would be a stronger acceptance', which are polite ways to give feedback and suggestions. The review maintains a professional and courteous tone throughout."", ""The sentiment score is -50 because the review is generally critical of the paper, pointing out its incremental nature and lack of substantial improvements. The reviewer notes that the work is 'very incremental' and the improvements are 'quite small and the task is ad-hoc.' However, it's not entirely negative as it acknowledges some positive aspects, such as the ablation study showing some improvements. The politeness score is 20 because while the reviewer is critical, they maintain a professional tone throughout. They offer constructive criticism and suggestions for improvement, such as 'The paper would have benefitted from a proper analysis...' and 'Further multi-agent tasks could also have been considered...'. The language is not overtly rude, but it's also not excessively polite, maintaining a neutral to slightly polite academic tone."", ""The sentiment score is slightly negative (-30) because the reviewer expresses concerns about the work being incremental and lacking sufficient explanation and theoretical support. They also point out limitations in the reward function design. However, it's not entirely negative as they acknowledge the work's aims and experimental evaluations. The politeness score is slightly positive (20) as the reviewer uses respectful language throughout, avoiding harsh criticism. They use phrases like 'I think' and 'It would be better if' which soften their critiques. The reviewer also provides constructive feedback and suggestions for improvement, which contributes to the polite tone.""]"
"[""This paper proposes a new few-shot learning method with class dependencies. To consider the structure in the label space, the authors propose to use conditional batch normalization to help change the embedding based on class-wise statistics. Based on which the final classifier can be learned by the gradient-based meta-learning method, i.e., MAML. Experiments on MiniImageNet show the proposed method can achieve high-performance, and the proposed part can be proved to be effective based on the ablation study.\n\nThere are three main concerns about this paper, and the final rating depends on the authors' response.\n1. The motivation\nThe authors claim the label structure is helpful in the few-shot learning. If the reviewer understands correctly, it is the change of embedding network based on class statistics that consider such a label structure. From the objective perspective, there are no terms related to this purpose, and the embedding space learning is also based on the same few-shot objective. Will it introduces more information w.r.t. only using embedding space to do the classification?\n\n2. The novelty.\nThis paper looks like a MAML version of TADAM. Both of the methods use the conditional batch normalization in the embedding network, while CAML uses MAML to learn another classifier based on the embedding. Although CAML uses the CBN at the example level and considers the class information in a transductive setting, it is not very novel. From the results, the proposed method uses a stronger network but does not improve a lot w.r.t. TADAM.\n\n3. Method details\n3.1 Since CBN is example induced, will it prone to overfitting?\n3.2 About the model architecture. \nCAML uses a 4*4 skip connection from input to output. It is OK to use this improve the final performance, but the authors also need to show the results without the skip connection to fairly compare with other methods. Is this skip connection very important for this particular model? Most methods use 64 channel in the convNet while 30 channels are used in this paper. Is this computational consideration or to avoid overfitting? It is a bit strange that the main network is just four layers but the conditional network is a larger and stronger resNet.\n3.3 About the MAML gradients\nHow to compute the gradient in the MAML flow? Will the embedding network be updated simultaneously? In other words, will the MAML objective influences the embedding network?\n3.4 The training details are not clear. \nThe concrete training setting is not clear. For example, does the method need model pre-train? What is the learning rate, and how to adapt it? For the MAML, we also need the inner-update learning rate. How many epochs does CAML need?\n3.5 How about build MAML directly on the embedding space?"", 'TL;DR. Significant contribution to meta-learning by incorporating latent metrics on labels.\n\n* Summary\n\nThe manuscript builds on the observation that using structured information from the labels space improves learning accuracy. The proposed method --CAML-- is an instance of MAML (Finn et al., 2017), where an additional embedding is used to characterize the dissimilarity among labels.\n\nWhile quite natural, the proposed method is supported by a clever metric learning step. The classes are first represented by centroids and an optimal mapping $\\phi$ is then learnt by maximizing a clustering entropy (similarly to what is performed in a K-means-flavored algorithm, though this connection is not made in the manuscript). A conditional batch normalization (Dumoulin et al., 2017) is then used to model how closeness (in the embedding space $f_\\phi$) among labels is taken into account at the meta-learning level.\n\nExisting literature is well acknowledged and I find the numerical experiments to be convincing. In my opinion, a clear accept.\n\n* Minor issues\n\n- I would suggest adding a footnote explaining why Table 1 reports confidence intervals and not just standard deviations. How are constructed those intervals?\n- Section 3.2 bears ambiguity as the manuscript reads ""We first define centroids [...]"" depending on $f_\\phi$ which is then defined as the argument of the minim of the entropy term. What appears as a circular definition is merely the effect of loose writing yet I am afraid it would confuse readers. I would suggest to rewrite this part, maybe using a pseudo-code to better make the point that $f_\\phi$ is learnt.', '[Summary]\nThe paper presents an enhancement to the Model-Agnostic Meta-Learning (MAML) framework to integrate class dependency into the gradient-based meta-learning procedure. Specifically, the class dependency is encoded by embedding the training examples via a clustering network into a metric space where semantic similarity is preserved via affinity under Euclidean distance. Embedding of an example in this space is further employed to modulate (scale and shift) features of the example extracted by the base-learner via a transformation network, and the final prediction is made on top of the modulated features. Experiments on min-ImageNet shows that the proposed approach improves the baseline of MAML.    \n\nPros\n- An interesting idea of leveraging class dependency in meta-learning.\n- Solid implementation with reasonable technical solutions.\n\nCons\n- Some relevant interesting areas/cases were not exploited/tested.\n- Improvement over state-of-the-arts (SOA) is marginal or none. \n\n[Originality]\nThe paper is motivated by an interesting observation that class dependency in the label space can also provide insights for meta-learning. This seems to be first introduced in the context of  meta-learning.\n\n[Quality]\nOverall the paper is well executed in some aspects, including motivation and technical implementation. There are, however, a few areas/cases I would like to see more from it so as to make a stronger case. \n\nIn terms of generalization, the proposed enhancement to MAML is claimed to be orthogonal to other SOAs that are also within the framework based on gradient-descent, e.g. LEO. It is not quite clear to me that if the use of class dependency can lead to general benefits to alike methods like LEO, or if it is just a specific case for the MAML baseline. Actually, it would be interesting to see how the proposed class-conditional modulation can help other SOA in table 1. Also, more empirical results from other use cases (e.g., other datasets or problems) also help provide more insights here. These augmentation can better justify the value or significance of this work.       \n\nIn the specific formulation of the approach in Fig 2, it looks to me that the whole system is a compounded framework that combines two classifiers with one (base-learner) producing base representation, and the second injects side-information (e.g., from class-dependency in this case) to modulates the base representation before the final prediction. I just wonder what would happen if similar process keeps on? E.g., by building the third stage that modulates the features from the previous two? Or what if we swap the roles of base-learner and the embedding from the metric space (i.e., using the base-learner to modulate the embedding)? It looks to me that the feature/embedding from both components (in Fig 5 and 6) are optimized to improve separability. The roles they play in this process are also very interesting to get more elucidation. \n \nAnother point worth discussion is that the class dependency currently imposed does not see to include hierarchical structure among classes, i.e., the label space is still flat. It would be great if this can be briefly discussed with respect to the current formulation to better inspire the future work.\n\n[Clarity]\nThe paper is generally well written and I did not have much difficulty to follow. \n\n[Significance]\nWhile the paper is built on an interesting idea, there are still a few areas for further improvement to justify its significance (the the comments above). \n']","[-30, 90, -20]","[60, 70, 60]","[""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'high-performance', 'effective based on the ablation study'), they express several significant concerns about motivation, novelty, and methodological details. The review is not entirely dismissive, but the concerns outweigh the positive elements.\n\nThe politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout. They frame their criticisms as 'concerns' rather than outright flaws, and use phrases like 'If the reviewer understands correctly' to soften potential criticisms. The reviewer also leaves room for the authors to respond and potentially change their rating, which is a polite approach.\n\nThe reasoning behind these scores is based on the overall tone and content of the review. The reviewer balances critique with acknowledgment of the paper's strengths, maintains a professional tone, and provides specific, constructive feedback. However, the multiple concerns raised and the statement that 'the final rating depends on the authors' response' indicate a generally cautious or skeptical stance towards the paper's current form."", ""The sentiment score is 90 (very positive) because the reviewer states it's a 'significant contribution', describes the method as 'clever', and concludes with 'In my opinion, a clear accept.' The politeness score is 70 (quite polite) as the reviewer uses respectful language throughout, acknowledges the authors' work positively, and frames criticisms as 'minor issues' and suggestions rather than demands. The reviewer also uses phrases like 'I would suggest' and 'I find', which are polite ways of offering feedback."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting idea', 'solid implementation'), they also point out several significant limitations and areas for improvement. The cons outweigh the pros, and phrases like 'Improvement over state-of-the-arts (SOA) is marginal or none' indicate a somewhat critical stance. The politeness score is moderately positive (60) as the reviewer uses respectful and constructive language throughout. They frame criticisms as suggestions for improvement rather than harsh judgments, using phrases like 'I would like to see more' and 'It would be great if'. The tone is professional and objective, avoiding personal attacks or overly negative language.""]"
"['This paper provides a visualization framework to understand the generative neural network in GAN models. To achieve this, they first find a group of interpretable units and then quantify the causal effect of interpretable units. Finally, the contextual relationship between these units and their surrounding is examined by inserting the discovered object concepts into new images. Extensive experiments are presented and a video is provided.\n\nOverall, I think this paper is very valuable and well-written. The experiments clearly show the questions proposed in the introduction are answered. Two concerns are as follows.\n\nCons:\n1) The visualization seems to be very heuristic. What I want to know is the theoretical interpretation of the visualization. For example, the Class Activation Maps (CAM) can be directly calculated by the output values of softmax function. How about the visual class for the generative neural networks?\n2) I am also very curious, how is the rate of finding the correct sets of units for a particular visual class?\n', '## Summary\nThis work proposes a novel analytic framework exploited on a semantic segmentation model to visualize GANs at unit (feature map) level. The authors show that some GAN representations can be interpreted, correlate with the parsing result from the semantic segmentation model but as variables that have a causal effect on the synthesis of semantic objects in the output. This framework could allow to detect and remove the artifacts to improve the quality of the generated images.\n\nThe paper is well-written and organized. The dissection and intervention for finding relationships between representation units and objects are simple, straightforward and meaningful. The visualizations are convincing and insightful. I recommend to accept the paper.\n\n## Detail comments\nAbout diagnosing and improving GANs, please give more details of the human annotation for the artifacts.\n\nI think there is a typo in the first and second paragraphs in section 4.3, Figure 14 -> Figure 8.  \n\nThe whole framework is based on a semantic segmentation model. The model is highly possibly imperfect and could have very different performances on different objects. Have you ever considerate to handle these imperfect models?\n\nIs there a way to apply the framework to the training process of GANs?\n', ""The paper proposes a method for visualizing and understanding GANs representation. This seems an important topic as several such methods were performed for networks trained in supervised learning, which relate\nto the predicted outcome, but there is lack of methods for interpreting GANs which are learned in an unsupervised manner and it is generally unclear what is the representation learned by GANs. \nThe method is finding correlations between the appearance of objects and the activation of units in each layer of the learned network. \nIn addition, the paper presents a 'causal' measure, where a causal effect of a unit is measured by removing and adding this unit from/to the network and computing the average effect on object appearance.\nThe authors demonstrate how the methods are applied by improving the appearance of images, by modifying units which were detected as important for specific objects. \nThe authors also provide an interactive interface where users can manually examine and modify their trained GANs in order to add/remove objects and to remove artifacts. \n\nThe method proposed by the authors seem to be appropriate for convolutional neural networks, where 'units' in each layer may correspond to objects and can be searched for in particular locations of image. \nIt is not clear to me if and how one can apply the author's methods to other architecture, and to other application domains (besides images), or whether the method is limited to vision applications. \nThe authors do not explain specifically how do they choose the 'units' for which they seek interpretation when reporting their results. It is written that each layer is divided into two sets: \nu  and u-bar, where we seek interpretation of u. But how large does u tend to be? how would one choose it? is it one filter out of all filters in a certain layer? when optimizing for sets of units together\n(using the alpha probabilities and the optimization in eq. 6) what is d? is it performed for all units in a single layer? more details would be useful here. \n\nThe paper is overall clearly written, with lots of visual examples demonstrating the methods presented in it. \nThe paper presents a new methodological idea, which allows for nice practical contribution. There is no theoretical contribution or any deep analysis. \nThere is no reference in the paper to the supp. info. figures and therefore it is not clear if and how the supp. info. adds valuable information to the reader. \nThe authors use scores like SWD and FIT for performance, but give no explanations for what do these scores measure. \n\n\nMinor: \n\nAbstract: immprovements -> improvements \n\nPage 6, middle: 'train on four LSUN' -> 'trained on four LSUN'\n\nPage 7, bottom: Fig. 14a and 14b should be Fig. 8a and 8b\n""]","[80, 90, 60]","[70, 80, 70]","[""The sentiment score is 80 (positive) because the reviewer states that the paper is 'very valuable and well-written' and that the experiments clearly answer the proposed questions. The overall tone is positive, with only two minor concerns mentioned. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's value and framing their concerns as curiosities rather than criticisms. The reviewer uses phrases like 'I think' and 'I am very curious,' which maintain a polite and constructive tone. The combination of positive feedback and constructive questions demonstrates a balanced and courteous approach to the review."", ""The sentiment score is 90 because the reviewer expresses a very positive view of the paper, stating it is 'well-written and organized' with 'convincing and insightful' visualizations. They explicitly 'recommend to accept the paper', which is a strong positive sentiment. The score is not 100 as there are a few minor suggestions for improvement. The politeness score is 80 because the language used is consistently respectful and constructive. The reviewer offers praise and frames their suggestions as questions or gentle recommendations rather than criticisms. The tone is professional and courteous throughout, without being overly formal or effusive, hence the high but not perfect score."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the importance of the topic, praises the clarity of the paper, and appreciates the visual examples. They also mention the 'nice practical contribution' of the work. However, it's not extremely positive as they point out some limitations and areas for improvement. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames their suggestions as requests for clarification rather than direct criticisms. They also acknowledge the paper's strengths before discussing its weaknesses. The minor corrections at the end are presented neutrally without any harsh language.""]"
"['Summary\n-------\nThis paper describes a model for musical timbre transfer.\nThe proposed method uses constant-Q transform magnitudes as the input representation, transfers between domains (timbres) by a CycleGAN-like architecture, and resynthesizes the generated CQT representation by a modified WaveNET-like decoder. The system is evaluated by human (mechanical turk) listening studies, and the results indicate that the proposed system is effective for pitch and tempo transfer, as well as timbre adaptation.\n\n\nHigh-level comments\n-------------------\n\nThis paper is extremely well written, and the authors clearly have a great attention to detail in both the audio processing and machine learning domains.  Each of the modifications to prior work was well motivated, and the ablation study at the end, while briefly presented, provides a good sense of the contributions of each piece.\n\nI was unable to listen to the examples provided by the link in section 6, which requires a Microsoft OneDrive login to access.  However, the youtube link provided in the ICLR comments gave a reasonable sample of the results of the system.  Overall, the outputs sound compelling, and match my expectations given the reported results of the listening studies.\n\nOn the quantitative side, it would have been nice to see a measurement of phase retrieval of the decoder component, which could be done in isolation from the transfer components by feeding in original CQT magnitudes.  This might help give a sense of how well the model can be expected to perform, particular as it breaks down along target timbres.  I would expect some timbres to be easier to model than others, and having a quantitative handle on that could help put the listener study in a bit more perspective.\n\nDetailed comments\n-----------------\n\nThe paper contains numerous typos and grammatical quirks, e.g.:\n    - page 5: ""GP can stable GAN training""\n    - page 7: ""CQT is equivalent to pitch""\n\n\nThe reverse-generation trick in section 3.2 was clever!\n', 'Main Idea: The authors use multiple techniques/tools to enable neural timbre transfer (converting music from one instrument to another, ex: violin to flute) without paired training examples. The authors are inspired by the success of CycleGANs for image style transfer, and by the success of Wavenet for generating realistic audio waveforms. Even without the CycleGAN, the use of CQT->WaveNet for time stretching and pitch shifting of a single piece is an interesting and valuable contribution.\n\nMethodology: Figure 1 captures the overall timbre-conversion methodology concisely. In general the details of the methodology look sound. The lengthy appendices offer additional implementation details, but without access to a source code repository, it is hard to say if the results are perfectly reproducible.\n\nExperiment and Results: Measuring the quality of generated audio is challenging.  To do so, subjective listening tests are conducted on Amazon mechanical turk, but without a comparison to a baseline system except for another performance of the target piece. Note that there are few published timbre-transfer methods (see Similar Work).\n\nOne issue with the AMT survey is that the total number of workers is not reported, and as such the significance of the results can be questioned.\n\nSignificance: In my mind, the paper offers validation of the three techniques used. CycleGANs, originally designed for images,  are shown to work for style transfers on audio spectrograms. Wavenet\'s claim to be a generic technique for audio generation is tested and validated for this domain (CQT spectrogram to audio). That CQT outperforms STFT on musical data seems to be a well established result already, but this offers further validation.\n\nThis paper also offers practical advice for adapting the techniques/tools (Wavenet, CycleGAN, CQT) to the timbre-transfer task.\n\n\nSimilar Work:\n\nI have only found 2 papers dedicated to timbre transfer in the field of Learning Representations.\n\nBitton, Adrien, Philippe Esling, and Axel Chemla-Romeu-Santos. ""Modulated Variational auto-Encoders for many-to-many musical timbre transfer."" arXiv preprint arXiv:1810.00222 (2018).\n\nwhich was published on sept 29th 2018, so less than 30 days ago, which is fine according to the reviewer guidelines.\n\n\nVerma, Prateek, and Julius O. Smith. ""Neural style transfer for audio spectograms."" arXiv preprint arXiv:1801.01589 (2018).\n\nwhich is a short 2 page exploratory paper.\n\n \nIt could be useful to cite:\n\nShuqi Dai, Zheng Zhang, Gus G. Xia.  ""Music Style Transfer: A Position Paper."" arXiv preprint arXiv:1803.06841 (2018)\n\n\nWriting Quality\n\nOverall the paper is written well with clear sentences.\n\nCertain key information would be useful to move from the appendices to the main body of the paper.  This includes the number of AMT workers, the size of the CQT frame/hop over which they are summarized, and the set of instruments that are being used in the experiments.\n\n\nSome minor nitpicks: \n\nsection 6.3, sentence 2 needs to be reworked. (\'After moving on to real world data, we noticed that real world data is harder to learn because compared to MIDI data it’s more irregular and more noisy, thus makes it a more challenging task.\') \n\nsection 3.2 sub-section \'Reverse Generation\', sentence 1 uses the word \'attacks\' for the first time. Please explain this for those not familiar.\n\nsection 3.1, sentence 3 has a typo, \'Thanks\' is wrongly capitalized.\n\ntable 1 (and other tables in appendix), \'Percentage\' (top left) does not add anything to the table.\n\n', 'The paper proposes a method for converting recordings of a specific musical instrument to another. The proposed approach is apply CycleGAN, which was developed for image style transfer, to transfer spectrograms. The synthesis is done using WaveNet.\n\nThe paper is interesting in the core idea. It demonstrates that this combination of building blocks can indeed map recordings while achieving certain characteristics of the target instrument.\n\nThe paper correctly describes ""timbre"" as a catch-all term for characterizing instruments besides pitch and volume. The success of the method should be judged along two dimensions, which are both very subjective:\n - Does the method transfer ""enough"" of the target instrument\'s characteristics?\n - Is the resulting audio quality sufficient?\n\nThe paper is easy to follow for someone with background in signal processing. I believe it is sufficiently easy to follow for readers with general computer-science and machine-learning background.\n\nThe paper focusses a lot on the choice of spectral representation. It compares short-term Fourier transform (STFT), which is the generic standard, and Constant-Q Transforms (CQT), a variant of STFT that uses a logarithmic frequency axis. To someone with signal-processing background, the choice of CQT seems logical and not something that would be challenged strongly as long as a simple comparison to STFT confirms that it works a bit better. I find the comparison between the two too dominant in the paper, and distracting from the other issues that I feel are more important (see below). For example, Section 6.2 states ""We demonstrate that the aforementioned translation does indeed result in a perceivable pitch shift when fed to our conditional WaveNet."" But that is trivial: Since changing the playback sample rate by a few half steps does not fundamentally alter the perceived timbre of an instrument, and such a change will, by construction of CQT, shift the CQT representation, and since the WaveNet has seen examples of the source instrument for all notes, shifting the CQT respresentation must necessarily result in a perceived pitch change in the re-synthesized wveform that does not fundamentally change its timbre. The real question here is whether the reconstructed signal is of the same quality as, for example, a simple PSOLA-based pitch change would be.\n\nA larger problem of the paper is that the result section seems to only test two instrument mappings, violin to flute, and piano to harpsichord. One notes that these instrument pairs mostly differ in spectral envelope, while they are rather similar in longer-term temporal variations, such as what is sometimes characterized as the ADSR curve (attack-decay-sustain-release) and vibrato. These, in my view, are very important aspects of a musical instrument\'s characteristics, which are not addressed by the paper. (Whether they are considered part of ""timbre"" is not clear, but without mapping these, one cannot meaningfully speak of mapping instruments, which is the end goal of this paper.)\n\nAnother big problem in my view is that the audio quality is just not good. I hear a lot of musical-noise artifacts and local timbre modulations. Also it is not clear why the source material is of poor quality (sounds quite noisy, most likely in part due to mu-law 8-bit encoding, and they sound like 11 kHz recordings), for which there is no justification in 2018.\n\nLastly, I am not happy with the ""beam-search"" approach. That approach is used to post-correct imperfections in the WaveNet synthesis. It samples multiple generation hypotheses, and re-weights hypotheses by how well they match the original CQT when converted back. The need for this indicates a fundamental flaw in the WaveNet synthesizer. The authors explicitly say they did not want to fix the WaveNet algorithm itself. In my view, this is what should have been done.\n\nThe authors should focus much more on how to achieve sufficient WaveNet synthesis quality. This should be the main bulk of the paper, and would be a requirement for me to accept the paper.\n\nSo overall, the paper feels a little too much of combining black boxes.\n\nIn terms of significance, I would not think that this paper is getting near solving this problem, hence I rate it of less significance in the current state of results.\n\nPros:\n - interesting idea\n - reasonable approach by combining existing building blocks\n\nCons:\n - too much focus on STFT vs. CQT\n - too little focus on getting WaveNet synthesis right\n - too limited experimental validation (too restricted choice of instruments)\n - poor resulting audio quality\n - feels too much of combining black boxes\n\nAs a result I rate the paper ""not good enough"" in its current form.\n']","[80, 60, -50]","[70, 70, 20]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as 'extremely well written' and praises the authors' attention to detail. They also mention that the outputs sound 'compelling' and that the modifications to prior work were 'well motivated'. The few criticisms (e.g., inability to access some examples, suggestion for additional measurements) are minor and constructive. The politeness score is 70 (polite) due to the overall respectful tone and the use of positive language. The reviewer offers constructive feedback and suggestions without harsh criticism. They acknowledge the paper's strengths while politely pointing out areas for improvement, such as typos and grammatical quirks. The language used is professional and courteous throughout the review."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses overall approval of the paper's methodology, results, and significance, while offering constructive feedback. They highlight the paper's contributions and validation of techniques, indicating a positive view. However, they also point out some issues and areas for improvement, which prevents the score from being higher. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively. They use phrases like 'it could be useful to' and 'Some minor nitpicks' when suggesting improvements, which maintains a polite tone. The reviewer also provides detailed explanations for their comments, showing engagement with the work. However, the score is not higher as the review maintains a professional, somewhat neutral tone rather than being overtly courteous."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects ('interesting idea', 'reasonable approach'), the overall tone is critical. The reviewer states the paper is 'not good enough' and lists several significant cons. The politeness score is 20 because the reviewer uses professional language and provides constructive criticism, but doesn't use overtly polite phrases. They balance positive and negative feedback, which maintains a respectful tone, but the critique is direct and doesn't soften negative points excessively.""]"
"['This paper provides a new dynamic perspective on deep neural network. Based on Gaussian weights and biases, the paper investigates the evolution of the covariance matrix along with the layers. Eventually the matrices achieve a stationary point, i.e., fixed point of the dynamic system. Local performance around the fixed point is explored. Extensions are provided to include the batch normalization. I believe this paper may stimulate some interesting ideas for other researchers.\n\nTwo technical questions:\n\n1. When the layers tends to infinity, the covariance matrix reaches stationary (fixed) point. How to understand this phenomenon? Does this mean that the distribution of the layer outputs will not change too much if the layer is deep enough? This somewhat conflicts the commonsense of ""the deeper the better?"" \n\n2. Typos: the weight matrix in the end of page 2 should be N_l times N_{l-1}. Also, the x_i\'s in the first line of page 3 should be bold.', '\nThis paper investigates the effect of the batch normalization in DNN learning.\nThe mean field theory in statistical mechanics was employed to analyze the\nprogress of variance matrices between layers. \nAs the results, the batch normalization itself is found to be the cause of gradient explosion. \nMoreover, the authors pointed out that near-linear activation function can improve such gradient explosion. \nSome numerical studies were reported to confirm theoretical findings.\n\nThe detailed analysis of the training of DNN with the batch normalization is quite interesting. \nThere are some minor comments below.\n\n- in page 3, 2line above eq(2): what is delta in the variance of the multivariate normal distribution?\n- the notation q appeared in the middle part of page 3 before the definition of q is shown in the last paragraph of p.3. \n- The randomized weight is not very practical. Though it may be the standard approach of mean field,\nsome comments would be helpful to the readers. \n', 'This paper develops a mean field theory for batch normalization (BN) in fully-connected networks with randomly initialized weights. There are a number of interesting predictions made in this paper on the basis of this analysis. The main technical results of the paper are Theorems 5-8 which compute the statistics of the covariance of the activations and the gradients.\n\nComments:\n\n1. The observation that gradients explode in spite of BN is quite counter-intuitive. Can you give an intuitive explanation of why this occurs?\n\n2. In a similar vein, there a number of highly technical results in the paper and it would be great if the authors provide an intuitive explanation of their theorems.\n\n3. Can the statistics of activations be controlled using activation functions or operations which break the symmetry? For instance, are BSB1 fixed points good for training neural networks?\n\n4. Mean field analysis, although it lends an insight into the statistics of the activations, needs to connected with empirical observations. For instance, when the authors observe that the structure of the fixed point is such that activations are of identical norm equally spread apart in terms of angle, this is quite far from practice. It would be good to mention this in the introduction or the conclusions.']","[70, 60, 50]","[80, 70, 75]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, stating that it 'provides a new dynamic perspective' and 'may stimulate some interesting ideas for other researchers.' The reviewer also acknowledges the paper's contributions and extensions. The score is not higher because the reviewer raises two technical questions, indicating some areas for improvement or clarification. The politeness score is 80 (polite) because the reviewer uses respectful and constructive language throughout. They frame their feedback as 'questions' rather than criticisms, and use phrases like 'I believe' to soften their statements. The reviewer also politely points out typos without being harsh. The tone is professional and courteous throughout, maintaining a positive and supportive atmosphere while still providing valuable feedback."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as 'quite interesting' and provides constructive feedback. They acknowledge the value of the detailed analysis and confirm the theoretical findings with numerical studies. The politeness score is 70 (polite) due to the respectful tone throughout the review. The reviewer uses phrases like 'Some minor comments' and frames their suggestions as questions or observations rather than direct criticisms. They also offer helpful suggestions, such as recommending additional comments for readers' benefit. The language is professional and courteous throughout, without any harsh or rude expressions."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting predictions and technical results, indicating a generally positive view. However, they also provide several suggestions for improvement, which balances out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, framing their comments as suggestions rather than criticisms. They use phrases like 'it would be great if' and 'Can you give' which are polite ways of requesting additional information or changes. The reviewer also acknowledges the paper's strengths before offering suggestions, which is a polite approach to feedback.""]"
"['The focus on novelty (mentioned in both the abstract, and conclusion as a direct claim) in the presentation hurts the paper overall. Without stronger comparison to other closely related work, and lack of citation to several closely related models, the claim of novelty isn\'t defined well enough to be useful. Describing what parts of this model are novel compared to e.g. Stochastic WaveNet or the conditional dilated convolutional decoder of ""Improved VAE for Text ..."" (linked below, among many others) would help strengthen the novelty claim, if the claim of novelty is needed or useful at all. Stochastic WaveNet in particular seems very closely related to this work, as does PixelVAE. In addition, use of autoregressive models conditioned on (non-variational, in some sense) latents have been shown in both VQ-VAE and ADA among others, so a discussion would help clarify the novelty claim.\n\nEmpirical results are strong, though (related to the novelty issue) there should be greater comparison both quantitatively and qualitatively to further work. In particular, many of the papers linked below show better empirical results on the same datasets. Though the results are not always directly comparable, a discussion of *why* would be useful - similar to how Z-forcing was included.\n\nIn the qualitative analysis, it would be good to see a more zoomed out view of the text (as in VRNN), since one of the implicit claims of the improvement from dense STCN is improved global coherence by direct connection to the ""global latents"". As it stands now the text samples are a bit too local to really tell. In addition, the VRNN samples look quite a bit different than what the authors present in their work - what implementation was used for the VRNN samples (they don\'t appear to be clips from the original paper)? \n\nOn the MNIST setting, there are many missing numbers in the table from related references (some included below), and the >= 60.25 number seems so surprising as to be (possibly) incorrect - more in-depth analysis of this particular result is needed. Overall the MNIST result needs more description and relation to other work, for both sequential and non-sequential models.\n\nThe writing is well-done overall, and the presented method and diagrams are clear. My primary concern is in relation to related work, clarification of the novelty claim, and more comparison to existing methods in the results tables. \n\nVariational Bi-LSTM https://arxiv.org/abs/1711.05717\n\nStochastic WaveNet https://arxiv.org/abs/1806.06116\n\nPixelVAE https://arxiv.org/abs/1611.05013\n\nFiltering Variational Objectives https://github.com/tensorflow/models/tree/master/research/fivo\n\nImproved Variational Autoencoders for Text Modeling using Dilated Convolutions https://arxiv.org/abs/1702.08139\n\nTemporal Sigmoid Belief Networks for Sequential Modeling http://papers.nips.cc/paper/5655-deep-temporal-sigmoid-belief-networks-for-sequence-modeling\n\nNeural Discrete Representation Learning (VQ-VAE) https://arxiv.org/abs/1711.00937\n\nThe challenge of realistic music generation: modelling raw audio at scale (ADA) https://arxiv.org/abs/1806.10474\n\nLearning hierarchical features from Generative Models https://arxiv.org/abs/1702.08396\n\nAvoiding Latent Variable Collapse with Generative Skip Models https://arxiv.org/abs/1807.04863\n\nEDIT: Updated score after second revisions and author responses', 'This paper introduces a new stochastic neural network architecture for sequence modeling. The model as depicted in figure 2 has a ladder-like sequence of deterministic convolutions bottom-up and stochastic Gaussian units top-down.\n\nI\'m afraid I have a handful of questions about aspects of the architecture that I found confusing. I have a difficult time relating my understanding of the architecture described in figure 2 with the architecture shown in figure 1 and the description of the wavenet building blocks. My understanding of wavenet matches what is shown in the left of figure 1: the convolution layers d_t^l depend on the convolutional layers lower-down in the model, thus with each unit d^l having dependence which reaches further and further back in time as l increases. I don\'t understand how to reconcile this with the computation graph in figure 2, which proposes a model which is Markov! In figure 2, each d_{t-1}^l depends only on on the other d_{t-1} units and the value of x_{t-1}, which then (in the left diagram of figure 2) generate the following x_t, via the z_t^l. Where did the dilated convolutions go…? I thought at first this was just a simplification for the figure, but then in equation (4), there is d_t^l = Conv^{(l)}(d_t^{l-1}). Shouldn\'t this also depend on d_{t-1}^{l-1}…? or, where does the temporal information otherwise enter at all? The only indication I could find is in equation (13), which has a hidden unit defined as d_t^1 = Conv^{(1)}(x_{1:t}).\n\nAdding to my confusion, perhaps, is the way that the ""inference network"" and ""prior"" are described as separate models, but sharing parameters. It seems that, aside from the initial timesteps, there doesn\'t need to be any particular prior or inference network at all: there is simply a transition model from x_{t-1} to x_{t}, which would correspond to the Markov operator shown in the left and middle sections of figure 2. Why would you ever need the right third of figure 2? This is a model that estimates z_t given x_t. But, aside from at time 0, we already have a value x_{t-1}, and a model which we can use to estimate z_t  given x_{t-1}…!\n\nWhat are the top-to-bottom functions f^{(l)} and f^{(o)}? Are these MLPs?\n\nI also was confused in the experiments by the >= and <= on the reported numbers. For example, in table 2, the text describes the values displayed as log-likelihoods, in which case the ELBO represents a lower bound. However, in that case, why is the bolded value the *lowest* log-likelihood? That would be the worst model, not the best — does table 2 actually show negative log-likelihoods, then? In which case, though, the numbers from the ELBO should be upper bounds, and the >= should be <=. Looking at figure 4, it seems like visually the STCN and VRNN have very good reconstructions, but the STCN-dense has visual artifacts; this would correspond with the numbers in table 2 being log-likelihoods (not negative), in which case I am confused only by the choice of which model to bold.\n\n\n\nUPDATE:\n\nThanks for the clarifications and edits. FWIW I still find the depiction of the architecture in Figure 2 to be incredibly misleading, as well as the decision to omit dependencies from the distributions p and q at the top of page 5, as well as the use in table 3 of ""ELBO"" to refer to a *negative* log likelihood.\n', 'This paper presents a generative sequence model based on the dilated CNN\npopularized in models such as WaveNet. Inference is done via a hierarchical\nvariational approach based on the Variational Autoencoder (VAE). While VAE\napproach has previously been applied to sequence modeling (I believe the\nearliest being the VRNN of Chung et al (2015)), the innovation where is the\nintegration of a causal, dilated CNN in place of the more typical recurrent\nneural network. \n\nThe potential advantages of the use of the CNN in place of\nRNN is (1) faster training (through exploitation of parallel computing across\ntime-steps), and (2) potentially (arguably) better model performance. This\nsecond point is argued from the empirical results shown in the\nliterature. The disadvantage of the CNN approach presented here is that\nthese models still need to generate one sample at a time and since they are\ntypically much deeper than the RNNs, sample generation can be quite a bit\nslower.\n\nNovelty / Impact: This paper takes an existing model architecture (the\ncausal, dilated CNN) and applies it in the context of a variational\napproach to sequence modeling. It\'s not clear to me that there are any\nsignificant challenges that the authors overcame in reaching the proposed\nmethod. That said, it certainly useful for the community to know how the\nmodel performs.\n\nWriting: Overall the writing is fairly good though I felt that the model\ndescription could be made more clear by some streamlining -- with a single\npass through the generative model, inference model and learning. \n\nExperiments: The experiments demonstrate some evidence of the superiority\nof this model structure over existing causal, RNN-based models. One point\nthat can be drawn from the results is that a dense architecture that uses multiple levels of the\nlatent variable hierarchy directly to compute the data likelihood is\nquite effective. This observation doesn\'t really bear on the central message\nof the paper regarding the use of causal, dilated CNNs. \n\nThe evidence lower-bound of the STCN-dense model on MNIST is so good (low)\nthat it is rather suspicious. There are many ways to get a deceptively good\nresult in this task, and I wonder if all due care what taken. In\nparticular, was the binarization of the MNIST training samples fixed in\nadvance (as is standard) or were they re-binarized throughout training? \n\nDetailed comments:\n- The authors state ""In contrast to related architectures (e.g. (Gulrajani et\nal, 2016; Sonderby et al. 2016)), the latent variables at the upper layers\ncapture information at long-range time scales"" I believe that this is\nincorrect in that the model proposed in at least Gulrajani et al also \n\n- It also seems that there is an error in Figure 1 (left). I don\'t think\nthere should be an arrow between z^{2}_{t,q} and z^{1}_{t,p}. The presence\nof this link implies that the prior at time t would depend -- through\nhigher layers -- on the observation at t. This would no longer be a prior\nat that point. By extension you would also have a chain of dependencies\nfrom future observations to past observations. It seems like this issue is\nisolated to this figure as the equations and the model descriptions are\nconsistent with an interpretation of the model without this arrow (and\nincluding an arrow between z^{2}_{t,p} and z^{1}_{t,p}.\n\n- The term ""kla"" appears in table 1, but it seems that it is otherwise not\ndefined. I think this is the same term and meaning that appears in Goyal et\nal. (2017), but it should obviously be defined here.\n']","[-30, -50, 20]","[60, 20, 60]","[""The sentiment score is slightly negative (-30) because the reviewer expresses several concerns about the paper, particularly regarding claims of novelty, lack of comparison to related work, and some questionable results. However, the reviewer also notes some positives like strong empirical results and clear writing. The politeness score is moderately positive (60) as the reviewer uses professional and constructive language throughout, offering specific suggestions for improvement rather than harsh criticism. The reviewer acknowledges the paper's strengths while tactfully pointing out areas for improvement, maintaining a respectful tone."", ""The sentiment score is -50 because the reviewer expresses significant confusion and points out several inconsistencies in the paper. Phrases like 'I'm afraid I have a handful of questions', 'I don't understand', and 'Adding to my confusion' indicate a negative sentiment towards the clarity of the paper. However, the reviewer does not completely dismiss the work, which is why the score is not lower. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I'm afraid' and 'perhaps' to soften criticism. They also thank the authors for clarifications in the update. However, the directness of the criticism and the lack of positive reinforcement keep the score from being higher. The reviewer's language is more neutral than overtly polite."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's usefulness and potential advantages, while also pointing out some limitations and areas for improvement. The overall tone is constructive, with phrases like 'certainly useful for the community' and 'demonstrates some evidence of superiority'. However, the reviewer also raises concerns and questions, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, employing phrases like 'I believe' and 'It's not clear to me' to soften criticisms. The reviewer also balances critiques with positive observations and provides detailed, constructive feedback, which is a polite approach to peer review. The language is professional and avoids any harsh or rude expressions.""]"
"['The paper propose a framework to deal with large state and action\nspaces with sparse rewards in reinforcement learning. In particular,\nthey propose to use a meta-learner to generate experience to the agent\nand to decompose the learning task into simpler sub-tasks. The authors\ntrain a DQN with a novel architecture to navigate the Web.\nIn addition the authors propose to use several strategies: shallow\nencoding (SE), reward shaping (AR) and curriculum learning (CI/CG). \nIt is shown how the proposed method outperforms state-of-the-art\nsystems on several tasks.\n\nIn the first set of experiments it is clear the improved performance\nof QWeb over Shi17 and Liu18, however, it is not clear why QWeb is not\nable to learn in the social-media-all problem. The authors tested only\none of the possible variants (AR) of the proposed approach with good\nperformance. \n\nIt is not clear in the book-flight-form environment, why the\nQWeb+SE+AR obtained 100% success while the MetaQWeb, which includes\none of main components in this paper, has a lower performance.\n\nThe proposed method uses a large number of components/methods, but it\nis not clear the relevance of each of them. The papers reads like, ""I\nhave a very complex problem to solve so I try all the methods that I\nthink will be useful"". The paper will benefit from an individual\nassessment of the different components.\n\nThe authors should include a section of conclusions and future work.\n', 'UPDATE:\n\nThank you to the authors for a comprehensive response.  I have increased my score based on these changes.  I apologize for the misunderstanding about ArXiV papers and indeed the authors are correct on that point.  Thank you as well for reporting the learning speeds.  As you mentioned, they confirm our intuitions and complete the picture of the algorithm’s behavior.  The addition of pseudo-code does make the paper and algorithm easier to follow.  Thank you for adding it.  The rewritten section 5 is indeed much easier to follow and makes the coordination between the agents clear.  Seeing that the instructor is a fixed policy resolves the game theoretic issue form the original review.\n\n\nSummary:\n\nThe paper proposes a deep reinforcement learning approach to filling out web forms, called QWeb.  In addition to both deep and shallow embeddings of the states, the authors evaluate various methods for improving the learning system, including reward shaping, introducing subgoals, and even a meta-learning algorithm that is used as an instructor.  These variations are tested in several environments and basic QWeb is shown to outperform the baselines and many of the adaptations perform even better than that in more complex domains.\n\nReview:\n\nOverall, the problem the paper considers is important and their results seem significant.  The authors have derived a novel architecture and are the first to tackle the problem of filling in web forms at this scale with an autonomous learning agent rather than one that is taught mostly by demonstration.  \n\nThe related work section is very well written with topical references to recent results and solid differentiations to the new algorithm.  However, I see many references in the paper are not from peer reviewed conferences or journals.  Unless absolutely necessary, such papers should not be cited because they have not been properly peer reviewed.  If the papers cited have actually been in a conference or journal, please add the correct attribution.\n\nThe experiments seem well conducted.  I liked that each new addition to the algorithm was tested incrementally in Figure 7 to give a realistic view of the gains introduced by each change.  I also thought the earlier comparisons to the baselines were well done and I liked that they were done against modern cutting-edge LfD demonstrations.  The only thing I would have liked to seen beyond these results are actual learning curves showing, after X iterations, what percentage of the tasks could be completed.  I suspect that in many domains the baseline LfD techniques are learning much faster since learning from teachers tends to be more targeted and sample efficient.  Learning curves would show us whether or not this is the case. \n\nThe weakest part of the paper was the description of the instructor network and the Meta-training in general.  This portion seemed ill-described and largely speculative, despite the promising results in Figure 7.  In particular, Section 5 is very unclear on how exactly the Meta-Learning works.  Pseudocode is definitely needed in this portion well beyond the quick descriptions in Figure 4 and 5, which I could not understand, despite multiple readings.  I suggest eliminating those figures and providing concrete pseudo—code describing the meta learning and also addressing the following open questions in the text:\n•\tWhy is a rule based randomized policy good to learn from?  How is this different from learning from demonstration in the baselines?\n•\tHow is a “fine grained signal” generated?  What does that mean?  Is it a reward?\n•\tIn Section 5.1, are there two RL agents, an instructor and a learner with different reward functions?  If so, isn’t this becoming game theoretic and is this likely to converge in most scenarios?\n•\tWhat does Q_D^I actually represent?  Why is maximizing these values a good thing?\n\nThere are a few grammatical mistakes in the paper including:\n\nAbstract – simpler environments -> simple environments\nAbstract- with gradually increasing -> with a gradually increasing\nPage 2 – generate unbounded -> generate an unbounded\nPage 7 – correct value -> correct values\nPage 9 – episode length -> episode lengths\n\n', 'This paper developed a curriculum learning method for training an RL agent to navigate a web. It is based on the idea of decomposing an instruction in to multiple sub-instructions, which is equivalent to decompose the original task into multiple easy to solve sub-tasks. The paper is well motivated and easily accessible. The problem tackled in this work is an interesting application of RL dealing with large action and state spaces. It also demonstrates superior performance over the state of the art methods on the same domains\n\nHere are the comments for improving this manuscript:\n  \nThere are a few notations used without definition, for example DOM tree, Potential (in equation (4))\n\nSome justification regarding the the Q value function specified in (1) might be helpful, otherwise it looks very adhoc.\n\nAlthough using both shallow encoding and augmented reward lead to good empirical results, it might be useful to give more insights, for example, sample size limit cause overfitting for deep models?\n\nWhat are the sizes of action state and action spaces?\n\nThe conclusion part is missing.\n']","[-20, 60, 80]","[50, 80, 70]","['The sentiment score is slightly negative (-20) because while the reviewer acknowledges the proposed framework and its improved performance over state-of-the-art systems, they also express several concerns and criticisms. The reviewer points out unclear aspects of the experiments, questions the relevance of different components, and suggests the paper needs more individual assessment of its components. The overall tone suggests the reviewer sees potential in the work but has significant reservations.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They present their criticisms as observations and suggestions rather than harsh judgments. The language used is neutral and academic, avoiding any personal attacks or overly negative phrasing. The reviewer offers constructive feedback, such as suggesting the inclusion of a conclusions section, which contributes to the polite tone.', ""The sentiment score is 60 (positive) because the reviewer starts by thanking the authors for their comprehensive response and mentions increasing their score based on the changes made. They acknowledge the authors' corrections and appreciate the additions made to the paper. The overall tone is positive, with phrases like 'thank you' used multiple times. However, it's not a perfect score as there are still some critiques and suggestions for improvement.\n\nThe politeness score is 80 (very polite) due to the reviewer's consistent use of polite language throughout. They begin with a thank you, apologize for a misunderstanding, and use phrases like 'thank you as well' and 'thank you for adding it.' The reviewer maintains a respectful tone even when providing critiques, using phrases like 'I would have liked to seen' and 'I suggest' rather than making demands. The high level of courtesy and consideration in the language contributes to the high politeness score."", ""The sentiment score is 80 (positive) because the reviewer starts with a positive overview of the paper, describing it as 'well motivated and easily accessible' and praising its approach to an 'interesting application of RL'. The reviewer also mentions that the method 'demonstrates superior performance over the state of the art methods'. For politeness, the score is 70 (polite) as the reviewer uses constructive language throughout, framing suggestions as ways of 'improving' the manuscript rather than criticizing it. The comments are phrased as helpful suggestions (e.g., 'might be useful', 'might be helpful') rather than demands. The reviewer also balances positive feedback with areas for improvement, maintaining a respectful tone throughout.""]"
"['While most works consider embedding as the problem of mapping an input into a point in an embedding space, paper 1341 considers the problem of mapping an input into a distribution in an embedding space. Computing the matching score of two inputs (e.g. two images) involves the following steps: (i) assuming a Gaussian distribution in the embedding space, computing the mean and standard deviation for each input, (ii) drawing a set of samples from each distribution, (3) computing the normalized distances between the samples and (iv) averaging to obtain a global score.\n\nThe proposed approach is validated on a new benchmark built on MNIST.\n\nOn the positive side:\n-\tThe topic of injecting uncertainty in neural networks should be of broad interest to the ICLR community.\n-\tThe paper is generally clear.\n-\tThe qualitative evaluation provides intuitive results.\n\nOn the negative side:\n-\tThe whole idea of drawing samples to compute the distance between two Gaussian distributions seems unnecessarily complicated. Why not computing directly a distance between distributions? There exist kernels between distributions, such as the Probability Product Kernel (PPK). See Jebara, Kondor, Howard “Probability product kernels”, JMLR’04. The PPK between two distributions p(x) and q(x) writes as: \\int_x p^a(x) q^a(x) dx, where a is a parameter. When a=1, it is known as the Expected Likelihood Kernel (ELK). When a=1/2, this is known as the Hellinger or Bhattacharyya kernel (BK). In p and q are Gaussian distributions, then the PPK can be computed in closed form. If p and q are mixtures of Gaussians, then the ELK can be computed in closed form. \n-\tThe Mixture of Gaussians embedding extension is lacking in details. How does the network generate C Gaussian distributions? By having 2C output branches generating C means and C standard deviation vectors? \n-\tIt might be useful to provide more details about why the self-similarity measure makes sense as an uncertainty measure. In its current state, the paper does not provide much intuition and it took me some time to understand (I actually understood when I made the connection with the ELK). Also, why not using a simpler measure of uncertainty such as the trace of the covariance matrix?\n-\tThe experiments are lacking in some respects:\no\tIt would be useful to report results without the VIB regularization.\no\tThe focus on the cases D=2 and D=3 (embedding in a 2D or 3D space) shades some doubt on the practical usefulness of this framework in a higher-dimensional case.\n\nMiscellaneous:\n-\tIt seems there is a typo between equations (4) and (5). It should write z_1^{(k_1)} \\sim p(z_1|x_1)\n\n--- \n\nIn their rebuttal, the authors satisfyingly addressed my concerns. Hence, I am upgrading my overall rating.\n', ""pros: The  paper is well-written and well-motivated. It seems like uncertain-embeddings will be a valuable tool as we continue to extend deep learning to Bayesian applications, and the model proposed here seems to work well, qualitatively. Additionally the paper is well-written, in that every step used to construct the loss function and training seem well motivated and generally intuitive, and the simplistic CNN and evaluations give confidence that this is not a random result. \n\ncons: I think the quantitative results are not as impressive as I would have expected, and I think it is because the wrong thing is being evaluated. It would make the results more  impressive to try to use these embeddings in some active learning framework, to see if proper understanding of uncertainty helps in a task where a good uncertainty measure actually affects the downstream task in a known manner. Additionally, I don't think Fig 5 makes sense, since you are using the embeddings for the KNN task, then measuring correlation between the embedding uncertainty and KNN, which might be a high correlation without the embedding being good. \n\nMinor comments: \n - Typo above (5) on page 3.\n - Appendix line under (12), I think dz1 and dz2 should be after the KL terms.\n\nReviewer uncertainty: I am not familiar enough with the recent literature on this topic to judge novelty. "", ""# Summary\nPaper proposes an alternative to current point embedding and a technique to train them. Point embedding are conventional embedding where an input x is deterministically mapped to a vector in embedding space.\n\ni.e         f(x) = z where f may be a parametric function or trained Neural network.\n\nNote that this point embedding means that every x is assigned a unique z, this might be an issue in cases where x is confusing for example if x is an image in computer vision pipeline then x may be occluded etc. In such cases paper argues that assigning a single point as embedding is not a great option.\n\nPaper says that instead of assigning a single point it's better to assign smear of points (collection of points coming from some distributions like Gaussian and mixture of Gaussian etc) \n\nThey provide a technique based on variational inference to train the network to produce such embeddings. They also propose a new dataset made out of MNIST to test this concept.\n\n# Concerns\n\nAlthough they have results to back up their claim on their proposed dataset and problem. They have not compared with many existing uncertainty methods like dropout. (But I’m not sure if such a comparison is relevant here)\nUnlike Kendall method or dropout method, hyperparameters here are a pain point for me, i.e how many Gaussians should I consider in my mixture of Gaussian to create the embeddings (results will depend upon that)\nI.e consider the following scenario\nThe first digit is occluded and can be anything 1,2,3,4,5,6,7,8,9,0 should I use only one Gaussian to create my embeddings like they have shown in the paper for this example, or should I choose 10 gaussian each centered about one of the digits, which might help in boosting the performance?\n\n\n""]","[20, 50, 20]","[60, 80, 60]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges some positive aspects of the paper, such as its broad interest, clarity, and intuitive results. However, they also point out several negative aspects and areas for improvement, which balances out the positives. The overall tone suggests a cautiously positive view, especially considering the final note about upgrading their rating after the rebuttal.\n\nThe politeness score is moderately high (60) because the reviewer uses professional and respectful language throughout. They present their criticisms constructively, offering specific suggestions for improvement rather than harsh criticism. The reviewer also acknowledges the positive aspects before delving into the negatives, which is a polite approach. The use of phrases like 'It might be useful to' and 'It would be useful to' further contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer begins with several positive comments about the paper being well-written, well-motivated, and potentially valuable. However, they also express significant concerns about the quantitative results and evaluation methods, balancing out the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. They also admit their own uncertainty about judging the paper's novelty, which shows humility. The use of 'pros' and 'cons' structure and the inclusion of minor comments also contribute to a professional and courteous tone."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's contributions and results, but also expresses some concerns. The review begins with a neutral summary of the paper's content, followed by specific concerns. While the concerns are significant, they are presented as areas for improvement rather than fundamental flaws. The politeness score is moderately high (60) as the reviewer uses professional and respectful language throughout. They present their concerns as questions or observations rather than harsh criticisms. The use of phrases like 'I'm not sure if such a comparison is relevant here' shows a considerate approach to offering feedback. The reviewer also acknowledges the paper's results and contributions, which adds to the overall polite tone.""]"
"['==== Summary ====\n\nThis paper proposes a model for learning problems that exhibit compositional and recursive structure, called Compositional Recursive Learner (CRL). The paper approaches the subject by first defining a problem as a transformation of an input representation x from a source domain t_x to a target domain t_y. If t_x = t_y then it is called a recursive problem, and otherwise a translational problem. A composite problem is the composition of such transformations. The key observation of the paper is that many real-world problems can be solved iteratively by either recursively transforming an instance of a problem to a simpler instance, or by translating it to a similar problem which we already know how to solve (e.g., translating a sentence from English to French through Spanish). The CRL model is essentially composed of two parts, a set of differential functions and a controller (policy) for selecting functions. At each step i, the controller observes the last intermediate computation x_i and the target domain t_y, and then selects a function and the subset of x_i to operate on. For each instance, the resulting compositional function is trained via back-propagation, and the controller is trained via policy gradient. Finally, the paper presents experiments on two synthetic datasets, translating an arithmetic expression written in one language to its outcome written in another language, and classifying MNIST digits that were distorted by an unknown random sequence of affine transformations. CRL is compared to RNN on the arithmetic task and shown to be able to generalize both to longer sequences and to unseen language pairs when trained on few examples, while RNN can achieve similar performance only using many more examples. On MNIST, it is qualitatively shown that CRL can usually (but not always) find the sequence of transformations to restore the digit to its canonical form.\n\n==== Detailed Review ====\n\nI generally like this article, as it contains a neat solution to a common problem that builds on and extends prior work. Specifically, the proposed CRL model is a natural evolution of previous attempts at solving problems via compositionally, e.g. Neural Programmer [1] that learns a policy for composing predefined commands, and Neural Module Networks [2] that learns the parameters of shared differential modules connected via deterministically defined structure (found via simple parse tree). The paper contains a careful review of the related works and highlights the similarities and differences from prior approaches. Though the experiments are mostly synthetic, the underlying method seems to be readily applicable to many real-world problems.\n\nHowever, the true contributions of the paper are somewhat muddied by presenting CRL as more general than what is actually supported by the experiments. More specifically, the paper presents CRL as a general method for learning compositional problems by decomposing them into simpler sub-problems that are automatically discovered, but in practice, a far more limited version of CRL is used in the experiments, and the suggested translational capabilities of CRL, which are important for abstract sub-problem discovery, are not properly validated:\n\n1. In both experiments, the building-block functions are hand-crafted to fit to the prior knowledge on the compositionally of the problem. For the arithmetic task, the functions are limited to operate each step just on a single window of encompassing 3 symbols (e.g., <number> <op> <number>,  <op> <number> <op>) and return a distribution over the possible symbols, which heavily forces the functions to represent simple evaluators for simple expressions of the form <number> <op> <number>. For the distorted MNIST task, the functions are limited to neural networks which choose the parameter of predetermined transformations (scaling, translation, or rotation) of the input. In both cases, CRL did not *found* sub-problems for reducing the complexity of the original instance but just had to *fine tune* loosely predefined sub-problems. Incorporating expert knowledge into the model like so is actually an elegant and useful trick for solving real problems, and it should be emphasized far clearly in the article. The story of “discovering subproblems” should be left for the discussion / future research section, because though it might be a small step towards that goal, it is not quite there yet.\n2. The experiments very neatly show how recursive transformations offer a nice framework for simplifying an instance of a problem. However, the translation capabilities of the model are barely tested by the presented experiments, and it can be argued that all transformations used by the model are recursive in both experiments. First, only the arithmetic task has a translation aspect to it, i.e., the task is to read an expression in one language and then output the answer in a different language. Second, this problem is only weakly related to translation because it is possible to translate the symbols independently, word by word, as opposed to written language that has complex dependencies between words. Third, the authors report that in practice proper translation was only used in the very last operation for translating the computed value of the input expression to the requested language, and not as a method to translate one instance that we cannot solve into another that we can. Finally, all functions operate and return on all symbols and not ones limited to a specific language, and so by the paper’s own definition, these are all recursive problems and not translational ones.\n\nIn conclusion, I believe this paper should be accepted even with the above issues, mostly because the core method is novel, clearly explained, and appears to be very useful in practice. Nevertheless, I strongly suggest to the authors to revise their article to focus on the core qualities of their method that can be backed by their current experiments, and correctly frame the discussion on possible future capabilities as such.\n\n[1] Reed et al. Neural Programmer-Interpreters. ICLR 2016.\n[2] Andreas et al. Neural Module Networks. CVPR 2016.', ""This is a good review paper. I am not sure how much it adds to the open question of how to learn representation with high structure. \n\nI would like to see more detail on what is communicated between the controller and the evaluator. Is it a single function selected or a probability distribution that is sent? How does the controller know how many function the evaluator has created? Or visa versa. \n\nThere is a penalty for the complexity of the program, is there a penalty for the number of functions generated? \n\nHaving just read Hudson and Manning's paper using a separate controller and action/answer generator they make strong use of attention. It is not clear if you use attention? Maybe in that you can operate on a portion of X. What role does attention play in your work?"", 'Summary: This paper is about trying to learn a function from typed input-output data so that it can generalize to test data with an input-output type that it hasn\'t seen during training. It should be able to use ""analogy"" (if we want to translate from French to Spanish but don\'t know how to do so directly, we should translate from French to English and English to Spanish). It should also be able to generalize better by learning useful ""subfunctions"" that can be composed together by an RL agent. We set up the solution as having a finite number of subfunctions, including ""HALT"" which signifies the end of computation. At each timestep an RL agent chooses a subfunction to apply to the current representation until ""HALT"" is chosen. The main idea is we parameterize these subfunctions and the RL agent as neural networks which are learned based on input -output data. RL agent is also penalized for using many subfunctions. The algorithm is called compositional recursive learner (CRL). Both analogy and meaningful subfunctions should arise purely because of this design.\n\nMultilingual arithmetic experiment. I found this experiment interesting although it would be helpful to specify that it is about mod-10 arithmetic. I was very confused for some time since the arithmetic expressions didn\'t seem to be evaluated correctly. It also seems that it is actually the curriculum learning that helps the most (vanilla CRL doesn\'t seem to perform very well) although authors do note that such curriculum learning doesn\'t help the RNN baseline. It also seems that CRL with curriculum doesn\'t outperform the RNN baseline that much on test data with the same length as training data. The difference is larger when tested on longer sequences. However here, the CRL learning curve seems to be very noisy, presumably due to the RL element. The qualitative analysis illustrates well how the subfunctions specialize to particular tasks (e.g. translation or evaluating a three symbol expression) and how the RL agent successively picks these subfunctions in order to solve the full task.\n\nImage transformations experiment. This experiment feels a bit more artificial although the data is more complicated than in the previous experiment. Also, in some of the examples in Figure 2, the algorithms seems to perform translation (action 2) twice in a row while it seems like this could be achieved by only one translation. How does this perform experimentally in comparison to an RNN (or other baseline)?\n\nI found this paper to be well-written. Perhaps it could be stronger if the ""image transformations"" experiment quantitatively compared to a baseline. I\'m not an expert in this area and don\'t know in detail how this relates to existing work (e.g. by Rosenbaum et al; 2018).\n\nEdit: change score to 7 in light of revisions and new experiment.']","[50, 20, 60]","[80, 50, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer begins by stating they 'generally like this article' and appreciate its 'neat solution' and 'natural evolution' of previous work. However, they also express significant criticisms, particularly about the paper overstating its contributions and not fully validating its claims. This mix of positive and negative feedback results in a moderately positive overall sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before presenting criticisms. They use phrases like 'I generally like this article' and 'I believe this paper should be accepted' which maintain a constructive tone. Even when presenting criticisms, the reviewer uses diplomatic language like 'However, the true contributions of the paper are somewhat muddied' rather than harsh or dismissive phrasing. The reviewer also offers specific suggestions for improvement, which is a polite and constructive approach to peer review."", ""The sentiment score is slightly positive (20) because the reviewer starts by calling it a 'good review paper', but then expresses uncertainty about its contribution to the field. The overall tone is constructive, with the reviewer asking for clarifications and additional information rather than criticizing. The politeness score is moderately positive (50) as the reviewer uses polite language throughout, framing their comments as requests for more information ('I would like to see...') and questions rather than demands. The reviewer also acknowledges other work in the field respectfully. The language is professional and courteous, without being overly formal or effusive."", ""The sentiment score is 60 (moderately positive) because the reviewer finds the paper 'well-written' and the experiments 'interesting', while also providing constructive criticism and suggestions for improvement. They note both strengths and limitations of the work. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, acknowledges their own potential lack of expertise in the field, and frames criticisms as suggestions rather than demands. They use phrases like 'I found this experiment interesting' and 'Perhaps it could be stronger if...' which maintain a collegial tone. The reviewer also provides detailed feedback and engages deeply with the content, showing respect for the authors' work.""]"
"['This paper presents a targeted empirical evaluation of generalization in models\nfor visual reasoning. The paper focuses on the specific problem of recognizing\n(object, relation, object) triples in synthetic scenes featuring letters and\nnumbers, and evaluates models\' ability to generalize to the full distribution of\nsuch triples after observing a subset that is sparse in the third argument. It\nis found that (1) NMNs with full layout supervision generalize better than other\nstate-of-the art visual reasoning models (FiLM, MAC, RelNet), but (2) without\nsupervised layouts, NMNs perform little better than chance, and without\nsupervised question attentions, NMNs perform better than the other models but\nfail to achieve perfect generalization.\n\nSTRENGTHS\n- thorough analysis with a good set of questions\n\nWEAKNESSES\n- some peculiar evaluation and presentation decisions\n- introduces *yet another* synthetic visual reasoning dataset rather than\n  reusing existing ones\n\nI think this paper would have been stronger if it investigated a slightly\nbroader notion of generalization and had some additional modeling comparisons.\nHowever, I found it interesting and think it successfully addresses the set of\nquestions it sets out to answer. If it is accepted, there are a few things that\ncan be done to improve the experiments.\n\nMODELING AND EVALUATION\n\n- Regarding the dataset: the proliferation of synthetic reasoning datasets is\n  annoying because it makes it difficult to compare results without downloading\n  and re-running a huge amount of code. (The authors have, to their credit, done\n  so for this paper.) I think all the experiments here could have been performed\n  successfully using either the CLEVR or ShapeWorld rendering engines: while the\n  authors note that they require a ""large number of different objects"", this\n  could have been handled by treating e.g. ""red circle"" and ""red square"" as\n  distinct atomic primitives in questions---the fact that redness is a useful\n  feature in both cases is no different from the fact that a horizontal stroke\n  detector is useful for lots of letters.\n\n- I don\'t understand the motivation behind holding out everything on the\n  right-hand side. For models that can\'t tell that the two are symmetric, why\n  not introduce sparsity everwhere---hold out some LHSs and relations?\n  \n- Table 1 test accuracies: arbitrarily reporting ""best of 3"" for some model /\n  dataset pairs and ""confidence interval of 5"" for others is extremely\n  unhelpful: it would be best to report (mean / max / stderr) for 5. Also, it\'s\n  never stated which convidence interval is reported.\n\n- Table 1 baselines: why not run Conv+LSTM and RelNet with easier #rhs/lhs data?\n\n- How many MAC cells are used? This can have significant performance\n  implications. I think if you used their code out of the box you\'ll wind up\n  with way bigger structures than you need for this task.\n\n- I\'m not sure how faithful the `find` module used here is to the one in the\n  literature, and one of the interesting claims in this work is that module\n  implementation details matter! The various Hu papers use an attentional\n  parameterization; the use of a ReLU and full convolution in Eq. 14 suggest\n  that that one here can pass around more general feature maps. This is fine but\n  the distinction should be made explicit, and it would be interesting to see\n  additional comparisons to an NMN with purely attentional bottlenecks.\n\n- Why do all the experiments after 4.3 use #rhs/lhs of 18? If it was 8 it would\n  be possible to make more direct comparisons to the other baseline models.\n\n- The comparison to MAC in 4.2 is unfair in the following sense: the NMN\n  effectively gets supervised textual attentions if the right parameters are\n  always plugged into the right models, while the MAC model has to figure out\n  attentions from scratch. A different way of structuring things would be to\n  give the MAC model supervised parameterizations in 4.2, and then move the\n  current MAC experiment to 4.3 (since it\'s doing something analogous to\n  ""parameterization induction"".\n  \n- The top-right number in Table 4---particularly the fact that it beats MAC and\n  sequential NMNs under the same supervision condition---is one of the most\n  interesting results in this paper. Most of the work on relaxing supervision\n  for NMNs has focused on (1) inducing new question-specific discrete structures\n  from scratch (N2NMN) or (2) finding fixed sequential structures that work well\n  in general (SNMN and perhaps MAC). The result this paper suggests an\n  alternative, which is finding good fixed tree-shaped structures but continuing\n  to do soft parameterization like N2NMN.\n\n- The ""sharpness ratio"" is not super easy to interpret---can\'t you just report\n  something standard like entropy? Fig 4 is unnecessary---just report the means.\n\n- One direction that isn\'t explored here is the use of Johnson- or Hu-style\n  offline learning of a model to map from ""sentences"" to ""logical forms"". To the\n  extent that NMNs with ground-truth logical forms get 100% accuracy, this turns\n  the generalization problem studied here into a purely symbolic one of the kind\n  studied in Lake & Baroni 18. Would be interesting to know whether this makes\n  things harder (b/c no grounding signal) or easier (b/c seq2seq learning is\n  easier.)\n\nPRESENTATION\n\n- Basically all of the tables in this paper are in the wrong place. Move them\n  closer to the first metnion---otherwise they\'re confusing.\n\n- It\'s conventional in this conference format to put all figure captions below\n  the figures they describe. The mix of above and below here makes it hard to\n  attach captions to figures.\n\n- Some of the language about how novel the idea of studying generalization in\n  these models is a bit strong. The CoGenT split of the CLEVR dataset is aimed\n  at answering similar questions. The original Andreas et al CVPR paper (which btw\n  appears to have 2 bib entries) also studied generalization to structurally\n  novel inputs, and Hu et al. 17 notes that the latent-variable version of this\n  model with no supervision is hard to train.\n\nMISCELLANEOUS\n\n- Last sentence before 4.4: ""NMN-Chain"" should be ""NMN-Tree""?\n\n- Recent paper with a better structure-induction technique:\n  https://arxiv.org/abs/1808.09942. Worth citing (or comparing if you have\n  time!)', 'Summary: The paper focuses on comparing the impact of explicit modularity and structure on systematic generalization by studying neural modular networks and “generic” models. The paper studies one instantiation of this systematic generalization for the setting of binary “yes” or “no” visual question answering task.  They introduce a new dataset called in which model has to answer questions that require spatial reasoning about pairs of randomly scattered letters and digits in the image. While the models are evaluated on all possible object pairs, they are trained on a smaller subset. They observe that NMNs generalize better than other neural models when an appropriate choice of layout and parametrization is made. They also show that current end-to-end approaches for inducing model layout or learning model parametrization fail to generalize better than generic models.\n\nPros:\n- The conclusions of the paper regarding the generalization ability of neural modular networks is timely given the widespread interest in these class of algorithms. \n- Additionally, they present interesting observations regarding how sensitive NMNs are to the layout of models. Experimental evidence (albeit on specific type of question) of this behaviour will be helpful for the community and hopefully motivate them to incorporate regularizers or priors that steer the learning towards better layouts.  \n- The authors provide a nice summary of all the models analyzed in Section 3.1 and Section 3.2. \n\nCons:\n- While the results on SQOOP dataset are interesting, it would have been very exciting to see results on other synthetic datasets. Specifically, there are two datasets which are more complex and uses templated language to generate synthetic datasets similar to this paper:\n    - CLEVR environment or a modification of that dataset to reflect the form of systematic the authors are studying in the paper. \n    - Abstract Scenes VQA dataset introduced in“Yin and Yang: Balancing and Answering Binary Visual Questions” by Zhang and Goyal et al. They provide a balanced dataset in which there are a pairs of scenes for every question, such that the answer to the question is “yes” for one scene, and “no” for the other for the exact same question. \n- Perhaps because the authors study a very specific kind of question, they limit their analysis to only three modules and two structures (tree & chain). However, in the most general setting NMN will form a DAG and it would have been interesting to see what form of DAGs generalize better than other. \n- It is not clear to me how the analysis done in this paper will generalize to other more complex datasets where the network layout NMN might be more complex, the number of modules and type of modules might also be more. Because, the results are only shown on one dataset, it is harder to see how one might extend this work to other form of questions on slightly harder datasets. \n\nOther Questions / Remarks:\n- Given that the accuracy drop is very significant moving from NMN-Tree to NMN-Chain, is there an explanation for this drop? \n- While the authors mention multiple times that #rhs/#lhs = 1 and 2 are more challenging than #rhs/#lhs=18, they do not sufficiently explain why this is the case anywhere in the paper. \n- Small typo in the last line of section 4.3 on page 7. It should say: This is in stark contrast with “NMN-Tree” …..\n- Small typo in the “Layout induction” paragraph, line 6 on Page 7:  … and for $p_0(tree) = 0.1$ and when we use the Find module   \n\n', 'The paper explores how well different visual reasoning models can learn systematic generalization on a simple binary task. They create a simple synthetic dataset, involving asking if particular types of objects are in a spatial relation to others. To test generalization, they lower the ratio of observed  combinations of objects in the training data. The authors show the result that tree structured neural module networks generalize very well, but other strong visual reasoning approaches do not. They also explore whether appropriate structures can be learned. I think this is a very interesting area to explore, and the paper is clearly written and presented.\n\nAs the authors admit, the main result is not especially surprising. I think everyone agrees that we can design models that show particular kinds of generalization by carefully building inductive bias into the architecture, and that it\'s easy to make these work on the right toy data. However, on less restricted data, more general architectures seem to show better generalization (even if it is not systematic). What I really want this paper to explore is when and why this happens. Even on synthetic data, when do or don\'t we see generalization (systematic or otherwise) from NMNs/MAC/FiLM? MAC in particular seems to have an inductive bias that might make some forms of systematic generalization possible. It might be the case that their version of NMN can only really do well on this specific task, which would be less interesting.\n\nAll the models show very high training accuracy, even if they do not show systematic generalization. That suggests that from the point of view of training, there are many equally good solutions, which suggests a number of interesting questions. If you did large numbers of training runs, would the models occasionally find the right solution? Could you somehow test for if a given trained model will show systematic generalization? Is there any way to help the models find the ""right"" (or better) solutions - e.g. adding regularization, or changing the model size? \n\nOverall, I do think the paper has makes a contribution in experimentally showing a setting where tree-structured NMNs can show better systematic generalization than other visual reasoning approaches. However, I feel like the main result is a bit too predictable, and for acceptance I\'d like to see a much more detailed exploration of the questions around systematic generalization.\n\n']","[50, 50, 20]","[70, 80, 70]","[""The sentiment score is 50 (slightly positive) because while the reviewer points out some weaknesses and areas for improvement, they also note strengths and find the paper 'interesting' and that it 'successfully addresses the set of questions it sets out to answer.' The overall tone is constructive rather than dismissive. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts (e.g., 'The authors have, to their credit, done so for this paper'), and frames criticisms as suggestions for improvement rather than harsh judgments. The reviewer also uses phrases like 'I think' and 'I found it interesting' to soften their opinions. However, it's not extremely polite as it does directly point out flaws and uses some strong language like 'extremely unhelpful' in one instance."", ""The sentiment score is 50 (slightly positive) because the review begins with a balanced summary and lists both pros and cons. The pros highlight the paper's timeliness, interesting observations, and helpful summary. The cons, while critical, are presented constructively as suggestions for improvement rather than outright criticisms. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout. They use phrases like 'it would have been very exciting to see' and 'it is not clear to me' when presenting criticisms, which softens the negative feedback. The reviewer also acknowledges the paper's strengths before presenting areas for improvement. The inclusion of 'Other Questions / Remarks' at the end, including noting small typos, shows a thorough and considerate approach to the review process."", ""The sentiment score is 20 (slightly positive) because while the reviewer acknowledges the paper's interesting area of exploration and clear presentation, they also express that the main result is not surprising and suggest more detailed exploration is needed. The reviewer sees value in the work but has significant reservations. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. Phrases like 'I think this is a very interesting area to explore' and 'I do think the paper makes a contribution' demonstrate a polite and considerate tone, even while providing critical feedback.""]"
"['This article presents experiments on medium- and large-scale language modeling when the ideas of adaptive softmax (Grave et al., 2017) are extended to input representations.\n\nThe article is well written and I find the contribution simple, but interesting. It is a reasonable and well supported increment from adaptive softmax of Grave et al. (2017).\n\nMy question is a bit philosophical: The only thing which I was concerned about when reading the paper is projection of the embeddings back to the d-dimensional space. I understand that for two matrices A and B we have rank(AB) <= min(rank(A), rank(B)), and we are not making the small-sized embeddings richer when backprojecting to R^d, but have you thought about how it would be possible to avoid this step and keep the original variable-size embeddings?\n\nReferences\nJoulin, A., Cissé, M., Grangier, D. and Jégou, H., 2017, July. Efficient softmax approximation for GPUs. In International Conference on Machine Learning (pp. 1302-1310).', 'This paper introduced a new architecture for input embeddings of neural language models: adaptive input representation (ADP). ADP allowed a model builder to define a set of bands of input words with different frequency where frequent words have larger embedding size than the others. The embeddings of each band are then projected into the same size. This resulted in lowering the number of parameters. \n\nExtensive experiments with the Transformer LM on WikiText-103 and Billion Word corpus showed that ADP achieved competitive perplexities. While tying weight with the output did not benefit the perplexity, it lowered the runtime significantly on Billion Word corpus. Further analyses showed that ADP gained performance across all word frequency ranges.\n\nOverall, the paper was well-written and the experiments supported the claim. The paper was very clear on its contribution. The variable-size input of this paper was novel as far as I know. However, the method, particularly on the weight sharing, lacked a bit of important background on adaptive softmax. The weight sharing was also needed further investigation and experimental data on sharing different parts.\n\nThe experiments compared several models with different input levels (characters, BPE, and words). The perplexities of the proposed approach were competitive with the character model with an advantage on the training time. However, the runtimes were a bit strange. For example, ADP and ADP-T runtimes were very close on WikiText-103 dataset but very different on Billion Word corpus (Table 3 and 4). The runtime of ADP seemed to lose in term of scaling as well to BPE. Perhaps, the training time was an artifact of multi-GPU training. \n\nQuestions:\n1. I am curious about what would you get if you use ADP on BPE vocab set?\n2. How much of the perplexity reduction of 8.7 actually come from ADP instead of the transformer and optimization?', ""The authors extend an existing approach to adaptive softmax classifiers used for the output component of neural language models into the input component, once again allowing tying between the embedding and softmax. This fills a significant gap in the language modeling architecture space, and the perplexity results bear out the advantages of combining adaptively-sized representations with weight tying. While the advance is in some sense fairly incremental, the centrality of unsupervised language modeling to modern deep NLP (ELMo, BERT, etc.) implies that perplexity improvements as large as this one may have meaningful downstream effects on performance on other tasks. Some things I noticed:\n\n- One comparison that I believe is missing (I could be misreading the tables) is comparing directly to Merity et al.'s approach (adaptive softmax but fixed embedding/softmax dimension among the bands). Presumably you're faster, but is there a perplexity trade-off?\n\n- The discussion/explanation of the differing performance of tying or not tying each part of the embedding weights for the different datasets is confusing; I think it could benefit from tightening up the wording but mostly I just had to read it a couple times. Perhaps all that's complicated is the distinction between embedding and projection weights; it would definitely be helpful to be as explicit about that as possible upfront.\n\n- The loss by frequency-bin plots are really fantastic. You could also try a scatterplot of log freq vs. average loss by individual word/BPE token.\n\n- Do you have thoughts as to why full-softmax BPE is worse than adaptive softmax word level? That goes against the current (industry) conventional wisdom in machine translation and large-scale language modeling that BPE is solidly better than word-level approaches because it tackles the softmax bottleneck while also sharing morphological information between words.\n""]","[80, 50, 70]","[90, 75, 80]","[""The sentiment score is 80 (positive) because the reviewer describes the article as 'well written' and the contribution as 'simple, but interesting'. They also state it's a 'reasonable and well supported increment' from previous work. The only slight concern raised is framed as a 'philosophical' question, not a criticism. The politeness score is 90 (very polite) due to the use of respectful language throughout. The reviewer uses phrases like 'I find' and 'My question is', showing consideration for the authors' perspective. The critique is phrased as a question for discussion rather than a demand for change, which is particularly polite. The overall tone is constructive and collegial."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and novelty, stating it is 'well-written' and 'very clear on its contribution'. However, they also point out some limitations and areas for improvement, creating a balanced view. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, offers constructive criticism, and poses questions for further consideration rather than making harsh demands. The reviewer maintains a professional tone, acknowledging both strengths and weaknesses of the paper without using overly critical language."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the work, noting that it 'fills a significant gap' and has 'meaningful downstream effects'. They describe the perplexity improvements as 'large' and the loss plots as 'fantastic'. The politeness score is 80 (polite) due to the constructive and respectful tone throughout. The reviewer offers suggestions and asks questions in a collegial manner, using phrases like 'Perhaps' and 'Do you have thoughts' rather than making demands. They also acknowledge the potential impact of the work. The review maintains a professional and courteous tone while providing detailed feedback.""]"
"['The paper proposes neural networks which are convex on inputs data to control problems. These types of networks, constructed based on either MLP or RNN, are shown to have similar representation power as their non-convex versions, thus are potentially able to better capture the dynamics behind complex systems compared with linear models. On the other hand, convexity on inputs brings much convenience to the later optimization part, because there are no worries on global/local minimum or escaping saddle points. In other words, convex but nonlinear provides not only enough search space, but also fast and tractable optimization. The compromise here is the size of memory, since 1) more weights and biases are needed to connect inputs and hidden layers in such nets and 2) we need to store also the negative parts on a portion of weights. \n\nEven though the idea of convex networks were not new, this work is novel in extending input convex RNN and applying it into dynamic control problems. As the main theoretical contribution, Theorem 2 shows that to have same representation power, input convex nets use polynomial number of activation functions, compared with exponential from using a set of affine functions. Experiments also show such effectiveness. The paper is clearly and nicely written. These are reasons I suggest accept.\n\n\nQuestions and suggestions:\n\n1) For Lemma 1 and Theorem 1, I wonder whether similar results can be established for non-convex functions. Intuitively, it seems that as long as assuming Lipschiz continuous, we can always approximate a function by a maximum of many affine functions, no matter it is convex or not. Is this right or something is missing?\n\n2) In the main paper, all experiments were aimed to address ICNN and ICRNN have good accuracy, but not they are easier to optimize due to convexity. In the abstract, it is mentioned ""... using 5X less time"", but I can only see this through appendix. A suggestion is at least describing some results on the comparison with training time in the main paper.\n\n3) In Appendix A, it seems the NN is not trained very well as shown in the left figure. Is this because the number of parameters of NN is restricted to be the same as in ICNN? Do training on both spend the same resource, ie, number of epoch? Such descriptions are necessary here.\n\n4) In Table 2 in appendix, why the running time of ICNN increases by a magnitude for large H in Ant case?\n\n\nTypos:\n\tPage 1 ""simple control algorithms HAS ...""\n\tPage 7 paragraph ""Baselines"": ""Such (a) method"".\n\tIn the last line of Table 2, 979.73 should be bold instead of 5577.\n\tThere is a ?? in appendix D.4.\n\t\n', 'This paper proposes to use input convex neural networks (ICNN) to capture a complex relationship between control inputs and system dynamics, and then use trained ICNN to form a model predictive control (MPC) problem for control tasks.\nThe paper is well-written and bridges the gap between neural networks and MPC.\nThe main contribution of this paper is to use ICNN for learning system dynamics. ICNN is a neural network that only contains non-negative weights. Thanks to this constraint, ICNN is convex with respect to an input, therefore MPC problem with an ICNN model and additional convex constraints on control inputs is a convex optimization problem.\nWhile it is not easy to solve such a convex problem, it has a global optimum, and a gradient descent algorithm will eventually reach such a point. It should also be noted that a convex problem has a robustness with respect to an initial starting point and an ICNN model itself as well. The latter is pretty important, since training ICNN (or NN) is a non-convex optimization, so the parameters in trained ICNN (or NN) model can vary depending on the initial random weights and learning rates, etc. Since a convex MPC has some robustness (or margin) over an error or deviation in system dynamics, while non-convex MPC does not, using ICNN can also stabilize the control inputs in MPC.\nOverall, I believe that using ICNN to from convex MPC is a sample-efficient, non-intrusive way of constructing a controller with unknown dynamics. Below are some minor suggestions to improve this paper.\n\n-- Page 18, there is Fig.??. Please fix this.\n-- In experiments, could you compare the result with a conventional end-to-end RL approach? I know this is not a main point of this paper, but it can be more compelling.', 'This is a well-motived paper that considers bridging the gap\nin discrete-time continuous-state/action optimal control\nby approximating the system dynamics with a convex model class.\nThe convex model class has more representational power than\nlinear model classes while likely being more tractable and\nstable than non-convex model classes.\nThey show empirical results in Mujoco continuous-control\nenvironments and in an HVAC example.\n\nI think this setup is a promising direction but I have\nsignificant concerns with some of the details and claims\nin this work:\n\n1. Proposition 2 is wrong and the proposed input-convex recurrent\n   neural network architecture not input-convex.\n   To fix this, the D1 parameters should also be non-negative.\n   To show why the proposition is wrong, consider the convexity of y2\n   with respect to x1, using g to denote the activation function:\n\n       z1 = g(U x1 + ...)\n       y2 = g(D1 z1 + ...)\n\n   Thus making\n\n       y2 = g(D1 g(U x1 + ...) + ...)\n\n   y2 is *not* necessarily convex with respect to x1 because D1 takes\n   an unrestricted weighted sum of the convex functions g(U x1 + ...)\n\n   With the ICRNN architecture as described in the paper not being\n   input-convex, I do not know how to interpret the empirical findings\n   in Section 4.2 that use this architecture.\n\n2. I think a stronger and more formal argument should be used to show\n   that Equation (5) is a convex optimization problem as claimed.\n   It has arbitrary convex functions on the equality constraints that\n   are composed with each other and then used in the objective.\n   Even with parts of the objective being convex and non-decreasing\n   as the text mentions, it\'s not clear that this is sufficient when\n   combined with the composed functions in the constraints.\n\n3. I have similar concerns with the convexity of Equation (6).\n   Consider the convexity of x3 with respect to u1, where g is\n   now an input-convex neural network (that is not recurrent):\n\n       x3 = g(g(x1, u1), u2)\n   \n   This composes two convex functions that do *not* have non-decreasing\n   properties and therefore introduces an equality constraint that\n   is not necessarily even convex, almost certainly making the domain\n   of this problem non-convex. I think a similar argument can be\n   used to show why Equation (5) is not convex.\n\nIn addition to these significant concerns, I have a few other\nminor comments.\n\n1. Figure 1 hides too much information. It would be useful to know,\n   for example, that the ICNN portion at the bottom right\n   is solving a control optimization problem with an ICNN as\n   part of the constraints.\n\n2. The theoretical results in Section 3 seem slightly out-of-place within\n   the broader context of this paper but are perhaps of standalone interest.\n   Due to my concerns above I did not go into the details in this portion.\n\n3. I think more information should be added to the last paragraph of\n   Section 1 as it\'s claimed that the representational power of\n   ICNNs and ""a nice mathematical property"" help improve the\n   computational time of the method, but it\'s not clear why\n   this is and this connection is not made anywhere else in the paper.\n\n4. What method are you using to solve the control problems in\n   Eq (5) and (6)?\n\n5. The empirical setup and tasks seems identical to [Nagabandi et al.].\n   Figure 3 directly compares to the K=100 case of their method.\n   Why does Fig 6 of [Nagabandi et al.] have significantly higher rewards\n   for their method, even in the K=5 case?\n\n6. In Figure 5, f_NN seems surprisingly bad in the red region of the\n   data on the left side. Is this because the model is not using\n   many parameters? What are the sizes of the networks used?']","[80, 80, -50]","[70, 70, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, highlighting its novelty, theoretical contributions, and clear writing. They explicitly suggest acceptance. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames suggestions as questions. They acknowledge the paper's strengths before offering critiques. The reviewer also helpfully points out typos, which is a courteous gesture. The language is professional and objective, avoiding any harsh or dismissive tones."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They describe it as 'well-written' and state that it 'bridges the gap between neural networks and MPC'. The reviewer also believes that the approach is 'sample-efficient' and 'non-intrusive'. The overall tone is highly supportive of the paper's contribution and methodology. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and offering constructive suggestions. The use of phrases like 'I believe' and 'could you' in the suggestions indicates a polite and considerate approach to feedback. The reviewer also balances praise with minor suggestions for improvement, maintaining a courteous tone throughout the review."", ""The sentiment score is -50 because while the reviewer acknowledges the paper as 'well-motivated' and the approach as 'promising', they express 'significant concerns' with key aspects of the work. The reviewer points out several major issues, including a wrong proposition, unclear convexity arguments, and concerns about the interpretation of empirical findings. These critical points outweigh the initial positive remarks, resulting in a slightly negative overall sentiment. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I think' and 'I have concerns' rather than making blunt criticisms. The reviewer also balances critique with positive acknowledgment and offers constructive suggestions for improvement. However, the score is not higher as the review is primarily focused on pointing out flaws rather than offering extensive praise or encouragement.""]"
"['This paper studies the forgetting behavior of the training examples during SGD. Empirically it shows there are forgettable and unforgettable examples, unforgettable examples are like ""support examples"", one can achieve similar performance by training only on these ""support examples"". The paper also shows this phenomenon is consistent across different network architectures.\n\nPros:\nThis paper is written in high quality, clearly presented. It is original in the sense that this is the first empirical study on the forgettability of examples in during neural network training.\n\nComments and Questions on the experiment details:\n1. Is the dataset randomly shuffled after every epoch? One concern is that if the order is fixed, some of the examples will be unforgettable simply because the previous batches have similar examples , and training the model on the previous batches makes it good on some examples in the current batch.\n2. It would be more interesting to also include datasets like cifar100, which has more labels. The current datasets all have only 10 categories.\n3. An addition figure can be provided which switches the order of training in figure 4b. Namely, start with training on b.2.\n\nCons:\nLack of insight. Subjectively, I usually expect empirical analysis papers to either come up with unexpected observations or provide guidance for practice. In my opinion, the findings of this work is within expectation, and there is a gap for practice.\n\nOverall this paper is worth publishing for the systematic experiments which empirically verifies that there are support examples in neural networks.', 'UPDATE 2 (Nov 19, 2018): The paper has improved very substantially since the initial submission, and the authors have addressed almost all of my comments. I have therefore increased my score to an 8 and recommend acceptance.\n------------------------------------------------------------------------------------------------------------------------------\n\nUPDATE (Nov 16, 2018) : In light of the author response, I have increased my score to a 6.\n------------------------------------------------------------------------------------------------------------------------------\n\nThis paper aims to analyze the extent to which networks learn to correctly classify specific examples and then “forget” these examples over the course of training. The authors provide several examples of forgettable and unforgettable examples, demonstrating, among other things, that examples with noisy examples are more forgettable and that a reasonable fraction of unforgettable examples can be removed from the training set without harming performance. \n\nThe paper is clearly written, and the work is novel -- to my knowledge, this is the first investigation of example forgetting over training. There are an interesting and likely important set of ideas here, and portions of the paper are quite strong -- in particular, the experiment demonstrating that examples with noisy examples are more forgettable is quite nice. However, there are several experimental oversights which make this paper difficult to recommend for publication in its current form.\n\nMajor points:\n\n1) The most critical issue is with the measurement of forgetting itself: the authors do not take into account the chance forgetting rate in any of their experiments. Simply due to chance, some examples will be correctly labeled at some point in training (especially in the datasets analyzed, which only contain 10 classes). This makes it difficult to distinguish whether a “forgotten” example was actually ever learned in the first place. In order to properly ground this metric, measurements of chance forgetting rates will be necessary (for example, what are the forgetting rates when random steps are taken at each update step?). \n\n2) Were the networks trained on MNIST, permutedMNIST, and CIFAR-10 trained for the same number of epochs? Related to point 1, the forgetting rate should increase with the number of epochs used in training as the probability of each example being correctly classified should increase. If the CIFAR-10 models were trained for more epochs, this would explain the observation that more CIFAR-10 examples were “forgettable.”\n\n3) In the experiment presented in Figure 4b, it is difficult to tell whether the never forgotten set suffers less degradation in the third training regime because the examples were never forgotten or because the model had twice has much prior experience. Please include a control where the order is flipped (e.g., forgotten, never forgotten, forgotten in addition to the included never forgotten, forgotten, never forgotten order currently present).\n\n4) The visual inspection of forgettable and unforgettable examples in Figure 2 is extremely anecdotal, and moreover, do not even appear to clearly support the claims made in the paper.\n\nMinor points:\n\n1) In the discussion of previous studies which attempted to assess the importance of particular examples to classification decisions, a citation to [1] should be added. \n\n2) The point regarding similarity across seeds is absolutely critical (especially wrt major comment 1) , and should be included earlier in the paper and more prominently.\n\n3) The histograms in Figure 1 are misleading in the cropped state. While I appreciate that the authors included the full histogram in the supplement, these full histograms should be included in the main figure as well, perhaps as an inset.\n\n4) The inclusion of a space after the commas in numbers (e.g., 50, 245) is quite confusing, especially when multiple numbers are listed as in the first line on page 4.\n\n[1] Koh, Pang Wei and Percy Liang. “Understanding Black-box Predictions via Influence Functions.” ICML (2017).\n', 'This is an excellent analysis paper of a very interesting phenomenon in deep neural networks.\n\nQuality, Clarity, Originality:\nAs far as I know, the paper explores a very relevant and original question -- studying how the learning process of different examples in the dataset varies. In particular, the authors study whether some examples are harder to learn than others (examples that are forgotten and relearned multiple times through learning.) We can imagine that such examples are ""support vectors"" for neural networks, helping define the decision boundary.\n\nThe paper is very clear and the experiments are of very high quality. I particularly appreciated the effort of the authors to use architectures that achieve close to SOTA on all datasets to ensure conclusions are valid in this setting. I also thought the multiple repetitions and analysing rank correlation over different random seeds was a good additional test.\n\nSignificance\nThis paper has some very interesting and significant takeaways.\nSome of the other experiments I thought were particularly insightful were the effect  on test error of removing examples that aren\'t forgotten to examples that are forgotten more. In summary, the ""harder"" examples are more crucial to define the right decision boundaries. I also liked the experiment with noisy labels, showing that this results in networks forgetting faster.\n\nMy one suggestion would be to try this experiment with noisy *data* instead of noisy labels, as we are especially curious about the effect of the data (as opposed to a different labelling task.)\n\nI encourage the authors to followup with a larger scaled version of their experiments. It\'s possible that for a harder task like Imagenet, a combination of ""easy"" and ""hard"" examples might be needed to enable learning and define good decision boundaries.\n\nI argue strongly for this paper to be accepted to ICLR, I think it will be of great interest to the community.']","[50, 50, 95]","[80, 75, 90]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's high quality, originality, and clear presentation. They state it's 'worth publishing' but also mention some cons like 'lack of insight' and 'gap for practice'. The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as 'comments and questions' rather than direct criticisms. They also balance negative points with positive ones, showing consideration for the authors' work."", ""The sentiment score is 50 (moderately positive) based on the following factors: The reviewer notes the paper has 'improved very substantially' and recommends acceptance in the final update. They describe the work as 'novel' and 'interesting and likely important'. However, they also point out several 'experimental oversights' and areas for improvement, balancing the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges improvements, and frames criticisms constructively as suggestions (e.g. 'Please include...'). They also provide detailed explanations for their concerns rather than dismissive comments. The tone remains professional and courteous even when pointing out issues."", ""The sentiment score is 95 because the reviewer expresses strong positive sentiment throughout the review. They describe the paper as 'excellent', 'very interesting', 'very clear', and of 'very high quality'. The reviewer also 'strongly' argues for the paper's acceptance and believes it will be of 'great interest to the community'. The only slight suggestion for improvement doesn't significantly detract from the overall positive sentiment. The politeness score is 90 because the reviewer uses consistently respectful and encouraging language. They appreciate the authors' efforts, offer constructive suggestions, and use phrases like 'I encourage the authors' which demonstrate a collegial and supportive tone. The review maintains a professional and courteous demeanor throughout, without any hint of rudeness or harsh criticism.""]"
"['This paper introduces the General Language Understanding Evaluation (GLUE) benchmark and platform, which aims to evaluate representations of language with an emphasis on generalizability. This is a timely contribution and GLUE will be an impactful resource for the NLP community. This is mitigated, perhaps, somewhat by the recent release of decaNLP. But, as discussed the authors, this has a different focus (re-framing all tasks as QQ) and further does not feature the practical tools released here (leaderboard, error analysis) that will help drive progress.\n\nSome comments below. \n\n- The inclusion of the small diagnostic dataset was a nice addition and it would be nice if future corpora included similar. \n\n- Implicit in this and related efforts is the assumption that parameter sharing ought to be possible and fruitful across even quite diverse tasks. While I do not object to this, it would be nice if the authors could make an explicit case here as to why should we believe this to be the case.\n\n- The proposed platform is touted as one of the main contributions here, but not pointed to -- I assume for anonymity preserving reasons, but still would have been nice for this to be made explicit. \n\n- I would consider pushing Table 5 (Appendix) into the main text. \n', 'The paper proposes a new benchmark for natural language understanding: GLUE. Models will be evaluated based on a diverse set of existing language understanding tasks which encourages the models to learn shared knowledge across different tasks. The authors empirically show that models trained with multiple tasks in the dataset perform better than models that focused on one specific task. They also point out existing methods are not able achieve good performance in this dataset and request for more general natural language understanding system. The work also collects an expert evaluated diagnostic evaluation dataset for further examination for the models.\n\nQuality: borderline, clarity:good, originality: borderline, significance: good,\n\nPros:\n- The benchmark is set up in a online platform with leaderboard which can be easily accessible to people.\n- The benchmark comes with a diagnostic evaluation dataset with coarse-grained and fine-grained categories that examine different aspect of language understanding abilities.\n- Baseline results for major existing models are provided\n\nCons:\n- The author should provide more detailed analysis and interpretable explanations for the results as opposed to simply stating that the overall performance is better.\nFor example, why attention hurts performance in single task training? Why multi-tasks training actually leads to worse performance on some of the dataset? Do these phenomenons still exist if you train on a different subset of the dataset?\nWhat are the samples that the models failed to perform well? It would be nice to get some more insights and conclusions based on the results obtained from this benchmark to shed some lights on how to improve these models. The results section should be seriously revised.\n\n- The diagnostic evaluation dataset seems to be a way to better understand the model, however, it is hard to see the scope of the data (are the samples under each categories balanced?). Besides, the examples in the dataset seems very confusing even for humans (Table 2).  The evaluation with NLP expert is also far from perfect. I wonder how accurate is this dataset annotated (or even the sentences make sense or not), and how suitable it is for evaluating model’s language understanding abilities. It would be nice if the authors can include some statistics about the dataset.\n\nThe paper proposes a useful benchmark that measures different aspects of language understanding abilities which would be helpful to the community. However, I feel the novelty or take away messages from the experiment section is limited. \n', ""Summary:\nGLUE is a benchmark consisting of multiple natural language understanding tasks\nthat functions via uploading to a website and receiving a score based on\nprivately held test set labels.\nTasks include acceptability judgement, sentiment prediction, semantic equivalence\ndetection, judgement of premise hypothesis entailment, question paragraph pair\nmatching, etc..\nThe benchmark also includes a diagnostic dataset with logical tasks such as\nlexical entailment and understanding quantifiers.\n\nIn addition to presenting the benchmark itself, the paper also presents models\nfor performance baselines.\nThere is some brief analysis of the ability of Sentence2Vector vs. more complex\nmodels with e.g. attention mechanisms and of single-task vs. multi-task training.\n\nEvaluation:\nThe GLUE benchmark seems like a well designed benchmark that could potentially\nignite new progress in the area of NLU.\nBut since I'm not an expert in the area of language modeling and know almost\nnothing about existing benchmarks I cannot validate the added benefit over\nexisting benchmarks and the novelty of the suggested benchmarking approach.\n\nDetails:\nThe paper is well written, clear and easy to follow.\n\nThe proposed benchmarks seem reasonable and illustrate the difficulty of\nbenchmark tasks that involve logical structure.\n\nPage 5: showing showing (Typo)\n""]","[80, 20, 60]","[70, 60, 80]","[""The sentiment score is 80 (positive) because the reviewer describes the paper as a 'timely contribution' and states that GLUE 'will be an impactful resource for the NLP community'. The overall tone is supportive and appreciative of the work. The politeness score is 70 (polite) due to the constructive nature of the feedback and the use of phrases like 'nice addition' and 'would be nice if'. The reviewer offers suggestions in a respectful manner, using language like 'I would consider' rather than making demands. The review maintains a professional and courteous tone throughout, providing balanced feedback that acknowledges the paper's strengths while offering areas for improvement."", 'The sentiment score is slightly positive (20) because the reviewer acknowledges the usefulness and potential benefits of the proposed benchmark, despite pointing out some limitations. The review begins with a neutral summary and lists both pros and cons, but ultimately concludes that the benchmark would be helpful to the community. The politeness score is moderately high (60) as the reviewer uses professional and respectful language throughout. They offer constructive criticism and suggestions for improvement without using harsh or dismissive language. The reviewer balances positive feedback with areas for improvement, maintaining a courteous tone even when expressing concerns.', ""The sentiment score is 60 (moderately positive) because the reviewer expresses that the GLUE benchmark seems 'well designed' and could 'potentially ignite new progress'. However, they also express uncertainty about its novelty and added benefit, which prevents a higher score. The politeness score is 80 (quite polite) due to the reviewer's constructive and respectful tone throughout. They acknowledge their own limitations ('I'm not an expert'), offer praise ('well written, clear and easy to follow'), and provide a helpful correction for a typo. The language used is professional and courteous, without any harsh criticisms or demanding language.""]"
"['This paper proposes to combine fitted value iteration with model predictive control (MPC) to speed up the learning process. The value iteration is the ""Learn offline"" subsystem while MPC is the ""Plan online"" subsystem. In addition, this paper also proposes an exploration technique that increases exploration if the multiple value function estimators disagree. The evaluation is complete and shows nice results.\n\nHowever, I did not rank this paper high for two reasons. First, it is not clear to me how the model is acquired in MPC. Does the method learn the model? Does the method linearize the dynamics and assume a linear model? I am not sure. I suspect that the method just uses the simulator as the model. If it is the case, the method is not so useful because for complexity systems, such as humanoids, we do not know the model. And the comparisons with model-free learning algorithms are not fair because the paper assumes that the model is given. If this is not the case, I suggest that a more detailed description of MPC should be presented in Section 2.3.\n\nSecond, the technical contributions are lean. The three main components, 1) fitted value iteration, 2) MPC and 3) exploration based on multiple value function estimates, are not novel. The combination of them seems straight forward. For example, the H-step Bellman update (Section 2.3) is a blend between Monte-Carlo method and Q learning. It seems to be similar to the TD(\\lambda) method. Thus, it is not surprising that it can accelerate convergence of value function.\n\nFor the above reasons, I would not recommend accepting this paper at this time.', 'In this paper, the authors propose POLO, a reinforcement learning algorithm which has access to the model of the environment and performs RL to mitigate the planning cost. For the planning, POLO uses the known model of the environment up to a fixed horizon H and then use an approximated value function in the leaf nodes. This way, instead of planning for an infinite horizon, the planning is factored to a shorter horizon, resulting in lower computation cost.\n\nThe novelty and motivation behind this approach is limited. Similar or even more general approach for discrete action space is introduced in ""Sample-Efficient Deep RL with Generative Adversarial Tree Search"" where they also learn the model of the environment and additionally consider the error due to the model estimation. There is also a clear motivation in the mentioned paper while I could not find a convincing one for the current paper. \nPutting the novel limitation aside,  both of these paper, the current paper, and the paper I mentioned, suffer from very lose estimation bounds. Both of these works bound somewhat similar (not the same) things via L_inf error of value function which in practice does not necessarily result in useful or insightful upper bounds (distribution dependent bound is desired). Moreover, with the assumption of knowing the environment model, the implication of the current work is significantly limited.\n\nThe authors do a good job of writing the paper and the paper is clear which is appreciatable.\n\nIn equation 6 the authors use log-sum-exp and claim it corresponds to UCB, but they do not provide any evidence to support their claim. \n\nIn addition, the Bayesian linear regression in the tabular setting is firstly proposed in Generalization and Exploration via Randomized Value Functions and beyond tabular setting (the setting in the current paper) was proposed in Efficient Exploration through Bayesian Deep Q-Networks. \n\nThe claims in this paper are not strong enough and the empirical study does not strongly support or provide sufficient insight. For example experiments in section 3.2 does not provide much insight beyond common knowledge.\n\nWhile bridging the gap between model based and model free approaches in RL are significantly important research directions in RL, I do not find the current draft significant enough to shed sufficient light into this topic.\n\n\n\n', 'This paper was a joy to read.   The description and motivation of the POLO framework was clear, smart, and sensible.  The fundamental idea is to explore the interplay between value-function estimation and model-predictive control and demonstrate how they benefit one another.  None of these ideas is fundamentally new, but the descriptions and their combination is very nice.\n\nAs I finished the paper, though, I was left with a lingering lack of understanding of the exact problem setting that is being addressed. The name is cute but didn\'t help clarify.    As I understand it:\n- we have a correct dynamics model (I\'m assuming that\'s what ""nominal dynamics model"" means) and a good trajectory optimization algorithm\n- the agent has limited online cognitive capacity\n- there is no opportunity for offline computation\nIf offline computation time were available, then we could run this algorithm (or your favorite other RL algorithm) in the agent\'s head before taking any actions in the actual world.   That does not seem to be the setting here, although it does seem to me that you might be able to show that POLO is a good algorithm for finding a value function, offline, with no actual interaction with the world.\n\nSo, fundamentally, this paper is about action under computational time constraints.   One strategy would be for the robot to use 7 of its cores to run your favorite approximate DP / RL algorithm in parallel with 1 core that\'s used for action selection.  Why is that worse than your algorithm 1?\n\nSetting this question aside, I had some other comments:\n- It is better *not* to use ""trajectory optimization"" and ""model-predictive control"" interchangeably.  I can use traj opt in other circumstances (e.g. with open loop trajectory following) and could use other planners for MPC.\n- Some version of lemma 2 probably (almost certainly) already exists somewhere in the literature;  I\'m sorry, though, that I can\'t point you to a concrete reference.\n- The argument about MPC letting us approximate H Bellman backups is plausible, but seems somewhat subtle;  it would be good to elaborate it in some more detail.\n- The set of assertions and experiments is very nice.\n- Why are no variances shown in figure 3?   Why does performance seem to degrade after a certain horizon.\n\nThis paper doesn\'t seem really to be about learning representations.  I don\'t know if that\'s important to the ICLR decision-making.']","[-60, -60, 60]","[20, 20, 80]","['The sentiment score is -60 because the reviewer expresses significant concerns and does not recommend accepting the paper. The review starts with some positive comments about the evaluation and results, but then presents two major criticisms that lead to a negative recommendation. The politeness score is 20 because the reviewer uses professional and respectful language throughout, acknowledging positive aspects before presenting criticisms. They avoid harsh or personal comments, instead focusing on specific technical issues. However, the overall tone is more neutral than overtly polite, hence the modest positive score.', ""The sentiment score is -60 because the review is predominantly negative. The reviewer points out several limitations of the paper, including limited novelty, loose estimation bounds, and insufficient empirical support. They state that the paper's claims are not strong enough and that it doesn't provide sufficient insight into the topic. However, it's not entirely negative as they do acknowledge that the paper is well-written and clear.\n\nThe politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'the authors do a good job of writing the paper' and 'which is appreciatable', showing some politeness. However, the criticism is direct and doesn't use many softening phrases, keeping the score only slightly positive rather than highly polite."", ""The sentiment score is 60 (positive) because the reviewer starts by saying 'This paper was a joy to read' and praises the clarity and sensibility of the framework. They also mention that the descriptions and combinations of ideas are 'very nice'. However, the score is not higher because the reviewer expresses some concerns and questions later in the review. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the strengths of the paper, and frames criticisms as questions or suggestions rather than direct attacks. Phrases like 'I'm sorry, though, that I can't point you to a concrete reference' show consideration for the authors. The reviewer maintains a professional and constructive tone throughout the review.""]"
"['\n\n=Major Comments=\nThe prior work on grid cells and deep learning makes it clear that the goal of the work is to demonstrate that a simple learning system equipped with representation learning will produce spatial representations that are grid-like. Finding grid-like representations is important because these representations occur in the mammalian brain. \n\nYour paper would be improved by making a similar argument, where you would need to draw much more explicitly on the neuroscience literature. Namely, the validation of your proposed representations for position and velocity are mostly validated by the fact that they yield grid-like representations, not that they are useful for downstream tasks.\n\nFurthermore, you should better justify why your simple model is better than prior work? What does the simplicity provide? Interpretability? Ease if optimization? Sample complexity for training?\n\nThis is important because otherwise it is unclear why you need to perform representation learning. The tasks you present (path integral and planning) could be easily performed in basic x-y coordinates. You wouldn’t need to introduce a latent v. Furthermore, this would mprove your argument for the importance of the block-diagonal M, since it would be more clear why interpretability matters.\n\n\nFinally, you definitely need to discuss the literature on randomized approximations to RBF kernels (random Fourier features). Given the way you pose the representation learning objective, I expect that these would be optimal. With this, it is clear why grid-like patterns would emerge.\n\n=Additional Comments=\nWhat can you say about the quality of the path returned by (10)? Is it guaranteed to converge to a path that ends at y? Is it the globally optimal path? \n\nI don’t agree with your statement that your approach enables simple planning by steepest descent. First of all, are the plans that your method outputs high-quality? Second, if you had solved (10) directly in x-y coordinates, you could have done this easily since it is an optimization problem in just 2 variables. That could be approximately solved by grid search.\n\nI would remove section 5.4. The latent vector v is a high-dimensional encoding of low-dimensional data, so of-course it is robust to corruptions. The corruptions you consider don’t come from a meaningful noise process, however? I can imagine, for example, that the agent observes corrupted versions of (x,y), but why would v get corrupted?\n\n', 'Updated score from 6 to 7 after the authors addressed my comments below.\n\nPrevious review:\n\nThis paper builds upon the recent work on computational models of grid cells that rely on trainable (parametric) models such as recurrent neural networks [Banino et al, 2018; Cueva & Wei, 2018]. It focuses entirely on path integration in 2D and 3D, from velocity inputs only, and it relies on two sub-networks: the motion model (an RNN) and the localization model (a feed-forward network). The avowed goal of the paper is to build a very simple and linear model for grid cells.\n\nBy linearly embedding the position x into a high-dimensional hidden vector v(x) (e.g., 96 elements), it can model motion using a linear model relying on matrix-vector multiplication: v(x + dx) = M(dx) v(x), where dx is the 2D or 3D displacement, v(.) is a vector and M(.) is a matrix. The embeddings v(.) are learnable and the paper assumes a square or cubic grid of N*N or N*N*N possible positions x (with N=40); these embeddings are also normalized to unit length and obey the kernel constraint that the dot-product between any two positions\' vectors v(x) and v(y) is a Gaussian or an exponential function. The motion matrix is represented as block diagonal, where each block is a rotation of subvector v_k(x) into v_k(x + dx), where each block corresponds to a specific grid cell, and where the diagonal block is further expressed as a quadratic function of dx_1, dx_2, dx_3 elements of the displacement vector.\n\nThe strengths of the paper are that:\n1) The supervision of the localization subnetwork only depends on Euclidean proximity between two positions x and y and therefore uses relative positions, not absolute ones. Similarly, the path integration supervision of the motion model uses only relative displacements.\n2) The resulting rate maps of the hidden units seem perfect; the model exhibits multi-scale grid behaviour.\n3) The idea of using disentangled blocks, rather than injecting noise or using dropout and a softmax bottleneck as in [Banino et al, 2018], is interesting.\n4) The model accumulates little path integration error over 1000 step-long episodes.\n\nThe weakness of the paper is its simplicity:\n1) The assumption that A(x, y) can be modeled by a Gaussian or exponential (Laplacian?) kernel is limiting, in particular for positions x and y that are far apart.\n2) There is no discussion about what egocentric vs. allocentric referentials, and dx is assumed to be aligned with (x, y) axes (which are also the axes defining the bounding box of the area).\n3) Unlike the other work on learning path integration using an RNN, the linear matrix model can only handle allocentric displacements dx_1, dx_2 (and optional dx_3 in 3D).\n4) No consideration is given to non-square areas: would the network also exhibit grid-like behavior if the area was circular?\n5) What happens if the quadratic parameterisation of block diagonals is dropped?\n6) The paper did not use metrics accepted in the neuroscience community for computing a gridness score of the grid cells (although the grid cell nature is evident). There should however be metrics for quantifying how many units represent the different scales, offsets and orientations.\n7) The authors did not consider (but mentioned) embedding locations from vision, and did not consider ambiguous position embeddings.\n\nThe experiments about path planning are unconvincing. First of all, the algorithm requires to input absolute positions of every obstacle into equation (9) - (10), which assumes that there is perfect information about the map. Secondly, the search algorithm is greedy and it is not obvious how it would handle a complex maze with cul-de-sac. Saying that ""there is no need for reinforcement learning or sophisticated optimal control"" is very misleading: the problem here is simplified to the extreme, and fully observed, and any comparison with deep RL algorithms that can handle partial observations is just out of place.\n\nIn summary, the authors have introduced an interesting and elegant model for grid cells that suffers from simplifications. The part on path planning should be cut and replaced with more analysis of the grid cells and an explanation of how the model would handle egocentric velocity.', 'This paper proposes a simple and elegant approach to learning ""grid-cell like"" representations that uses a high-dimensional encoding of position, together with a matrix for propagating position that involves only local connections among the elements of the vector.  The vectors are also constrained to have their inner products reflect positional similarity.  The paper also shows how such a representation may be used for path planning.\n\nBy stripping away the baggage and assumptions of previous approaches, I feel this paper starts to get at the essence of what drives the formation of grid cells.   It is still steps away from having direct ties to neurobiology, but is trying to get at the minimal components necessary for bringing about a grid cell like solution.  But I feel the paper also stops just a few steps short of developing a fuller theoretical understanding of what is going on.  For example the learned solution is quite Fourier like, and we know that Fourier transforms are good for representing position shift in terms of phase shift.  That would correspond to block size of two (i.e., complex numbers) in terms of this model.  So what\'s wrong with this solution (in terms of performance) and what is gained by having block size of six, beyond simply looking more grid like?  It would be nice to go beyond phenomenology and look at what the grid-like solution is useful for.\n']","[-20, 20, 60]","[50, 60, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the work and provides constructive feedback, they point out several areas where the paper needs significant improvement. The reviewer suggests that the authors need to better justify their approach, draw more explicitly from neuroscience literature, and discuss relevant prior work. These criticisms indicate that the paper has substantial room for improvement.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'Your paper would be improved by...' and 'you should better justify...' which offer suggestions rather than harsh criticisms. The reviewer also acknowledges the importance of the work and its goals. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral, professional tone overall.\n\nThe language used is constructive and focused on improving the paper, rather than being dismissive or overly critical. The reviewer provides specific recommendations and explains why these changes would be beneficial, which is a polite and helpful approach to peer review."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges several strengths of the paper, such as the supervision method, the quality of rate maps, and the interesting approach to using disentangled blocks. However, the reviewer also points out significant weaknesses and limitations, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer maintains a professional and respectful tone throughout, presenting both strengths and weaknesses objectively without using harsh language. The reviewer uses phrases like 'The strengths of the paper are...' and 'The weakness of the paper is...' which are direct but not impolite. The concluding summary is balanced, acknowledging the model as 'interesting and elegant' while also pointing out its limitations."", ""The sentiment score is 60 (positive) because the reviewer expresses appreciation for the paper's 'simple and elegant approach' and believes it 'starts to get at the essence of what drives the formation of grid cells.' The reviewer also sees value in the paper's minimalist approach. However, it's not extremely positive as the reviewer suggests the paper 'stops just a few steps short of developing a fuller theoretical understanding.' The politeness score is 70 (polite) due to the reviewer's respectful tone throughout. They use phrases like 'I feel' to soften criticisms and acknowledge the paper's strengths before suggesting improvements. The language is constructive and encouraging, avoiding harsh or dismissive statements.""]"
"['The paper proposes a method to prevent posterior collapse, which refers to the phenomenon that VAEs with powerful autoregressive decoders tend to ignore the latent code, i.e., the decoder models the data distribution independently of the code. Specifically, the encoder, decoder, and prior distribution families are chosen such that the KL-term in the ELBO is bounded away from 0, meaning that the encoder output cannot perfectly match the prior. Assuming temporal data, the authors employ a 1-step autoregressive (across) prior with an encoder whose codes are independent conditionally on the input. Furthermore, they propose to use a causal decoder together with an anti-causal or non-causal encoder, which translates into a PixelSNAIL/PixelCNN style decoder and an anti-causal version thereof as encoder in the case of image data. The proposed approach is evaluated on CIFAR10, Imagenet 32x32, and the LM1B data set (text).\n\nPros:\n\nThe method obtains state-of-the-art performance in image generation. The paper features extensive ablation experiments and is well-written. Furthermore, it is demonstrated that the code learns an abstract representation by repeatedly sampling form the decoder conditionally on the code.\n\nCons:\n\nOne question that remains is the relative contribution of 1) lower-bounding the KL-term 2) using causal decoder/anti-causal encoder to the overall result. Is the encoder-decoder structure alone enough to prevent posterior collapse? In this context it would also be interesting to see how the encoder-decoder structure performs without \\delta-constraint, but with regularization as in \\beta-VAE.\n\nWhat data set are the ablation experiments performed on? As far as I could see this is not specified.\n\nAlso, I suggest toning down the claims that the proposed method works ""without altering the ELBO training objective"" in the introduction and conclusion. After all, the encoding and decoding distributions are chosen such that the KL term in the ELBO is lower-bounded by \\delta. In other words the authors impose a constraint to the ELBO.\n\nMinor comments:\n- Space missing in the first paragraph of p 5: \\kappaas\n- ""Auxiliary prior""-paragraph on p 5: marginal posterior -> aggregate posterior?', 'General:\nThe paper attacks a problem of the posterior collapse that is one of the main issues encountered in deep generative models like VAEs. The idea of the paper relies on introducing a constraint on the family of variational posteriors in such a way that the KL term could be controlled.\n\nThe authors propose to use a linear autoregressive process (AR(1)) as the prior. Alternatively, they trained a single-layer LSTM network with conditional-Gaussian outputs as the prior (the auxiliary prior). Additionally, the authors claim that the encoder should contain anti-causal dependencies in order to introduce additional bias that may diminish the posterior collapse.\n\nThe experiments present various results on image and text datasets. Interestingly, the proposed techniques allowed to perform on a par with purely autoregressive models, however, the latent variables were utilized (i.e., no posterior collapse). For instance, in Figure 3(a) we can notice that a decoder is capable of generating similar images for given latent variable. A similar situation is obtained for text data (e.g., Figure 12).\n\nIn general, I find the paper interesting and I believe it should be discussed during ICLR.\n\nPros:\n+ The paper is well-written and all ideas are clearly presented.\n+ The idea of “hard-coded” constraints is interesting and constitutes an alternative approach to utilizing either quantized values in the VAE (VQ-VAE) or a constrained family of variational posteriors (e.g., Hyperspherical VAE).\n+ The obtained results are convincing. Additionally, I would like to highlight that at the first glance it might seem that there is no improvement over the autoregressive models. However, the proposed approach allows to encode an image or a document and then decode it. This is not a case for purely autoregressive models.\n+ The introduction of the Slow Features into the VAE framework constitutes an interesting direction for future research.\n\nCons:\n- The quality of Figure 4 is too low.\n- I am not fully convinced that the auxiliary prior is significantly better than the AR(1) prior. Indeed, the samples seem to be a bit better for the aux. prior but it is rather hard to notice by inspecting quantitative metrics.\n- In general, the proposed approach is a specific solution rather than a general framework. Nevertheless, I find it very interesting with a potential for future work.', ""The majority of approaches for preventing posterior collapse in VAEs equipped with powerful decoders to better model local structure involve either: alteration of the ELBO training objective, or a restriction on the decoder structure.\n\nThis paper presents an approach which broadly falls into the latter category; by limiting the family of the variational approximation to the posterior, the minimum KL divergence between the prior and posterior is lower bounded to a 'delta' value, preventing collapse.\n\nThe paper is well written, and the methodology clearly explained.\n\nThe experiments show that the proposed approach (delta VAE combined with the 'anti-causal' architecture) captures both local and global structure, and appears to do so while preserving SOTA discriminative performance on some tasks.  Tests are performed on both generative image and language tasks.\n\nI believe that the paper is of low-medium significance: whilst it does outline a different method of restricting the family of posteriors, it does not give a detailed reasoning (empirical or theoretical) as to why this should be a generally better solution as compared to other approaches.\n\nPros:\n- Very clear and well written.\n- Good execution and ablation/experimentation section.\n\nCons:\n- Lack of theory (and minimal experimentation) as to why this approach should be better than competing methods.\n""]","[60, 70, 50]","[80, 80, 80]","[""The sentiment score is 60 (positive) because the reviewer begins by highlighting the paper's contributions and strengths, mentioning 'state-of-the-art performance' and 'extensive ablation experiments'. They also note that it is 'well-written'. The cons are presented as questions and suggestions rather than harsh criticisms. The politeness score is 80 (quite polite) due to the constructive nature of the feedback. The reviewer uses phrases like 'I suggest' and asks questions instead of making direct criticisms. They also balance positive and negative feedback, starting with pros before moving to cons. The language throughout is professional and respectful, without any harsh or rude comments."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, stating it's 'interesting' and 'should be discussed during ICLR'. They list several pros and only a few minor cons. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths and framing criticisms constructively. They use phrases like 'I find the paper interesting' and 'The idea... is interesting', showing appreciation for the authors' work. Even when pointing out cons, the language remains professional and courteous."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths (well-written, clear methodology, good experiments) while also pointing out its limitations (low-medium significance, lack of detailed reasoning). The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's merits, and frames criticisms constructively. The reviewer uses phrases like 'I believe' to soften opinions and provides a balanced view with both pros and cons, which contributes to the polite tone.""]"
"['The paper introduces a method for online adaptation of a model that is expected to adapt to changes in the environment the model models. The method is based on a mixture model, where new models are spawned using a Chinese restaurant process, and where each newly spawned model starts with weights that have been trained using meta-learning to quickly adapt to new dynamics. The method is demonstrated on model-based RL for a few simple benchmarks.\n\nThe proposed method is well justified, clearly presented, and the experimental results are convincing. The paper is generally clear and well written. The method is clearly most useful for situations where the environment suddenly changes, which is relevant in some real-world problems. As a drawback, using a mixture model (that also grows with time) for such modelling can be considered quite heavy in some situations. Nevertheless, the idea of combining a spawning process with meta-learned priors is neat, and clearly works well.\n\nMinor comments:\n- Algorithm 1: is the inequality correct, and is T* supposed to be an argmin instead of argmax?', 'The paper presents a nonparametric mixture model of neural networks for learning in an environment with a nonstationary distribution. The problem setup includes having access to only a few ""modes"" of the distribution. Training of the initial model occurs with MAML, and distributional changes during test/operation are handled by a combination of online adaptation and creations of new mixture components when necessary. The mixture is nonparametric and modeled with a CRP. The application considered in the paper is RL, and the experiments compare proposed model against baselines that do not utilize meta-learning (achieved in the proposed method with MAML), and baselines which utilize only a single model component.\n\nI thought the combination of meta-learning and a CRP was a neat way to tackle the problem of modeling and learning the ""modes"" of a nonstationary distribution. Applications in other domains would have been nice, but the presented results in RL sufficiently demonstrate the benefits of the proposed method.\n\n* Questions/Comments\n\nFigure 3 left vs right?\n\nIs the test in the middle of Algorithm 1 correct?', 'The authors proposed a new method to learn streaming online updates for neural networks with meta-learning and applied it to multi-task reinforcement learning. Model-agnostic meta-learning is used to learn the initial weight and task distribution is learned with the Chinese restaurant process. It sounds like an interesting idea and practical for RL. Extensive experiments show the effectiveness of the proposed method.\n\nThe authors said that online updating the meta-learner did not improve the results, which is a bit surprised. Also how many data are meta-trained is not clearly described in the paper. Maybe the authors can compare the results with less data for meta-training.\n']","[80, 70, 60]","[70, 50, 50]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They state that the method is 'well justified, clearly presented, and the experimental results are convincing.' The reviewer also praises the paper as 'generally clear and well written' and describes the idea as 'neat' and working well. While they mention a potential drawback, it's presented as a minor concern.\n\nThe politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They begin with positive comments and frame their critique in a balanced way. The use of phrases like 'well justified,' 'clearly presented,' and 'convincing' shows respect for the authors' work. Even when pointing out a potential drawback, the reviewer does so gently and follows it with more praise. The 'Minor comments' section is presented neutrally and appears to be genuinely aimed at improving the paper rather than criticizing it."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper. They describe the approach as 'neat' and state that the results 'sufficiently demonstrate the benefits of the proposed method.' There are no significant criticisms mentioned. The politeness score is 50 (slightly polite) because the language is professional and respectful, without being overly formal or effusive. The reviewer uses phrases like 'I thought' to soften their opinions and asks questions rather than making demands. However, the review is also quite direct and doesn't use many explicitly polite phrases, keeping it from scoring higher on politeness."", ""The sentiment score is 60 (positive) because the reviewer describes the proposed method as 'interesting' and 'practical', and mentions that 'extensive experiments show the effectiveness of the proposed method'. However, it's not extremely positive as the reviewer also expresses surprise at one of the results and suggests additional comparisons. The politeness score is 50 (somewhat polite) because the language is professional and constructive, without any harsh criticism. The reviewer offers suggestions for improvement in a respectful manner, using phrases like 'Maybe the authors can...' which is polite. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral, professional tone overall.""]"
"['Update:\n\nI thank the authors for the response. Unfortunately, the response does not mention modifications made to the paper according to the comments. According to pdfdiff, modifications to the paper are very minor, and none of my comments are addressed in the paper. I think the paper shows good results, but it could very much benefit from improved presentation and evaluation. I do recommend acceptance, but if the authors put more work in improving the paper, it could have a larger impact.\n\n------\n\nThe paper proposes a learnable planning model based on value iteration. The proposed methods can be seen as modifications of Value Iteration Networks (VIN), with some improvements aimed at improving sample efficiency and generalization to large environment sizes. The method is validated on gridworld-type environments, as well as on a more complex StarCraft-based domain with raw pixel input.\n\nPros:\n1) The topic of the paper is interesting: combining the advantages of learning and planning seems like a promising direction to achieving adaptive and generalizable systems.\n2) The presentation is quite good, although some details are missing.\n3) The proposed method can be effectively trained with reinforcement learning and generalizes well to much larger environments than trained on. It beats vanilla VIN by a large margin. The MVProp variant of the method is especially successful.\n\nCons:\n1) I would like to see a more complete discussion of the MVProp method. Propagation of only positive rewards seems like somewhat of a hack. Is this a general solution or is it only applicable to gridworld navigation-type tasks? Why? If not, is the area of applicability of MVProp different from VProp? Also, is the area of applicability of VProp different from VIN? It’s important to discuss this in detail.\n2) I wonder how would the method behave in more realistic gridworld environments, for instance similar in layout to those used in RL navigation literature (DMLab, ViZDoom, MINOS, etc). The presented environments are quite artificial and seem to basically only require “obstacle avoidance”, not so much deliberate long-distance planning.\n3) Some details are missing. For instance, I was not able to find the exact network architectures used in different tasks. \nRelated to this, I was confused by the phrase “As these new environments are not static, the agent needs to re-plan at every step, forcing us to train on 8x8 maps to reduce the time spent rolling-out the recurrent modules.” I might be misunderstanding something, but is there any recurrent network in VProp? Isn’t it just predicting the parameters once and then rolling our value iteration forward without any learning? Is this so time-consuming?\n4) Why does the performance even of the best method not reach 100% even in the simpler environments in Figure 2? Why is the performance plateauing far from 100% in the more difficult case? It would be interesting to see more analysis of how the method works, when it fails, and which parts still need improvement. On a related topic, it would be good to see more qualitative results both in MazeBaze and StarCraft - in the form of images or videos.\n5) Novelty is somewhat limited: the method is conceptually similar to VIN. \n\nTo conclude, I think the paper is interesting and the proposed method seems to perform well in the tested environments. I am quite positive about the paper, and I will gladly raise the rating if my questions are addressed satisfactorily.', ""Update:\nI thank the authors for their clarifications. I have raised my rating, however I believe the exposition of the paper should be improved and some of their responses should be integrated to the main text.\n\nThe paper proposes two new modules to overcome some limitations of VIN, but the additional or alternative hypotheses used compared to VIN are not clearly stated and explained in my opinion. \n\n    Pros :\n    - experiments are numerous and advanced\n    - transition probabilities are not transition-invariant compared to VIN\n    - do not need pretraining trajectories\n\n    Cons :\n    - limitation and hypotheses are not very explicit\n\n    Questions/remarks :\n    - d_{rew} is not defined \n    - the shared weights should be explained in more details\n    - sometimes \\psi(s) is written as parametrized by \\theta, sometime not\n    - is it normal that the \\gamma never appears in your formula to update the \\theta and w? yet reading the background part I feel that you optimize the discounted sum of the rewards, is it the case?\n    - I think there is a mistake in the definition of 1_{s' \\neq \\emptyset }, it is 1 if s' is NOT terminal and 0 otherwise, am I wrong?\n    - why do you need the parameters w to represent the value function V, if you already have v^k_{i,j} available? is it just to say that your NN is updated with two distinct cost functions? \n    - I did not understand the assumptions made by VProp, do you consider that the transition function T is known? this seems to be the case when you explain that transitions are deterministic and that there is a mapping between the actions and the positions, but is never really said\n    - Compared to VIN, VProp uses an extra maximum to compute v^k_{i, j}, why? In this case, the approximation of the value function can never decrease.\n    - How is R_{a, i, j, i ', j'} broken into r^{in}_{i ', j'} - r^{out}_{i, j} in VProp? Is the reward function known to the agent at all points?\n    - In MVProp, can r_{i, j} be negative?\n    - In MVProp, how does the rewriting in p * v + r * (1-p) shows that only positive rewards are propagated? Does not it come only from the max?\n    - In the experiments, S is not fully described, \\phi(s) neither\n"", ""The paper presents an extension of the original value iteration networks (VIN) by considering state-dependent transition function, which alleviates the limitation of VIN to translation-invariant transition functions and further constraining the reward function parametrization to improve sample efficiency of learning to plan algorithms. The first problem is addressed  by interpreting transition probabilities as state-dependent discount factors, given by a sigmoid function that takes as input state features. The second problem is addressed by defining the reward function as the difference between an input reward and an output cost. Obstacle states are given a high cost. The proposed method is evaluated on random grids of different sizes, of the same type as the grids considered in the VIN paper. Comparaisons with VIN show that the proposed MVProp approach outperforms VIN by several orders of magnitude and can learn optimal plans in less than a thousand episodes, compared to VIN that doesn't seem here to learn much even after 30 thousands episodes. \nThe paper is well-written in general. Certain aspects of value iteration networks were explained too briefly and the reviewer had to re-read the original VIN paper to grasp certain details of the proposed approach. This work is an interesting improvement of VIN, but somehow incremental in nature as the improvement is limited to slightly changing the reward and transition representations. However, the resulting performance seems very impressive, especially for larger grids. One question that needs to be clarified is: how is this work situated with respect to the body of work on RL? How does this method compare empirically to model-free algorithms such as DDPG and PPO?""]","[-20, 20, 50]","[50, 60, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('good results', 'interesting topic', 'quite good' presentation), they express disappointment that their previous comments were not addressed and that only minor modifications were made to the paper. The reviewer also lists several 'cons' and areas for improvement, indicating a mixed but slightly negative overall sentiment.\n\nThe politeness score is moderately positive (50) because the reviewer uses respectful and professional language throughout. They begin by thanking the authors for their response, which is a polite gesture. The critique is presented in a constructive manner, with both pros and cons listed. The reviewer also uses phrases like 'I would like to see', 'I wonder', and 'It would be interesting to see' when suggesting improvements, which maintains a polite tone. The conclusion is also balanced and encouraging, stating that the reviewer is 'quite positive about the paper' and would 'gladly raise the rating' if their questions are addressed."", ""Sentiment Score (20): The review starts with a positive note, thanking the authors for clarifications and mentioning a raised rating. However, it also points out areas for improvement and lists both pros and cons. The majority of the review consists of questions and remarks, indicating a critical but not overly negative stance. The overall tone is slightly positive but with significant reservations.\n\nPoliteness Score (60): The reviewer uses polite language throughout, starting with a thank you and using non-confrontational phrasing for criticisms. Questions are posed in a respectful manner, and the tone remains professional. The use of 'I believe' and 'in my opinion' softens potential criticisms. However, the review doesn't go out of its way to be excessively polite, maintaining a professional, slightly formal tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and impressive performance improvements, calling it an 'interesting improvement.' However, they also note that it's 'somehow incremental in nature' and point out some limitations, balancing the positive aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'well-written in general' and 'interesting improvement,' which maintain a positive tone. The reviewer also poses questions for clarification rather than making outright criticisms. The slightly lower score is due to some direct statements about limitations, but these are presented professionally.""]"
"['This paper considers how to augment training data by applying class-preserving transformations to selected datapoints.\nIt proposes improving random datapoint selection by selection policies based on two metrics: the training loss \nassociate with each datapoint (""Loss""), and the influence score (from Koh and Liang that approximates leave-one-one test loss). The authors consider two policies based on these metrics: apply transformations to training points in decreasing \norder of their score, or to training points sampled with probability proportional to score. They also consider two \nrefinements: downweighting observations that are selected for transformation, and updating scores everytime \ntransformations associated with an observation are added. \n\nThe problem the authors tackle is important and their approach is natural and promising. On the downside, the theoretical \ncontribution is moderate, and the empirical studies quite limited. \n\nThe stated goals of the paper are quite modest: ""In this work, we demonstrate that it is possible to significantly reduce the \nnumber of data points included in data augmentation while realizing the same accuracy and invariance benefits of \naugmenting the entire dataset"". It is not too surprising that carefully choosing observations according suitable policies \nis an improvement over random subsampling, especially, when the test data has been ""poisoned"" to highlight this effect. \nThe authors have demonstrated that two intuitive policies do indeed work, have quantified this on 3 datasets. \n\nHowever they do not address the important question of whether doing so can improve training time/efficiency. In other words, the authors have not attempted to investigate the computational cost of trying to assign importance scores to each observation. Thus this paper does not really demonstrate the overall usefulness of the proposed methodology.\n\nThe experimental setup is also limited to (I think) favor the proposed methodology. Features are precomputed on images using a CNN, and the different methods are compared on a logistic regression layer acting on the frozen features. The existence of such a pretrained model is necessary for the proposed methods, otherwise one cannot assign selection scores to different datapoints. However, this is not needed for random selection, where the transformed inputs can directly be input to the system. A not unreasonable baseline would be to train the entire CNN with the augmented 5%,10%, 25% datasets, rather than just the last layer. Of course this now involves training the entire CNN on the augmented dataset, rather than just the last layer, but how relevant is the two stage training approach that the authors propose?\n\nIn short, while I think the proposed methodology is promising, the authors missed a chance to include a more thorough analysis of the trade-offs of their method.\n\nI also think the paper makes only a minimal effort to understand the policies, the experiments could have helped shed some more light on this.\n\nMinor point:\nThe definition of ""influence"" is terse e.g. I do not see the definition of H anywhere (the Hessian of the empirical loss)', 'Data augmentation is a useful technique, but can lead to undesirably large data sets. The authors propose to use influence or loss-based methods to select a small subset of points to use in augmenting data sets for training models where the loss is additive over data points, and investigate the performance of their schemes when logistic loss is used over CNN features. Specifically, they propose selecting which data points to augment by either choosing points where the training loss is high, or where the statistical influence score is high (as defined in Koh and Liang 2017). The cost of their method is that of fitting an initial model on the training set, then fitting the final model on the augmented data set.\n\nThey compare to reasonable baselines: no augmentation, augmentation by transforming only a uniformly random chosen portion of the training data, and full training data augmentation; and show that augmenting even 10% of the data with their schemes can give loss competitive with full data augmentation, and lower than the loss achievable with no augmentation or augmentation of a uniformly random chosen portion of the data of similar size. Experiments were done on MNIST, CIFAR, and NORB.\n\nThe paper is clearly written, the idea is intuitively attractive, and the experiments give convincing evidence that the method is practically useful. I believe it will be of interest to a large portion of the ICLR community, given the usefulness of data augmentation.', 'Summary: The authors study the problem of identifying subsampling strategies for data augmentation, primarily for encoding invariances in learning methods. The problem seems relevant with applications to learning invariances as well as close connections with the covariate shift problem. \n\nContributions: The key contributions include the proposal of strategies based on model influence and loss as well as empirical benchmarking of the proposed methods on vision datasets. \n\nClarity: While the paper is written well and is easily accessible, the plots and the numbers in the tables were a bit small and thereby hard to read. I would suggest the authors to have bigger plots and tables in future revisions to ensure readability. \n\n>> The authors mention in Section 4.1 that ""support vector are points with non-zero loss"": In all generality, this statement seems to be incorrect. For example, even for linearly separable data, a linear SVM would have support vectors which are correctly classified. \n\n>> The experiment section seems to be missing a table on the statistics of the datasets used: This is important to understand the class distribution in the datasets used and if at all there was label imbalance in any of them. It looks like all the datasets used for experimentation had almost balanced class labels and in order to fully understand the scope of these sampling strategies, I would suggest the authors to also provide results on class imbalanced datasets where the distribution over labels is non-uniform. \n\n>> Incomprehensive comparison with benchmarks: \na) The comparison of their methods with VSV benchmark seems incomplete. While the authors used the obtained support vectors as the augmentation set and argued that it is of fixed size, a natural way to extend these to any support size is to instead use margin based sampling where the margins are obtained from the trained SVM since these are inherently margin maximizing classifiers. Low margin points are likely to be more influential than high margin points.\nb) In Section 5.3, a key takeaway is ""diversity and removing redundancy is key in learning invariances"". This leads to possibly other benchmarks to which the proposed policies could be compared, for example those based on Determinantal point processes (DPP) which are known for inducing diversity in subset selection. There is a large literature on sampling diverse subsets (based on submodular notions of diversity) which seems to be missing from comparisons. Another possible way to overcome this would be to use stratified sampling to promote equal representation amongst all classes. \nc) In Section 2, it is mentioned that general methods for dataset reduction are orthogonal to the class of methods considered in this paper. However, on looking at the data augmentation problem as that of using fewest samples possible to learn a new invariance, it can be reduced to a dataset reduction problem. One way of using these reduction methods is to use the selected set of datapoints as the augmentation set and compare their performance. This would provide another set of benchmarks to which proposed methods should be compared.\n\n>> Accuracy Metrics: While the authors look at the overall accuracy of the learnt classifiers, in order to understand the efficacy of the proposed sampling methods at learning invariances, it would be helpful to see the performance numbers separately on the original dataset as well as the transformed dataset using the various transformations. \n\n>> Experiments in other domains: The proposed schemes seem to be general enough to be applicable to domains other than computer vision. Since the focus of the paper is the proposal of general sampling strategies, it would be good to compare them to baselines on other domains possibly text datasets or audio datasets. ']","[-20, 80, 20]","[50, 60, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the importance of the problem and the promising approach, they express several criticisms. They note that the theoretical contribution is moderate, the empirical studies are limited, and the authors missed opportunities for more thorough analysis. The reviewer also points out limitations in the experimental setup and suggests that the authors didn't fully demonstrate the overall usefulness of their methodology. However, the tone isn't entirely negative, as the reviewer does recognize some positive aspects of the work.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They balance criticism with acknowledgment of the paper's strengths, using phrases like 'The problem the authors tackle is important and their approach is natural and promising.' Even when pointing out limitations, the language remains constructive rather than harsh. The reviewer also uses softening phrases like 'I think' and 'not unreasonable' when presenting alternative viewpoints, which contributes to the overall polite tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They describe the idea as 'intuitively attractive' and the experiments as giving 'convincing evidence'. They also state that the paper is 'clearly written' and will be 'of interest to a large portion of the ICLR community'. The politeness score is 60 (moderately polite) because the reviewer uses respectful and professional language throughout, acknowledging the authors' work positively without using overly effusive praise. They provide a balanced and constructive review, focusing on the merits of the work without any harsh criticism or dismissive language."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the relevance and contributions of the paper, and provides constructive feedback. However, they also point out several areas for improvement and missing elements, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers suggestions rather than demands, and acknowledges the paper's strengths. The reviewer maintains a professional tone, using phrases like 'I would suggest' and 'it would be helpful', which contributes to the politeness. The critique is presented as constructive feedback rather than harsh criticism, further supporting the positive politeness score.""]"
"['The papers studies neural network-based sparse signal recovery, and derives many new theoretical insights into the classical LISTA model. The authors proposed Analytic LISTA (ALISTA), where the weight matrix in LISTA is pre-computed with a data-free coherence minimization, followed by a separate data-driven learning step for merely (a very small number of) step-size and threshold parameters. Their theory is extensible to convolutional cases. The two-stage decomposed pipeline was shown to keep the optimal linear convergence proved in (Chen et al., 2018). Experiments observe that ALISTA has almost no performance loss compared to the much heavier parameterized LISTA, in contrast to the common wisdom that (brutal-force) “end-to-end” always outperforms stage-wise training. Their contributions thus manifest in both novel theory results, and the practical impacts of simplifying/accelerating LISTA training.  Besides, they also proposed an interesting new strategy called Robust ALISTA to overcome the small perturbations on the encoding basis, which also benefits from this decomposed problems structure. \n\nThe proofs and conclusions are mathematically correct to my best knowledge. I personally worked on similar sparse unfolding problems before so this work looks particularly novel and interesting to me. My intuition then was that, it should not be really necessary to use heavily parameterized networks to approximate a simple linear sparse coding form (LISTA idea). Similar accelerations could have been achieved with line search for something similar to steepest descent (also computational expensive, but need learn step-sizes only, and agnostic to input distribution). Correspondingly, there should exist a more elegant network solution with very light learnable weights. This work perfectly coincides with the intuition, providing very solid guidance on how a LISTA model could be built right. Given in recent three years, many application works rely on unfold-truncating techniques (compressive sensing, reconstruction, super resolution, image restoration, clustering…), I envision this paper to generate important impacts for practitioners pursuing those ideas. \n\nAdditionally, I like Theorem 3 in Section 3.1, on the provable efficient approximation of general convolution using circular convolution. It could be useful for many other problems such as filter response matching. \n\nI therefore hold a very positive attitude towards this paper and support for its acceptance. Some questions I would like the authors to clarify & improve in revision:\n\n1.\tEqn (7) assumes noise-free case. The author stated “The zero-noise assumption is for simplicity of the proofs.” Could the authors elaborate which part of current theory/proof will fail in noisy case? If so, can it be overcome (even by less “simpler” way)? How about convolutional case, the same? Could the authors at least provide some empirical results for ALISTA’s performance under noise?\n\n2.\tSection 5.3. It is unclear to me why Robust ALISTA has to work better than the data augmented ALISTA. Is it potentially because that in the data augmentation baseline, the training data volume is much amplified, and one ALISTA model might become underfitting? It would be interesting to create a larger-capacity ALISTA model (e.g., by increasing unfolded layer numbers), train it on the augmented data, and see if it can compare more favorably against Robust ALISTA?\n\n3.\tThe writeup is overall very good, mature, and easy to follow. But still, typos occur from time to time, showing a bit rush. For example, Section 5.1, “the x-axes denotes is the indices of layers” should remove “is”. Please make sure more proofreading will be done.\n\n', 'The paper describes ALISTA, a version of LISTA that uses the dictionary only for one of its roles (synthesis) in ISTA and learns a matrix to play the other role (analysis), as seen in equations (3) and (6). The number of matrices to learn is reduced by tying the different layers of LISTA together.\n\nThe motivation for this paper is a little confusing. ISTA, FISTA, etc. are algorithms for sparse recovery that do not require training. LISTA modified ISTA to allow for training of the ""dictionary matrix"" used in each iteration of ISTA, assuming that it is unknown, and offering a deep-learning-based alternative to dictionary learning. ALISTA shows that the dictionary does not need to change, and fewer parameters are used than in LISTA, but it still requires learning matrices of the same dimensionality as LISTA (i.e., the reduction is in the constant, not the order). If the argument that fewer parameters are needed is impactful, then the paper should discuss the computational complexity (and computing times) for training ALISTA vs. the competing approaches.\n\nThere are approaches to sparse modeling that assume separate analysis and synthesis dictionaries (e.g., Rubinstein and Elad, ""Dictionary Learning for Analysis-Synthesis Thresholding""). A discussion of these would be relevant in this paper.\n\n* The intuition and feasibility of identifying ""good"" matrices (Defs. 1 and 2) should be detailed. For example, how do we know that an arbitrary starting W belongs in the set (12) so that (14) applies? \n* Can you comment on the difference between the maximum entry ""norm"" used in Def. 1 and the Frobenius norm used in (17)?\n* Definition 3: No dependence on theta(k) appears in (13), thus it is not clear how ""as long as theta(k) is large enough"" is obtained. \n* How is gamma learned (Section 2.3)?\n* The notation in Section 3 is a bit confusing - lowercase letters b, d, x refer to matrices instead of vectors. In (20), Dconv,m(.) is undefined; later Wconv is undefined.\n* For the convolutional formulation of Section 3, it is not clear why some transposes from (6) disappear in (21).\n* In Section 3.1, ""an efficient approximated way"" is an incomplete sentence - perhaps you mean ""an efficient approximation""?. Before (25), Dconv should be Dcir? The dependence on d should be more explicitly stated.\n* Page 8 typo ""Figure 1 (a) (a)"".\n* Figure 2(a): the legend is better used as the label for the y axis.\n* I do not think Figure 2(b) verifies Theorem 1; rather, it verifies that your learning scheme gives parameter values that allow for Theorem 1 to apply (which is true by design).\n* Figure 3: isn\'t it easier to use metrics from support detection (false alarm/missed detection proportions given by the ALISTA output)?', 'The paper raises many important questions about unrolled iterative optimization algorithms, and answers many questions for the case of iterative soft thresholding algorithm (ISTA, and learned variant LISTA). The authors demonstrate that a major simplification is available for the learned network: instead of learning a matrix for each layer, or even a single (potentially large) matrix, one may obtain the matrix analytically and learn only a series of scalars. These simplifications are not only practically useful but allow for theoretical analysis in the context of optimization theory. On top of this seminal contribution, the results are extended to the convolutional-LISTA setting. Finally, yet another fascinating result is presented, namely that the analytic weights can  be determined from a Gaussian-perturbed version of the dictionary. Experimental validation of all results is presented.\n\nMy only constructive criticism of this paper are a few grammatical typos, but specifically the 2nd to  last sentence before Sec 2.1 states the wrong thing ""In this way, the LISTA model could be further significantly simplified, without little performance loss""\n...\nit should be ""with little"".\n']","[90, -20, 90]","[80, 50, 80]","[""The sentiment score is 90 (highly positive) because the reviewer expresses strong approval of the paper, using phrases like 'very positive attitude', 'support for its acceptance', and praising the work as 'novel and interesting'. They highlight the paper's contributions in theory and practical impacts, and predict it will have important impacts in the field. The politeness score is 80 (quite polite) due to the respectful and constructive tone throughout. The reviewer uses phrases like 'I personally worked on similar problems' and 'I like Theorem 3', showing engagement with the work. They offer suggestions for improvement in a courteous manner, using phrases like 'Could the authors elaborate' and 'It would be interesting'. The slight deduction from 100 is due to the mention of typos, which is a mild criticism, albeit expressed politely."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contribution, they express confusion about the motivation and point out several areas needing clarification or improvement. The review is not entirely negative, as it provides constructive feedback, but the overall tone suggests the paper needs significant work. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout. They phrase criticisms as questions or suggestions rather than direct attacks, and use polite language like 'can you comment' and 'please'. The reviewer also provides detailed, helpful feedback, which is a courteous approach to peer review. However, the score is not extremely high as the language, while polite, is not overly warm or encouraging."", ""The sentiment score is 90 (highly positive) because the reviewer describes the paper as raising 'important questions' and making a 'seminal contribution'. They use positive phrases like 'fascinating result' and praise the 'experimental validation'. The only criticism is minor and described as 'constructive'. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their single criticism very gently as 'constructive' and focusing on a small grammatical error. The reviewer's tone is professional and appreciative throughout, without being overly deferential.""]"
"['The authors propose a bidirectional model for learning a policy. In particular, a backtracking model was proposed to start from a high-value state and sample back the sequence of actions and states that could lead to the current high-value state. These traces can be used later for learning a good policy. The experiments show the effectiveness of the model in terms of increase the expected rewards in different tasks. However, learning the backtracking model would add some computational efforts to the entire learning phase. I would like to see experiments to show the computational time for these components. \n', ""This paper nicely proposes a back-tracking model that predicts the trajectories that may lead to high-value states. The proposed approach was shown to be effective in improving sample efficiency for a number of environments and tasks.\n\nThis paper looks solid to me, well-written motivation with theoretical interpretations, although I am not an expert in RL.\n\nComments / questions:\n- how does the backtracking model correspond to a forward-model? And it doesn't seem to be contradictory to me that the two can work together.\n- could the authors give a bit more explanation on why the backtracking model and the policy are trained jointly? Would it still work if to train the backtracking model offline by, say, watching demonstration?\n\nOverall this looks like a nice paper. "", ""Revision:\nThe authors have thoroughly addressed my review and I have consequently updated my rating accordingly.\n\nSummary:\nModel-free reinforcement learning is inefficient at exploration if rewards are\nsparse / low probability.\nThe paper proposes a variational model for online learning to backtrack\nstate / action traces that lead to high reward states based on best previous\nsamples.\nThe backtracking models' generated recall traces are then used to augment policy\ntraining by imitation learning, i.e. by optimizing policy to take actions that\nare taken from the current states in generated recall traces.\nOverall, the methodology seems akin to an adaptive importance sampling\napproach for reinforcement learning.\n\nEvaluation:\nThe paper gives a clear (at least mathematically) presentation of the core idea\nbut it some details about modeling choices seem to be missing.\nThe experimental evaluation seems preliminary and it is not fully evident when\nand how the proposed method will be practically relevant (and not relevant).\n\nMy knowledgable of the previous literature is not sufficient to validate the\nclaimed novelty of the approach.\n\nDetails:\nThe paper is well written and easy to follow in general.\n\nI'm not familiar enough with reinforcment learning benchmarks to judge the\nquality of the experiments compared to the literature as a whole.\nAlthough there are quite a few experiments they seem rather preliminary.\nIt is not clear whether enough work was done to understand the effect of the\nmany different hyperparameters that the proposed method surely must have.\n\nThe authors claim to show empirically that their method can improve sample\nefficiency.\nThis is not necessarily a strong claim as such and could be achieved on\nrelatively simple tests.\nIn the discussion the authors claim their results indicate that their approach\nis able to accelearte learning on a variety of tasks, also not a strong claim.\n\nThe paper could be improved by adding a more clear explanation of the exact way\nby which the method helps with exploration and how it affects finding sparse\nrewards (based on e.g. Figure 1).\nIt seems that since only knowledge of seen trajectories can be used to generate\npaths to high reward states it only works for generating new trajectories\nthrough previously visited states.\n\nQuestions that could be clarified:\n- It is not entirely obvious to me what parametric models are used for the\nbacktracking distributions.\n- Does this method not also potentially hinder exploration by making the agent\nlearn to go after the same high rewards / Does the direction of the variational\nproblem guarantee coverage of the support of the R > L distribution by samples?\n- What would be the effect of a hyperparameter that balances learning the recall\ntraces and learning the true environment?\n- Are there also reinforcement learning tasks where the proposed methods'\nimprovement is marginal and the extra modeling effort is not justified (e.g.\ndue to increase complexity).\n\nPage 1: iwth (Typo)\nPage 2: r(s_t) -> r(s_t, a_t)\nPage 6: Prioritize d (Typo)\n""]","[50, 80, 50]","[75, 90, 75]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the effectiveness of the proposed model in increasing expected rewards, but also expresses concerns about computational efforts and requests additional experiments. This balanced view indicates a moderately positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, such as 'I would like to see' instead of demanding changes. The reviewer also begins by summarizing the authors' work objectively before offering critiques, which is a polite approach in academic reviews."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'nicely proposes', 'effective', 'solid', and 'well-written'. They conclude by saying 'Overall this looks like a nice paper.' The only slight hesitation is when they mention not being an expert in RL, but this doesn't detract significantly from the positive tone. The politeness score is 90 (very polite) due to the consistently respectful and constructive language used throughout. The reviewer offers praise, asks questions politely, and suggests improvements in a gentle manner. They use phrases like 'could the authors give' instead of demanding changes, which contributes to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges that the authors have 'thoroughly addressed' their previous review and updated their rating accordingly. They also note that the paper is 'well written and easy to follow in general'. However, they also point out areas for improvement and express some reservations about the experimental evaluation. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames their comments as suggestions or questions rather than demands. They acknowledge their own limitations ('My knowledgable of the previous literature is not sufficient...') and use phrases like 'could be improved' rather than more critical language. The reviewer also points out positive aspects of the paper alongside areas for improvement.""]"
"['\nThis paper shows that with a clever initialization method ResNets can be trained without using batch-norm (and other normalization techniques).  The network can still reach state-of-the-art performance.\n\n\nThe authors propose a new initialization method called ""ZeroInit"" and use it to train very deep ResNets (up to 10000 layers). They also show that the test performance of their method matches the performance of state-of-the-art results on many tasks with the help of strong data augmentation. This paper also indicates that the role of normalization in training deep resnets might not be as important as people thought. In sum, this is a very interesting paper that has novel contribution to the practical side of neural networks and new insights on the theoretical side. \n\nPros:\n1. The analysis is not complicated and the algorithm for ZeroInit is not complicated.  \n2. Many people believe normalization (batch-norm, layer-norm, etc. ) not only improves the trainability of deep NNs but also improves their generalization. This paper provides empirical support that NNs can still generalize well without using normalization. It might be the case that the benefits from the data augmentation (i.e., Mixup + Cutout) strictly contain those from normalization. Thus it is interesting to see if the network can still generalize well (achieving >=95% test accuracy on Cifar10)  without using strong data-augmentation like mixup or cutout. \n3.Theoretical analysis of BatchNorm (and other normalization methods) is quite challenging and often very technical. The empirical results of this paper indicate that such analysis, although very interesting, might not be necessary for the theoretical understanding of ResNets.  \n\n\nCons:\n1.The analysis works for positively homogeneous activation functions i.e. ReLU, but not for tanh or Swish. \n2.The method works for Residual architectures, but may not be applied to Non-Residual networks (i.e. VGG, Inception)  ', ""Summary: \nA method is presented for initialization and normalization of deep residual networks. The method is based on interesting observations regarding forward and backward explosion in such networks with the standard Xavier or (He, 2015) initializations. Experiments with the new method show that it is able to learn with very deep networks, and that its performance is on a par with the best results obtained by other networks with more explicit normalization.\nAdvantages:\n-\tThe paper includes interesting observations, resulting in two theorems,  which show the sensitivity of traditional initializations in residual networks\n-\tThe method presented seems to work comparable to other state of the art initialization + normalization methods, providing overall strong empirical results. \nDisadvantages:\n-\tThe authors claim to suggest a method without normalization, but the claim is misleading: the network has additive and multiplicative normalization nodes, and their function and placement is at least as ‘mysterious’  as the role of normalization in methods like batch and layer normalization.\no\tThis significantly limits the novelty of the method: it is not ‘an intialization’ method, but a combination of initialization and normalization, which differ from previous ones in some details. \n-\tThe method includes 3 components, of which only one is justified in a principled manner. The other components are not justified neither by an argument, nor by experiments. Without such experiments, it is not clear what actually works in this method, and what is not important.\n-\tThe argument for the ‘justified’ component is not entirely clear to me. The main gist is fine, but important details are not explained so I could not get the entire argument step-by-step. This may be a clarity problem, or maybe indicate deeper problem of arbitrary decisions made without justification – I am not entirely sure. Such lack of clear argumentation occurs in several places\n-\tExperiments isolating the contribution of the method with respect to traditional initializations are missing (for example: experiments on Cifar10 and SVHN showing the result of traditional initializations with all the bells and whistles (cutout, mixup) as the zeroInit gets.\n\nMore detailed comments:\nPage 3:\n-\tWhile I could follow the general argument before eq. 2, leading to the conclusion that the initial variance in a resnet explodes exponentially, I could not understand eq. 2. What is its justification and how is it related to the discussion before it? I think it requires some argumentation.\nPage 4:\n-\tI did not understand example 2) for a p.h. set. I think an argument, reminder of the details of resnet, or a figure are required.\n-\tI could not follow the details of the argument leading to the zeroInit method:\no\tHow is the second design principle “Var[F_l(x_l)] = O( 1/L) justified?\nAs far as I can see, having Var[F_l(x_l)] = 1/L will lead to output variance of (1+1/L)^L =~e, which is indeed O(1). Is this the argument? Is yes, why wasn’t it stated? Also: why not smaller than O(1/L)?\no\tFollowing this design principle several unclear sentences are stated:\n\uf0a7\tWe strive to make Var[F_l(x_l)] = 1/L, yet we set the last convolutional layer in the branch to 0 weights. Does not it set Var[F_l(x_l)] = 0, in contradiction to the 1/L requirement?\n\uf0a7\t “Assuming the error signal passing to the branch is O(1),” – what does the term “error signal” refer to? How is it defined? Do you refer to the branch’s input?\n\uf0a7\tI understand why the input to the m-th layer in the branch is O(\\Lambda^m-1) if the branch input is O(1) but why is it claimed that “the overall scaling of the residual branch after update is O(\\lambda^(2m-2))”? what is ‘the overall scaling after update’ (definition) and why is it the square of forward scaling?\n-\tThe zero Init procedure step 3 is not justified by any argument in the proceeding discussion. Is there any reason for this policy? Or was it found by trial and error and is currently unjustified theoretically (justified empirically instead). This issue should be clearly elaborated in the text. Note that the addition of trainable additive and multiplicative elements is inserting the normalization back, while it was claimed to be eliminated. If I understand correctly, the ‘zeroInit’ method is hence not based on initialization (or at least: not only on initialization), but on another form of normalization, which is not more justified than its competitors (in fact it is even more mysterious: what should we need an additive bias before every element in the network?)\nPage 5:\n-\tWhat is \\sqrt(1/2) scaling? It should be defined or given a reference.\nPage 6:\n-\tIt is not stated on what data set figure 2 was generated.\n-\tIn table 2, for Cifar-10 the comparison between Xavier init and zeroInit shows only a small advantage for the latter. For SVHN such an experiment is completely missing, and should be added.\no\tIt raises the suspect the the good results obtained with zeroInit in this table are only due to the CutOut and mixup used, that is: maybe such results could be obtained with CutOut+Mixup without zero init, using plain Xavier init? experiments clarifying this point are also missing.\nAdditional missing experiments:\n-\tIt seems that  ZeroInit includes 3 ingredients (according to the box in page 4), among which only one (number 2) is roughly justified from the discussion.  Step 1) of zeroing the last layer in each branch is not justified –why are we zeroing the last layer and not the first, for example? Step 3 is not even discussed in the text – it appear without any argumentation. For such steps, empirical evidence should be brought, and experiments doing this are missing. Specifically experiments of interest are:\no\tUsing zero init without its step 3: does it work? The theory says it should.\no\tUsing only step 3 without steps 1,2. Maybe only the normalization is doing the magic?\nThe paper is longer than 8 pages.\n\nI have read the rebuttal.\nRegarding normalization: I think that there are at least two reasonable meanings to the word 'normalziation': in the wider sense is just means mechanism for reducing a global constant (additive normalization) and dividing by a global constant (multiplicative normalization). In this sense the constant parameters can be learnt in any way. In the narrow sense the constants have to be statistics of the data. I agree with the authors that their method is not normalization in sense 2, only in sense 1. Note that keeping the normalization in sense 1 is not trivial (why do we need these normalization operations? at least for the multiplicative ones, the network has the same expressive power without them).  I think the meaning of normalization  should be clearly explained in the claim for 'no  normalization'.\nRegarding additional mathematical and empirical justifications required: I think such justifications are missing in the current paper version and are not minor or easy to add. I believe the work should be re-judged after re-submission of a version addressing the problems."", 'This paper proposes an exploration of the effect of normalization and initialization in residual networks. In particular, the Authors propose a novel way to initialize residual networks, which is motivated by the need to avoid exploding/vanishing gradients. The paper proposes some theoretical analysis of the benefits of the proposed initialization. \n\nI find the paper well written and the idea well executed overall. The proposed analysis is clear and motivates well the proposed initialization. Overall, I think this adds something to the literature on residual networks, helping the reader to get a better understanding of the effect of normalization and initialization. I have to admit I am not an expert on residual networks, so it is possible that I have overlooked at previous contributions from the literature that illustrate some of these concepts already. Having said that, the proposal seems novel enough to me. \n\nOverall, I think that the experiments have a satisfactory degree of depth. The only question mark is on the performance of the proposed method, which is comparable to batch normalization. If I understand correctly, this is something remarkable given that it is achieved without the common practice of introducing normalizations. However, I have not found a convincing argument against the use of batch normalization in favor of ZeroInit. I believe this is something to elaborate on in the revised version of this paper, as it could increase the impact of this work and attract a wider readership. ']","[80, -20, 70]","[50, 50, 80]","[""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, describing it as 'very interesting' with 'novel contribution' and 'new insights'. They list several pros and only two minor cons. The politeness score is 50 (moderately polite) because the reviewer uses neutral, professional language throughout. They provide balanced feedback, acknowledging both strengths and limitations of the work without using overly effusive praise or harsh criticism. The tone is respectful and constructive, typical of academic peer reviews."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some advantages of the paper ('interesting observations', 'strong empirical results'), they also list several significant disadvantages and missing elements. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout, balancing critiques with positive observations. They use polite language like 'interesting observations' and frame criticisms as areas for improvement rather than outright dismissals. However, the score isn't higher due to the directness of some criticisms and the lack of overtly polite phrases."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'well written' and 'well executed overall'. They state that it 'adds something to the literature' and has a 'satisfactory degree of depth' in experiments. However, it's not a perfect score as they do raise some questions and suggest areas for improvement. The politeness score is 80 (very polite) due to the reviewer's consistently respectful and constructive tone. They use phrases like 'I find', 'I think', and 'I believe', which are polite ways to express opinions. They also acknowledge their own potential limitations ('I am not an expert') and offer suggestions for improvement in a gentle manner ('I believe this is something to elaborate on'). The language is professional and courteous throughout.""]"
"['The paper proposes a method for generating diverse outputs for various conditional GAN frameworks including image-to-image translation, image-inpainting, and video prediction. The idea is quite simple, simply adding a regularization term so that the output images are sensitive to the input variable that controls the variation of the images. (Note that the variable is not the conditional input to the network.) The paper also shows how the regularization term is related to the gradient penalty term. The most exciting feature about the work is that it can be applied to various conditional synthesis frameworks for various tasks. The paper includes several experiments with comparison to the state-of-the-art. The achieved performance is satisfactory. \n\nTo the authors, wondering if the framework is applicable to unconditional GANs.', 'The paper proposes a simple way of addressing the issue of mode-collapse by adding a regularisation to force the outputs to be diverse. Specifically, a loss is added that maximises the l2 loss between the images generated, normalised by the distance between the corresponding latent codes. This method is also used to control the balance between visual quality and diversity.\n\nThe paper is overall well written, introducing and referencing well existing concepts, and respected the 8 pages recommendation.\n\nWhy was the maximum theta (the bound for numerical stability) incorporated in equation 2? What happens if this is omitted in practice? How is this determined?\n\nIn section 4, an increase of the gradient norm of the generator is implied: does this have any effect on the robustness/sensitivity of the model to adversarial attacks?\n\nIn section 5, how is the “appropriate CGAN” determined?\n\nMy main issue is with the experimental setting that is somewhat lacking. The visual quality of the samples illustrated in the paper is inferior to that observed in the state-of-the-art, begging the question of whether this is a tradeoff necessary to obtain better diversity or if it is a consequence of the additional regularisation.. The diversity observed seems to mainly be attributable to colour differences rather than more elaborate differences. Even quantitatively, the proposed method seems only marginally better than other methods.\n\nUpdate post rebuttal\n-----------------------------\nThe experimental setting that is a little lacking. Qualitatively and quantitatively, the improvements seem marginal, with no significant improvement shown. I would have liked a better study of the tradeoff between visual quality and diversity, if necessary at all.\n\nHowever, the authors addressed well the issues. Overall, the idea is interesting and simple and, while the paper could be improved with some more work, it would benefit the ICLR readership in its current form, so I would recommend it as a poster -- I am increasing my score to that effect.', 'The paper proposes a regularization term for the conditional GAN objective in order to promote diverse multimodal generation and prevent mode collapse. The regularization maximizes a lower bound on the average gradient norm of the generator network as a function of the noise variable.\n\nThe regularization is a simple addition to existing conditional GAN models and is certainly simpler than the architectural modifications and optimization tweaks proposed in recent work (BicycleGAN, etc). It is useful to a such a simple solution for preventing mode collapse as well as promoting diversity in generation.\n\nIt is shown to promote the generator landscape to be more spread out by lower bounding the expected average gradient norm under the noise distribution. This is a point to be noted when comparing with other work which focus on the vanishing gradients through the discriminator and try to tweak the discriminator gradients. It is a surprising result that such a penalty on the lower bound can prevent mode collapse while also promoting diversity, since I would expect that upper bounding the generator gradient (i.e. lipschitz continuity which wasserstein GANs and related work rely on but for their discriminator instead) makes sense if a smooth interpolation in latent space is desired. \n\nIt is also not evident how the vanishing discriminator gradient problem is solved using this regularization -- will it work if the discriminator is allowed to converge before updating the generator?\n\nThis simple regularization presented in this paper and its connection to preventing mode collapse feels like an important step towards understanding how conditional generative models like cGANs behave. Alleviating the need to investigate significant changes to model families by focusing instead on a novel optimization objective is an important contribution.\n']","[80, 20, 80]","[70, 60, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses enthusiasm about the paper's applicability to various tasks, describes the performance as 'satisfactory', and calls the work's feature 'exciting'. The language is generally positive and appreciative of the paper's contributions. The politeness score is 70 (polite) as the reviewer uses respectful and professional language throughout. They offer a balanced view, acknowledging the paper's strengths without being overly effusive. The final question to the authors is phrased politely as a curiosity rather than a criticism. The overall tone is constructive and courteous, typical of a positive academic peer review."", ""The sentiment score is slightly positive (20) because while the reviewer initially points out some issues and asks for clarifications, they ultimately recommend the paper for a poster presentation after the authors' rebuttal. They describe the idea as 'interesting and simple' and state it would benefit the ICLR readership. However, they still note some limitations, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the paper's strengths ('well written', 'interesting and simple idea') while constructively pointing out areas for improvement. They avoid harsh criticism and frame their concerns as questions or suggestions rather than direct criticisms. The update post-rebuttal shows the reviewer's willingness to reconsider their initial assessment, which is a polite and professional approach."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its simplicity, usefulness, and importance. They use phrases like 'useful', 'surprising result', and 'important contribution'. The politeness score is 70 (polite) as the reviewer maintains a professional and respectful tone throughout, acknowledging the paper's strengths and contributions without using overly effusive language. They offer constructive feedback and questions in a courteous manner, such as 'It is also not evident how...' rather than using more critical language. The reviewer balances praise with thoughtful inquiries, maintaining a polite and constructive tone throughout the review.""]"
"['\n-- Originality --\n\nThis paper studies how to use KL-regularization with information asymmetry to speed up and improve reinforcement learning (RL). Compared with existing work, the major novelty in the proposed algorithm is that it uses a default policy learned from data, rather than a fixed default policy. Moreover, the proposed algorithm also limits the amount of information the default policy receives, i.e., there is an ""information asymmetry"" between the agent policy and the default policy. In many applications, the default policy is purposely chosen to be ""goal agnostic"" and hence conducts the ""transfer learning"". To the best of my knowledge, this ""informationally asymmetric"" KL-regularization approach is novel.\n\n-- Clarify --\n\nThe paper is well written in general and is easy to follow.\n\n-- Significance --\n\nI think the idea of regularizing RL via an informationally asymmetric default policy is interesting. It might be an efficient way to do transfer learning (generalization) in some RL applications. This paper has also done extensive and rigorous experiments. Some experiment results are thought-provoking.\n\n-- Pros and Cons\n\nPros:\n\n1)  The idea of regularizing RL via an informationally asymmetric default policy is interesting. To the best of my knowledge, this ""informationally asymmetric"" KL-regularization approach is novel.\n\n2) The experiment results are extensive, rigorous, and thought-provoking.\n\nCons:\n\n1) My understanding is that this ""informationally asymmetric"" KL-regularization approach is a general approach and can be combined with many policy learning algorithms. It is not completely clear to me why the authors choose to combine it with an actor-critic approach (see Algorithm 1)? Why not combine it with other policy learning algorithms? Please explain.\n\n2) This paper does not have any theoretical results. I fully understand that it is highly non-trivial or even impossible to analyze the proposed algorithm in the general case. However, I recommend the authors to analyze (possibly a variant of) the proposed algorithm in a simplified setting (e.g. the network has only one layer, or even is linear) to further strengthen the results.\n\n3) The experiment results of this paper are interesting, but I think the authors can do a better job of intuitively explaining the experiment results. For instance, the experiment results show that when the reward is ""dense shaping"", the proposed method and the baseline perform similarly. Might the authors provide an intuitive explanation for this observation? I recommend the authors to try to provide intuitive explanation for all such interesting observations in the paper. \n\n', 'This is a very interesting piece of work. We know from cognitive science literature, that there are 2 distinct modes of decision making - habit based and top-down control (goal directed) decision making. The paper proposes to use this intuition by using information theoretic objective such that the agent follows ""default"" policy on average and agent gets penalized for changing its ""default"" behaviour, and the idea is to minimize this cost on average across states.\n\nThe paper is very well written. I think, this paper would have good impact in coming up with new learning algorithms which are inspired from cognitive science literature as well as mathematically grounded. But I dont think, paper in its current form is suitable for publication. \n\nThere are several reasons, but most important:\n\n1) Most of the experiments in this paper use of the order of  10^9 or even 10^10 steps. Its practically not possible for anyone in academia to have such a compute. Now, that said, I do think this paper is pretty interesting. Hence, Is it possible to construct a toy problem which has similar characteristics, and then show similar results using like 10^6 or 10^7 steps ? I think it would be easy to construct a 2D POMPD maze navigation env and test similar results. This would improve the paper, as well as could provide a baseline which people in the future can compare to.\n\n2) It becomes more important to compare to stronger baselines like maximum entropy RL ( for ex. Soft Actor Critic). And spend some good of amount time getting these baselines right on these new environments. ', ""This paper shows that significant speed-up gains can be achieved by using KL-regularization with information asymmetry in sparse-reward settings.  Different from previous works, the policy and default policy are learned simultaneously.  Furthermore, it demonstrates that the default policy can be used to perform transfer learning.\n\nPros:\n\n- Overall the paper is well-written and the organization is easy to follow.  The approach is novel and most relevant works are compared and contrasted.  The intuitions provided nicely complements the concepts and experiments are thorough.\n\nCons:\n\n- The idea of separating policy and default policy seems similar to having high and low level controller (HLC and LLC) in hierarchical control -- where LLC takes proprioceptive observations as input, and HLC handles task specific goals.  In contrast, one advantage of the proposed method in this work is that the training is end-to-end.  Would have liked to see comparison between the proposed method and hierarchical control.\n\n- As mentioned, the proposed method does not offer significant speed-up in dense-reward settings.  Considering that most of the tasks experimented in the paper can leverage dense shaping to achieve speed-up over sparse rewards, it'd be nice to have experiments to show that for some environments the proposed method can out-perform baseline methods even in dense-reward settings.\n\n""]","[70, 20, 70]","[80, 80, 80]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its novelty, interesting approach, and extensive experiments. They use phrases like 'well written', 'interesting', and 'thought-provoking'. However, it's not 100 as they also point out some areas for improvement. The politeness score is 80 (polite) because the reviewer maintains a respectful and constructive tone throughout. They use phrases like 'I recommend' and 'Please explain' when suggesting improvements, and acknowledge the difficulty of certain aspects ('I fully understand that it is highly non-trivial'). The reviewer balances praise with constructive criticism, which is a hallmark of polite academic discourse."", ""The sentiment score is slightly positive (20) because the reviewer starts by calling the work 'very interesting' and 'well written', and mentions it could have 'good impact'. However, they also state it's not suitable for publication in its current form, which tempers the positivity. The politeness score is high (80) as the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. They phrase their suggestions as questions ('Is it possible...?') rather than demands, which is particularly polite. The reviewer also explains their reasoning for each point, which is a courteous approach to feedback."", ""The sentiment score is 70 (positive) because the review starts with highlighting the paper's significant contributions and novel approach. The reviewer uses phrases like 'well-written,' 'easy to follow,' and 'thorough experiments,' indicating a generally positive view. However, it's not 100 as there are some cons mentioned. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, balancing praise with constructive criticism. They use phrases like 'would have liked to see' and 'it'd be nice to have' when suggesting improvements, which is a polite way to offer feedback. The review maintains a professional and courteous tone without any harsh or rude language.""]"
"[""In this paper, authors proposed a so-called FLOWQA for conversational question answering (CoQA). Comparing with machine reading comprehension (MRC),  CoQA includes a conversation history. Thus, FLOWQA makes use of this property of CoQA and adds an additional encoder to handle this. It also includes one classifier to handle with no-answerable questions.\n\nPros:\nThe idea is pretty straightforward which makes use of the unique property of CoQA.\n\nResults are strong, e.g., +7.2 improvement over current state-of-the-art on the CoQA dataset. \n\nThe paper is well written.\n\nCons:\nIt is lack of detailed analysis how the conversation history affects results and what types of questions the proposed model are handled well.\n\nLimited novelty. The model is very similar to FusionNet (Huang et al, 2018) with an extra history encoder and a no-answerable classifier. \n\nQuestions:\nOne of simple baseline is to treat this as a MRC task by combining the conversation history with documents. Do you have this result?\n\nThe model uses the full history. Have you tried partial history? What's the performance? \n"", 'The paper proposes a method to model the flow of context in multi-turn machine comprehension (MC) tasks. The proposed model achieves amazing improvements in the two recent conversational MC tasks as well as an instruction understanding task. I am very impressed by the improvements and the ablation test that actually shows the effectiveness of the FLOW mechanism they proposed.\n\nHowever, this paper has a lack of clarity (especially, Section 3) which makes it difficult to follow and easy to lose the major contribution points of the work. I summarized the weaknesses as follows:\n\n# lack of motivation and its validation\nThe paper should have more motivational questions at the beginning of why such flow information is necessary for the task. Authors already mentioned about some of it in Figure 1 and here: “such as phrases and facts in the context, for answering the previous questions, and hence provide additional clues on what the current conversation is revolving around”. However, the improvement of absolute scores in the Experiment section didn’t provide anything related to the motivation they mentioned. Have you actually found the real examples in the testing set that are correctly predicted by the FLOW model but not by the baseline? Are they actually referring to the “phrases and facts in the context”, “additional clues on what the current conversation is revolving around”? Another simple test authors can try is to show the attention between the context in a flow and question and see whether appropriate clues are actually activated given the question. \n\n# unclear definition of “flow”\nThe term “flow” is actually little over-toned in my opinion. Initially, I thought that flow is a sequence of latent information in a dialog (i.e., question-answer) but it turns to be a sequence of the context of the passage. The term “flow” is more likely a sequence of latent and hierarchical movement of the information in my opinion. What is your exact definition of “flow” here? Do you believe that the proposed architecture (i.e., RNN sequence of context) appropriately take into account that? RNN sequence of the passage context actually means your attention over the passage given the question in turn, right? If yes, it shouldn’t be called a flow. \n\n# Lack of clarity in Section 3\nDifferent points of contributions are mixed together in Section 3 by themselves or with other techniques proposed by others. For example, the authors mention the computational efficiency of their alternating structure in Figure 2 compared to sequential implementation. However, none of the experiment validates its efficiency. If the computational efficiency is not your major point, Figure 2 and 3 are actually unnecessary but rather they should be briefly mentioned in the implementation details in the later section. Also, are Figure 2 and 3 really necessary? \n\nSection 3.1 and 3.3.1 are indeed very difficult to parse: This is mainly because authors like to introduce a new concept of “flow” but actually, it’s nothing more than a thread of a context in dialog turns. This makes the whole points very hyped up and over-toned like proposing a new “concept”. Also, the section introduces so many new terms (“context integration”. “Flow”, “integration layers”, “conversational flow”, “integration-flow”) without clear definition and example. The name itself looks not intuitive to me, too. I highly recommend authors provide a high-level description of the “flow” mechanism at first and then describe why/how it works without any technical terms. If you can provide a single example where “flow” can help with, it would be nicer to follow it.\n\n# Some questions on the experiment\nThe FLOW method seems to have much more computation than single-turn baselines (i.e., BiDAF). Any comparison on computational cost?\n\nIn Table 3, most of the improvements for QuAC come from the encoding N answer spans to the context embeddings (N-ans). Did you also compare with (Yatskar, 2018) with the same setting as N-ans? \n\nI would be curious to see for each context representation (c), which of the feature(e.g., c, em, g) affect the improvement the most? Any ablation on this?\n\nThe major and the most contribution of the model is probably the RNN of the context representations and concatenation of the context and question at turn in Equation (4). For example, have you tested whether simple entity matching or coreference links over the question thread can help the task in some sense? \n\nLastly for the model design, which part of the proposed method could be general enough to other tasks? Is the proposed method task-specific so only applicable to conversational MC tasks or restricted sequential semantic parsing tasks? \n', 'The paper presents a new model FlowQA for conversation reading comprehension. Compared with the previous work on single-turn reading comprehension, the idea in this paper differs primarily in that it alternates between the context integration and the question flow in parallel. The parallelism enables the model to be trained 5 to 10 times faster. Then this process is formulated as layers of a neural network that are further stacked multiple times. Besides, the unanswerable question is predicted with additional trainable parameters. Empirical studies confirm FlowQA works well on a bunch of datasets. For example, it achieves new state-of-the-art results on two QA datasets, i.e., CoQA and QuAC, and outperforms the best models on all domains in SCONE. Ablation studies also indicates the importance of the concept Flow.\n\nAlthough the idea in the paper is straightforward (it is not difficult to derive the model based on the previous works), this work is by far the first that achieves nontrivial improvement over CoQA and QuAC. Hence I think it should be accepted.\n\nCan you conduct ablation studies on the number of Reasoning layers (Figure 3) in FlowQA? I am quite curious if a deeper/shallower model would help.']","[50, -20, 80]","[70, 50, 60]","[""Sentiment score (50): The review begins with a neutral summary, then lists several pros (strong results, well-written paper) balanced with some cons (lack of detailed analysis, limited novelty). The overall tone is more positive than negative, but not overwhelmingly so. Politeness score (70): The language used is professional and constructive throughout. The reviewer offers balanced feedback, acknowledging strengths while also pointing out areas for improvement. The use of phrases like 'pretty straightforward' and posing questions at the end rather than making demands contributes to a polite tone. The reviewer avoids harsh criticism or dismissive language, maintaining a respectful approach."", ""The sentiment score is slightly negative (-20) because while the reviewer is initially impressed by the improvements and ablation tests, they go on to list several significant weaknesses and areas needing clarification. The review is more critical than positive overall. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms as suggestions or questions rather than harsh statements. They use phrases like 'I would be curious to see' and 'I highly recommend' which maintain a collegial tone despite the criticisms."", ""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, highlighting its achievements and recommending acceptance. The phrase 'achieves new state-of-the-art results' and the statement 'I think it should be accepted' clearly indicate a positive sentiment. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the paper's contributions without being overly effusive. The reviewer also offers a constructive suggestion for further research in a polite manner. The language is professional and courteous, but not excessively formal or deferential, hence the moderate positive score.""]"
"['The authors formulate planning as sampling from an intractable distribution motivated by control-as-inference, propose to approximately sample from the distribution using a learned model of the environment and SMC, then evaluate their approach on 3 Mujoco tasks. They claim that their method compares favorably to model-free SAC and to CEM and random shooting (RS) planning with model-based RL.\n\nThis is an interesting idea and an important problem, but there appear to be several inconsistencies in the proposed algorithm and the experimental results do not provide compelling support for the algorithm. In particular,\n\nLevine 2018 explains that with stochastic transitions, computing the posterior leads to overly optimistic behavior because the transition dynamics are not enforced, whereas the variational bound explicitly enforces that. Is that an issue here?\n\nThe value function estimated in SAC is V^\\pi the value function of the current policy. The value function needed in Sec 3.2 is a different value function. Can the authors clarify on this discrepancy?\n\nThe SMC procedure in Alg 1 appears to be incorrect. It multiplies the weights by exp(V_{t+1}) before resampling. This needs to be accounted for by setting the weights to exp(-V_{t+1}) instead of uniform. See for example auxiliary particle filters.\n\nThe experimental section could be significantly improved by addressing the following points: \n* How was the planning horizon h chosen? Is the method sensitive to this choice? What is the model accuracy?\n* Does CEM use a value function? If not, it seems like a reasonable baseline to consider CEM w/ a value function to summarize the values beyond the planning horizon. This will evaluate whether SMC or including the value function is important. \n* Comparing to state-of-the-art model-based RL (e.g., one of Chua et al. 2018, Kurutach et al. 2018, Buckman et al. 2018). \n* How were the task # of steps chosen? They seem arbitrary. What is the performance at 1million and 5million steps?\n* Was SAC retuned for this small number of samples/steps?\n* Clarify where the error bars come from in Fig 5.2 in the caption.\nAt the moment, SMCP is within the error bars of a baseline method.\n\nComments:\n\nIn the abstract, the authors claim that the major challenges in planning are: 1) model compounding errors in roll-outs and 2) the exponential search space. Their method only attempts to address 2), is that correct? If so, can the authors state that explicitly.\n\nRecent papers (Chua et al. 2018, Kurutach et al. 2018, Buckman et al. 2018, Ha and Schmidhuber 2018) all show promising model-based results on continuous state/action tasks. These should be mentioned in the intro.\n\nThe connection between Gu et al.\'s work on SMC and SAC was unclear in the intro, can the authors clarify?\n\nFor consistency, ensure that sums go to T instead of \\infty.\n\nI found the discussion of SAC at the end of Sec 2.1 confusing. As I understand SAC, it does try to approximate the gradient of the variational bound directly. Can the authors clarify what they mean?\n\nAt the end of Sec 2.2, the authors claim that the tackle the particle degeneracy issue (a potentially serious issue) by ""selecting the temperature of the resampling distribution to not be too low."" I could not find further discussion of this anywhere in the paper or appendix.\n\nSec 3.2, mentions an action prior for the first time. Where does this come from?\n\nSec 3.3 derives updates assuming a perfect model, but we learn a model. What are the implications of this?\n\nPlease ensure the line #\'s and the algorithm line #\'s match.\n\nModel learning is not described in the main text though it is a key component of the algorithm. The appendix lacks details (e.g., what is the distribution used to model the next state?) and contradicts itself (e.g., one place says 3 layers and another says 2 layers).\n\nIn Sec 4.1, a major difference between MCTS and SMC is that MCTS runs serially, whereas SMC runs in parallel. This should be noted and then it\'s unclear whether SMC-Planning should really be thought of as the maximum entropy tree search equivalent of MCTS.\n\nIn Sec 4.1, the authors claim that Alpha-Go and SMCP learn proposals in similar ways. However, SMCP minimizes the KL in the reverse direction (from stated in the text). This is an important distinction.\n\nIn Sec 4.3, the authors note that Gu et al. learn the proposal with the reverse KL from SMCP. VSMC (Le et al. 2018, Naesseth et al. 2017, Maddison et al. 2017) is the analogous work to Gu et al. that learn the proposal using the same KL direction as SMCP. The authors should consider citing this work as it directly relates to their algorithm.\n\nIn Sec 4.3, the authors claim that their direction of minimizing KL is more appropriate for exploration. Gu et al. suggest the opposite in their work. Can the author\'s justify their claim?\n\nIn Sec 5.1, the authors provide an example of SMCP learning a multimodal policy. This is interesting, but can the authors explain when this will be helpful?\n\n====\n\n11/26\nAt this time, the authors have not responded to reviews. I have read the other reviews. Given the outstanding issues, I do not recommend acceptance.\n\n12/7\nAfter reading the author\'s response, I have increased my score. However, baselines that establish the claim that SMC improves planning which leads to improved control are missing (such as CEM + value function). Also, targeting the posterior introduces an optimism bias that is not dealt with or discussed.', 'This paper proposes a sequential Monte Carlo Planning algorithm that depicts planning as an inference problem solved by SMC. The problem is interesting and the paper has a nice description of the related work. In terms of the connection between the the problem and Bayesian filtering as well as smoothing, the paper has novelty there. But it is unclear to me how the algorithm proposed is applicable in complex continuous tasks as claimed.\n\nIn the introduction, the authors wrote that ""We design a new algorithm, Sequential Monte Carlo Planning (SMCP), by leveraging modern methods in Sequential Monte Carlo (SMC), Bayesian smoothing, and control as inference"". From my understanding, the SMC algorithm adopted is the bootstrap particle which is the simplest and earliest SMC algorithm adopted. The Bayesian smoothing algorithm described is also standard. I do not see the modern parts of these algorithms.\n\nThe experiment section reports the return, but it is unclear to me how the SMC algorithm in this case. For example, what is the effective sample size (ESS) in these settings?\n\nThe experiment described seems to be a 2-dimensional set up. How does the algorithm perform with a high-dimensional planning problem?\n\n', 'Sequential Monte Carlo (SMC) has since its inception some 25 years ago proved to be a powerful and generally applicable tool. The authors of this paper continue this development in a very interesting and natural way by showing how SMC can be used to solve challenging planning problems. This is a enabled by reformulating the planning problem as an inference problem via the recent trend referred to as ""control as inference"". While there is unfortunately no real world experiments, the simulations clearly illustrate the potential of the approach.\nWhile the idea of viewing control as inference is far from new the idea of using SMC in this context is clearly novel as far as I can see. Well, there has been some work along the same general topic before, see e.g.\nAndrieu, C., Doucet, A., Singh, S.S., and Tadic, V.B. (2004). Particle methods for change detection, system identification, and contol. Proceedings of the IEEE, 92(3), 423–438.\nHowever, the particular construction proposed in this paper is refreshingly novel and interesting. Hence, I view the specific idea put fourth in this paper as highly novel. The general idea of viewing control as inference goes far back and there are very nice dual relationships between LQG and the Kalman filter established and exploited long time ago.\n\nThe authors interprets ""control as inference"" as viewing the planning problem as a simulation exercise where we aim to approximate the distribution of optimal future trajectories. A bit more specifically, the SMC-based planning proposed in the paper stochastically explores the most promising trajectories in the tree and randomly removes (via the resampling operation) the less promising branches. Importantly there are convergence guarantees via the use of SMC. The idea is significant in that it opens up for the use of the by now strong SMC body of methods and analysis when it comes to challenging and intractable planning problems. I foresee many interesting developments to follow in the direction layed out by this paper. \n\nWhen it comes to your SMC algorithm you will suffer from path degeneracy (as all SMC algorithms does, see e.g. Figure 1 in https://arxiv.org/pdf/1307.3180.pdf) and if h is large I think this can be a problem for you. However, this can easily be fixed via backward simulation. For an overview of backward simulation see \nLindsten, F. and Schon, T. ""Backward simulation methods for Monte Carlo statistical inference"". Foundations and Trends in Machine Learning, 6(1):1-143, 2013.\n\nI am positive to this paper (clearly reveled by my score as well), but there are of course a few issues as well:\n1. There are no theoretical results on the properties of the proposed approach. However, given the large body of literature when it comes to the analysis of SMC methods I would expect that you can provide some results via the nice bridge that you have identified.\n2. Would this be possible to implement in a real-world setting with real-time requirements?\n3. A very detailed question when it comes to Figure 5.2 (right-most plot), why is the performance of your method significantly degraded towards the end? It does recover indeed, but I still find this huge dip quite surprising.\n\nMinor details:\n* The initial references when it comes to SMC are wrong. The first papers are:\nN.J. Gordon, D. Salmond and A.F.M. Smith, Novel approach to nonlinear/non-Gaussian Bayesian state estimation, IEE Proc. F, 1993\nL. Stewart, P. McCarty, The use of Bayesian Belief Networks to fuse continuous and discrete information for target recognition and discrete information for target recognition, tracking, and situation assessment, in Proc. SPIE Signal Processing, Sensor Fusion and Target Recognition,, vol. 1699, pp. 177-185, 1992.\n G. Kitagawa, Monte Carlo filter and smoother for non-Gaussian nonlinear state-space models, JCGS, 1996 \n* When it comes to the topic of learning a good proposal for SMC with the use of variational inference the authors provide a reference to Gu et al. (2015) which is indeed interesting and relevant in this respect. However, on this hot and interesting topic there has recently been several related papers published and I would like to mention:\nC. A. Naesseth, S. W. Linderman, R. Ranganath, D. M. Blei, Variational Sequential Monte Carlo. Proceedings of the 21st International Conference on Artificial Intelligence and Statistics, Lanzarote, Spain, April 2018.\nC. J. Maddison, D. Lawson, G. Tucker, N. Heess, M. Norouzi, A. Mnih, A. Doucet, and Y. Whye Teh. Filtering variational objectives. In Advances in Neural Information Processing Systems, 2017.\nT. A. Le, M. Igl, T. Jin, T. Rainforth, and F. Wood. AutoEncoding Sequential Monte Carlo. arXiv:1705.10306, May 2017.\n\nI would like to end by saying that I really like your idea and the way in which you have developed it. I have a feeling that this will inspire quite a lot of work in this direction.']","[-50, -20, 80]","[20, 50, 90]","[""The sentiment score is -50 because while the reviewer acknowledges the work as 'interesting' and addresses an 'important problem', they express significant concerns about 'inconsistencies in the proposed algorithm' and state that the 'experimental results do not provide compelling support for the algorithm'. The review lists numerous issues and requests for clarification, indicating an overall negative sentiment. However, it's not entirely negative as the reviewer sees potential in the idea. The politeness score is 20 because the reviewer uses generally polite language, framing criticisms as questions or suggestions (e.g. 'Can the authors clarify...', 'The experimental section could be significantly improved by...'). They also acknowledge positive aspects before critiquing. However, some direct statements of problems (e.g. 'The SMC procedure in Alg 1 appears to be incorrect') prevent a higher politeness score."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting problem', 'nice description of related work', 'novelty'), they express significant doubts about the paper's claims and methodology. The reviewer questions the applicability of the algorithm to complex tasks, the modernity of the methods used, and the lack of crucial information in the experiments.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns ('it is unclear to me', 'I do not see') rather than making accusatory statements. The reviewer also acknowledges positive aspects before presenting criticisms, which is a polite approach. However, the score is not higher as the review doesn't include explicitly courteous phrases or compliments beyond the initial positive remarks."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, describing it as 'very interesting', 'refreshingly novel', and 'highly novel'. They foresee 'many interesting developments to follow' and state they are 'positive to this paper'. The few criticisms are presented as minor issues or suggestions for improvement. The politeness score is 90 (very polite) due to the consistently respectful and encouraging tone. The reviewer uses phrases like 'I really like your idea' and 'I would like to end by saying', which are courteous. They also provide constructive feedback and additional references in a helpful manner, rather than being critical. The language is professional and supportive throughout, with no harsh or rude comments.""]"
"['The idea, transforming the input data to an output space in which the data is distributed uniformly and thus indexing is easier, is interesting. \n\nMy main concerns come from experimental results.\n\n(1) Table 1: where are the results of OPQ and LSQ from? run the codes by the authors of this paper? or from the original paper?\n\nIt is not consistent to the LSQ paper (https://www.cs.ubc.ca/~julm/papers/eccv16.pdf). For BigANN1M, from the LSQ paper, the result is >29 recall at 1 for 64 bits. \n\n(2) Figure 5: similarly, how did you get the results of PQ and OPQ?\n\n(3) There are some other advanced algorithms: e.g.,  additive quantization (Babenko & Lempitsky, 2014) and composite quantization (https://arxiv.org/abs/1712.00955)\n\nThe above points make it hard to judge this paper.', 'Pros\n----\n\n[Originality]\nThe authors propose a novel idea of learning representations that improves the performance of the subsequent fixed discretization method.\n\n[Clarity]\nThe authors clearly motivate their solution and explain the different ideas and enhancements introduced. The manuscript is fairly easy to follow. The different terms in the optimization problem are clearly explained and their individual behaviour are presented for the better understanding.\n\n[Significance]\nThe empirical results for the proposed scheme are compared against various baselines under various scenarios and the results demonstrate the significant utility of the proposed scheme.\n\nLimitations\n-----------\n\n[Clarity]\nThe training times for the catalyzer is never discussed in this manuscript (even relative to the training times of the considered baselines). Moreover, it is not clear if the inference time of the catalyzer is included in the results such as Table 1. Even if, PQ and the catalyzer+lattice might have comparable search recalls, it would be good to understand the relative search times to get similar accuracy especially since the inference time for the catalyzer (which is part of the search time) can be fairly significant.\n\n[Clarity/Significance]\nOne important point not discussed in this manuscript is the choice of the structure (architechture) of the catalyzer. Is the catalyzer architecture dependent on the data?\n  - If yes, how to find an appropriate architecture?\n  - If no, what is it about the proposed architecture that makes it sufficient for all data sets?\nIn my opinion, this is extremely important since this drives the applicability of the proposed scheme beyond the presented examples.\n\n[Minor question]\n- Is the parameter r in the rank loss same as the norm r in the lattice quantizer? This is a bit confusing.', 'The authors propose a method to adapt the data to the quantizer, instead of having to work with a difficult to optimize discretization function. The contribution is interesting.\n\nAdditional comments and suggestions:\n\n- in the related work overview it would be good to also check possible connections with optimal transport methods using entropy regularization.\n\n- at some points in the paper, e.g. section 3.3, the authors mention Voronoi cells. However, in the related work in section 2 vector quantization and self-organizing maps have not been mentioned.\n\n- more details on the optimization or learning algorithms for eq (3)(4) should be given. The loss function is non-smooth and rather complicated. What are the implications on the learning algorithm when training neural networks? Is it important to have a good initialization or not?\n\n- How reproducible are the results? In Table 1 only one number in each column is shown while eqs (3)(4) are non-convex problems. Is it the best result of several runs or an average that is reported in the Table? \n\n']","[-20, 60, 50]","[50, 80, 75]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting idea, they express 'main concerns' about the experimental results and point out inconsistencies and missing comparisons. This indicates a generally critical stance, though not entirely negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, starting with a positive comment and framing criticisms as questions or suggestions rather than direct accusations. They use phrases like 'My main concerns' and 'It is not consistent' rather than more confrontational language. The reviewer also provides specific examples and references to support their points, which is a constructive approach."", ""The sentiment score is 60 (positive) because the review starts with a 'Pros' section that highlights several positive aspects of the paper, including its originality, clarity, and significance. The reviewer praises the novel idea, clear motivation, and empirical results. However, the score is not higher because there's also a 'Limitations' section that points out some areas for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths before discussing limitations, and phrase their criticisms as suggestions or questions rather than direct criticisms. The use of phrases like 'it would be good to understand' and 'in my opinion' further contribute to the polite tone."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by stating that the authors' contribution is 'interesting', which is a positive comment. However, the rest of the review consists of suggestions for improvement, indicating a balanced perspective. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, framing their comments as suggestions rather than criticisms. They use phrases like 'it would be good to' and 'more details... should be given', which are polite ways of requesting improvements. The reviewer also asks questions rather than making direct accusations, such as 'Is it important to have a good initialization or not?', which maintains a courteous tone.""]"
"['The authors propose a novel method for learning graph convolutional networks. The core idea is to use the Lanczos algorithm to obtain a low-rank approximation of the graph Laplacian. The authors propose two ways to include the Lanczos algorithm. First, as a preprocessing step where the algorithm is applied once on the input graph and the resulting approximation is fixed during learning. Second, by including a differentiable version of the algorithm into an end-to-end trainable model. \n\nThe proposed method is novel and achieves good results on a set of experiments. \n\nThe authors discuss related work in a thorough and meaningful manner. \n\nThere is not much to criticize. This is a very good paper. The almost 10 pages are perhaps a bit excessive considering there was an (informal) 8 page limit. It might make sense to provide a more accessible discussion of the method and Theorem 1, and move some more detailed/technical parts in pages 4, 5, and 6 to an appendix. \n', 'This paper proposes to use a Lanczos alogrithm, to get approximate decompositions of the graph Laplacian, which would facilitate the computation and learning of spectral features in graph convnets. It further proposes an extension with back propagation through the Lanczos algorithm, in order to train end to end models. \n\nOverall, the idea of using Lanczos algorithm to bypass the computation of the eigendecomposition, and thus simplify filtering operations in graph signal processing is not new [e.g., 35]. However, using this algorithm in the framework of graph convents is new, and certainly interesting. The authors seem to claim that their method permits to learn spectral filters, what other methods could not do - this is not completely true and should probably be rephrased more clearly: many graph convnets, actually learn features. \n\nThe general construction and presentation of the algorithms are generally clear, and pretty complete. A few things that could be clarified are the following:\n\n- in the spectral filters of Eq (4), what gets fundamentally different from polynomial filters proposed in other graph convnets architectures?\n- what happens when the graph change? Do the learned features make sense on different graphs? And if yes, why? If not, the authors should be more explicit in their presentation\n- what is the complexity of the proposed methods? that should be minimally discussed (at least), as it is part of the key motivations for the proposed algorithms\n- how is the learning done in 3.2? If there is any learning at all? (btw, S below Eq (6) is a poor notation choice, as S is used earlier for something else)\n- the results are not very impressive - they are good, but not stellar, and could benefit from showing an explicit tradeoff in terms of complexity too?\n\nThe discussion in the related work, and the analogy with manifold learning are interesting. However, that brings probably to one of the main issues with the papers - the authors are obviously very knowledgeable in graph convnets, graph signal processing, and optimisation. However, there are really too many things in this paper, which leads to numerous shortcuts, and some time confusion. Given the page limits, not everything can be treated with the level of details that it would deserve. It might be good to consider trimming down the paper to its main and core aspects for the next version. \n\n\n\n', 'The paper under review builds useful insights and novel methods for graph convolutional networks, based on the Lanczos algorithm for efficient computations involving the graph Laplacian matrices induced by the neighbor edge structure of graph networks.\n\nWhile previous work [35] has explored the Lanczos algorithm from numerical linear algebra as a means to accelerate computations in graph convolutional networks, the current paper goes further by:\n(1) exploring in significant more depth the low rank decomposition underlying the Lanczos algorithm.\n(2) learning the spectral filter (beyond the Chebychev design) and potentially also the graph kernel and node embedding.\n(3) drawing interesting connections with graph diffusion methods which naturally arise from the matrix power computation inherent to the Lanczos iteration.\n\nThe paper includes a systematic evaluation of the proposed approach and comparison with existing methods on two tasks: semi-supervised learning in citation networks and molecule property prediction from interactions in atom networks. The main advantage of the proposed method as illustrated in particular by the experimental results in the citation network domain is its ability to generalize well in the presence of a small  amount of training data, which the authors attribute to its efficient capturing of both short- and long-range interactions.\n\nIn terms of presentation quality, the paper is clearly written, the proposed methods are well explained, and the notation is consistent.\n\nOverall, a good paper.\n\nMinor comment:\npage 3, footnote: ""When faced with a non-symmetric matrix, one can resort to the Arnoldi algorithm."": I was wondering if the authors have tried that? I think that the Arnoldi algorithm for non-symmetric matrices are significantly less stable than their Lanczos counterparts for symmetric matrices.']","[90, 20, 80]","[80, 60, 70]","[""The sentiment score is 90 because the reviewer expresses a very positive opinion of the paper, calling it 'very good' and stating there is 'not much to criticize.' They praise the novelty of the method, its good results, and the thorough discussion of related work. The only minor criticism is about the paper's length, which doesn't significantly detract from the overall positive sentiment. The politeness score is 80 because the reviewer uses respectful and professional language throughout. They offer constructive feedback about the paper's length in a gentle manner, suggesting it 'might make sense' to move some parts to an appendix rather than demanding changes. The tone is consistently courteous and appreciative of the authors' work."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the novelty and interest of the paper's approach, stating 'using this algorithm in the framework of graph convents is new, and certainly interesting.' However, they also point out several areas for improvement and clarification, which tempers the overall positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'could be clarified' and 'it might be good to consider,' which maintain a polite tone. The reviewer also acknowledges the authors' expertise, which adds to the politeness. However, the score is not higher as the review is primarily focused on improvements rather than praise, and some criticisms are quite direct, though still professionally stated."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper. They describe it as 'a good paper' and highlight several strengths, including 'useful insights', 'novel methods', and 'systematic evaluation'. The reviewer also praises the paper's presentation quality and its ability to generalize well with limited training data. The score is not 100 as there is a minor comment/question at the end, but overall the sentiment is quite positive. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They acknowledge the authors' work positively without being overly effusive. The tone is constructive, even when raising a question at the end. The reviewer avoids harsh criticism and frames their comments in a collegial manner, which is typical of polite academic discourse.""]"
"['PAPER SUMMARY\n-------------\nThis paper proposes an approach to video prediction which autonomously finds an action space encoding differences between subsequent frames. This approach can be used for action-conditioned video prediction and visual servoing. \nUnlike related work, the proposed method is initially trained on video sequences without ground-truth actions. A representation for the action at each time step is inferred in an unsupervised manner. This is achieved by imposing that the representation of this action be as small as possible, while also being composable, i.e. that that several actions can be composed to predict several frames ahead.\nOnce such a representation is found, a bijective mapping to ground truth actions can be found using only few action-annotated samples. Therefore the proposed approach needs much less annotated data than approaches which directly learn a prediction model using actions and images as inputs.\n\nThe approach is evaluated on action-conditioned video prediction and visual servoing. The paper shows that the learned action-space is meaningful in the sense that applying the same action in different initial condition indeed changes the scenes in the same manner, as one would intuitively expect. Furthermore, the paper shows that the approach achieves state of the art results on a action-conditioned video prediction dataset and on a visual servoing task.\n\nPOSITIVE POINTS\n---------------\nThe idea of inferring the action space from unlabelled videos is very interesting and relevant.\n\nThe paper is well written.\n\nThe experimental results are very interesting, it is impressive that the proposed approach manages to learn meaningful actions in an unsupervised manner (see e.g. Figure 3).\n\nNEGATIVE POINTS\n---------------\nIt is not exactly clear to me how the model is trained for the quantitative evaluation. On which sequences is the bijective mapping between inferred actions and true actions learned? Is is a subset of the training set? If yes, how many sequences are used? Or is this mapping directly learned on the test set? This, however, would be an unfair comparison in my opinion, since then the actions would be optimized in order to correctly predict on the tested sequences.\n\nThe abstract and introduction are too vague and general. It only becomes clear in the technical and experimental section what problem is addressed in this paper.', 'The authors propose a way to learn models that predict what will happen next in scenarios where action-labels are not available in abundance. The agents extend previous work by proposing a compositional latent-variable model. Results are shown on BAIR (robot pushing objects) and simulated reacher datasets. The results indicate that it is possible to learn a bijective mapping between the latent variables inferred from a pair of images and the action executed between the observations of the two images. \n\nI like the proposed model and the fact that it is possible to learn a bijection between the latent variables and actions is cute. I have following questions/comments: \n\n(a) The authors have to learn a predictive model from passive data (i.e. without having access to actions). Such models are useful, if for example an agent can observe other agents or internet videos and learn from them. In such scenarios, while it would be possible to learn “a” model using the proposed method, it is unclear how the bijective mapping would be learnt, which would enable the agent to actually use the model to perform a task that it is provided with. \nIn the current setup, the source domain of passive learning and target domain from which action-labelled data is available are the same. In such setups, the scarcity of action-labelled data is not a real concern. When an agent acts, it trivially has access to its own actions. So collecting observation, action trajectories is a completely self-supervised process without requiring any external supervision. \n\n(b)  How is the model of Agrawal 2016 used for visual serving? Does it used the forward model in the feature space of the inverse model or something else? \n\n(c) In the current method, a neural network is used for composition. How much worse would a model perform if we simply compose by adding the feature vectors instead of using a neural network. It seems like a reasonable baseline to me. Also, how critical is including binary indicator for v/z in the compositional model? \n\nOverall, I like the technical contribution of the paper. The authors have a very nice introduction on how humans learn from passive data. However, the experiments make a critical assumption that domains that are used for passive and action-based learning are exactly the same. In such scenarios, action-labeled data is abundantly available. I would love to see some results and/or hear the authors thoughts on how their method can be used to learn by observing a different agent/domain and transfer the model to act in the agent’s current domain. I am inclined to vote for accepting the paper if authors provide a convincing rebuttal. ', ""The paper proposes a Variational IB based approach to learn action representations directly from video of actions being taken. The basic goal of the work is to disentangle the dynamic parts of the scene in the video from the static parts and only capture those dynamic parts in the representation. Further, a key property of these learned representations is that they contain compositional structure of actions so as to their cumulative effects. The outcome of such a method is better efficiency of the subsequent learning methods while requiring lesser amount of action label videos. \n\nTo achieve this, the authors start with a previously proposed video prediction model  that uses variational information bottleneck to learn minimal action representation. Next, this model is augmented with composability module where in latent samples across frames are composed into a single trajectory and is repeated in a iterative fashion and again the minimal representation for the composed action space is learned using IB based objective. The two objectives are learned in a joint fashion. Finally, they use a simple MLP based bijection to learn the correspondence between actions and their latent representations. Experiments are done on two datasets - reacher and BAIR - and evaluation is reported for action  conditioned video prediction and visual servoing.\n\n- The paper is well written and provides adequate details to understand the flow of the material.\n- The idea of learning disentangled representation is being adopted in many domains and hence this contribution is timely and very interesting to the community.\n- The overall motivation of the paper to emulate how humans learn by looking at other's action is very well taken. Being able to learn from only videos is a nice property especially when the actual real world environment is not accessible.\n- High Performance in terms of error and number of required action labeled videos demonstrates the effectiveness of the approach.\n\nHowever, there are some concerns with the overall novelty and some technical details in the paper:\n- It seems the key contribution of the paper is to add the L_comp part to the already available L_pred part in Denton and Fergus 2018. The trick use to compose the latent variables is not novel and considering that variational IB is also available, the paper lacks overall novelty. A better justification and exposition of novelty in this paper is required.\n- Two simple MLP layers for bijection seems very adhoc. I am not able to see why such a simple bijection would be able to map the disentangled composed action representations to the actual actions. It seems it is working from the experiments but a better  analysis is required on how such a bijection is learned and if there are any specific properties of such bijection such that it will work only in some setting. Will the use of better network improve the learned bijection?\n- While videos are available, Figures in the paper itself are highly unreadable. I understand the small figures in main paper but it should not be an issue to use full pages for the figure on appendix.\n- Finally, it looks like one can learn the composed actions (Right + UP) representation while being not sensitive to static environment. If that is the case, does it work on the environment where except the dynamic part everything else is completely different? For example, it would be interesting to see if a model is trained where the only change in environment is a robot's hand moving in 4 direction while everything else remaining same. Now would this work, if the background scene is completely changed while keeping the same robot arm?\n""]","[60, 50, 50]","[70, 80, 80]","[""The sentiment score is 60 (positive) because the reviewer expresses strong interest in the paper's main idea, praising it as 'very interesting and relevant.' They also commend the paper's writing quality and find the experimental results 'very interesting' and 'impressive.' However, the score is not higher due to some negative points raised, particularly about clarity in the methodology and vagueness in the abstract and introduction. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, balancing positive feedback with constructive criticism. They use phrases like 'well written' and 'impressive' to compliment the work, while tactfully presenting concerns using non-confrontational language such as 'It is not exactly clear to me...' instead of direct accusations of poor explanation."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses liking aspects of the paper ('I like the proposed model', 'Overall, I like the technical contribution') while also raising several questions and concerns. The overall tone is constructive and not overly critical. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout, framing criticisms as questions or suggestions ('I have following questions/comments', 'I would love to see'), and expressing willingness to accept the paper with a good rebuttal. The reviewer maintains a professional and courteous tone, even when pointing out potential issues with the research."", ""The sentiment score is 50 (slightly positive) because the reviewer begins with positive comments about the paper being well-written, timely, and interesting. They also praise the motivation and performance of the approach. However, the reviewer then expresses some concerns about novelty and technical details, which balances out the overall sentiment to be only slightly positive. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as 'concerns' rather than outright flaws. They use phrases like 'It seems' and 'I am not able to see' when expressing doubts, which softens the critique. The reviewer also offers constructive suggestions for improvement, which is a polite way to address weaknesses.""]"
"['General:\nThe paper tackles one of the most important problems of learning VAEs, namely, the posterior collapse. Typically, this problem is attacked by either proposing a new model or modifying the objective. Interestingly, the authors considered a third option, i.e., changing the training procedure only, leaving the model and the objective untouched. Moreover, they show that in fact the modified objective (beta-VAE) could drastically harm training a VAE.\n\nI find the idea very interesting and promising. The proposed algorithm is very easy to be applied, thus, it could be easily reproduced. I believe the paper should be presented at the ICLR 2019.\n\nPros:\n+ The paper is written in a lucid manner. All ideas are clearly presented. I find the toy problem (Figure 2) very illuminating.\n+ It might seem that the idea follows from simple if not even trivial remarks. But this impression is fully due to the fashion the authors presented their idea. I am truly impressed by the writing style of the authors.\n+ I find the proposed approach very appealing because it requires changes only in the optimization procedure while the model and the objective remain the same. Moreover, the paper formalizes some intuition that could be found in other papers (e.g., (Alemi et al., 2018)).\n+ The presented results are fully convincing.\n\nCons:\n- It would be beneficial to see samples for the same latent variables to verify whether the model utilizes the latent code. Additionally, a latent space interpolation could be also presented.\n- The choice of the stopping criterion seems to be rather arbitrary. Did the authors try other methods? If yes, what were they? If not, why the current stopping criterion is so unique?\n- The proposed approach was applied to the case when the prior is a standard Normal. What would happen if a different prior is considered?\n\nNeutral remark:\n* Another problem, next to the posterior collapse, is the “hole problem” (see Rezende & Viola, “Taming VAEs”, 2018). A natural question is whether the proposed approach also helps to solve this issue? One possible solution to that problem is to take the aggregated posterior as the prior (e.g., (Tomczak & Welling, 2018)) or to ensure that the KL between the aggregated posterior and the prior is small. In Figure 4 it seems it is the case, however, I am really curious about the authors’ opinion on this matter.\n* Can the authors relate the proposed algorithm to the wake-sleep algorithm? Obviously, the motivation is different, however, I find these two approaches a bit similar in spirit.\n\n--REVISION--\nI would like to thank the authors for their comments. In my opinion the paper is very interesting and opens new directions for further research (as discussed by the authors in their reply). I strongly believe the paper should be accepted and presented at the ICLR.', 'This work looks into the phenomenon of posterior collapse, and shows that training the inference network more can reduce this problem, and lead to better optima. The exposition is clear. The proposed training procedure is simple and effective. Experiments were carried out in multiple settings, though I would\'ve liked to see more analysis. Overall, I think this is a nice contribution. I have some concerns which I hope the authors can address.\n\nComments:\n - I think [1] should be cited as they first mentioned Eq 5 and also performed similar analysis.\n - Were you able to form an unbiased estimate for the log of the aggregate posterior which is used extensively in this paper (e.g. MI)? Some recents works also estimate this but they use biased estimators. If your estimator is biased, please add a sentence clarifying this so readers aren\'t mislead.\n - Apart from KL and (biased?) MI, a metric I really would\'ve liked to see is the number of active/inactive units as measured in [2]. I think this is a more reliable and very explainable metric for posterior collapse, whereas real-valued information-theoretic quantites can be hard to interpret.\n\nQuestions:\n - Has this approach truly completely solved posterior collapse? (e.g. can you show that the mutual information between z and x is maximal or the number of inactive units is zero?) \n - How robust is this approach to the effects of randomness during training such as initialization and use of minibatches? (e.g. can you show some standard deviations of the metrics you report in Table 1?)\n - (minor) I wasn\'t able to understand why the top right is optimal, as opposed to anywhere on the dashed line, in Figures 1(b) and 3?\n\n[1] Hoffman, Matthew D., and Matthew J. Johnson. ""Elbo surgery: yet another way to carve up the variational evidence lower bound."" \n[2] Burda, Yuri, Roger Grosse, and Ruslan Salakhutdinov. ""Importance weighted autoencoders.""\n\n--REVISION--\n\nThe paper has significantly improved since the revision and I am happy to increase my score. I do still think that the claim of ""preventing"" or ""avoiding"" posterior collapse is too strong, as I agree with the authors that ""it is unknown whether there is a better local optimum that [activates] more or all latent units"". I would suggest not to emphasize it too strongly (ie. in the abstract) or using words like ""reducing"" or ""mitigate"" instead.', 'Response to Authors\n-------------\nI\'ve read all other reviews and the author responses. Most responses to my issues seem to be ""we will run more experiments"", so my review scores haven\'t changed. I\'m glad the authors are planning many revised experiments, and I understand that these take time. It\'s too bad revised results won\'t be available before the review revision deadline (tomorrow 11/26). I guess I\'m willing to take the author\'s promises to update in good faith. Thus, I think this is an ""accept"", but only if the authors really do follow through on promises to add uncertainty quantification and include some complete comparisons to KL annealing strategies. \n\nReview Summary\n--------------\n\nOverall, I think the paper offers a reasonable story for why its proposed innovation -- an alternative scheduling of parameter-specific updates where encoder parameters are always trained to convergence during early iterations -- might offer a reliable way to avoid posterior collapse that is far faster and easier-to-implement than other options that require some per-example iterations (e.g. semi-amortized VAE). My biggest concerns are that relative performance gains (in bound quality) over alternatives are not too large and hard to judge as significant because no uncertainty in these estimates is quantified. Additionally, I\'d like to see more careful evaluation of the KL annealing baseline and more attention to within-model comparisons (do you really need to update until convergence?).\n\nGiven the method\'s simplicity and speed, I think with a satisfactory rebuttal and plan for revision I would lean towards acceptance.\n\nPaper Summary\n-------------\nThe paper investigates a common problem known as ""posterior collapse"" observed when training generative models such as VAEs (Kingma & Welling 2014) with high-capacity neural networks. Posterior collapse occurs when the encoder distribution q(z|x) (parameterized by a NN) becomes indistinguishable from the generative prior on codes p(z), which is often a local optima of the VI ELBO objective. While other better fixed points exist, once this one is reached during optimization it is hard to escape using the typical local gradient steps for VAEs that jointly update the parameters of an encoder and a decoder with each gradient step. \n\nThe proposed solution (presented in Alg. 1) is to avoid joint gradient updates early in training, and instead use an alternating update scheme where after each single-gradient-step decoder parameter update, the encoder is updated with as many gradient steps as are needed to reach convergence. This proposed scheme, which the paper terms ""aggressive updates"", forces the encoder to better approximate the true posterior p(z|x) at each step.\n\nExperiments study a synthetic task where visualizing the evolution of true posterior mean of p(z|x) side-by-side with approximate q(z|x) is possible in 2D, as well as benchmark comparisons to several other methods that address posterior collapse on text modeling (Yahoo, Yelp15) and image modeling (Omniglot). Studied baselines include annealing the KL term in the VI objective, the \\beta VAE (which keeps the KL term fixed with a weight \\beta), and semi-amortized VAEs (SA-VAEs, Kim et al. 2018). The presented approach is said to reach better values of the log likelihood while also being ~10x faster to train than the Kim et al. approach on large datasets.\n\nSignificance and Originality\n----------------------------\nThere exists strong interest in deploying amortized VI to fit sophisticated models efficiently while avoiding posterior collapse, so the topic is definitely relevant to ICLR. Certainly solutions to this issue are welcome, though I worry with the crowded field that performance is starting to saturate and it is becoming hard to identify significant vs. marginal contributions. Thus it\'s important to interpret results across multiple axes (e.g. speed and heldout likelihood).\n\nThe paper does a nice job of highlighting related work on this problem, and I\'d rate its methodological contributions as clearly distinct from prior work, even though the eventual procedure is simple.\n\nThe closest related works in my view are:\n\n* Krishnan et al. AISTATS 2018, where VAE joint-training algorithms for nonlinear factor analysis problems are shown to be improved by an algorithm that uses the encoder NN as an *initialization* and then doing several standard SVI updates to refine per-example parameters. Encoder parameters are updated via gradient updates, *after* the decoder parameters are updated (not jointly).\n\n* SA-VAEs (Kim et al. ICML 2018) which studies VAEs for deep text models and develops an algorithm that at each a new batch uses the encoder to initialize per-example parameters, updates these via several iterations of SVI, then *backpropagates* through those updates to compute a gradient update of the encoder NN.\n\nCompared to these, the detailed algorithm presented in this work is both distinct and simpler. It does not require any per-example parameter updates, instead it only requires a different scheduling of when encoder and decoder NN updates occur. \n\n\nConcerns about Technical Quality (prioritized)\n----------------------------------------------\n\n## C1: Without error bars in Table 1 and 3, hard to know which gaps are significant\n\nAre 500 Monte Carlo samples enough to be sure that the numbers reported in Table 1 are precise estimates and not too noisy? How much error is there in the estimation of various quantities like the NLL or the KL if we repeated 500-MC samples 5x or 10x or 25x? My experience is that even with 100 or more samples, evaluations of the ELBO bound for classic VAEs can differ non-trivally. I\'d like to see evidence that these quantities are estimated with certainty, or (even better) some direct reporting of the uncertainties across several estimates.\n\n\n## C2: Baseline comparison to KL annealing needs to be more thorough\n\nThe current paper dismisses the strategy that annealing the KL term as ineffective in addressing posterior collapse (e.g. VAE + anneal has a 0.0 KL term in Table 1). However, it\'s not clear that a reasonable annealing schedule was used, or even that any reasonable effort was made to try more than one schedule. For example, if we set the KL term to exactly 0.0 weight, the optimization has no incentive to push q towards the prior, and thus posterior collapse *cannot* occur. It may be that this leads to other problems, but it\'s unclear to me why a schedule that keeps the KL term weight exactly at 0 for a few updates and then gradually increases the weight should lead to collapse. To me, the KL annealing story is much simpler than the presented approach and I think as a community we should invest in giving it a fair shot. If the answer is that annealing takes too long or the schedule is tough to tune, that\'s sensible, but I think the claim that annealing still leads to collapse just means the schedule probably wasn\'t set right.\n\nNotice that ""Ours"" is improved by ""Ours+Annealing"" for 2 datasets in Table 1. So annealing *can* be effective. Krishnan et al. 2018\'s Supplementary Fig. 10 suggests that if annealing is slow enough (unfolding over 100000 updates instead of 10000 updates), then KL annealing will get close to pure SVI in effective, non-collapsed posterior approximation. The present paper\'s Sec. B.3 indicates that the attempted annealing schedule was 0.1 to 1.0 linearly over 10 epochs with batch size 32 and train set size 100k, which sounds like only 30k updates of annealing were performed. I\'d suggest comparing against KL annealing that both starts with a smaller weight (perhaps exactly at 0.0) and grows much slower.\n\n\n## C3: Results do not analyze variability due to random initialization or random minibatch traversal\n\nMany factors can impact the final performance values of a model trained via VI, including the random initialization of its parameters and the random order of minibatches used during gradient updates. Due to local optima, often best practice is to take the best of many separate initializations (see several figures in Bishop\'s PRML textbook). The present paper doesn\'t make clear whether it\'s reporting single runs or the best of many runs. I suggest a revision is needed to clarify. Quantifying robustness to initialization is important.\n\n\n## C4: Results do not analyze relative sensitivity of encoder and decoder to using the same learning rate\n\nOne possible explanation for ""lagging"" might be that the gradient vectors of the encoder and the decoder have different magnitudes, and thus using the same fixed learning rate for both (as seems to be done from a skim of Sec. B) might not be optimal. Perhaps a quick experiment that separately tunes learning rates of encoder and decoder is necessary? If the learning rate for encoder is too small, this could easily explain the lagging when using joint updates.\n\n\n## C5: Is it necessary to update until convergence? Or would a fixed budget of 25 or 100 updates to the encoder suffice?\n\nIn Alg. 1, during the ""aggressive"" phase the encoder is updated until convergence. I\'d like to see some coverage of how long this typically takes (10 updates? 100 updates?). I\'d also like to know if there are significant time-savings to be had by not going *all* the way to convergence. It\'s concerning that in Fig. 1 convergence on a toy dataset takes more than 2000 iterations.\n\n\n## C6: Sensitivity to the initialization of the encoder is not discussed and could matter\n\nIn the synthetic example figure, it seems the encoder is initialized so that across many examples, the typical encoding will be near the origin and thus favored under the prior. Thus, the *initialization* is in some ways setting optimization up for posterior collapse. I wonder if some more diverse initialization might avoid the problem.\n\n\n\nPresentation comments\n---------------------\n\nOverall the paper reads reasonably. I\'d suggest mentioning the KL annealing comparison a bit earlier, but otherwise I have few complaints.\n\nI\'m not sure I like the chosen terminology of ""aggressive"" update. The procedure is more accurately a ""repeat-until-convergence"" update. There\'s nothing aggressive about it, it\'s just repeated.\n\n\nLine-by-line Detailed comments\n------------------------------\n\nCitations for ""traditional"" VI with per-example parameters should go much further back than 2013. For example, Matthew Beal\'s thesis, work by Blei in 2003 on LDA, or work by MacKay or M.I. Jordan or others even further back.\n\nAlg 1 Line 12: This update should be to \\theta (model parameters), not \\phi (approx posterior parameters).\n\nAlg 1: Might consider using notation like g_\\theta to denote the grad. of specific parameters, rather than have the same symbol ""g"" overloaded as the gradient of \\theta, \\phi, and both in the same Algo.\n\n\nFig. 3: This is interesting, but I think it\'s missing something as a visualization of the algorithm. There\'s nothing obvious visually that indicates the encoder update involves *many* steps, but the decoder update is only one step. I\'d suggest at least turning each vertical arrow into *many* short arrows stacked end-to-end, indicating many steps. Also use a different color (not green for both).\n\nFig. 4: Shows various quantities like KL(q, prior) traced over optimization. This figure would be more illuminating if it also showed the complete ELBO objective and the expected log likelihood term. Then it would be clear why annealing is failing to avoid posterior collapse.\n\nTable 1: How exactly is the negative log likelihood (NLL) computed? Is it the expected value of the data likelihood: -1 * E_q[log p(x|z)]? Or is it the variational lower bound on marginal likelihood? \n\n\n']","[90, 60, 20]","[80, 80, 60]","[""The sentiment score is 90 because the reviewer expresses strong positive sentiment throughout, using phrases like 'very interesting and promising', 'should be presented at ICLR 2019', and 'fully convincing'. They list several pros and only minor cons, concluding with a strong recommendation for acceptance. The politeness score is 80 as the reviewer uses respectful and professional language throughout, acknowledging the authors' work positively. They offer constructive feedback and suggestions politely, using phrases like 'It would be beneficial' and 'I am really curious about the authors' opinion'. The reviewer also thanks the authors for their comments in the revision section, further demonstrating politeness."", ""The sentiment score is 60 (positive) because the reviewer describes the work as a 'nice contribution' with 'clear exposition' and an 'effective' proposed method. They express overall approval while noting some concerns. The increase in score mentioned in the revision further supports a positive sentiment. The politeness score is 80 (quite polite) due to the constructive tone, use of phrases like 'I hope the authors can address' and 'I would suggest', and the absence of harsh criticism. The reviewer offers suggestions and asks questions in a respectful manner, maintaining a collegial tone throughout."", ""The sentiment score is slightly positive (20) because while the reviewer expresses some concerns and requests for additional experiments, they ultimately lean towards acceptance, stating 'I think with a satisfactory rebuttal and plan for revision I would lean towards acceptance.' The overall tone is constructive rather than dismissive. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges the authors' efforts ('I'm glad the authors are planning many revised experiments'), and frames criticisms as suggestions for improvement rather than harsh judgments. The reviewer also demonstrates fairness by considering the authors' perspective ('I understand that these take time'). However, it's not extremely polite as it maintains a professional, critical tone appropriate for peer review.""]"
"['This paper considers the problem of inferring unspecified costs in an RL problem (e.g., inferring that vases in a room should not be broken). The primary insight is that the initial state of the environment conveys rich information about such unspecified costs since environments are often optimized for humans. The paper frames the problem of inferring unspecified costs from the initial condition as an inverse reinforcement learning (IRL) problem and applies the Maximum Causal Entropy IRL framework to solve this problem. Two methods are proposed for combining the inferred unspecified costs with specified costs. The efficacy of the proposed approach is demonstrated on a number of simulated examples.\n\nOverall, I was impressed by this paper and I believe that it makes a strong contribution. The paper presents an interesting perspective on a relatively old problem (the frame problem in AI). The primary intuition of the paper (that the initial state conveys information about unspecified costs) and the framing of this problem in terms of IRL is novel. The simulated examples (while relatively simple in terms of the number of states and actions) are informative and demonstrate the strengths of the approach (and also some of the weaknesses; the paper is explicit about the current challenges). The paper is very clearly written and is easy to read.\n\nMy concerns are relatively minor:\n- Perhaps the weakest bit of the paper is Section 5 (combining the specified reward with the inferred reward). As presented, the Additive method is somewhat hard to justify. However, the simulated results suggest that the Additive method performs slightly better than the Bayesian method. I would suggest either presenting a bit more intuition and justification for the Additive method or getting rid of this method altogether (since the results are not too different from the Bayesian method, which seems a bit more justifiable).\n- One practical (and potentially important) question that the paper does not directly address is the problem of choosing the time horizon T (i.e., the time horizon for the past). In the standard IRL setting, it is reasonable to assume that the time horizon is given (since the demonstrations have an associated horizon). However, it is not entirely clear how to choose T in the setting considered in this paper. It is possible that if one chooses T to be too small, the inferred rewards will not be accurate (and one may have to look further back in the past to correctly infer rewards). A discussion of this issue and possible ways to choose T would be helpful.\n- In Section 6.1 (baselines), the paper mentions that ""while relative reachability makes use of known dynamics, it does not benefit from our handcoded featurization"". Is it possible to modify the relative reachability method to also take advantage of the handcoded features, perhaps by considering dynamics over the feature space? If not, a sentence explaining that this is not straightforward would be helpful.\n- In the related work section (and also in the introduction), I would recommend being more explicit about precisely what the differences are between the presented work and the approaches presented in (Krakovna et al. 2018) and (Turner, 2018). The paper is currently slightly vague about the differences.\n- Currently, the title of the paper is a bit uninformative. On first reading the title, I expected a paper on control theory; the title makes no mention of unspecified costs, or reinforcement learning, or humans, etc. I believe that this is a good paper and that the paper would have more readers if the title was more inline with the content of the paper. Of course, this is at the discretion of the authors. My suggestion would be something along the lines of ""Inferring Unspecified Rewards in RL from the Initial State"".\n\nTypos:\n- Pg. 1, second paragraph, 3rd line: there is a placeholder for citations.\n- Periods are missing at the end of equations.\n', 'The authors propose to augment the explicitly stated reward function of an RL agent with auxiliary rewards/costs inferred from the initial state and a model of the state dynamics.  Intuitively, the fact that a vase precariously placed in the center of the room remains intact suggests that it is a precious object that should be handled with care, even though the reward function may not explicitly say so.  Technically, implicit rewards like these are inferred via inverse reinforcement learning: the agent (e.g. robot) first estimates the most likely reward functions to have guided existing agents (e.g. humans) by integrating over all possible state-action paths that could have led to the initial condition and evaluating their probability under different rewards (and hence different optimal policies).  The proposal is clever, but there are some philosophical hurdles to overcome and the experimental results offer little quantitative evidence to support this idea. \n\nIn my view, the biggest challenge is how to balance explicitly stated rewards with those inferred from the initial condition.  Section 5 briefly addresses this question, but essentially capitulates by saying, ""This trade-off is inevitable given our problem formulation, since we have two sources of information...and they will conflict in some cases.""  I fear this conflict may be the rule rather than the exception.  For example, when I deploy my brand new dish-washing robot on my sink full of dirty dishes, my instructions to clean up will be in direct conflict with my past self\'s actions (or lack thereof).  How is the agent to know how strongly to adhere to the stated goals and when to deviate?  One possible solution is to only allow the inferred reward to affect features that are not explicitly included in the specified reward.  Neither the Additive nor the Bayesian combination methods have this property though. \n\nThe technical presentation could use some improvement.  The preliminaries in Section 3 do a decent job of introducing MDPs and IRL, but stop short of saying how the objective function for MCEIRL is actually computed.  Specifically, theta does not appear on the right hand side of Eq (1); implicitly, pi is a function of theta that is estimated, presumably, via value or policy iteration.  The marginal probability of the initial state and its gradients presented in Section 4.1 are the main technical contribution of the paper, but most of the key details are deferred to the appendix or referenced to Ziebart (2010).  For example, the dynamic programming algorithm for computing Eq (3) and the expectations over state-action paths in Eq (5) could use more discussion in the main text, as could some elements of the derivation of Eq (5).  \n\nThe experimental results are presented primarily in words (e.g. ""\\pi_spec walks over the vase while \\pi_deviation and \\pi_reachability both avoid it."").  It would be helpful to see the resulting paths taken by the various agents, or even better, to see their learned reward functions alongside the true reward functions.  The only quantitative results are those in Figure 3, and unfortunately they are a bit confusing.  Why would we expect non-monotonic rewards at some temperatures?  Moreover, why are some reward ""percentages"" negative?  \n\nThe idea of leveraging the initial state for augmenting the reward function is clever, but there are a few shortcomings of the current paper.  There are basic concerns about how implicit and explicit rewards can be combined, and the technical presentation needs some improvement.  Most importantly, the experimental results do not show enough quantitative evidence of how the proposed method performs. \n\n[UPDATE] I appreciate the authors\' detailed response and revisions to the paper.  I\'ve updated my score accordingly.', ""The framework of this work is Reinforcement Learning (RL) optimisation. The data consists of states of the space where the action takes place. Actions are possible, and they lead to possible transitions in the state space. A reward function assesses how adequate a state space is.\nThe main originality of the work is to use the initial state as a key information about the features that translate many desired state of background objects in a scene. An algorithm is built to make use of this information to build an ad hoc reward function, which specifies a good landscape of desired vs non-desired states of the space. An empirical evaluation of the introduced method is presented. It is rich and interesting, although hard to fully grasp for a non-expert.\n\nKey questions/remarks:\n - how different is your approach to a Bayesian approach with the combination of a likelihood (~reward) and prior (~initial state analysis) into a posterior distribution of the space? This seems to be the case in Section 5, where your alternative formulation clearly resembles a Lasso approach (which can be cast in a Bayesian framework).\n - I quite like your decomposition of your ideas into many titled paragraphs. The drawback is that there is sometimes a lack of connections between the many ideas you combine. A would see a big figure in the form of a map as a central contribution of your work to explain the different bits. Still, I appreciate the effort to have a synthetic contribution!\n\nSmall remarks:\n - the abstract could be improved to provide an easier reading experience\n - first time IRL on p2 is mentioned, without a prior explanation of the acronym\n - the world is already optimised for human preferences: yes and no, this is one of your (strong?) assumptions. The robot could well move the vase to a location which is acceptable. Or put it back. \n - on p3, beg.  of Section 3, explain the decomposition of r(s) = \\theta^{T}f(s).\n - in IRL paragraph: say the elements of \\tau_{i} are s.t. the transitions need be possible.\n - p8 'access to a simulator': what can be simulated if very little is know about the background, but via an initial state?\n - past point of the discussion: I simply don't get it!?!"", ""This work proposes a way to infer the implicit information in the initial state using IRL and combine the inferred reward with a specified reward to achieve better performance in a few simulated environments where the specified reward is not sufficient to solve the task. The main novelty of this work is to reformulate the Maximum Causal Entropy IRL objective using just the initial state as the end state of an expert trajectory to infer the underlying preference. Overall the proposed approach is impressive and the intuition behind the paper is novel and easy to understand.\n\nMy main concerns are the following:\n- All the simulated experiments are able to demonstrate the effectiveness of the method, though they seem to be a bit too simplistic, e.g. known dynamics. As mentioned in Section 7, more real-environment experiments would make this method a lot stronger.\n- The way of choosing the distribution s_{-T} seems to require some sort of human preference, e.g. in the apple collection case,  s_{-T} has to be sampled from the distribution where there's no apple in the basket in order to make the algorithm to work. This assumption seems to make the implicit information of the initial state not so *implicit*. Besides, it's unclear how to choose the horizon T. It would be interesting to see how the value of T affects the performance.""]","[80, -30, 50, 60]","[70, 50, 70, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses being 'impressed' by the paper and believes it makes a 'strong contribution'. They praise the paper's novelty, clarity, and demonstration of strengths and weaknesses. The concerns raised are described as 'relatively minor'. The politeness score is 70 (polite) due to the reviewer's constructive and respectful tone throughout. They use phrases like 'I would suggest' and 'would be helpful', showing consideration. They also acknowledge the authors' discretion in the title suggestion. The reviewer balances praise with constructive criticism, maintaining a professional and courteous tone throughout the review."", ""The sentiment score is -30 because while the reviewer acknowledges the proposal as 'clever', they express significant concerns about philosophical hurdles, technical presentation, and lack of quantitative evidence. The overall tone is more critical than positive, but not entirely negative. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement rather than harsh criticism. They use phrases like 'In my view' and 'It would be helpful to see' which maintain a polite tone. The reviewer also acknowledges the authors' response and revisions in an update, showing respect for the authors' efforts."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the originality of the work and finds the empirical evaluation 'rich and interesting'. However, they also point out areas for improvement and have several questions, indicating a balanced view. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, such as 'I quite like your decomposition' and 'I appreciate the effort'. They frame their criticisms as questions or suggestions rather than direct criticisms. The reviewer also balances critique with praise, showing consideration for the authors' efforts. The language is professional and constructive throughout, without any rudeness or harsh criticism."", ""The sentiment score is 60 (positive) because the reviewer starts with praise, calling the approach 'impressive' and the intuition 'novel and easy to understand'. However, it's not extremely high due to the 'main concerns' raised later. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the work's strengths before presenting concerns. They use phrases like 'My main concerns' instead of direct criticism, and suggest improvements rather than pointing out flaws. The reviewer maintains a professional and constructive tone throughout.""]"
"['The paper proposed a defensive mechanism against adversarial attacks using GANs. The general network structure is very much similar to a standard GANs -- generated perturbations are used as adversarial examples, and a discriminator is used to distinguish between them. The performance on MNIST, SVHN, and CIFAR10 demonstrate the effectiveness of the approach, and in general, the performance is on par with carefully crafted algorithms for such task. \n\npros\n- the presentation of the approach is clean and easy-to-follow.\n- the proposed network structure is simple, but it surprisingly works well in general. \n- descriptions of training details are reasonable, and the experimental results across several datasets are extensive\n\ncons\n- the network structure may not be novel, though the performance is very nice. \n- there are algorithms that are carefully crafted to perform the network defense mechanism, such as Samangouei et al, 2018. However, the method described in this paper, despite simple, works very good. It would be great if authors can provide more insights on why it works well (though not the best, but still reasonable), besides only demonstrating the experimental results.\n- it would also be nice if authors can visualize the behavior of their design by showing some examples using the dataset they are working on, and provide side-to-side comparisons against other approaches.', 'The paper ""A Direct Approach to Robust Deep Learning Using Adversarial Networks"" proposes a GAN solution for deep models of classification, faced to white and black box attacks. It defines an architecture where a generator network seeks to produce slight pertubations that succeed in fooling the discriminator. The discriminator is the targetted classification model. \n\nThe paper is globally well written and easy to follow. It well presents related works and the approach is well justified. Though the global idea is rather straightforward from my point of view, it looks to be a novel - effective - application of GANs. The implementation is well designed (it notably uses recent GAN stabilization techniques). The experiments are quite convincing, since it looks to produce rather robust models, without a loss of performance with clean (which appears crucial to me and  is not the case of its main competitors). \n\nMinor comments:\n    - eq1 : I do not understand the argmax (the support is missing). It corresponds to the class with higher probability I suppose but...\n    - Authors say that GANs are usually useful for the generator (this is not always the case by the way), while in their case both obtained discriminator and generator have value. I do not understand in what the generator could be useful here, since it is only fitted to attack its own model (so what is the interest, are its attacks transferable on other models?)\n    - Tables 1 and 2 are described as giving attack accuracies. But scores reported are classification accuracy right ? This is rather defense accuracies so...\n', 'Summary: The paper proposes a GAN-based approach for dealing with adversarial instances, with the training of a robust discriminator that is able to identify adversaries from clean samples, and a generator that produces adversarial noise for its given input clean image in order to mislead the discriminator. In contrast to the state-of-the-art “ensemble adversarial training” approach, which relies on several pre-trained neural networks for generating adversarial examples, the authors introduce a way for dynamically generating adversarial examples on-the-fly by using a generator, which they along with their clean counterparts are then consumed for training the discriminator. \n\nQuality: The paper is relatively well-written, although a little sketchy, and its motivations are clear. The authors compare their proposed approach with a good of variety of strong defenses such as “ensemble adversarial training” and “PGD adversarial training”, supporting with convincing experiments their approach.\n\nOriginality: Xioa et al. (2018) used very similar technique for generating new adversarial examples (generator attack), then used for training a robust discriminator. Likewise, Lee et al. (2018) also used GANs to produce perturbations for making images misclassified. Given this, what is the main novelty of this approach comparing to the (Xioa et al., 2018) and (Lee et al., 2018)? These references should be discussed in details in the paper.\n\nMoreover, limited comparison with different attacks: Why did not compare against targeted attacks such as T-FGS, C&W or GAN-attack?\n\nIt is really surprising that undefended network is working better (showing more robustness) than the defended network “adversarial PGD” on black-box attacks, why this is happening?\n\nReferences:\n- Xiao, C., Li, B., Zhu, J. Y., He, W., Liu, M., & Song, D. (2018). Generating adversarial examples with adversarial networks. arXiv preprint arXiv:1801.02610.\n- Lee, H., Han, S., & Lee, J. (2017). Generative Adversarial Trainer: Defense to Adversarial Perturbations with GAN. arXiv preprint arXiv:1705.03387.\n']","[60, 70, -20]","[70, 60, 50]","[""The sentiment score is 60 (positive) because the reviewer begins with a neutral description of the paper's content, followed by a list of pros that outweigh the cons. The reviewer acknowledges the effectiveness of the approach and its good performance across datasets. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offers constructive criticism, and balances positive and negative feedback. They use phrases like 'it would be great if' and 'it would also be nice if' when suggesting improvements, which maintains a polite tone. The reviewer also acknowledges the strengths of the paper, using words like 'clean,' 'easy-to-follow,' and 'extensive' to describe various aspects of the work."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper. They describe it as 'well written and easy to follow', with a 'well justified' approach and 'convincing' experiments. The reviewer also notes that the paper presents a 'novel - effective - application of GANs'. The score is not higher because there are some minor criticisms and questions raised.\n\nThe politeness score is 60 (moderately polite) because the reviewer uses respectful and constructive language throughout. They begin with positive comments and frame their criticisms as 'Minor comments'. The tone is professional and objective, without any harsh or rude language. However, the score is not higher because the review doesn't go out of its way to be exceptionally polite or use particularly warm language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'relatively well-written', 'motivations are clear', 'convincing experiments'), they also raise significant concerns about originality and missing comparisons. The phrase 'a little sketchy' also contributes to the negative sentiment. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, poses questions rather than making accusations, and balances criticism with praise. They use phrases like 'It is really surprising' instead of more confrontational language. The review maintains a professional tone without being overly formal or deferential.""]"
"['This paper addresses the generalization of adversarial training by proposing a new domain adaptation method. In order to have robust defense for adversarial examples, they combine supervised and unsupervised learning for domain adaptation. The idea of domain adaptation is to increase the similarity between clear and adversarial examples. For this purpose, in their objective, they are minimizing the domain shift by aligning the covariance matrix and mean vector of the clean and adversarial examples.\n\nFrom experimental viewpoint, they have lower performance than almost all competitors on clean data, but they are beating them when there is white-box as well as the back-box threats. This means their method gives a good generalization. In CIFAR-100 they do not have this trade-off for accuracy and generalization; they are beating other competitors in clean data as well.\n\nThe paper is clear and well-written. The introduction and background give useful information. \n\nIn general, I think the paper has a potential for acceptance, but I have to mention that I am not an expert in Adversarial networks area.\n\n ', 'Authors propose a new adversarial training with domain adaptation method to overcome the weak generalisation problem in adversarial training for adversarial examples from different attacks. Authors consider the adversarial training as a domain adaptation task with limited number of target labeled data. They demonstrate that by combining unsupervised and supervised domain adaptation with adversarial training, the generalisation ability on adversarial examples from various attacks can be improved for efficient defence. The experimental results on several benchmark datasets suggest that\nthe proposed approach achieves significantly better generalisation results in most cases, when compared to current\ncompeting adversarial training methods. Paper is clearly written and well structured. The novelty of the proposed technique is fair and the originality alike. The results are not very conclusive therefore I think more experiments are needed and possible further adjustments.', 'The paper casts the problem of learning from adversarial examples to make models resistant to adversarial perturbations to a domain adaptation problem. The proposed method Adversarial training with Domain adapatation( ATDA) learns a representation that is invariant to clean and adversarial data achieving state of the art results on CIFAR. \n\nquality - Paper is well written, explanation of the mathematical parts are good, experimental quality can be much better.\nclarity - the problem motivation as well as the methodology is clearly explained. the learning from the experiments are unclear and need more work.\noriginality - The casting of the problem as domain adaptation is original but from the experiments it was not conclusive as to how much benefit we get. \nsignificance of this work -  Current models being sensitive to adversarial perturbations is quite a big problem so the particular problem authors are trying to address is very significant.\n\npros\n\nA good idea, enough experiments that indicate the benefit of casting this as a domain adaptation problem.\n\ncons \n\nI feel, the authors should have extended the experiments to ImageNet which is a much larger dataset and validate the findings still hold, I feel the discussion section and comparison to other methods needs to be worked to be more thorough and to tease out the benefit of each of the various terms added to the loss functions as currently all we have is final numbers without much explanation and details. TSNE embeddings part is also very qualitative and while the plots indicate a better separation for ATDA, I feel authors should do more quantitative analysis on the embeddings instead of just qualitative plots.']","[70, 50, 50]","[80, 75, 70]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper. They mention that the paper has 'potential for acceptance', praise its clarity and writing, and highlight its strengths in generalization and performance on certain datasets. The score is not higher because the reviewer notes some limitations, such as lower performance on clean data for some experiments. The politeness score is 80 (polite) due to the reviewer's constructive and respectful tone throughout. They offer balanced feedback, acknowledging both strengths and areas for improvement. The reviewer also humbly admits their expertise limitations, which adds to the polite tone. The language used is professional and courteous, without any harsh criticisms or demanding statements."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's clear writing, good structure, and fair novelty. They also mention that the proposed approach achieves better generalization results in most cases. However, the score is not higher because the reviewer suggests that more experiments are needed and the results are not very conclusive. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and offers constructive criticism without harsh or negative phrasing. The suggestions for improvement are presented as recommendations rather than demands, maintaining a courteous tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths (well-written, clear explanation, original approach) while also pointing out areas for improvement. The overall tone is constructive rather than overly critical or enthusiastic. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, balancing praise with suggestions for improvement. They use phrases like 'I feel' to soften criticisms and acknowledge the significance of the work. The review maintains a professional and courteous tone without being overly formal or deferential.""]"
"['The paper proposes a subgradient descent method to learn orthogonal, squared /complete n x n  dictionaries under l1 norm regularization. The problem is interesting and relevant, and the paper, or at least the first part, is clear.\n\nThe most interesting property is that the solution does not depend on the dictionary initialization, unlike many other competing methods. \n\nThe experiments sections in disappointingly short. Could the authors play with real data? How does sparsity affect the results? How does it change with different sample complexities? Also, it would be nice to have a final conclusion section. I think the paper contains interesting material but, overall, it gives the impression that the authors rushed to submit the paper before the deadline!', 'This paper is a direct follow-up on the Sun-Qu-Wright non-convex optimization view on the Spielman-Wang-Wright complete dictionary learning approach. In the latter paper the idea is to simply realize that with Y=AX, X being nxm sparse and A a nxn rotation, one has the property that for m large enough, the rows of X will be the sparsest element of the subspace in R^m generated by the rows of Y. This leads to a natural non-convex optimization problem, whose local optimum are hopefully the rows of X. This was proved in SWW for *very* sparse X, and then later improved in SQW to the linear sparsity scenario. The present paper refines this approach, and obtain slightly better sample complexity by studying the most natural non-convex problem (ell_1 regularization on the sphere).\n\n\nI am not an expert on SQW so it is hard to evaluate how difficult it was to extend their approach to the non-smooth case (which seems to be the main issue with ell_1 regularization compared to the surrogate loss of SQW).\n\n\nOverall I think this is a solid theoretical contribution, at least from the point of view of non-smooth non-convex optimization. I have some concerns about the model itself. Indeed *complete* dictionary learning seemed like an important first step in 2012 towards more general and realistic scenario. It is unclear to this reviewer whether the insights gained for this complete scenario are actually useful more generally.\n', 'This paper studies nonsmooth and nonconvex optimization and provides a global analysis for orthogonal dictionary learning. The analysis is highly nontrivial compared with existing work. Also for dictionary learning nonconvex $\\ell_1$ minimization is very important due to its robustness properties. \n\nI am wondering how extendable is this approach to overcomplete dictionary learning. It seems that overcomplete dictionary would break the key observation of ""sparsest vector in the subspace"". \n\nIs it possible to circumvent the difficulty of nonsmoothness using (randomized) smoothing, and then apply the existing theory to the transformed objective? My knowledge is limited but this seems to be a more natural thing to try first. Could the authors compare this naive approach with the one proposed in the paper?\n\nAnother minor question is about the connection with training deep neural networks. It seems that in practical training algorithms we often ignore the fact that ReLU is nonsmooth since it only has one nonsmooth point — only with diminishing probability, it affects the dynamics of SGD, which makes subgradient descent seemingly unnecessary. Could the authors elaborate more on this connection?', 'This paper studies dictionary learning problem by a non-convex constrained l1 minimization. By using subgradient descent algorithm with random initialization, they provide a non-trivial global convergence analysis for problem. The result is interesting, which does not depend on the complicated initializations used in other methods. \n\nThe paper could be better, if the authors could provide more details and results on numerical experiments.   This could be used to confirm the proved theoretical properties in practical algorithms. ', 'The paper provides a very nice analysis for the nonsmooth (l1) dictionary learning minimization in the case of orthogonal complete dictionaries and linearly sparse signals. They utilize a subgradient method and prove a non-trivial convergence result.\n\nThe theory provided is solid and expands on the earlier works of sun et al. for the nonsmooth case. Also interesting is the use a covering number argument with the d_E metric.\n\nA big plus of the method presented is that unlike previous methods the subgradient descent based scheme presented is independent of the initialization.\n\nDespite a solid theory developed, lack of numerical experiments reduces the quality of the paper. Additional experiments with random data to illustrate the theory would be beneficial and it would also be nice to find applications with real data.\n\nIn addition as mentioned in the abstract the authors suggest that the methods used in the paper may also aid in the analysis of shallow non-smooth neural networks but they need to continue and elaborate with more explicit connections.\n\nMinor typos near the end of the paper and perhaps missing few definitions and notation are also a small concern\n\nThe paper is a very nice work and still seems significant! Nonetheless, fixing the above will elevate the quality of the paper.\n']","[20, 50, 70, 60, 70]","[50, 60, 80, 50, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting and relevant topic, and praises its clear first part and the solution's independence from initialization. However, the score is not higher due to criticism of the short experiments section and the impression of a rushed submission. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement without harsh or rude phrasing. The reviewer balances positive comments with areas for improvement, maintaining a professional tone."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the paper as a 'solid theoretical contribution' and acknowledges its refinement of previous approaches. However, they also express some concerns about the model's broader applicability, which tempers the positivity. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('I am not an expert on SQW'), and frames their concerns diplomatically ('It is unclear to this reviewer...'). The reviewer maintains a professional tone without using overly formal or effusive language."", ""The sentiment score is 70 (positive) because the reviewer begins by praising the paper's contribution, describing the analysis as 'highly nontrivial' and emphasizing the importance of the topic. The questions raised are constructive and show engagement with the work. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing critiques as questions or suggestions rather than direct criticisms. Phrases like 'I am wondering' and 'Could the authors' indicate a polite, collaborative tone. The reviewer also acknowledges their own limited knowledge on one point, showing humility."", ""The sentiment score is 60 (positive) because the reviewer describes the paper's result as 'interesting' and acknowledges its contribution in providing a 'non-trivial global convergence analysis' without relying on complicated initializations. However, it's not extremely positive as the reviewer suggests an improvement. The politeness score is 50 (somewhat polite) because the reviewer uses neutral language and offers constructive feedback. The phrase 'The paper could be better' is a polite way to suggest improvements without being overly critical. The reviewer also uses phrases like 'if the authors could' which is a respectful way to make suggestions."", ""The sentiment score is 70 (positive) because the reviewer uses phrases like 'very nice analysis', 'solid theory', and 'significant work', indicating a generally positive view of the paper. However, they also point out some areas for improvement, which prevents the score from being higher. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement without harsh or negative phrasing. They balance praise with areas for improvement, maintaining a professional and courteous tone. The reviewer's use of phrases like 'would be beneficial' and 'it would be nice' when suggesting improvements contributes to the polite tone.""]"
"[""The authors propose three improvements to the DNC model: masked attention, erasion of de-allocated elements, and sharpened temporal links --- and show that this allows the model to solve synthetic memory tasks faster and with better precision. They also show the model performs better on average on bAbI than the original DNC.\n\nThe negatives are that the paper does not really show this modified DNC can solve a task that the original DNC could not. As the authors also admit, there have been other DNC improvements that have had more dramatic improvements on bAbI.\n\nI think the paper is particularly clearly written, and I would vote for it being accepted as it has implications beyond the DNC. The fact that masked attention works so much better than the standard cosine-weighted content-based attention is pretty interesting in itself. The insights (e.g. Figure 5) are interesting and show the study is not just trying to be a benchmark paper for some top-level results, but actually cares about understanding a problem and fixing it. Although most recent memory architectures do not seem to have incorporated the DNC's slightly complex memory de-allocation scheme, any resurgent work in this area would benefit from this study."", '\nOverview: \nThis paper proposes modifications to the original Differentiable Neural Computer architecture in three ways. First by introducing a masked content-based addressing which dynamically induces a key-value separation. Second, by modifying the de-allocation system by also multiplying the memory contents by a retention vector before an update. Finally, the authors propose a modification in the link distribution, through renormalization. They provide some theoretical motivation and empirical evidence that it helps avoiding memory aliasing. \nThe authors test their approach in the some algorithm task from the DNC paper (Copy, Associative Recall and Key-Value Retrieval), and also in the bAbi dataset.\n\n\nStrengths: Overall I think the paper is well-written, and proposes simple adaptions to the DNC architecture which are theoretically grounded and could be effective for improving general performance. Although the experimental results seem promising when comparing the modified architecture to the original DNC, in my opinion there are a few fundamental problems in the empirical session (see weakness discussion bellow).\n\nWeaknesses: Not all model modifications are studied in all the algorithmic tasks. For example, in the associative recall and key-value retrieval only DNC and DNC + masking are studied. \n\nFor the bAbi task, although there is a significant improvement (43%) in the mean error rate compared to the original DNC, it\'s important to note that performance in this task has improved a lot since the DNC paper was release. Since this is the only non-toy task in the paper, in my opinion, the authors have to discuss current SOTA on it, and have to cite, for example the universal transformer[1], entnet[2], relational nets [3], among others architectures that shown recent advances on this benchmark. \nMoreover, the sparse DNC (Rae el at., 2016) is already a much better performant in this task. (mean error DNC: 16.7 \\pm 7.6, DNC-MD (this paper) 9.5 \\pm 1.6, sparse DNC 6.4 \\pm 2.5). Although the authors mention in the conclusion that it\'s future work to merge their proposed changes into the sparse DNC, it is hard to know how relevant the improvements are, knowing that there are much better baselines for this task.\nIt would also be good if besides the mean error rates, they reported best runs chosen by performance on the validation task, and number of the tasks solve (with < 5% error) as it is standard in this dataset.\n\n\nSmaller Notes. \n1) In the abstract, I find the message for motivating the masking from the sentence  ""content based look-up results... which is not present in the key and need to be retrieved.""  hard to understand by itself. When I first read the abstract, I couldn\'t understand what the authors wanted to communicate with it. Later in 3.1 it became clear. \n\n2) page 3, beta in that equation is not defined\n\n3) First paragraph in page 5 uses definition of acronyms DNC-MS and DNC-MDS before they are defined.\n\n4) Table 1 difference between DNC and DNC (DM) is not clear. I am assuming it\'s the numbers reported in the paper, vs the author\'s implementation? \n\n5)In session 3.1-3.3, for completeness. I think it would be helpful to explicitly compare the equations from the original DNC paper with the new proposed ones. \n\n--------------\n\nPost rebuttal update: I think the authors have addressed my main concern points and I am updating my score accordingly. ', 'Summary:\n\nThis paper is built on the top of DNC model. Authors observe a list of issues with the DNC model: issues with deallocation scheme, issues with the blurring of forward and backward addressing, and issues in content-based addressing. Authors propose changes in the network architecture to solve all these three issues. With toy experiments, authors demonstrate the usefulness of the proposed modifications to DNC. The improvements are also seen in more realistic bAbI tasks.\n\nMajor Comments:\n\nThe paper is well written and easy to follow. The proposed improvements seem to result in very clear improvements. The proposed improvements also improve the convergence of the model. I do not have any major concerns about the paper. I think that contributions of the paper are good enough to accept the paper.\n\nI also appreciate that the authors have submitted the code to reproduce the results.\n\nI am curious to know if authors observe similar convergence gains in bAbI tasks as well. Can you please provide the mean learning curve for bAbI task for DNC vs proposed modifications?\n']","[60, 20, 80]","[80, 70, 90]","[""The sentiment score is 60 (positive) because the reviewer expresses several positive aspects of the paper, such as its clear writing, interesting insights, and potential implications beyond the DNC. They also recommend acceptance. However, it's not extremely positive due to some noted limitations. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms constructively. They use phrases like 'I think' and 'The authors admit' which maintain a courteous tone. The review balances praise with constructive feedback in a professional manner."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges strengths of the paper ('well-written', 'theoretically grounded', 'promising results'), they also point out several weaknesses and areas for improvement. The overall tone is constructive but with significant critiques. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, acknowledging positives before presenting criticisms, and phrases feedback as suggestions rather than demands (e.g., 'it would be good if', 'I think it would be helpful'). The reviewer also maintains a professional tone, focusing on the content rather than making personal comments about the authors."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper. They state that it is 'well written and easy to follow', the improvements 'result in very clear improvements', and they have 'no major concerns'. The reviewer also explicitly states that the 'contributions of the paper are good enough to accept the paper'. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'I appreciate' and 'I am curious to know', which demonstrate courtesy and engagement. They also provide positive feedback before making a suggestion, which is a polite approach to reviewing. The language throughout is professional and considerate, without any harsh or critical phrasing.""]"
"['\nIn this paper, the authors address the problem of learning to achieve perceptually specified goals in a fully unsupervised way. For doing so, they simultaneously learn a goal-conditioned policy and a goal achievement reward function based on the mutual information between goals sampled from an a priori distribution and states achieved using the goal-conditioned policy. These two learning processes are coupled through the mutual information criterion, which seems to result in efficient state representation learning for the visual specified goal space. A key feature is that the resulting metrics in the visual goal space helps the agent focus on what it can control and ignore distractors, which is critical for open-ended learning.\n\nOverall, the idea looks very original and promissing, but the methods are quite difficult to understand under the current form, the messages from the results are not always clear, and the lack of ablative studies makes it difficult to determine which of the mechanisms are crucial in the system performance and which are not.\n\n* Clarification of the methods:\n\nGiven the key features outlined above, I believe the work described in this paper has a lot of potential, but the main issue is that the methods are not easy to get, and the authors could do a better job in that respect. Here is a list of remarks meant to help the authors write a clearer presentation of their method:\n\n- the ""problem formulation"" section contains various things. Part of it could be inserted as a subsection in Section 3, and the last paragraph may rather come into the related work section.\n\n- in Section 3, optimization paragraph, the details given after ""As will be discussed""... might rather come in Section 4 were most of all other details are given.\n\n- in Section 4, I would refer to Algorithm 1 only in the end of the section after all the details have been explained: I went first to the algorithm and could not understand many details that are explained only afterwards.\n\n- in Algorithm 1, shouldn\'t the two procedures be called ""Imitator"" and ""Teacher"", rather than ""actor"" and ""learner"", to be consistent with the end of Section 3?\n\n- there must be a mathematical relationship between $\\xsi_\\phi$ and $\\hat{q}$, but I could not find this relationship anywhere in the text. What is $\\xsi_\\phi$ is never introduced clearly...\n\n- p4: we treat h as fixed ... => explain why.\n\n- I don\'t have a strong background about variational methods, and it is unclear to me why using an expanding set of goals corresponding to already seen states recorded in a buffer makes it that maximizing the log likelihood given in (4) is easier than something else.\n\nMore generally, the above are local remarks from a reader who did not succeed in getting a clear picture of what is done exactly and why. Anything you can do to give a more didactic account of the methods is welcome.\n\n* Related work:\n\nThe related work section is too poor for a strong paper like this one. Learning to reach goals and learning goal representations are two extremely active domains at the moment and the authors should position themselves with respect to more of these works. Here is a short list in which the authors may find many more relevant papers:\n\n (Machado and Bowling, 2016), (Machado et al., 2017), GoalGANs (Florensa et al., 2018), RIG (Nair et al., 2018), Many-Goals RL (Veeriah et al., 2018), DAYN (Eysenbach et al., 2018), FUN (Vezhnevets et al., 2017), HierQ, HAC (Levy et al., 2018), HIRO (Nachum et al., 2018), IMGEP (Pere et al., 2018), MUGL IMGEP (Laversanne-Finot et al., 2018).\n\nIt would also be useful to position yourself with respect to Sermanet et al. : ""Unsupervised Perceptual Rewards for Imitation Learning"".\n\nAbout state representation learning, if you consider the topic as relevant for your work, you might have a look at the recent survey from Lesort et al. (2018).\n\nExternal comments on ICLR web site also point to missing references. The authors should definitely consider doing a much more serious job in positioning their work with respect to the relevant literature.\n\n* Experimental study:\n\nThe algorithm comes with a lot of mechanisms and small tricks (at the end of Section 3 and in Section 4) whose importance is never assessed by specific experimental studies. This matters all the more than some of the details do not seem to be much principled. It would be nice to have elements to figure out how important they are with ablative studies putting them aside and comparing performance. Among other things, I would be glad to know how well the system performs without its HER component. Is it critical?\n\nThe same about the goal sampling strategy, as mentioned in the discussion: how critical is it in the performance of the algorithms?\n\n- Fig. 1b is not so easy to exploit: it is hard to figure out what the reader should actually extract from these figures\n\n- difficult tasks like cartpole: other papers mention cartpole as a rather easy task.\n\nIn the begining of Section 4, the authors mention that the mechanisms of DISCERN naturally induce a form of curriculum (which may be debated), but this aspect is not highlighted clearly enough in the experimental study.\n\nIn my opinion, studying fewer environments but giving a more detailed analysis of the performance of DISCERN and its variations in these environment would make the paper stronger.\n\n\n\n* typos:\n\np3: the problem (of) learning a goal achievement reward function\n\nIn (3), p_g should most probably be p_{goal}\n\np4: we treated h(.) ... and did not adapt => treat, do not\n\np9: needn\'t => need not\n', 'The paper proposes an unsupervised learning algorithm to learn a goal conditioned policy and the corresponding reward function (for the goal conditioned policy) by maximizing the mutual information b/w the goal state and the state achieved by running  the goal conditioned policy for K time steps. The paper proposes a tractable way to maximize this mutual information objective, which basically amounts to learning a reward function for the goal conditioned policy. \n\nThe paper is very well written and easy to understand. \n\nMISSING CITATIONS: Original UVFA [1] paper should be cited while citing goal conditioned policies. \n\nIn the paragraph,  ""Goal distribution"" , the paper uses a non parametric approach to approximate the goal distribution. Previous works ([2], [3]) have used such an approach and relevant work should be cited. \n\n[1] http://proceedings.mlr.press/v37/schaul15.html\n[2] Many Goals Reinforcement Learning https://arxiv.org/abs/1806.09605\n[3] Recall Traces: Backtracking Models for efficient RL https://arxiv.org/abs/1804.00379\n\nI wonder if  learning the variational distribution would be tricky in scenarios where one need to extract a representation of the end state that can distinguish states based on actions required to reach them. Like consider a U-shaped maze \n|       |         |\n|       |         |\n|_A__|__B__|\nIn this maze, even though the states represented by points A and B close to each other, but functionally they are very far apart.  I\'m curious as to what authors have to say in this regard. \n\nBaseline Comparison: I find the experiment results not really convincing. First, comparison to other ""unsupervised"" exploration methods like Variational information maximizing exploration (VIME),  Variational Intrinsic Control (VIC), Curiosity driven learning (using inverse models) is missing.  I understand that VIME and VIC are really not scalable as compared to the proposed method, and hence it should be easy to construct a toy task where it is possible to intuitively understand whats really going on, as well as one can compare with the other baselines (VIME, VIC).\n\nI would recommend authors to study a toyish environment in a proper way as compared to running (incomplete) experiments on 3 different set of envs. It would make the paper really strong.', ""Summary:\n\nThe authors take up an important problem in unsupervised deep reinforcement learning which is to learn perceptual reward functions for goal-conditioned policies without extrinsic rewards from the environment. The problem is important in order to push the field forward to learning representations of the environment without predicting value functions from scalar rewards and learn more generalizable aspects of the environment (the authors call this mastery) as opposed to just memorizing the best sequence of actions in typical value/policy networks. \n\nModel-based methods are currently hard to execute as far as mastery is concerned and goal-conditioned value functions are a good alternative. The authors, therefore, propose to learn UVFA (Schaul et al) with a learned perceptual reward function r(s, s_g) where 's' and 's_g' are current and goal observations respectively. They investigate a few choices for deriving this reward, such as pixel-space L2 distance, Auto-Encoder feature space, WGAN Discriminator (as done in SPIRAL - Ganin and Kulkarni et al), and their approach: cosine similarity based log-likelihood for similarity metric (as in Matching Networks).  They show that their approach works better than other alternatives on a number of visual goal-based tasks.\n\nSpecific aspects:\n\n1. A slight negative: I find the whole pipeline extremely hacky and raises serious questions on whether this paper/technique is easy to apply on a wide variety of tasks. It gives me the suspicion that the environments were cherry-picked for showing the success of the proposed method, though, that's, in general, true of most deep RL papers. It would be nice if the authors instead wrote the paper from the perspective of proposing a new benchmark (it would be amazing if the benchmark is open sourced so that it will lead to more people working specifically on this setting and a lot more comparisons). \n\n-- Revision: The pipeline is hacky, but getting GAN based reward learning to work is also not very straightforward. The authors do plan to release the detectors used for the benchmarking.\n\n2. To elaborate on the above, these are the portions I find hacky: \n(i) Need for decoy observations to learn an approximate log-likelihood \n(ii) Using sparse reward for all transitions except the final terminal state: Yes, I am aware of the fact that HER has already shown sparse rewards are easier to learn value functions with, compared to dense rewards. But I am genuinely surprised that you have pretty much the same setting (ie re-label only terminal transition, r(s_T, s_g)) and motivate the need for learning a perceptual metric. If the information bits per transition is similar to HER in terms of the policy network's objective function, I am not sure why you need to learn a perceptual reward then? There's also no baseline comparison with just naive HER on image observations. That will be worth seeing actually. I feel this kind of comparisons are more interesting and important for the message of the paper. Note that in other papers cited in this, such as SPIRAL, UPN, etc, the reward metrics are used for every state transition. \n(iii) In addition to naive image HER, I would really like to see a SPIRAL + HER baseline as is. ie use the GAN reward for all transitions and also use relabeling for successes. My prior belief is that this will work really well. I would really like to know how the reward for each transition in the trajectory works (both for SPIRAL and your approach) and how the naive HER works. \n\n--Revision: The authors have added HER baselines. Agreed with the authors that comparison of per-timestep perceptual reward vs terminal state perceptual reward is a good topic for future work.\n\n3. Another place I really found confusing throughout the paper is the careless swapping of notations, especially in the xi(h) and e(h). Please use consistent notations especially in equation (3), the pseudocode and the rest of the paper. \n\n4.  a. Would be nice to know if a VAE feature space metric is bad, but not a strict requirement if you don't have time to do it. But I think showing Euclidean metric baseline on VAE is better than an AE. \n      b. Another baseline that is related is to learn a metric with a triplet loss as in Sermanet's work. Or any noise contrastive loss approach (such as CPC). The matching networks approach is similar in spirit. Just pointing out as reference and something worth trying, but not expecting it to be done for rebuttal. \n     \n5. Overall, I think this is a good paper, gives a good overview of an important problem; the matching networks idea is nice and simple; but the paper could be more broader in terms of writing than trying to portray the success of DISCERN specifically. I would be happy accepting it even if the SPIRAL baseline or VAE / AE baseline worked as well as the matching networks because I think those approaches are more principled and likely to require fewer hacks and could be applied to a lot of domains easily. I also hope the authors run the baselines I asked for just to make the paper more scientifically complete. \n\n6. Not a big deal for me in terms of deciding acceptance, but for the sake of good principles in academics, related work could be stronger, though I can understand it must have been small purely due to page limits. \n\nSome papers which could be cited are (1) Unsupervised Perceptual Rewards (though it uses AlexNet pre-trained), (2) Time Contrastive Networks (which also uses AlexNet and doesn't really work on single-view tasks but is a good citation to add), (3) Original UVFA  (definitely has to be there given you even use the abbreviation for the keywords description of the paper)\n\n7. Some slightly incorrect facts/wording in the paper: The two papers cited in model-based methods (Oh and Chiappa) are not really unsupervised. They use a ton of demonstrations to learn those world models. Better citation might be David Ha's World Models or Chelsea Finn's Video Prediction. \n""]","[-20, 50, 50]","[60, 80, 70]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the potential and originality of the work ('the idea looks very original and promising'), they express significant concerns about the clarity of methods, lack of ablative studies, and insufficient related work. The overall tone suggests the paper needs substantial improvements. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and provides detailed suggestions for improvement. They use phrases like 'the authors could do a better job' and 'Anything you can do to give a more didactic account of the methods is welcome', which are polite ways of pointing out areas for improvement. The reviewer also offers helpful resources and suggestions, demonstrating a supportive attitude towards the authors' work."", ""The sentiment score is 50 (slightly positive) because the reviewer starts with positive comments about the paper being 'very well written and easy to understand'. However, they also point out several areas for improvement, including missing citations and unconvincing experimental results. The overall tone is constructive rather than overtly critical. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers suggestions rather than demands, and phrases criticisms as curiosities or recommendations. For example, they use phrases like 'I wonder if...', 'I'm curious as to what authors have to say...', and 'I would recommend...', which maintain a polite and collaborative tone."", ""The sentiment score is 50 (slightly positive) because while the reviewer acknowledges the importance of the problem and the merits of the paper, they also express several concerns and suggest improvements. The overall tone is constructive, but not overwhelmingly positive. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offers suggestions rather than demands, and acknowledges the constraints the authors might face (e.g., 'not expecting it to be done for rebuttal'). The reviewer also balances criticism with praise, showing consideration for the authors' work. However, some direct criticisms (e.g., calling aspects 'hacky') prevent a higher politeness score.""]"
"['First, the writing can be better. I had a hard time to understand the paper. It has many symbols, but some of them are not explained. For instance, in  formula (9), what are Q or s? Also, formula (14). I probably can guess them. Is it possible to simplify the notations or use a table to list the symbols? \n\nFinding good models is a bi-level or tri-level optimization problem. The paper describes a gradient-based hyperparameter optimization method, which finds model parameters, hyperparameter schedules, and network structure (limited) the same time. It is a interesting idea. Comparing random search, grid search and Spearmint, it seems to be better them. The paper rules out the performance gain is from the randomness of the hyperparameters, which is a good thought. \n\nMore evidences are needed to show this method is superior. The paper doesn\'t explain well why it works, and the experimental results are just ok. The network architecture search part is limited to number of filters in the experiments. Certainly, the results is not as good as  PNASNet or NASNet. \n\nEvolution algorithm or GA shows good performance in hyperparameter optimization or neural architecture search. Why not compare with them? Random and grid search are not good generally, and Bayesian optimization is expensive and its performance depends on implementation.   \n\nIn Table 2 and figure 4, should ""Loss"" be ""Error""? \n\n\n', '\n========\\\\\nSummary\\\\\n========\\\\\n\nThe paper deals with hyper-parameter optimization of neural networks. The authors formulate the problem as a bilevel optimization problem: minimizing the validation loss over the hyperparameters, subject to the parameters being at the minimum of the training loss. The authors propose an approximation of the so-called best-response function, that maps the hyperparameters to the corresponding optimal parameters (w.r.t the minimization of the training loss), allowing a formulate as a single-level optimization problem and the use gradient descent algorithm. The proposed\napproximation is based on shifting and scaling the weights and biases of the network. There are no guarantee on its quality except in some very simple cases. The approach assumes a distribution on the hyperparameters, governed by a parameter, which is adapted during the course of the training to achieve a compromise between the flexibility of the best-response function and the quality of its local approximation around the current hyperparameters. The authors show\nthat their approach beats grid-search, random search and Bayesian optimization on the CIFAR-10 and PTB datasets. They point out that the dynamic update of the hyperparameters during the training allows to reach a better performance than any fixed hyperparameter. \\\\\n\n\n======================\\\\\nComments and questions\\\\\n======================\\\\\n\nCan cross-validation be adapted to this approach? \\\\\n\nCan this be used to optimize the learning rate? Which is of course a crucial hyperparameter and that needs an update schedule during the training. \\\\\n\nSection 3.2:\\\\\n\n""If the entries are too large, then θ̂ φ will not be flexible enough to capture the best- response over the sampled neighborhood. However, its entries must remain sufficiently large so that θ̂ φ captures the local shape around the current hyperparameter values."" Not clear why -- more explanations would be helpful. \\\\\n\n""minimizing the first term eventually moves all probability mass towards an optimum λ∗ ,resulting in σ = 0"". I can\'t see how minimizing the first term w.r.t \\phi (as in section ""2.2.Local approximation"") would alter \\sigma. \\\\\n\n""τ must be set carefully to ensure..."". The authors still do not explain how to set \\tau. \\\\\n\nSection 3.3: \\\\\n\nIf the hyperparameter is discrete and falls in Case 2, then REINFORCE gradient estimator is used. What about the quality of this gradient? \\\\\n\nSection 5, paragraph Gradient-Based HO: ""differentiating gradient descent"" needs reformulation -- an algorithm cannot be differentiated. \\\\\n\nPros \\\\\n- The paper is pretty clear \\\\\n- Generalizes a previous idea and makes it handle discrete hyperparameters and scale better. \\\\\n- I like the idea of hyperparameters changing dynamically during the training which allows to explore a much larger space than one value \\\\\n- Although limited, the experimental results are convincing \\\\\n\nCons \\\\\n- The method itself depends on some parameters and it is not clear how to choose them. Therefore it might be tricky to make it work in practice. I feel like there is a lot of literature around HO but very often people still use the very simple grid/random search, because the alternative methods are often quite complex to implement and make really work. So the fact that the method depends on ""crucial"" parameters but that are not transparently managed may be a big drawback to its applicability. \\\\\n- No theoretical guarantee on the quality of the used approximation for neural networks \\\\\n- Does not handle the learning rate which is a crucial hyperparameter (but maybe it could) \\\\\n', 'The paper proposes a bilevel optimization approach for hyperparameter tuning. This idea is not new having been proposed in works prior to the current resurgence of deep learning (e.g., Do et al., 2007, Domke 2012, and Kunisch & Pock, 2013). However, the combination of bilevel optimization for hyperparameter tuning with approximation is interesting. Moreover, the proposed approach readily handles discrete parameters.\n\nExperiments are run on small scale problems, namely, CIFAR-10 and PTB. Results are encouraging but not stellar. More work would need to be done to validate the utility of the proposed approach on larger scale problems.']","[-20, 50, 20]","[20, 80, 50]","[""The sentiment score is slightly negative (-20) because the reviewer points out several issues with the paper, such as difficulty in understanding, unexplained symbols, and the need for more evidence to support the method's superiority. However, the reviewer also acknowledges some positive aspects, like the interesting idea and good experimental design, which prevents the score from being more negative. The politeness score is slightly positive (20) as the reviewer uses generally respectful language and offers constructive criticism. They suggest improvements and ask questions rather than making harsh judgments. The tone is professional and academic, avoiding rudeness while also not being overly deferential or polite."", ""The sentiment score is 50 (slightly positive) because the reviewer provides a balanced assessment, noting both pros and cons. They acknowledge the paper's clarity, generalization of previous ideas, and convincing experimental results. However, they also point out limitations such as the method's dependence on parameters that are not clearly defined and the lack of theoretical guarantees. The overall tone is constructive rather than overtly critical or enthusiastic.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful and professional language throughout. They frame their criticisms as questions or suggestions rather than direct attacks. For example, they ask 'Can cross-validation be adapted to this approach?' and suggest 'more explanations would be helpful' rather than stating the explanations are inadequate. The reviewer also takes care to highlight positive aspects of the paper, demonstrating a fair and considerate approach."", ""The sentiment score is slightly positive (20) because while the reviewer acknowledges that the idea is not new, they find the combination of bilevel optimization with approximation interesting and note that the approach handles discrete parameters well. The experiments are described as 'encouraging but not stellar,' which suggests a cautiously positive view. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language without any harsh criticism. They objectively state the paper's strengths and limitations, suggesting improvements in a constructive manner. The tone is respectful and balanced throughout, neither overly effusive nor critical.""]"
"['Summary: This paper aims to find important regions to classify an image. The main algorithm, FIDO, is trained to find a saliency map based on SSR or SDR objective functions. The main novelty of this work is that it uses generative models to in-fill masked out regions by SSR or SDR. As such, compared to existing algorithms, FIDO can synthesize more realistic samples to evaluate.\n\nI like the motivation of this paper since existing algorithms have clear limitations, i.e., using out-of-distribution samples. This issue can be addressed by using a generative network as described in this paper.\n\nHowever, I think this approach yields another limitation: the performance of the algorithm is bound by the generative network. For example, let’s assume that a head region is important to classify birds. Also assume that the proposed algorithm somehow predicts a mask for the head region during training. If the generative network synthesizes a realistic bird from the mask, then the proposed algorithm will learn that the head region is a supporting region of SSR. In the other case, however, the rendered bird is often not realistic and classified incorrectly. Then, the algorithm will seek for other regions. As a result, the proposed method interprets a classifier network conditioned on the generative network parameters. Authors did not discuss these issues importantly in the paper.\n\nAlthough the approach has its own limitation, I still believe that the overall direction of the paper is reasonable. It is because I agree that using a generative network to in-fill images to address the motivation of this paper is the best option we have at this current moment. In addition, authors report satisfactory amount of experimental results to support their claim.\n\nQuality: The paper is well written and easy to follow.\n\nClarify: The explanation of the approach and experiments are clear. Since the method is simple, it also seems that it is easy to reproduce their results.\n\nOriginality: Authors apply off-the-shelf algorithms to improve the performance of a known problem. Therefore, I think there is no technical originality except that authors found a reasonable combination of existing algorithms and a problem.\n\nSignificance: The paper has a good motivation and deals with an important problem. Experimental results show improvements. Overall, the paper has some amount of impact in this field.\n\nPros and Cons are discussed above. As a summary,\nPros: \n+ Good motivation.\n+ Experiments show qualitative and quantitative improvements.\n\nCons: \n- Lack of technical novelty and justification of the approach.\n', 'The paper is aimed at answering the following question: ""for model M, given an instance input and a predicted label, what parts of the input are most relevant for making the M choose the predicted label?"". \nThis is by far not the first paper aimed at answering this question, but it makes important innovations to the best of my knowledge. The most important one is proposing a stronger approach to the counterfactual question ""had this part of the input been different, what would have been the output?"". Because the input can be different in many ways, an important question is addressing in what specific way would it have been different. \n\nSpecifically in the domain of images, most models assume a blurring or simple local in-painting approach: ""if this patch were just a blurry average, what would have been the output?"". However, ss the current paper correctly points out, blurring or other simple in-painting methods leads to an image which is outside the manifold of natural images and outside the domain of the training set. This can lead to biased or inaccurate results. \n\nThe paper therefore propose two innovations on top of existing methods, most closely building on work by Fong & Vedaldi (2017): \n(1) Optimizing an inference network for discovering image regions which are most informative\n(2) Using a GAN to in-paint the proposed regions, leading to a much more natural image and a more meaningful counterfactual question.\n\nThe presentation is crisp, especially the pseudo-code in Figure 5. In addition, the paper includes several well-executed experiments assessing the contributions of different design choices on different metrics and making careful comparisons with several recent methods addressing the same problem. \n\nSpecific comments:\n\n1. In sec. 4.5, the comparison is not entirely fair because FIDO was already trained with CA-GAN, and therefore might be better adapted for it.\n2. Related to the point above: could one train BBMP with a CA-GAN in-painting model?\n3. I would have liked to see an ablation experiment where either one of the two innovations presented in this paper is missing.\n\n\nMinor:\n1. In eq. (2), wouldn\'t it be more accurate to denote it as \\phi(x,z,\\hat{x}) ? \n2. I would like to know the true labels for all the examples presented in the paper.', 'This paper introduces a new saliency map extractor to visualize which input features are relevant for the deep neural network to recognize objects in the image. The proposed saliency map extractor searches over a big space of potentially relevant image features and in-fills the irrelevant image regions using generative models.\n\nThe algorithmic machinery in the paper is poorly justified, as it is presented as a series of steps without providing much intuition why these steps are useful (especially compared to previous works). Also, I would like to know how this paper compares to Fan et al. ""Adversarial localization network"" (NIPS workshop, 2017), which has not been cited and it proposes similar ideas.\n\nAlso, the results are not convincing. Only one previous work (among many) has been compared with the proposed algorithm, and the qualitative examples are not enlightening showing the advantages of the introduced saliency map extractor. What are the new insights into the functioning of deep networks that were gained from the proposed saliency map extractor?\n\nIn summary, it is unclear to me if there is any novelty in the approach (missing references, lack of motivation of the algorithm) and if the results show any improvement over previous works (only one previous work has been compared and the qualitative examples do not show anything particularly interesting).']","[50, 80, -70]","[80, 70, 20]","[""The sentiment score is 50 (slightly positive) because the reviewer expresses both positive and negative aspects of the paper. They appreciate the motivation and overall direction, acknowledging improvements and good experimental results. However, they also point out limitations and lack of technical novelty. The balanced view with a slight lean towards positivity justifies this score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while constructively presenting criticisms. They use phrases like 'I like the motivation' and 'I still believe that the overall direction of the paper is reasonable,' which demonstrate a courteous tone. The reviewer also provides a balanced summary of pros and cons, further indicating a polite and professional approach to the review."", ""The sentiment score is 80 (positive) because the reviewer acknowledges the paper's important innovations, praises its crisp presentation, and commends the well-executed experiments. The reviewer uses phrases like 'important innovations' and 'well-executed experiments,' indicating a positive view of the paper. The politeness score is 70 (polite) because the reviewer maintains a professional and respectful tone throughout. They offer constructive feedback and specific comments without using harsh language. The reviewer acknowledges the paper's strengths before providing suggestions for improvement, which is a polite approach to peer review. The use of phrases like 'I would have liked to see' and 'I would like to know' for suggestions maintains a courteous tone."", ""The sentiment score is -70 because the review is predominantly negative. The reviewer expresses concerns about poor justification of the algorithm, lack of comparison to relevant work, unconvincing results, and unclear novelty. The only positive aspect mentioned is the introduction of a new saliency map extractor, but this is overshadowed by the criticisms. The politeness score is 20 because while the reviewer is critical, they use relatively neutral language and avoid personal attacks. They use phrases like 'I would like to know' and 'it is unclear to me,' which maintain a professional tone. However, the review doesn't go out of its way to be particularly polite or encouraging, hence the modest positive score.""]"
"['After author response, I have increased my score. I\'m still not 100% sure about the interpretation the authors provided for the negative distances. \n\nThe paper is well written and is mostly clear. (1st line on page 4 has a typo, \\bar{x}_k in eq (4) should be \\bar{x}^l?)\n\nNovelty: I am not sure whether the paper adds any significant on top of what we know from Bartlett et al., Elsayed et al. since:\n\n(i). The fact that ""normalized"" margins are strongly correlated with the test set accuracy was shown in Bartlett et al. (figure 1.). A major part of the definition comes from there or from the reference they cite; \n(ii). Taylor approximation to compute the margin distribution is in Elsayed et al.; \n(iii). I think the four points listed in page 2 (which make the distinction between related work) is misleading: the way I see it is that the authors use the margin distribution in Elsayed et al which simply overcomes some of the obstacles that norm based margins may face. The only novelty here seems to be that the authors use the margin distribution at each layer. \n\nTechnical pitfalls: Computing the d_{f,x,i,j} using Equation (3) is missing an absolute value in the numerator as in equation (7) Elsayed et al.. The authors interpret the negative values as misclassification: why is it true? The margin distribution used in Bartlett et al. (below Figure 4 on page 5 in arxiv:1706.08498) uses labeled data and it is obvious in this case to interpreting negative values as misclassification. I don\'t see how this is true for eq (3) here in this paper. Secondly, why are negative points ignored?? Misclassified points in my opinion are equally important, ignoring the information that a point is misclassified doesn\'t sound like a great idea. How do the experiments look if we don\'t ignore them?\n\nExperiments: Good set of experiments. However I find the results to be mildly taking the claims of the authors made in four points listed in page 2 away: Section 4.1, ""Empirically, we found constructing this only on four evenly-spaced layers, input, and 3 hidden layers, leads to good predictors."". How can the authors explain this? \n\nBy using linear models, authors implicitly assume that the relationship between generalization gaps and signatures are linear (in Eucledian or log spaces). However, from the experiments (table 1), we see that log models always have better results than linear models. Even assuming linear relationship, I think it is informative to also provide other metrics such as MSE, AIC, BIC etc..', 'This paper does not even try to propose yet another ""vacuous"" generalization bounds, but instead empirically convincingly shows an interesting connection between the proposed margin statistics and the generalization gap, which could well be used to provide some ""prescriptive"" insights (per Sanjeev Arora) towards understanding generalization in deep neural nets.\n\nI have no major complaints but for a few questions regarding clarifications,\n1. From Eq.(5), such distances are defined for only one out of the many possible pairs of labels. So when forming the so-called ""margin signature"", how exactly do you compose it from all such pair-wise distances? Do you pool all the distances together before computing the statistics, or do you aggregate individual statistics from pair-wise distances? And how do you select which pairs to include or exclude? Are you assuming ""i"" is always the ground-truth label class for $x_k$ here?\n\n2. In Eq.(3), the way you define the distance (that flipping i and j would change the sign of the distance) is implying that {i, j} should not be viewed as an unordered pair, in which case a better notation might be (i, j) (i.e. replacing sets ""{}"" with tuples ""()"" to signal that order matters).\n\nAnd why do you ""only consider distances with positive sign""? I can understand doing this for when neither i nor j corresponds to the ground-truth label of x, because you really can\'t tell which score should be higher. But when i happens to be the ground-truth label, wouldn\'t a positive distance and a negative distance be meaningful different and therefore it should only be beneficial to include both of them in the margin samples?\n\nAnd a minor typo: In Eq.(4), $\\bar{x}_k$ should have been $\\bar{x}^l$?', ""The author(s) suggest using geometric margin and layer-wise margin distribution in [Elsayed et al. 2018] for predicting generalization gap.\n\npros,\na). The author shows large experiments to support their argument.\n\ncons,\na). No theoretical verification (nor convincing intuition) is provided, especially for the following questions,\n    i) what benefit can be acquired when using geometric margin defined in the paper.\n    ii) why does normalization make sense beyond the simple scaling-free reason. For example, spectral complexity as a normalization factor in [Bartlett et al. 2017] is proposed from the fact, that the Lipschitz constant determines the complexity of network space.\n    iii) why does the middle layer margin can help? \n    iv) why a linear (linear log) relation between the statistic and generalization gap.\n\nFurther question towards experiment,\ni) I don't think your comparison with Bartlett's work is fair. Their bounds suggest the gap is approximately Prob(0<X<\\gamma) + Const/\\gamma for a chosen \\gamma, where X is the normalized margin distribution. I think using the extracted signature from margin distribution and a linear predictor don't make sense here.\nii) If you do regression analysis on a five layers cnn, can you have a good prediction on a nine layers cnn (or even residue cnn)?\n\nFinally, I'm not sure the novelty is strong enough since the margin definition comes from [Elsayed et al. 2018] and the strong linear relationship has been shown in [Bartlett et al. 2017, Liao et al. 2018] though in different settings.""]","[-20, 80, -50]","[60, 70, 20]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is well written and is mostly clear', 'Good set of experiments'), they express significant doubts about the novelty and technical aspects of the paper. They question whether the paper adds anything significant to existing knowledge and point out potential technical pitfalls. The overall tone suggests the reviewer is not fully convinced by the paper's contributions.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I'm not sure', 'I think', and 'How can the authors explain this?', which soften their criticisms. They also acknowledge positive aspects of the paper and provide constructive feedback. However, the score is not higher because the review is quite direct in its criticisms, particularly regarding novelty and technical issues."", ""The sentiment score is 80 (positive) because the reviewer starts by praising the paper for showing 'an interesting connection' and providing 'prescriptive insights', which are strong positive statements. They also mention having 'no major complaints'. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, framing their questions as requests for clarification rather than criticisms. They also acknowledge the paper's strengths before moving to their questions. The slightly lower politeness score compared to sentiment is due to the direct nature of the questions, which, while not impolite, could be phrased more deferentially. The reviewer also points out a typo, which slightly reduces the overall politeness, though it's done in a matter-of-fact way."", ""The sentiment score is -50 because the review is predominantly critical, listing several cons and questions about the paper's approach. While it acknowledges some pros (large experiments), the majority of the review focuses on theoretical and experimental shortcomings. The reviewer also questions the novelty of the work. However, it's not entirely negative, hence not a lower score.\n\nThe politeness score is 20 because the reviewer maintains a professional and objective tone throughout. They use neutral language like 'I don't think' and 'I'm not sure' rather than harsh criticisms. The reviewer also acknowledges positive aspects ('pros') before diving into criticisms. However, the review is direct in its criticisms without much softening language, preventing a higher politeness score.""]"
"['The manuscript entitled ""Kernel Change-Point Detection with Auxiliary Deep Generative Models"" describes a novel approach to optimising the choice of kernel towards increased testing power in this challenging machine learning problem.  The proposed method is shown to offer improvements over alternatives on a set of real data problems and the minimax objective identified is well motivated, however, I am not entirely convinced that (a) the performance improvements arise for the hypothesised reasons, and (b) that the test setting is of wide applicability.\n\nA fundamental distinction between parametric and non-parametric tests for CPD in timeseries data is that the adoption of parametric assumptions allows for an easier introduction of strict but meaningful relationships in the temporal structure---e.g. a first order autoregressive model introduces a simple Markov structure---whereas non-parametric kernel tests typically imagine samples to be iid (before and after the change-point).  For this reason, the non-parametric tests may lack robustness to certain realistic types of temporal distributional changes: e.g. in the parameter of an autoregressive timeseries.  On the other hand, it may be prohibitively difficult to design parametric models to well characterise high dimensional data, whereas non-parametric models can typically do well in high dimension when the available data volumes are large.  In the present application it seems that the setting imagined is for low dimensional data of limited size in which there is likely to be non-iid temporal structure (i.e., outside the easy relative advantage of non-parametric methods).  For this reason it seems to me the key advantage offered by the proposed approach with its use of a distributional autoregressive process for the surrogate model may well be to introduce robustness against Type 1 errors due to otherwise unrepresented temporal structure in the base distribution (P).  In summarising the performance results by AUC it is unclear whether it is indeed the desired improvement in test power that offers the advantages or whether it is in fact a decrease in Type 1 errors.\n\nAnother side of my concern here is that I disagree with the statement: ""As no prior knowledge of Q ... intuitiviely, we have to make G as close to P as possible"" interpretted as a way to maximise test power; as a way to minimise Type 1 errors, yes.\n\nAcross change-point detection methods it is also important to distinguish key aspects of the problem formulation.  One particular specification here is that we have already some labelled instances of data known to come from the P distribution, and perhaps also some fewer instances of data labelled from Q.  This is distinct from fully automated change point detection methods for time series such as automatic scene selection in video data.  Another dissimilarity to that archetypal scenario is that here we suppose the P and Q distributions may have subtle differences that we\'re interested in; and it would also seem that we assume there is only one change-point to detect.  Or at least the algorithm does not seem to be designed to be applied in a recursive sense as it would be for scene selection.\n\nFinally there is no discussion here of computational complexity and cost?', 'A new approach to choose a kernel to maximize the test power, for the kernel change-point detection. This provides an extension to the two-sample version of the problem (Gretton et al. 2012b, Sutherland et al. 2017). The difficulty is caused by that there is very limited samples from the abnormal distribution. The idea is based on choosing a surrogate distributions using generative model. The idea makes sense although there seems to be not much detail in how to choose the surrogate distribution. There is a mechanism to study the threshold. Real-data and simulation demonstrates the good performance. I think the idea is really interesting and I am impressed by the completeness of the work. ', '+ Using a generative model as the surrogate distribution for kernel two-sample test is novel\n+ An important and new application of deep generative models \n+ Strong experiments on synthetic and real-world time series data sets\n+ Very clear writing and explanation of the idea \n\n- reply sample segments from both directions (past and future) while in the practical setting, CPD is usually sequential and in one directional\n- lack theoretical understanding of the limit of the neural-generator in the kernel two-sample test']","[-20, 80, 60]","[60, 50, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the manuscript ('The proposed method is shown to offer improvements over alternatives'), they express significant concerns and skepticism ('I am not entirely convinced'). The reviewer raises several issues and disagreements with the authors' approach and interpretations. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout, avoiding harsh criticism. They present their concerns as personal opinions ('it seems to me', 'I disagree') rather than absolute statements, and use phrases like 'I am not entirely convinced' instead of more confrontational language. The review is detailed and constructive, offering specific points for improvement, which is a polite approach to peer review."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the work, using phrases like 'really interesting' and 'impressed by the completeness of the work'. They also highlight the good performance demonstrated in real-data and simulations. The only slight criticism is about the lack of detail in choosing the surrogate distribution, but this doesn't significantly detract from the overall positive tone. The politeness score is 50 (moderately polite) because while the reviewer doesn't use overtly polite language, they maintain a respectful and professional tone throughout. They offer constructive feedback and acknowledge the strengths of the work without using any harsh or critical language."", ""The sentiment score is 60 (positive) because the review starts with several positive points, using phrases like 'novel', 'important and new', 'strong experiments', and 'very clear writing'. These positive aspects outweigh the two criticisms mentioned at the end. The politeness score is 50 (somewhat polite) because the reviewer uses neutral, professional language throughout. They present both positive and negative points in a balanced manner without using harsh or overly critical language. The use of bullet points for both pros and cons also contributes to a professional and respectful tone.""]"
"[""Summary:\nThe paper proposes a fast method for generating visual metamers – physically different images that cannot be told apart from an original – via foveated, fast, arbitrary style transfer. The method achieves the same goal as an earlier approach (Freeman & Simoncelli 2011): locally texturizing images in pooling regions that increase with eccentricity, but is orders of magnitude faster. The authors perform a psychophysical evaluation to test how (in)discriminable their synthesized images are amongst each other and compared with originals. Their experiment replicates the result of Freeman & Simoncelli of a V2-like critical scaling in the synth vs. synth condition, but shows that V1-like or smaller scaling is necessary for the original vs. synth condition.\n\nI reviewed an earlier version of this paper for a different venue, where I recommended rejection. The authors have since addressed some of my concerns, which is why I am more positive about the paper now.\n\nStrengths:\n+ The motivation for the work is clear and the implementation straightforward, combining existing tools from style transfer in a novel way.\n+ It's fast. Rendering speed is indeed a bottleneck in existing methods, so a fast method is useful.\n+ The perceptual quality of the rendered images is quantified by psychophysical testing.\n+ The role of the scaling factor for the pooling regions is investigated and the key result of Freeman & Simoncelli (pooling regions scale with 0.5*eccentricity) is replicated with the new method. In addition, the result of Wallis et al. (2018) that lower scale factors are required for original vs. synth is replicated as well.\n\n\nWeaknesses:\n- Compared with earlier work, an additional fudge parameter (alpha) is introduced. It is not clear why it is necessary and it complicates interpretation.\n- The paper contains a number of sections with obscure mathiness and figures that I can't follow and whose significance is unclear.\n\n\nConclusion:\nThe work is well motivated, the method holds up to its promise of being fast and is empirically validated. However, it feels quite ad-hoc and the writing of the paper is very obscure at various places, which leaves room for improvement.\n\n\nDetails:\n\n- The motivation for introducing alpha not clear to me. Wasn't the idea of F&S that you can reduce the image to its summary statistics within a pooling region whose size scales with eccentricity? Why do you need to retain some content information in the first place? How do images with alpha=1 (i.e. keep only texture) look?\n\n- Related to above, why does alpha need to change with eccentricity? Experiment 1 seems to suggest that changing alpha leads to similar SSIM differences between synths and originals as F&S does, but what's the evidence that SSIM is a useful/important metric here?\n\n- Again related to above, why do you not use the same approach of blending pooling regions like F&S did instead of introducing alpha?\n\n- I would like to know some details about the inference of the critical scaling. It seems surprisingly spot on 0.5 as in F&S for synth vs. synth, but looking at the data in Fig. 12 (rightmost panel), I find the value 0.5 highly surprising given that all the blue points lie more or less on a straight line and the point at a scaling factor of 0.5 is clearly above chance level. Similarly, the fit for original vs. synth does not seem to fit the data all that well and a substantially shallower slope seems equally plausible given the data. How reliable are these estimates, what are the confidence intervals, and was a lapse rate included in the fits (see Wichmann & Hill 2001)?\n\n- I don't get the point of Figs. 4, 13 and 14. I think they could as well be removed without the paper losing anything. Similarly, I don't think sections 2.1 and the lengthy discussion (section 5) are useful at all. Moreover, section 3 seems bogus. I don't understand the arguments made here, especially because the obvious options (alpha=1 or overlapping pooling regions; see above) are not even mentioned.\n\n- How is the model trained? Do the authors use the pre-trained model of Huang & Belongie or is the training different in the context of the proposed method? I could only find the statement that the decoder is trained to invert the encoder, but that doesn't seem to be what Huang & Belongie's model does and the paper does not say anything about how it's trained to invert. Please clarify.\n\n- At various places the writing is somewhat sloppy (missing words, commas, broken sentences), which could have been avoided by carefully proof-reading the paper."", ""This paper presents an interesting analysis of metamerism and a model capable of rapidly producing metamers of value for experimental psychophysics and other domains.\n\nOverall I found this work to be well written and executed and the experiments thorough. Specific points on positives and negatives of the work follow:\n\nPositives:\n- The paper shows a solid understanding of the literature in this domain and presents a strong motivation\n- The problem itself is addressed at a deep level with many nuanced (but important) considerations discussed\n- Ultimately the results of the model seem convincing in particular with the accompanying psychophysical experiments\n\nNegatives:\n- (Maybe not a negative, but a question) At the extreme tradeoff between intrinsic structure and texture, the notion of a metamer seems somewhat obscured. At what point is a metamer no longer a metamer?\n- (Also not necessarily a negative) Exercising SSIM is a valid decision given it's widespread use. I am curious if MS-SSIM, IW-SSIM or other metrics make any significant difference. "", 'Summary\nThis paper proposes a NeuroFovea (NF) model for generation of point-of-fixation metamers. As opposed to previous algorithms which use gradient descent to match the local texture and image statistics, NF proposed to use a style transfer approach via an Encoder-Decoder style architecture, which allows it to produce metamers in a single forward pass, allowing it to achieve a significant speed-up as compared to early approaches.\n\nPros\n-The paper tackles a very intriguing topic.\n-The paper is very well written using concise and clear language allowing it to present a large -amount of information in the 10 pages + appendix.\n-The paper provides a thorough discussion of both the problem, related work and the model itself.\n-A single forward pass nature of the model allows it to achieve a 1000x speed-up in generating metamers as opposed to previous GD based approaches.\n-The authors provide enough details to allow for reproducibility.\n\nCons\n-(Not necessarily a negative) Requires a very careful reading as the paper provides a lot of information (though as mentioned it is very well written)\n-The quantitative evaluation is somewhat lacking in that there are no quantitative psychophysical experiments to compare this model to competing ones across different observers. For example, it would have been interesting to compare the ability of observers to distinguish between original images and metamers generated by different models. \n\nAdditional comments\nOn page 10., you show Fig. 13 however you mention at the end of the first paragraph you further elaborate on Fig 13. in the Supplementary Materials. I think it would be better to either provide more discussion in the text and refer to the figure, or just move it fully to Supplementary materials.\n\nAlso, in the qualitative comparison of various models you mention that SideEye runs in milliseconds whereas NF runs in seconds. It would be interesting to discuss the potential trade-off between speed and the quality of generated metamers between the models.']","[50, 80, 80]","[60, 70, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges improvements from a previous version and notes several strengths of the paper, while also pointing out some weaknesses. The overall tone is constructive and the conclusion suggests the work has merit but needs improvement. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts to address previous concerns, and frames criticisms as suggestions for improvement rather than harsh judgments. The reviewer also balances positive and negative feedback, which contributes to a polite tone. However, some direct criticisms (e.g., calling certain sections 'bogus' or 'obscure') prevent the score from being higher."", ""The sentiment score is 80 (positive) because the reviewer expresses an overall positive view of the paper, describing it as 'interesting', 'well written and executed', and with 'thorough' experiments. The reviewer lists more positives than negatives, and the negatives are framed more as questions or points for discussion rather than criticisms. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the paper and framing potential issues as questions or points for consideration rather than direct criticisms. The reviewer also uses phrases like 'I found' and 'I am curious', which maintain a polite, collegial tone."", ""The sentiment score is 80 (positive) because the review begins with a clear summary of the paper's content and lists several pros, indicating a generally favorable view. The reviewer acknowledges the paper as 'very well written' and praises its clarity and thoroughness. The cons mentioned are minor and presented more as suggestions for improvement rather than critical flaws. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions. The reviewer acknowledges the paper's strengths before mentioning areas for improvement, and phrases criticisms as 'Additional comments' rather than direct criticisms. The language is professional and objective, avoiding any harsh or dismissive tones.""]"
"['The paper makes a nice contribution to solving Circuit-SAT problem from a Neuro-Symbolic approach, particularly, 1) a novel DAG embedding with a forward layer and a reverse layer that captures the structural information of a circuit-sat input. 2) Compared with Selsam et al.\'s work of Neuro-SAT, the proposed model in this paper, DG-DAGRNN, directly produces an assignment of variables, and the method is unsupervised and end-to-end differentiable. 3) Empirical experiments on random k-SAT and random graph k-coloring instances that support the authors\' claim on better generalization ability.\n\nThe paper is lucid and well written, I would support its acceptance at ICLR. Though I have a few comments and questions for the authors to consider.\n\n- In figure 1 (a), what are x11, x12, etc?\n\n- When comparing the two approaches of Neuro-Symbolic methods, besides the angles of optimality and training cost, it is worth to mention that the first one that based on classical algorithms always has a correctness guarantee, while the second one (learning the entire solution from scratch) usually does not.\n\n- Section 4.1, as a pure decision problem, solving SAT means that giving a yes/no answer (i.e., a classification); while for practical purposes, solving SAT means that producing a model (i.e., a witness) of the formula if it is SAT. This can be misleading for some readers when the authors mentioning ""solving SAT"", and it would be clear if the authors could make a distinction when using such terms.\n\n- Section 4.1, ""without requiring to see the actual SAT solutions during training"", again, what is the meaning of ""solutions"" is not very clear at this point. Readers may realize the experiments in the paper only train with satisfiable formulae from the afterward description, so the ""solutions"" indicates the assignments of variables. But it would be better to make it clear.\n\n- Section 4.1/The Evaluator Network, ""one can show also show that min() < S_min() <= S_max() < max()"", what is the ordering relation (i.e., < and <=) here? It is a bit confusing if a forall quantifier for inputs (a_1, ... a_n) is required here.\n\n- Section 4.1/The Evaluator Network, how does the temperature affect the results of R_G? It would be helpful to show their dynamics.\n\n- Section 4.1/Optimization, ""if the input circuit is UNSAT, one can show that the maximum achievable values for S_\\theta is 0.5"", it would be better to provide a brief description of how it is guaranteed. Also, this seems to be suggesting the DG-SAGRNN solver has no false positives, i.e., it will never produce a satisfiable result for unsatisfiable formulae? This would be interesting toward some semi-correctness if the answer is yes.\n\n- Section 5.1, are the testing data all satisfiable formulae? If yes, then the figure 2 shows there is a number of satisfiable formulae but both the models cannot produce correct results -- is that a correct understanding of figure 2? If not, then what is the ground truth?\n\n- I would love to see more experiments on SAT instances with a moderate number of variables but from real-world applications. It would be interesting to see how the model utilizes the rich structural information of instances from real applications (instead of randomly generated formulae).\n\n- The training time and testing time(per instance) are not reported in the experiments.\n', 'The Authors of this paper investigate Neuro-Symbolic methods in the context of learning a SAT solver generalized to the Circuit-SAT problem. Using a reinforcement learning – inspired approach to demonstrate a framework that is capable of (unsupervised) learning, by means of an end-to-end differentiable training procedure. Their formulation incorporates the solving of a given SAT problem into the architecture, meaning the algorithm is trained to produce a solution if a given problem is satisfiable. This is in contrast to previous similar work by (Selsam et al. 2018), where the framework was trained as a SAT classifier. Their results outline the performance increase over the previous work (Selsam et al. 2018) on finding a given solution for a SAT problem, on in-sample and out-sample results.\n\nNeg: \nFigure descriptions are not very clear\nWhen it comes to comparing the results, they do use a prepossessing step for their algorithm which they do not incorporate into the results\n\nPros:\nClear outline of the data sets used for benchmarks.\nGood Literature review, expressing in-depth knowledge of the current state of the art formulation for same/similar tasks \nExtensive background section, that explains the theoretical concepts and their architecture used well.\nClear outline of the Solver, where the individual parts/networks are explained and justified in detail\nVery well outlined argumentation for approaching this particular problem by the proposed method/\nThe experimental results as well are easy to follow and show promising results for the proposed framework\nThe proposed method as well is novel and outperforms similar algorithms in the experimental evaluation.\n\n\nThe paper is very well written, proposes a novel Neuro-Symbolic  approach to the classical SAT problem, and demonstrates promising results.\n ', 'The paper proposes a graph neural network architecture that is designed to use the DAG structure in the input to learn to solve Circuit SAT problems. Unlike graph neural nets for undirected graphs, the proposed network propagates information according to the edge directions, using a deep sets representation to aggregate over predecessors of each vertex and GRUs to implement recurrent steps. The network is trained by using a ""satisfiability function"" which takes soft variable assignments computed by the network and applying a relaxed version of the circuit to be solved (replacing AND with softmax, OR with softmin, and NOT with 1 - variable value) to compute a continuous score that measures how satisfying the assignment is. Training is done by maximizing this score on a dataset of problem instances that are satisfiable. Results are shown on random k-SAT and graph coloring problems.\n\nThe paper is reasonably well-written and easy to follow. The idea of using the relaxed version of the circuit for training is nice. Combining ideas from DAG-RNNs and Deep Sets is interesting, although incremental.\n\nCriticisms:\n- How much does tailoring the network architecture to the DAG structure of the circuit actually help? A comparison to a regular undirected graph neural network on the circuit input without edge directions would be useful. In particular, since both edge directions are used in the current architecture but represented as two different DAGs, it naturally raises the question of whether a regular undirected graph neural net would also work well.\n- How does the proposed approach compare to the current state-of-the-art non-learning approaches to SAT (CDCL, local search, etc.)? There is a huge literature on SAT, and ignoring all that work and comparing to only NeuroSAT seems unjustified. Without such comparisons, it is hard to say what is the benefit learning approaches in general, and the specific approach in this paper, provide in this domain. Even basic sanity-check baselines, e.g., random search, can be valuable given that the domain is somewhat new to learning approaches.\n- One way to interpret the proposed approach is that it is learning to propose soft assignments that can be easily rounded. It would be good to compare to a Linear Programming relaxation-based approach that represents the SAT instance as an integer program with binary variables, relaxes the variables to be in [0,1], solves the resulting linear program, and rounds the solution. Do these approaches share the same failure modes, how does their performance differ, etc.\n- The proposed approach has an obvious advantage over NeuroSAT in that it has access to the circuit structure, in addition to the flat representation of the SAT instance. According to the paper, not providing the circuit structure to the proposed approach hurts its performance. It would be useful to devise an experiment where a modified version of NeuroSAT is given the circuit structure as an additional input to see whether that closes the gap between the approaches.\n']","[70, 80, 20]","[80, 70, 60]","[""The sentiment score is 70 (positive) because the reviewer starts by praising the paper's contribution, calling it 'nice' and highlighting several positive aspects. They explicitly state support for acceptance at ICLR. The overall tone is constructive and appreciative, though they do have some questions and suggestions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing their comments as suggestions rather than demands (e.g., 'I would love to see', 'it would be better to'). They acknowledge the paper's strengths before offering critiques, and their questions are phrased in a curious rather than confrontational manner. The reviewer maintains a professional and courteous tone throughout the entire review."", ""The sentiment score is 80 (positive) because the review is predominantly positive. The reviewer praises the paper's clear outline, good literature review, extensive background section, and novel approach. They mention that the paper is 'very well written' and demonstrates 'promising results'. There are only two minor negative points mentioned. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They provide a balanced review, acknowledging both strengths and weaknesses without using harsh or critical language. The reviewer's tone is constructive and appreciative of the authors' work, which contributes to the polite impression."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some positive aspects of the paper, such as it being 'reasonably well-written and easy to follow' and having 'nice' and 'interesting' ideas. However, the bulk of the review consists of criticisms and suggestions for improvement, which tempers the overall positive sentiment. The politeness score is moderately high (60) because the reviewer uses respectful language throughout, framing criticisms as suggestions or questions (e.g., 'How much does...', 'It would be good to...') rather than direct criticisms. The reviewer also acknowledges the paper's strengths before moving on to areas for improvement, which is a polite approach to giving feedback.""]"
"[""\n\nSummary: This work considers the problem of learning in input-driven environments -- which are characterized by an addition stochastic variable z that can affect the dynamics of the environment and the associated reward the agent might see. The authors show how the PG theorem still applied for a input-aware critic and then they show that the best baseline one can use in conjecture with this critic is a input-dependent one. My main concerns are highlighted in points (3) and (4) in the detailed comments below. \n\nClarity: Generally it reads good, although I had to go back-and-forth between the main text and appendix several times to understand the experimental side. Even with the supplementary material, examples in Section 3 and Sections 6.2 could be improved in explanation and discussion.\n\nOriginality and Significance: Limited in this version, but could be improved significantly by something like point (3)&(4) in detailed comments. Fairly incremental extension of the PG (and TRPO) with the conditioning on the potentially (unobserved) input variables. The fact that a input-aware critic could benefit from a input-aware baseline is not that surprising. The fact that it reduces variance in the PG update is an interesting result; nevertheless I strongly feel the link or comparison needed is with the standard PG update. \n\nDisclaimer: I have not checked the proofs in the appendix.\n\nDetailed comments:\n\n1) On learning the input-dependent baselines: Generalising over context via a parametric functional approximation, like UVFAs [1] seems like a more natural first choice. Also these provide a zero-shot generalisation, bypassing the need for a burn-in period of the task. Can you comment on why something like that was not used at least as baseline?\n\n2) Motivating example. The exposition of this example lacks a bit of clarity and can use some more details as it is not a standard MDP example, so it’s harder to grasp the complexity of this task or how standard methods would do on it and where would they struggle. I think it’s meant to be an example of high variance but the performance in Figure 2 seems to suggest this is actually something manageable for something like A2C. It is also not clear in this example how the comparison was done. For instance, are the value functions used, input-dependent? Is the policy input aware? \n\n3) Input-driven MDP. Case 1/Case 2 : As noted by the authors, in case 1 if both s_t and z_t are observed, this somewhat uninteresting as it recovers a particular structured state variable of a normal MDP. I would argue that the more interesting case here, is where only s_t is observed and z_t is hidden, at least in acting. This might still be information available in hindsight and used in training, but won’t be available ‘online’ -- similar to slack variable, or privileged information at training time.  And in this case it’s not clear to me if this would still result in a variance reduction in the policy update. Case 2 has some of that flavour, but restricts z_t to an iid process. Again, I think the more interesting case is not treated or discussed at all and in my opinion, this might add the best value to this work.\n  \n4) Now, as mentioned above the interesting case, at least in my opinion, is when z is hidden. From the formulae(eq. (4),(5)), it seems to be that the policy is unaware of the input variables. Thus we are training a policy that should be able to deal with a distribution of inputs z. How does this compare with the normal PG update, that would consider a critic averaged over z-s and a z-independent baseline? Is the variance of the proposed update always smaller than that of the standard PG update when learning a policy that is unaware of z? \n\nReferences:\n[1] Schaul, T., Horgan, D., Gregor, K. and Silver, D., 2015, June. Universal value function approximators. In International Conference on Machine Learning (pp. 1312-1320).\n\n[POST-rebuttal] I've read the author's response and it clarified some of the concerns. I'm increase the score accordingly."", 'The paper introduces and develops the notion of input-dependent baselines for Policy Gradient Methods in RL.\n\nThe insight developed in the paper is clear: in environments such as data centers or outside settings external factors (traffic load or wind) constitute high magnitude perturbations that ultimately strongly change rewards.\nLearning an input-dependent baseline function helps clear out the variance created by such perturbations in a way that does not bias the policy gradient estimate (the authors provide a theoretical proof of that fact).\n\nThe authors propose different methods to train the input dependent baseline function:\n   o) a multi-value network based approach\n   o) a meta-learning approach\nThe performance of these two methods is compared on simulated robotic locomotion tasks as well as a load balancing and video bitrate adaptation task.\nThe input dependent baseline strongly outperforms the state dependent baseline in both cases.\n\nStrengths:\n   o) The paper is well written\n   o) The method is novel and simple while strongly reducing variance in Monte Carlo policy gradient estimates without inducing bias.\n   o) The experiment evidence is strong.\n\nWeaknesses:\n   o) Vehicular traffic has been the subject of recent development through deep reinforcement learning (e.g. https://arxiv.org/pdf/1701.08832.pdf and https://arxiv.org/pdf/1710.05465.pdf). In this particular setting exogenous noise (demand for throughput and accidents) could strongly benefit from input dependent baselines. I believe the authors should mention such potential applications of the method which may have major societal impact.\n   o) There is a lot of space dedicated to well know facts about policy gradient methods. I believe it could be more impactful to put the proof of Theorem 1 in the main body of the paper as it is clearly a key theoretical property.', ""\nIntroduction: \n“Since the state dynamics and rewards depend on the input process” -> why do the rewards depend on the input process conditioned on the state? \n\nDoes the scenario being considered basically involve any scenario with stochastic dynamics? Or is the fact that the disturbances may come from a stateful process what makes this distinct?\n\nif the input sequence following the action -> vague, would help if this would just be written a bit more clearly. \n\nIs just the baseline input dependent or does the policy need to be input dependent as well? From later reading, this point is still quite confusing. One line says “At time t, the policy only depends only on (st, zt).”. Another line says that the policy is pi_theta(a|s), with no mention of z. I’m pretty confused by the consistency here. This is also important in the proof of Lemma 1, because P(a|s,z) = pi_theta(a|s). Please clarify this.\n\nSection 4:\n Is the IID version of Figure 3 basically the same as stochastic dynamics? (Case 2)\n\nSection 4.1\n“In input-driven MDPs, the standard input-agnostic baseline is ineffective at reducing variance” -> can you give some more intuition/proof as to why. \n\nIn Lemma 2, how come the Q function is dependent on z, but the policy is only dependent on s (not even the current and past z’s). \n\nI think the proof of theorem 1 should be included in the main paper rather than unnecessary details about policy gradient. \n\nTheorem 1 and theorem 2 are really some of the most important parts of the paper, and they deserve a more thorough discussion besides the 2 lines that are in there right now. \n\n\nAlgorithm 1 -> should it be eqn 4?\n\nThe meta-algorithm provided in Section 5 is well motivated and well described. An experimental result including what happens with LSTM baselines would be very helpful. \n\nOne question is whether it is actually possible to know what the z’s are at different steps? In some cases these might be latent and hard to infer?\n\nCan you compare to Clavera et al 2018? It seems like it might be a relevant comparison. \n\nThe difference between MAML and the 10 value network seems quite marginal. Can the authors discuss why this is? And when we would expect to see a bigger difference. \n\nRelated work: Another relevant piece of work\nMeta-Learning Priors for Efficient Online Bayesian Regression\n\nMajor todos:\n1. Improve clarity of what z's are observed, which are not and whether the policy is dependent on these or not. \n2. Compare with other prior work such as Clavera et al, Harrison et al. \n3. Add more naive baselines such as training an LSTM, etc. \n4. Provide more analysis of the meta-learning component, how much does it actually help.\n\nOverall impression: \u2028I think this paper covers an interesting problem, and proposes a simple, straightforward approach conditioning the baseline and the critic on the input process. What bothers me in the current version of the paper is the lack of clarity about the observability of z, where it comes from and also some lack of comparisons with other prior methods. I think these would make the paper stronger.""]","[-20, 80, -20]","[60, 70, 50]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('Generally it reads good', 'The fact that it reduces variance in the PG update is an interesting result'), they express several concerns and limitations ('My main concerns are highlighted', 'Limited in this version', 'Fairly incremental extension'). The overall tone suggests the paper needs significant improvements. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, offers constructive criticism, and frames concerns as suggestions for improvement rather than harsh criticisms. They also acknowledge their own limitations ('I have not checked the proofs in the appendix') and provide detailed, helpful feedback. The language is professional and courteous, even when pointing out weaknesses in the work."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They highlight several strengths, including that the paper is well-written, the method is novel and effective, and the experimental evidence is strong. The reviewer does mention some weaknesses, but these are presented as suggestions for improvement rather than major criticisms. The politeness score is 70 (polite) because the reviewer uses respectful and constructive language throughout. They acknowledge the paper's merits and offer suggestions for improvement in a considerate manner. The reviewer doesn't use any harsh or critical language, instead framing their feedback as opportunities to enhance the paper's impact. The tone is professional and supportive throughout the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper covers an interesting problem and proposes a straightforward approach, they express several concerns and areas for improvement. The reviewer points out lack of clarity on key points, missing comparisons with prior work, and the need for more analysis and baselines. These criticisms outweigh the positive aspects mentioned.\n\nThe politeness score is moderately positive (50) as the reviewer maintains a professional and constructive tone throughout. They use polite language like 'can you' and 'please' when making requests. The critique is presented as suggestions for improvement rather than harsh criticism. The reviewer also acknowledges positive aspects of the work before diving into areas of concern. However, the score is not higher as the review is quite direct in pointing out flaws and doesn't use overly deferential language.""]"
"['This paper presents a study of the community detection problem via graph neural networks. The presented results open the possibility that neural networks are able to discover the optimal algorithm for a given task. This is rather convincingly demonstrated on the example of the stochastic block model, where the optimal performance is known (for 2 symmetric groups) or strongly conjectured (for more groups). The method is rather computationally demanding, and also somewhat unrealistic in the aspect that the training examples might not be available, but for a pioneering study of this kind this is well acceptable.\n\nDespite my overall very positive opinion, I found a couple of claims that are misleading and overall hurt the quality of the paper, and I would strongly suggest to the authors to adjust these claims:\n\n** The method is claimed to ""even improve upon current computational thresholds in hard regimes."" This is misleading, because (as correctly stated in the body of the paper) the computational threshold to which the paper refers apply in the limit of large graph sizes whereas the observed improvements are for finite sizes. It is shown here that for finite sizes the present method is better than belief propagation. But this clearly does not imply that it improves the conjectured computational thresholds that are asymptotic. At best this is an interesting hypothesis for future work, not more. \n\n** The energy landscape is analyzed ""under certain simplifications and assumptions"". Conclusions state ""an interesting transition from rugged to simple as the size of the graphs increase under appropriate concentration conditions."" This is very vague. It would be great if the paper could offer intuitive explanation of there simplifications and assumptions that is between these unclear remarks and the full statement of the theorem and the proof that I did not find simple to understand. For instance state the intuition on in which region of parameters are those results true and in which they are not. \n\n** ""multilinear fully connected neural networks whose landscape is well understood (Kawaguchi, 2016)."" this is in my opinion grossly overstated. While surely that paper presents interesting results, they are set in a regime that lets a lot to be still understood about landscape of fully connected neural networks. It is restricted to specific activation functions, and the results for non-linear networks rely on unjustified simplifications, the sample complexity trade-off is not considered, etc. \n\n\nMisprint: Page 2: cetain -> certain. \n', 'Graph Neural Networks(GNN) are gaining traction and generating a lot of interest. In this work, the authors apply them to the community detection problem, and in particular to graphs generated from the stochastic block model. The main new contribution here is called ""line graph neural network"" that operate directly over the edges of the graph, using efficiently the power of the ""non backtracking operator"" as a spectral method for such problems.\n\nTraining such GNN on data generated from the stochastic block model and other graph generating models, the authors shows that the resulting method can be competitive on both artificial and real datasets.\n\nThis is definitely an interesting idea, and a nice contribution to GNN, that should be of interest to ICML folks.\n\nReferences and citations are fine for the most part, except for one very odd exception concerning one of the main object of the paper: the non-backtracking operator itself! While discussed in many places, no references whatsoever are given for its origin in detection problems. I believe this is due to (Krzakala et al, 2013) ---a paper cited for other reasons--- and given the importance of the non-backtracking operator for this paper, this should be acknowledged explicitly.\n\nPro: Interesting new idea for GNN, that lead to more powerful method and open exciting direction of research. A nice theoretical analysis of the landscape of the graph. \n\nCon:The evidence provided in Table 1 is rather weak. The hard phase is defined in terms of computational complexity (polynomial vs exponential) and therefore require tests on many different sizes.\n\n', 'This paper introduces a novel graph conv neural network, dubbed LGNN, that extends the conventional GNN using the line graph of edge adjacencies and a non-backtracking operator. It has a form of learning directed edge features for message-passing. An energy landscape analysis of the LGNN is also provided under linear assumptions. The performance of LGNN is evaluated on the problem of community detection, comparing with some baseline methods. \n\nI appreciate the LGNN formulation as a reasonable and nice extension of GNN. The formulation is clearly written and properly discussed with message passing algorithms and other GNNs. Its potential hierarchical construction is also interesting, and maybe useful for large-scale graphs. In the course of reading this paper, however, I don’t find any clear reason why this paper restricts itself to community detection, rather than general node-classification problems for broader audience. It would have been more interesting if it covers other classification datasets in their experiments. \n\nMost of the weak points of this paper lie in the experimental section. \n1. The experimental sections do not have proper ablation studies, e.g., as follows.   \nAs commented in Sec 6.3, GAT may underperform due to the absence of the degree matrix and this needs to be confirmed by running GAT with the degree term. And, as commented in footnote 4, the authors used spatial batch normalization to improve the performance of LGNN. But, it’s not clear how much it obtains for each experiment and, more importantly, whether they use the same spatial batch norm in other baselines. To make sure the actual gain of LGNN, this needs be done with some ablation studies. \n2. The performance gain is not so significant compared to other simpler baselines, so the net contribution of  the line-graph extension is unclear considering the above. \n3. The experimental section considers only a few number of classes (2-5) so that it’s does not show how it scales with a large number of classes. In this sense, other benchmark datasets with more classes (e.g., PPI datasets used in GAT paper) would be better. \n\nI hope to get answers to these. ']","[60, 70, -20]","[70, 80, 60]","[""The sentiment score is 60 (positive) because the reviewer expresses an 'overall very positive opinion' and describes the paper as 'rather convincingly demonstrated' and 'well acceptable'. However, it's not 100 due to several criticisms and suggestions for improvement. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. Phrases like 'I would strongly suggest' and 'It would be great if' indicate a polite tone. The reviewer also provides specific examples and explanations for their critiques, which is a courteous approach to peer review."", ""The sentiment score is 70 (positive) because the reviewer expresses strong interest in the work, calling it 'definitely an interesting idea' and 'a nice contribution'. They highlight its relevance to ICML and mention both pros and cons, indicating a balanced but overall positive view. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledging the authors' contributions positively. They offer constructive criticism and suggestions for improvement without harsh language. The use of phrases like 'interesting idea', 'nice contribution', and 'exciting direction of research' contribute to the polite tone. Even when pointing out weaknesses, the reviewer maintains a professional and courteous demeanor."", ""The sentiment score is slightly negative (-20) because while the reviewer appreciates aspects of the paper ('I appreciate the LGNN formulation...'), they identify several weaknesses, particularly in the experimental section. They request additional studies and express concerns about the performance gains and scope of the experiments. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects before critiquing, and phrases criticisms as suggestions or hopes ('I hope to get answers to these'). The reviewer maintains a professional tone without harsh language, even when pointing out weaknesses.""]"
"[""Summary: The paper proposes a new smoothness constraint in the original cycle-gan formulation. The cycle-gan formulation minimizes reconstruction error on the input, and there is no criterion other than the adversarial loss function to ensure that it produce a good output (this is in sync with the observations from Gokaslan et al. ECCV'18 and Bansal et al. ECCV'18). A smoothness constraint is defined across random patches in input image and corresponding patches in transformed image. This enables the translation network to preserve edge discontinuities and variation in the output, and leads to better outputs for medical imaging, image to labels task, and horse to zebra and vice versa.\n\nPros: \n\n1.  Additional smoothness constraints help in improving the performance over multiple tasks. This constraint is intuitive.\n\n2. Impressive human studies for medical imaging.\n\n3. Improvement in the qualitative results for the shown examples in paper and appendix.\n\nThings not clear from the submission: \n\n1. The paper is lacking in technical details: \n\na. what is the patch-size used for RGB-histogram?\n\nb. what features or conv-layers are used to get the features from VGG (19?) net? \n\nc. other than medical imaging where there isn't a variation in colors of the two domains, it is not clear why RGB-histogram would work?\n\nd. the current formulation can be thought as a variant of perceptual loss from Johnson et al. ECCV'16 (applied for the patches, or including pair of patches). In my opinion, implementing via perceptual loss formulation would have made the formulation cleaner and simpler? The authors might want to clarify as how it is different from adding perceptual loss over the pair of patches along with the adversarial loss. One would hope that a perceptual loss would help improve the performance. Also see, Chen and Koltun, ICCV'17.\n\n2. The proposed approach is highly constrained to the settings where structure in input-output does not change. I am not sure how would this approach work if the settings from Gokaslan et al. ECCV'18 were considered (like cats to dogs where the structure changes while going from input to output)? \n\n3. Does the proposed approach also provide temporal smoothness in the output? E.g. Figure-6 shows an example of man on horse being zebrafied. My guess is that input is a small video sequence, and I am wondering if it provides temporal smoothness in the output? The failure on human body makes me wonder that smoothness constraints are helping learn the edge discontinuities. What if the edges of the input (using an edge detection algorithm such as HED from Xie and Tu, ICCV'15) were concatenated to the input and used in formulation? This would be similar in spirit to the formulation of deep cascaded bi-networks from Zhu et al . ECCV'16."", 'This paper adds a spatial regularization loss to the well-known CycleGAN loss for unpaired image-to-image translation (Zhu et al., ICCV17).  Essentially, the regularization loss (Eq. 6) is similar to imposing a CRF (Conditional Random Field) term on the network outputs, encouraging spatial consistency between patches within each generated image.\n\nThe paper is clear and well written.\n\nUnpaired Image-to-Image translation is an important problem. \n\nThe way the smoothness loss (Eq. 6) is presented gives readers the impression that spatial pairwise regularization is new, ignoring its long history (e.g., CRFs) in computer vision (not a single classical paper on CRFs is cited). Putting aside classical spatial regularization works, imposing pairwise regularization on the outputs of modern deep networks has been investigated in a very large number of works recently, particularly in the context of weakly-supervised semantic CNN segmentation, e.g.,  [Tang et al., On Regularized Losses for Weakly-supervised CNN Segmentation, ECCV 18 ], [Lin et al. : Scribblesup: Scribble-supervised convolutional networks for semantic segmentation, CVPR 2016], among  many other works. Very similar in spirit to this ICLR submission, these works impose within-image pairwise regularization (e.g., CRF) on the latent outputs of deep networks, with the main difference that these works use CNN semantic segmentation classifiers whereas here we have a CycleGAN for image generation.\n\nAlso, in the context of supervised CNN segmentation, CRFs have made a significant impact when used as post-processing step, e.g., very well known works such as [DeepLab by Chen et al. ICLR15] and [CRFs as recurrent Neural Networks by Zheng et al., ICCV 2015]. \n\nIt might be a valid contribution to evaluate spatial regularization (e.g., CRFs losses) on image generation tasks (such as CycleGAN), but the paper really needs to acknowledge very related prior works on regularization (at least in the context of deep networks).\n\nThere are also related pioneering semi-supervised deep learning works based on graph Laplacian regularization, e.g., [Westen et al., Deep Learning via Semi-supervised embedding, ICML 2008], which the paper does not acknowledge/discuss. \n\nThe manifold regularization terminology is misleading. The regularization is not over the feature space of image samples. It is within the spatial domain of each generated image (patch or pixel level); so, in my opinion, CRF (or spatial) regularization (instead of manifold regularization) is a much more appropriate terminology. \n\nAlso, I would not call this approach HarmonicGan. I would call it CRF-GAN or Spatially-Regularized GAN. The computation of harmonic functions is just one way, among many other (potentially better) ways to optimize pairwise smoothness terms (including the case of the used smoothness loss). And, by the way, I did not get how the loss in (9) gives a harmonic function. Could you please clarify and give more details? In my understanding, the harmonic solution in [ Zhu and Ghahramani, ICML 2013] comes directly as a solution of the graph Laplacian (and it assumes some labeled points, i.e., a semi-supervised setting). Even, if the solution is correct (which I do not see how), I do not think it is an efficient way to handle pairwise-regularization problems in image processing, particularly when matrix  W = [w_{ij}] is dense (which might be the case here, unless you are truncating the Gaussian kernel with some heuristics). In this case, back-propagating the proposed loss would be of quadratic complexity w.r.t the number of image patches. Again, there is a long tradition in optimizing efficiently pairwise regularizers in vision/learning (even in the case of dense affinity matrices), and one very well-known work, which is currently being used a lot in the context imposing CRF structure on the outputs of deep networks, is  [Krahenbuhl and Koltun, Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials], NIPS 2011. This highly related and widely used inference work for dense pairwise regulation is not cited/discussed neither. The Gaussian filtering ideas of the work of Krahenbuhl and Koltun, which ease optimizing dense pairwise terms (from quadratic to linear) are applicable here (as a Gaussian kernel is used), and are widely used in computer vision, including closely related works imposing spatial regularization losses on the outputs of deep networks, e.g., [Tang et al., On Regularized Losses for Weakly-supervised CNN Segmentation, ECCV 18], among many others.  \n  \nWhen using feature from pre-training (VGG) in the CRF loss, the comparison with unsupervised CycleGAN is not fair. In Table 2 (Label translation on Cityscapes), CycleGAN outperforms the proposed method in all metrics when only unsupervised histogram features are used, which makes me doubt about the practical value of the proposed regularization in the context of image-translation tasks. Having said that, the histogram-based regularization is helping in the medical-imaging application (Table 1). By the way, the use of histograms (of patches or super-pixels) as unsupervised features in pairwise regularization is not new neither; see for instance [Lin et al.: Scribblesup: Scribble-supervised convolutional networks for semantic segmentation, CVPR 2016]. Also, it might be better to use super-pixels instead of patches. \n\nSo, in summary, the technical contribution is minor, in my opinion (imposing pairwise regularization on the outputs of deep networks has been done in many works, but not for CycleGAN); optimization of the proposed loss as a harmonic function is not clear to me; using VGG in the comparisons with CycleGAN is not fair; and the long history of closely-related spatial regularization terms (e.g., CRFs) in computer vision is completely ignored.\n\nMinor: please use ‘term’ instead of ‘constraint’. These are unconstrained optimization problems and there are no equality or inequality constraints here.    \n\n', ""This paper proposes a method called HarmonicGAN for unpaired image-to-image translation. The key idea is to introduce a regularization term on the basis of CycleGAN, which encourages similar image patches to acquire similar transformations.  Two feature domains are explored for evaluating the patch-level similarity, including soft RGB histogram and semantic features based on VGGNet. In fact, the key idea is very similar to that of DistanceGAN. The proposed method can be regarded as a combination of the advantages of DistanceGAN and CycleGAN. Thus, the technical novelty is very limited in my opinion. Some experimental results are provided to demonstrate the superiority of the proposed method over CycleGAN, DistanceGAN and UNIT.\n\nGiven the limited novelty and the inadequate number of experiments, I am leaning to reject this submission.\n\nMajor questions:\n1. Lots of method details are missing. In Section 3.3.2, what layers are chosen for computing the semantic features? What exactly is the metric for computing the distance between semantic features.\n2. The qualitative results on the task, Horse2Zebra and Zebra2Horse, are not impressive. Obvious artifacts can be observed in the results. Although the paper claims that the proposed method does not change the background and performs more complete transformations, the background is changed in the result for the Horse2Zebra case in Fig. 5. More qualitative results are needed to demonstrate the effectiveness of the proposed method.\n3. To demonstrate the effectiveness of a general unpaired image-to-image translation method, the proposed method is needed to be testified on more tasks.\n4. Implementation details are missing. I am not able to judge whether the comparisons are fair enough.\n\n[New comment:] I have read the authors' explanations and clarifications that make me increase my rating. Regarding the technical novelty, I still don't think this paper bears sufficient stuff. If there is extra quota, I would recommend Accept.\n""]","[20, -60, -50]","[60, 20, 20]","[""The sentiment score is slightly positive (20) because the review starts by acknowledging the paper's contributions and listing some pros, such as the 'impressive human studies' and 'improvement in the qualitative results'. However, it also raises several questions and points out areas that are 'not clear', which tempers the positive sentiment. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, framing criticisms as 'things not clear' rather than outright flaws, and using phrases like 'The authors might want to clarify' instead of more demanding language. The reviewer also balances critique with praise, which contributes to the polite tone. The review maintains a professional and constructive approach, offering specific suggestions for improvement without being overly critical or harsh."", ""The sentiment score is -60 because the review is predominantly critical. While it acknowledges some positive aspects (e.g., 'The paper is clear and well written'), the majority of the review points out significant shortcomings, such as lack of acknowledgment of prior work, misleading terminology, and questionable technical contributions. The reviewer expresses doubt about the practical value of the proposed method and suggests the technical contribution is minor.\n\nThe politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'Could you please clarify' and 'It might be a valid contribution'. However, the criticism is direct and sometimes blunt, which prevents a higher politeness score. The reviewer also offers constructive suggestions and alternatives, which adds to the politeness."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's novelty and experimental rigor, leaning towards rejection. However, they do acknowledge some positive aspects and show willingness to reconsider their stance based on the authors' explanations. The politeness score is 20 because the reviewer maintains a professional tone throughout, offering constructive criticism and specific questions for improvement. They avoid harsh language and acknowledge the authors' clarifications positively. The reviewer's use of phrases like 'I am leaning to reject' and 'If there is extra quota, I would recommend Accept' indicate a polite and considerate approach to delivering criticism.""]"
"[""Summary:\nThe authors propose a method to learn and improve problem-tailored PDE solvers from existing ones. The linear updates of the target solver, specified by the problem's geometry and boundary conditions, are computed from the updates of a well-known solver through an optimized linear map.  The obtained solver is guaranteed to converge to the correct solution and\nachieves a considerable speed-up compared to solvers obtained from alternative state-of-the-art methods.   \n\nStrengths:\nSolving PDEs is an important and hard problem and the proposed method seems to consistently outperform the state of the art. I ve liked the idea of learning a speed-up operator to improve the performance of a standard solver and adapt it to new boundary conditions or problem geometries. The approach is simple enough to allow a straightforward proof of correctness. \n\nWeaknesses:\nThe method seems to rely strongly on the linearity of the solver and its deformation (to guarantee the correctness of the solution). The operator H is a matrix of finite dimensions and it is not completely clear to me what is the role of the multi-layer parameterization. Based on a grid approach, the idea applies only to one- or two-dimensional problems. \n\nQuestions:\n- in the introduction, what does it mean that generic solvers are effective 'but could be far from optimal'?  Does this refer to the convergence speed or to the correctness of the solution? \n- other deep learning approaches to PDE solving are mentioned in the introduction. Is the proposed method compared to them somewhere in the experiments? \n- given a PDE and some boundary conditions, is there any known method to choose the liner iterator T optimally? For example, since u* is the solution of a linear system, could one choose the updates to be the gradient descent updates of a least-squares objective such as || A u - f||^2?\n- why is the deep network parameterization needed? Since no nonlinearities are present, isn t this equivalent to fix the rank of H?\n- given the `  interpretation of H' sketched in Section 3.3, is there any relationship between the proposed accelerated update and the update of second-order coordinated descent methods (like Newton or quasi-Newton)?"", '==Summary==\nThis paper is well-executed and interesting. It does a good job of bridging the gap between distinct bodies of literature, and is very in touch with modern ML ideas. \n\nI like this paper and advocate that it is accepted. However, I expect that it would have higher impact if it appeared in the numerical PDE community. I encourage you to consider this conference paper to be an early version of a more comprehensive piece of work to be released to that community.\n\nMy main critique is that the paper needs to do a better job of discussing prior work on data-driven methods for improving PDE solvers.\n==Major comments==\n* You need to spend considerably more space discussing the related work on using ML to improve PDE solvers. Most readers will be unfamiliar with this. You should explain what they do and how they are qualitatively different than your approach. \n\n* You do a good job 3.3 of motivating for what H is doing. However, you could do a better job of motivating the overall setup of (6). Is this a common formulation? If so, where else is it used?\n* I’m surprised that you didn’t impose some sort of symmetry conditions on the convolutions in H, such as that they are invariant to flips of the kernel. This is true, for example, for the linearized Poisson operator. \n\n==Minor comments==\n\n* Valid iterators converge to a valid solution. However, can’t there be multiple candidate solutions? How would you construct a method that would be able to find all possible solutions?\n\n* In (9), why do you randomize the value of k? Wouldn’t you want to learn a different H depending on what computation budget you knew you were going to use downstream when you deploy the solver? \n\n* In future work it may make sense to learn a different H_i for each step i of the iterative solver. \n\n* When introducing iterative solvers, you leave it as an afterthought that b will be enforced by clamping values at the end of each iteration. This seems like a pretty important design decision. Are there alternatives that guarantee that u satisfies b always, rather than updating u in such a way that it violates G and then clamping it back? Along these lines, it might be useful to pose (2) with additional terms in the linear system to reflect G. \n', 'This paper develops a method to accelerate the finite difference method in solving PDEs. Basically, the paper proposes a revised framework for fixed point iteration after discretization. The framework introduces a free linear operator --- the choice of the linear operator will influence the convergence rate. The paper uses a deep linear neural network to learn a good operator. Experimental results on Poisson equations show that the learned operator achieves significant speed-ups. The paper also gives theoretical analysis about the range of the valid linear operator (convex open set) and guarantees of the generalization for the learned operator. \n\nThis is, in general, a good paper. The work is solid and results promising.  Solving PDEs is no doubt an important problem, having broad applications. It will be very meaningful if we can achieve the same accuracy using much less computational power.  Here, I have a few questions. \n\n1). Why didn’t you try the nonlinear deep network? Is it merely for computational efficiency? I expect that nonlinear networks might result in even better estimates of H and further reduce the number of fixed-point iterations, despite each operation of H will be more expensive. There might be some trade-off here. But I would like to see some empirical results and discussions.\n\n2). The evaluation is only on Poisson equations, which are known to be easy. Have you tried other PDEs, such as Burger’s equations? I think your method will be more meaningful for those challenging PDEs, because they will require much more fine-grained grids to achieve a satisfactory accuracy and hence much more expensive. It will be great if your method can dramatically improve the efficiency for solving these equations. \n\n3). I am a bit confused about the statement of Th 3 --- the last sentence “H is valid for all parameters f and b if the iterator \\psi converges …” I think it should be “for one parameter”. \n\nMiscellaneous:\n1)\tTypo. In eq. (7) \n2)\tSection 3.3, H(w) should be Hw (for consistency)\n']","[60, 70, 70]","[70, 80, 80]","[""The sentiment score is 60 (moderately positive) because the reviewer begins by highlighting the strengths of the paper, noting that the proposed method consistently outperforms the state of the art and praising the idea as simple enough to allow for a straightforward proof of correctness. However, the reviewer also points out some weaknesses and asks several questions, indicating a balanced but overall positive view. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing criticisms as 'weaknesses' rather than flaws, and posing questions in a curious rather than confrontational manner. The reviewer also uses phrases like 'I've liked the idea' which adds a personal, positive touch to the feedback."", ""The sentiment score is 70 (positive) because the reviewer explicitly states 'I like this paper and advocate that it is accepted.' They also describe the paper as 'well-executed and interesting.' However, it's not a perfect score as the reviewer suggests publishing in a different community for higher impact and mentions some critiques. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions positively. For example, they say 'I encourage you to consider' and 'You could do a better job' rather than using more forceful or negative language. The reviewer also balances critique with praise, which contributes to the polite tone."", ""The sentiment score is 70 (positive) because the reviewer starts by describing the paper as 'a good paper' with 'solid' work and 'promising' results. They also mention that the topic is important and meaningful. The overall tone is supportive, although they do raise some questions and suggestions for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, framing their comments as questions or suggestions rather than criticisms. They use phrases like 'I would like to see' and 'It will be great if' which maintain a constructive and courteous tone. The reviewer also acknowledges the potential impact of the work, which adds to the politeness. The slight deduction from a perfect score is due to the direct pointing out of a typo and a potential confusion, which, while not impolite, are slightly more direct critiques.""]"
"['This paper proposes a meta-learning approach for the problem of few-shot classification. Their method, based on parametrizing the learner for each task by a closed-form solver, strikes an interesting compromise between not performing any adaptation for each new task (as is the case in pure metric learning methods) and performing an expensive iterative procedure, such as MAML or Meta-Learner LSTM where there is no guarantee that after taking the few steps prescribed by the respective algorithms the learner has converged. For this reason, I find that leveraging existing solvers that admit closed-form solutions is an attractive and natural choice. \n\nSpecifically, they propose ridge regression as their closed-form solver (R2-D2 variant). This is easily incorporated into the meta-learning loop with any hyperparameters of this solver being meta-learned, along with the embedding weights as is usually done. The use of the Woodbury equation allows to rewrite the closed form solution in a way that scales with the number of examples instead of the dimensionality of the features; therefore taking advantage of the fact that we are operating in a few-shot setting. While regression may seem to be a strange choice for eventually solving a classification task, it is used as far as I understand due to the availability of this widely-known closed-form solution. They treat the one-hot encoded labels of the support set as the regression targets, and additionally calibrate the output of the network (via a transformation by a scale and bias) in order to make it appropriate for classification. Based on the loss of ridge regression on the support set of a task, a parameter matrix is learned for that task that maps from the embedding dimensionality to the number of classes. This matrix can then be used directly to multiply the embedded (via the fixed for the purposes of the episode embedding function) query points, and for each query point, the entry with the maximum value in the corresponding row of the resulting matrix will constitute the predicted class label.\n\nThey also experimented with a logistic regression variant (LR-D2) that does not admit a closed-form solution but can be solved efficiently via Newton’s Method under the form of Iteratively Reweighted Least Squares. When using this variant they restrict to tackling the case of binary-classification.\n\nA question that comes to mind about the LR-D2 variant: while I understand that a single logistic regression classifier is only capable of binary classification, there seems to be a straightforward extension to the case of multiple classes, where one classifier per class is learned, leading to a total of N one-vs-all classifiers (where N is the way of the episode). I’m curious how this would compare in terms of performance against the ridge regression variant which is naturally multi-class. This would allow to directly apply this variant in the common setting and would enable for example still oversampling classes at meta-training time as is done usually.\n\nI would also be curious to see an ablation where for the LR-D2 variant SGD was used as the optimizer instead of Newton’s method. That variant may require more steps (similar to MAML), but I’m curious in practice how this performs.\n\nA few other minor comments:\n- In the related work section, the authors write: “On the other side of the spectrum, methods that optimize standard iterative learning algorithms, [...] are accurate but slow.” Note however that neither MAML nor MetaLearner LSTM have been showed to be as effective as Prototypical Networks for example. So I wouldn’t really present this as a trade-off between accuracy and speed.\n- I find the term multinomial classification strange. Why not use multi-class classification?\n- In page 8, there is a sentence that is not entirely grammatically correct: ‘Interestingly, increasing the capacity of the other method it is not particularly helpful’.\n\nOverall, I think this is good work. The idea is natural and attractive. The writing is clear and comprehensive. I enjoyed how the explanation of meta learning and the usual episodic framework was presented. I found the related work section thorough and accurate too. The experiments are thorough as well, with appropriate ablations to account for different numbers of parameters used between different methods being compared. This approach is evidently effective for few-shot learning, as demonstrated on the common two benchmarks as well as on a newly-introduced variant of cifar that is tailored to few-shot classification. Notably, the ridge regression variant can reach results competitive with SNAIL that uses significantly more weights and is shown to suffer when its capacity is reduced. Interestingly, other models such as MAML actually suffer when given additional capacity, potentially due to overfitting.\n', 'Summary: The paper proposes an algorithm for meta-learning which amounts to fixing the features (ie all hidden layers of a deep NN), and treating each task  as having its own final layer which could be a ridge regression or a logistic regression. The paper also proposes to separate the data for each task into a training set used to optimize the last, task specific layer, and a validation set used to optimize all previous layers and hyper parameters. \n\nNovelty: This reviewer is unsure what the paper claims as a novel contribution. In particular training multi-task neural nets with shared feature representation and task specific final layer is probably 20-30 years old by now and entirely common. It is also common freeze the feature representation learned from the first set of tasks, and to simply use it for new tasks by modifying the last (few) layer(s) which would according to this paper qualify as meta-learning since the new task can be learned with very few new examples. \n\n', 'This paper proposes a new meta-learning method based on closed-form solutions for task specific classifiers such as ridge regression and logistic regression (iterative). The idea of the paper is quite interesting, comparing to the existing metric learning based methods and optimization based methods. \n\nI have two concerns on this paper. \nFirst, the motivation and the rationale of the proposed approach is not clear. In particular, why one can simply treat \\hat{Y} as a scaled and shifted version of X’W?\n\nSecond, the empirical performance of the proposed approach is not very promising and it does not outperform the comparison methods, e.g., SNAIL.  It is not clear what is the advantage. \n']","[80, -50, -20]","[70, 0, 50]","[""The sentiment score is 80 because the reviewer expresses a very positive view of the paper, describing it as 'good work' with a 'natural and attractive' idea. They praise the clear writing, comprehensive explanation, thorough related work section, and effective experimental results. The few criticisms are minor and presented constructively. The politeness score is 70 because the reviewer uses respectful and professional language throughout, offering praise and constructive feedback. They use phrases like 'I find', 'I'm curious', and 'I would be curious to see', which are polite ways of expressing opinions and suggestions. The reviewer also acknowledges the strengths of the paper before offering any critiques, which is a polite approach to reviewing."", ""The sentiment score is -50 because the reviewer expresses significant doubt about the novelty of the paper's contribution. The phrase 'This reviewer is unsure what the paper claims as a novel contribution' indicates skepticism, and the reviewer suggests that the main ideas presented are already well-established in the field. However, the review is not entirely negative, as it does provide a neutral summary of the paper's content, which prevents the score from being lower.\n\nThe politeness score is 0 (neutral) because the reviewer maintains a professional tone throughout without using overtly polite or rude language. The criticism is presented factually without personal attacks or overly harsh wording, but also without any particularly courteous phrasing. The use of phrases like 'This reviewer is unsure' instead of more direct criticism contributes to the neutral tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's interesting idea, they express two significant concerns about the motivation and empirical performance. The initial positive comment is outweighed by these concerns. The politeness score is moderately positive (50) as the reviewer uses respectful language, acknowledges the paper's merits, and frames their concerns as questions rather than harsh criticisms. They use phrases like 'I have two concerns' and 'It is not clear' which maintain a professional and courteous tone while still conveying their reservations about the paper.""]"
"['The paper addresses a challenging problem of predicting the states of entities over the description of a process. The paper is very well written, and easily understandable. The authors propose a graph structure for entity states, which is updated at each step using the outputs of a machine comprehension system. The approach is novel and well motivated. I will suggest a few improvements: \n\n1. the NPN model seems a good alternative, will be good to have a discussion about why your model is better than NPN. Also, NPN can probably be modified to output spans of a sentence. I will be curious to know how it performs.\n\n2. A more detailed illustration of the system / network is needed. Would have made it much easier to understand the paper. \n\n3. What are the results when using the whole training set of Recipes ?\n\n\n', 'The paper proposes a recurrent knowledge graph (bipartite graph between entities and location nodes) construction & updating mechanism for entity state tracking datasets such as (two) ProPara tasks and Recipes. The model goes through the following three steps: 1) it reads a sentence at each time step t and identifies the location of each entity via machine reading comprehension model such as DrQA (entities are predefined). 2) Co-reference module adjusts relationship scores (soft adjacency matrix) among nodes, including possibly new nodes introduced by the MRC model. 3) to propagate the relational information across all the nodes, the model performs L layers of LSTM for each entity that attend on other nodes via attention (where the weights come from the adjacency matrix). The model repeats the three steps for each sentence. The model is trained by directly supervising for the correct span by the MRC model at each time step, which is possible because the data provides strong supervision for each sentence (not just the answer at the end).\n The model achieves the state of the art in the two tasks of ProPara and Recipes dataset.\n\nStrengths: The paper provides an elegant solution for tracking relationship between entities as time (sentence) progresses. I also agree with the authors that this line of work (dynamic KG construction and modification) is an important area of research. While the model shares a similar spirit to EntNet, I think the model has enough distinctions / contributions, especially given that it outperforms EntNet by a large margin. The model also obtains non-trivial improvement over previous SOTA models.\n\nWeaknesses: Paper could have been written better. I had hard time understanding it. The notations are overall confusing and not explained well. Also there are a few unclear parts which I discuss in questions below.\n\nQuestions: \n1. Are e_{i,t} and lambda_{i,t} vectors? Scalars? Abstract node notations? It is not clear in the model section. Also, it took me a long time to figure out that ‘i’ is used to index each entity (it is mentioned later).\n2. The paper says v_i (initial representation of each entity) is obtained by looking at the contextualized representations (LSTM outputs) of entity mention in the context. What happens if there are multiple mentions in the text? Which one does it look at?\n3. For the LSTM in the graph update, why does it have only one input? Shouldn’t it have two inputs, one for previous hidden state and the other for input?\n4. Regarding Recipe experiments, the paper says it reaches a better performance than the baseline using just 10k examples out of 60k. This is great, but could you also report the number when the full dataset is used?\n5. What does it mean that in training time the model “updates” the location node representation with the encoding of correct span. Do you mean you use the encoding instead?\n6. For ProPara task 2, what threshold did you choose to obtain the P/R/F1 score? Is it the threshold that maximizes F1?\n', ""* Summary\nThis paper addresses machine reading tasks involving tracking the states of entities over text. To this end, it proposes constructing a knowledge graph using recurrent updates over the sentences of the text, and using the graph representation to condition a reading comprehension module. The paper reports positive evaluations on three different tasks.\n\n* Review\n\nThis is an interesting paper. The key technical component in the proposed approach is the idea that keeping track of entity states requires (soft) coreference between newly read entities and locations and the ones existing in the knowledge graph constructed so far.\n\nThe proposed method seems plausible, but some details are impressionistic and it is not clear why and whether the modeling choices do what the paper says. This is especially the case in a few places involving coreference:\n1. The paper says at the top of page 6 that the result of Eq 1 is a disambiguated intermediate node representation.\n2. The self attention in Eq 2 performs coreference disamguation which prevents different instances of the same location from being predicted for multiple entities.\n\nWhile these may indeed be working as advertised, it would be good to see some evaluation that verifies that after learning, what is actually happening is coreference.\n\nWhy does the graph update require coreference pooling again?  Don't the updates in Eq 1 and 2 take care of this? The ablation does not test this, right?\n\nAnother modeling choice that is not clear is regarding how the model processes the text -- reading prefixes of the paragraph, rather than one sentence at a time. What happens if the model is changed to be read one sentence at a time?\n\nThat the model implicitly learns constraints from data is interesting!\n   \nBottomline: The paper presents interesting ideas and good results, but would be better if the modeling choices were better explored/motivated.\n""]","[80, 60, 20]","[90, 70, 60]","[""The sentiment score is 80 (positive) because the reviewer starts with praising the paper as 'very well written, and easily understandable'. They also describe the approach as 'novel and well motivated'. The overall tone is very positive, with only minor suggestions for improvement. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, such as 'I will suggest a few improvements' and 'I will be curious to know'. They frame their suggestions as questions or curiosities rather than demands, which is a polite approach. The reviewer also balances criticism with praise, which is a hallmark of polite academic discourse."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's strengths, describing the solution as 'elegant' and the work as 'important'. They also note that the model achieves state-of-the-art results and shows significant improvement over previous models. However, the score is not higher due to the mentioned weaknesses in writing clarity and some confusing aspects. The politeness score is 70 (polite) because the reviewer maintains a professional and respectful tone throughout. They balance positive feedback with constructive criticism and pose questions in a neutral, inquisitive manner rather than confrontational. The use of phrases like 'I agree with the authors' and 'This is great, but...' shows a collegial approach to the review process."", ""The sentiment score is slightly positive (20) because the reviewer describes the paper as 'interesting' and acknowledges 'good results', but also expresses several concerns and areas for improvement. The overall tone is constructive rather than overtly negative or enthusiastic. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers suggestions politely ('it would be good to see...'), and frames criticisms as questions or areas for clarification rather than direct attacks. The reviewer also acknowledges positive aspects of the work alongside areas for improvement, maintaining a balanced and professional tone.""]"
"['UPDATE:\n\nI\'ve read the revised version of this paper, I think the concernings have been clarified.\n\n-------\n\nThis paper proposes to employ the bandit optimization based approach for the generation of adversarial examples under the loss accessible black-box situation. The authors examine the feasibility of using the step and spatial dependence of the image gradients as the prior information for the estimation of true gradients. The experimental results show that the proposed method out-performs the Natural evolution strategies method with a large margin.\n\nAlthough I think this paper is a decent paper that deserves an acceptance, there are several concernings:\n\n1. Since the bound given in Theorem 1 is related to the square root of k/d, I wonder if the right-hand side could become ""vanishingly small"", in the case such as k=10000 and d=268203. I wish the authors could explain more about the significance of this Theorem, or provide numerical results (which could be hard).\n\n2. Indeed I am not sure if Section 2.4 is closely related to the main topic of this paper, these theoretical results seem to be not helpful in convincing the readers about the idea of gradient priors. Also, the length of the paper is one of the reasons for the rating.\n\n3. In the experimental results, what is the difference between one ""query"" and one ""iteration""? It looks like in one iteration, the Algorithm 2 queries twice?', 'Paper formalizes the gradient estimation problem in a black-box setting, and provs the equivalence of least Squares with NES. It then improves on state of the art by using priors coupled with a bandit optimization technique.\n\nThe paper is well written. The idea of using priors to improve adversarial gradient attacks is an enticing idea. The results seem convincing.\n\nComments:\n- I missed how data dependent prior is factored into the algorithms 1-3. Is it by the choice of d? I suggest a clearer explanation.\n- In fig 4, I was confused that the loss of the methods is increasing. it took me a minute to realize this is the maximized adversarial loss, and thus higher is better. you may want to spell this out for clarity. I typically associate lower loss with better algorithms.\n- I am confused by Fig 4c. If I am comparing g to g*, I do expect a high cosine similarity. cos = 1 is the best. Why is correlation so small? and why is it 0 for NES? You may also want to offer additional insight in the text explaining 4c. \n\nMinor comments:\n- Is table one misplaced?\n- The symbol for ""boundary of set U"" may be confused with a partial derivative symbol\n- first paragraph of 2.4: ""our estimator a sufficiently"". something missing?\n- ""It is the actions g_t (equal to v_t) which..."" refering to g_t as actions is confusing. Although may be technically correct in bandit setting\n- Further explain the need for the projection of algorithm 3, line 7.\n- Fig 4: refer to true gradient as g*\n\nCaveat: Although I am well versed in bandits, I am not familiar with adversarial training and neural network literature. There is a chance I may have misevaluated central concepts of the paper.', 'This paper formulates the black-box adversarial attack as a gradient estimation\nproblem, and provide some theoretical analysis to show the optimality of an\nexisting gradient estimation method (Neural Evolution Strategies) for black-box\nattacks.\n\nThis paper also proposes two additional methods to reduce the number of queries\nin black-box attack, by exploiting the spacial and temporal correlations in\ngradients. They consider these techniques as priors to gradients, and a bandit\noptimization based method is proposed to update these priors. \n\nThe ideas used in this paper are not entirely new. For example, the main\ngradient estimation method is the same as NES (Ilyas et al. 2017);\ndata-dependent priors using spatially local similarities was used in Chen et\nal. 2017.  But I have no concern with this and the nice thing of this paper is \nto put these tricks under an unified theoretical framework, which I really \nappreciate.\n\nExperiments on black-box attacks to Inception-v3 model show that the proposed\nbandit based attack can significantly reduces the number of queries (2-4 times\nfewer) when compared with NES. \n\nOverall, the paper is well written and ideas are well presented.\nI have a few concerns:\n\n1) In Figure 2, the authors show that there are strong correlations between the\ngradients of current and previous steps. Such correlation heavily depends on\nthe selection of step size.  Imagine that the step size is sufficiently large,\nsuch that when we arrive at a new point for the next iteration, the\noptimization landscape is sufficiently changed and the new gradient is vastly\ndifferent than the previous one. On the other hand, when using a very small\nstep-size close to 0, gradients between consecutive steps will be almost the\nsame. By changing step-size I can show any degree of correlation.  I am not\nsure if the improvement of Bandit_T comes from a specific selection of\nstep-size. More empirical evidence on this need to be shown - for example, run\nBandit_T and NES with different step sizes and observe the number of queries\nrequired.\n\n2) This paper did not compare with many other recent works which claim to\nreduce query numbers significantly in black-box attack. For example, [1]\nproposes ""random feature grouping"" and use PCA for reducing queries, and [2]\nuses a good gradient estimator with autoencoder. I believe the proposed method\ncan beat them, but the authors should include at least one more baseline to \nconvince the readers that the proposed method is indeed a state-of-the-art.\n\n3) Additionally, the results in this paper are only shown on a single model\n(Inception-v3), and it is hard to compare the results directly with many other\nrecent works. I suggest adding at least two more models for comparison (most\nblack-box attack papers also include MNIST and CIFAR, which should be easy to\nadd quickly). These numbers can be put in appendix.\n\nOverall, this is a great paper, offering good insights on black-box adversarial\nattack and provide some interesting theoretical analysis. However currently it\nis still missing some important experimental results as mentioned above, and\nnot ready to be published as a high quality conference paper. I conditionally\naccept this paper as long as sufficient experiments can be added during the\ndiscussion period.\n\n\n[1] Exploring the Space of Black-box Attacks on Deep Neural Networks, by Arjun\nNitin Bhagoji, Warren He, Bo Li and Dawn Song, https://arxiv.org/abs/1712.09491\n(conference version accepted by ECCV 2018)\n\n[2] AutoZOOM: Autoencoder-based Zeroth Order Optimization Method for Attacking\nBlack-box Neural Networks, by Chun-Chen Tu, Paishun Ting, Pin-Yu Chen, Sijia\nLiu, Huan Zhang, Jinfeng Yi, Cho-Jui Hsieh, Shin-Ming Cheng,\nhttps://arxiv.org/abs/1805.11770\n\n==========================================\n\nAfter discussing with the authors, they provided better evidence to support the conclusions in this paper, and fixed bugs in experiments. The paper looks much better than before. Thus I increased my rating.']","[50, 70, 60]","[70, 80, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer starts by stating that the paper 'deserves an acceptance' and is a 'decent paper', indicating a generally positive view. However, they also raise several concerns, which tempers the positivity. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, such as 'I think', 'I wish', and 'I wonder', which softens their criticisms. They also acknowledge the potential difficulty of addressing one of their concerns ('which could be hard'). The reviewer maintains a professional and constructive tone, offering specific suggestions for improvement without being harsh or dismissive."", ""The sentiment score is 70 (positive) because the reviewer starts by praising the paper as 'well written' and mentions that the idea is 'enticing' and the results are 'convincing'. These are strong positive indicators. However, it's not a perfect score due to the several comments and suggestions for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offers constructive criticism, and even acknowledges their own potential limitations in evaluating the paper. The use of phrases like 'I suggest', 'you may want to', and 'I missed' instead of more direct criticisms contributes to the polite tone. The reviewer also balances critique with praise, which is a polite approach to peer review."", ""The sentiment score is 60 (moderately positive) because the reviewer expresses appreciation for the paper's unified theoretical framework and describes it as 'well written' with 'good insights'. However, they also raise several concerns and request additional experiments, indicating it's not entirely positive. The politeness score is 80 (quite polite) due to the reviewer's constructive tone, use of phrases like 'I really appreciate' and 'nice thing', and the balanced way they present both strengths and areas for improvement. They offer conditional acceptance, showing respect for the authors' work while maintaining academic rigor. The language throughout is professional and courteous, avoiding any harsh or rude phrasing.""]"
"['In this paper, the authors extend the HER framework to deal with dynamical goals, i.e. goals that change over time.\nIn order to do so, they first need to learn a model of the dynamics of the goal, and then to select in the replay buffer experience reaching the expected value of the goal at the expected time. Empirical results are based on three (or four, see the appendix) experiments with a Mujoco UR10 simulated environment, and one experiment is successfully transfered to a real robot.\n\nOverall, the addressed problem is relevant (the question being how can you efficiently replay experience when the goal is dynamical?), the idea is original and the approach looks sound, but seems to suffer from a fundamental flaw (see below).\n\nDespite some merits, the paper mainly suffers from the fact that the implementation of the approach described above is not explained clearly at all.\nAmong other things, after reading the paper twice, it is still unclear to me:\n- how the agent learns of the goal motion (what substrate for such learning, what architecture, how many repetitions of the goal trajectory, how accurate is the learned model...)\n- how the output of this model is taken as input to infer the desired values of the goal in the future: shall the agent address the goal at the next time step or later in time, how does it search in practice in its replay buffer, etc.\n\nThese unclarities are partly due to unsufficient structuring of the ""methodology"" section of the paper, but also to unsufficient mastery of scientific english. At many points it is not easy to get what the authors mean, and the paper would definitely benefit from the help of an experienced scientific writer.\n\nNote that Figure 1 helps getting the overall idea, but another Figure showing an architecture diagram with the main model variables would help further.\n\nIn Figures 3a and 5, we can see that performance decreases. The explanation of the authors just before 4.3.1 seem to imply that there is a fundamental flaw in the algorithm, as this may happen with any other experiment. This is an important weakness of the approach.\n\nTo me, Section 4.5 about transfer to a real robot does not bring much, as the authors did nothing specific to favor this transfer. They just tried and it happens that it works, but I would like to see a discussion why it works, or that the authors show me with an ablation study that if they change something in their approach, it does not work any more.\n\nIn Section 4.6, the fact that DHER can outperform HER+ is weird: how can a learn model do better that a model given by hand, unless that given model is wrong? This needs further investigation and discussion.\n\nIn more details, a few further remarks:\n\nIn related work, twice: you should not replace an accurate enumeration of papers with ""and so on"".\n\np3: In contrary, => By contrast, \n\nwhich is the same to => same as\n\ncompare the above with the static goals => please rephrase\n\nIn Algorithm 1, line 26: this is not the algorithm A that you optimize, this is its critic network.\n\nline 15: you search for a trajectory that matches the desired goal. Do you take the first that matches? Do you take all that match, and select the ""best"" one? If yes, what is the criterion for being the best?\n\np5: we find such two failed => two such failed\n\nthat borrows from the Ej => please rephrase\n\nwe assign certain rules to the goals so that they accordingly move => very unclear. What rules? Specified how? Please give a formal description.\n\nFor defining the reward, you use s_{t+1} and g_{t+1}, why not s_t and g_t?\n\np6: the same cell as the food at a certain time step. Which time step? How do you choose?\n\nThe caption of Fig. 6 needs to be improved to be contratsed with Fig. 7.\n\np8: the performance of DQN and DHER is closed => close?\n\nDHER quickly acheive(s)\n\nBecause the law...environment. => This is not a sentence.\n\nMentioning in the appendix a further experiment (dy-sliding) which is not described in the paper is of little use.\n', 'This paper proposes a way of extending Hindsight Experience Replay (HER) to dynamic or moving goals. The proposed method (DHER) constructs new successful trajectories from pairs of failed trajectories where the goal accomplished at some point in the first trajectory happens to match the desired goal in the second trajectory. The method is demonstrated to work well in several simulated environments and some qualitative sim2real transfer results to a real robot are also provided.\n\nThe paper is well written and is mostly easy to follow. I liked the idea of combining parts of two trajectories and to the best of my knowledge it is new. It is a simple idea that seems to work well in practice. While DHER has some limitations I think the key ideas will lead to interesting future work.\n\nThe main shortcoming of the paper is that it does not consider other relevant baselines. For example, since the position of the goal is known, why not use a shaped reward as opposed to a sparse reward? The HER paper showed that using sparse rewards with HER can work better than shaped rewards. These findings may or may not transfer to the dynamic goal case so including a shaped reward baseline would make the paper stronger.\n\nSome questions and suggestions on how to improve the paper:\n- It would be good to be more upfront about the limitations of the method. For example, the results on a real robot probably require accurate localization of the gripper and cup. Making this work for precise manipulation will probably require end-to-end training from vision where it’s not obvious DHER would apply.\n- It would be interesting to see quantitative results for the simulated experiments in section 4.5. \n- The performance of DHER on Dy-Reaching seems to degrade in later stages of training (Figures 3a and 5). Do you know what is causing it? DQN or DHER?\n\nOverall, I think this a good paper.', 'The authors propose an extension of hindsight replay to settings where the goal is moving. This consists in taking a failed episode and constructing a valid moving goal by searching prior experiences for a compatible goal trajectory. Results are shown on simulated robotic grasping tasks and a toy task introduced by the authors. Authors show improved results compared to other baselines. The authors also show a demonstration of transfering their policies to the real world.\n\nThe algorithm appears very specific and not applicable to all cases with dynamic goals. It would be good if the authors discussed when it can and cannot be applied. My understanding is it would be hard to apply this when the environment changes across episodes as there needs to be matching trajectories. It would also be hard to apply  this for the same reason if there are dynamics chaging the environment (besides the goal). If the goal was following more complex dynamics like teleporting from one place it seems it would again be rather hard to adapt this. I am also wondering if for most practical cases one could construct a heuristic for making the goal trajectory a valid one (not necessarily relying on knowing exact dynamics) thus avoiding the matching step.\n\nThe literature review and the baselines do not appear to consider any other methods designed for dynamic goals. The paper seems to approach the dynamic goal problem as if it was a fresh problem. It would be good to have a better overview of this field and baselines that address this problem as it has certainly been studied in robotics, computer vision, and reinforcement learning. I find this paper hard to assess without a more appropriate context for this problem besides a recently proposed technique for sparse rewards that the authors might want to adapt to it.  I find it difficult to believe that nobody has studied solutions to this problem and solutions specific to that don’t exist.\n\nThe writing is a bit repetitive at times and I do believe the algorithm can be more tersely summarized earlier in the paper. It’s difficult to get the full idea from the Algorithm block.\n\nOverall, I think the paper is borderline. There is several interesting ideas and a new dataset introduced, but I would like to be more convinced that the problems tackled are indeed as hard as the authors claim and to have a better literature review.\n']","[-30, 80, -20]","[20, 90, 50]","[""The sentiment score is -30 because while the reviewer acknowledges some merits of the paper ('the addressed problem is relevant', 'the idea is original'), they also point out significant flaws and areas for improvement. The review highlights unclear explanations, insufficient structuring, and potential fundamental flaws in the algorithm. The overall tone suggests more criticism than praise.\n\nThe politeness score is 20 because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'Overall, the addressed problem is relevant' and 'Despite some merits' to soften criticism. The reviewer also offers specific suggestions for improvement rather than just pointing out flaws. However, some phrases like 'unsufficient mastery of scientific english' could be perceived as slightly harsh, preventing a higher politeness score."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'well written,' praising the novelty of the idea, and stating that it's a 'good paper' overall. They mention that the method 'works well' and will lead to 'interesting future work.' The score is not 100 because the reviewer does point out some shortcomings and limitations. The politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They balance praise with criticism, offer suggestions for improvement, and phrase their concerns as questions or gentle recommendations rather than harsh criticisms. The reviewer also uses phrases like 'I liked' and 'I think' to soften their statements. The overall tone is professional and supportive."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting ideas and a new dataset, they express several concerns and criticisms. The reviewer states the paper is 'borderline' and wants to be 'more convinced' about the claims and literature review. They also point out limitations of the proposed algorithm and repetitiveness in writing. However, it's not entirely negative as they recognize some positive aspects.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'It would be good if' and 'I am wondering if' to suggest improvements, rather than making harsh criticisms. The reviewer also acknowledges the paper's strengths alongside its weaknesses. However, the score isn't higher because the review doesn't go out of its way to be exceptionally polite or encouraging, maintaining a more neutral, academic tone.""]"
"['Optimization algorithms such as stochastic gradient descent (SGD) and stochastic mirror descent (SMD) have found wide applications in training deep neural networks. In this paper the authors provide some theoretical studies to understand why SGD/SMD can produce a solution with good generalization performance when applied to high-parameterized models. The authors developed a fundamental identity for SGD with least squares loss function, based on which the minimax optimality of SGD is established, meaning that SGD chooses the best estimator that safeguards against the worst-case disturbance. Implicit regularization of SGD is also established in the interpolating case, meaning that SGD iterates converge to the one with minimal distance to the starting point in the set of models with no errors. Results are then extended to SMD with general loss functions.\n\nComments:\n\n(1) Several results are extended from existing literature. For example, Lemma 1 and Theorem 3 have analogues in (Hassibi et al. 1996). Proposition 8 is recently derived in (Gunasekar et al., 2018). Therefore, it seems that this paper has some incremental nature. I am not sure whether the contribution is sufficient enough.\n\n(2) The authors say that they show the convergence of SMD in Proposition 9, while (Gunasekar et al., 2018) does not. It seems that the convergence may not be surprising since the interpolating case is considered there.\n\n(3) Implicit regularization is only studied in the over-parameterized case. Is it possible to say something in the general setting with noises?\n\n(4) The discussion on the implicit regularization for over-parameterized case is a bit intuitive and based on strong assumptions, e.g., the first iterate is close to the solution set. It would be more interesting to present a more rigorous analysis with relaxed assumptions.', 'The authors look at SGD, and SMD updates applied to various models and loss functions. They derive a fundamental identity lemma 2 for the case of linear model and squared loss + SGD and in general for non-linear models+ SMD + non squared loss functions. The main results shown are\n1. SGD is optimal in a certain sense for squared loss and linear model.\n2. SGD always converges to a solution closest to the starting point.\n3. SMD when it converges, converges to a point closest to the starting point in the bregman divergence. The convergence of SMD iterates is shown for certain learning scenarios.\n\nPros: Shows implicit regularization properties for models beyond linear case.\nCons: 1. The notion of optimality is w.r.t. a metric that is pretty non-standard and it was not clear to me as to why the metric is important to study (the ratio metric in eq 9).\n2. The result is not very surprising since SMD is pretty much a gradient descent w.r.t a different distance metric. ', 'This is a very interesting paper and it suggests a novel way to think of ""implicit regularization"". The power of this paper lies in its simplicity and its inspiring that such almost-easy arguments could be made to get so much insight. It suggests that minimizers of the Bregrman divergence are an alternative characterization of the asymptotic end-points of  ""Stochastic Mirror Descent"" (SMD) when it converges. So choice of the strongly convex potential function in SMD is itself a regularizer!  \n\nIts a very timely paper given the increasing consensus that ""implicit regularization"" is what drives a lot of deep-learning heuristics. This paper at its technical core suggests a modified notion of Bregman-like divergence (equation 15) which on its own does not need a strongly convex potential. Then the paper goes on to show that there is an invariant of the iterations of SMD along its iterations which involves a certain relationship (equation 18) between the usual Bregman divergence and their modified divergence. I am eager to see if such relationships can be shown to hold for more complicated iterative algorithms! \n\nBut there are a few points in the paper which are not clear and probably need more explanation and let me list them here. ( and these are the issues that prevent me from giving this paper a very high rating despite my initial enthusiasm )\n\n1. \nCan the authors explain how is the minimax optimality result of Theorem 6 (and Corollary 7) related to the main result of the paper which is probably Proposition 8 and and 9? Is that minimax optimiality a different insight separate from the main line of the arguments (which I believe is Proposition 8 and 9)? \n\n2.\nIs the gain in Proposition 9 over Proposition 8 is all about using loss convexity to ensure that the SMD converges and w_\\infty exists? \n\n3. \nThe paper has highly insufficient comparisons to many recent other papers on the idea of ""implicit bias"" like, https://arxiv.org/abs/1802.08246, https://arxiv.org/abs/1806.00468 and https://arxiv.org/abs/1710.10345. It seems pretty necessary that there be a section making a detailed comparison with these recent papers on similar themes. ']","[-20, 20, 60]","[60, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the theoretical contributions of the paper, they express concerns about the incremental nature of the work and question whether the contribution is sufficient. They also point out limitations in the study and suggest areas for improvement. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, framing their criticisms as suggestions or questions rather than direct criticisms. They use phrases like 'I am not sure' and 'It would be more interesting' which maintain a polite tone while still conveying their concerns. The reviewer also begins by summarizing the paper's contributions before moving on to their comments, which is a courteous approach."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges some pros of the paper, such as showing implicit regularization properties beyond the linear case. However, they also point out significant cons, which tempers the positive sentiment. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language without any harsh criticism. They present their concerns as observations ('it was not clear to me') rather than direct criticisms. The reviewer also balances their feedback by mentioning both pros and cons, which contributes to a polite tone."", ""The sentiment score is 60 (positive) because the reviewer expresses enthusiasm and interest in the paper, calling it 'very interesting' and praising its simplicity and insights. However, they also mention some issues that prevent them from giving it a 'very high rating'. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths before offering constructive criticism. They phrase their concerns as questions or suggestions rather than direct criticisms, using phrases like 'Can the authors explain...' and 'It seems pretty necessary...', which maintains a polite tone.""]"
"['The reviewer feels that the paper is hard to follow. The abstract is confusing enough and raises a number of questions.  The paper talks about `""local maxima"" without defining an optimization problem. What is the optimization problem are we talking about? Is it a maximization problem or minimization problem? If we are dealing with a minimization problem, why do we care about maxima?\n\nThe first several paragraphs did not make the problem of interest clearer. But at least the fourth paragraph starts talking about training networks (the reviewer guesses this ""network"" refers to neural network, not other types network (e.g., Bayesian network) arising in machine learning). This paragraph talks about random initialization for minimizing a loss function, does this mean we are considering a minimization problem\'s local maxima? In addition, random initialization-based neural network training algorithms like back propagation cannot guarantee giving local maxima or local minima of the problem of interest (which is the loss function for training). It is even not clear if a stationary point can be achieved. So if the method in this paper wishes to work with local maxima of an optimization problem, this may not be a proper example.\n\nThe next paragraph brings out a notion of value function, which is hard to follow what it is. A suggestion is to give a much more concrete example to enlighten the readers.\n\nThe next two paragraphs seem to be very disconnected. It is not properly defined what is x and how to obtain it. If they are local maxima of a problem, please give us an example: what is the optimization problem, and why this is an interesting setup?\n\nSince the problem setup of this paper is very hard to decode, it is also very hard to appreciate why the papers in the ""related work"" section are really related.\n\nThe motivation and intuition behind the formulations in (1) and (2) are hard to follow, perhaps because the goal and objective of the paper is unclear.\n\nOverall, there is no formal problem definition or statement, and the notions and terminologies in this paper are not properly defined or introduced. This makes evaluating this work very hard.\n\n\n========= after author feedback =======\nAfter discussing with the authors through OpenReview, the reviewer feels that a lot of things have been clarified. The paper is interesting in its setting, and seems to be useful in different applications.  The clarity can still be improved, but this might be more of a style matter.  The analysis part is a bit heavy and overwhelming and not very insightful at this moment. Overall, the reviewer appreciate the effort for improving the readability of the paper and would like to change the recommendation to ````   accept.', 'This paper describes a new form of one-class/set beloning learning, based on definition of 4 player game:\n- Classifier player (c), which is a typical one-class classifier model\n- Comparator player (h), which given two instances answers if first is ""not smaller"" (wrt. set belonging) than the other\n- Classifier adversary player (Gc), which tries to produce hard to distinguish samples for (c)\n- Comparator adversary player (Gh), which tries to produce hard to classify samples for (h)\nThis way authors end up with cooperative-competitive game, where c and h act cooperatively to solve the problem, while Gc and Gh constantly try to ""beat"" them. \n\nOverall I find this paper to be interesting and worth presenting, however I strongly encourage authors to rethink the way story is presented so that it is more approachable by people who do not have much experience with viewing typical classification problems as games. In particular, one could completely avoid talking about ""sets of local maxima"" and just talk about the density estimation problem, with c being characteristic function (of belonging to the support) and h being comparator of the pdf.\n\nStrong points:\n- Novel, multi-agent in nature, approach to one-class classification\n- Proposed method build a complex system, which can be used in much wider class of problems than just classification (due to joint optimisation of classifier and comparator)\n- Extensive evaluation on 4 problems\n- Nice ablation study showing that most of the benefits come from pure c/Gc game (on average 68.8% acc vs 65.2% of just c, and 69.8% of entire system) but that h/Gh players do indeed still improve (an extra 1%). It might be interesting to investigate what exactly changed in c due to existance of h in training. Are there any identifiable properties of the model that can now be analysed?\n\nWeak points:\nIn general I believe that theoretical analysis is the weakest part of the paper, and while interesting - it is actually a minor point, and shows interesting properties, but not the ones that would guarantee anything in ""practical setup"". I would suggest ""downplaying"" this part of the paper, maybe moving most of it to the appendix. \nTo be more specific:\n- Theorem 1 shows that representation can be more compact, however existance of compactness does not rely imply that this particular solution can ever be learned or that it is a good thing (number of parameters is not correlated with generalisation capabilities of the model).\n- Lemma 1 seems a bit redundant for the story. While it is nice to be able to show generalisation bounds in general, this paper is not really introducing new class of models (since in the end c is going to be used for actual classification), but rather training regime, and generalisations bounds do not tell us anything about the emerging dynamical system. The fact that adding v does not constrain c too much seems quite obvious, and as a result I would suggest moving this section to appendix.\nInstead, if possible, the actual tricky mathematical bit for methods like this would be, in reviewers opinion, any analysis of learning dynamics of the system like this. Multi-agent systems cannot be optimised with independent gradient descent in general (convergence guarantees are lost). Consequently many papers focus on methods that bring these properties back (e.g. Consensus Optimisation or Symplectic Gradient Ascent). It would be beneficial for the reader to spend some time discussing stability of the system proposed, even if only empirically and on small problems.\n\nOther remarks:\n- eq. (1) is missing \\cdot\n- it could be useful to include explicit parameters dependences in (1) and (2) so that one sees how losses really define asymmetric game between the players\n- why do we need 4 players and not just 3, with Gc and Gh being a single player/neural network? can we consider this as another ablation?\n- given small performance gaps in Table 1 can we get error estimates/confidence intervals there? Deep SVDD paper includes error estimates of the baseline methods\n- since training is performed in mini batch (it does not have to be decomposible over samples) shouldn\'t equations be based on expectations rather than sums?\n\n- ', 'In this paper, the authors focus on the task of learning the value function and the constraints in unsupervised case. Different from the conventional classification-based approach, the proposed algorithm uses local maxima as an indicator function. The functions c and h and two corresponding generators are trained in an adversarial way. Besides, the authors analyzed that the proposed algorithm is more efficient than the conventional classification-based approach, and a suitable generalization bound is given. Overall, this work is theoretically complete and experimentally sufficient.\n1.\tThe trained c and h give different predictions in most cases. As a unsupervised method, how to deal with them?\n2.\tIn Table3, why can h achieve better results when adding noise?\n']","[-50, 50, 80]","[20, 80, 50]","[""The sentiment score is -50 because the initial review is quite critical, pointing out numerous issues with clarity, definitions, and structure. However, the sentiment improves significantly in the post-feedback section, where the reviewer acknowledges clarifications and expresses a willingness to accept the paper. This positive shift balances out some of the initial negativity. The politeness score is 20 because while the reviewer is direct in their criticisms, they maintain a professional tone throughout. They use phrases like 'hard to follow' and 'suggestion is to' rather than harsh language. The reviewer also shows willingness to change their opinion based on author feedback, which demonstrates respect and openness."", ""The sentiment score is 50 (slightly positive) because the reviewer finds the paper 'interesting and worth presenting', highlighting several strong points. However, they also point out weak areas and suggest significant changes, indicating a mixed but overall positive sentiment. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offering constructive criticism and suggestions. They use phrases like 'I strongly encourage authors to rethink' and 'it would be beneficial' which are polite ways of suggesting improvements. The reviewer also balances critique with praise, acknowledging both strong and weak points of the paper in a professional manner."", ""The sentiment score is 80 (positive) because the reviewer uses phrases like 'theoretically complete and experimentally sufficient' and 'Overall, this work is theoretically complete and experimentally sufficient,' indicating a generally positive view of the paper. The reviewer also acknowledges the paper's contributions and analysis. The politeness score is 50 (slightly polite) because the language is professional and respectful, without being overly formal or effusive. The reviewer provides constructive feedback in the form of questions, which is a polite way to address potential issues. The tone is neutral to slightly positive throughout, maintaining a courteous academic discourse.""]"
"['The paper introduces Neural Logic Machines, a particular way to combine neural networks and first order but finite logic. \n\nThe paper is very well written and structured. However, there are also some downsides.\n\nFirst of all, Section 2.1 is rather simple from a logical perspective and hence it is not clear what this gets a special term. Moreover, why do mix Boolean logic (propostional logic) and first order logic? Any how to you deal with the free variables, i.e., the variables that are not bounded by a quantifier? The semantics you define later actually assumes that all free variables (in your notation) are bounded by all quantifiers since you apply the same rule to all ground instances. Given that you argue that you want a neural extension of symbolic logic (""NLM is a neural realization of (symbolic) logic machines"") this has to be clarified as it would not be an extension otherwise. \n\nFurthermore, Section 2.2 argues that we can use a MLP with a sigmoid output to encode any joint distribution. This should be proven. It particular, given that the input to the network are the marginals of the ground atoms. So this is more like a conditional distribution? Moreover, it is not clear how this is different to other approaches that encode the weight of weighted logical rule (e.g. in a MLN) using neural networks, see\ne.g. \n\nMarco Lippi, Paolo Frasconi:\nPrediction of protein beta-residue contacts by Markov logic networks with grounding-specific weights. \nBioinformatics 25(18): 2326-2333 (2009)\n\nNow of course, and this is the nice part of the present paper, by stacking several of the rules, we could directly specify that we may need a certain number of latent predicates. \nThis is nice but it is not argued that this is highly novel. Consider again the work by Lippi and Frasconi. We unroll a given NN-parameterized MLN for s fixed number of forward chaining steps. This gives us essentially a computational graph that could also be made differentiable and hence we could also have end2end training. The major difference seems to be that now objects are directly attached with vector encodings, which are not present in Lippi and Frasconi\'s approach. This is nice but also follows from Rocktaeschel and Riedel\'s differentiable Prolog work (when combined with Lippi and Frasconi\'s approach).\nMoreover, there have been other combinations of tensors and logic, see e.g. \n\nIvan Donadello, Luciano Serafini, Artur S. d\'Avila Garcez:\nLogic Tensor Networks for Semantic Image Interpretation. \nIJCAI 2017: 1596-1602\n \nHere you can also have vector encodings of constants. This also holds for \n\nRobin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, Luc De Raedt:\nDeepProbLog: Neural Probabilistic Logic Programming. CoRR abs/1805.10872 (2018)\n\nThe authors should really discuss this missing related work. This should also involve\na clarification of the ""ILP systems do not scale"" statement. At least if one views statistical relational learning methods as an extension of ILP, this is not true. Probabilistic ILP aka statistical relational learning has been used to learn models on electronic health records, see e.g., the papers collectively discussed in \n\nSriraam Natarajan, Kristian Kersting, Tushar Khot, Jude W. Shavlik:\nBoosted Statistical Relational Learners - From Benchmarks to Data-Driven Medicine. Springer Briefs in Computer Science, Springer 2014, ISBN 978-3-319-13643-1, pp. 1-68\n\nSo the authors should either discuss SRL and its successes, separating SRL from ILP, or they cannot argue that ILP does not scale. In the related work section, they decided to view both as ILP, and, in turn, the statement that ILP does not scale is not true. Moreover, many of the learning tasks considered have been solved with ILP, too, of course in the ILP setting. Any ILP systems have been shown to scale beyond those toy domains.   \nThis also includes the blocks world. Here relational MDP solvers can deal e.g. with BW worlds composed of 10 blocks, resulting in MDPs with several million states. And the can compute relational policies that solve e.g. the goal on(a,b) for arbitrary number of blocks. This should be incorporated in the discussion of the introduction in order to avoid the wrong impression that existing methods just work for toy examples. \n\nComing back to scaling, the current examples are on rather small datasets, too, namely <12 training instances. Moreover, given that we learn a continuous approximation with a limit depth of reasoning, it is also very likely that the models to not generate well to larger test instances. So the scaling issue has to be qualified to avoid to give the wrong impression that the present paper solves this issue. \n\nFinally, the BW experiments should indicate some more information on the goal configuration. This would help to understand whether an average number of moves of 84 is good or bad. Moreover, some hints about the MDP formulation should be provided, given that there have been relational MDPs that solve many of the probabilistic planning competition tasks. And, given that the conclusions argue that NLMs can learn the ""underlying logical rules"", the learned rules should actually be shown. \n\nNevertheless, the direction is really interesting but there several downsides that have to be addressed. ', 'In this paper the authors propose a neural-symbolic architecture, called Neural Logic Machines (NLMs), that can learn logic rules.\n\nThe paper is pretty clear and well-written and the proposed system is compelling. I have only some small concerns.\nOne issue concerns the learning time. In the experimental phase the authors do not state how long training is for different datasets.\nMoreover it seems that the “rules” learnt by NSMs cannot be expressed in a logical formalism, isn’t it? If I am right, I think this is a major difference between dILP (Evans et. al) and NLMs and the authors should discuss about that. If I am wrong, I think the authors should describe how to extract rules from NLMs.\nIn conclusion I think that, once these little issues are fixed, the paper could be considered for acceptance.\n\n[minor comments]\np. 4\n“tenary” -> “ternary”\n p. 5\n“ov varying size” -> “of varying size”\n“The number of parameters in the block described above is…”. It is not clear to me how the number of parameters is computed.\n“In Eq. equation 4” -> “In Eq. 4”\n\np. 16\n“Each lesson contains the example with same number of objects in our experiments.”. This sentence sounds odd.\n', 'This paper presents a model to combine neural network and logic programming. It proposes to use 3 primitive logic rules to model first-order predicate calculus in the neural networks. Specifically, relations with different numbers of arguments over all permutations of the groups of objects are represented as tensors with corresponding dimensions. In each layer, a MLP (shared among different permutations) is applied to transform the tensor. Multiple layers captures multiple steps of deduction. On several synthetic tasks, the proposed method is shown to outperform the memory network baseline and shows strong generalization.  \n\nThe paper is well written, but some of the contents are still a bit dense, especially for readers who are not familiar with first-order predicate calculus. \n\nThe small Python example in the Appendix helps to clarify the details. It would be good to include the details of the architectures, for example, the number of layers, and the number of hidden sizes in each layer, in the experiment details in the appendix. \n\nThe idea of using the 3 primitive logic rules and applying the same MLP to all the permutations are interesting. However, due to the permutation step, my concern is whether it can scale to real-world problems with a large number of entities and different types of relations, for example, a real-world knowledge graph.\n\nSpecifically:\n\n1. Each step of the reasoning (one layer) is applied to all the permutations for each predicate over each group of objects, which might be prohibitive in real-world scenario. For example, although there are usually only binary relations in real-world KG, the number of entities is usually >10M. \n\n2. Although the inputs or preconditions could be sparse, thus efficient to store and process, the intermediate representations are dense due to the probabilistic view, which makes the (soft) deduction computationally expensive. \n\nSome clarification questions: \n\nIs there some references for the Remark on page 3? \n\nWhy is there a permutation before MLP? I thought the [m, m-1, …, m-n+1] dimensions represent the permutations. For example, if there are two objects, {x1, x2}. Then the [0, 1, 0] represents the first predicate applied on x1, and x2. [1, 0, 0] represents the first predicate applied on x2 and x1. Some clarifications would definitely help here. \n\nI think this paper presents an interesting approach to model FOPC in neural networks. So I support the acceptance of the paper. However, I am concerned with its scalability beyond the toy datasets. \n']","[-20, 50, 50]","[50, 80, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The paper is very well written and structured', 'This is nice'), they raise several significant concerns and criticisms throughout the review. These include issues with the logical framework, lack of novelty, missing related work, and potential scalability problems. The overall tone suggests the paper needs substantial revisions. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges positive aspects, and frames criticisms constructively ('The authors should really discuss...', 'This should be incorporated...'). The reviewer maintains a professional tone even when pointing out flaws, avoiding harsh or personal criticism."", ""The sentiment score is 50 (slightly positive) because the reviewer states the paper is 'pretty clear and well-written' and the system is 'compelling'. They also suggest the paper could be considered for acceptance after addressing 'little issues'. However, they do raise some concerns, which prevents a higher positive score. The politeness score is 80 (quite polite) due to the use of respectful language throughout. The reviewer frames their concerns as questions or suggestions rather than criticisms, uses phrases like 'I think' to soften their statements, and provides constructive feedback. They also acknowledge the paper's strengths before mentioning areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses support for the paper's acceptance and finds the approach interesting, but also raises concerns about scalability and requests clarifications. The overall tone is constructive and balanced. The politeness score is 80 (quite polite) due to the respectful language used throughout. The reviewer acknowledges the paper's strengths, offers suggestions for improvement, and frames criticisms as concerns rather than harsh judgments. The use of phrases like 'It would be good to...' and 'Some clarification questions:' contribute to the polite tone. The reviewer also ends on a positive note, supporting acceptance while expressing concerns, which maintains a courteous approach.""]"
"['imho, this manuscript is clearly written, addresses a confusing point in the current literature, clarifies some issues, and provides a novel and useful approach to mitigate those issues. \nreading the other comments online, the authors seem to have addressed those concerns as well.', ""Summary: \nThe paper proposes a regualrization scheme to protect quantized neural networks from adversarial attacks. The authors observe that quantized models become less robust to adversarial attacks if the quantization includes the inner layers of the network. They propose a Lipschitz constant filtering of the inner layers' input-output to fix the issue.  \n\nStrengths:\nThe key empirical observation that fully quantized models are more exposed to adversarial attacks is remarkable in itself and the explanation given by the authors is reasonable. The paper shows how a simple regularization scheme may become highly effective when it is supported by a good understanding of the underlying process.\n\nWeaknesses:\nExcept for observing the empirical weakness of fully quantized models, the technical contribution of the paper seems to be limited to combining the Lipschitz-based regularization and quantization. Has the Lipschitz technique already been proposed and analysed elsewhere? If not, the quality of the paper would be improved by investigating a bit more the effects of the regularization from an empirical and theoretical perspective. If yes, are there substantial differences between applying the scheme to quantized models and using it on full-precision networks? It looks like the description of the Lipschitz method in Section 4 is restricted to linear layers and it is not clear if training is feasible/efficient in the general case.\n \nQuestions:\n- has the Lipschitz technique been proposed and analysed elsewhere? Is the robustness of full-precision models under adversarial attacks also improved by Lipschitz regularization?\n- how popular is the practice of quantizing inner layers? Has the performance of fully quantized models ever been compared to full-precision or partially quantized models in an extensive way (beyond adversarial attack robustness)? \n- are the adversarial attacks computed using the full-precision or the quantized models? would this make any difference?\n- the description of the Lipschitz regularization given in Section 4 assumes the layers to be linear. Does the same approach apply to non-linear layers? Would the training be feasible in this case? "", 'Summary of paper\nThis paper presents an approach  for quantising neural networks such that the resulting quantised model is robust to adversarial and random perturbations.\nThe core idea of the paper is to enforce the Lipschitz constant of each linear layer of the network approximately close to 1. Since the Lipschitz constant of the neural network is bounded by the product of the\nLipschitz constant of its linear layer (assuming Lipschitz 1 activation functions) the Lipschitz constant of the trained neural network is bounded by 1. This results in a model which is robust to adversarial and random noise ad all directions in the model space are non-expansive. Algorithmically, controlling the Lipschitz constant is achieved by using the orthogonal regulariser presented in the paper Cisse et.al which has the same motivation for this work but for standard neural network training but not quantising. The authors presents thorough experimental study showing why standard quantisation schemes are prone to adversarial noise and demonstrate clearly how this approach improves robustness of quantised network and sometimes even improve over the accuracy of original model. \n\nReview:\nThe paper is well written with clear motivation and very easy to follow. \nThe core idea of using orthogonal regulariser for improving the robustness of neural network models have been presented in Cisse et.al and the authors re-use it for improving the robustness of quantised models. The main contribution of this work is in identifying that the standard quantised models are very vulnerable to adversarial noise which is illustrated through experiments and then empirically showing that the regulariser presented in Cisse et. al improves the robustness of quantised models with rigorous experiments. The paper add value to the research community through thorough experimental study as well as in industry since quantised models are widely used and the presented model is simple and easy to use. \n\nSome suggestions and ideas:\n\n1. It will be great if the authors could add a simple analytical explanation why the quantised networks are not robust.                      \n\n2. The manifold of Orthogonal matrices does not include all 1 - Lipschitz matrices and also the Orthogonal set is not convex. I think a better strategy for this problem is to regularise the spectral norm to be 1.  Regularising the spectral norm is computationally cheaper than Orthogonal regulariser when combined with SGD using power iterations.  Moreover the regulariser part of the model becomes nice and convex.\n\n3. Another strategy to control the Lipschitz constant of the network is to directly penalise the norm of the Jacobian as explained in Improved Training of Wasserstein GANs (Gulrajani et. al).\n']","[90, 50, 80]","[70, 75, 90]","[""The sentiment score is 90 (highly positive) because the reviewer uses phrases like 'clearly written', 'clarifies some issues', and 'provides a novel and useful approach', indicating strong approval of the manuscript. The politeness score is 70 (quite polite) as the reviewer uses respectful language and acknowledges the authors' efforts to address other concerns. The phrase 'imho' (in my humble opinion) adds a touch of humility. The review is constructive and focuses on the manuscript's strengths without using overly effusive language, maintaining a professional tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths, particularly the 'remarkable' key observation and the effectiveness of the proposed regularization scheme. However, they also point out weaknesses and raise several questions, indicating a balanced view. The politeness score is 75 (quite polite) as the reviewer uses respectful language throughout, framing criticisms as suggestions for improvement and asking questions rather than making harsh statements. They use phrases like 'the quality of the paper would be improved' and 'it looks like,' which soften potential criticisms. The review maintains a professional and constructive tone throughout."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, describing it as 'well written with clear motivation and very easy to follow.' They also highlight the paper's value to both the research community and industry. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer offers praise before providing suggestions, uses phrases like 'It will be great if...' and 'I think,' which are polite ways of offering ideas. The suggestions are framed as possibilities rather than demands, further contributing to the polite tone. The review maintains a professional and courteous language throughout, without any harsh criticism or rude remarks.""]"
"['Summary:\n\nThis paper introduces a new supervised dimensionality reduction model. Supervision is provided in the form of class probabilities and the learning algorithm learns low-dimensional representations such that posterior cluster assignment probabilities given the representations match the observed class probabilities. The representations can be learned directly or the parameters of a neural network can be learned which maps inputs to the lower-dimensional space. The authors provide an extensive theoretical analysis of the proposed method and evaluate it on dimensionality reduction, visualization, and zero-shot learning tasks.\n\nReview:\n\nOverall, I thought this was an excellent paper. The idea is well-motivated, the presentation is clear, and the evaluations are both comprehensive and provide insight into the behavior of the proposed methods (I will not comment on the theoretical analysis, as it is entirely contained in the supplemental materials). I was honestly impressed by the shear volume of content in this paper, particularly since I found none of it to be superfluous. Frankly, this paper might be better served as two papers or a longer journal paper, but that is hardly a reason not to accept it. I strongly recommend acceptance and have only a couple of comments on presentation.\n\nComments:\n\n- When trying to understand the proposed method, I found it useful to expand out the full objective function and derive the gradients w.r.t. to f_i. If my maths were correct, the gradient of the objective w.r.t. f_i can be written as the difference between the expected gradient of the divergence w.r.t Y and the expected gradient of the divergence w.r.t. the posterior cluster assignment probabilities. Though not surprising in and of itself, the authors might consider including this equation as it really helped me understand what the learning algorithm was doing. \n\n- The authors might consider adding a more complete description of the zero-shot learning task. My understanding of the task was that there are text descriptions of each category and at test time new text descriptions are added that were not in the training set. The goal is to map an unseen image to a class based on the text descriptions of the classes. A couple of sentences explaining this in the first paragraph of section 4.2 would help those who are not familiar with this zero-shot learning setup.', ""Authors propose a method of embedding training data examples into low-dimensional spaces such that mixture probabilities from a mixture model on these points are close to probability predictions from the original model in terms of KL divergence. Authors suggest two use-cases of such an approach: 1) data visualization, and 2) zero-shot learning. For the visualization use-case, authors compare against other dimensionality reduction methods with qualitative analysis on a synthetic problem, as well as evaluation metrics such as Neighborhood-Preservation Ratio and Clustering Distance Preservation Ratio. For zero-shot use-case, they take pre-trained models on two zero-shot tasks, and improve the accuracy by using probability outputs from pre-trained models as target.\n\nRegarding the benefit of using the proposed method for visualization, the DRPR is making a strong assumption that representations of data points that belong to the same class form a uni-modal, Gaussian distribution (since authors don't experiment with distance functions other than L2). This inductive bias comes with a strong benefit when the assumption is true - as demonstrated in the toy dataset experiment - but when it is not true, the visualization would strongly distort the underlying structure of the model. And I don't believe this is a realistic assumption, because there has to be a reason that most deep-learning based classification models in the literature don't always use a model like (3) or Prototypical Networks instead of typical fully-connected + softmax layer, unless the data size is small and we need stronger inductive bias to improve the performance of the model.  That is, we usually don't think unimodality is the right assumption, even with learned representations. I suspect that the while DRPR might be good at visualizing relationships between class labels - especially which class can be easily confused with another - but would be worse at faithfully representing each data point, especially the ambiguity of class labels on individual ones. I would argue, however, that faithful representation of each data point is more important for scatter plots than relationship between classes, because the latter can be more effectively analyzed with other methods such as confusion matrices. As it is typical in most dimensionality reduction papers, I would encourage authors to consider more types of synthetic datasets which nonlinearity and multimodality are critical to be learned. I don't believe quantitative evaluation in Table 1 and 2 are very meaningful, because DRPR's objective function is much better aligned with these metrics than others. \n\nZero-shot experiments show a promising lift over the baseline pre-trained models. The kind of bias we should be careful about, however, is that when we distillate one model into another, the performance generally improves even when the same exact model is both the teacher and the student: (Furlanello et al, ICML 2018 https://arxiv.org/abs/1805.04770 ). Therefore, it would be interesting to compare against distillation with baseline models themselves.\n\nPros:\n* Extensive theoretical and empirical analysis\n* Simple idea that generalizes to multiple use-cases, which implies robustness of the approach as a methodology\n\nCons:\n* Unimodal assumption is likely not realistic, which would result in misleading visualization of data\n* Visualization analysis focuses on how class-relationships are preserved rather than faithful representation of each data point, which is a wrong target\n* Synthetic experiment is conducted on a single, too simplistic one; more examples are needed to understand the capabilities of the model in more detail\n* The bias of knowledge distillation is not controlled"", 'The paper deals with a problem formulation adjacent to that of the sufficient dimension reduction: given training set of pairs (x_i,y_i), how to reduce the dimension of the first element, i.e. map x_i --> f(x_i), so that f(x_i)\'s still have all the information to recover y_i\'s.\n\nIn the paper, the output y_i is a probability distribution over k labels that softly describes inclusion of example i into k classes.\n\nThey consider a nonlinear case, i.e. the mapping f is taken from a prespecified set of mappings, parameterized by Theta (e.g. neural network). Then by ""recovering y_i"" they mean that EM algorithm for {f(x_i)} will result in a clustering of the data into k soft clusters similar to given {y_i}.\n\nThe algorithm that is presented is quite natural, though no guarantees that it will converge to something relevant were given. Theoretical analysis deals with a question --- how far the empirical discrepancy could be from the true expected one. Especially, easiness of substitution of \\bar{Y}_{ic} with Y_{ic} in the algorithm is unclear (roughly speaking, the latter means that E-step is omitted in EM). If matrix Y in algorithm is fixed, why we need to compute \\pi in the loop? Isn\'t it going to be the same? Does this algorithm really minimizes the discrepancy?']","[90, -20, -20]","[80, 60, 0]","[""The sentiment score is 90 because the reviewer expresses strong positive sentiment, using phrases like 'excellent paper', 'well-motivated', 'clear presentation', 'comprehensive evaluations', and 'strongly recommend acceptance'. The only slight criticism is about the paper's length, but it's framed positively. The politeness score is 80 because the reviewer uses respectful and professional language throughout, offering constructive suggestions rather than criticisms. Phrases like 'I thought', 'I was honestly impressed', and 'The authors might consider' indicate a polite and considerate tone. The reviewer also acknowledges their own limitations ('I will not comment on the theoretical analysis'), which adds to the politeness."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros ('Extensive theoretical and empirical analysis', 'Simple idea that generalizes to multiple use-cases'), they express significant concerns about the methodology and assumptions. The cons outweigh the pros, and the reviewer suggests several improvements and additional experiments. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout. They offer constructive criticism and suggestions rather than harsh judgments, and use phrases like 'I would encourage authors to consider' and 'it would be interesting to compare' which maintain a collegial tone. The reviewer also balances critique with acknowledgment of the paper's strengths."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's topic and approach, they express several concerns and uncertainties about the method's effectiveness and theoretical foundations. The reviewer points out lack of guarantees, unclear aspects of the algorithm, and questions its ability to minimize discrepancy. These critiques suggest a somewhat skeptical view of the paper's contributions.\n\nThe politeness score is neutral (0) as the reviewer maintains a professional and objective tone throughout. They neither use overly polite language nor any rude or dismissive expressions. The review focuses on technical aspects and questions without personal comments or strong emotional language. The reviewer presents their observations and concerns in a straightforward, matter-of-fact manner typical of academic peer reviews.""]"
"['This work adds to a growing literature on biologically plausible (BP) learning algorithms. Building off a study by Bartunov et al. that shows the deficiencies of some BP algorithms when scaled to difficult datasets, the authors evaluate a different algorithm, sign-symmetry, and conclude that there are indeed situations in which BP algorithms can scale. This seemingly runs counter to the conclusions of Bartunov et al.; while the authors state that their results are ""complementary"", they also state that the findings “directly conflict” with the results of Bartunov, concluding that BP algorithms remain viable options for both learning in artificial networks and the brain.\n\nTo reach these conclusions the authors report results on a number of experiments. First, they show successful training of a ResNet-18 architecture on ImageNet using sign-symmetry, with their model performing nearly as well as one trained with backpropagation. Next, they demonstrate decent performance on MS COCO object detection using RetinaNet. Finally, they end with a discussion that seeks to explain the differences in their approach and the approach of Batunov et al, and with a potential biological implementation of sign symmetry.\n\nOverall the clarity of the writing is sufficient. The algorithm is properly explained, and there are sufficient citations to reference prior work. The results are generally clear (though there is an incomplete experiment, I agree with the authors that it is unlikely for the preliminary results to change). I believe that there is enough detail for this work to be reproducible. The work is also sufficiently novel in that experiments using sign-symmetry on difficult datasets have not been undertaken, to my knowledge.\n\nUnfortunately, the clarity and rigor of the *scientific argument* is insufficient for a number of reasons. These will be enumerated below.\n\nFirst, the explicit writing and underlying tone of the paper reveal a misrepresentation of the scientific argument in Bartunov et al. The scientific question in Bartunov et al. is not a matter of whether BP algorithms can be useful in purely artificial settings, but rather whether they can say anything about the way in which the brain learns. In this work, on the other hand, there seems to be two scientific questions: first, to assess whether BP algorithms can be useful in artificial settings, and second, to determine whether they can say anything about how the brain learns, as in Bartunov (indeed, the author’s conclusions highlight precisely these two points). Unfortunately, the experiments and underlying experimental logic push towards addressing the first question, and use this as evidence towards a conclusion to the second question. More concretely, experiments are run on biologically problematic architectures such as ResNet-18, often with backpropagation in the final layer (though admittedly this doesn’t seem to be an important detail with sign-symmetry, for reasons explained below). This is fine under the pretense of answering the first question, but to seriously engage with the results of Bartunov et al. and assess sign-symmetry’s merit as a BP algorithm for learning in the brain, the work requires the authors the algorithms to be tested under similar conditions before claiming that there is a “direct conflict”. To this end, though the authors claim that the conditions on which Bartunov et al tested are “somewhat restrictive”, this logic can equally be flipped on its head: the conditions under which this paper tests sign-symmetry are not restrictive enough to productively move in the direction of assessing sign-symmetry’s usefulness as a description of learning in the brain, and so the conclusion that the algorithm remains a viable option for describing learning in the brain is not sufficiently supported. On the other hand, I think the conclusions regarding the first question -- whether sign-symmetry can be useful in artificial settings -- are fine given the experiments.\n\nSecond, the work does not sufficiently weigh the “degree” of implausibility of sign-symmetry compared to the other algorithms, and implicitly speaks of feedback alignment, target propagation, and sign-symmetry as equally realistic members of a class of BP algorithms. Of course, one doesn’t want to go down the road of declaring that “algorithm A is more plausible than algorithm B!”, but the nuances should at least be seriously discussed if the algorithms are to be properly compared. In backpropagation the feedback connections must be similar in sign and magnitude. Sign-symmetry eliminates the requirement that the connections be similar in magnitude. However, this factor is arguably the least important of the two (the direction of the gradient is more important than the magnitudes), and we are still left with feedback weights that somehow have to tie their sign to their feedforward counterparts, which is not an issue in target propagation or feedback alignment. The authors try to explain away this difficulty with an appeal to molecular biology, which leads into my third point.\n\nThird, the appeal to molecular mechanisms to explain how sign-symmetry can arise is not rigorous. There is a plethora of molecular mechanisms at play in our cells; indeed, there are enough mechanisms to hand-craft *any* sort of circuit one likes. Thus, it is somewhat vacuous to conclude that a particular circuit can be “easily implemented” in the brain simply by appealing to a hand-crafted circuit. For this argument to hold one needs to appeal to biological data to demonstrate that such a circuit either a) exists already, b) most probably exists because of reasons X, Y, Z. Unfortunately there is no biological backing, rendering this argument a possibly fun thinking exercise, but not a serious scientific proposal. But perhaps most problematic, the argument leaves the problem of sign-switching in the feedforward network to “future work”. This is perhaps *the most* important problem at play here, and until it is answered, these arguments don’t have sufficient impact.\n\nAltogether the scientific argument of this work needs tightening. The tone, the title, and the overall writing should be modified to better tackle the nuances underlying the arguments of biologically plausible learning algorithms. The claims and conclusions need to be more explicit, and the work needs to better seated in the context of both the previous literature, and the important questions at play for assessing biologically plausible learning algorithms.\n', 'In the submitted manuscript, the authors compare the performance of sign-symmetry and feedback alignment on ImageNet and MS COCO datasets using different network architectures, with the aim of testing biologically-plausible learning algorithms alternative to the more artificial backpropagation.\nThe obtained results are promising and quite different to those in (Bartunov , 2018) and lead to the conclusion that biologically plausible learning algorithms in general and sign- symmetry in particular are effective alternatives for ANN training.\n\nAlthough all the included ideas are not fully novel, the manuscript shows a relevant originality, paving the way for what can be a major breakthrough in deep learning theory and practice in the next few years. The paper is well written and organised, with the tackled problem well framed into the context. The suite of experiments is broad and diverse and overall convincing, even if the performances are not striking. Very interesting the biological interpretation and the proposal for the construction in the brain.\nA couple of remarks: I would be interested in understanding the robustness of the sign-symmetry algorithm w.r.t. for instance dropout and (mini)batch size, and to see the behaviour of the algorithm on datasets with small sample size; second, there is probably too much stress on comparing w/ (Bartunov , 2018), while the manuscript is robust enough not to need such motivation.\n\nMinor: refs are not homogeneous, first names citations are not consistent.', 'Summary: The authors are interested in whether particular biologically plausible learning algorithms scale to large problems (object recognition and detection using ImageNet and MS COCO, respectively). In particular, they examine two methods for breaking the weight symmetry required in backpropagation: feedback alignment and sign-symmetry. They extend results of Bartunov et al 2018 (which found that feedback alignment fails on particular architectures on ImageNet), demonstrating that sign-symmetry performs much better, and that preserving error signal in the final layer (but using FA or SS for the rest) also improves performance.\n\nThe paper is clear, well motivated, and significant in that it advances our understanding of how recently proposed biologically plausible methods for getting around the weight symmetry problem work on large datasets.\n\nIn particular, I appreciated: the clear introduction and explanation of the weight symmetry problem and how it arises in the context of backprop, the thorough experiments on two large scale problems, the clarity of the presented results, and the discussion about future directions of study.\n\nMinor comments:\n- s/there/therefore in the first paragraph on page 2\n- The authors claim that their conclusions ""largely disagree with results from Bartunov et al 2018"". I would suggest a slight rewording here: the authors\' results *extend* our understanding of Bartunov et al 2018. They do not disagree in the sense that this paper also finds that feedback alignment alone is insufficient to train large models on ImageNet.\n- Figure 1: I was expecting to see a curve for performance of feedback alignment on AlexNet\n- Figure 1: The colors are hard to follow. For example, the two shades of purple represent the two FA models, which makes sense, but then there are two separate hues (black and blue) for the sign-symmetry models. Instead, I would suggest keeping black (or gray) for backpropagation (the baseline), and then using two hues of one color (e.g. light blue and dark blue) for the two sign-symmetry models. This would make it easier to group the related models.\n- Figure 2: Would be nice if these colors (for backprop/FA/SS) matched the colors in Figure 1.\n- Figure 3: Why is there such a small change in the average alignment angle (2 degrees?) I found that surprising.\n- Figure 3: The right two panels would be clearer on the same panel. That is, instead of showing the std. dev. separately, show it as the spread (using error bars) on the plot with the mean. This makes it easier to get a sense if the distributions overlap or not.\n- Figure 3 (b/c): Could also use the same colors for BP/SS as Figs 1 and 2.\n- Figure 3 (caption): I think the blue/red labels in the caption are mixed up for panel (a).']","[-50, 80, 80]","[50, 70, 70]","[""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper (e.g., clarity of writing, sufficient citations, novelty), they express significant concerns about the scientific argument and methodology. The review is predominantly critical, pointing out several major issues with the paper's approach and conclusions. The politeness score is 50 because the reviewer maintains a professional and respectful tone throughout, using phrases like 'Unfortunately' and 'I believe' to soften criticisms. They also acknowledge positive aspects before delving into critiques. The language is not overly formal or polite, but it avoids rudeness or harsh language, striking a balance between constructive criticism and courtesy."", ""The sentiment score is 80 (positive) because the reviewer expresses that the results are 'promising', the manuscript shows 'relevant originality', and it could lead to a 'major breakthrough'. The reviewer also praises the paper as 'well written and organised' and the experiments as 'broad and diverse and overall convincing'. The politeness score is 70 (polite) due to the use of respectful and constructive language throughout. The reviewer offers praise and constructive feedback without harsh criticism. They use phrases like 'I would be interested in understanding' and 'there is probably too much stress on', which are polite ways of suggesting improvements. The minor criticisms are presented gently and balanced with positive comments."", ""The sentiment score is 80 (positive) because the reviewer expresses clear appreciation for the paper, describing it as 'clear, well motivated, and significant'. They highlight several positive aspects, including the clear introduction, thorough experiments, and clarity of results. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticisms. They use phrases like 'I appreciated' and 'I would suggest', which are polite ways of giving feedback. The minor comments are presented as suggestions for improvement rather than demands. The overall tone is professional and supportive, though not excessively formal or deferential, hence the score of 70 rather than higher.""]"
"['# Summary\n\nThe paper proposes training generative models that produce multi-agent trajectories using heuristic functions that label variables that would otherwise be latent in training data. The generative models are hierarchical, and these latent variables correspond to higher level goals in agent behavior. The paper focuses on basketball offenses as a motivating scenario in which multiple agents have coordinated high-level behavior. The generative models are RNNs where each output is fed into the decoder of a variational autoencoder to produce observed states. The authors add an intermediate layer to capture the latent variables, called macro-intents. The parameters are learned by maximizing an evidence lower bound.\n\nExperiments qualitatively and quantitatively show that the hierarchical model produces realistic multi-agent traces.\n\n# Comments\n\nThe paper presents a sensible solution for heuristically labeling latent variables. It is not particularly surprising that the model then learns useful behavior because it no longer has to maximize the marginal likelihood over all possible macro-intents. What is more interesting is that a heuristic labeling function is sufficient to label macro-intents that lead to learning realistic basketball offenses and swarm behavior.\n\nAre any of the baselines (VRNN-single, VRNN-indep, and VRNN-mi) equivalent to training the hierarchical model by maximizing an ELBO on the marginal likelihood? I do not think this comparison is done, which might be interesting to quantify how much of a difference heuristic labeling makes. Of course, the potentially poor fit of a variational distribution would confound the results.\n\n# Minor things\n\n1) In the caption of Table 1, it says ""Our hierarchical model achieves higher log-likelihoods than baselines for both datasets."" Are not the reported scores evidence lower-bounds? So it achieves a higher evidence lower bound, but without actually computing the true likelihood, could not the other models have higher likelihoods?\n\n2) Under ""Human preference study"" it says ""All judges preferred our model over the baselines with 98% statistical significance."" I am not familiar with this terminology. Does that mean that a p value for some null hypothesis is .02?\n\n3) Something is wrong with the citation commands. Perhaps \\citep should be used.', '\nThis paper proposes training multiple generative models that share a common latent variable, which is learned in a weakly supervised fashion, to achieve high level coordination between multiple agents. Each agent has a separate VRNN model which is conditioned on the agent’s own trajectory history as well as the shared latent variable. The model is trained to maximize the ELBO objective and log-likelihood over macro-intent labels. Experimental results are conducted over a basketball gameplay dataset (to model the trajectories of the offensive team members) and a synthetic dataset. The results show that the proposed model is on-par with the baseline models in terms of ELBO while showing that it can model multi-modality better and is preferred more by humans. \n\nIn general, the paper is well written and the overall framework captures the essence of the problem that the authors are trying to solve.\nFurthermore, incorporating an auxiliary latent variable to model the coordination between multiple agents is interesting.\nI have several comments related to the strength of the baselines and contribution of individual components in the proposed model.\n\n\nMajor Comments\n\n- It seems that VRNN-single and VRNN-indep are two models on the far two ends of a spectrum. To understand the contribution of the shared macro-intent, how would an intermediate baseline model where a set of parameters are shared between agents and each agent also has an independent set of parameters perform? This could be accomplished by sharing the parameters of the first layer of GRU networks and learning the second layer parameters independently.\n\n- How is the threshold for macro-intent generation selected? How does this parameter affect the overall performance? Since the smoothness of the segments between two macro-intents depend on this parameter, I am wondering its effect on the learned posterior distribution.\n\n- Rather than using the prediction of the macro-intent RNN as a single global vector (\\hat{g}_t), could using separate vectors for each agent (corresponding blocks of \\hat{g}_t) as inputs to VRNN give the same results? Since the macro-intent RNN is already aware of all the macro-intents, it would be interesting to see if individual macro-intents are sufficient for VRNN to generate corresponding trajectories.\n\n\nMinor Comments\n\n- Do results in Table (1) come from sampling or using mode of the distributions? How peaked are the learned posterior distributions?\n- What is the performance of the macro-intent RNN model?\n- In Eq (2), “<=T” should be “<=t” (as in Eq (11) in Chung 2015).\n- In Page 6, bullet point 4: it should be “except we maximize the mutual information…”\n', 'Very strong paper, building on top of variational RNNs for multi-agent sequential generation. Dialogue use case is mentioned in Discussion is indeed very exciting. The approach extends VRNN to a hierarchical setup with high level coordination via a shared learned latent variable. The evaluations are not very strong due to toy task setup, however the approach is clear and impactful.']","[50, 50, 80]","[70, 80, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper presents a 'sensible solution' and finds aspects 'interesting', while also raising some questions and pointing out minor issues. This indicates a generally positive but balanced view. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, frames criticisms constructively (e.g. 'might be interesting to...'), and includes positive feedback. The tone is professional and courteous, avoiding harsh or dismissive language."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by acknowledging the paper is 'well written' and the framework 'captures the essence of the problem'. They also describe the approach as 'interesting'. However, they follow this with 'several comments' and 'major comments', indicating some significant concerns, which prevents a higher positive score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, such as 'I have several comments' and 'It would be interesting to see', rather than making blunt criticisms. They also phrase their suggestions as questions or possibilities, which is a polite way of offering critique. The reviewer maintains a professional and constructive tone throughout, even when pointing out errors or suggesting improvements."", ""The sentiment score is 80 (positive) because the review starts with 'Very strong paper' and uses positive phrases like 'exciting', 'clear and impactful'. The reviewer praises the approach and its potential applications. The score is not 100 due to the mention of weak evaluations. The politeness score is 50 (somewhat polite) as the language is professional and respectful, without being overly formal or effusive. The reviewer provides a balanced perspective, acknowledging both strengths and limitations without harsh criticism.""]"
"['This paper proposes a GCN variant that addresses a limitation of the original model, where embedding is propagated in only a few hops. The architectural difference may be explained in the following: GCN interleaves the individual node feature transformation and the single-hop propagation, whereas the proposed architecture first transforms the node features, followed by a propagation with an (in)finite number of hops. The propagation in the proposed method follows personalized PageRank, where in addition to following direct links, there is a nonzero probably jumping to a target node.\n\nI find the idea interesting. The experiments are comprehensive, covering important points including data split, training set size, number of hops, teleport probability, and ablation study. Two interesting take-home messages are that (1) GCN-like propagation without teleportation leads to degrading performance as the number of hops increases, whereas propagation with teleportation leads to converging performance; and (2) the best-performing teleport probability generally falls within a narrow range.\n\nQuestion: The current propagation approach uses the normalized adjacency matrix proposed by GCN, which is, strictly speaking, not the transition matrix used by PageRank. What prevents from using the transition matrix? Note that this matrix naturally handles directed graphs.\n', 'This paper proposed a variant of graph neural network, which added additional pagerank-like propagations (with constant aggregation weights), in additional to the normal message-passing like propagation layers. Experiments on some benchmark transductive node classification tasks show some empirical gains.\n\nUsing more propagations with constant aggregation weights is an interesting idea to help propagate the information in a graph. However, this idea is not completely new. In the very first graph neural network [1], the propagation is done until convergence. If the operator in each layer is a contraction map, then according to the Banach Fixed Point theorem [2], a unique solution can be guaranteed. The constant operator used in this paper is thus a special case of this contraction map.\n\nAlso, the closed form solution in (3) is not practical. It may not be suitable for large graphs (e.g., graphs with >10k nodes). And that’s why this approach is not suitable for Pubmed and Microsoft dataset. The PEP_A is more practical. However, in this case I’m curious how it would compare with a GNN having same number of layers, but with proper gating/skip connections like ResNet. \n\nThe experiments show some marginal gains on the small graphs. However, I think it would be important to test on large graphs. Since small graphs typically have small diameter, thus several GNN layers would already cover the entire graph, and the additional propagation done by pagerank here might not be super helpful. \n\nFinally, I think the author should properly cite another relevant paper [3], which uses fixed point iteration to help propagate the local information. \n\n[1] Scarselli et.al, “The Graph Neural Network Model”, IEEE Transactions on Neural Networks, 2009\n[2] Mohamed A. Khamsi, An Introduction to Metric Spaces and Fixed Point Theory\n[3] Dai et.al, Learning Steady-States of Iterative Algorithms over Graphs, ICML 2018', 'The thurst behind this paper is that graph convolutional networks (GCNs) are constrained by construction\nto focus on small neighborhoods around any given node. Large neighborhoods introduce in principle\na large number of parameters (while as the authors point out, weight sharing is an option to avoid this issue), \nplus even worse oversmoothing may occur. Specifically, Xu et al. (2018) showed that for a k-layer GCN one can \nthink of the influence score of a node x on node y as the probability  that a walker that starts at x, \nlands on y after k steps of random walk (modulo some details). \n\nTherefore, as k increases the random walks reaches its stationary distribution, forgetting any local information that is useful, \ne.g., for node classification. To avoid this problem, the authors propose the following: use personalized Pagerank\ninstead of the standard Markov chain of Pagerank. In PPR there is a restart probability, which allows \ntheir algorithm to avoid “forgetting” the local information around a walk, thus allowing for an arbitrary \nnumber of steps in their random walk. The authors define two methods PEP, and PEPa based on PPR. The latter \nmethod is faster in practice since it approximates the PPR.   \n\nA key advantage of the proposed method is the separation of the node embedding part from the propagation scheme. In this sense, \nfollowing the categorization of existing methods into three categories, PEP is a hybrid of message passing algorithms,\nand random walk based node embeddings. The experimental evaluation tests certain basic properties of the proposed method. One interesting performance feature of \nPEP and PEPa is that they can perform well using few training examples. This is valuable especially when obtaining labeled\nexamples is expensive.  Finally, the authors compare their proposed methods against state-of-the-art GCN-based methods.  \n\nSome remarks follow. \n\n- The idea of using PPR for node embeddings has been suggested in recent prior work “LASAGNE: Locality and structure aware graph node embeddings” \nBy Faerman et al.  While according to the authors’ categorization of the existing methods in the intro, LASAGNE \nfalls under the “random walk” family  of methods, the authors should compare against it. \n \n- Continuing the previous point,  even simpler baselines would be desirable. How inferior is for instance \nan approach on one-vs-all classification using the approximate personalized Pagerank node embedding and \nsupport vector machines?  \n \n- Also, the authors mention “since our datasets are somewhat similar…”. Please clarify with respect to \nwhich aspects? Also, please use datasets that are different. For instance, see the LASAGNE paper for \nmore datasets that have different number of classes.  \n\n- In the experiments the authors use two layers for fair comparison. Given that one of the advantages of the \nproposed method is the  ability to have more layers without suffering from the GCN shortcomings \nwith large neighborhood exploration, it would be interesting to see an experiment where the number of layers is a variable. \n\n']","[80, -20, 50]","[70, 60, 75]","[""The sentiment score is 80 (positive) because the reviewer finds the idea interesting and praises the comprehensive experiments. They highlight two 'interesting take-home messages', indicating a positive view of the paper's contributions. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths and posing a question in a constructive manner. The reviewer doesn't use overly formal or effusive language, which prevents a higher politeness score. The overall tone is professional and supportive, without being excessively deferential."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some interesting aspects of the paper, they raise several critical points and limitations. They mention that the idea is not completely new, question the practicality of the approach for large graphs, and suggest that the gains shown are only marginal. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's contributions, and frames criticisms as suggestions or areas for improvement rather than direct attacks. They use phrases like 'I'm curious' and 'I think it would be important' which maintain a constructive tone. The reviewer also provides helpful references and suggestions for improvement, which contributes to the polite and professional tone of the review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and potential advantages, such as the ability to avoid 'forgetting' local information and perform well with few training examples. However, they also provide several suggestions for improvement, indicating a balanced view. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'Some remarks follow'), and offers specific suggestions for improvement rather than harsh criticism. The use of phrases like 'please clarify' and 'it would be interesting to see' further contribute to the polite tone.""]"
"['The submission presents a reinforcement learning method for exploring/probing the environment to determine an environment’s properties and exploit these during later tasks. The method relies on jointly learning an embedding that simplifies prediction of future states and a policy that maximises a curiosity/intrinsic motivation like reward to learn to explore areas where the prediction model underperforms. In particular, the reward is based on the difference between prediction based on the learned embedding and prediction based on a prior collected dataset, such that the reward optimises to collect data with a large difference between the prediction accuracy of both models. The subsequently frozen policy and embedding are then used in other domains in a system identification like manner with the embedding utilised as input for a final task policy. The method is evaluated on a striker and hopper environment with varying dynamics parameters and shown to outperform a broad set of baselines. \n\nIn particular the broad set of baselines and small performed ablation study on the proposed method are quite interesting and beneficial for understanding the approach. However, the ablation study could be in more detail with respect to the additional training variations (Section 4.1.3; e.g. without all training tricks). Additionally, information about the baselines should be extended in the appendix as e.g. different capacities alone could have an impact where the performances of diff. algorithms are comparably similar. In particular, additional information about the training procedure for the UP-OSI (Yu et al 2017) baseline is required as the original approach relies on iterative training and it is unclear if the baseline implementation follows the original implementation (similar to Section 4.1.3.). \n\nOverall the submission provides an interesting new direction on learning system identification approaches, that while quite similar to existing work (Yu et al 2017), provides increased performance on two benchmark tasks. The contribution of the paper focuses on detailed evaluation and, overall, beneficial details of the proposed method. The novelty of the submission is however limited and highly similar to current methods.\n\nMinor issues:\n- Related work on learning system identification:\nLearning to Perform Physics Experiments via Deep Reinforcement Learning\nMisha Denil, Pulkit Agrawal, Tejas D Kulkarni, Tom Erez, Peter Battaglia, Nando de Freitas\n', 'This paper proposes an “Environment-Probing” Interaction (EPI) policy used as an additional input for reinforcement learning (RL). This EPI allows to extract environment representations and implicitly understand the environment in order to improve the generalization on novel testing environments.\n\nPros:\n\nThis paper is well written and clear and the contribution is relevant to ICLR. Although I am not familiar with RL , the contribution seems novel and the model performances are compared with strong and appropriate baselines.', 'Some argumentation might better be supported by some reference, like : \n\n""When humans are tasked to perform in a new environment, we do not explicitly know what param-\neters affect performance. Instead, we probe the environment to gain an intuitive understanding of\nits behavior (Fig. 1). The purpose of these initial interactions is not to complete the task imme-\ndiately, but to extract information about the environment. This process facilitates learning in that\nenvironment. Inspired by this observation,\n""\n\nThe overall idea is interesting, the implementation is correct via a TRANSITION PREDICTION MODELS\n\nMore place could be taken for more detailed results, use appendix to swap some text...\n\n']","[50, 80, 50]","[75, 70, 20]","[""Sentiment score: The review is generally positive, acknowledging the interesting aspects of the submission and its benefits. However, it also points out limitations in novelty and suggests improvements. This mix of positive and constructive criticism suggests a moderately positive sentiment, hence the score of 50.\n\nPoliteness score: The language used is professional and respectful throughout. The reviewer offers constructive criticism without being harsh or dismissive. They use phrases like 'quite interesting and beneficial' and 'provides an interesting new direction,' which are polite ways of offering praise. Even when pointing out limitations, the tone remains courteous. The high politeness score of 75 reflects this professional and considerate approach."", ""The sentiment score is 80 (positive) because the review starts with listing the pros of the paper, describing it as 'well written and clear' and stating that the contribution is 'relevant' and 'novel'. The reviewer also mentions that the model performances are compared with 'strong and appropriate baselines', which is a positive assessment. There are no negative comments in this excerpt. The politeness score is 70 (polite) because the language used is professional and respectful. The reviewer acknowledges their potential lack of expertise in RL but still offers positive feedback, which shows humility and politeness. The use of phrases like 'This paper proposes' and 'the contribution seems' indicates a respectful tone without being overly deferential."", ""The sentiment score is 50 (slightly positive) because the reviewer describes the overall idea as 'interesting' and the implementation as 'correct', which are positive comments. However, there are also suggestions for improvement, indicating it's not entirely positive. The politeness score is 20 (slightly polite) because the language is generally neutral and professional, with some polite phrasing like 'might better be supported' instead of more direct criticism. The reviewer offers constructive feedback without harsh language, but also doesn't use overtly polite expressions. The review is brief and to the point, focusing on specific recommendations rather than elaborate courtesy.""]"
"['Summary:\nThe paper reformulates the task of video prediction/interpolation so that a predictor is not forced to generate frames at fixed time intervals, but instead it is trained to generate frames that happen at any point in the future. The motivation for such approach is that there might be future states that are highly uncertain – and thus, difficult to predict – that might not be useful for other tasks involving video prediction such as planning. The authors derive different loss functions for such Time-Agnostic Prediction (TAP), including extensions to the Variational AutoEncoders (VAE) and Generative Adversarial Networks (GAN) frameworks, and conduct experiments that suggest that the frames predicted by TAP models correspond to ‘subgoal’ states useful for planning.\n\nStrenghts:\n[+] The idea of TAP is novel and intuitively makes sense. \nIt is clear that there are frames in video prediction that might not be interesting/useful yet are difficult to predict, TAP allows to skip such frames.\n[+] The formulation of the TAP losses is clear and well justified. \nThe authors do a good job at showing a first version of a TAP loss, generalizing it to express preferences, and its extension to VAE and GAN models, showing that \n\nWeaknesses:\n[-] The claim that the model discovers meaningful planning subgoals might be overstated. \nThe hierarchical planning evaluation experiment seems like it would clearly favor TAP compared to a fixed model (why would the middle prediction in time of the fixed model correspond to reasonable planning goals?). Furthermore, for certain tasks and environments it seems like the uncertain frames might be the ones that correspond to important subgoals. For example, for the BAIR Push Dataset, usually the harder frames to predict are the arm-object interactions, which probably would correspond to the relevant subgoals.\n\nOverall I believe that the idea in this paper is a meaningful novel contribution. The paper is well-written and the experiments support the fact that TAP might be a better choice for training frame predictors for certain tasks.', 'Revision\n----------\nThanks for taking the comments on board. I like the paper, before and after, and so do the other reviewers. Some video results might prove more valuable to follow than the tiny figures in the paper and supplementary. Adding notes on limitations is helpful to understand future extensions.\n\n-----------------------------------------------\nInitial Feedback:\n---------------------\nThis is a very exciting proposal that deviates from the typical assumption that all future frames can be predicted with the same certainty. Instead, motivated by the benefits of discovering bottlenecks for hierarchical RL, this work attempts to predict ‘predictable video frames’ – those that can be predicted with certainty, through minimising over all future frames (in forward prediction) or all the sequence (in bidirectional prediction). Additional, the paper tops this with a variational autoencoder to encode uncertainty, even within those predictable frames, as well as a GAN for pixel-level generation of future frames. \n\nThe first few pages of the paper are a joy to read and convincing by default without looking at experimental evidence. I do not work myself in video prediction, but having read in the area I believe the proposal is very novel and could make a significant shift in how prediction is currently perceived. It is a paper that is easy to recommend for publication based on the formulation novelty, topped with VAEs and GANs as/when needed.\n\nBeyond the method’s explanation, I found the experiment section to be poorly structured. The figures are small and difficult to follow – looking at all the figures it felt that “more is actually less”. Many of the evidence required to understand the method are only included in the appendices. However, having spent the time to go back and forth, I believe the experiments to be scientifically sound and convincing.\n\nI would have liked a discussion in the conclusion on the method’s limitation. This reviewer believes that the approach will struggle to deal with cyclic motions. In this case the discovered bottlenecks might not be the most useful to predict, as these will correspond to future frames (not nearby though) that are visually similar to the start (in forward) or to the start/end (in bidirectional) frames. An additional loss to reward difficult-to-predict frames (though certain compared to other times) might be an interesting additional to conquer more realistic (rather than synthetic) video sequences.\n', 'The authors present a method on prediction of frames in a video, with the key contribution being that the target prediction is floating, resolved by a minimum on the error of prediction. The authors show the merits of the approach on a synthetic benchmark of object manipulation with a robotic arm. \n\nQuality: this paper appears to contain a lot of work, and in general is of high quality. \n\nClarity: some sections of the paper were harder to digest, but overall the quality of the writing is good and the authors have made efforts to present examples and diagrams where appropriate. Fig 1, especially helps one get a quick understanding of the concept of a `bottleneck` state. \n\nOriginality: To the extent of my knowledge, this work is novel. It proposes a new loss function, which is an interesting direction to explore.\n\nSignificance: I would say this work is significant. There appears to be a significant improvement in the visual quality of predictions. In most cases, the L1 error metric does not show such a huge improvement, but the visual difference is remarkable, so this goes to show that the L1 metric is perhaps not good enough at this point. \n\nOverall, I think this work is significant and I would recommend its acceptance for publication at ICLR. There are some drawbacks, but I don’t think they are major or would justify rejection (see comments below). \n\n\nI’m curious as to why you called the method in section 3.2 the “Generalized minimum”? It feels more like a weighted (or preference weighted) minimum to me and confused me a few times as I was reading the paper (GENerative? GENeralized? what’s general about it?). Just a comment.\n\nWhat results does figure 4 present? Are they only for the grasping sequence? Please specify.  \n\nIn connection with the previous comment, I think the results would be more readable if the match-steps were normalized for each sequence (at least for Figure 4). There would be a clearer mapping between fixT methods and the normalized matching step (e.g., we would expect fix0.75 to achieve a matching step of 0.75 instead of 6 / ? ).\n\nSection 4, Intermediate prediction. The statement “the genmin w(t) preference is bell-shaped” is vague. Do you mean a Gaussian? If so, you should say “a Gaussian centered at T/2 and tuned so that …”\n\nSection 4, Bottleneck discovery frequency. I am not entirely convinced by the measuring of bottleneck states. You say that a distance is computed between the predicted object position and the ground-truth object position. If a model were to output exactly the same frame as given in context, would the distance be zero? If so, doesn’t that mean that a model who predicts a non-bottleneck state before or after the robotic arm moves the pieces is estimated to have a very good bottleneck prediction frequency? I found this part of the paper the hardest to follow and the least convincing. Perhaps some intermediate results could help prospective readers understand better and be convinced of the protocol’s merits.\n\n\n\nTypos:\n\nAppendix E, 2nd paragraph, first sentence: “... generate an bidirectional state” --> “generate A bidirectional state” \n']","[60, 80, 80]","[80, 70, 90]","[""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its novel contribution and well-written nature. They mention several strengths and only one main weakness, concluding that the idea is 'a meaningful novel contribution.' The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the authors' efforts and contributions. They present criticisms constructively, using phrases like 'might be overstated' rather than harsh language. The review maintains a professional and courteous tone, balancing praise with thoughtful critique."", ""The sentiment score is 80 (positive) because the reviewer expresses enthusiasm for the paper, calling it 'very exciting' and 'a joy to read'. They recommend it for publication and praise its novelty. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the authors' efforts and providing constructive feedback. They balance praise with suggestions for improvement. The reviewer's tone is professional and courteous, even when pointing out areas for enhancement. The use of phrases like 'Thanks for taking the comments on board' and 'I like the paper' in the revision section further reinforces the positive and polite tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally positive view of the paper, recommending its acceptance and describing it as 'high quality', 'novel', and 'significant'. They mention some drawbacks but state these are not major. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer offers praise where due, frames criticisms as questions or suggestions, and uses polite language throughout (e.g., 'I'm curious', 'Please specify'). They also provide helpful feedback on typos. The scores are not 100 in either case as there is some criticism and room for even more politeness, but overall the review is very positive and courteous.""]"
"['This paper presents a method to reconstruct images using only noisy measurements. This problem is practically interesting, since the noiseless signal may be unavailable in many applications. The approach combines ideas from recent development in compressed sensing and GANs. However, the model’s presentation is confusing, and many important details of the experiments are missing.\n\nPros:\n\n* The problem is interesting and important\n* The combination of compressed sensing and GANs for image reconstruction is novel\n\nCons:\n\n* The model structure is unclear: for example, what is the role of the variable \\theta? Section 2.1 says it is known, but the algorithm samples from its prior(?). Since there is no further explanation with respect to the experiments, I am not sure how the values of \\theta or its distributions were determined. Although \\theta is formally similar to the \\theta parameters of the measurement function in ambientGANs, this interpretation is at odds with the example given in the paper (below eq.1, saying \\theta can be positions or sizes).\n* A few important details of the model are missing. For example, what is the exact structure of the measurement function F?\n* The baseline models are a bit confusing. More detail about unpaired vs paired supervision would also be helpful for understanding how these baseline models use the additional information.\n* Although the paper mentioned parameters are obtained from cross-validation, it would still be helpful to describe a few important ones (e.g., neural network size, weight \\lambda) for comparison with other models.The experiments on only CelebA dataset are too limited.', ""This is a very interesting paper that achieves something that seems initially impossible: \nto learn to reconstruct clear images from only seeing noisy or blurry images. \n\nThe paper builds on the closely related prior work AmbientGAN which shows that it is possible to learn the *distribution* of uncorrupted samples using only corrupted samples, again a very surprising finding. \nHowever, AmbientGAN does not try to reconstruct a single image, only to to learn the clear image distribution. The key idea that makes this is possible is knowledge of the statistics of the corruption process: the generator tries to create images that *after they have been corrupted* they look indistinguishable from real corrupted images. This surprisingly works and provably recovers the true distribution under a very wide set of corruption distributions, but tells us nothing about reconstructing an actual image from measurements. \n\nGiven access to a generative model for clear images, an image can be reconstructed from measurements by maximizing the likelihood term. This method (CS-GAN) was introduced by Bora et al. in 2017. Therefore one approach to solve the problem that this paper tackles is to first use AmbientGAN to get a generative model for clear images and then use CS-GAN using the learned GAN. If I understand correctly, this is the 'Conditional AmbientGAN' approach that is used as a baseline. This is a sensible approach given prior work. However, the authors show that their method ('Unpaired Supervision') performs significantly better compared to the Conditional AmbientGAN baseline. This is very surprising and interesting to me. Please discuss this a bit more ? As far as I understand the proposed method is a merging of AmbientGAN and CS-GAN, but much better than the naive separation. Could you give a bit more intuition on why ?\n\nI would like to add also that the authors can use their approach to learn a better AmbientGAN. After getting their denoised images, these can be used to train a new AmbientGAN, with cleaner images as input , which should be even better no ?\n\nIn the appendix where is the proposed method in fig 5- 8 ?\n\nDoes the proposed method outperform Deep Image Prior ? \n\n\n"", 'The authors address the problem of recovering an underlying signal from lossy and inaccurate measurements in an unsupervised fashion. They use a GAN framework to recover plausible signals from the measurements in the data. \n\n* Authors need to test other datasets, CelebA dataset is too limited. \n* Similarly, the experiment with different corruption processes are required. \n* What is a definition of F. It is not clear ""measurement process"".\n']","[-20, 80, -20]","[50, 90, 0]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting and important problem', 'novel combination'), they express several significant concerns about the paper's clarity and completeness. The cons outweigh the pros in both number and depth. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout and frames criticisms constructively as areas for improvement rather than harsh judgments. They begin with positive points before moving to critiques, which is a polite approach. The reviewer also uses phrases like 'it would be helpful' when suggesting additions, maintaining a respectful tone."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'very interesting' and 'surprising', and expresses genuine interest in the work. They acknowledge the paper's achievements and its significance in relation to prior work. The politeness score is 90 (very polite) because the reviewer uses respectful language throughout, asks questions in a constructive manner, and offers suggestions politely. They use phrases like 'Please discuss this a bit more?' and 'Could you give a bit more intuition on why?', which are courteous ways of requesting more information. The reviewer also offers a constructive suggestion for improvement, framed in a positive way ('I would like to add also that the authors can use their approach to learn a better AmbientGAN'). The overall tone is professional, engaged, and supportive, without any harsh criticism or rude language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the authors' approach to the problem, they provide several critical points for improvement without offering any positive feedback. The review suggests that the work is incomplete or insufficient in its current state. The politeness score is neutral (0) as the language used is direct and matter-of-fact, neither particularly polite nor rude. The reviewer states their points concisely without using overly harsh language or personal attacks, but also without any softening phrases or compliments that would indicate politeness.""]"
"[""The paper builds upon Deep Image Prior (DIP) - work which shows that one can optimize a neural generator to fit a single image without learning on any dataset, and the output of the generator (which approximates the image) can be used for denoising / super resolution / etc. The paper proposes a new architecture for the DIP method which has much less parameters, but works on par with DIP. Another contribution of the paper is theoretical treatment of (a simplified version of) the proposed architecture showing that it can’t fit random noise (and thus maybe better suited for denoising).\n\nThe paper is clearly written, and the proposed architecture has too cool properties: it’s compact enough to be used for image compression; and it doesn’t overfit thus making early stopping notnesesary (which was crucial for the original DIP model).\n\nI have two main concerns about this paper.\nFirst, it is somewhat misleading about its contributions: it's not obvious from abstract/introduction that the whole model is the same as DIP except for the proposed architecture. Specifically, the first contribution listed in the introduction makes it look like this paper introduces the idea of not learning the decoder on the dataset (the one that starts with “The network is not learned and itself incorporates all assumptions on the data.”).\n\nMy second concern is about the theoretical contribution. On the one hand, I enjoyed the angle the authors tackled proving that the network architecture is underparameterized enough to be a good model for denoising. On the other hand, the obtained results are very weak: only one layered version of the paper is analysed and the theorem applies only to networks with less than some threshold of parameters. Roughly, the theorem states that if for example we fix any matrix B of size e.g. 256 x k and matrix U of size 512 x 256 and then compute U relu(B C) where C is the vector of parameters of size k x 1, AND if k < 2.5 (i.e. if we use at most 2 parameters), then it would be very hard to fit 512 iid gaussian values (i.e. min_C ||U relu(B C) - eta|| where eta ~ N(0, 1)). This restriction of the number of parameters to be small is only mentioned in the theorem itself, not in the discussion of its implications.\nAlso, the theorem only applies to the iid noise, while most natural noise patterns have structure (e.g. JPEG artifacts, broken pixels, etc) and thus can probably be better approximated with deep models.\n\nSince the paper manages to use very few parameters (BTW, how many parameters in total do you have? Can you please add this number to the text?), it would be cool to see if second order methods like LBFGS can be applied here.\n\nSome less important points:\n\nFig 4 is very confusing.\nFirst, it doesn’t label the X axis.\nSecond, the caption mentions that early stopping is beneficial for the proposed method, but I can’t see it from the figure.\nThird, I don’t get what is plotted on different subplots. The text mentions that (a) is fitting the noisy image, (b) is fitting the noiseless image, and (c) is fitting noise. Is it all done independently with three different models? Then why does the figure says test and train loss? And why DIP loss goes up, it should be able to fit anything, right? If not and it’s a single model that gets fitted on the noisy image and tested on the noiseless image, then how can you estimate the level of noise fitting? ||G(C) - eta|| should be high if G(C) ~= x.\nAlso, in this quote “In Fig. 4(a) we plot the Mean Squared Error (MSE) over the number of iterations of the optimizer for fitting the noisy astronaut image x + η (i.e., FORMULA ...” the formula doesn’t correspond to the text.\nAnd finally, the discussion of this figure makes claims about the behaviour of the model that seems to be too strong to be based on a single image experiment.\n\nI don’t get the details of the batch normalization used: with respect to which axis the mean and variance are computed?\n\nThe authors claim that the model is not convolutional. But first, it’s not obvious why this would be a good thing (or a bad thing for that matter). Second, it’s not exactly correct (as noted in the paper itself): the architecture uses 1x1 convolutions and upsampling, which combined give a weak and underparametrized analog of convolutions.\n\n> The deep decoder is a deep image model G: R N → R n, where N is the number of parameters of the model, and n is the output dimension, which is typically much larger than the number of parameters (N << n).\nI think it should be vice versa, N >> n\n\nThe following footnote\n> Specifically, we took a deep decoder G with d = 6 layers and output dimension 512×512×3, and choose k = 64 and k = 128 for the respective compression ratios.\nUses unintroduced (at that point) notation and is very confusing.\n\nIt would be nice to have a version of Figure 6 with k = 6, so that one can see all feature maps (in contrast to a subset of them).\n\nI’m also wondering, is it harder to optimize the proposed architecture compared to DIP? The literature on distillation indicates that overparameterization can be beneficial for convergence and final performance.\n"", 'Brief summary:\n\nThis paper presents a deep decoder model which given a target natural image and a random noise tensor learns to decode the noise tensor into the target image by a series of 1x1 convolutions, RELUs, layer wise normalizations and upsampling. The parameter of the convolution are fitted to each target image, where the source noise tensor is fixed. The method is shown to serve as a good model for natural image for a variety of image processing tasks such as denoising and compression.\n\nPros:\n* an interesting model which is quite intriguing in its simplicity.\n* good results and good analysis of the model\n* mostly clear writing and presentation (few typos etc. nothing too serious).\n\nCons and comments:\n* The author say explicitly that this is not a convolutional model because of the use of 1x1 convolutions. I disagree and I actually think this is important for two reasons. First, though these are 1x1 convolutions, because of the up-sampling operation and the layer wise normalizations the influence of each operation goes beyond the 1x1 support. Furthermore, and more importantly is the weight sharing scheme induced by this - using convolutions is a very natural choice for natural images (no pun intended) due to the translation invariant statistics of natural images. I doubt this would have worked so well hadn\'t it been modeled this way (not to mention this allows a small number of parameters).\n\n* The upsampling analysis is interesting but it is only done on synthetic data - will the result hold for natural images as well? should be easy to try and will allow a better understanding of this choice. Natural images are only approximately piece-wise smooth after all.\n\n* The use of the name ""batch-norm"" for the layer wise normalization is both wrong and misleading. This is just channel-wise normalization with some extra parameters - no need to call it this way (even if it\'s implemented with the same function) as there is no ""batch"".\n\n* I would have loved to see actual analysis of the method\'s performance as a function of the noise standard deviation. Specifically, for a fixed k, how would performance increase or decrease, and vice versa - for a given noise level, how would k affect performance.\n\n* The actual standard deviation of the noise is not mentioned in any of the experiments (as far as I could tell)\n\n* What does the decoder produce when taking a trained C on a given image and changing the source noise tensor? I think that would shed light on what structures are learned and how they propagated in the image, possibly more than Figure 6 (which should really have something to compare to because it\'s not very informative out of context).', 'In this paper, the authors propose a method for dimensionality reduction of image data. They provide a structured and deterministic function G that maps a set of parameters C to an image X = G(C). The number of parameters C is smaller than the number of free parameters in the image X, so this results in a predictive model that can be used for compression, denoising, inpainting, superresolution and other inverse problems.\n\nThe structure of G is as follows: starting with a small fixed, multichannel white noise image, linearly mix the channels, truncate the negative values to zero and upsample. This process is repeated multiple times and finally the output is squashed through a sigmoid function for the output to remain in the 0..1 range.\n\nThis approach makes sense and the model is indeed more principled than the one taken by Ulyanov et al. In fact, the DIP of Ulyanov et al. can hardly be considered ""a model"" (or a prior, for that matter), and instead should be considered ""an algorithm"", since it relies on the early stopping of a specific optimization algorithm. This means that we are not interested in the minimum of the cost function associated to the model, which contradicts the very concept of ""cost function"". If only global optimizers were available, DIP wouldn\'t work, showing its value is in the interplay of the ""cost"" function and a specific optimization algorithm. None of these problems exist with the presented approach.\n\nThe exposition is clear and the presented inverse problems as well as demonstrated performance are sufficient.\n\nOne thing that I missed while reading the paper is more comment on negative results. Did the authors tried any version of their model with convolutions or pooling and found it not to perform as well? Measuring the number of parameters when including pooling or convolutions can become tricky, was that part of the reason?\n\nMinor:\n\n""Regularizing by stopping early for regularization,""\n\nIn this paper ""large compression ratios"" means little compression, which I found confusing.\n']","[20, 50, 70]","[60, 70, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's clear writing and 'cool properties' of the proposed architecture. However, they also express two main concerns and several minor points for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases their concerns as suggestions rather than harsh criticisms. They also compliment aspects of the paper and express enjoyment of certain parts. The reviewer maintains a professional tone, avoiding personal attacks or overly negative language, even when pointing out areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by highlighting the pros of the paper, describing it as 'interesting' and praising its 'good results and good analysis'. However, this is balanced by a list of cons and comments, indicating areas for improvement. The overall tone suggests the reviewer sees merit in the work but also has significant suggestions for enhancement. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, even when offering criticisms. They use phrases like 'I would have loved to see' and 'I think that would shed light on', which soften the impact of their suggestions. The reviewer also acknowledges the paper's strengths before delving into areas of concern, which is a polite approach to critique. There are no harsh or rude comments, and the overall tone is constructive and professional."", 'The sentiment score is 70 (positive) because the reviewer expresses a generally favorable view of the paper. They describe the approach as making sense, being more principled than previous work, and having clear exposition. The reviewer also notes that the performance demonstrations are sufficient. The score is not higher because the reviewer does mention missing some information about negative results.\n\nThe politeness score is 80 (polite) because the reviewer uses respectful and professional language throughout. They offer constructive feedback and frame their comments in a positive manner, even when pointing out areas for improvement. The reviewer acknowledges the value of the work and provides specific, helpful suggestions without using harsh or critical language. The tone is collegial and supportive overall, demonstrating a high level of politeness in academic discourse.']"
"['Thanks the authors for an interesting work!\nThe paper studies the differences between human and DNN vision via means of minimal images (i.e. smallest image crops that can be correctly classified).\n\nThere are a few notable take-away messages:\n1. DNNs are not invariant to even tiny (1-2 px) translations of small image crops.\n    - It would be more insightful if authors added comparison between DNN sensitivity to tiny translations of small image crops vs. full-size images (i.e. translation-based adversarial examples https://openreview.net/forum?id=BJfvknCqFQ ).\n2. The smaller the image crops, the more sensitive DNNs become (here, more FRIs)\n3. DNNs and human vision misclassify the image crops differently: (1) DNNs have almost twice more FRI(s) and (2) FRIs of human and DNNs differ in location.\n\nQuestions:\n\n- ""After extracting the region from the image, the region is resized to be of the size required by the network.""\nWould upscaling say a small 28x28 crop into 224x224 image here naturally negatively impact the DNN predictive performance?\nThat is, because typically image classifiers are trained on one (or a few) fixed resolution(s) of images.\n\nOne hypothesis here is that fragile recognition may be because the test image resolution does not match the training image resolution.\nHuman on the other hands, have been trained on images of variable resolutions.\n\nAn alternative to upscaling here is to zero-pad the crop region. Can you help us understand your choice of upscaling here?\n\n+ Originality\nThe originality is limited as it is a close extenstion work of Ullman et al. 2016\n\n+ Clarity\nThe paper is well written and presented.\n\n+ Significance\nThis work extends our understanding of the differences between DNNs and human vision.\nHowever, given what we learned from the adversarial example research area, the contribution of this work is low because results might not be too surprising.', 'This paper is a more thorough follow-up to e a previous work by Ullman et al that was comparing minimally recognizable patches by humans compared to deep neural network. This paper exhibits that a wide range of architectures features the same fragility and that these effects can combated by better training methodology and different pooling architectures. Still even with those changes deep CNNs still posses more fragile behavior than human vision. One of my criticism is that human vision is kind of different: it makes multiple passes over the same images at multiple scales, so this might contribute significantly to these differences. Still this paper makes a lot of interesting observations and analyses and represents a first methodological study of this phenomenon.\n\nA novelty of this work is that it is the first paper that methodologically analyses FRIs for DNNs a reasearch area which might shed new light on the understanding of how vision systems work and the source of misrecognitions and the limitations of recognition systems.\n\nIn light of the changes of the paper and the clarification on the novelty aspect of this research, I suggest this paper to be accepted as it constitutes novel research in understanding how DNNs recognize image content and its similarities and differences to human vision.\n\n\n\n', ""Ullman et al. showed that slight changes in location or size of visible regions in minimal recognizable images can significantly impair human ability to recognize objects. This paper is a  follow-up of Ullman et al. paper, with focus on sensitivity of DNNs to certain regions in images. In other words, slight change of such regions’ size or location in the image can significantly affect DNN ability in recognizing them, even-though these changes are not noticeable for humans. \n\n\nComments and questions:\n\nThis paper provides in-depth study of fragile recognition in DNNs. \n\n- Visualizing activations of different layers of DNN for Loose shift/shrink FRIs can potentially provide more details on why the final output of DNN is significantly different for two visually similar images.   \n\n- Naively augmenting training data with crops of small FRI sizes can potentially harm and confuse DNN in classifying training samples as many small patches in training images are background and they don't contain target object. It is interesting to see the sensitivity of DNNs that are trained for the task of object detection to FRIs, like sensitivity of R-CNN to FRIs. In this case augmenting training data with crops of small FRI sizes can be properly done since ground-truth bounding boxes can determine which region is foreground and which region is background. ""]","[20, 80, 60]","[70, 70, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper as 'interesting' and notes some 'notable take-away messages'. They also praise the clarity of writing. However, they express concerns about limited originality and low contribution. The politeness score is fairly high (70) as the reviewer begins by thanking the authors, uses respectful language throughout, and frames criticisms as questions or suggestions rather than direct criticisms. They also highlight positive aspects like clarity alongside areas for improvement."", ""The sentiment score is 80 (positive) because the reviewer expresses a generally favorable view of the paper. They describe it as 'interesting', 'novel', and making 'a lot of interesting observations and analyses'. The reviewer recommends acceptance of the paper, which is a strong positive indicator. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They offer criticism in a constructive manner ('One of my criticism is...') and acknowledge the paper's contributions. The tone is consistently professional and courteous, without any harsh or rude language. The reviewer balances praise with constructive feedback, which is a hallmark of polite academic discourse."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as providing an 'in-depth study' and offers constructive suggestions for improvement, indicating overall approval. The tone is not overwhelmingly enthusiastic, but clearly positive. The politeness score is 50 (somewhat polite) as the reviewer uses neutral, professional language without any harsh criticisms. They offer suggestions in a respectful manner, using phrases like 'It is interesting to see' and 'can potentially provide more details'. The review maintains a courteous and constructive tone throughout, without being excessively formal or deferential.""]"
"[""This paper proposed a novel approach for learning disentangled representation from supervised data (x as the input image, y as different attributes), by learning an encoder E and a decoder D so that (1) D(E(x)) reconstructs the image, (2) E(D(x)) reconstruct the latent vector, in particular for the vectors that are constructed by mingling different portion of the latent vectors extracted from two training samples, (3) the Jacobian matrix matches and (4) the predicted latent vector matches with the provided attributes. In addition, the work also proposes to progressively add latent nodes to the network for training. The claim is that using this framework, one avoid GAN-style training (e.g., Fader network) which could be unstable and hard to tune. \n\nAlthough the idea is interesting, the experiments are lacking. While previous works (e.g., Fader network) has both qualitative (e.g., image quality when changing attribute values) and quantitative results (e.g., classification results of generated image with novel combination of attributes), this paper only shows visual comparison (Fig. 4 and Fig. 5), and its comparison with Fader network is a bit vague (e.g., it is not clear to me why Fig. 5(e) generated by proposed approach is “more natural” than Fig. 5(d), even if I check the updated version mentioned by the authors' comments). Also in the paper there are five hyperparameters (Eqn. 14) and the center claim is that using Jacobian loss is better. However, there is no ablation study to support the claim and/or the design choice. From my opinion, the paper should show the performance of supervised training of attributes, the effects of using Jacobian loss and/or cycle loss, the inception score of generated images, etc. \n\nI acknowledge the authors for their honesty in raising the issues of Fig. 4, and providing an updated version. "", ""Summary: The paper proposes a method to tackle the disentanglement-reconstruction tradeoff problem in many disentangling approaches. This is achieved by first training the teacher autoencoder (unsupervised or supervised) that learns to disentangle the factors of variation at the cost of poor reconstruction, and then distills these learned representations into a student model with extra latent dimensions, where these extra latents can be used to improve the reconstructions of the student autoencoder compared to the teacher autoencoder. The distillation of the learned representation is encouraged via a novel Jacobian loss term that encourages the change in reconstructions of the teacher and student to be similar when the latent representation changes. There is one experiment for progressive unsupervised disentangling (disentangling factor by factor) on MNIST data, and one experiment for semi-supervised disentangling on CelebA-HQ.\n\nPros:\n- I think the idea of progressively capturing factors of variation one by one is neat, and this appears to be one of the first successful attempts at this problem.\n- The distillation appears to work well on the MNIST data, and does indeed decrease the reconstruction loss of the student compared to the teacher.\n- The qualitative results on CelebA-HQ look strong (especially apparent in the video), with the clear advantage over Fader Networks being that the proposed model is a single model that can manipulate the 40 different attributes, whereas Fader Nets can only deal with at most 3 attributes per model.\n\nCons:\n- There are not enough quantitative results supporting the claim that the model is “effective at both disentangling and reconstruction.” The degree of disentanglement in the representations is only shown qualitatively via latent interpolation, and only for a single model. Such qualitative results are generally prone to cherry-picking and it is difficult to reliably compare different disentangling methods in this manner. This calls for quantitative measures of disentanglement. Had you used a dataset where you know the ground truth factors of variation (e.g. dSprites/2D Shapes data) for the unsupervised disentangling method, then the level of disentanglement in the learned representations could be quantified, and thus your method could be compared against unsupervised disentangling baselines. For the semi-supervised disentanglement example on CelebA, you could for example quantify how well the encoder predicts the different attributes (because there is ground truth here) e.g. report RMSE of the y_i’s on a held out test set with ground truth. A quantitative comparison with Fader Networks in this manner appears necessary. The qualitative comparison on a single face in Figure 5 is nowhere near sufficient.\n- There is quantitative evidence that the reconstruction loss decreases when training the student, but here it’s not clear whether this quantitative difference makes a qualitative difference in the reconstructions. Getting higher fidelity images is one of the motivations behind improving reconstructions, so It would be informative to compare the reconstructions of the teacher and the student on the same image.\n- In the CelebA experiments, the benefit of student training is not visible in the results. In Figure 5 you already show that the teacher model gives decent reconstructions, yet you don’t show the reconstruction for the student model (quantitatively you show that it improves in Figure 3b, but again it is worth checking if it makes a difference visually). Also it’s not clear whether Figure 4 are results from the student model or the teacher model. I’m guessing that they are from the student model.\n- These quantitative results could form the basis of doing ablation studies for each of the different losses in the additive loss (for both unsupervised & semi-supervised tasks). Because there are many components in the loss, with a hyperparameter for each, it would be helpful to know what losses the results are sensitive to for the sake of tuning hyperparameters. This would be especially useful should I wish to apply the proposed method to a different dataset.\n- I think the derivation of the Jacobian loss requires some more justification. The higher order terms in the Taylor expansion in (2) and (3) can only be ignored when ||y_2 - y_1|| is small compared to the coefficients, but there is no validation/justification regarding this.\n\nOther Qs/comments:\n- On page 5 in the last paragraph of section 3, you say that “After training of the student with d=1 is finished, we consider it as the new teacher”. Here do you append z to y when you form the new teacher?\n- On page 6 in the paragraph for prediction loss, you say “This allows the decoder to naturally …. of the attributes”. I guess you mean this allows the model to give realistic interpolations between y=-1 and 1?\n- bottom of page 6: “Here we could have used any random values in lieu of y_2” <- not sure I understand this?\n- typo: conditionnning -> conditioning\n- I would be inclined to boost the score up to 7 if the authors include some quantitative results along with more thorough comparisons to Fader Networks\n\n************ Revision ***********\nThe authors' updates include further quantitative comparisons to Fader Networks and ablation studies for the different types of losses, addressing the concerns I had in the review. Hence I have boosted up my score to 7."", 'The paper aims to learn an autoencoder that can be used to effectively encode the known attributes/ generative factors and this allows easy and controlled manipulation of the images while producing realistic images.\n\nTo achieve this, ordinarily, the encoder produces latent code with two components y and z where y are clamped to known attributes using supervised loss while z is unconstrained and mainly useful for good reconstruction. But his setup fails when z is sufficiently large as the decoder can learn to ignore y altogether. Smaller sized z leads to poor reconstruction.\n\nTo overcome this issue, the authors propose to employ a student teacher training paradigm. The teacher is trained such that the encoder only produces y and the decoder that only consumes y. This ensures good disentanglement but poor reconstruction. Subsequently, a student autoencoder is learned which has a much larger latent code and produces both y and z. The y component is mapped to the teacher encoder’s y component using Jacobian regularization.\n\nPositives:\nThe results of image manipulation using known attributes is quite impressive. The authors propose modifications to the Jacobian regularization as simple reconstruction losses for efficient training. The approach avoids adversarial training and thus is easier to train.\n\nNegatives:\nUnsupervised disentanglement results are only shown for MNIST. I am not convinced similar results for unsupervised disentanglement can be obtained on more complex datasets. Authors should include some results on this aspect or reduce the emphasis on unsupervised disentanglement. Also when studying this quantitative evaluation for disentanglement such as in beta-VAE will be nice to have.\n\nTypos:\npage 3: tobtain -> obtain\npage 5: conditionning -> conditioning ']","[-50, 50, 60]","[20, 80, 70]","[""The sentiment score is -50 because while the reviewer acknowledges the interesting idea, they express significant concerns about the lack of experiments and quantitative results. The reviewer points out several shortcomings in the paper's methodology and presentation, indicating a generally negative sentiment. However, it's not entirely negative as they do recognize some positive aspects, hence not a lower score. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'I acknowledge the authors for their honesty' which shows respect. They also frame criticisms as suggestions for improvement rather than harsh judgments. However, the overall tone is more neutral than overtly polite, hence a modest positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer provides a balanced assessment with both pros and cons. They acknowledge the strengths of the paper, such as the novel approach and strong qualitative results, while also pointing out areas for improvement. The initial review suggests room for improvement, but the final paragraph indicates the authors addressed the main concerns, leading to a boosted score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and frames suggestions as recommendations rather than demands. They use phrases like 'I think' and 'It would be informative' which maintain a collegial tone. The reviewer also acknowledges the potential of the work by suggesting how the score could be improved, showing a supportive attitude."", ""The sentiment score is 60 (positive) because the reviewer highlights several positives about the paper, such as 'impressive' results and an approach that is 'easier to train'. However, it's not extremely positive due to some negatives mentioned, like the lack of unsupervised disentanglement results for complex datasets. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offers constructive criticism, and even points out typos in a helpful manner. The tone is professional and courteous, avoiding harsh criticism while still providing valuable feedback.""]"
"[""Mode collapse in the context of GANs occurs when the generator only learns one of the \nmultiple modes of the target distribution. Mode collapsed can be tackled, for instance, using Wasserstein distance instead of Jensen-Shannon divergence. However, this sacrifices accuracy of the generated samples.\n\nThis paper is positioned in the context of Bayesian GANs (Saatsci & Wilson 2017) which, by placing a posterior distribution over the generative and discriminative parameters, can potentially learn all the modes. In particular, the paper proposes a Bayesian GAN that, unlike previous Bayesian GANs, has theoretical guarantees of convergence to the real distribution.\n\nThe authors put likelihoods over the generator and discriminator with logarithms proportional to the traditional GAN objective functions. Then they choose a prior in the generative parameters which is the output of the last iteration. The prior over the discriminative parameters is a uniform improper prior (constant from minus to plus infinity). Under this specifications, they demonstrate that the true data distribution is an equilibrium under this scheme. \n\nFor the inference, they adapt the Stochastic Gradient HMC used by Saatsci & Wilson. To approximate the gradient of the discriminator, they take samples of the generator parameters. To approximate the gradient of the generator they take samples of the discriminator parameters but they also need to compute a gradient of the previous generator distribution. However, because this generator distribution is not available in close form they propose two simple approximations.\n\nOverall, I enjoyed reading this paper. It is well written and easy to follow. The motivation is clear, and the contribution is significant. The experiments are convincing enough, comparing their method with Saatsci's Bayesian GAN and with the state of the art of GAN that deals with mode collapse. It seems an interesting improvement over the original Bayesian GAN with theoretical guarantees and an easy implementation.\n\nSome typos:\n\n- The authors argue that compare to point mass...\n+ The authors argue that, compared to point mass...\n\n- Theorem 1 states that any the ideal generator\n+ Theorem 1 states that any ideal generator\n\n- Assume the GAN objective and the discriminator space are symmetry\n+ Assume the GAN objective and the discriminator space have symmetry\n\n- Eqn. 8 will degenerated as a Gibbs sampling\n+ Eqn. 8 will degenerate as a Gibbs sampling"", ""Summary\n=========\nThe paper extends Bayesian GANs by altering the generator and discriminator parameter likelihood distributions and their respective priors. \nThe authors further propose an SGHMC algorithm to collect samples of the resulting posterior distributions on each parameter set and evaluate their approach on both a synthetic and the CIFAR-10 data set. \nThey claim superiority of their method, reporting a higher distance to mode centers of generated data points and better generator space coverage for the synthetic data set and better inception scores for the real world data for their method.\n\nReview\n=========\nAs an overall comment, I found the language poor, at times misleading.\nThe authors should have their manuscript proof-read for grammar and vocabulary.\nExamples: \n- amazing superiority (page 1, 3rd paragraph)\n- Accutally... (page 1, end of 3rd paragraph)\n- the total mixture of generated data distribution (page 3, mid of 3.1)\n- Similarity we define (page 3, end of 3.1)\n- etc.\nOver the whole manuscript, determiners are missing.\n\nThe authors start out with a general introduction to GANs and Bayesian GANs in particular, \narguing that it is an open research question whether the generator converges to the true data generating distribution in Bayesian GANs.\nI do not agree here. The Bayesian GAN defines a posterior distribution for the generator that\nis proportional to the likelihood that the discriminator assigns to generated samples.\nThe better the generator, the higher the likelihood that the discriminator assign to these samples.\nIn the case of a perfect generator, here the discriminator is equally unable to distinguish real and generated samples and consequently degenerates to a constant function.\nUsing the same symmetry argument as the authors, one can show that this is the case for Bayesian GANs.\n\nWhile defining the likelihood functions, the iterator variable t is used without introduction.\n\nFurther, I a confused by their argument of incompatibility.\nFirst, they derive a Gibbs style update scheme based on single samples for generator and discriminator parameters using\nposteriors in which the noise has been explicitly marginalized out by utilizing a Monte Carlo estimate.\nSecond, the used posteriors are conditional distributions with non-identical conditioning sets.\nI doubt that the argument still holds under this setting.\n\nWith respect to the remaining difference between the proposed approach and Bayesian GAN,\nI'd like the authors elaborate where exactly the difference between expectation of objective value\nand objective value of expectation is.\nSince the original GAN objectives used for crafting the likelihoods are deterministic functions,\nrandomness is introduced by the distributions over the generator and discriminator parameters.\nI would have guessed that expectations propagate into the objective functions.\n\nIt is, however, interesting to analyze the proposed inference algorithm, especially the introduced posterior distributions.\nFor the discriminator, this correspond simply to the likelihood function.\nFor the generator, the likelihood is combined with some prior for which no closed form solution exists.\nIn fact, this prior changes between iterations of the inference algorithm.\nThe resulting gradient of the posterior decomposes into the gradient of the current objective and the sum over all previous gradients.\nWhile this is not a prior in the Bayesian sense (i.e. in the sense of an actual prior belief), it would be interesting to have a closer look at the effect this has on the sampling method.\nMy educated guess is, that this conceptually adds up to the momentum term in SGHMC and thus slows down the exploration of the parameter space and results in better coverage.\n\nThe experiments are inspired by the ones done in the original Bayesian GAN publication.\nI liked the developed method to measure coverage of the generator space although I find the\nterm of hit error misleading.\nGiven that the probabilistic methods all achieve a hit rate of 1, a lower hit error actually points to worse coverage.\nI was surprised to see that hit error and coverage are only not consistently negatively correlated.\nAdding statistics over several runs of the models (e.g. 10) would strengthen the claim of superior performance."", 'PRIOR COMMENT:   This paper should be rejected based on the experimental work.\nExperiments need to be reported for larger datasets.  Note the MGAN\npaper reports results on STL-10 and ImageNet as well.\n\nNOTE:  this was addressed by the 27/11 revision, which included good\n   results for these other data sets, thus I now withdraw the comment\n\nNote, your results on CIFAR-10 are quite different to those in the\nMGAN paper.  Your inceptions scores are worse and FIDs are better!!  I\nexpect you have different configurations to their paper, but it would\nbe good for this to be explained.  NOTE:   explained in response!\n\nNOTE:  this was addressed by the 27/11 revision\n\nI thought the related work section was fabulous, and as an extension\nto BGAN, the paper is a very nice idea.  So I benefited a lot from reading\nthe paper.\n\nI have some comments on Bayesian treatment.  In Bayesian theory, the\ntrue distribution $p_{data}$ cannot appear in any evaluated formulas,\nas you have it there in Eqn (1) which is subsequently used in your\nlikelihood Eqn (2).  Likelihoods are models and cannot involve ""truth"".\n\nLemma 1:  Very nice observation!!  I was trying to work that out,\nonce I got to Eqn (3), and you thought of it. \n\nAlso, you do need to explain 3.2 better.  The BGAN paper, actually, is\na bit confusing from a strict Bayesian perspective, though for\ndifferent reasons.  The problem you are looking at is not a\ntime-series problem, so it is a bit confusing to be defining it as\nsuch.  You talk about an iterative Bayesian model with priors and\nlikelihoods.  Well, maybe that can be *defined* as a probabilistic\nmodel, but it is not in any sense a Bayesian model for the estimation\nof $p_{model}$.\n\nNOTE:  anonreviewer2 expands more on this\n\nWhat you do with Equation (3) is define a distribution on\n$q_g(\\theta_g)$ and $q_d(\\theta_d)$ (which, confusingly, involves the\n""true"" data distribution ... impossible for a Bayesian formulation).\nYou are doing a natural extension of the BGAN papers formulation in\ntheir Eqs (1) and (2).  This, as is alluded to in Lemma 1.  Your\nformulation is in terms of two conditional distributions, so\nconditions should be given that their is an underlying joint\ndistribution that agrees with these.  Lemma 1 gives a negative result.\nYou have defined it as a time series problem, and apparantly one wants\nthis to converge, as in Gibbs sampling style.  Like BGAN, you have\njust arbitrarily defined a ""likelihood"".\n\nTo me, this isn\'t a Bayesian model of the unsupervised learning task,\nits a probabilistic style optimisation for it, in the sense that you are defining a probability\ndistribution (over $q_g(\\theta_g)$ and $q_d(\\theta_d)$) and sampling\nfrom it, but its not really a ""likelihood"" in the formal sense.  A\nlikelhood defines how data is generated.  Your ""likelihood"" is over\nmodel parameters, and you seem to have ignored the data likelihood,\nwhich you define in sct 3.1 as $p_{model}()$.\n\nAnyway, I\'m happy to go with this sort of formulation, but I think you\nneed to call it what it is, and it is not Bayesian in the standard sense.  The theoretical\ntreatment needs a lot of cleaning up.  What you have defined is a\nprobabilistic time-series on $q_g(\\theta_g)$ and $q_d(\\theta_d)$.\nFair enough, thats OK.  But you need to show that it actually works in\nthe estimation of $p_{model}$.  Because one never has $p_{data}$, all\nyour Theorem 1 does is show that asymptotically, your method works.\nUnfortunately, I can say the same for many crude algorithms, and most\nof the existing published work.  Thus, we\'re left with requiring a\nsubstantial empirical validation to demonstrate the method is useful.\n\nNow my apologies to you: I could make somewhat related statements\nabout the theory of the BGAN paper, and they got to publish theirs at\nICLR!  But they did do more experimentation.\n\nOh, and some smaller but noticable grammar/word usage issues.\n\nNOTE:  thanks for your good explanation of the Bayesian aspects of the model ...\nyes I agree, you have a good Bayesian model of the GAN computation , but it\nis still not a Bayesian model of the unsupervised inference task.  This is a somewhat\nminor point, and should not in anyway influence worth of the paper ... but clarification\nin paper would be nice.']","[80, -50, 50]","[90, 20, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses enjoyment in reading the paper, praises its clarity and significance, and describes the contribution as 'interesting' and an 'improvement'. The overall tone is very positive, with only minor suggestions for typo corrections. The politeness score is 90 (very polite) due to the reviewer's use of respectful and encouraging language throughout. They offer constructive feedback and frame their comments positively, using phrases like 'I enjoyed reading this paper' and 'It is well written and easy to follow'. The reviewer also provides specific, helpful suggestions for minor corrections without being overly critical."", ""The sentiment score is -50 because the review is generally critical of the paper, pointing out numerous issues with language, arguments, and methodology. However, it's not entirely negative as the reviewer does acknowledge some interesting aspects of the work. The politeness score is 20 because while the reviewer is direct in their criticisms, they use relatively polite language such as 'I found', 'I do not agree', and 'I'd like the authors to elaborate'. They also offer constructive feedback and suggestions for improvement. The reviewer maintains a professional tone throughout, even when pointing out errors or disagreements."", ""The sentiment score is 50 (slightly positive) because while the reviewer initially suggests rejection, they later withdraw this comment and express appreciation for aspects of the paper ('I thought the related work section was fabulous', 'So I benefited a lot from reading the paper'). They also compliment specific parts ('Lemma 1: Very nice observation!!'). However, they still have significant concerns about the theoretical treatment and Bayesian aspects. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges when their concerns have been addressed, and even apologizes for potential inconsistency with previous reviews ('Now my apologies to you...'). They offer constructive criticism and suggestions rather than harsh judgments, and their tone remains professional and courteous even when pointing out issues.""]"
"['* Description\n\nThe work is motivated by the empirical performance of Batch Normalization and in particular the observed better robustness of the choice of the learning rate.  Authors analyze theoretically the asymptotic convergence rate for objectives involving normalization, not necessarily BN, and show that for scale-invariant groups of parameters (appearing as a result of normalization) the initial learning rate may be set arbitrary while still asymptotic convergence is guaranteed with the same rate as the best known in the general case. Offline gradient descent and stochastic gradient descent cases are considered.\n\n* Strengths\n\nThe work addresses better theoretical understanding of successful heuristics in deep learning, namely batch normalization and other normalizations. The technical results obtained are non-trivial and detailed proofs are presented. Also I did not verify the proofs the paper appears technically correct and technically clear. The result may be interpreted in the following form: if one chooses to use BN or other normalization, the paper gives a recommendation that only the learning rate of scale-variant parameters need to be set, which may have some practical advantages. Perhaps more important than the rate of convergence, is the guarantee that the method will not diverge (and will not get stuck in a non-local minimum). \n\n* Criticism\nThis paper presents non-trivial theoretical results that are worth to be published but as I argue below its has a weak relevance to practice and the applicability of the obtained results is unclear.\n-- Concerns regarding the clarity of presentation and interpretation of the results.\n \nThe properties of BN used as motivation for the study, are observed non-asymptotically with constant or empirically decreased learning rate schedules for a limited number of iterations. In contrast, the studied learning rates are asymptotic and there is a big discrepancy. SGD is observed to be significantly faster than batch gradient when far from convergence (experimental evidence), and this is with or without normalization. In practice, the training is stopped much before convergence, in the hope of finding solutions close to minimum with high probability. There is in fact no experimental evidence that the practical advantages of BN are relevant to the results proven. It makes a nice story that the theoretical properties justify the observations, but they may be as well completely unrelated. \n\nAs seen from the formal construction, the theoretical results apply equally well to all normalization methods. It occludes the clarity that BN is emphasized amongst them. \n\nConsidering theoretically, what advantages truly follow from the paper for optimizing a given function? Let’s consider the following cases.\n1. For optimizing a general smooth function with all parameters forming a single scale-invariant vector. In this case, the paper proves that no careful selection of the learning rate is necessary. This result is beyond machine learning and unfortunately I cannot evaluate its merit. Is it known / not known in optimization?\n\n2. The case of data-independent normalization (such as weight normalization).\nWithout normalization, we have to tune learning rate to achieve the optimal convergence. With normalization we still have to tune the learning rate (as scale-variant parameters remain or are reintroduced with each invariance to preserve the degrees of freedom), then we have to wait for the phase two of Lemma 3.2 so that the learning rate of scale-invariant parameters adapts, and from then on the optimal convergence rate can be guaranteed.\n\n3. The case of Batch Normalization. Note that there is no direct correspondence between the loss of BN-normalized network (2) and the loss of the original network because of dependence of the normalization on the batches. In other words, there is no setting of parameters of the original network that would make its forward pass equivalent to that of BN network (2) for all batches. The theory tells the same as in case 2 above but with an additional price of optimizing a different function.\n\nThese points remain me puzzled regarding either practical or theoretical application of the result. It would be great if authors could elaborate. \n\n\n-- Difference from Wu et al. 2018\n\nThis works is cited as a source of inspiration in several places in the paper. As the submission is a theoretical result with no immediate applicability, it would be very helpful if the authors could detail the technical improvements over this related work. Note, ICLR policy says that arxiv preprints earlier than one month before submission are considered a prior art. Could the authors elaborate more on possible practical/theoretical applications?\n \n\n* Side Notes (not affecting the review recommendation)\n\nI believe that the claim that “BN reduces covariate shift” (actively discussed in the intro) was an imprecise statement in the original work. Instead, BN should be able to quickly adapt to the covariate shift when it occurs. It achieves this by using the parameterization in which the mean and variance statistics of neurons (the quantities whose change is called the covariate shift) depend on variables that are local to the layer (gamma, beta in (1)) rather than on the cumulative effect of all of the preceding layers.\n\n* Revision\nI took into account the discussion and the newly added experiments and increased the score. The experiments verify the proven effect and make the paper more substantial. Some additional comments about experiments follow.\nTraining loss plots would be more clear in the log scale.\nComparison to ""SGD BN removed"" is not fair because the initialization is different (application of BN re-initializes weight scales and biases). The same initialization can be achieved by performing one training pass with BN with 0 learning rate and then removing it, see e.g. Gitman, I. and Ginsburg, B. (2017). Comparison of batch normalization and weight normalization algorithms for the large-scale image classification.\nThe use of Glorot uniform initializer is somewhat subtle. Since BN is used, Glorot initialization has no effect for a forward pass. However, it affects the gradient norm. Is there a rationale in this setting or it is just a more tricky method to fix the weight norm to some constant, e.g. ||w||=1?\n\n', 'The paper is well written and easy to follow. The topic is apt.\n\nI don’t have any comments except the following ones.\n\nLemma 2.4, Point 1: The proof is confusing. Consider the one variable vector case. Assuming that there is only one variable w, then \\nabla L(w) is not perpendicular to w in general. The Rayleigh quotient example L(w)  = w’*A*w/ (w’*w) for a symmetric matrix A, then \\nabla L(w) = (2/w’*w)(Aw - L(w)*w), which is not perpendicular to w. \nEven if we constrain ||w ||_2 = 1, then also  \\nabla L(w)  is not perpendicular to w.\nAm I missing something?\n\nWhat is G_t in Theorem 2.5. It should be defined in the theorem itself. There is another symbol G_g which is a constant.\n', ""* Strengths:\n- The paper gives theoretical insight into why Batch Normalization is useful in making neural network training more robust and is therefore an important contribution to the literature.\n- While the actual arguments are somewhat technical as is expected from such a paper, the motivation and general strategy is very easy to follow and insightful.\n\n* Weaknesses:\n- The bounds do not immediately apply in the batch normalization setting as used by neural network practitioners, however there are practical ways to link the two settings as pointed out in section 2.4\n- As the authors point out, the idea of using a batch-normalization like strategy to set an adaptive learning rate has already been explored in the WNGrad paper. However it is valuable to have a similar analysis closer to the batch normalization setting used by most practitioners.\n- Currently there is no experimental evaluation of the claims, which would be valuable given that the setting doesn't immediately apply in the normal batch normalization setting. I would like to see evidence that the main benefit from batch normalization indeed comes from picking a good adaptive learning rate.\n\nOverall I recommend publishing the paper as it is a well-written and insightful discussion of batch normalization. Be aware that I read the paper and wrote this review on short notice, so I didn't have time to go through all the arguments in detail.""]","[-20, 50, 70]","[60, 75, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the technical merit of the work ('non-trivial theoretical results that are worth to be published'), they express significant concerns about its practical relevance and applicability. The reviewer states that the paper has 'weak relevance to practice' and that 'the applicability of the obtained results is unclear'. They also raise several critical points and express confusion about the practical implications.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They acknowledge the strengths of the paper ('technically correct and technically clear') and frame their criticisms as 'concerns' rather than outright flaws. The language used is constructive, such as 'It would be great if authors could elaborate' and 'Could the authors elaborate more on possible practical/theoretical applications?'. The reviewer also notes that they increased their score after considering new experiments, showing a willingness to reconsider their initial assessment.\n\nOverall, while the review expresses significant concerns, it does so in a polite and constructive manner, balancing criticism with acknowledgment of the paper's strengths."", ""The sentiment score is 50 (slightly positive) because the reviewer starts with positive comments about the paper being 'well written and easy to follow' and the topic being 'apt'. However, they then proceed to point out some specific issues, which balances out the initial positivity. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, starts with positive feedback, and phrases their criticisms as questions or suggestions rather than direct criticisms. For example, they ask 'Am I missing something?' when pointing out a potential error, which is a polite way of raising concerns. The reviewer also uses phrases like 'Consider' when making suggestions, which is a courteous way to provide feedback."", ""The sentiment score is 70 (positive) because the review starts with highlighting the strengths of the paper, noting its importance and insightfulness. The reviewer recommends publishing the paper, which is a strong positive signal. However, it's not 100 because there are some weaknesses mentioned and suggestions for improvement. The politeness score is 80 (very polite) because the reviewer uses respectful language throughout, acknowledges the value of the work even when pointing out weaknesses, and ends with a humble note about the quick turnaround of the review. The tone is constructive and supportive, avoiding harsh criticism.""]"
"['This paper discusses the effect of weight decay on the training of deep network models with and without batch normalization and when using first/second order optimization methods. \n\nFirst, it is discussed how weight decay affects the learning dynamics in networks with batch normalization when trained with SGD. The dominant generalization benefit due to weight decay comes from increasing the effective learning rate of parameters on which batch normalization is applied. The authors therefore hypothesize that a larger learning rate has a regularization effect.\n\nSecond, the role of weight decay is discussed when training with second order methods without batch normalization. Under the approximation of not differentiating the curvature matrix used in second order method, it is shown that using weight decay is equivalent to adding to the loss an L2 regularization in the metric space of the curvature matrix considered. It is then shown that if the curvature matrix is the Gauss-Newton matrix, this L2 regularization (and hence the weight decay) is equivalent to the Frobenius norm of the input-output Jacobian when the input has a spherical Gaussian distribution. Similar arguments are made about KFAC with Gauss-Newton norm. The generalization benefit due to weight decay in this case is claimed based on the recent paper by Novak et al 2018 which empirically shows a strong correlation between input-output Jacobian norm and generalization error.\n\n\nFinally, the role of weight decay is discussed for second order methods when using batch normalization. In this case it is discussed for Gauss-Newton KFAC that the benefit mostly comes from the application of weight decay on the softmax layer and the effect of weight decay on other weights cancel out due to batch normalization. A comparison between Gauss-Newton KFAC and Fischer KFAC is also made. Thus the generalization benefit is presumably attributed to the second order properties of KFAC and a smaller norm of softmax layer weights.\n\nComments:\nThe paper is technically correct and proofs look good.\n\nI have mixed comments about this paper. I find the analysis in section 4.2 and 4.3 which discuss about the role of weight decay for second order methods (with and without batch-norm) to be novel and insightful (described above). \n\nBut on the other hand, I feel section 4.1 is more of a discussion on existing work rather than novel contribution. Most of what is said, both analytically and experimentally, is a repetition of van Laarhoven 2017, except for a few details. It would have been interesting to carefully study the effect of weight decay on the gamma parameter of batch-norm which controls the complexity of the network along with the softmax layer weights as it was left for future work in van Laarhoven 2017. But instead the authors brush it under the carpet by saying they did not find the gamma and beta parameters to have significant impact on performance, and fixed them during training.  I also find the claim of section 4.1 to be a bit mis-leading because it is claimed that weight decay applied with SGD and batch normalization only has benefits due to batch-norm dynamics, and not due to complexity control even though in Fig 2 and 4, there is a noticeable difference between training without weight decay, and training with weight decay only on last layer. Furthermore, when hypothesizing the regularization effect of large learning rate in section 4.1, a large body of literature that has studied this effect has not been cited. Examples are [1], [2], [3]. \n\nI have other concerns which mainly stem from lack of clarity in writing:\n\n1. In the line right above remark 1, it is not clear what “assumption” refer to. I am guessing the distribution of the input being spherical Gaussian?\n2. In remark 1, regarding the claim about the equivalence of L2 norm of theta under Gauss-Newton metric and the Frobenius norm of input-output Jacobian, why does f_theta need to be a linear function without any non-linearity? I think the linearity part is only needed for the KFAC result.\n3. In remark 1, what does it mean by “Furthermore, if G is approximated by KFAC”? For linear f_theta, given lemma 1 and theorem 1, the claimed equivalence always holds true, no?\n4. In the 1st line of last paragraph of page 6, what are the general conditions under which the connection between Gauss-Newton norm and Jacobian norm does not hold true?\n5. In figure 5, how are the different points in the plots achieved? By varying hyper-parameters?\n\nA minor suggestion: in theorem 1 (and lemma 1), instead of assuming network has no bias, it can be said that the L2 regularization term does not have bias terms. This is more reasonable because bias terms have no effect on complexity and so it is reasonable to not apply weight decay on bias.\n\nOverall I think the paper is good *if* section 4.1 is sorted out and writing (especially in section 4.2) is improved. For these reasons, I am currently giving a score of 6, but I will increase it if my concerns are addressed.\n\n[1] a bayesian perspective on generalization and stochastic gradient descent\n[2] Train longer, generalize better: closing the generalization gap in large batch training of neural networks\n[3] Three Factors Influencing Minima in SGD', 'This paper identifies and investigates three mechanisms of weight decay regularization. The authors consider weight decay for DNN architectures with/without BN and different types of optimization algorithms (SGD, Adam, and two versions of KFAC). The paper unravels insights on weight decay regularization effects, which cannot be explained only by traditional L2 regularization approach. This understanding is of high importance for the further development of regulations techniques for deep learning.\n\nStrengths:\n+ The authors draw connections between identified mechanisms and effects observed in prior work.\n+ The authors provide both clear theoretical analysis and adequate experimental evidence supporting identified regularization mechanisms.\n+ The paper is organized and written clearly.\n\nI cannot point out any flaws in the paper. The only recommendation I would give is to discuss in more detail possible implications of the observed results for new methods of regularization in deep learning and potential directions for future work. It would emphasize the significance of the obtained results.', 'I have read the author\'s response, and I would like to stick to my rating. From the authors\' response on the convergence issue, the result from [1] does not directly apply since the activation function that the authors use in this paper is relu (not linear). Having said that, authors didn\'t find any issues empirically.\n\nQ7: Yes, I agree that the result depends on the gradient structure of the relu activations. But my point was that, it is still a calculation that one has to carry out, and the insight we gain from the calculation seem computational: that one can regularize jacobian norm easily. True, but is that necessary? Or in other words, can we use techniques (not-so) recent  implicit regularization literature to analyze KFAC? I still think that the work is good, these are just my questions.\n====\n\nThe paper investigates how weight decay (according to the authors, this is done by scaling weights at each iteration) can be used as a regularizer while using standard first order methods and KFAC. As far as I can see, the experimental conclusion seem pretty consistent with other papers that the authors themselves cite (for eg: Neelakantan et al. (2015);  Martens & Grosse, 2015. \n\nIn page 2, the authors mention the three different mechanisms by which weight decay has a regularizing effect. First, what is the definition of ""effective learning rate""? If the authors mean that regularization just changes the learning rate in some case, that is true. In fact, it is only true while using l2-norm. I looked through the paper, and I couldn\'t find one. Similarly, I find point #1. to be confusing: why does reducing the scale of the weights increase the effective learning rate? (This confusion carries over to/remains in section 4.1.). The sentence starting (in point #1.) with ""As evidence,"", what is the evidence for? Is it for the previous statement that weight decay helps as a regularizer? Looking at Figure 1., Table 1., I can see that weight decay is actually helpful even with BN+D. In fact, the improvement provided by weight decay is uniform across the board. \n\nThe conclusion of mechanism 1 is that for layers with BN, weight decay is implicitly using higher learning rate and not by limiting the capacity as pointed out by van Laarhoven (2017). The two paragraphs below (12) are contradictory or I\'m missing something: first paragraph says that ""This is contrary to our intuition that weight decay results in a simple function."" but immediately below, ""We show empirically that weight decay only improves generalization by controlling the norm, and therefore the effective learning rate."" Can the authors please explain what the ""effective learning rate"" argument is?\n\nProposition 1 and theorem 1 are extensions from Martens & Gross, 2015, I didn\'t fully check the calculations. I glanced through them, and they mostly use algebraic manipulations. The main empirical takeaway as the authors mention is that: weight decay in both KFAC-F and KFAC-G serves as a complexity regularizer which sounds trivial (assuming Martens & Grosse, 2015) since in both of these cases, BN is not used and the fact that weight decay is regularization using the local norm. \n\nIf I understand correctly, KFAC is an approximate second order method with the approximation chosen to be such that it is invariant under affine transformations. Are there any convergence guarantees at all for either of these approaches? Newton\'s method, even for strongly convex loss functions, requires self-concordance to ensure convergence, so I\'m a bit skeptic when using approximate (stochastic) Jacobian norm. \n\nSome of the plots have loss values, some have accuracy etc., which is also confusing while reading. I strongly suggest that Figure 1 be shown differently, especially the x-axis! Essentially weight decay improves the accuracy about 2-4% but it is hard to interpret that from the figure.\n']","[20, 90, -20]","[60, 80, 30]","[""The sentiment score is slightly positive (20) because while the reviewer has some criticisms, they overall find the paper 'good' and parts of it 'novel and insightful'. They give it a score of 6 out of 10 with potential to increase. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as 'concerns' or 'suggestions'. They avoid harsh language and maintain a professional tone. However, it's not extremely polite as they do directly state criticisms and areas needing improvement."", ""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer praises the paper's insights, importance, theoretical analysis, and experimental evidence. They explicitly state they 'cannot point out any flaws in the paper.' The only suggestion is for additional discussion, which is framed as a recommendation rather than a criticism. The politeness score is 80 because the language used is respectful and constructive throughout. The reviewer uses phrases like 'The authors draw connections' and 'The paper is organized and written clearly,' which are polite ways of giving praise. The suggestion for improvement is phrased gently as a recommendation, further indicating politeness. The review maintains a professional and courteous tone throughout."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper ('the work is good', 'experimental conclusion seem pretty consistent'), they raise several critical points and express skepticism about some claims and methodologies. The reviewer points out confusing explanations, contradictions, and areas needing clarification, indicating an overall cautious and somewhat critical stance. The politeness score is moderately positive (30) as the reviewer maintains a professional tone throughout, using phrases like 'Can the authors please explain' and 'I strongly suggest', which are polite ways of offering criticism. The reviewer also acknowledges positive aspects and frames many criticisms as questions or suggestions rather than direct attacks. However, the language is not overly deferential, maintaining a balance between politeness and directness appropriate for peer review.""]"
"['This is an experimental paper that investigates how spatial ordering of patches influences the classification performances of CNNs. To do so, the authors design CNNs close to ResNets that almost only consist in a simple cascade of 1x1 convolutions, obtaining relatively small receptive field. It is an interesting read, and I recommend it as a valuable contribution to ICLR, that might lead to nice future works.\n\nI have however several comments and questions, that I would like to be addressed.\n\n1) First I think a reference is missing. Indeed, to my knowledge, it is not the first work to use this kind of techniques. Cf [1]. This does not alterate however the novelty of the approach.\n\n2) « We construct a linear DNN-based BoF » : I do not like this formulation. Here, you assume that you build a ResNet-50 with 1x1 as a representation and have a last final linear layer as a classifier. One could also claim it is a ResNet-48 as a representation followed by 2 layers of 1x1 as a classifier.\n\n3) « our proposed model architecture is simpler » this is very subjective because for instance the FV models are learned in a layer-wise fashion, which makes their learning procedure more interpretable because each layer objective is specified. Furthermore, analyzing these models is now equivalent to analyze a cascade of fully connected layers, which is not simple at all.\n\n4) Again, the interpretability mentioned in Sec. 3  is in term of spatial localization, not mapping. I think it is important to make clear this consideration. Indeed, this work basically leaves the problem of understanding general CNNs to the problem of understanding MLPs.\n\n5) The graphic of the Appendix A is a bit misleading : it seems 13 downsampling are performed whereas it is not the case, because the first element of each group of block is actually only done once.(if I understood correctly)\n\n6) I think the word feature is sometimes mis-used: sometimes it seems it can refer to a patch, sometimes to the code for a patch. (« Surprisingly, feature sizes assmall as 17 × 17 pixels »)\n\nI got also few questions:\nQ1 : I was wondering if you did try manifold learning on the patches ? Do you expect it to work ?\nQ2 : Is there a batch normalization in the FC or a normalization? Did you try to threshold the heat maps before feeding them to the linear layer? I\'m wondering indeed if the amplitude of those heatmaps is really key.\nQ3 : do you think it would be easy to exploit the non-overlapping patches for a better parallelization of computations ?\n\nFinally, I find very positive the amount of experiments to test the similarity with standard CNNs. Of course, it’s far from being a formal proof, but I think it is a very nice first step.\n\n[1] Oyallon, Edouard, Eugene Belilovsky, and Sergey Zagoruyko. ""Scaling the scattering transform: Deep hybrid networks."" International Conference on Computer Vision (ICCV). 2017.', 'This paper suggests a novel and compact neural network architecture which uses the information within bag-of-words features. The proposed algorithm only uses the patch information independently and performs majority voting using independently classified patches. The proposed method provides the state-of-the-art prediction accuracy unexpectedly, and several additional experiments show the state-of-the-art neural networks mainly learn without association between information in different patches.\n\nThe proposed algorithm is simple and does not provide completely new idea, but this paper has a clear contribution connecting the previous main idea of feature extraction, bag-of-words, and the prevailing blackbox algorithm, CNN. The results in the paper are worth to be shared in the community and need further investigated.\n\nThe presented experiments look fair and reasonable to show the importance of the independent patch information (without association between them), and the presented experimental results show some state-of-the-art methods also perform with independent patch information. \n\nComparison with attention models is necessary to compare the important patches obtained from conventional networks.\n', 'The idea of image classification based on patch-level deep feature in the BoF model has been studied extensively.  \n\n Just list few of them:\n\nWei et al. HCP: A Flexible CNN Framework for Multi-label Image Classification, IEEE TPAMI 2016\nTang et al. Deep Patch Learning for Weakly Supervised Object Classification and Discovery, Pattern Recognition 2017\nTang et al. Deep FisherNet for Object Classification, IEEE TNNLS\nArandjelović et al. NetVLAD: CNN Architecture for Weakly Supervised Place Recognition, CVPR 2016\n\nThe above papers are not cited in this paper.\n\nThere are some unique points. This work does not use RoIPooling layer and has results on ImageNet. But, the previous works use RoIPooling layer to save computations and works on scene understanding images, such as PASCAL. \n\nBesides, the paper uses the smallest patch among all the patch-based deep networks. It is interesting.\n\nI highly encourage the authors to finetune the ImageNet pre-trained BagNet on PASCAL VOC and compare to the previous patch-based deep networks.\n']","[60, 70, -20]","[80, 80, 50]","[""The sentiment score is 60 (positive) because the reviewer recommends the paper as a 'valuable contribution' and finds it 'interesting', despite having several comments and questions. The overall tone is constructive and encouraging. The politeness score is 80 (quite polite) due to the reviewer's use of respectful language throughout, such as 'I would like to be addressed' and 'I think'. They offer criticisms in a gentle manner, using phrases like 'I do not like this formulation' instead of more harsh language. The reviewer also acknowledges positive aspects, like the 'amount of experiments', which contributes to the polite tone."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its novel approach, state-of-the-art results, and clear contribution to the field. The reviewer notes that while the algorithm is simple and not completely new, it's worth sharing and investigating further. The politeness score is 80 (polite) as the reviewer uses respectful and constructive language throughout. They acknowledge the paper's strengths and provide suggestions for improvement without harsh criticism. The tone is professional and encouraging, using phrases like 'worth to be shared' and 'need further investigated', which indicate respect for the authors' work while still offering guidance for enhancement."", ""The sentiment score is slightly negative (-20) because the reviewer points out that the idea has been extensively studied and lists several papers that were not cited, implying a lack of novelty. However, they do acknowledge some unique points and interesting aspects of the work. The politeness score is moderately positive (50) as the language used is professional and constructive. The reviewer uses phrases like 'I highly encourage' and notes interesting aspects, which maintains a respectful tone. They provide specific suggestions for improvement without harsh criticism.""]"
"['This paper proposes learning exploration policies for navigation. The problem is motivated well. The learning is conducted using reinforcement learning, bootstrapped by imitation learning. Notably, RL is done using sensor-derived intrinsic rewards, rather than extrinsic rewards provided by the environment. The results are good.\n\nI like this paper a lot. It addresses an important problem. It is written well. The approach is not surprising but is reasonable and is a good addition to the literature.\n\nOne reservation is that the method relies on an oracle for state estimation. In some experiments, synthetic noise is added, but this is not a realistic noise model and the underlying data still comes from an oracle that would not be available in real-world deployment. I recommend that the authors do one of the following: (a) use a real (monocular, stereo, or visual-inertial) odometry system for state estimation, or (b) acknowledge clearly that the presented method relies on unrealistic oracle odometry.\n\nEven with this reservation, I support accepting the paper.\n\nMinor: In Section 3.4, ""existing a room"" -> ""exiting a room""', 'This is a well explained and well executed paper on using classical SLAM-like 2D maps for helping a standard Deep RL navigation agent (convnet + LSTM) explore efficiently an environment and without the need for extrinsinc rewards. The agent relies on 3 convnets, one processing RGB images, one the image of a coarse map in egocentric referential, and one of the image of a fine-grained map in egocentric referential (using pre-trained ResNet-18 convnets). Features produced by the convnets are fed into a recurrent policy trained using PPO. Two rewards are used: the increase in the map\'s coverage and an obstacle avoidance penalty. The agent is further bootstrapped through imitation learning in a goal-driven task executed by a human controlling the agent. The authors analyze the behavior of the navigation algorithm by various ablations, a baseline consisting of Pathak\'s (2017) Intrinsic Curiosity Module-based navigation and, commendably, a classical SLAM baseline with path planning to empty, unexplored spaces.\n\nUsing an explicit map is a great idea but the authors need to acknowledge how hand-engineered all this is, when comparing it to actual end-to-end methods. First, the map reconstruction is done by back-projections of a depth image (using known projective geometry parameters) onto a 3D point cloud, then by slicing it to get a 2D map, accumulated over time using nearly perfect odometry. SLAM was an extremely hard problem to start with, and it took decades and particle filters to get to the quality of the images shown in this paper as obvious. Normally, there is drift and catastrophic map errors, whereas the videos show a nearly perfect map reconstruction. Is the motion model of the agent unrealistic? Would this ever work out of the box on a robot in a real world? The authors brush off the need for bundle adjustment, saying that the convnet can handle noisy local maps. Second, how do you get and maintain such nice ego-centric maps? Compared to other end-to-end work on learning how to map (see Wayne et al. or Zhang et al. or Parisotto et al., referred to later in the paper), it looks like the authors took a giant shortcut. All this SLAM apparatus should be learned!\n\nOne crucial baseline that is missing is that of explicit extrinsic rewards encouraging exploration. These rewards merely scatter reward-yielding objects throughout the environment; over the course of an episode, an object reward that is picked does not re-appear until the next exploration episode, meaning that the agent needs to cover the whole space to forage for rewards. Examples of such rewards have been published in Mnih et al. (2016) ""Asynchronous methods for deep reinforcement learning"" and are implemented in DeepMind Lab (Beatie et al., 2016). Such an extrinsic reward would be directly related to the increase of coverage.\n\nA second point of discussion that is missing is that of the collision avoidance penalty: roboticists working on SLAM know well that they need to keep their robot away from plain-texture walls, otherwise the image processing cannot pick useful features for visual odometry, image matching or ICP. What happens if that penalty is dropped in this navigation agent?\n\nFinally, the authors mention the Neural Map paper but do not discuss Zhang et al. (2017) ""Neural SLAM"" or Wayne et al. (2018) ""Unsupervised Predictive Memory in a Goal-Directed Agent"", where a differentiable memory is used to store map information over the course of an episode and can store information relative to the agent\'s position and objects\' / obstacles\' positions as well.\n\nMinor remark: the word ""finally"" is repeated twice at the end of the introduction.', 'This paper proposes a method for learning how to explore environments. The paper mentions that the “exploration task” that is defined in this paper can be used for improving the well-known navigation tasks. For solving this task, a reward function a network architecture that uses RGBD images + reconstructed map + imitation learning + PPO is designed.\n\n<<Pros>>\n\n-The paper is well-written (except for a few typos).\n-The overall approach is simple and does not have much complications. \n-The underling idea and motivation is clearly narrated in the intro and abstract and the paper has a easy-to-understand flow.  \n\n<<Cons>>\n\n**The technical novelty is not significant**\n\n-This paper does not provide significant technical novelty. It is a combination of known prior methods: imitation learning + ppo (prior RL work). The presented exploration task is not properly justified as to how it could be useful for the navigation task. The reconstruction of maps for solving the navigation problem is a well-explored problem in prior SLAM and 3D reconstruction methods. Overall the novelty of the approach and the proposed problem is incremental. \n\n**The paper has major short comings in the experimental section. The presented experiments do not support the main claim of the paper which is improving the performance in the well-known navigation task. Major baselines are missing. Also, the provided results are not convincing in doing the right comparison with the baselines. **\n\n-Experimental details are missing. The major experimental evaluations (Fig. 2 and Fig. 3) are based on the m^2 coverage after k steps and the plots are cut at 1000 steps. What are the statistical properties of the 3D houses used for training and testing? E.g what is their area in m^2? How big is each step in meters?  Why are the graphs cut at 1000 steps? How would different methods converge after more than 1000 steps, e.g. 2000 steps? I would like to see how would the different methods converge after larger number of steps? How long would each step take in terms of time? How could these numbers convey the significance of the proposed method in a real would problem settings? \n\n-The experiments do not convey if learning has significantly resulted in improved exploration. Consider a simple baseline that follows a similar approach as explained in the paper for constructing the occupancy map using the depth sensor. A non-learning agent could use this map at each step to make a greedy choice about its next action which greedily maximizes the coverage gain based on its current belief of the map. While the performance of random policy is shown in Fig.2 the performance of this greedy baseline is a better representative of the lower bound of the performance on the proposed task and problem setup.\n\n-What is the performance of a learning-based method that only performs collision avoidance? Collision avoidance methods tend to implicitly learn to do a good map coverage. This simple baseline can show a tangible lower bound of a learning-based approach that does not rely on map.\n\n-The major promise of the paper is that the proposed exploration task can improve navigation. However, the navigation experiment does not compare the proposed method with any of prior works in navigation. There is a huge list of prior methods for navigation some of which are cited in the “learning for Navigation” section of the related works and the comparison provided in Fig. 4 is incomplete compared to the state-of-the-arts in navigation. For example, while the curiosity driven approach is compared for the exploration, the more related curiosity based navigation method which uses both “exploration strategy” and “imitation learning” : “Pathak, Deepak, et al. ""Zero-shot visual imitation.""\xa0International Conference on Learning Representations. 2018.\n“ is missed in navigation comparison. The aforementioned paper is also missed in the references.  \n\n-Algorithmic-wise, it would make the argument of the paper clearer if results were conducted by running different exploration strategies for navigation to see if running RL with a good exploration strategy could solve the exploration challenge of the navigation problem without needing an explicit exploration stage (similar to the proposed method) which first explores and constructs the map and then does navigation by planning.\n\n-The navigation problem as explained in section is solved based on planning approach that uses a reconstructed map. This is a fairly conventional approach that SLAM based methods use. Therefore, comparison with a SLAM method that constructs the map and then does navigation would be necessary. \n\n\n** Technical details are missing or not explained clearly**\n\n- Section 3.1 does not clearly explain the map construction. It seems that the constructed map is just a 2D reconstruction of the space (and not 3D) using the depth sensor which does not need transformation of the 3D point cloud. What is the exact 3D transformation that you have done using the intrinsic camera parameters? This section mentions that there can be error in such map reconstruction because of robot noise but alignment is not needed because the proposed learning method provides robustness against miss-alignment. How is this justified? Why not using the known loop closure techniques in SLAM? \n\n-The technical details about the incorporated imitation learning method are missing. What imitation learning method is used? How is the policy trained during the imitation learning phase? \n\n-Last paragraph of intro mentions that the proposed method uses 3D information efficiently for doing exploration. The point of this sentence is unclear. What 3D information is used efficiently in the paper? Isn’t it only 2.5D (information obtained by depth sensor) used in the proposed method?\n\n**Presentation can be improved**\n\n-The left and right plots of the Figure 3 contains lots of repetitions which brings in confusion in comparing the performance of runs with different settings. These two plots should be presented in a single plot. \n\n- Interpretation of “green vs white vs black” in the reconstructed maps is left to the reader in Fig. 1. \n\n- Last line in page 5: there is no need for reiteration. It is already clear.\n\n**Missing references**\n\n-Since the paper is about learning to explore, discussion about “exploration techniques in RL” is recommended to be added in at least the related work section. \n\n-A big list papers for 3D map reconstruction is missing. Since the proposed method relies on a map reconstruction, those papers are relevant to this work and can potentially be used for comparison (as explained above). It is highly recommended that relevant prior 3D map reconstruction papers be added to the related work sections. \n\n\n']","[80, 50, -60]","[90, 75, 20]","[""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, stating 'I like this paper a lot' and 'I support accepting the paper.' They praise the paper's motivation, writing, and results. The only reservation mentioned is presented constructively and doesn't significantly detract from the overall positive sentiment. The politeness score is 90 (very polite) due to the reviewer's consistently respectful and encouraging tone. They use phrases like 'I like this paper' and offer constructive feedback in a non-confrontational manner. The reviewer also balances critique with praise and provides clear, helpful suggestions for improvement. The language is professional and courteous throughout, without any harsh or rude comments."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by praising the paper as 'well explained and well executed,' and commends the authors for including a classical SLAM baseline. However, the reviewer also raises several significant concerns and points out missing elements, which balances out the initial positive sentiment. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the strengths of the paper, and frames criticisms as suggestions or areas for improvement rather than direct attacks. Phrases like 'the authors need to acknowledge,' 'One crucial baseline that is missing,' and 'A second point of discussion that is missing' are constructive and polite ways of pointing out shortcomings. The reviewer also uses phrases like 'commendably' and 'great idea' to soften critiques and acknowledge positive aspects."", ""The sentiment score is -60 because the review is predominantly negative. While it starts with some positive comments about the paper being well-written and having a clear flow, the majority of the review focuses on significant criticisms. These include lack of technical novelty, major shortcomings in the experimental section, missing technical details, and inadequate comparisons with baselines and state-of-the-art methods. The cons significantly outweigh the pros, indicating a negative overall sentiment.\n\nThe politeness score is 20 because the reviewer maintains a professional and objective tone throughout. They use neutral language to express criticisms, such as 'The technical novelty is not significant' and 'Experimental details are missing,' rather than using harsh or personal language. The reviewer also acknowledges some positive aspects of the paper at the beginning. However, the score is not higher because the review is quite direct in its criticisms and doesn't use many softening phrases or overtly polite language.""]"
"['The fundamental idea proposed in this paper is a sensible one:  design the functional form of a policy so that there is an initial parameterized stage that operates on perceptual input and outputs some ""symbolic"" (I\'d be happier if we could just call them ""discrete"") characterization of the input, and then an arbitrary program that operates on the symbolic output of the first stage.\n\nMy fundamental problem is with equation 3.  If you want to talk about the factoring of the probability distribution p(a | s) that\'s fine, but, to do it in fine detail, it should be:\nP(a | s) = \\sum_sigma P(a, sigma | s) = \\sum_sigma P(a | sigma, s) * P(sigma | s)\nAnd then by conditional independence of a from s given sigma\n = \\sum_sigma P(a | sigma) * P(sigma | s)\nBut, critically, there needs to be a sum over sigma!  Now, it could be that I am misunderstanding your notation and you mean for p(a | sigma) to stand for a whole factor and for the operation in (3) to be factor multiplication, but I don\'t think that\'s what is going on.\n\nThen, I think, you go on to assume, that p(a | sigma) is a delta distribution.  That\'s fine.\n\nBut then equation 5 in Theorem 1 again seems to mention delta without summing over it, which still seems incorrect to me.\n\nAnd, ultimately, I think the theorem doesn\'t make sense because the transformation that the program performs on its input is not included in the gradient computation.  Consider the case where the program always outputs action 0 no matter what its symbolic input is.   Then the gradient of the log prob of a trajectory with respect to theta should be 0, but instead you end up with the gradient of the log prob of the symbol trajectory with respect to theta.\n\nI got so hung up here that I didn\'t feel I could evaluate the rest of the paper.  \n\nOne other point is that there is a lot of work that is closely related to this at the high level, including papers about Value Iteration Networks, QMDP Networks, Particle Filter Networks, etc.  They all combine a fixed program with a parametric part and differentiate the whole transformation to do gradient updates.  It would be important in any revision of this paper to connect with that literature.', 'This paper proposes the perceptor gradients algorithm to learn symbolic representations for devising autonomous agent policies to act.\nThe perceptor gradients algorithm decomposes a typical policy into a perceptor network that maps observations to symbolic representations and a user-provided task encoding program which is executed on the perceived symbols in order to generate an action. Experiments show the proposed approach achieves faster learning rates compared to methods based solely on neural networks and yields transferable task related symbolic representations. The results prove the programmatic regularisation is a general technique for structured representation learning. Although the reviewer is out of the area in this paper, this paper seems to propose a novel algorithm to learn the symbolic representations.', 'The high-level problem this paper tackles is that of learning symbolic representations from raw noisy data, based on the hypothesis that symbolic representations that are grounded in the semantic content of the environment are less susceptible to overfitting.\n\nThe authors propose the perceptor gradients algorithm, which decouples the policy into 1) a perceptor network that maps raw observations to domain-specific representations, which are inputs to 2) a pre-specified domain-specific control or planning program. The authors claim that such a decomposition is general enough to accommodate any task encoding program.\n\nThe proposed method is evaluated on three experiments: a simple control task (cartpole-balancing), a navigation task (minecraft: go to pose), and a stochastic single-object retrieval task (minecraft: collect wood). The authors show that the perceptor gradients algorithm learns much faster than vanilla policy gradient. They also show that the program provides an inductive bias that helps ground the representations to the true state of the agent by manually inspecting the representations and by reconstructing the representation into a semantically coherent scene.\n\nThis paper is clear and well-written and I enjoyed reading it. It proposes a nice perspective of leveraging programmatic domain knowledge and integrating such knowledge with a learned policy for planning and control. If the following concerns were addressed I would consider increasing my score.\n\n1. To what extent do the experiments support the authors\' claims: Although the existing experiments are very illustrative and clear, they did not seem to me to illustrate that the learned representations are transferable as the authors claimed in the introduction. This perhaps is due to the ambiguous definition of ""transferable;"" it would be helpful if the authors clarified what they mean by this. Nevertheless, as the paper suggests in the introduction that symbolic representations are less likely to overfit to the training distribution, I would be interested to see an experiment that illustrates the capability of the program-augmented policy to generalize to new tasks. For example, Ellis et al. [1] suggested that the programs can be leveraged to extrapolate to problems not previously seen in the input (e.g. by running the for loop for more iterations). To show the transferability of such symbolic representations, is it possible for the authors to include an experiment to show to what extent the perceptor gradients algorithm can generalize to new problems? For example, is it possible for the proposed approach to train on ""Minecraft: Go to Pose"" and generalize to a larger map? Or is it possible for the proposed approach to train on one wood block and generalize to more wood blocks?\n2. Experiment request: The paper seems to suggest that the ""Minecraft: Go to Pose"" task and the ""Minecraft: Collect Wood"" task were trained with an autoencoding perceptor. To more completely assess to what extent the program is responsible for biasing the representations to be semantically grounded in environment, would the authors please provide ablation experiments (learning curves, and visualization of the representations) for these two tasks where only the encoder was used?\n3. Question: I am a bit confused by the beta-VAE results in Figure 4. If the beta-VAE is trained to not only reconstruct its input as well as perform a ""linear regression between the learnt latent space and the ground truth values"" (page 6), then I would have expected that the latent space representations to match the ground truth values much more closely. Would the authors be able to elaborate more on the training details and objective function of the beta-VAE and provide an explanation for why the learned latent space deviates so far from the ground truth?\n5. Related work: \n    a) The paper briefly discusses representation learning in computer vision and physical dynamics modeling. However, in these same domains it lacks a discussion of approaches that do use programs to constrain learned representations, as in [1-3]. Without this discussion, my view is that the related work would be very incomplete because program-induced constraints are core to this paper. Can the authors please provide a more thorough and complete treatment of this area?\n    b) The approaches that this paper discusses for representation learning have been around for quite a long time, but it seems rather a misrepresentation of the related work to have all but two citations in the Related Work section 2017 and after. For example, statistical constraints on the latent space have been explored in [4-5]. Can the authors please provide a more thorough and complete treatment of the related work?\n6. Possible limitation: A potential limitation for decoupling the policy in this particular way is that if the perceptor network produced incorrect representations that are fed into the program, the program cannot compensate for these errors. It would be helpful for the authors to include a discussion about this in paper.\n7. How does this scale? As stated in the intro, the motivation for this work is for enabling autonomous agents to learn from raw visual data. Though the experiments in this paper were illustrative of the approach, these experiments assumed that the agent had access to the true state variables of its environment (like position and velocity), and the perceptor network is just inferring the particular values of these variables for a particular problem instance. However, presumably the motivation for learning from raw visual data is that the agent does not have access to the simulator of the environment. How do the authors envision their proposed approach scaling to real world settings where the true state variables are unknown? There is currently not an experiment that shows a need for learning from raw visual data. This is a major concern, because if the only domains that the perceptor gradients algorithm can be applied are those where the agent already has access to the true state variables, then there may be no need to learn from pixels in the first place. This paper would be made significantly stronger with an experiment where 1) learning from raw visual data is necessary (for example, if it is the real world, or if the true state variables were unknown) and 2) where the inductive bias provided by the program helps significantly on that task in terms of learning and transfer. Such an experiment would decisively reflect the paper\'s claims.\n8. Clarity: The paper mentions that it is possible to generate new observations from the latent space. The paper can be made stronger by a more motivated discussion of why generating new observations is desirable, beyond just as a visualization tool. For example, the authors may consider making a connection with the analysis-by-synthesis paradigm that characterizes the Helmholtz machine.\n\n[1] Ellis et al. (https://arxiv.org/pdf/1707.09627.pdf)\n[2] Wu et al. (http://papers.nips.cc/paper/6620-learning-to-see-physics-via-visual-de-animation.pdf)\n[3] Kulkarni et al. (https://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Kulkarni_Picture_A_Probabilistic_2015_CVPR_paper.html)\n[4] Schmidhuber (ftp://ftp.idsia.ch/pub/juergen/factorial.pdf)\n[5] Bengio et al. (https://arxiv.org/abs/1206.5538)']","[-50, 70, 50]","[20, 50, 80]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the paper's methodology, particularly equation 3 and Theorem 1. The reviewer states they 'got so hung up here that I didn't feel I could evaluate the rest of the paper,' indicating a major issue. However, the review isn't entirely negative as it acknowledges the fundamental idea as 'sensible.' The politeness score is 20 because the reviewer uses respectful language throughout, such as 'I'd be happier if...' and 'My fundamental problem is...', showing consideration for the authors. The reviewer also offers constructive criticism and suggestions for improvement, like connecting with related literature. However, the tone is more neutral than overtly polite, hence the moderate positive score."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, noting that it proposes a 'novel algorithm' and achieves 'faster learning rates'. The reviewer also states that the results 'prove' the effectiveness of the technique. However, it's not extremely positive as the reviewer admits to being 'out of the area'. The politeness score is 50 (slightly polite) because the language is professional and respectful, without being overly formal or effusive. The reviewer uses neutral language and focuses on the content of the paper rather than making personal comments. The phrase 'seems to propose' adds a slight hedge, which can be seen as polite caution."", ""The sentiment score is 50 (slightly positive) because the reviewer begins by stating they enjoyed reading the paper and found it clear and well-written. They also mention that they would consider increasing their score if certain concerns were addressed, indicating a generally positive but cautious stance. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as requests or questions, and offers constructive feedback. They use phrases like 'would the authors please' and 'it would be helpful if' which maintain a polite tone. The review is thorough and detailed, offering specific suggestions for improvement without being harsh or dismissive.""]"
"['The paper proposes a dimensionality reduction method that embeds data into a product manifold of spherical, Euclidean, and hyperbolic manifolds. The proposed algorithm is based on matching the geodesic distances on the product manifold to graph distances. I find the proposed method quite interesting and think that it might be promising in data analysis problems. Here are a few issues that would be good to clarify:\n\n- Could you please formally define K in page 3?\n\n- I find the estimation of the signature very interesting. However, I am confused about how the curvature calculation process is (or can be) integrated into the embedding method proposed in Algorithm 1. How exactly does the sectional curvature estimation find use in the current results? Is the “Best model” reported in Table 2 determined via the sectional curvature estimation method? If yes, it would be good to see also the Davg and mAP figures of the best model in Table 2 for comparison.\n\n- I think it would also be good to compare the results in Table 2 to some standard dimensionality reduction algorithms like ISOMAP, for instance in terms of Davg. Does the proposed approach bring advantage over such algorithms that try to match the distances in the learnt domain with the geodesic distances in the original graph?\n\n- As a general comment, my feeling about this paper is that the link between the different contributions does not stand out so clearly. In particular, how are the embedding algorithm in Section 3.1, the signature estimation algorithm in Section 3.2, and the Karcher mean discussed in Section 3.3 related? Can all these ideas find use in an overall representation learning framework? \n\n- In the experimental results in page 7, it is argued that the product space does not perform worse than the optimal single constant curvature spaces. The figures in the experimental results seem to support this. However, I am wondering whether the complexity of learning the product space should also play a role in deciding in what kind of space the data should be embedded in. In particular, in a setting with limited availability of data samples, I guess the sample error might get too high if one tries to learn a very high dimensional product space.  \n\n\nTypos: \n\nPage 3: Note the “analogy” to Euclidean products\nPage 7 and Table 1: I guess “ring of cycles” should have been “ring of trees” instead\nPage 13: Ganea et al formulates “basic basic” machine learning tools …', '\nPage 2: What are p_i, i=1,2,...,n, their set T and \\mathcal{P}?\n\nWhat is | | used to compute distortion between a and b?\n\nPlease fix the definition of the Riemannian manifold, such that M is not just any manifold, but should be a smooth manifold or a particular differentiable manifold. Please update your definition more precisely, by checking page 328 in J.M. Lee, Introduction to Smooth Manifolds, 2012, or Page 38 in do Cormo, Riemannian Geometry, 1992.\n\nPlease define \\mathcal{P} in equation (1).\n\nDefine K used in the definition of the hyperboloid more precisely.\n\nPlease provide proofs of these statements for product of manifolds with nonnegative and nonpositive curvatures: “In particular, the squared distance in the product decomposes via (1). In other words, dP is simply the l2 norm of the component distances dMi.”\n\nPlease explain what you mean by “without the need for optimization” in “These distances provide simple and interpretable embedding spaces using P, enabling us to introduce combinatorial constructions that allow for embeddings without the need for optimization.” In addition, how can you compute geodesic etc. if you use l1 distance for the embedded space?\n\nBy equation (2), the paper focuses on embedding graphs, which is indeed the main goal of the paper. Therefore, first, the novelty and claims of the paper should be revised for graph embedding. Second, three particular spaces are considered in this work, which are the sphere, hyperbolic manifold, and Euclidean space. Therefore, you cannot simply state your novelty for a general class of product spaces. Thus, the title, novelty, claims and other parts of the paper should be revised and updated according to the particular input and output spaces of embeddings considered in the paper. \n\nPlease explain how you compute the metric tensor  g_P and apply the Riemannian correction (multiply by the inverse of the metric tensor g_P) to determine the Riemannian gradient in the Algorithm 1, more precisely. \n\nStep (9) of the Algorithm 1 is either wrong, or you compute v_i without projecting the Riemannian gradient. Please check your theoretical/experimental results and code according to this step.\n\nWhat is h_i used in the Algorithm 1? Can we suppose that it is the ith component of h?\n\nIn step (6) and step (8), do you project individual components of the Riemannian gradient to the product manifold? Since their dimensions are different, how do you perform these projections, since definitions of the projections given on Page 5 cannot be applied? Please check your theoretical/experimental results and code accordingly.\n\nPlease define exp_{x^(t)_i}(vi) and Exp(U) more precisely. I suppose that they denote exponential maps.\n\nHow do you initialize x^(0) randomly?\n\nThe notation is pretty confusing and ambiguous. First, does x belong to an embedded Riemannian manifold P or a point on the graph, which will be embedded? According to equation (2), they are on the graph and they will be embedded. According to Algorithm 1, x^0 belongs to P, which is a Riemannian manifold as defined before. So, if x^(0) belongs to P, then L is already defined from P to R (in input of the Algorithm 1). Thereby, gradient \\nabla L(x) is already a Riemannian gradient, not the Euclidean gradient, while you claim that \\nabla L(x) is the Euclidean gradient in the text.\n\nOverall, Algorithm 1 just performs a projection of Riemannian or Euclidean gradient  \\nabla L(x) onto a point v_i for each ith individual manifold. Then, each v_i is projected back to a point on an individual component of the product manifold by an exponential map. \n\nWhat do you mean by “sectional curvature, which is a function of a point p and two directions x; y from p”? Are x and y not points on a manifold?\n \nYou define \\xi_G(m;b,c) for curvature estimation for a graph G. However, the goal was to map G to a Riemannian manifold. Then, do you also consider that G is itself a Riemannian manifold, or a submanifold?\n\nWhat is P in the statement “the components of\nthe points in P” in Lemma 2?\n\nWhat is \\epsilon in Lemma 2?\n\nHow do you optimize positive w_i, i=1,2,...,n?\n\nWhat is the “gradient descent” refered to in Lemma 2?\n\nPlease provide computational complexity and running time of the methods.\n\nPlease define \\mathbb{I}_r.\n\nAt the third line of the first equation of the proof of Lemma 1, there is no x_2. Is this equation correct?\n\nIf at least of two of x1, y1, x2 and y2 are linearly dependents, then how does the result of Lemma 1 change?\n\nStatements and results given in Lemma 1 are confusing. According to the result, e.g. for K=1, curvature of product manifold of sphere S and Euclidean space E is 1, and that of E and hyperbolic  H is 0. Then, could you please explain this result for the product of S, E and H, that is, explain the statement “The last case (one negative, one positive space) follows along the same lines.”? If the curvature of the product manifold is non-negative, then does it mean that the curvature of H is ignored in the computations?\n\nWhat is \\gamma more precisely? Is it a distribution or density function? If it is, then what does (\\gamma+1)/2 denote?\n\nThe statements related to use of Algorithm 1 and SGD to optimize equation (2) are confusing. Please explain how you employed them together in detail.\n\nCould you please clarify estimation of K_1 and K_2, if they are unknown. More precisely, the following statements are not clear;\n\n- “Furthermore, without knowing K1, K2 a priori, an estimate for these curvatures can be found by matching the distribution of sectional curvature from Algorithm 2 to the empirical curvature computed from Algorithm 3. In particular, Algorithm 2 can be used to generate distributions, and K1, K2 can then be found by matching moments.” Please explain how in more detail? What is matching moments?\n\n- “we find the distribution via sampling (Algorithm 3) in the calculations for Table 3, before being fed into Algorithm 2 to estimate Ki” How do you estimation K_1 and K_2 using Algorithm 3?\n\n- Please define, “random (V)”, “random neighbor m” and “\\delta_K/s” used in Algorithm 3 more precisely.\n', 'This paper proposes a new method to embed a graph onto a product of spherical/Euclidean/hyperbolic manifolds. The key is to use sectional curvature estimations to determine proper signature, i.e., all component manifolds, and then optimize over these manifolds. The results are validated on various synthetic and real graphs. The proposed idea is new, nontrivial, and is well supported by experimental evidence.']","[50, -50, 90]","[80, 20, 50]","[""The sentiment score is 50 (slightly positive) because the reviewer finds the proposed method 'quite interesting' and 'promising', but also raises several questions and issues to be addressed. This indicates a generally positive view with some reservations. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions (e.g., 'Could you please...', 'I think it would be good to...'), and even points out typos in a helpful manner. The tone is constructive and collaborative rather than harsh or dismissive."", ""The sentiment score is -50 because the review is predominantly critical, pointing out numerous issues and requesting many clarifications and revisions. However, it's not entirely negative as it doesn't outright reject the paper, but rather seeks improvements. The politeness score is 20 because while the reviewer maintains a professional tone and uses polite language like 'Please' frequently, the review is quite direct and doesn't use many softening phrases. The reviewer asks questions and makes requests in a straightforward manner, which is appropriate for a scientific review but not overtly polite. The lack of any positive comments or acknowledgment of the paper's strengths also slightly reduces the perceived politeness."", ""The sentiment score is 90 (highly positive) because the reviewer describes the paper's proposed method as 'new, nontrivial, and well supported by experimental evidence.' These are strong positive descriptors in academic review contexts. The reviewer also mentions that the results are 'validated on various synthetic and real graphs,' which further supports the positive sentiment. The politeness score is 50 (moderately polite) because while the language is professional and respectful, it doesn't contain explicitly polite phrases. The tone is neutral and factual, which is appropriate for a scientific review, but not overtly courteous. The reviewer focuses on the merits of the work without using unnecessarily flowery or overly formal language.""]"
"['This paper proposes fine-tuning an out-of-distribution detector using an Outlier Exposure (OE) dataset. The novelty is in proposing a model-specific rather than dataset-specific fine-tuning. Their modifications are referred to as Outlier Exposure. OE includes the choice of an OE dataset for fine-tuning and a regularization term evaluated on the OE dataset. It is a comprehensive study that explores multiple datasets and improves dataset-specific baselines.\n\nSuggestions and clarification requests:\n- The structure of the writing does not clearly present the novel aspects of the paper as opposed to the previous works. I suggest moving the details of model-specific OE regularization terms to section 3 and review the details of the baseline models. Then present the other set of novelties in proposing OE datasets in a new section before presenting the results. Clearly presenting two sets of novelties in this work and then the results. If constrained in space, I suggest squeezing the discussion, conclusion, and 4.1.\n- In the related work section Radford et al., 2016 is references when mentioning GAN. Why not the original reference for GAN?\n- Maybe define BPP, BPC, and BPW in the paragraphs on PixelCNN++ and language modeling or add a reference.\n- Numbers in Table 3 column MSP should match the numbers in Table 1, right? Or am I missing something?', 'This paper describes how a deep neural network can be fine-tuned to perform outlier detection in addition to its primary objective. For classification, the fine-tuning objective encourages out-of-distribution samples to have a uniform distribution over all class labels. For density estimation, the objective encourages out-of-distribution samples to be ranked as less probability than in-distribution samples. On a variety of image and text datasets, this additional fine-tuning step results in a network that does much better at outlier detection than a naive baseline, sometimes approaching perfect AUROC.\n\nThe biggest weakness in this paper is the assumption that we have access to out-of-distribution data, and that we will encounter data from that same distribution in the future. For the typical anomaly detection setting, we expect that anomalies could look like almost anything. For example, in network intrusion detection (a common application of anomaly detection), future attacks are likely to have different characteristics than past attacks, but will still look unusual in some way. The challenge is to define ""normal"" behavior in a way that captures the full range of normal while excluding ""unusual"" examples. This topic has been studied for decades.\n\nThus, I would not classify this paper as an anomaly detection paper. Instead, it\'s defining a new task and evaluating performance on that task. The empirical results demonstrate that the optimization succeeds in optimizing the objective it was given. What\'s missing is the justification for this problem setting -- when is it the case that we need to detect outliers *and* have access to the distribution over outliers?\n\n--------\n\nUPDATE AFTER RESPONSE PERIOD:\n\nMy initial read of this paper was incorrect -- the authors do indeed separate the outlier distribution used to train the detector from the outlier distribution used for evaluation. Much of these details are in Appendix A; I suggest that the authors move some of this earlier or more heavily reference Appendix A when describing the methods and introducing the results. I am not well-read in the other work in this area, but this looks like a nice advance.\n\nBased on my read of the related work section (again, having not studied the other papers), it looks like this work fills a slightly different niche from some previous work. In particular, OE is unlikely to be adversarially robust. So this might be a poor choice for finding anomalies that represent malicious behavior (e.g., network intrusion detection, adversarial examples, etc.), but good for finding natural examples from a different distribution (e.g., data entry errors).\n\nMy main remaining reservation is that this work is still at the stage of empirical observation -- I hope that future work (by these authors or others) can investigate the assumptions necessary for this method to work, and even characterize how well we should expect it to work. Without a framework for understanding generalization in this context, we may see a proliferation of heuristics that succeed on benchmarks without developing the underlying principles.', 'I have read authors\' reply.  In response to authors\' comprehensive reply and feedback. I upgrade my score to 6. As authors mentioned, the extension to density estimators is an original novelty of this paper, but I still have some concern that OE loss for classification is basically the same as [2]. I think it is better to clarify this in the draft. \n\nSummary===\n\nThis paper proposes a new fine-tuning method for improving the performance of existing anomaly detectors. The main idea is additionally optimizing the “Outlier Exposure (OE)” loss on outlier dataset. Specifically, for softmax classifier, the authors set the OE loss to the KL divergence loss between posterior distribution and uniform distribution. For density estimator, they set the OE loss to a margin ranking loss. The proposed method improves the detection performance of baseline methods on various vision and NLP datasets. While the research topic of this paper is interesting, I recommend rejections because I have concerns about novelty and the experimental results.\n\nDetailed comments ===\n\n1. OE loss for softmax classifier\n\nFor softmax classifier, the OE loss forces the posterior distribution to become uniform distribution on outlier dataset. I think this loss function is very similar to a confidence loss (equation 2) proposed in [2]: Lee et al., 2017 [2] also proposed the loss function minimizing the KL divergence between posterior distribution and uniform distribution on out-of-distribution, and evaluated the effects of it on ""unseen"" out-of-distribution (see Table 1 of [2]). Could the authors clarify the difference with the confidence loss in [2], and compare the performance with it? Without that, I feel that the novelty of this paper is not significant.\n\n2. More comparison with baselines\n\nThe authors said that they didn’t compare the performance with simple inference methods like ODIN [3] since ODIN tunes the hyper-parameters using data from (tested) out-of-distribution. However, I think that the authors can compare the performance with ODIN by tuning the hyper-parameters of it on outlier dataset which is used for training OE loss. Could the authors provide more experimental results by comparing the performance with ODIN? \n\n3. Related work\n\nI would appreciate if the authors can survey and compare more baselines such as [4] and [5]. \n\n[1] Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-of-distribution examples in neural networks. International Conference on Learning Representations, 2017. \n[2] Kimin Lee, Honglak Lee, Kibok Lee, and Jinwoo Shin. Training confidence-calibrated classifiers for detecting out-of-distribution samples. International Conference on Learning Representations, 2018. \n[3] Shiyu Liang, Yixuan Li, and R. Srikant. Enhancing the reliability of out-of-distribution image detection in neural networks. International Conference on Learning Representations, 2018. \n[4] Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A Simple Unified Framework for Detecting Out-of-Distribution Samples and Adversarial Attacks. In NIPS, 2018.\n[5] Apoorv Vyas, Nataraj Jammalamadaka, Xia Zhu, Dipankar Das, Bharat Kaul, and Theodore L. Willke. Out-of-Distribution Detection Using an Ensemble of Self Supervised Leave-out Classifiers, In ECCV, 2018.']","[60, 20, -20]","[80, 60, 50]","[""The sentiment score is 60 (positive) because the reviewer describes the paper as a 'comprehensive study' that 'improves dataset-specific baselines'. The overall tone is constructive and appreciative of the work. However, it's not extremely positive as the reviewer suggests several improvements. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, framing their suggestions as 'requests for clarification' rather than criticisms. They use phrases like 'I suggest' which is polite and non-confrontational. The reviewer also acknowledges space constraints, showing consideration for the authors' situation. The language is professional and constructive throughout, without any harsh or rude comments."", ""The sentiment score is slightly positive (20) because while the reviewer initially points out weaknesses and expresses reservations, they later update their review to acknowledge their initial misunderstanding and recognize the paper as a 'nice advance'. The overall tone shifts from critical to cautiously optimistic. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges their own misunderstanding, and offers constructive feedback. They use phrases like 'I suggest' and 'I hope' which maintain a collegial tone even when expressing concerns. The reviewer also takes care to contextualize their expertise, noting they are 'not well-read in the other work in this area', which shows humility and respect for the authors' work."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting research topic', 'improves detection performance'), they ultimately recommend rejection due to concerns about novelty and experimental results. The reviewer upgrades their initial score but still expresses reservations. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, makes suggestions politely ('I would appreciate if...', 'Could the authors...'), and acknowledges the authors' efforts in responding to feedback. The reviewer maintains a professional tone while clearly stating their concerns and recommendations for improvement.""]"
"['I enjoyed reading this manuscript. The paper is based on a simple idea used by others as well (i.e., the image has two components, one  that encode content which is shared across domains and another one characterizing the domain specific style). The other important idea is the use of feature masks that steer the translation process without requiring semantic labels. This is similar to attention models used by others but I think it is novel when applying to this specific application domain. I was a bit disappointed by the evaluation part. The authors decided to perform ablation and to show the importance of each component using only the MNIST-Single dataset. While this is good as a toy example I would have expected to see such analysis on a more complex example, e.g., street-view translation. This is also surprising considering that it is not even present in the supplementary material. Overall, this is a solid submission with interesting ideas and good implementation.   ', ""The introduction is written to perfection. The paper discusses a core failing and need for I2I translation models. The one-to-one mapping assumption does not apply to most tasks. While the approach seems novel the analysis of the results are insufficient to convince me that the method is really working. This should be a workshop paper.\n\nFor the motivation of the approach I am not convinced how the conditioned style is being used. It would be nice to see some analysis of how the latent space changes given different input images. Why would style information be propagated through the network? Why wouldn't noise work just as well? Although an abiliation study is performed there is no standard deviation reported so it is unclear if this number is fair. \n\nIn Figure 5 the t-sne doesn't look correct. The points all seems to be projected on walls which could indicate some sort of overflow error. The text only devotes 3 lines to discuss this figure. It is not mentioned what part of the model the t-sne is computed from. To me this experiment that studies the internal representation is critical to convincing a reader to use this method. \n\nThe segmentation results sound good. Where is the improvement coming from? The experimental section is cut short. The experiment section is really squeezed in the last two pages while the other sections are overly descriptive and could be reduced.\n\nThe figures should be changed to be visible without color (put a texture on each block).\n"", 'The paper is well organized with a clear idea of the proposed method and good related work descriptions. Overall, the descriptions are clear and easy to follow, but the experimental results need clarifying.\n\n- Regarding the multi-digit translation task, it is not straightforward to this reviewer how the proposed method could match the digits (semantic) with different colors (style) in different locations. The description in the paper is not enough to explain the results in Fig. 6. To this reviewer, this task is more complex than the street view translation one. In the same line, it is curious what the results would be if digits with different colors are overlapping at random location, rather than the grid-like arrangement.\x00\n\n- For the potential readers who are not knowledgeable in semantic segmentation, please give the full name of mIoU for reference. \n\n- For further researches in this topic, it would be good to depict the limitations of the proposed method. For examples, the translated images in the CelebA dataset are not photorealistic (Fig. 8)  and there are odd red lights in the middle of the results in GTA5<-BDD (Fig. 12).\n\n- typos: Fig. 2-caption: m_{a}->m_{A}']","[70, -30, 50]","[80, 20, 80]","[""The sentiment score is 70 (positive) because the reviewer expresses enjoyment in reading the manuscript, praises the paper's ideas as interesting, and describes it as a 'solid submission'. However, it's not 100 due to the expressed disappointment in the evaluation part. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticism constructively. The reviewer begins with positive feedback, uses phrases like 'I enjoyed reading' and 'interesting ideas', and even when expressing disappointment, does so in a mild manner ('I was a bit disappointed'). The overall tone is professional and courteous."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges some positive aspects ('The introduction is written to perfection', 'The segmentation results sound good'), they express significant concerns about the analysis, results, and presentation of the paper. The reviewer suggests it should be a workshop paper, which implies it's not ready for full publication. They also point out several areas needing improvement or clarification.\n\nThe politeness score is slightly positive (20) because the reviewer maintains a professional tone throughout. They use phrases like 'It would be nice to see' and 'To me this experiment... is critical' rather than making harsh demands. The criticism is presented as constructive feedback rather than outright dismissal. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a mostly neutral, professional tone."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by praising the paper's organization and clarity, but then points out several areas that need improvement or clarification. This balanced approach suggests a moderately positive sentiment. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, such as 'please give' and 'it would be good to,' and frames criticisms as suggestions or requests for clarification rather than direct criticisms. The reviewer also acknowledges their own perspective with phrases like 'To this reviewer,' which adds to the polite tone. The review maintains a professional and constructive tone throughout, offering specific recommendations for improvement without being harsh or dismissive.""]"
"['Overall:\nThis paper works on improving the gradient estimator of the ELBO. Author experimentally found that the estimator of the existing work(STL) is biased and proposed to reduce the bias by using the technique like  REINFORCE.\nThe problem author focused on is unique and the solution is simple, experiments show that proposed method seems promising.\n\nClarity:\nThe paper is clearly written in the sense that the motivation of research is clear, the derivation of the proposed method is easy to understand.\n\nSignificance:\nI think this kind of research makes the variational inference more useful, so this work is significant. But I cannot tell the proposed method is really useful, so I gave this score.\nThe reason I doubt the reason is that as I written in the below, the original STL can handle the mixture of Gaussians as the latent variable but the proposed method cannot. So I do not know which is better and whether I should use this method or use the original STL with flexible posterior distribution to tighten the evidence lower bound. I think additional experiments are needed. I know that motivation is a bit different for STL and proposed method but some comparisons are needed.\n\nQuestion and minor comments:\nIn the original paper of STL, the author pointed out that by freezing the gradient of variational parameters to drop the score function term, we can utilize the flexible variational families like the mixture of Gaussians.\nIn this work, since we do not freeze the variational parameters, we cannot utilize the mixture of Gaussians as in the STL. IWAE improves the lower bound by increasing the samples, but we can also improve the bound by specifying the flexible posteriors like the mixture of Gaussians in STL.\nFaced on this, I wonder which strategy is better to tighten the lower bound, should we use the STL with the mixture of Gaussians or use the proposed method?  \nTo clarify the usefulness of this method, I think the additional experimental comparisons are needed.\n\nAbout the motivation of the paper, I think it might be better to move the Fig.1 about the Bias to the introduction and clearly state that the author found that the STL is biased ""experimentally"".\n\nFollowings are minor comments.\nIn experiment 6.1, I\'m not sure why the author present the result of K ELBO estimator in the plot of Bias and Variance.\nI think author want to point that when K=1, STL is unbiased with respect to the 1 ELBO, but when k>1, it is biased with respect to IWAE estimator.\nHowever, the objective of K ELBO and IWAE are different, it may be misleading. So this should be noted in the paper.\n\nIn Figure 3, the left figure, what each color means? Is the color assignment is the same with the middle figure?\n(Same for Figure 4)', 'The paper observes the gradient of multiple objective such as IWAE, RWS, JVI are in the form of some “reward” multiplied with score function which can be calculated with one more reparameterization step to reduce the variance. The whole paper is written in a clean way and the method is effective.\n\nI have following comments/questions:\n\n1. The conclusion in Eq(5) is correct but the derivation in Sec. 8.1. may be arguable. Writing \\phi and \\tilde{\\phi} at the first place sets the partial derivative of \\tilde{\\phi}  to \\phi as 0. But the choice of \\tilde{\\phi} in the end is chosen as \\phi. If plugging  \\phi to \\tilde{\\phi}, the derivation will change. The better way may be calculating both the reparameterization and reinforce gradient without redefining a \\tilde{\\phi}.\n\n2. How does the variance of gradient calculated where the gradient is a vector? And how does the SNR defined in the experiments?\n\n3. How does the variance reduction from DReG changes with different value of K?\n\n4. Is there any more detailed analysis or intuition why the right hand side of Eq(5) has lower variance than the left hand side?', ""This paper applies a reparameterization trick to estimate the gradients objectives encountered in variational autoencoder based frameworks with continuous latent variables.  Especially the authors use this double reparameterization trick on Importance Weighted Auto-Encoder (IWAE) and Reweighted Wake-Sleep (RWS)  methods. Compared to IWAE, the developed method's SNR does not go to zero with increasing the number of particles.\n\nOverall, I think the idea is nice and the results are encouraging. I checked all the derivations, and they seem to be correct. Thus I recommend this paper to be accepted in its current form.""]","[50, 70, 80]","[80, 80, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the uniqueness of the problem, the simplicity of the solution, and the promising experimental results. However, they also express some doubts about the method's usefulness compared to existing techniques, which prevents a higher score. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, offers constructive feedback, and frames their criticisms as questions or suggestions rather than direct criticisms. They also acknowledge the paper's clarity and significance. The reviewer maintains a professional and courteous tone while providing detailed feedback and recommendations for improvement."", ""The sentiment score is 70 (positive) because the reviewer starts by praising the paper as 'written in a clean way' and the method as 'effective'. This indicates a generally positive view of the work. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, framing their comments as questions or suggestions rather than criticisms. For example, they use phrases like 'I have following comments/questions' and 'The better way may be...' which are constructive and polite ways of providing feedback. The reviewer also acknowledges the correctness of the authors' conclusions while suggesting potential improvements, which is a balanced and courteous approach to peer review."", ""The sentiment score is 80 (positive) because the reviewer states that 'the idea is nice and the results are encouraging,' and recommends the paper to be accepted in its current form. This indicates a strong positive sentiment towards the paper. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledging the authors' work and providing a clear, professional assessment. The reviewer doesn't use overly formal or excessively polite language, but maintains a courteous tone. The lack of criticism or suggestions for improvement, which is unusual in peer reviews, contributes to the politeness score as it avoids potentially confrontational language.""]"
"['This paper studied data poisoning attacking for graph neural networks. The authors proposed treating graph structures as hyperparameters and leveraged recent progress on meta-learning for optimizing the adversarial attacks. Different from some recent work on adversarial attacks for graph neural networks (Zuigner et al. 2018; Dai et al. 2018), which focus on attacking specific nodes, this paper focuses on attacking the  overall performance of graph neural networks. Experiments on a few data sets prove the effectiveness of the proposed approach. \n\nStrength:\n- the studied problem is very important and recently attracting increasing attention\n- Experiments show that the proposed method is effective.\n\nWeakness:\n- the complexity of the proposed method seems to be very high\n- the data sets used in the experiments are too small\nDetails:\n-- the complexity of the proposed method seems to be very high. The authors should explicitly discuss the complexity of the proposed method. \n-- the data sets in the experiments are too small. Some large data sets would be much more compelling.\n-- Are the adversarial examples identified by the proposed method transferrable to other graph embedding algorithms (e.g., the unsupervised node embedding methods, DeepWalk, LINE, and node2vec)?\n-- I like Figure 3, though some concrete examples would be more intuitive. ', ""This paper studies the problem of learning a better poisoned graph parameters that can maximize the loss of a graph neural network. The proposed using meta-learning to compute the second-order derivatives to get the meta-gradients seems reasonable. The authors also proposed approximate methods to compute the graph as learning parameters, which could be more efficient since the second-order derivatives are no longer computed. The experimental results on three graph datasets show that the proposed model could improve the misclassification rate of the unlabeled nodes.\n\nThe paper is well-written. It would be good if the authors could address the following suggestions or concerns:\n\n1) The proposed attack model assumes the only the graph structure are accessiable to the attackers, which might limit the proposed model in real applications. Joint study with the graph features would be useful to convince more audience and potentially have larger impacts.\n\n2) In the self-learning setting, in order to define l_atk, l_self is used, however, l_self is using v_u, which is the ground truth label of the test nodes based on my understanding, so this approach is using labels of the unlabeled data, which might be not applicable in real world.\n\n3) About the action space, based on the constraints of the attacker's capability, the possible attacks will be significantly smaller than O(N^2 delta), might be O(N^delta).\n\n4) Change 'treat the graph structure as a hyperparameter' to 'treat the graph structure tensor/matrix as a hyperparameter' would be earier to understand. And is the graph structure tensor with shape (NXN)? \n\n5) What's the relationship between T and S? Are T in theta_T is the same as the S in G_S?\n\n6) The title of section 4.2 is misleading. It would be better to name it as 'Greedy Computing Meta-Gradients'. \n\n7) It lacks intuition of why define S(u,v)=delta . (-2.a_uv+1). '(-2.a_uv+1)' looks lack of intuition. Please also change 'pair (i,j), we define S(u,v)' -> 'pair (u,v)'.\n\n8) In the experiments, what's the definition of meta-train? l_atk=-l_train?\n\n9) In the experiments, it would be interesting to study the impact of unnoticaability constraints on the model results.\n\n10) In figure 1, it is not surprising that when increasing the number of edges changed, the misclassification rates will increase. A graph NN considers more graph features rather than the structure is expected to show the impact of the graph structure change.\n\nI have read the authors' detailed rebuttal. Thanks."", 'This paper proposes an algorithm to alter the structure of a graph by adding/deleting edges so as to degrade the global performance of node classification. The main idea is to use the idea of meta-gradients from meta-learning to solve the bilevel optimization problem. \n\nThe paper is clearly presented. The main contribution is to use meta-learning to solve the bilevel optimization in the discrete graph data using greedy selection approach. From the experimental results, this treatment is really effective in attacking the graph learning models (GCN, CLN, DeepWalk). However, the motivation in using meta-learning to solve the bilevel optimization is not very clear to me, e.g., what are the advantages it can offer?\n\nTheoretically, the paper could have given some discussion on the optimality of the meta-gradient approach to bilevel optimization to strengthen the theoretical aspect. For the greedy selection approach in Eq (8), is there any sub-modularity for the score function used?\n\nSome minor suggestions and comments:\n1) please summarize the attacking procedures in the form of an algorithm\n2) please have some discussion on attacking the graph attributes besides the structure\n3) please have an complexity analysis and empirical evaluations of the meta-gradient computations and approximations']","[50, 50, 50]","[70, 80, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the importance of the studied problem and the effectiveness of the proposed method. However, they also point out significant weaknesses, creating a balanced view. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offers constructive criticism, and even compliments aspects of the work (e.g., 'I like Figure 3'). The reviewer presents weaknesses as areas for improvement rather than harsh criticisms, and uses phrases like 'the authors should' instead of more demanding language."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and reasonable approach, stating it is 'well-written' and shows improvement in misclassification rates. However, they also provide several suggestions and concerns, indicating room for improvement. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, such as 'It would be good if the authors could address...' and 'Thanks' at the end. They frame their comments as suggestions rather than demands and acknowledge the authors' rebuttal. The tone is constructive and professional throughout."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's clear presentation and effectiveness of the proposed method, but also raises some questions and suggests improvements. The reviewer notes the paper's main contribution and its effectiveness in experimental results, which are positive points. However, they also mention areas where the paper could be improved or clarified, indicating a balanced view.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They begin by acknowledging the paper's strengths and use phrases like 'please' when making suggestions. The critique is presented as questions or areas for improvement rather than direct criticisms. The tone remains professional and courteous throughout, even when pointing out potential weaknesses or areas for additional work.""]"
"['*Summary :\nThe paper explores variants of popular adaptive optimization methods.\nThe idea is to clip the magnitude of the gradients from above and below in order to prevent too aggressive/conservative updates.\nThe authors provide regret bound to this algorithm in the online convex setting and perform several illustrative experiments.\n\n\n*Significance:\n-There is not much novelty in Theorems 1,2,3 since similar results already appeared in Reddi et al.\n\n-Also, the theoretical part does not demonstrate the benefit of the clipping idea. Concretely, the regret bounds seem to be similar to the bounds of AMSBound.\nIdeally, I would like to see an analysis that discusses a situation where AdaGrad/AMSBound fail or perfrom really bad, yet the clipped versions do well.\n\n-The experimental part on the other hand is impressive, and the results illustrate the usefulness of the clipping idea.\n\n*Clarity:\nThe idea and motivation are very clear and so are the experiments.\n\n\n*Presentation:\nThe presentation is mostly good.\n\nSummary of review:\nThe paper suggests a simple idea to avoid extreme behaviour of the learning rate in standard adaptive methods. The theory is not so satisfying, since it does not illustrate the benefit of the method over standard adaptive methods. The experiments are more thorough and illustrate the applicability of the method.\n\n', ""The authors introduce AdaBound, a method that starts off as Adam but eventually transitions to SGD. The motivation is to benefit from the rapid training process of Adam in the beginning and the improved convergence of SGD at the end. The authors do so by clipping the weight updates of Adam in a dynamic way. They show numerical results and theoretical guarantees. The numerical results are presented on CIFAR-10 and PTB while the theoretical results are shown on assumptions similar to AMSGrad (& using similar proof strategies). As it stands, I have some foundational concerns about the paper and believe that it needs significant improvement before it can be published. I request the authors to please let me know if I misunderstood any aspect of the algorithm, I will adjust my rating promptly. I detail my key criticisms below:\n\n- I'm somewhat confused by the formulation of \\eta_u and \\eta_l. The way it is set up (end of Section 4), the final learning rate for the algorithm converges to 0.1 as t goes to infinity. In the Appendix, the authors show results also with final convergence to 1. Are the results coincidental with the fact that SGD works well with those learning rates? It is a bit odd that we indirectly encode the final learning rate of the algorithm into the \\eta s. \n\n- Am I correct in saying that with t=100 (i.e., the 100th iteration), the \\eta s constrain the learning rates to be in a tight bound around 0.1? If beta=0.9, then \\eta_l(1) = 0.1 - 0.1 / (0.1*100+1) = 0.091. After t=1000 iterations, \\eta_l becomes 0.099. Again, are the good results coincidental with the fact that SGD with learning rate 0.1 works well for this setup? In the scheme of the 200 epochs of training (equaling almost 100-150k iterations), if \\eta s are almost 0.099 / 0.10099, for over 99% of the training, we're only doing SGD with learning rate 0.1. \n\n- Along the same lines, what learning rates on the grid were chosen for each of the problems? Does the setup still work if SGD needs a small step size and we still have \\eta converge to 1? A VGG-11 without batch normalization typically needs a smaller learning rate than usual; could you try the algorithms on that? \n\n- Can the authors plot the evolution of learning rate of the algorithm over time? You could pick the min/median/max of the learning rates and plot them against epochs in the same way as accuracy.This would be a good meta-result to show how gradual the transition from Adam to SGD is. \n \n- The core observation of extreme learning rates and the proposal of clipping the updates is not novel; Keskar and Socher (which the authors cite for other claims) motivates their setup with the same idea (Section 2 of their paper). I feel that the authors should clarify what they are proposing as novel. Is it correct that a careful theoretical analysis of this framework is what stands as the authors' major contribution?\n\n- Can you try experimenting with/suggesting trajectories for \\eta which converge to SGD stepsize more slower? \n\n- Similarly, can you suggest ways to automate the choice for the \\eta^\\star? It seems that the 0.1 in the numerator is an additional hyperparameter that still might need tuning? \n"", 'This paper presents new variants of ADAM and AMSGrad that bound the gradients above and below to avoid potential negative effects on generalization of excessively large and small gradients; and the paper demonstrates the effectiveness on a few commonly used machine learning test cases.  The paper also presents detailed proofs that there exists a convex optimization problem for which the ADAM regret does not converge to zero.\n\nThis paper is very well written and easy to read.  For that I thank the authors for their hard word.  I also believe that their approach to bound is well structured in that it converges to SGD in the infinite limit and allows the algorithm to get teh best of both worlds - faster convergence and better generalization.  The authors\' experimental results support the value of their proposed algorithms.  In sum, this is an important result that I believe will be of interest to a wide audience at ICLR.\n\nThe proofs in the paper, although impressive, are not very compelling for the point that the authors want to get across.  That fact that such cases of poor performance can exists, says nothing about the average performance of the algorithms, which is practice is what really matters.\n\nThe paper could be improved by including more and larger data sets.  For example, the authors ran on CIFAR-10.  They could have done CIFAR-100, for example, to get more believable results.\n\nThe authors add a useful section on notation, but go on to abuse it a bit.  This could be improved.  Specifically, they use an ""i"" subscript to indicate the i-th coordinate of a vector and then in the Table 1 sum over t using i as a subscript.  Also, superscript on vectors are said to element-wise powers.  If so, why is a diag() operation required?  Either make the outproduct explicit, or get rid of the diag().']","[20, -50, 80]","[50, 50, 90]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the impressive experimental results and clear presentation, they express concerns about the lack of novelty in the theoretical part and its failure to demonstrate the benefits of the clipping idea. The overall tone is balanced, recognizing both strengths and weaknesses. The politeness score is moderately positive (50) as the reviewer uses respectful and professional language throughout, offering constructive criticism without harsh or rude phrasing. They use phrases like 'I would like to see' when suggesting improvements, which maintains a polite tone. The review is objective and focuses on the content of the paper rather than making personal comments about the authors."", ""The sentiment score is -50 because the reviewer expresses significant concerns about the paper, stating it 'needs significant improvement before it can be published.' They list several critical points and questions, indicating a generally negative view of the current state of the work. However, it's not entirely negative as they do acknowledge some positive aspects and offer constructive feedback. The politeness score is 50 because the reviewer uses respectful language throughout, such as 'I request the authors to please let me know if I misunderstood any aspect of the algorithm' and phrases questions politely. They also offer to adjust their rating if they've misunderstood anything, showing consideration. The tone is professional and constructive, even while expressing concerns."", ""The sentiment score is 80 (positive) because the reviewer expresses strong approval of the paper, calling it 'very well written,' 'easy to read,' and 'an important result.' They thank the authors for their hard work and believe the paper will be of interest to a wide audience. The few criticisms are minor and constructive. The politeness score is 90 (very polite) due to the reviewer's use of respectful and appreciative language throughout. They explicitly thank the authors, use phrases like 'I believe,' and offer constructive suggestions for improvement rather than harsh criticisms. The tone is consistently professional and courteous, even when pointing out areas for potential enhancement.""]"
"['This paper describes a novel method for solving inverse problems in imaging.\n\nThe basic idea of this approach is use the following steps:\n1. initialize with nonnegative least squares solution to inverse problem (x0)\n2. compute m different projections of x0\n3. estimate x from the m different projections by solving ""reformuated"" inverse problem using TV regularization.\n\nThe learning part of this algorithm is in step 2, where m different convolutional neural networks are used to learn m good projections. The projections correspond to computing a random Delaunay triangulation over the image domain and then computing pixel averages within each triangle. It\'s not clear exactly what the learning part is doing, i.e. what makes a ""good"" triangulation, why a CNN might accurately represent one, and what the shortcomings of truly random triangulations might be.\n\nMore specifically, for each projection the authors start with a random set of points in the image domain and compute a Delaunay triangulation. They average x0 in each of the Delaunay triangles. Then since the projection is constant on each triangle, the projection into the lower-dimensional space is given by the magnitude of the function over each of the triangular regions. Next they train a convolutional neural network to approximate the above projection. The do this m times. It\'s not clear why the neural network approximation is necessary or helpful. \n\nEmpirically, this method outperforms a straightforward use of a convolutional U-Net to invert the problem.\n\nThe core novelty of this paper is the portion that uses a neural network to calculate a projection onto a random Delaunay triangulation. The idea of reconstructing images using random projections is not especially new, and much of the ""inverse-ness"" of the problem here is removed by first taking the pseudoinverse of the forward operator and applying it to the observations. Then the core idea at the heart of the paper is to speed up this reconstruction using a neural network by viewing the projection onto the mesh space as a set of special filter banks which can be learned.\n\nAt the heart of this paper is the idea that for an L-Lipschitz function f : R^k → R the sample complexity\nis O(L^k), so the authors want to use the random projections to essentially reduce L. However, the Cooper sample complexity bound scales with k like k^{1+k/2}, so the focus on the Lipschitz constant seems misguided.\nThis isn\'t damning, but it seems like the piecewise-constant estimators are a sort of regularizer, and that\'s where we\nreally get the benefits.\n\nThe authors only compare to another U-Net, and it\'s not entirely clear how they even trained that U-Net. It\'d be nice to see if you get any benefit here from their method relative to other approaches in the literature, or if this is just better than inversion using a U-Net. Even how well a pseudoinverse does would be nice to see or TV-regularized least squares.\n\nPractically I\'m quite concerned about their method requiring training 130 separate convolutional neural\nnets. The fact that all the different datasets give equal quality triangulations seems a bit odd, too. Is\nit possible that any network at all would be okay? Can we just reconstruct the image from regression\non 130 randomly-initialized convolutional networks? \n\nThe proposed method isn\'t bad, and the idea is interesting. But I can\'t help but wonder whether it works just because what we\'re doing is denoising the least squares reconstruction, and regression on many random projections might be pretty good for that. Unfortunately, the experiments don\'t help with developing a deeper understanding. \n', ""This paper proposes a novel method of solving ill-posed inverse problems and specifically focuses on geophysical imaging and remote sensing where high-res samples are rare and expensive. \nThe motivation is that previous inversion methods are often not stable since the problem is highly under-determined.  To  alleviate these problems, this paper proposes a novel idea: \ninstead of fully reconstructing in the original space, the authors create reconstructions in projected spaces. \nThe projected spaces they use have very low dimensions so the corresponding Lipschitz constant is small. \nThe specific low-dimensional reconstructions they obtain are piecewise constant images on random Delaunay trinagulations. This is theoretically motivated by classical work (Omohundro'89) and has the further advantage that the low-res reconstructions are interpretable. One can visually see how closely they capture the large shapes of the unknown image. \n\nThese low-dimensional reconstructions are subsequently combined in the second stage of the proposed algorithm, to get a high-resolution reconstruction. The important aspect is that the piecewise linear reconstructions are now treated as measurments which however are local in the pixel-space and hence lead to more stable reconstructions. \n\nThe problem of reconstruction from these piecewise constant projections is of independent interest. Improving this second stage of their algorithm, the authors would get a better result overall. For example I would recommend using Deep Image prior as an alternative technique of reconstructing a high-res image from multiple piecewise constant images, but this can be future work. \n\nOverall I like this paper. It contains a truly novel idea for an architecture in solving inverse problems. The two steps can be individually improved but the idea of separation is quite interesting and novel. \n\n"", ""Summary:\nGiven an inverse problem, we want to infer (x) s.t. Ax = y, but in situations where the number of observations are very sparse, and do not enable direct inversion. The paper tackles scenarios where 'x' is of the form of an image. The proposed approach is a learning based one which trains CNNs to infer x given y (actually an initial least square solution x_init is used instead of y).\n\nThe key insight is that instead of training to directly predict x, the paper proposes to predict different piecewise constant projections of x from x_init , with one CNN trained for each projection, each projection space defined from a random delaunay triangulation, with the hope that learning prediction for each projection is more sample efficient. The desired x is then optimized for given the predicted predicted projections.\n\nPros:\n- The proposed approach is interesting and novel - I've not previously seen the idea of predicting different picewise constant projections instead of directly predicting the desired output (although using random projections has been explored)\n- The presented results are quantitatively and qualitatively better compared to a direct prediction baseline\n- The paper is generally well written, and interesting to read\n\nCons:\nWhile the method is interesting, it is apriori unclear why this works, and why this has been only explored in context of linear inverse problems if it really does work.\n\n- Regarding limited demonstration: The central idea presented here is is generally applicable to any per-pixel regression task. Given this, I am not sure why this paper only explores it in the particular case of linear inversion and not other general tasks (e.g. depth prediction from a single image). Is there some limitation which would prevent such applications? If yes, a discussion would help. If not, it would be convincing to see such applications.\n\n- Regarding why it works: While learning a single projection maybe more sample efficient, learning all of them s.t. the obtained x is accurate may not be. Given this, I'm not entirely sure why the proposed approach is supposed to work. One hypothesis is that the different learned CNNs that each predict a piecewise projection are implicitly yielding an ensembling effect, and therefore a more fair baseline to compare would be a 'direct-ensemble' where many different (number = number of projections) direct CNNs (with different seeds etc.) are trained, and their predictions ensembled.\n\n\nOverall, while the paper is interesting to read and shows some nice results in a particular domain, it is unclear why the proposed approach should work in general and whether it is simply implicitly similar to an ensemble of predictors.""]","[-20, 80, 50]","[50, 70, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('The proposed method isn't bad, and the idea is interesting'), they express several concerns and criticisms throughout the review. They question the necessity and helpfulness of certain aspects of the method, point out potential flaws in the theoretical justification, and express skepticism about the experimental comparisons and results. The overall tone suggests that the reviewer sees potential in the work but has significant reservations.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and respectful tone throughout. They use neutral language to express their concerns and criticisms, avoiding harsh or dismissive statements. The reviewer acknowledges positive aspects of the work and frames their criticisms as questions or suggestions for improvement rather than outright dismissals. However, the score is not higher because the review lacks overtly polite or encouraging language, maintaining a mostly neutral, academic tone."", ""The sentiment score is 80 (positive) because the reviewer expresses a clearly positive view of the paper. They describe the proposed method as 'novel' and 'interesting', and state 'Overall I like this paper.' The reviewer also highlights the paper's strengths and potential impact. The politeness score is 70 (polite) as the reviewer uses respectful and constructive language throughout. They offer suggestions for improvement in a considerate manner, using phrases like 'I would recommend' rather than demanding changes. The tone is professional and supportive, acknowledging both the paper's strengths and areas for potential enhancement without being overly critical or harsh."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges several pros of the paper, including its novelty, interesting approach, and good results. However, they also express some significant concerns and uncertainties about the method's general applicability and underlying mechanisms. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their criticisms as questions or suggestions rather than harsh judgments. They use phrases like 'interesting to read' and 'nice results' while presenting their concerns in a constructive manner.""]"
"['This is a paper of the verification of neural networks, i.e. check their robustness, \nand the main contribution here is to tackle it as a statistical problem adressed with \nmulti-level splitting Monte Carlo approach. I found the paper well motivated and original, \nresulting in a publishable piece of research up to a few necessary adjustments. These \nconcern principally notation issues and some potential improvements in the writing. \nLet me list below some main remarks along the text, including also some typos. \n\n* In the introduction, ""the classical approach"" is mentioned but to be the latter is \ninsufficiently covered. Some more detail would be welcome. \n\n* page 2, ""predict the probability"": rather employ ""estimate"" in such context? \n\n* ""linear piecewise"": ""piecewise linear""? \n\n* what is ""an exact upper bound""? \n\n* In related work, no reference to previous work on ""statistical"" approaches to NN \nverification. Is it actually the case that this angle has never been explored so far?\n\n* I am not an expert but to me ""the density of adversarial examples"" calls for further \nexplanation. \n\n* From page 3 onwards: I was truly confused by the use of [x] throughought the text \n(e.g. in Equation (4)). x is already present within the indicator, no need to add yet \nanother instance of it. Here and later I suffered from what seems to be like an awkward \nattempts to stress dependency on variables that already appear or should otherwise \nappear in a less convoluted way. \n\n* In Section 4, it took me some time to understand that the considered metrics do not \nrequire actual observations but rather concern coherence properties of the NN per se. \nWhile this follows from the current framework, the paper might benefit from some more \nexplanation in words regarding this important aspect. \n\n* In page 6, what is meant by ""more perceptually similar to the datapoint""? \n\n* In the discussion: is it really ""a new measure"" that is introduced here? \n\n* In the appendix: the MH acronym should better be introduced, as should the notation \ng(x,|x\') if not done elsewhere (in which case a cross-reference would be welcome). \nBesides this, writing ""the last samples"" requires disambiguation (using ""respective""?). \n\n\n \n\n ', 'Given a network and input model for generating adversarial examples, this paper presents an idea to quantitatively evaluate the robustness of the network to these adversarial perturbations. Although the idea is interesting, I would like to see more experimental results showing the scalability of the proposed method and for evaluating defense strategies against different types of adversarial attacks.  Detailed review below:\n- How does the performance of the proposed method scale wrt scalability? It will be useful to do an ablation study, i.e. keep the input model fixed and slowly increase the dimension. \n- Did you experiment with other MH proposal beyond a random walk proposal? Is it possible to measure the diversity of the samples using techniques such as the effective sample size (ESS) from the SMC literature?\n- What is the performance of the proposed method against ""universal adversarial examples""?\n- The most interesting question is whether this method gives reasonable robustness estimates even for large networks such as AlexNet?\n- Please provide some intuition for this line in Figure 3: ""while the robustness to perturbations of size \x0f = 0:3 actually starts to decrease after around 20 epochs.""\n- A number of attack and defense strategies have been proposed in the literature. Isn\'t it possible to use the proposed method to quantify the increase in the robustness towards an attack model using a particular defense strategy? If it is possible to show that the results of the proposed method match the conclusions from these papers, then this will be an important contribution. ', 'Verifying the properties of neural networks can be very difficult.  Instead of\nfinding a formal proof for a property that gives a True/False answer, this\npaper proposes to take a sufficiently large number of samples around the input\npoint point and estimate the probability that a violation can be found.  Naive\nMonte-Carlo (MC) sampling is not effective especially when the dimension is\nhigh, so the author proposes to use adaptive multi-level splitting (AMLS) as a\nsampling scheme. This is a good application of AMLS method.\n\nExperiments show that AMLS can make a good estimate (similar quality as naive\nMC with a large number of samples) while using much less samples than MC, on\nboth small and relatively larger models.  Additionally, the authors conduct\nsensitivity analysis and run the proposed algorithm with many different\nparameters (M, N, pho, etc), which is good to see.\n\n\nI have some concerns on this paper:\n\nI have doubts on applying the proposed method to higher dimensional inputs. In\nsection 6.3, the authors show an experiments in this case, but only on a dense\nReLU network with 2 hidden layers, and it is unknown if it works in general.\nHow does the number of required samples increases when the dimension of input\n(x) increases? \n\nFormally, if there exists a violation (counter-example) for a certain property,\nand given a failure probability p, what is the upper bound of number of samples\n(in terms of input dimension, and other factors) required so that the\nprobability we cannot detect this violation with probability less than p?\nWithout such a guarantee, the proposed method is not very useful because we\nhave no idea how confident the sampling based result is. Verification needs\nsomething that is either deterministic, or a probabilistic result with a small\nand bounded failure rate, otherwise it is not really a verification method.\n\nThe experiments of this paper lack comparisons to certified verification\nmethods. There are some scalable property verification methods that can give a\nlower bound on the input perturbation (see [1][2][3]).  These methods can\nguarantee that when epsilon is smaller than a threshold, no violations can be\nfound.  On the other hand, adversarial attacks give an upper bound of input\nperturbation by providing a counter-example (violation). The authors should\ncompare the sampling based method with these lower and upper bounds. For\nexample, what is log(I) for epsilon larger than upper bound?\n\nAdditionally, in section 6.4, the results in Figure 2 also does not look very\npositive - it unlikely to be true that an undefended network is predominantly\nrobust to perturbation of size epsilon = 0.1. Without any adversarial training,\nadversarial examples (or counter-examples for property verification) with L_inf\ndistortion less than 0.1 (at least on some images) should be able to find. It\nis better to conduct strong adversarial attacks after each epoch and see what\nare the epsilons of adversarial examples.\n\nIdeas on further improvement:\n\nThe proposed method can become more useful if it is not a point-wise method.\nIf given a point, current formal verification method can tell if a property is\nhold or not.  However, most formal verification method cannot deal with a input\ndrawn from a distribution randomly (for example, an unseen test example). This\nis the place where we really need a probabilistic verification method. The\nsetting in the current paper is not ideal because a probabilistic estimate of\nviolation of a single point is not very useful, especially without a guarantee\nof failure rates.\n\nFor finding counter-examples for a property, using gradient based methods might\nbe a better way. The authors can consider adding Hamiltonian Monte Carlo to\nthis framework (See [4]).\n\nReferences: \nThere are some papers from the same group of authors, and I merged them to one.\nSome of these papers are very recent, and should be helpful for the authors\nto further improve their work.\n\n[1] ""AI2: Safety and Robustness Certification of Neural Networks with Abstract\nInterpretation"", IEEE S&P 2018 by Timon Gehr, Matthew Mirman, Dana\nDrachsler-Cohen, Petar Tsankov, Swarat Chaudhuri, Martin Vechev \n\n(see also ""Differentiable Abstract Interpretation for Provably Robust Neural\nNetworks"", ICML 2018. by Matthew Mirman, Timon Gehr, Martin Vechev.  They also\nhave a new NIPS 2018 paper ""Fast and Effective Robustness Certification"" but is\nnot on arxiv yet)\n\n[2] ""Efficient Neural Network Robustness Certification with General Activation\nFunctions"", NIPS 2018. by Huan Zhang, Tsui-Wei Weng, Pin-Yu Chen, Cho-Jui\nHsieh, Luca Daniel.  \n\n(see also ""Towards Fast Computation of Certified Robustness for ReLU Networks"",\nICML 2018 by Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh,\nDuane Boning, Inderjit S. Dhillon, Luca Danie.)\n\n[3] Provable defenses against adversarial examples via the convex outer\nadversarial polytope, NIPS 2018. by Eric Wong, J. Zico Kolter.\n\n(see also ""Scaling provable adversarial defenses"", NIPS 2018 by the same authors)\n\n[4] ""Stochastic gradient hamiltonian monte carlo."" ICML 2014. by Tianqi Chen,\nEmily Fox, and Carlos Guestrin.\n\n============================================\n\nAfter discussions with the authors, they agree to revise the paper according to our discussions and my primary concerns of this paper have been resolved. Thus I increased my rating.\n']","[60, 20, 20]","[70, 60, 60]","[""The sentiment score is 60 (positive) because the reviewer states that the paper is 'well motivated and original, resulting in a publishable piece of research'. They mention only 'a few necessary adjustments' are needed, indicating overall approval. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, such as 'I found', 'Some more detail would be welcome', and phrases suggestions as questions or gentle recommendations. They also acknowledge their own potential lack of expertise in one area. The review provides constructive feedback without harsh criticism, maintaining a professional and courteous tone."", ""The sentiment score is slightly positive (20) because the reviewer finds the idea 'interesting' but wants to see more experimental results. This indicates cautious approval rather than strong enthusiasm or criticism. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, phrasing critiques as questions or suggestions rather than direct criticisms. The reviewer also acknowledges the potential importance of the work. The tone is professional and constructive, offering specific recommendations for improvement without being overly effusive or harsh."", ""The sentiment score is 20 (slightly positive) because while the reviewer acknowledges the paper's strengths ('This is a good application of AMLS method', 'Experiments show that AMLS can make a good estimate'), they also express significant concerns and doubts about the method's applicability and usefulness. The overall tone suggests cautious approval with substantial room for improvement. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as 'concerns' rather than outright flaws. They also offer constructive suggestions for improvement and provide helpful references. The language is professional and objective, avoiding any harsh or dismissive statements.""]"
"['In this paper, the authors propose a new approach to representation learning in the context of reinforcement learning.\nThe main idea is that two states should be distinguished *functionally* in terms of the actions that are needed to reach them,\nin contrast with generative methods which try to capture all aspects of the state dynamics, even those which are not relevant for the task at hand.\nThe method of the authors assumes that a goal-conditioned policy is already learned, and they use a Kullback-Leibler-based distance\nbetween policies conditioned by these two states as the loss that the representation learning algorithm should minimize.\nThe experimental study is based on 6 simulated environments and outlines various properties of the framework.\n\nOverall, the idea is interesting, but the paper suffers from many weaknesses both in the framework description and in the experimental study that make me consider that it is not ready for publication at a good conference like ICLR.\n\nThe first weakness of the approach is that it assumes that a learned goal-conditioned policy is already available, and that the representation extracted from it can only be useful for learning ""downstream tasks"" in a second step. But learning the goal-conditioned policy from the raw input representation in the first place might be the most difficult task. In that respect, wouldn\'t it be possible to *simultaneously* learn a goal-conditioned policy and the representation it is based on? This is partly suggested when the authors mention that the representation could be learned from only a partial goal-conditioned policy, but this idea definitely needs to be investigated further.\n\nA second point is about unsufficiently clear thoughts about the way to intuitively advocate for the approach. The authors first claim that two states are functionally different if they are reached from different actions. Thinking further about what ""functionally"" means, I would rather have said that two states are functionally different if different goals can be reached from them. But when looking at the framework, this is close to what the authors do in practice: they use a distance between two *goal*-conditioned policies, not *state*-conditioned policies. To me, the authors have established their framework thinking of the case where the state space and the goal space are identical (as they can condition the goal-conditioned policy by any state=goal). But thinking further to the case where goals and states are different (or at least goals are only a subset of states), probably they would end-up with a different intuitive presentation of their framework. Shouldn\'t finally D_{act} be a distance between goals rather than between states?\n\nSection 4 lists the properties that can be expected from the framework. To me, the last paragraph of Section 4 should be a subsection 4.4 with a title such as ""state abstraction (or clustering?) from actionable representation"". And the corresponding properties should come with their own questions and subsection in the experimental study (more about this below).\n\nAbout the related work, a few remarks:\n- The authors do not refer to papers about using auxiliary tasks. Though the purpose of these works is often to supply for additional reward signals in the sparse reward context, then are often concerned with learning efficient representations such as predictive ones.\n- The authors refer to Pathak et al. (2017), but not to the more recent Burda et al. (2018) (Large-scale study of curiosity-driven learning) which insists on the idea of inverse dynamical features which is exactly the approach the authors may want to contrast theirs with. To me, they must read it.\n- The authors should also read Laversanne-Finot et al. (2018, CoRL) who learn goal space representations and show an ability to extract independently controllable features from that.\n\nA positive side of the experimental study is that the 6 simulated environments are well-chosen, as they illustrate various aspects of what it means to learn an adequate representation. Also, the results described in Fig. 5 are interesting. A side note is that the authors address in this Figure a problem pointed in Penedones et al (2018) about ""The Leakage Propagation problem"" and that their solution seems more convincing than in the original paper, maybe they should have a look.\nBut there are also several weaknesses:\n- for all experiments, the way to obtain a goal-conditioned policy in the first place is not described. This definitely hampers reproducibility of the work. A study of the effect of various optimization effort on these goal-conditioned policies might also be of interest.\n- most importantly, in Section 6.4, 6.5 and 6.6, much too few details are given. Particularly in 6.6, the task is hardly described with a few words. The message a reader can get from this section is not much more than ""we are doing something that works, believe us!"". So the authors should choose between two options:\n* either giving less experimental results, but describing them accurately enough so that other people can try to reproduce them, and analyzing them so that people can extract something more interesting than ""with their tuning (which is not described), the framework of the authors outperforms other systems whose tuning is not described either"".\n* or add a huge appendix with all the missing details.\nI\'m clearly in favor of the first option.\n\nSome more detailed points or questions about the experimental section:\n- not so important, Section 6.2 could be grouped with Section 6.1, or the various competing methods could be described directly in the sections where they are used.\n- in Fig. 5, in the four room environment, ARC gets 4 separated clusters. How can the system know that transitions between these clusters are possible?\n- in Section 6.3, about the pushing experiment, I would like to argue against the fact that the block position is the important factor and the end-effector position is secundary. Indeed, the end-effector must be correctly positioned so that the block can move. Does ARC capture this important constraint?\n- Globally, although it is interesting, Fig.6 only conveys a quite indirect message about the quality of the learned representation.\n- Still in Fig. 6, what is described as ""blue"" appears as violet in the figures and pink in the caption, this does not help when reading for the first time.\n- In Section 6.4, Fig.7 a, ARC happens to do better than the oracle. The authors should describe the oracle in more details and discuss why it does not provide a ""perfect"" representation.\n- Still in Section 6.4, the authors insist that ARC outperforms VIME, but from Fig.7, VIME is not among the best performing methods. Why insist on this one? And a deeper discussion of the performance of each method would be much more valuable than just showing these curves.\n- Section 6.5 is so short that I do not find it useful at all.\n- Section 6.6 should be split into the HRL question and the clustering question, as mentioned above. But this only makes sense if the experiments are properly described, as is it is not useful.\n\nFinally, the discussion is rather empty, and would be much more interesting if the experiments had been analyzed in more details.\n\ntypos:\n\np1: that can knows => know\np7: euclidean => Euclidean\n', 'The paper presents a method to learn representations where proximity in euclidean distance represents states that are achieved by similar policies. The idea is novel (to the best of my knowledge), interesting and the experiments seem promising. The two main flaws in the paper are the lack of details and missing important experimental comparisons.\n\nMajor remarks:\n\n- The author state they add experimental details and videos via a link to a website. I think doing so is very problematic, as the website can be changed after the deadline but there was no real information on the website so it wasn’t a problem this time.\n\n- While the idea seems very interesting, it is only presented in very high-level. I am very skeptical someone will be able to reproduce these results based only on the given details. For example - in eq.1 what is the distribution over s? How is the distance approximated? How is the goal-conditional policy trained? How many clusters and what clustering algorithm?\n\n- Main missing details is about how the goal reaching policy is trained. The authors admit that having one is “a significant assumption” and state that they will discuss why it is reasonable assumption but I didn’t find any such discussion  (only a sentence in 6.4).  \n\n- While the algorithm compare to a variety of representation learning alternatives, it seems like the more natural comparison are model-based Rl algorithms, e.g. “Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning”. This is because the representation tries to implicitly learn the dynamics so it should be compared to models who explicitly learn the dynamics. \n\n- As the goal-conditional policy is quite similar to the original task of navigation, it is important to know for how long it was trained and taken into account.\n\n- I found Fig.6 very interesting and useful, very nice visual help.\n\n- In fig.8 your algorithm seems to flatline while the state keeps rising. It is not clear if the end results is the same, meaning you just learn faster, or does the state reach a better final policy. Should run and show on a longer horizon.\n\n', ""The paper suggests a method for generating representations that are linked to goals in reinforcement learning. More precisely, it wishes to learn a representation so that two states are similar if the policies leading to them are similar.\n\nThe paper leaves quite a few details unclear. For example, why is this particular metric used to link the feature representation to policy similarity? How is the data collected to obtain the goal-directed policies in the first place? How are the different methods evaluated vis-a-vis data collection?  The current discussion makes me think that the evaluation methodology may be biased. Many unbiased experiment designs are possible. Here are a few:\n\nA. Pre-training with the same data\n\n1. Generate data D from the environment (using an arbitrary policy).\n2. Use D to estimate a model/goal-directed policies and consequenttly features F. \n3. Use the same data D to estimate features F' using some other method.\n4. Use the same online-RL algorithm on the environment and only changing features F, F'.\n\nB. Online training\n\n1. At step t, take action $a_t$, observe $s_{t+1}$, $r_{t+1}$\n2. Update model $m$ (or simply store the data points)\n3. Use the model to get an estimate of the features \n\nIt is probably time consuming to do B at each step t, but I can imagine the authors being able to do it all with stochastic value iteration. \n\nAll in all, I am uncertain that the evaluation is fair.\n""]","[-50, -20, -30]","[50, 60, 20]","[""The sentiment score is -50 because while the reviewer acknowledges the idea as interesting, they state that the paper 'suffers from many weaknesses' and is 'not ready for publication at a good conference like ICLR'. The review lists several major criticisms and areas for improvement, indicating an overall negative sentiment. However, it's not entirely negative as the reviewer does point out some positive aspects, such as the well-chosen simulated environments. The politeness score is 50 because the reviewer maintains a professional and constructive tone throughout. They use phrases like 'the idea is interesting' and offer specific suggestions for improvement rather than harsh criticisms. The language is direct but not rude, and the reviewer takes care to explain their reasoning for each point of criticism. The presence of both positive and negative feedback, delivered in a balanced manner, contributes to the politeness of the review."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the novelty and interest of the paper, they also point out significant flaws such as lack of details and missing experimental comparisons. The overall tone suggests more concerns than praise. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging positive aspects ('novel', 'interesting', 'promising') and framing criticisms as suggestions or observations rather than direct attacks. They use phrases like 'I think', 'I am very skeptical', and 'It is not clear' which maintain a professional and courteous tone even when expressing concerns."", ""The sentiment score is -30 because the reviewer expresses uncertainty and points out several unclear aspects of the paper. They state that 'The paper leaves quite a few details unclear' and 'I am uncertain that the evaluation is fair,' indicating a somewhat negative sentiment. However, it's not extremely negative as they do provide constructive feedback and suggestions for improvement. The politeness score is 20 because the reviewer maintains a professional tone throughout, offering suggestions and alternative approaches without using harsh language. They use phrases like 'I can imagine the authors being able to do it' which shows consideration. The reviewer is critical but presents their concerns in a respectful manner, avoiding personal attacks or overly negative language.""]"
"['Authors propose a parameter sharing scheme by allowing parameters to be reused across layers. It further makes connection between traditional CNNs with RNNs by adding additional regularization and using hard sharing scheme.\n\nThe way of parameter sharing is similar to the filter prediction method proposed in Rebuff et al’s work, where they model a convolutional layer’s parameters as a linear combination of a bank of filters and use that to address difference among multiple domains.\n\nSylvestre-Alvise Rebuffi, Hakan Bilen, Andrea Vedaldi, Learning multiple visual domains with residual adapters, NIPS 2017.\n\nThe discussion on the connection between coefficients for different layers and a network’s structure and visualization of layer similarity matrix is interesting. Additional regularization can further encourage a recurrent neural network to be learned. \n\nHowever, they only experiment with one or two templates and advantage on accuracy and model size  over other methods is not very clear.', ""This work is motivated by the widely recognized issue of over-parameterization in modern neural nets, and proposes a clever template sharing design to reduce the model size. The design is sound, and the experiments are valid and thorough. The writing is clear and fluent. \n\nThe reviewer is not entirely sure of the originality of this work. According to the sparse 'related work' section, the contribution is novel, but I will leave it to the consensus of others who are more versed in this regard.\n\nThe part that I find most interesting is the fact that template sharing helps with the optimization without even reducing the number of parameters, as illustrated in CIFAR from Table 1. The trade-off of accuracy and parameter-efficiency is overall well-studied in CIFAR and ImageNet, although results on ImageNet is not as impressive. \n\nRegarding the coefficient alpha, I'm not sure how cosine similarity is computed. I have the impression that each layer has its own alpha, which is a scalar. How is cosine similarity computed on scalars?\n\nIn the experiments, there's no mentioning of the regularization terms for alpha, which makes me think it is perhaps not important? What is the generic setup?\n\nIn summary, I find this work interesting, and with sufficient experiments to backup its claim. On the other hand, I'm not entirely sure of its novelty/originality, leaving this part open to others."", 'The manuscript introduces a novel and interesting approach to weight sharing among CNNs layers, by learning linear combinations of shared weight templates. This allows parameter reduction, better sample efficiency. Furthermore, the authors propose a very simple way to inspect which layers choose similar combinations of template, as well as to push the network toward using similar combinations at each layer. This regularization term has a clear potential for computation reuse on dedicated hardware. The paper is well written, the method is interesting, the results are convincing and thoroughly conducted. I recommend acceptance.\n\n1) It would be interesting to explore how often the layer parameters converge to similar weights and how similar. To this end I suggest to plot a 2d heatmap representing the similarity matrices between every pair of layers.\n\n2) Figure 1 is not of immediate interpretability. Especially for the middle figure, what does the dotted box represent? What is the difference between weights and templates? Also it’s unclear which of the three options corresponds to the proposed method. I would have thought the middle one, but the text seems to indicate it is the rightmost one instead.\n\n3) How are the alphas initialized? How fast are their transitions? Do they change smoothly over training? Do they evolve rapidly and plateau to a fixed value or keep changing during training? It would be really interesting to plot their value and discuss their evolution.\n\n4) While the number of learned parameters is indeed reduced when the templates are shared among layers - which could lead to better sample efficiency - I am not sure whether the memory footprint on GPU would change (i.e., I believe that current frameworks would allocate the same kernel n-times if the same template was shared by n layers, but I am not certain). Although the potential reduction of the number of trainable parameters is an important result by itself, I wonder if what you propose would also allow to run bigger models on the same device or not, without heavy modifications of the inner machineries of pyTorch or Tensorflow.  Can you comment on this? Also note that the soft sharing regularization scheme that you propose can be of great interest for FPGA hardware implementations, that benefit a lot from module reuse. You could mention that in the paper.\n\n5) Sec 4.1, the number of layers in one group is defined as (L-4)/3. It’s unclear to me where the 4 comes from. Also on page 6, k = (L-2)/3 - 2 is said to set one template per layer. I thought the two formulas would be the same in that case. What am I missing? Is it possible that one of the two formulas contain a typo (I believe that at the very least it should be either (L-2) or (L-4) in both cases)?\n\n6) Sec 4.1, I find the notation SWRN-L-w-k and SWRN-L-w confusing. My suggestion is to set k to be the total number of templates (as opposed to the number of templates *per group of layers*), which makes it much easier to relate to, and most importantly allows for an immediate comparison with the capacity of the vanilla model. As a side effect, it also makes it very easy to spot the configuration with one template per layer (SWRN-L-w-L) thus eliminating the need for an ad-hoc notation to distinguish it.\n\n7) The authors inspect how similar the template combination weights alphas are among layers. It would also be interesting to look into what is learned in the templates. CNN layers are known to learn peculiar and somewhat interpretable template matching filters. It would be really interesting to compare the filters learned by a vanilla network and its template sharing alternative. Also, I would welcome an analysis of which templates gets chosen the most at each layer in the hierarchy. It would be compelling if some kind of pattern of reuse emerged from learning.\n\n8) Sec 4.4, it is unclear to me what can be the contribution of the 1x1 initial convolution, since it will see no context and all the information at the pixel level can be represented by a binary bit. Also, are the 3x3 convolutions “same” convolutions? If not, how are the last feature maps upscaled to be able to predict at the original resolution?\n\n9) At the end of sec 4.4 the authors claim that the SCNN is “also advantaged over a more RNN-like model”. I fail to understand how to process this sentence, but I have a feeling that it’s incorrect to make any claims to the performance of “RNN-like models” as such a model was not used as a baseline in the experiments in any way. Similarly, in the conclusions I find it a bit stretched to claim that you can “gain a more flexible form of behavior typically attributed to RNNs”. While it’s true that the proposed network can in theory learn to reuse the same combination of templates, which can be mapped to a network with recursion, the results in this direction don’t seem strong enough to draw any conclusion and a more in-depth comparison against RNN performance would be in order before making any claim in this direction.\n\n\nMINOR\n- Sec3: I wouldn’t say the parameters are shared among layers in LSTMs, but rather among time unrolls.\n- One drawback of the proposed method is that the layers are constrained to have the same shape. This is not a major disadvantage, but is still a constraint that would be good to make more explicit in the description of the model.\n- Sec3, end of page 3: does the network reach the same accuracy as the vanilla model when k=L? Also, does the network use all the templates? How is the distribution of the alpha weights across layers in this case?\n- Sec3.1, the V notation makes the narrative unnecessarily heavy. I suggest to drop it and refer directly to the templates T. Also the second part of the section, with examples of templates, doesn’t add much in my opinion and would be better depicted with a figure.\n- Sec3.1, the e^(i) notation can be confused with an exp. I suggest to replace it with the much more common 1_{i=j}.\n- Figure 2 depicts the relation between the LSM matrix and the topology of the network. This should be declared more clearly in the caption, in place of the ambiguous “capturing implicit recurrencies”. Also, the caption should explain what black/white stand for as well, and possibly quickly describe what the LSM matrix is. Also, it would be more clear that the network in the middle is equivalent to that on the right if the two were somehow connected in the figure. To this end they could, e.g., share a single LSM matrix among them. Finally, if possible try and put the LSM matrices on top of the related network, so that it’s clear which network they refer to. Sec 3.2 should also refer to Fig2 I believe.\n- Table 1: I suggest to leave the comment on the results out of the caption, since it’s already in the main text.\n- Table 2: rather than using blue, I suggest to underline the overall best results, so that it’s visible even if the paper is printed in B&W.\n- Fig 3, I would specify that it’s better viewed in color\n- Discussion: I feel the discussion of Table 1 is a bit difficult to follow. It could be made easier by reporting the difference in test error against the corresponding vanilla model (e.g., “improves the error rate on CIFAR10 by 0.26%”, rather than reporting the performance of both models)\n- Fig 4, are all the stages the same and is the network in the left one such stages? If so, update the caption to make it clear please.\n- Fig 4, which lambda has been used? Is it the same for all stages?\n- Fig 5, specify that the one on the right is the target grid. Also, I believe that merging the two figures would make it easier to understand (e.g., some of the structure in the target comes from how the obstacles are placed, which requires to move back and forth from input to target several times to understand)\n- Sec 4.4, space permitting, I would like to see at least one sample of what kind of shortest path prediction the network can come up with.\n\n\n\nA few typos:\n    * End of 3.2: the closer elements -> the closer the elements\n    * Parameter efficiency: the period before re-parametrizing should probably be a comma?\n    * Fig 4, illustration of stages -> illustration of the stages\n    * End of pag7, an syntetic -> a syntetic']","[20, 60, 90]","[50, 80, 80]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges some interesting aspects of the work, such as the discussion on layer connections and visualization. However, they also point out limitations, like limited experimentation and unclear advantages. The politeness score is moderately positive (50) as the reviewer uses neutral language and presents criticisms constructively without harsh words. They acknowledge the authors' contributions while providing balanced feedback, maintaining a professional tone throughout the review."", ""The sentiment score is 60 (positive) because the reviewer expresses overall positive views about the work, describing it as 'clever', 'sound', 'valid and thorough', and 'interesting'. However, it's not extremely positive due to some reservations about originality and ImageNet results. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges their own potential limitations ('I will leave it to the consensus of others'), and frames criticisms as questions or mild concerns rather than harsh judgments. The reviewer maintains a professional and courteous tone while providing constructive feedback."", ""The sentiment score is 90 (very positive) because the reviewer explicitly recommends acceptance, praises the paper as 'well written', the method as 'interesting', and the results as 'convincing and thoroughly conducted'. The politeness score is 80 (quite polite) due to the constructive and respectful tone throughout. The reviewer offers suggestions and asks questions without being critical or demanding. They use phrases like 'It would be interesting to...', 'I suggest...', and 'Can you comment on this?', which maintain a polite and collaborative tone. The reviewer also balances critique with praise, acknowledging the paper's strengths while offering areas for improvement.""]"
"['This paper presents the following approach to domain adaptation. Train a source domain RNN. While doing inference on the target domain, first you run the source domain RNN on the sequence. Then while running the target domain RNN, set the hidden state at time step i, h^t_i, to be a function \'f\' of  h^t_{i-1} and information from source domain \\psi_i; \\psi_i is computed as a convex combination of the state of the source domain RNN, h^s_{i}, and an attention-weighted average of all the states h^s{1...n}. So in effect, the paper transfers information from each of source domain cells -- the cell at time step i and all the ""collocated"" cells (collocation being defined in terms of attention). This idea is then extended in a straightforward way to LSTMs as well. \n \nDoing ""cell-level"" transfer enables more information to be transferred according to the authors, but it comes at a higher computation since we need to do O(n^2) computations for each cell.\n\nThe authors show that this beats a variety of baselines for classification tasks (sentiment), and for sequence tagging task (POS tagging over twitter.)\n\nPros:\n1. The idea makes sense and the experimental results show solid \n\nCons:\n1. Some questions around generalization are not clearly answered. E.g. how are the transfer parameters of function \'f\' (that controls how much source information is transferred to target) trained? If the function \'f\' and the target RNN is trained on target data, why does \'f\' not overfit to only selecting information from the target domain? Would something like dropping information from target domain help?\n\n2. Why not also compare with a simple algorithm of transferring parameters from source to target domain? Another simple baseline is to just train final prediction function (softmax or sigmoid) on the concatenated source and target hidden states. Why are these not compared with? Also, including the performance of simple baselines like word2vec/bow is always a good idea, especially on the sentiment data which is very commonly used and widely cited. \n\n3. Experiments: the authors cite the hierarchical attention transfer work of Li et al (https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/16873/16149) and claim their approach is better, but do not compare with them in the experiments. Why?\n\nWriting:\nThe writing is quite confusing at places and is the biggest problem with this paper. E.g.\n\n1. The authors use the word ""collocated"" everywhere, but it is not clear at all what they mean. This makes the introduction quite confusing to understand. I assumed it to mean words in the target sentences that are strongly attended to. Is this correct? However, on page 4, they claim ""The model needs to be evaluated O(n^2) times for each sentence pair."" -- what is meant by sentence pair here? It almost leads me to think that they consider all source sentence and target sentences? This is quite confusing. \n\n2. The authors keep claiming that ""layer-wise transfer learning mechanisms lose the fine-grained cell-level information from the source domain"", but it is not clear exactly what do they mean by layer-wise here. Do they mean transferring the information from source cell i to target cell i as it is? In the experiments section on LWT, the authors claim that ""More specifically, only the last cell of the RNN layer transfers information. This cell works as in ART. LWT only works for sentence classification."" Why is it not possible to train a softmax over both the source hidden state and the target hidden state for POS tagging? \n\nnits:\npage 4 line 1: ""i\'th cell in the source domain"" -> ""i\'th cell in the target domain"". ""j\'th cell in target"" -> ""j\'th cell in sourcE"".\n\n\nRevised: increased score after author response.\n', 'The proposed method is suitable for many NLP tasks, since it can handle the sequence data.\n\nI find it difficult to follow through the model descriptions.  Perhaps a more descriptive figures would make this easier to follow, I feel that the ART model is a very strait forward and it can be easily described in much simpler and less exhausting (sorry for the strong word) way, while there is nothing wrong with being as elaborating as you are, I feel that all those details belong in an appendix. \nCan you please explain the exact learning process?\nI didn’t fully understand the exact way of collocations, you first train on the source domain and then use the trained source network when training in the target domain with all the collocated words for each training example? I deeply encourage you to improve the model section for future readers. \nIn contrast to the model section, the related work and the experimental settings sections are very thin.\nThe experimental setup for the sentiment analysis experiments is quite rare in the transfer learning/domain adaptation landscape, having equal amount of labeled data from both source and target domains is not very realistic in my humble opinion.\nMore realistic setup is unsupervised domain adaptation (like in DANN and MSDA-DAN papers) or minimally supervised domain adaptation (like you did in your POS and NER experiments).\n\nIn addition to the LSTM baseline (which is trained with target data only), I think that LSTM which is trained on both source and target domains data is required for truly understand ART gains – this goes for the POS and NER tasks as well.\nThe POS and NER experiments can use some additional baselines for further comparison, for example:\nhttp://www.aclweb.org/anthology/Q14-1002\nhttps://hornhehhf.github.io/hangfenghe/papers/14484-66685-1-PB.pdf\n\nI am not sure I understand the “cell level transfer” claim, did you mean that you are the first to apply inner LSTM/RNN cell transfer or that you are the first ones to apply word-level fine grained transfer, the latter has already been done:\nhttps://arxiv.org/pdf/1802.05365.pdf\nhttps://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=4531&context=sis_research\nhttp://www.aclweb.org/anthology/N18-1112\nhttps://openreview.net/pdf?id=rk9eAFcxg\n', '== Quality of results ==\nThis paper\'s empirical results are its main strength. They evaluate on a well-known benchmark for transfer learning in text classification (the Amazon reviews dataset of Blitzer et al 2007), and improve by a significant margin over recent state-of-the-art methods. They also evaluate on several sequence tagging tasks and achieve good results.\n\nOne weakness of the empirical results is that they do not compare against training a model on the union of the source and target domain. I think this is very important to compare against.\n\nNote: the authors cite a paper in the introduction ""Hierarchical Attention Transfer Network for Cross-domain Sentiment\nClassification"" (Li et al 2018) which also achieves state of the art results on the Amazon reviews dataset, but do not compare against it. At first glance, Li et al 2018 appear to get better results. However, they appear to be training on a larger amount of data for each domain (5600 examples, rather than 1400). It is unclear to me why their evaluation setup is different, but some clarification about this would be helpful.\n\n== Originality ==\nA high level description of their approach:\n1. Train an RNN encoder (""source domain encoder"") on the source domain\n2. On the target domain, encode text using the following strategy:\n  - First, encode the text using the source domain encoder\n  - Then, encode the text using a new encoder (a ""target domain encoder"") which has the ability to attend over the hidden states of the source domain encoder at each time step of encoding.\n\nThey also structure the target domain encoder such that at each time step, it has a bias toward attending to the hidden state in the source encoder at the same position.\n\nThis has a similar flavor to greedy layer-wise training and model stacking approaches. In that regard, the idea is not brand new, but feels well-applied in this setting.\n\n== Clarity ==\nI felt that the paper could have been written more clearly. The authors set up a comparison between ""transfer information across the whole layers"" vs ""transfer information from each cell"" in both the abstract and the intro, but it was unclear what this distinction was referring to until I reached Section 4.1 and saw the definition of Layer-Wise Transfer.\n\nThroughout the abstract and intro, it was also unclear what was meant by ""learning to collocate cross domain words"". After reading the full approach, I see now that this simply refers to the attention mechanism which attends over the hidden states of the source domain encoder.\n\n== Summary ==\nThis paper has good empirical results, but I would really like to see a comparison against training a model on the union of the source and target domain. I think superior results against that baseline would increase my rating for this paper.\n\nI think the paper\'s main weakness is that the abstract and intro are written in a way that is somewhat confusing, due to the use of unconventional terminology that could be replaced with simpler terms.']","[20, -30, 20]","[50, 20, 50]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges some pros of the paper, such as the idea making sense and experimental results being solid. However, they also list several cons and areas for improvement, balancing out the positive aspects. The politeness score is moderately positive (50) as the reviewer maintains a professional tone throughout, offering constructive criticism without using harsh language. They use phrases like 'The idea makes sense' and frame suggestions as questions, which comes across as respectful. The reviewer also provides specific examples and suggestions for improvement, which is helpful and courteous. However, the review is not overly effusive or extremely polite, maintaining a neutral-to-positive professional tone overall."", ""The sentiment score is slightly negative (-30) because while the reviewer acknowledges the method's suitability for NLP tasks, they express several criticisms and concerns about the paper. These include difficulty following the model descriptions, thin related work and experimental settings sections, and unrealistic experimental setup. The politeness score is slightly positive (20) as the reviewer uses polite language like 'I find it difficult', 'Perhaps', 'I feel that', and 'in my humble opinion'. They also apologize for using a 'strong word'. However, the overall tone is still critical, balancing out the politeness somewhat. The reviewer provides constructive feedback and suggestions for improvement, which contributes to the slightly positive politeness score."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's strengths, particularly in empirical results, while also pointing out some weaknesses. The review starts by highlighting the main strength of the paper and mentions 'good results' in several areas. However, it also notes some weaknesses and areas for improvement, which prevents the score from being higher. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offering constructive criticism without being harsh. They use phrases like 'I think' and 'I felt' to soften their critiques, and provide specific suggestions for improvement rather than just pointing out flaws. The reviewer maintains a professional tone throughout, balancing praise with areas for improvement.""]"
"['Summary:\nThe authors propose to apply the Deep Variational Information Bottleneck (VIB) method of [1] on discriminator networks in various adversarial-learning-based scenarios. They propose a way to adaptively update the value for the bêta hyper-parameter to respect the constraint on I(X,Z). Their technique is shown to stabilize/allow training when P_g and P_data do not overlap, similarly to WGAN and gradient-penalty based approaches, by essentially pushing their representation distributions (p_z) to overlap with the mutual information bottleneck. It can also be considered as an adaptive version of instance noise, which serves the same goal. The method is evaluated on different adversarial learning setup (imitation learning, inverse reinforcement learning and GANs), where it compares positively to most related methods. Best results for ‘classical’ adversarial learning for image generation are however obtained when combining the proposed VIB with gradient penalty (which outperforms by itself the VGAN in this case).\n\n\nPros :\n- This paper brings a good amount of evidence of the benefits to use the VIB formulation to adversarial learning by first showing the effect of such approach on a toy example, and then applying it to more complex scenarios, where it also boosts performance. The numerous experiments and analyses have great value and are a necessity as this paper mostly applies the VIB to new learning challenges. \n\n- The proposition of a principled way of adaptively varying the value of Bêta to actually respect more closely the constraint I(X,Z) < I_c, which to my knowledge [1] does not perform, is definitely appealing and seems to work better than fixed Bêtas and does also bring the KL divergence to the desired I_c.\n\n- The technique is fairly simple to implement and can be combined with other stabilization techniques such as gradient penalties on the discriminator.\n\n\nCons:\n\n- In my view, the novelty of the approach is somewhat limited, as it seems like a straightforward application of the VIB from [1] for discriminators in adversarial learning, with the difference of using an adaptive Bêta.\n\n- I think the Bêta-VAE [2] paper is definitely related to this paper and to the paper on which it is based [1] and should thus be cited as the authors use a similar regularization technique, albeit from a different perspective, that restricts I(X,Z) in an auto-encoding task.\n\n- I think the content of batches used to regularize E(z|x) w.r.t. to the KL divergence should be clarified, as the description of p^tilde “being a mixture of the target distribution and the generator” (Section 4) can let the implementation details be ambiguous. I think batches containing samples from both distributions can cause problems as the expectation of the KL divergence on a batch can be low even if the samples from both distributions are projected into different parts of the manifold. This makes me think batches are separated? Either way, this should be more clearly stated in the text.\n\n- The last results for  the ‘traditional’ GAN+VIB show that in this case, gradient penalty (GP) alone outperforms the proposed VGAN, and that both can be combined for best results. I thus wonder if the results in all other experiments could show similar trends if GP had been tested in these cases as well. In the imitation learning task, authors compare with instance noise, but not with GP, which for me are both related to VIB in what they try to accomplish. Was GP tested in Imitation Learning/Inverse RL ? Was it better? Could it still be combined with VIB for better results? \n\n- In the saliency map of Figure 5, I’m unclear as to what the colors represent (especially on the GAIL side). I doubt that this is simply due to the colormap used, but this colormap should be presented.\n\nOverall, I think this is an interesting and relevant paper that I am very likely to suggest to peers working on adversarial learning, and should therefore be presented. I think the limited novelty is counterbalanced by the quality of empirical analysis. Some clarity issues and missing citations should be easy to correct. I appreciate the comparison and combination with a competitive method (Gradient Penalty) in Section 5.3, but I wish similar results were present in the other experiments, in order to inform readers if, in these cases as well, combining VIB with GP leads to the best performance.\n\n[1] Deep Variational Information Bottleneck, (Alemi et al. 2017)\n[2] beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework (Higgins et al. 2017)\n', 'The paper ""Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse RL, and GANs by Constraining Information Flow"" tackles the problem of discriminator over-fitting in adversarial learning. Balancing the generator and the discriminator is difficult in generative adversarial techniques, as a too good discriminator prevents the generator to converge toward effective distributions. The idea is to introduce an information constraint on a intermediate layer, called information bottleneck, which limits the content of this layer to the most discriminative features of the input. Based on this limited representation of the input, the disciminator is constrained to longer tailed-distributions, maintaining some uncertainty on simulated data distributions. Results show that the proposal outperforms previous researches on discriminator over-fitting, such as noise adding in the discriminator inputs. \n\nWhile the use of information bottleneck is not novel, its application in adversarial learning looks inovative and the results are impressive in a broad range of applications. The paper is well-written and easy to follow, though I find that it would be nice to give more insights on the intuition about information bottleneck in the preliminary section to make the paper self-contained (I had to read the previous work from Alemi et al (2016) to realize what information bottleneck can bring). My only question is about the setting of the constaint Ic: wouldn\'t it be possible to consider an adaptative version which could consider the amount of zeros gradients returned to the generator ? ', 'This paper proposed a constraint on the discriminator of GAN model to maintain informative gradients. It is completed by control the mutual information between the observations and the discriminator’s internal representation to be no bigger than a predefined value.  The idea is interesting and the discussions of applications in different areas are useful. However, I still have some concerns about the work:\n1.\tin the experiments about image generation, it seems that the proposed method does not enhance the performance obviously when compared to GP and WGAN-GP, Why the combination of VGAN and GP can enhance the performance greatly(How do they complementary to each other), what about the performance when combine VGAN with WGAN-GP?\n2.\tHow do you combine VGAN and GP, is there any parameter to balance their effect?\n3.\tThe author stated on page 2 that “the  proposed information bottleneck encourages the discriminator to ignore irrelevant cues, which then allows the generator to focus on improving the most discerning differences between real and fake samples”, a proof on theory or experiments should be used to illustrate this state.\n4.\tIs it possible to apply GP and WGAN-GP to the Motion imitation or adversarial inverse reinforcement learning problems? If so, will it perform better than VGAN?\n5.\tHow about VGAN compares with Spectral norm GAN?\n']","[60, 80, 20]","[80, 70, 60]","[""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, highlighting several pros and stating that it's 'interesting and relevant' and 'should be presented'. However, they also mention some cons and areas for improvement, which prevents the score from being higher. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout, offering balanced feedback and suggestions for improvement without being harsh or dismissive. They use phrases like 'I appreciate' and 'I think', which maintain a polite tone. The reviewer also acknowledges the paper's strengths while providing critiques, demonstrating a considerate approach to feedback."", ""The sentiment score is 80 (positive) because the reviewer praises the paper as 'well-written and easy to follow' and describes the results as 'impressive'. They also note that the application of information bottleneck in adversarial learning 'looks innovative'. The only criticism is minor, suggesting more background on information bottleneck. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, offering constructive feedback and framing their suggestion as 'it would be nice'. The reviewer also poses their final point as a question rather than a demand, which is a polite approach. The overall tone is professional and encouraging."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the interesting idea and useful discussions in the paper, but also expresses several concerns. The overall tone is constructive rather than dismissive. The politeness score is moderately high (60) as the reviewer uses respectful language, phrases concerns as questions, and avoids harsh criticism. The reviewer begins with positive aspects before listing concerns, and uses phrases like 'it seems that' and 'is it possible' which soften the critique. The language is professional and objective throughout, maintaining a courteous tone while still providing substantive feedback.""]"
"['This paper proposes a new approach to use more informative signals (than only class labels), specifically, regions humans deem important on images, to improve deep convolutional neural networks. They collected a large dataset by implementing a game on clickme.ai and showed that using this information results in both i) improved classification accuracy and ii) more interpretable features. \n\nI think this is good work and should be accepted. The main contribution is three fold: i) a publicly available dataset that many researchers can use, ii) a network module to incorporate this human information that might be inserted into many networks to improve performance, and iii) some insights on the effect of such human supervision and the relation between features that humans deem important to those that neural nets deem important. \n\nSome suggestions on how to improve the paper:\n1. I find Sections 3 & 4 hard to track - some missing details and notation issues. Several variables are introduced without detailing the proper dimensions, e.g., the global feature attention vector g (which is shown in the figure actually). The relation between U and u_k isn\'t clear. Also, it will help to put a one-sentence summary of what this module does at the beginning of Section 3, like the last half-sentence in the caption of Figure 3. I was quite lost until I see that. Some more intuition is needed, on W_expand and W_shrink; maybe moving some of the ""neuroscience motivation"" paragraph up into the main text will help. Bold letters are used to denote many different things - in  Section 4 as a set of layers, in other places a matrix/tensor, and even an operation (F). \n\n2. Is there any explanation on why you add the regularization term to every layer in a network? This setup seems to make it easy to explain what happens in Figure 4. One interesting observation is that after your regularization, the GALA features with ClickMe maps exhibit minimal variation across layers (those shown). But without this supervision the features are highly different. What does this mean? Is this caused entirely by the regularization? Or there\'s something else going on, e.g., this is evidence suggesting that with proper supervision like human attention regions, one might be able to use a much shallower network to achieve the same performance as a very deep one?\n\n3. Using a set of 10 images to compute the correlation between ClickMe and Clicktionary maps isn\'t ideal - this is even less than the number of categories among the images. I\'m also not entirely convinced that ""game outcomes from the first and second half are roughly equal"" says much about humans not using a neural net-specific strategy, since you can\'t rule out the case that they learned to play the game very quickly (in the first 10 of the total 380 rounds). \n\n4. Title - this paper sound more ""human feedback"" to me than ""humans-in-the-loop"", because the loop has only 1 iteration.  Because you are collecting feedback from humans but not yet giving anything back to them. Maybe change the title?', '\nSUMMARY\n\nThis paper argues that most recent gains in visual recognition are due to the use of visual attention mechanisms in deep convolutional networks (DCNs). According to the authors; the networks learn where to focus through a weak form of supervision based on image class labels. This paper introduces a data set that complements ImageNet with circa 500,000 human-derived attention maps, obtained through a large-scale online experiment called ClickMe. These attention maps can be used in conjunction with DCNs to add a human-in-the-loop feature that significantly improves accuracy.\n\nREVIEW\n\nThis paper is clearly within scope of the ICLR conference and addresses a relevant and challenging problem: that of directing the learning process in visual recognition tasks to focus on interesting or useful regions. This is achieved by leveraging a human-in-the-loop approach.\n\nThe paper does a fair job in motivating the research problem and describing what has been done so far in the literature to address the problem. The proposed architecture and the data collection online experiment are also described to a sufficient extent.\n\nIn my view, the main issue with this paper is the reporting of the experiment design and the analysis of the results. Many of the design choices of the experiments are simply listed and not motivated at all. The reader has to accept the design choices without any justification. The results for accuracy are simply listed in a table and some results are indicated as “p<0.01” but the statistical analysis is never described. Interpretability is highlighted in the abstract and introduction as an important feature of the proposed approach but the evaluation of interpretability is limited to a few anecdotes from the authors’ review of the results. The paper does not present a procedure or measure for evaluating interpretability.\n\nOTHER SUGGESTIONS FOR IMPROVEMENT\n\n- The verb “attend” is used in many places where “focus” seems to be more appropriate.\n\n- “we ran a rapid experiment”: what does rapid mean in this context?\n\n- “the proposed GALA architecture is grounded in visual neuroscience” : this and many other statements are only elaborated upon in the appendix. I understand that page limit is always an issue but I think it is important to prioritise this and similar motivations and put at least a basic description in the main body\n\nUPDATE\n\nMy most serious concerns have been addressed in the revised version.\n', 'The paper presents a new take on attention in which a large attention dataset is collected (crowdsourced) and used to train a NN (with a new module) in a supervised manner to exploit self-reported human attention. The empirical results demonstrate the advantages of this approach.\n\n*Pro*:\n-\tWell-written and relatively easily accessible paper (even for a non-expert in attention like myself)\n-\tWell-designed crowdsourcing experiment leading to a novel dataset (which is linked to state-of-the-art benchmark)\n-\tAn empirical study demonstrates a clear advantage of using human (attention) supervision in a relevant comparison \n\n*Cons*\n-\tSome notational confusion/uncertainty in sec 3.1 and Fig 3 (perhaps also Sec 4.1): E.g. $\\mathbf{M} and {L_clickmaps} are undefined in Sec 3.1.\n\n*Significance:* I believe this work would be of general interest to the image community at ICLR as it provides a new high-quality dataset and an attention module for grounding investigations into attention mechanisms for DNNs (and beyond). \n\n*Further comments/questions:*\n-\tThe transition between sec 2 and sec 3 seems abrupt; consider providing a smoother transition. \n-\tFigure 3: reconsider the logical flow in the figure; it took me a while to figure out what going on (especially the feedback path to U’).\n-\tIt would be beneficial to provide some more insight into the statistical tests casually reported (i.e., where did the p values come from)\n-\tThe dataset appears to be available online but will the code for the GALA module also be published?\n\n']","[70, 50, 70]","[80, 80, 80]","[""The sentiment score is 70 (positive) because the reviewer states 'I think this is good work and should be accepted' and highlights three main contributions of the paper. The overall tone is supportive and constructive. The politeness score is 80 (polite) due to the reviewer's use of respectful language throughout, such as 'Some suggestions on how to improve the paper' and phrasing criticisms as questions or suggestions rather than direct criticisms. The reviewer provides detailed, constructive feedback while maintaining a positive and encouraging tone. The slightly lower sentiment score compared to the politeness score reflects the presence of several improvement suggestions, which, while politely phrased, indicate areas where the paper could be strengthened."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's relevance and scope, and mentions that their most serious concerns have been addressed in the revised version. However, they also point out some issues with the experiment design and analysis of results. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and provides specific suggestions for improvement. They use phrases like 'fair job,' 'sufficient extent,' and 'in my view,' which maintain a professional and courteous tone. The reviewer also acknowledges the constraints of page limits, showing understanding of the authors' situation."", ""The sentiment score is 70 (positive) because the reviewer starts with a neutral summary and then lists more pros than cons. They also mention the paper is 'well-written' and 'easily accessible', and state that the work would be of 'general interest'. The cons mentioned are minor and technical in nature. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offers constructive feedback, and frames their comments as suggestions rather than demands. They use phrases like 'consider providing' and 'it would be beneficial', which are polite ways of offering recommendations. The reviewer also acknowledges their own potential lack of expertise in one area, which is a humble and polite approach.""]"
"['General comment\n==============\nThe authors describe two loss functions for learning embeddings of protein amino acids based on i) predicting the global structural similarity of two proteins, and ii) predicting amino acid contacts within proteins. As far as I know, these loss functions are novel and the authors show clear improvements when using the learned embeddings in downstream tasks. The paper is well motivated and mostly clearly written. However, the evaluation must be strengthened and some aspects of it clarified. Provided that the authors address my comments below, I think it is a good ICLR application paper.\n\nMajor comments\n=============\n1. The authors should describe how they optimized hyperparameters such as the learning, lambda (loss section 3.3), or the smoothing factor (section 3.4). These should be optimized on an evaluation set, but the authors only mentioned that they split the dataset into training and holdout (test) set (section 4.1).\n\n2. The way the authors present results in table 1 and table 2 is unclear. Both table 1 and table 2 contain results of the structural similarity tasks but with different baselines. ‘SSA w/ contact predictions’ is also undefined and can be interpreted as ‘with’ or ‘without’ contacts predictions. I therefore strongly recommend to show structural similarity results in table 1 and secondary structure results in table 2 and include in both tables i) ‘SSA full’, ‘SSA without contact predictions’, and ‘SSA without language model’.\n\n3. The authors should compare SSA to the current state-of-the art in structure prediction in addition to baseline models.\n\n4. The authors should evaluate how well their method predicts amino acid contact maps.\n\n5. The authors should describe how they were dealing with variable-length protein sequences. Are sequences truncated and embedded to a fixed length? What is the mean and variance in protein sequence lengths in the considered datasets? The authors should point out that their method is limited to fixed length sequences.\n\n6. The authors should briefly describe the training and inference time on a single GPU and CPU. How much memory is required for training with a certain sequence length, e.g. 400 amino acids per sequence? Does the model fit on a single GPU?\n\n7. The authors should discuss limitations of their method, e.g. that it cannot handle variable length sequences and that the memory scales quadratically by the the sequence length.\n\n8. CRF (SSA) (table 3) includes a biLSTM layer between SSA and the CRF. However, the biLSTM can learn a non-linear projection of embeddings learned by SSA such that it is unclear if improvements are due to the embeddings learned by SSA or the biLSTM+CRF architecture. The authors should therefore train a biLSTM+CRF model on one-hot encoded amino-acids and include it as baseline in table 3.\n\n\nMinor comments\n=============\n9. The way the similarity score s’ is computed (section 3.2.1) should be motivated more clearly. Why do the authors compute the score s’ manually instead of predicting it, e.g. using a model that takes the embeddings z of both proteins as input and predicts a single scalar s’? \n\n10. How does ordinal regression (section 3.2.2) perform compared with a softmax layer? Why do the authors compute s’ and then train logistic regression classifiers on s’ to predict the similarity level, instead of predicting the similarity level directly based on the embeddings z?\n\n11. Why do the authors use a distance threshold of 8A (section 3.3)? Is this common practice in the field?\n\n12. Why do the authors use the not product and the absolute difference as features instead of the embeddings z directly? Which activation function is used to predict contact probabilities (sigmoid, softmax, …)?\n\n13. The authors should reference and describe the results presented in table 1 more clearly.\n\n14. Optional: the authors should analyze if learned embeddings are correlated with amino acid and structural properties such as their size, charge, or solvent accessibility. Do embeddings clusters by certain properties? This can be analyzed, e.g., using a tSNE plot. \n\n15. How does TMalign perform when using the maximum or geometric average instead of the arithmetic average of the two scores (section 4.1)', ""Thanks for the detailed responses. After reading the author response and the updated paper, I am satisfied on several of my concerns, many of which were due to the writing in the earlier submission. The updated results on various comparisons are also good.  I have updated my score accordingly. Some qualitative analysis of the results would have been nice -- examples of protein pairs where they do well and other methods have difficulty as they don't use the structural similarity info / global sequence info used by this paper. But maybe those can be in a journal submission.\nMy only remaining concern is on the lack of reporting average performance on the test data (which used to be the norm until recently for papers submitted to ML conferences).\n\n\nSummary:\nThis paper proposes an approach for embedding proteins using their amino-acid sequences, with the goal that embeddings of proteins with similar structure are encouraged to be close in the embedded space. A stacked 3-layer Bi-directional LSTM is used for embedding the proteins. The structure information is obtained from the SCOP database which is used in an ordinal regression framework, where the output is the structural similarity and inputs are the embeddings. Along with the ordinal regression, another loss term to incorporate contacts of amino-acid residues is used. Results are shown on structural similarity prediction and secondary structure prediction.\n\nClarity:\n1. The introduction of the paper is not very well written and it takes some time to figure out the exact problem being addressed. Is it learning sequence embeddings, or predicting structure from sequence or searching for similar structures in a database. Defining a clear goal -- input/output of their pipeline is important before describing the applications of the method, such as predicting structural similarity. \n2. Due to the write-up, the method comes across as having too many modeling components without a very clear motivation for why these help the problem at hand. Where is the alignment part?\n3. Why is each sequence embedded as a matrix? What is the motivation for a vector representation at each amino-acid position?\n4. The authors need to explain the particular choice of 3 layers of bi-directional LSTMs. Why three? And why Bi-LSTM and not LSTMs? \n\nQuality:\n1. While the problem being addressed is interesting, the work lacks a clear reasoning behind the choice of modeling components which makes it seem ad-hoc.\n2. Structural similarity is defined using the hierarchy of protein structure classes and the numbers seemed a bit arbitrary to me. Why not have a vector to encode the different aspects of structure? Have they looked at prior work?\n3. How does the pre-trained language model on Pfam sequences help? Why is the output from it concatenated; have other composition functions been considered? \n\nOriginality:\nThe various components of the model are not novel, but the particular framework of putting them together is novel.\n\nResults:\n1. While the authors claim that some prior methods only work with high sequence similarity, their own evaluation only considers pairs of sequences with 95% identity. HHalign for instance, considers sequences with ~20% identity.\n2. Why weren't several train/test splits of the data tried, so that performance can be reported with std. error bars?\n3. Methods against which they compare have not been described properly.\n\n"", 'This work learns embeddings for proteins. They use techniques from deep learning on natural langauge that are typically applied to scentences and words, and apply them correspondinly to proteines and amino acids. Thus they learn a vector representation using a bi-directional LSTM for amino acids by training the amino acid equivalent of a language model.\n\nThe authors then multitask 2 models using the embeddings that perform contact prediction (using an mlp and CNN) and structural class similarity model, which appear to perform very well.\n\nTheir SSA - soft symmetric alignment mechanism is neat and gives a single scalar value for a pair of proteins (by comparing their strings of emebedded amino acids by L1 distance), and it is descriptive enough feature for a simple ordinal regression to output a set structural similarity scores via a linear classifier (one for each strength of similarity re. the SCOP classification hierachy). It seems to work well, but I am unable to judge how good this is with respect to more recent work in this field. I would suspect being able to backprop to the embedding LSTMs through the SSA at this point would give much better results. \n\nAuthors only give 2 recent refeneces for protein embedding work [12,13] but should also take a look at this work: Melvin et. al, PLOS Computational Biology, this work uses structural class labels from SCOP to supervise the embedding. Although they do mention profile HMM in \'related work\' which was used to create features in that work.\n\nThese authors, as far as I can tell do not ""backprop"" to the amino acid embeddings (and the LSTMs) from the contact or similarty loss. So the bi-LSTM-produced feature vectors, although trained unsupervised from many proteins, are not trained with structural supervision as claimed in the title (they state this in last paragraph of 3.1) and so the embeddings are not related to structural similarity directly. They do, however, seem to produce good features for the tasks they then tackle.\nThey say in the conclusion that the SSA model is fully differentiable, but I don\'t see where they ""backprop"" through it.\n\nI would say (if this assessment is correct) then the title is very misleading, although the work and  final results look good.\n\n\nupdate: the authors have assured me in comments that the model is trained end to end - changing rating to good..\n']","[50, 20, 60]","[80, 50, 70]","[""The sentiment score is 50 (moderately positive) because the reviewer starts by acknowledging the novelty of the work and its clear improvements, stating it's a 'good ICLR application paper'. However, they also mention that 'the evaluation must be strengthened and some aspects of it clarified', indicating room for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive criticism and suggestions rather than harsh critiques. They use phrases like 'The authors should...' instead of more demanding language, and they provide detailed explanations for their recommendations. The review maintains a professional and courteous tone while still providing thorough feedback."", ""For the sentiment score, I assigned a slightly positive value of 20 because the reviewer expresses satisfaction with some aspects of the revised paper and author responses, noting improvements in writing and results. However, they still have some remaining concerns, which prevents a higher positive score. The politeness score of 50 reflects the generally courteous tone of the review. The reviewer uses phrases like 'Thanks for the detailed responses' and offers constructive criticism without harsh language. They provide specific suggestions for improvement and acknowledge the interesting aspects of the work. The review maintains a professional and respectful tone throughout, even when pointing out weaknesses, which justifies a moderately positive politeness score."", ""The sentiment score is 60 (positive) because the reviewer initially expresses a generally positive view of the work, praising aspects like the 'neat' SSA mechanism and stating that the results 'appear to perform very well'. The reviewer does raise some concerns and suggestions, but ultimately updates their rating to 'good' after clarification from the authors. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the work and framing criticisms constructively. They use phrases like 'I would suspect' and 'as far as I can tell' to soften potential criticisms, and show willingness to update their view based on author feedback. The reviewer also provides helpful suggestions for improvement and additional references, which is a courteous approach in academic review.""]"
"['I have no major complaints with this work.  It is well presented and easily understandable. I agree with the claim that the largest gains are largely syntactic, but this leads me to wonder about more tail phenomena.   PP attachment is a classic example of a syntactic decision requiring semantics, but one could also imagine doing a CCG supertagging analysis to see how well the model captures specific long-tail phenomena.  Though a very different task Vaswani et al 16, for example, showed how bi-LSTMs were necessary for certain constructions (presumably current models would perform much better and may capture this information already).\n\nAn important caveat of these results is that the evaluation (by necessity) is occurring in English.  Discourse in a pro-drop language would presumably require longer contexts than many of these approaches currently handle.', 'This paper provides new insights on what is captured contextualized word embeddings by compiling a set of “edge probing” tasks.  This is not the first paper to attempt this type of analysis, but the results seem pretty thorough and cover a wider range of tasks than some similar previous works.  The findings in this paper are very timely and relevant given the increasing usage of these types of embeddings.  I imagine that the edge probing tasks could be extended towards looking for other linguistic attributes getting encoded in these embeddings.\n\nQuestions & other remarks:\n-The discussion of the tables and graphs in the running text feels a bit condensed and at times unclear about which rows are being referred to.\n-In figures 2 & 3: what are the tinted areas around the lines signifying here? Standard deviation?  Standard error?  Confidence intervals?\n-It seems the orthonormal encoder actually outperforms the full elmo model with the learned weights on the Winograd Schema.  Can the authors comment on this a bit more?\n', '\nThis is a nice paper that attempts to tease apart some questions about the effectiveness of contextual word embeddings (ELMo, CoVe, and the Transformer LM). The main question is about the value of context in these representations, and in particular how their ability to encode context allows them to also (implicitly) represent linguistic properties of words. What I really like about the paper is the “Edge probing” method it introduces. The idea is to probe the representations using diagnostic classifiers—something that’s already widespread practice—but to focus on the relationship between spans rather than individual words. This is really nice because it enables them to look at more than just tagging problems: the paper looks at syntactic constituency, dependencies, entity labels, and semantic role labeling. I think the combination of an interesting research question and a new method (which will probably be picked up by others working in this area) make this a strong candidate for ICLR. The paper is well-written and experimentally thorough.\n\nNitpick: It would be nice to see some examples of cases where the edge probe is correct, and where it isn’t.']","[70, 70, 90]","[80, 60, 80]","[""The sentiment score is 70 (positive) because the reviewer starts by saying they have 'no major complaints' and describes the work as 'well presented and easily understandable'. They agree with the main claim and offer constructive suggestions for further analysis, indicating overall approval. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the work's strengths, and frames suggestions as possibilities to consider rather than criticisms. They also recognize the necessity of certain limitations in the study. The tone is professional and collegial throughout."", ""The sentiment score is 70 (positive) because the reviewer expresses that the paper provides new insights, is thorough, timely, and relevant. They also suggest potential extensions, indicating interest in the work. The politeness score is 60 (moderately polite) as the reviewer uses respectful language, frames criticisms as questions or remarks, and acknowledges the paper's contributions. The reviewer doesn't use overly formal or deferential language, maintaining a professional tone. The sentiment isn't 100 due to some minor criticisms, and the politeness isn't 100 as it's not excessively formal or complimentary."", ""The sentiment score is 90 because the reviewer uses very positive language throughout, calling it a 'nice paper' with a 'strong' method that will likely be adopted by others. They praise the paper's writing, experimental thoroughness, and consider it a 'strong candidate for ICLR'. The only slight negative is a minor 'nitpick' at the end. The politeness score is 80 because the reviewer uses respectful and encouraging language, acknowledging the paper's strengths and contributions. They offer constructive feedback in a gentle way ('It would be nice to see...') rather than demanding changes. The tone is professional and courteous throughout, without any harsh criticism.""]"
"[""\nThe authors make a case that deep networks are biased\ntoward fitting data with simple functions.\n\nThe start by examining the priors on classifiers obtained by sampling\nthe weights of a neural network according to different distributions.  They do this\nin two ways.  First, they examine properties of the distribution\non binary-valued functions on seven boolean inputs obtained by\nsampling the weights of a small neural network.  They also empirically compare\nthe labelings obtained by sampling the weights of a network with\nlabelings obtained from a Gaussian process model arising from earlier\nwork.\n\nNext, they analyze the complexity of the functions produced, using\ndifferent measures of the complexity of boolean functions.  A\nfavorite of theirs is something that they call Lempel-Ziv complexity,\nwhich is measured by choosing an arbitrarily ordering of the\ndomain, writing the outputs of the function in that ordering,\nand looking at how well the Lempel-Ziv algorithm compresses this\nsequence.  I am not convinced that this is the most meaningful\nand fundamental measure of the complexity of functions.\n(In the supplementary material, they examine some others.\nThey show plots relating the different measures in the body\nof the paper.  None of the measures is specified in detail in the\nbody of the paper. They provide plots relating these complexity\nmeasures, but they don't demonstrate a very close connection.)\n\nThe authors then evaluate the generalization bound obtained by\napplying a PAC Bayes bound, together with the assumption that\nthe training process produces weights sampled from the distribution\nobtained by conditioning weights chosen according to the random\ninitialization on the event that they fit they fit the training\ndata perfectly.  They do this for small networks and simple datasets.\nThey bounds are loose, but not vacuous, and follow the same order\nof difficulty on a handful of datasets as the true generalization\nerror.\n\nIn all of their experiments, they stop training when the training\naccuracy reaches 100%, where papers like https://arxiv.org/pdf/1706.08947.pdf\nhave found that continuing training past this point further improves test\naccuracy.  The experiments all use architectures that are\nquite dissimilar to what is commonly used in practice, and\nachieve much worse accuracy, so that a reader is concerned\nthat the results differ qualitatively in other respects.\n\nI do not find it surprising that randomly sampling parameters\nof deep networks leads to simple functions.\n\nPapers like the Soudry, et al paper cited in this submission are\ninconsistent with the assumption in the paper that SGD samples\nparameters uniformly.\n\nIt is not clear to me how many hidden layers were used for the\nresults in Table 1 (is it four?).  \n\nI did find it interesting to see exactly how concentrated the\ndistribution of functions obtained in their 7-input experiment\nwas, and also found results on the agreement of the Gaussian process\nmodels with the randomly sampled weight interesting, as far as they\nwent.  Overall, I am not sure that this paper provided enough\nfundamental new insight to be published in ICLR.\n"", 'This paper propose an interesting perspective to explain the generalization behaviors of large over-parameterized neural networks by saying that the parameter-function map in neural networks are biased towards ""simple"" functions, and through a PAC-Bayes argument, the generalization behavior will be good if the target concept is also ""simple"". I like the perspective of view that combines the ""complexity"" of both the algorithm bias and the target concept in the view of generalization. However, the implementation and presentation of the paper could be improved.\n\nFirst of all, the paper is a bit difficult to follow as some important information is either missing or only available in the appendix. For example, in Section 2, to measure the properties of the parameter-function mapping, a simple boolean neural network is explored. However, it is not clear how the sampling procedure is carried out. There is also a \'training set of 64 examples\', and it not obvious to the reader how this training set is used in this sample of neural network parameters.\n\nFollowing that, the paper uses Gaussian Process and Expectation-Propagation to approximately compute P(U). But the description is brief and vague (to non-expert in GP or EP). As one of the main contribution stated in the introduction, it would be better if more details are included.\n\nMoreover, the generalization bound is derived with the assumption that the learning algorithm uniformly sample from the set of all hypothesis that is consistent with a given training set. It is unlikely that this is what SGD is doing. But explicit experiments to verify how close is the real-world behavior to the hypothetical behavior would be helpful.\n\nThe experiment in section 6 that verify the \'complexity\' of \'high-probability\' functions in the given prior is very interesting. It would be good if some kind of measurements more directly on the real world tasks could be done, which will better support the argument made in the paper.\n', 'The paper brings a fresh study to the generalization capabilities of (deep) neural networks, with the help of an original use of PAC-Bayesian learning theory and some empirically backed intuitions.\n\nExpressing the prior over the input-output function space generated by the neural network is very interesting. This provides an original analysis compared to the common PAC-Bayesian analysis of neural networks that express the prior over network parameters space. The theoretical study here appears simple (noteworthy, it is based one of the very first PAC-Bayesian theorems of McAllester that is not the most used nowadays), and the study is conducted mainly by empirical observation. Nevertheless, the experiments leading to these observations are cleverly designed, and I think it gives great insights and might open the way to other interesting studies.\n\nOverall, the paper is enjoyable to read. I also appreciate the completeness of the supplementary material. I recommend the paper acceptance, but I would like the authors to consider the concerns I rise below:\n- The paper title is a bit presumptuous. The paper presents a conjunction backed by empirical evidence on some not-so-deep neural networks. Even if I consider it as an important piece of work, it does not provide any definitive answer to the generalization puzzle. \n- Many peer-reviewed publications are cited as arXiv preprints. Please carefully complete the bibliography. Some papers are referenced by the name, title and year only (Smith and Le 2018; Zhang et al, 2017)\n- I recommend adding to the learning curves of Figures 2 and 3 the loss on the training set. \n\nOther minor comments and typos:\n- Intro: Please define ""parameter-function"" map \n- Page 4: Missing parentheses around Mand et al. (2017)\n- SGD has not had time ==> SGD did not have time\n- Please refers to the definition in the supplementary material/information the first time you mention Lempel-Ziv complexity.\n- Please mention that SI stands for Supplementary Information\n']","[-30, 20, 70]","[20, 60, 80]","[""The sentiment score is -30 because the reviewer expresses several concerns and criticisms about the paper, such as questioning the choice of complexity measure, noting loose bounds, and stating that the experiments use dissimilar architectures to common practice. However, they do find some aspects interesting, which prevents the score from being more negative. The politeness score is 20 because the reviewer uses professional and neutral language throughout, avoiding harsh criticism. They acknowledge some positive aspects and frame their concerns as observations rather than attacks. The reviewer maintains a respectful tone while still clearly communicating their reservations about the paper's contributions."", ""The sentiment score is slightly positive (20) because the reviewer starts by acknowledging the paper's 'interesting perspective' and mentions liking the approach. However, they also point out several areas for improvement, which tempers the overall positivity. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offering constructive criticism with phrases like 'it would be better if' and 'it would be good if'. They avoid harsh criticism and frame their suggestions as ways to improve the paper rather than pointing out flaws. The reviewer maintains a professional and courteous tone while providing detailed feedback."", ""The sentiment score is 70 (positive) because the reviewer recommends acceptance of the paper and uses phrases like 'fresh study', 'original use', 'very interesting', and 'great insights'. They express overall positive sentiment about the paper's contribution and readability. However, it's not 100 because there are some concerns and suggestions for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively. Phrases like 'I recommend', 'I would like the authors to consider', and 'Please' indicate a polite tone. The reviewer also balances praise with constructive feedback, maintaining a courteous and professional tone throughout.""]"
"[""Adversarial attacks and defences are of growing popularity now a days. As AI starts to be present everywhere, more and more people can start to try to attack those systems. Critical systems such as security systems are the ones that can suffer more from those attacks. In this paper the case of vehicles that attack an object detection system by trying to not be detected are tackled.\n\nThe proposed system is trained and evaluated in a simulation environment. A set of possible camouflage patterns are proposed and the system learns how to setup those in the cars to reduce the performance of the detection system. Two methods are proposed. Those methods are based on Expectation over transformation method. This method requires the simulator to be differentiable which is not the case with Unity/Unreal environments. The methods proposed skip the need of the simulator to be differentiable by approximating it with a neural network.\n\nThe obtained results reduce the effectivity of the detection system. The methods are compared with two trivial baselines. Isn't there any other state of the art methods to compare with?\n\nThe paper is well written, the results are ok, the related work is comprehensive and the formulation is correct. The method is simply but effective. Some minor comments:\n - Is the simulator used CARLA? Or is a new one? Where are the 3D assets extracted from?\n - Two methods are proposed but I only find results for one"", 'This is an interesting paper targeting adversarial learning for interfering car detection. The approach is to learn camouflage patterns, which will be rendered as a texture on 3D car models in urban and mountain scenes, that minimizes car detection scores by Mask R-CNN and YOLOv3-SPP.\n\nDifferent from image-based adversarial learning, this paper examines whether 3D car textures can degrade car detection quality of recent neural network object detectors. This aspect is important because the learned patterns can be used in the painting of real-world cars to avoid automatic car detection in a parking lot or on a highway.\n\nThe experimental results show that the car detection performance significantly drops by learned vehicle camouflages.\n\n Major comments:\n\n- It is not clear how learned camouflage patters are different in two scenes. Ideally, we should find one single camouflage patter that can deceive the two or more object detection systems in any scenes.\n\nMinor comments:\n\n- In abstract, it is not good that you evaluated your study as ""interesting"". I recommend another word choice.\n', 'The authors investigate the problem of learning a camouflage pattern which, when applied to a simulated vehicle, will prevent an object detector from detecting it. The problem is frames as finding the camouflage pattern which minimises the expected decision scores from the detector over a distribution of possible views of this pattern applied to a vehicle (e.g. vantage point, background, etc). This expectation is approximated by sampling detector scores when applying the detector considered to images synthesised using a number of vantage points and scene contexts. In order to generate a gradient signal with respect to the camouflage applied (the simulated image rendering is non-differentiable) the approach considers learning a clone network which takes as input the camouflage pattern, the vehicle model and a given environment and outputs the vehicle detector’s devision values. The clone network and the optimal camouflage are learned alternately in order to obtain a relatively faithful approximation. The approach is evaluated in simulation using two standard object detectors (Mask R-CNN and YOLOv3) on two vehicle models over a range of transformations.\n\nPros:\n———\n- interesting challenge\n\n- the clone network provides an interesting solution to the challenge of having a (non-differentiable) simulator in the loop.\n\nCons:\n———\n- the fact that this is done in simulation is understandable but to some degree negates the authors’ point that physicality matters because it is harder than images. How effective is a learned camouflages in reality? It would be great to get at least some evidence of this.\n\n- if the sim-2-real gap is too big it is not clear how this approach could ever be feasibly employed in the real world. Some intuition here would add value.\n\n- the approach presented critically hinges on the quality of the clone network. Some analysis of robustness of the approach with respect to network performance would add value.\n\n- little is offered in terms of analysis of the camouflages generated. The three failure modes triggered and discussed are intuitive. But are there any insights available as to what aspect of the camouflages triggers these behaviours in the object detectors? This could also add significant value.\n\nIn summary, this work addresses an interesting problem but it is not clear how impactful the approach will be in real-world settings and hence how significant it it. Some of the more technically interesting aspects of the submission (e.g. the quality of the clone network, any learning derived from the camouflages generated) are not explored. \n\nMisc comments: \n- equs 1, 2 & 3: min_* should be argmin_*\n']","[50, 60, -20]","[80, 80, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's relevance, comprehensive related work, and correct formulation. They describe the results as 'ok' and the method as 'simple but effective'. However, they also raise questions and point out some minor issues, which prevents a higher positive score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames their criticisms as questions or 'minor comments' rather than direct criticisms. The reviewer maintains a professional and constructive tone throughout the review."", ""The sentiment score is 60 (positive) because the reviewer describes the paper as 'interesting' and acknowledges its importance in the field. They highlight the novelty of the approach and the significant results. However, it's not extremely positive due to the presence of major and minor comments for improvement. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offering constructive feedback. They use phrases like 'I recommend' instead of demanding changes. The only slightly negative point is the criticism of the authors' use of 'interesting' in the abstract, but this is presented as a minor comment and phrased politely."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the work as 'interesting' and notes some pros, they express several significant concerns and limitations of the study. The cons outweigh the pros, and the summary suggests that the impact and significance of the work are unclear. The politeness score is moderately positive (60) as the reviewer uses professional and respectful language throughout. They acknowledge the interesting aspects of the work and frame their criticisms constructively, suggesting ways to improve the study rather than dismissing it outright. The use of phrases like 'it would be great to' and 'some analysis... would add value' contribute to the polite tone.""]"
"['In this paper the authors present mutual posterior divergence regularization, a data-dependent regularization for the ELBO that enforces diversity and smoothness of the variational posteriors. The experiments show the effectiveness of the model for density estimation and representation learning.\nThis is an interesting paper dealing with the important issues of fully exploiting the stochastic part of VAE models and avoiding inactive latent units in the presence of very expressive decoders. The paper reads well and is well motivated. \n\nThe authors claim that their method is ""encouraging the learned variational posteriors to be diverse"". While it is important to have models that can use well the latent space, the constraints that are encoded seem too strong. If two data points are very similar, why should there be a term encouraging their posterior approximation to be different? In this case, their true posteriors will be in fact be similar, so it seems counter-intuitive to force their approximations to be different.\n\nThe numerical results seem promising, but I think they could be further improved and made more convincing.\n- For the density estimation experiments, while there is an improvement in terms of NLL thanks to the new regularizer, it is not clear which is the additional computational burden. How much longer does it takes to train the model when computing all the regularization terms in the experiments with batch size 100? \n- I am not completely convinced by the claims on the ability of the regularizer to improve the learned representations. K-means implicitly assumes that the data manifold is Euclidean. However, as shown for example by [Arvanitidis et al. Latent space oddity: on the curvature of deep generative models, ICLR 2018] and other authors, the latent manifold of VAEs is not Euclidean, and curved riemannian manifolds should be used when computing distances and performing clustering. Applying k-means in the high dimensional latent spaces of ResNet VAE and VLAE does not seem therefore a good idea.\nOne possible reason why your MAE model may perform better in the unsupervised clustering of table 2 is that the terms added to the elbo by the regularizer may force the space to be more Euclidean (e.g. the squared difference term in the Gaussian KL) and therefore more suitable for k-means. \n- The semi-supervised classification experiment is definitely better to assess the representation learning capabilities, but KNN suffers with the same issues with the Euclidean distance as in the k-means experiments, and the linear classifier may not be flexible enough for non-euclidean and non-linear manifolds. Have you tried any other non-linear classifiers?\n- Comparisons with other methods that aim at making the model learn better representation (such as the kl-annealing of the beta-vae) would be useful.\n- The lack of improvements on the natural image task is a bit concerning for the generalizability of the results.\n\nTypos and minor comments:\n- devergence -> divergence in introduction\n- assistant -> assistance in 2.3\n- the items (1) and (2) in 3.1 are not very clear\n- set -> sets in 3.2\n- achieving -> achieve below theorem 1\n- cluatering -> clustering in table 2', ""This paper presents a new regularization technique for VAEs similar in motivation and form to the work on InfoVAE.  The basic intuition is to encourage different training samples to occupy different parts of z-space, by maximizing the expected KL divergence between pairwise posteriors, which they call Mutual Posterior-Divergence (MPD).  They show that this objective is a symmetric version (sum of the forward and reverse KL) of the Mutual Info regularization used by the InfoVAE.  In practice however, they do not actually use this objective.  They use a different regularization which is based on the MPD loss but they say is more stable because it's always greater than zero, and ensures that all latent dimensions are used.  In addition to the MPD based term, they also add another term which encouraging the pairwise KL-divergences to have a low standard-deviation, to encourge more even spreading over the z-space rather than the clumpy distribution that they observed with only the MPD based term.\n\nThey show state of the art results on MNIST and Omniglot, improving over the VLAE.  But on natural data (CIFAR10), their results are worse than VLAE.  \n\nPros:\n\t1. The technique has a nice intuitive (but not particularly novel) motivation which is kinda-sorta theoretically motivated if you squint at it hard enough.\n\t2. The results on the simple datasets are solid and encouraging.\n\nCons:\n\t1.  The practical implementation is a bit ad-hoc and requires turn two additional hyper parameters (like most regularization techniques).\n\t2. The basic motivation and observations are the same as InfoVAE, so it's not completely novel.\n\t3. The CIFAR10 results are bit concerning, and one can't help but wondering if the technique really only helps when the data has simpler shared structure.\n\nOverall:  I think the idea is interesting enough, and the results encouraging enough to be just above the bar for acceptance at ICLR.\n\nI have the following question for the authors:\n\n\t1. Why do you use the truncated pixelcnn on CIFAR10?  Did you try it with the more expressive decoder (as was used on the binary images) and got worse results?  or is there some other justification for this difference?\n\nI would have like to see the following modifications to the paper:\n\n\t1. The paper essentially presents two related but separate regularization techniques.  It would be nice to have ablation results to show how each of these perform on their own.\n\t2. Bonus points for showing results which combine VLAE (which already has a form of the MPD regularization) with the smoothness regularization.\n\t3. It would be nice to see samples from VLVAE in Figure 3 next to the MAE samples to more easily compare them directly.\n\t4. There are many grammatical and English mistakes.  The paper is still quite readably, but please make sure the paper is proofread by a native English speaker.\n"", 'This paper proposes changes to the ELBO loss used to train VAEs, to avoid posterior collapse. They motivate their additional components rather differently than what has been done in the literature so far, which I found quite interesting.\nThey compare against appropriate baselines, on MNIST and OMNIGLOT, in a complete way.\n\nOverall, I really enjoyed this paper, which proposed a novel way to regularise posteriors to force them to encode information. However, I have some reservations (see below), and looking squarely at the results, they do not seem to improve over existing models in a significant manner as of now.\n\nCritics:\n1.\tThe main idea of the paper, in introducing a measure of diversity, was well explained, and is well supported in its connection to the Mutual Information maximization framing. One relevant citation for that is Esmaeili et al. 2018, which breaks the ELBO into its components even further, and might help shed light on the exact components that this new paper are introducing. E.g. how would MAE fit in their Table A.2?\n2.\tOn the contrary, the requirement to add a “Measure of Smoothness” was less clear and justified. Figure 1 was hard to understand (a better caption might help), and overall looking at the results, it is even unclear if having L_smooth is required at all?\n\u2028Its effect in Table 1, 2 and 3 look marginal at best?\u2028\nGiven that it is not theoretically supported at all, it may be interesting to understand why and when it really helps.\n3.\tOne question that came up is “how much variance does the L_diverse term has”? If you’re using a single minibatch to get this MC estimate, I’m unsure how accurate it will be. Did changing M affect the results?\n4.\tL_diverse ends up being a symmetric version of the MI. What would happen if that was a Jensen-Shannon Divergence instead? This would be a more principled way to symmetrically compare q(z|x) and q(z).\n5.\tOne aspect that was quite lacking from the paper is an actual exploration of the latent space obtained. \u2028The authors claim that their losses would control the geometry of the latents and provide smooth, diverse and well-behaved representations. Is it the case?\n\u2028Can you perform latent traversals, or look at what information is represented by different latents?\u2028 \nThis could actually lend support to using both new terms in your loss.\n6.\tReconstructions on MNIST by VLAE seem rather worst than what can be seen in the original publication of Chen et al. 2017? Considering that the re-implementation seems just as good in Table 1 and 3, is this discrepancy surprising?\n7.\tFigure 2 would be easier to read by moving the columns apart (i.e. 3 blocks of 3 columns).\n\nOverall, I think this is an interesting paper which deserves to be shown at ICLR, but I would like to understand if L_smooth is really needed, and why results are not much better than VLAE.\n\nTypos:\n-\tKL Varnishing -> vanishing surely?\n-\tDevergence -> divergence\n']","[20, 20, 50]","[70, 60, 80]","[""The sentiment score is slightly positive (20) because the reviewer describes the paper as 'interesting' and dealing with 'important issues'. They also mention that the paper 'reads well and is well motivated' and that the numerical results 'seem promising'. However, the score is not higher due to several criticisms and concerns raised about the methodology and results. The politeness score is relatively high (70) as the reviewer uses respectful language throughout, offers constructive criticism, and phrases their concerns as suggestions or questions rather than direct criticisms. They also acknowledge the positive aspects of the work before diving into areas for improvement. The presence of a 'minor comments' section for typos also indicates a thorough and considerate review process."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges the paper's interesting ideas and encouraging results on simple datasets, stating it's 'just above the bar for acceptance at ICLR'. However, they also point out several cons and areas for improvement, which prevents a higher positive score. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, offers constructive feedback, and frames criticisms as suggestions for improvement rather than harsh judgments. They also use phrases like 'I would have liked to see' and 'It would be nice to see', which are polite ways of suggesting changes. The mention of grammatical errors is done tactfully, asking for proofreading rather than criticizing directly."", ""Sentiment score: The review starts positively, stating the reviewer 'really enjoyed this paper' and found it 'quite interesting'. However, they also express 'some reservations' and note that the results 'do not seem to improve over existing models in a significant manner'. This mix of positive and negative comments suggests a moderately positive sentiment, hence the score of 50.\n\nPoliteness score: The reviewer uses polite and constructive language throughout. They offer specific, detailed feedback and suggestions for improvement without being harsh or dismissive. Phrases like 'I really enjoyed this paper' and 'This paper deserves to be shown at ICLR' demonstrate respect for the authors' work. The reviewer also frames criticisms as questions or suggestions rather than direct attacks. The high politeness score of 80 reflects this consistently courteous tone.""]"
"['Summary: \n \nThe paper provides the convergence analysis at linear rate of gradient descent to global minima for deep linear neural networks – the fully-connected neural networks with linear activation with l2 loss. The convergence only works under two necessary assumptions on initialization: “weight matrices at initialization are approximately balanced” and “the initial loss is smaller than the loss of any rank-deficient solution”. The result of this work is similar to that of Barlett et al. 2018, but the difference is that, in Barlett et al. 2018, they consider a subclass of linear neural networks (linear residual networks – a subclass of linear neural networks which the input, output and all hidden layers are the same dimensions). \n \nComments: \n \nThis paper focuses on theoretical aspect of Deep Learning. Yes, theoretical study of gradient-based optimization in deep learning is still open and needs to spread more. I have the following comments and questions to the author(s) and hope to discuss further during the rebuttal period: \n \n1) Most of the deep learning applications are well-known used the neural networks with non-linear activation (specifically ReLU). Could you please provide any successful applications that linear neural networks could achieve better performance over the “non-linear” one? Yes, more layers may lead to better performance since we have more parameters. However, it is still not clear that which one is better between “linear” and “non-linear” with the same size of networks. I am not sure if this linear neural networks could generalize well. \n \n2) For N=1, the problem should become linear regression with strongly convex loss, which means that there exists a unique W: y = W*x in order to minimize the loss. Hence, if W = W_N*....*W_1, the problem becomes non-convex w.r.t parameters W_N, ...., W_1 but all the minima could be global. Can you please provide some intuitions why the loss function could have saddle points? Also, is not easier to just solve the minimization problem on W?\n\n3) Similar with l2 loss, it seems that the problem needs to be restricted on l2 loss. In understand that it could have in some applications. Do you try to think of different loss for example in binary classification problems? \n \n4) I wonder about the constant “c > 0” in the definition 2 and it would use it to determine the learning rate. Do you think that in order to satisfy the definition 2 for the most cases, constant c would be (arbitrarily) small or may be very close to 0? If so, the convergence rate may be affected in this case. \n \n5) The result of Theorem 2 is nice and seems new in term of probabilistic bound.  I did not see the similar result in the existing literature for neural networks. \n \n6)  It would be nice if the author(s) could provide some experiments to verify the theory. I am also curious to know what performance it could achieve for this kind of networks. \n \nI would love to discuss with the author(s) during the rebuttal period. ', 'This paper studies the convergence of gradient descent on the squared loss of deep linear neural networks. The authors prove linear convergence rate if (1) the network dimensions are big enough so that the full product can have full rank, (2) the singular values of each weight matrices are approximately the same, (3) the initialized point is “close enough” to the target.\n\nFirst of all, this paper is well-written. It reads smoothly, effectively presents the key ideas and implications of the result, and properly answers to possible concerns that arise while reading. The improvement over the previous work ([Bartlett et al 18’]) is quite substantial.\n\nDeep linear neural networks are important, and having a good understanding of linear neural networks can provide us useful insights for understanding the more complex ones, i.e., the nonlinear neural networks. In that regard, I really liked the discussion at the end of Section 3.1. My general opinion for this paper is acceptance, but I also have a number of concerns and questions.\n\nMy main concern about the study of GD on linear neural network is whether we really get any “benefit” or “acceleration” from depth, i.e., is GD on linear neural nets any faster than GD on linear models. It’s been shown that we get acceleration in some cases (e.g., $\\ell_p$ regression when $p>2$ [Arora et al. 18’]), but some other results (e.g., [Shamir 18’] mentioned in Section 5) show that GD on linear neural nets (when weight matrices are all scalar) suffer exponential (in depth) increase in convergence time at near zero region, due to the vanishing gradient phenomenon. From my understanding, this paper circumvents this problem by assuming deficiency margin, because in the setting of [Shamir 18’], deficiency margin means that the initialized product ($W_{1:N}$) has the same sign as $\\Phi$ and far enough from zero, so we don’t have to pass through the near-zero region.\n\nEven with the deficiency margin assumption, the exponential dependence in depth can also be observed in this paper, if we use independent initialization of each weight matrices. In Claim 3, in order to get the probability 0.49 result, the margin $c$ must be very small (O(1/N^N)) as N goes to infinity, resulting in very small $\\delta$ and $\\eta$ in Theorem 1, and convergence time $T$ exploding in depth. On the other hand, if we fix $0 < c < 1$, then the probability of satisfying deficiency margin will be smaller and smaller as $N$ increases. Is this “blow-up in N” problem due to the fact that the loss is l2? Or am I making false claims? I would like to hear the authors’ opinion about this.\n\nThe paper proposes a balanced initialization scheme that doesn’t suffer exponential blow up (Procedure 1 and Theorem 2), but even with this, the learning rate must decay to zero in polynomial rate in N, also resulting in polynomial increase in convergence time as depth increases. Moreover, this type of initialization scheme (specifically tailored for linear neural networks) is not what people would do in practice; we normally would initialize each layer at random, and may suffer the problems discussed in the above paragraph. That is why I’d love to hear about the authors’ future work on layer-wise independent initialization, as noted in the conclusion section.\n\nBelow, I’ll list specific concerns/questions/comments.\n* In my opinion, the statements about “necessity” of two key assumptions are too strong, because the authors only provide counterexamples of non-convergence. As [Theorem 3, Shamir 18’] shows (although in scalar case), even when the assumptions are not satisfied, a convergence rate $O(exp(N) * log(1/\\epsilon))$ is possible. It will be an interesting future work to clearly delineate the boundary between convergence and non-convergence.\n\n* In Thm 2 and Claim 3, what happens if dimension $d_0$ is smaller? What is the reason that you had to restrict it to high dimension? Is it due to high variance with few samples?\n\n* In Thm 2, constants $d’_0$ and $a$ hide the dependence of the result on p, but I would suggest stating the dependence of those parameters on p, and also dependence on other parameters such as N.\n\n* In Section 5, there is a statement “This negative result, a theoretical manifestation of the “vanishing gradient problem”, is circumvented by balanced initialization.” Can you elaborate more on that? If my understanding is correct, there is still $\\sigma_min$ multiplier in Eq (9), which means that at near-zero regions, the gradient will still vanish.\n\nI appreciate the authors for their efforts, especially on the heavy math in the proof of the main theorem. I would like to hear your comments and/or corrections (especially on my “T blowing up in N” claim) and discuss further.', 'This paper continues the recent line of study on the convergence behaviour of gradient descent for deep linear neural networks. For more than 2 layers, the optimization problem is nonconvex and it is known strict saddle points exist. The main contribution is a relaxation of the balancedness condition in previous work by Arora et al and a new deficiency margin condition, which together allowed the authors to prove that gradient descent will converge to an epsilon solution in at most O(log 1/epsilon) iterations (under reasonable assumptions on step size and other parameters). Examples on how to satisfy the two conditions are discussed. Overall, the obtained results appear to be a solid contribution beyond our current understanding of deep linear neural networks, and potentially may be helpful towards our understanding of deep nonlinear neural networks.\n\nThis paper is very well-written. The authors gave an elegant short proof for the gradient flow case and spent efforts in proving the discretized version as well. The discussion of related works seems to be appropriate and thorough. \n\nOne thing I would love to see more discussions about is the deficiency margin assumption. I know the authors provided some argument about its necessity in the appendix, but is it possible that under the deficiency margin assumption, the nonconvex optimization problem is really ""trivial"" hence the linear convergence of gradient descent? For instance, can one prove that on this level set there still could be some (strict) saddle-point? And what if Phi is rank-deficient?\n\nIn the paragraph proceeding Section 3.2, the authors mentioned that ""overly small standard deviation will render high magnitude for the deficiency margin, and therefore fast convergence improbable."" Is there a typo here? Do you mean  a smaller deficiency margin? If not, can you please provide more details?\n\nLastly, it would be great if the authors could complement the theoretical results with some numerical experiments, especially to test the initialization strategies in Section 3.3.']","[20, 50, 80]","[80, 80, 90]","[""The sentiment score is slightly positive (20) because while the reviewer acknowledges the theoretical contribution of the paper and finds some aspects 'nice' and 'new', they also raise several questions and suggest areas for improvement. The overall tone is constructive rather than overtly critical or enthusiastic. The politeness score is high (80) as the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and expresses a desire for further discussion. They use phrases like 'Could you please...', 'I wonder...', and 'It would be nice if...' which contribute to a polite and constructive tone. The reviewer also expresses interest in further discussion during the rebuttal period, indicating a collegial approach."", ""The sentiment score is 50 (moderately positive) because the reviewer expresses a generally favorable opinion of the paper, stating 'My general opinion for this paper is acceptance' and praising aspects like its writing quality and substantial improvement over previous work. However, the reviewer also raises several concerns and questions, which tempers the overall positivity. The politeness score is 80 (quite polite) due to the reviewer's consistently respectful and constructive tone. They use phrases like 'I really liked', 'I appreciate the authors for their efforts', and 'I would like to hear your comments', which demonstrate courtesy and professionalism. The reviewer also balances criticism with praise and frames concerns as questions or areas for discussion rather than outright criticisms."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, describing it as a 'solid contribution' and 'very well-written'. They praise the authors' efforts and the potential impact of the work. The few criticisms are presented as suggestions for improvement rather than major flaws. The politeness score is 90 (very polite) due to the consistently respectful and constructive tone. The reviewer uses phrases like 'I would love to see' and 'it would be great if' when making suggestions, and acknowledges the authors' efforts throughout. The language is professional and courteous, avoiding any harsh or negative phrasing.""]"
"['Strengths:\n- Good coverage of related work\n- Clear presentation of the methods\n- Evaluation using established SemEval datasets\n\n\nWeaknesses:\n1. It is not entirely clear what is the connection between fuzzy bag of words and DynaMax. In principle DynaMax can work with other methods too. This point should be elaborated a bit more.\n2. It is claimed that the this paper shows that max-pooled word vectors are a special case of fuzzy bag of words. This is not correct. The paper shows how to ""convert"" one to the other. \n3. It is also claimed that point 2 above implies that max-pooled vectors should be compared with the fuzzy Jaccard index instead of cosine similarity. There is no proof or substantial justification to support this. \n4. Some relevant work that is missing:\n- De Boom, C., Van Canneyt, S., Demeester, T., Dhoedt, B.: Representation learning for very\nshort texts using weighted word embedding aggregation. Pattern Recognition Letters 80,\n150–156 (2016)\n- Kenter, T., De Rijke, M.: Short text similarity with word embeddings. In: International on\nConference on Information and Knowledge Management. pp. 1411–1420. ACM (2015)', ""This submission presents a simple model for sentence representation based on max-pooling of word vectors. The model is motivated by fuzzy-set theory, providing both a funded pooling scheme and a similarity score between documents. The proposed approach is evaluated on sentence similarity tasks (STS) and achieves very strong performance, comparable to state-of-the-art, computationally demanding methods.\n\nPros:\n+ The problem tackled by this paper is interesting and well motivated. Fast, efficient and non-parametric sentence similarity has tons of important applications (search, indexing, corpus mining).\n+ The proposed solution is elegant and very simple to implement. \n+ When compared to standard sentence representation models, the proposed approach has very good performance, while being very efficient. It only requires a matrix vector product and a dimension-wise max.\n+ The paper is very well written and flows nicely.\n+ Empirical results show significant differences between different word vectors. The simplicity of this approach makes it a good test bed for research on word vectors.\n\nCons:\n- Nothing much, really. \n- Eq. (3) is awkward, as it is a sequence of equalities, which has to be avoided. Moreover, if U is the identity, I don't think that the reader really need this Eq...\n\nI have several questions and remarks that, if answered would make the quality of the presentation better:\n\n* In infersent, the authors reported the performance of a randomly-initialized and max-pooled bi-lstm with fasttext vectors as the input lookup. This can be seen as an extreme case of the presented formalism, where the linear operator U is replaced by a complicated non linear function that is implemented by the random LSTM. Drawing that link, and maybe including this baseline in the results would be good.\n\n* Related to this previous question, several choices for U are discussed in the paper. However, only two are compared in the experiments. It would be interesting to have an experimental comparison of:\n- taking U = W\n- taking U = I\n- taking U as the principal directions of W\n- taking U as a random matrix, and comparing performance for different output dimensions. \n\nOverall, this paper is a very strong baseline paper. The presented model is elegant and efficient. I rate it as an 8 and await other reviews and the author's response."", ""This is one of the best papers I reviewed so far this year (ICLR, NIPS, ICML, AISTATS), in terms of both the writing and technical novelty.\n\nWriting: the author provided sufficient context and did comprehensive literature survey, which made the paper easily accessible to a larger audience. And the flow of this paper was very smooth and I personally enjoyed reading it.\n\nNovelty: I wouldn't say this paper proposed a groundbreaking innovation, however, compared to many other submissions that are more obscure rather than inspiring to the readers, this paper presented a very natural extension to something practitioners were already very familiar with: taking an average of word vectors for a sentence and measure by cosine similarity.  Both max pooling and Jaccard distance are not something new, but the author did a great job presenting the idea and proved it's effectiveness through extensive experiments. (disclaimer: I didn't follow the sentence embedding literature recently, and I would count on other reviewers to fact check the claimed novelty of this paper by the authors)\n\nSimplicity: besides the novelty mentioned above, what I enjoyed more about this paper is it's simplicity. Not just because it's easy to understand, but also it's easy to be reproduced by practitioners.\n\nQuibbles: the authors didn't provide error bar / confidence interval to the results presented in experiment session. I'd like to know whether the difference between baselines and proposed methods were significant or not.\n\nMiscellaneous: I have to say the authors provided a very eye-catching name to this paper as well, and the content of the paper didn't disappoint me neither. Well done :)\n""]","[-20, 90, 95]","[50, 80, 90]","[""The sentiment score is slightly negative (-20) because while the review acknowledges some strengths ('Good coverage of related work', 'Clear presentation of methods'), it focuses more on weaknesses and areas for improvement. The reviewer points out several issues with claims and connections made in the paper, as well as missing relevant work. However, the tone is not overly harsh, hence not an extremely negative score. The politeness score is moderately positive (50) as the reviewer uses neutral, professional language throughout. They begin by noting strengths before moving to weaknesses, which is a polite approach. The critique is direct but not rude, maintaining a respectful tone while providing specific, constructive feedback."", ""The sentiment score is 90 because the review is overwhelmingly positive. The reviewer lists several pros and only minor cons, describing the paper as 'very strong' and 'elegant'. They rate it highly (8/10) and express eagerness to see the authors' response. The politeness score is 80 because the language used is consistently respectful and constructive. The reviewer offers suggestions for improvement in a polite manner, using phrases like 'it would be interesting' and 'if answered would make the quality of the presentation better'. The tone is professional and encouraging throughout, without any harsh criticism."", ""The sentiment score is 95 because the reviewer expresses highly positive opinions throughout the review, calling it 'one of the best papers' they've reviewed, praising the writing, novelty, and simplicity. They use phrases like 'very smooth,' 'enjoyed reading it,' and 'well done,' indicating strong approval. The only minor criticism is about missing error bars, which slightly reduces the perfect score. The politeness score is 90 because the reviewer uses respectful and encouraging language throughout, such as 'the author provided,' 'I personally enjoyed,' and 'Well done :)'. They offer constructive feedback politely and even compliment the paper's title. The slightly lower score than sentiment is due to the review being professional rather than overly deferential.""]"
"['It is shown empirically that common algorithms used in supervised learning (SGD) yield networks for which such upper bound decreases as the number of hidden units increases. This might explain why in some cases overparametrized models have better generalization properties.\n\nThis paper tackles the important question of why in the context of supervised learning, overparametrized neural networks in practice generalize better. First, the concepts of \\textit{capacity} and \\textit{impact} of a hidden unit are introduced. Then, {\\bf Theorem 1} provides an upper bound for the empirical Rademacher complexity of the class of 1-layer networks with hidden units of bounded \\textit{capacity} and \\textit{impact}. Next, {\\bf Theorem 2} which is the main result, presents a new upper bound for the generalization error of 1-layer networks. An empirical comparison with existing generalization bounds is made and the presented bound is the only one that in practice decreases when the number of hidden units grows. Finally {\\bf Theorem 3} is presented, which provides a lower bound for the Rademacher complexity of a class of neural networks, and such bound is compared with existing lower bounds.\n\n## Strengths\n- The paper is theoretically sound, the statement of the theorems\n    are clear and the authors seem knowledgeable when bounding the\n    generalization error via Rademacher complexity estimation.\n\n- The paper is readable and the notation is consistent throughout.\n\n- The experimental section is well described, provides enough empirical\n    evidence for the claims made, and the plots are readable and well\n    presented, although they are best viewed on a screen.\n\n- The appendix provides proofs for the theoretical claims in the\n    paper. However, I cannot certify that they are correct.\n\n- The problem studied is not new, but to my knowledge the\n    presented bounds are novel and the concepts of capacity and\n    impact are new. Theorem 3 improves substantially over\n    previous results.\n\n- The ideas presented in the paper might be useful for other researchers\n    that could build upon them, and attempt to extend and generalize\n    the results to different network architectures.\n\n- The authors acknowledge that there might be other reasons\n    that could also explain the better generalization properties in the\n    over-parameterized regime, and tone down their claims accordingly.\n\n## Weaknesses\n\\begin{itemize}\n- The abstract reads ""Our capacity bound correlates with the behavior\n    of test error with increasing network sizes ..."", it should\n    be pointed out that the actual bound increases with increasing\n    network size (because of a sqrt(h/m) term), and that such claim\n    holds only in practice.\n\n- In page 8 (discussion following Theorem 3) the claim\n    ""... all the previous capacity lower bounds for spectral\n        norm bounded classes of neural networks (...) correspond to\n        the Lipschitz constant of the network. Our lower bound strictly\n    improves over this ..."", is not clear. Perhaps a more concise\n    presentation of the argument is needed. In particular it is not clear\n    how a lower bound for the Rademacher complexity of F_W translates into a\n    lower bound for the rademacher complexity of l_\\gamma F_W. This makes the claim of tightness of Theorem 1 not clear. Also this makes\n    the initial claim about the tightness of Theorem 2 not clear.\n', 'Let me start by apologizing for the delayed review - in fact I was asked today to replace an earlier assigned reviewer. Hopefully the clarifications I request won\'t be too time consuming to meet the deadline coming up. \n\n###\n\nFirst of all, the problem which the authors are attempting to answer is quite important: the effect of over-parametrization is not well understood on a theoretical level. As the paper illustrate, 2-layer networks are already capable of generalizing while being over-parameterized, therefore justifying their setting. \n\nNext this paper motivates the study of complexity quantities that tend to decrease with the number of parameters, in particular figure 3 motivates the conjecture that the complexity measure in Theorem 2 can control generalization error. The paper also does a great job comparing related work, motivating their results. \n\n###\n\nAt this point, I would like to request a couple of clarifications in the proofs. Perhaps it\'s due to the fact that I only spent a day reading, but at least I think we could improve on its readability. Regardless, I currently do not yet trust a couple of the proofs, and I believe the acceptance of this paper should be conditioned on confirming the correctness of these proofs.\n\n(1) Let\'s start with Lemma 10. In the middle equation block, we obtain a bound \n  \\| alpha^prime \\|_p^p <= beta^p ( 1 + D/K )\nand the proof concludes alpha^prime is in Q. However this cannot be the case for all alpha^prime. \n\nConsider x=0 which is in S_{p, beta}^D, then we have alpha^prime = 0 as well. In the definition of Q, we require all the j\'s to sum up to K+D, which is not met here. \n\nAt the same time, the next claim \n  \\| alpha \\|_2 <= D^{1/2 - 1/p} \\| alpha^prime \\|_p\ndoes not seem to follow from the above calculations. In particular, alpha^prime seems to be defined with respect to an x in S_{p, beta}, however in this case we did not specify such an x. Perhaps did you mean there exist such an alpha^prime?\n\n(2) In the proof of Theorem 3, there is an important inequality needed to complete the proof \n  max{ <s, f_i> , <s, -f_i> } >= 1/2 * ( <s, [f_i]_+> + <s, [-f_i]_+> )\n\nPerhaps I am missing something obvious, but I believe this inequality fails when we choose s as a constant vector, and f_i to have the same number of positive and negative signs (which is possible in a Hadamard matrix). In this case, the left hand side should be equal to zero, where as the right hand side will be positive. \n\n###\n\nTo summarize, if these proofs can be confirmed, I believe this paper would have made significant contribution to the problem of over-parametrization in deep learning, and of course should be accepted. \n\n###\n\nI corrected several typos and found minor issues as I read, perhaps this will be useful to improve readability as well.\n\nPage 13, proof of Lemma 8\n  - after the V_0 term is separated, there is a sup over \\|V_0\\|_F <= r in the expectation, which should be \\|V-V_0\\|_F <= r instead.\n\nPage 14, Lemma 9\n  - the lemma did not define rho_{ij} in the statement\n\nPage 15, proof of Lemma 9\n  - in equation (12), there is an x_y vector that should x_t\n\nPage 15, proof of Theorem 1\n  - while I eventually figured it out, it\'s unclear how Lemma 8 is applied here. Perhaps one more step identifying the exact matrices in the statement of Lemma 8 will be helpful to future readers, and maybe explain where the sqrt(2) factor come from as well. \n\nPage 16, proof of Lemma 10\n  - in the beginning of the proof, to stay consistent with the notation, we should replace S_{p, beta} with S_{p, beta}^D\n  - I believe the cardinality of Q should be (K + D - 1) choose (D - 1), as we need to choose positive j\'s to sum up to (K+D) in the definition of Q. This reduces down to the problem of choosing natural numbers j\'s summing K, which is (K+D-1) choose (D-1). Consider the stack exchange post here:\nhttps://math.stackexchange.com/questions/919676/the-number-of-integer-solutions-of-equations\n\nPage 16, proof and statement of Lemma 11\n  - I believe in the first term, the factor should be m instead of sqrt(m). I think the mistake happened when applying the union bound, as it should only affect the term containing delta\n\nPage 17, Lemma 12\n  - same as Lemma 11, we should have m instead of sqrt(m)\n\nPage 18, proof of Theorem 3\n  - at the bottom the statement ""F is orthogonal"" does not imply the norm is less than 1, but rather we should say ""F is orthonormal""\n\nPage 19, proof of Theorem 3\n  - at the top, ""we will omit the index epsilon"" should be ""xi"" instead\n  - in the final equation block, we have the Rademacher complexity of F_{W_2}, instead it should be F_{W^prime}\n\n', 'The authors aim to shed light on the role of over-parametrization in generalization error. They do so for the special case of 2 layer fully connected ReLU networks, a ""simple"" setting where one still sees empirically that the test error decreasing as over-parametrization increases.\n\nBased on empirical observations of norms (and norms relative to initialization) in trained overparametrized networks, the authors are led to the definition of a new norm-bounded class of neural networks. Write u_i for the vector of weights incoming to hidden node i. Write v_i for the weights outgoing from hidden node i. They study classes where the Euclidean norm of v_i is bounded by a constant alpha_i and where the Euclidean norm of u_i - u^0_i is bounded by beta_i, where u^0_i is the value of u_i after random initialization. Call this class F_{alpha,beta} where alpha,beta are specific vectors of bounds.\n\nThe main result is a bound on the empirical Rademacher complexity of F_{alpha,beta}. \nThe authors also given lower bounds on the empirical Rademacher complexity for carefully chosen data points, showing that the bounds are tight. These Rademacher bounds yield standard bounds on the ramp loss for fixed alpha,beta, and margin, and then a union bound argument extends the bound to data-dependent alpha,beta and margin.\n\nThe authors compare the bounds to existing norm-based bounds in the literature. The basic argument is that the terms in other bounds tend to grow as networks get much larger, while their terms shrink. Note that at no point are the bounds in this paper ""nonvacuous"", ie they are always larger than one.\n\nIn summary, I think this is a strong paper. The explanatory power of the results are still oversold in my opinion, even if they use hedged language like ""could explain the role..."". But the work is definitely pointing the way towards an explanation and deserves publication. The technical results in the appendix will be of interest to the learning theory community.\n\nissues:\n\n""could explain role of over-parametrization"". Perhaps this work might point the way to an explanation, but it does not yet provide an explanation.  It is a big improvement it seems.\n\n""bound improves over the existing bounds"". From this statement and the discussion comparing the bounds, it is not clear whether this bound formally dominates existing bounds or merely does so empirically (or under empirical conditions). \n\ntypos: \n\nbigger than the Lipschitz CONSTANT of the network class\n\nH undefined\n\nRademacher defined for H but must be defined on loss class (or a generic function class, not H)\n\n""we need to cover"" --> ""it suffices to""\n\n""the following two inequaliTIES hold by Lemma 8""\n\nbibliography is a mess: half of the arxiv papers are published. typos everywhere, very sloppy.\n\n(This review was requested late in the process due to another reviewer dropping out of the process.)\n\n[UPDATE]. The authors addressed my concerns stated in my review above. I think the bibliography has improved and I recommend acceptance. ']","[80, 50, 70]","[70, 80, 80]","[""The sentiment score is 80 (positive) because the review is predominantly positive, highlighting several strengths of the paper such as its theoretical soundness, readability, and novel contributions. The reviewer acknowledges the paper's importance and potential impact. The weaknesses mentioned are relatively minor and presented as suggestions for improvement rather than severe criticisms. The politeness score is 70 (polite) because the reviewer uses respectful and professional language throughout. They provide constructive feedback and balance positive comments with areas for improvement. The reviewer also acknowledges their limitations (e.g., 'I cannot certify that they are correct') which shows humility. The tone is consistently professional and supportive, without any harsh or rude language."", ""The sentiment score is 50 (slightly positive) because while the reviewer expresses the importance of the paper's topic and praises certain aspects ('great job comparing related work'), they also raise significant concerns about the proofs and request clarifications. This mix of positive and critical feedback results in a moderately positive overall sentiment. The politeness score is 80 (quite polite) due to the reviewer's consistently respectful tone. They begin with an apology for the delay, use phrases like 'I would like to request' and 'Perhaps I am missing something obvious', and offer constructive feedback throughout. The reviewer also provides detailed suggestions for improvement, which is a polite way to offer criticism. The language is professional and courteous throughout, even when pointing out potential errors."", ""The sentiment score is 70 (positive) because the reviewer states 'I think this is a strong paper' and recommends acceptance, indicating a generally positive view. They mention that the paper 'deserves publication' and that it's 'a big improvement'. However, it's not 100 because there are some criticisms, such as the results being 'oversold' and the explanation not being complete yet. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'I think' and 'in my opinion', which are polite ways to express views. The reviewer also provides specific, helpful feedback on typos and areas for improvement, which is considerate. The tone remains professional and courteous even when pointing out issues.""]"
"[""The main theory points out two scenarios causing Adam-type optimizers to diverge, which extends Reddi et al's results. \n\nThe theorem in this paper applies to all Adam-type algorithms, which combine momentum with adaptive learning rates and thus are more general as compared to the recent papers, such as Zhou et al's. The relationship between optimizers' effective step size, step size oscillation and convergence is well demonstrated and is interesting.\n\nRemarks:\n1. The main theorem and proof are based on the non-convex settings while the examples to demonstrate the convergence condition are simple convex functions.\n\n2. The message delivered by MNIST experiment is limited, is not clear and is not very relevant to the main part of the paper. It would be better to compare these algorithms in larger deep learning tasks.\n\nTypo:\nPage 5, section 3.1: Term A is a generalization of term alpha^2 g^2 (instead of just alpha^2) for SGD."", 'The work studies the convergence properties of a ""Adam-type"" class of optimization algorithms used for neural network. \nThe “Adam-type” class includes the popular algorithms such as Adam, AMSGrad and AdaGrad. Mathematical analysis is conducted to study the convergence of those algorithms in the non-convex setting. The authors derive theorems that guarantee the convergence of Adam-type algorithms under certain conditions to first-order stationary solutions of the non-convex problem, with O(log T /√ T) convergence rate. These conditions for convergence presented in this work is are “tight”, in the sense that violating them can make an algorithm diverge. In addition, these conditions can also be checked in practice to monitor empirical convergence, which gives a positive practical aspect to this work. The authors propose a correction to the Adam algorithm to prevent an option of divergence, and propose a new algorithm called AdaFom accordingly. \nOverall this seems like a high-quality work with interesting contribution to the research community. This reviewer is not an expert in theoretical analysis of optimization algorithms, therefore it is hard to assess the true contribution of this work and its comparison to other works in this field. ', 'Summary:\n\nThis paper presents a convergence analysis in the non-convex setting for a family of optimization algorithms, which the authors call the ""Adam-type"". This family incorporates popular existing methods like Adam, AdaGrad and AMSGrad. The analysis relies only on standard assumptions like Lipschitz smoothness and bounded gradients.\n\nIndividual Comments/Questions:\n\n- In Table 1, the characterization of Adam ignores the fact that, in practice, Adam adds a positive epsilon to the $\\hat{v}_t$ in the denominator. I would like the authors to at least comment on that in the paper. I assume that AdaFom and AMSGrad also need such an epsilon in practice. Could the author comment on whether (and how) this would affect their analysis of those methods? In particular, in Theorem 3.1, can we really assume the term $\\Vert \\alpha_t m_t / \\sqrt{\\hat{v}_t} \\Vert$ to be bounded by a constant without such an epsilon?\n\n- In the first bullet point in Section 3.1, the authors relate the term\n\n$$ \\sum_t \\Vert \\alpha_t g_t / \\sqrt{\\hat{v}_t} \\Vert^2 $$ (*)\n\nto the term $\\sum_t \\alpha_t^2$ in the analysis of SGD. I don\'t think this is a fair analogy. The effective step size of Adam-type methods is $\\alpha_t / \\sqrt{\\hat{v}_t}$, while the aformentioned term also contains the magnitude of the stochastic gradient $g_t$. So, while the SGD analysis only poses a condition on the step sizes, bounding (1) also poses a condition on the magnitude of the stochastic gradient.\n\n- In the experiments of Section 3.2.1, the authors use a step size of 0.01 for SGD (which really is gradient descent, since this is a non-stochastic problem). Existing theory tells us that GD only converges for step sizes smaller than 2/L where L is the Lipschitz constant of the gradient, which is L=200 in this example. So this is literally setting the method up for failure and I don\'t really see any merit in that experiment.\n\n- The experiments in Section 4 are of course very limited, but this paper makes a significant theoretical contribution, so I don\'t really see the need for extensive experiments.\n\n- To my knowledge, under similar assumptions, plain SGD has been show to converge at a rate of O(1/sqrt(T)). The convergence analysis presented here has an additional log(T) factor, so it is not really suitable to explain any possible benefits of these adaptive methods over SGD. This is totally fine in and of itself; after all the analysis of theses methods is hard and this is a great first step. The issue I have is that this is not mentioned in the paper at all. \n\nOriginality:\n\nTo the best of my knowledge, the convergence analysis of the Adam-type methods (including established methods AdaGrad, RMSprop, Adam, AMSGrad) in the _non-convex_ setting is a novel, original contribution. The authors also propose a new algorithm, AdaFom. This exact algorithm is proposed in [1], which was uploaded to arXiv before the ICLR deadline. However, this can be considered concurrent work.\n\nSignificance:\n\nThe convergence properties of popular optimization methods in machine learning (e.g., Adam) are generally very poorly understood in ""realistic"" settings. The analysis presented in this paper is an important step to better theoretical understanding of these methods which, in my opinion, is highly significant.\n\nCorrectness:\n\nThis was a short-notice emergency review and I did not check any of the proofs in the appendix. I will try to verify at least parts of the proofs in the coming days.\n\nConclusion:\n\nThis is an original paper making a significant theoretical contribution. I can\'t comment on the correctness of the mathematical analysis (yet). I\'m cautiously recommending acceptance for now, but would be willing to upgrade my rating if the authors respond to my comments/questions.\n\n\n[1] Zou and Shen. On the Convergence of Weighted AdaGrad with Momentum for Training Deep Neural Networks. https://arxiv.org/abs/1808.03408.\n\n--------------------------------\nUpdate\n--------------------------------\n\nThe authors have provided a detailed response to my concerns and have fixed many of them in their revised version. I verified parts of the proofs in the appendix (Theorem 3.1 and its Corollaries). I congratulate the authors on their work and recommend acceptance!']","[70, 80, 60]","[60, 50, 70]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, highlighting its contributions and interesting aspects. They mention that the paper extends previous results, applies to a broader range of algorithms, and demonstrates relationships well. The politeness score is 60 (moderately polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticism. They use phrases like 'would be better' instead of more demanding language. The reviewer also points out positive aspects before mentioning areas for improvement. The presence of specific, helpful remarks and the notation of a typo further indicate a professional and courteous tone, although it doesn't reach the highest levels of politeness due to its direct nature."", ""The sentiment score is 80 (positive) because the reviewer describes the work as 'high-quality' with 'interesting contribution to the research community'. They highlight several positive aspects of the study, such as the derivation of theorems, practical applicability, and the proposal of a new algorithm. The only slight reservation is the reviewer's admission of not being an expert in the field, which prevents them from fully assessing the work's contribution. The politeness score is 50 (moderately polite) because the language used is professional and respectful throughout. The reviewer acknowledges the quality of the work and presents their limitations in evaluating it honestly. However, the review doesn't contain overtly polite phrases or expressions of gratitude, keeping it more neutral than extremely polite."", ""The sentiment score is 60 (positive) because the reviewer recommends acceptance, praises the paper's originality and significance, and congratulates the authors. However, it's not maximally positive due to initial caution and some critiques. The politeness score is 70 (polite) as the reviewer uses respectful language, acknowledges the paper's merits, and frames criticisms constructively. The reviewer also shows willingness to upgrade their rating based on author responses, which is considerate. The language is professional and courteous throughout, without being overly formal or effusive.""]"
"[""Summary:\nThis paper studies the properties of applying gradient flow and gradient descent to deep linear networks on linearly separable data. For strictly decreasing loss like the logistic loss, this paper shows 1) the loss goes to 0, 2) for every layer the normalized weight matrix converges to a rank-1 matrix 3) these rank-1 matrices are aligned. For the logistic loss, this paper further shows the linear function is the maximum margin solution.\n\nComments:\nThis paper discovers some interesting properties of deep linear networks, namely asymptotic rank-1, and the adjacent matrix alignment effect. These discoveries are very interesting and may be useful to guide future findings for deep non-linear networks. The analysis relies on many previous results in Du et al. 2018, Arora et al. 2018 and Soudry et al. 2017  authors did a good job in combing them and developed some techniques to give very interesting results. \nThere are two weaknesses. First, there is no convergence rate. Second, the step size assumption (Assumption 5) is unnatural. If the step size is set proportional to 1/t or 1/t^2  does this setup satisfies this assumption? \n\nOverall I think there are some interesting findings for deep linear networks and some new analysis presented, so I think this paper is above the bar.\nHowever, I don't think this is a strong theory people due to the two weakness I mentioned."", 'In this work the authors prove several claims regarding the inductive bias of gradient descent and gradient flow trained on deep linear networks with linearly separable data. They show that asymptotically gradient descent minimizes the risk, each weight matrix converges to its rank one approximation and the top singular vectors of two adjacent weight matrices align. Furthermore, for the logistic and exponential loss the induced linear predictor converges to the max margin solution. \n\nThis work is very interesting and novel. It provides a comprehensive and exact characterization of the dynamics of gradient descent for linear networks. Such strong guarantees are essential for understanding neural networks and extremely rare in the realm of non-convex optimization results. The work is a major contribution over the paper of Gunasekar et al. (2018) which assume that the risk is minimized. The proof techniques are interesting and I believe that they will be useful in analyzing neural networks in other settings.\n\nRegarding Lemma 3, the proof is not clear. Lemma 8 does not exist in the paper of Soudry et al. (2017). It is also claimed that with probability 1 there are at most d support vectors. How does this relate with assumption 3, which implies that there are at least d support vectors?\n\n-------Revision---------\n\nThank you for the response. I have not changed the original review.\n', 'This paper analyzes the asymptotic convergence of GD for training deep linear network for classification using smooth monotone loss functions (e.g., the logistic loss). It is not a breakthrough, but indeed provides some useful insights.\n\nSome assumptions are very restricted: (1) Linear Activation; (2) Separable data. However, to the best of our knowledge, these are some necessary simplifications, given current technical limit and significant lack of theoretical understanding of neural networks.\n\nThe contribution of this paper contains multiple manifolds: For Deep Linear Network, GD tends to reduce the complexity:\n(1)\tConverge to Maximum Margin Solution;\n(2)\tTends to yield extremely simple models, even for every single weight matrix.\n(3)\tWell aligned means handle the redundancy.\n(4)\tExperimental results justify the implication of the proposed theory.\n\nThe authors use gradient flow analysis to provide intuition, but also present a discrete time analysis.\n\nThe only other drawbacks I could find are (1) The paper only analyze the asymptotic convergence; (2) The step size for discrete time analysis is a bit artificial. Given the difficulty of the problem, both are acceptable to me.']","[50, 90, 60]","[60, 80, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges interesting findings and states the paper is 'above the bar', but also mentions two weaknesses. The overall tone is more positive than negative, but not overwhelmingly so. The politeness score is 60 (moderately polite) because the reviewer uses respectful language, acknowledges the authors' good work, and presents criticisms constructively. The phrases 'authors did a good job' and 'interesting findings' contribute to the polite tone. However, the directness in stating weaknesses keeps it from being extremely polite."", ""The sentiment score is 90 because the reviewer describes the work as 'very interesting and novel', a 'major contribution', and provides 'strong guarantees' that are 'extremely rare'. They also praise the proof techniques as interesting and potentially useful in other settings. The only slight negative is a question about Lemma 3, but this doesn't significantly detract from the overall positive sentiment. The politeness score is 80 because the language is consistently respectful and professional. The reviewer uses phrases like 'Thank you for the response' and frames their critique as questions rather than direct criticisms. They also take care to highlight the strengths of the work before mentioning any concerns. The tone is constructive and collegial throughout, without any harsh or impolite language."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's useful insights and contributions, despite noting it's not a breakthrough. They mention multiple positive aspects of the paper's findings and justify the necessary simplifications. The few drawbacks mentioned are described as acceptable. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the paper's merits and the difficulty of the subject matter. They phrase criticisms constructively, using phrases like 'to the best of our knowledge' and 'given the difficulty of the problem, both are acceptable to me,' which shows consideration for the authors' work.""]"
"['This paper presents an approach for hierarchical RL based on an ensemble of low-level controllers.\nFrom what I can tell, you train K randomly initialized models to maximize displacement (optionally with a periodic implementation).\nThis ensemble of low-level models is then presented to a high-level controller, that can use them for actions.\nWhen you do this, the resultant algorithm performs well on a selection of deep RL tasks.\n\nThere are several things to like about this paper:\n- Hierarchical RL is an important area of research, and this algorithm appears to make progress beyond the state of the art.\n\n- The ideas of using ensemble of low-level policies is intuitive and appealing.\n\n- The authors provide a reasonable explanation of their ""periodicity"" ideas, together with evidence that it can be beneficial, but is not always essential to the algorithm.\n\n- Overall the writing is good... but I did find the main statement of the algorithm confusing! I think this deserves a proper appendix with everything spelled out.\n\n\nThere are several places this paper could be improved:\n- First, the statement of the *main* algorithm needs to be brought together so that people can follow it clearly. I understand one of the main reasons this is complicated is because the authors have tried to make this ""general"" or to be used with DQN/PPO/A3C... but if you present a clear implementation for *one* of them (PPO?) then I think this will be a huge improvement.\n\n- Something *feels* a little hacky about this... why are there only two timescales? Is this a general procedure that we should always expect to work? *why* are we doing this... and what can its downsides be? The ablation studies are good, but I think a little more thought/discussion on how this fits in with a bigger picture of RL/control would be good.\n\nOverall, I hope that I understood the main idea correctly... and if so, I generally like it.\nI think it will be possible to make this much clearer even with some simple amendments.', 'Brief summary: \nHRL method which uses a 2 level hierarchy for sparse reward tasks. The low level policies are only provided access to proprioceptive parts of the observation, and are trained to maximize change in the non-proprioceptive part of the state as reward. The higher level policy is trained as usual by commanding lower level policies. \n\nOverall impression:\nI think the paper has a major assumption about the separation of internal and external state, thereby setting the form of the low level primitives. This may not be fully general, but is particularly useful for the classes of tasks shown here as seen from the strong results. I would like to see the method applied more generally to other robotic tasks, and a comparison to Florensa et al. And perhaps the addition of a video which shows the learned behaviors. \n\nIntroduction: \nthe difficulty of learning a high-level controller when the low-level policies shifts -> look at “data efficient hierarchical reinforcement learning” (Nachum et al)\n\nThe basic assumption that we can separate out observations into proprioceptive and not proprioceptive can often be difficult. For example with visual inputs or entangled state representations, this might be very challenging to extract. This idea seems to be very heavily based on what is “internal” and what is “external” to the agent, which may be quite challenging to separate. \n\nThe introduction of phase functions seems to be very specific to locomotion?\n\u2028Related work: \nThe connection of learning diverse policies should be discussed with Florensa et al, since they also perform something similar with their mutual information term. DeepMimic, DeepLoco (Peng et al) also use phase information in the state, worthwhile to cite. \n\nSection 3.1:\nThe pros and cons of making the assumption that representation is disentangled enough to make this separation, should be discussed. \n\nAlso, the internal and external state should be discussed with a concrete example, for the ant for example. \n\nSection 3.2:\nThe objective for learning diverse policies is in some sense more general than Florensa et al, but in the same vein of thinking. What are the pros and cons of this approach over that?\u2028\u2028The objective is greedy in the change of external state. We’d instead like something that over the whole trajectory maximizes change?\n\nSection 3.3: \u2028How well would these cyclic objectives work in a non-locomotion setting? For example manipulation\n\nSection 3.4:\u2028This formulation is really quite standard in many HRL methods such as options framework. The details can be significantly cut down, and not presented as a novel contribution. \n\nExperiments:\nIt is quite cool that Figure 2 shows very significant movement, but in some sense this is already supervised to say “move the CoM a lot”. This should be compared with explicitly optimizing for such an objective, as in Florensa et al. I’m not sure that this would qualify as “unsupervised” per se. As in it too is using a particular set of pre-training tasks, just decided by the form of choosing internal and external state.\n\nall of the baselines fail to get close to the goal locations.-> this is a bit surprising? Why are all the methods performing this poorly even when rewarded for moving the agent as much as possible.\n\nOverall, the results are pretty impressive. A video would be a great addition to the paper. \n\nComparison to Eysenbach et al isn’t quite fair since that method receives less information. If given the extra information, the HRL method performs much better (as indicated by the ant waypoint plot in that paper).', 'This paper proposes a method to train high- and low-level controllers to tackle hierarchical RL.  The novelty is framing hierarchical RL as a problem of training a diverse set of LL controllers such that they can be used by a HL controller to solve high-level tasks.  By dividing state representation into proprioceptive and task-specific, the reward used to train LL and HL controllers are simplified.  Experimental result shows that the method is effective at solving maze environments for both ant and humanoid.\n\nThe good parts:\n- The method of training diversified LL controller and a single high-level controller seems to work unreasonably well.  And one benefit of this approach is that the rewards for both high (sparse) and low (difference) level controllers can be trivially defined.\n\n- The separation of proprioceptive and task-specific states seems to be gaining popularity.  For the maze environment (and any task that involves locomotion), this can be done intuitively.\n\nPlace to improve:\n- Terrain-Adaptive Locomotion (Peng et al. 2016) used a similar approach of phase-indexed motion, as well as selecting from a mixture of experts to generate action sequence for the next cycle.  Perhaps worthwhile to cite.\n\n- In fact, it seems that phase in this work only benefited training of low-level controller for humanoid.  But it should be possible to train humanoid locomotion with using phase information.\n\n- This hierarchical approach shouldn\'t depend on the selection of state space.  What would happen when LL and HL controllers all receive the same inputs?\n\n- The paper is difficult to follow at places.  Ex. b_phi element of R^d in Section 3.3.  I\'m still not sure what is b_phi, and what is d here.\n\n- The choice of K = 10 feels arbitrary.  Since K corresponds to the length of a cycle, it should make sense to choose K such that the period is reasonable compared to average human stride period, etc.  What is the simulation step length?\n\n- Since LL policies control the style of the motion and the only reward it gets is to keep moving, presumably the resulting motion would look unnatural or exhibit excessive energy consumption.  Does ""keep moving"" reward work with other common rewards like energy penalty, etc?\n']","[60, 50, 50]","[80, 70, 70]","[""The sentiment score is 60 (positive) because the reviewer expresses several positive aspects of the paper, such as 'There are several things to like about this paper' and 'Overall, I hope that I understood the main idea correctly... and if so, I generally like it.' However, it's not extremely positive as the reviewer also points out areas for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively, such as 'There are several places this paper could be improved' instead of using harsh language. The reviewer also uses phrases like 'I hope' and 'I think,' which soften the critique and maintain a collegial tone."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the strong results and impressive performance of the proposed method, while also pointing out areas for improvement and raising questions about certain aspects. The overall tone is constructive and balanced, indicating a generally positive but not overly enthusiastic sentiment. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offers suggestions rather than demands, and acknowledges the strengths of the work. Phrases like 'I think,' 'I would like to see,' and 'It is quite cool' contribute to a polite tone. The reviewer also provides specific, constructive feedback without using harsh or dismissive language."", ""The sentiment score is 50 (slightly positive) because the review begins with a neutral summary of the paper's content, followed by a section on 'good parts' which highlights the strengths of the method. However, this is balanced by a longer 'place to improve' section, suggesting areas for enhancement. The overall tone is constructive rather than overtly positive or negative. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing criticisms as suggestions for improvement rather than direct attacks. Phrases like 'Place to improve' and 'Perhaps worthwhile to cite' indicate a considerate approach to feedback. The reviewer also acknowledges the strengths of the paper before moving on to areas for improvement, which is a polite way to structure criticism.""]"
"['This paper presents an approach to creating word representations that operate at both the sub-word level and generalise across languages. The paper presents soft decoupled encoding as a method to learn word representations from weighted bags of character-n grams, a language specific transformation layer, and a ""latent semantic embedding"" layer. The experiments are conducted over low-resource languages from the multilingual TED corpus. The experiments show consistent improvements compared to existing approaches to training translation models with sub-word representations. The ablation studies in Section 4.4 are informative about the relative importance of different parts of the proposed model.\n\nCan you comment on how your model is related to the character-level CNN of Lee et al. (TACL 2017)?\n\nIn the experiments, do you co-train the LRLs with the HRLs? This wasn\'t completely clear to me from the paper. In Section 4.2 you use phrases like ""concatenated bilingual data"" but I couldn\'t find an explicit statement that you were co-training on both language pairs.\n\nWhat does it mean for the latent embedding to have a size of 10,000? Does that mean that W_s is a 10,000 x D matrix?\n\nIs Eq (4) actually a residual connection, as per He et al. (CVPR 2016)? It looks more like a skip connection to me.\n\nWhy do you not present results for all languages in Section 4.6?\n\nWhat is the total number of parameters in the SDE section of the encoder? The paper states that you encode 1--5 character n-grams, and presumably the larger the value of N, the sparser the data, and the larger the number of parameters that you need to estimate.\n\nFor which other tasks do you think this model would be useful?', 'This paper focuses on the problem of word representations in multilingual NMT system. The idea of multilingual NMT is to share data among multiple language pairs. Crucially this requires some way to tie the parameters of words from different languages, and one popular method is to share subword units among languages. The problem is that subword units in different languages may not be semantically equivalent, and many semantically-equivalent concepts are not represented by the same subwords. This paper proposes an alternative way to share word representation, in particular by proposing a common set of ""semantic"" concept vectors across languages which are then folded into the word representations via attention. \n\nThe problem is well-motivated and the proposed solution is reasonable. Previous works such as (Gu et. al. 2018) have been motivated in a similar fashion, and the proposed solution seems to outperform it on the TED dataset of Qi et. al. 2018. \n\nThe experiments are informative. The main open questions I have are:\n\n(a) Varying the latent embedding size. It seems like only 10,000 is tried. Since this is the main contribution of the work, it will be desirable to see results for different sizes. Is the method sensitive to this hyperparameter? Also suggestions on how to pick the right number based on vocabulary size, sentence size, or other language/corpus characteristics will be helpful. \n\n(b) What do the latent embeddings look like? Intuitively will they be very different from those from Gu et. al. 2018 because you are using words rather than subwords as the lexical unit? \n\n(c) The explanation for why your model outperforms Gu et. al. 2018 seems insufficient -- it would be helpful to provide more empirical evidence in the ablation studies in order really understand why your method, which is similar to some extent, is so much better. \n\nThe paper is generally clear. Here are few suggestions for improvement:\n\n- Table 1: Please explain lex unit, embedding, encoding in detail. For example, it is not clear what is joint-Lookup vs. pretrain-Lookup. It can be inferred if one knows the previous works, but to be self-contained, I would recommend moving this table and section to Related Works and explaining the differences more exactly.\n\n- Sec 4.2: Explain the motivation for examining the three different lexical units. \n\n- Table 3: ""Model = Lookup (ours)"" was confusing. Do you mean ""our implementation of Neubig & Hu 2018? Or ours=SDE? I think the former?\n\n- Are the word representions in Eq 4 defined for each word type or word token? In other words, for the same word ""puppy"" in two different sentences in the training data, do they have the same attention and thus the same e_SDE(w)? You do not have different attentions depending on the sentence, correct? I think so, but please clarify. (Actually, Figure 2 has a LSTM which implies a sentential context, so this was what caused the potential confusion). \n\n- There are some inconsistencies in the terms: e.g. latent semantic embedding vs latent word embedding. Lexical embedding vs Character embedding. This makes it a bit harder to line up Sec 4.4 results with Sec 3.2 methods. \n\n- Minor spelling mistakes. e.g. dependant -> dependent. Please double-check for others. \n', 'Overall:\nThis paper proposed soft decoupled encoding (SDE), a special multilingual lexicon encoding framework which can share lexical-level information without requiring heuristic preprocessing. Experiments for low-resource languages show consistent improvements over strong multilingual NMT baselines.\n\nGeneral Comments:\nTo me this paper is very interesting and is nicely summarized and combined previous efforts in two separated directions for sharing multilingual lexicons: based on the surface similarity (how the word is spelled, e.g. subword/char-level models), and based on latent semantic similarity (e.g. Gu et.al. 2018). However, in terms of the proposed architecture, it seems to lack some novelty. Also, more experiments are essential for justification.\n\nI have some questions:\n(1) One of the motivation proposed by Gu et.al. 2018 is that spelling based sharing sometimes is difficult/impossible to get (e.g. distinct languages such as French and Korean), but monolingual data is relatively easy to obtain. Some languages such as Chinese is not even “spelling” based. Will distinct languages still fit in the proposed SDE? In my point of view, it will break the “query” vector to attention to the semantic embeddings.\n(2) How to decide the number of core semantic concepts (S) in the latent semantic embeddings? Is this matrix jointly trained in multilingual setting?\n(3) Is the latent semantic embeddings really storing concepts for all the languages? Say would you pick words in different languages with similar meanings, will the they naturally get similar attention weights? In other words, do multiple languages including very low resource languages learn to naturally align together to the semantic embeddings during multilingual training? I am a bit doubtful especially for the low resource languages.\n(4) It seems that the language specific transformation does not always help. Is it because there is not enough data to learn this matrix well?\n(5) During multilingual training, how you balance the number of examples for low and high resource languages?\n']","[70, 50, 50]","[80, 70, 80]","[""The sentiment score is 70 (positive) because the reviewer begins by summarizing the paper's approach and contributions in a neutral tone, then notes that the experiments show 'consistent improvements' and that the ablation studies are 'informative'. This indicates a generally positive view of the work. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, poses questions in a constructive manner (e.g., 'Can you comment on...', 'Why do you not...'), and acknowledges the paper's contributions. The reviewer also uses phrases like 'wasn't completely clear to me' which softens potential criticism. The questions are direct but framed as requests for clarification or additional information, maintaining a collegial tone throughout the review."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's well-motivated problem and reasonable solution, noting that it outperforms previous work. However, they also raise several questions and suggest improvements, indicating a balanced view. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, offering constructive feedback and suggestions for improvement rather than harsh criticism. They use phrases like 'Please explain,' 'It would be helpful,' and 'I would recommend,' which contribute to a polite tone. The reviewer also acknowledges the paper's strengths before diving into suggestions, which is a polite approach to feedback."", ""The sentiment score is 50 (slightly positive) because the reviewer expresses interest in the paper and acknowledges its contributions, stating it is 'very interesting' and 'nicely summarized'. However, they also point out some limitations, such as lack of novelty in architecture and the need for more experiments. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'it seems to lack some novelty' rather than stating it definitively), and frames their points as questions or suggestions rather than demands. The use of phrases like 'To me' also shows a polite acknowledgment that their view is subjective.""]"
"['This work presents an extension of the MAML framework for ""learning to learn."" This extension changes the space in which ""inner-loop"" gradient steps are taken to adapt the model to a new task, and also introduces stochasticity. The authors validate their proposed method with regression experiments in a toy setting and few-shot classification experiments on mini- and tiered-Imagenet. The latter are well known and competitive benchmarks in few-shot learning.\n\nThe primary innovations that distinguish this work from previous gradient-based approaches to meta-learning (namely MAML) are that (i) the initial set of parameters is data-dependent and drawn from a generative distribution; and (ii) the adaptation of model parameters proceeds in a lower-dimensional latent space rather than in the higher-dimensional parameter space. Specifically, model parameters are generated from a distribution parameterized by an adapted latent code at each adaptation step. I find both of these innovations novel.\n\nThe experimental results, in which LEO outperforms the state of the art on two benchmarks derived from ImageNet by ""comfortable margins,"" and the ablation study demonstrate convincingly that these innovations are also significant. I also found the curvature analysis and embedding visualization illuminating of the model\'s function. My one suggestion would be to test the model on realistic data from beyond the image domain, perhaps on something sequential like language (consider the few-shot PTB setting from Vinyals et al. (2016)). I\'m aware anecdotally that MAML struggles with adapting RNNs and I wonder if LEO overcomes that weakness.\n\nThe paper is clearly written and I had little difficulty in following the algorithmic details, although I\'m sure it helped to be familiar with the convoluted meta-learning and inner-/outer- loop frameworks. I recommend it for publication.\n\nPros:\n- Natural, novel extension to gradient-based meta-learning\n- state of the art results on two competitive few-shot benchmarks\n- good analysis\n- clear writing\n\nCons:\n- realistic, high-dim data is only from the image domain\n\nMinor questions for the authors:\n- Relation Networks are computationally intensive, although in few-shot learning the sets encoded are fairly small. Can you discuss the computational cost and training time of the full framework?\n- What happens empirically when you generate parameters for more than just the output layer in, eg, your convolutional networks?\n- What happens if you try to learn networks from scratch through the meta-learning process rather than pre-training and fine-tuning them? Some of the methods you compare against do so, to my understanding.', 'This paper proposes a latent embedding optimization (LEO) method for meta-learning, in particular, few-shot learning.  The proposed model has three meta components, an encoding network, a relation network, and a decoding network. It claims the contribution is to decouple the optimization-based meta-learning techniques from high-dimensional space of model parameters. \n\nThe proposed work focuses on the standard few-shot learning scenario. The notable merit of this work is that it presented the so-far best empirical results. On miniImageNet, it produced 61.76% (1-shot) and 77.59(5-shot) accuracy results. This is quite amazing. \n\nThe presentation of the work however lacks sufficient details and motivations, which makes it difficult to judge the proposed model. (1) It is not clear what are the specific architectures and model parameter settings for the encoding, decoding and relation networks.  (2) In Eq.(4), it defines \\mu_n^d,\\sigma_n^d as the output of the decoding network which takes the single z_n as input. I doubt a single z_n input can provide information on both \\mu_n^d,\\sigma_n^d. (3) How to use the developed model in the testing phase?\n', 'This paper presents a new meta-learning framework that learns data-dependent latent space and performs fast adaptation in the latent space. To this end, an encoder that maps data to latent codes and a decoder that maps latent codes to parameters are also learned. Experimental results demonstrate its effectiveness for few-shot learning.\n\nInterestingly, the initialization for adaptation is task-dependent, which is different from conventional MAML-like methods. Furthermore, the results on multimodal few-shot regression seems to show that it works well for multimodal task distribution, which is important for generalization of meta-learning. However, there are quite a few questions that are less clear and require more discussions and insights. \n\n1. Since this work relies heavily on an encoding process and a decoding process, more details and discussions on the design and requirement of the encoder and decoder are necessary. Particularly, the inclusion of a relation network in the encoding process seems ad hoc. More explanations may be helpful. \n\n2. It is less clear why this method can deal with multimodal task distribution as shown in the regression experiment. Is it related to the data-dependent model initialization?\n\n3. It applies meta-learning in a learned latent space, which seems quite related to a recent work, Deep Meta-Learning: Learning to Learn in the Concept Space, Arxiv 2018, where meta-learning is performed in a learned concept space. A discussion on its difference to this prior work seems necessary. ']","[90, 50, 50]","[80, 20, 75]","[""The sentiment score is 90 because the reviewer expresses a highly positive view of the paper. They describe the work as novel, significant, and state-of-the-art, recommending it for publication. The only minor criticism is the limited data domain. The politeness score is 80 because the reviewer uses respectful and constructive language throughout. They offer praise, provide a balanced assessment, and frame their suggestions politely (e.g., 'My one suggestion would be...'). The tone is professional and courteous, without being overly deferential."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's 'notable merit' and 'amazing' results, but also points out significant shortcomings in presentation and details. The politeness score is 20 (slightly polite) as the reviewer uses neutral language and frames criticisms as questions or observations rather than direct attacks. They balance positive feedback with constructive criticism, maintaining a professional tone throughout."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's interesting aspects and effectiveness, but also raises several questions and concerns. The review begins positively, highlighting the paper's novelty and effectiveness, but then transitions to pointing out areas that need clarification or further discussion. This balanced approach suggests a moderately positive sentiment.\n\nThe politeness score is 75 (quite polite) because the reviewer uses respectful and constructive language throughout. They begin by summarizing the paper's contributions and noting its interesting aspects. When raising concerns, they frame them as questions or areas needing more discussion rather than direct criticisms. Phrases like 'Interestingly,' 'more details and discussions... are necessary,' and 'It is less clear why' maintain a polite and professional tone while still conveying the need for improvements.""]"
"['This work proposes to use semantic knowledge about the relationships and functionality of different objects, to help in navigation tasks, in both familiar and unfamiliar situations. The paper is very well written and it is clear what the authors did. The approach seems sound, and while it combines two existing approaches (actor-critic reinforcement learning for navigation, and belief propagation using graph convolution networks) is sufficiently novel to be of interest to at least some members of the community. The experimental evaluation is good, and the proposed method outperforms Mnih 2016 by a significant margin, especially in the more interesting settings. A good ablation study is provided. \n\nMy main concern is that there seems to be a larger pool of work in semantic navigation than what the evaluation includes. Anderson 2018, Zhu 2017 and Gupta 2017 seem relevant. While none of these use knowledge graphs, some of these show they outperform Mnih 2016 so would be stronger baselines. \n\nI am also curious whether the proposed work generalizes across scene type categories (e.g. if it learns on kitchens but it tested on living rooms). This would be an experiment in the spirit of unknown object/scene but even more challenging. ', ""This paper explores the use of semantic priors for semantic navigation. The semantic priors are derived from language datasets (in the form of word embeddings, which assign similar feature vectors to related words) and from visual datasets (Visual Genome, which represents relationships between objects that co-occur in scenes).\n\nThe general ideas are reasonable. The experimental protocol is sound and uses recent best practices. The results are fine.\n\nI'm a bit puzzled by the way the GCN is used. Figure 2 implies that the GCN doesn't actually use information from the current image. I.e., the GCN input doesn't change as the agent navigates the scene. (In Figure 2, the GCN path appears similar to the Word Embedding path. The Word Embedding path doesn't update when the agent moves, so the reader can infer that the GCN path doesn't update either.) But then I don't quite understand how the GCN incorporates information from the current scene.\n\nFigure 4 implies that the GCN is re-evaluated when the agent moves and the input image changes. But how is information from the image fed into the GCN? The text implies that an ImageNet classification model is run on the image. But why image classification and not object detection? It seems that what one would really want is to understand what objects are in the scene. And how is output of the image classification network supplied to the GCN? Is the target object type used as well? Overall it's not clear to me exactly how information from the current image is supplied to the GCN, why this mechanism is right, and what the GCN is expected to do. (I do understand how GCNs work, just not how exactly they are used here and why this precise usage is right for this application.) I hope the authors can clarify in the response.\n"", 'This paper tackles the problem of navigating scenes to find objects which are potentially not included in the training phase. To find an unseen object from a scene, the proposed model incorporates an external knowledge graph as an augmented input of the actor-critic model. To construct a knowledge graph, entities in a scene are identified by ResNet and then the link structure between entities are extracted from VIsual Genome dataset. Through the ablation study, it is shown that using the knowledge graph helps to track and identify unseen objects during training.\n\n- The original knowledge graph (KG) has relation labels (such as next to, on in figure 3) between different objects, however, GCN does not take into account the relations between objects. Only co-occurrence patterns will be encoded into the KG constructed from an image. There are more complex graph convolutional models modelling relations between nodes such as [1]. Have you considered adding explicit relations between entities? will it increase the navigation performance? if not why?\n- It is unclear how many objects are used to construct a KG from an image. For example, are top-k objects identified by ResNet used to construct a KG?\n- Description of the reward is a bit unclear as well, especially when the model is trained without stop action. From the text, the agents receive a positive reward when it is close to the target (within a certain number of steps). Does this mean that the agent gets a positive reward on every step near the target while it\'s not in the final state?\n- This might be a trivial question, but I couldn\'t find it from the text. Can you find all object from AI2-THOR in the categories of ImageNet and of Visual Genome? is there any information loss while constructing a KG from the classification result? What is the average number of nodes of a KG? and is there any correlation between the size of KG and the result?\n- Why are the performances of the models is unstable with Bedroom dataset (in terms of variance)? \n- The input feature of GCN is a combination of word feature and image feature. It is clear that there is a corresponding word embedding for each of the identified objects, but it is unclear what is the corresponding image feature. If two objects are identified in the same frame, do input features of these two objects share the same image features from Resnet?\n\n[1] Schlichtkrull, Michael, et al. ""Modeling relational data with graph convolutional networks."" European Semantic Web Conference. Springer, Cham, 2018. \n']","[70, 20, 50]","[80, 60, 70]","[""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, praising its clarity, novelty, and experimental evaluation. They state that the paper is 'very well written' and the approach 'seems sound'. The reviewer does have some concerns, but these are presented as constructive feedback rather than major criticisms. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the paper before offering suggestions for improvement. They phrase their concerns as curiosities or suggestions rather than demands, using phrases like 'I am also curious' and 'would be stronger baselines'. The reviewer maintains a professional and courteous tone throughout the review."", ""Sentiment score (20): The review starts with a generally positive tone, noting that the ideas are 'reasonable', the protocol is 'sound', and the results are 'fine'. However, the reviewer expresses confusion about certain aspects of the methodology, which slightly dampens the overall positive sentiment. The score is slightly positive to reflect this mix.\n\nPoliteness score (60): The language used is consistently professional and courteous. The reviewer uses phrases like 'I'm a bit puzzled' and 'I hope the authors can clarify' instead of more direct criticisms. They also acknowledge their own understanding of GCNs to frame their confusion. This approach is more polite than neutral, but not excessively formal or deferential, hence the moderately positive score."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and the effectiveness of the proposed model, but also raises several questions and points for improvement. The overall tone is constructive rather than critical. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, poses questions in a non-confrontational manner (e.g., 'Have you considered...?', 'Can you find...?'), and offers suggestions rather than demands. The reviewer also acknowledges potential trivial questions, showing consideration for the authors. The language is professional and objective, maintaining a courteous tone while providing detailed feedback.""]"
"['This manuscript contributes a new online gradient descent algorithm with adaptation to local curvature, in the style of the Adam optimizer, ie with a diagonal reweighting of the gradient that serves as an adaptive step size. First the authors identify a limitation of Adam: the adaptive step size decreases with the gradient magnitude. The paper is well written.\n\nThe strengths of the paper are a interesting theoretical analysis of convergence difficulties in ADAM, a proposal for an improvement, and nice empirical results that shows good benefits. In my eyes, the limitations of the paper are that the example studied is a bit contrived and as a results, I am not sure how general the improvements.\n\n# Specific comments and suggestions\n\nUnder the ambitious term ""theorem"", the results of theorem 2 and 3 limited to the example of failure given in eq 6. I would have been more humble, and called such analyses ""lemma"". Similarly, theorem 4 is an extension of this example to stochastic online settings. More generally, I am worried that the theoretical results and the intuitions backing the improvements are built only on one pathological example. Are there arguments to claim that this example is a prototype for a more general behavior?\n\n\nAli Rahimi presented a very simple example of poor perform of the Adam optimizer in his test-of-time award speech at NIPS this year (https://www.youtube.com/watch?v=Qi1Yry33TQE): a very ill-conditioned factorized linear model (product of two matrices that correspond to two different layers) with a square loss. It seems like an excellent test for any optimizer that tries to be robust to ill-conditioning (as with Adam), though I suspect that the problem solved here is a different one than the problem raised by Rahimi\'s example.\n\n\nWith regards to the solution proposed, temporal decorrelation, I wonder how it interacts with mini-batch side. With only a light understanding of the problem, it seems to me that large mini-batches will decrease the variance of the gradient estimates and hence increase the correlation of successive samples, breaking the assumptions of the method.\n\n\nUsing a shared scalar across the multiple dimensions implies that the direction of the step is now the same as that of the gradient. This is a strong departure compared to ADAM. It would be interesting to illustrate the two behaviors to optimize an ill-conditioned quadratic function, for which the gradient direction is not a very good choice.\n\n\nThe performance gain compared to ADAM seems consistent. It would have been interesting to see Nadam in the comparisons.\n\n\n\nI would like to congratulate the authors for sharing code.\n\nThere is a typo on the y label of figure 4 right.\n', 'In this paper, the authors found that decorrelating $v_t$ and $g_t$ fixes the non-convergence issue of Adam. Motivated by that, AdaShift that uses a temporal decorrelation technique is proposed. Empirical results demonstrate the superior performance of AdaShift compared to Adam and AMSGrad. My detailed comments are listed as below. \n\n1) Theorem 2-4 provides interesting insights on Adam. However, the obtained theoretical results rely on specific toy problems (6) and (13). In the paper, the authors mentioned that ""... apply the net update factor to study the behaviors of Adam using Equation 6 as an example. The argument will be extended to the stochastic online optimization problem and general cases."" What did authors mean the general cases?\n\n2) The order of presenting Algorithm 1, 2 and Eq. (17) should be changed. I suggest to first present AdaShift (i.e., Eq. (17) or Algorithm 3 with both modified adaptive learning rate and moving average), and then elaborate on temporal decorrelation and others. AdaShift should be presented as a new Algorithm 1.  In experiments, is there any result associated with the current Algorithm 1 and 2? If no, why not compare in experiments? One can think that Algorithm 1 and 2 are adaptive learning rate methods against adaptive gradient methods (e.g., Adam, AMSGrad). \n\n3) Is there any convergence rate analysis of AdamShift even in the convex setting?\n\n4) The empirical performance of AdamShift is impressive. Can authors mention more details on how to set the hyperparameters for AdamShift, AMSGrad, Adam, e.g., learning rate, \\beta 1, and \\beta 2? \n', ""Summary\n------\n\nBased on an extensive argument acoordig to which Adam potential failures are due to the positive correlation between gradient and moment estimation, the authors propose Adashift, a method in which temporal shift (and more surprisingly 'spatial' shift, ie mixing of parameters) is used to ensure that moment estimation is less correlated with gradient, ensuring convergence of Adashift in pathological cases, without the efficiency cost of simpler method such as AMSGrad. An extensive analysis of a pathological counter example, introduced in Reddi et al. 2018 is analysed, before the algorithm presentation and experimental validation. Experiments shows that the algorithm has equivalent speed as Adam and sometimes false local minima, resulting in better training error, and potentially better test error.\n\nReview\n-------\n\nThe decorrelation idea is original and well motivated by an extensive analysis of a pathological examples. The experimental validation is thorough and convincing, and the paper is overall well written. \n\nRegarding content, the reviewer is quite dubious about the spatial decorrelation idea. ASsuming shared moment estimation for blocks of parameters is definitely meaningful from an information perspective, and has indeed been used before, but it seems to have little to do with the 'decorrelation' idea. The reviewer would be curious to see a comparison with temporal-only adashift in the experiment, as the block / max operator \\phi, to isolate the temporal and 'spatial' effect.\n\nRegarding presentation, the reviewer's opinion is that the paper is too long. Too much space is spent discussing an interesting yet limited counterexample, on which 5 theorems (that are simple analytical derivations) are stated. This should be summarized (and its interesting argument stated more concisely), to the benefit of the actual algorithm presentation, that should appear in the main text (algorithm 3). The spatial decorrelation method, that remains unclear to the reviewer, should be discussed more and validated more extensively. The current size of the paper is 10 pages, which is much above the ICLR average length.\n\nHowever, due to the novelty of the algorithm, the reviewer is in favor of accepting the paper, provided the authors can address the comments above.\n""]","[60, 50, 60]","[80, 70, 70]","[""The sentiment score is 60 (positive) because the review starts with acknowledging the manuscript's contribution and mentions its strengths, including 'interesting theoretical analysis', 'proposal for an improvement', and 'nice empirical results'. However, it's not extremely positive as it also points out limitations. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offers congratulations for sharing code, and frames criticisms constructively. The reviewer uses phrases like 'I would have been more humble' instead of direct criticism, and offers suggestions rather than demands. The overall tone is professional and courteous, even when pointing out areas for improvement."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the interesting insights and impressive empirical performance of the proposed method. However, they also raise several questions and suggest improvements, indicating a balanced view. The politeness score is 70 (fairly polite) as the reviewer uses respectful language throughout, such as 'I suggest' and 'Can authors mention', and frames their comments as questions or suggestions rather than criticisms. The reviewer also begins by summarizing the paper's contributions positively before moving on to their detailed comments."", ""The sentiment score is 60 (positive) because the reviewer expresses overall positive sentiment towards the paper, praising its originality, motivation, and experimental validation. They are 'in favor of accepting the paper' despite some concerns. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while offering constructive criticism. They use phrases like 'the reviewer is quite dubious' and 'the reviewer's opinion is' to soften critiques. The reviewer also provides specific suggestions for improvement in a professional manner, indicating a polite and constructive approach to the review process.""]"
"['This paper presents an extension of Wasserstein autoencoder (WAE) by modifying the regularization term in learning objective of variational autoencoder. This term measures the divergence between the distribution of the encoded training samples and the samplable prior distribution. The modification is based on the sliced-Wasserstein distance where the distance between two distributions is measured through slicing or projecting the high-dimensional distributions into one-dimensional marginal distributions. As a result, a closed-form solution to the integral in Eq. (9) is obtained via a numerical method. The adversarial learning in WAE, designed to fulfill the calculation of high-dimensional distance, can be avoided. In general, this is an interesting work by introducing new idea of sliced-Wasserstein distance.\n\nRemarks:\n1. A theoretical paper which addresses how and why the sliced-Wasserstein distance between p_z and q_z is reasonable to build a new variant of variational auto-encoder.\n2.  Reformulating the Wasserstein distance into Monge primal formulation with the assumption based on the property of diffeomorphic mapping.\n3. As a result, the implementation based on the unstable adversarial training or the maximum mean discrepancy (MMD) training can be avoided. Computational attractiveness is assured. MMD needs the choice of kernel function which is basically a data-dependent design parameter.\n4. Provide an empirical numerical solution which is compatible with SGD optimization.\n5. The key idea of this paper is shown in Eq. (14). Learning objective is expressed in a deterministic way. However, the style of objective in Eq. (14) involves the stochastic learning.\n6. This paper is not actually doubly-blind reviewed. Authors have exposed their identities in arXiv.\n', 'This paper proposes training generative models with Wasserstein auto-encoders. It uses the sliced-Wasserstein distance to measure the dissimilarity between p_z and q_z.\n\nStrengths:\n1.    This paper is easy to read. \n2.    Concepts are introduced clearly. \n\nMy major comments are the following:\n1.  The innovation is a bit on the incremental level, especially given the results from WAE (Tolstikhin, ICLR18). The training objective is the same as Eq(4) in the WAE paper. The only difference is that the dissimilarity measure between p_z and q_z used in this paper is the sliced- Wasserstein distance, while WAE used GAN/MMD-based penalties. The advantage of using sliced-Wasserstein distance is not clear to me either.  \n\n2. The empirical results are fairly weak.  The authors may consider reporting the sample qualities (e.g. FID) for all the methods. \n\n3. The results of WAE-MMD are not reported.\n', 'The authors propose a new autoencoding algorithm for the unsupervised generative modeling which they call Sliced Wasserstein Autoencoders (SWAE). SWAE minimizes a reconstruction cost (measured with respect to the non-negative cost function c(x,x\') defined for pairs of input images x, x\'), regularized by a penalty measuring a discrepancy between the prior distribution over the latent space qz and the push-forward pz of the unknown data distribution through the deterministic encoder. The authors present an extensive theoretical argument supporting the choice of this objective and a number of empirical results performed on MNIST, LSUN bedrooms, and Celeba. \n\nEven though this paper raises several interesting questions, I have several major issues with it:\n****\n**** 1. Claim around Equation 3 is not proved.\n****\nAll the sections before 2.3 are providing a rather detailed theoretical argument meant to support the choice of the SWAE objective appearing in Eq. 14 of Section 2.3. Here I wand to point out to a mathematical inaccuracy in the authors\' discussions, which may render the whole argument questionable. In short, the authors claim around Eq. 3 that ""Eq. 3 is equivalent to Theorem 1 of [1] for deterministic encoder-decoder pairs"" and don\'t provide any proofs for this nontrivial fact. \n\nThe following is based on some quick derivations I did while reviewing. \n\nRecall that in the current paper Px is the data distribution, Py is the push-forward of Px through the superposition of the encoder \\phi and decoder \\psi (in other words Py is a distribution of \\psi(\\phi(X)) when X is distributed according Px). The authors state that:\n   \\inf_{\\phi, \\psi} Wc(Px, Py)\n    is equivalent to\n   (* ) \\inf_{\\phi, \\psi} E_{X \\sim Px}[ c(X, \\psi(\\phi(X))) ].\nIn other words, the authors state that using Theorem 1 of [1] they are able to show that minimizing a c-optimal transport distance between Px and Py (which is parametrized by \\psi and \\phi) is *equivalent* to an unconstrained optimization problem appearing on the r.h.s. of Equation 3. \n\nNow, the Theorem 1 of [1] referenced by authors states that if Pz is any prior distribution over the latent space and \\psi * Pz is its push-forward through the deterministic decoder \\psi, then the optimal transport between Px and the resulting latent variable model \\psi * Pz can be equivalently written as:\n   (**) Wc(Px, \\psi * Pz) = \\inf_{f such that f * Px = Pz} E_{X \\sim Px}[ c(X, \\psi(f(X))) ].\nImportantly, note how the right hand side of (**) contains a constrained optimization over an auxiliary (encoder) function f, which does not appear at all in the left hand side. If the authors were to apply (**) directly, they would arrive at the following statement:\n   \\inf_{\\phi, \\psi} Wc(Px, Py)\n    is equivalent to\n   (*** ) \\inf_{\\phi, \\psi} \\inf_{f such that f * Px = \\phi * Px} E_{X \\sim Px}[ c(X, \\psi(f(X))) ].\nFinally, comparing (*) stated by the authors and (***) obtained above, we see that (*) is obtained by selecting one particular function f = \\phi from the set {f such that f * Px = \\phi * Px}. Meanwhile, this set in general may contain multiple other functions f and as a result this only shows that (*) >= (***) (as we replace \\inf_f with one particular choice of f). However, in this case, I think it is indeed possible to show that (*) = (***). Imagine (***) has a global minimum at (\\psi_0,\\phi_0, f_0), that is the global optimum of (***) equals E_{X \\sim Px}[ c(X, \\psi_0(f_0(X))) ]. The same value can be achieved by (*) by setting \\phi = f_0. QED. \n\nOnce again, these are my preliminary derivations and they need to be checked. But it looks like the claim of the authors is indeed true. \n\n****\n**** 2. Empirical evidence is not convincing. ****\n****\nThe main topic of the paper is the unsupervised generative modeling, and the authors claim certain improvements in this field compared to the previous literature. Even though there are no ultimate evaluation metrics available in the field, recently the researchers started supporting their methods with several metrics, including FID scores. By now for most of the widely used datasets the state of art FID scores are well known. In all the experiments the authors provide pictures and interpolations (last row of Fig. 3, Fig. 5) without numbers. I would say nowadays presenting pictures is not enough (being too subjective) and at least some objective numbers (preferably FID) capturing the quality of generated samples should be reported. The authors go into detailed measurements of discrepancy between the aggregate posterior pz and the prior qz, but it is not clear how this affects the actual sample generation. Finally, it is not clear why the authors compare only to WAE-GAN and did not consider WAE-MMD, which is free of adversarial training (in contrast to WAE-GAN) and thus has a stable training and does not involve extra computations of updating the discriminator (as noted by authors on page 10).\n\n[1] Bousquet et al., 2017.']","[70, -20, -50]","[50, 50, 20]","[""The sentiment score is 70 (positive) because the reviewer describes the paper as 'interesting' and highlights several positive aspects, such as the introduction of new ideas, theoretical contributions, and computational attractiveness. The overall tone is supportive and appreciative of the work. The politeness score is 50 (slightly polite) because the reviewer uses neutral, professional language throughout and offers constructive remarks without harsh criticism. The use of phrases like 'interesting work' and the structured, respectful presentation of remarks contribute to a polite tone, though it doesn't reach extremely high levels of politeness."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some strengths (easy to read, clear concepts), they express major concerns about the paper's innovation level, empirical results, and missing comparisons. The overall tone suggests the reviewer is not fully convinced by the paper's contributions. The politeness score is moderately positive (50) as the reviewer uses professional language, acknowledges strengths, and frames criticisms as 'comments' rather than harsh judgments. They use phrases like 'The authors may consider' which is a polite way of suggesting improvements."", ""The sentiment score is -50 because the reviewer expresses 'several major issues' with the paper, indicating a generally negative view. However, they do acknowledge some positive aspects like 'interesting questions' raised, so it's not maximally negative. The politeness score is 20 because the reviewer uses professional language and provides detailed explanations for their critiques, which is respectful. They avoid harsh personal criticisms and use phrases like 'I want to point out' rather than more accusatory language. However, the overall critical tone prevents a higher politeness score. The reasoning is based on the reviewer's opening statement about 'major issues', their detailed critique of mathematical claims and empirical evidence, and their professional but critical tone throughout.""]"
"['The authors analyze the local SGD algorithm, where $K$ parallel chains of SGD are run, and the iterates are occasionally synchronized across machines by averaging. For sufficiently short intervals between synchronization, the algorithm achieves the same convergence rate in terms of the number of gradient evaluations as parallel minibatch SGD, but with the advantage that communication can be significantly reduced.\n\nThe algorithm is simple and practical, and the analysis is concise and seems like it could be applicable more generally to other parallel SGD variants.\n\nI am curious about what happens for the analysis of the algorithm when $H$ becomes large. As the authors point out, when $H=T$, this is one-shot averaging which is known to converge. The authors mention not working too hard to optimize the bounds for extreme values of $H$, which is fine, but I wonder if this is possible using their analysis technique, or whether new tools would be necessary.', 'This paper presents an analysis of ""local SGD"", which averages estimators obtained by running SGD in separate machines once in a while. The paper presents bounds on ""how frequent"" the estimators required to be averaged in order to yield linear parallelization speedups. This is an interesting paper, but I have some concerns that I will elaborate on below:\n\n[1] This paper\'s assumption of bounded variance of Stochastic Gradients and drawing conclusions about frequency of averaging does not reflect practical implementations of SGD for Machine Learning contexts. For example, note that in this oracle model, there exists bound on batch size (T^alpha, alpha\\in[1/3,1/2]) that yield linear parallelization speedups (for example, see Dekel et al. (2012)); however, as Dekel et al (2012) note, such bounds are fairly crude estimates on a per-problem basis for practical purposes. These issues naturally continue to exist with regards to the upperbound on the frequency of communication as argued by this paper. \n\n[2] Furthermore, the claim that such a bound on frequency of communication for local SGD which is not known before is not really true. In the convex case, the paper of Jain et al. (2016) presents a precise characterization of when to average of iterates across machines to obtain linear parallelization speedups, and this is a problem dependent quantity that works without assumptions such as bounded variance of stochastic gradients for the least squares problem. Note that, as reflective in practice, this result conveys that averaging the solutions of multiple independent runs of SGD does not help anything when the bias (initial error) dominates the variance. \n\n[3] Note that local SGD has been known for a while and is referred to as Iterative Parameter Mixing in the literature. An example of this is the thesis of Greg Coppola (2015). A more careful literature search can provide more references/results on this topic.\n\n[4] This paper claims that (in page 2) in order to ""improve computation versus communication tradeoff, one can increase the batch size or increase communication interval"". This appears to be an imprecise statement. For example, if I kept increasing batchsize without any limit, and the bias in my problem is much larger than the variance (where bias and variance follows definitions from Bach and Moulines (2011,2013)), this does not lead to any parallelization speedup. This is in contrast to when the variance dominates the bias, wherein, model averaging/increasing batch size helps. What is the reason for the authors to conclude that increasing batch size is equivalent to increasing communication interval?', 'The authors of this paper analyze a well known technique for parallel training, where each compute node locally trains a model with SGD, and once in a while the K compute nodes average their models. Local SGD, although not as widely used as mini-batch SGD, can provide some gains in terms of the cost of communication. This can be achieved by decreasing the frequency of synchronization, while locally also increasing the minibatch. \n\nTo the best of my knowledge, the authors are the first to provide a complete theoretical analysis of local SGD for strongly convex functions. They prove that under strong convexity, and the bounded gradients assumption, local SGD will (in the worst case) achieve a linear speedup over vanilla SGD, as long as the parallel models are averaged frequently enough. They show that although frequent averaging is important for speedup, the overall communication cost can be lower than minibatch SGD that may require smaller batches and hence more frequent communication. \n\nThe authors extend their results to the asynchronous case, where a similar convergence bound is derived. The overall theory seems to be partly inspired by the perturbed iterates framework of Mania et al., however the application is novel and interesting.\n\nThe authors include some limited experimental results that validate their bounds.\n\nThis is a well-written paper, that will certainly be of interest to researchers working on stochastic optimization, and distributed learning. The results are interesting and clearly stated. The proofs seem complete and correct, and are easy to follow. \n\nI have two minor comments:\n1) In a recent paper, Dong et al. [1] suggest that for any problem (convex or nonconvex), the largest possible batch size in minibatch SGD that allows for linear speedups will be proportional to “gradient diversity”, i.e., a measure of similarity between the concurrently processed gradients. For example, when all gradient are identical, there is no speedup to be extracted. This diversity term does not seem to appear in the main theorem, as one may expect. For example, the presented bounds still seem to provide speedup gains for the case where all individual n functions are identical (eg minimum grad. diversity). This should not be possible, as there are no parallel speedups to be extracted in this case. I’m wondering how that fact is reflected in the presented bounds (maybe it’s one of the extreme parameter cases that are not covered by the main theorem).\n\n2) The authors do not provide details of their experimental setup. For example it would be useful to know what hardware they implemented their algorithms on. It seems that they run experiments for up to 1K workers. Are these individual cores, or was this the result of hyper-threading? Finally, it’s unclear if Fig 1 is a theoretical, or an experimental curve.\n\n\n\n[1] http://proceedings.mlr.press/v84/yin18a/yin18a.pdf\n']","[80, -50, 80]","[70, 20, 70]","[""The sentiment score is 80 (positive) because the reviewer expresses a favorable view of the paper, describing the algorithm as 'simple and practical' and the analysis as 'concise' and potentially widely applicable. The reviewer also shows interest in the work by asking a curious question about extending the analysis. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledges the authors' choices ('which is fine'), and frames their question as curiosity rather than criticism. The reviewer also uses phrases like 'I am curious' and 'I wonder,' which maintain a polite and constructive tone. The scores are not 100 in either case because while positive and polite, the review does include some implicit suggestions for improvement and is not overly effusive in its praise."", ""The sentiment score is -50 because while the reviewer acknowledges the paper as 'interesting', they express several significant concerns and criticisms. The review points out multiple issues with the paper's assumptions, claims, and literature review, indicating a generally negative sentiment. However, it's not entirely negative as the reviewer does recognize some merit in the work. The politeness score is 20 because the reviewer maintains a professional tone throughout, using phrases like 'This is an interesting paper, but I have some concerns' and avoiding harsh or personal criticisms. They present their concerns in a factual manner, citing relevant literature to support their points. However, the language is not overtly polite or complimentary either, maintaining a mostly neutral, academic tone with a slight lean towards politeness."", ""The sentiment score is 80 (positive) because the reviewer describes the paper as 'well-written' and states that it 'will certainly be of interest to researchers'. They also mention that the 'results are interesting and clearly stated' and the 'proofs seem complete and correct'. The overall tone is very positive, with only minor comments provided. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, acknowledging the authors' contributions and providing constructive feedback. They use phrases like 'To the best of my knowledge' and 'I'm wondering', which show consideration. The reviewer also frames their comments as suggestions rather than criticisms. The score is not higher because the language, while polite, is primarily neutral and professional rather than overtly courteous.""]"
"['The paper extends an existing topic model - DocNADE - by replacing the feedforward part of the network which combines the textual context with an LSTM sequence model. Hence this paper fits in a long tradition of work which aims to extend the bad-of-words model from the original LDA paper with some sequence information.\n\nThe authors do a commendable job in thoroughly evaluating the proposed extension, using a number of evaluations based on perplexity, topic coherence, and text retrieval and categorization.\n\nMy main problem with the paper as it stands is that it a) arguably oversells the contribution, and b) is unclear when explaining certain crucial aspects of the model.\n\nIt would also help to have a clearer statement of whether the contribution here is on the document modeling side, or the language modeling side. Motivation is provided from both angles, but the evaluation focuses largely on the topic modeling (which is fine, just need to say it).\n\nMore specific comments:\n--\nThe abstract should mention that the DocNADE model already exists, and that the contribution of the current work is to extend that existing model in a particular way. For those readers unfamiliar with DocNADE, this will help situate the work with regard to the existing literature.\n\nUsing existing word embeddings as a \'prior\' for the LSTM word embeddings is a completely standard alternative now to learning those embeddings from scratch. I\'m not sure that can count as a second, major contribution of the paper. (I\'m also not sure that either extension to DocNADE warrants a new name, but I\'ll leave that to the authors\' judgement.)\n\nI\'m confused by one aspect of the DocNADE model: ""the topic assigned ...equally depends all the other words appearing in the same document"". But the model is generative, no? And eqn 1 suggests that each word is generated conditioned on the *previous* words in the document, or did I miss something? \n\nRelated to this point, DocNADE transforms its BoWs into a sequence. But what\'s the order? Is it just the order of the words in the document? In which case it\'s very similar to the LSTM extension, except the LSTM keeps the order in the history, whereas the bag-of-words model doesn\'t.\n\nRelation to generative models: LDA is a generative model with a generative story. It\'s not completely obvious to me what the generative story is in the new model. Talking about ""distributed compositional priors"" doesn\'t help, since I\'m assuming these aren\'t priors in a Bayesian modeling sense? (It\'s also not clear in what sense these ""priors"" are compositional, but that\'s a separate question.)\n\nEquation 2: what\'s the motivation for mixing the LSTM history with the bag-of-words (esp. if the history is from the same bag of words in each case). Why not just use the LSTM?\n\nIt would be useful to state in the main body of the text what the value of lambda ends up being. In 3.1 there\'s a suggestion this might be 0.01, but that effectively ignores the LSTM?\n\nSimilar question: how can the DocNADE model provide a *global* context if the model is generative?\n\nPerplexity is a reasonable thing to measure, but presumably the auto-regressive nature of the LSTM means that it\'s more-or-less guaranteed to do better than a bag-of-words model? I wonder if it\'s worth acknowledging this fact?\n\nI don\'t understand why lambda has to be zero ""to compute the exact log-likelihood"".\n\nThe first line of the conclusion doesn\'t say much: it\'s pretty obvious that the ordering of the words is going to help better estimate the probability of a word in a given context; 50 years of language modeling research has already taught us that.\n\nMinor presentational comments:\n--\nSome of the hyphenation looks odd, eg in the title. Are you using the standard LaTeX hyphenation settings?\n\nStrictly speaking, I\'m not sure that \'bear\' in the example is a proper noun.\n\n""orderless sets of words"": bags, not sets, since the counts matter, no?\n\nThe tables are too small, with a lot of numbers in them. One option is to move some of the details to the Appendix. Either way there needs to be more summary in the main body explaining what the numbers tell us.\n', 'DocNADE has great performance so this is a welcome bit of\nresearch extending it.\n\nThere has been a huge amount of activity in combining topic models with\n(1) embeddings and (2) neural networks such as LSTMs and RNNs.\nI will say I have great sympathy for the poor author trying to do\nfair comparisons against start-of-the-art because the standards are\nmoving quickly.\n\nIn this case, some neural network papers I have seen are TopicRNNs by\nDieng, Wang Gao and Paisley, and LLA by Zaheer, Ahmed and Smola.  The\nlatter is still a bag-of-words model and but places the LSTM over the\nsequence of topic proportions.  The Gauss-LDA and glove-DMM work is\nfairly dated (in our fast-paced ML world) and their performance is\nknown to be poor, as some papers in 2017 show.  Now I know historically LDA has been fairly poor\nwith IR tasks, but I would expect the recent supervised LDA methods,\nsome also have word embeddings, to do better as well.\nSo the discussion of related work and comparative experiments\nare poor.\n\nIf you want to illustrated good improvememts gained using embeddings,\nit helps to try different proportions, say 20/40/60/80% of a data\nset and plot.  Usually, you should see embeddings aid performance\ndramatically for smaller fractions of data sets.  Hence, your results\nseem strange.\n\nNote the data sets are all fairly small, which makes me wonder about\nthe computation time.  Could you give some computational performance\nstats for a data set?\n\nIn section 2.2 top of page 5, why is it ""pseudo"" log likelihood?\nIsn\'t that formula exact?\n\nThe paper has a relatively small part devoted to the model, and\nvirtually nothing on the algorithm, although this is probably covered\nin earlier DocNADE papers.   I\'m assuming the model is\ntrained by SGD on the log likelihood with all the parameters\nshoved in there in one go.  Is that right?  Would be nice to mention\nwhatever it is.\n\nThe use of four different kinds of evaluations (classification, IR,\nperplexity, etc.) is good.  Note that the improvement over the earlier\nDocNADE is quite small but clearly significant, and improvement of adding\nembeddings seems even smaller, though seems better for short texts.\nI wonder if the method for including embeddings is much good!\nNot fully convinced.\n\nAFTER RESPONSE:   Wow guys, what a great revision.  Thanks so much.', '\nCons: \nThe proposed method is not novel. For example, Lauly et al., 2017 have proposed a similar way of combining LM and DocNADE. This paper does not provide some motivations or theories behind such artificial combination (i.e., just linearly combine their hidden state) to explain why it works better than other alternatives (e.g., what about adding some linear layers before combining h_i^{DN} and h_i^{LM}).\n\nPros: \nHowever, the results seem to be solid and significantly better than the previous state-of-the-art methods. I think some recent neural topic models such as [1,2,3] are still missing even though there are already many tables in the paper (I am not an expert on neural topic modeling or embedding for IR tasks, so there might be others missing state of the arts which I am not aware of). In addition, why does Table 5 only compares perplexity between 3 methods and Table 6 only compares coherence between 4 or 5 methods, while there are 9 or 12 methods are compared in IR task (Table 3 and 4). What\'s the difficulty of comparing the coherence and perplexity of all different topic models (including [1,2,3])?\nI will vote for acceptance if the mentioned baselines are also compared or there are good reasons why they cannot be compared.\n\n\nWriting and presentation:\nThe quality of writing should be improved. Here are several examples.\n1. In the abstract, the following sentence needs to be rewritten and the rule of capitalization should be consistent. ""(2) Limited Context and/or Smaller training corpus of documents: In settings with a small number of word occurrences (i.e., lack of context) in short text or data sparsity in a corpus of few documents, the application of TMs is challenging.""\n2. I do not understand what\'s the purpose of the right figure in Figure 1. I think the paper does not do any matching like that.\n3. In the 3rd paragraph of the introduction, ""topmost"" -> top most \n4. The paper should have a related work section. In addition to the related work discussion scattered in the introduction, authors should discuss the difference between this work and Lauly et al., 2017. Authors should also include some related work such as [1,2,3].\n5. Just below (1), ""where,"" -> , where\n6. In the last sentence of the paragraph after (1), you mentioned ""v_{<i} are orderless"", so what\'s the ordering used in experiments? Random ordering?\n7. I guess ""a"" in algorithm 1 means sum_{k<i}(W_{:,v_k}), but I cannot find the explicit explanation about the purpose of ""a"".\n8. For ctx-DocNADEe, is W+E the embedding of words at input layer in LM?\n9. In the 3rd paragraph of section 2.2, you said: ""each row vector W_{j,:} is a distribution over vocabulary of size K"". Could W has negative values during optimization?  If yes, why a distribution representing a topic could have negative value. If no, you should explicitly mention this non-negativity constraint.\n10. Why are some values in Table 12 and 13 missing?\n\n[1] Cao, Z., Li, S., Liu, Y., Li, W., & Ji, H. (2015, January). A Novel Neural Topic Model and Its Supervised Extension. In AAAI (pp. 2210-2216).\n[2] Srivastava, A., & Sutton, C. (2017). Autoencoding variational inference for topic models. ICLR\n[3] Card, D., Tan, C., & Smith, N. A. (2017). A Neural Framework for Generalized Topic Models. arXiv preprint arXiv:1705.09296.']","[20, 50, -20]","[60, 70, 50]","[""Sentiment Score (20): The review begins positively, praising the authors for their 'commendable job' and thorough evaluation. However, it then expresses concerns about overselling the contribution and unclear explanations, which moderates the overall positive sentiment. The reviewer provides constructive criticism and suggestions for improvement, indicating a generally positive but cautious stance.\n\nPoliteness Score (60): The reviewer maintains a professional and respectful tone throughout. They use polite phrases like 'commendable job' and frame criticisms as suggestions or questions rather than direct attacks. The reviewer also acknowledges the authors' efforts and provides detailed feedback to help improve the paper. However, the score is not higher as the review is direct in pointing out flaws and doesn't use overly deferential language."", ""The sentiment score is 50 (slightly positive) because the reviewer starts by praising the research as 'welcome' and acknowledges the 'great performance' of DocNADE. However, they also point out several areas for improvement, including poor comparative experiments and discussion of related work. The overall tone is constructive rather than overtly negative or positive. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, acknowledges the challenges faced by the authors ('I have great sympathy for the poor author...'), and ends with an enthusiastic response to the revision ('Wow guys, what a great revision. Thanks so much.'). The reviewer offers criticisms, but does so in a professional and constructive manner, suggesting improvements rather than simply pointing out flaws."", ""The sentiment score is slightly negative (-20) because the review starts with criticisms about the lack of novelty and insufficient motivation for the proposed method. However, it also acknowledges some positive aspects like solid results and significant improvements over previous methods. The overall tone is more critical than positive, but not overwhelmingly negative. The politeness score is moderately positive (50) because the reviewer uses respectful language throughout, offers constructive criticism, and balances negative points with positive ones. The reviewer also uses phrases like 'I think' and 'I will vote for acceptance if...' which maintain a polite tone. The detailed list of writing improvements is presented in a helpful manner rather than a harsh critique.""]"
"['Several recent works propose to discover bugs in code by creating dataset of presumably correct code and then to augment the data by introducing a bug and creating a classifier that would discriminate between the buggy and the correct version. Then, this classifier would be used to predict at each location in a program if a bug is present.\n\nThis paper hypothetizes that when running on buggy code (to discover the bug) would lead to such classifier misbehave and report spurious bugs at many other locations besides the correct one and would fail at precisely localizing the bug. Then, they propose a solution that essentially create a different classifier that is trained to localize the bug.\n\nUnfortunatley this leads to a number of weaknesses:\n - The implementation and evaluation are only on a quite syntactic system with low precision and that needs to sift through a huge amount of weak and irrelevant signals to make predictions.\n - The gap here is huge: the proposed system is only based on program syntax and gets 62.3% accuracy, but state-of-the-art has 85.5% (there is actually another recent technique [1] also with accuracy in the >80% range)\n - It is not clear that the entire discussed problem is orthogonal to the selection of such weak baselines to build the improvements on.\n - Trade-offs are not clear: is the proposed architecture slower to train and query than the baselines?\n\nStrengths of the paper are:\n - Well-written and easy to follow and understand.\n - Evaluation on several datasets.\n - Interesting architecture for bug-localization if the idea really works.\n\n[1] Michael Pradel, Koushik Sen. DeepBugs: a learning approach to name-based bug detection', ""This paper considers the problem of VarMisuse, a kind of software bug where a variable has been misused. Existing approaches to the problem create a complex model, followed by enumerating all possible variable replacements at all possible positions, in order to identify where the bug may exist. This can be problematic for training which is performed using synthetic replacements; enumeration on non-buggy positions does not reflect the test case. Also, at test time, enumerating is expensive, and does not accurately capture the various dependencies of the task. This paper instead proposes a LSTM based model with pointers to break the problem down into multiple steps: (1) is the program buggy, (2) where is the bug, and (3) what is the repair. They evaluate on two datasets, and achieve substantial gains over previous approaches, showing that the idea of localizing and repairing and effective.\n\nI am quite conflicted about this paper. Overall, the paper has been strengths:\n- It is quite well-written, and clear. They do a good job of describing the problems with earlier approaches, and how their approach can address it.\n- The proposed model is straightforward, and addresses the problem quite directly. There is elegance in its simplicity.\n- The evaluation is quite thorough, and the resulting gains are quite impressive.\n\nHowever, I have some significant reservations about the novelty and the technical content. The proposed model doesn't quite bring anything new to the table. It is a straightforward combination of LSTMs with pointers, and it's likely the benefits are coming from the reformulation of the problem, not from the actual proposed model. This, along with the fact that VarMisuse is a small subset of the kinds of bugs that can appear in software, makes me feel the ideas in this paper may not lead to significant impact on the research community.\n\nAs a minor aside, this paper addresses some specific aspects of VarMisuse task and the Allamanis et al 2018 model, and introduces a model just for it. I consider the Allamanis model a much more general representation of programs, and much more applicable to other kinds of debugging tasks (but yes, since they didn't demonstrate this either, I'm not penalizing this paper for it).\n\n--- Update ----\nGiven the author's response and the discussion, I'm going to raise the score a little. Although there are some valid concerns, it provides a clear improvement over Allamanis et al paper, and provides an interesting approach to the task.\n"", 'This paper presents an LSTM-based model for bug detection and repair of a particular type of bug called VarMisuse, which occurs at a point in a program where the wrong identifier is used. This problem is introduced in the Allamanis et al. paper. The authors of the paper under review demonstrate significant improvements compared to the Allamanis et al. approach on several datasets.\n\nI have concerns with respect to the evaluation, the relation of the paper compared to the state-of-the-art in automatic program repair (APR), and the problem definition with respect to live-variable analysis.\n\nMy largest concern about both this paper and the Allamanis et al. paper is how it compares to the state-of-the-art in APR in general. There is a large and growing amount of work in APR as shown in the following papers:\n[1] L. Gazzola, D. Micucci, and L. Mariani, “Automatic Software Repair: A Survey,” IEEE Transactions on Software Engineering, pp. 1–1, 2017.\n[2] M. Monperrus, “Automatic Software Repair: A Bibliography,” ACM Comput. Surv., vol. 51, no. 1, pp. 17:1–17:24, Jan. 2018.\n[3] M. Motwani, S. Sankaranarayanan, R. Just, and Y. Brun, “Do automated program repair techniques repair hard and important bugs?,” Empir Software Eng, pp. 1–47, Nov. 2017.\n\nAlthough the proposed LSTM-based approach for VarMisuse is interesting, it seems to be quite a small delta compared to the larger APR research space. Furthermore, the above papers on APR are not referenced.\n\nThe paper under review mostly uses synthetic bugs. However, they do have a dataset from an anonymous industrial setting that they claim is realistic. In such a setting, I would simply have to trust the blinded reviewers. However, the one industrial software project tells me little about the proposed approach’s effectiveness when applied to a significant number of widely-used software programs like the ones residing in state-of-the-art benchmarks for APR, of which there are at least the following two datasets:\n[4] C. L. Goues et al., “The ManyBugs and IntroClass Benchmarks for Automated Repair of C Programs,” IEEE Transactions on Software Engineering, vol. 41, no. 12, pp. 1236–1256, Dec. 2015.\n[5] R. Just, D. Jalali, and M. D. Ernst, “Defects4J: A Database of Existing Faults to Enable Controlled Testing Studies for Java Programs,” in Proceedings of the 2014 International Symposium on Software Testing and Analysis, New York, NY, USA, 2014, pp. 437–440.\n\nThe above datasets are not used or referenced by the paper under review.\n\nMy final concern about the paper is the formulation of live variables. A variable is live at certain program points (e.g., program statements, lines, or tokens as called in this paper). For example, from Figure 1 in the paper under review, at line 5 in (a) and (b), object_name and subject_name are live, not just sources.  In the problem definition, the authors say that ""V_def^f \\subseteq V denotes the set of all live variables"", which does not account for the fact that different variables are alive (or dead) at different points of a program. The authors then say that, for the example in Figure 1, ""V_def^f contains all locations in the program where the tokens in V appear (i.e., tokens in the Blue boxes), as well as token sources from line 1”. The explanation of the problem definition when applied to the example does not account for the fact that different variables are alive at different program points. I’m not sure to what extent this error negatively affects the implementation of the proposed model. However, the error could be potentially quite problematic.']","[-30, 20, -50]","[20, 70, 50]","[""The sentiment score is -30 because while the reviewer acknowledges some strengths of the paper, they primarily focus on several weaknesses and limitations. The review starts with 'Unfortunately this leads to a number of weaknesses' which sets a negative tone. However, it's not extremely negative as they do mention positive aspects. The politeness score is 20 because the reviewer uses relatively neutral language and doesn't use harsh or rude phrasing. They present their criticisms in a professional manner, using phrases like 'It is not clear that...' rather than more confrontational language. The positive comments at the end also contribute to the politeness. However, it's not extremely polite either, as it doesn't go out of its way to be overly courteous or encouraging."", ""The sentiment score is slightly positive (20) because while the reviewer expresses some significant reservations about the novelty and technical content, they also acknowledge several strengths of the paper, including its clear writing, elegant simplicity, and impressive evaluation results. The reviewer's conflicted feelings and the subsequent update raising the score slightly contribute to this mildly positive sentiment. The politeness score is relatively high (70) as the reviewer uses respectful and professional language throughout, acknowledging both strengths and weaknesses without harsh criticism. They use phrases like 'I am quite conflicted' and 'I have some significant reservations' which express concerns politely. The reviewer also shows openness to changing their opinion based on the authors' response, which is a courteous approach in academic discourse."", ""The sentiment score is -50 because while the reviewer acknowledges some positive aspects of the paper (e.g., 'demonstrate significant improvements'), they express several significant concerns about the evaluation, relation to state-of-the-art, and problem definition. The overall tone is critical, indicating a negative sentiment, but not entirely dismissive. The politeness score is 50 because the reviewer uses professional and respectful language throughout, avoiding harsh or personal criticisms. They present their concerns objectively and provide specific references to support their points. The reviewer also uses phrases like 'I have concerns' and 'My largest concern' which are polite ways to express criticism. However, the review doesn't go out of its way to be overly polite or complimentary, maintaining a neutral professional tone.""]"
"['This manuscript describes a deep convolutional neural network for\nassigning proteins to subcellular compartments on the basis of\nmicroscopy images.\n\nPositive points:\n\n- This is an important, well-studied problem.\n\n- The results appear to improve significantly on the state of the art.\n\n- The experimental comparison is quite extensive, including\n  reimplementations of four, competing state-of-the-art methods, and\n  lots of details about how the comparisons were carried out.\n\n- The manuscript also includes a human-computer competition, which the\n  computer soundly wins.\n\n- The manuscript is written very clearly.\n\nConcerns:\n\nThere is not much here in the way of new machine learning methods.\nThe authors describe a particular neural network architecture\n(""GapNet-PL"") and show empirical evidence that it performs well on a\nparticular dataset.  No claims are made about the generalizability of\nthe particular model architecture used here to other datasets or other\ntasks.\n\nA significant concern is one that is common to much of the deep\nlearning literature these days, namely, that the manuscript fails to\nseparate model development from model validation. We are told only\nabout the final model that the authors propose here, with no\ndiscussion of how the model was arrived at.  The concern here is that,\nin all likelihood, the authors had to try various model topologies,\ntraining strategies, etc., before settling on this particular setup.\nIf all of this was done on the same train/validation/test split, then\nthere is a risk of overfitting.\n\nThe dataset used here is not new; it was the basis for a competition\ncarried out previously.  It is therefore somewhat strange that the\nauthors chose to report only the results from their reimplementations\nof competing methods.  There is a risk that the authors\'\nreimplementations involve some suboptimal choices, relative to the\nmethods used by the originators of those methods.\n\nAnother concern is the potential circularity of the labels.  At one\npoint, we are told that ""Most importantly, these labels have not been\nderived from the given microscopy images, but from other\nbiotechnologies such as microarrays or from literature.""  However,\nearlier we are told that the labels come from ""a large battery of\nbiotechnologies and approaches, such as microarrays, confocal\nmicroscopy, knowledge from literature, bioinformatics predictions and\nadditional experimental evidence, such as western blots, or small\ninterfering RNA knockdowns.""  The concern is that, to the extent that\nthe labels are due to bioinformatics predictions, then we may simply\nbe learning to re-create some other image processing tool.\n\nThe manuscript contains a fair amount of biology jargon (western\nblots, small interfering RNA knockdowns, antibodies, Hoechst staining,\netc.) that will not be understandable to a typical ICLR reader.\n\nAt the end, I think it would be instructive to show some examples\nwhere the human expert and the network disagreed.\n\nMinor:\n\np. 2: ""automatic detection of malaria"" -- from images of what?\n\np. 2: Put a semicolon before ""however"" and a comma after.\n\np. 2: Change ""Linear Discriminant"" to ""linear discriminant."" Also, remove\nthe abbreviations (SVM and LDA), since they are never used again in\nthis manuscript.\n\np. 5: Delete comma in ""assumption, that.""\n\np. 8: ""nearly perfect"" -> ""nearly perfectly""\n\nThe confusion matrices in Figure 5 should not be row normalized --\njust report raw counts.  Also, it would be better to order the classes\nso that confusable ones are nearby in the list.\n', 'The paper proposes a CNN variant tailored for high-resolution\nimmunofluorescence confocal microscopy data.  The authors show\nthat the method outperforms a human expert.\n\nThe proposed method is evaluated on benchmark instances\ndistributed by Cyto Challenge \'17, which is presumably the best\ndata source for the target application.  Indeed, the method\nperforms better than several competitors plus a single human\nexpert.\n\nThe paper is well written and easy to follow.  I could not spot any\nmajor technical issues.\n\nThis is an applicative paper targeting a problem that is very\nrelevant in bioinformatics, but it sports little methodological\ninnovation.  On the biological side, the contribution looks\nsignificant.  Why not targeting a bioinformatics venue?\n\n\nDetailed comments:\n\nPapers that stretch multiple fields are always hard to review.  On\none hand, having contributions that cross different fields is a\nhigh-risk (but potentially highly rewarding) route, and I applaud\nthe authors for taking the risk.  On the other hand, there\'s the risk\nof having unbalanced contributions.\n\nI think that the contribution here is mostly on the bioinformatics\nside, not on the deep learning side.  Indeed, the method boils\ndown to a variant of CNNs.  I am skeptical that this is enough to\nspark useful discussion with practitioners of deep learning\n(although I could be wrong?).\n\nFinally, I am always skeptical of ""human-level"" performance claims.\nThese are strong claims that are also hard to substantiate.  I don\'t\nthink that comparing to a *single* expert is quite enough.  The fact\nthat ""the human expert stated that he would be capable to localize\nproteins with the provided data"" doesn\'t sound quite enough.  I\nagree that the user study could be biased (and that ""It would be\na tremendous effort to find a completely fair experimental\nsetting""), but, if this is the case, the argument that the method\nreaches human-level performance is brittle.\n\n\nOther remarks and questions:\n\n- Why wasn\'t the dataset of Liimatainen et al. used for the\ncomparison?\n\n- The authors say that ""due to memory restrictions, the smallest\nvariant of DenseNet was used"".  How much of an impact could have\nthis had on performance?\n\n- ""One random crop per training sample is extracted in every epoch"".\nDoesn\'t this potentially introduce labeling errors?  Did you observe\nthis to occur in practice?\n\n- The authors claim that the method is close to perfect in terms\nof AUC.  In decision-making applications, the AUC is a very\nindirect measure of performance, because it is independent of\nany decision threshold.  In other words, the AUC does not measure\nthe yes/no decisions suggested by the method.  Why is the AUC\nimportant in the biological application at hand?  Why is it important\nto the users (biologists, I suppose) of the system?\n\nIn particular, ""our method performs nearly perfect, achieving an\naverage AUC of 98% and an F1 score of 78%"" seems inconsistent\nto me---the F1 is indeed ""only"" 78%.\n\n- I would appreciate if there was a thorough discussion of the\nfailure mode of the expert.  What kind of errors did he/she\nmake?  How are these cases handled by the model?', 'This paper designed a GapNet-PL architecture and applied GapNet-PL, DenseNet, Multi-scale CNN etc. to the protein image (multi-labels) classification dataset.\n\nPros:\n\n1. The proposed method has a good performance on the given task. Compared to the claimed baselines (Liimatainen et al. and human experts), the proposed architecture shows a much higher performance.\n\nCons:\n\n1. The novelty of the proposed architecture is limited. The main contribution of this work is the application of CNN-based methods to the specific biological images.\n\n2. The existing technical challenge of this task is not significant and the motivation of the proposed method could be hardly found in this paper. \n\n3. The baselines are not convincing enough. Since the performance of Liimatainen et al. is calculated on a different test dataset, the results here are not comparable. The prediction from a human expert, which may vary from individuals, fails to provide a confident performance comparison.\n\n4. Compared to the existing models (DenseNet, Multi-scale CNN etc.), the performance improvement of the proposed model is limited.']","[50, 50, -20]","[75, 80, 50]","['The sentiment score is 50 (slightly positive) because the review begins with several positive points, praising the importance of the problem, the improvement on state of the art, the extensive experimental comparison, and the clear writing. However, it also raises significant concerns about the methodology, potential overfitting, and circularity of labels, which balance out the positive aspects. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, acknowledges the strengths of the work, and frames concerns as constructive criticism rather than harsh judgments. The reviewer also offers specific suggestions for improvement and points out minor issues in a helpful manner. The tone remains professional and courteous throughout the review.', ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths (well-written, easy to follow, no major technical issues, significant biological contribution) while also pointing out limitations (little methodological innovation, skepticism about human-level performance claims). The overall tone is balanced but leans positive.\n\nThe politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the authors' efforts, and frames criticisms constructively. Phrases like 'I applaud the authors for taking the risk' and 'I could be wrong?' demonstrate a considerate approach. The reviewer also offers detailed feedback and suggestions, which is a polite way to help improve the paper.\n\nThe reviewer maintains a professional and courteous tone while providing both positive feedback and constructive criticism, resulting in a review that is both slightly positive in sentiment and notably polite in language use."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the paper, there are more cons listed and they seem to outweigh the positives. The reviewer points out limited novelty, lack of significant technical challenge, unconvincing baselines, and limited performance improvement. However, it's not extremely negative as the reviewer does recognize the good performance of the proposed method.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and objective tone throughout. They present both pros and cons without using harsh language or personal attacks. The critique is presented in a constructive manner, using phrases like 'could be hardly found' instead of more accusatory language. The reviewer also uses neutral language like 'the performance improvement... is limited' rather than more negative phrasing.""]"
"['Summary:\n\nThis paper proposes learning reward functions via inverse reinforcement learning (IRL) for vision-based instruction following tasks like ""go to the cup"". The agent receives the language instruction (generated via grammar templates) and a set of four images (corresponding to four cardinal directions) from virtual cameras mounted on the agent as input at every time step and its aim is either to 1. navigate to the goal location (navigation task) or 2. move an object from one place to another (pick task). \n\nThe really interesting part in this paper is learning reward functions such that they generalize across different tasks and environments (e.g. indoor home layouts). This differentiates it from the standard IRL setting where reward functions are learnt and then policies optimized on this reward function on the *same* environment. \n\nIn order to generalize across tasks and environments a slight modification to the max-ent IRL gradient equations are made: 1. Similar to meta-learning the gradient is taken with respect to multiple tasks (in a sampling-based manner) and 2. Making the reward function a function of not just states and actions but also language context. The overall algorithm (Algorithm 1) is simple and the critical step of computing an optimal policy to compute the IRL gradient is done by assuming that one has access to full state and dynamics and essentially running a planner on the MDP. This assumption is not unreasonable since in a simulator one has access to the full dynamics and can hence one can compute the optimal trajectories by planning. \n\nExperiments are presented on the SUNCG dataset of indoor environments. Two baselines are presented: One using behavior cloning (BC) and an oracle baseline which simply regresses to the ground truth reward function which is expected to be an upper bound of performance. Then DQN is used (with and without reward shaping) using the learnt reward functions to learn policies which are shown to have better performance on different tasks. \n\nComments and Questions:\n\n- The paper is generally well-written and easy to understand. Thanks!\n\n- The idea of using IRL to learn generalizable reward functions to learn policies so as to aid transfer between environments in such vision-language navigation tasks is interesting and clearly shows benefits to behavior cloning.\n\n- One of my main concerns (and an interesting question that this paper naturally raises) is how does this approach compare to imitation learning (not vanilla behavior cloning which is straight-up supervised learning and has been theoretically and empirically shown to have worse performance due to distribution shifts. See Ross and Bagnell, 2011, Ross, Gordon, Bagnell 2012 (DAgger, Ross and Bagnell 2014 (AggreVate), Chang et al., 2015 (LOLS), etc). If the same budget of 10 demonstrations per environment is used via DAgger (where say each iteration of DAgger gets say 2 or 3 demonstrations until the budget is exhausted) how does it compare? Note online version of DAgger has already been used in similar settings in ""Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments"" by Anderson et al, CVPR 2018. The main difference from their setting is that this paper considers higher level tasks instead of taking as input low-level turn-by-turn language inputs. \n\n- The following papers are relevant and should be cited and discussed:\n""Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments"" by Anderson et al, CVPR 2018.\n\n""Embodied Question Answering"", Das et al, CVPR 2018.\n\nUpdate:\n------------\nAfter looking at other reviews and author rebuttals to all reviews I am raising my grade. \n', 'Paper Summary: This paper studies the inverse reinforcement learning problem for language-based navigation. Given the panorama image as its observation, language embedding as its goal, a deep neural network architecture is proposed to predict the reward function from the input observation and goal. Maximum causal entropy IRL has been adopted to learn such language-conditioned reward function. This paper used the SUNCG environment for experiments and designed two tasks (navigation and pick-and-place) for evaluation.\n\n==\nNovelty & Significance:\nThis paper studies a very interesting topic in reinforcement learning and the problem has potential usage when training robot agent in the real world.\n\n==\nQuality:\nOverall, reviewer feels that the experimental results are not very strong. Some of the points are not clearly presented. \n\nFirstly, is not very clear whether the argument made in the abstract “directly learning a language-conditioned policy leads to a poor performance” is justified or not. Please clarify this point in the rebuttal.\n\nSecondly, Table 1 and Table 2 can only be treated as ablation studies. The “reward-regression” is not a baseline but more about a oracle model. \nIs it possible to compare against some recent work such as Tung et al 2018 or Bahdanau et al 2018? Otherwise, it is not very clear whether the proposed approach is the state-of-the-art or not.\n\nThirdly, using the panorama image as observation seems not a practical choice. Is it possible to provide some ablation studies or discussions on the performance over number of views? \n\nFinally, the architecture design is not well-justified. Why not using pre-trained image classifiers (or DQN encoder) as feature extractor (or finetune the model from pre-trained image classifier)? The actual resolution (32 x 24 x 3) in the paper looks a bit unusual. \n\nOne more thing, the url provided in the paper directs to an empty project page. \n\nIf these concerns can be addressed in the rebuttal, reviewer is happy to re-evaluate (e.g., raise scores) this work.\n', 'This paper applies IRL to the cases of multiple tasks/environments and multimodal input features involving natural language (text) and vision (images). It is interesting to see the better performance of their proposed approaches with language-conditioned rewards over language-conditioned policies. The paper is written well.\n\nI view the technical contributions of this work to be at best incremental; it does not seem to address any significant technical challenge to be able to integrate the various known tools in their work. I am not able to learn as much as i would have liked from this paper.\n\nConsidering the use of deep learning that can handle highly complex images and text, the practical significance of this work can be considerably improved by grounding their work in real-world context and/or larger-scale environments/tasks, as opposed to simulated environments in this paper. See, for example,\n\nM. Wulfmeier, D. Rao, D. Z. Wang, P. Ondruska, and I. Posner, Large-scale cost function learning for path planning using deep inverse reinforcement learning, The International Journal of Robotics Research, 2017. \n\nThe authors say that ""The work of MacGlashan et al. (2015) requires an extensively hand-designed, symbolic reward function class, whereas we use generic, differentiable function approximators that can handle arbitrary observations, including raw images."" What then is the implication on how their proposed IRL algorithm is designed differently? How would the algorithm of MacGlashan et al. (2015) empirically perform as compared to the authors\' proposed approach?\n\n\n\nMinor issues\n\nPage 2: a comparison to in Section 6 to as an oracle?\nPage 3: What is rho_0?\nPage 7: In order compare against?\nPage 7: and and indicator on?']","[60, -20, -20]","[80, 50, 50]","[""The sentiment score is 60 (moderately positive) because the reviewer expresses interest in the paper's approach, noting it is 'interesting' and 'clearly shows benefits'. They also thank the authors for a well-written paper. However, they raise some concerns and suggest comparisons to other methods, indicating it's not entirely positive. The politeness score is 80 (quite polite) due to the reviewer's respectful tone throughout, use of phrases like 'Thanks!', and constructive framing of suggestions. They provide specific recommendations and relevant citations in a helpful manner, without harsh criticism. The reviewer also shows openness to changing their opinion, as evidenced by the update at the end raising their grade after considering other reviews and author rebuttals."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the interesting topic and potential usage, they express several concerns about the experimental results and presentation clarity. The reviewer states that 'the experimental results are not very strong' and lists multiple issues, indicating an overall negative sentiment. However, they do offer the possibility of re-evaluation if concerns are addressed, which prevents the score from being more negative. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, offers constructive criticism, and expresses willingness to reconsider their evaluation. They use phrases like 'Please clarify' and 'Is it possible to' which maintain a polite tone while raising concerns. The reviewer also ends on a positive note, indicating openness to improving their assessment if issues are addressed."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('interesting to see better performance', 'paper is written well'), they also express significant criticisms. The reviewer states that the technical contributions are 'at best incremental' and that they didn't learn as much as they would have liked. They also suggest ways to improve the work's practical significance. The politeness score is moderately positive (50) because the reviewer uses polite and professional language throughout. They offer constructive criticism and suggestions rather than harsh judgments, and they phrase their concerns as observations or questions rather than direct attacks. The reviewer also begins with positive comments before moving to criticisms, which is a polite approach. The minor issues are pointed out respectfully.""]"
"['Paper summary:\n\nThe paper presents two distinct contributions in text-to-speech systems:\na) It describes a method for distilling a Gaussian WaveNet into a Gaussian Inverse Autoregressive Flow that uses an analytically computed KL between their conditionals.\nb) It presents a text-to-speech system that is trained end-to-end from text to waveforms.\n\nTechnical quality:\n\nThe distillation method presented in the paper is technically correct. The evaluation is based on Mean Opinion Score and seems to follow good practices.\n\nThe paper makes three claims:\na) A WaveNet with Gaussian conditionals can model speech waveforms equally well as WaveNets with other types of conditionals.\nb) Analytically computing KL divergence stabilizes distillation.\nc) A text-to-speech system trained end-to-end from text to waveforms outperforms one that has separately trained text-to-spectrogram and spectrogram-to-waveform subsystems.\n\nClaims (a) and (c) are clearly demonstrated in the experiments. However, there is nothing in the paper that substantiates claim (b). I think the paper would be strengthened if the performance of sample-based KL distillation was added into Table 2, and if learning curves were reported that evaluate the amount of stabilization that an analytical KL may offer vs a sample-based KL.\n\nFurther points about the experiments:\n- It wasn\'t clear to me whether distillation happens at the same time as the autoregressive WaveNet is trained on data, or after it has been fully trained. I think the paper should make this clear.\n- The paper says that distillation makes generation three orders of magnitude faster. I think it would be good if actual generation times (e.g. in seconds) were reported.\n\nClarity:\n\nThe paper is generally well-written. Sections 1 and 2 in particular are excellent.\n\nHowever, section 3 contains several notational errors and technical inaccuracies, that makes it rather confusing to read. In particular:\n- q(x_t | z_{<=t}) is used in several places to mean the Gaussian conditional q(x_t | z_{<t}) (e.g. in Eqs (6) and (7), and elsewhere). This is confusing, as q(x_t | z_{<=t}) is actually a delta distribution.\n- q(x | z) is used in several places to mean q(x) (e.g. in Eq. (7), in Alg. 1 and elsewhere). This is confusing, as q(x | z) is also a delta distribution.\nI believe that section 3, especially subsections 3.2 and 3.3.1, should be reworked to be made clearer, and the notation should be carefully revised.\n\nI don\'t think the paper needs to span 9 pages. Section 3 is rather wordy, and should be compressed to the important points.\n\nOriginality:\n\nDistilling a Gaussian autoregressive model to another Gaussian autoregressive model by matching their Gaussian conditionals with an analytical KL is rather straightforward, and, methodologically speaking, I wouldn\'t consider it an original contribution on its own. However, I think its application and demonstration in text-to-speech constitutes an original contribution.\n\nSignificance:\n\nThe paper contains a substantial amount of significant work that I think is important to be communicated to the ICLR community, especially the text-to-speech community.\n\nReview summary:\n\nPros:\n+ Substantial amount of good work.\n+ Significant improvement in text-to-speech end-to-end software.\n+ Generally well-written (with the exception of section 3 which needs work).\n\nCons:\n- Some more experiments would be good to substantiate the claim that analytical KL is better.\n- Notational errors and confusion in section 3.\n- Too wordy, no need for 9 pages.\n\nNitpicks:\n- As I said above, I wouldn\'t consider distillation of models with Gaussian conditionals using analytical KLs methodologically novel, so I think the phrase ""novel regularized KL divergence"" should be moderated.\n- Eq. (1) should contain theta on the left hand side too.\n- Page 3: ""at Appendix B"" --> ""in Appendix B"".\n- Page 4: In flows we don\'t just ""suppose z has the same dimension as x""; rather, it\'s a necessary condition that must hold.\n- Footnote 5: It\'s unclear to me what it means to ""make the loss less sensitive"".\n- References: Real NVP, Fourier, Bayes, PixelCNN, WaveNet, VoiceLoop should be properly capitalized.', 'After reading other reviews and author comments, I have raised my rating to a 6. My main concerns remain (lack of significant contribution and lack of an ablation study with more comprehensive experiments). However, I\'m not against the paper as an interesting finding in and of itself. It would be great if the authors (or interested members of the research community) may analyze how general-purpose their proposals are (e.g., of Gaussian base distribution) and how extensive the results are on TTS benchmarks.\n\n--\n\nOverall, I very much like the direction this paper pursues. However, the content doesn\'t substantiate their two claimed contributions. I highly recommend the authors either back up their claims in more detail, or center their work in terms of the result and less so about the ideas (which at the moment, are not convincing to use outside of this specific setup).\n\nThe authors propose two contributions:\n\n1. They build on parallel WaveNet which uses distillation by minimizing a KL divergence from a Logistic IAF as a student to a Mixture of Logistic AF as a teacher. Instead, they simply use Gaussians which has a closed-form KL divergence and makes training during distillation significantly simpler. Because of stability problems, they also add 1. a penalty term to discourage the original loss from dividing by a standard deviation close to zero; and 2. converting van den Oord et al. (2018)\'s average power loss penalty to a frame-level loss penalty.\n\nTheir choice of Gaussians requires a restriction on the likelihood, and they show one result arguing the likelihood choice doesn\'t make much of a difference. This result comprises 4 human-evaluated numbers, with a fixed architecture and training hyperparameters of their choice. Unfortunately, I\'m not convinced. Can the authors provide more compelling evidence? If the authors argue this is one of their main contributions, I find that lack of a more comprehensive empirical or theoretical study disconcerting.\n\nSimilarly, while I like that using Gaussian KLs makes the distillation objective in closed-form, there isn\'t evidence indicating the benefit. The one result (the 4 numbers above) are conflated by both the change in model as well as utilizing the closed-form loss. The same goes for their one result (2 numbers) comparing forward to reverse KL.\n\n2. They ""propose the first text-to-wave neural architecture for TTS, which can be trained from scratch in an end-to-end\nmanner."" I\'m not an expert on speech so I can\'t accurately assess the novelty here. However, it would be nice to show these results independent of the other proposed changes.\n\nWriting-wise, the paper was clear, although potentially too packed with background information. As a expert on generative models, most of Sections 1-3 are already well-known and could be made more concise by referencing past works for more details. They add various details (such as the architecture notes at the end of 3.1) which should be better placed elsewhere to tease out what the important changes are in this paper.', 'This paper proposes some modifications to established procedures for neural speech synthesis and investigates their effect experimentally. The proposed modifications are mostly fairly straightforward conceptually, but appear to work well, and this reviewer feels the paper has huge value in its experimental contributions extending and clarifying certain aspects of WaveNet training and distillation. The paper is well-written and fairly concise, with a short-and-sweet experimental results section.\n\nMajor comments:\n\nThe conceptual novelty seems a little overstated in the abstract. For example, the value seems to not really be in the ""proposing"" a text-to-wave neural architecture for speech synthesis (which, aside from important experimental tweaks, is essentially Tacotron 2 training all parameters from scratch) but in showing that it works well experimentally. Conceptually the paper is extremely close to the parallel wavenet paper, the main differences being slightly different component distributions (Gaussian instead of logistic), a different set of loss terms in addition to the reverse KL, and joint training of the spectral synthesis and waveform synthesis parts of the model.\n\nIt would be super insightful to include log probabilities on the test set (everywhere MOS results have been reported) in the experimental results. This would help tease apart the effects of architecture inductive bias, different divergences, distillation, etc. One of the really nice things about flow-based models is the ability to compute the log probability tractably.\n\n\nMinor comments:\n\nPerhaps mention that teacher forcing is maximum likelihood in the introduction? Currently it almost sounds like the paper is contrasting teacher forcing for WaveNet (paragraph 2) and MLE (list item 1).\n\nAt the end of paragraph 3 in the introduction, it would be helpful to mention that the intractable KL divergence being referred to is the frame-level one-step-ahead predictions, not the entire sequence-level prediction. Also, for 1D distributions isn\'t taking a large number of samples quite effective in practice?\n\nIn introduction list item 3, suggest mentioning Tacotron 2 (Shen et al) and contrasting with the present work for clarity.\n\nIn section 3.1, it surprises me slightly that clipping at -7 is essential. It would be helpful to state what exactly goes wrong if this is not done. Does it lead to overfitting and so bad test log likelihoods? What effect is noticeable in the generated samples?\n\nEquation (6) is incorrect. It should be conditioned on < t, not <= t. Conditioning on z <= t would make x_t deterministic.\n\nEquation (7) is technically true as written, but only because all the distributions involved are deterministic. If <= t is replaced with < t (which based on the mistake in (6) is what I suspect the authors intended) then it is no longer true. This equation is not used anywhere as far as I can tell. It seems to me like the property that enables non-recursive-over-time (""parallel"") sampling is (5), not (7). Incidentally, when multiple one-step-ahead samples are taken per frame for parallel wavenet, the samples viewed at the sequence level are highly correlated, and do not obey anything like (7), but it doesn\'t affect the correctness of the expected value.\n\nThe IAF doesn\'t really ""infers its output x at all time steps"". Maybe ""models"" instead of ""infers""?\n\nLearning an ""IAF directly through maximum likelihood"" doesn\'t seem all that impractical. People train networks with recursive dependence such as RNNs (which is essentially what would be required to train certain forms of IAF with MLE) as opposed to non-recursive dependence such as CNNs all the time, after all. It seems like this claim depends on the details of the transform $f$.\n\nOut of interest, did the authors consider reversing the sequence being generated in time between successive IAF blocks? This would limit the ability to do low latency synthesis but might improve performance considerably.\n\nThe first paragraph in section 3.3 seems like it should probably be part of section 3.3.1 (it\'s not related to other losses such as spectrogram frame loss, for example). It would be helpful to state explicitly that: (a) the goal is to minimize the sequence-level reverse KL; (b) this can be approximated by taking a single sample z, but this may have high variance; (c) the variance of this estimate can be reduced by marginalizing over the one-step-ahead predictions for each frame; (d) parallel wavenet\'s mixture of logistics means it has to use a separate Monte Carlo sampling at the frame-level, whereas the proposed Gaussian allows this one-step-ahead marginalization to be performed analytically. This one-step-ahead marginalization is an example of Rao-Blackwellization.\n\nIt didn\'t seem clear from section 3.3 and 3.3.1 that parallel wavenet also uses the one-step-ahead marginalization trick to reduce the variance.\n\nIt might be helpful to mention that using the reverse KL would be expected to have mode-fitting behavior, making samples sound better but log probability on the test set worse.\n\nIt was not clear to me what difference or similarity was being demonstrated in Figure 1.\n\nSmall point, but ""Oord et al"" should be ""van Oord et al"" throughout (it\'s a surname).\n\nIn section 3.3.2, can the authors give any insight as to why training with reverse KL alone leads to whispering, and why adding the STFT term fixes this? (If it\'s only something that\'s been noticed empirically, ""will lead"" -> ""empirically we found""?)\n\nI noticed quite a large qualitative perceptual difference between the student and teacher samples, particularly in the speech synthesis case (experiment 3), even though I think I\'d rate the quality on a linear scale as fairly similar (in line with the MOS results). The teacher sounds noticeably ""harsher"" but ""clearer"" Do the authors have any insight as to why this perceptual difference occurs (if they also perceive a qualitative difference)? Is it probably a difference in inductive bias between an AF (which WaveNet can be seen as) and IAF?\n\nI found it fascinating that reverse KL and forward KL lead to roughly the same MOS for spectrum-to-waveform. I assumed reverse KL would be better due to its preference for high-quality samples due to mode fitting.\n\nOut of curiosity, what is responsible for the pops at the start of the spectrogram-conditioned distilled models? Also why are the synthesized samples shorter than the ground truth (less initial silence)?\n\n']","[50, -20, 80]","[80, 50, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's substantial and significant work, especially in text-to-speech systems, and praises its general writing quality. However, they also point out several areas for improvement, including the need for additional experiments and clarity in certain sections. The politeness score is 80 (quite polite) as the reviewer maintains a professional and respectful tone throughout, using phrases like 'I think' and 'I believe' to soften criticisms. They also balance negative feedback with positive comments, acknowledging the paper's strengths before discussing its weaknesses. The reviewer offers constructive suggestions for improvement rather than harsh criticisms, further contributing to the polite tone."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges liking the direction of the paper and raises their rating, they still express significant concerns about the lack of substantial contribution and comprehensive experiments. The reviewer suggests major improvements and is not fully convinced by the current results. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledges positive aspects, and provides constructive feedback. They use phrases like 'I very much like the direction' and 'It would be great if' which contribute to a polite tone. However, they also directly state their concerns without excessive softening, keeping the score from being extremely high."", ""The sentiment score is 80 (positive) because the reviewer expresses that the paper has 'huge value' and is 'well-written and fairly concise'. They state that the proposed modifications 'appear to work well' and praise the experimental contributions. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions. They use phrases like 'it would be helpful' and 'out of interest' when making recommendations, maintaining a collegial tone. The reviewer balances positive feedback with areas for improvement, and frames criticisms as suggestions rather than demands. However, it's not extremely polite, as the reviewer directly points out errors and areas where claims may be overstated.""]"
"['The goal of this paper is to use deep generative models for missing data imputation. This paper proposes learning a latent variable deep generative model over every randomly sampled subset of observed features. First, a masking variable is sampled from a chosen prior distribution. The mask determines which features are observed. Then, the likelihood of the observed features is maximized via a lower bound. Inference in this latent variable model is achieved through the use of an inference network which conditions on the set of ""missing"" (to the generative model) features.\n\nNovelty:\nGenerative models have a long history of being used to impute missing data. e.g. http://www.cs.toronto.edu/~fritz/absps/ranzato_cvpr2011.pdf, https://arxiv.org/pdf/1610.04167.pdf,\nhttps://arxiv.org/pdf/1808.01684.pdf, https://arxiv.org/pdf/1401.4082.pdf [Appendix F]\nIt is a little difficult to guage what the novelty of this work is.\n\nClarity\nThis is a poorly written paper. Distilling the proposed methodology down to one paragraph was challenging since the text meanders through several concepts whose relevance to the overarching goal is questionable. For example, it is not clear what Section 3.2 adds to the discussion. The text describes a heuristic used in learning GSNNs only to say that the loss function used by GSNNs is not used in the experimental section for this paper -- this renders most of 4.3.2 redundant. There are issues like awkward grammar, sloppy notation, and spelling mistakes (please run spell check!) throughout the manuscript. Please use a different notation when referring to the variational distributions (do not re-use ""p"").\n\nExperimental Results\nThe model is evaluated against MICE and MissForest on UCI datasets. RMSE and accuracy of classification (from imputed data is compared). The complexity of data considered is simplistic (and may not make use of the expressivity of the deep generative model). Why not run these experiments on datasets like MNIST and Omniglot?\nBeyond that:\n(a) was there any comparison to how classification performance behaves when using another neural network based imputation baseline (e.g. the method in Yoon et. al)?\n(b) the *kind* of missingness considered here appears to be MCAR (the easiest kind to tackle) -- did you consider experiments with other kinds of missingess?\n\nThe qualitative results presented in this work are interesting. The method does appear to produce more diverse in-paintings than the method from Yeh et. al (though the examples considered are not aligned).\n\nTable 5 claims negative log-likelihood numbers on MNIST as low as 61 and 41 (I assume nats...). These numbers do not make sense. How were they computed?\n\n\nPriors on b:\nWhat kind of priors on b did you experiment with? ', 'The paper presents a model for learning conditional distribution when arbitrary partitioning the input to observed and masked parts. The idea is to extend the conditional VAE framework such that the posterior is a function of an arbitrary subset of observed variables. Accordingly, reconstruction loss only penalizes the error in the reconstruction of masked (unobserved) variables. The method is compared against 1) classical approaches in missing data imputation on UCI benchmarks; 2) image inpainting against recently proposed GANS for the similar task, as well as; 3) against universal marginalizer, which learns conditional densities using a feedforward / autoregressive architecture.\n\nMy concern about the experimental results on missing data imputation is that strong competition such as Gondra et al’17 and Yoon et al’18 that report better results on UCI than classical approaches are not included. Could you please comment? See also [1,2] for other autoencoding architectures for this task.\n\nWhile the derivation of the method is principled, it assumes that either the mask is known during the training OR one could efficiently sample a distribution of masks to learn arbitrary conditional densities. Given the exponential number of valid masks in a general setting, one only subsamples a small portion during the training. The question is whether the model can generalize well in this regime? The experimental results in this setting is not very encouraging, suggesting the proposed approach is effective only when the limitted mask patterns are known in advance. \n\n[1] Gondara, Lovedeep, and Ke Wang. ""Multiple imputation using deep denoising autoencoders."" arXiv preprint arXiv:1705.02737 (2017).\n\n[2] Zhang, Hongbao, Pengtao Xie, and Eric Xing. ""Missing Value Imputation Based on Deep Generative Models."" arXiv preprint arXiv:1808.01684 (2018).\n', 'This paper introduces the VAEAC model, inspired by CVAEs, it allows conditioning on any subset\nof the latent features. This provides a model able to achieve good results on image inpainting\nand feature imputation tasks.\n\nThe paper appears to be technically sound, and the experiments are\nthoughtfully designed. The writing is clear and the model is easy to\nunderstand. The closest work to this of the Universal Marginalizer is\ncompared to well, with more compelling examples in the appendix. I\nwould have preferred if more of the experimental results were in the\nmain paper instead of in the appendix especially as the authors state\nthey chose to highlight their better results in the main paper.\n\nWhile not the first model to try to handle modeling data with missing features, it is\nstill a fairly original and elegant formulation.\n\nMinor details:\n\nIn equation (8) should x be x_b?\n']","[-50, -20, 70]","[-20, 60, 80]","[""The sentiment score is -50 because the review is generally critical, pointing out several issues with the paper such as lack of clarity, questionable novelty, and problematic experimental results. However, it's not entirely negative as it does acknowledge some interesting qualitative results. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the tone is quite blunt and critical, using phrases like 'poorly written paper' and 'sloppy notation'. The reviewer also questions the relevance and accuracy of certain sections, which comes across as somewhat harsh. However, the reviewer does provide specific recommendations and areas for improvement, which prevents the score from being lower."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's contributions, they express concerns about the experimental results and the method's generalizability. The reviewer points out missing comparisons with strong competitors and questions the effectiveness of the approach in certain scenarios. However, the tone is not entirely critical, as they recognize the principled derivation of the method. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, asks questions politely ('Could you please comment?'), and provides constructive feedback with references to support their points. The reviewer maintains a professional and courteous tone while raising their concerns."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'technically sound,' with 'thoughtfully designed' experiments, 'clear' writing, and an 'easy to understand' model. They also note it's a 'fairly original and elegant formulation.' The only mild criticism is about preferring more experimental results in the main paper. The politeness score is 80 (quite polite) due to the reviewer's constructive and respectful tone throughout. They use phrases like 'appears to be' and 'I would have preferred,' which are polite ways of offering feedback. The reviewer also balances critique with praise and offers specific, helpful suggestions, which is a polite approach to peer review.""]"
"['I really enjoyed this paper. It takes an idea which at first glance seems to be obviously bad (if you want permutation invariance, build a model that considers all permutations) and uses it to make the important point that the universal approximation results contained in Deep Sets [Zaheer et al. 2017] are not the last word on pooling. Janossy Pooling is intractable for most problems of interest (because it sums over all n! permutations of the input set) so the authors suggest 3 tractable alternatives: canonical orderings, k-ary dependencies and SGD / sampling-based approaches. Only the latter two are explored in detail, so I’ll focus on them:\n\nK-ary dependencies\nFunctions that are restricted to k-ary dependencies in Janossy Pooling require summing over only |h|! / (|h| - k)! terms - that is they sum over the permutations of subsets of h of length k. In the experimental section, the authors show that this recovers some of the performances lost by using sum / mean pooling (as in Deep Sets), but this suggests the natural question: is it the fact that you’re explicitly modelling higher-order interactions that improves performance? Or is it that you’re doing Janossy pooling over the higher order interactions (i.e. summing over permutations of non-invariant functions)? \n\nThese two effects could be separated by comparing to invariant models that allow higher order interactions. E.g. you could compare against Santoro et al. [2017] who explicitly model pairwise interactions (or similarly any of the graph convolutional models [Kipf and Welling 2016, Hamilton et al 2017, etc.] with a fully connected graph would do the same); similarly Hartford, et al. [2018] allow for k-wise interactions by extending Deep Sets to exchangeable tensors - the permutation invariant analog of k-ary Janossy Pooling. All of these approaches model k-wise interactions through sum-pooling over permutation invariant functions so this lets you address the question - is it the permutation invariance that’s the problem (necessitating k-ary Janossy pooling) or is it the lack of higher-order interaction terms? \n\nSGD approaches:\nI think that the point that the sampling-based approaches are bias with respect to the Janossy sum is important to make and I liked the discussion around it, but I don’t follow the relevance of Proposition 2.2? I see that it gives conditions under which we can expect \\pi-SGD to converge, but we aren’t provided with any guidance about how likely those conditions are to be satisfied? Furthermore - these conditions don’t seem to be specific to \\pi-SGD - any SGD algorithm with “slightly biased” gradients that satisfy these conditions would converge. The regularization idea is interesting, but it isn’t evaluated so we’re left with theory that doesn’t provide guidance and isn’t evaluated.\n\nSummary:\nThere are two ways to read this paper:\n 1. Janossy pooling as a framework & proposed pooling approach implemented in one of the two ways discussed above.\n 2. Janossy pooling as an intractable upper bound on what we might want from a pooling method (with approximations in the form of the LSTM approaches) and a demonstration that our current invariant pooling methods are insufficient.\n\nI liked the paper based on reading (2). Janossy pooling clearly demonstrates limitations to sum / mean pooling which is widely used in practice which shows the need for better alternatives and it is on this basis that I’m arguing for it’s acceptance. My view is that the experimental section is too limited to support reading (1) which asserts that k-ary pooling or LSTM + sampling approaches are the right solution to this problem. \n\n[Zaheer et al. 2017] - Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan Salakhutdinov, and\nAlexander Smola. Deep Sets\n[Santoro et al. 2017] - Adam Santoro, David Raposo, David G Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, and Tim Lillicrap. A simple neural network module for relational reasoning.\n[Kipf and Welling 2016] - Thomas N. Kipf and Max Welling. Semi-Supervised Classification with Graph Convolutional Net- works\n[Hamilton et al 2017] - William L. Hamilton, Rex Ying, and Jure Leskovec. Inductive Representation Learning on Large Graphs\n[Hartford, et al. 2018] - Jason S. Hartford, Devon R. Graham, Kevin Leyton-Brown, and Siamak Ravanbakhsh. Deep models of interactions across sets', ""In this paper, the authors presented a new pooling method called Janossy Pooling (JP), which is designed to better capture high-order information by addressing two limitations of existing works - fixed pooling function and fixed-size inputs. The studied problem is important and the motivation is clear, where the inputs are sets of objects such as values or vectors and how we can learn a good aggregation function to maximally preserve the information in the original sequence. The authors attacked this problem by firstly formally formulating this problem and introducing a general approach as well as a few of approximation methods to realize it in practice. They also discussed the connections of this work and some existing works such as deep set, which I found is quite useful. \n\nIn general, JP was proposed to learn permutation-invariant function for aggregating the information of the input sequence. The basic idea of JP is to simply take all generated order of sequences from the original sequence input, which however I found is not new since it has been conceptually discussed already in the literature.  Since this approach is computationally prohibitive, there are several ways of approximations to approach the solution. As the authors are aware of the existing works in the literature, these approaches were discussed before either in the same context or in some particular learning tasks. From this perspective, the proposed solutions are not novel either. \n\nThe experimental results are particularly weak. It is little interesting on the first toy problem and the results on graph embedding are not promising. In Table 2, it is clearly shown that the LSTM aggregation functions on the randomly sampled sequences are really beating the simple mean aggregation function. I think the authors need much more experiments to demonstrate why we need LSTM based pooling for realizing JP in terms of both the final accuracy and computational cost. \n\n-------------------------------------------------\nAfter reading the authors' rebuttals, they have addressed part of my concerns but I still think the current form is not below the acceptance threshold due to its weak experimental results and unclear technical details. \n\n"", 'I have found the ideas proposed in the paper very insightful and interesting. The paper, in general, is written very well and is accessible.  My most important concern is \n\n The whole development seems not as effective as k =1 in Table.2 (BTW, there is a typo there). One wonders, why for k =2, k =1 is not included? That is, can the formulation be changed in a way that \\downarrow operator represents l \\in {1 \\cdots k} projections?  In the end, the method creates k tuples and feed them through specific fs so why not having smaller tuples?\n\nThe rest of my review below hopefully can help improving the paper;\n\n\n- Is there any reason as to why higher order Janossy poolings do not perform as good as k =1 for the sum experiment? \n\n- Can you report the number of parameters for the developments (Janossy -k)? Some examples according to the experiments help.\n\n- I am a bit lost to grasp the paragraph below Eq.4, can you rephrase it and possibly provide references?\n\n- When it comes to testing, how do you use Eq.13? Do you sample a few permutation and compute 13? If yes, how many in practice? \n\n- In preposition 2.1,  n seems confusing, why not |h|\n\n- In P6, x_i is a sequence. this needs to be mentioned \n\n']","[70, -50, 50]","[80, 20, 80]","[""The sentiment score is 70 (positive) because the reviewer starts by saying they 'really enjoyed this paper' and praises its important contributions. They recommend acceptance and highlight the paper's strengths. However, they also raise some concerns and suggest improvements, which prevents a perfect score. The politeness score is 80 (quite polite) due to the reviewer's consistently respectful and constructive tone. They use phrases like 'I liked the paper' and frame criticisms as suggestions or questions rather than direct attacks. The reviewer maintains a professional and courteous demeanor throughout, even when pointing out limitations."", ""The sentiment score is -50 because the review is generally critical, pointing out several weaknesses in the paper. The reviewer states that the basic idea is 'not new', the proposed solutions are 'not novel', and the experimental results are 'particularly weak' and 'not promising'. However, the reviewer does acknowledge some positive aspects, such as the clear motivation and useful discussion of connections to existing work, which prevents the score from being even lower. The politeness score is 20 because while the reviewer is critical, they express their concerns in a professional and constructive manner. They use phrases like 'I found' and 'I think' to soften their criticisms, and they acknowledge the authors' efforts in addressing some concerns in the rebuttal. The language is not overtly polite, but it maintains a respectful tone throughout, avoiding harsh or rude expressions."", ""The sentiment score is 50 (moderately positive) because the reviewer starts by praising the paper as 'very insightful and interesting' and 'written very well'. However, they also express 'important concern' about the effectiveness of the method, which tempers the positivity. The politeness score is 80 (quite polite) due to the respectful tone throughout. The reviewer uses phrases like 'hopefully can help improving the paper' and frames criticisms as questions or suggestions rather than direct criticisms. They also acknowledge the paper's strengths before diving into concerns. The review maintains a professional and constructive tone throughout, avoiding harsh language or personal attacks.""]"
"['This paper considers learning informative priors for convolutional neural network models based on fits to data sets from similar problem domains.  For trained networks on related datasets the authors use autoencoders to obtain an expressive prior on the filter weights, with independence assumed between different layers.  The resulting prior is generative and its density has no closed form expression, and a novel variational method for dealing with this is described.  Some empirical comparisons of the deep weight prior with alternative priors is considered, as well as a comparison of deep weight samples for initialization with alternative initialization schemes.  \n\nThis is an interesting paper.  It is mostly clearly written, but there is a lack of detail in Section 4 that makes it hard for me, at least, to understand exactly what was done there.  I think the originality level of the paper is high.  The issue of informative priors in these complex models seems wide open and the authors provide an interesting approach both conceptually and computationally.  I did wonder whether there was any link between the suggested priors and the idea of modelling the current and related data sets used in constructing the prior jointly, with data set specific parameters given an exchangeable prior?  This would be a standard hierarchical modelling approach.  Such an approach would not be computationally attractive, I just wondered if there is some conceptual link with the current method being an approximation of that approach in some sense.  In Section 4.1, it seems that for the trained networks on the source datasets, point estimates of the filter weights are treated as data for learning the variational autoencoder - is that correct?  Could you model dataset heterogeneity here as well?  Presumably the p_l(z) density is N(0,I)?  Details of the inference and reconstruction networks are sketchy.  In Section 4.2, you say that the number of filters is proportional to the scale parameter k and that you vary k.  What scale parameter do you mean?  \n\n\n', 'Summary:\n\nThis paper proposes the ‘deep weight prior’: the idea is to elicit a prior on an auxiliary dataset and then use that prior over the CNN filters to jump start inference for a data set of interest.  Both explicit and implicit priors are considered, with the latter having the benefit of increased flexibility but having the drawback of a lack of a parametric form to plug in to the ELBO.  The authors address this last point by extending the ELBO appropriately.  Experiments are performed testing the prior’s ability to capture trained filters (Figure 1), provide a good initialization (Figure 2), improve sample efficiency (Figure 3), improve training speed (Figure 4).  \n\nPros:\n\nI like this paper: it is a intuitive idea, and the experiments explore exactly what one would hope to gain from the prior (i.e. better initialization, improved sample efficiency).  I find the paper clearly written and to have a logical flow.  Furthermore, I think eliciting priors---while so crucial in more traditional Bayesian modeling---has been mostly overlooked by the Bayesian ML community, and this paper clearly shows that there are gains to be had from a fairly straightforward procedure.  \n\n\nCons:\n\nThe only potential issue with the paper is the use of the implicit prior, as it complicates variational inference, requiring the extension to the ELBO described in Section 3.2.  As far as I can tell, all experiments use the implicit priors.  I would have liked to have seen an experiment using a parametric prior (eg Gaussian) that shows what gains the implicit prior provides.  Or is it simply a matter of memory efficiency?  \n\n\nOther comments:\n\n-- Nice first sentence in the introduction!  I like how it’s a general statement but immediately focuses the reader’s attention to the paper’s topic.\n\n-- While it doesn’t say so explicitly, the paper seems to imply it is the first to use implicit priors.  Some previous work that uses some form of implicit prior includes:\n\nRuns a chain to refine the prior: Alex Lamb et al. ""GibbsNet: Iterative Adversarial Inference for Deep Graphical Models."" Advances in Neural Information Processing Systems. 2017.\n\nOptimizes a NN implicit prior based on an invariance objective: Eric Nalisnick and Padhraic Smyth. ""Learning priors for invariance."" International Conference on Artificial Intelligence and Statistics. 2018.\n\nDefines implicit priors over functions through samplers: Chao Ma, Yingzhen Li, and José Miguel Hernández-Lobato. ""Variational Implicit Processes."" arXiv preprint arXiv:1806.02390 (2018).\n\n\nEvaluation:  I recommend this paper for acceptance.  It is a sensible idea with pointed experimental validation.\n', 'This paper considers modeling convolutional neural network by a Bayes method. The prior for the weights is considered in which the weights from various layers, input and output channels are assumed to be independent.  A varational method is considered to approximate the posterior distribution of the weights of CNN.  It looks to me that the prior distribution is a fairly standard product which may not perfectly suitable for CNN. Also the validity of the proposed variational method needs further evaluation. Below I summarize my concerns more technically.\n\n1. CNN essentially has a tree structure, i.e., each layer can be viewed as the parent of the next layer. So the consecutive layers should have a sort of dependence. Also, the weights based on the same input channel should all inherit features of that channel. Based on these considerations, is it really reasonable to assume that the random weights are independent?\nI agree that independence assumption makes the model and computation easier, but the prior itself should reflect the possible dependence structure of the channels.\n\n2. The KL divergence might not be tractable and so the proposed variational method replaces it with an upper bound. This method highly depends on the assumption that the upper bound of the KL divergence is accurate. Otherwise it is hard to tell that the method really approximates the authentic variational method very well. It would be great if the accuracy of the upper bound can be further evaluated (theoretically and numerically).\n\n\n\n\n\n']","[60, 80, -20]","[80, 90, 60]","[""The sentiment score is 60 (positive) because the reviewer describes the paper as 'interesting' and praises its originality and approach. They mention that it's 'mostly clearly written' and provides 'an interesting approach both conceptually and computationally'. However, they also point out some lack of detail and raise questions, which prevents a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms constructively (e.g., 'I think the originality level of the paper is high'), and asks questions in a courteous manner (e.g., 'Could you model dataset heterogeneity here as well?'). The reviewer maintains a professional and considerate tone while providing both positive feedback and areas for improvement."", ""The sentiment score is 80 (positive) because the reviewer expresses a clear liking for the paper, praising it as intuitive, clearly written, and logically structured. They highlight several pros and recommend the paper for acceptance. The only con mentioned is relatively minor and presented as a suggestion for improvement rather than a major flaw. The politeness score is 90 (very polite) due to the reviewer's consistently respectful and constructive tone. They use phrases like 'I like this paper' and 'Nice first sentence', and even when suggesting improvements, they do so in a gentle manner. The reviewer also acknowledges the paper's contributions to the field and provides helpful additional references, demonstrating a collegial and supportive approach."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's approach, they express several concerns and suggest that further evaluation is needed. The review points out potential issues with the model's assumptions and the accuracy of the proposed method, indicating a somewhat critical stance. However, the tone is not entirely negative, as the reviewer offers constructive feedback and suggestions for improvement. The politeness score is moderately positive (60) because the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions (e.g., 'is it really reasonable...?'), and uses phrases like 'It would be great if...' to soften recommendations. The reviewer also acknowledges the benefits of the authors' approach (e.g., 'I agree that independence assumption makes the model and computation easier') before offering critiques, which contributes to a polite tone.""]"
"['This paper studies the problem of *learning* online combinatorial algorithms via Reinforcement Learning. In particular, the paper studies three different well-studied problems, namely AdWords/Online Matching, Online Knapsack, and Secretary Problem. The common thread to all three problems is that they are special cases of Online Packing problem and that there exist optimal algorithms with theoretical guarantees. Moreover, all these problems have an algorithm based on the unifying Primal-Dual framework (*). The paper runs extensive experiments and shows that the learned RL policies resemble the algorithms created in theory by comparing many properties of the returned policy. Overall I think this paper tackles a very interesting question, is well-written and has extensive experiments. \n\nI will detail my technical comments and questions to authors. I would especially appreciate detailed answers to (1), (2), (3). (4) and (5) are more open-ended questions and/or beyond the scope of the current paper. It can be viewed as feedback for some future work.\n\n(1) (*) The paper starts with the claim that one of the key insights to this work is the primal-dual framework. Yet this has not been exploited in the paper; at least I can\'t see where it is used! Can the authors give more details? For example, one way I could see this being used is as follows. In the AdWords problem, the evolution of the Dual variable is well understood (See [Devanur, Kleinberg, Jain \'13]). One can experiment to see how the dual values change over the run of the algorithm for the learned policy and compare that with how it changes in the analysis. If they are similar, then that is yet another evidence that the two algorithms are similar.\n\n(2) One key point to note is that all three algorithms include only the ""primal"" observations in the state. This strengthens this work since all these algorithms, in theory, are analyzed by realizing that the primal algorithm can be interpreted as an appropriate process on the evolution of the dual variables.  Thus it seems like the RL policy is actually learning the optimal way to set the dual variables in the online phase. Is this true? I guess the experiments above can indeed verify this. If this is true, it implies that the key message of this paper is that RL algorithms can be used to learn algorithms that can be analyzed via the primal-dual framework. Right now, the authors stop short of this by saying this work is inspired from it. It would be good to see this taken to completion.\n\n(3) It seems like there has been some work on using RL to learn algorithms in combinatorial optimization (see [Dai et al., NIPS 2017]). Can the authors discuss both in the rebuttal and in the paper on how their work compares and differs from this work? \n\n(4) I wonder if the authors experimented with the i.i.d. arrival process for Knapsacks and/or Online Matching/Adwords. It is known that the theoretical algorithms for both these problems do much better than the pessimistic adversarial arrival order. It will be interesting to see if the RL policies also find this. On a related note, did the authors try this on b-matching with b=1? The problem tends to get easier as b is large and/or when bid/budget ratio is small in Adwords. However even when b=1, in theory, we can get 1-1/e [KVV \'90].\n\n(5) Finally, I am curious if the authors tested this on problems that are not packing but covering and/or mixed packing and covering problems. Online Set Cover is a candidate example. The other direction is also to test Online Minimization problems. Note that Online Min-cost matching is significantly harder than Online maximum weight matching. Moreover, Online Min-cost matching does not have a primal-dual analysis (to the best of my knowledge). The latter helps because if the RL policy fails to learn the best-known algorithm, then it is further evidence that it is indeed learning through the primal-dual framework.\n\nSome minor comments:\n\nStyling is not consistent throughout the paper. For example, there are places with the header followed by a colon sometimes, a period other times and sometimes no punctuation. Please make these consistent throughout the paper.\n\nThe fonts on the figures are very small to read. It would be easy on the reader if the sizes were made larger.\n\n\n', 'The overall goal of this paper is to solve online combinatorial optimization (OCO) problems using reinforcement learning. Importantly, the authors are not seeking to establish new results for unsolved problems, but instead they are motivated by analyzing and comparing the quality of solutions predicted by reinforcement learners with respect to the well-known near-optimal strategies for some OCO tasks. In doing so, the authors focused on an MDP framework using policy gradient and DQN methods. This framework was trained on three OCO tasks; online budget allocation, online knapsack, and the secretary problem. For each, the trained model is consistent with the near-optimal “handcrafted’’ algorithms.\n\nThe idea of checking whether a standard RL framework, without prior information about “how to” solve a given OCO task, is capable from experience to reach the performance of existing optimal strategies (especially primal-dual approaches), is clearly interesting. But I am not entirely convinced that the paper is making novel contributions in this direction. My comments are detailed below:\n\n(1) OCO problems have been a subject of extensive research in online learning (see e.g. [1,2,3]). Notably, the main issues related to “input length independence” (Sec 1.1) and “adversarially chosen input distributions” (Sec 1.2) have already been addressed in online learning frameworks. Input length independence is related to “horizon-independence” in online learning (the number $T$ of trials is not known in advance), and well-known approaches have been developed for devising horizon-independent forecasters, or transforming a horizon-dependent forecaster into a horizon-independent one (see e.g. [4]). Also, the study of online learners with respect to different properties of input sequences (stochastic, adversarial, or hybrid), is a well-known topic of research which have been conceptualized and formalized with appropriate metrics (see e.g. [5,6]). \n\n(2) Although the authors are interested in making connection between RL and “primal-dual approaches” in online learning, this connection was not made clear in the paper. Namely, the overall contribution was to show that deep RL architectures can compete with existing, handcrafted online strategies, on three specific tasks. But in order to make a concrete connection with primal-dual approaches, this study should be extended to more general primal (covering) and dual (packing) problems as described in [7], and the RL framework should be compared with “generic” online primal-dual algorithms also described in [7]. We may note in passing that the offline versions of the three tasks examined in the present paper belong to the approximation classes PTAS or APX. By contrast, the complexity class of general covering/packing problems is much higher (a constant approximation ratio is not achievable unless P=NP) and, to this point, it would be interesting to examine whether a standard deep RL framework can compete with existing online strategies (for example in [7,8]) on such hard problems.\n\n(3) Even if we stick to the three problems examined in the paper, the neural nets vary between tasks, with different numbers of layers, different widths, different batch sizes, etc. On the one hand, it is legitimate to seek for an appropriate learning architecture for the input problem. On the other hand, such adjustments are conveying some prior knowledge about “how to” solve this problem using a deep RL model. Moreover, for knapsack and secretary tasks, additional knowledge about the history (i.e. state augmentation) is required for establishing convergence, but the resulting model is no longer a standard MDP. So, unless I missed the point about the overall goal of this paper, these different aspects are somewhat in contradiction with the idea of starting with a deep RL architecture with default settings, in which the varying components are essentially the states, transitions, and rewards of the MDP that encodes the problem description. \n\n[1] Bubeck, S., Introduction to Online Optimization. Lecture Notes, Princeton University, 2011.\n\n[2] Audibert, J-Y., Bubeck, S., and Lugosi, G. Minimax policies for combinatorial prediction games. In COLT, 2011.\n\n[3] Rajkumar, A. and Agarwal, S. Online decision-making in general combinatorial spaces. In NIPS, 2014.\n\n[4] N. Cesa-Bianchi and G. Lugosi. Prediction, Learning, and Games. Cambridge University Press, 2006.\n\n[5] A. Rakhlin, K. Sridharan, and A. Tewari. Online learning: Stochastic, constrained, and smoothed adversaries. In NIPS, 2011.\n\n[6] N. Buchbinder, S. Chen, J. Naor, O. Shamir: Unified Algorithms for Online Learning and Competitive Analysis. In COLT, 2012.\n\n[7] N. Buchbinder and J. Naor. The Design of Competitive Online Algorithms via a Primal-Dual Approach. Foundations and Trends in Theoretical Computer Science, 2009.\n\n[8] S. Arora, E. Hazan, and S. Kale. The Multiplicative Weights Update Method: a Meta-Algorithm and Applications, Theory of Computing, 2012.\n\n', ""This paper introduces a new framework to solve online combinatorial problems using reinforcement learning. The idea is to encode the current input, the global parameters, and a succinct data structure (to represent current states of the online problem) as MDP states. Such a problem can then be solved by deep RL methods. To train such models, the authors use a mixture of input distributions. Some come from hard distributions which are used to prove lower bounds in the TCS community, and the others are carefully constructed distributions to fool a specific set of algorithms. The authors made an important point that their algorithms are uniform in the TCS sense, i.e., the algorithm does not depend on the input length.\nFurthermore, the authors show that the learned algorithms have similar behavior as those classical optimal algorithms that are first obtained in the online combinatorial optimization community. \n\nThe idea of using hard distributions to train the model is reasonable, but not extremely interesting/exciting to me since this is by now a standard idea in TCS. Moreover, in many cases (especially those problems that don't have a lower bound), it is even very hard to construct a hard distribution. In general, how should we use construct the input distribution in those cases? Can the proposed methods still generalize if we don't have an appropriate hard distribution? I would like to see some discussion/experiments along this line. \n\nMoreover, it is unclear to me whether the methods proposed here can really learn *uniform* algorithms for the ADWORDS problem. To make the state length independent of the number of advertisers (n), the authors discretized the state space (see Appendix B). This approach might work for small (constant) n. But as we increase n to infinity, it seems to me that due to precision issues this approach will fail. If this is true, then in order to make this algorithm work, we also need to increase the precision of the real numbers used to describe the state as we increase n. If it is the case, why is the algorithm still uniform? If it is not the case, the authors need to provide extra experimental results to show that the effectiveness of the learned algorithm keeps unchanged, even if we keep increasing n and do not change the representation of the states.\n\nIt is an interesting observation that deep RL methods can actually learn an algorithm with similar behavior as optimal classical combinatorial optimization algorithms. However, there is no explanation for this, which is a little bit frustrating. Would this phenomenon be explained by the use of hard distributions? The paper can be strengthened by providing more discussions along this line. \n\nMinor comments:\n\nThe caption of Table 2 seems to contradict its explanation (on top of page 14). Is the state space discretized or the number of advertisers changed?""]","[80, -30, -20]","[70, 60, 60]","[""The sentiment score is 80 (positive) because the reviewer expresses a very positive overall impression in the first paragraph, stating that the paper tackles 'a very interesting question, is well-written and has extensive experiments.' The reviewer also mentions that the paper is 'well-written' and shows appreciation for the extensive experiments. The politeness score is 70 (polite) because the reviewer uses respectful language throughout, phrases criticisms constructively, and expresses appreciation for potential responses ('I would especially appreciate detailed answers...'). The reviewer also offers suggestions for improvement in a collegial manner, using phrases like 'It would be good to see...' and 'I wonder if...'. The tone is professional and courteous throughout, without any harsh or rude language."", ""The sentiment score is -30 because while the reviewer acknowledges the interesting idea of the paper, they express significant doubts about its novelty and contributions. The reviewer points out several limitations and areas where the paper falls short, indicating a generally negative sentiment. However, it's not extremely negative as they do recognize some merit in the approach.\n\nThe politeness score is 60 because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I am not entirely convinced' and 'unless I missed the point' which soften their criticisms. The reviewer also provides detailed explanations and references to support their points, showing a constructive approach rather than harsh criticism. However, it's not extremely polite as it does contain direct criticisms and doesn't use overly deferential language."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects of the paper (e.g., 'interesting observation'), they express several concerns and criticisms. The reviewer finds the main idea 'not extremely interesting/exciting' and raises questions about the method's effectiveness and uniformity. They also express frustration about the lack of explanation for certain phenomena.\n\nThe politeness score is moderately positive (60) because the reviewer maintains a professional and respectful tone throughout. They use phrases like 'I would like to see' and 'It is an interesting observation' which soften their criticisms. The reviewer also provides constructive feedback and suggestions for improvement, rather than outright dismissal of the work. However, the score is not higher because there are some direct criticisms and the overall tone, while polite, is not overly warm or enthusiastic.""]"
"['DOM-Q-NET:\u2028GROUNDED RL ON STRUCTURED LANGUAGE \n\nThis paper presents a somewhat novel graph-based Q-learning method for web navigation benchmark tasks. The authors show that multi-task learning helps in this case and their method is able to learn without BC as previous works have needed. While this work is interesting and to my knowledge somewhat novel. I concerns with one aspect of the evaluation. In some part it was stated that they show the highest success rate for testing on 100 episodes, if this is indeed the maximum success rate, it is unclear if these results are misleading or not. It is possible that there was a lucky seed in those 100 episodes leading to a higher max that is not representative of the algorithm performance. Also, please have the submission proof-read for English style and grammar issues. There are many minor mistakes, some of which are pointed out below. I am rating marginally below due mainly to the potentially misleading results from the comment on using the highest success rate to report results and to a minor extent due to the novelty aspect (though this is an interesting application).\n\n\nComments:\n\n- “Evaluation metric: we plot the moving average of the reward for last 100 episodes, and report the highest success rate for testing on 100 episodes.” —> This is unclear, do you mean you only displayed the maximum success rate out of all 100 episodes? So if the success rates are [0, 100, 0, 0, 0], Figure 2 shows 100% success? If so, this is somewhat misleading and a better metric may have been the average success rate with confidence intervals. Otherwise you may have just gotten a lucky random seed potentially.\n- I would’ve liked to see if this is the only method which benefits from multitask learning or do DOMNETs also benefit. This however, is just a nice to have.\n- I appreciate the inclusion of hyper parameters and commitment to releasing the code in an effort to promote reproducibility! Great job there. \n- I really like the idea of using graph networks with RL, though I’m not sure if it’s novel to this work. Interesting line of work!\n- While this is an interesting application, I’m not sure about the novelty. I suggest spending a bit more time discussing how this work contrasts with methods like Wang et al., or others cited here.\n\nTypos:\n\n“MiniWoB(Shi et al., 2017) benchmark tasks. “ —> missing space between citation\n“Q network architecture with graph neural network” —> with a graph neural network\n""MiniWoB(Shi et al., 2017)” —> MiniWoB (Shi et al., 2017) (missing space)\n“achieved the state” —> achieved state of the art \n“2016; Wang et al., 2018)as main” —> missing space\n“series of attentions between DOM elements and goal” —> series of attention (modules?) between the DOM elements and the goal (?)\n“constrained action set” —> constrained action sets\n“In appendix, we define our criteria for difficulties of different tasks.” —> In the appendix', 'The authors propose a novel architecture for RL-based web navigation to address both of these problems, DOM-Q-NET, which utilizes a graph neural network to represent tree-structured HTML along with a shared state space across multiple tasks. It is believed more flexible to be probed on WorldOfBits environments. Significant improvements are shown by experiment.', 'Caveat: I am an emergency reviewer filling in for someone that fell through on their commitment to review for ICLR.  The framing of this paper is quite outside my typical area, so I am not super familiar with the related work here, nor do I have time to get familiar with it for this last-minute review.                                                                                                                                                                             \n                                                                                                     \nThis paper presents a new model for deep reinforcement learning on web pages, where the system is given a goal (stated in text) and is supposed to interact with the web page (through clicking and entering text) in order to achieve that goal.  The supervision is a positive reward when the sequence of actions taken matches the goal.  The novel model presented in this paper is a modular Q function that incorporates graph embeddings of the web page\'s DOM, as well as similarity scores between elements in the DOM with words in the goal.\n                                                                                                     \nJust judging the presentation of the paper, it looks sound.  The methods seem reasonable (very similar to methods that are known to work well on related problems; more on that below), and the experiments look to be well done.  The paper is reasonably well written.  I don\'t know the RL community well enough to know how impactful this particular piece of work would be there - it\'s a new model architecture, basically, that gives improved performance.  I\'d probably give a similar paper in my area a 3.5-4 out of 5 for an ACL conference.  The one major drawback I see in this paper is that it is _so_ similar to work on semantic parsing, but doesn\'t realize it.\n                                                                                                     \nI am not a ""reinforcement learning"" researcher, though I am a ""semantic parsing"" researcher.  The problem statement in this paper reads to me exactly like a semantic parsing problem: map a piece of text to a statement in some formal language.  In this case, the ""statement"" is a sequence of actions on the DOM of a web page.  The web page is possibly unseen at test time (the particulars of the data setup weren\'t totally clear to me), so the model has to be able to handle linking words in the sentence to pieces of the DOM in a way that doesn\'t rely on having seen those DOM elements during training.  This setup seems almost identical to the WikiTableQuestions dataset (Pasupat and Liang 2015), which has seen several RL-inspired works recently (e.g., https://arxiv.org/abs/1807.02322).  The way that the authors propose to use attention scores in the ""global module"" is _very_ similar to the linking mechanism proposed by Krishnamurthy, Dasigi and Gardner (EMNLP 2017) for WikiTableQuestions, and the way that the ""word-token selection"" only allows words in the goal sentence is very reminiscent of Chen Liang\'s language for parsing questions in WikiTableQuestions, which has similar restrictions for similar reasons.\n                                                                                                     \nI think the main difference between what we call ""weakly-supervised semantic parsing"" and what you call ""deep reinforcement learning"" is that semantic parsing leverages the fact that we know the language we\'re parsing into, so we don\'t need to use model-free RL methods like Q-learning.  We know the model, so we can be much smarter about learning.  Again, I\'m not super familiar with the tasks you\'re looking at here, but I\'m pretty sure there are much better _supervised_ learning techniques that you could apply to these problems.\n                                                                                                     \nAll of this is to say that the methods proposed here look _very_ similar to methods that have been studied for quite a while in the semantic parsing literature (I gave only recent references above, but the basic problems go back decades; e.g., http://aclweb.org/anthology/P09-1010, or http://www.cs.utexas.edu/~ml/papers/senior-aaai-2008.pdf).  Yet this paper only cites recent deep RL papers.  I think the authors would benefit greatly from familiarizing themselves with this literature.  I think the semantic parsing community would also benefit from this, as there are surely ideas in the deep RL community that we could benefit from, too.  But the two communities don\'t really talk to each other much, it seems, even though in some cases we are working on _very_ similar problems.\n                                                                                                     \nSo, to summarize: the paper seems reasonable enough.  I\'m guessing that the RL community would find it at least moderately interesting, and it appears well written and well executed.  My one concern is that it\'s totally oblivious to the fact that it\'s sitting right next to a well-established literature that could probably teach it a thing or two about mapping language to actions.\n\n\n--------------\n\nAfter seeing the authors engage at least a little with the related semantic parsing literature, I\'ve increased my score to a 7.']","[-20, 80, 20]","[50, 50, 60]","[""The sentiment score is slightly negative (-20) because while the reviewer finds the work interesting and acknowledges some positive aspects, they express concerns about potentially misleading results and rate the paper 'marginally below' due to these issues and limited novelty. The politeness score is moderately positive (50) as the reviewer uses respectful language, offers constructive feedback, and includes positive comments like 'Great job there' and 'I really like the idea'. However, they maintain a professional tone without being overly effusive. The reasoning is based on the overall tone, specific phrases used, and the balance of positive and negative comments throughout the review."", ""The sentiment score is 80 (positive) because the review highlights the novelty of the proposed architecture, its flexibility, and significant improvements shown by experiments. The language used is generally positive, emphasizing the benefits and advancements of the proposed method. The politeness score is 50 (slightly polite) because while the review is professional and respectful, it doesn't contain explicitly polite language. The tone is neutral and factual, focusing on the merits of the work without personal comments or excessive praise, which is typical for scientific reviews."", ""The sentiment score is slightly positive (20) because while the reviewer finds the paper 'sound' and 'reasonably well written', they express concerns about its lack of engagement with relevant literature. The initial skepticism due to unfamiliarity with the field is balanced by acknowledging the paper's merits. The increase in score at the end indicates a more positive view. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledges their own limitations, and offers constructive criticism. They provide detailed explanations and suggestions rather than harsh criticisms. The caveat at the beginning and phrases like 'I think' and 'I'm guessing' further soften the tone.""]"
"['This paper proposes a well-designed instance level unsupervised image-to-image translation method which can handle the arbitrary number of instances in a permutation-invariant way. The idea is interesting and the results on various translation datasets are reasonable.  \n\nPros:\n* The proposed method process each instance separately to handle multiple instances. The summarization operation is a simple but effective way to achieve the permutation-invariant property. The context preserving loss is suitable for preserving the background information.\n* The paper is well written and easy to follow.\n\nCons:\n* My main concern is about the comparisons with CycleGAN in Figure 4 to 6. Although the CycleGAN+Seg results are shown in Figure 9 indicating that the proposed method can handle multiple instances better. I think there should also be CycleGAN+Seg results in Figure 4 to 6, since the instance segmentation is an extra information. And in my opinion, the CycleGAN+Seg can handle the situation where there are only a few instances (also can be observed in the 1st row in Figure 9). Besides, CycleGAN+Seg can naturally handle the arbitrary number of instances without extra computation cost.\n\nQuestions:\n*  I wonder what will happen if the network does not permutation-invariant. Except that the results will vary for different the input order, will the generated quality decrease? Since the order information may be useful for some applications.\n\nOverall, I think the proposed method is interesting but the comparison should be fairer in Figure 4 to 6. \n', 'Post rebuttal: I am satisfied by the points mentioned by authors!\n\n----------------------------------------------------------------\nSummary: The paper proposes to add instance-aware segmentation masks for the problem of unpaired image-to-image translation. A new formulation is proposed to incorporate instance masks with an input image to generate a new target image and corresponding mask. The authors demonstrate it on multiple tasks, and show nice results for each of them.\n\nPros: \n\n1. The formulation is intuitive and well done!\n\n2. The idea of sequential mini-batch translation connects nicely to the old school of making images by layering. \n\n3. Nice qualitative analysis, and good results in comparison with Cycle-GAN (an obvious baseline for the formulation). I would make an observation that two domains for translation (such as sheep to giraffe, jeans to skirts etc) are thoughtfully selected because Cycle-GAN is somewhat bound to fail on them. There is no way Cycle-GAN can work for jeans to skirts because by design the distribution for images from both set would be mostly similar, and it is way too hard for the discriminator to distinguish between two. This ultimately leads the generator to act as an identity mapping (easily observed in all the qualitative examples).\n\n4. The proposed approach can easily find direct application in places where a user-control is required for image editing or synthesis.\n\n5. The literature review is extensive.\n\nCons: \n\n1. My biggest criticism of this work is the absence of simple baselines.  Given the fact that the formulation use an instance segmentation map with the given input, the following obvious baseline need consideration: \n\nSuppose the two domains are sheep and giraffe: \n\na. given the input of sheep and its instance mask, find a shape/mask in giraffe from the training images that is closest (it could be same location in image or some other similarity measure).\n\nb. mask the input image using the sheep mask. Use giraffe mask and add corresponding RGB components of the masked giraffe (from the training set) to the masked input image. \n\nThe above step would give a rough image with some holes.\n\nc. To remove holes, one can either use an image inpainting pipeline, or can also simply use a CNN with GAN loss.\n\nI believe that above pipeline should give competitive (if not better) outputs to the proposed formulation. (Note: the above pipeline could be considered a simpler version of PhotoClipArt from Lalonde et al, 2007).\n\n2. Nearest neighbors on generated instance map needs to be done. This enables to understand if the generated shapes are similar to ones in training set, or there are new shapes/masks being generated. Looking at the current results, I believe that generated masks are very similar to the training instances for that category. And that makes baseline described in (1) even more important.\n\n3. An interesting thing about Cycle-GAN is its ability to give somewhat temporally consistent (if not a lot) -- ex. Horse to Zebra output shown by the authors of Cycle-GAN. I am not sure if the proposed formulation will be able to give temporally consistent output on shorts/skirts to jeans example. It would be important to see how the generated output looks for a given video input containing a person and its segmentation map  of jeans to generate a video of same person in shorts? \n\n', 'This paper does unpaired cross-domain translation of multi-instance images, proposing a method -- InstaGAN -- which builds on CycleGAN by taking into account instance information in the form of per-instance segmentation masks. \n\n=====================================\n\nPros:\n\nThe paper is well-written and easy to understand. The proposed method is novel, and does a good job of handling a type of information that previous methods couldn’t.\n\nThe motivation for each piece of the model and training objective is clearly explained in the context of the problem. Intuitively seems like a nice and elegant way to take advantage of the extra segmentation information available.\n\nThe results look pretty good and clearly compare favorably with CycleGAN and other baselines. The tested baselines seem like a fair comparison -- for example, the model capacity of the baseline is increased to compensate for the larger proposed model.\n\n=====================================\n\nCons / suggestions:\n\nThe results are somewhat limited in terms of the number of domains tested -- three pairs of categories (giraffe/sheep, pants/skirts, cup/bottle).  In a sense, this is somewhat understandable -- one wouldn’t necessarily expect the method to be able to translate between objects with different scale or that are never seen in the same contexts (e.g. cups and giraffes). However, it would still have been nice to see e.g. more pairs of animal classes to confirm that the category pairs aren’t the only ones where the method worked.\n\nRelatedly, it would have been interesting to see if a single model could be trained on multiple category pairs and benefit from information sharing between them.\n\nThe evaluation is primarily qualitative, with quantitative results limited to Appendix D showing a classification score. I think there could have been a few more interesting quantitative results, such as segmentation accuracy of the proposed images for the proposed masks, or reconstruction error. Visualizing some reconstruction pairs (i.e., x vs. Gyx(Gxy(x))) would have been interesting as well.\n\nI would have liked to see a more thorough ablation of parts of the model. For example, the L_idt piece of the loss enforcing that an image in the target domain (Y) remain identical after passing through the generator mapping X->Y. This loss term could have been included in the original CycleGAN as well (i.e. there is nothing about it that’s specific to having instance information) but it was not -- is it necessary?\n\n=====================================\n\nOverall, while the evaluation could have been more thorough and quantitative, this is a well-written paper that proposes an interesting, well-motivated, and novel method with good results.\n\n\n==========================================================================\n\nREVISION\n\nThe authors\' additional results and responses have addressed most of my concerns, and I\'ve raised my rating from 6 to 7.\n\n> We remark that the identity mapping loss L_idt is already used by the authors of the original CycleGAN (see Figure 9 of [2]). \n\nThanks, you\'re right, I didn\'t know this was part of the original CycleGAN. As a final suggestion, it would be good to mention in your method section that this loss component is used in the original CycleGAN for less knowledgeable readers (like me) as it\'s somewhat hard to find in the original paper (only used in some of their experiments and not mentioned as part of the ""main objective"").']","[60, 50, 70]","[80, 80, 80]","[""The sentiment score is 60 (positive) because the reviewer begins by describing the paper as 'well-designed' and the idea as 'interesting'. They also mention 'reasonable' results and list several pros. However, they do express some concerns and questions, which prevents a higher score. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as 'concerns' and 'questions' rather than direct attacks. They use phrases like 'I think' and 'I wonder' to soften their critiques, maintaining a professional and courteous tone."", ""The sentiment score is 50 (moderately positive) because the reviewer expresses satisfaction with the authors' rebuttal and lists several pros of the paper, including an 'intuitive and well done' formulation, 'nice qualitative analysis', and 'good results'. However, the reviewer also provides significant criticisms and suggestions for improvement, balancing out the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms constructively as suggestions for improvement rather than harsh judgments. Phrases like 'I would make an observation' and 'I believe that' soften the critique. The reviewer also uses positive adjectives like 'nice', 'good', and 'thoughtfully' when describing the paper's strengths."", ""The sentiment score is 70 (positive) because the reviewer expresses an overall positive view of the paper, praising its novelty, clarity, and good results. They use phrases like 'well-written', 'novel', and 'good job'. While they do offer some criticisms and suggestions for improvement, these are presented as minor issues rather than major flaws. The final paragraph summarizes the review positively, despite noting some limitations. The politeness score is 80 (quite polite) because the reviewer uses respectful and constructive language throughout. They balance praise with criticism, and frame their suggestions as opportunities for improvement rather than attacks. Phrases like 'it would have been nice to see' and 'I would have liked to see' are used to soften criticism. The reviewer also acknowledges when their initial criticism was mistaken in the revision section, showing humility and fairness.""]"
"['This paper presents a system that infers programs describing 3D scenes composed of simple primitives. The system consists of three stages each of which is trained separately. First, the perceptual module extracts object masks and their attributes. The objects are then are split into several groups. Finally, each group is mapped to a corresponding DSL program using a sequence-to-sequence network similar to the ones typically employed in neural machine translation.\n\nPros:\n+ The paper is written clearly and easy to read.\n+ Visual program synthesis is very exciting and important direction both for image understanding and generation.\n+ The results on synthetic datasets are good. The authors also demonstrate the applicability of the approach to real-world data (albeit significantly constrained).\n+ I find it surprising that a seq2seq is good at producing an accurate program for a group of objects.\n+ Visual analogy making experiments are impressive.\n\nCons:\n- The proposed model requires rich annotation of training data since all the components of the systems are trained in a supervised fashion. It’s not clear how to use the method on the in-the-wild data without such annotation.\n- Related to the previous point, even when it’s possible to synthesize data, it is non-trivial to obtain the ground-truth grouping of objects. Judging by Table 2, it seems that the system breaks in absence of the grouping information.\n- The data used in the paper is quite simplistic (limited number of primitives located in a regular grid). I’m wondering if there is a natural way to extend the approach to more complex settings. My guess is that the performance will drop significantly.\n\nNotes/questions:\n* Section 2, paragraph 1: The paper by [Ganin et al., 2018] presents both a system for reproducing an image as well as for sampling from a distribution; moreover, it presents experiments on 3D data (i.e., not limited to drawing).\n* Section 3.4, paragraph 2: I’m not sure I understand the last sentence. How can we know that we successfully recovered the scene at test time? Could the authors elaborate on the stopping criterion for sampling?\n* Section 4.2, paragraph 2: Do I understand correctly that the main difference between the test set and the generalization set is the number of groups? (i.e., 2 vs 3). If so, it’s a fairly limited demonstration of generalization capabilities of the system.\n* Section 4.2, paragraph 4: “we search top 3 proposals ...” – How do we decide which one is better? Do we somehow have an access to the ground truth program at test time?\n* Could the authors explain the representation of a program more clearly? How are loops handled? How can one subtract/add programs in the analogy making experiment?\n\nOverall, I think it is a interesting paper and can be potentially accepted on the condition that the authors address my questions and concerns.', 'This paper investigates a descriptive representation of scenes using programs. Given an input image and an initial set of detections obtained from bottom-up detectors a sequence to sequence network is used to generate programs in a domain specific language (DSL). The authors consider a dataset where simple primitives are arranged in layouts in 3D scenes with varying material and color properties. They argue that the scene representation lead to better generalization on novel scene types and improve over baselines on image analogy tasks. The paper is well written but the evaluation and technical novelty is weak. \n\nFirst, the use of scene programs is not a contribution of this paper. Going beyond the works cited in the related work section, several recent works have proposed and investigated the advantages of program synthesis for shape generation (e.g., CSGNet Sharma et al. CVPR 2018 and Scene derendering, Wu et al., CVPR 2017), visual reasoning (Modular networks, Andreas et al., 2015), among others. \n\nAt a high-level the motivation of the program level representation for the considered tasks is not highlighted. It seems that an attribute-based representation, i.e., the output of the mask R-CNN detector that describes the image as a collection of objects, material properties, and their positions and scales is a sufficient representation. The higher-order relationships can be relatively easily extracted from the detections since the images are clean and clutter free. A baseline approach where the program synthesis was performed using search and grouping should be compared with. \n\nThe considered tasks are relatively simple achieving 99.5% token-level accuracy. The evaluation beyond the synthetic datasets is fairly limited and it is unclear how well the method generalizes to novel images in clutter and occlusion. \n\nIn summary, the paper makes a number of observations that have been motivated in a number of prior works, but the contributions of this paper is not highlighted (e.g., over neural scene derendering). The main claim that higher-order relationships are being modeled is not apparent due to the simplicity of the scenes being considered. For example, the program blocks being considered are somewhat arbitrary and a comparison with a clustering based grouping approach should have been evaluated. The experimental evaluation is weak in several aspects. The generalization to real images is anecdotal with only two examples shown in the Figure 7. ', '[Overview]\n\nIn this paper, the authors proposed a new format of representation called scene programs, to describe the visual scenes. To extract the scene programs from scenes, the authors exploited the off-the-shelf object detection and segmentations model, mask r-cnn to extract all objects and the corresponding attributes from the images, and then detect groups for those objects, which are then used to generate the programs which matches the input scenes. The experiments are performed on a synthetics datasets which consists of multiple shapes with different attributes. The experiments shows that the proposed model can infer more accurate programs from the scenes, and those generated programs can be used to recover the input scenes more accurately. Besides, the authors also showed that the generated scene programs can be used for image editing and making visual analogy.\n\n[Strengthes]\n\n1. The authors proposed a new representation, called scene programs, to describe the visual scenes with some textual program. This is a new scene representation, which could be potentially used in various scenarios, such as the image synthesis in graphics.\n\n2. The authors proposed a hierarchical method to model the structures in scenes. Specifically, the objects in a scene are first extracted and then grouped into multiple clusters, which will be used to guide the scene program synthesis. \n\n3. The experimental results demonstrate the effectiveness of the proposed method both qualitatively and quantitatively. The authors also showed the the programs generated  can be sued for image editing and cross-modality matching. \n\n[Weaknesses]\n\n1. It is a bit unfair to compare the proposed method with the two baseline methods listed in Table 2. The authors used a pre-trained mask-rcnn to detect all objects and predict the attributes for all objects. However, the counterpart methods have no access to this supervision. Even in this case, CNN-LSTM seems achieve comparable performance on the first three metrics. \n\n2. The advantage of scene program compared with scene graph (Johnson et al) are not clear to me. Scene graph is also a symbolic representation for images. Also, for all the tasks mentioned in this paper, such as image editing and visual analogy, scene graph can probably also complete well. The authors should comment about the specific advantages of scene program in comparison with scene graph.\n\n3. All the images shown in the paper seems arranged uniformly, which I think contains some bias to the proposed grouping strategy. I would like to see more diverse configurations of the foreground objects. It would be good to see if the proposed model can describe more complicated scenes.\n\n[Summary]\n\nThis paper proposed a novel scene representations, called scene program. To extract the scene program, the authors proposed a hieratchical inference method. The resulting scene programs based on the proposed model outperforms several baseline models quantitatively. The authors also showed the proposed scene program is suitable for image editing and visual analogy making. However, as pointed above, there are some unclear points to me, especially the advantages of scene program compared with scene graph, and the representation power of scene program for complicated scenes.']","[50, -50, 50]","[80, 20, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer lists several pros and expresses interest in the paper, stating it's 'interesting' and 'can be potentially accepted'. However, they also list significant cons and questions, balancing out the positive aspects. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as questions or suggestions rather than harsh statements. They use phrases like 'Could the authors explain' and 'I'm wondering if' which maintain a courteous tone. The review concludes with a constructive overall assessment, suggesting potential acceptance with revisions."", ""The sentiment score is -50 because the review is generally critical, stating that 'the evaluation and technical novelty is weak.' The reviewer points out several limitations and argues that the paper's contributions are not well highlighted. However, it's not entirely negative as the reviewer acknowledges that the paper is well-written and makes some observations. The politeness score is 20 because while the reviewer is critical, they maintain a professional and respectful tone throughout. They use phrases like 'the paper is well written' and provide specific, constructive feedback without using harsh language. The reviewer also balances criticism with acknowledgment of the paper's strengths, which contributes to a polite tone overall."", ""Sentiment Score (50): The review is generally positive, acknowledging the paper's strengths such as proposing a new representation, demonstrating effectiveness, and showing potential applications. However, it also points out some weaknesses and areas for improvement, balancing the positive aspects. This mix of praise and constructive criticism suggests a moderately positive sentiment.\n\nPoliteness Score (80): The language used in the review is consistently professional and respectful. The reviewer presents both strengths and weaknesses in a balanced manner, using phrases like 'The authors proposed...', 'It would be good to see...', and 'I would like to see...'. The critique is presented constructively without harsh or dismissive language. The high politeness score reflects the reviewer's courteous and considerate tone throughout the review.""]"
"[""Given an additively decomposable function F(X, Q) = sum_over_x_in_X cost(x, Q), one can approximate it using either random sampling of x in X (unbiased, possibly high variance), or using importance sampling and replace the sum_over_x with a sum_over_coreset importance_of_a_point * cost(x, Q) which if properly defined can be both unbiased and have low variance [1]. In this work the authors consider the weighted sum of activations as F and suggest that for each neuron we can subsample the incoming edges. To construct the importance sampling strategy the authors adapt the classic notion of sensitivity from the coreset literature. Then, one has to carefully balance the approximation quality from one layer to the next and essentially union bound the results over all layers and all sampled points. The performed analysis is sound (up to my knowledge).\n\nPro:\n- I commend the authors for a clean and polished writeup.\n- The analysis seems to be sound (apart from the issues discussed below)\n- The experimental results look promising, at least in the limited setup.\n\nCon:\n- There exists competing work with rigorous guarantees, for example [2].\n- The analysis hinges on two assumptions which, in my opinion, make the problem feasible: having (sub) exponential tails allows for strong concentration results, and with proper analysis (as done by the authors), the fact that the additively decomposable function can be approximated given well-behaving summands is not surprising. The analysis is definitely non-trivial and I commend the authors for a clean writeup.\n- While rigorous guarantees are lacking for some previous work, previously introduced techniques were shown to be extremely effective in practice and across a spectrum of tasks. As the guarantees arguably stem from the assumptions 1 and 2, I feel that it’s unfair to not compare to those results empirically. Hence, failing to compare to results of at least [2, 3] is a major drawback of this work.\n- The result holds for n points drawn from P. However, in practice the network might receive essentially arbitrary input from P at inference time. Given that we need to decide on the number of edges to preserve apriori, what are the implications?\n- The presented bounds should be discussed on an intuitive level (i.e. the number of non zero entries is approximately cubic in L).\n\nI consider this to be a well-executed paper which brings together the main ideas from the coreset literature and shows one avenue of establishing provable results. However, given that no comparison to the state-of-the-art techniques is given I'm not confident that the community will apply these techniques in practice. On the other hand, the main strength -- the theoretical guarantees -- hinge on the introduced assumptions. As such, without additional empirical results demonstrating the utility with respect to the state-of-the-art methods (for the same capacity in terms of NNZ) I cannot recommend acceptance.\n\n[1] https://arxiv.org/abs/1601.00617\n[2] papers.nips.cc/paper/6910-net-trim-convex-pruning-of-deep-neural-networks-with-performance-guarantee\n[3] https://arxiv.org/abs/1510.00149\n\n\n========\nThank you for the detailed responses. Given the additional experimental results and connections to existing work, I have updated my score from 5 to 6. "", 'The authors propose to reduce the size of fully connected neural networks, defined as the total number of nonzeros in the weight matrices, by calculating sensitivity scores for each incoming connection to a neuron, and randomly keeping only some of the incoming connections with probability proportional to their share of the total sensitivity. They provide a specific definition for the sensitivity scores and establish that the sparsified neural network, with constant probability for any sample from the training population, provides an output that is a small multiplicative factor away from the output of the unsparisfied neural network. The cost of the sparsification is essentially the application of the trained neural network to a small number of data points in order to compute the sensitivity scores\n\nPros:\n- the method works empirically, in that their empirical evaluations on MNIST, CIFAR, and FashionMNIST classification problems show that the drop in accuracy is lower when the neural net is sparsified using their CoreNet algorithm and variations than when it is randomly sparsified or the neural network size is reduced by using SVD.\n- theory is provided to argue the consistency of the sparsified neural network\n\nCons:\n- no comparison is made to the baseline of using matrix sparsification algorithms on the weight matrices themselves. I do not see why CoreNet should be expected to perform empirically better than simply using e.g. the entry-wise sampling scheme from ""Near-optimal entrywise sampling for data matrices"" by Achlioptas and co-authors, or earlier works addressing the same problem of sparsifying matrices.\n- the theory makes very strong assumptions (Assumptions 1 and 2) that are not explained or justified well. Both depend on the specific weight matrices being sparsified, and it isn\'t clear a priori when the weight matrices obtained from whatever optimization procedure was used to train the neural net will be such that these assumptions hold.\n- despite the suggestions of the theory, the accuracy drop can be quite large in practice, as in the CIFAR panel of Figure 1\n\nI think the ICLR audience will appreciate the attempt to provide a principled approach to decreasing the size of neural networks, but I do not think this approach is widely compelling as :\n(1) no true guaranteed control on the trade-off between accuracy loss and network size is available\n(2) empirically the method does not perform well consistently\n(3) comparisons with reasonable and informative baselines are missing\n\nUpdated in response to author response: the inclusion of experimental comparisons with linear algebraic sparsification baselines, showing that the proposed method can be significantly more accurate, strengthens the appeal of the method.', 'In this work the authors improve upon the work of Arora et al. mainly with respect to one aspect, i.e.,\nThey provide eps-approximation of a fully connected neural network output neuron-wise. The idea of \ncompression is very natural and has been explored by various previous works (key refs are cited). Intuitively,\nthe number of effective parameters is significantly less than the number of parameters in the neural network.\nThe authors introduce the notion of the coreset that is suitable for compressing the weight parameters \nin definition 1. Their main result is stated as Theorem 4. Finally, the authors experiment on standard benchmarks, \nperform a careful experimental analysis (i.e., they ensure fairness of comparison between methods such as \nSVD and the rest).  It would be interesting to see the histogram/distribution of the weights per layer and at an aggregate level\nfor the datasets used.  Also, in the light of the recent results of Arora et al. that show that the signal out of a layer\nis correlated with the top singular values, how would coresets\ndeveloped in the numerical linear algebraic community  (e.g., Near-optimal Coresets For Least-Squares Regression \nby Boutsidis et al.) perform, even as an experimental heuristic compared to the proposed method?']","[20, -20, 60]","[60, 50, 70]","[""The sentiment score is slightly positive (20) because the reviewer acknowledges several strengths of the paper, including a 'clean and polished writeup', 'sound analysis', and 'promising' experimental results. However, they also raise significant concerns and ultimately cannot recommend acceptance without additional work. The politeness score is moderately high (60) as the reviewer uses respectful language throughout, acknowledging the authors' efforts with phrases like 'I commend the authors' and providing balanced feedback with both pros and cons. They offer constructive criticism and suggestions for improvement rather than harsh criticism. The final paragraph maintains a polite tone while clearly stating the reviewer's position."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some pros of the paper, they express more significant cons and ultimately conclude that the approach is not 'widely compelling'. The reviewer points out issues with the lack of comparison to baseline methods, strong assumptions in the theory, and inconsistent empirical performance. However, the score is not deeply negative as the reviewer does recognize some positive aspects and the potential interest of the ICLR audience.\n\nThe politeness score is moderately positive (50) because the reviewer maintains a professional and objective tone throughout. They clearly separate pros and cons, use neutral language to describe the paper's content, and provide specific, constructive feedback. The reviewer also acknowledges the authors' response and its positive impact on the paper's appeal. While not overly warm, the language is respectful and avoids any harsh or personal criticisms."", ""The sentiment score is 60 (positive) because the reviewer acknowledges the authors' improvements on previous work, praises their 'careful experimental analysis', and shows interest in further exploration. The tone is generally positive, though not overwhelmingly enthusiastic. The politeness score is 70 (polite) as the reviewer uses respectful language throughout, acknowledges the authors' contributions, and offers suggestions for improvement in a constructive manner. The reviewer avoids harsh criticism and instead frames potential additions as 'interesting' to see. The language is professional and courteous throughout, without being overly formal or effusive.""]"
"['The paper proposes a method of regularising goal-conditioned policies with a mutual information term. While this is potentially useful, I found the motivation for the approach and the experimental results insufficient. On top of that the presentation could also use some improvements. I do not recommend acceptance at this time.\n\nThe introduction is vague and involves undefined terms such as ""useful habits"". It is not clear what problems the authors have in mind and why exactly they propose their specific method. The presentation of the method itself is not self-contained and often relies on references to other papers to the point where it is difficult to understand just by reading the paper. Some symbols are not defined, for example what is Z and why is it discrete?\n\nThe experiments are rather weak, they are missing comparison to strong exploration baselines and goal-oriented baselines.', 'This paper proposes the concept of decision state, which is the state where decision is made “more” dependent to a particular goal. The authors propose a KL divergence regularization to learn the structure of the tasks, and then use this information to encourage the policy to visit the decision states. The method is tested on several different experiment setups.\n\nIn general the paper is well-written and easy to follow. Learning a more general policy is not new (as also discussed in the paper), but using the learned structure to further guide the exploration of the policy is novel and interesting.\n\nI have a couple questions about the experimental part though, mostly about the baselines.\n1. What is the reasoning behind the selection of the baselines, e.g. A2C as the baseline for the miniGrid experiments? \n2. What are the performances of the methods in Table 2, in direct policy generalization? Or is there any reason not reporting them here?\n3.  What is the reasoning of picking “Count-base baseline” for Figure 4, rather than the method of curiosity-based exploration?\n4. For the Mujoco tasks, there are couple ones outperforming PPO, e.g. TD3, SAC etc.. [1,2] The authors should include their results too. \n5. As an ablation study, it would be interesting to see how the bonus reward of visiting decision states can help the exploration on the training tasks, compared to the policy learned from equation (1), and the policies learned without information of other tasks.\n6. Lastly, the idea of decision states can also be used in other RL algorithms. It would be also interesting to see if this idea can further improve their performances.\n\nOther comments:\n1. Equation (3) should be \\le.\n2. Why would Equation (5) hold? \n3. Right before section 2.2, incomplete sentence.\n\n\nDisclaimer: The reviewer is not familiar with multitask reinforcement learning, and the miniGrid environment in the paper. Other reviewers should have better judgement on the significance of the experimental results.\n\n[1] Haarnoja, Tuomas, et al. ""Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor.""\xa0arXiv preprint arXiv:1801.01290\xa0(2018).\n[2] Fujimoto, Scott, Herke van Hoof, and Dave Meger. ""Addressing Function Approximation Error in Actor-Critic Methods.""\xa0arXiv preprint arXiv:1802.09477\xa0(2018).', 'The authors propose a new regularizer for policy search in a multi-goal RL setting. The objective promotes a more efficient exploration strategy by encouraging the agent to learn policies that depend as little as possible on the target goal. This is achieved by regularizing standard RL losses with the negative conditional mutual information I(A;G|S). Although this regularizer cannot be optimize, the authors propose a tractable bound. The net effect of this regularizer is to promote more effective exploration by encouraging the agent to visit decision states, in which goal-depend decisions play a more important role. The idea of using this particular regularizer is inspired by an existing line of work on the information bottleneck.\n\nI find the idea proposed by the authors to be interesting. However, I have the following concerns, and overall I think this paper is borderline.\n\n1. The quality of the experimental validation provided by the authors is in my opinion borderline acceptable. Although the method performs better on toy settings, it seems barely better on more challenging ones. Experiments in section 4.5 lack detail and context.\n2. The clarity of the presentation is also not great.\n    2.1. The two-stage nature of the method was confusing to me. I didn’t understand the role of the second stage. Most focus is on the first stage, and only very little on the second stage. For example, I was confused about why the sign of the regularizer was flipped.\n    2.2. I was confused by how exactly the bounds (3) and (4) we applied and in what order.\n    2.3. I think the intuition of the method could be better explained and better validated by experiments.\n\nI also have the following additional comments:\n* How is the regularizer applied with other policy search algorithms besides Reinforce? Was it done in the paper? I can’t say for sure. Specifically, when comparing to PPO, was the algorithm compared to a version of PPO augmented with this regularizer? Why yes or why no?\n* More generally, experiments where more modern policy search algorithms are combined with the regularizer would be helpful. In particular, does it matter which policy search algorithm we use with this method?\n* Experimental plots in section 4.4 are missing error bars, and I can’t tell if the results are significant without them.\n* I thought the motivation for choosing this regularizer was lacking. The authors cite the information bottleneck literature, but we shouldn’t need to read all these papers, the main ideas should be summarized here.\n* The argument for how the regularizer improves exploration seemed to me very hand-wavy and not well substantiated by experiments.\n* I would love to see a better discussion of how the method is useful when he RL setting is not truly multi-goal.\n* The second part of the algorithm needs to be explained much more clearly.\n* What is the effect of the approximation on Q?\n\n---\n\nI have read the response of the authors, and they have addressed a significant numbers of concerns that I had. I am upgrading my rating to a 7.']","[-70, 60, -20]","[-20, 80, 50]","[""The sentiment score is -70 because the reviewer explicitly states 'I do not recommend acceptance at this time' and points out several significant weaknesses in the paper, including insufficient motivation, experimental results, and presentation. The overall tone is critical and negative. The politeness score is -20 because while the reviewer doesn't use overtly rude language, the critique is direct and somewhat blunt, with phrases like 'vague', 'not clear', and 'rather weak' without much softening language or positive feedback to balance the criticism. The reviewer also doesn't offer many constructive suggestions for improvement, which contributes to the slightly impolite tone."", ""The sentiment score is 60 (positive) because the reviewer states that the paper is 'well-written and easy to follow' and describes the method as 'novel and interesting'. However, it's not extremely positive as the reviewer raises several questions and suggests improvements. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, phrases criticisms as questions or suggestions, and even includes a disclaimer about their own expertise. The reviewer also acknowledges the paper's strengths before diving into questions and recommendations, which is a polite approach to peer review."", ""The sentiment score is slightly negative (-20) because while the reviewer finds the idea interesting, they express several concerns and describe the paper as 'borderline'. They point out issues with experimental validation, clarity of presentation, and lack of detail in certain areas. However, it's not entirely negative as they do acknowledge some positive aspects. The politeness score is moderately positive (50) because the reviewer uses professional and respectful language throughout. They phrase criticisms as 'concerns' and use polite expressions like 'I find the idea... to be interesting'. Even when expressing doubts, they maintain a courteous tone. The final paragraph indicating an upgrade in rating after the authors' response also contributes to the overall polite impression.""]"
"['This paper proposes an unsupervised style transfer method uses two-pathway encoder and a decoder for both domains. The loss function can be written using reconstruction losses and the confusion term. Experimental results are very promising comparing to state of the art methods. \n\nThe methodology presented in this paper is simple yet powerful according to the experimental results. However I do have a few concerns:   \n\n1. The writing can certainly be improved.  I had a difficult time understanding Section 2. For example the function Q is upper cased but later the f and g are all lower cased. Why domains A and B are defined using the space and the probability measure? ""our framework assumes that the distribution of persons with sunglasses and that of persons without them is the same,"" The ""distribution of persons"" is not a rigorous definition and is hard to infer what does it actually mean. ""f"" does not appear in the loss terms although it appears under ""min"". \n\n2. I like the simplicity of the objective function, but it is hard for me to understand that why the algorithm does not pick up spurious differences between A and B. For example, what if there are lighting differences and glasses/no-glasses differences between A and B? See 3rd row of figure 2 for an example. \n\n3. Given the huge differences in performance between the proposed method and MUNIT and DRIT, some analysis/discussion on the reason of success/failure should be given.\n\n--------------------------------------------------------\n\nI have read authors\' response. ', 'The paper proposes an unsupervised approach for mapping two sets of objects, A and B, such that set B contains all the information that is in set A and some additional information. The paper learns a latent space which encodes: (a) information which is shared in both sets, and (b) the additional content present in B. This is done by employing a two-pathway encoder and a decoder for both the sets. Experiments on problems such as adding glasses or facial hair to faces shows that the proposed method performs better than existing disentanglement approaches. ', 'This paper tackles the task of content transfer. For a given type of images (frontal face shots), the goal is to transfer a particular localized property (e.g. glasses or facial hair) extracted from one image to another image of the same type (difference face). This is also known as the problem of guided image-to-image translation. \nThe problem is formalized as the one of learning to map two different domains, one domain being composed of images with the property/attribute of interest, the other one containing images without it. The problem is said to be ‘unsupervised’, i.e. there is no pairwise correspondences between images of the two domains (with/without attributes).\nThe novelty of the approach lies on\n-\tthe loss, which is composed of three terms: two reconstruction losses and a domain confusion loss\n-\tthe overall architecture and in particular the fact that images are represented as a combination of the output of two encoders: one encodes the face and the other encodes the property (e.g. glasses).\n\nOverall comments:\n+ a theoretical part discusses generalization bounds and the emergence of disentangled representations\n+ visual results are appealing showing the suitability of the method to the considered task\n- the discussion of the advantages of the proposed method could be improved\n- the motivation for some of the experimental results is unclear (choice of experimental protocol and baselines). \n- the scope of the method seems limited\n\nDetailed comments:\n\nI personally like the described model. The disentanglement mechanism is intuitive to understand, and seems well suited for this particular task, as qualitative evidence suggests. I am not sure if this approach would be applicable beyond the very specific scenario considered in the paper. \n\nThe paper emphasizes that the strength of the method lies on its simplicity w.r.t. competitors, and its better results. These two aspects could be better discussed. \n\nSimplicity: \nIn several places the paper claims that the proposed approach is considerably simpler. Some parts hint to criteria for the ‘complexity’ comparison, such as Table 1 or a few sentences (e.g. “this allows us to train with many less parameters and without the need to applying excessive tuning”). It would be more convincing to have a dedicated discussion of the practical advantages of the simplicity claimed by this method, discussing e.g. training/testing time, memory footprint of the models, convergence properties, stability, etc. \n\nComparison: \nThe chosen baselines, i.e. MUNIT and DRIT are experimentally shown to perform poorly on the considered task. Yet although these methods were also developed for guided image translation, they were designed for a rather different application: style transfer. I am not sure these comparisons bring much insight on the performance of the method.\nExperiments are conducted for a very specific task, on a single dataset. Would the method have broader application?\n\nExperimental protocol:\nI understand that such an approach is difficult to evaluate quantitatively but I am not sure what there is to learn from experiments reported in Table 3, as there is no point of comparison on this task. This could be clarified. \n\nAdditional comments:\n-\tThe paper relies on the assumption that the distribution of persons with sunglasses and that of persons without them is the same, except for the sunglasses. This sounds like a strong requirement for the data used to train the network; it would be interesting to discuss the practical impact of this assumption, especially on the data requirement for the method to perform well\n-\tI found Figure 1 quite useful. A visual representation of the architecture and its associated description help follow the technical part. \n-\tI got confused with some of the claims in section 4.2. More generally, I found the technical part hard to follow.\n-\tThe user study seems small: only 10 pairs of images are considered. How were those pair chosen? Is the set representative?\n']","[50, 80, 20]","[70, 50, 60]","[""The sentiment score is 50 (slightly positive) because the reviewer begins by praising the paper's methodology as 'simple yet powerful' and notes that the experimental results are 'very promising'. However, they also express several concerns, which tempers the overall positivity. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, framing their criticisms as 'concerns' rather than outright flaws. They also use phrases like 'I like' and 'I had a difficult time understanding' which maintain a constructive tone. The reviewer provides specific, actionable feedback without using harsh or dismissive language."", ""The sentiment score is 80 (positive) because the review highlights the paper's novel approach and its superior performance compared to existing methods. The reviewer describes the paper's methodology in detail and mentions its successful application to specific problems, indicating a favorable view of the research. The politeness score is 50 (slightly polite) because the language used is neutral and professional, focusing on describing the paper's content without personal comments or criticisms. The reviewer maintains an objective tone throughout, which is appropriate for a scientific review, but doesn't go out of their way to use particularly polite language either."", ""Sentiment score (20): The review has a slightly positive sentiment overall. The reviewer mentions liking the described model and notes some positive aspects like 'appealing visual results' and 'intuitive disentanglement mechanism'. However, there are also several criticisms and areas for improvement mentioned, which temper the positivity. The balance of positive and negative points, with a slight lean towards positive, justifies a score of 20.\n\nPoliteness score (60): The language used in the review is generally polite and professional. The reviewer uses phrases like 'I personally like', 'It would be more convincing', and 'I am not sure' which maintain a respectful tone. They provide constructive criticism without being harsh or dismissive. The reviewer also acknowledges positive aspects before presenting criticisms. However, the score is not higher as the review maintains a formal, neutral tone rather than being overtly courteous or warm.""]"
"['The paper proposes embedding the data into low-dimensional Wasserstein spaces. These spaces are larger and more flexible than Euclidean spaces and thus, can capture the underlying structure of the data more accurately. However, the paper simply uses the automatic differentiation to calculate the gradients. Thus, it offers almost no theoretical contribution (for instance, how to calculate these embeddings more efficiently (e.g. faster or more efficient calculation of the Sinkhorn divergence), how to motivate loss functions than can benefit the structure of the Wasserstein spaces, what the interpretation of phi(x) is for each problem, e. g. word embedding, etc.). Additionally, the experiments are unclear and need further improvement. For instance, which method is used to find the Euclidean embedding of the datasets? Have you tried any alternative loss functions for the discussed problems? Are these embeddings useful (classification accuracy, other distortion measure)? How does the 2-D visualizations compare to DR methods such as t-SNE? What is complexity of the method? How does the runtime compare to similar methods?', ""The paper ‘Learning Discrete Wasserstein Embeddings' describes a new embedding method that,\ncontrary to usual embedding approaches, does not try to embed (complex, structured) data into an \nHilbertian space where Euclidean distance is used, but rather to the space of probability measures\nendowed with the Wasserstein distance. As such, data are embed on an empirical \ndistribution supported by Diracs, which locations can be determined by a map that is learnt from data.\nInterestingly, authors note a 'potential universality' for W_p(R^3) (from a result of Andoni et al., 2015), \nsuggesting that having Diracs in R^3 could embed potentially any kind of metric on symbolic data. \n\nExperimental validations are presented on graph and word embedding, and a discussion on visualization of \nthe embedding is also proposed (since the Diracs are located in a low dimensional space).   \n\nAll in all the paper is very clear and interesting. The idea of embedding in a Wasserstein space is \noriginal (up to my knowledge) and well described. I definitely believe that this work should be presented\nat ICLR. I have a couple of questions and remarks for the authors:\n - It is noted in section 3.2 that both Diracs location and associated weights could be optimized. Yet the authors \n   chose to only optimize locations. Why not only optimizing the weights (as in an Eulerian view of probability\n   distributions) ? The sentence involving works of Brancolini and Claici 2018 is not clear to me. Why weighting \n   does not improve asymptotically the approximation quality ? \n - Introducing the entropic regularization is mainly done for being able to differentiate the Wasserstein \n   distance. However, few is said on the embeddability of metrics in W^\\lambda_p(R). Is using an entropic \n   version of W moderating the capacity of embedding ? At least experimentally, a discussion could be made  \n   on the choice of the regularization parameter, at least in section 4.1. In eq. (9), it seems that it is not \n   the regularized version of W. ? \n - I assume that the mapping is hard to invert, but did the authors tried to experiment reconstructing an object \n   of interest by following a geodesic in the Wasserstein space ?  \n - It seems to me that authors never give generalization results. What is the performance of the metric approximation \n   when tested on unseen graphs or words ? This point should be clarified in the experiment.        \n\n"", 'This paper learns embeddings in a discrete space of probability distributions, endowed with a (regularized) Wasserstein distance.\n\npros:\n\n- interesting idea, nice results, mostly readable presentation.\n- the paper is mostly experimental but the message delivers clearly the paper’s objective\n- the direct visualisation is interesting\n- the paper suggests interesting problems related to the technique\n\ncons:\n\n- to be fair with the technique, the title should mention the fact that the paper minimises a regularised version of Wasserstein distances (Wasserstein -> Sinkhorn ? put “regularised"" ?)\n- and to be fair, the paper should put some warnings related to regularisation -- this is not a distance anymore, sparsity is affected by regularisation (which may affect visualisation). Put some reminders in the conclusion, reword at least the third paragraph in the introduction.\n- the paper could have been a little bit more detailed on Section 2.3, in particular for its third paragraph. Even when it is an experimental paper.\n- the direct visualisation is interesting in the general case but has in fact a problem when distributions are highly multimodal, which can be the case in NLP. This blurs the interpretation.\n- the paper delivers a superficial message on the representation: I do not consider that nice having modes near physical locations (Paris, France) is wrong. It is also a city. However, it would have been interesting to see the modes of “city” (or similar) to check whether the system indeed did something semantically wrong.\n\nQuestions:\n\n- beyond that last remark comes the problem as to whether one can ensure that semantic hierarchies appear in the plot: for example if Nice was only a city, would we observe a minimal intersection with the support of word “city” ? (intersection to be understood at minimal level set, not necessarily 0).\n\n']","[-50, 80, 50]","[0, 90, 70]","[""The sentiment score is -50 because the review is generally critical of the paper, pointing out several shortcomings such as lack of theoretical contribution and unclear experiments. However, it's not entirely negative as it acknowledges the potential of the proposed method. The politeness score is 0 (neutral) because the language used is direct and professional without being overtly polite or rude. The reviewer states criticisms plainly but doesn't use harsh language. The review focuses on the content and methodology rather than personal attacks or overly deferential language."", ""The sentiment score is 80 (positive) because the reviewer expresses a very favorable view of the paper, describing it as 'very clear and interesting' and stating 'I definitely believe that this work should be presented at ICLR.' The reviewer also praises the originality of the idea. The score is not 100 as the reviewer does have some questions and remarks for improvement. The politeness score is 90 (very polite) because the reviewer uses respectful and constructive language throughout. They frame their questions as curiosities rather than criticisms, using phrases like 'I have a couple of questions and remarks' and 'did the authors tried to experiment...?' The tone is consistently professional and courteous, showing respect for the authors' work while offering thoughtful suggestions for improvement."", ""The sentiment score is 50 (slightly positive) because the review begins with a list of pros, indicating an overall positive view of the paper. However, it also includes a substantial list of cons and questions, which balances out the positivity. The reviewer acknowledges the paper's interesting ideas and nice results, but also points out areas for improvement. The politeness score is 70 (fairly polite) because the reviewer uses respectful language throughout, offering constructive criticism without harsh or dismissive comments. The reviewer uses phrases like 'to be fair' and 'interesting idea', which contribute to a polite tone. The suggestions for improvement are presented as recommendations rather than demands, further contributing to the polite nature of the review.""]"
"[""Paper overview: Model ensembling techniques aim at improving machine learning model prediction results by i) executing several different algorithms on the same task and ii) solving the discrepancies in the responses of all the algorithms, for each task. Some common methods are voting and averaging (arithmetic or geometric average) on the results provided by the different algorithms. \nSince averaging amounts to computing barycenters with different distance functions, this paper proposes to use the Wassertein barycenter instead of the L2 barycenter (arithmetic average) or the extended KL barycenter (geometric mean). \n\nRemarks, typos and experiences that would be interesting to add: \n     1) Please define the acronyms before using them, for instance DNN (in first page, 4th line), KL (also first page), NLP, etc. \n    2) In practice, when ensembling different methods, the geometric and arithmetic mean are not computed with equal weights ($\\lambda_l$ in Definition 1). Instead, these weights are computed as the optimal values for a given small dev-set. It would be interesting to see how well does the method compare to these optimal weighted averages, and also if it improves is we also compute the optimal $\\lambda_l$ for the Wasserstein barycenter. \n    3) How computationally expensive are these methods? \n    4) So the output of the ensembling method is a point in the word embedding space, but we know that not all points in this space have an associated word, thus, how are the words chosen?\n    5) The image captioning example of Fig.4 is very interesting (although the original image should be added to understand better the different results), can you show also some negative examples? That is to say, when is the Wassertein method is failing but not the other methods.\n\n\nPoints in favor: \n     1)Better results: The proposed model is not only theoretically interesting, but it also improves the arithmetic and geometric mean baselines.\n    2) Interesting theoretical and practical properties: semantic accuracy, diversity and robustness (see Proposition 1). \n\nPoints against: The paper is not easy to read. Ensembling methods are normally applied to the output of a classifier or a regression method, so it is not evident to understand why the 'underlying geometry' is in the word embedding space (page 2 after the Definition 1). I think this is explained in the second paragraph of the paper, but that paragraph is really not clear. I assume that is makes sense to use the word-embedding space for the image caption generation or other ML tasks where the output is a word, but I am not sure how this is used in other cases. \n\nConclusion: The paper proposes a new method for model assembling by rethinking other popular methods such as the arithmetic and geometric average. It also shows that it improves the current methods. Therefore, I think it presents enough novelties to be accepted in the conference."", 'The paper proposes a framework based on Wasserstein barycenter to ensemble learning models for a multiclass or a multilabel learning problem. The paper has theoretically shown that the model ensembling using Wasserstein barycenters preserves accuracy, and has a higher entropy than the individual models. Experimental results in the context of attribute-based classification, multilabel learning, and image captioning generation have shown the effectiveness of Wasserstein-based ensembling in comparison to geometric or arithmetic mean ensembling.\n\nThe paper is well-written and the experiments demonstrate comparable results. However, the idea of Wasserstein barycenter based ensembling comes at the cost of time complexity since computation of Wasserstein barycenter is more costly than geometric or arithmetic mean. An ensemble is designed to provide lower test error, but also estimate the uncertainty given by the predictions from different models. However, it is not clear how Wasserstein barycenter based ensembling can provide such uncertainty estimate. \n\nCan the authors comment on the time-complexity of the proposed framework in comparison with its baseline methods? Moreover, is it possible to evaluate the uncertainty of predictions with the proposed framework?\n\nIn the context of multilabel learning, Frogner et. al. (2015, https://arxiv.org/abs/1506.05439) suggested using Wasserstein distance as a loss function. In the model, they also leverage the side information from word embedding of tag labels. Is the proposed ensembling framework comparable with theirs?\n\nIn short, this paper can provide a useful addition to the literature on model ensembling.  Though the proposed framework does improve the performance of predictions in several applications, I am still not fully convinced on time-complexity introduced when computing Wasserstein barycenters.', ""This paper has a simple message. When predicting families (weight vectors) of labels, it makes sense to use an ensemble of predictors and average them using a Wasserstein barycenter, where the ground metric is defined using some a priori knowledge on the labels, here usually distances between word embeddings or more elaborate metrics (or kernels K, as described in p.8). Such barycenters can be easily computed using an algorithm proposed by Benamou et al. 18. When these histograms are not normalized (e.g. their count vectors do not sum to the same quantity) then, as shown by Frogner, Zhang et al, an alternative penalized formulation of OT can be studied, solved numerically with a modified Sinkhorn algorithm, which also leads to a simple W barycenter algorithm as shown by Chizat et al.\n\nThe paper starts with a lot of reminders, shows some simple theoretical/stability results on barycenters, underlines the role of the regularization parameter, and then spends a few pages showing that this idea does, indeed, work well to carry out ensemble of multi-tag classifiers.\n\nThe paper is very simple from a methodological point of view. Experimental results are convincing, although sometimes poorly presented. Figure are presented in a sloppy way, and a more clear discussion on what K should be used would be welcome, beyond what's proposed in p.8. For these reasons I am positive this result should be published, but I'd expect an additional clarification effort from the authors to reach a publishable draft.\n\nminor comment:\n- in remark 1 you mention that as epsilon->0 the solution of Benamou et al. converges to a geometric mean. I would have thought that, on the contrary, the algorithm would have converged to the solution of the true (marginal-regularized) W barycenter. Hence the result your propose is a bit counter-intuitive, could you please develop on that in a future version? Is this valid only because \\lambda here is finite? on the contrary, what would happen when eps -> infty then, and K = ones?\n\n- GW for generalized Wasserstein is poor naming. GW usually stands for Gromov-Wasserstein (see Memoli's work).\n\n- \\lambda and \\lambda_l somewhat clash...""]","[60, 50, 50]","[80, 80, 60]","[""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's novelty, improved results, and interesting theoretical properties. They conclude that it presents enough novelties to be accepted. However, they also mention some points against the paper, such as readability issues, which prevents a higher score. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, offers constructive feedback, and balances positive and negative points. They provide specific suggestions for improvement and frame criticisms as 'remarks' or 'points against' rather than using harsh language. The reviewer's conclusion is supportive while remaining objective."", ""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's contributions and potential usefulness, stating it's 'well-written' and 'can provide a useful addition to the literature.' However, they also express some reservations about time complexity and uncertainty estimation. The politeness score is 80 (quite polite) due to the reviewer's constructive tone, use of respectful language, and framing of criticisms as questions or suggestions. They use phrases like 'Can the authors comment on...' and 'Is it possible to...' which maintain a courteous dialogue. The review balances praise with constructive criticism and ends on a positive note, all indicators of polite academic discourse."", ""The sentiment score is 50 (slightly positive) because the reviewer states they are 'positive this result should be published' but also mentions several areas for improvement. The overall tone is constructive rather than overly critical or enthusiastic. The politeness score is 60 (moderately polite) as the reviewer uses respectful language throughout, acknowledges the paper's strengths, and frames criticisms as suggestions for improvement rather than harsh judgments. The reviewer uses phrases like 'I'd expect' and 'could you please' which contribute to a polite tone. However, some direct criticisms (e.g., 'poorly presented', 'sloppy') slightly reduce the politeness score from being very high.""]"
"['This paper is well set-up to target the interesting problem of degraded generalisation after adversarial training. The proposal of applying spectral normalisation (SN) is well motivated, and is supported by margin-based bounds. However, the experimental results are weak in justifying the paper\'s claims.\n\nPros:\n* The problem is interesting and well explained\n* The proposed method is clearly motivated\n* The proposal looks theoretically solid\n\nCons:\n\n* It is unclear to me whether the ""efficient method for SN in convolutional nets"" is more efficient than the power iteration algorithm employed in previous work, such as Miyato et al. 2018, which also used SN in conv nets with different strides. There is no direct comparison of performance.\n\n* Fig. 3 needs more explanation. The horizontal axes are unlabelled, and ""margin normalization"" is confusing when shown together with SN without an explanation. Perhaps it\'s helpful to briefly introduce it in addition to citing Bartlett et al. 2017.\n\n* The epsilons in Fig. 5 have very different scales (0 - 0.5 vs. 0 - 5). Are these relevant to the specific algorithms and why?\n\n* Section 5.3 (Fig. 6) is the part most relevant to the generalisation problem. However, the results are unconvincing: only the results for epsilon = 0.1 are shown, and even so the advantage is marginal. Furthermore, the baseline models did not use other almost standard regularisation techniques (weight decay, dropout, batch-norm). It is thus unclear whether the advantage can be maintained after applying these standard regularsisers.\n\nA typo in page 6, last line: wth -> with', 'This paper proposes using spectral normalization (SN) as a regularization for adversarial training, which is based on [Miyato et. al., ICLR 2018], where the original paper used SN for GAN training. The paper also uses the results from [Neyshabur et. al., ICLR 2018], where the original paper provided generalization bounds that depends on spectral norm of each layer. \n\nThe paper is well written in general, the experiments are extensive. \n\nThe idea of studying based on the combination of the results from two previous papers is quite natural, since one uses spectral normalization in practice for GAN training, and the other provides generalization bound that depends on spectral norm. \n\nThe novelty of the algorithm itself is limited, since GAN and adversarial training are both minmax problems, and the original algorithm can be carried over easily. The experimental result itself is quite comprehensive. \n\nOn the other hand, this paper provides specific generalization bounds under three adversarial attack methods, which explains the power of SN under those settings. However, it is not clear to me that these are some novel results that can better help adversarial training.\n', 'The paper first provides a generalization bounds for adversarial training, showing that the error bound depends on Lipschitz constant. This motivates the use of spectral regularization (similar to Miyato et al 2018) in adversarial training. Using spectral regularization to improve robustness is not new, but it\'s interesting to combine spectral regularization and adversarial training. Experimental results show significant improvement over vanilla adversarial training. \n\nThe paper is nicely written and the experimental results are quite strong and comprehensive. I really like the paper but I have two questions about the results: \n\n1. The numbers reported in Figure 5 do not match with the performance of adversarial training in previous paper. In PGM L_inf adversarial training/attack (column 3 of Figure 5), the prediction accuracy is roughly 50% under 0.1 infinity norm perturbation. However, previous papers (e.g., ""Obfuscated Gradients Give a False Sense of Security"") reported 55% accuracy under 0.031 infinity norm perturbation. I wonder why the numbers are so different. \n\nMaybe it\'s because of different scales? Previous works usually scale each pixel to [0,1] or [-1,1], maybe the authors use the [0, 255] scale? But 0.1/255 will be much smaller than 0.031. \n\nAnother factor might be the model structure. If Alexnet has much lower accuracy, it\'s probably worthwhile to conduct experiments on the same structure with previous works (Madry et al and Athalye et al) to make the conclusion more clear. \n\n2. What\'s the training time of the proposed method compared with vanilla adversarial training? \n\n3. The idea of using SN to improve robustness has been introduced in the following paper: \n""Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks""\n(but this paper did not combine it with adv training). \n']","[-20, 20, 70]","[60, 50, 80]","[""The sentiment score is slightly negative (-20) because while the reviewer acknowledges some positive aspects ('well set-up', 'interesting problem', 'well motivated'), they express significant concerns about the experimental results being 'weak in justifying the paper's claims'. The cons outweigh the pros in terms of detail and importance. The politeness score is moderately positive (60) as the reviewer uses respectful language throughout, acknowledging strengths before presenting criticisms, and phrases concerns as questions or suggestions rather than harsh criticisms. They also helpfully point out a typo. The tone is professional and constructive, even when pointing out weaknesses."", ""The sentiment score is slightly positive (20) because the reviewer acknowledges that the paper is well-written and has extensive experiments. They also note that the idea is natural and the experimental results are comprehensive. However, they express some reservations about the novelty of the algorithm and the clarity of the contribution to adversarial training, which prevents a higher positive score. The politeness score is moderately positive (50) as the reviewer uses respectful language throughout, acknowledging the paper's strengths while also providing constructive criticism. They avoid harsh or dismissive language, instead using phrases like 'it is not clear to me' when expressing concerns, which maintains a polite tone."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, stating 'I really like the paper' and noting that it is 'nicely written' with 'strong and comprehensive' results. However, it's not a perfect 100 as the reviewer does raise some questions and concerns. The politeness score is 80 (polite) because the reviewer uses respectful language throughout, framing their concerns as questions rather than criticisms, and begins with positive feedback. The reviewer also uses phrases like 'I wonder' and 'it's probably worthwhile,' which maintain a constructive and collegial tone. The language is consistently professional and courteous, without any harsh or rude comments.""]"
"['Overview:\n\nThis paper proposes a new approach to do unsupervised phoneme recognition by learning from unlabelled speech in combination with a trained phoneme language model. The proposed loss function is a combination of a term encouraging the language model of predicted phonemes to match the given language model distribution, and a term to encourage adjacent speech frames to be assigned to the same phoneme class. Phoneme boundaries are iteratively refined using a separate model. Experiments where a hidden Markov model is applied on top of the predicted phonemes are also performed.\n\n\nMain strengths:\n\nThe paper is clear and addresses a very important research problem. The approach and losses proposed in Section 2 have also not been proposed before, and given that an external language model is available, are very natural choices.\n\n\nMain weaknesses:\n\nThe main weakness of this paper is that it does not situate itself within the rich body of literature on this problem.  I give several references below, but I think the authors can include even more studies -- there are several studies around ""zero-resource"" speech processing, and I would encourage the authors to work through the review papers [1, 6].\n\nConcretely, I do not think the authors can claim that ""this is the first fully unsupervised speech recognition method that does not use any oracle segmentation or labels."" I think it could be argued that the system of [3] is doing this, and there are even earlier studies. I also don\'t think this claim is actually necessary since the paper has enough merit to stand on its own, as long as the related work is discussed properly.\n\nFor instance, the proposed approach shares commonalities with several other approaches: [2] also used two separate steps for acoustic modelling and boundary segmentation; [4, 7, 8] builds towards the setting where non-matching text data is available (for language model training) together with untranscribed speech for model development; the approach of [5] uses a very similar refinement step to the one described in Section 3, where an HMM model is initialised and retrained on noisy predicted labels.\n\nIn the experiments (Section 4), it would also be useful to report more fine-grained metrics. [6] gives an overview of several of the standard metrics used in this area, but at a minimum phoneme boundary recall, precision and F-scores should be reported in order to allow comparisons to other studies.\n\n\nOverall feedback:\n\nGiven that this paper is situated within the broader context of this research area, which already has a small community around it, I think the novelty in the approach is strong enough to warrant publication given that the additional metrics are reported in the experiments.\n\n\nPapers/links that should be reviewed and cited:\n\n1. E. Dunbar et al., ""The Zero Resource Speech Challenge 2017,"" in Proc. ASRU, 2017.\n2. H. Kamper, K. Livescu, and S. Goldwater. An embedded segmental k-means model for unsupervised segmentation and clustering of speech. in Proc. ASRU, 2017.\n3. Lee, C.-y. and Glass, J. R. A nonparametric Bayesian approach to acoustic model discovery. ACL, 2012.\n4. Ondel, Lucas, Lukaš Burget, Jan Černocký, and Santosh Kesiraju. ""Bayesian phonotactic language model for acoustic unit discovery."" In Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on, pp. 5750-5754. IEEE, 2017.\n5. Walter, O., Korthals, T., Haeb-Umbach, R., and Raj, B. (2013). A hierarchical system for word discovery exploiting DTW-based initialization. ASRU, 2013.\n6. M. Versteegh, X. Anguera, A. Jansen, and E. Dupoux, ""The Zero Resource Speech Challenge 2015: Proposed approaches and results,” in Proc. SLTU, 2016.\n7. https://www.clsp.jhu.edu/wp-content/uploads/sites/75/2018/05/jsalt2016-burget-building-speech-recognition.pdf\n8. https://www.clsp.jhu.edu/workshops/16-workshop/building-speech-recognition-system-from-untranscribed-data/\n\n', 'This paper proposes fully unsupervised learning algorithm for speech recognition. It involves two alternating trained component, a phoneme classifier, and a boundary refining model. The experiment results demonstrate that it achieves first success on speech recognition that approaches the supervised learning performance.  \n\nPros:\n+ The paper propose to use a frame-wise smoothing term J_FS added on J_ODM cost. In the new cost function, J_ODM controls the coarse-grained inter-segment distribution using a prepared language model P_LM, while J_FS controls the fine-grained intra-segment distribution. It is actually benefit to take use of this hierarchical 2-level scopes than only 1-level scope on evaluate the distribution mismatch in the cost function. Because otherwise, if only focus on fine-grained frame level,  much larger number of frame labels and longer N-gram have to be considered to evaluate the distribution of phoneme. Consequently, the computation can be exploding. \n+ The proposed unsupervised phoneme classification method is superior to the baseline (Liu et al., 2018) because the baseline relies on a clustering which is upper-bounded by cluster purity. Directly optimize on \\theta using an end-to-end scheme is preferred. \n+ I like the idea to use an iterative training algorithm to jointly improve classifier parameter \\theta and segment boundaries b. \n+ It is quite impressive that unsupervised learning system get close to performance of supervised system on speech recognition. The proposed system also outperforms state-of-the-art baseline with large margin. \n+ The settings of experiments are rather comprehensive. Especially the “non-matching language model”, tests the case where language model cannot directly estimated from training set.  \n\nQuestions:\n1.\tIn Appendix B you mentioned that for the N-gram you choose N=5. So the original language model P_LM can be a high-dim matrix with exactly 39^5 elements. How sparse is the original P_LM? It describes that 10000 elements are chosen, which are only 0.001%(=10000/39^5) of elements in the original one. How representative are they?\n\n2.\tI notice for the balance weight of J_FS in (3), you empirically take the best \\lambda=1e-5 during experiment. To me, the scale of optimal \\lambda is such small value maybe because the order of J_FS is improperly determined. My suggestion is, could you try using square root on the current J_FS, or using standard deviation of intra-segment outputs. The reasons are, first, minimizing std is a more interpretable penalty on diversion in a same segment; second, since you have used mean of outputs in J_ODM, then it is better to use a same dimension statistics, such as std of outputs in J_FS rather than sum of squared differences, when you combine J_ODM and J_FS in a uniform cost.\n\n3.\tWhat is the time complexity of running a comparable supervised speech recognition task with unsupervised learning method? \n\nMinor issues:\nMaybe it is a typo that the second term of Eqn (2) should be “-p_\\theta(y_(t+1)=y|x_(t+1))” instead? Since the p_\\theta is defined as posterior probability of the frame label given the corresponding input. \n', 'This paper presents a method to learn an acoustic model for phoneme recognition with only the training input acoustic features and a pretrained phoneme LM. This is done by matching the output phoneme sequence distribution of the training set with the phoneme LM distribution. The cost function is proposed by extending a previously proposed unsupervised cost function (Empirical-ODM) to the segmental level, and integrating an intra-segment cost function to encourage the frame-wise output distribution to be similar to each other within a segment. The authors conducted thorough experiments on TIMIT phoneme recognition and demonstrated impressive results.\n\nThe paper is technically sound and the presentation is generally clear. The idea is interesting and novel by extending a previous unsupervised sequence modeling approach to speech recognition and exploiting the segmental structure of the problem. Unsupervised learning is an important research topic, and its application to potentially save high cost of human labeling for developing ASR systems is important to the community.\n\nHere are a few general comments/questions:\n\n1. It would be interesting to see whether and how much using a larger acoustic training set and a phoneme LM trained on more data can close the gap between unsupervised and supervised performance. Also it would be great to see how well the learned acoustic model performs in a full ASR system together with the lexicon and LM to predict words, which could generate more accurate unsupervised transcript than the acoustic model itself for refining the model further. These could be done in future work.\n\n2. The current cost function is based on matching the N-gram distribution in the phoneme LM and that in the DNN acoustic model output of the training set, where N is relatively small. How could the framework be extended for the state-of-the-art LM and AM with RNNs where the history is arbitrarily long?\n\n3. Why can this paper just use a larger mini-batch size to alleviate the effect that SGD is intrinsically biased for the Empirical-ODM functional form, while Liu et al. 2017 needed to propose the Stochastic Primal-Dual Gradient approach?\n\n4. The paper compares the unsupervised cost function with the supervised cross-entropy function in terms of quality. How about training time? The computation looks expensive for the unsupervised case since it needs to go through all possible N-grams (which is approximated by the most frequent 10000 5-grams according to Appendix B but still a large space).\n\n5. If the segmentation quality affects the learned acoustic model quality, why not also report the segmentation accuracy for all unsupervised systems and iterations, including the Wang et al. 2017 system?\n\nMore specific comments:\n\n7. The outer summation in Eq(1) seems to indicate summing over all possible \\tau, which is infeasible. Please clarify how it is computed.\n8. Eq(5): ""p(y_t | y_1 ... y_t)"" should be ""p(y_t | y_1 ... y_{t-1})"".\n9. Why are there periodic spikes in both self-validation loss and validation FER in Figure 2(a)? What training stage do they correspond to?\n10. In Figure 2, ""validation error"" in the y-axis should probably be ""validation FER"". In Figure 2(b), the number ranges on the left and right of the y-axis were probably swapped.\n11. Section 2.5: why is Eq(1) instead of Eq(3) used for the self-validation loss?\n12. Conclusion: ""the a potential"" -> ""the potential"".']","[50, 80, 70]","[75, 70, 80]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper's strengths ('clear', 'addresses a very important research problem', 'novel approach') and recommends publication, but also points out significant weaknesses, particularly in situating the work within existing literature. The politeness score is 75 (quite polite) because the reviewer uses respectful language throughout, offers constructive criticism, and provides helpful suggestions for improvement. The reviewer balances critique with praise and uses phrases like 'I think' and 'I would encourage' to soften critical points. The tone remains professional and supportive throughout, even when pointing out flaws in the paper."", ""The sentiment score is 80 (positive) because the review begins with a summary of the paper's novel approach and its success in approaching supervised learning performance. The reviewer lists several pros, using positive language like 'superior', 'impressive', and 'comprehensive'. The questions and minor issues raised are constructive and don't detract significantly from the overall positive tone. The politeness score is 70 (polite) due to the respectful and professional tone throughout. The reviewer uses phrases like 'I like the idea' and 'My suggestion is', which are polite ways of offering feedback. The questions are posed in a neutral, inquisitive manner rather than being confrontational. The minor issues are presented as potential improvements rather than criticisms. The overall language is formal and appropriate for a scientific peer review, maintaining a courteous and constructive tone throughout."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'technically sound' and 'interesting and novel', and states that the topic is 'important to the community'. They also mention 'impressive results'. However, it's not a perfect score as the reviewer does provide several comments and questions for improvement. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, phrases criticisms as suggestions or questions (e.g. 'It would be interesting to see...', 'Why can this paper...'), and acknowledges the value of the work. The reviewer also provides detailed, constructive feedback, which is a polite way to help improve the paper.""]"
"['This work is an extension to the work of Sukbaatar et al. (2016) with two main differences:\n1) Selective communication: agents are able to decide whether they want to communicate.\n2) Individualized reward: Agents receive individual rewards; therefore, agents are aware of their contribution towards the goal.\nThese two new extensions enable their model to work in either cooperative or a mix of competitive and competitive/collaborative settings. The authors also claim these two extensions enable their model to converge faster and better. \nThe paper is well written, easy to follow, and everything has been explained quite well. The experiments are competent in the sense that the authors ran their model in four different environments (predator and prey, traffic junction, StarCraft explore, and StarCraft combat). The comparison between their model with three baselines was extensive; they reported the mean and variance over different runs. I have some concerns regarding their method and the experiments which are brought up in the following:\n \nMethod:\n\nIn a non-fully-cooperative environment, sharing hidden state entirely as the only option for communicate is not very reasonable; I think something like sending a message is a better option and  more realistic (e.g., something like the work of Mordatch & Abbeel, 2017)\n\nExperiment:\n\nThe experiment ""StarCraft explore"" is similar to predator-prey; therefore, instead of explaining StarCraft explore, I would like to see how the model works in StarCraft combat. Right now, the authors explain a bit about the model performance in Starcraft combat, but I found the explanation confusing.\n \nAuthors provide 3 baselines:\n1) no communication, but IR\n2) no communication, no IR\n3) global communication, no IR (commNet)\n\nI think having a baseline that has global communication with IR can show the effect of selective communication better. \n\nThere are some questions in the experiment section that have not been addressed very well. For example:\n Is there any difference between the results of table 1, if we look at the cooperative setup? \nDoes their model outperform a model which has global communication with IR? \nWhy do IRIC and IC work worst in the medium in comparison to hard in TJ in table1? \nWhy is CommNet work worse than IRIC and IC in table 2?', 'From a methodological perspective, this paper describes a simple bu clever learning architecture with individual agents able to decide when to communicate through a learned gating mechanism. Each agent is an LSTM able to decide at each time point which aspects of its internal state should be exposed to other agents through this gating mechanism. The presentation of this method is clear to a level that should allows the reader to implement this him/herself. It would be great if the code associated to this could be released but the presentation allows for reproducibility. \n\nThe experiments are interesting as well. Experimental results are presented on 3 problems and compared with known baselines from the academic community. The obtained results do show the merit of the approach. That being said, while the experimental results are extensive, there are places that could benefit from more clarity. For instance, I have found section 4.2 a bit dry. For instance, I had to read the plots caption and the text several times to map get at the deductions made in 4.2. Given the importance of gating in this work, I recommend expanding on this a bit (if space allows it). Small note: in the caption for Figure 3, on the fourth line, did you mean (f) instead of (d) when arguing that agents stop communicating once they reach the prey ( or am I missing something here)? Also, would it be possible to provide more insights on why IC3Net is doing better than CommNet except for the Combat-10Mv3Ze task (last table before the conclusion, what makes this task harder for IC3Net)? Another observation is on the variance terms that are reported for IC3Net. They are often (not always but definitely in the last table before the conclusion) quite higher when compared to the values associated with the baselines. Can this be explained? Another small thing: please add captions to your tables (at least a table number; I think that Table 2 does not have a caption). \n\n\nOverall, the paper is well written, interesting. Addressing the questions raised above would definitely help me and probably the eventual readers better appreciate its quality. ', 'The authors propose a new network architecture for multi-agent reinforcement learning. The new architecture addresses three issues: (1) the applicability of existing algorithms to semi-cooperative or competitive settings; (2) the ability to use local rewards during agent training; (3) the credit assignment problem with global multi-agent rewards. The authors address these issues with a new architecture that is comprised of several LSTM controllers with tied weights that transmit a continuous vector to each other, and that are augment with a gating mechanism that allows them to abstain from communicating.\n\nI think that this paper makes a solid contribution over the existing literature. My main comments are the following:\n* I feel like the paper can be strengthened by comparing to additional baselines. The authors compare mainly to Sukhbataar et al., but I think a more detailed comparison to other approaches (e.g. Foerster et al.)\n* One of the advantages of this method is that it can be used in non-cooperative settings. I am not familiar with this regime, and I would like a better explanation about why we would train competing agent with the same controller, rather than using a different controller for each team.\n* In several experimental results, the proposed method seems to have significantly higher variance than the baselines. I would like to see some discussion about why it is the case.\n* Also, in some places (e.g. Table 1), the method is highlighted in bold, even though it doesn’t actually outperform the baseline. Please correct this and only highlight the best method (if several methods are tied, either highlight them one, or don’t highlight any).\n* Also, in some cases when the error bars contain the previous best result, I am not sure if we can say that the proposed method is obviously better.']","[50, 60, 50]","[80, 80, 70]","[""The sentiment score is 50 (slightly positive) because the reviewer acknowledges the paper is well-written and easy to follow, with competent experiments. However, they also express some concerns about the method and experiments. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledging the strengths of the paper before presenting their concerns. They phrase their criticisms as suggestions or questions rather than direct attacks. The reviewer also uses phrases like 'I think' and 'I would like to see' which soften their critiques. The overall tone is constructive and professional, aiming to improve the paper rather than dismiss it."", ""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, describing it as 'interesting' and praising its 'clear' presentation and 'clever' architecture. They also note that the experimental results 'show the merit of the approach.' However, it's not extremely positive as the reviewer does point out areas for improvement and asks for clarifications. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, offering constructive feedback and suggestions rather than harsh criticisms. Phrases like 'it would be great if' and 'would definitely help me' demonstrate a collaborative and supportive tone. The reviewer also acknowledges the paper's strengths before suggesting improvements, which is a polite approach to feedback."", ""The sentiment score is 50 (moderately positive) because the reviewer states that the paper 'makes a solid contribution over the existing literature,' indicating a generally positive view. However, they also provide several critiques and suggestions for improvement, which tempers the overall positivity. The politeness score is 70 (quite polite) because the reviewer uses respectful language throughout, framing their critiques as suggestions ('I think,' 'I would like to see') rather than demands. They acknowledge the paper's contributions while offering constructive feedback. The reviewer maintains a professional tone without using overly harsh or negative language, even when pointing out areas for improvement.""]"
"['After the rebuttal:\n\n1.  Still, the novelty is limited. The authors want to tell a more motivated storyline from Nestrove-dual-average, but that does not contribute to the novelty of this paper. The real difference to the existing works is ""using soft instead of hard constraint"" for BNN. \n\n2. The convergence is a decoration. It is easy to be obtained from existing convergence proof of proximal gradient algorithms, e.g. [accelerated proximal gradient methods for nonconvex programming. NIPS. 2015].\n\n---------------------------\nThis paper proposes solving binary nets and it variants using proximal gradient descent. To motivate their method, authors connect lazy projected SGD with straight-through estimator. The connection looks interesting and the paper is well presented. However, the novelty of the submission is limited.\n\n1. My main concern is on the novelty of this paper. While authors find a good story for their method, for example,\n- A Proximal Block Coordinate Descent Algorithm for Deep Neural Network Training\n- Training Ternary Neural Networks with Exact Proximal Operator\n- Loss-aware Binarization of Deep Networks\n\nAll above papers are not mentioned in the submission. Thus, from my perspective, the real novelty of this paper is to replace the hard constraint with a soft (penalized) one (section 3.2). \n\n2. Could authors perform experiments with ImageNet?\n\n3. Could authors show the impact of lambda_t on the final performance? e.g., lambda_t = sqrt(t) lambda, lambda_t = sqrt(t^2 lambda', ""This paper proposed ProxQuant method to train neural networks with quantized weights. ProxQuant relax the quantization constraint to a continuous regularizer and then solve the optimization problem with proximal gradient method. The authors argues that previous solvers straight through estimator (STE) in BinaryConnect (Courbariaux et al. 2015) may not converge, and the proposed ProxQuant is better.\n\n I have concerns about both theoretical and experimental contributions\n\n1. The proposed regularizer for relaxing quantized constraint looks similar to BinaryRelax (Yin et al. 2018 BinaryRelax: A Relaxation Approach For Training Deep Neural Networks With Quantized Weights.), which is not cited. I hope the authors can discuss this work and clarify the novelty of the proposed method. One difference I noticed is that BinaryRelax use lazy prox-graident, while the proposed ProxQuant use non-lazy update. It is unclear which one is better.\n\n2. On page 5, the authors claim ‘’Our proposed method can be viewed as … generalization ...’’ in page 5. It seems inaccurate because unlike proposed method, BinaryConnect use lazy prox-gradient.\n\n3. What’s the purpose of equation (4)? I am confused and did not find it explained in the content.\n\n4. The proposed method introduced more hyper-parameters, like the regularizer parameter \\lambda, and the epoch to perform hard quantization. In section 4.2, it is indicated that parameter \\lambda is tuned on validation set. I have doubts about the fairness comparing with baseline BinaryConnect. Though BC does not have this parameter, we can still tune learning rate.\n\n5. ProxQuant is fine-tuned based on the pre-trained real-value weights. Is BinaryConnect also fine-tuned? For a CIFAR-10 experiments, 600 epochs are a lot for fine-tuning. As a comparison, training real-value weights usually use less than 300 epochs. BinaryConnect can be trained from scratch using same number of epochs. What does it mean to hard-quantize BinaryConnect? The weights are already quantized after projection step in BinaryConnect.  \n\n6. The authors claim there are no reported results with ResNets on CIFAR-10 for BinaryConnect, which is not true. (Li et al. 2017 Training Quantized Nets: A Deeper Understanding) report results on ResNet-56, which I encourage authors to compare with. \n\n7. What is the benefit of ProxQuant? Is it faster than BinaryConnect? If yes, please show convergence curves. Does it generate better results? Table 1 and 2 does not look convincing, especially considering the fairness of comparison.\n8. How to interpret Theorem 5.1? For example,  Li et al. 2017 show the real-value weights in BinaryConnect can converge for quadratic function, does it contradict with Theorem 5.1?\n\n9. I would suggest authors to rephrase the last two paragraphs of section 5.2. It first states ‘’one needs to travel further to find a better net’’, and then state ProxQuant find good result nearby, which is confusing. \n\n10.  The theoretical benefit of ProxQuant is only intuitively explained, it looks to me there lacks a rigorous proof to show ProxQuant will converge to a solution of the original quantization constrained problem.\n\n11. The draft is about 9 pages, which is longer than expected. Though the paper is well written and I generally enjoyed reading, I would appreciate it if the authors could shorten the content. \n\nMy main concerns are novelty of the proposed method, and fairness of experiments. \n\n\n\n\n======================= after rebuttal =======================\n\nI appreciate the authors' efforts and am generally satisfied with the revision. I raised my score. \n\nThe authors show advantage of the proposed ProxQuant over previous BinaryConnect and BinaryRelax in both theory and practice. The analysis bring insights into training quantized neural networks and should be welcomed by the community. \n\nHowever, I still have concerns about novelty and experiments.\n\n- The proposed ProxQuant is similar to BinaryRelax except for non-lazy vs. lazy updates. I personally like the theoretical analysis showing ProxQuant is better, although it is based on smooth assumptions. However, I am quite surprised BinaryRelax is so much worse than ProxQuant and BinaryConnect in practice (table 1). I would encourage the authors to give more unintuitive explanation.\n\n-  The training time is still long, and the experimental setting seems uncommon. I appreciate the authors' efforts on shortening the finetuning time, and provide more parameter tuning.  However, 200 epochs training full precision network and 300 epochs for finetuning is still a long time, consider previous works like BinaryConnect can train from scratch without a full precision warm start. In this long-training setting, the empirical advantage of ProxQuant over baselines is not much (less than 0.3% for cifar-10 in table 1, and comparable with Xu 2018 in table 2).\n\n"", ""This paper proposes a new approach to learning quantized deep neural networks, which overcome some of the drawbacks of previous methods, namely the lack of understanding of why straight-through gradient works and its optimization instability. The core of the proposal is the use of quantization-encouraging regularization, and the derivation of the corresponding proximity operators. Building on that core, the rest of the approach is reasonably standard, based on stochastic proximal gradient descent, with a homotopy scheme.\n\nThe experiments on benchmark datasets provide clear evidence that the proposed method doesn't suffer from the drawbacks of  straight-through gradient, does contributing to the state-of-the-art of this class of methods.\n\n""]","[-50, -50, 80]","[20, 50, 50]","[""The sentiment score is -50 because the reviewer expresses significant concerns about the novelty of the paper, stating it is 'limited' multiple times. They also dismiss some aspects of the work as 'decoration' or easily derived from existing work. However, they do acknowledge some positive aspects like the 'interesting' connection and 'well presented' paper, preventing an extremely negative score. The politeness score is 20 because while the reviewer is direct in their criticisms, they use relatively neutral language and offer constructive suggestions for improvement. They avoid harsh or rude phrasing, instead using professional academic language throughout. The tone is more matter-of-fact than overtly polite, hence a slightly positive but not high score."", ""The sentiment score is -50 because the reviewer expresses several concerns about both the theoretical and experimental contributions of the paper. They point out potential issues with novelty, fairness of comparisons, and the need for more rigorous proofs. However, it's not entirely negative as they acknowledge some positive aspects like the paper being well-written. The politeness score is 50 because the reviewer uses respectful language throughout, offering constructive criticism and suggestions for improvement. They use phrases like 'I hope', 'I would suggest', and 'I would appreciate', which maintain a polite tone. The reviewer also acknowledges positive aspects, such as enjoying reading the paper, which contributes to the politeness. However, the criticism is direct and substantial, preventing a higher politeness score."", ""The sentiment score is 80 (positive) because the review is generally very favorable. The reviewer praises the paper's new approach, highlighting its ability to overcome drawbacks of previous methods. They also mention that the experiments provide 'clear evidence' of the method's effectiveness and its contribution to the state-of-the-art. The politeness score is 50 (slightly positive) because while the language is professional and respectful, it doesn't contain overtly polite phrases. The reviewer presents their assessment in a straightforward, factual manner without using particularly warm or courteous language, but also without any rudeness or harsh criticism.""]"
"[""The paper considers a shortcoming of sequence to sequence models trained using maximum likelihood estimation. In particular, a model trained in this way can be biased in the sense that training sequences typically have different sets of prefixes compared to test sequences. As a result, at the prediction time the model does not generalize well and for a given input sequence the decoder constructs a label sequence which reflects the training label sequences rather than the actual target label.\n\nTo address this shortcoming, the authors propose an approach based on edit distances and the implicit use of given label sequences during training. The main idea is to generate a label sequence with respect to the current parameter vector of a conditional probabilistic model (see Eqs. 2 & 3, as well as the objective in Eq. 6) and then based on the edit distance find the best possible completions for any prefix of that model-based label sequence. The training objective is then defined in Eq. (6): to each element in the output sequence the objective assigns the KL-divergence between a conditional distribution of the next element in the label sequence given a label prefix generated using the current model and the exponential family model based on edit distances given by the prefixes and optimal completions after the position of interest in the label sequence. The objective and the corresponding gradient can be computed efficiently using dynamic programming.\n\nIntuitively, the approach tries to find a parameter vector such that the decoder at a particular instance is likely to construct a label sequence with a small edit distance to the target label. As the training objective now considers all possible elements of the vocabulary given a prefix sequence, it is reasonable to expect that it performs better than MLE which only considers target vocabulary elements given target prefix sequences (e.g., compare Eqs. 3 & 6).\n\nThe experiments were conducted on the `Wall Street Journal' and `Librispeech' datasets and the reported results are a significant improvement over the state-of-the-art. I am not an expert in the field and cannot judge the related work objectively but can say that the context for their approach is set appropriately. I would, however, prefer more clarity in the presentation of the approach. This especially applies to the presentation of the approach around Eq. (6). It might not be straightforward for a reader to figure out how the tilde-sequences are obtained. As the objective is non-convex, in order to be able to reproduce the results it would be useful to provide some heuristics for choosing the initial solutions for the parameter vector. In Section 3, please also provide a reference to the appendix so that a reader can understand the conditional probabilistic model."", 'The authors propose an alternative approach to training seq2seq models, which addresses concerns about exposure bias and about the typical MLE objective being different from the final evaluation metric. In particular, the authors propose to use a dynamic program to compute the optimal continuations of predicted prefixes (during training) in terms of edit distance to the true output, and then use a per-token cross entropy loss, with a target distribution that is uniform over all optimal next-tokens. The authors conduct a number of experiments, and show that this scheme allows them to attain state-of-the-art performance on end-to-end speech recognition, and that they can moreover do this without needing to pretrain the model with the MLE objective.\n\nThis is a very nice paper; it is generally well written, it gets excellent results, and it contains a comprehensive set of experiments and analysis. It is also quite exciting to see an approach to alleviating exposure bias that does not require pretraining with MLE. Accordingly, my suggestions mainly relate to the presentation and related work:\n\n - It seems a bit strange to argue that the proposed approach doesn\'t increase the time complexity over MLE. While technically true (as the authors note) if the vocabulary is bigger than the sequence lengths, the difference in (on policy) training time will presumably be felt when dealing with very long sequences, or with cases where the number of labels per time-step is small, like in character-level generation or in seq2seq style sequence labeling.\n\n - I think it\'s difficult to argue that the proposed approach isn\'t essentially a modification of imitation learning/learning-to-search algorithms like, say, AggreVaTe or LOLS (Chang et al., ICML 2015). As far as I can tell, the only differences are that cross entropy is used rather than a cost-sensitive classifier, and, perhaps, that the training is done in minibatches (with no aggregation).\n \n - Relatedly, while it is interesting that the loss uses all the optimal completion tokens, it should be noted that there is much work in transition-based parsing that adopts a learning-to-search approach and uses losses that incorporate multiple optimal next-predictions as given by a ""dynamic oracle""; see Goldberg and Nivre (COLING, 2012) and others.  \n\n - I think it\'s also worth noting that training approaches like MIXER and others can target arbitrary rewards (and not just those where we can efficiently compute optimal next-steps), and so the proposed approach is a compelling competitor to MIXER-like approaches on problems such as machine translation or image captioning only to the extent that training with edit-distance is useful for such problems. Do you have a sense of whether training with edit-distance does indeed improve performance on such tasks?\n\nPros:\n- well written and interesting\n- good experiments, results, and analysis\n\nCons:\n - perhaps slightly more similar to previous work than is argued\n\n\nUpdate after author response: thanks for your response; I think the revised paper largely addresses my comments and those of the other reviewers, and I continue to hope it is accepted. Here are two small notes on the related work section of the revised paper:\n- In distinguishing OCD from DAgger, you note that the optimal policy is computed rather than provided at training time. In fact, structured prediction applications of SEARN (Daume III et al., 2009, which should also be cited) and DAgger often have this flavor too, such as when using them for sequence labeling (where optimal continuations are calculated based on Hamming distance).\n- Please include a reference to Goldberg and Nivre\'s (2012) dynamic oracle work.', 'Quality and Clarity:\nThe writing is good and easy to read, and the idea is clearly demonstrated.\n\nOriginality:\nThe idea of never training over the ground-truth sequence, but training on sampled prefix and an optimized suffix is very novel. The similar idea is also related to imitation learning in other domains such as self-driving car where an oracle can give optimal instruction when exploring a new state. \n\nComments:\nThe paper proposed a very interesting training algorithm for auto-regressive models especially it does not require any MLE pre-training and can directly optimize from the sampling.\n\nHere are some questions:\n(1) The idea should also apply on many “incremental rewards”, for instance, BLEU scores in machine translation, etc. Do you have any comparison? What if the best suffix cannot be found using dynamic programming (when the evaluation metric is not edit-distance, but a sentence-level reward)?\n(2) Can the proposed algorithm be applied in other “bigger” tasks such as neural machine translation?\n(3) Eq. (6) is not very clear. Do you first sample the whole sequence, and then supervise one token for each step? Or the whole suffix?\n(4) Do you have a comparison with the learning efficiency between MLE and OCD? Will it get unstable in the beginning of training as all the samples are wrong.\n\n----------------------------\nMissing Reference:\nDing, Nan, and Radu Soricut. ""Cold-Start Reinforcement Learning with Softmax Policy Gradient."" Advances in Neural Information Processing Systems. 2017.\n\nThis paper used a very similar idea as the proposed learning method which relies on incremental rewards to find the “optimal” suffix (for instance, edit-distance is a special example). It would be better to have some discussion,\n']","[60, 70, 70]","[80, 80, 80]","[""The sentiment score is 60 (positive) because the reviewer acknowledges the paper's contribution to addressing a shortcoming in sequence-to-sequence models, describes the approach as reasonable, and mentions that the results show significant improvement over the state-of-the-art. However, it's not extremely positive as the reviewer suggests some improvements in clarity and presentation. The politeness score is 80 (quite polite) because the reviewer uses respectful language throughout, acknowledges their own limitations ('I am not an expert in the field'), and frames suggestions as preferences ('I would, however, prefer more clarity') rather than demands. The reviewer also provides constructive feedback and specific suggestions for improvement without using harsh or critical language."", ""The sentiment score is 70 (positive) because the reviewer describes the paper as 'very nice', 'well written', with 'excellent results' and 'comprehensive experiments'. They express excitement about the approach and hope for its acceptance. However, they do have some critiques and suggestions, which prevents a perfect score. The politeness score is 80 (quite polite) due to the reviewer's consistently respectful tone. They use phrases like 'It seems', 'I think', and 'perhaps' to soften criticisms, and they acknowledge the paper's strengths before offering suggestions. The reviewer also thanks the authors for their response and maintains a constructive tone throughout. The slightly lower score accounts for the direct nature of some critiques, which is expected in academic reviews."", ""The sentiment score is 70 (positive) because the reviewer expresses a generally positive view of the paper, praising its writing quality, clarity, and novelty. They describe the idea as 'very interesting' and 'very novel'. The politeness score is 80 (polite) as the reviewer uses respectful language throughout, offering constructive feedback and asking questions in a courteous manner. They acknowledge the paper's strengths before presenting their queries and suggestions. The reviewer also politely points out a missing reference, framing it as a suggestion for improvement rather than a criticism. The overall tone is professional and supportive, indicative of a positive and polite peer review.""]"
"['This paper proposes a novel approach with the hypothesis that the reliable features can guide the less reliable ones. This approach is applied to the object detection task and show consistent performance improvements.\n\npros)\n(+) This paper is well-written and easy to follow.\n(+) The base idea that divides the learned features into two sets; the reliable feature set and the less reliable one is very interesting and looks novel. Plus, the hypothesis, which is that reliable features can guide the features in the less reliable set is also interesting.\n(+) The performance improvements are quite large.\n(+) Extensive ablative studies are provided to support the proposed method well.\n\ncons)\n(-) The method of obtaining the representative in buffer B is not clearly presented.\n(-) The overall training and inference procedure are not clearly presented. \n(-) Some notations and descriptions are vague and confusing.\n(-) More than two datasets are necessary to show the effectiveness of the methods\n\ncomments)\n- What is the higher level feature map P_m? and How did you choose the higher level feature map at the m-th level in option (b) and (c) in Section 3.3.\n- What is the meaning of the ""past"" features in Section 3.2?\n- It is better to show the exact architecture of the make-up module and the critic module.\n- Can this method apply to the other backbones such as VGG or ResNets without FPN?\n- The sentences at the bottom of p.4 starting with ""Note that only~"" looks ambiguous. \n- f_critic^j may be the j-th element of F_critic, please denote what f_critic^j stands for.\n\nEven if the paper needs to be revised for better readability, I think this paper is above the standard of ICLR because the idea is interesting and novel. Furthermore, the experimental studies are properly designed and well support the main idea. I am leaning toward acceptance, but I would like to see the other reviewers\' comments.', 'OVERVIEW:\nThe authors tackle the problem of detecting small/low resolution objects in an image. Their key idea is that detecting bigger objects is an easier task and can be used to guide the detection of smaller objects. This is done using the ""Feature Intertwiner""  which consists of two branches, one for the larger objects (more reliable set that is also easier to detect) and one for the smaller objects (less reliable set). The second branch contains a make-up layer learned during training (which acts as the guidance from the more reliable set) that helps compensate details needed for detection. The authors define a class buffer that contains representative elements of object features from the reliable set for every category & scale and an intertwiner loss that computes the L2 loss between the features from the less reliable set & the class buffer. They also use an Optimal Transport procedure with a Sinkhorn divergence loss between object features from both sets. The overall loss of the system is now a sum of the detection loss, the intertwiner loss and the optimal transport loss. They evaluate their model on the COCO Object detection challenge showing state-of-the-art performance. They also provide thorough ablation analysis of various design choices. The qualitative result in Fig.1 showing well clustered features for both high & low resolution objects via t-SNE is a nice touch.\n\nCOMMENTS:\nClarity - The paper is well written and easy to follow.\nOriginality & Significance - The paper tackles an important problem and provides a novel solution. \nQuality - The paper is complete in that it tackles an important problem, provides a novel solution and demonstrates via thorough experiments the improvement achieved using their approach. \n\nQUESTIONS:\n1. The Class Buffer seems very restricted in having a single element per object category per scale to represent all features. The advantage of forcing such a representation is tight clustering in the feature space. But, wouldn\'t a dictionary approach with multiple elements give more flexibility to the model and learn a richer feature representation at the cost of not-so-good clustering ?\n2. Any comment on why you drop performance for couch ? (and baseball bat + bedroll)\n3. In Table 4 of Appendix where you compare with more object detection results, I find it interesting that Mask RCNN, updated results has a might higher AP_S (43.5) compared to you (27.2) and everyone else. I was expecting you to be the best under that metric due to the explicit design for small objects. They (MaskRCNN, updated results) are also significantly better than the rest under AP_M but worse under AP_L. Can you explain this behavior ? Is the ResNeXt backbone that much better for small objects ?\n', 'This paper aims to facilitate feature learning in NN models by exploiting more from reliable examples. This is very similar to self-paced learning where the model  learns from the easier samples at first and proceeds to learn from difficult and challenging samples. The authors should discuss their difference with self-paced learning. \n\nThe method is positioned as a general one for feature learning. I do not know the reason why the authors only apply for object detection on a very specific dataset. It is expected to see whether the proposed method is also effective for image classification. \n\nMore datasets for evaluation are needed, even only for the object detection application. ']","[60, 80, -20]","[80, 90, 20]","[""The sentiment score is 60 (positive) because the reviewer expresses a generally positive view of the paper, noting its novelty, interesting ideas, and performance improvements. They state they are 'leaning toward acceptance' despite some concerns. The politeness score is 80 (quite polite) as the reviewer uses respectful language throughout, acknowledging both pros and cons, and phrases criticisms constructively. They use phrases like 'It is better to' and 'Can this method' when making suggestions, which maintains a polite tone. The reviewer also acknowledges the paper's strengths before discussing areas for improvement, which is a polite approach to feedback."", ""The sentiment score is 80 (positive) because the reviewer provides a detailed overview of the paper's content, highlighting its strengths and contributions. They use phrases like 'well written', 'easy to follow', 'tackles an important problem', and 'provides a novel solution', indicating a very positive view of the work. The reviewer also mentions 'state-of-the-art performance' and 'thorough ablation analysis', further emphasizing the paper's quality. The politeness score is 90 (very polite) due to the reviewer's consistently respectful and constructive tone. They offer praise where due and frame their questions as genuine inquiries rather than criticisms. The language used is professional and courteous throughout, with no harsh or negative comments. The reviewer's approach of providing an overview, comments, and questions demonstrates a thoughtful and considerate review process."", ""The sentiment score is slightly negative (-20) because while the reviewer acknowledges the paper's aim and draws comparisons to existing methods, they express several concerns and suggestions for improvement. The reviewer points out the need for discussion on differences with self-paced learning, questions the limited application of the method, and requests more datasets for evaluation. These critiques indicate a somewhat negative sentiment towards the current state of the paper. The politeness score is slightly positive (20) as the reviewer uses neutral language and phrases their criticisms as suggestions or questions rather than direct criticisms. They use phrases like 'The authors should discuss...' and 'It is expected to see...' which maintain a professional and respectful tone. The review doesn't contain overtly polite language, but it also avoids any rudeness, resulting in a slightly positive politeness score.""]"
